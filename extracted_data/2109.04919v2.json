{
  "paper_id": "2109.04919v2",
  "title": "Emowoz: A Large-Scale Corpus And Labelling Scheme For Emotion Recognition In Task-Oriented Dialogue Systems",
  "published": "2021-09-10T15:00:01Z",
  "authors": [
    "Shutong Feng",
    "Nurul Lubis",
    "Christian Geishauser",
    "Hsien-chin Lin",
    "Michael Heck",
    "Carel van Niekerk",
    "Milica Gašić"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "The ability to recognise emotions lends a conversational artificial intelligence a human touch. While emotions in chit-chat dialogues have received substantial attention, emotions in task-oriented dialogues remain largely unaddressed. This is despite emotions and dialogue success having equally important roles in a natural system. Existing emotion-annotated task-oriented corpora are limited in size, label richness, and public availability, creating a bottleneck for downstream tasks. To lay a foundation for studies on emotions in task-oriented dialogues, we introduce EmoWOZ, a large-scale manually emotion-annotated corpus of task-oriented dialogues. EmoWOZ is based on MultiWOZ, a multi-domain task-oriented dialogue dataset. It contains more than 11K dialogues with more than 83K emotion annotations of user utterances. In addition to Wizard-of-Oz dialogues from MultiWOZ, we collect human-machine dialogues within the same set of domains to sufficiently cover the space of various emotions that can happen during the lifetime of a data-driven dialogue system. To the best of our knowledge, this is the first large-scale open-source corpus of its kind. We propose a novel emotion labelling scheme, which is tailored to task-oriented dialogues. We report a set of experimental results to show the usability of this corpus for emotion recognition and state tracking in task-oriented dialogues.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Incorporating human intelligence into conversational artificial intelligence (AI) has been a challenging and long-term goal  (Picard, 1997) . Emotional intelligence, defined as the ability to regulate, perceive, assimilate, and express emotions, is a key component of general intelligence  (Mayer et al., 1999) . Such emotion awareness can help the conversational AI generate more emotionally and semantically appropriate responses  (Zhou et al., 2018) . Dialogue systems generally fall into two classes. Taskoriented systems converse with users to help complete tasks determined by user goals. Chit-chat systems are set up to mimic the unstructured conversations or 'chats' characteristic of human-human interaction  (Jurafsky and Martin, 2009) . Chat-oriented systems are typically modelled in a supervised fashion with large available corpora  (Vinyals and Le, 2015) . In contrast, task-oriented systems track the user goal throughout the dialogue and a policy is typically trained via some form of reinforcement learning (RL) to conduct dialogue towards successful goal completion  (Young, 2002) . Moreover, the scope of the dialogue can also be extended during this process, e.g. by adding new domains to the dialogue system  (Madotto et al., 2021) . Consequently, the distribution of data from which a task-oriented system learns can change. Emotions appear in both chit-chat and task-oriented dialogues. However, the cause of emotion may differ as well as their role. Chit-chat dialogues are a means to express emotion. Speakers may discuss emotional ex-periences  (Li et al., 2017) , or topics that induce emotions such as news broadcasts  (Lubis et al., 2017) . In task-oriented dialogues, the user is primarily interested in achieving their goal. While an emotional situation may be a reason to interact with the system, e.g. the user just missed a flight and needs to rebook one, the emotion the user exhibits is more often a reaction to potential goal completion or failure. Since the emotion is centred around the user goal, it is more contextual and subtle. Therefore, besides inferring emotional states from dialogue utterances, an agent also needs to reason about emotion-generating situations  (Poria et al., 2021) . Substantial research efforts in emotion recognition in conversations (ERC) have been invested in chit-chat dialogues  (Majumder et al., 2019; Ghosal et al., 2020) . There are several public ERC corpora containing chitchat dialogues  (Li et al., 2017; Poria et al., 2019; Zahiri and Choi, 2018)  and conversational data from social media  (Zhou and Wang, 2018) . These corpora can tremendously accelerate the building of emotional chatbots using data-driven approaches  (Zhou et al., 2018) . In task-oriented dialogues, recognising emotions is equally important but remains largely unaddressed. Using RL to optimise a dialogue policy necessitates a feedback signal. While it is accepted that the feedback signal needs to correlate with user satisfaction  (Ultes et al., 2017) , this feedback signal is often based on hand-coded rules. Could an emotional model instead be directly used to provide such a feedback signal? Could it also be used to support emotion-aware natural language generation  (Mairesse and Walker, 2007) , or even improve dialogue state tracking through multi-task learning  (Heck et al., 2020a) ? Existing corpora are small in size, and labels are limited to sentiment polarity, creating a bottleneck, so these questions remain largely unexplored. In this work, we present EmoWOZ, a largescale manually labelled corpus for emotion in taskoriented dialogues. EmoWOZ is derived from Multi-WOZ  (Budzianowski et al., 2018) , one of the largest multi-domain corpora and the benchmark dataset for various dialogue modelling tasks, from dialogue state tracking  (Heck et al., 2020b; Lin et al., 2021)  to policy optimisation  (He et al., 2022) . We also collected and annotated human-machine dialogues as a complement. Our contributions are as follows:\n\n• We construct a corpus containing task-oriented dialogues with emotion labels, comprising more than 11K dialogues and 83K annotated user utterances. To the best of our knowledge, this is the first large-scale open-source corpus & code 1 for emotion recognition in task-oriented dialogues.\n\n• We propose a novel labelling scheme, containing 7 emotion classes, adapted from the Ortony, Clore and Collins (OCC) model  (Ortony et al., 1988) , specifically tailored to capture an array of emotions in relation to user goals in task-oriented dialogue.\n\n• We report a series of emotion recognition baseline results to show the usability of this corpus. We also empirically show that the emotion labels can be used to improve the performance of other task-oriented dialogue system modules, in this case, a dialogue state tracker (DST).",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Related Work",
      "text": "",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Emotion Models",
      "text": "Within the area of affective computing, emotion models are commonly grouped into two types: dimensional models and categorical models. Dimensional models describe emotions as a combination of values across a set of dimensions. The longest established dimensions are valence and arousal, as proposed by  Russell (1980)  in the circumplex model of emotion. Valence measures the positivity, while arousal measures the activation. Happiness, for example, is an emotion with positive valence and high activation. Additional dimensions, namely dominance and expectancy  (Fontaine et al., 2007) , have also been proposed to further describe and distinguish complex emotions.\n\nCategorical models group emotions into distinct categories. The \"Big six\" theory is one of the most wellknown theories on universal emotions. Based on studies of facial expressions,  Ekman (1992)  proposed six 1 https://doi.org/10.5281/zenodo.5865437 basic human emotions which are influenced neither by culture nor other social influences: happiness, anger, sadness, disgust, fear, surprise.  Parrott (2001)  conceptualised over a hundred emotions into a tree-structured list and identified six primary emotions from it.  Ortony et al. (1988)  proposed the Ortony, Clore and Collins (OCC) emotion model, which is explicitly developed for implementation in computers. In the OCC model, 22 emotion types are described as a valenced reaction to one of three cognitive elicitors: consequences of events, actions of agents, or aspects of objects. For example, dissatisfied is specified as disapproving of someone else's blameworthy action. These cognitive aspects are in line with the cognitive process of a computational agent, making the OCC model suitable for building emotional artificial agents. However, the use of this model for dialogue agents is not yet widespread. In a similar spirit,  Gross and Thompson (2007)  formulated the process of emotion regulation as the attention, appraisal, and response originated from various situations.\n\nAlthough there are corpora with real-valued annotation of multiple emotion dimensions  (Preot ¸iuc-Pietro et al., 2016; Buechel and Hahn, 2017) , researchers often focus on the valence dimension and annotate with discrete classes  (Socher et al., 2013) , often called sentiment polarity. Emotion datasets also consider emotions from various categorical models in the annotation scheme  (Li et al., 2017; Poria et al., 2019) , but some datasets have domain-specific labels. For instance,  Zhou and Wang (2018)  leverage common emojis in social media posts. The Topical-Chat dataset  (Gopalakrishnan et al., 2019)  introduces curious to dive deeper in addition to other basic emotions.\n\nIn this work, we propose a novel set of 7 emotions and motivate it using OCC model as the basis. We aim for this scheme to capture the cognitive context of emotions while retaining the simplicity of labels that facilitates large-scale crowd-sourcing of emotion annotations.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Emotion Dialogue Datasets",
      "text": "Early works on ERC focus on speech signals  (Cowie et al., 2001; Riccardi and Hakkani-Tür, 2005; Carrión and López-Cózar, 2008) . More recently, there are increasing number of text-based ERC datasets focusing on chit-chat dialogue. Chit-chat dialogue lends itself well to affective computing research due to its open-domain set-up, where conversation topics are diverse and not restricted to a particular task. One of the largest such corpora is DailyDialog  (Li et al., 2017) , which contains conversations between English learners on various topics ranging from relationships to money. Other similar datasets include EmoryNLP  (Zahiri and Choi, 2018)  and MELD  (Poria et al., 2019) . They contain multiparty dialogues from the TV show Friends. TV recordings in talk show format have also been utilised to collect emotion-rich and topic-specific dialogues (Lubis   et al., 2015) . Unfortunately, existing data suitable for task-oriented corpora, such as customer service chat logs, are typically not within the public domain.\n\nThere also exist a few corpora concerning the affective aspect of task-oriented dialogues.  Wang et al. (2020)  proposed a large-scale sentiment classification corpus containing customer service dialogues in Chinese. However, this dataset is not publicly available.  Saha et al. (2020)  annotated dialogues from bAbI  (Bordes et al., 2017)  with sentiment for policy optimisation. Since dialogues are machine-generated, it is unclear how well these emotions match real human emotions and whether sentiment on its own sufficiently captures emotional nuances in task-oriented dialogue. In a similar spirit,  Shi and Yu (2018)  annotated the DSTC1 dataset with user sentiment. Unfortunately, containing only 50 dialogues, the dataset is very limited in terms of coverage and application in machine learning. To summarise, existing corpora are either limited in size or not publicly available, limiting further works on emotions in task-oriented dialogue systems. Furthermore, their annotation schemes focus on sentiment polarities, overlooking the effect of goals on users' emotional states.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Dataset Construction",
      "text": "",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Task-Oriented Dialogues",
      "text": "MultiWOZ: Our dataset covers the entirety of Multi-WOZ, which was constructed using the Wizard-of-Oz framework  (Kelley, 1984) . It contains over 10k dialogues. Each dialogue was completed by two workers, each acting as the user or the operator, to achieve specified goals such as information retrieval or making reservations. There are 7 domains in total. A single dialogue or even a single turn can span multiple domains.\n\nComplementary Dialogues: We envisage emotions as learning signal for dialogue system optimisation. Since emotions in task-oriented dialogue systems can be a direct effect of the user perception of the ability of the system to fulfill their goal, the policy performance can largely influence emotion distribution. During the life span of a data-driven task-oriented dialogue system, the distributions of dialogues and emotions may change as the policy learns and improves over time. An immediate impact of such a distributional shift is the increase in the number of negative emotions due to failed dialogues during the early stages of learning. Therefore, in addition to the human wizard policy in MultiWOZ, it is important that EmoWOZ covers a variety of dialogues which represent the emotions throughout such a dialogue system life span. We complement MultiWOZ with human-machine dialogues from a machine-generated policy (DialMAGE). To elicit more genuine reactions, we let subjects directly interact with a machinegenerated policy instead of human wizards trying to make machine-like mistakes. We launched a dialogue interactive task on Amazon Mechanical Turk, where workers are asked to retrieve information by interacting with the learning policy. We start with a policy trained in a supervised fashion on MultiWOZ that achieved a task success rate of 55% when evaluated with the ConvLab-2  (Zhu et al., 2020)  rule-based user simulator. Throughout the task, the policy learned and improved as user feedback on task success is used for further training using RL. The policy reached a final human-rated success rate of 73%. Similar to  Li et al. (2020) , the policy uses a recurrent neural network (RNN) based model to produce multiple actions in a single turn, followed by the ConvLab-2 template-based NLG module for response generation.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Emotion Annotation Scheme",
      "text": "EmoWOZ focuses on user emotions rather than system ones. We believe recognising user emotions is the starting point for building emotion-aware task-oriented dialogue systems. We use the OCC model to arrive at Table  2 : Comparison between the OCC model and our labelling scheme. Emotions that do not occur in our dataset are marked as \"not applicable to our dataset\". {User, negative, impolite} has too few instances and {neutral, impolite} is not strong enough to be considered as abusive and therefore are not modelled for now. For simplicity, emotion words in blue are used to represent each emotion category. The OCC model is illustrated in Appendix A.\n\nspecific emotion categories. For that, we consider the following aspects:\n\n1. Elicitor or cause: The OCC model defines three main elicitors of emotion: events, agents, and objects.\n\nIn task-oriented dialogues, events describe the situation which brings the user to interact with the system. For example, a user may be looking for a hotel for an upcoming trip or asking for the police information after a robbery. Agents are participants of the dialogue: the user and the system. Objects are equal to entities being talked about in the dialogue, such as the recommended hotel or the nearest police station. In our dataset, an object is always associated with either the operator, who proposes it, or an event, which drives the need for it.\n\nFor this reason, we do not consider the object as an elicitor alone. On the other hand, within the agent category, it is important to distinguish between the user and the system. Therefore, we arrive at three elicitors for our annotation scheme: 1) the system, 2) the user, and 3) events (or facts).",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Valence:",
      "text": "In essence, the OCC model describes emotion as a valenced reaction towards an elicitor. Valence is a dimension which expresses the positivity or negativity of emotion. For example, successfully achieving a goal is likely to bring positive valence, while a misunderstanding with an agent is likely to cause negative valence. As EmoWOZ will demonstrate in a later section, valence is highly related to task success or failure, making it an important signal for a task-oriented system. We distinguish neutral and emotional utterances, and further separate emotional utterances into those with negative and positive valence.\n\n3. Conduct: Conduct is not a part of the OCC model, but given the rising concern of how humans behave when interacting with virtual assistants (Cercas Curry and Rieser, 2018), we decided to include it. Conduct describes the politeness of users and is usually associated with emotional acts. Politeness can indicate the degree of valence. For example, the user can express very strong dissatisfaction through rudeness. It also helps distinguish emotions such as those associ-ated with apology or abuse, which are both intrinsically negative. Considering all combinations of these three aspects for annotation leads to a large number of classes. When choosing the final set of classes we were guided by whether or not a particular emotion category occurs in the database and the potential impact of that emotion category on the dialogue policy. We also carried out several trials and considered the ease of communicating to the annotator how to label such instances. We finally arrive at a set of 6 non-neutral emotion categories: An emotion elicited by the operator is defined as satisfied if it is positive, and dissatisfied if it is negative. Positive emotion caused by an event gives us excited, and negative fearful. In terms of negative emotions expressed towards the system, we consider user conduct to distinguish between dissatisfied and abusive, since they require very different responses from the system  (Curry and Rieser, 2019) . In terms of the negative emotions that users may direct toward themselves, we single out apologetic behaviours since it features in human-human information-seeking dialogues. Emotion categories and their attributes in the abovementioned aspects and their relation to the original OCC model are shown in Table  2 .",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Emotion Annotation Setup",
      "text": "We crowd-source the emotion annotation on Amazon Mechanical Turk in a controlled manner. As suggested by  Carrión and López-Cózar (2008)  to improve the annotation quality, workers are shown the dialogue history up to the utterance they are required to label. Each emotion category is followed by a list of emotion words that best fit into the category and an explanation. Due to the high subjectivity in the emotion annotation  (Devillers et al., 2005) , each dialogue is annotated by three different workers. We also implement several measures to ensure the quality of the emotion labels:\n\nQualification tests: The test contains fifteen questions, seven are straight-forward and eight are more complex. The test also serves as a tutorial. For diffi-cult questions, hints are provided to guide the workers to identify implicit emotions and use contextual information (see Appendix B).\n\nHidden tests: We pre-label more than 1000 utterances containing obvious emotions and use them as sanity checks. The hidden tests serve as an indicator of worker reliability. If a worker scores above 80% on the hidden tests, we assume that the worker is reliable.\n\nOtherwise, the workers' submission is subject to manual review.\n\nReview for outliers: We use a simple lexicon-based recogniser and manually annotate a small batch to have an estimate of the overall emotion distribution. If the label distribution in a worker's submissions deviates substantially from our prior belief, we mark them for manual review.\n\nAnnotation limit: We limit each worker to annotate at most 500 dialogues to ensure a diversity of workers and to avoid that workers adapt to our approval policy. Overall, we had 215 workers, each annotating 160 dialogues on average.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Emowoz Characteristics",
      "text": "",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Linguistic Style",
      "text": "Dialogues from MultiWOZ and DialMAGE differ linguistically. As seen in Table  3 , DialMAGE has longer dialogues than MultiWOZ as it takes longer for the machine-generated policy to accomplish user goals. Meanwhile, users use simpler and shorter sentences when talking to a machine. Especially when the system under-performs, users are discouraged to converse with it (see sample dialogues with annotations in Appendix C). We will analyse the impact of these differences on emotion recognition in Section 5.1.3.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Emotion Distribution",
      "text": "According to Table  4 , the most common non-neutral emotion in EmoWOZ is satisfied, followed by dissatisfied. This is expected in task-oriented dialogues as users mainly express emotion in relation to their goals. While MultiWOZ contains more neutral utterances, it has a more diverse emotion distribution than DialMAGE. MultiWOZ contributes most satisfied utterances whereas DialMAGE contributes most dissatisfied utterances. This is in line with their respective dialogue-generating setup.\n\nSometimes users also express emotion to engage or provoke the operator. MultiWOZ contains more apologetic and less abusive utterances than DialMAGE, suggesting that users tend to be more polite when talking to human operators. Dialogues from MultiWOZ also contain more event-elicited emotions (fearful and excited) than DialMAGE. Users are more talkative when conversing with human operators. Users may describe a miserable situation they were experiencing, hoping to be helped and comforted. A human operator would naturally show empathy. In MultiWOZ, the operator sometimes asks if the user is alright when the user is looking for help from a robbery. When talking to machines, users tend not to express such chit-chat-style emotions due to the expected incapability of the machine to reciprocate. This indicates that an emotionally intelligent agent will allow dialogues that are emotionally richer and more nuanced, even in a task-oriented setting.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Inter-Annotator Agreement",
      "text": "We measure the inter-annotator agreement by computing Fleiss' Kappa  (Fleiss, 1971 ). Fleiss' Kappa for EmoWOZ is 0.602, suggesting a substantial agreement. Fleiss' Kappa for MultiWOZ is 0.611, higher than 0.465 for DialMAGE. Emotions in DialMAGE are more challenging to annotate because users express emotion less explicitly when they know that they are talking to a machine that does not react to emotions. Annotators often have to infer the user's implicit emotions from dialogue history, for example, based on repetitions or misunderstanding. Among all utterances, 72.1% see a full agreement among three annotators, 26.4% see a partial agreement, and 1.5% see no agreement. The count of each case in each subset can be found in Appendix D. Utterances for which no agreement is reached are resolved manually. Figure  1  illustrates the confusion matrix between annotators' labels and the golden labels. Most disagreements occur between non-neutral emotions and neutral, as well as abusive and dissatisfied. A reasonable explanation is that workers adopt different valence or impoliteness thresholds when they make decisions. Note that dissatisfied is rarely confused with abusive, but rather with neutral, suggesting that the ambiguity lies in when an expression of dissatisfaction is considered  to be rude or abusive, and not due to the similarity between abuse and dissatisfaction.\n\nOn the other hand, confusions between fearful and dissatisfied suggest workers may also interpret elicitors differently. For example, a user may express negative emotions after the agent informed that there is no attraction meeting the user's criteria. While the emotion is caused by the fact that there is no match, one can also argue that the operator failed to suggest alternative options. We believe differences on interpretations are natural to a certain extent, as emotion appraisal may differ across individuals  (Kuppens et al., 2007) .",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Experiment",
      "text": "",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Emotion Recognition In Dialogue",
      "text": "Emotion recognition aims to recognise emotion within an utterance. Unlike utterances in isolation, emotion recognition in dialogues is highly contextual with respect to the dialogue history. As baselines, we compare two models originally developed for chit-chat emotion recognition as well as various BERT-based models. We believe emotion recognition is the first step towards an emotion-aware task-oriented agent, as a means for a deployed agent to obtain emotion information during an interaction.\n\n5.1.1. Baselines BERT  (Devlin et al., 2019) : BERT is used as the utterance encoder. Each user turn is encoded in isolation without any dialogue context. The [CLS] token from a bert-base-cased model is used as the feature representation, which is then fed into a linear output layer for classification.\n\nContextBERT: The set-up is identical to that of BERT, except that the entire dialogue history and the current user utterance are concatenated in the reversed order to form one long sequence. We add \"User:\" and \"System:\" to mark the speaker of each turn.\n\nDialogueRNN  (Majumder et al., 2019) : The model combines gated recurrent units (GRUs) with an attention mechanism to capture the long-term trajectory of the dialogue. We experiment with using GloVe embeddings  (Pennington et al., 2014)  or the [CLS] representation from BERT as input features. When GloVe is used, a convolutional neural network (CNN) layer is used as a feature extractor to generate utterance representations. This CNN layer is dropped when using BERT features. COSMIC  (Ghosal et al., 2020) : This model also combines GRUs with the attention mechanism. In addition to utterance representations from a pretrained language model (LM), it supplements input features with common-sense knowledge extracted from a pre-trained commonsense transformer model called COMET  (Bosselut et al., 2019) . Although the original paper uses RoBERTa as input features, we found that BERT results in a better sequence representation for emotion recognition on our data. Therefore we use BERT as the utterance encoder in our experiments.",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "Experimental Setup",
      "text": "We perform a recognition task on the 7 emotions proposed in our annotation scheme 2  . All models are implemented in PyTorch  (Paszke et al., 2019) . For COS-MIC and DialogueRNN, we use the code provided by the respective papers. We include more details on the hyperparameters of each model in Appendix E. To split EmoWOZ into training, validation, and testing sets, we Table  6 : Performance of ContextBERT in cross-dataset experiments. We report the F1 for each emotion label (Neutral, Fearful, Dissatisfied, Apologetic, Abusive, Excited, Satisfied), as well as Macro and Weighted F1 (excluding neutral). * indicates statistically significant difference with p < 0.05 between the best and the second best values in each column. For detailed results, please refer to Appendix F.1.\n\nkeep the original split of MultiWOZ and further divide DialMAGE with a ratio of 8:1:1, leading to 9,234, 1,100, and 1,100 dialogues in each set. We run each task on 5 different seeds and report the average performance.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Results And Discussion",
      "text": "Recognition on emotion classes. Table  5  summarises the performance of baseline models. Since almost 70% of the annotations are neutral, we exclude it when calculating average F1 scores. In general, models that take into account context information perform better on the full EmoWOZ. This shows the importance of context or dialogue-level features in emotion recognition in task-oriented dialogues. An exception is DialogueRNN with GloVe feature, which underperforms in EmoWOZ macro F1, likely due to the non-contextual embedding used. On the other hand, BERT scores very well on MultiWOZ dialogues but performs poorly on DialMAGE for both setups. This suggests that emotions in MultiWOZ are less contextdependent. BERT, the only non-contextual model among our baselines, performs well for apologetic, excited, and satisfied, potentially due to the existence of distinguishable keywords associated with these emotions such as \"thank you\" for satisfied and \"sorry\" for apologetic. These emotion labels do not benefit much from context. In contrast, BERT produces a significantly worse F1 on dissatisfied, probably because users tend to express dissatisfaction more implicitly, for instance via repetition or correction, making dialogue-level features necessary.\n\nFigure  2  shows two dialogues with implicit emotions and predictions made by respective baseline models. In example 1, the system gives the wrong time of arrival, eliciting mild annoyance from the user. BERT predicts neutral because in isolation, the utterance has no words suggesting dissatisfaction. All other models correctly recognise dissatisfied, as they capture the misunderstanding occurs in previous dialogue turns. Example 2 presents a similar but more implicit case, where all models fail. This shows that EmoWOZ contains contextualised emotions that are more implicit and subtle, requiring more sophisticated features and models. Complementarity between MultiWOZ and Dial-MAGE. Due to different linguistic features and emotion distributions in MultiWOZ and DialMAGE, one concern is that the models learn to predict emotion based on these statistical artifacts. According to Table 3, the most obvious difference is the average utterance length  (5.8 in DialMAGE and 11.8 in MultiWOZ) . A naive model may simply recognise the data source from word count and predict the most likely emotion from that source. Table  7  presents how ContextBERT trained on EmoWOZ predicts emotion in long Dial-MAGE and short MultiWOZ utterances. The emotion distribution in model prediction is vastly different from that in the complementing subset. Clearly, the model does not simply count words to decide on the underlying emotion.  Recall and precision on satisfied and dissatisfied for task-oriented dialogue. We further investigate the change in F1 of each emotion on MultiWOZ by looking at the change in recall and precision after complementing MultiWOZ with DialMAGE. We believe it is necessary to distinguish recall and precision, as for some emotions, one may be more important than the other. The relative importance of recall and precision for each emotion class depends on its implication to a task-oriented dialogue system and the consequence of false recognition. Most importantly for task-oriented dialogue system, a high recall of dissatisfied is desirable because the system should not miss any failure in dialogues. Failing to recognise dissatisfaction can trigger more anger from the user and therefore impair task completion (see Figure  C .2). On the other hand, a high precision may be more desirable for all other emotions to ensure proper affective response from the system. When the relative importance of recall and precision of the emotion is taken into account, complementing Mul-tiWOZ with DialMAGE is beneficial to {dissatisfied} for higher recall and {fearful, excited, satisfied} for higher precision, see Table  8 . Detailed results can be found in Appendix F.4.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Emotions For Dialogue State Tracking",
      "text": "In task-oriented dialogues, dialogue state tracking (DST) aims to continuously track the user's goal and intent as the dialogue progresses  (Young et al., 2010) . We hypothesise that the user emotion can help inform the system about their goal. To investigate this, we train a dialogue state tracker that incorporates an additional task to predict one of 7 emotional classes on MultiWOZ 2.1  (Eric et al., 2020) . We utilise the outof-task training approach and the available code presented in  (Heck et al., 2020a) . We follow the multitask learning (MTL) algorithm, where on each training step, the same model is trained on two different batches, one from the main task (DST) and one from the auxiliary task (emotion recognition). Since neutral emotion provides limited information on the user goal, we remove a half of the neutral utterances when performing MTL. We show that additional emotion labels can lead to a significant improvement (p < 0.02) in the joint goal accuracy (JGA) of DST (see Table  9 ).",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Conclusion",
      "text": "In this work, we examined emotions and their expression in the context of task-oriented dialogues, where emotions are centred around a user goal. We used the OCC model as a starting point to derive a comprehensive annotation scheme beyond sentiment polarity for emotions in relation to user goals. We designed a set of 7 emotions that differ in terms of valence, conduct and elicitor to capture the cognitive context of emotions, while maintaining labeling simplicity. With EmoWOZ, we present a publicly available, large-scale human-annotated emotion corpus consisting of Wizard-of-Oz style as well as dialogues with a machine-generated policy.\n\nOur intention with EmoWOZ is to overcome the lack of large emotionlabelled corpora to support research towards emotionaware task-oriented dialogue systems, for dialogues closer to human-human interactions. We apply various emotion recognition models to EmoWOZ and examined the effect of context for different emotions. In cross-dataset experiments we analysed the complementarity of WOZ-style data and machine-generated policy data. Our results show that recognising context-dependent and implicit emotions from task-oriented dialogues is a challenging task that will benefit from further research. EmoWOZ provides an ideal test bed for that. Lastly, we leveraged emotion recognition in the dialogue state tracking task to exemplify the utility of emotion labels in dialogue modeling. We hope this dataset can offer insights beyond the scope of emotion recognition and push the performance of downstream tasks in task-oriented dialogue modelling. In future work, we plan to investigate tailored models for emotion recognition in task-oriented dialogues that take advantage of high-level features such as dialogue acts or belief states. We are also interested in using emotion as a feedback signal within reinforcement learning policy optimisation.",
      "page_start": 8,
      "page_end": 9
    },
    {
      "section_name": "F.2. Confusion Matrix Of Contextbert",
      "text": "",
      "page_start": 9,
      "page_end": 9
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: illustrates the confusion matrix between an-",
      "page": 5
    },
    {
      "caption": "Figure 1: Confusion matrix of emotion annotations.",
      "page": 6
    },
    {
      "caption": "Figure 2: Example dialogues and the emotion prediction for the last utterance by each model.",
      "page": 7
    },
    {
      "caption": "Figure 2: shows two dialogues with implicit emotions",
      "page": 7
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Model": "BERT",
          "Set-up": "D → D\nM → D\nE → D",
          "F1 for each Emotion Label\nNeutral\nFearful\nDissatisﬁed\nApologetic\nAbusive\nExcited\nSatisﬁed": "50.34\n72.43\n59.75\n0\n0\n12.99\n61.42\n71.57\n11.67\n100\n64.30\n1.36\n6.15\n68.85\n29.41\n69.94\n0\n41.43\n60.0\n56.01\n69.13",
          "Average F1 w/o Neutral\nMicro Macro Weighted": "52.50\n51.45\n32.86\n16.97\n42.05\n9.36\n42.66\n45.47\n43.82",
          "Average F1 w Neutral\nMicro Macro Weighted": "59.08\n36.70\n55.94\n56.94\n46.27\n43.02\n61.09\n46.56\n57.95"
        },
        {
          "Model": "",
          "Set-up": "D → M\nM → M\nE → M",
          "F1 for each Emotion Label\nNeutral\nFearful\nDissatisﬁed\nApologetic\nAbusive\nExcited\nSatisﬁed": "71.09\n0\n6.02\n0\n11.11\n15.60\n88.07\n95.34\n43.00\n40.87\n73.03\n40.45\n90.39\n19.05\n21.43\n92.67\n41.43\n27.76\n70.35\n39.98\n89.44",
          "Average F1 w/o Neutral\nMicro Macro Weighted": "62.63\n20.13\n77.16\n85.19\n51.13\n84.82\n79.79\n48.4\n83.19",
          "Average F1 w Neutral\nMicro Macro Weighted": "70.58\n27.41\n72.77\n92.57\n57.45\n92.43\n88.88\n54.72\n90.05"
        },
        {
          "Model": "",
          "Set-up": "E → E",
          "F1 for each Emotion Label\nNeutral\nFearful\nDissatisﬁed\nApologetic\nAbusive\nExcited\nSatisﬁed": "89.75\n36.17\n35.10\n70.38\n27.50\n42.89\n88.79",
          "Average F1 w/o Neutral\nMicro Macro Weighted": "73.67\n50.14\n73.55",
          "Average F1 w Neutral\nMicro Macro Weighted": "84.82\n55.80\n84.83"
        }
      ],
      "page": 16
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "ContextBERT": "",
          "D → D\nM → D\nE → D": "D → M\nM → M\nE → M",
          "75.69\n71.69\n80.16\n0\n0\n5\n58.58\n11.67\n43.71\n60.07\n72.11\n7.73\n11.87\n66.29\n81.58\n52.81\n5.00\n75.46\n40.00\n57.31\n69.23": "89.37\n0\n11.18\n0\n0\n13.86\n77.07\n95.09\n35.71\n36.35\n70.34\n19.44\n90.01\n34.05\n37.06\n93.45\n33.70\n30.39\n62.42\n17.27\n89.75",
          "73.91\n35.16\n72.85\n21.29\n33.56\n14.49\n49.97\n73.49\n73.71": "59.43\n17.02\n67.81\n84.36\n47.65\n83.87\n80.44\n45.10\n83.14",
          "77.19\n41.59\n76.81\n57.80\n39.06\n45.67\n77.89\n54.48\n77.87": "80.44\n27.35\n83.40\n92.14\n54.43\n91.98\n89.65\n52.00\n90.60"
        },
        {
          "ContextBERT": "",
          "D → D\nM → D\nE → D": "E → E",
          "75.69\n71.69\n80.16\n0\n0\n5\n58.58\n11.67\n43.71\n60.07\n72.11\n7.73\n11.87\n66.29\n81.58\n52.81\n5.00\n75.46\n40.00\n57.31\n69.23": "92.10\n30.08\n61.69\n62.36\n41.73\n40.83\n89.14",
          "73.91\n35.16\n72.85\n21.29\n33.56\n14.49\n49.97\n73.49\n73.71": "78.99\n54.30\n79.67",
          "77.19\n41.59\n76.81\n57.80\n39.06\n45.67\n77.89\n54.48\n77.87": "87.93\n59.70\n88.33"
        }
      ],
      "page": 16
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "DialogueRNN\n(GloVe)": "",
          "D → D\nM → D\nE → D": "D → M\nM → M\nE → M",
          "64.01\n40.13\n0\n0\n0\n52.05\n65.59\n67.00\n100\n0\n22.91\n0\n54.45\n55.96\n63.72\n73.57\n23.83\n0\n61.75\n60\n0": "59.78\n0\n5.34\n0\n0\n13.80\n85.57\n21.57\n21.53\n87.25\n52.16\n0\n26.21\n85.51\n88.24\n57.56\n27.92\n86.73\n13.59\n18.67\n0",
          "62.56\n62.03\n30.28\n31.03\n38.89\n26.23\n43.17\n62.06\n61.23": "50.51\n17.45\n74.87\n34.50\n72.78\n78.12\n74.04\n79.22\n34.08",
          "54.88\n50.18\n31.68\n42.90\n54.07\n48.30\n50.24\n40.41\n40.99": "55.46\n23.50\n63.96\n42.03\n82.21\n84.72\n83.41\n85.74\n41.81"
        },
        {
          "DialogueRNN\n(GloVe)": "",
          "D → D\nM → D\nE → D": "E → E",
          "64.01\n40.13\n0\n0\n0\n52.05\n65.59\n67.00\n100\n0\n22.91\n0\n54.45\n55.96\n63.72\n73.57\n23.83\n0\n61.75\n60\n0": "83.46\n12.71\n51.38\n57.67\n0\n32.75\n86.35",
          "62.56\n62.03\n30.28\n31.03\n38.89\n26.23\n43.17\n62.06\n61.23": "70.93\n40.14\n74.56",
          "54.88\n50.18\n31.68\n42.90\n54.07\n48.30\n50.24\n40.41\n40.99": "78.56\n46.33\n80.76"
        }
      ],
      "page": 16
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "DialogueRNN\n(BERT)": "",
          "D → D\nM → D\nE → D": "D → M\nM → M\nE → M",
          "68.35\n65.24\n0\n58.24\n0\n27.69\n54.51\n66.63\n0\n4.24\n43.52\n2.86\n41.48\n53.87\n61.01\n91.67\n28.14\n60.92\n49.81\n0\n66.70": "85.48\n0\n8.17\n0\n6.71\n20.48\n87.46\n92.11\n34.49\n34.83\n58.59\n0\n26.32\n87.48\n47.12\n71.22\n15.48\n33.92\n88.28\n90.54\n18.08",
          "58.45\n34.80\n57.97\n17.33\n24.33\n9.64\n60.95\n51.41\n60.56": "65.74\n20.47\n76.91\n79.18\n40.28\n80.84\n45.68\n81.52\n76.26",
          "61.95\n61.90\n39.15\n50.73\n30.37\n40.48\n51.18\n56.58\n54.74": "78.71\n29.76\n83.11\n88.13\n88.99\n47.69\n52.09\n86.10\n88.04"
        },
        {
          "DialogueRNN\n(BERT)": "",
          "D → D\nM → D\nE → D": "E → E",
          "68.35\n65.24\n0\n58.24\n0\n27.69\n54.51\n66.63\n0\n4.24\n43.52\n2.86\n41.48\n53.87\n61.01\n91.67\n28.14\n60.92\n49.81\n0\n66.70": "86.85\n41.32\n47.51\n71.48\n25.56\n39.42\n87.58",
          "58.45\n34.80\n57.97\n17.33\n24.33\n9.64\n60.95\n51.41\n60.56": "72.48\n52.15\n75.50",
          "61.95\n61.90\n39.15\n50.73\n30.37\n40.48\n51.18\n56.58\n54.74": "81.78\n57.10\n83.41"
        }
      ],
      "page": 16
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "COSMIC": "",
          "D → D\nM → D\nE → D": "D → M\nM → M\nE → M",
          "72.25\n69.34\n0\n59.68\n0\n0\n64.30\n71.56\n33.33\n2.67\n100\n15.38\n67.04\n70.80\n61.47\n100\n43.71\n69.74\n66.59\n0\n68.19": "86.68\n0\n8.78\n0\n0\n20.91\n88.90\n94.86\n40.97\n89.93\n50\n67.12\n0\n41.77\n58.18\n70.52\n0\n37.92\n92.61\n24.68\n89.10",
          "60.31\n32.71\n59.25\n19.98\n48.21\n11.03\n62.09\n57.18\n61.67": "67.85\n19.77\n78.19\n84.22\n48.30\n84.27\n79.84\n46.73\n82.74",
          "65.07\n64.71\n37.94\n57.16\n51.54\n43.79\n58.53\n64.47\n64.33": "80.32\n29.32\n84.33\n91.81\n54.95\n91.93\n88.81\n53.29\n89.88"
        },
        {
          "COSMIC": "",
          "D → D\nM → D\nE → D": "E → E",
          "72.25\n69.34\n0\n59.68\n0\n0\n64.30\n71.56\n33.33\n2.67\n100\n15.38\n67.04\n70.80\n61.47\n100\n43.71\n69.74\n66.59\n0\n68.19": "89.80\n51.98\n50.69\n70.93\n31.62\n44.42\n88.42",
          "60.31\n32.71\n59.25\n19.98\n48.21\n11.03\n62.09\n57.18\n61.67": "75.89\n56.34\n77.09",
          "65.07\n64.71\n37.94\n57.16\n51.54\n43.79\n58.53\n64.47\n64.33": "85.26\n61.12\n85.94"
        }
      ],
      "page": 16
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Model": "BERT",
          "Set-up": "D → D\nM → D\nE → D",
          "F1 for each Sentiment Label\nNeutral\nNegative\nPositive": "61.32\n72.48\n57.61\n71.70\n3.80\n68.47\n70.01\n41.73\n67.84",
          "Average F1 w/o Neutral\nMicro\nMacro Weighted": "62.45\n66.90\n62.61\n17.78\n36.13\n11.27\n46.16\n54.78\n44.74",
          "Average F1 w Neutral\nMicro\nMacro Weighted": "63.80\n59.91\n60.54\n57.39\n47.99\n43.93\n61.68\n59.86\n58.39"
        },
        {
          "Model": "",
          "Set-up": "D → M\nM → M\nE → M",
          "F1 for each Sentiment Label\nNeutral\nNegative\nPositive": "71.97\n7.77\n84.71\n95.43\n56.68\n90.05\n92.90\n44.99\n89.08",
          "Average F1 w/o Neutral\nMicro\nMacro Weighted": "56.23\n46.24\n76.94\n87.00\n73.37\n86.69\n81.99\n67.04\n84.63",
          "Average F1 w Neutral\nMicro\nMacro Weighted": "65.82\n54.82\n73.35\n93.11\n80.72\n92.99\n89.66\n75.66\n90.60"
        },
        {
          "Model": "",
          "Set-up": "E → E",
          "F1 for each Sentiment Label\nNeutral\nNegative\nPositive": "89.93\n41.96\n88.27",
          "Average F1 w/o Neutral\nMicro\nMacro Weighted": "75.74\n65.11\n75.60",
          "Average F1 w Neutral\nMicro\nMacro Weighted": "85.57\n73.39\n85.56"
        }
      ],
      "page": 17
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "ContextBERT": "",
          "D → D\nM → D\nE → D": "D → M\nM → M\nE → M",
          "76.74\n70.81\n80.67\n71.69\n6.65\n64.22\n82.91\n76.60\n65.71": "89.04\n17.89\n69.53\n95.38\n55.09\n89.89\n93.98\n51.94\n88.38",
          "76.08\n73.77\n76.05\n20.02\n35.43\n13.30\n75.25\n71.15\n75.34": "54.85\n43.71\n64.32\n86.81\n72.49\n86.38\n83.75\n70.16\n84.70",
          "76.07\n78.53\n78.55\n57.27\n47.52\n44.85\n79.48\n79.43\n75.07": "79.01\n58.82\n82.16\n93.03\n80.12\n92.88\n91.05\n78.10\n91.40"
        },
        {
          "ContextBERT": "",
          "D → D\nM → D\nE → D": "E → E",
          "76.74\n70.81\n80.67\n71.69\n6.65\n64.22\n82.91\n76.60\n65.71": "92.69\n67.98\n87.55",
          "76.08\n73.77\n76.05\n20.02\n35.43\n13.30\n75.25\n71.15\n75.34": "81.95\n77.76\n82.19",
          "76.07\n78.53\n78.55\n57.27\n47.52\n44.85\n79.48\n79.43\n75.07": "89.36\n82.74\n89.49"
        }
      ],
      "page": 17
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "DialogueRNN\n(GloVe)": "",
          "D → D\nM → D\nE → D": "D → M\nM → M\nE → M",
          "69.49\n58.50\n67.55\n68.70\n20.44\n52.21\n71.96\n42.57\n66.00": "84.93\n77.27\n10.88\n91.06\n50.36\n84.13\n90.71\n48.85\n84.21",
          "69.21\n68.52\n69.26\n29.70\n36.32\n24.11\n68.98\n66.68\n66.56": "62.22\n47.90\n77.46\n80.22\n67.25\n80.72\n79.77\n66.53\n80.64",
          "64.98\n65.18\n63.45\n55.21\n47.12\n48.21\n58.16\n60.17\n53.65": "71.38\n57.69\n77.32\n87.57\n75.19\n88.18\n87.14\n74.59\n87.91"
        },
        {
          "DialogueRNN\n(GloVe)": "",
          "D → D\nM → D\nE → D": "E → E",
          "69.49\n58.50\n67.55\n68.70\n20.44\n52.21\n71.96\n42.57\n66.00": "86.75\n61.03\n83.74",
          "69.21\n68.52\n69.26\n29.70\n36.32\n24.11\n68.98\n66.68\n66.56": "76.42\n72.39\n77.53",
          "64.98\n65.18\n63.45\n55.21\n47.12\n48.21\n58.16\n60.17\n53.65": "82.91\n77.18\n83.94"
        }
      ],
      "page": 17
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "DialogueRNN\n(BERT)": "",
          "D → D\nM → D\nE → D": "D → M\nM → M\nE → M",
          "69.53\n47.53\n65.27\n71.10\n7.04\n64.41\n65.81\n50.18\n68.63": "59.37\n8.08\n86.36\n93.75\n52.28\n88.13\n86.61\n25.98\n88.11",
          "67.40\n65.74\n65.76\n20.25\n35.72\n13.67\n66.10\n66.14\n67.22": "51.21\n47.22\n78.46\n84.27\n70.20\n84.52\n73.03\n57.04\n81.84",
          "59.05\n60.78\n55.91\n56.77\n47.52\n44.70\n60.04\n61.54\n57.52": "55.78\n51.27\n64.68\n90.94\n78.05\n91.18\n81.92\n66.90\n85.29"
        },
        {
          "DialogueRNN\n(BERT)": "",
          "D → D\nM → D\nE → D": "E → E",
          "69.53\n47.53\n65.27\n71.10\n7.04\n64.41\n65.81\n50.18\n68.63": "83.30\n47.16\n87.36",
          "67.40\n65.74\n65.76\n20.25\n35.72\n13.67\n66.10\n66.14\n67.22": "71.40\n67.26\n76.36",
          "59.05\n60.78\n55.91\n56.77\n47.52\n44.70\n60.04\n61.54\n57.52": "78.72\n72.61\n81.19"
        }
      ],
      "page": 17
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "COSMIC": "",
          "D → D\nM → D\nE → D": "D → M\nM → M\nE → M",
          "68.32\n70.52\n63.51\n71.69\n5.22\n67.57\n69.28\n57.68\n69.66": "80.31\n12.43\n86.38\n95.01\n57.85\n89.48\n91.63\n36.68\n89.32",
          "68.58\n69.42\n68.57\n18.79\n36.39\n12.42\n59.30\n63.67\n59.06": "62.62\n49.41\n78.92\n86.41\n73.67\n86.29\n79.78\n63.00\n84.01",
          "66.45\n67.45\n65.83\n57.32\n48.16\n44.45\n64.80\n65.54\n64.58": "73.66\n59.71\n79.92\n92.58\n80.78\n92.58\n87.99\n72.54\n89.51"
        },
        {
          "COSMIC": "",
          "D → D\nM → D\nE → D": "E → E",
          "68.32\n70.52\n63.51\n71.69\n5.22\n67.57\n69.28\n57.68\n69.66": "88.97\n48.15\n88.55",
          "68.58\n69.42\n68.57\n18.79\n36.39\n12.42\n59.30\n63.67\n59.06": "75.66\n68.35\n77.5",
          "66.45\n67.45\n65.83\n57.32\n48.16\n44.45\n64.80\n65.54\n64.58": "84.6\n75.22\n85.47"
        }
      ],
      "page": 17
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Learning end-to-end goal-oriented dialog",
      "authors": [
        "A Bibliographical References Bordes",
        "Y.-L Boureau",
        "J Weston"
      ],
      "year": "2017",
      "venue": "Learning end-to-end goal-oriented dialog"
    },
    {
      "citation_id": "2",
      "title": "COMET: Commonsense transformers for automatic knowledge graph construction",
      "authors": [
        "A Bosselut",
        "H Rashkin",
        "M Sap",
        "C Malaviya",
        "A Celikyilmaz",
        "Y Choi"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "3",
      "title": "MultiWOZ -a large-scale multi-domain Wizard-of-Oz dataset for task-oriented dialogue modelling",
      "authors": [
        "P Budzianowski",
        "T.-H Wen",
        "B.-H Tseng",
        "I Casanueva",
        "S Ultes",
        "O Ramadan",
        "M Gašić"
      ],
      "year": "2018",
      "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "4",
      "title": "EmoBank: Studying the impact of annotation perspective and representation format on dimensional emotion analysis",
      "authors": [
        "S Buechel",
        "U Hahn"
      ],
      "year": "2017",
      "venue": "Proceedings of the 15th Conference of the European Chapter"
    },
    {
      "citation_id": "5",
      "title": "Influence of contextual information in emotion annotation for spoken dialogue systems",
      "authors": [
        "Z Carrión",
        "R López-Cózar"
      ],
      "year": "2008",
      "venue": "Speech Commun"
    },
    {
      "citation_id": "6",
      "title": "#MeToo Alexa: How conversational systems respond to sexual harassment",
      "authors": [
        "A Cercas Curry",
        "V Rieser"
      ],
      "year": "2018",
      "venue": "Proceedings of the Second ACL Workshop on Ethics in Natural Language Processing"
    },
    {
      "citation_id": "7",
      "title": "Emotion recognition in human-computer interaction",
      "authors": [
        "R Cowie",
        "E Douglas-Cowie",
        "N Tsapatsoulis",
        "G Votsis",
        "S Kollias",
        "W Fellenz",
        "J Taylor"
      ],
      "year": "2001",
      "venue": "IEEE Signal Processing Magazine"
    },
    {
      "citation_id": "8",
      "title": "A crowd-based evaluation of abuse response strategies in conversational agents",
      "authors": [
        "A Curry",
        "V Rieser"
      ],
      "year": "2019",
      "venue": "Proceedings of the 20th Annual SIGdial Meeting on Discourse and Dialogue"
    },
    {
      "citation_id": "9",
      "title": "Challenges in real-life emotion annotation and machine learning based detection",
      "authors": [
        "L Devillers",
        "L Vidrascu",
        "L Lamel"
      ],
      "year": "2005",
      "venue": "Neural networks : the official journal of the International Neural Network Society"
    },
    {
      "citation_id": "10",
      "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "authors": [
        "J Devlin",
        "M.-W Chang",
        "K Lee",
        "K Toutanova"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computa-tional Linguistics: Human Language Technologies"
    },
    {
      "citation_id": "11",
      "title": "An argument for basic emotions",
      "authors": [
        "P Ekman"
      ],
      "year": "1992",
      "venue": "Cognition and Emotion"
    },
    {
      "citation_id": "12",
      "title": "MultiWOZ 2.1: A consolidated multi-domain dialogue dataset with state corrections and state tracking baselines",
      "authors": [
        "M Eric",
        "R Goel",
        "S Paul",
        "A Sethi",
        "S Agarwal",
        "S Gao",
        "A Kumar",
        "A Goyal",
        "P Ku",
        "D Hakkani-Tur"
      ],
      "year": "2020",
      "venue": "Proceedings of the 12th Language Resources and Evaluation Conference"
    },
    {
      "citation_id": "13",
      "title": "Measuring nominal scale agreement among many raters",
      "authors": [
        "J Fleiss"
      ],
      "year": "1971",
      "venue": "Psychological bulletin"
    },
    {
      "citation_id": "14",
      "title": "The world of emotions is not two-dimensional",
      "authors": [
        "J Fontaine",
        "K Scherer",
        "E Roesch",
        "P Ellsworth"
      ],
      "year": "2007",
      "venue": "Psychological science"
    },
    {
      "citation_id": "15",
      "title": "COSMIC: COmmonSense knowledge for eMotion identification in conversations",
      "authors": [
        "D Ghosal",
        "N Majumder",
        "A Gelbukh",
        "R Mihalcea",
        "S Poria"
      ],
      "year": "2020",
      "venue": "Findings of the Association for Computational Linguistics: EMNLP 2020"
    },
    {
      "citation_id": "16",
      "title": "Topical-Chat: Towards Knowledge-Grounded Open-Domain Conversations",
      "authors": [
        "K Gopalakrishnan",
        "B Hedayatnia",
        "Q Chen",
        "A Gottardi",
        "S Kwatra",
        "A Venkatesh",
        "R Gabriel",
        "D Hakkani-Tür"
      ],
      "year": "2019",
      "venue": "Proc. Interspeech"
    },
    {
      "citation_id": "17",
      "title": "Emotion regulation: Conceptual foundations. Handbook of Emotion Regulation",
      "authors": [
        "J Gross",
        "R Thompson"
      ],
      "year": "2007",
      "venue": "Emotion regulation: Conceptual foundations. Handbook of Emotion Regulation"
    },
    {
      "citation_id": "18",
      "title": "Galaxy: A generative pre-trained model for taskoriented dialog with semi-supervised learning and explicit policy injection",
      "authors": [
        "W He",
        "Y Dai",
        "Y Zheng",
        "Y Wu",
        "Z Cao",
        "D Liu",
        "P Jiang",
        "M Yang",
        "F Huang",
        "L Si"
      ],
      "year": "2022",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence"
    },
    {
      "citation_id": "19",
      "title": "Outof-task training for dialog state tracking models",
      "authors": [
        "M Heck",
        "C Geishauser",
        "H.-C Lin",
        "N Lubis",
        "M Moresi",
        "C Van Niekerk",
        "M Gasic"
      ],
      "year": "2020",
      "venue": "Proceedings of the 28th International Conference on Computational Linguistics"
    },
    {
      "citation_id": "20",
      "title": "TripPy: A triple copy strategy for value independent neural dialog state tracking",
      "authors": [
        "M Heck",
        "C Van Niekerk",
        "N Lubis",
        "C Geishauser",
        "H.-C Lin",
        "M Moresi",
        "M Gasic"
      ],
      "year": "2020",
      "venue": "Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue"
    },
    {
      "citation_id": "21",
      "title": "Speech and Language Processing",
      "authors": [
        "D Jurafsky",
        "J Martin"
      ],
      "year": "2009",
      "venue": "Speech and Language Processing"
    },
    {
      "citation_id": "22",
      "title": "An iterative design methodology for user-friendly natural language office information applications",
      "authors": [
        "J Kelley"
      ],
      "year": "1984",
      "venue": "ACM Trans. Inf. Syst"
    },
    {
      "citation_id": "23",
      "title": "Individual differences in patterns of appraisal and anger experience",
      "authors": [
        "P Kuppens",
        "I Van Mechelen",
        "D Smits",
        "P De Boeck",
        "E Ceulemans"
      ],
      "year": "2007",
      "venue": "Cognition and Emotion"
    },
    {
      "citation_id": "24",
      "title": "DailyDialog: A manually labelled multiturn dialogue dataset",
      "authors": [
        "Y Li",
        "H Su",
        "X Shen",
        "W Li",
        "Z Cao",
        "S Niu"
      ],
      "year": "2017",
      "venue": "Proceedings of the Eighth International Joint Conference on Natural Language Processing"
    },
    {
      "citation_id": "25",
      "title": "Rethinking supervised learning and reinforcement learning in task-oriented dialogue systems",
      "authors": [
        "Z Li",
        "J Kiseleva",
        "M De Rijke"
      ],
      "year": "2020",
      "venue": "Findings of the Association for Computational Linguistics: EMNLP 2020"
    },
    {
      "citation_id": "26",
      "title": "Knowledge-aware graph-enhanced GPT-2 for dialogue state tracking",
      "authors": [
        "W Lin",
        "B.-H Tseng",
        "B Byrne"
      ],
      "year": "2021",
      "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "27",
      "title": "Construction and analysis of social-affective interaction corpus in english and indonesian",
      "authors": [
        "N Lubis",
        "S Sakti",
        "G Neubig",
        "T Toda",
        "S Nakamura"
      ],
      "year": "2015",
      "venue": "2015 International Conference Oriental COCOSDA held jointly with 2015 Conference on Asian Spoken Language Research and Evaluation"
    },
    {
      "citation_id": "28",
      "title": "Processing negative emotions through social communication: Multimodal database construction and analysis",
      "authors": [
        "N Lubis",
        "M Heck",
        "S Sakti",
        "K Yoshino",
        "S Nakamura"
      ],
      "year": "2017",
      "venue": "Seventh International Conference on Affective Computing and Intelligent Interaction (ACII)"
    },
    {
      "citation_id": "29",
      "title": "Continual learning in task-oriented dialogue systems",
      "authors": [
        "A Madotto",
        "Z Lin",
        "Z Zhou",
        "S Moon",
        "P Crook",
        "B Liu",
        "Z Yu",
        "E Cho",
        "P Fung",
        "Z Wang"
      ],
      "year": "2021",
      "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "30",
      "title": "PERSONAGE: Personality generation for dialogue",
      "authors": [
        "F Mairesse",
        "M Walker"
      ],
      "year": "2007",
      "venue": "Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics"
    },
    {
      "citation_id": "31",
      "title": "Dialoguernn: An attentive rnn for emotion detection in conversations",
      "authors": [
        "N Majumder",
        "S Poria",
        "D Hazarika",
        "R Mihalcea",
        "A Gelbukh",
        "E Cambria"
      ],
      "year": "2019",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence"
    },
    {
      "citation_id": "32",
      "title": "Emotional intelligence meets traditional standards for an intelligence",
      "authors": [
        "J Mayer",
        "D Caruso",
        "P Salovey"
      ],
      "year": "1999",
      "venue": "Intelligence"
    },
    {
      "citation_id": "33",
      "title": "The Cognitive Structure of Emotions",
      "authors": [
        "A Ortony",
        "G Clore",
        "A Collins"
      ],
      "year": "1988",
      "venue": "The Cognitive Structure of Emotions"
    },
    {
      "citation_id": "34",
      "title": "Emotions in social psychology: essential readings. Key readings in social psychology",
      "authors": [
        "W Parrott"
      ],
      "year": "2001",
      "venue": "Emotions in social psychology: essential readings. Key readings in social psychology"
    },
    {
      "citation_id": "35",
      "title": "PyTorch: An imperative style, high-performance deep learning library",
      "authors": [
        "A Paszke",
        "S Gross",
        "F Massa",
        "A Lerer",
        "J Bradbury",
        "G Chanan",
        "T Killeen",
        "Z Lin",
        "N Gimelshein",
        "L Antiga",
        "A Desmaison",
        "A Kopf",
        "E Yang",
        "Z De-Vito",
        "M Raison",
        "A Tejani",
        "S Chilamkurthy",
        "B Steiner",
        "L Fang",
        "J Bai",
        "S Chintala"
      ],
      "year": "2019",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "36",
      "title": "GloVe: Global vectors for word representation",
      "authors": [
        "J Pennington",
        "R Socher",
        "C Manning"
      ],
      "year": "2014",
      "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)"
    },
    {
      "citation_id": "37",
      "title": "Affective Computing",
      "authors": [
        "R Picard"
      ],
      "year": "1997",
      "venue": "Affective Computing"
    },
    {
      "citation_id": "38",
      "title": "MELD: A multimodal multi-party dataset for emotion recognition in conversations",
      "authors": [
        "S Poria",
        "D Hazarika",
        "N Majumder",
        "G Naik",
        "E Cambria",
        "R Mihalcea"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "39",
      "title": "Modelling valence and arousal in Facebook posts",
      "authors": [
        "S Poria",
        "N Majumder",
        "D Hazarika",
        "D Ghosal",
        "R Bhardwaj",
        "S Jian",
        "P Hong",
        "R Ghosh",
        "A Roy",
        "N Chhaya",
        "A Gelbukh",
        "R Mihalcea",
        "D Pietro",
        "H Schwartz",
        "G Park",
        "J Eichstaedt",
        "M Kern",
        "L Ungar",
        "E Shulman"
      ],
      "year": "2016",
      "venue": "Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis"
    },
    {
      "citation_id": "40",
      "title": "Grounding emotions in human-machine conversational systems",
      "authors": [
        "G Riccardi",
        "D Hakkani-Tür"
      ],
      "year": "2005",
      "venue": "Grounding emotions in human-machine conversational systems"
    },
    {
      "citation_id": "41",
      "title": "A circumplex model of affect",
      "authors": [
        "J Russell"
      ],
      "year": "1980",
      "venue": "Journal of personality and social psychology"
    },
    {
      "citation_id": "42",
      "title": "Towards sentiment aided dialogue policy learning for multi-intent conversations using hierarchical reinforcement learning",
      "authors": [
        "T Saha",
        "S Saha",
        "P Bhattacharyya"
      ],
      "year": "2020",
      "venue": "PLOS ONE"
    },
    {
      "citation_id": "43",
      "title": "Sentiment adaptive end-toend dialog systems",
      "authors": [
        "W Shi",
        "Z Yu"
      ],
      "year": "2018",
      "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "44",
      "title": "Recursive deep models for semantic compositionality over a sentiment treebank",
      "authors": [
        "R Socher",
        "A Perelygin",
        "J Wu",
        "J Chuang",
        "C Manning",
        "A Ng",
        "C Potts"
      ],
      "year": "2013",
      "venue": "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "45",
      "title": "Domainindependent user satisfaction reward estimation for dialogue policy learning",
      "authors": [
        "S Ultes",
        "P Budzianowski",
        "I Casanueva",
        "N Mrksic",
        "L Rojas-Barahona",
        "P Hao Su",
        "T.-H Wen",
        "M Gašić",
        "S Young"
      ],
      "year": "2017",
      "venue": "Domainindependent user satisfaction reward estimation for dialogue policy learning"
    },
    {
      "citation_id": "46",
      "title": "A neural conversational model. ICML Deep Learning Workshop",
      "authors": [
        "O Vinyals",
        "Q Le"
      ],
      "year": "2015",
      "venue": "A neural conversational model. ICML Deep Learning Workshop"
    },
    {
      "citation_id": "47",
      "title": "Sentiment classification in customer service dialogue with topic-aware multi-task learning",
      "authors": [
        "J Wang",
        "J Wang",
        "C Sun",
        "S Li",
        "X Liu",
        "L Si",
        "M Zhang",
        "G Zhou"
      ],
      "year": "2020",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence"
    },
    {
      "citation_id": "48",
      "title": "The hidden information state model: A practical framework for POMDP-based spoken dialogue management",
      "authors": [
        "S Young",
        "M Gašić",
        "S Keizer",
        "F Mairesse",
        "J Schatzmann",
        "B Thomson",
        "K Yu"
      ],
      "year": "2010",
      "venue": "Computer Speech & Language"
    },
    {
      "citation_id": "49",
      "title": "Talking to machines (statistically speaking)",
      "authors": [
        "S Young"
      ],
      "year": "2002",
      "venue": "Seventh International Conference on Spoken Language Processing"
    },
    {
      "citation_id": "50",
      "title": "Emotion Detection on TV Show Transcripts with Sequence-based Convolutional Neural Networks",
      "authors": [
        "S Zahiri",
        "J Choi"
      ],
      "year": "2018",
      "venue": "Proceedings of the AAAI Workshop on Affective Content Analysis, AF-FCON'18"
    },
    {
      "citation_id": "51",
      "title": "MojiTalk: Generating emotional responses at scale",
      "authors": [
        "X Zhou",
        "W Wang"
      ],
      "year": "2018",
      "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "52",
      "title": "Emotional chatting machine: Emotional conversation generation with internal and external memory",
      "authors": [
        "H Zhou",
        "M Huang",
        "T Zhang",
        "X Zhu",
        "B Liu"
      ],
      "year": "2018",
      "venue": "Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence and Thirtieth Innovative Applications of Artificial Intelligence Conference and Eighth AAAI Symposium on Educational Advances in Artificial Intelligence"
    },
    {
      "citation_id": "53",
      "title": "ConvLab-2: An open-source toolkit for building, evaluating, and diagnosing dialogue systems",
      "authors": [
        "Q Zhu",
        "Z Zhang",
        "Y Fang",
        "X Li",
        "R Takanobu",
        "J Li",
        "B Peng",
        "J Gao",
        "X Zhu",
        "M Huang"
      ],
      "year": "2020",
      "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, ACL 2020"
    }
  ]
}