{
  "paper_id": "2112.12455v1",
  "title": "Your Face Mirrors Your Deepest Beliefs-Predicting Personality A N D Morals Through Facial Emotion Recognition",
  "published": "2021-12-23T10:46:51Z",
  "authors": [
    "P. A. Gloor",
    "A. Fronzetti Colladon",
    "E. Altuntas",
    "C. Cetinkaya",
    "M. F. Kaiser",
    "L. Ripperger",
    "T. Schaefer"
  ],
  "keywords": [
    "artificial intelligence",
    "facial emotion recognition",
    "personality",
    "moral values",
    "risk-taking",
    "forecasting"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "This article is a n open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https:/ / creativecommonsorg / licenses / b y / 4.0 / ).",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "I N T R O D U C T I O N",
      "text": "A face is like the outside of a house, a n d most faces, like most houses, give us a n idea of what we can expect to find inside. ~ Loretta Young\n\nThe face is the mirror of the mind, a n d eyes without speaking confess the secrets of the heart. ~ St. ]erome Proverbs like the ones above allude to the fact that our faces have the potential to give away our deepest emotions. However, just like the f a c a d e of a house might be misleading about what is inside the house, the mind behind the face might hide its true feelings. Emotionally competent people claim to be able to guess what another person is thinking by just watching that person's face. However, humans are not particularly good a t reading emotions in other's faces. For instance, the test \"reading the mind in the eyes\"  [1] , which only shows the eyes of a face, is frequently answered correctly with a n accuracy of less than fifty percent. Psychologist Lisa Feldmann Barrett claims that we are actually not much better than randomness when we are not primed in reading others' emotions  [2] . Humans are also notoriously bad a t identifying personality characteristics in others  [3] . While early systems to read emotions f r o m the face were extracting features f r o m different F u t u r e Internet 2022, 14, 5. https: / / doi.org / 10.3390 / fi14010005 https: / / www.mdpi.com / journal / futureinternet F u t u r e Internet 2022, 14, 5 2 0 f 1 8 parts of the face, and comparing them directly, f o r instance on the basis of the facial action coding system FACS [4], facial emotion recognition has made huge progress over the last 10 years thanks to advances in AI and deep learning  [5] [6] [7] . In this paper, we used latest advances in this field to automatically predict personality characteristics calibrated using f o u r well-established frameworks assessing different facets of personality: Neo-FFI [8],\n\nmoral foundations [9], Schwartz moral values [10], a n d attitudes towards taking risk  [11] .\n\nThe remainder of this paper is organized as follows. First, we set the stage by explaining how the emotional response to a n external event can demonstrate the moral values of a n individual. We also motivate how facial expressions might indicate the personality characteristics of a person. We then introduce our system that tracks emotions through facial emotion recognition while the viewer is watching a video, with 15 small emotionally triggering video snippets. We then present our results, demonstrating through correlations, regression, and machine learning that the emotional response in the f a c e of the viewer, captured through face emotion recognition, will indeed predict the personality and moral values of the viewer. We conclude the paper with a discussion of the results, limitations, and f u t u r e work.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "2. Background",
      "text": "",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "2.1. Emotional Response Shows Individual Value System",
      "text": "On the basis of their moral values, humans experience o r show different emotions in response to a n external stimulus. Emotional actions triggered through moral values are called \"moral a f f e c t \"  [12] . Moral affect-such as shame, guilt, and embarrassment-is linked to moral behavior, leading to prohibitions against behavior that is likely to have negative consequences f o r the well-being of others  [13] . For instance, on the basis of the personal value system, an individual might have shown a different emotional reaction when President Trump was announcing the construction of a wall to keep out asylum seekers f r o m Mexico  [14] . Both philosophers [14] and psychologists  [2]  have investigated this link between morals and emotions. In order to experience that something is wrong, one needs to have a feeling of disapproval towards it  [14] . To measure this feeling of disapproval, thus far, technologies such as tracking the hormone level in blood o r saliva have been used. For instance, it has been shown that the hormone level in saliva of homosexual and heterosexual men, when shown pictures of t w o men kissing, is radically different  [15] . The researchers showed homosexual and heterosexual men in Utah pictures of same-sex public display of affection, plus disgusting images, such as a bucket of maggots. They used the link between disgust and prejudice, which has been shown to be capable of eliciting responses f r o m the sympathetic nervous system, one of the body's major stress systems  [16] . Salivary alpha-amylase is considered a biomarker of the sympathetic nervous system that is especially responsive to inductions of disgust. The researchers f o u n d that the difference in salivary alpha-amylase explained the degree of sexual prejudice against homosexuality among their test subjects, similar to their disgust about a bucket of maggots. In other words, their emotional response, measured through salivary alpha-amylase, indicated their moral values. Instead of measuring negative (and positive) emotions through the saliva, in o u r research, we measured it through face emotion recognition, maintaining the existence of a similar link between emotional response and moral values.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Reading Personality Attributes From Facial Characteristics",
      "text": "Studying the relationship between facial and personality characteristics has a long history going back to antiquity. The book \"Physiognomics\", discussing the relationship between facial appearance and character, was written 300 BC in Aristotle's name, b u t is today attributed t o a different author b y most researchers. Swiss poet, writer, philosopher, physiognomist, and theologian Johann Caspar Lavater published between 1775 and 1778 his magnum opus on physiognomy, \"Physiognomische Fragmente z n r Befb'rderung der Menschenkenntnis a n d Menschenliebe\" (Physiognomic fragments to promote knowledge of human nature and human love)  [17] , which cataloged leaders and ordinary men (there were very f e w pictures of women) of his time by their facial shape, or what he called their \"lines of countenance\". Lavater even invented an apparatus f o r taking facial silhouettes to quickly capture the characteristics of a face, and thus the personality of the person.\n\nLater, statistician Francis Galton tried to define physiognomic characteristics of health, beauty, and criminology by creating composites through overlaying pictures of archetypical faces [18]. Italian criminologist and scientist Cesare Lombroso continued this work by defining facial measures of degeneracy and insanity including facial angles, \"abnormalities\" in bone structure, and volumes of brain fluid [19]. For the better p a r t of the 20th century, scientists derogatively titled physiognomics as \"pseudoscience\". This changed towards the end of the 20th century. While early physiognomists f r o m Aristotle to Lombroso tried to develop manually assembled frameworks, AI and deep learning has given a huge boost to this emerging field. Recently, physiognomics has been experiencing renewed interest by researchers, particularly by comparing facial width to height ratio with personality. The theory of \"facial width to height ratio\" (fW HR) posits that men with higher \"facial width t o height ratio\", that means with broader, rounder faces, are more aggressive, while men with thinner faces are more trustworthy [20-23].\n\nRecognizing these features automatically through facial emotion recognition has come a long way since the early days of the facial action coding system, thanks to recent advances in Al and deep learning. A large amount of research has addressed the issue of recognizing personality characteristics f r o m facial attributes. For instance, ChaLearn \"Looking a t People First Impression Challenge\" released a dataset with 10,000 15 5 videos with faces (https: / / chalearnlap.cvc.uab.cat / dataset / 20 / description / , accessed on 21 December 2021) [24], asking participants in the challenge to identify the FFI personality characteristics [8] of the person on the video, and their age, ethnicity, and gender attributes  [25] . The problem with this dataset is that the personality attributes had been added by Amazon Mechanical Turkers, which sometimes leads to a biased ground truth, as it is based on guesswork by humans (the turkers). As was mentioned in the introduction, it has been shown by other researchers that accuracy of human labelers in recognizing emotions is only incrementally better than guesswork a t slightly below 50 percent [2]. Nevertheless, the winners of the ChaLearn challenge have achieved impressive accuracy on this pre-labeled dataset to correctly predict the FFI personality characteristics a t over 91% [26]. However, it would be better to have true ground truth on the personality characteristics of the subjects on the video. In another project using Facebook likes, where ground truth was available, the researchers showed that the computer was actually better in recognizing personality characteristics than work colleagues, who reached only 27% accuracy, while the computer achieved 56% accuracy [3] ; spouses were the most accurate a t 58%. The personality characteristics had been collected f r o m 86,220 users through a personality survey on Facebook and were predicted through Facebook likes using regression.\n\nEarlier work has used facial expression of the viewer to measure the quality of a video [27-29]. We extend this work to not only measure the degree of enjoyment of the viewer, but the personality characteristics and moral values of the viewer-motivated b y the insight that facial expressions will mirror moral values-combining f a c e emotion recognition with ground truth obtained directly f r o m surveys taken by the individual.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Methodology-Recording Emotions While Watching Videos",
      "text": "Our approach extends existing systems by not only measuring video quality, but moral values and personality of the viewers, as it uses real ground t r u t h on personality characteristics and moral values f o r prediction by asking the people whose faces are recorded while watching a sequence of 15 emotionally touching video segments to also fill out a series of personality characteristics tests.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Measuring Facial Emotions",
      "text": "Our system consists of a website (coinproject.compel.ch, accessed on 21 December 2021) where the participant watches a sequence of 15 videos (Figure  1 ).  Table  1  lists the 15 movie snippets, at a total length of 9 min 22 s, that are shown to users on the website, while the emotions of their faces are recorded after they have given informed consent that their anonymized emotions will be recorded; no video of the face is recorded.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Video Number",
      "text": "Short Description puppies-cute puppies running avocado-a toddler holding an avocado condom ad-child throwing a tantrum in a supermarket runner-competitive runners supporting a girl from another team over the finish line maggot-a guy eating a maggot soldier-soldiers at battle Trump-Donald Trump talking about the Mexican mass migration mountain bike-mountain biker on daring ride down a rock bridge roof bike-guy biking on top of a skyscraper roof run-guy balancing and almost falling on top of skyscraper racoon-man beating racoon to death abandoned-social worker feeding a starved abandoned black toddler waste-residents collecting electronic waste in the slums of Accra dog-sad dog on the gravestone of his master, missing him monster-man discovering an invisible monster through the picture on his instant camera\n\nThe 15 video snippets show controversial scenes with the aim of generating a wide range of emotions in respondents  [30] . We use the face-api.js tool (httpsz/ /justadudewhohacks. githubio / face-api.js / docs / indexhtml, accessed on 21 December 2021), which employs a convolutional neural network with a ResNet-34 architecture  [31] , to recognize the user '5 facial emotions in each frame (up to 30 times per second) of the user '5 web cam. The tracked emotions are joy, sadness, anger, fear, surprise, and disgust [32]. In addition, a seventh emotion \"neutral\" was added, which greatly increases machine learning accuracy when none of the six Ekman emotions can be recognized.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Measuring Personality And Morals 0F The Viewers",
      "text": "Our dependent variables are collected through four well-validated personality and moral values assessments. The user is asked on the same website where the videos are shown to fill out four online surveys for the revised NEO FFI personality inventory, the Haidt moral foundations test, the Schwartz personal value system, and the domain-specific risk-taking scale (DOSPERT). The OCEAN (Openness, Conscientiousness, Extroversion, Agreeability, Neuroticism) personality characteristics are measured with the Neo-FFI [8] survey. Risk-preference is measured by the Domain-Specific Risk-Taking (DOSPERT) survey  [11] , which assesses disposition to take risks in five specific domains of life  (ethical, financial, recreational, health, and social)",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": ". It Measures Both The Willingness To Take Risks And The Individual Perception Of An Activity As Risky. Moral Foundational Values Are Measured With The Haidt Moral Foundations Survey [9]. It Measures The Moral Values Of The Respondent",
      "text": "in five categories  (care, fairness, loyalty, authority, and sanctity) . In addition, the two dimensions of Conservation and Transcendence also are assessed through a survey  [10, 33] .\n\nThe Schwartz values have been validated in many countries around the world  [34] .",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Results-Emotional Response Predicted Values",
      "text": "We found that all four dimension of a personality, FFI characteristics, DOSPERT risk taking, moral foundations, and Conservation and Transcendence  (Schwartz values) , can be predicted on the basis of the emotions shown while watching the 15 different video segments. Table  2  shows the descriptive statistics of our dependent variables for all four dimensions of a personality, listing the individual traits we mapped through psychometric tests. In Appendix A, we show the Pearson's correlation coefficients of individual traits with the different emotions experienced while watching the videos. Neither commenting on each single association and its significance, nor investigating the possible reasons behind associations, is in the scope of this research. Rather we wanted to show the possibility of predicting individual traits, based on the differential emotional response of individuals exposed to the same set of stimuli, by considering automatically recognized emotions through artificial intelligence.\n\nThe preliminary result of correlations-a suggested association between individual differences and people's emotional responses-is confirmed by the regression models presented in Tables  3 4 5 6 . For each set of dependent variables, they show the best model, i.e., the optimal combination of predictors that can explain the larger proportion of variance. We found no evidence of collinearity problems (evaluated by calculating variance inflation factors). These regressions illustrate the predictability of personality characteristics and morals f r o m facial expression of emotions using conventional statistical methods. In general, we f o u n d that models f o r some traits-such as conservation, transcendence, and ethical and financial likelihood-had promising adjusted R2 values. In terms of emotions, f e a r seemed more relevant f o r the predictions of the DOSPERT scores, whereas happiness seemed more associated with the Big Five personality traits. Being neutral in front of a video can also play a role in determining the individual's personality characteristics. Remember that the facial emotion recognition system returns this value if it cannot assign any other emotion with a sufficiently high threshold, corresponding to the individual sitting in f r o n t of the computer with an unmoving face. We also see that different videos triggered a variety of emotional responses, which were possibly useful for the prediction of different traits. All the relationships explored in this study could be further investigated in f u t u r e research in order to better analyze their meaning f r o m a psychological perspective.\n\nFigure  2  summarizes findings f r o m the regression models, providing evidence to the importance of each video and emotion f o r the prediction of individual traits.\n\nFor example, we can observe that videos number 14, 9, and 2 were those that triggered the most useful emotional responses. Among emotions, fear and happiness were those most used to make predictions, with f e a r being particularly relevant f o r the DOSPERT traits.",
      "page_start": 5,
      "page_end": 6
    },
    {
      "section_name": "Predicting Personality And Morals Using Machine Learning",
      "text": "While correlations and regressions showed promising results, we wanted to complete o u r analysis to explore non-linear relationships and the possibility of making predictions by using machining learning and considering a test sample (a subset of observations) not used f o r model training. In particular, w e binned the continuous scores of our dependent variables into three classes in order to understand if values were high, medium, or low. Subsequently, we used a gradient boosting approach to make predictions, namely, noost  [35] . We trained o u r models using 10-Fold Cross Validation and the SMOTE technique  [36]  in order to treat unbalanced classes. ADASYN was also used as a n alternative to SMOTE  [37] ,\n\nin the cases where this led to improved forecasts. In Table  7 , we present the results of these forecasting exercises, made on 10% of observations that were held o u t f o r testing prediction accuracy.     As the table shows, we obtained good prediction results, both in terms of average accuracy and Cohen's Kappa. Only for the health perceived trait of the DOSPERT scale did we obtain an accuracy score that was below 70% (60% average accuracy and a Kappa value of 0.38). This confirms our original hypothesis that facial emotion recognition can be used to predict personality and other individual traits.\n\nSimilarly to the regression models, different features were more important f o r the prediction of personality and other individual traits. In order to evaluate the contribution of each feature to model prediction, we used Shapley additive explanations (SHAP)  [38, 39] . In the following (Figures  3 4 5 6 ), we provide some examples, while the remaining charts are shown in Appendix A.",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "As The S H A P L E Y Charts Illustrate, Again The Emotions H A P P I N E S S And Fear Were F O U N D T O Have The Strongest Predictive Power. However, We Cannot Make Any Claim About What Emotional Response T O Which Movie Predicts What Personality Characteristics. T H I S I S Not The Point Of This Paper. The Point I S That \"Your Emotional Response Predicts Your Personality Characteristics And Moral Values\". I D E N T I F I C A T I O N Of The Most Emotionally Provocative Movies I S Most L I K E L Y Dependent On The Individual Personality And Values Of The Viewer, Which I S Also Related T O Local Cultures And Values. It Would T H E R E F O R E Be Another Research Project T O Precisely I D E N T I F Y A Minimal Set Of Short Movies That Consistently Provoke The Most Expressive Emotions That Are The Most Indicative Of An Individual'S Personality And Morals.",
      "text": "",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": ". Limitations, Future W O R K , And Conclusions",
      "text": "",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "I N This W O R K , We Show That Al Can Be Used For The Task Of Facial Emotion Recognition, Producing Features That Can In Turn Predict People'S Personality And Moral Values. Ours I S An E X P L O R A T O R Y Analysis With Regard T O Associations F O U N D Between D I F F E Rent Individual Traits And Emotions Produced In Response T O A D I F F E R E N T Set Of Audiovisual Stimuli. T H E S E Relationships Could Be Further Investigated In Future Research In O R D E R T O Better Understand Their Meaning From A Psychological Perspective. Future Research Should Consider More Control Variables, Which We Could Not Collect In Our Experiment ( D U E T O Privacy Arrangements), Such As A G E , Gender, And Ethnicity Of Experiment Participants. Similarly, A D I F F E R E N T Set Of V I D E O S Could Be Taken Into Account, Also Looking For The O P T Imal Set Of Stimuli That Could Produce An Emotional Response Better Associable T O Specific Individual D I F F E R E N C E S . Our Research Has Both Practical And Theoretical Implications. On The Theoretical S I D E , It Further C O N F I R M S The Insight That Moral A F F E C T -E M O T I O N S In Response T O Positive And Negative Experiences-Are At The Center Of Our Ethical Values. On The Practical S I D E , Our Approach O F F E R S A Novel And More Honest W A Y T O Measure Personality Characteristics, Attitudes T O R I S K , And Moral Values. As Has Been D I S C U S S E D Above, While Humans Tend T O M I S J U D G E Personality And Moral Values Of Others And Themselves, Ai Provides An Honest Virtual Mirror Assisting In This T A S K . I N Conclusion, This S T U D Y Has Shown That While Humans",
      "text": "f r e q u e n t l y are incapable of looking behind the facade of the face and \"read the mind in the eyes\", artificial intelligence can lend a helping hand t o people who have difficulties in this t a s k .",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Data Availability Statement: The D A T A Presented In This S T U D Y Are Available On Request F R O M The Corresponding Author. The D A T A Are Not Publicly Available Because They Contain I N F O R M A T I O N That Could Compromise The Privacy Of Research Participants. C O N Fl I C T S O F I N T E R E S T : The Authors Declare No C O N Fl I C T Of Interest.",
      "text": "",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "A P P E N D I X A Table A1 Shows The Pearson'S Correlation C O E F F I C I E N T S Of Individual Traits With The D I F F E R E N T Emotions Experienced While Watching The V I D E O S . Each Emotion I S Indicated Together With The Number Of The V I D E O It I S Referring T O . It I S Interesting T O Notice How Significant Associations Emerge For E V E R Y Individual Trait-With Some Emotions Being",
      "text": "particularly relevant for some traits, such as fear (revealed while watching videos 4-13 and 1 5 ) for the DOSPERT scale.  A1-A18 ). W e excluded those already presented in the results section.    8 8 6 0 8 6 8 8 8 8 8",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "I N The F O L L O W I N G , We Provide Additional Charts That Show The S H A P Values Of The Features Used For Machine Learning Predictions (Figures",
      "text": "",
      "page_start": 11,
      "page_end": 11
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Setup of our system with video website and four online surveys.",
      "page": 4
    },
    {
      "caption": "Figure 2: summarizes findings from the regression models, providing evidence to the",
      "page": 6
    },
    {
      "caption": "Figure 2: Alluvial diagrams illustrating the significant relationships between videos, emotions, and",
      "page": 9
    },
    {
      "caption": "Figure 3: Feature importance for predicting conservation.",
      "page": 9
    },
    {
      "caption": "Figure 4: Feature importance for predicting authority / respect.",
      "page": 10
    },
    {
      "caption": "Figure 5: Feature importance for predicting conscientiousness.",
      "page": 10
    },
    {
      "caption": "Figure 6: Feature importance for predicting health likelihood.",
      "page": 10
    }
  ],
  "tables": [
    {
      "caption": "Table 1: lists the 15 movie snippets, at a total length of 9 min 22 s, that are shown to",
      "page": 4
    },
    {
      "caption": "Table 1: List of 15 movie snippets.",
      "page": 4
    },
    {
      "caption": "Table 2: shows the descriptive statistics of our dependent variables for",
      "page": 5
    },
    {
      "caption": "Table 2: Descriptive statistics of individual traits.",
      "page": 5
    },
    {
      "caption": "Table 3: Regression models for the Big Five personality traits.",
      "page": 6
    },
    {
      "caption": "Table 7: , we present the results of",
      "page": 6
    },
    {
      "caption": "Table 5: Regression models for conservation and transcendence.",
      "page": 8
    },
    {
      "caption": "Table 6: Regression models for the Haidt moral values.",
      "page": 8
    },
    {
      "caption": "Table 7: Accuracy of noost models.",
      "page": 8
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Plumb, I. The \"reading the mind in the eyes\" test revised version: A study with normal adults, and adults with asperger syndrome or high-functioning autism",
      "authors": [
        "S Baron-Cohen",
        "S Wheelwright",
        "I Hill",
        "Y Raste"
      ],
      "year": "2001",
      "venue": "I. Child Psychol. Psychiatry"
    },
    {
      "citation_id": "2",
      "title": "How Emotions Are Made: The Secret Life of the Brain",
      "authors": [
        "L Barrett"
      ],
      "year": "2017",
      "venue": "How Emotions Are Made: The Secret Life of the Brain"
    },
    {
      "citation_id": "3",
      "title": "Computer-based personality judgments are more accurate than those made by humans",
      "authors": [
        "W Youyou",
        "M Kosinski",
        "D Stillwell"
      ],
      "year": "1969",
      "venue": "Proc. Natl. Acad. Sci"
    },
    {
      "citation_id": "4",
      "title": "K0, B. A brief review of facial emotion recognition based on visual information",
      "authors": [
        "I.-I Biel",
        "L Teijeiro-Mosquera",
        "D Gatica-Perez",
        "I Facetube ; Robler",
        "I Sun",
        "P Gloor"
      ],
      "year": "2012",
      "venue": "Proceedings o f the 14th ACM International Conference on Multimodal Interaction-ICMI '12"
    },
    {
      "citation_id": "5",
      "title": "The revised NEO personality inventory (NEO-PI-R)",
      "authors": [
        "P Costa",
        "R Mccrae"
      ],
      "year": "2008",
      "venue": "The SAGE Handbook of Personality Theory and Assessment"
    },
    {
      "citation_id": "6",
      "title": "Moral foundations theory Adv. Exp. Soc. Psychol",
      "authors": [
        "I Graham",
        "I Haidt",
        "S Koleva",
        "M Motyl",
        "R Iyer",
        "S Wojcik",
        "P Ditto"
      ],
      "year": "2013",
      "venue": "Moral foundations theory Adv. Exp. Soc. Psychol"
    },
    {
      "citation_id": "7",
      "title": "Toward a universal psychological structure of human values",
      "authors": [
        "S Schwartz",
        "W Bilsky"
      ],
      "year": "1987",
      "venue": "I. Pers. Soc. Psychol"
    },
    {
      "citation_id": "8",
      "title": "A domain-specific risk-taking (DOSPERT) scale for adult populations",
      "authors": [
        "A.-R Blais",
        "E Weber"
      ],
      "year": "2006",
      "venue": "Iudgm. Decis. Mak"
    },
    {
      "citation_id": "9",
      "title": "Moral affect: The good, the bad, and the ugly. I. Pers",
      "authors": [
        "I Tangney",
        "] Tangney",
        "I Stuewig",
        "D Mashek"
      ],
      "year": "1991",
      "venue": "Annu. Rev. Psychol"
    },
    {
      "citation_id": "10",
      "title": "The emotional basis of moral judgments",
      "authors": [
        "I Prinz"
      ],
      "year": "2006",
      "venue": "Philos. Explor"
    },
    {
      "citation_id": "11",
      "title": "What do two men kissing and a bucket o f maggots have in common? Heterosexual men's indistinguishable salivary oc-amylase responses to photos of two men kissing and disgusting images",
      "authors": [
        "B O'handley",
        "K Blair",
        "R Hoskin"
      ],
      "year": "2017",
      "venue": "Psychol. Sex"
    },
    {
      "citation_id": "12",
      "title": "Disgust is a factor in extreme prejudice",
      "authors": [
        "K Taylor"
      ],
      "year": "2007",
      "venue": "Br. I. Soc. Psychol"
    },
    {
      "citation_id": "13",
      "title": "Beforderung der Menschenkenntnifl und Menschenliebe; Weidmann and Reich",
      "authors": [
        "C Fragmente"
      ],
      "venue": "Beforderung der Menschenkenntnifl und Menschenliebe; Weidmann and Reich"
    },
    {
      "citation_id": "14",
      "title": "Composite portraits, made by combining those of many different persons into a single resultant figure",
      "authors": [
        "F Galton"
      ],
      "venue": "I. Anthropol. Inst. G. B. Irel"
    },
    {
      "citation_id": "15",
      "title": "Criminal Man, According to the Classification of Cesare Lombroso; G P Putnam's Sons",
      "authors": [
        "Lombroso Ferrero"
      ],
      "year": "1911",
      "venue": "Criminal Man, According to the Classification of Cesare Lombroso; G P Putnam's Sons"
    },
    {
      "citation_id": "16",
      "title": "Increased facial width-to-height ratio and perceived dominance in the faces o f the UK's leading business leaders",
      "authors": [
        "S Alrajih",
        "J Ward"
      ],
      "year": "2014",
      "venue": "Br. I. Psychol"
    },
    {
      "citation_id": "17",
      "title": "Men's facial width-to-height ratio predicts aggression: A meta-analysis",
      "authors": [
        "M Haselhuhn",
        "M Ormiston",
        "E Wong"
      ],
      "year": "2015",
      "venue": "PLoS ONE"
    },
    {
      "citation_id": "18",
      "title": "Facial morphology predicts male fitness and rank but not survival in second world war finnish soldiers",
      "authors": [
        "I Loehr",
        "R O'hara"
      ],
      "year": "2013",
      "venue": "Biol. Lett"
    },
    {
      "citation_id": "19",
      "title": "Group facial width-to-height ratio predicts intergroup negotiation outcomes",
      "authors": [
        "Y Yang",
        "C Tang",
        "X Qu",
        "C Wang",
        "T Denson"
      ],
      "year": "2018",
      "venue": "Front. Psychol"
    },
    {
      "citation_id": "20",
      "title": "ChaLearn looking at people challenge 2014: Dataset and results",
      "authors": [
        "S Escalera",
        "X Baro",
        "I Gonzalez",
        "M Bautista",
        "M Madadi",
        "M Reyes",
        "V Ponce-Lopez",
        "H Escalante",
        "I Shotton",
        "I Guyon"
      ],
      "year": "2015",
      "venue": "Computer Vision-ECCV 2014 Workshops"
    },
    {
      "citation_id": "21",
      "title": "First round challenge on first impressions-dataset and results",
      "authors": [
        "V Ponce-Lopez",
        "B Chen",
        "M Oliu",
        "C Corneanu",
        "A Clap√©s",
        "I Guyon",
        "X Baro",
        "H Escalante",
        "S Escalera",
        "Lap Chalearn"
      ],
      "year": "2016",
      "venue": "Computer Vision-ECC V 2016 Workshops"
    },
    {
      "citation_id": "22",
      "title": "Deep bimodal regression of apparent personality traits f r o m short Video sequences",
      "authors": [
        "X.-S Wei",
        "C.-L Zhang",
        "H Zhang",
        "J Wu"
      ],
      "year": "2018",
      "venue": "IEEE Trans. Afiect. Comput"
    },
    {
      "citation_id": "23",
      "title": "",
      "authors": [
        "S Porcu",
        "A Floris"
      ],
      "venue": ""
    },
    {
      "citation_id": "24",
      "title": "Estimation of the quality of experience during video streaming f r o m facial expression and gaze direction",
      "authors": [
        "N Atzori",
        "L Moller"
      ],
      "year": "2020",
      "venue": "IEEE Trans. Netw. Serv. Manag"
    },
    {
      "citation_id": "25",
      "title": "A n improved QoE estimation method based on (205 and affective computing",
      "authors": [
        "L Amour",
        "M Boulabiar",
        "S Souihi",
        "A Mellouk"
      ],
      "year": "2018",
      "venue": "Proceedings of the 2018 International Symposium on Programming and Systems (ISPS)"
    },
    {
      "citation_id": "26",
      "title": "Quality of experience evaluation of voice communication: An affect-based approach. Hum-Centric Comput",
      "authors": [
        "A Bhattacharya",
        "W Wu",
        "Z Yang"
      ],
      "year": "2007",
      "venue": "Inf. Sci"
    },
    {
      "citation_id": "27",
      "title": "",
      "authors": [
        "P Ekman"
      ],
      "year": "1993",
      "venue": ""
    },
    {
      "citation_id": "28",
      "title": "Deep residual learning f o r image recognition",
      "authors": [
        "K He",
        "X Zhang",
        "S Ren",
        "J Sun"
      ],
      "year": "2016",
      "venue": "Proceedings of the 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
    },
    {
      "citation_id": "29",
      "title": "Constants across cultures in the f a c e and emotion",
      "authors": [
        "P Ekman",
        "W Friesen"
      ],
      "year": "1971",
      "venue": "Pers. Soc. Psychol"
    },
    {
      "citation_id": "30",
      "title": "Universals in the content and structure of values: Theoretical advances and empirical tests in 20 countries",
      "authors": [
        "S Schwartz"
      ],
      "year": "1992",
      "venue": "Adv. Exp. Soc. Psychol"
    },
    {
      "citation_id": "31",
      "title": "Bringing values back in: The adequacy of the European social survey to measure values in 20 countries",
      "authors": [
        "E Davidov",
        "P Schmidt",
        "S Schwartz"
      ],
      "year": "2008",
      "venue": "Public Opin. Q"
    },
    {
      "citation_id": "32",
      "title": "Reliable large-scale tree boosting system",
      "authors": [
        "T Chen",
        "C Guestrin",
        "Xgboost"
      ],
      "year": "2016",
      "venue": "Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining"
    },
    {
      "citation_id": "33",
      "title": "Synthetic minority over-sampling technique",
      "authors": [
        "N Chawla",
        "K Bowyer",
        "L Hall",
        "W Kegelmeyer",
        "Smote"
      ],
      "year": "2002",
      "venue": "Artif. Intell. Res"
    },
    {
      "citation_id": "34",
      "title": "Adaptive synthetic sampling approach f o r imbalanced learning",
      "authors": [
        "H He",
        "Y Bai",
        "E Garcia",
        "S Li",
        "Adasyn"
      ],
      "year": "2008",
      "venue": "Proceedings of the 2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence)"
    },
    {
      "citation_id": "35",
      "title": "Consistent Feature Attribution f o r Tree Ensembles",
      "authors": [
        "S Lundberg",
        "G Erion",
        "S Lee"
      ],
      "year": "2019",
      "venue": "Consistent Feature Attribution f o r Tree Ensembles"
    },
    {
      "citation_id": "36",
      "title": "A unified approach to interpreting model predictions",
      "authors": [
        "S Lundberg",
        "Lee"
      ],
      "year": "2017",
      "venue": "Proceedings of the 3lst Conference on Neural Information Processing System"
    }
  ]
}