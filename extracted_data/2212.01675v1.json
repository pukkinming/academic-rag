{
  "paper_id": "2212.01675v1",
  "title": "Facial Emotion Recognition Systems In Smart Classroom: A Survey",
  "published": "2022-12-03T19:16:45Z",
  "authors": [
    "Rajae Amimi",
    "Amina radgui",
    "Ibn el haj el hassane"
  ],
  "keywords": [
    "smart classrooms",
    "students affect states",
    "FER system",
    "intelligent tutoring",
    "student expressions database"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Technology has transformed traditional educational systems around the globe; integrating digital learning tools into classrooms offers students better opportunities to learn efficiently and allows the teacher to transfer knowledge more easily. In recent years, there have been many improvements in smart classrooms. For instance, the integration of facial emotion recognition systems (FER) has transformed the classroom into an emotionally aware area using the power of machine intelligence and IoT. This paper provides a consolidated survey of the state-of-the-art in the concept of smart classrooms and presents how the application of FER systems significantly takes this concept to the next level.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "The concept of a modern classroom has long ago attracted the interest of many researchers. It dates back to the early 16th century when the Pilgrims Fathers established the first public school in 1635. Since the 1980s, with the development of information technology such as networking, multimedia, and computer science, the classrooms of various schools have become more and more information-based at different levels.\n\nGenerally, a classroom is defined as an educational space where a teacher transfers knowledge to a group of students; this learning environment is one of the basic elements that influence the quality of education. Therefore, researchers suggest smart classrooms as an innovative approach that gives rise to a new intelligent teaching methodology, which became popular since 2012. The literature presents two visions of this concept. The first approach that has taken good advantage of the joint growth of the computer science and electronics industry concentrates on the feasibility of deploying various intelligent devices in replacement to traditional materials, such as replacing books with optical discs or pen drives, getting rid of shalk board in favor of interactive whiteboard. In his paper \"what is a smart classroom?\", Yi Zhang  [1]  notes \" The smart classroom can be classified as a classroom with computers, projectors, multimedia devices (video and DVD), network access, loudspeakers, etc., and capable of adjusting lighting and controlling video streams;\". According to some authors, this concept of a \"technology-rich classroom\" has a significant limitation in that it concentrates solely on the design and equipment of the classroom environment, ignoring pedagogy and learning activities  [2] . However, propositions from other studies point to a different insight,  [3]  and al. envision making classrooms an emotionally aware environment that emphasizes improving teaching methodologies, this second approach focuses on the pedagogical aspect rather than technology and software design. Kim and al propose integrating machine intelligence and IOT to create a classroom that can listen, see and analyze students' engagement  [3]  .\n\nIn 2013, Derick Leony and al confirm that \" Many benefits can be obtained if intelligent systems can bring teachers with knowledge about their learner's emotions\"  [4] , emotions may be a fundamental factor that influences learning, as well as a driving force that encourages learning and engagement. As a result,https://www.overleaf.com/project/62ec3930f99c128355b000c7 researchers suggest a variety of approaches for assessing students' affect states, including textual, visual, vocal, and multimodal methodologies. According to  [5] , the most widely utilized measurement channels are textual and visual. In comparison to the visual channel, textual (based on questionnaires and text analysis) is less innovative, and Facial Emotion Recognition (FER) systems are classified at the top of the visual channel. In another state of the art, numerous researchers propose performant FER approaches with high accuracy up to 80%  [6] ; this encourages their integration as an efficient method to analyze student affect states.\n\nEven though there has been an increasing amount of attention paid to technologies used in smart education, there is no literature that tackles the many elements of employing students' facial expression recognition systems in smart classrooms. Our article helps understand the concept of future classrooms and their technologies, particularly students' FER.\n\nWe organize this paper as follows: In Section 2, we define smart classrooms and we present some of their technologies. In Section 3, we investigate the integration of FER systems to intelligent classrooms; enumerating FER databases and approaches. In Section 4, we elaborate our insight and future works, then in Section 5, we present a brief conclusion.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Smart Classroom: Definition And Technologies",
      "text": "",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Definition Of Smart Classroom",
      "text": "Smart learning is technology-enhanced learning, it facilitates interaction between students and their instructor and provides learners access to digital resources; it also provides guidance, tips, helpful tools, and recommendations to teach and learn efficiently. This innovative learning system comes with several new ways of learning classified into two categories: Learning via technology: for instance, taking interactive courses via massively open online courses (MOOC), educational games, or intelligent tutoring systems (ITS). Learning with a teacher: consists of learning in a technology-enhanced physical classroom, which is generally the concept of Smart classrooms (SC) .\n\nThere are many definitions of smart classroom; indeed, it is hard to agree on a single definition that is accepted by the scientific community overall. Authors like  [1] , introduce intelligent classroom as learners-centered environment that supports students, adapts to their learning abilities, and helps teachers transfer their knowledge interactively and easily. Meanwhile,  [7]  [8] and al define a smart classroom as a physical environment containing digital tools, interactive devices, and various technologies to facilitate the activity of teaching and enhance learning.  [3]  and al comes up with a definition that goes beyond considering just the possibility of deploying intelligent materials into a physical place, they envision a smart classroom as an emotionally aware environment using real-time sensing and the power of machine intelligence, and in this context, they suggest a new system with advanced technologies and provide directions to deploy it. In literature, authors present the concept of the future classroom in their own distinctive way, but the goal remains the same: to enhance education through technology. A pertinent question to ask here, is, what elements make up a typical intelligent classroom? In response to this question,  [8]  and al. propose a taxonomy of a typical smart classroom, as shown in Figure  1 . A typical smart classroom provides tools such as desktop computers, digital cameras, recording and casting equipments, interactive whiteboards, etc;  [9]  for effective presentation, better assessment, constructive interaction, and comfortable physical environment. In order to present this taxonomy, four components are to consider: Smart content and presentation: technology assists the instructor in preparing the content of his courses and presenting it easily and interactively  [9] . Smart assessment: includes automated evaluation of students learning capacity; also, it consists of managing students' attendance and recuperating their feedback to enhance lectures' quality as presented by  [10]    [11] . Smart physical environment: smart classrooms offer a healthy climate by controlling factors like air, temperature, humidity, etc; using sensors and actuators  [12]  [13]  [14]  . Smart interaction and engagement: it focuses on analyzing the level of students engagement and consists of providing tools to enhance interaction  [10]  [15]  [16] .",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Smart Classroom Technologies",
      "text": "Education technology (edtech) is a multi-billion-dollar business that is rising every year. Many nations in the Organisation for Economic Co-operation and Development (OECD) spend more than 10% of their budgets on education  [17] . Furthermore, as more nations raise their education investment, public spending on Edtech is expected to rise. Low-and middle-income nations, for example, expect to boost education expenditure from US$ 1.2 trillion to US$3 trillion per year  [18] . According to the Incheon Declaration, nations must devote at least 4% to 6% of their GDP to education, or at least 15% to 20% of public spending to education. Aside from the predicted expansion in the educational sector, the market for smart classroom technologies is rapidly growing and is strongly linked to advances in computer science, robotics, and machine intelligence. As indicated in Table  1 , every technology has advantages and disadvantages; the most prevalent constraints of most of these technologies are cost in the first position, followed by technical knowledge concerns ( generally, teachers and students don't have the required technical knowledge to use those technologies correctly) in the second place. Below are some of the main SC technologies: Interactive Whiteboard (IWB): is an intelligent tool that allows users to manipulate their presentations and project them on a board's surface using a special pen or simply their hand  [19] . IWB can be used to digitalize operations and tasks or merely as a presentational device  [20] . The use of this device has revolutionized the nature of educational activities; it has the power to reduce the complexity of teaching and offers the instructor more flexibility during presentations. RFID Attendance Management System: RFID stands for Radio Frequency Identification; it is a wireless technology used to track an object then memorize and recuperate data using radio tags  [21] . An RFID attendance system automatically marks students' presence in the classroom by validating their ID cards on the reader. It is a bright, innovative solution to replace classic attendance registers  [22] , and help teachers gain wasted time verifying students' presence daily. Educational cobot: is a new innovative tool used as a co-worker robot to help with teaching tasks. It contains several sensors, cameras, microphones, and motors so it can listen, see, communicate with students and assist the teacher  [23] . Embedded into classrooms, cobots represent the school of the future and have significantly changed the traditional ways of teaching  [24] . Sensors and actuators: consists of installing sensors to collect data from their environment, then sending this data to the cloud to be analyzed, and might decide to act using actuators; for example, a temperature sensor detects and measures hotness and coolness, then sends the information to another device to adjust the temperature. This technology provides an adequate healthy climate by controlling air, temperature, humidity, etc  [13] . Augmented Reality (AR): is a system that combines real and virtual worlds, it is a real-world interactive experience in which computer-generated perceptual information enhances real objects  [25] . It was first used in training pilots applications in the 1990s  [26] , and over the years, it has demonstrated a high efficiency when adopted in educational settings; it has been used to enhance many disciplines particularly when students learn subjects with complex, abstract concepts or simply things they find difficult to visualize such like mathematics, geography, anatomy, etc  [27] . A Classroom Response System (CRS): is used to collect answers from all students and send them electronically to be analyzed by the teacher, who can graphically display a summary of the gathered data  [28] . CRS is an efficient method to increase classroom interaction  [29] .According to  Martyn (2007)    [30] , \"One of the best aspects about an CRS is that it encourages students to contribute without fear of being publicly humiliated or of more outspoken students dominating the discussion.\" Commercial off-the-shelf (COTS) eye tracker : is a gaze-based model that is used to monitor students' attention and detect their mind wandering in the classroom. It helps the instructor to better understand their interests and evaluate their degree of awareness  [31]    [32] . Wearable badges: tracks the wearer's position, detects when other badge wearers are in range, and can predict emotion from the wearer's emotional voice tone. It helps the teacher manage the classroom; he can use those badges to detect if a student leaves without permission or when a group of learners make a loud noise that disturbs the rest of their classmates. MIT has developed a wearable badge by Sandy Pentland's team  [24]    [17] . Learning Management System (LMS): is a web-based integrated software; used to create, deliver and track courses and outcomes. It aids educators to develop courses, post announcements, communicate easily and interactively, grade assignments, and assess their students; besides, it allows students to submit their work, participate in discussions, and take quizzes  [33]  [34]  [35] . Student facial emotions recognition (FER): is a technology that analyzes expressions using a person's images; it is part of the affective computing field. Authors uses this technology to predict real-time student feedback during lectures  [6] , which helps the instructor improve the quality of his presentations.",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "Wearable Badges",
      "text": "It increases the level of security and privacy in classrooms.\n\nPrivacy concern: pupils may have some misapprehension about their privacy when it comes to wearable devices.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Lms",
      "text": "It saves wasted time on menial tasks like grading papers. It gives students access to learning material in one place from any device.\n\nIt requires IT and programming knowledge.\n\n3 The application of FER system to smart classroom",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Fer Approaches Used For Smart Classroom",
      "text": "Analyzing student's affective states during a lecture is a pertinent task in smart classroom  [36] . It is crucial to determine student engagement during a lecture in order to measure the effectiveness of teaching pedagogy and enhance the interaction with the instructor. Therefore, in order to get student feedback and achieve his satisfaction, researchers suggest different methods such as: body gesture recognition detected by using Electroencephalography (EEG) signals  [37] , body posture using either cameras or a sensing chair  [16] , hand gestures  [38] , heart rate  [39] , and so forth. Meanwhile, FER systems appear in literature like the most used solution to recognize student's affective states in smart classroom.\n\nRecently, FER systems are used in several domains like robotics, security, psychology, etc; thus, over time many researchers suggest new performant FER approaches. The framework of FER systems is structured as shown in Figure  2 ; the input of this system is the images from a FER database; those images are pre-processed in a way to match the input size of the network, then, adequate algorithms are used to detect area of the face properly and extract the main features that help the network learn from training data; the final step is to classify results according to the database labels  [6] . Thousands of articles have been written on this subject, but only a few of them have applied FER systems to smart classrooms. In Table  2 , we cite FER approaches used in smart classrooms; we classify those approaches into three categories: Handcrafted approaches: are traditional methods of machine learning that consist of manually extracting features. Some examples include edge detection, sharpening, corner detection, histograms, etc. LBP pattern, for instance, is a type of image descriptor used to extract a texture of an image. Then, for classification, an adequate classifier is used; it is also a traditional machine learning algorithm such as: Support Vector Machine (SVM), K-nearest neighbor (KNN), decision tree, etc. Deep learning approaches: are new methods based on neural networks for both feature extraction and classification. Learned features are extracted automatically using deep learning algorithms; Convolutional Neural Network (CNN) is the most commonly used for analyzing visual imagery; it can choose the best features to classify the images. Hybrid approaches: combine both algorithms of machine learning and deep learning. They utilize traditional machine-learning algorithms to extract features and neural networks to classify images; Notes and Comments. In the beginning, approaches (before 2019) employed classical machine learning methods like Gabor filters, LPB, KNN, and SVM to extract features and classify emotions; then gradually, since 2019, authors started integrating neural networks. As shown in Table  2 ,  [41]  and al utilize a hybrid approach that consists of using LBP-TOP as a descriptor then deep neural network (DNN) for classification which gives a better result (85%) in comparison to both the methods proposed by  [40] [10] accuracies (respectively 72%, 79% ) and the new deep method suggested by  [42] ; additionally, Ashwin and al. suggest methods with different accuracies improved ( from 61% to 88%) by changing the training data  [43]    [38] ; which point on the importance of choosing an adequate database.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Fer Student'S Databases",
      "text": "Over the past years, there was a lack of student facial expressions databases  [36] , and most of the authors use general FER databases like FER2013 and CK+ to train their models  [44]   [38] . It is essential to have an adequate database to increase the models' accuracy and get better results  [16] , because the efficiency of FER models depends mainly on the quality of both databases and FER approaches  [19] . Each created database has its characteristics, depending on the classes of expressions, ethnicity of participants, labeling methods, Size, method and angle of image acquisition. In Table  3 , we have gathered students' expressions databases used in intelligent classrooms. In this paper, we have surveyed the concept of smart classroom and its technologies, especially FER systems. In the future, we plan to consider the evolution of smart classrooms in this critical period of the pandemic. Today, the pandemic of coronavirus is causing a global health crisis. During this time, countries around the world have imposed restrictions on social distancing, masking, and other aspects of public life. The lockdowns in response to the spread of the virus are significantly impacting educational systems. As a result, governments are striving to maintain continuity of learning and are proposing distance learning as a suitable interim solution, but unfortunately, not all students around the globe have access to digital learning resources. In our future work, we propose a model for an intelligent physical classroom that respects the restrictions of Covid-19. We base our model on two propositions; as shown in Figure  3 :\n\nProposition 1: we propose a system that automatically detects whether the students in the classroom are wearing their masks or not.\n\nProposition 2: we detect the distances between students and compare them with the allowed distance.\n\nIf the students do not comply with the restrictions, the system sends a warning to the teacher in real-time. Notes and Comments. The Proposed intelligent classroom system in Figure  3  consisting of (Model 1, Model 2) artificial neural networks to detect students not wearing masks and to measure distances between learners. Wearing face masks strongly confuses facial emotions recognition systems (FER). In our future work, we will study the limitations of these systems, used in today's smart classrooms, as well as the possibility of predicting emotions in a student face wearing a mask; since it is possible, for example, to predict students' mind wandering and the level of their engagement based only on their gaze  [31]    [32] .",
      "page_start": 8,
      "page_end": 9
    },
    {
      "section_name": "Conclusion",
      "text": "Smart classroom is not a new concept, but over the years it has known many changes through the integration of various technologies. Researchers have trans-formed the classroom from a simple physical space gathering learners and their instructors to an emotionally aware environment that can interact with students and help them learn efficiently. Numerous technologies have revolutionized the evolution of digital classrooms, and FER systems are considered the most innovative. The authors have adapted FER 's systems for use in smart classrooms using approaches with high accuracies and personalized databases. The evolution of these interactive classrooms can be considered to aid in teaching during the restrictions of the COVID 19 pandemic. It can also be adapted for teaching students with special needs or intellectual disabilities to facilitate their interaction with their teachers.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Acknowledgement",
      "text": "Authors would like to thank the National Center for Scientific and Technical Research (CNRST) for supporting and funding this research.",
      "page_start": 11,
      "page_end": 11
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Fig. 1. Taxonomy of a typical smart classroom",
      "page": 3
    },
    {
      "caption": "Figure 2: Facial expressions recognition system Framework",
      "page": 7
    },
    {
      "caption": "Figure 3: Proposition 1: we propose a system that automatically detects whether the",
      "page": 10
    },
    {
      "caption": "Figure 3: Proposed model for intelligent classroom",
      "page": 10
    },
    {
      "caption": "Figure 3: consisting of (Model 1, Model 2) artiﬁcial neural networks to detect students not",
      "page": 10
    }
  ],
  "tables": [
    {
      "caption": "Table 1: Merits and limitations of smart classroom technologies",
      "data": [
        {
          "Technology": "IWB",
          "Merits": "The touchscreen made its use simpler and more eﬀective.\nIt is equipped with smart tools such as a pointer, screen\ncapture...\nIt provides access to the web.",
          "Limitations": "Expensive: many schools are not able to aﬀord it.\nTeacher\ntraining: The\nschool\nshould\nspend\ntime\nand\nmoney teaching their\ninstructors how to use the equip-\nment correctly."
        },
        {
          "Technology": "RFID",
          "Merits": "Quick and Rapid:\nit identiﬁes students in seconds.\nAccuracy :\nit provides more accurate identiﬁcation.",
          "Limitations": "Expensive : In case of a large strength of students,\npurchasing tags for everyone is costly.\nNot secure : the system is prone to manipulation."
        },
        {
          "Technology": "COBOT",
          "Merits": "Wide Knowledge:\nit saves a large amount of information.",
          "Limitations": "Technical Disruptions:\nit can break down at any time.\nHuman-machine interaction:\nit may have trouble in try-\ning to interact with the students.\nExpensive."
        },
        {
          "Technology": "Sensors\nand\nac-\ntuators",
          "Merits": "Comfort:\nit provides a healthy and comfortable environ-\nment.",
          "Limitations": "Technical support :\nit needs IT professionals to help set\nit up and maintain it"
        },
        {
          "Technology": "AR",
          "Merits": "It provides outstanding visualizations.\nIt Increases Students’ Engagement.",
          "Limitations": "It may presents functionality Issues.\nIt is expensive."
        },
        {
          "Technology": "CRS",
          "Merits": "Rapid assessment: It provides outcomes of\nformative as-\nsessment.\nIt provides immediate feedback for student.\nTime saving:\nfor instance, Fast grading.",
          "Limitations": "Expensive :\nit costs an average of $75 / device\nIt presents technical problems.\nIneﬀective for opinion questions."
        },
        {
          "Technology": "COTS",
          "Merits": "It records real time eye movements and ﬁxations, which\ncan report student reactivity.",
          "Limitations": "It is not able to track all eyes: eye-tracking camera is\nimpacted for example by lenses or glasses.\nIt costs money, time and labor resources.\nEﬃciency: visual attention is not suﬃcient to interpret\nstudents’ engagement."
        },
        {
          "Technology": "Wearable\nbadges",
          "Merits": "It\nincreases\nthe\nlevel\nof\nsecurity and privacy in class-\nrooms.",
          "Limitations": "Privacy concern: pupils may have some misapprehension\nabout their privacy when it comes to wearable devices."
        },
        {
          "Technology": "LMS",
          "Merits": "It saves wasted time on menial tasks like grading papers.\nIt gives students access to learning material\nin one place\nfrom any device.",
          "Limitations": "It requires IT and programming knowledge."
        }
      ],
      "page": 6
    },
    {
      "caption": "Table 2: FER approaches in application to smart classroom",
      "data": [
        {
          "Approach": "Handcrafted",
          "Works Year": "[40]",
          "Feature\nextraction": "2014 Gabor features",
          "Classiﬁcation": "Support vector\nmachine (SVM)",
          "Accuracy": "72%"
        },
        {
          "Approach": "",
          "Works Year": "[10]",
          "Feature\nextraction": "ULGBPHS",
          "Classiﬁcation": "K-nearest neighbor\nclassiﬁer (KNN)",
          "Accuracy": "79%"
        },
        {
          "Approach": "Hybrid",
          "Works Year": "[41]",
          "Feature\nextraction": "LBP-TOP",
          "Classiﬁcation": "Deep Neural Network\n(DNN)",
          "Accuracy": "85%"
        },
        {
          "Approach": "Deep Learning",
          "Works Year": "[42]",
          "Feature\nextraction": "Convolutional Neural Network\n(CNN)",
          "Classiﬁcation": "",
          "Accuracy": "70%"
        },
        {
          "Approach": "",
          "Works Year": "[43]",
          "Feature\nextraction": "CNN-1: analyze single face\nexpression in single image.\nCNN- 2 analyze multiple faces\nin single image",
          "Classiﬁcation": "",
          "Accuracy": "86% for CNN1\n70% for CNN2"
        },
        {
          "Approach": "",
          "Works Year": "[38]",
          "Feature\nextraction": "CNN based\non GoogleNet architecture\nwith 3 types of Databases",
          "Classiﬁcation": "",
          "Accuracy": "88 %\n79 %\n61%"
        }
      ],
      "page": 8
    },
    {
      "caption": "Table 3: Student’s FER databases",
      "data": [
        {
          "Works": "[40]",
          "Database": "Spontaneous",
          "Expressions\nClasses": "4 classes\nNot engaged\nNominally engaged\nEngaged in task\nVery engaged",
          "Ethnicity &\ngender of\nparticipants": "Asian-American\nCaucasian-American\nAfrican-American\n25 female",
          "Method or angle\nof acquisition": "Pictures are taken\nfrom an IPad\ncamera posed\nin 30 centimeters\nin front of the\nparticipant’s face\nwhile playing\na cognitive game",
          "Labeling": "Labeled by\nstudents from\ndiﬀerent disciplines:\ncomputer science,\ncognitive and\npsychological science",
          "Database\ncontent": "N/A\n34 participant"
        },
        {
          "Works": "[10]",
          "Database": "Spontaneous",
          "Expressions\nClasses": "5 classes:\nJoviality\nSurprise\nConcentration\nConfusion\nFatigue",
          "Ethnicity &\ngender of\nparticipants": "Asian",
          "Method or angle\nof acquisition": "Acquired using a\nfull 1080p HD\ncamera conﬁgured\nat the front of\nthe classroom while\nthe student watching\na 6 minutes video",
          "Labeling": "Participants labeled\ntheir own pictures",
          "Database\ncontent": "200 images\n23 participants"
        },
        {
          "Works": "[45]",
          "Database": "Spontaneous",
          "Expressions\nClasses": "4 Classes :\nFrustration\nBoredom\nEngagement\nExcitement",
          "Ethnicity &\ngender of\nparticipants": "N/A",
          "Method or angle\nof acquisition": "Computer webcam\ntakes a photograph\nevery 5 seconds",
          "Labeling": "Labeled using\na mobile\nelectroencephalo\n-graphy (EEG)\ntechnology called\nEmotiv Epoc",
          "Database\ncontent": "730 images"
        },
        {
          "Works": "[46]",
          "Database": "Spontaneous",
          "Expressions\nClasses": "5 classes:\nConfusion\nDistraction\nEnjoyment\nNeutral\nFatigue",
          "Ethnicity &\ngender of\nparticipants": "Chinese\n(29 male and\n53 female)",
          "Method or angle\nof acquisition": "Acquired using\nComputers cameras",
          "Labeling": "Labeled by\nthe participants\nand external coders",
          "Database\ncontent": "1,274 video\n30,184 mages\n82 participants"
        },
        {
          "Works": "[38]",
          "Database": "Posed and\nspontaneous",
          "Expressions\nClasses": "14 Classes:\n7 classes of\nEkman’s basic\nemotions\n3 learning-centered\nemotions\n( Frustration,\nconfusion\nand boredom )\nNeutral",
          "Ethnicity &\ngender of\nparticipants": "Indian",
          "Method or angle\nof acquisition": "Frontal posed\nexpressions",
          "Labeling": "Labeled using\nthe semi-automatic\nannotation process\nand reviewed\nmanually to\ncorrect wrong\nannotations",
          "Database\ncontent": "4000"
        }
      ],
      "page": 9
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "What is a smart classroom? a literature review",
      "authors": [
        "Y Zhang",
        "X Li",
        "L Zhu",
        "X Dong",
        "Q Hao"
      ],
      "year": "2019",
      "venue": "Perspectives on Rethinking and Reforming Education"
    },
    {
      "citation_id": "2",
      "title": "Decoding classdojo: Psycho-policy, social-emotional learning and persuasive educational technologies",
      "authors": [
        "B Williamson"
      ],
      "year": "2017",
      "venue": "Learning, Media and Technology"
    },
    {
      "citation_id": "3",
      "title": "Towards emotionally aware AI smart classroom: Current issues and directions for engineering and education",
      "authors": [
        "Y Kim",
        "T Soyata",
        "R Behnagh"
      ],
      "year": "2018",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "4",
      "title": "Provision of awareness of learners' emotions through visualizations in a computer interaction-based environment",
      "authors": [
        "D Leony",
        "P Muñoz-Merino",
        "A Pardo",
        "C Kloos"
      ],
      "year": "2013",
      "venue": "Expert Systems with Applications"
    },
    {
      "citation_id": "5",
      "title": "Affective computing in education: A systematic review and future research",
      "authors": [
        "E Yadegaridehkordi",
        "N Noor",
        "M Ayub",
        "H Affal",
        "N Hussin"
      ],
      "year": "2019",
      "venue": "Computers & Education"
    },
    {
      "citation_id": "6",
      "title": "New framework for personindependent facial expression recognition combining textural and shape analysis through new feature extraction approach",
      "authors": [
        "M Kas",
        "Y Ruichek",
        "Y Messoussi"
      ],
      "year": "2021",
      "venue": "Information Sciences"
    },
    {
      "citation_id": "7",
      "title": "The 'smart'classroom: a new frontier in the age of the smart university",
      "authors": [
        "M Kwet",
        "P Prinsloo"
      ],
      "year": "2020",
      "venue": "Teaching in Higher Education"
    },
    {
      "citation_id": "8",
      "title": "How smart are smart classrooms? a review of smart classroom technologies",
      "authors": [
        "M Saini",
        "N Goel"
      ],
      "year": "2020",
      "venue": "ACM Computing Surveys"
    },
    {
      "citation_id": "9",
      "title": "A context-aware smart classroom for enhanced learning environment",
      "authors": [
        "M Miraoui"
      ],
      "year": "2018",
      "venue": "International Journal on Smart Sensing and Intelligent Systems"
    },
    {
      "citation_id": "10",
      "title": "Automatic facial expression analysis of students in teaching environments",
      "authors": [
        "C Tang",
        "P Xu",
        "Z Luo",
        "G Zhao",
        "T Zou"
      ],
      "year": "2015",
      "venue": "Biometric Recognition"
    },
    {
      "citation_id": "11",
      "title": "Unobtrusive behavioral analysis of students in classroom environment using non-verbal cues",
      "authors": [
        "T Ashwin",
        "R Guddeti"
      ],
      "year": "2019",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "12",
      "title": "A smart classroom based on deep learning and osmotic IoT computing",
      "authors": [
        "A Pacheco",
        "P Cano",
        "E Flores",
        "E Trujillo",
        "P Marquez"
      ],
      "year": "2018",
      "venue": "Congreso Internacional de Innovación y Tendencias en Ingeniería (CONIITI)"
    },
    {
      "citation_id": "13",
      "title": "Iot based cloud integrated smart classroom for smart and a sustainable campus",
      "authors": [
        "R Revathi",
        "M Suganya",
        "G Nr"
      ],
      "year": "2020",
      "venue": "Procedia Computer Science"
    },
    {
      "citation_id": "14",
      "title": "IoT based cloud integrated smart classroom for smart and a sustainable campus",
      "year": "2020",
      "venue": "Procedia Computer Science"
    },
    {
      "citation_id": "15",
      "title": "Automatic prediction of frustration",
      "authors": [
        "A Kapoor",
        "W Burleson",
        "R Picard"
      ],
      "year": "2007",
      "venue": "International Journal of Human-Computer Studies"
    },
    {
      "citation_id": "16",
      "title": "Multimodal affect recognition in learning environments",
      "authors": [
        "A Kapoor",
        "R Picard"
      ],
      "year": "2005",
      "venue": "Proceedings of the 13th annual ACM international conference on Multimedia -MULTIMEDIA '05"
    },
    {
      "citation_id": "17",
      "title": "Learning enhancement in higher education with wearable technology",
      "authors": [
        "S Khosravi",
        "S Bailey",
        "H Parvizi",
        "R Ghannam"
      ],
      "year": "2021",
      "venue": "Learning enhancement in higher education with wearable technology",
      "arxiv": "arXiv:2111.07365"
    },
    {
      "citation_id": "18",
      "title": "Sdg4-education 2030 framework for action",
      "authors": [
        "I Declaration"
      ],
      "year": "2016",
      "venue": "Sdg4-education 2030 framework for action"
    },
    {
      "citation_id": "19",
      "title": "Interactive whiteboard use and student engagement",
      "authors": [
        "C Lant",
        "M Lawson"
      ],
      "year": "2016",
      "venue": "Publishing Higher Degree Research"
    },
    {
      "citation_id": "20",
      "title": "The interactive whiteboard: a literature survey",
      "authors": [
        "D Glover",
        "D Miller",
        "D Averis",
        "V Door"
      ],
      "year": "2005",
      "venue": "Technology, Pedagogy and Education"
    },
    {
      "citation_id": "21",
      "title": "Attendance and information system using RFID and web-based application for academic sector",
      "authors": [
        "H Salih",
        "N Al",
        "A Al-Sadawi",
        "B Alsharqi"
      ],
      "year": "2018",
      "venue": "International Journal of Advanced Computer Science and Applications"
    },
    {
      "citation_id": "22",
      "title": "Web-based student attendance system using RFID technology. In: 2012 IEEE Control and System Graduate Research Colloquium",
      "authors": [
        "M Kassim",
        "H Mazlan",
        "N Zaini",
        "M Salleh"
      ],
      "year": "2012",
      "venue": "IEEE"
    },
    {
      "citation_id": "23",
      "title": "Educational Robotics in the Makers Era",
      "authors": [
        "D Alimisis",
        "M Moro",
        "E Menegatti"
      ],
      "year": "2017",
      "venue": "Educational Robotics in the Makers Era"
    },
    {
      "citation_id": "24",
      "title": "Letting artificial intelligence in education out of the box: Educational cobots and smart classrooms",
      "authors": [
        "M Timms"
      ],
      "year": "2016",
      "venue": "International Journal of Artificial Intelligence in Education"
    },
    {
      "citation_id": "25",
      "title": "Augmented reality in science laboratories: The effects of augmented reality on university students' laboratory skills and attitudes toward science laboratories",
      "authors": [
        "M Akçayır",
        "G Akçayır",
        "H Pektaş",
        "M Ocak"
      ],
      "year": "2016",
      "venue": "Computers in Human Behavior"
    },
    {
      "citation_id": "26",
      "title": "Augmented reality: An application of heads-up display technology to manual manufacturing processes",
      "authors": [
        "P Thomas",
        "W David"
      ],
      "year": "1992",
      "venue": "Hawaii international conference on system sciences"
    },
    {
      "citation_id": "27",
      "title": "A review of using augmented reality in education from 2011 to 2016",
      "authors": [
        "P Chen",
        "X Liu",
        "W Cheng",
        "R Huang"
      ],
      "year": "2016",
      "venue": "Innovations in Smart Learning"
    },
    {
      "citation_id": "28",
      "title": "Shaping Future Schools with Digital Technology",
      "year": "2019",
      "venue": "Shaping Future Schools with Digital Technology"
    },
    {
      "citation_id": "29",
      "title": "Classroom response systems: A review of the literature",
      "authors": [
        "C Fies",
        "J Marshall"
      ],
      "year": "2006",
      "venue": "Journal of Science Education and Technology"
    },
    {
      "citation_id": "30",
      "title": "Clickers in the classroom: An active learning approach",
      "authors": [
        "M Martyn"
      ],
      "year": "2007",
      "venue": "Educause quarterly"
    },
    {
      "citation_id": "31",
      "title": "out of the fr-eye-ing pan",
      "authors": [
        "S Hutt",
        "C Mills",
        "N Bosch",
        "K Krasich",
        "J Brockmole",
        "S D'mello"
      ],
      "year": "2017",
      "venue": "Proceedings of the 25th Conference on User Modeling, Adaptation and Personalization"
    },
    {
      "citation_id": "32",
      "title": "Automated gaze-based mind wandering detection during computerized learning in classrooms",
      "authors": [
        "S Hutt",
        "K Krasich",
        "C Mills",
        "N Bosch",
        "S White",
        "J Brockmole",
        "S D'mello"
      ],
      "year": "2019",
      "venue": "User Modeling and User-Adapted Interaction"
    },
    {
      "citation_id": "33",
      "title": "Using technology to create a dynamic classroom experience",
      "authors": [
        "B Courts",
        "J Tucker"
      ],
      "year": "2012",
      "venue": "Journal of College Teaching & Learning (TLC)"
    },
    {
      "citation_id": "34",
      "title": "An evolving learning management system for new educational environments using 2.0 tools",
      "authors": [
        "M Conde",
        "F García-Peñalvo",
        "M Rodríguez-Conde",
        "M Alier",
        "M Casany",
        "J Piguillem"
      ],
      "year": "2012",
      "venue": "Interactive Learning Environments"
    },
    {
      "citation_id": "35",
      "title": "Why lms failed to support student learning in higher education institutions",
      "authors": [
        "A Alhazmi",
        "A Rahman"
      ],
      "year": "2012",
      "venue": "2012 IEEE symposium on e-learning, emanagement and e-services"
    },
    {
      "citation_id": "36",
      "title": "Smart classroom: real-time feedback on lecture quality",
      "authors": [
        "N Gligorić",
        "A Uzelac",
        "S Krco"
      ],
      "year": "2012",
      "venue": "2012 IEEE International Conference on Pervasive Computing and Communications Workshops"
    },
    {
      "citation_id": "37",
      "title": "Affective modelling of users in HCI using EEG",
      "authors": [
        "J Kumar",
        "J Kumar"
      ],
      "year": "2016",
      "venue": "Procedia Computer Science"
    },
    {
      "citation_id": "38",
      "title": "Affective database for e-learning and classroom environments using indian students' faces, hand gestures and body postures",
      "authors": [
        "A Guddeti"
      ],
      "year": "2020",
      "venue": "Future Generation Computer Systems"
    },
    {
      "citation_id": "39",
      "title": "Automated detection of engagement using video-based estimation of facial expressions and heart rate",
      "authors": [
        "H Monkaresi",
        "N Bosch",
        "R Calvo",
        "S D'mello"
      ],
      "year": "2017",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "40",
      "title": "The faces of engagement: Automatic recognition of student engagementfrom facial expressions",
      "authors": [
        "J Whitehill",
        "Z Serpell",
        "Y Lin",
        "A Foster",
        "J Movellan"
      ],
      "year": "2014",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "41",
      "title": "Prediction and localization of student engagement in the wild",
      "authors": [
        "A Kaur",
        "A Mustafa",
        "L Mehta",
        "A Dhall"
      ],
      "year": "2018",
      "venue": "Digital Image Computing: Techniques and Applications (DICTA)"
    },
    {
      "citation_id": "42",
      "title": "Facial emotion recognition of students using convolutional neural network",
      "authors": [
        "I Lasri",
        "A Solh",
        "M Belkacemi"
      ],
      "year": "2019",
      "venue": "2019 Third International Conference on Intelligent Computing in Data Sciences (ICDS)"
    },
    {
      "citation_id": "43",
      "title": "Automatic detection of students' affective states in classroom environment using hybrid convolutional neural networks",
      "authors": [
        "A Guddeti"
      ],
      "year": "2019",
      "venue": "Education and Information Technologies"
    },
    {
      "citation_id": "44",
      "title": "Impact of inquiry interventions on students in elearning and classroom environments using affective computing framework",
      "authors": [
        "T Ashwin",
        "R Guddeti"
      ],
      "year": "2020",
      "venue": "User Modeling and User-Adapted Interaction"
    },
    {
      "citation_id": "45",
      "title": "Building a face expression recognizer and a face expression database for an intelligent tutoring system",
      "authors": [
        "R Zatarain-Cabada",
        "M Barron-Estrada",
        "F Gonzalez-Hernandez",
        "H Rodriguez-Rangel"
      ],
      "year": "2017",
      "venue": "IEEE 17th International Conference on Advanced Learning Technologies (ICALT)"
    },
    {
      "citation_id": "46",
      "title": "Spontaneous facial expression database for academic emotion inference in online learning",
      "authors": [
        "C Bian",
        "Y Zhang",
        "F Yang",
        "W Bi",
        "W Lu"
      ],
      "year": "2019",
      "venue": "IET Computer Vision"
    }
  ]
}