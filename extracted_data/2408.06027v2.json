{
  "paper_id": "2408.06027v2",
  "title": "A Comprehensive Survey On Eeg-Based Emotion Recognition: A Graph-Based Perspective",
  "published": "2024-08-12T09:29:26Z",
  "authors": [
    "Chenyu Liu",
    "Xinliang Zhou",
    "Yihao Wu",
    "Yi Ding",
    "Liming Zhai",
    "Kun Wang",
    "Ziyu Jia",
    "Yang Liu"
  ],
  "keywords": [
    "EEG",
    "Emotion Recognition",
    "Graph Graphs in EEG-based Emotion Recognition Node Regregation Graph Manipulation Edge Computatio Feature Selection Temporal Nodes Frequency Nodes ATGRNet [54]",
    "SGLNet [26]",
    "ST-GCLSTM [20]",
    "Siam-GCAN [114]",
    "MD-AGCN [58]",
    "ASTG-LSTM [62]",
    "VSGT [12]. BGAGCN [109]",
    "PGCN [37]",
    "BGAGCN [109]. IAG [94]",
    "V-IAG [95]",
    "GECNN [96]",
    "SCC-MPGCN [119]",
    "GMSS [63]",
    "LGGNet [16]",
    "STFCGAT [65]",
    "PGCN [122]",
    "LAG [23] MSTGNN [68]",
    "G2G [38]",
    "STFCGAT [65]",
    "ResGAT [7]. HetEmotionNet [36]",
    "MD-AGCN [58]",
    "DBGC-ATFFNetAFTL [99]",
    "MD GRL[101]. 2 SparseDGCNN [115]",
    "SOGNN [55]",
    "AHGCN [108]",
    "DAGAM",
    "[107]",
    "GJFusion [35]",
    "CCSR-GCN [110]",
    "MD GRL[101]. 2 VBH-GNN [67]",
    "VSGT [12]",
    "OnMHF [73]",
    "GDDN [8]",
    "DGCNN [98]",
    "GCB-Net [116]",
    "RGNN [121]",
    "OGSSL [77]",
    "SparseDGCNN [115]",
    "GMSS [63]",
    "OMHGL [72]",
    "etc. BF-GCN [53]",
    "Grop [106]",
    "DS-AGC [112]",
    "IAG [94]",
    "HetEmotionNet [36]",
    "SOGNN [55]",
    "GFIL [79]",
    "SWSC [78]",
    "HD-GCN [111]",
    "AHGCN [108]",
    "MD-GCN [17]",
    "etc IAG [94]",
    "V-IAG [95]",
    "ASTG-LSTM [62]",
    "SOGNN [55]",
    "PGCN [122]",
    "HN-DGST [11]",
    "ResGAT [7]",
    "PGCN [37]",
    "Gusa [61]. Elucidean Distance: GFIL [79]",
    "SWSC [78]. Parameter Matrix: GECNN [96]",
    "AHGCN [108]",
    "ASGC [76]",
    "DBGC-ATFFNetAFTL [99]",
    "BF-GCN [53]",
    "ATGRNet [54]",
    "CCSR-GCN [110]. Manhattan Distance: Siam-GCAN [114]",
    "JAGP [80]. Concatenation: VBH-GNN [67]",
    "VSGT [12]",
    "CGRU-MDGN [31]",
    "GDDN [8]. Dot Product: LGGNet [16]. Gaussian Kernel: HD-GCN [111] RGNN [121]",
    "MD-GCN [17]",
    "DAGAM [107]",
    "SGLNet [26]",
    "PGCN [122]",
    "MD GRL[101]. Brain Region: HD-GCN [111]",
    "GMSS [63]",
    "LGGNet [16]. Node Connection: G2G [38]",
    "PGCN [37]",
    "BGAGCN [109]",
    "CU-GCN [24]",
    "SSPA-GCN [118] DGCNN [98]",
    "GCB-Net [116]",
    "Grop [106]",
    "SparseDGCNN [115]",
    "Residual GCB-Net [56]",
    "DGGN [30]",
    "BLB-DGCNN [3]. MI: HetEmotionNet [36]",
    "GJFusion [35]",
    "MTLFuseNet [57]. PCC: MD-AGCN [58]",
    "ST-GCLSTM [20]",
    "HN-DGST [11]",
    "BGAGCN [109]. PLV: SCC-MPGCN [119]",
    "ST-SCGNN [88]",
    "BF-GCN [53]. PLI: MSTGNN [68]",
    "STFCGAT [65]",
    "MESNP [52]. Euclidean: OGSSL [77]",
    "MDTDDL [29]",
    "MRGCN [84]. Cosine Similarity: TARDGCN [60]",
    "OMHGL [72]",
    "OnMHF [73]. Logarithm: CGCNN [45]",
    "DG-JCA [10]. Dot Product: AMGCT [64] HetEmotionNet [36]",
    "SCC-MPGCN [119]",
    "BLB-DGCNN [3]",
    "LGGNet [16]",
    "SGLNet [26]",
    "ResGAT [7]",
    "GCNs-FSMI [59]",
    "BGAGCN [109]",
    "OnMHF [73]",
    "VSGT [12]",
    "SSPA-GCN [118]",
    "VBH-GNN [67]. ASM: SparseDGCNN [115]",
    "SOGNN [55]. Check Table.1 for detail. 2"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Compared to other modalities, electroencephalogram (EEG) based emotion recognition can intuitively respond to emotional patterns in the human brain and, therefore, has become one of the most focused tasks in affective computing. The nature of emotions is a physiological and psychological state change in response to brain region connectivity, making emotion recognition focus more on the dependency between brain regions instead of specific brain regions. A significant trend is the application of graphs to encapsulate such dependency as dynamic functional connections between nodes across temporal and spatial dimensions. Concurrently, the neuroscientific underpinnings behind this dependency endow the application of graphs in this field with a distinctive significance. However, there is neither a comprehensive review nor a tutorial for constructing emotion-relevant graphs in EEG-based emotion recognition. In this paper, we present a comprehensive survey of these studies, delivering a systematic review of graph-related methods in this field from a methodological perspective. We propose a unified framework for graph applications in this field and categorize these methods on this basis. Finally, based on previous studies, we also present several open challenges and future directions in this field. \n CCS Concepts ‚Ä¢ Computing methodologies ‚Üí Artificial intelligence; ‚Ä¢ Humancentered computing ‚Üí Human computer interaction (HCI).",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Emotion is an integral and complex aspect of human cognition, playing a crucial role in decision-making, behavior, and social interactions  [1] . Consequently, emotion recognition is essential for mental health diagnosis and human-computer interaction  [122] . In this context, the direct correlation between electroencephalogram (EEG) signals and brain activity has established EEG-based emotion recognition as a highly specific and valuable task. First, EEG is a manifestation rather than an expression of emotion, which is more likely to reveal the genuine emotional state than other modalities objectively. The expression of emotion includes facial micro-gestures  [102] , embodied behavior  [13] , gesture  [40] , speech intonation and voice quality  [24] , which serve a communicative function and are largely under conscious deliberate control  [31] . In addition, EEG recordings provide direct measures of neural activity, offering a more accurate representation of brain emotional states than other physiological manifestations of emotion. Physiological metrics such as skin conductivity, temperature, heart rate, etc., are manifestations of physiological systems in emotional states that do not reflect emotional activity in the human brain directly. Therefore, EEG-based emotion recognition tasks hold irreplaceable significance in the study of genuine human emotions and the exploration of emotional activities within the human brain.\n\nIn the field of EEG-based research, emotion recognition requires more attention to dependency between brain regions compared to other paradigms  [41] . As illustrated in Figure  1  (a), the human brain functions as a complex network with hierarchical and functional organization at the level of brain regions  [84] . These regions are responsible for processing specific functions and are particularly relevant to various EEG-based paradigms, as shown in Figure  1 (b) . Specifically, the speech decoding paradigm focuses on the temporal lobe, which is responsible for language comprehension and processing  [26] . The primary motor cortex, located in the frontal lobe,  regulates motor functions and is thus relevant to motor imagery paradigms  [45] . Visual stimulation activates the occipital lobe, the primary brain region of interest for the steady-state visually evoked potentials (SSVEP) paradigm  [91] . However, as shown in Figure  1  (c), emotions are high-level neurocognitive functions expressed as cognitive-emotional interactions generated from brain regions with a high degree of connectivity  [82] . These interconnected brain regions do not function independently  [21] . Activating a particular brain region often leads to the activation of other regions within the connected network  [42] . Thus, developing neurophysiologically meaningful networks to effectively model the connectivity among functional brain regions during emotional states is central to the field. A significant trend in modeling the aforementioned connectivity is the application of graphs. Graphs excel at representing relational data through nodes and edges, making them particularly suitable for modeling the complex interactions between brain regions during emotional states. The local or distributed processes between brain regions during emotional states  [49]  can be effectively modeled by edge-based node aggregation  [41] , where the edge represents the connectivity between brain regions. As a result, an increasing number of methods have employed graphs to capture the intricate connectivity patterns inherent in emotion-related EEG, which are crucial for enhancing the accuracy of emotion recognition  [27] . These approaches are specifically developed from diverse perspectives to integrate brain physiology paradigms, distinguishing them structurally from graph-based techniques in other fields. Nonetheless, there is currently no standardized framework for the application of graphs in EEG-based emotion recognition. This lack of standardization highlights the need for a comprehensive survey that encompasses various graph-based methodologies in this field.\n\nTo this end, this paper presents a systematic survey of graph applications in EEG-based emotion recognition. Our aim is to offer comprehensive guidance on constructing graph-based models in this field. The contributions of this survey are summarized as follows:\n\n‚Ä¢ The first survey. This survey provides a comprehensive and systematic review of graph-related methods in EEG-based emotion recognition. To the best of our knowledge, this is the first and only survey work on such a topic.\n\n‚Ä¢ Systematic methodology-centric taxonomy. This survey introduces a unified framework from a methodological standpoint on graph application and provides a clear guideline for the construction of graph-related methods in this field. ‚Ä¢ Future research directions. This survey summarises and highlights future directions to facilitate graph application in this field.\n\n(a) Feature Selection",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Background 2.1 Eeg-Based Emotion Recognition",
      "text": "EEG-based emotion recognition leverages the close relationship between EEG signals and brain activity to accurately identify emotional states. As shown in Figure  1  (c), emotions are complex neurocognitive processes involving dynamic interactions among multiple brain regions, such as the frontal lobes, parietal lobes, and temporal lobes  [86] . Each brain region's activity during emotional states contributes uniquely to the overall emotional experience, with specific areas playing distinct roles in the processing of different emotions  [5, 32, 88] . These regions do not operate in isolation; rather, they interact in a highly coordinated manner, forming a network of activity that underlies the processing and regulation of emotions  [83] . The various channels of an EEG can measure the neural activity of these corresponding regions, capturing real-time changes in brain dynamics  [2] . Thus, emotion-related EEG can reflect the functional connectivity between different brain regions during emotional states, providing a comprehensive view of how emotions are processed in the brain.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Preliminaries",
      "text": "Graph-related methods in EEG-based emotion recognition can be indicated as taking EEG signal X ‚àà R ùê∂ √óùëÜ as input, where ùê∂ is the number of channels and ùëÜ is the number of samples, constructing graphs and predicting emotion labels Y ‚àà R 1 . We consider an emotion-related graph denoted as G = {V, E}, where V and E represent the sets of nodes and edges, respectively. The feature matrix of V is denoted as V ‚àà R ùê∂ √óùê∑ , where ùê∑ is the dimension of node features. An adjacency matrix A ‚àà R ùê∂ √óùê∂ represent the connections between nodes, where ùëí ùëñ,ùëó = A[ùëñ, ùëó] if (ùë£ ùëñ , ùë£ ùëó ) ‚àà E.\n\nTo learn the node representations in a graph G, most methods adhere to the following paradigm of neighborhood aggregation and message passing:\n\nwhere ùêø is the number of network layers, h\n\nùëñ (1 ‚â§ ùëô ‚â§ ùêø) denotes the node embedding of ùë£ ùëñ at the ùëô-th layer. AGGR and COMB represent functions used for aggregating information from neighborhood nodes N (ùë£ ùëñ ) and combining ego-and neighbor-representations, respectively.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Taxonomy",
      "text": "Recent advancements in graph application have demonstrated their great potential to achieve better performance in EEG-based emotion recognition. These methods focus on different aspects of the graph but generally address a few key questions:  (1)  what kind of EEG features should be selected; (2) how to compute the adjacency matrix to characterize the connectivity of brain regions in emotional states; (3) how to perform node aggregation; and (4) what kind of graph manipulation should be adopted. Based on these questions, we summarized and categorized the existing studies based on a unified framework as shown in Figure  2 .\n\nThe proposed taxonomy is illustrated in Figure  3 , and the related works can be found in Table  1 . The proposed taxonomy offers a structured and comprehensive classification to deepen the understanding of graph-based approaches in EEG-based emotion recognition. It is organized into four hierarchical levels, starting with the feature selection, followed by the edge computation, node aggregation, and finally, the graph manipulation. (a) Feature selection indicates the type of node features selected, which contains temporal and frequency nodes; (b) Edge computation specifically refers to calculating the adjacency matrix, which is further classified into model-dependent and model-independent edges according to the participation of parameters. (c) Node aggregation denotes the updating method of nodes, which is categorized into spectral-based and spatial-based methods. (d) Graph manipulation represents the manipulation of graph structures at the network level, including multi-graphs, hierarchical graphs and spatio-temporal graphs. In the following, we introduce the four stages and their subcategories in more detail.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Feature Selection",
      "text": "The unique characteristics of emotion-related EEG have led to the development of distinct methods for node feature selection in graphbased approaches within this field. As EEG is a time series data, the most intuitive approach is to utilize temporal features. Additionally, due to the direct correlation between EEG frequency and emotional activity  [4] , some methods employ unique approaches to extract frequency domain features as nodes. In this section, we classify the types of nodes employed in graph-based methods into temporal and frequency nodes. In the following, we provide a detailed introduction to these two types.\n\nTemporal Nodes: This is the most intuitive and straightforward method, where nodes directly use raw signals or time-related features. For example, LGGNet  [15]  and SCC-MPGCN  [118]  input the raw EEG signals into the network after basic filtering. Raw EEG signals facilitate joint analysis with other physiological signals. HetEmotionNet  [35]  and VBH-GNN  [67]  incorporate temporal physiological signals such as Electrocardiogram (ECG) and Galvanic Skin Response (GSR) as auxiliary modalities for synchronous time-domain analysis. Additionally, Sparse-DGCNN  [115]  employs Amplitude Spectrum Mean (ASM), using the average amplitude spectrum of EEG signals as node features.\n\nFrequency Nodes: The fundamental reason for utilizing frequency features as nodes is that there exists a direct connection between different frequency bands of EEG and different emotions  [4, 70] , such as the ùõΩ-band is associated with anxiety. Therefore, frequency nodes typically focus on five specific bands: delta (1-3 Hz), theta (4-7 Hz), alpha (8-13 Hz), beta (14-30 Hz), and gamma (31-50 Hz) bands. The most commonly used frequency node at present is the Differential Entropy (DE) feature  [17] :\n\nwhere ùúá and ùúé denote the parameters of Gaussian distribution N ùúá, ùúé 2 that the EEG obeys. Many methods, such as  [16, 64, 78] , estimate the probability density function of the signal and use the aforementioned formula to calculate the DE for each band as node features. Furthermore, methods such as  [60, 95, 116]  utilize combinations of DE features from symmetrical electrodes (differential asymmetry and rational asymmetry). In addition, methods such as  [37, 61, 73]  use the Power Spectral Density (PSD) of EEG signals. A few methods employ other frequency domain features, such as the Differential Cumulative Average of Uniformity (DCAU) used by DGCNN  [98]  and the Short-Time Fourier Transform (STFT) used by GDDN  [8] .\n\nRemark. Although the majority of current research employs frequency nodes, we argue this prevalence is not due to the superiority of frequency nodes over temporal nodes but is instead influenced by the datasets. For instance, methods using the SEED  [119]  dataset commonly adopt DE features, while those using the MPED  [97]  dataset typically use STFT. Only a few methods utilizing the DREAMER  [93]  and DEAP  [43]  datasets employ temporal nodes. The high usage rate of the SEED dataset has contributed to the prevalence of frequency nodes. It is evident that frequency nodes can mitigate the effect of transient noise (e.g., eye movements) across multiple frequency bands, thereby providing a more stable representation of emotional states. However, apart from their endto-end implementation, temporal nodes exhibit greater potential in reflecting event-related potentials in EEG under emotional activity, such as transient changes in amplitude and waveform  [90] . Additionally, temporal nodes offer higher extensibility, as they can accommodate other physiological signals for joint analysis  [104] .",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Edge Computation",
      "text": "Edge computation poses a significant challenge for graph-based methods in EEG-based emotion recognition. On the one hand, the edges in emotion-related graphs have inherent neurophysiological foundations. For instance, the electrode positions of EEG acquisition devices generally conform to the 10-20 system, which dictates fixed distances and connectivity between nodes, each representing different brain regions. On the other hand, the dependencies between brain regions under emotional states are highly variable. Firstly, there are differences in brain region dependencies across different emotional states  [82] . Secondly, even under the same emotional state, different subjects exhibit variations in the intensity and patterns of their emotional brain activities  [65] . Additionally, for the same subject, brain activity patterns can vary when experiencing the same emotion at different times due to differences in response intensity and psychophysiological states  [100] . Therefore, graphbased methods in this field strive to balance the fixed and variable nature of edges. In this section, we categorize these methods into two types based on whether model parameters are involved in edge computation: model-independent and model-dependent methods.\n\nIn the following, we describe these two methods and their subtypes in detail.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Model-Independent Edge",
      "text": "The computation of model-independent edges does not involve model parameters. These edges aim to maximally preserve the neurophysiological foundations of emotion-related edges, thus having clear physiological structures and physical significance. The existing literature typically adopts the following two strategies.\n\nPrior Edge: In this method, edges are manually defined based on electrode connections from physiological paradigms. An example of prior edges is in  [16, 107, 120] , which utilize the theory that the strength of connections between brain regions decays as a function of the inverse square of the physical distance  [87] . These methods use 3-D coordinates to calculate the physical distances between electrodes as the edges. Methods such as  [37, 109, 121]  determine the connectivity between electrodes directly based on the electrode arrangement in the International 10-20 system, thereby constructing the adjacency matrix. Based on this,  [15, 62, 111]  restrict the connectivity between electrodes within specific groups, considering the distribution of brain regions and the symmetry between the left and right hemispheres.\n\nSiganl Correlation Edge: The computation in this method is based on signal processing, using the similarity or distance between EEG signals from different channels as edges. The propagation of physiological electrical signals is diffusive  [76] , which means that the signal collected by one electrode will contain EEG signals from adjacent electrodes. Therefore, signal correlation edges preserve the neurophysiological foundations between electrodes through signallevel similarity.  [28, 78, 85]  use the Euclidean distance between node signals as edges. Similarly,  [59, 73]  employ cosine distance, while MSTGNN  [68]  uses the Phase Lag Index (PLI). Additionally,  [11, 19, 57, 109]  utilize the Pearson Correlation Coefficient (PCC) to compute the strength of the linear relationship between signals as edges.  [51, 52, 72, 118]  use the Phase Locking Value (PLV) to calculate the degree of phase similarity between electrode signals at a particular frequency as their edges. Other methods include Gaussian kernel, such as  [98, 115, 116] , and Mutual Information (MI), as used by  [34, 35, 56] .\n\nRemark. The limitation of model-independent edges is that, although they preserve the basic connectivity of electrodes under emotional states, it is challenging to model the synergistic relationships between brain regions during emotional activities. Even the relatively flexible signal correlation edges, which use data-driven computation methods to reflect differences between different individuals and emotional states, are still insufficient to capture the complex spatial-temporal dependencies. However, the relatively fixed learning approach of model-independent edges does not mean they cannot be optimized during training. A common update method is:\n\nwhere ùúå denotes the learning rate. This allows model-independent edges to adapt to the variability of EEG under emotional states to some extent and ensures stable performance in scenarios with limited training data.",
      "page_start": 5,
      "page_end": 6
    },
    {
      "section_name": "Model-Dependent Edge",
      "text": "The introduction of parameters allows model-dependent edges to dynamically fit the complex dependencies in emotion-related EEG. Model-dependent edges can adjust and refine the relationships between nodes, which represent different brain regions, based on the varying intensities and patterns of emotional activities. The existing literature typically adopts the following two strategies.\n\nWeighted Edge: In this method, model parameters are introduced as a weight matrix in the computation, transforming the connection between nodes into nonlinear ones through activation functions. It can be regarded as a special case of signal correlation edges combined with model parameters. A common computation method for weighted edges is:\n\nwhere ùúé (‚Ä¢) represents an activation function, such as ReLU. ùë• ùëñ and ùë• ùëó represent the node embeddings of ùë£ ùëñ and ùë£ ùëó , and ùúî denotes the model parameters. R{‚Ä¢, ‚Ä¢} represents a specific operation on the node embedding pairs. For example, in  [81, 114] , it represents the computation of the Manhattan distance, while in  [71, 112] , it represents the computation of the Euclidean distance. Additionally, some methods, such as  [8, 30] , concatenate the node embeddings directly for linear transformation, with VBH-GNN concatenating the node embeddings along the channel dimension and using convolutional layers instead of linear transformations to reduce the number of parameters.\n\nSubspace Edge: This method uses model parameters to project the node embeddings into a subspace, where the dot product of the projected nodes is used as edges. The process can be described as:\n\nwhere ùúî ùëñ and ùúî ùëó represent the projection matrices for two nodes, respectively. For example,  [94, 95, 121]  adopt the above computation formula. Fundamentally, the dot product in the projection space is consistent with the dot product of the Query and Key matrices in the attention mechanism. Therefore, some methods, such as  [7, 11, 54, 61] , directly use the output of the attention mechanism as edges.\n\nRemark. Model parameters allow these edges to dynamically fit the complex spatial-temporal dependencies in emotion-related EEG.\n\nFor example, as a special case of signal correlation edges, weighted edges create more flexible nonlinear connections. However, the introduction of more model parameters increases the risk of overfitting. This is particularly true for subspace edges, which lack specific node relationship constraints, making it difficult to generalize in scenarios with insufficient training data. Additionally, some methods, such as  [53, 77, 108, 110] , randomly initialize a parameter matrix as the adjacency matrix. This entirely data-independent approach is even more challenging to train. Although many previous studies have not opted for model-dependent edges in subjectdependent scenarios, we argue that this parameterized, data-driven edge computation method is the future trend for EEG-based emotion recognition. For example, for cross-dataset or cross-subject domain adaptation scenarios or emotion foundation models, adopting model-dependent edges can more accurately capture the underlying dependencies in emotion-related EEG data. Moreover, one potential approach is to integrate more neurophysiological foundations into model-dependent edges. For instance, VSGT  [66]  simulates the superposition state of neuronal electrical signals using Gaussian approximation and introduces parameters through reparameterization  [38]  to update model-dependent edges.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Node Aggregation",
      "text": "Graph-based methods in this field commonly utilize convolutional operations to aggregate node features. These methods generate representations for node ùë£ ùëñ by aggregating its own features ‚Ñé ùëñ and the features of its neighbors ‚Ñé ùëó where ùë£ ùëó ‚àà N (ùë£ ùëñ ). Consequently, these methods employ a fixed number of convolutional graph layers to extract high-level node representations, thereby capturing the dependencies between brain regions under emotional states. We categorize these methods into spectral-based and spatial-based approaches. In the following sections, we delve into the specifics of these two categories and their subtypes.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Spectral-Based Method",
      "text": "Spectral-based methods capture the dependencies between brain regions under emotional states by transforming all node features into a weighted sum of different feature vectors through the graph Fourier transform. This means that the features of all EEG channels are filtered through a fully connected feature space, with messages being simultaneously transmitted between all nodes, thereby simulating the global coordination between brain regions under emotional states. We define the convolution process of this aggregation method as:\n\nwhere ùúé is the activation function, ‚Ñé (ùëô -1) ùëñ denotes the node embedding of ùë£ ùëñ at the ùëô-th layer, and G (ùëô -1) ùëñ ùëó represents a diagonal matrix with learnable parameters. This process can also be seen as using G as a filter to remove noise from the emotion-related EEG graph signals. The existing research employs the following two types of filters.\n\nPolynomial Filters: In this method, the filter is replaced by a simplified polynomial function, avoiding explicit eigenvalue decomposition and thereby reducing the time complexity. In this field, all methods using polynomial filters, such as  [53, 95, 98] , employ Chebyshev expansion mentioned in ChebNet  [14]  to construct the filter:\n\nwhere Œõ = 2ùö≤ ùúÜ max -I ùëÅ is the eigenvalue matrix scaled in the range [-1, 1]. ùö≤ is a diagonal matrix of eigenvalues. T ùëò (ùë•) = 2ùë• T ùëò -1 (ùë•) -T ùëò -2 (ùë•) constructs the orthogonal space, and T ùëò ( Œõ) is the ùëò-th order Chebyshev polynomial at Œõ.\n\nLinear Filters: Linear filters are a further simplification of polynomial filters. Methods that use linear filters, such as  [72, 81, 112] , similar to GCN  [39] , adopt the first-order approximation of the Chebyshev expansion as the filter. Their convolution process can be summarized as follows:\n\nwhere ùúî ùëñ represents the weight matrix.\n\nis the renormalization trick of the adjacency matrix. Obviously, the graph filter is linear with the input adjacency matrix. From a spatial-based perspective, these methods can be considered as aggregating feature information from a node's neighborhood.\n\nRemark. Currently, there has been limited innovation in the design of filters within graph-based methods in this field. Instead, researchers continue to use established methods such as ChebNet and GCN. However, even GCN, an improved form of ChebNet, has seen numerous advancements and modifications within the graph neural network domain due to its inherent limitations. The brain region activities under emotional states are complex and dynamic, making it challenging for the simple linear filters of GCN to effectively capture the relationships between EEG channels. This is because the predefined filters in GCN are typically designed for firstorder information, which cannot directly capture such high-order relationships. In summary, there is a need for further exploration and improvement in the selection and design of filters, as well as in the development of methods specifically tailored for emotionrelated EEG. Combining linear filters with complex filters to learn high-order brain region dependencies should be a key focus for EEG-based emotion recognition.",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "Spatial-Based Methdos",
      "text": "Spatial-based methods define node aggregation based on the spatial relationships between nodes. Specifically, these methods convolve the node representation of the central channel with those of its neighboring channels to derive an updated representation for the central channel, thereby propagating information along the connectivity of the electrodes. The primary distinction between spatial-based and spectral-based methods lies in their respective modes of information propagation between nodes. Methods such as  [7, 37, 64]  incorporate attention mechanisms during the propagation process to assign weights to the contributions of neighboring nodes to the central node. Consistent with the GAT  [103] , their update process can be summarized as:\n\nwhere ùõº ùëñ ùëó = ùúé (ATT(‚Ñé\n\n)) represents the attention weight, or connective strength, between ùë£ ùëñ and ùë£ ùëó . Similar to linear filters, these methods update node embeddings through linear transformations. However, their adjacency matrices, which denote the existence of edges between nodes, limit the update scope of the central node to its connected neighbors. This results in sparse adjacency matrices that emphasize local spatial dependencies.\n\nAnother method is grounded in the theory that there exist inherent connections and pathways in the brain during emotional activities  [6] . MSTGNN  [68]  utilizes the minimum spanning tree to simulate pathways between electrodes. The pathways are defined as the routes through which electrical signals propagate during emotional activities. Within a pathway, each node can have up to one parent node and multiple child nodes. Consequently, the update method is:\n\nwhere ‚Ñé (ùëô -1) ùëì represents the node embedding of the parent node. If ùë£ ùëñ is the root node, the parent node embedding is set to zero. ‚Ñé (ùëô -1) ùëê represents the node embeddings of the child nodes ùë£ ùëê ‚àà N (ùë£ ùëñ ). MEAN denotes averaging over all child nodes. ùúî ùëì and ùúî ùëê are learnable parameters for parent and child nodes.\n\nRemark. In EEG-based emotion recognition, the boundaries between spatial-based and spectral-based methods are becoming increasingly blurred. This is because node aggregation in spatial-based methods is essentially an approximate linear process, which aligns with the principles of linear filters used in spectral-based methods. Consequently, employing an attention mechanism to infer emotion-related EEG edges followed by node aggregation using spectral-based methods is fundamentally and practically similar to first determining electrode connectivity and then incorporating attention mechanisms within spatial-based aggregation.\n\nA promising approach is to integrate neurophysiological foundations into spectral-based methods. For example, MSTGNN uses Minimum Spanning Trees (MST) to simulate brain pathways under emotional states. This aligns with the perspectives introduced in edge computation, emphasizing the incorporation of neurophysiological foundations into model parameters. By doing so, models can more accurately capture the intricate dependencies and interactions that characterize emotional brain activity, enhancing both the robustness and interpretability of EEG-based emotion recognition systems. In summary, the convergence of spatial-based and spectralbased methods, along with the integration of neurophysiological insights, holds significant potential for advancing the effectiveness of EEG-based emotion recognition models.",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "Graph Manipulation",
      "text": "In EEG-based emotion recognition, graph-related methods frequently implement specific model-level graph manipulations to enhance the model's ability to represent and learn the complex dependencies inherent in the data. These manipulations address the multifaceted nature of emotion-related EEG, which includes variations across both the frequency and temporal domains, as well as intra-and inter-regional brain connections. Such structural adjustments are crucial for tailoring graph representations to better align with the neurophysiological foundations of emotional brain activity. Existing literature frequently adopts the following three strategies:",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Hierachical Graph",
      "text": "Hierarchical Graphs leverage the natural grouping of nodes to align with the physiological foundations of emotion-related EEG, particularly the distribution of brain regions. This approach aims to construct the spatial dependencies of emotion-related EEG from a more macroscopic perspective. Based on the different types of dependencies established by this method, we categorize existing research into two types.\n\nBrain Region Graph: In this method, channel-level nodes are grouped to further infer inter-regional dependencies at the brain region level. These dependencies reflect the coordination between different brain areas, such as the interactions between the frontal cortex and the amygdala during emotion regulation  [88] . One type of method employs a manually established hierarchy based on the distribution of electrodes corresponding to different brain regions. For example,  [94, 95]  infer fully connected spatial dependencies in emotion-related EEG and then divide the brain regions into 17 groups according to the 10-20 system, averaging the embeddings of channels within each group to obtain regional embeddings. Another strategy, adopted by methods such as  [22, 62, 64, 96] , is to first group nodes based on brain region distribution to learn intra-regional spatial dependencies and then use the regional graph embeddings as nodes in a global graph to learn inter-regional relationships. In addition to grouping based on brain regions, some methods like  [15, 121]  also divide the hierarchy according to the left and right hemispheres of the brain. The rest method involves adaptively grouping channels and then inferring spatial dependencies between these groups. For instance,  [108, 118]  set a parameter weight matrix to linearly transform the channel-level node embeddings, reducing the dimensionality of the graph embeddings from the number of channels to the number of brain regions to achieve hierarchical division.\n\nSparse Graph: This method aims to represent the small-world topology  [75]  of brain regions during emotional activities, characterized by densely clustered local connections with sparse long-range connections  [20] . The underlying theory is that certain brain functions activate only a limited number of brain regions. Thus, sparse cortical activity can explain the EEG patterns generated by deeper sources  [47] . For example, MD 2 GRL  [101]  uses a parameter as a threshold to filter and retain a specific number of nodes, thereby achieving sparse connectivity among brain regions. Similarly, methods in  [107, 118]  learn a variable weight for all nodes, selecting a specific number of nodes based on ranking. Additionally, conventional pooling methods can achieve similar results, as demonstrated by GJFusion  [34] .\n\nRemark. These two types of methods represent efforts in the field to combine neurological foundations with network structures. We argue that integrating them could potentially offer significant benefits. Currently, the approach of retaining a specific number of nodes in sparse graphs inevitably leads to the loss of potentially valuable information. Therefore, basing the model on the brain region graph and then inferring sparsity on the coarsened graph could maximize the retention of channel information while simulating the sparse connectivity of brain regions.",
      "page_start": 7,
      "page_end": 8
    },
    {
      "section_name": "Multi-Graph",
      "text": "Multi-Graph allows models to capture different emotion-related EEG dependencies simultaneously by concatenating multiple types of graph embeddings. This method leverages the complementary information provided by different graph structures, enriching the feature space and improving the model's ability to discern emotional states. Based on the complementary domains, we further introduce two types of this method in the following.\n\nTemporal&Frequency Graph: In this method, the model employs parallel graph structures to build the dependencies of emotionrelated EEG in both the temporal and frequency domains. Temporal dependencies enable the model to detect amplitude features that are closely correlated with brain region, while frequency dependencies capture the activation of specific frequency bands associated with different emotional states, such as increased energy in the alpha band during sadness  [18, 92] . Methods in  [35, 101]  integrate temporal&frequency graphs at the graph embedding level. They utilize a two-stream structure, where each stream corresponds to the temporal-spatial and frequency-spatial domains, respectively, and compute its own adjacency matrix. The graph embeddings from both streams are then concatenated and fed into a classifier. A distinct strategy employed by  [57, 99]  involves merging the adjacency matrices of the two streams before the node aggregation, resulting in a shared hybrid adjacency matrix.\n\nLocal&Globle Graph: This graph is less commonly applied in this field. Since it distinguishes itself from brain region graph methods only by decoupling the inference of inter-regional and intra-regional dependencies into two parallel processes. In the Local stream, electrodes are grouped based on brain regions, and connectivity is confined within these regions. Methods such as  [36, 109, 111]  utilize this strategy to focus on the local dependencies within specific brain areas. MRGCN  [85]  replaces the fixed brain region divisions with a more flexible framework. It introduces short-range and long-range spatial dependencies, which correspond to localized intra-region correlations and inter-region correlations, respectively.\n\nRemark. Currently, multi-graph methods in the field struggle to ensure that the accuracy improvements gained from multi-stream structures justify the additional computational burden. This challenge arises because most multi-graph implementations simply merge two types of graph embeddings without fully optimizing the interaction between them. However, it is undeniable that multigraph methods effectively leverage the complementary nature of different dependencies in emotion-related EEG data.",
      "page_start": 7,
      "page_end": 8
    },
    {
      "section_name": "Spatial-Temporal Graph",
      "text": "In this method, emotion-related EEG is decomposed into multiple time slices to construct temporal dependencies between these slices. This method views emotions as dynamic processes rather than static states. By using a temporal encoder, it captures the changes in these spatial dependencies over time to infer emotion labels. The difference between the current methods lies mainly in the selection of the encoder. For example,  [19, 25, 61]  employ LSTM as the encoder for sequential data. In HetEmotionNet, the LSTM is replaced with Gated Recurrent Units, while ATGRNet  [53]  uses a Temporal Convolutional Network (TCN). Some relatively simplified approaches, such as Siam-GCAN  [114] , concatenate all the graph embeddings and feed them into a fully connected layer. MD-AGCN  [57]  averages the graph embeddings of all time slices for further classification.\n\nRemark. Although the use of spatial-temporal graphs is currently limited, we argue this approach holds significant potential in this field. Emotions are dynamic processes that evolve with the development, intensification, and subsidence of internal and external stimuli  [33, 46] . Therefore, this method aligns more closely with the neurophysiological foundations of emotions. However, current applications of spatial-temporal graphs have not deeply explored the construction of dynamic brain region relationships under emotional states. Existing methods typically treat the graph embeddings of EEG time slices as wholes to learn temporal dependencies between slices, thus limiting spatial dependencies to within individual slices. In other words, current research mainly focuses on the temporal variations of spatial relationships within isolated segments and is unable to construct connections between different nodes across slices.",
      "page_start": 8,
      "page_end": 9
    },
    {
      "section_name": "Future Directions",
      "text": "In this section, we discuss some future research directions and possible approaches for graph application in EEG-based emotion recognition in addition to the challenges or limitations mentioned in the remarks in the previous sections.\n\nTemporal Graph: This method aims to address the issue of incomplete temporal dependency present in current spatio-temporal graph methods, as discussed in Section 7.3. This incomplete dependency refers to the lack of correlation between different channels across time slices. The spatio-temporal dependencies learned by existing methods are limited to the same electrode across different time slices, such as ùë£ ùë° -1 ùëñ and ùë£ ùë° ùëñ , while ignoring the relationships between different electrodes across time slices, such as ùë£ ùë° -1 ùëñ and ùë£ ùë° ùëó . These inter-electrode relationships across time slices correspond to the delayed responses of brain regions in emotional states, indicating that interactions between brain regions exhibit asynchrony. The persistence of emotions involves asynchronous activities of brain regions, representing delayed responses of other regions to the current region's activity  [50] . Therefore, a potential direction is to establish a temporal graph between adjacent time slices, where edges exist between nodes across time slices rather than within the same time slice. In summary, computing a temporal graph for every pair of adjacent time slices can model the more intricate temporal dependencies of brain regions in emotional states.\n\nDependency-Level Interpretability: Currently, interpretability in graph methods for this field has garnered little attention. However, given the physiological basis of emotion-related EEG, interpretability is a crucial direction for the future. We argue that the necessary interpretability methods in this field should focus on explaining the graph structure, specifically identifying which edges, rather than just nodes, are most important for emotion labels. Most interpretability methods are feature-level, such as  [9, 89]  that determine which channels or time slices are most important for emotion prediction. Due to the direct relationship between emotions and brain region dependencies, a promising approach is to highlight the significant edges, as illustrated in XGNN  [113] , thereby reflecting crucial brain region relationships in emotion-related EEG. Another potential direction is using this method to learn interpretable sparse graphs. Similar to XGNN, by predicting how adding edges to the current graph affects the final label and setting an upper limit on the number of edges, it is possible to identify the most impactful edges for the final emotion label. These edges represent the sparse cortical activity between brain regions during emotional activities.\n\nHeterogeneous Graph for Mixed Emotion: Although heterogeneous graphs have seen limited application in this field, we argue they represent a future mainstream trend, particularly as a promising approach for mixed emotion recognition. It is increasingly recognized that emotions are often mixed, meaning that subjects frequently experience two or more emotions simultaneously  [12, 48, 105] . The potential of heterogeneous graphs lies in their ability to reveal the blurred boundaries between mixed emotional states more effectively than brain-centric emotional interaction models alone. By integrating multimodal physiological data, heterogeneous graphs build upon EEG-based brain emotion interaction models to construct comprehensive representations of emotional interactions within brain-based physiological systems. These interactions are strongly associated with emotion; for example, there is a correlation between prefrontal cortex oxygenation and decreased facial skin blood flow during positive emotions, whereas this correlation is less pronounced during negative emotions  [69] . In summary, mixed emotion recognition is a crucial future research direction in this field, and the potential of heterogeneous graphs to elucidate the boundaries between mixed emotions makes it a method deserving of greater attention.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Conclusion",
      "text": "The rapid development of graph-based methods has revolutionized EEG-based emotion recognition. In this survey, we provide a comprehensive and updated review of graph techniques specifically designed for this field. We propose a novel taxonomy based on key components such as feature selection, edge computation, node aggregation, and graph manipulation. Our survey facilitates understanding the underlying mechanisms of applying graph methods to emotion recognition. Furthermore, we believe that consolidating the latest advancements and exploring future directions will inspire more innovative works within EEG-based emotion recognition.",
      "page_start": 9,
      "page_end": 9
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: (a), the human brain",
      "page": 1
    },
    {
      "caption": "Figure 1: Description of brain regions and EEG-based",
      "page": 2
    },
    {
      "caption": "Figure 1: (c), emotions are high-level neurocognitive functions expressed",
      "page": 2
    },
    {
      "caption": "Figure 2: A Unified framework of graph-related methods in",
      "page": 2
    },
    {
      "caption": "Figure 1: (c), emotions are complex neu-",
      "page": 2
    },
    {
      "caption": "Figure 2: The proposed taxonomy is illustrated in Figure 3, and the related",
      "page": 3
    },
    {
      "caption": "Figure 3: An overview of the categorization.",
      "page": 4
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Baseline": "",
          "Featrue Selection": "Temporal\nFrequency\nNodes\nNodes",
          "Edge Computation": "Model-independent Edge\nModel-dependent Edge",
          "Node Aggregation": "Spectral-\nSpatial-\nbased\nbased",
          "Graph Manipulation": "Hierachical\nMulti-\nSpatial-Temporal\nGraph\nGraph\nGraph",
          "Year": ""
        },
        {
          "Baseline": "",
          "Featrue Selection": "",
          "Edge Computation": "Prior\nSignal Correlation\nWeighted\nSubspace",
          "Node Aggregation": "",
          "Graph Manipulation": "",
          "Year": ""
        },
        {
          "Baseline": "DGCNN [98]\nGCB-Net [116]\nIAG [94]\nRGNN [120]\nV-IAG [95]\nSparseDGCNN [115]\nHetEmotionNet [35]\nASTG-LSTM [61]\nMD-AGCN [57]\nGECNN [96]\nSOGNN [54]\nGFIL [80]\nSWSC [79]\nSiam-GCAN [114]\nResidual GCB-Net [55]\nSCC-MPGCN [118]\nOGSSL [78]\nMSTGNN [68]\nJAGP [81]\nHD-GCN [111]\nGMSS [62]\nTARDGCN [59]\nAHGCN [108]\nBLB-DGCNN [3]\nMD-GCN [16]\nDBGC-ATFFNetAFTL [99]\nCGCNN [44]\nMDTDDL [28]\nOMHGL [73]\nLGGNet [15]\nG2G [37]\nSTFCGAT [64]\nMESNP [51]\nST-GCLSTM [19]\nDAGAM [107]\nDGGN [29]\nMSFR-GCN [71]\nST-SCGNN [72]\nSGLNet [25]\nGJFusion [34]\nAMGCT [63]\nASGC [77]\nST-SCGNN [72]\nPGCN [121]\nHN-DGST [11]\nMRGCN [85]\nResGAT [7]\nMTLFuseNet [56]\nGCNs‚ÄìFSMI [58]\nLAG [22]\nBF-GCN [52]\nPGCN [36]\nGusa [60]\nGDDN [8]\nBGAGCN [109]\nDG-JCA [10]\nCU-GCN [23]\nATGRNet [53]\nMD2GRL [101]\nCCSR-GCN [110]\nGrop [106]\nDS-AGC [112]\nOnMHF [74]\nCGRU-MDGN [30]\nVSGT [66]\nSSPA-GCN [117]\nVBH-GNN [67]",
          "Featrue Selection": "DE,PSD,DASM,RASM,DCAU\nDE,PSD,DASM,RASM\nDE\nDE\nDE,PSD,DASM,RASM\nASM\nDE,PSD,DASM,RASM,DCAU\nRaw\nDE,PSD\nDE\nDE,PSD,HHS\nASM\nDE,PSD,DASM,RASM,DCAU\nDE,PSD,DASM,RASM,DCAU\nDE,PSD,DASM,RASM,DCAU\nDE\nDE,PSD,DASM,RASM\nRaw\nDE\nDE\nDE\nDE\nDE\nDE,Welch\nDE\nRaw\nDE\nDE,PSD\nDE,PSD,DASM\nDE,PSD\nDE,PSD\nRaw\nDE,PSD\nDE\nPSD\nDE\nDE\nDE\nDE\nDE,STFT\nRaw\nDE\nDE\nDE\nDE\nDE,STFT\nDE,PSD,DASM,RASM,DCAU\nDE\nRaw\nDE\nRaw\nDE\nDE\nDE,STFT\nDE,PSD,DASM,RASM,DCAU\nDE,STFT\nRaw\nDE,PSD\nDE,PSD,DASM,RASM,DCAU\nDE,PSD,DASM,RASM\nDE,PSD\nDE,PSD\nDE\nDE\nDE\nRaw\nPSD\nDE\nRaw\nRaw\nRaw",
          "Edge Computation": "Gaussian Kernel\nGaussian Kernel\nAttention\nPhysical distance\nAttention\nGaussian Kernel\nMutual Information\nAttention\nPCC\nParameter Matrix\nAttention\nEuclidean Distance\nEuclidean Distance\nManhattan distance\nGaussian Kernel\nPLV\nEuclidean Distance\nPLI\nManhattan distance\nBrain Region\nGaussian Kernel\nBrain Region\nCosine Similarity\nParameter Matrix\nGaussian Kernel\nPysical Distance\nParameter Matrix\nLogarithm\nEuclidean Distance\nCosine Similarity\nBrain Region,Hemisphere\nDot Product\nNode Connection\nPLI\nPLI\nPCC\nPysical Distance\nGaussian Kernel\nEuclidean Distance\nPLV\nPysical Distance\nMutual Information\nDot Product\nParameter Matrix\nPLV\nPysical Distance\nAttention\nPCC\nAttention\nEuclidean Distance\nAttention\nMutual Information\nPCC\nDot Product\nPLV\nParameter Matrix\nNode Connection\nAttention\nAttention\nConcatenation\nNode Connection\nPCC\nLogarithm\nNode Connection\nParameter Matrix\nPysical Distance\nParameter Matrix\nGaussian Kernel\nEuclidean Distance\nCosine Similarity\nConcatenation\nConcatenation\nNode Connection\nConcatenation",
          "Node Aggregation": "Polynomial\nPolynomial\nPolynomial\nPolynomial\nPolynomial\nPolynomial\nLinear\nPolynomial\nLinear\nPolynomial\nLinear\nLinear\nLinear\nPolynomial\nPolynomial\nPolynomial\nPolynomial\nMST\nPolynomial\nLinear\nPolynomial\nPolynomial\nLinear\nPolynomial\nLinear\nPolynomial\nPolynomial\nPolynomial\nPolynomial\nLinear\nAttention\nAttention\nPolynomial\nLinear\nLinear\nLinear\nLinear\nPolynomial\nLinear\nLinear\nLinear\nLinear\nPolynomial\nLinear\nLinear\nLinear\nAttention\nLinear\nLinear\nPolynomial\nPolynomial\nLinear\nPolynomial\nLinear\nPolynomial\nLinear\nPolynomial\nPolynomial\nLinear\nPolynomial\nPolynomial\nPolynomial\nLinear\nLinear\nLinear\nPolynomial\nLinear",
          "Graph Manipulation": "Brain Region Graph\nBrain Region Graph\nSparse Graph\nTemporal&Frequency\nLSTM\nTemporal&Frequency\nAverage\nBrain Region Graph\nSparse Graph\nLinear\nBrain Region Graph\nLocal&Global\nBrain Region Graph\nSparse Graph\nTemporal&Frequency\nBrain Region Graph\nBrain Region Graph\nLSTM\nSparse Graph\nSNN,LSTM\nSparse Graph\nBrain Region Graph\nBrain Region Graph\nLocal&Global\nLocal&Global\nTCN\nSparse Graph\nTemporal&Frequency\nSparse Graph\nTemporal Graph",
          "Year": "2018\n2019\n2020\n2020\n2021\n2021\n2021\n2021\n2021\n2021\n2021\n2021\n2021\n2022\n2022\n2022\n2022\n2022\n2022\n2022\n2022\n2022\n2022\n2022\n2022\n2022\n2022\n2022\n2023\n2023\n2023\n2023\n2023\n2023\n2023\n2023\n2023\n2023\n2023\n2023\n2023\n2023\n2023\n2023\n2023\n2023\n2023\n2023\n2023\n2024\n2024\n2024\n2024\n2024\n2024\n2024\n2024\n2024\n2024\n2024\n2024\n2024\n2024\n2024\n2024\n2024\n2024"
        }
      ],
      "page": 12
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Cognitive neuroscience of human social behaviour",
      "authors": [
        "Ralph Adolphs"
      ],
      "year": "2003",
      "venue": "Nature reviews neuroscience"
    },
    {
      "citation_id": "2",
      "title": "A review of channel selection algorithms for EEG signal processing",
      "authors": [
        "Turky Alotaiby",
        "E Abd Fathi",
        "El-Samie",
        "Ishtiaq Saleh A Alshebeili",
        "Ahmad"
      ],
      "year": "2015",
      "venue": "EURASIP Journal on Advances in Signal Processing"
    },
    {
      "citation_id": "3",
      "title": "Accurate emotion recognition using Bayesian model based EEG sources as dynamic graph convolutional neural network nodes",
      "authors": [
        "Shiva Asadzadeh",
        "Tohid Yousefi Rezaii",
        "Soosan Beheshti",
        "Saeed Meshgini"
      ],
      "year": "2022",
      "venue": "Scientific Reports"
    },
    {
      "citation_id": "4",
      "title": "Decoding naturalistic affective behaviour from spectro-spatial features in multiday human iEEG",
      "authors": [
        "Maryam Bijanzadeh",
        "N Ankit",
        "Maansi Khambhati",
        "Deanna Desai",
        "Alia Wallace",
        "Heather Shafi",
        "Virginia Dawes",
        "Edward Sturm",
        "Chang"
      ],
      "year": "2022",
      "venue": "Nature human behaviour"
    },
    {
      "citation_id": "5",
      "title": "Anxious individuals shift emotion control from lateral frontal pole to dorsolateral prefrontal cortex",
      "authors": [
        "Bob Bramson",
        "Sjoerd Meijer",
        "Annelies Van Nuland",
        "Ivan Toni",
        "Karin Roelofs"
      ],
      "year": "2023",
      "venue": "Nature Communications"
    },
    {
      "citation_id": "6",
      "title": "Complex brain networks: graph theoretical analysis of structural and functional systems",
      "authors": [
        "Ed Bullmore",
        "Olaf Sporns"
      ],
      "year": "2009",
      "venue": "Nature reviews neuroscience"
    },
    {
      "citation_id": "7",
      "title": "Multi-channel EEG emotion recognition through residual graph attention neural network",
      "authors": [
        "Hao Chao",
        "Yiming Cao",
        "Yongli Liu"
      ],
      "year": "2023",
      "venue": "Frontiers in Neuroscience"
    },
    {
      "citation_id": "8",
      "title": "GDDN: Graph Domain Disentanglement Network for Generalizable EEG Emotion Recognition",
      "authors": [
        "Bianna Chen",
        "C Philip Chen",
        "Tong Zhang"
      ],
      "year": "2024",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "9",
      "title": "Learning to explain: An information-theoretic perspective on model interpretation",
      "authors": [
        "Jianbo Chen",
        "Le Song",
        "Martin Wainwright",
        "Michael Jordan"
      ],
      "year": "2018",
      "venue": "International conference on machine learning"
    },
    {
      "citation_id": "10",
      "title": "Dense Graph Convolutional With Joint Cross-Attention Network for Multimodal Emotion Recognition",
      "authors": [
        "Cheng Cheng",
        "Wenzhe Liu",
        "Lin Feng",
        "Ziyu Jia"
      ],
      "year": "2024",
      "venue": "IEEE Transactions on Computational Social Systems"
    },
    {
      "citation_id": "11",
      "title": "Hybrid Network Using Dynamic Graph Convolution and Temporal Self-Attention for EEG-Based Emotion Recognition",
      "authors": [
        "Cheng Cheng",
        "Zikang Yu",
        "Yong Zhang",
        "Lin Feng"
      ],
      "year": "2023",
      "venue": "IEEE Transactions on Neural Networks and Learning Systems",
      "doi": "10.1109/TNNLS.2023.3319315"
    },
    {
      "citation_id": "12",
      "title": "Understanding anhedonia in schizophrenia through lexical analysis of natural speech",
      "authors": [
        "Alex Cohen",
        "Annie St-Hilaire",
        "Jennifer Aakre",
        "Nancy Docherty"
      ],
      "year": "2009",
      "venue": "Cognition and emotion"
    },
    {
      "citation_id": "13",
      "title": "Towards the neurobiology of emotional body language",
      "authors": [
        "Beatrice De"
      ],
      "year": "2006",
      "venue": "Nature reviews neuroscience"
    },
    {
      "citation_id": "14",
      "title": "Convolutional neural networks on graphs with fast localized spectral filtering",
      "authors": [
        "Micha√´l Defferrard",
        "Xavier Bresson",
        "Pierre Vandergheynst"
      ],
      "year": "2016",
      "venue": "Advances in neural information processing systems"
    },
    {
      "citation_id": "15",
      "title": "LGGNet: Learning from local-global-graph representations for braincomputer interface",
      "authors": [
        "Yi Ding",
        "Neethu Robinson",
        "Chengxuan Tong",
        "Qiuhao Zeng",
        "Cuntai Guan"
      ],
      "year": "2023",
      "venue": "IEEE Transactions on Neural Networks and Learning Systems"
    },
    {
      "citation_id": "16",
      "title": "A multi-dimensional graph convolution network for EEG emotion recognition",
      "authors": [
        "Guanglong Du",
        "Jinshao Su",
        "Linlin Zhang",
        "Kang Su",
        "Xueqian Wang",
        "Shaohua Teng",
        "Peter Liu"
      ],
      "year": "2022",
      "venue": "IEEE Transactions on Instrumentation and Measurement"
    },
    {
      "citation_id": "17",
      "title": "Differential entropy feature for EEG-based emotion classification",
      "authors": [
        "Jia-Yi Ruo-Nan Duan",
        "Bao-Liang Zhu",
        "Lu"
      ],
      "year": "2013",
      "venue": "Differential entropy feature for EEG-based emotion classification"
    },
    {
      "citation_id": "18",
      "title": "Brain mechanisms underlying the emotion processing bias in treatment-resistant depression",
      "authors": [
        "Xiaoxu Fan",
        "Madaline Mocchi",
        "Bailey Pascuzzi",
        "Jiayang Xiao",
        "Brian Metzger",
        "Raissa Mathura",
        "Carl Hacker",
        "Joshua Adkinson",
        "Eleonora Bartoli",
        "Salma Elhassa"
      ],
      "year": "2024",
      "venue": "Nature Mental Health"
    },
    {
      "citation_id": "19",
      "title": "EEG-based emotion recognition using spatial-temporal graph convolutional LSTM with attention mechanism",
      "authors": [
        "Lin Feng",
        "Cheng Cheng",
        "Mingyan Zhao",
        "Huiyuan Deng",
        "Yong Zhang"
      ],
      "year": "2022",
      "venue": "IEEE Journal of Biomedical and Health Informatics"
    },
    {
      "citation_id": "20",
      "title": "The connectomics of brain disorders",
      "authors": [
        "Alex Fornito",
        "Andrew Zalesky",
        "Michael Breakspear"
      ],
      "year": "2015",
      "venue": "Nature Reviews Neuroscience"
    },
    {
      "citation_id": "21",
      "title": "Language, mind and brain",
      "authors": [
        "Angela Friederici",
        "Noam Chomsky",
        "Robert Berwick",
        "Andrea Moro",
        "Johan Bolhuis"
      ],
      "year": "2017",
      "venue": "Nature human behaviour"
    },
    {
      "citation_id": "22",
      "title": "A Local-Ascending-Global Learning Strategy for Brain-Computer Interface",
      "authors": [
        "Dongrui Gao",
        "Haokai Zhang",
        "Pengrui Li",
        "Tian Tang",
        "Shihong Liu",
        "Zhihong Zhou",
        "Shaofei Ying",
        "Ye Zhu",
        "Yongqing Zhang"
      ],
      "year": "2024",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence"
    },
    {
      "citation_id": "23",
      "title": "Graph Convolutional Network With Connectivity Uncertainty for EEG-Based Emotion Recognition",
      "authors": [
        "Hongxiang Gao",
        "Xingyao Wang",
        "Zhenghua Chen",
        "Min Wu",
        "Zhipeng Cai",
        "Lulu Zhao",
        "Jianqing Li",
        "Chengyu Liu"
      ],
      "year": "2024",
      "venue": "IEEE Journal of Biomedical and Health Informatics"
    },
    {
      "citation_id": "24",
      "title": "The representational dynamics of perceived voice emotions evolve from categories to dimensions",
      "authors": [
        "Caroline Bruno L Giordano",
        "Nikolaus Whiting",
        "Sonja Kriegeskorte",
        "Joachim Kotz",
        "Pascal Gross",
        "Belin"
      ],
      "year": "2021",
      "venue": "Nature human behaviour"
    },
    {
      "citation_id": "25",
      "title": "A spiking neural network with adaptive graph convolution and lstm for eegbased brain-computer interfaces",
      "authors": [
        "Peiliang Gong",
        "Pengpai Wang",
        "Yueying Zhou",
        "Daoqiang Zhang"
      ],
      "year": "2023",
      "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering"
    },
    {
      "citation_id": "26",
      "title": "Phonemic segmentation of narrative speech in human cerebral cortex",
      "authors": [
        "Alexander Xue L Gong",
        "Fatma Huth",
        "Keith Deniz",
        "Jack Johnson",
        "Fr√©d√©ric Gallant",
        "Theunissen"
      ],
      "year": "2023",
      "venue": "Nature communications"
    },
    {
      "citation_id": "27",
      "title": "A review of Graph Neural Networks for Electroencephalography data analysis",
      "authors": [
        "Manuel Gra√±a",
        "Igone Morais-Quilez"
      ],
      "year": "2023",
      "venue": "Neurocomputing"
    },
    {
      "citation_id": "28",
      "title": "Multi-source domain transfer discriminative dictionary learning modeling for electroencephalogram-based emotion recognition",
      "authors": [
        "Xiaoqing Gu",
        "Weiwei Cai",
        "Ming Gao",
        "Yizhang Jiang"
      ],
      "year": "2022",
      "venue": "IEEE Transactions on Computational Social Systems"
    },
    {
      "citation_id": "29",
      "title": "A domain generative graph network for EEG-based emotion recognition",
      "authors": [
        "Yun Gu",
        "Xinyue Zhong",
        "Cheng Qu",
        "Chuanjun Liu",
        "Bin Chen"
      ],
      "year": "2023",
      "venue": "IEEE Journal of Biomedical and Health Informatics"
    },
    {
      "citation_id": "30",
      "title": "Convolutional gated recurrent unitdriven multidimensional dynamic graph neural network for subject-independent emotion recognition",
      "authors": [
        "Wenhui Guo",
        "Yanjiang Wang"
      ],
      "year": "2024",
      "venue": "Expert Systems with Applications"
    },
    {
      "citation_id": "31",
      "title": "Why faces don't always tell the truth about feelings",
      "authors": [
        "Douglas Heaven"
      ],
      "year": "2020",
      "venue": "Nature"
    },
    {
      "citation_id": "32",
      "title": "Emotion-modulated performance and activity in left dorsolateral prefrontal cortex",
      "authors": [
        "Aprajita John D Herrington",
        "Nancy Mohanty",
        "Joscelyn Koven",
        "Jennifer Fisher",
        "Marie Stewart",
        "Andrew Banich",
        "Gregory Webb",
        "Wendy Miller",
        "Heller"
      ],
      "year": "2005",
      "venue": "Emotion"
    },
    {
      "citation_id": "33",
      "title": "The relation between short-term emotion dynamics and psychological well-being: A meta-analysis",
      "authors": [
        "Marlies Houben",
        "Wim Van Den",
        "Peter Noortgate",
        "Kuppens"
      ],
      "year": "2015",
      "venue": "Psychological bulletin"
    },
    {
      "citation_id": "34",
      "title": "GJFusion: A channel-level correlation construction method for multimodal physiological signal fusion",
      "authors": [
        "Wuliang Huang",
        "Yiqiang Chen",
        "Xinlong Jiang",
        "Teng Zhang",
        "Qian Chen"
      ],
      "year": "2023",
      "venue": "ACM Transactions on Multimedia Computing, Communications and Applications"
    },
    {
      "citation_id": "35",
      "title": "HetEmotionNet: two-stream heterogeneous graph recurrent neural network for multi-modal emotion recognition",
      "authors": [
        "Ziyu Jia",
        "Youfang Lin",
        "Jing Wang",
        "Zhiyang Feng",
        "Xiangheng Xie",
        "Caijie Chen"
      ],
      "year": "2021",
      "venue": "Proceedings of the 29th ACM International Conference on Multimedia"
    },
    {
      "citation_id": "36",
      "title": "PGCN: Pyramidal graph convolutional network for EEG emotion recognition",
      "authors": [
        "Ming Jin",
        "Changde Du",
        "Huiguang He",
        "Ting Cai",
        "Jinpeng Li"
      ],
      "year": "2024",
      "venue": "IEEE Transactions on Multimedia"
    },
    {
      "citation_id": "37",
      "title": "Graph to Grid: Learning Deep Representations for Multimodal Emotion Recognition",
      "authors": [
        "Ming Jin",
        "Jinpeng Li"
      ],
      "year": "2023",
      "venue": "Proceedings of the 31st ACM International Conference on Multimedia"
    },
    {
      "citation_id": "38",
      "title": "Auto-encoding variational bayes",
      "authors": [
        "P Diederik",
        "Max Kingma",
        "Welling"
      ],
      "year": "2013",
      "venue": "Auto-encoding variational bayes",
      "arxiv": "arXiv:1312.6114"
    },
    {
      "citation_id": "39",
      "title": "Semi-supervised classification with graph convolutional networks",
      "authors": [
        "N Thomas",
        "Max Kipf",
        "Welling"
      ],
      "year": "2016",
      "venue": "Semi-supervised classification with graph convolutional networks",
      "arxiv": "arXiv:1609.02907"
    },
    {
      "citation_id": "40",
      "title": "Gesture links language and cognition for spoken and signed languages",
      "authors": [
        "Sotaro Kita",
        "Karen Emmorey"
      ],
      "year": "2023",
      "venue": "Nature Reviews Psychology"
    },
    {
      "citation_id": "41",
      "title": "Graph neural network-based eeg classification: A survey",
      "authors": [
        "Dominik Klepl",
        "Min Wu",
        "Fei He"
      ],
      "year": "2024",
      "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering"
    },
    {
      "citation_id": "42",
      "title": "Functional grouping and cortical-subcortical interactions in emotion: a meta-analysis of neuroimaging studies",
      "authors": [
        "Hedy Kober",
        "Lisa Barrett",
        "Josh Joseph",
        "Eliza Bliss-Moreau",
        "Kristen Lindquist",
        "Tor D Wager"
      ],
      "year": "2008",
      "venue": "Neuroimage"
    },
    {
      "citation_id": "43",
      "title": "Deap: A database for emotion analysis; using physiological signals",
      "authors": [
        "Sander Koelstra",
        "Christian Muhl",
        "Mohammad Soleymani",
        "Jong-Seok Lee",
        "Ashkan Yazdani",
        "Touradj Ebrahimi",
        "Anton Thierry Pun",
        "Ioannis Nijholt",
        "Patras"
      ],
      "year": "2011",
      "venue": "IEEE transactions on affective computing"
    },
    {
      "citation_id": "44",
      "title": "Causal graph convolutional neural network for emotion recognition",
      "authors": [
        "Wanzeng Kong",
        "Min Qiu",
        "Menghang Li",
        "Xuanyu Jin",
        "Li Zhu"
      ],
      "year": "2022",
      "venue": "IEEE Transactions on Cognitive and Developmental Systems"
    },
    {
      "citation_id": "45",
      "title": "Martijn van den Heuvel, et al. 2021. Sensory-motor cortices shape functional connectivity dynamics in the human brain",
      "authors": [
        "Xiaolu Kong",
        "Ru Kong",
        "Csaba Orban",
        "Peng Wang",
        "Shaoshi Zhang",
        "Kevin Anderson",
        "Avram Holmes",
        "John Murray",
        "Gustavo Deco"
      ],
      "year": "2021",
      "venue": "Nature communications"
    },
    {
      "citation_id": "46",
      "title": "Decoding the nature of emotion in the brain",
      "authors": [
        "A Philip",
        "Kevin Kragel",
        "Labar"
      ],
      "year": "2016",
      "venue": "Trends in cognitive sciences"
    },
    {
      "citation_id": "47",
      "title": "Sparsity enables estimation of both subcortical and cortical activity from MEG and EEG",
      "authors": [
        "Pavitra Krishnaswamy",
        "Gabriel Obregon-Henao",
        "Jyrki Ahveninen",
        "Sheraz Khan",
        "Behtash Babadi",
        "Juan Iglesias",
        "Matti H√§m√§l√§inen",
        "Patrick Purdon"
      ],
      "year": "2017",
      "venue": "Proceedings of the National Academy of Sciences"
    },
    {
      "citation_id": "48",
      "title": "Further evidence for mixed emotions",
      "authors": [
        "T Jeff",
        "A Larsen",
        "Peter Mcgraw"
      ],
      "year": "2011",
      "venue": "Journal of personality and social psychology"
    },
    {
      "citation_id": "49",
      "title": "Emotionotopy in the human right temporo-parietal cortex",
      "authors": [
        "Giada Lettieri",
        "Giacomo Handjaras",
        "Emiliano Ricciardi",
        "Andrea Leo",
        "Paolo Papale",
        "Monica Betta",
        "Pietro Pietrini",
        "Luca Cecchetti"
      ],
      "year": "2019",
      "venue": "Nature communications"
    },
    {
      "citation_id": "50",
      "title": "Bridging emotion theory and neurobiology through dynamic systems modeling",
      "authors": [
        "Lewis Marc"
      ],
      "year": "2005",
      "venue": "Behavioral and brain sciences"
    },
    {
      "citation_id": "51",
      "title": "Effective emotion recognition by learning discriminative graph topologies in EEG brain networks",
      "authors": [
        "Cunbo Li",
        "Peiyang Li",
        "Yangsong Zhang",
        "Ning Li",
        "Yajing Si",
        "Fali Li",
        "Zehong Cao",
        "Huafu Chen",
        "Badong Chen",
        "Dezhong Yao"
      ],
      "year": "2023",
      "venue": "IEEE Transactions on Neural Networks and Learning Systems"
    },
    {
      "citation_id": "52",
      "title": "An Efficient Graph Learning System for Emotion Recognition Inspired by the Cognitive Prior Graph of EEG Brain Network",
      "authors": [
        "Cunbo Li",
        "Tian Tang",
        "Yue Pan",
        "Lei Yang",
        "Shuhan Zhang",
        "Zhaojin Chen",
        "Peiyang Li",
        "Dongrui Gao",
        "Huafu Chen",
        "Fali Li"
      ],
      "year": "2024",
      "venue": "IEEE Transactions on Neural Networks and Learning Systems"
    },
    {
      "citation_id": "53",
      "title": "Attention-based Temporal Graph Representation Learning for EEG-based Emotion Recognition",
      "authors": [
        "Chao Li",
        "Feng Wang",
        "Ziping Zhao",
        "Haishuai Wang",
        "Bj√∂rn Schuller"
      ],
      "year": "2024",
      "venue": "IEEE Journal of Biomedical and Health Informatics"
    },
    {
      "citation_id": "54",
      "title": "Cross-subject EEG emotion recognition with self-organized graph neural network",
      "authors": [
        "Jingcong Li",
        "Shuqi Li",
        "Jiahui Pan",
        "Fei Wang"
      ],
      "year": "2021",
      "venue": "Frontiers in Neuroscience"
    },
    {
      "citation_id": "55",
      "title": "Residual GCB-Net: Residual graph convolutional broad network on emotion recognition",
      "authors": [
        "Qilin Li",
        "Tong Zhang",
        "Ke Cl Philip Chen",
        "Long Yi",
        "Chen"
      ],
      "year": "2022",
      "venue": "IEEE Transactions on Cognitive and Developmental Systems"
    },
    {
      "citation_id": "56",
      "title": "MTLFuseNet: a novel emotion recognition model based on deep latent feature fusion of EEG signals and multi-task learning",
      "authors": [
        "Rui Li",
        "Chao Ren",
        "Yiqing Ge",
        "Qiqi Zhao",
        "Yikun Yang",
        "Yuhan Shi",
        "Xiaowei Zhang",
        "Bin Hu"
      ],
      "year": "2023",
      "venue": "Knowledge-Based Systems"
    },
    {
      "citation_id": "57",
      "title": "A multi-domain adaptive graph convolutional network for EEG-based emotion recognition",
      "authors": [
        "Rui Li",
        "Yiting Wang",
        "Bao-Liang Lu"
      ],
      "year": "2021",
      "venue": "Proceedings of the 29th ACM International Conference on Multimedia"
    },
    {
      "citation_id": "58",
      "title": "GCNs-FSMI: EEG recognition of mental illness based on fine-grained signal features and graph mutual information maximization",
      "authors": [
        "Wei Li",
        "Hong Wang",
        "Luhe Zhuang"
      ],
      "year": "2023",
      "venue": "Expert Systems With Applications"
    },
    {
      "citation_id": "59",
      "title": "EEG-based emotion recognition using trainable adjacency relation driven graph convolutional network",
      "authors": [
        "Wei Li",
        "Mingming Wang",
        "Junyi Zhu",
        "Aiguo Song"
      ],
      "year": "2023",
      "venue": "IEEE Transactions on Cognitive and Developmental Systems"
    },
    {
      "citation_id": "60",
      "title": "Gusa: Graphbased unsupervised subdomain adaptation for cross-subject eeg emotion recognition",
      "authors": [
        "Xiaojun Li",
        "Bianna Cl Philip Chen",
        "Tong Chen",
        "Zhang"
      ],
      "year": "2024",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "61",
      "title": "Attention-based spatio-temporal graphic lstm for eeg emotion recognition",
      "authors": [
        "Xiaoxu Li",
        "Wenming Zheng",
        "Yuan Zong",
        "Hongli Chang",
        "Cheng Lu"
      ],
      "year": "2021",
      "venue": "2021 International Joint Conference on Neural Networks (IJCNN)"
    },
    {
      "citation_id": "62",
      "title": "GMSS: Graph-based multi-task self-supervised learning for EEG emotion recognition",
      "authors": [
        "Yang Li",
        "Ji Chen",
        "Fu Li",
        "Boxun Fu",
        "Hao Wu",
        "Youshuo Ji",
        "Yijin Zhou",
        "Yi Niu",
        "Guangming Shi",
        "Wenming Zheng"
      ],
      "year": "2022",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "63",
      "title": "Towards adaptable graph representation learning: An adaptive multi-graph contrastive transformer",
      "authors": [
        "Yan Li",
        "Liang Zhang",
        "Xiangyuan Lan",
        "Dongmei Jiang"
      ],
      "year": "2023",
      "venue": "Proceedings of the 31st ACM International Conference on Multimedia"
    },
    {
      "citation_id": "64",
      "title": "Emotion recognition using spatial-temporal EEG features through convolutional graph attention network",
      "authors": [
        "Zhongjie Li",
        "Gaoyan Zhang",
        "Longbiao Wang",
        "Jianguo Wei",
        "Jianwu Dang"
      ],
      "year": "2023",
      "venue": "Journal of Neural Engineering"
    },
    {
      "citation_id": "65",
      "title": "The brain basis of emotion: a meta-analytic review",
      "authors": [
        "Kristen Lindquist",
        "Tor Wager",
        "Hedy Kober",
        "Eliza Bliss-Moreau",
        "Lisa Barrett"
      ],
      "year": "2012",
      "venue": "Behavioral and brain sciences"
    },
    {
      "citation_id": "66",
      "title": "VSGT: Variational Spatial and Gaussian Temporal Graph Models for EEG-based Emotion Recognition",
      "authors": [
        "Chenyu Liu",
        "Jiaping Zhou",
        "Zhengri Xiao",
        "Liming Zhu",
        "Ziyu Zhai",
        "Yang Jia",
        "Liu"
      ],
      "year": "2024",
      "venue": "IJCAI"
    },
    {
      "citation_id": "67",
      "title": "VBH-GNN: Variational Bayesian Heterogeneous Graph Neural Networks for Cross-subject Emotion Recognition",
      "authors": [
        "Chenyu Liu",
        "Xinliang Zhou",
        "Zhengri Zhu",
        "Liming Zhai",
        "Ziyu Jia",
        "Yang Liu"
      ],
      "venue": "The Twelfth International Conference on Learning Representations"
    },
    {
      "citation_id": "68",
      "title": "Minimum spanning tree based graph neural network for emotion classification using EEG",
      "authors": [
        "Hanjie Liu",
        "Jinren Zhang",
        "Qingshan Liu",
        "Jinde Cao"
      ],
      "year": "2022",
      "venue": "Neural Networks"
    },
    {
      "citation_id": "69",
      "title": "Deactivation of the prefrontal cortex during exposure to pleasantly-charged emotional challenge",
      "authors": [
        "Kanji Matsukawa",
        "Ryota Asahara",
        "Miho Yoshikawa",
        "Kana Endo"
      ],
      "year": "2018",
      "venue": "Scientific Reports"
    },
    {
      "citation_id": "70",
      "title": "Dynamic emotional states shape the episodic structure of memory",
      "authors": [
        "Mason Mcclay",
        "Matthew Sachs",
        "David Clewett"
      ],
      "year": "2023",
      "venue": "Nature Communications"
    },
    {
      "citation_id": "71",
      "title": "MSFR-GCN: A multi-scale feature reconstruction graph convolutional network for EEG emotion and cognition recognition",
      "authors": [
        "Haohao Deng Pan",
        "Feifan Zheng",
        "Yu Xu",
        "Zhe Ouyang",
        "Chu Jia",
        "Hong Wang",
        "Zeng"
      ],
      "year": "2023",
      "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering"
    },
    {
      "citation_id": "72",
      "title": "ST-SCGNN: a spatio-temporal selfconstructing graph neural network for cross-subject EEG-based emotion recognition and consciousness detection",
      "authors": [
        "Jiahui Pan",
        "Rongming Liang",
        "Zhipeng He",
        "Jingcong Li",
        "Yan Liang",
        "Xinjie Zhou",
        "Yanbin He",
        "Yuanqing Li"
      ],
      "year": "2023",
      "venue": "IEEE Journal of Biomedical and Health Informatics"
    },
    {
      "citation_id": "73",
      "title": "Multimodal physiological signals fusion for online emotion recognition",
      "authors": [
        "Tongjie Pan",
        "Yalan Ye",
        "Hecheng Cai",
        "Shudong Huang",
        "Yang Yang",
        "Guoqing Wang"
      ],
      "year": "2023",
      "venue": "Proceedings of the 31st ACM International Conference on Multimedia"
    },
    {
      "citation_id": "74",
      "title": "Online multi-hypergraph fusion learning for cross-subject emotion recognition",
      "authors": [
        "Tongjie Pan",
        "Yalan Ye",
        "Yangwuyong Zhang",
        "Kunshu Xiao",
        "Hecheng Cai"
      ],
      "year": "2024",
      "venue": "Information Fusion"
    },
    {
      "citation_id": "75",
      "title": "Traumatic brain injury impairs small-world topology",
      "authors": [
        "Paul Anand S Pandit",
        "Renaud Expert",
        "Valerie Lambiotte",
        "Robert Bonnelle",
        "Federico Leech",
        "David Turkheimer",
        "Sharp"
      ],
      "year": "2013",
      "venue": "Neurology"
    },
    {
      "citation_id": "76",
      "title": "Geometric constraints on human brain function",
      "authors": [
        "Kevin James C Pang",
        "Marianne Aquino",
        "Oldehinkel",
        "Ben Peter A Robinson",
        "Michael Fulcher",
        "Alex Breakspear",
        "Fornito"
      ],
      "year": "2023",
      "venue": "Nature"
    },
    {
      "citation_id": "77",
      "title": "Identifying sex differences in EEG-based emotion recognition using graph convolutional network with attention mechanism",
      "authors": [
        "Dan Peng",
        "Wei-Long Zheng",
        "Luyu Liu",
        "Wei-Bang Jiang",
        "Ziyi Li",
        "Yong Lu",
        "Bao-Liang Lu"
      ],
      "year": "2023",
      "venue": "Journal of Neural Engineering"
    },
    {
      "citation_id": "78",
      "title": "OGSSL: A semi-supervised classification model coupled with optimal graph learning for EEG emotion recognition",
      "authors": [
        "Yong Peng",
        "Fengzhe Jin",
        "Wanzeng Kong",
        "Feiping Nie",
        "Bao-Liang Lu",
        "Andrzej Cichocki"
      ],
      "year": "2022",
      "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering"
    },
    {
      "citation_id": "79",
      "title": "Self-weighted semi-supervised classification for joint EEG-based emotion recognition and affective activation patterns mining",
      "authors": [
        "Yong Peng",
        "Wanzeng Kong",
        "Feiwei Qin",
        "Feiping Nie",
        "Jinglong Fang",
        "Bao-Liang Lu",
        "Andrzej Cichocki"
      ],
      "year": "2021",
      "venue": "IEEE Transactions on Instrumentation and Measurement"
    },
    {
      "citation_id": "80",
      "title": "GFIL: A unified framework for the importance analysis of features, frequency bands, and channels in EEG-based emotion recognition",
      "authors": [
        "Yong Peng",
        "Feiwei Qin",
        "Wanzeng Kong",
        "Yuan Ge",
        "Feiping Nie",
        "Andrzej Cichocki"
      ],
      "year": "2021",
      "venue": "IEEE Transactions on Cognitive and Developmental Systems"
    },
    {
      "citation_id": "81",
      "title": "Joint feature adaptation and graph adaptive label propagation for cross-subject emotion recognition from EEG signals",
      "authors": [
        "Yong Peng",
        "Wenjuan Wang",
        "Wanzeng Kong",
        "Feiping Nie",
        "Bao-Liang Lu",
        "Andrzej Cichocki"
      ],
      "year": "2022",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "82",
      "title": "On the relationship between emotion and cognition",
      "authors": [
        "Luiz Pessoa"
      ],
      "year": "2008",
      "venue": "Nature reviews neuroscience"
    },
    {
      "citation_id": "83",
      "title": "Emotion processing and the amygdala: from a'low road'to'many roads' of evaluating biological significance",
      "authors": [
        "Luiz Pessoa",
        "Ralph Adolphs"
      ],
      "year": "2010",
      "venue": "Nature reviews neuroscience"
    },
    {
      "citation_id": "84",
      "title": "Functional network organization of the human brain",
      "authors": [
        "Jonathan Power",
        "Steven Alexander L Cohen",
        "Nelson",
        "S Gagan",
        "Wig",
        "Anne Kelly",
        "Jessica Barnes",
        "Alecia Church",
        "Timothy Vogel",
        "Laumann",
        "Bradley Fran M Miezin",
        "Schlaggar"
      ],
      "year": "2011",
      "venue": "Functional network organization of the human brain"
    },
    {
      "citation_id": "85",
      "title": "A multi-head residual connection GCN for EEG emotion recognition",
      "authors": [
        "Xiangkai Qiu",
        "Shenglin Wang",
        "Ruqing Wang",
        "Yiling Zhang",
        "Liya Huang"
      ],
      "year": "2023",
      "venue": "Computers in Biology and Medicine"
    },
    {
      "citation_id": "86",
      "title": "Anatomical insights into the interaction of emotion and cognition in the prefrontal cortex",
      "authors": [
        "D Rebecca",
        "David Ray",
        "Zald"
      ],
      "year": "2012",
      "venue": "Neuroscience & Biobehavioral Reviews"
    },
    {
      "citation_id": "87",
      "title": "Neurophysiological architecture of functional magnetic resonance images of human brain",
      "authors": [
        "Raymond Salvador",
        "John Suckling",
        "John Martin R Coleman",
        "David Pickard",
        "E Menon",
        "Bullmore"
      ],
      "year": "2005",
      "venue": "Cerebral cortex"
    },
    {
      "citation_id": "88",
      "title": "Emotion, cognition, and mental state representation in amygdala and prefrontal cortex",
      "authors": [
        "Salzman Daniel",
        "Stefano Fusi"
      ],
      "year": "2010",
      "venue": "Annual review of neuroscience"
    },
    {
      "citation_id": "89",
      "title": "Interpreting graph neural networks for NLP with differentiable edge masking",
      "authors": [
        "Nicola Michael Sejr Schlichtkrull",
        "Ivan Cao",
        "Titov"
      ],
      "year": "2020",
      "venue": "Interpreting graph neural networks for NLP with differentiable edge masking",
      "arxiv": "arXiv:2010.00577"
    },
    {
      "citation_id": "90",
      "title": "Attention and emotion: an ERP analysis of facilitated emotional stimulus processing",
      "authors": [
        "Harald Schupp",
        "Markus Jungh√∂fer",
        "Alfons O Almut I Weike",
        "Hamm"
      ],
      "year": "2003",
      "venue": "Neuroreport"
    },
    {
      "citation_id": "91",
      "title": "A human parietal face area contains aligned head-centered visual and tactile maps",
      "authors": [
        "I Martin",
        "Ruey-Song Sereno",
        "Huang"
      ],
      "year": "2006",
      "venue": "Nature neuroscience"
    },
    {
      "citation_id": "92",
      "title": "Altered cortical functional network in major depressive disorder: A resting-state electroencephalogram study",
      "authors": [
        "Miseon Shim",
        "Chang-Hwan Im",
        "Yong-Wook Kim",
        "Seung-Hwan Lee"
      ],
      "year": "2018",
      "venue": "NeuroImage: Clinical"
    },
    {
      "citation_id": "93",
      "title": "A multimodal database for affect recognition and implicit tagging",
      "authors": [
        "Mohammad Soleymani",
        "Jeroen Lichtenauer",
        "Maja Thierry Pun",
        "Pantic"
      ],
      "year": "2011",
      "venue": "IEEE transactions on affective computing"
    },
    {
      "citation_id": "94",
      "title": "Instance-adaptive graph for EEG emotion recognition",
      "authors": [
        "Tengfei Song",
        "Suyuan Liu",
        "Wenming Zheng",
        "Yuan Zong",
        "Zhen Cui"
      ],
      "year": "2020",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence"
    },
    {
      "citation_id": "95",
      "title": "Variational instance-adaptive graph for EEG emotion recognition",
      "authors": [
        "Tengfei Song",
        "Suyuan Liu",
        "Wenming Zheng",
        "Yuan Zong",
        "Zhen Cui",
        "Yang Li",
        "Xiaoyan Zhou"
      ],
      "year": "2021",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "96",
      "title": "Graph-embedded convolutional neural network for image-based EEG emotion recognition",
      "authors": [
        "Tengfei Song",
        "Wenming Zheng",
        "Suyuan Liu",
        "Yuan Zong",
        "Zhen Cui",
        "Yang Li"
      ],
      "year": "2021",
      "venue": "IEEE Transactions on Emerging Topics in Computing"
    },
    {
      "citation_id": "97",
      "title": "MPED: A multi-modal physiological emotion database for discrete emotion recognition",
      "authors": [
        "Tengfei Song",
        "Wenming Zheng",
        "Cheng Lu",
        "Yuan Zong",
        "Xilei Zhang",
        "Zhen Cui"
      ],
      "year": "2019",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "98",
      "title": "EEG emotion recognition using dynamical graph convolutional neural networks",
      "authors": [
        "Tengfei Song",
        "Wenming Zheng",
        "Peng Song",
        "Zhen Cui"
      ],
      "year": "2018",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "99",
      "title": "A dual-branch dynamic graph convolution based adaptive transformer feature fusion network for EEG emotion recognition",
      "authors": [
        "Mingyi Sun",
        "Weigang Cui",
        "Shuyue Yu",
        "Hongbin Han",
        "Bin Hu",
        "Yang Li"
      ],
      "year": "2022",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "100",
      "title": "Emotional brain states carry over and enhance future memory formation",
      "authors": [
        "Arielle Tambini",
        "Ulrike Rimmele",
        "Elizabeth Phelps",
        "Lila Davachi"
      ],
      "year": "2017",
      "venue": "Nature neuroscience"
    },
    {
      "citation_id": "101",
      "title": "Multi-Domain Based Dynamic Graph Representation Learning for EEG Emotion Recognition",
      "authors": [
        "Hao Tang",
        "Songyun Xie",
        "Xinzhou Xie",
        "Yujie Cui",
        "Bohan Li",
        "Dalu Zheng",
        "Yu Hao",
        "Xiangming Wang",
        "Yiye Jiang",
        "Zhongyu Tian"
      ],
      "year": "2024",
      "venue": "IEEE Journal of Biomedical and Health Informatics"
    },
    {
      "citation_id": "102",
      "title": "Georgios Tzimiropoulos, and Maja Pantic. 2021. Estimation of continuous valence and arousal levels from faces in naturalistic conditions",
      "authors": [
        "Antoine Toisoul",
        "Jean Kossaifi",
        "Adrian Bulat"
      ],
      "year": "2021",
      "venue": "Nature Machine Intelligence"
    },
    {
      "citation_id": "103",
      "title": "",
      "authors": [
        "Petar Veliƒçkoviƒá",
        "Guillem Cucurull",
        "Arantxa Casanova",
        "Adriana Romero",
        "Pietro Lio",
        "Yoshua Bengio"
      ],
      "year": "2017",
      "venue": "",
      "arxiv": "arXiv:1710.10903"
    },
    {
      "citation_id": "104",
      "title": "Research Progress of EEG-Based Emotion Recognition: A Survey",
      "authors": [
        "Yiming Wang",
        "Bin Zhang",
        "Lamei Di"
      ],
      "year": "2024",
      "venue": "Comput. Surveys"
    },
    {
      "citation_id": "105",
      "title": "Can mixed emotions peacefully coexist",
      "authors": [
        "Patti Williams",
        "Jennifer Aaker"
      ],
      "year": "2002",
      "venue": "Journal of consumer research"
    },
    {
      "citation_id": "106",
      "title": "Grop: Graph Orthogonal Purification Network for EEG Emotion Recognition",
      "authors": [
        "Mengqi Wu",
        "Bianna Cl Philip Chen",
        "Tong Chen",
        "Zhang"
      ],
      "year": "2024",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "107",
      "title": "DAGAM: a domain adversarial graph attention model for subject-independent EEG-based emotion recognition",
      "authors": [
        "Tao Xu",
        "Wang Dang",
        "Jiabao Wang",
        "Yun Zhou"
      ],
      "year": "2023",
      "venue": "Journal of Neural Engineering"
    },
    {
      "citation_id": "108",
      "title": "Adaptive hierarchical graph convolutional network for eeg emotion recognition",
      "authors": [
        "Yunlong Xue",
        "Wenming Zheng",
        "Yuan Zong",
        "Hongli Chang",
        "Xingxun Jiang"
      ],
      "year": "2022",
      "venue": "2022 International Joint Conference on Neural Networks (IJCNN)"
    },
    {
      "citation_id": "109",
      "title": "Bridge Graph Attention based Graph Convolution Network with Multi-Scale Transformer for EEG Emotion Recognition",
      "authors": [
        "Huachao Yan",
        "Kailing Guo"
      ],
      "year": "2024",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "110",
      "title": "Automatically Extracting and Utilizing EEG Channel Importance Based on Graph Convolutional Network for Emotion Recognition",
      "authors": [
        "Kun Yang",
        "Zhenning Yao",
        "Keze Zhang",
        "Jing Xu",
        "Li Zhu",
        "Shichao Cheng",
        "Jianhai Zhang"
      ],
      "year": "2024",
      "venue": "IEEE Journal of Biomedical and Health Informatics"
    },
    {
      "citation_id": "111",
      "title": "Hierarchical dynamic graph convolutional network with interpretability for EEG-based emotion recognition",
      "authors": [
        "Mengqing Ye",
        "Tong Philip Chen",
        "Zhang"
      ],
      "year": "2022",
      "venue": "IEEE transactions on neural networks and learning systems"
    },
    {
      "citation_id": "112",
      "title": "Semi-supervised dual-stream self-attentive adversarial graph contrastive learning for cross-subject eeg-based emotion recognition",
      "authors": [
        "Weishan Ye",
        "Zhiguo Zhang",
        "Fei Teng",
        "Min Zhang",
        "Jianhong Wang",
        "Dong Ni",
        "Fali Li",
        "Peng Xu",
        "Zhen Liang"
      ],
      "year": "2024",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "113",
      "title": "Xgnn: Towards modellevel explanations of graph neural networks",
      "authors": [
        "Jiliang Hao Yuan",
        "Xia Tang",
        "Shuiwang Hu",
        "Ji"
      ],
      "year": "2020",
      "venue": "Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery & data mining"
    },
    {
      "citation_id": "114",
      "title": "Siam-GCAN: A Siamese graph convolutional attention network for EEG emotion recognition",
      "authors": [
        "Hong Zeng",
        "Qi Wu",
        "Yanping Jin",
        "Haohao Zheng",
        "Mingming Li",
        "Yue Zhao",
        "Hua Hu",
        "Wanzeng Kong"
      ],
      "year": "2022",
      "venue": "IEEE Transactions on Instrumentation and Measurement"
    },
    {
      "citation_id": "115",
      "title": "SparseDGCNN: Recognizing emotion from multichannel EEG signals",
      "authors": [
        "Guanhua Zhang",
        "Minjing Yu",
        "Yong-Jin Liu",
        "Guozhen Zhao",
        "Dan Zhang",
        "Wenming Zheng"
      ],
      "year": "2021",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "116",
      "title": "GCB-Net: Graph convolutional broad network and its application in emotion recognition",
      "authors": [
        "Tong Zhang",
        "Xuehan Wang",
        "Xiangmin Xu",
        "Chen Philip"
      ],
      "year": "2019",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "117",
      "title": "A novel EEG-based graph convolution network for depression detection: incorporating secondary subject partitioning and attention mechanism",
      "authors": [
        "Zhongyi Zhang",
        "Qinghao Meng",
        "Licheng Jin",
        "Hanguang Wang",
        "Huirang Hou"
      ],
      "year": "2024",
      "venue": "Expert Systems with Applications"
    },
    {
      "citation_id": "118",
      "title": "SCC-MPGCN: self-attention coherence clustering based on multi-pooling graph convolutional network for EEG emotion recognition",
      "authors": [
        "Huijuan Zhao",
        "Jingjin Liu",
        "Zhenqian Shen",
        "Jingwen Yan"
      ],
      "year": "2022",
      "venue": "Journal of Neural Engineering"
    },
    {
      "citation_id": "119",
      "title": "Investigating critical frequency bands and channels for EEG-based emotion recognition with deep neural networks",
      "authors": [
        "Wei-Long Zheng",
        "Bao-Liang Lu"
      ],
      "year": "2015",
      "venue": "IEEE Transactions on autonomous mental development"
    },
    {
      "citation_id": "120",
      "title": "EEG-based emotion recognition using regularized graph neural networks",
      "authors": [
        "Peixiang Zhong",
        "Di Wang",
        "Chunyan Miao"
      ],
      "year": "2020",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "121",
      "title": "Progressive graph convolution network for EEG emotion recognition",
      "authors": [
        "Yijin Zhou",
        "Fu Li",
        "Yang Li",
        "Youshuo Ji",
        "Guangming Shi",
        "Wenming Zheng",
        "Lijian Zhang",
        "Yuanfang Chen",
        "Rui Cheng"
      ],
      "year": "2023",
      "venue": "Neurocomputing"
    },
    {
      "citation_id": "122",
      "title": "Emotion self-regulation training in major depressive disorder using simultaneous realtime fMRI and EEG neurofeedback",
      "authors": [
        "Vadim Zotev",
        "Ahmad Mayeli",
        "Masaya Misaki",
        "Jerzy Bodurka"
      ],
      "year": "2020",
      "venue": "NeuroImage: Clinical"
    }
  ]
}