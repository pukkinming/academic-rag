{
  "paper_id": "2408.01838v1",
  "title": "Tracking Emotional Dynamics In Chat Conversations: A Hybrid Approach Using Distilbert And Emoji Sentiment Analysis",
  "published": "2024-08-03T18:28:31Z",
  "authors": [
    "Ayan Igali",
    "Abdulkhak Abdrakhman",
    "Yerdaut Torekhan",
    "Pakizar Shamoi"
  ],
  "keywords": [
    "machine learning",
    "deep learning",
    "emotion detection",
    "sentiment analysis",
    "chat analysis"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Computer-mediated communication has become more important than face-toface communication in many contexts. Tracking emotional dynamics in chat conversations can enhance communication, improve services, and support wellbeing in various contexts. This paper explores a hybrid approach to tracking emotional dynamics in chat conversations by combining DistilBERT-based text emotion detection and emoji sentiment analysis. A Twitter dataset was analyzed using various machine learning algorithms, including SVM, Random Forest, and AdaBoost. We contrasted their performance with DistilBERT. Results reveal Dis-tilBERT's superior performance in emotion recognition. Our approach accounts for emotive expressions conveyed through emojis to better understand participants' emotions during chats. We demonstrate how this approach can effectively capture and analyze emotional shifts in real-time conversations. Our findings show that integrating text and emoji analysis is an effective way of tracking chat emotion, with possible applications in customer service, work chats, and social media interactions.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Understanding and analyzing emotional cues is extremely important in the digital era, where communication increasingly occurs through text. The significance of digital communication, particularly chat-based interactions, is evident in various contexts. This capability has far-reaching benefits across various sectors, such as marketing, customer service, and mental health, leading to more empathetic and efficient engagements.\n\nThe shift to digital communication has transformed consumer behavior and interpersonal relationships. Several studies highlight the role of web-based chatting in this transformation  [1] ,  [2] , with  [1]  focusing on the motivations and strategies of chatters, and  [2]  emphasizing the complementarity of online and face-to-face relationships. However,  [3]  raises concerns about the impact of computer-mediated communication on meaningful interpersonal interaction, particularly due to the lack of non-verbal cues and the potential for misunderstandings. In the organizational context,  [4]  underscores the growing importance of social media in internal communication but also acknowledges the continued value of face-to-face interaction. Another work highlights the growing importance of social media as a customer service channel, emphasizing the need for its integration into customer interaction management tools  [5] .\n\nNowadays, chat systems enhance the user experience by employing graphics-based interfaces and including interactive elements such as avatars and emoticons  [6] . Emojis play a significant role in digital communication, particularly in conveying humor and emotions  [7] ,  [8] . They help to bridge cultural differences and form digital communities, with their use varying based on the gender of the communicator  [9] . Emoticons, a type of emoji, are influenced by the social context and the relationship between communicators  [10] .\n\nThe ability to track emotional dynamics in chat conversations is crucial for understanding the evolution of interactions and relationships. Several studies emphasize the importance of this tracking  [11] ,  [12] , with  [11]  introducing a method for labeling emotional states over time and  [12]  proposing a method for tracking collective emotional trajectories.  [13]  and  [14]  further contribute to this area by developing computational approaches for tracking and recognizing emotions in short text messages, with Chen's approach being particularly effective in real-time chat scenarios. These studies demonstrate the significance of tracking emotional dynamics in chat conversations for various applications, from qualitative discourse analysis to machine learning models.\n\nThe advent of Natural Language Processing (NLP) has transformed how machines comprehend human emotions, converting unprocessed text into usable data. Historically, traditional machine learning approaches such as Support Vector Machines (SVM) were used to analyze textual sentiments, employing feature extraction through Word2Vec techniques  [15] . The recent shift towards more sophisticated models, especially with transformer-based architectures like DistilBERT, has significantly improved the understanding of context and subtleties in language  [16] .\n\nThis paper proposes a hybrid approach to evaluate emotional dynamics in chat conversations by fusing text and emoji emotion detection results. We focus on the importance of emojis in chat conversations, highlighting their expressive capability in digital communication. The contributions of this paper are as follows:\n\n• Comparative overview of ML and deep learning algorithms for emotion detection • Introduction of the novel hybrid method for the fusion of emotions detected in text and emojis\n\nThe paper is structured as follows. Section I is this Introduction. Section 2 presents an overview of research works in chat emotion analysis. Section III describes methods, including data collection, text, and emoji emotion detection. Next, section IV presents experimental results. Finally, concluding remarks and future works are presented in Section V.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Related Work",
      "text": "Sentiment analysis in NLP has progressed from basic lexicon-based methods to sophisticated techniques. Initially relying on word-based sentiment lexicons, the field transformed with machine learning, particularly through deep learning and transformer models like DistilBERT, which improved context understanding  [17] . This advancement is crucial for applications like social media analytics and customer feedback, highlighting its significance in modern NLP research.\n\nA range of studies have explored the dynamics of emotions in online chatting. The study  [18]  developed a computational approach to track and analyze emotions in real time, which was effective and efficient. Another study  [19]  used simulations to show that a Bot with a fixed emotion can influence the collective emotional state in a chat network. Next,  [20]  found that emotional expressions in online chatrooms exhibit remarkable persistence, leading to specific emotional \"tones\" in these spaces.  [21]  proposed two weakly supervised approaches for detecting fine-grained emotions in contact center chat utterances, achieving high accuracy. Another study presented the emotion flow (EF) model in dialog systems, which incorporates memes  [22] .\n\nEmotion recognition in conversations, also known as ERC, is a branch of sentiment analysis, a growing field within NLP with important implications for various domains, including healthcare, education, human-computer interaction, and social sciences. Several ERC works employed emotion recognition from various sides.\n\nSeveral works investigated the application of emotion detection in chat conversations  [23] [24] [25] . One study presented the context encoder and emotion-shift detection model that can surpass chit-chat and even improve some aspects of task-oriented conversation  [23] . Another study commonly used techniques for ERC problems based on recent research on sequential, graph, and transformer models  [24] . Some works analyzed context modeling in conversations, speaker dependency, and methods for combining multimodal information  [26] .\n\nOne significant limitation of the reviewed methods is that they miss the emotional context provided by emojis. This can lead to an incomplete understanding of feelings and intentions in digital communication, as emojis are important in expressing emotions in chats. The analysis may miss important emotional nuances without emojis, resulting in less accurate data interpretation.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Dataset For Text Emotion Detection",
      "text": "This study explores text-based emotion detection by analyzing two distinct datasets.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Dataset 1",
      "text": "The first dataset  [27] , derived from a collection of English Twitter messages, was used to identify six basic emotions: anger, fear, joy, love, sadness, and surprise. It contains 20,000 data rows in 6 classes.\n\nAs shown in Fig.  1 , the aggregated emotion frequencies highlight significant trends in emotional expressions across the collected tweets. Furthermore, the word cloud in Fig.  2  provides a visual representation of the most frequently used words in the Twitter dataset, emphasizing the predominant themes and sentiments.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Dataset 2",
      "text": "The second dataset was sourced from Kaggle and contains a collection of tweets annotated with emotions [28]. It contains 13 classes and has a size of 39,774 data rows. This dataset presents a significant challenge due to the imbalanced nature of emotion representation and the number of emotional states, ranging over thirteen different sentiments.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Dataset For Emoji Emotion Detection",
      "text": "We used the Emoji Sentiment Ranking dataset  [29] . It provides standardized sentiment scores for various emojis commonly employed in digital communication. As summarized in Table  1 , the dataset encompasses 751 instances each for negative, neutral, and positive sentiments. The mean sentiment scores illustrate a predominant positivity with a value of ≈ 0.447, despite the range of scores spanning from a minimum of ≈ 0.007 to a maximum of ≈ 0.972 for positive sentiments. For example, for the emoji \"SMILING FACE WITH HEART-SHAPED EYES\" (Unicode codepoint 0x1f60d), the  negative, neutral, positive, and compound sentiment scores are 0.052, 0.219, 0.729, and 0.678, respectively. Fig.  5  displays a bar chart of the sentiment scores for various emojis  [29] . This visualization provides a clear and quantifiable overview of how different emojis are typically interpreted in terms of sentiment.  This dataset is critical for validating the effectiveness of emotion recognition and understanding emojis' role in chat communications. Evaluation of how emojis contribute to emotional expression in text is crucial for enhancing automatic emotion detection systems in practical scenarios  [16, 23, 24] .",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Synthetic Work Chat Dataset",
      "text": "Messages in this dataset were artificially generated by ChatGPT 4.0 to simulate a realistic project-focused group chat environment involving four participants: Person 1, Person 2, Person 3, and Person 4. As illustrated in Fig.  6 , the dataset encompasses 113 chat messages for 1 full work day from 9 a.m. to 6 p.m. We will use it to analyze emotional dynamics in a professional communication setting.\n\nMessages reflect how team members exchange insights and updates about the project's progress and potential issues. In the simulated dialogues, each participant adopts a distinct role and emotional tone, employing emojis to enhance the expressiveness of their messages.\n\nKey interactions in the dataset include:\n\n• Person 1: Motivator and encourager, initiates optimistic discussions and frequently encourages the team. • Person 2: Technical expert with a cynical edge. Raises technical and procedural concerns. • Person 3: Taskmaster and coordinator who is focused on deadlines and deliverables, managing the project timeline, and coordinating tasks. • Person 4: Realist and expresses urgency. Expresses frustration and urgency about the project, highlighting issues and challenges.\n\nThis artificial dataset supports the analysis of how emotions are conveyed through text and emojis in professional exchanges and serves as an example for validating the effectiveness of emotion recognition algorithms under varied communicative contexts  [23, 24] . Fig.  7  visualizes the dataset's most frequently used words.\n\nional settings  [16, 30] .",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "Text Emotion Detection",
      "text": "Analysis of emotions can be derived from various channels, such as colors  [31] , music  [32] , faces  [33] ,  [34] , multichannel  [35, 36] , emoji  [37] . Each channel provides unique data, allowing for a more detailed understanding of emotional states.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Machine Learning Algorithms",
      "text": "SVM Support Vector Machines (SVM) is a supervised, machine learning algorithm commonly used for classification tasks  [15] . The algorithm behind SVMs classifies input data x by finding the optimal hyperplane that maximizes the distance between opposite classes y in the feature space.\n\nFor training sample x i ∈ R n , i = 1, ..., m, which given in two classes, and label vector y ∈ R m such that y i ∈ {-1, 1}, SVM solves the following optimization problem:\n\nwhere ϕ(x i ) maps into higher-dimensional space and C > 0 is the regularization parameter.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Gaussiannb",
      "text": "Naive Bayes is a probabilistic and supervised machine learning algorithm used for classification tasks  [38] . It is based on Bayes' theorem and makes a \"naive\" assumption about the independence of features. For classification, it uses:\n\nThe Naive Bayes classifier picks the most probable hypothesis, which is known as the maximum a posteriori. ŷ = argmax y P (y)\n\nGaussian Naive Bayes assumes that the likelihood of feature values associated with each class follows a normal (or Gaussian) distribution.",
      "page_start": 7,
      "page_end": 8
    },
    {
      "section_name": "Adaboost",
      "text": "Adaptive Boosting (AdaBoost) is a supervised machine learning algorithm where a classifier is built incrementally  [39] . Each iteration employs a basic learning algorithm called the base learner, producing a classifier. These classifiers are then assigned weight coefficients. Ultimately, the final classification is determined through a weighted combination of the base classifiers' decisions.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Decision Tree",
      "text": "Decision Tree is a non-parametric, supervised machine learning algorithm for classification and regression tasks  [40] . It adopts a hierarchical tree structure with root, internal and leaf nodes, and branches (see Fig.  8 ). There are two methods of choosing the best attributes, information gain and Gini impurity, that act as splitting criteria for decision trees.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "K-Nearest Neighbors",
      "text": "K-Nearest Neighbors (KNN) is a simple, non-parametric, supervised machine learning algorithm for classification and regression tasks  [41] . In classification tasks, the algorithm calculates the distance between input data x and training samples X, then determines class ŷ of input data by the nearest k neighbors in the feature space.\n\nDistance between data points can be calculated by Euclidean  (5) , Manhattan  (6)  or Minkowski  (7)  distances:\n\nThe class ŷ of input data x is set to the most common class among k neighbours of x:\n\nRandom Forrest\n\nRandom forests are supervised ensemble learning algorithms used for tasks such as classification and regression  [41] . During training, they generate multiple decision trees (see Fig.  9 ). For classification tasks, the overall prediction is based on the most frequently selected class among these trees.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Deep Learning Approach",
      "text": "DistilBERT  [16] , a streamlined version of BERT (Bidirectional Encoder Representations from Transformers), is designed to be smaller, faster, and more efficient while retaining most of BERT's performance. It uses the same foundational transformer architecture and training objectives as BERT, with some modifications for efficiency (see Fig.  10 ). The DistilBert self-attention mechanism computes attention scores based on the input vectors (Eq. 9):\n\nFig.  10 : The DistilBERT model architecture  [42]  Attention\n\nWhere Q, K, and V represent the query, key, and value matrices, respectively, and d k is the dimensionality of the key vectors. Next, Multi-head attention allows the model to attend to information from different representation subspaces at different positions  (10, 11) :\n\nHere, W Q i , W K i , W V i , and W O are parameter matrices. Each transformer block in DistilBert contains a feed-forward network, which applies the following transformations  (12) :\n\nTo help stabilize the learning process, techniques such as layer normalization and residual connections are used (13):\n\nLayerNorm(x + Sublayer(x))  (13)  where Sublayer(x) could be either an attention mechanism or a feed-forward network. DistilBERT uses a distillation loss, often parameterized by a temperature-scaled cross-entropy loss, to help the smaller model learn from the larger model.",
      "page_start": 9,
      "page_end": 10
    },
    {
      "section_name": "Emoji Emotion Detection",
      "text": "In digital communication, emojis are acknowledged to significantly enhance the conveyance of emotional nuance. Fig.  11 : Emoji Sentiment Ranking from  [29] , showing the distribution of sentiment scores among popular emojis A sentiment lexicon, which attributes sentiment scores to a broad spectrum of emojis, has been employed for emoji-based emotion detection. This ranking categorizes emojis by the intensity and polarity of the sentiments they typically express, with scores derived from user feedback  [43] . As demonstrated in Fig.  11 , the Emoji Sentiment Ranking offers a comprehensive visual overview of sentiment scores for commonly used emojis.\n\nEmojis are extracted from a corpus of messages, and each emoji is correlated with its associated emotional sentiment according to the lexicon. The collective presence of emojis within messages is interpreted as a composite expression, contributing to the overall sentiment. This method integrates emoji sentiment analysis into the emotion detection framework, substantiating the role of emojis as a unique communicative lexicon.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Proposed Approach",
      "text": "Our approach focuses on analyzing chat conversations by integrating NLP with emoji sentiment scoring, as seen in Fig.  12 . This section presents the mathematical framework that supports feature extraction, sentiment analysis, and intensity adjustment:\n\n• Feature Extraction. Textual features are derived using a tokenizer function τ from the pre-trained DistilBERT model, transforming text into a sequence of tokens T. Meanwhile, emoji features are identified through a set of regular expressions R, which capture the Unicode representations of emojis E from the text. • Intensity Factor for Emoji Sentiment Analysis. For each emoji e, the sentiment intensity factor ϕ(e) is determined from the emoji sentiment ranking S. The ranking assigns positive p i , negative n i , and neutral u i sentiment scores to each emoji e i ∈ E, where S = {s 1 , s 2 , . . . , s k }, and s i = (p i , n i , u i ). The intensity factor Fig.  12 : Schematic representation of the proposed hybrid approach ϕ(e i ) for each emoji is computed as follows:\n\n• Sentiment Analysis with DistilBERT. The base emotional score is obtained using the DistilBERT model D, which produces a set of logits L(x) for given text x. These logits are processed through a softmax function σ to yield a probability distribution over possible emotions E:\n\nThe emotion prediction ê and its corresponding textual sentiment score ψ(x) are determined by: ê = arg max e∈E P (E|x) (  16 )\n\n• Integration of Text and Emoji Sentiments. The final sentiment score Ω(x) for text x combines the textual sentiment score ψ(x) and the emoji sentiment intensity  factors Φ(x). The computation of Ω(x) is as follows:\n\nWhere each ϕ ∈ Φ(x) represents the sentiment intensity contributed by an individual emoji. The expression 1",
      "page_start": 11,
      "page_end": 12
    },
    {
      "section_name": "|Φ(X)|",
      "text": "ϕ∈Φ(x) ϕ calculates the average sentiment intensity of all the emojis in the text. It scales the textual sentiment score ψ(x) based on the average sentiment intensity of the emojis. This factor is always greater than or equal to 1, ensuring that the final sentiment score Ω(x) is at least as strong as the textual sentiment score. The final score Ω(x) reflects the overall sentiment by integrating both the text and the emojis. Note that in the case of just one emoji, the equation is as follows:\n\n4 Results",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "Performance Evaluation",
      "text": "Now let us compare the performance of various machine learning models and Dis-tilBERT across two datasets using Accuracy, Precision, Recall, and F1 Score as performance metrics. Our findings show that performance varied significantly across different models (see Table  2 , Fig.  13 ).\n\nFor Dataset 1 (6 classes, 20,000 instances), SVM and GaussianNB show low performance, with metrics around 0.20 and 0.19, respectively. AdaBoost performs slightly better, with an Accuracy of 0.26. Decision Tree and KNN show good performance, with Accuracy of 0.75 and 0.67, respectively. RandomForest exhibits excellent performance, with an Accuracy of 0.78. DistilBERT outperforms all models with an Accuracy of 0.93, Precision of 0.90, Recall of 0.91, and F1 Score of 0.90.\n\nFor Dataset 2 (13 classes, 39,774 instances), SVM and GaussianNB again show poor performance, with GaussianNB having the lowest metrics around 0.12. AdaBoost also performs poorly, with an Accuracy of 0.16. Decision Tree and KNN perform well",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "Analysis Of Emotional Dynamics Within Professional Communication",
      "text": "This subsection explores emotional dynamics within a professional communication setting using the proposed approach. The goal is to analyze the distribution and track the changes in emotional expressions among team members during one working day's interactions in a chat. Fig.  14a  and Fig.  14b  illustrate the distribution of dominant emotions exhibited in the chat messages. As shown, joy is the most prevalent emotion, followed by sadness.  Anger and fear are also present but in fewer messages. No messages with the dominant emotions of love and surprise were found. Fig.  14b  illustrates stacked emotion scores over a full working day. It can be seen that the emotion of sadness was abnormally high towards the end of the day, possibly because some goals planned for the day were not achieved. However, the emotion of joy was dominant throughout the day, likely because people used polite and greeting words and tried to maintain a positive atmosphere.\n\nNext, Fig.  15a  illustrates the emotion tracking results in the analyzed chat. It can be seen that joy was dominant throughout the day, but fear and sadness became noticeable towards the end of the day, possibly due to the pressure of meeting deadlines. Fig.  15b  shows the distribution of scores for each emotion and their respective intensities. It is evident that the intensity of sadness is significantly higher than other emotions. In conclusion, the analysis revealed the complex emotional interactions in professional settings, highlighting the various emotions people experience in collaborative environments. These findings are important for creating supportive workplaces, understanding how people interact, and improving communication to boost team productivity and emotional well-being  [23] [24] [25] .\n\nThe proposed emotion tracking approach has various applications, such as:\n\n• Social Media Analysis. Understanding public emotional trends on social media platforms posts involving conversations. • Education. Improving online learning environments by responding to students' emotional states. This can involve face emotion recognition as an additional channel. • Customer Support Services. Improving company response strategies by analyzing customer emotions during interactions. • Chatbots. Developing more empathetic AI chatbots and virtual assistants.\n\n• Tracking mental health. For example, in support groups or therapy through chat.",
      "page_start": 14,
      "page_end": 16
    },
    {
      "section_name": "Conclusion",
      "text": "This paper uses advanced text analysis and emoji sentiment mapping to focus on emotion and sentiment detection in chat conversations. It compares traditional ML methods and the DistilBERT transformer model in the text's context of emotion detection. The results highlight the superior accuracy and F1 scores achieved by Dis-tilBERT, demonstrating the significant impact of deep learning in NLP. Moreover, incorporating emoji analysis has been crucial in bridging the gap between textual data and emojis' rich, emotive context.\n\nThe study has several limitations. Firstly, the analysis relied on synthetically generated chat data rather than real-world conversations, which may limit the generalizability of our findings. Secondly, while we used emoji sentiment analysis, analyzing the specific emotions conveyed by emojis would be more accurate, as they can represent a wide range of emotions that sentiment analysis may not capture.\n\nFuture work should address these limitations by incorporating real-world chat data. Building a fully functional application that can track and analyze emotional dynamics in real-time chat conversations will be a significant next step, allowing for practical applications in various domains. Additionally, expanding the analysis to include multimodal data analysis, such as images or voice messages, could provide a better understanding of emotional dynamics in chat conversations.",
      "page_start": 16,
      "page_end": 16
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Aggregated emotion frequencies",
      "page": 4
    },
    {
      "caption": "Figure 2: Word cloud generated from the",
      "page": 4
    },
    {
      "caption": "Figure 1: , the aggregated emotion frequencies highlight significant trends",
      "page": 4
    },
    {
      "caption": "Figure 2: provides a visual representation of the most frequently used words in the Twitter",
      "page": 4
    },
    {
      "caption": "Figure 3: Bar chart illustrating the fre-",
      "page": 5
    },
    {
      "caption": "Figure 4: Word cloud representing the lin-",
      "page": 5
    },
    {
      "caption": "Figure 5: displays a bar chart of the sentiment scores for various emojis [29]. This",
      "page": 5
    },
    {
      "caption": "Figure 5: A bar chart representing the sentiment scores of various emojis, based on the",
      "page": 5
    },
    {
      "caption": "Figure 6: Examples of records in the collected dataset showcasing the interaction among",
      "page": 6
    },
    {
      "caption": "Figure 6: , the dataset encompasses",
      "page": 6
    },
    {
      "caption": "Figure 7: visualizes the dataset’s most frequently used words.",
      "page": 6
    },
    {
      "caption": "Figure 7: Word cloud depicting the most frequently used words in the synthetic dataset",
      "page": 7
    },
    {
      "caption": "Figure 8: ). There are two methods of choosing",
      "page": 8
    },
    {
      "caption": "Figure 8: Schematic representation of decision tree algorithm.",
      "page": 8
    },
    {
      "caption": "Figure 9: ). For classification tasks, the overall prediction is based on the most",
      "page": 9
    },
    {
      "caption": "Figure 9: Schematic representation of Random Forest algorithm.",
      "page": 9
    },
    {
      "caption": "Figure 10: ). The DistilBert self-attention mechanism computes attention scores based",
      "page": 9
    },
    {
      "caption": "Figure 10: The DistilBERT model architecture [42]",
      "page": 10
    },
    {
      "caption": "Figure 11: Emoji Sentiment Ranking from [29], showing the distribution of sentiment",
      "page": 11
    },
    {
      "caption": "Figure 11: , the Emoji Senti-",
      "page": 11
    },
    {
      "caption": "Figure 12: This section presents the mathemat-",
      "page": 11
    },
    {
      "caption": "Figure 12: Schematic representation of the proposed hybrid approach",
      "page": 12
    },
    {
      "caption": "Figure 13: Illustration of metrics of ML models and Distilbert performance as bar charts",
      "page": 14
    },
    {
      "caption": "Figure 14: a and Fig. 14b illustrate the distribution of dominant emotions exhibited in",
      "page": 14
    },
    {
      "caption": "Figure 14: Participants’ most frequently exhibited emotions",
      "page": 15
    },
    {
      "caption": "Figure 14: b illustrates stacked emotion scores",
      "page": 15
    },
    {
      "caption": "Figure 15: a illustrates the emotion tracking results in the analyzed chat. It can",
      "page": 15
    },
    {
      "caption": "Figure 15: b shows the distribution of scores for each emotion and their respective",
      "page": 15
    },
    {
      "caption": "Figure 15: Emotion tracking results",
      "page": 15
    }
  ],
  "tables": [
    {
      "caption": "Table 1: Statistical Summary of Emoji Sentiment Scores",
      "data": [
        {
          "Sentiment": "Neg",
          "Count": "751",
          "Unique": "271",
          "Freq": "31",
          "Mean": "0.164",
          "Max": "0.778",
          "Min": "0.006"
        },
        {
          "Sentiment": "Neut",
          "Count": "751",
          "Unique": "360",
          "Freq": "30",
          "Mean": "0.389",
          "Max": "0.987",
          "Min": "0.014"
        },
        {
          "Sentiment": "Pos",
          "Count": "751",
          "Unique": "374",
          "Freq": "24",
          "Mean": "0.447",
          "Max": "0.972",
          "Min": "0.007"
        }
      ],
      "page": 5
    },
    {
      "caption": "Table 2: Comparison of various machine learning algorithms and DistilBERT across",
      "data": [
        {
          "Accuracy Precision Recall F1": "0.20 0.21 0.20 0.16\n0.19 0.19 0.19 0.16\n0.26 0.25 0.26 0.24\n0.75 0.72 0.75 0.73\n0.67 0.67 0.67 0.67\n0.78 0.76 0.78 0.77\n0.93 0.90 0.91 0.90"
        }
      ],
      "page": 13
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Web-based chatting: Consumer communication in cyberspace",
      "authors": [
        "G Zinkhan",
        "H Kwak",
        "M Morrison",
        "C Peters"
      ],
      "year": "2003",
      "venue": "Journal of Consumer Psychology",
      "doi": "10.1207/S15327663JCP13-1&2_02"
    },
    {
      "citation_id": "2",
      "title": "Online chat rooms: Virtual spaces of interaction for socially oriented people",
      "authors": [
        "R Peris",
        "M Gimeno",
        "D Pinazo",
        "G Ortet",
        "V Carrero",
        "M Sanchiz",
        "I Ibáñez"
      ],
      "year": "2002",
      "venue": "CyberPsychology & Behavior",
      "doi": "10.1089/109493102753685872"
    },
    {
      "citation_id": "3",
      "title": "Challenges for meaningful interpersonal communication in a digital era",
      "authors": [
        "E Venter"
      ],
      "year": "2019",
      "venue": "HTS Teologiese Studies / Theological Studies",
      "doi": "10.4102/hts.v75i1.5339"
    },
    {
      "citation_id": "4",
      "title": "Communicating in organizations in the digital age",
      "authors": [
        "J West",
        "Z Ivanisov"
      ],
      "year": "2017",
      "venue": "SSRN Electronic Journal",
      "doi": "10.2139/ssrn.2973903"
    },
    {
      "citation_id": "5",
      "title": "Customer interaction 2.0: Adopting social media as customer service channel",
      "authors": [
        "M Geierhos"
      ],
      "year": "2011",
      "venue": "Journal of Advances in Information Technology",
      "doi": "10.4304/jait.2.4.222-233"
    },
    {
      "citation_id": "6",
      "title": "Humans and bots in internet chat: Measurement, analysis, and automated classification",
      "authors": [
        "S Gianvecchio",
        "M Xie",
        "Z Wu",
        "H Wang"
      ],
      "year": "2011",
      "venue": "IEEE/ACM Transactions on Networking",
      "doi": "10.1109/tnet.2011.2126591"
    },
    {
      "citation_id": "7",
      "title": "The role of emojis and emoticons in enhancing interpersonal communication through messenger and whatsapp applications",
      "authors": [
        "A Hasan"
      ],
      "year": "2018",
      "venue": "Adab Al-Kufa",
      "doi": "10.36317/0826-010-037-053"
    },
    {
      "citation_id": "8",
      "title": "Emojis and the performance of humour in everyday electronicallymediated conversation: A corpus study of whatsapp chats",
      "authors": [
        "A Sampietro"
      ],
      "year": "2020",
      "venue": "Internet Pragmatics",
      "doi": "10.1075/ip.00062.samp"
    },
    {
      "citation_id": "9",
      "title": "A wink and a nod: The role of emojis in forming digital communities",
      "authors": [
        "S Graham"
      ],
      "year": "2019",
      "venue": "Multilingua",
      "doi": "10.1515/multi-2018-0037"
    },
    {
      "citation_id": "10",
      "title": "Emoticons in computer-mediated communication: Social motives and social context",
      "authors": [
        "D Derks",
        "A Bos",
        "J Grumbkow"
      ],
      "year": "2008",
      "venue": "CyberPsychology & Behavior",
      "doi": "10.1089/cpb.2007.9926"
    },
    {
      "citation_id": "11",
      "title": "Tracking conflict and emotions with a computational qualitative discourse analytic support approach",
      "authors": [
        "N Rybak",
        "D Angus"
      ],
      "year": "2021",
      "venue": "PLOS ONE",
      "doi": "10.1371/journal.pone.0251186"
    },
    {
      "citation_id": "12",
      "title": "Analyzing Microblogging Posts for Tracking Collective Emotional Trajectories",
      "authors": [
        "C Loglisci",
        "G Andresini",
        "A Impedovo",
        "D Malerba"
      ],
      "year": "2018",
      "venue": "Analyzing Microblogging Posts for Tracking Collective Emotional Trajectories",
      "doi": "10.1007/978-3-030-03840-3_10"
    },
    {
      "citation_id": "13",
      "title": "Tracking and recognizing emotions in short text messages from online chatting services",
      "authors": [
        "C.-H Chen",
        "W.-P Lee",
        "J.-Y Huang"
      ],
      "year": "2018",
      "venue": "Information Processing & Management",
      "doi": "10.1016/j.ipm.2018.05.008"
    },
    {
      "citation_id": "14",
      "title": "Emotion analysis of dialogue text based on chatgpt: a research study",
      "authors": [
        "C Ran"
      ],
      "year": "2023",
      "venue": "International Conference on Algorithms, High Performance Computing, and Artificial Intelligence (AHPCAI 2023)",
      "doi": "10.1117/12.3011507"
    },
    {
      "citation_id": "15",
      "title": "Libsvm: A library for support vector machines",
      "authors": [
        "C.-C Chang",
        "C.-J Lin"
      ],
      "year": "2011",
      "venue": "ACM Trans. Intell. Syst. Technol"
    },
    {
      "citation_id": "16",
      "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter",
      "authors": [
        "V Sanh",
        "L Debut",
        "J Chaumond",
        "T Wolf"
      ],
      "year": "2019",
      "venue": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter",
      "doi": "10.48550/ARXIV.1910.01108"
    },
    {
      "citation_id": "17",
      "title": "Emotion and sentiment analysis from twitter text",
      "authors": [
        "K Sailunaz",
        "R Alhajj"
      ],
      "year": "2019",
      "venue": "Journal of Computational Science",
      "doi": "10.1016/j.jocs.2019.05.009"
    },
    {
      "citation_id": "18",
      "title": "Tracking and recognizing emotions in short text messages from online chatting services",
      "authors": [
        "C.-H Chen",
        "W.-P Lee",
        "J.-Y Huang"
      ],
      "year": "2018",
      "venue": "Information Processing & Management",
      "doi": "10.1016/j.ipm.2018.05.008"
    },
    {
      "citation_id": "19",
      "title": "Collective emotion dynamics in chats with agents, moderators and bots",
      "authors": [
        "Tadić Šuvakov"
      ],
      "year": "2014",
      "venue": "Condensed Matter Physics",
      "doi": "10.5488/cmp.17.33801"
    },
    {
      "citation_id": "20",
      "title": "Emotional persistence in online chatting communities",
      "authors": [
        "A Garas",
        "D Garcia",
        "M Skowron",
        "F Schweitzer"
      ],
      "year": "2012",
      "venue": "Scientific Reports",
      "doi": "10.1038/srep00402"
    },
    {
      "citation_id": "21",
      "title": "Fine-Grained Emotion Detection in Contact Center Chat Utterances",
      "authors": [
        "S Mundra",
        "A Sen",
        "M Sinha",
        "S Mannarswamy",
        "S Dandapat",
        "S Roy"
      ],
      "venue": "Fine-Grained Emotion Detection in Contact Center Chat Utterances"
    },
    {
      "citation_id": "22",
      "title": "",
      "authors": [
        "Springer"
      ],
      "year": "2017",
      "venue": "",
      "doi": "10.1007/978-3-319-57529-2_27"
    },
    {
      "citation_id": "23",
      "title": "Towards building an open-domain dialogue system incorporated with internet memes",
      "authors": [
        "H Lu",
        "Z Guo",
        "C Li",
        "Y Yang",
        "H He",
        "S Bao"
      ],
      "year": "2024",
      "venue": "IEEE/ACM Transactions on Audio, Speech, and Language Processing",
      "doi": "10.1109/taslp.2023.3288413"
    },
    {
      "citation_id": "24",
      "title": "Emotion Recognition in Conversation: Research Challenges, Datasets, and Recent Advances",
      "authors": [
        "S Poria",
        "N Majumder",
        "R Mihalcea",
        "E Hovy"
      ],
      "venue": "Emotion Recognition in Conversation: Research Challenges, Datasets, and Recent Advances"
    },
    {
      "citation_id": "25",
      "title": "Emotion recognition in conversations: A survey focusing on context, speaker dependencies, and fusion methods",
      "authors": [
        "Y Fu",
        "S Yuan",
        "C Zhang",
        "J Cao"
      ],
      "year": "2023",
      "venue": "Electronics",
      "doi": "10.3390/electronics12224714"
    },
    {
      "citation_id": "26",
      "title": "EmotionLines: An emotion corpus of multi-party conversations",
      "authors": [
        "C.-C Hsu",
        "S.-Y Chen",
        "C.-C Kuo",
        "T.-H Huang",
        "L.-W Ku",
        "N Calzolari",
        "K Choukri",
        "C Cieri",
        "T Declerck",
        "S Goggi",
        "K Hasida",
        "H Isahara",
        "B Maegaard",
        "J Mariani",
        "H Mazo",
        "A Moreno",
        "J Odijk"
      ],
      "year": "2018",
      "venue": "Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)"
    },
    {
      "citation_id": "27",
      "title": "Emotion recognition in conversations: A survey focusing on context, speaker dependencies, and fusion methods",
      "authors": [
        "Y Fu",
        "S Yuan",
        "C Zhang",
        "J Cao"
      ],
      "year": "2023",
      "venue": "Electronics",
      "doi": "10.3390/electronics12224714"
    },
    {
      "citation_id": "28",
      "title": "CARER: Contextualized affect representations for emotion recognition",
      "authors": [
        "E Saravia",
        "H.-C Liu",
        "Y.-H Huang",
        "J Wu",
        "Y.-S Chen"
      ],
      "year": "2018",
      "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
      "doi": "10.18653/v1/D18-1404"
    },
    {
      "citation_id": "29",
      "title": "Sentiment of emojis",
      "authors": [
        "Kralj Novak",
        "P Smailović",
        "J Sluban",
        "B Mozetič"
      ],
      "year": "2015",
      "venue": "PLoS ONE"
    },
    {
      "citation_id": "30",
      "title": "A detailed study on sentimental analysis using twitter data with an improved deep learning model",
      "year": "2021",
      "venue": "2021 Fifth International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC)",
      "doi": "10.1109/I-SMAC52330.2021.9640850"
    },
    {
      "citation_id": "31",
      "title": "Color-emotion associations in art: Fuzzy approach",
      "authors": [
        "M Muratbekova",
        "P Shamoi"
      ],
      "year": "2024",
      "venue": "IEEE Access",
      "doi": "10.1109/ACCESS.2024.3375361"
    },
    {
      "citation_id": "32",
      "title": "Music emotion recognition using k-nearest neighbors algorithm",
      "authors": [
        "A Ualibekova",
        "P Shamoi"
      ],
      "year": "2022",
      "venue": "2022 International Conference on Smart Information Systems and Technologies (SIST)",
      "doi": "10.1109/SIST54437.2022.9945814"
    },
    {
      "citation_id": "33",
      "title": "Fuzzy approach for audio-video emotion recognition in computer games for children",
      "authors": [
        "P Kozlov",
        "A Akram",
        "P Shamoi"
      ],
      "year": "2024",
      "venue": "14th International Conference on Emerging Ubiquitous Systems and Pervasive Networks / 13th International Conference on Current and Future Trends of Information",
      "doi": "10.1016/j.procs.2023.12.139"
    },
    {
      "citation_id": "34",
      "title": "Understanding environmental posts: Sentiment and emotion analysis of social media data",
      "authors": [
        "D Amangeldi",
        "A Usmanova",
        "P Shamoi"
      ],
      "year": "2024",
      "venue": "IEEE Access",
      "doi": "10.1109/ACCESS.2024.3371585"
    },
    {
      "citation_id": "35",
      "title": "Group movie selection using multi-channel emotion recognition",
      "authors": [
        "E Kadyrgali",
        "A Yerkin",
        "Y Torekhan",
        "P Shamoi"
      ],
      "year": "2024",
      "venue": "2024 IEEE AITU",
      "doi": "10.1109/IEEECONF61558.2024.10585521"
    },
    {
      "citation_id": "36",
      "title": "Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems",
      "authors": [
        "A Yerkin",
        "E Kadyrgali",
        "Y Torekhan",
        "P Shamoi"
      ],
      "year": "2024",
      "venue": "Multi-channel Emotion Analysis for Consensus Reaching in Group Movie Recommendation Systems"
    },
    {
      "citation_id": "37",
      "title": "Emotion recognition based emoji retrieval using deep learning",
      "authors": [
        "S Srivastava",
        "P Gupta",
        "P Kumar"
      ],
      "year": "2021",
      "venue": "2021 5th International Conference on Trends in Electronics and Informatics (ICOEI)",
      "doi": "10.1109/icoei51242.2021.9452832"
    },
    {
      "citation_id": "38",
      "title": "Idiot's bayes: Not so stupid after all?",
      "authors": [
        "D Hand",
        "K Yu"
      ],
      "year": "2007",
      "venue": "International Statistical Review",
      "doi": "10.1111/j.1751-5823.2001.tb00465.x"
    },
    {
      "citation_id": "39",
      "title": "A decision-theoretic generalization of on-line learning and an application to boosting",
      "authors": [
        "Y Freund",
        "R Schapire"
      ],
      "year": "1997",
      "venue": "Journal of Computer and System Sciences",
      "doi": "10.1006/jcss.1997.1504"
    },
    {
      "citation_id": "40",
      "title": "Classification and regression trees",
      "authors": [
        "L Breiman",
        "J Friedman",
        "R Olshen",
        "C Stone"
      ],
      "year": "1984",
      "venue": "Classification and regression trees"
    },
    {
      "citation_id": "41",
      "title": "Probabilistic Machine Learning: An Introduction",
      "authors": [
        "K Murphy"
      ],
      "year": "2022",
      "venue": "Probabilistic Machine Learning: An Introduction"
    },
    {
      "citation_id": "42",
      "title": "Improving crisis events detection using distilbert with hunger games search algorithm",
      "authors": [
        "H Adel",
        "A Dahou",
        "A Mabrouk",
        "M Abd Elaziz",
        "M Kayed",
        "I El-Henawy",
        "S Alshathri",
        "A Amin Ali"
      ],
      "year": "2022",
      "venue": "Mathematics",
      "doi": "10.3390/math10030447"
    },
    {
      "citation_id": "43",
      "title": "Sentiment of emojis",
      "authors": [
        "Kralj Novak",
        "P Smailovic",
        "J Sluban",
        "B Mozetic"
      ],
      "year": "2015",
      "venue": "PloS one",
      "doi": "10.1371/journal.pone.0144296"
    }
  ]
}