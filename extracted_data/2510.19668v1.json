{
  "paper_id": "2510.19668v1",
  "title": "Unraveling Emotions With Pre-Trained Models",
  "published": "2025-10-22T15:13:52Z",
  "authors": [
    "Alejandro Pajón-Sanmartín",
    "Francisco De Arriba-Pérez",
    "Silvia García-Méndez",
    "Fátima Leal",
    "Benedita Malheiro",
    "Juan Carlos Burguillo-Rial"
  ],
  "keywords": [
    "Emotion recognition",
    "large language models",
    "natural language processing",
    "open-ended responses",
    "prompt engineering",
    "transformer models."
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Transformer models have significantly advanced the field of emotion recognition. However, there are still open challenges when exploring open-ended queries for Large Language Models (LLMs). Although current models offer good results, automatic emotion analysis in open texts presents significant challenges, such as contextual ambiguity, linguistic variability, and difficulty interpreting complex emotional expressions. These limitations make the direct application of generalist models difficult. Accordingly, this work compares the effectiveness of fine-tuning and prompt engineering in emotion detection in three distinct scenarios: (i) performance of fine-tuned pre-trained models and general-purpose LLMs using simple prompts; (ii) effectiveness of different emotion prompt designs with LLMs; and (iii) impact of emotion grouping techniques on these models. Experimental tests attain metrics above 70 % with a fine-tuned pretrained model for emotion recognition. Moreover, the findings highlight that LLMs require structured prompt engineering and emotion grouping to enhance their performance. These advancements improve sentiment analysis, human-computer interaction, and understanding of user behavior across various domains. INDEX TERMS Emotion recognition, large language models, natural language processing, open-ended responses, prompt engineering, transformer models.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "I. Introduction",
      "text": "Emotion recognition is a task for Natural Language Processing (NLP), which enables machines to understand and respond to human emotions embedded in text. Emotion recognition analyzes texts to detect and classify emotions such as sadness, joy, love, anger, fear, and surprise  [1] . This ability is essential for various applications, including sentiment analysis, customer service, mental health monitoring, and human-computer interaction. The advent of transformer models has significantly advanced the field, offering good accuracy in capturing human emotions  [2] . NLP models have gained significant importance in recent years, primarily due to advances in their ability to analyze and understand human language in an automated manner  [3] . These improvements have been significantly enhanced, and the technology has been popularized by companies such as OpenAI and Google.\n\nTransformer models, introduced by  [4] , are a type of deep learning architecture that leverages self-attention mechanisms to process data sequences. These models can capture long-range dependencies and contextual information more effectively than previous architectures, such as Recurrent Neural Networks (RNNs) and their subset, Long Short-term Memory Networks (LSTMs)  [5] . Building on transformer architecture, Large Language Models (LLMs) are deep learning models trained on vast amounts of text data to understand and generate human language. LLMs, such as the Generative Pre-trained Transformer models (e.g., GPT-3 and GPT-4), leverage the extensive knowledge gained during pre-training on diverse text corpora and can be fine-tuned for specific tasks, achieving high accuracy in various NLP applications. In contrast, traditional machine learning (ML) models, such as logistic regression, support vector machines, and decision trees, typically rely on manually engineered features and are trained on specific tasks with limited data sets. While effective for certain applications, these models often lack the scalability and contextual understanding of transformerbased architectures and LLMs.\n\nTransformer models, such as Bidirectional Encoder Representations from Transformers (BERT) GPT, have demonstrated superior performance in a wide range of NLP tasks due to their ability to capture long-range dependencies and contextual information effectively. These models can be employed for prompt engineering and fine-tuning. Prompt engineering formulates specific prompts to guide the model's responses without altering internal parameters. At the same time, fine-tuning adjusts the model's weights by training it on a task-specific dataset.\n\nOne of the most challenging approaches to emotion recognition is the joint exploration of open-ended queries and transformer models. Unlike structured data, open-ended questions are rich in context and detail, providing a comprehensive view of the inquirer's emotions and desires. This complexity presents significant challenges for emotion detection models, as they must accurately interpret diverse expressions and contexts of emotion. To address this challenge, this work compares the effectiveness of prompt engineering and fine-tuning in emotion detection with open-ended questions.\n\nThis paper analyses three distinct scenarios in the context of emotion recognition: (i) performance of fine-tuned pre-trained models and general-purpose LLMs using simple prompts; (ii) effectiveness of different emotion prompt designs; and (iii) impact of different emotion grouping techniques on the performance of LLMs. Regarding emotion recognition with open-ended responses, the goal is to identify the most effective methods to improve the accuracy and reliability of BERT, RoBERTa, Gemma, GPT-3.5, and LLaMA-3. The results with six emotion classes show that fine-tuned BERT and spaCy models are effective at emotion detection with at least 80 % accuracy, while general-purpose LLMs using prompt engineering achieve only around 50 % accuracy. The latter models reach 80 % accuracy when focusing solely on two emotion categories.\n\nThis document is structured as follows. Section II surveys multiple works based on traditional and transformer-based models. Section III details the proposed method, describing the explored scenarios. Moreover, Section IV presents and discusses the results compared to competing works from the literature. Finally, Section V makes the final remarks.\n\nDespite recent advances, automatic emotion recognition in open-ended responses still presents significant research gaps. In particular, general-purpose LLMs show limitations in handling complex emotional expressions without specific tuning, and there is a critical dependence on prompt design. Furthermore, systematic comparisons between fine-tuningbased approaches and prompt engineering remain scarce in open-ended natural language contexts. Given these opportunities for contribution, the following objectives are proposed:\n\n• To comparatively evaluate the performance of finetuned pre-trained models and general-purpose LLMs using prompt engineering in emotion recognition tasks.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Ii. Related Work",
      "text": "Open-ended questions are a qualitative data collection method in which respondents can answer questions in their own words rather than selecting from predetermined options. Unlike closed-ended questions, which offer a fixed set of options (e.g., yes/no, multiple-choice), open-ended queries enable respondents to express their thoughts, feelings, and experiences. Additionally, open-ended questions are employed across various domains, including psychology  [6] , sociology  [7] , marketing  [8] , and education  [9] . Typically, they are employed in surveys, interviews, and focus groups to gather individual feedback and derive insights.\n\nThe analysis of open-ended responses presents several challenges. The unstructured nature of the data requires sophisticated methods of processing and interpretation. Traditionally, researchers have relied on manual classification, where themes and patterns are identified through an intensive reading process and categorization of responses  [10] . However, recent advancements in NLP and ML have automated the analysis of open-ended data, enabling efficient and scalable evaluation  [11] . NLP has grown significantly in recent years, primarily due to its flexibility to adapt to a wide range of applications and to generate complex responses with minimal instructions.\n\nAdditionally, in emotional evaluation, open-ended questions are a powerful source of information, as emotions are complex and multifaceted. In this context, open questions can help individuals understand how they feel and express emotions, which is fundamental to understanding consumer behavior  [12] , inferring mental health states  [13] , or improving human-computer interaction  [14] . To address this challenge, this research explores the ability of NLP models (LLMs and traditional approaches) to perform text-based emotional evaluation, aiming to comprehend and analyze the emotions expressed in a text.\n\nThe literature on emotional evaluation includes methodologies for analyzing emotional content  [15] , ML classification methods  [16] , NLP techniques  [17] , and the implications of these findings for various domains  [18] . Understanding human emotions in texts enables the analysis of human communication, leading to more informed decisions, better services, and improved outcomes across various fields  [19] . The integration of emotional evaluation into the analysis of open-ended responses represents a critical advancement in harnessing the full potential of textual data.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "A. Ml Models For Emotion Recognition",
      "text": "ML models have revolutionized the field of emotional evaluation, offering tools for extracting and interpreting the emotional content embedded in textual data  [20] . These models leverage advanced algorithms to analyze vast amounts of text efficiently and accurately, identifying patterns and emotional cues that may be imperceptible to traditional manual analysis.\n\nSupervised learning involves training models with labeled data sets where the emotional categories of text samples are predefined. This approach allows the model to learn the relationship between linguistic features and specific emotions. Standard supervised learning algorithms used in emotional evaluation include: (i) Naive Bayes (NB); (ii) Support Vector Machines (SVM); (iii) Neural Networks (NN); (iv) Logistic Regression (LR); (v) K-Nearest Neighbours (KNN); and/or (vi) Boosting and Gradient ensemble techniques, e.g., Random Forest. These ML algorithms have been successfully applied to sentiment analysis and emotion recognition  [21] .\n\nElaborating on the characteristics of these models for our work, NB is a probabilistic classifier based on Bayes' theorem that estimates the probability of a given class based on a series of observed features. This model has proven effective in text classification tasks, where vector representations (such as bags of words or TF-IDF) generate high-dimensional structures. Thanks to its low computational cost, ease of implementation, and competitive results, it can be used as a baseline. Moreover, SVM is especially effective for highdimensional data such as text, as it optimizes class separation through the superposition of hyperplanes. This enables robust classification even with small data sets. Its ability to handle multi-class problems makes it suitable for emotional analysis extended to a vast number of categories. NNs enable the capture of nonlinear and complex relationships in data. In text processing, this approach can learn hierarchical representations, detecting emotional nuances that elude simpler methods. Furthermore, LR is a linear classifier that is widely used for binary and multi-class classification. Its simplicity makes it a solid starting point, especially when combined with text representation techniques such as TF-IDF or word embeddings. On the contrary, KNN is a nonparametric method that classifies based on proximity in feature space. Although timeconsuming to perform, it is helpful in exploratory phases and as a benchmark against more sophisticated models. Finally, boosting and gradient ensemble techniques combine multiple classifiers to build more accurate and robust models. They are instrumental when working with unbalanced distributions.\n\nSentiment analysis enables automated and efficient processing of textual data to discern and categorize sentiment patterns. Typically, it focuses on determining the polarity of a text -whether it expresses positive, negative, or neutral sentiment -and is often used to measure public opinion, customer feedback, or overall sentiment towards a particular topic, product, or event  [22] . In this line,  [23]  applied SVM to train a sentiment classifier with reference data sets. Moreover,  [24]  employed Convolutional Neural Networks (CNNs) for sentiment analysis. Unlike traditional languagedependent methods that rely on word-level, this languageagnostic model processes raw text at the character level. The resulting robust sentiment classifier works across multiple languages without extensive pre-processing or languagespecific resources. Later,  [25]  performed a sentiment analysis on Twitter data using the NB model. The probabilistic model categorized sentiment, providing valuable information on public opinion and trends on social media platforms.\n\nEmotion recognition identifies the emotions contained within a text. Unlike sentiment analysis, which typically categorizes text into broad sentiment categories (positive, negative, and neutral), emotion recognition aims to identify and categorize emotions such as sadness, joy, love, and anger. This more sophisticated analysis involves complex modeling to detect emotional cues  [22] . Accordingly,  [26]  used an ML-based ensemble technique to classify six primary textual emotions. Specifically, it compares eight standard ensemble techniques to conclude that the ensemble with Term Frequency-Inverse Document Frequency (TF-IDF) achieves the best results. Moreover,  [27]  proposed a Multi-label KNN classifier to enable iterative adjustments in multi-label emotion recognition. This method was applied to enhance the accuracy and efficiency of emotion recognition in short Twitter texts. Among more recent works are the studies  [28]  and  [29] , which focused on emotion recognition from audio data.\n\nThe study  [28]  uses deep neural networks while  [29]  exploits CNNs.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "B. Transformer Models",
      "text": "LLMs represent a significant evolution in deep learning applied to natural language. Based on transformer-like architectures, these models are capable of processing text sequences considering the full context of a sentence or paragraph, allowing for a richer and more accurate understanding of meaning. An LLM is characterized by having been trained with large volumes of textual data, giving it a generalist capability to tackle multiple linguistic tasks. Typical applications include text generation, machine translation, sentiment analysis, and, more recently, emotion recognition  [30] .\n\nLinguistic feature extraction, used by initiatives such as the Semantic Orientation Calculator  [31] , assigns polarities to different words, creates a dictionary, and applies several algorithms to calculate emotional scores for each entry, resulting in a final classification. Recent advancements in NLP rely on developing transformer models and LLMs  [32] . While a transformer model provides the underlying deep learning architecture, an LLM applies the same architecture to complex linguistic tasks on a considerably larger scale. This is the case of well-known LLMs like ChatGPT and Gemini, which have become the basis for many state-of-the-art NLP solutions. These models are dedicated to understanding and generating human language, including billions of parameters, and are trained with large amounts of text data in parallel.\n\nThe mathematical operation of an LLM begins with the conversion of the text into numeric tokens using a Byte Pair Encoding (BPE) segmentation scheme  [33] . These tokens are transformed into fixed-dimensional vectors through an embedding layer, which assigns each token a continuous representation in a vector space. These vectors are processed sequentially by a stack of decoder blocks, each of which is responsible for progressively refining the internal repre-sentation of the sequence. The central component of each block is the Multi-Head Attention (MHA) mechanism  [34] , which enables the model to determine the relevance of each token concerning the others within the sequence context. Mathematically, this mechanism projects the input vectors into three matrices: Query (Q), Key (K), and Value (V ). The attention weights are then calculated using the scaled dotproduct attention formula, which adjusts the magnitude of the similarities between Q and transposed K by dividing them by the square root of the dimension of K, thereby stabilizing the gradients and improving training efficiency. The final step is to apply the softmax function, which takes a vector of real values as input and converts them into a probability distribution.\n\nThe result of this operation is a weighted combination of the vectors V , in which the weights assigned to each position depend on its contextual relevance in the sequence. Now that each token has a contextual vector, it is passed to a Feed-Forward Network (FFN) model 1  [34] , which is applied independently to each position in the sequence. This network is composed of two linear transformations separated by a nonlinear ReLU activation function (max(0, z)). This component introduces nonlinearity and more complex transformation capability, allowing the model to represent highly expressive functions.\n\nWhere x is the input vector for a token, already enriched by the attention function; W 1 and W 2 are trainable weight matrices, whose values are adjusted during training using an optimization algorithm; and b 1 and b 2 are bias vectors that allow shifting the output and increasing the flexibility of the model.\n\nCurrently, the most advanced and sophisticated solutions are based on transformers, which capture representations of words and contexts in a general and flexible way, adding significant value. Prominent models in emotion recognition include BERT  [35]  and GPT  [36] . Consideration should also be given to proprietary solutions, such as Anthropic, the basis for the enterprise conversational assistant Claude, or Inflection, a model used to create a personal intelligence assistant, as well as open source offers, such as Vicuna, a modified version of the LLM by Meta, LLaMA.\n\nTransformer technology has been employed in various emotion recognition tasks, demonstrating superior performance in accurately identifying and classifying emotions across diverse data sets and languages  [36] ,  [37] ,  [38] . This is true for both multimodal environments -including multiple types of data like audio, video, and text  [39] ,  [40] ,  [41]  -and unimodal environments -which rely on a single data type 1 Available at https://arxiv.org/pdf/2406.08413, September 2025.  [30] ,  [42] ,  [43] ,  [44] ,  [45] . Consequently, transformer models can perform audio-based, video-based, and text-based emotion recognition.\n\n[39] proposed Emotion-LLaMA, a large multimodal language model. It incorporates HuBERT for audio processing and visual encoders to gather facial details, dynamics, and context. Emotion-LLaMA significantly enhances emotional recognition and reasoning capabilities by integrating multiple descriptive elements like the audio tone, lexical subtitle, visual objective, visual expression, classification label, and modality. Conversely,  [41]  applied model adaptation techniques -deep prompt tuning and low-rank adaptation -to customize the Chat General Language Model (ChatGLM), an open-source pre-trained language model, for emotion recognition tasks. The adapted versions outperform state-of-the-art models, tested on six audio, video, and text datasets.\n\nMore recent solutions using transformers are  [46] ,  [47] ,  [48] . Firstly,  [46]  proposed MobileBERT for emotion recognition from textual and video data. A similar solution is proposed in  [47] , which utilizes KoELECTRA and HuBERT in a multimodal scenario involving both textual and audio data. Finally, in  [48] , a textual emotion recognition system based on LLaMA2 is presented.\n\nMoreover, Emotion Recognition in Conversation (ERC) focuses on detecting emotions during dialogues. It aims to identify the emotional category of each utterance in a conversation, whether text-based or audio-based. In this line,  [42]  introduced InstructERC, a framework that combines the strengths of retrieval-augmented mechanisms and LLM solutions like GPT-3 and T5 to access external knowledge and contextual information, thereby addressing the limitations of traditional ERC models. By employing these models, In-structERC improves the accuracy of emotion classification in dialogues. Conversely,  [30]  explored the text-generating capabilities of LLMs to enrich intelligent conversational agents with the ability to recognize and adapt to the emotions of the partner speaker during textual dialogues. Similarly,  [43]  proposed a text-based ERC considering contents and contextual factors like dialogue history, speaker roles, and the interplay between different conversational turns. In the end,  [44]  presented DialogueLLM, an emotion and context knowledge enhanced language model designed explicitly for ERC, based on open-source base models, namely LLaMA2. Similarly,  [45]  and  [49]  presented new advancements in the field of ERC. More in detail,  [45]  worked with ambiguous emotions in zero-shot and few-shot settings, while  [49]  focused on zero-shot conditions but performed experiments with real and synthetic data in both text and speech modalities.\n\nSpeech Emotion Recognition (SER) identifies and classifies the speaker's emotional state based on vocal expressions. This implies analyzing various speech signal features, such as pitch, tone, intensity, rhythm, and prosody, to detect emotions like happiness, sadness, anger, and fear. In this line,  [40]  explored the integration of speech analysis, text generation, and speech synthesis. The data2vec pre-trained model performs speech analysis to capture nuanced vocal features;\n\nGPT-4 generates text to provide contextual understanding and augment emotion detection, and Azure Text-to-Speech implements emotional speech synthesis to create a more expressive and accurate SER system.\n\nFinally, recognizing emotions through transformer technology enables asking open-ended questions using an old human strategy, i.e.. An open-ended query expands the range of potential responses and increases the model's uncertainty. The model generates an elongated response to traverse the spectrum of possible interpretations to curtail this ambiguity. In this regard,  [50]  evaluated the capabilities of LLMs to understand human intentions, emotions, and reasoning processes when addressing open-ended questions. The study compares human and LLM responses using Zephyr-7B, LLaMA2, and GPT-4. The results show the effectiveness of incorporating mental states, such as human intentions and emotions, into prompt tuning to improve the quality of LLM reasoning. Moreover, our prior work by  [51]  combined contextual information with prompt engineering and a general-purpose LLM to enhance emotion recognition. We adopted a prompt template integrating the head, emotions, polarities, objective, structure, question, and optional conversation. In addition,  [41]  recommended and implemented a two-sentence prompt template. The first sentence provides the emotion recognition instructions: \"Classify the sentiment of the sentence to Emotion1, Emotion2, ..., Emotion k \". The second sentence holds the contents submitted for emotion recognition: \"<a single sentence from the test set>\". The value of k corresponds to the number of sentiment/emotion categories specific to the dataset.\n\nIn summary, most of the reviewed research follows code rather than prompt-oriented strategies, which significantly restricts reuse by other researchers and professionals. Standard code-oriented strategies can be used with specialized and general-purpose pre-trained models, whereas promptoriented strategies only work with general-purpose pretrained models. The primary advantages of the current prompt-based proposal over existing methods lie in its simplicity and seamless adaptability to diverse fields and general-purpose pre-trained models.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "C. Research Contributions",
      "text": "Emotion recognition has improved human-computer interaction, enhanced customer service, and supported mental health interventions. It involves identifying and classifying emotional states from textual, auditory, or visual data, making it essential for creating empathetic and responsive intelligent systems. This work presents a novel contribution to the field of emotion recognition from open text through the combined use of specialized pre-trained models and general-purpose LLMs. Unlike previous studies that focus exclusively on a single technique (either fine-tuning or prompt engineering), our proposal systematically compares both approaches in different scenarios, also incorporating different prompt design and emotion grouping strategies. The main contributions are the following:\n\n• A hybrid approach is proposed that integrates fine-tuned models and general models with prompt engineering techniques.\n\n• Five types of prompts and three different ways of grouping emotions are analyzed, evaluating their impact on model performance.\n\n• The approach's replicability and extension are facilitated by providing reusable prompt structures that are adaptable to different models. Table  1  offers a comparative analysis of the emotion recognition works referred to above considering the task (emotion classification: EC, emotion recognition: ER, ERC, sentiment analysis: SA and SER), the data modality (audio: A, text: T, video: V), the category of the technique (traditional ML or transformer-based) and the usage of prompt-based strategies.\n\nWhile earlier works, such as those by  [23] ,  [24] , and  [25] , focused on sentiment analysis using ML-based techniques, more recent studies adopt transformer-based methods for text-based  [30] ,  [36] ,  [38] ,  [42] ,  [43] ,  [50] ,  [51] ,  [44] ,  [45]  and multimodal  [39] ,  [40] ,  [41] ,  [49]  emotion detection. Only  [41] ,  [50] , and  [51]  have explored prompt-based strategies for emotion recognition with transformer models.  [50]  used prompts to perform text-based emotion recognition. Specifically, they compare, for a given topic, the reasoning quality and the emotional contents of open-ended responses produced by humans and LLM models.  [51]  used prompt engineering with GPT-3.5 for contextual emotion recognition within interactive conversations and extensive texts. The extensive texts are dynamically divided into fragments and submitted sequentially as a conversation. In the case of a conversation, the prompt holds the entire conversation as context and indicates which part to analyze in each iteration; in the case of an extensive text, the prompt holds the emotions and polarities identified so far as context and specifies the text fragment to analyze in each iteration. This decision to provide the maximum possible context enables the model to achieve more profound results, as past events are essential.  [41]  adapted the pre-trained ChatGLM language model for emotion recognition and then tested the resulting models using a sentence-level emotion recognition prompt.\n\nIn contrast, the proposed solution integrates ML-and transformer-based techniques with multiple prompt strategies and emotion groupings. The design and refinement of openended questions are innovative features that enhance the model's ability to adapt and respond to contextual variations, significantly advancing emotion recognition. Furthermore, the current work leverages the power of fine-tuned specialized and general-purpose pre-trained models to enhance the performance of text-based emotion recognition.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Iii. Method",
      "text": "",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "A. Large Language Models",
      "text": "This work explores the following LLM implementations: Gemma, GPT-3.5, LLaMA-3, and BERT.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "1) Gemma",
      "text": "Gemma is a model developed by Google and introduced in February 2024. The adopted Gemma 1.1 model (gemma1.1-7b-it 2 ) has 7 billion parameters and offers excellent ver- 2 Available at https://huggingface.co/docs/transformers/model_doc/ gemma, September 2025. satility in a wide range of areas. This version (1.1) has undergone substantial modifications by being trained using a novel method of Reinforcement Learning from Human Feedback (RLHF). This resulted in significant improvements in quality, coding capabilities, veracity, instruction following, and quality of multi-turn conversations.\n\nThe great advantage of this model lies in the balance between computing capacity and the resources required. Although it has a limited number of parameters compared to others, it exhibits very high performance in various applications.\n\n2) GPT-3.5 GPT-3.5 3 , based on GPT-3, represents a significant evolution in natural language generation technology. This model, created by OpenAI, demonstrates an enhanced ability to comprehend and generate text with a deeper and more coherent context, thanks to its use of 175 billion parameters and extensive training on diverse datasets.\n\nCompared to other models, the distinctive features of GPT-3.5 are its scale and complexity, which translate into high fluency and a deep understanding of complex linguistic features. This last feature allows this version to explore broader contexts than its predecessors.\n\nThanks to these improvements, the GPT-3.5 model can be utilized in complex domains and real-time applications due to its enhanced inference capability, which enables faster responses. This makes it ideal for complex process automation tasks, such as the current work.",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "3) Llama-3",
      "text": "LLaMA-3 is a model developed by Meta and introduced in April 2024. The third and most recent version includes powerful NLP capabilities similar to those of the models mentioned above.\n\nThe current system uses the 8 billion parameters version oriented to instructions  4  to provide optimized outputs for feature extraction processes. Unlike other models, LLaMA-3 needs to incorporate different prompts delimited by keywords indicated in the documentation to exemplify the outputs.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "4) Bert",
      "text": "BERT is a language model developed by Google in 2018. Unlike traditional NLP models, which process text sequentially and in only one direction (left-to-right or right-toleft), BERT employs a transformer architecture that enables bidirectional encoding of context. This means that BERT can simultaneously consider information from both preceding and following words in a sentence, providing a richer and more accurate understanding of the contextual meaning of each word.\n\nOne of the most prominent features of BERT is its ability to pre-train large corpora of unlabelled text using two main tasks: masked language modeling (MLM) and next sentence prediction (NSP). With MLM, BERT learns to predict hidden words in a sentence based on context, while with NSP, the model learns the relationship between two consecutive sentences.\n\nThe versatility of BERT lies in its ability to adjust to specific NLP tasks with little additional labeled data. This feature allowed us to fine-tune BERT for emotion recognition. The process ensures that the system consistently produces an adequate output, regardless of the quality of a specific prompt.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "5) Roberta",
      "text": "RoBERTa is an optimized variant of BERT, introduced by Facebook AI in 2019. Unlike the original BERT, RoBERTa removes the next-sentence prediction objective, applies dynamic masking during pretraining, and is trained on a significantly larger corpus. These modifications lead to richer contextual representations and better generalization capabilities, which are crucial for fine-grained emotion recognition. Consequently, RoBERTa has been widely adopted as one of the reference transformer models in multiple NLP tasks, including sentiment and emotion analysis  [52] . To avoid redundancy in diagrams and figures, only BERT is explicitly depicted since RoBERTa is a direct improvement, sharing the same underlying architecture with modifications in the pretraining process (e.g., dynamic masking and removal of the next-sentence prediction objective). Therefore, whenever BERT is referenced in methodological diagrams, it should be understood that RoBERTa is also encompassed in the evaluation.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "B. Traditional Models",
      "text": "spaCy is an NLP library written in Python, which stands out for speed, efficiency, and accuracy in a wide range of NLP tasks. Spacy allows the training of small models focused on a specific classification function, like detecting six emotion classes  5  .\n\nSpacy is a powerful tool for building a text classification model for polarity or entity detection. These features, combined with the extensive existing community, make SpaCy a versatile tool for text-based emotion detection.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "C. Emotion Recognition 1) Prompt Engineering",
      "text": "The current prompt engineering approach is applied to Gemma, GPT-3.5, and LLaMA-3. The prompts used with Gemma (see Listing 1 for an illustrative example) and GPT-3.5 (see Listing 2) are similar because the system understands the instructions perfectly without needing special commands. The LLaMA-3 prompt requires, as referred to in Section III-A3, specific keywords to obtain optimal results (see Listing 3). These prompts provide context (Contxt), instructions (Instru), and the sentence (Sentnc) for the general-purpose LLM to analyze.\n\nPrompt execution comprises prompt submission, with the support of function calling in the case of GPT-3.5, and response post-processing. The goal is to identify the specified emotions within the submitted text.\n\n• Submission. The interface with Gemma was provided via a Python server with Flask 6 as front-end and the gemma1.1-7b-it 7 model as a back-end. The LLaMA-3 model was deployed using the Text Generation Interface  8  system provided by Hugginface to optimize model generation runtime. However, it is not yet fully compatible with Gemma. Both models have been deployed using Kubernetes, allowing a fast and resource-efficient deployment. The interface with GPT-3.5 was via the API offered by OpenAI. The calls to the API require using an API-key. Being GPT-3.5, a private model, OpenAI implements a pay-as-you-go charging model. • Function calling is used with GPT-3.5. This functionality allows the specification of the expected outputs. This provides greater precision when making requests, avoiding results with additional text or wrong ones. However, it is still necessary to incorporate post-processing functions to obtain a clean output according to the desired format.\n\n• Post-processing is applied to LLM outputs to filter out unwanted words and incorrect formatting. In some cases, emotions with similar connotations can be confused, e.g., joy and hope. Therefore, one of the postprocessing steps is to normalize the values using a dictionary regarding the six considered emotions  9  . Using model-specific regular expressions 10  helps to remove unwanted characters and words, e.g., line breaks or quotation marks, or the word JSON that appears explicitly with Gemma.",
      "page_start": 7,
      "page_end": 8
    },
    {
      "section_name": "2) Fine-Tuning",
      "text": "As fine-tuning of Gemma, GPT-3.5 and LLaMA-3 is out of the scope of this work, this step was applied just to spaCy and BERT.\n\nBeing a transformer model, BERT was fine-tuned to recognize the six emotions. First, it was trained using the aforementioned fine-tuning data partition with the parameters in Table  2 . Table  3  details the parameters used in the RoBERTa model. This training produces a reduced model that can be executed on machines with limited resources.\n\nspaCy is a traditional model that incorporates a series of functionalities, allowing for adaptation to any field or application. This is the case of pipes, which support model retraining for emotion recognition. Specifically, this work uses a test categorizer of six classes corresponding to the target emotions. Subsequently, pretraining was performed with the fine-tuning data partition described in Section IV-A to detect the six target classes solely. Finally, the fine-tuned BERT, RoBERTa and spaCy models are ready for evaluation using the fine-tuning data partition also described in Section IV-A. Note that neither BERT, RoBERTa nor spaCy supports user prompting.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "3) Evaluation",
      "text": "The results are evaluated using classical Artificial Intelligence metrics, such as accuracy, recall, precision, and Fscore.\n\nTo analyze the behavior of the selected models with different prompts and emotion groups, there are experiments with five types of prompts (see Section III-D) and three emotion groupings with six, three, and two classes (see Table  4 ). The six classes correspond to the sadness, joy, love, anger, fear, and surprise emotions; the three classes refer to positive (love), negative (fear), and neutral (surprise), whereas the two classes correspond to positive (joy/love) and negative (anger/sadness) feelings. The class grouping was based on the emotional charge.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "D. Scenarios",
      "text": "The experiments consider three scenarios:\n\n• S1 compares the performance of general-purpose LLMs versus pre-trained models using basic prompts (see Section III-C1). • S2 analyses the performance of the LLMs with different prompts:\n\n-Basic prompt requests a single emotion from the available lists (see Section III-C1).\n\n-Mask prompt applies a binary mask to detect the emotions (see Table  5 ). -Percent prompt requests emotion percentages in JSON format. The model will be instructed that the desired output is a JSON list with the percentage of each analyzed emotion in the text. It will also be established that there must always be a dominant emotion. -Numerical prompt associates each emotion with a number. -Inverse prompt asks for the inverse emotion. The model is instructed to identify the inverse emotion to the one in the text. This prompt establishes whether the model can make complex associations between emotions.\n\n• S3 assesses the impact of the distribution, choice, and grouping of emotions (six, three, and two classes) in the LLMs.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Iv. Experimental Results",
      "text": "Experiments were performed on a computer with the following hardware specifications:\n\n-Operating System: Ubuntu 22.04.4 LTS 64 bits.\n\n-Processor: IntelCore i7-13700K 3.40 GHz.\n\n-RAM: 32 GB DDR4.\n\n-Disk: 1000 GB NVME.\n\n-GPU: Nvidia GTX-1050Ti 4 GB. The LLM experiments were performed in a server with the following hardware specifications:\n\n-Operating System: Debian 10 Buster 64 bits.\n\n-Processor: IntelXeon Gold 5317 3.00 GHz.\n\n-RAM: 128 GB DDR4.\n\n-Disk: 100 GB SSD.\n\n-GPU: Nvidia A10 20 GB.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "A. Experimental Data Sets",
      "text": "The experimental data is publicly available  11  . Table  6  shows the distribution by emotion category of two subsets (train and test). The first is used to fine-tune the traditional and BERT models. The second, with 16 000 samples, is intended for their evaluation.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "B. Theoretical Evaluation",
      "text": "In this section, a theoretical evaluation of the scenarios S1, S2, and S3 presented in Section III-D is performed.  The performance difference between LLMs and pre-trained models can be expressed as:\n\nwhere\n\nGiven a model m, different prompt strategies are evaluated p ∈ P = {p b , p m , p % , p n , p inv }, where:\n\n• p b is the basic prompt.\n\n• p m is the binary-masked prompt.\n\n• p % is the prompt based on percentages in JSON format.\n\n• p n is the numerical codified prompt.\n\n• p inv is the inverse emotion prompt.\n\nThe difference in performance between the two prompt strategies is defined as:\n\nBeing C the set of emotional classess and Π k a partition of C in k non-empty subsets (in our study k = {6,3,2}), Π k fulfills that\n\nThis relationship follows the partition refinement principle, where Π k is a refinement of Π k ′ , which implies a higher emotional granularity.\n\nFor a model m and a prompt p, we define the performance as M(m, p, Π k ). The difference in performance from a higher to a lower granularity, that is, grouping emotions, is defined as:\n\nThis value represents the gain obtained by reducing the class space complexity. Under the specific emotion separability hypothesis, we may assume that if H(Π k ) is the entropy associated with the portion Π k .\n\nThis formulation enables us to assess the impact on output space reduction as a supervised semantic compression phenomenon using set theory and information theory.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "C. Experimental Evaluation",
      "text": "Table  7  shows the results of the first scenario. The finetuning approaches (BERT, spaCy, and especially RoBERTa) yield the best results, with RoBERTa clearly outperforming all other models by reaching 90 % precision, 88 % accuracy, recall, and F-score. In contrast, general-purpose LLMs return results with accuracy close to 60 % and around 50 % for the remaining metrics. The confusion matrices (Figure  2 ) reveal that these models make many mistakes between close emotions (e.g., joy/love and sadness/anger) and even confuse opposite emotions (joy/sadness).\n\nThis highlights the advantage in this case of fine-tuned transformer models, which can distinguish fine-grained emotional categories thanks to their ability to capture deep contextual dependencies. Among them, RoBERTa achieves the best overall results due to several key improvements over BERT. It removes the next-sentence prediction objective, uses dynamic masking during pretraining, and is trained on a significantly larger corpus. These modifications allow RoBERTa to learn richer contextual representations and generalize better to unseen examples, which is crucial for separating semantically similar emotions. In contrast, general-purpose models without task-specific training struggle to separate the categories. These values may be the result of two possible factors. The issue may stem from the use of an inappropriate prompt or the existence of similar emotional categories that are difficult to classify. Both approaches are explored below. Table  8  shows the variability in performance depending on the prompt engineering strategy used. Prompt 1 presents the best F-score for all models, while more complex formulations, such as inverse emotion (i.e., strategy 5), lead to significantly lower performance, especially in Gemma and GPT-3.5.\n\nThe lower results are obtained with prompts 2 (binary mask) and 5 (inverse emotion). The results with the inverse emotion prompt indicate that the models cannot establish complex relationships, such as detecting an opposite emotion. In this respect, LLaMA-3 is the most powerful model, with values of accuracy 10 % to 25 % above those of the others, as can be seen in Table  8  with the fifth prompt engineering strategy. The results obtained with the binary mask prompt are limited. In this case, the model trained solely on text was asked to establish a relationship between an emotion and a binary mask representation of that emotion.\n\nFurthermore, the results of prompt 2 (binary mask) show the limited ability of the models to understand the translation to a binary space. However, the numerical interpretation (prompt 4), although it does not improve the results, does offer an acceptable translation compared to the basic prompt, except in the case of Gemma, which again drastically reduces its performance.\n\nThis suggests that LLMs are highly sensitive to prompt design and that complex reasoning, such as emotion inversion, is subject to improvement. The latter emphasizes the importance of clear and concise communication for achieving effective emotion detection in zero-shot scenarios. Furthermore, the limited ability of the models to address categorization tasks in highly granular contexts, where emotions with very similar semantic meanings exist, is identified.\n\nGiven that LLMs detect emotions at the word level instead of the sentence level, the six emotion classes were grouped into three classes, applying the prompt 1 strategy: positive (love), negative (fear), and neutral (surprise). Table  9  and Figure  3  show the results of this approach. As can be seen in Table  9 , the results show a notable improvement when reducing the number of emotion classes from six to three. Fscore values increase 10 % points compared to the previous scenario, confirming that emotion grouping reduces ambigu-ity and confusion between semantically close classes (e.g., joy and love). This result supports our claim that generalist LLMs have difficulty discriminating fine-grained emotion categories if they have not been previously fine-tuned.\n\nThe confusions decrease, reaching 60 % in all metrics with Gemma and GTP-3.5. However, it is still far from the 90 % of the fine-tuned RoBERTa model with the six emotions.\n\nAdditionally, the confusion matrices reflect a large number of errors committed by the neutral category toward positive and negative emotions. This effect translates into metrics that fail to exceed 70 %, hampered by the results obtained in this intermediate category.\n\nFinally, Table  10  and Figure  4  elaborate on the binary scheme (positive versus negative emotions). As observed in Table  10 , the models achieve accuracies and F-score values greater than 78 % in all cases. These results demonstrate that LLMs can be effective in simplified emotional analysis tasks, even without specialized training, validating their applicability in contexts where it is sufficient to identify the general emotional polarity of the text.\n\nFurthermore, the experimental results support the conclusion that general-purpose LLM instances have difficulty detecting more than two classes and that optimal performance requires fine-tuning.  [50]  examined the extent to which LLM understand and integrate human intentions and emotions in their open-ended answers. The approach consists of submitting human prompts from an online discussion forum and collecting and evaluating the LLM-generated responses. The evaluation relies on (i) humans to determine the reasoning quality of the LLM responses; (ii) statistical significance to establish the emotional dissimilarity between human and LLM responses; and (iii) metrics to quantify the semantic similarity and lexical overlap between human and LLM responses. Although with a different objective, this work on the human-like reasoning capabilities of LLMs addresses open-ended questions and identifies emotions and sentiments. Moreover, two of the general-purpose LLM used are related: LLaMA-2 and GPT-4 versus LLaMA-3 and GPT-3.5, respectively. Regrettably, the emotion recognition metrics are not comparable. Nonetheless, existing similarities allow the comparison of qualitative results regarding emotion recognition with the same-family models. Best results were obtained with GPT-4 followed by LLaMA-2 in the case of  [50] . The identical behavior of the same-family models in the current proposal supports the findings.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "D. Discussion",
      "text": "[51] explored contextual information to improve emotion recognition with general-purpose LLM. The designed prompt always contains full or partial contextual data (the complete text or, alternatively, the emotions and polarities detected so far). The evaluation involved three public datasets and GPT-3.5. The Conversations and TED talks, manually labeled by the authors, achieved an F-score above 70 % for emotions and 78 % for polarities. The Short phrases, pre-labeled by default with positive and negative polarities, reached 62 % with emotions and 87 % with polarities. Since the data sets differ from those adopted in the current work, the results are not directly comparable. In the current work, with the emotion data set, GPT-3.5 achieved values of F1 around 52 % (Table  7 ), 62 % (Table  9 ) and 80 % (Table  10 ) in the detection of six classes, three classes, and two polarities, respectively. While the polarity results obtained with the emotion data set are aligned with those obtained by  [51]  with the Short phrases, the emotion recognition values are considerably lower. This difference may result from the impact of contextual data and the manual labeling of conversations and TED talks.\n\nThe basic prompt templates are tailored to each LLM, resulting in three prompt templates. These templates are more detailed than the one proposed by  [41]  and less detailed than the one adopted by  [50] . The size of this more extended template is related to the specific context and the dimensions of the instructions. While all templates provide the task instructions, the list of emotions, and the sentence to be examined, the LLM prompt templates designed for this work and by  [50]  also provide some context. However, it is far from the total or partial context provided by  [51] . While supplying context makes perfect sense, primarily when the data are organized by conversation, topic, or document, it has little impact when the data are made of unrelated short sentences.\n\nThe best overall results regarding the detection of six emotions were achieved with the fine-tuned pre-trained RoBERTa model, with all metrics above 88 %.     further. As can be observed, our solution is the one that attains better performance in all metrics, with difference values of 35.63 % in accuracy compared to  [30]  and 33.55 % in F-measure compared to  [43] .\n\nRegarding the most recent work, our proposal continues to be the one with better performance. Compared to the works by  [44]  and  [45] , the differences surpass the 20 % while being even higher between our proposal and that by  [49] , in which we attained an accuracy more than 35 % points superior. The results presented indicate that generalist LLMs show limitations in fine-grained and multi-class emotion recognition tasks. However, their performance improves significantly when both the prompt design and the emotional class structure are simplified. While complex prompts reduce accuracy, simpler ones allow for better extraction of implicit knowledge from the model. Furthermore, by grouping emotions into more general classes, the models achieve competitive results without the need for fine-tuning. This empirical evidence supports the use of a hybrid strategy, which combines the specialization of trained models with the flexibility of generalist models guided by prompt engineering.\n\nDespite the promising results, it is essential to elaborate on the limitations of the proposal. First, general-purpose LLMs may underperform in multi-class emotion recognition tasks without applying fine-tuning. Additionally, performance is highly dependent on prompt design, thereby increasing the complexity of implementation. Moreover, the experiments focused initially on six emotions, and further analyses will be required to reflect the emotional richness present in real-world applications. Context-aware prompt engineering strategies may also be appropriate.",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "V. Conclusions",
      "text": "With the advent of transformer models, the field of emotion recognition has experienced significant advancements. However, challenges remain regarding the exploration of open-ended queries and transformer models. Consequently, this study evaluates the performance of a large set of wellknown LLMs with different prompt strategies and emotion groupings.\n\nThe evaluation stage comprises three scenarios to provide a comprehensive analysis of LLMs for emotion detection in open-ended queries: (i) performance of fine-tuned pre-trained models and general-purpose LLMs using simple prompts; (ii) effectiveness of different emotion prompt designs; and (iii) impact of emotion grouping techniques on the performance of LLMs.\n\nThe fine-tuned RoBERTa, one of the most widely used LLMs in the literature, was the best emotion detector with metrics above 88 %. Moreover, the spaCy model optimized for emotion recognition reports an average performance equivalent to that of the fine-tuned BERT. Conversely, the general-purpose LLMs using prompt engineering obtained results close to 50 % with six emotions. Their performance improved as the number of emotion groupings decreased, reaching values near 80 % for both positive and negative polarities. The prompts with the best results are the basic prompts.\n\nShortly, the plan is to do further research on (i) prompt design and refinement -define a unique user prompt template, automatically refine the submitted user prompts, and automatically translate them to the different requirements of distinct general-purpose LLM models; (ii) perform emotion recognition through general-purpose LLM modelsexperiment with additional general-purpose LLM models, namely ChatGLM and GPT-4o, with other publicly available benchmark data sets; and (iii) incorporating multimodal approaches that integrate text, audio, and images for emotion recognition in more complex contexts.",
      "page_start": 14,
      "page_end": 15
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: presents the modules of the proposed architecture.",
      "page": 5
    },
    {
      "caption": "Figure 3: show the results of this approach. As can be seen",
      "page": 11
    },
    {
      "caption": "Figure 4: elaborate on the binary",
      "page": 11
    }
  ],
  "tables": [
    {
      "caption": "Table 1: offers a comparative analysis of the emotion recog-",
      "page": 5
    },
    {
      "caption": "Table 2: Table 3 details the parameters used in the RoBERTa",
      "page": 9
    },
    {
      "caption": "Table 7: shows the results of the first scenario. The fine-",
      "page": 10
    },
    {
      "caption": "Table 8: shows the variability in performance depending",
      "page": 11
    },
    {
      "caption": "Table 8: with the fifth prompt",
      "page": 11
    },
    {
      "caption": "Table 9: , the results show a notable improvement when",
      "page": 11
    },
    {
      "caption": "Table 10: and Figure 4 elaborate on the binary",
      "page": 11
    },
    {
      "caption": "Table 10: , the models achieve accuracies and F-score values",
      "page": 11
    },
    {
      "caption": "Table 7: ), 62 % (Table 9) and 80 % (Table 10) in the detection of six",
      "page": 12
    },
    {
      "caption": "Table 11: presents a comparison with the most related",
      "page": 12
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "A survey of state-of-the-art approaches for emotion recognition in text",
      "authors": [
        "N Alswaidan",
        "M Menai"
      ],
      "year": "2020",
      "venue": "Knowledge and Information Systems"
    },
    {
      "citation_id": "2",
      "title": "Mem-oCMT: multimodal emotion recognition using cross-modal transformerbased feature fusion",
      "authors": [
        "M Khan",
        "P.-N Tran",
        "N Pham",
        "A Saddik",
        "A Othmani"
      ],
      "year": "2025",
      "venue": "Scientific Reports"
    },
    {
      "citation_id": "3",
      "title": "Natural language processing: State of the art, current trends and challenges",
      "authors": [
        "D Khurana",
        "A Koli",
        "K Khatter",
        "S Singh"
      ],
      "year": "2023",
      "venue": "Multimedia tools and applications"
    },
    {
      "citation_id": "4",
      "title": "Attention is All you Need",
      "authors": [
        "A Vaswani",
        "N Shazeer",
        "N Parmar",
        "J Uszkoreit",
        "L Jones",
        "A Gomez",
        "L Kaiser",
        "I Polosukhin"
      ],
      "year": "2017",
      "venue": "Proceedings of the Annual Conference on Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "5",
      "title": "Modeling multi-factor user preferences based on Transformer for next point of interest recommendation",
      "authors": [
        "Y Zheng",
        "X Zhou"
      ],
      "year": "2024",
      "venue": "Expert Systems with Applications"
    },
    {
      "citation_id": "6",
      "title": "Adaptation of quizzing in learning psychology concepts",
      "authors": [
        "N Obergassel",
        "S Heitmann",
        "A Grund",
        "S Fries",
        "K Berthold",
        "J Roelle"
      ],
      "year": "2025",
      "venue": "Learning and Instruction"
    },
    {
      "citation_id": "7",
      "title": "Statistical Analysis of Empirical Data in the Process ff Sociological Research",
      "authors": [
        "K Kosimov"
      ],
      "year": "2025",
      "venue": "Proceedings of the International Scientific Research Conference"
    },
    {
      "citation_id": "8",
      "title": "No marketing on a dead planet\": rethinking marketing education to support a restoration economy",
      "authors": [
        "S Helm",
        "V Little",
        "C Frethey-Bentham"
      ],
      "year": "2024",
      "venue": "Journal of Macromarketing"
    },
    {
      "citation_id": "9",
      "title": "Are Open-Ended Question Assessments an Emerging Trend in US Medical Education?",
      "authors": [
        "D Olvet",
        "T Fulton",
        "M Kruidering",
        "J Brenner",
        "J Bird",
        "J Willey"
      ],
      "year": "2025",
      "venue": "Teaching and Learning in Medicine"
    },
    {
      "citation_id": "10",
      "title": "Integrating open-and closed-ended questions on attitudes towards outgroups with different methods of text analysis",
      "authors": [
        "K Hansen",
        "A Świderska"
      ],
      "year": "2024",
      "venue": "Behavior research methods"
    },
    {
      "citation_id": "11",
      "title": "Automated classification for open-ended questions with BERT",
      "authors": [
        "H Gweon",
        "M Schonlau"
      ],
      "year": "2024",
      "venue": "Journal of Survey Statistics and Methodology"
    },
    {
      "citation_id": "12",
      "title": "Exploring the Impact of 'Emotion-Recognition-AI'on Consumer Trust and Satisfaction",
      "authors": [
        "A Vyas"
      ],
      "year": "2024",
      "venue": "Proceedings of the IEEE International Students' Conference on Electrical, Electronics and Computer Science"
    },
    {
      "citation_id": "13",
      "title": "Neural network-based face detection for emotion recognition in mental health monitoring",
      "authors": [
        "R Ajayi",
        "B Adedeji"
      ],
      "year": "2024",
      "venue": "Int J Res Publ Rev"
    },
    {
      "citation_id": "14",
      "title": "Speech emotion recognition for human-computer interaction",
      "authors": [
        "D Thiripurasundari",
        "K Bhangale",
        "V Aashritha",
        "S Mondreti",
        "M Kothandaraman"
      ],
      "year": "2024",
      "venue": "International Journal of Speech Technology"
    },
    {
      "citation_id": "15",
      "title": "An integrated approach to Bayesian weight regulations and multitasking learning methods for generating emotion-based content in the metaverse",
      "authors": [
        "W Park",
        "D Shin",
        "H Mutahira"
      ],
      "year": "2025",
      "venue": "Expert Systems with Applications"
    },
    {
      "citation_id": "16",
      "title": "Exploring sentiment analysis in handwritten and E-text documents using advanced machine learning techniques: a novel approach",
      "authors": [
        "R Ahamad",
        "K Mishra"
      ],
      "year": "2025",
      "venue": "Journal of Big Data"
    },
    {
      "citation_id": "17",
      "title": "Unveiling Emotions: NLP-Based Mood Classification and Well-Being Tracking for Enhanced Mental Health Awareness",
      "authors": [
        "A Mishra",
        "A Rai",
        "D Nandan",
        "U Kshirsagar",
        "M Singh"
      ],
      "year": "2025",
      "venue": "Mathematical Modelling of Engineering Problems"
    },
    {
      "citation_id": "18",
      "title": "Leveraging explainable artificial intelligence for emotional label prediction through health sensor monitoring",
      "authors": [
        "E Houssein",
        "S Mohsen",
        "M Emam",
        "N Abdel Samee",
        "R Alkanhel",
        "E Younis"
      ],
      "year": "2025",
      "venue": "Cluster Computing"
    },
    {
      "citation_id": "19",
      "title": "How do emotions affect decision making?",
      "authors": [
        "J Lerner",
        "C Dorison",
        "J Klusowski"
      ],
      "year": "2024",
      "venue": "Emotion theory: The Routledge comprehensive guide"
    },
    {
      "citation_id": "20",
      "title": "Machine learning techniques for emotion detection and sentiment analysis: current state, challenges, and future directions",
      "authors": [
        "A Alslaity",
        "R Orji"
      ],
      "year": "2024",
      "venue": "Behaviour & Information Technology"
    },
    {
      "citation_id": "21",
      "title": "Leveraging distant supervision and deep learning for Twitter sentiment and emotion classification",
      "authors": [
        "M Kastrati",
        "Z Kastrati",
        "A Shariq Imran",
        "M Biba"
      ],
      "year": "2024",
      "venue": "Journal of Intelligent Information Systems"
    },
    {
      "citation_id": "22",
      "title": "A review on sentiment analysis and emotion detection from text",
      "authors": [
        "P Nandwani",
        "R Verma"
      ],
      "year": "2021",
      "venue": "Social network analysis and mining"
    },
    {
      "citation_id": "23",
      "title": "Sentiment analysis using Support Vector Machine",
      "authors": [
        "N Zainuddin",
        "A Selamat"
      ],
      "year": "2014",
      "venue": "Proceedings of the International Conference on Computer, Communications, and Control Technology"
    },
    {
      "citation_id": "24",
      "title": "A characterbased convolutional neural network for language-agnostic Twitter sentiment analysis",
      "authors": [
        "J Wehrmann",
        "W Becker",
        "H Cagnini",
        "R Barros"
      ],
      "year": "2017",
      "venue": "Proceedings of the International Joint Conference on Neural Networks"
    },
    {
      "citation_id": "25",
      "title": "Sentiment Analysis Using Naive Bayes Algorithm Of The Data Crawler: Twitter",
      "authors": [
        "M Wongkar",
        "A Angdresey"
      ],
      "year": "2019",
      "venue": "Proceedings of the International Conference on Informatics and Computing"
    },
    {
      "citation_id": "26",
      "title": "An Ensemble Technique to Classify Multi-Class Textual Emotion",
      "authors": [
        "T Parvin",
        "M Hoque"
      ],
      "year": "2021",
      "venue": "Procedia Computer Science"
    },
    {
      "citation_id": "27",
      "title": "Emotion classification for short texts: an improved multi-label method",
      "authors": [
        "X Liu",
        "T Shi",
        "G Zhou",
        "M Liu",
        "Z Yin",
        "L Yin",
        "W Zheng"
      ],
      "year": "2023",
      "venue": "Humanities and Social Sciences Communications"
    },
    {
      "citation_id": "28",
      "title": "Automatic emotion recognition using deep neural network",
      "authors": [
        "R Sujatha",
        "J Chatterjee",
        "B Pathy",
        "Y.-C Hu"
      ],
      "year": "2025",
      "venue": "Multimedia Tools and Applications"
    },
    {
      "citation_id": "29",
      "title": "Speech emotion recognition via cnn-transformer and multidimensional attention mechanism",
      "authors": [
        "X Tang",
        "J Huang",
        "Y Lin",
        "T Dang",
        "J Cheng"
      ],
      "year": "2025",
      "venue": "Speech Communication"
    },
    {
      "citation_id": "30",
      "title": "Exploring Text-Generating Large Language Models (LLMs) for Emotion Recognition in Affective Intelligent Agents",
      "authors": [
        "A Pico",
        "E Vivancos",
        "A García-Fornes",
        "V Botti"
      ],
      "year": "2024",
      "venue": "Proceedings of the International Conference on Agents and Artificial Intelligence. Science and Technology Publications"
    },
    {
      "citation_id": "31",
      "title": "Lexicon-Based Methods for Sentiment Analysis",
      "authors": [
        "M Taboada",
        "J Brooke",
        "M Tofiloski",
        "K Voll",
        "M Stede"
      ],
      "year": "2011",
      "venue": "Computational Linguistics"
    },
    {
      "citation_id": "32",
      "title": "Advancements and Applications of Large Language Models in Natural Language Processing: A Comprehensive Review",
      "authors": [
        "M Ren"
      ],
      "year": "2024",
      "venue": "Applied and Computational Engineering"
    },
    {
      "citation_id": "33",
      "title": "Research on Compressed Input Sequences Based on Compiler Tokenization",
      "authors": [
        "Z Li",
        "X Lu"
      ],
      "year": "2025",
      "venue": "Information (Switzerland)"
    },
    {
      "citation_id": "34",
      "title": "A Low Power Attention and Softmax Accelerator for Large Language Models Inference",
      "authors": [
        "J.-H Kim",
        "C.-H Kim",
        "S.-M Rho",
        "K.-S Chung"
      ],
      "year": "2024",
      "venue": "Proceedings of the IEEE International Conference on Consumer Electronics-Asia"
    },
    {
      "citation_id": "35",
      "title": "EmoDet2: Emotion detection in English textual dialogue using BERT and BILSTM models",
      "authors": [
        "H Al-Omari",
        "M Abdullah",
        "S Shaikh"
      ],
      "year": "2020",
      "venue": "Proceedings of the International Conference on Information and Communication Systems"
    },
    {
      "citation_id": "36",
      "title": "The Biases of Pre-Trained Language Models: An Empirical Study on Prompt-Based Sentiment Analysis and Emotion Detection",
      "authors": [
        "R Mao",
        "Q Liu",
        "K He",
        "W Li",
        "E Cambria"
      ],
      "year": "2023",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "37",
      "title": "A survey on deep learning for textual emotion analysis in social networks",
      "authors": [
        "S Peng",
        "L Cao",
        "Y Zhou",
        "Z Ouyang",
        "A Yang",
        "X Li",
        "W Jia",
        "S Yu"
      ],
      "year": "2022",
      "venue": "Digital Communications and Networks"
    },
    {
      "citation_id": "38",
      "title": "Bias in Emotion Recognition with ChatGPT",
      "authors": [
        "N Wake",
        "A Kanehira",
        "K Sasabuchi",
        "J Takamatsu",
        "K Ikeuchi"
      ],
      "year": "2023",
      "venue": "Bias in Emotion Recognition with ChatGPT"
    },
    {
      "citation_id": "39",
      "title": "Emotion-LLaMA: Multimodal Emotion Recognition and Reasoning with Instruction Tuning",
      "authors": [
        "Z Cheng",
        "Z.-Q Cheng",
        "J.-Y He",
        "J Sun",
        "K Wang",
        "Y Lin",
        "Z Lian",
        "X Peng",
        "A Hauptmann"
      ],
      "year": "2024",
      "venue": "Emotion-LLaMA: Multimodal Emotion Recognition and Reasoning with Instruction Tuning"
    },
    {
      "citation_id": "40",
      "title": "Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing",
      "authors": [
        "Z Ma",
        "W Wu",
        "Z Zheng",
        "Y Guo",
        "Q Chen",
        "S Zhang",
        "X Chen"
      ],
      "year": "2024",
      "venue": "Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing"
    },
    {
      "citation_id": "41",
      "title": "Customising General Large Language Models for Specialised Emotion Recognition Tasks",
      "authors": [
        "L Peng",
        "Z Zhang",
        "T Pang",
        "J Han",
        "H Zhao",
        "H Chen",
        "B Schuller"
      ],
      "year": "2024",
      "venue": "Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing"
    },
    {
      "citation_id": "42",
      "title": "InstructERC: Reforming Emotion Recognition in Conversation with a Retrieval Multi-task LLMs Framework",
      "authors": [
        "S Lei",
        "G Dong",
        "X Wang",
        "K Wang",
        "S Wang"
      ],
      "year": "2024",
      "venue": "InstructERC: Reforming Emotion Recognition in Conversation with a Retrieval Multi-task LLMs Framework"
    },
    {
      "citation_id": "43",
      "title": "BITS Pilani at SemEval-2024 Task 10: Fine-tuning BERT and Llama 2 for Emotion Recognition in Conversation",
      "authors": [
        "D Venkatesh",
        "P Prasanjith",
        "Y Sharma"
      ],
      "year": "2024",
      "venue": "Proceedings of the International Workshop on Semantic Evaluation"
    },
    {
      "citation_id": "44",
      "title": "DialogueLLM: Context and emotion knowledge-tuned large language models for emotion recognition in conversations",
      "authors": [
        "Y Zhang",
        "M Wang",
        "Y Wu",
        "P Tiwari",
        "Q Li",
        "B Wang",
        "J Qin"
      ],
      "year": "2025",
      "venue": "Neural Networks"
    },
    {
      "citation_id": "45",
      "title": "AER-LLM: Ambiguity-aware emotion recognition leveraging large language models",
      "authors": [
        "X Hong",
        "Y Gong",
        "V Sethu",
        "T Dang"
      ],
      "year": "2025",
      "venue": "Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing"
    },
    {
      "citation_id": "46",
      "title": "Low-resource MobileBERT for emotion recognition in imbalanced text datasets mitigating challenges with limited resources",
      "authors": [
        "M Hussain",
        "C Chen",
        "S Albouq",
        "K Shinan",
        "F Alanazi",
        "M Iqbal",
        "M Ashraf"
      ],
      "year": "2025",
      "venue": "PloS one"
    },
    {
      "citation_id": "47",
      "title": "HyFusER: Hybrid Multimodal Transformer for Emotion Recognition Using Dual Cross Modal Attention",
      "authors": [
        "M.-H Yi",
        "K.-C Kwak",
        "J.-H Shin"
      ],
      "year": "2025",
      "venue": "Applied Sciences"
    },
    {
      "citation_id": "48",
      "title": "LaERC-S: Improving LLM-based Emotion Recognition in Conversation with Speaker Characteristics",
      "authors": [
        "Y Fu",
        "J Wu",
        "Z Wang",
        "M Zhang",
        "L Shan",
        "Y Wu",
        "B Liu"
      ],
      "year": "2025",
      "venue": "Proceedings of the International Conference on Computational Linguistics. Association for Computational Linguistics"
    },
    {
      "citation_id": "49",
      "title": "Toward zero-shot speech emotion recognition using LLMs in the absence of target data",
      "authors": [
        "S Bo-Hao",
        "S Upadhyay",
        "L Chi-Chun"
      ],
      "year": "2025",
      "venue": "Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing"
    },
    {
      "citation_id": "50",
      "title": "Do LLMs Exhibit Human-Like Reasoning? Evaluating Theory of Mind in LLMs for Open-Ended Responses",
      "authors": [
        "M Amirizaniani",
        "E Martin",
        "M Sivachenko",
        "A Mashhadi",
        "C Shah"
      ],
      "year": "2024",
      "venue": "Do LLMs Exhibit Human-Like Reasoning? Evaluating Theory of Mind in LLMs for Open-Ended Responses"
    },
    {
      "citation_id": "51",
      "title": "Emotional Evaluation of Open-Ended Responses with Transformer Models",
      "authors": [
        "A Pajón-Sanmartín",
        "F De Arriba-Pérez",
        "S García-Méndez",
        "J Burguillo",
        "F Leal",
        "B Malheiro"
      ],
      "year": "2024",
      "venue": "Proceedings of the World Conference on Information Systems and Technologies"
    },
    {
      "citation_id": "52",
      "title": "Emotion-Aware RoBERTa enhanced with emotion-specific attention and TF-IDF gating for fine-grained emotion recognition",
      "authors": [
        "F Alqarni",
        "A Sagheer",
        "A Alabbad",
        "H Hamdoun"
      ],
      "year": "2025",
      "venue": "Scientific Reports"
    },
    {
      "citation_id": "53",
      "title": "He is currently a researcher in the Information Technologies Group at the University of Vigo, Spain. His research encompasses the development of Machine Learning solutions for various domains",
      "venue": "His research interests include Natural Language Processing techniques and Large Language Models. FRANCISCO DE ARRIBA-PÉREZ received a B.S. degree in telecommunication technologies engineering in 2013, an M.S. degree in telecommunication engineering in 2014, and a Ph.D. in 2019 from the University of Vigo"
    },
    {
      "citation_id": "54",
      "title": "FÁTIMA LEAL holds a Ph.D. in Information and Communication Technologies from the University of Vigo, Spain. She is an Auxiliary Professor at Universidade Portucalense in Porto, Portugal, and a researcher at REMIT (Research on Economics, Management, and Information Technologies)",
      "authors": [
        "D Silvia García-Méndez Received A Ph"
      ],
      "venue": "She holds a Ph.D., M.Sc., and a fiveyear degree in Electrical Engineering and Computers from the University of Porto. Her research interests include Artificial Intelligence, Computer Science, and Engineering Education. She is a member of the Association for the Advancement of Artificial Intelligence (AAAI), the Portuguese Association for Artificial Intelligence (APPIA), the Association for Computing Machinery (ACM), and the Professional Association of Portuguese Engineers (OE). JUAN CARLOS BURGUILLO-RIAL received an M.Sc. in Telecommunication Engineering and a Ph.D. in Telematics at the University of Vigo"
    }
  ]
}