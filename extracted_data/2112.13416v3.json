{
  "paper_id": "2112.13416v3",
  "title": "Attribute Inference Attack Of Speech Emotion Recognition On Federated Learning",
  "published": "2021-12-26T16:50:42Z",
  "authors": [
    "Tiantian Feng",
    "Hanieh Hashemi",
    "Rajat Hebbar",
    "Murali Annavaram",
    "Shrikanth S. Narayanan"
  ],
  "keywords": [
    "Speech Emotion Recognition",
    "Federated Learning",
    "Adversarial",
    "Machine Learning",
    "Privacy"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "SER systems often acquire and transmit speech data collected at the client-side to remote cloud platforms for further processing. However, speech data carry rich information about emotions and other sensitive demographic traits like gender and age. Given the increasing emphasis on privacy considerations, it is desirable for SER systems to classify emotion constructs while preventing inferences of other sensitive information embedded in the speech signal. Federated learning (FL) is a distributed machine learning algorithm that coordinates clients to train a model collaboratively without sharing local data. While FL improves privacy by preventing direct sharing of client's data, recent works have demonstrated that FL is still vulnerable to many privacy attacks. To assess the information leakage of SER systems trained using FL, we propose an attribute inference attack framework that infers sensitive attribute information of the clients from shared model updates. As a use case, we empirically evaluate our approach for predicting the client's gender using three SER benchmark datasets: IEMOCAP, CREMA-D, and MSP-Improv. We show that the attribute inference attack is achievable for SER systems trained using FL. We perform further analysis and make observations such as the most information leakage comes from the first layer in the SER model.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "S PEECH emotion recognition (SER) aims to identify emotional states conveyed in vocal expressions. Speech emotion recognition systems are currently deployed in a wide range of applications such as in smart virtual assistants  [1] , clinical diagnoses  [2] ,  [3] , and education  [4] . A typical centralized SER system has three parts: data acquisition, data transfer, and emotion classification  [5] . Under this framework, the client typically shares the raw speech samples or the acoustic features derived from the speech samples (to obfuscate the actual content of the conversation) to the remote cloud servers for emotion recognition. However, the same speech signal carries rich information about individual traits (e.g., age, gender) and states (e.g., health status), many of which can be deemed sensitive from an application point of view. Attribute inference attacks would aim to reveal an individual's sensitive attributes (e.g., age and gender) that they did not intend or expect to share  [6] ,  [7] . These undesired/unauthorized usages of data may occur when the service provider is not trustworthy (insider attack) or an intruder attacks the cloud system (outsider attack)  [8] ,  [9] ,  [10] .\n\nFederated learning (FL) is a popular privacy-preserving distributed learning approach that allows clients to train a model collaboratively without sharing their local data  [11] . In an FL setting, during the training process, a central server aggregates model updates from multiple clients. Each client generates such model updates by locally training a model on the private data available at the client. This machine learning approach reduces information leaks compared to classical centralized machine learning frameworks since personal data does not leave the client.\n\n• Tiantian Feng is with the Department of Computer Science, USC, Los Angeles, CA, 90007. Hanieh Hashemi, Rajat Hebbar, Murali Annavaram, and Shrikanth S. Narayanan are with the Department of Electrical Engineering, USC, Los Angeles, CA, 90007. email: tiantiaf@usc.edu.\n\nTherefore, this distributed learning paradigm can be a natural choice for developing real-world multiuser SER applications as sharing raw speech or speech features from users' devices is vulnerable to attribute inference attacks. Attacks in Federated Learning: Arguably, while sharing model updates can be considered more privacy preserving than sharing raw data, recent works have demonstrated that FL can be susceptible to a variety of privacy attacks, including membership inference attacks  [12]  and reconstruction attacks  [13] ,  [14] . For instance, recent work has shown that the attacker can efficiently reconstruct a training image from the gradients  [13] . More recent works increasingly show that image reconstruction is also achievable through the model parameter updates even without accessing to the raw gradients  [14] . On the other hand, prior work has demonstrated that the attacker can perform membership attacks in FL settings to infer whether a particular model update belongs to the private training data of a single participant (if the update is of a single participant) or of several participants (if the update is the aggregate)  [12] . While existing research has demonstrated the vulnerability of FL training to privacy attacks in the CV domain, it is reasonable to believe that the shared model updates in training the SER model using the FL technique also introduce information leakage.\n\nThreat Model: This work presents a detailed analysis of the attribute inference attack on the SER application trained in an FL setting. In general there are two sub-types of attacks based on what attacker can observe. In the black-box attack, the attacker can only observe the outputs of the model (F(x; W)) for any given input  [15] . However, in the white-box attack, attacker can access the model parameters, intermediate values, and other model information as well  [16] . In this work, we support white-box attack in which the attacker knows all model parameters and hyperparameters in the FL process, including learning rate, local epochs, local batch size, local sample size, and model architecture. The white-box attack is a realistic scenario in this setting because this information can be available to the attacker from any participating client or if the attacker operate as client itself. Any adversary that has access to the shared model updates can execute the attack. The attacker's goal is to infer sensitive attributes of the client using shared model updates (parameters/gradients) of SER applications trained under FL architecture. In this work, we consider gender prediction as the exemplary attribute inference attack task. We show that the adversary can effectively infer a client's gender attribute while training the SER model in an FL setup; we use the IEMOCAP  [17] , Crema-D  [18] , and MSP-Improv  [19]  datasets for the experiments. To the best of our knowledge, this is the first work to demonstrate that shared model updates that are communicated in FL to train an SER model can cause attribute information leakage (e.g., gender).",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Ser Experimental Data Sets",
      "text": "In this work, we use three data sets for developing SER models and threat models. Due to the data imbalance issue in the IEMOCAP corpus, previous works use the four most frequently occurring emotion labels (neutral, sad, happiness, and anger) for training the SER model  [20] . In addition to this, we pick these four emotion classes because all three corpora contain these labels. Table  1  shows the label distribution of utterances in these corpora. The details of these corpora are provided below:",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Iemocap",
      "text": "The IEMOCAP database  [17]  was collected using multi-modal sensors that capture motion, audio, and video of acted human interactions. The corpus contains 10,039 utterances from ten subjects (five male and five female) who target expressing categorical emotions. In addition, the utterances are divided into improvised and scripted conditions where the speakers use utterances from a fixed script in the latter case. In this work, follow the suggestion from  [20]  and focus on the improvised sessions.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Crema-D",
      "text": "The CREMA-D  [18]  corpus is a multi-modal database of emotional speech collected from 91 actors, 48 of whom are male, and 43 are female. The set contains 7,442 speech recordings that simulate emotional expressions, including happy, sad, anger, fear, and neutral.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Msp-Improv",
      "text": "The MSP-Improv  [19]  corpus was created to study naturalistic emotions captured from improvised scenarios. The corpus includes audio and visual data of utterances spoken in natural condition (2,785 utterances), target condition (652 target utterances in an improvised scenario), improvised condition (4,381 utterances from the remainder of the improvised scenarios), and read speech condition (620 utterances). The data is collected from 12 participants (six male and six female). Similar to the IEMOCAP data set, we use the data only from the improvised conditions.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Problem Setup",
      "text": "In this section, we describe preliminaries and the problem setup of the attack framework. To improve readability, we summarize the notations adopted in this paper in Table  2 .\n\nFedAvg In the FedAvg algorithm, each client locally takes several epochs of model updates using its entire training data set D k and obtains a local model with parameters θ t k . Each client then submits the resulting model to the server, which calculates a weighted average shown below:",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Problem Definition",
      "text": "Fig.  2  shows the attack problem setup we investigate in this work. In this study, the primary task is SER, models for which are trained using the FL framework, while in the Adversarial task the attacker attempts to predict the client's gender label. We follow a setup in which we have a private-labeled data set D p from a number of clients, where each client has a feature set X and an emotion label set y. We also assume a gender label z associated with each client. This work focuses on the white-box attack, where the attacker knows the model architecture and hyper-parameters like batch size, local epochs, and learning rate. We also assume that the attacker does not have access to the private training data. However, the adversary can access public data-sets with a similar data format to D p . Similar to the attacking framework proposed in  [14] , we define two attack scenarios based on two FL algorithms: FedSGD and FedAvg.\n\nFedSGD In the FedSGD framework, we assume that the attacker has access to shared gradients g t k from the k th client in the t th global training epoch but not the private speech data X k . The attacker attempts to predict the sensitive attribute z k (e.g. gender label) of the k-th client using g t k . FedAvg In the FedAvg framework, the attacker has access to the global model parameter θ t and shared model parameters θ t k from k-th client at the t-th global training round but not the private speech data X k . The attacker's goal is to infer the sensitive attribute z k (e.g. gender label) of the k-th client using θ t and θ t k .",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Attacking Formulation",
      "text": "In this section, we describe our proposed method for attribute inference attack in detail.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Private Training",
      "text": "We  assume that the attacker cannot access the private training data. However, the shared training updates (either the gradients or the model parameters) are insecure, where the attacker can obtain this information.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Shadow Training",
      "text": "The shadow training is first proposed in the membership inference attack  [15] . In this paper, we use a similar attack framework to construct our attribute inference attack. Specifically, the shadow models M s\n\nFedAvg Herein, only the global model parameters θ t and the updated model parameters θ t k from the k-th client are accessible by the attacker but not the raw gradients. Thus, we derive a pseudo gradient that is similar to previous work in  [14]  as the attack model's input data. Specifically, we assume that the global model undergoes T times of local updates at the k-th client, where T is the product between the local training epoch and the number of mini-batches within a local training epoch. Thus, we can define the following with the pseudo gradients g t k and the learning rate η:\n\nEventually, we can define the pseudo gradients g t k as:\n\nGiven this, we aim to train the attack model with parameters ψ to minimize the following cross entropy loss function: Our attack model is similar to the membership inference attack model architecture in  [16] . The attack model consists of CNN feature extractors and classifiers as shown in Fig.  4 . ∇W i and ∇b i represent the weight updates and the bias updates in g corresponding to the i th layer, respectively. Each layer's weight updates (generated from the FL training) is first fed into a threelayer CNN feature extractor to compute the hidden representation. We then flatten the output from the CNN feature extractor and concatenate it with the layer's bias updates. We then pass this combined representation to the MLP classifier to predict gender. We use a fusion layer to combine the predictions from the individual layer classifiers; the fusion method used in this work is a weighted average function. We determine the importance of each layer's gender prediction output based on the size of the shared updates. Finally, we evaluate the performance of the attack model using the shared model updates generated in the private FL setting where the attack model's goal is to infer the gender labels of clients in the private training data set.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Experiments",
      "text": "In this section, we describe our experimental setup including data processing, data setup, and training details. The implementation of this paper is at https://github.com/usc-sail/fed-ser-leakage.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Data Preprocessing",
      "text": "To investigate the effectiveness of the proposed attack framework, we train our SER models on a variety of speech representations. We first generate the Emo-Base feature set using the OpenSMILE toolkit  [23]  for each utterance. In addition to the knowledge-based speech feature set, we propose to evaluate our framework on SU-PERB (Speech Processing Universal PERformance Benchmark)  [24] , which is designed to provide a standard and comprehensive testbed for pre-trained models on various downstream speech tasks. We compute the deep speech representations from the pretrained models that are available in SUPERB including APC  [25] , Vq-APC  [26] , Tera  [27] , NPC  [28] , and DeCoAR 2.0  [29] . We further compute the global average of the last layer's hidden state as the final feature from the pre-trained model's output. Using the last hidden state is suggested in prior works for downstream tasks  [25] ,  [28] ,  [29] ,  [30] . Our feature sizes are 988 in Emo-Base; 512 in APC, Vq-APC, and NPC; 768 in Tera and DeCoAR 2.0.\n\nWe apply z-normalization to the speech features within each speaker. Since there are only 10 speakers in the IEMOCAP data set and 12 speakers in the MSP-Improv data set, we further divide each speaker's data in these two data sets into 10 parts of equal size. This mimics a scenario where a single person owns multiple clients and their data is distributed across them (e.g. a person can own cell phones, tables and computer devices across wich their data is distributed). This division is to create more clients for the FL training. Each divided speaker data is the local training data on a client. In the CREMA-D data set, each speaker is a unique client in the FL training as there are 91 unique speakers in the dataset. We leave 20% of speakers as the test data. Then, we repeat the experiments 5 times with test folds of different speakers. Finally, we report the average results of the 5-fold experiments.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Data Setup",
      "text": "We simulate the experiments using different private training data sets. For instance, in the case of the IEMOCAP data set being the private training data set D p , the MSP-Improv data set We also run the experiment on each speech representation.",
      "page_start": 5,
      "page_end": 6
    },
    {
      "section_name": "Model And Training Details",
      "text": "In",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Evaluation Metrics",
      "text": "Speech Emotion Recognition We use the Unweighted Average Recall (UAR) score to evaluate predictions in SER models. Attacker Task Inspired by  [31] ,  [32] , and  [33] , we define the attack success rate (ASR) to measure the attacker performance. Specifically, given a client in FL training setup, we randomly select a gradient update from the whole training process, and make a prediction. We repeat this process 10 times for each client, and report the percentage of correct predictions as the attack success rate. We average the attack success rate from all clients as the final performance of the attacker. More formally, the ASR over K clients is defined as:",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Results",
      "text": "In this section, we present SER results on different private data sets. We also show results of the attack model in predicting gender labels of the clients in the private data set.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Speech Emotion Recognition Using Fl",
      "text": "The emotion prediction results of FL training on different private training data sets are shown in Table  3 . We report the SER prediction results in accuracy (Acc) scores and unweighted average recall (UAR) scores. We observe that the knowledge-based feature set, Emo-Base, performs comparably in the SER task to prior works  [34] ,  [35]  that use spectrograms or MFCCs. In addition, we can observe that the deep speech representation, DeCoAR 2.0, yields the best UAR scores in prediction emotions when the private training data sets are CREMA-D (FedSGD: 73.69%; FedAvg: 71.64%) and IEMOCAP (FedSGD: 65.18%; FedAvg: 64.21%). TERA feature set produces the best UAR scores when the private training data is MSP-Improv (FedSGD: 52.60%). Our results show that the SER task performs better when the training data sets are IEMOCAP and CREMA-D. In summary, these results suggest that our SER models, trained within a FL architecture, produce reasonable predictions for the SER task. Speech features: We observe that this attribute inference attack is possible regardless of the speech representation (UAR scores are all above 70%) used for the SER task. It is also interesting to note that the attack model yields the best overall performance in predicting gender labels when the deep speech representations, such as APC and Tera, are the input data to the SER task but not the knowledge-based feature set, Emo-Base. Noticeably, these deep speech representations also provide the best overall emotion prediction performance as shown in Table  3 . Typically, deep speech representations are more generalized feature embeddings for downstream speech applications. Besides the knowledge-based speech feature set, Tera and APC, we find that other deep speech representations can also generate shared model updates in the FL, which can leak significant attribute information about the client.",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "Attribute Inference Attack",
      "text": "",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Fedsgd And Fedavg:",
      "text": "We find that this attribute information leakage exists in both these FL learning algorithms. Increasingly, we discover that the attack model has higher chances to predict the client's gender information when we train the private SER model using the FedSGD algorithm. One reason behind this is the model updates in FedAvg create averaged model differences for the inference attack, This observation is consistent with the results of data reconstruction attacks reported in  [14] .\n\nData Set: In general, we find that this attribute inference attack is possible with all data set combinations used in this work. However, the attack model appears to have slightly better gender prediction performance when the private training data sets are either the IEMOCAP or the MSP-Improv. This is probably because the CREMA-D data set consists of more unique speakers, creating more diverse FL training updates.\n\nSummary: The experimental results above demonstrate that our proposed attack framework is robust to infer gender information of the clients involved in the FL without accessing the client's private speech feature data but the shared model updates (raw gradients or pseudo gradients). Consequently, even though the speech feature samples are not accessible by the attacker in FL when training the global SER model, the attribute information about a client can leak through the model updates.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Mitigation Possibilities",
      "text": "There are protection schemes such as cryptography solutions  [36] ,  [37]  and the use of trusted execution environments  [38] ,  [39]  for secure aggregation. However, cryptography solutions have a significant performance overhead and they are not scalable to systems with many edge devices. Trusted Execution Environments such as Intel SGX  [40]  provide private environments for data privacy and computational integrity. However, they are not available on all the data centers. In this section, we present an analysis of potential factors related to the attribute information leakage in the FL of the SER model. We aim to investigate a few mitigation strategies based on these possible information leakage factors. Note that all of these proposed mitigation strategies are softwarebased solutions with low performance overhead. These methods do not need any special system support.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Fedsgd And Fedavg",
      "text": "As we observe from the Table  4 , the attack model performs better when we train the SER model using the FedSGD algorithm. Thus, a straightforward defense is to train the global SER model using the FedAvg algorithm. An additional benefit of using the FedAvg is that it significantly reduces the communication overhead during training. The client can transfer the shared model updates after T times of local training instead of each local mini-batch. The primary reason of why the attack model performs worse in the FedAvg scenario is that the averaged model differences contain less information about the training samples than the raw gradients as shown in  [14] .",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "The Layer Position Of Shared Model Updates",
      "text": "As suggested in the previous works  [41] ,  [42] , most information leakage is related to the early layers in a machine learning model. To evaluate this in our attack scenario, we measure the gender prediction performance of the individual classifier without fusion. Table  5  shows the gender prediction performance by using the shared model updates from different layers in the SER model.\n\nFrom Table  5 , we can observe that the attack model can consistently predict the client's gender label using only the shared model updates between the feature input and first dense layer (∇W 1 and ∇b 1 ) of the classifier model. However, the gender prediction performance decreases significantly when using the shared model updates between the first to second dense layer (∇W 2 and ∇b 2 ) or between the second to the output layer (∇W 3 and ∇b 3 ) of the model. The attack success rate is in the range of 50% -75% using ∇W 2 and ∇b 2 in most of the experiment setups following the FedSGD, and this performance is around 55% -65% when using input ∇W 3 and ∇b 3 . When training the SER model using the FedAvg, the attacks are much weaker using ∇W 2 + ∇b 2 or ∇W 3 + ∇b 3 . Thus, we can conclude that the earlier layer's shared updates leak more information about the client's gender attribute when training the SER model using FL.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Dropout",
      "text": "Another possible defense is to employ higher dropout  [43] , a popular regularization technique used to mitigate overfitting in neural networks. Dropout randomly deactivates activations between neurons, with a probability between 0 and 1. Random deactivations may weaken the attack model because the adversary observes fewer gradients corresponding to the active neurons. We evaluate this assumption by increasing the dropout value to 0.4 and 0.6 after the first dense layer of the MLP classifier. We only increase the dropout rate associated with the first dense layer, since we have shown that this attribute information leakage comes mostly from ∇W 1 and ∇b 1 . Table  6  shows the UAR scores of the SER task and the inference attack task using the shared model updates, for different dropout values. Increasing dropout value can remove features that is relevant for our primary application, thus decreasing the performance of the SER task. However, our attacks become stronger with increased randomness of dropout applied to the SER model, which is similar to the results shown in  [12] . Our assumption is that there are many shared features which are both informative of emotion and gender. Therefore, removing non-important features for the SER task also eliminates irrelevant features for the gender prediction, while the remaining features are more informative about the gender information.\n\nThe parameter ε > 0 defines the privacy guarantee that the DP provides, and a smaller ε indicates a stronger privacy guarantee. δ ∈ [0, 1) indicates the probability that the privacy leaks can occur under the privacy guarantee ε  [44] . In our recent work  [31] , we have explored using the User-level Differential Privacy (UDP) algorithm to mitigate the attribute inference attack in the FedAvg setup. We extend our prior work to mitigate the attribute inference attack in the FedSGD setting in this work. Specifically, we implement the FedSGD-DP algorithm that has been described in  [45] . We experiment with ε ∈ {1, 5, 10, 100, 1000} and δ = 0.1. The norm clipping threshold is set to 1.5. We evaluate the attacker performance using the first layer's model gradients that are similar to our prior work  [31] . Fig.  5  shows the performance of SER model (left column) and the attacker task (right column) under different ε. ε = ∞ indicates the case where there is no mitigation in the training process. SER Performance: From the SER predictions, we find that SER performance drops by 1-2% on IEMOCAP and MSP-Improv dataset when ε = 1000 or ε = 100. This decrease in SER performance is around 4-5% on CREMA-D dataset. We also observe that SER performance starts to drop substantially when ε ≤ 10.\n\nAttacker Performance: On the other hand, we observe that attacker performance decreases significantly even when ε is at 1000. Similar to SER prediction results, the attacker is unable to perform the privacy attacks when ε ≤ 10.\n\nAttacker Performance with access to multiple updates: In the above mitigation, we explore the DP mitigation when the attacker has access to only one round of model updates. However, in our prior work  [31] , we have shown that the attacker can regain the ability to infer gender through aggregating multiple rounds of training updates with a weaker privacy guarantee. Similarly, we explore the ASR where the attacker can access multiple rounds of model updates in Fig.  6 . We can find that the attacker can indeed regain the ability to infer gender with access to multiple rounds of training updates at a weaker privacy guarantee (ε = 1000). However, the attacker fails to infer gender when the privacy guarantee is strong. This validates that DP can effectively mitigate the proposed attribute inference attack when the attacker can only access one round of training updates. The DP mitigation becomes less effective with multiple rounds of training updates leaked to the attacker, where the attacker is able to perform the privacy attack under a weaker privacy guarantee. On the other hand, we notice that the performance drop in the SER application becomes substantial when ε ≤ 10. These observations imply that DP can provide satisfied privacy protection against our proposed privacy attacks but with a noticeable drop in SER performance.",
      "page_start": 8,
      "page_end": 10
    },
    {
      "section_name": "Conclusion",
      "text": "In this paper, we investigated attribute inference attacks on speech emotion recognition models trained within federated learning scenarios of shared gradient (FedSGD) and shared model (Fe-dAvg). Our results show that unintended, and potentially private, properties (like gender) associated with the clients in the FL can leak through the shared updates when training the SER model. The deep models appear to internally capture many uncorrelated features with the tasks they are being trained for. Consequently, the attribute inference attacks are potentially powerful in this setting because the shared training updates carry significant potentially sensitive information about a (training) client. Our results suggest that the attacks are stronger in training the global SER model using the FedSGD algorithm than the FedAvg algorithm. We also show that the shared updates between the input and first dense layer leaks most information in this attribute inference attack. We further empirically demonstrate that defense strategies like dropout are not effective in mitigating this information leakage. We then show that Differential Privacy (DP) can mitigate this privacy attack with a stronger privacy budget by sacrificing the utility of the SER model.\n\nThese results motivate future work on defenses using the adversarial training technique to unlearn the sensitive attribute. Some of the limitations of our study include the relatively small number of clients and data sets even by combining three widely used SER test-beds. In addition, our work considers that attacker has access to each client's model updates, but this can be mitigated by aggregating shared updates from several clients in a local aggregator before transferring them to the central aggregator. In the future, we aim to build our SER model using more complex model structures, e.g., RNN+classifer. We also wish to apply the defense mechanism, such as adversarial training shown in  [46] , to train the SER model in the FL setup. Meanwhile, the current attack model utilizes only two public SER data sets, and we aim to include more public data sets to further increase the attacker's performance. Finally, we wish to evaluate the membership inference attack  [33]  and label inference attack  [32]  within similar experimental settings.",
      "page_start": 10,
      "page_end": 11
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: , a subset of selected clients receive a global",
      "page": 2
    },
    {
      "caption": "Figure 1: The ﬁgure shows the training process of a global round in Federated Learning. The server shares a global model with several clients to",
      "page": 3
    },
    {
      "caption": "Figure 2: The ﬁgure shows the problem setup of the attribute inference",
      "page": 3
    },
    {
      "caption": "Figure 2: shows the attack problem setup we investigate in this work.",
      "page": 3
    },
    {
      "caption": "Figure 3: In each subsequent subsection, we",
      "page": 3
    },
    {
      "caption": "Figure 3: The framework of our proposed attack. We form m shadow training data sets and train m shadow models that mimics the private FL training",
      "page": 4
    },
    {
      "caption": "Figure 4: The architecture of our proposed attack model. The model updates (raw gradients in FedSGD; pseudo gradients in FedAvg) are the input",
      "page": 5
    },
    {
      "caption": "Figure 5: The ﬁgure shows the prediction results of the SER task and the attribute inference task at different privacy levels (ε ∈{1,5,10,100,1000}). A",
      "page": 9
    },
    {
      "caption": "Figure 5: shows the performance of SER",
      "page": 9
    },
    {
      "caption": "Figure 6: We can ﬁnd that the attacker can indeed",
      "page": 9
    },
    {
      "caption": "Figure 6: The ﬁgure shows the attribute inference task at different privacy levels (ε ∈{1,10,100,1000}) and with different numbers of leaked model",
      "page": 10
    }
  ],
  "tables": [
    {
      "caption": "Table 1: shows the label distribution of utterances in these corpora. The",
      "page": 2
    },
    {
      "caption": "Table 1: Statistics of emotion labels in three different SER data sets.",
      "page": 2
    },
    {
      "caption": "Table 2: Notation used in this paper.",
      "page": 2
    },
    {
      "caption": "Table 3: Prediction results of the SER model trained under the FedSGD and FedAvg FL scenarios. The accuracy and unweighted average recall (UAR)",
      "page": 6
    },
    {
      "caption": "Table 4: Prediction results of the attribute inference attack model. The attack",
      "page": 6
    },
    {
      "caption": "Table 3: We report the SER pre-",
      "page": 6
    },
    {
      "caption": "Table 5: Prediction results of the attribute inference attack model using shared updates between different layers in the SER model. The attack success rate",
      "page": 7
    },
    {
      "caption": "Table 4: summarizes the performance of the proposed attack model.",
      "page": 7
    },
    {
      "caption": "Table 3: Typically, deep",
      "page": 7
    },
    {
      "caption": "Table 6: Prediction results of the attribute attacker model and SER model using different dropout probability. The unweighted average recall (UAR) scores",
      "page": 8
    },
    {
      "caption": "Table 4: , the attack model performs better",
      "page": 8
    },
    {
      "caption": "Table 5: shows the gender prediction performance by using the",
      "page": 8
    },
    {
      "caption": "Table 5: , we can observe that the attack model can consis-",
      "page": 8
    },
    {
      "caption": "Table 6: shows the UAR scores of the",
      "page": 8
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Study on emotion recognition and companion chatbot using deep neural network",
      "authors": [
        "M.-C Lee",
        "S.-Y Chiang",
        "S.-C Yeh",
        "T.-F Wen"
      ],
      "year": "2020",
      "venue": "Multimedia Tools and Applications"
    },
    {
      "citation_id": "2",
      "title": "Speech emotion recognition approaches in human computer interaction",
      "authors": [
        "S Ramakrishnan",
        "I Emary"
      ],
      "year": "2013",
      "venue": "Telecommunication Systems"
    },
    {
      "citation_id": "3",
      "title": "Signal processing and machine learning for mental health research and clinical applications",
      "authors": [
        "D Bone",
        "C.-C Lee",
        "T Chaspari",
        "J Gibson",
        "S Narayanan"
      ],
      "year": "2017",
      "venue": "IEEE Signal Processing Magazine"
    },
    {
      "citation_id": "4",
      "title": "Speech emotion recognition in e-learning system based on affective computing",
      "authors": [
        "W Li",
        "Y Zhang",
        "Y Fu"
      ],
      "year": "2007",
      "venue": "Third International Conference on Natural Computation (ICNC 2007)"
    },
    {
      "citation_id": "5",
      "title": "Emotion recognition from speech: a review",
      "authors": [
        "S Koolagudi",
        "K Rao"
      ],
      "year": "2012",
      "venue": "International journal of speech technology"
    },
    {
      "citation_id": "6",
      "title": "Attribute inference attacks in online social networks",
      "authors": [
        "N Gong",
        "B Liu"
      ],
      "year": "2018",
      "venue": "ACM Transactions on Privacy and Security (TOPS)"
    },
    {
      "citation_id": "7",
      "title": "Privacy in deep learning: A survey",
      "authors": [
        "F Mireshghallah",
        "M Taram",
        "P Vepakomma",
        "A Singh",
        "R Raskar",
        "H Esmaeilzadeh"
      ],
      "year": "2020",
      "venue": "Privacy in deep learning: A survey",
      "arxiv": "arXiv:2004.12254"
    },
    {
      "citation_id": "8",
      "title": "Privacy-preserving cloud computing on sensitive data: A survey of methods, products and challenges",
      "authors": [
        "J Domingo-Ferrer",
        "O Farras",
        "J Ribes-González",
        "D Sánchez"
      ],
      "year": "2019",
      "venue": "Computer Communications"
    },
    {
      "citation_id": "9",
      "title": "Exploring data security issues and solutions in cloud computing",
      "authors": [
        "P Kumar",
        "P Raj",
        "P Jelciana"
      ],
      "year": "2018",
      "venue": "Procedia Computer Science"
    },
    {
      "citation_id": "10",
      "title": "A survey on security challenges in cloud computing: issues, threats, and solutions",
      "authors": [
        "H Tabrizchi",
        "M Rafsanjani"
      ],
      "year": "2020",
      "venue": "The journal of supercomputing"
    },
    {
      "citation_id": "11",
      "title": "Communication-efficient learning of deep networks from decentralized data",
      "authors": [
        "B Mcmahan",
        "E Moore",
        "D Ramage",
        "S Hampson",
        "B Arcas"
      ],
      "year": "2017",
      "venue": "Artificial intelligence and statistics"
    },
    {
      "citation_id": "12",
      "title": "Exploiting unintended feature leakage in collaborative learning",
      "authors": [
        "L Melis",
        "C Song",
        "E Cristofaro",
        "V Shmatikov"
      ],
      "year": "2019",
      "venue": "2019 IEEE Symposium on Security and Privacy (SP)"
    },
    {
      "citation_id": "13",
      "title": "Deep leakage from gradients",
      "authors": [
        "L Zhu",
        "S Han"
      ],
      "year": "2020",
      "venue": "Deep leakage from gradients"
    },
    {
      "citation_id": "14",
      "title": "Towards general deep leakage in federated learning",
      "authors": [
        "J Geng",
        "Y Mou",
        "F Li",
        "Q Li",
        "O Beyan",
        "S Decker",
        "C Rong"
      ],
      "year": "2021",
      "venue": "Towards general deep leakage in federated learning",
      "arxiv": "arXiv:2110.09074"
    },
    {
      "citation_id": "15",
      "title": "Membership inference attacks against machine learning models",
      "authors": [
        "R Shokri",
        "M Stronati",
        "C Song",
        "V Shmatikov"
      ],
      "year": "2017",
      "venue": "Membership inference attacks against machine learning models"
    },
    {
      "citation_id": "16",
      "title": "Comprehensive privacy analysis of deep learning: Passive and active white-box inference attacks against centralized and federated learning",
      "authors": [
        "M Nasr",
        "R Shokri",
        "A Houmansadr"
      ],
      "year": "2019",
      "venue": "2019 IEEE symposium on security and privacy (SP)"
    },
    {
      "citation_id": "17",
      "title": "IEMOCAP: Interactive emotional dyadic motion capture database",
      "authors": [
        "C Busso",
        "M Bulut",
        "C.-C Lee",
        "A Kazemzadeh",
        "E Mower",
        "S Kim",
        "J Chang",
        "S Lee",
        "S Narayanan"
      ],
      "year": "2008",
      "venue": "Language resources and evaluation"
    },
    {
      "citation_id": "18",
      "title": "Crema-d: Crowd-sourced emotional multimodal actors dataset",
      "authors": [
        "H Cao",
        "D Cooper",
        "M Keutmann",
        "R Gur",
        "A Nenkova",
        "R Verma"
      ],
      "year": "2014",
      "venue": "IEEE transactions on affective computing"
    },
    {
      "citation_id": "19",
      "title": "Msp-improv: An acted corpus of dyadic interactions to study emotion perception",
      "authors": [
        "C Busso",
        "S Parthasarathy",
        "A Burmania",
        "M Abdelwahab",
        "N Sadoughi",
        "E Provost"
      ],
      "year": "2016",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "20",
      "title": "Attention based fully convolutional network for speech emotion recognition",
      "authors": [
        "Y Zhang",
        "J Du",
        "Z Wang",
        "J Zhang",
        "Y Tu"
      ],
      "year": "2018",
      "venue": "2018 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference"
    },
    {
      "citation_id": "21",
      "title": "Openmoji",
      "venue": "Openmoji"
    },
    {
      "citation_id": "22",
      "title": "Advances and open problems in federated learning",
      "authors": [
        "P Kairouz",
        "H Mcmahan",
        "B Avent",
        "A Bellet",
        "M Bennis",
        "A Bhagoji",
        "K Bonawitz",
        "Z Charles",
        "G Cormode",
        "R Cummings"
      ],
      "year": "2019",
      "venue": "Advances and open problems in federated learning",
      "arxiv": "arXiv:1912.04977"
    },
    {
      "citation_id": "23",
      "title": "Opensmile: the munich versatile and fast open-source audio feature extractor",
      "authors": [
        "F Eyben",
        "M Wöllmer",
        "B Schuller"
      ],
      "year": "2010",
      "venue": "Proceedings of the 18th ACM international conference on Multimedia"
    },
    {
      "citation_id": "24",
      "title": "SUPERB: Speech Processing Universal PERformance Benchmark",
      "authors": [
        "S Yang",
        "P.-H Chi",
        "Y.-S Chuang",
        "C.-I Lai",
        "K Lakhotia",
        "Y Lin",
        "A Liu",
        "J Shi",
        "X Chang",
        "G.-T Lin",
        "T.-H Huang",
        "W.-C Tseng",
        "K Lee",
        "D.-R Liu",
        "Z Huang",
        "S Dong",
        "S.-W Li",
        "S Watanabe",
        "A Mohamed",
        "H Yi Lee"
      ],
      "year": "2021",
      "venue": "Proc. Interspeech 2021"
    },
    {
      "citation_id": "25",
      "title": "An unsupervised autoregressive model for speech representation learning",
      "authors": [
        "Y.-A Chung",
        "W.-N Hsu",
        "H Tang",
        "J Glass"
      ],
      "year": "2019",
      "venue": "An unsupervised autoregressive model for speech representation learning"
    },
    {
      "citation_id": "26",
      "title": "Vector-quantized autoregressive predictive coding",
      "year": "2020",
      "venue": "Vector-quantized autoregressive predictive coding"
    },
    {
      "citation_id": "27",
      "title": "Tera: Self-supervised learning of transformer encoder representation for speech",
      "authors": [
        "A Liu",
        "S.-W Li",
        "H.-Y Lee"
      ],
      "year": "2021",
      "venue": "IEEE/ACM Transactions on Audio, Speech, and Language Processing"
    },
    {
      "citation_id": "28",
      "title": "Non-autoregressive predictive coding for learning speech representations from local dependencies",
      "authors": [
        "A Liu",
        "Y.-A Chung",
        "J Glass"
      ],
      "year": "2020",
      "venue": "Non-autoregressive predictive coding for learning speech representations from local dependencies",
      "arxiv": "arXiv:2011.00406"
    },
    {
      "citation_id": "29",
      "title": "Decoar 2.0: Deep contextualized acoustic representations with vector quantization",
      "authors": [
        "S Ling",
        "Y Liu"
      ],
      "year": "2020",
      "venue": "Decoar 2.0: Deep contextualized acoustic representations with vector quantization"
    },
    {
      "citation_id": "30",
      "title": "Mockingjay: Unsupervised speech representation learning with deep bidirectional transformer encoders",
      "authors": [
        "A Liu",
        "S -W. Yang",
        "P.-H Chi",
        "P.-C Hsu",
        "H.-Y Lee"
      ],
      "year": "2020",
      "venue": "ICASSP 2020 -2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
    },
    {
      "citation_id": "31",
      "title": "User-level differential privacy against attribute inference attack of speech emotion recognition in federated learning",
      "authors": [
        "T Feng",
        "R Peri",
        "S Narayanan"
      ],
      "year": "2022",
      "venue": "User-level differential privacy against attribute inference attack of speech emotion recognition in federated learning",
      "arxiv": "arXiv:2204.02500"
    },
    {
      "citation_id": "32",
      "title": "User label leakage from gradients in federated learning",
      "authors": [
        "A Wainakh",
        "F Ventola",
        "T Müßig",
        "J Keim",
        "C Cordero",
        "E Zimmer",
        "T Grube",
        "K Kersting",
        "M Mühlhäuser"
      ],
      "year": "2021",
      "venue": "User label leakage from gradients in federated learning",
      "arxiv": "arXiv:2105.09369"
    },
    {
      "citation_id": "33",
      "title": "Source inference attacks in federated learning",
      "authors": [
        "H Hu",
        "Z Salcic",
        "L Sun",
        "G Dobbie",
        "X Zhang"
      ],
      "year": "2021",
      "venue": "2021 IEEE International Conference on Data Mining (ICDM)"
    },
    {
      "citation_id": "34",
      "title": "Efficient emotion recognition from speech using deep learning on spectrograms",
      "authors": [
        "A Satt",
        "S Rozenberg",
        "R Hoory"
      ],
      "year": "2017",
      "venue": "Interspeech"
    },
    {
      "citation_id": "35",
      "title": "Context-aware attention mechanism for speech emotion recognition",
      "authors": [
        "G Ramet",
        "P Garner",
        "M Baeriswyl",
        "A Lazaridis"
      ],
      "year": "2018",
      "venue": "2018 IEEE Spoken Language Technology Workshop (SLT)"
    },
    {
      "citation_id": "36",
      "title": "Practical secure aggregation for privacy-preserving machine learning",
      "authors": [
        "K Bonawitz",
        "V Ivanov",
        "B Kreuter",
        "A Marcedone",
        "H Mcmahan",
        "S Patel",
        "D Ramage",
        "A Segal",
        "K Seth"
      ],
      "year": "2017",
      "venue": "proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security"
    },
    {
      "citation_id": "37",
      "title": "Securing secure aggregation: Mitigating multi-round privacy leakage in federated learning",
      "authors": [
        "J So",
        "R Ali",
        "B Guler",
        "J Jiao",
        "S Avestimehr"
      ],
      "year": "2021",
      "venue": "Securing secure aggregation: Mitigating multi-round privacy leakage in federated learning",
      "arxiv": "arXiv:2106.03328"
    },
    {
      "citation_id": "38",
      "title": "Byzantinerobust and privacy-preserving framework for fedml",
      "authors": [
        "H Hashemi",
        "Y Wang",
        "C Guo",
        "M Annavaram"
      ],
      "year": "2021",
      "venue": "Byzantinerobust and privacy-preserving framework for fedml",
      "arxiv": "arXiv:2105.02295"
    },
    {
      "citation_id": "39",
      "title": "Mitigating byzantine attacks in federated learning",
      "authors": [
        "S Prakash",
        "A Avestimehr"
      ],
      "year": "2020",
      "venue": "Mitigating byzantine attacks in federated learning",
      "arxiv": "arXiv:2010.07541"
    },
    {
      "citation_id": "40",
      "title": "Intel sgx explained",
      "authors": [
        "V Costan",
        "S Devadas"
      ],
      "year": "2016",
      "venue": "IACR Cryptol. ePrint Arch"
    },
    {
      "citation_id": "41",
      "title": "Shredder: Learning noise distributions to protect inference privacy",
      "authors": [
        "F Mireshghallah",
        "M Taram",
        "P Ramrakhyani",
        "A Jalali",
        "D Tullsen",
        "H Esmaeilzadeh"
      ],
      "year": "2020",
      "venue": "Proceedings of the Twenty-Fifth International Conference on Architectural Support for Programming Languages and Operating Systems"
    },
    {
      "citation_id": "42",
      "title": "Origami inference: Private inference using hardware enclaves",
      "authors": [
        "K Narra",
        "Z Lin",
        "Y Wang",
        "K Balasubramanian",
        "M Annavaram"
      ],
      "year": "2021",
      "venue": "2021 IEEE 14th International Conference on Cloud Computing (CLOUD)"
    },
    {
      "citation_id": "43",
      "title": "Exploring hashing and cryptonet based approaches for privacy-preserving speech emotion recognition",
      "authors": [
        "M Dias",
        "A Abad",
        "I Trancoso"
      ],
      "year": "2018",
      "venue": "2018 IEEE International Conference on Acoustics, Speech and Signal Processing"
    },
    {
      "citation_id": "44",
      "title": "Federated learning with differential privacy: Algorithms and performance analysis",
      "authors": [
        "K Wei",
        "J Li",
        "M Ding",
        "C Ma",
        "H Yang",
        "F Farokhi",
        "S Jin",
        "T Quek",
        "H Poor"
      ],
      "year": "2020",
      "venue": "IEEE Transactions on Information Forensics and Security"
    },
    {
      "citation_id": "45",
      "title": "Deep learning with differential privacy",
      "authors": [
        "M Abadi",
        "A Chu",
        "I Goodfellow",
        "H Mcmahan",
        "I Mironov",
        "K Talwar",
        "L Zhang"
      ],
      "year": "2016",
      "venue": "Proceedings of the 2016 ACM SIGSAC conference on computer and communications security"
    },
    {
      "citation_id": "46",
      "title": "Privacy enhanced multimodal neural representations for emotion recognition",
      "authors": [
        "M Jaiswal",
        "E Provost"
      ],
      "year": "2020",
      "venue": "Tiantian Feng received the B.S. degree in instrument technology from the Nanjing University of Posts and Telecommunications"
    }
  ]
}