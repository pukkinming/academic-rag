{
  "paper_id": "2211.08029v2",
  "title": "Persian Emotion Detection Using Parsbert And Imbalanced Data Handling Approaches",
  "published": "2022-11-15T10:22:49Z",
  "authors": [
    "Amirhossein Abaskohi",
    "Nazanin Sabri",
    "Behnam Bahrak"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Emotion recognition is one of the machine learning applications which can be done using text, speech, or image data gathered from social media spaces. Detecting emotion can help us in different fields, including opinion mining. With the spread of social media, different platforms like Twitter have become data sources, and the language used in these platforms is informal, making the emotion detection task difficult. EmoPars and ArmanEmo are two new human-labeled emotion datasets for the Persian language. These datasets, especially EmoPars, are suffering from inequality between several samples between two classes. In this paper, we evaluate EmoPars and compare them with ArmanEmo. Throughout this analysis, we use data augmentation techniques, data re-sampling, and class-weights with Transformer-based Pretrained Language Models(PLMs) to handle the imbalance problem of these datasets. Moreover, feature selection is used to enhance the models' performance by emphasizing the text's specific features. In addition, we provide a new policy for selecting data from EmoPars, which selects the high-confidence samples; as a result, the model does not see samples that do not have specific emotion during training. Our model reaches a Macro-averaged F1-score of 0.81 and 0.76 on ArmanEmo and EmoPars, respectively, which are new state-of-the-art results in these benchmarks. 1",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "In people's social and professional lives, emotional expression and detection are crucial due to the fact that systems can change their responses and behavioral patterns in response to human emotions, improving the naturalness of interactions (Tzirakis   1 Code is publicly available at https://github.com /AmirAbaskohi/Persian-Emotion-Detectionusing-ParsBERT-and-Imbalanced-Data-Handl ing-Approaches et al., 2019). They strongly influence the variety and quality of our experiences and social interactions, and they are intimately tied to our cognitive and communicative abilities  (Dolan, 2002) . Social networks, for example, have evolved into mediums for users to express their emotions  (Tettegah and Noble, 2015) . Additionally, they are valuable tools to keep up with the news. Furthermore, finding new social trends based on stakeholder groups' or the general public's expectations, attitudes, and dispositions is the aim of opinion research. Opinion research is often used in policymaking to more accurately predict the effects of proposed changes and to better communicate the projected advantages and drawbacks  (Sobkowicz et al., 2012) . As a result, we use the data from these platforms for emotion recognition for opinion mining.\n\nSentiment analysis tools are helpful if we just want to check the polarity of a sentence or document  (Andalibi and Buss, 2020) . In this paper, we want to go deeper, trying to detect a social media post's emotion since sentiment analysis can find whether a sample is positive or not, whereas emotion is a more complex concept. With emotion recognition, we can get more granular data, bringing out the real emotions of the user who created that specific post.\n\nThe precision with which people can gauge the emotions of others varies greatly  (Gendron et al., 2014)  and this is a reason why automated systems have problems in this task. Automating the identification of facial emotions from video, spoken expressions from audio, written expressions from text, and physiology, as measured by wearables, has received the most attention to date. The technology generally performs best when it integrates several modalities into the environment  (Tzirakis et al., 2017) . However, gathering enough synchronous multi-modal data is not easy, and as a result, there is a need for improving single-modal models. Here our focus is using text data for emotion recognition.\n\nOne of the usages of emotion recognition is in detecting psychological disorders. Severe social interaction deficiencies are a hallmark of borderline personality disorder (BPD), which may be related to abnormalities in emotion perception  (Minzenberg et al., 2006; Domes et al., 2009) . Furthermore, emotion recognition is essential for society's satisfaction evaluation. This evaluation can be used in different situations like an election or even a recent pandemic,  COVID-19(Esmin et al., 2012; Shyry et al., 2020; Meléndez et al., 2020) . Moreover, emotion recognition can be used in examining the well-being of people under different circumstances. For instance, in  (Schlegel et al., 2021) , emotion recognition was used as a predictor of well-being during the COVID-19 pandemic. Consequently, emotion detection is a helpful research line, and using social media, like Twitter, whose data type is textual data, plays an important role here since they provide a massive amount which makes the data collection pipeline a lot easier. However, the mentioned papers are in English, and in this paper, we propose an emotion recognition model to use in the areas above. Despite several pieces of research in English, in Persian, mining emotions from text and other media needs more research as the provided datasets for this task in Persian is no specific model for these datasets is provided. EmoPars  (Sabri et al., 2021)  and ArmanEmo  (Mirzaee et al., 2022)  are two famous textual emotion datasets. Although some methods for detecting emotions are provided in  (Mirzaee et al., 2022) , in this paper, we try to improve those approaches by solving the imbalance dataset issue and providing a feature-selecting method.\n\nIn order to achieve a high F1-score in Persian emotion detection, we attempt to use transformer architecture  (Vaswani et al., 2017)  and various methods for handling imbalanced data such as undersampling for the major class, suitable class weights, F1-Cross-Entropy loss function, and data augmentation techniques. Our method reaches a state-ofthe-art result in both EmoPars  (Sabri et al., 2021)  and ArmanEmo  (Mirzaee et al., 2022)  benchmarks. In general, the main contributions of this paper are:\n\n• Introducing new data sampling on the EmoPars dataset to improve the results on this dataset. Our strategy aims to use more data in contrast to the methodology presented in  (Mirzaee et al., 2022) , which eliminates 96% of the tweets in this dataset.\n\n• Improving the model's fairness in EmoPars benchmark by using random undersampling for major class and Easy Data Augmentation(synonym replacement, word addition, word elimination, and shuffling)to decrease the differences in the number of samples in classes and using proper class weights and F1-Cross-Entropy loss function.\n\n• Introducing a feature extraction method to help the model to pay more attention to specific features in the data, which has much information about the emotion of the sample, such as hashtags and emojis.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Related Works",
      "text": "In this section, we first discuss emotion detection studies that have been previously investigated, especially in Persian texts. We then provide a brief review of approaches for handling imbalanced datasets. Finally, we will look at the feature extraction approaches in English and Persian texts.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Emotion Detection Methods In Texts",
      "text": "People still prefer using text to communicate their thoughts regarding other people, objects, or events  (WARSI, 2021) . Due to the nature of the data, it is still more challenging to extract emotion from the text since the whole text, including metaphors and sarcasm, should be considered  (Skórzewski, 2022) . Sometimes several emotions might be present in a single paragraph. Additionally, some words in texts have many meanings, while others express the same feeling with multiple words.\n\nThere are several methods for detecting textual emotions. Affective computing includes tasks like emotion recognition, and diverse academics have divided the computational techniques employed in this field into several categories. These researchers' methodologies may be broadly divided into four groups: machine learning method, lexicon-based method, keyword-based method, and hybrid method  (Andalibi and Buss, 2020) . Machine learning methods got more popular due to the adequate performance of word embedding and transformer architecture in sentiment analysis tasks, and this was not just in English.\n\nEmotion recognition in English has been investigated in several studies. In speech emotion recognition, various approaches, including self-supervised, multilingual fusion, and knowledge transfer, were used  (Neumann et al., 2018; Sarkar and Etemad, 2020; Iosifov et al., 2022) . In text emotion recognition, using the psychological frameworks offered by  (Russell, 1980)  and  (Ekman, 1992b)  to map documents, phrases, and words to a set of emotions was among the first approaches. The problem with traditional methodologies was then overcome by machine learning-based approaches, leading to notable improvements in text emotional recognition  (Zhang et al., 2016) . In text analysis research, deep learning-based methods have emerged as the cutting edge. They have demonstrated the capacity to pick up on the key emotion characteristics, which has significantly improved text emotion identification performance  (Alswaidan and Menai, 2020) . Convolutional Neural Networks(CNNs) and Long Short Term Memories(LSTMs) are among these approaches  (Shrivastava et al., 2019; Mahto and Yadav, 2022; Alla et al., 2022) . With the introduction of Transformer architecture, transformer-based, especially BERT-based models, were used for emotion recognition on text data and multi-modal scenarios  (Li et al., 2020; Acheampong et al., 2021) .\n\nAlthough emotion recognition in Persian has been studied in speech and text domains  (Hamidi and Mansoorizade, 2012; Pourebrahim et al., 2021; Yazdani et al., 2021) , very few studies have been conducted on emotion detection from Persian text  (Sadeghi et al., 2021) . One of the reasons for this is the few Persian datasets available for emotion detection. After the introduction of EmoPars  (Sabri et al., 2021) , the study of this topic has started with more effort. This dataset includes Persian Tweets and will be introduced in Section 3.1. However, emotion detection is not investigated in the provided paper, and just the data and its statistics are provided. ArmanEmo  (Mirzaee et al., 2022)  is another dataset that includes other data sources like Instagram. In addition to introducing a new dataset, they performed transformer-based approaches including ParsBERT  (Mehrdad Farahani and Manthouri, 2021)  and XLM-RoBERTa  (Conneau et al., 2020)  to evaluate their dataset and EmoPars dataset. These models will be used in this paper as well. Moreover, we will investigate different approaches for solving the imbalance problem of these datasets and improving the performance of the model as well.\n\nIn Persian emotion detection, Sadeghi et al.  (Sadeghi et al., 2021 ) used a hybrid ap-proach by combining the cognitive features and Word2Vec  (Mikolov et al., 2013)  embedding. The emotional construction, keywords, and parts of speech are utilized to construct the cognitive features. Then the features are passed to a Gated Recurrent Unit (GRU)  (Cho et al., 2014)  network for classification. However, this method needs human supervision which makes it hard to use in other scenarios in this paper our goal is to have a more automatic approach. Since we are dealing with imbalanced data sets illustrated in Section 3.1, we need to refer to previous work on how to deal with these datasets.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Handling Imbalanced Datasets",
      "text": "Unbalanced datasets have become increasingly important in machine learning in recent years since if the data set is imbalanced, then you get a high accuracy just by predicting the majority class. However, you fail to capture the minority class. Hence, the model does not give good results in production and unseen data since it would completely ignore the minority class in favor of the majority class. The ratio between the majority and minority classes can range from 100:1 to 1000:1  (Makki et al., 2019) , meaning that more people belong to the majority class than the minority class. As a consequence, some helpful information about the data itself, which could be necessary for building rule-based classifiers, may be lost.\n\nIn data-level approaches, Majority Weighted Minority Oversampling Technique (MW-MOTE)  (Barua et al., 2012)  has been introduced to use oversampling and weights for major classes to solve the negative effect of imbalanced data in 20 real-world datasets. In another study, Neighbourhood Balanced Bagging (NBBag)  (Błaszczyński and Stefanowski, 2015)  was introduced. In this approach, sampling probabilities of examples are modified according to the class distribution in their neighborhood. Two versions are considered: the first one keeps a larger size of bootstrap samples by hybrid over-sampling, and the other reduces this size with stronger under-sampling.\n\nIn algorithm-level approaches, defining class weights for machine learning models has been used in random forest algorithms to overcome imbalanced data problems in medical data  (Zhu et al., 2018) . Furthermore, different loss functions have been used to increase the model performance by concentrating more on minor data in the process of learning  (Zhang et al., 2020; Li et al., 2021) . Also, data augmentation methods have been studied for solving the imbalanced data problem(dos Santos Tanaka and Aranha, 2019;  Jiang and Ge, 2020; Abaskohi et al., 2022) .",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Feature Extraction",
      "text": "Specific features of social media texts like emojis and hashtags usually carry valuable information  (Alfano et al., 2021) . In English,  (Sari et al., 2014)  and  (Lemmens et al., 2020)  used these features to improve the result of their model by giving them separately to the model. This method has been used in Persian for rumor detection, and verification  (Mahmoodabad et al., 2018; Jahanbakhsh-Nagadeh et al., 2021) . In this paper, in addition to using emojis and hashtags, we used Part of Speech(POS) and misspelled words. We believe misspelled words are usually used to grab more attention, which is a reason for having a piece of helpful information. Furthermore, as the language models used in our experiments do not follow the formal sentence structure used in the language models' pre-training phase, POS tagging helps the model better understand the sentence structure.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Methods And Data",
      "text": "This section explains the properties of the dataset utilized in this work. In addition, we will contrast this dataset with other Persian datasets currently accessible for emotion recognition. Finally, we will outline our process to develop a superior generic model for emotion recognition.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Datasets",
      "text": "Emotion detection, as one of the complex tasks in natural language processing, not only has challenges in detecting tweets but also the data, as the vital part of the deep learning model, has its challenges.\n\nEmoPars  (Sabri et al., 2021) , is a dataset of 30,000 Persian Tweets labeled with Ekman's six basic emotions (Anger, Fear, Happiness, Sadness, Hatred, and Wonder)  (Ekman, 1992a) . The first publicly available Persian emotion dataset provides enough information for further data analysis. Although other available datasets like Ar-manEmo  (Mirzaee et al., 2022)  believe each sentence can only contain one emotion, it seems emotion detection is a multi-label task  (Bhowmick et al., 2009; Deng and Ren, 2020; Fei et al., 2021) . In contrast, the EmoPars dataset considers this task as a multi-label task. In this paper, we use multi-label training in one of our experiments on EmoPars; however, using multiple binary classifiers reaches better results since in this approach handling data imbalance is easier and the model has a simple task as well since it faces just two classes.\n\nEmoPars uses information obtained from Twitter's official developer API  (Sabri et al., 2021) . They gather tweets using multiple keywords, including articles and prepositions, from various topics to avoid data being skewed by any topic or debate. Include at least a few tweets from each period in your tweets. As in the published dataset, the vote counts have been provided in the range of  [0, 5]  for classification; various policies can be used to create a classification (whether binary, multi-label, or multi-class). Here we try to find out the best policy for classification.\n\nArmanEmo  (Mirzaee et al., 2022)  is another dataset whose data is gathered from Twitter, Instagram, and customers' comments on Digikala (an online shopping platform), and it consists of approximately 2.55 million raw samples(1.5 million from Twitter, 1 million from Instagram, and 50K from Digikala). Unlike EmoPars, they removed samples whose lengths felt outside of a specific range or included specific user IDs or links in the annotation step. Furthermore, they controlled the class balance and considered only using samples with one emotion and removed samples with multiple or no emotions.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Data Selection Policy",
      "text": "Data annotation is not a simple task, especially in emotion detection, where some emotions are debatable, and detecting whether they have a specific emotion is more challenging and may result in incorrectly labeled data. The voting method used in this paper's datasets, EmoPars and ArmanEmo, can cause some disagreement in the data. Although ArmanEmo tries to handle this problem by removing samples with no emotion or multiple emotions, EmoPars does not.\n\nOne possible solution might be using a threshold to annotate samples. Additionally, tweets close to this level can result in other issues. Using a specific threshold to decide whether a tweet contains an emotion can be helpful but finding this threshold may be challenging. In addition, tweets near this threshold may cause different problems.\n\nAlthough we have tried different threshold values, and the results are discussed in Section 4, we are introducing a new strategy for selecting valuable data for training our model. In this approach, the tweet is not considered when two or three individuals out of 5 annotators agree that a tweet contains a particular emotion.\n\nWe have also selected thirty tweets from each emotion's label and labeled them ourselves. The results in Table  1  show us that our approach is acceptable. In general, there is no confidence in labels two and three. Nonetheless, about Wonder emotion, our general idea is applicable; the crucial point here is the hardness of predicting Wonder label. It is important to note that fewer than thirty tweets with the label \"5\" for each emotion. Because of this, we have included this label in all tweets. Table  1 : The result of labeling thirty tweets of each label of each emotion to check whether removing tweets with two or three agreed annotators is an acceptable approach.",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "Data Augmentation",
      "text": "One of the main challenges in solving emotion detection using the EmoPars dataset is the unbalanced data. Figure  1  shows a big difference between 0 and 1 labels in each emotion. This unbalanced data will result in biased results. There are several approaches to solve this issue.\n\nAlthough there is a massive difference in our case, it may not only not help us but also weaken the result, as was shown in  (Aquino et al., 2017) . In addition, our analysis of the length of the tweets which can be seen in Figure  2 , shows us that creating 100 new views of the initial sample may create tweets in which the sentiment of the sentence is different or tweets with the same sentiment.\n\nMutation-based data augmentation, which uses synonym replacement, word elimination, word addition, and word swap, has been shown to improve the models' results in various tasks  (Kafle et al., 2017; Parida and Motlicek, 2019; Shorten et al., 2021; Abaskohi et al., 2022) . We used this data augmentation to create more samples of label 1 of each emotion to decrease the difference between classes.\n\nIn our data augmentation, we used NLPAug(Ma, 2019) python module's ContextualWordEmbsAug and RandomWordAug methods. This module uses a language model for word insertion and synonym replacement. We used ParsBERT(Mehrdad Farahani and Manthouri, 2021) as the language model in this section. Due to the different ratios between 0 and 1 classes in each emotion, the number of augmented samples per initial sample is different per emotion. Table  2  shows data augmentation hyper-parameters used for each emotion.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Model",
      "text": "This section presents baseline models for EmoPars transfer learning-based emotion classification. Since labels are expensive, supervised learning is challenging to apply to NLP issues, including emotion detection. Transfer learning is helpful in this situation. In recent years, state-of-the-art performance in various NLP tasks has resulted from transfer learning from pre-trained deep neural Language Models (LMs) towards downstream language issues  (Ying et al., 2019; Durrani et al., 2021) .\n\nWe use the ParsBERT(Mehrdad Farahani and Manthouri, 2021) pre-trained language model for Persian in most of our experiments to find the best solution. A monolingual language model called ParsBERT is built on the BERT architecture  (Devlin et al., 2019) . The ParsBERT model surpasses the multilingual BERT  (Pires et al., 2019)  and earlier models in some Persian NLP downstream tasks, such as text categorization and sentiment analysis, according to research by  Farahani et al.(Mehrdad Farahani and Manthouri, 2021) . Pars-BERT has been trained on a broader and more varied set of pre-trained Persian datasets than the multilingual BERT, making it lighter in weight. Although, due to the unbalanced data, we used other strategies to increase the model's performance. We will introduce them in the following sections.\n\nIn addition, to compare the quality of the EmoPars and ArmanEmo (a human-labeled emotion dataset of more than 7000 Persian sentences labeled for seven categories)  (Mirzaee et al., 2022) , we used XLM-RoBERTa  (Conneau et al., 2020)  and XLM-EMO  (Bianchi et al., 2022) .   A multilingual language model called XLM-RoBERTa has already been trained using Masked Language Modeling (MLM). XLM-RoBERTa performs better than multilingual BERT since it has more training data. XLM-RoBERTa is trained on 100 languages was.\n\nA multilingual emotion prediction model called XLM-EMO was developed using social media data. The model performs admirably in a zero-shot scenario, indicating that it is helpful for low-resource languages.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Data Pre-Processing",
      "text": "The data pre-processing method used in our approach was like what was used in ArmanEmo paper  (Mirzaee et al., 2022) . We used the Parsivar toolkit  (Mohtaj et al., 2018)  in this manner. Along with various character refining procedures, Parsivar does several rule-based space correction operations (including word, punctuation, and affix spacing) (such as removing stretching letters). However, its normalization guidelines are not exhaustive. In addition to normalization, we did the following pre-processings:\n\n• If there is an English word in the sentence; first we check if the word exists in a single token to single token dictionary provided by Meta 2  . If the word does not exist in the dictionary, we use transliteration provided by Polyglot module 3  . Information from other languages is not considered in our approach.\n\n• Removing letters from Persian words that are frequently purposely misspelled in order to emphasize certain words more strongly in casual writing.\n\n• Removing from the text any Arabic diacritics that the Parsivar normalizer did not remove.\n\n• After completing the aforementioned stages, we removed any last non-Persian characters.\n\n• Removing the \"#\" from the text's hashtags while retaining the information they contain.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Loss Function",
      "text": "The loss function greatly impacts a model's performance. The influence of the different loss functions has been investigated in (Abdel-Salam, 2022) for the sarcasm detection task. In their results, they found that F1-Cross-Entropy and Recall-Cross-Entropy may help that to reach a good F1-Sarcastic. Equation  1 and 2 shows how this loss functions work respectively. In these equations, F 1 c and Recall c are the F1-Score and Recall corresponding to a specific class c, respectively.\n\nAlthough in the mentioned task, Recall-Cross-Entropy reaches better results, in our task, F1-Cross-Entropy showed better results.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Feature Extraction",
      "text": "Although considering the whole context gives the sample's sentiment and emotion, some specific parts of the samples, like hashtags or emojis, include more information. Considering these features, as well as the embedding of the sample, showed improvement in previous studies  (Hernández-Farías et al., 2015; Yaghoobian et al., 2021; Nandwani and Verma, 2021) . After extracting some lexical-based features, using the splitting token \"</s></s>\", all text features are simply added to the pre-processed tweets. Figure  3  shows how this process works.\n\nThe feature extraction methods we used for this task are:\n\n• Emoji: After examining a sizable amount of Twitter data, emoji are a notable multi-model feature that depicts human emotions.\n\n• Parts of Speech(POS): Additionally, changing the sentence structure sometimes is used to show the writer's emotion. As a result, POS tags are utilized as a crucial component.\n\n• Misspelled Words: Occasionally, incorrectly spelled and capitalized words that are not at the start of a phrase might increase the emotion.\n\n• Hashtags: Hashtags show the main point of the sentence more clearly. Using them as a particular feature would be helpful.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Undersampling And Class Weight",
      "text": "In Section 3.3, we used data augmentation to decrease the big difference between the number of samples between the two classes. In addition, we mentioned that due to the vast difference, creating nearly 100 views of a sentence using augmentation methods not only does not help us but may also weaken the performance of the model. Other methods can help us to do, in addition to data augmentation, to make the number of overcome the unbalanced dataset problem. Instead of increasing the number of samples for the minor class, we can decrease the number of samples in the significant class, which is called undersampling. Undersampling is a technique to balance uneven datasets by keeping all of the data in the minority class and decreasing the size of the majority class. This method has been investigated in previous papers  (Zhu and Hovy, 2007; Kapadi and Luz, 2022) . To do undersampling, we selected the tweets randomly with a preference for shorter tweets(using 1 T weetLength as the weight of our selection).\n\nIn addition to undersampling, class weights can be used in the training approach. Most machine learning algorithms are not very useful with partial class data. However, we can modify the current training algorithm to consider the skewed distribution of the classes. This can be achieved by giving weight to both the majority and minority classes. The difference in weights will influence the classification of the classes during the training phase. The purpose is to penalize the misclassification made by the minority class by setting a higher class weight and simultaneously reducing the weight for the majority class.\n\nWe decreased our dataset imbalance using data augmentation, undersampling, and class weights. Table  3  shows information about the final dataset to the model. In addition to these methods, feature extraction introduced in Section 3.4.3 and the F1-Cross-Entropy loss function mentioned in Section 3.4.2 were also helpful.\n\nFigure  3 : We use different feature extractors, and then we add the extracted features to the pre-processed tweet using the \"</s></s>\" token. The input sentence translation in English is: \"There's nothing wrong with saying that you took the exam at that time :))). My health does not matter <broken-heart-emoji> <neutral-face-emoji>. How about yours?#postponement_of_safe_conditions\".",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Experiments",
      "text": "In this section, we report our results in different experiments. We compare two famous Persian emotion datasets with our approach. In addition, on EmoPars, we evaluate the effectiveness of our method through different experiments, including multi-label training and different threshold in selecting tweets.\n\nIn our experiments, 10% of the datasets have been used for evaluation and the rest for training. In addition, batch size 16, 5 epochs, the learning rate of 1e-4, and a max length of 256 were utilized in these experiments.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Training With Using Class Weights Only",
      "text": "Because no baseline has been provided in the EmoPars paper and the analysis in the ArmanEmo paper on this dataset is not fair, we first trained  ParsBERT without using any of the other methods. The only method that has been used to handle imbalanced datasets was using class weights. The class weight was set based on the number of samples, where the ratio of the number of significant class samples by the number of minor class samples was used as the weight of the minor class, and the weight of the major class was one.\n\nTable  4  shows the baseline results for EmoPars dataset. The interesting fact about these results might be that although happiness has the best results, sadness does not show this fact. This is because people use more specific words in happiness, while in sadness, the words can conflict with those in hatred. Another reason may be the larger number of samples in class zero in sadness than happiness, resulting in using a larger class weight for class  one.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Multi-Label Training",
      "text": "As mentioned in Section 3.1, emotion detection is multi-label task which EmoPars considers this fact. One of the first experiments we did was using the ParsBERT model for multi-label training of the model. We used Hamming Loss to evaluate the model. Equation  3 shows how hamming loss is calculated. In this formula, N is the number of samples, L is the number of labels, and ⊕ denotes exclusive-or.\n\nTable  5  shows the result of multi-label training with different thresholds on ParsBERT. The hamming score shows the accuracy of the model. Although we have a high score on the last two thresholds, we should consider this result unreliable since we face imbalanced data, which Figure  1  depicts. When the considered threshold is bigger, the number of samples in one class(class zero) is higher. As a result, we have a more hamming score. Even though multi-label is more efficient, we have to use multiple binary classifiers to detect the emotions in one sample. Moreover, Figure  4  illustrates loss per each batch for every five epochs which is less smooth for thresholds 4 and 5.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Removing Indeterminate Data",
      "text": "One of our ideas to evaluate the EmoPars dataset properly was removing indeterminate data explained in Section 3.2. Before applying our method for handling imbalanced data, we need to check the effect of the provided policy.\n\nTable  6  shows the effect of removing samples with labels two and three. As the results show,  F1-score has been increased to 0.1, which is a noticeable improvement in this imbalanced dataset.",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Impact Of Our Approach",
      "text": "Since we were facing with imbalanced data, we used some approaches to solve this issue which is introduced in Sections 3.  3, 3.4.1, 3.4.2, 3.4.3, and 3.4.4 . The combination of all of these methods resulted in significant improvement in the result of our method.\n\nTable  7  shows our approach has approximately double the F1-score in each emotion. We believe this result is due to using a small amount of each method for handling the imbalanced data. Using just data augmentation can make redundant samples, and under-sampling can decrease the number of samples. Nevertheless, using both of them and adding more attention by feature extraction can help us more. Moreover, the F1-Cross-Entropy tries to increase the F1-score instead of Accuracy, which will help us to reach higher precision and recall.\n\nFigure  5  shows the influence of our approach on training. Feature extraction has a significant impact on the initial loss of the model. Then, the loss function helps the model. In addition, since the model sees more samples in the positive class, it can reach better results.",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Comparing Datasets",
      "text": "One of the experiments in  (Mirzaee et al., 2022)  compared the provided dataset, ArmanEmo, and the EmoPars dataset. However, their data selection policy was not fair and accurate. They just used 919 samples from EmoPars, a small amount compared to 4700 samples in ArmanEmo.\n\nHere, we trained the model on EmoPars with more samples and used the same model and imbalanced data handling approaches. Table  9  shows the results of our comparison. Unlike the results provided in ArmanEmo, training on one dataset results in a better F1-score on the same dataset. However, results show that EmoPars is noisier and harder to learn, which can be because of including multiple emotions in one sample.",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "Comparison Among Different Models",
      "text": "Another experiment that we have done was evaluating different models on EmoPars. All the experiments till this section were done using the Pars-BERT model. Table  8  shows the results of the three models we have used: XLM-EMO  (Bianchi et al., 2022) , XLM-RoBERTa  (Bianchi et al., 2022), and ParsBERT(Mehrdad Farahani and Manthouri, 2021) . XLM-RoBERTa and XLM-EMO have higher values due to having a higher number of parameters.",
      "page_start": 14,
      "page_end": 14
    },
    {
      "section_name": "Conclusion",
      "text": "This paper uses an approach for handling imbalanced data on EmoPars, an emotion recognition dataset. Since EmoPars produces imbalanced multilabel data labeled with voting technique, selecting definite data is essential. Our experiment on EmoPars shows that removing uncertain samples increased the F1-score of the method up to 51%. However, this could not help with imbalanced data, which results in a biased model. As a result, we used data augmentation (including swapping words, synonym substitution, word deletion, and word addition), undersampling, and F1-Cross-Entropy loss function to solve this issue. In addition, we used a feature extraction technique that adds emojis, hashtags, POS tags, and misspelled words at the end of the sentence to improve the performance. Our model reaches a Macro-F1-score of 0.76 on the EmoPars. Furthermore, our introduced method reaches a Macro-F1-score of 0.81 on ArmanEmo  (Mirzaee et al., 2022) .",
      "page_start": 14,
      "page_end": 14
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: shows a big difference between 0",
      "page": 5
    },
    {
      "caption": "Figure 2: , shows us that creat-",
      "page": 5
    },
    {
      "caption": "Figure 1: An overview of the number of data samples in each emotion. There are 1 to 100 different labels for each",
      "page": 6
    },
    {
      "caption": "Figure 2: Length of each tweet by words. As most",
      "page": 6
    },
    {
      "caption": "Figure 3: shows how this process works.",
      "page": 7
    },
    {
      "caption": "Figure 3: We use different feature extractors, and then we add the extracted features to the pre-processed tweet",
      "page": 8
    },
    {
      "caption": "Figure 4: illustrates loss",
      "page": 9
    },
    {
      "caption": "Figure 5: shows the inﬂuence of our approach",
      "page": 9
    },
    {
      "caption": "Figure 4: An overview of hamming loss of ParsBERT that was trained on the EmoPars per epoch.",
      "page": 10
    },
    {
      "caption": "Figure 5: An overview of the loss value while employing our strategy and a comparison to training the model",
      "page": 10
    }
  ],
  "tables": [
    {
      "caption": "Table 1: show us that our approach is replacement. We used ParsBERT(Mehrdad Fara-",
      "data": [
        {
          "Emotion": "Predicted\n0\nAnger\nPredicted\n1",
          "Labels\n0\n1\n2\n3\n4\n5": "23\n21\n17\n15\n9\n3\n7\n9\n13\n15\n21\n21"
        },
        {
          "Emotion": "Predicted\n0\nFear\nPredicted\n1",
          "Labels\n0\n1\n2\n3\n4\n5": "24\n23\n18\n16\n10\n1\n6\n7\n12\n14\n20\n1"
        },
        {
          "Emotion": "Predicted\n0\nSadness\nPredicted\n1",
          "Labels\n0\n1\n2\n3\n4\n5": "23\n28\n27\n18\n10\n6\n7\n2\n3\n12\n20\n22"
        },
        {
          "Emotion": "Predicted\n0\nHappiness\nPredicted\n1",
          "Labels\n0\n1\n2\n3\n4\n5": "28\n25\n18\n16\n12\n1\n2\n5\n12\n14\n18\n10"
        },
        {
          "Emotion": "Predicted\n0\nWonder\nPredicted\n1",
          "Labels\n0\n1\n2\n3\n4\n5": "27\n28\n21\n17\n15\n1\n3\n2\n9\n13\n15\n7"
        },
        {
          "Emotion": "Predicted\n0\nHatred\nPredicted\n1",
          "Labels\n0\n1\n2\n3\n4\n5": "22\n20\n15\n16\n10\n1\n8\n10\n15\n14\n20\n12"
        }
      ],
      "page": 5
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "UTNLP at SemEval-2022 task 6: A comparative analysis of sarcasm detection using generative-based and mutation-based data augmentation",
      "authors": [
        "Amirhossein Abaskohi",
        "Arash Rasouli",
        "Tanin Zeraati",
        "Behnam Bahrak"
      ],
      "year": "2022",
      "venue": "Proceedings of the 16th International Workshop on Semantic Evaluation (SemEval-2022)",
      "doi": "10.18653/v1/2022.semeval-1.135"
    },
    {
      "citation_id": "2",
      "title": "reamtchka at SemEval-2022 task 6: Investigating the effect of different loss functions for sarcasm detection for unbalanced datasets",
      "authors": [
        "Reem Abdel-Salam"
      ],
      "year": "2022",
      "venue": "Proceedings of the 16th International Workshop on Semantic Evaluation (SemEval-2022)",
      "doi": "10.18653/v1/2022.semeval-1.126"
    },
    {
      "citation_id": "3",
      "title": "Transformer models for text-based emotion detection: a review of bert-based approaches",
      "authors": [
        "Francisca Adoma",
        "Henry Nunoo-Mensah",
        "Wenyu Chen"
      ],
      "year": "2021",
      "venue": "Artificial Intelligence Review"
    },
    {
      "citation_id": "4",
      "title": "The affiliative use of emoji and hashtags in the black lives matter movement: A twitter case study",
      "authors": [
        "Mark Alfano",
        "Ritsaart Reimann",
        "Ignacio Quintana",
        "Marc Cheong",
        "Colin Klein"
      ],
      "year": "2021",
      "venue": "The affiliative use of emoji and hashtags in the black lives matter movement: A twitter case study"
    },
    {
      "citation_id": "5",
      "title": "Abhinav Muthavarapu, and Swarna Kuchibhotla",
      "authors": [
        "Keerthi Reddy",
        "Nikhil Kandibanda",
        "Priyanka Katta"
      ],
      "year": "2022",
      "venue": "Proceedings of Sixth International Congress on Information and Communication Technology"
    },
    {
      "citation_id": "6",
      "title": "A survey of state-of-the-art approaches for emotion recognition in text",
      "authors": [
        "Nourah Alswaidan",
        "Bachir Menai"
      ],
      "year": "2020",
      "venue": "Knowledge and Information Systems"
    },
    {
      "citation_id": "7",
      "title": "The human in emotion recognition on social media: Attitudes, outcomes, risks",
      "authors": [
        "Nazanin Andalibi",
        "Justin Buss"
      ],
      "year": "2020",
      "venue": "Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems"
    },
    {
      "citation_id": "8",
      "title": "Md Monirul Islam, Xin Yao, and Kazuyuki Murase. 2012. Mwmote-majority weighted minority oversampling technique for imbalanced data set learning",
      "authors": [
        "Matheus Romero Aquino",
        "Leandro Gutoski",
        "Heitor S Hattori",
        "Lopes"
      ],
      "year": "2017",
      "venue": "IEEE Transactions on knowledge and data engineering"
    },
    {
      "citation_id": "9",
      "title": "Multi-label text classification approach for sentence level news emotion analysis",
      "authors": [
        "Plaban Kr Bhowmick",
        "Anupam Basu",
        "Pabitra Mitra",
        "Abhishek Prasad"
      ],
      "year": "2009",
      "venue": "International conference on pattern recognition and machine intelligence"
    },
    {
      "citation_id": "10",
      "title": "XLM-EMO: Multilingual emotion prediction in social media text",
      "authors": [
        "Federico Bianchi",
        "Debora Nozza",
        "Dirk Hovy"
      ],
      "year": "2022",
      "venue": "Proceedings of the 12th Workshop on Computational Approaches to Subjectivity, Sentiment & Social Media Analysis",
      "doi": "10.18653/v1/2022.wassa-1.18"
    },
    {
      "citation_id": "11",
      "title": "Neighbourhood sampling in bagging for imbalanced data",
      "authors": [
        "Jerzy Błaszczyński",
        "Jerzy Stefanowski"
      ],
      "year": "2015",
      "venue": "Neurocomputing"
    },
    {
      "citation_id": "12",
      "title": "On the properties of neural machine translation",
      "authors": [
        "Kyunghyun Cho",
        "Bart Van Merriënboer",
        "Dzmitry Bahdanau",
        "Yoshua Bengio"
      ],
      "year": "2014",
      "venue": "On the properties of neural machine translation",
      "arxiv": "arXiv:1409.1259"
    },
    {
      "citation_id": "13",
      "title": "Unsupervised cross-lingual representation learning at scale",
      "authors": [
        "Alexis Conneau",
        "Kartikay Khandelwal",
        "Naman Goyal",
        "Vishrav Chaudhary",
        "Guillaume Wenzek",
        "Francisco Guzmán",
        "Edouard Grave",
        "Myle Ott",
        "Luke Zettlemoyer",
        "Veselin Stoyanov"
      ],
      "year": "2020",
      "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/2020.acl-main.747"
    },
    {
      "citation_id": "14",
      "title": "Multi-label emotion detection via emotion-specified feature extraction and emotion correlation learning",
      "authors": [
        "Jiawen Deng",
        "Fuji Ren"
      ],
      "year": "2020",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "15",
      "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "authors": [
        "Jacob Devlin",
        "Ming-Wei Chang",
        "Kenton Lee",
        "Kristina Toutanova"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
      "doi": "10.18653/v1/N19-1423"
    },
    {
      "citation_id": "16",
      "title": "Emotion, cognition, and behavior",
      "authors": [
        "J Raymond",
        "Dolan"
      ],
      "year": "2002",
      "venue": "science"
    },
    {
      "citation_id": "17",
      "title": "Emotion recognition in borderline personality disorder-a review of the literature",
      "authors": [
        "Gregor Domes",
        "Lars Schulze",
        "Sabine Herpertz"
      ],
      "year": "2009",
      "venue": "Journal of personality disorders"
    },
    {
      "citation_id": "18",
      "title": "Data augmentation using gans",
      "authors": [
        "Fabio Henrique",
        "Santos Tanaka",
        "Claus Aranha"
      ],
      "year": "2019",
      "venue": "Proceedings of Machine Learning Research"
    },
    {
      "citation_id": "19",
      "title": "How transfer learning impacts linguistic knowledge in deep nlp models? arXiv preprint",
      "authors": [
        "Nadir Durrani",
        "Hassan Sajjad",
        "Fahim Dalvi"
      ],
      "year": "2021",
      "venue": "How transfer learning impacts linguistic knowledge in deep nlp models? arXiv preprint",
      "arxiv": "arXiv:2105.15179"
    },
    {
      "citation_id": "20",
      "title": "Are there basic emotions? Paul Ekman. 1992b. An argument for basic emotions",
      "authors": [
        "Paul Ekman"
      ],
      "year": "1992",
      "venue": "Cognition & emotion"
    },
    {
      "citation_id": "21",
      "title": "Hierarchical classification approach to emotion recognition in twitter",
      "authors": [
        "Roberto L De Ahmed Aa Esmin",
        "Stan Oliveira",
        "Matwin"
      ],
      "year": "2012",
      "venue": "2012 11th International Conference on Machine Learning and Applications"
    },
    {
      "citation_id": "22",
      "title": "Machine and deep learning algorithms for wearable health monitoring",
      "authors": [
        "Chengwei Fei",
        "Rong Liu",
        "Zihao Li",
        "Tianmin Wang",
        "Baig"
      ],
      "year": "2021",
      "venue": "Computational intelligence in healthcare"
    },
    {
      "citation_id": "23",
      "title": "Perceptions of emotion from facial expressions are not culturally universal: evidence from a remote culture",
      "authors": [
        "Maria Gendron",
        "Debi Roberson",
        "Jacoba Marietta Van Der Vyver",
        "Lisa Barrett"
      ],
      "year": "2014",
      "venue": "Emotion"
    },
    {
      "citation_id": "24",
      "title": "Emotion recognition from persian speech with neural network",
      "authors": [
        "Mina Hamidi",
        "Muharram Mansoorizade"
      ],
      "year": "2012",
      "venue": "International Journal of Artificial Intelligence & Applications"
    },
    {
      "citation_id": "25",
      "title": "Applying basic features from sentiment analysis for automatic irony detection",
      "authors": [
        "Irazú Hernández-Farías",
        "José-Miguel Benedí",
        "Paolo Rosso"
      ],
      "year": "2015",
      "venue": "Iberian Conference on Pattern Recognition and Image Analysis"
    },
    {
      "citation_id": "26",
      "title": "Transferability evaluation of speech emotion recognition between different languages",
      "authors": [
        "Ievgen Iosifov",
        "Olena Iosifova",
        "Oleh Romanovskyi",
        "Volodymyr Sokolov",
        "Ihor Sukailo"
      ],
      "year": "2022",
      "venue": "International Conference on Computer Science, Engineering and Education Applications"
    },
    {
      "citation_id": "27",
      "title": "A semisupervised model for persian rumor verification based on content information",
      "authors": [
        "Zoleikha Jahanbakhsh-Nagadeh",
        "Mohammad-Reza Feizi-Derakhshi",
        "Arash Sharifi"
      ],
      "year": "2021",
      "venue": "A semisupervised model for persian rumor verification based on content information"
    },
    {
      "citation_id": "28",
      "title": "Data augmentation classifier for imbalanced fault classification",
      "authors": [
        "Xiaoyu Jiang",
        "Zhiqiang Ge"
      ],
      "year": "2020",
      "venue": "IEEE Transactions on Automation Science and Engineering"
    },
    {
      "citation_id": "29",
      "title": "Data augmentation for visual question answering",
      "authors": [
        "Kushal Kafle",
        "Mohammed Yousefhussien",
        "Christopher Kanan"
      ],
      "year": "2017",
      "venue": "Proceedings of the 10th International Conference on Natural Language Generation"
    },
    {
      "citation_id": "30",
      "title": "Natural language processing of electronic patient records to predict psychiatric inpatients at risk of early readmission to hospital using predictive models derived through machine learning",
      "authors": [
        "Tarif Kapadi",
        "Saturnino Luz"
      ],
      "year": "2022",
      "venue": "BJPsych Open"
    },
    {
      "citation_id": "31",
      "title": "Sarcasm detection using an ensemble approach",
      "authors": [
        "Jens Lemmens",
        "Ben Burtenshaw",
        "Ehsan Lotfi",
        "Ilia Markov",
        "Walter Daelemans"
      ],
      "year": "2020",
      "venue": "proceedings of the second workshop on figurative language processing"
    },
    {
      "citation_id": "32",
      "title": "Autobalance: Optimized loss functions for imbalanced data",
      "authors": [
        "Mingchen Li",
        "Xuechen Zhang",
        "Christos Thrampoulidis",
        "Jiasi Chen",
        "Samet Oymak"
      ],
      "year": "2021",
      "venue": "Neural Information Processing Systems"
    },
    {
      "citation_id": "33",
      "title": "Hierarchical transformer network for utterance-level emotion recognition",
      "authors": [
        "Qingbiao Li",
        "Chunhua Wu",
        "Zhe Wang",
        "Kangfeng Zheng"
      ],
      "year": "2020",
      "venue": "Applied Sciences"
    },
    {
      "citation_id": "34",
      "title": "",
      "authors": [
        "Edward Ma"
      ],
      "year": "2019",
      "venue": ""
    },
    {
      "citation_id": "35",
      "title": "Persian rumor detection on twitter",
      "authors": [
        "Sajjad Dehghani Mahmoodabad",
        "Saeed Farzi",
        "Danial Bakhtiarvand"
      ],
      "year": "2018",
      "venue": "2018 9th international symposium on telecommunications (IST)"
    },
    {
      "citation_id": "36",
      "title": "Hierarchical bi-lstm based emotion analysis of textual data",
      "authors": [
        "Dashrath Mahto",
        "Subhash Chandra"
      ],
      "year": "2022",
      "venue": "Bulletin of the Polish Academy of Sciences. Technical Sciences"
    },
    {
      "citation_id": "37",
      "title": "An experimental study with imbalanced classification approaches for credit card fraud detection",
      "authors": [
        "Sara Makki",
        "Zainab Assaghir",
        "Yehia Taher",
        "Rafiqul Haque",
        "Mohand-Said Hacid",
        "Hassan Zeineddine"
      ],
      "year": "2019",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "38",
      "title": "Mohammad Gharachorloo and Mohammad Manthouri. 2021. Parsbert: Transformer-based model for persian language understanding",
      "authors": [
        "Marzieh Farahani",
        "Mehrdad Farahani"
      ],
      "venue": "Mohammad Gharachorloo and Mohammad Manthouri. 2021. Parsbert: Transformer-based model for persian language understanding",
      "doi": "10.1007/s11063-021-10528-4"
    },
    {
      "citation_id": "39",
      "title": "Emotion recognition changes in a confinement situation due to covid-19",
      "authors": [
        "Encarnacion Juan C Meléndez",
        "Maria Satorres",
        "Iraida Reyes-Olmedo",
        "Elena Delhom",
        "Yaiza Real",
        "Lora"
      ],
      "year": "2020",
      "venue": "Journal of Environmental Psychology"
    },
    {
      "citation_id": "40",
      "title": "Efficient estimation of word representations in vector space",
      "authors": [
        "Tomas Mikolov",
        "Kai Chen",
        "Greg Corrado",
        "Jeffrey Dean"
      ],
      "year": "2013",
      "venue": "Efficient estimation of word representations in vector space",
      "arxiv": "arXiv:1301.3781"
    },
    {
      "citation_id": "41",
      "title": "Social-emotion recognition in borderline personality disorder. Comprehensive psychiatry",
      "authors": [
        "John Michael J Minzenberg",
        "Sophia Poole",
        "Vinogradov"
      ],
      "year": "2006",
      "venue": "Social-emotion recognition in borderline personality disorder. Comprehensive psychiatry"
    },
    {
      "citation_id": "42",
      "title": "Armanemo: A persian dataset for text-based emotion detection",
      "authors": [
        "Hossein Mirzaee",
        "Javad Peymanfard",
        "Hamid Habibzadeh Moshtaghin",
        "Hossein Zeinali"
      ],
      "year": "2022",
      "venue": "Armanemo: A persian dataset for text-based emotion detection",
      "arxiv": "arXiv:2207.11808"
    },
    {
      "citation_id": "43",
      "title": "Parsivar: A language processing toolkit for Persian",
      "authors": [
        "Salar Mohtaj",
        "Atefeh Behnam Roshanfekr",
        "Habibollah Zafarian",
        "Asghari"
      ],
      "year": "2018",
      "venue": "Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)"
    },
    {
      "citation_id": "44",
      "title": "A review on sentiment analysis and emotion detection from text",
      "authors": [
        "Pansy Nandwani",
        "Rupali Verma"
      ],
      "year": "2021",
      "venue": "Social Network Analysis and Mining"
    },
    {
      "citation_id": "45",
      "title": "Cross-lingual and multilingual speech emotion recognition on english and french",
      "authors": [
        "Michael Neumann"
      ],
      "year": "2018",
      "venue": "2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
    },
    {
      "citation_id": "46",
      "title": "Abstract text summarization: A low resource challenge",
      "authors": [
        "Shantipriya Parida",
        "Petr Motlicek"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)"
    },
    {
      "citation_id": "47",
      "title": "How multilingual is multilingual BERT?",
      "authors": [
        "Telmo Pires",
        "Eva Schlinger",
        "Dan Garrette"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/P19-1493"
    },
    {
      "citation_id": "48",
      "title": "Parallel shared hidden layers autoencoder as a cross-corpus transfer learning approach for unsupervised persian speech emotion recognition",
      "authors": [
        "Yousef Pourebrahim",
        "Farbod Razzazi",
        "Hossein Sameti"
      ],
      "year": "2021",
      "venue": "Signal Processing and Renewable Energy"
    },
    {
      "citation_id": "49",
      "title": "A circumplex model of affect",
      "authors": [
        "Russell James"
      ],
      "year": "1980",
      "venue": "Journal of personality and social psychology"
    },
    {
      "citation_id": "50",
      "title": "EmoPars: A collection of 30K emotionannotated Persian social media texts",
      "authors": [
        "Nazanin Sabri",
        "Reyhane Akhavan",
        "Behnam Bahrak"
      ],
      "year": "2021",
      "venue": "Proceedings of the Student Research Workshop Associated with RANLP 2021"
    },
    {
      "citation_id": "51",
      "title": "Automatic persian text emotion detection using cognitive linguistic and deep learning",
      "authors": [
        "S Seyedeh",
        "Hasan Sadeghi",
        "M Khotanlou",
        "Mahand Rasekh"
      ],
      "year": "2021",
      "venue": "Journal of AI and Data Mining"
    },
    {
      "citation_id": "52",
      "title": "User emotion identification in twitter using specific features: hashtag, emoji, emoticon, and adjective term",
      "authors": [
        "Yuita Arum",
        "Evy Ratnasari",
        "Siti Mutrofin",
        "Agus Zainal Arifin"
      ],
      "year": "2014",
      "venue": "Jurnal Ilmu Komputer dan Informasi"
    },
    {
      "citation_id": "53",
      "title": "Self-supervised ecg representation learning for emotion recognition",
      "authors": [
        "Pritam Sarkar",
        "Ali Etemad"
      ],
      "year": "2020",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "54",
      "title": "Emotion recognition ability as a predictor of well-being during the covid-19 pandemic",
      "authors": [
        "Katja Schlegel",
        "Helene M Von Gugelberg",
        "Lisa Makowski",
        "Danièle Gubler",
        "Stefan Troche"
      ],
      "year": "2021",
      "venue": "Social psychological and personality science"
    },
    {
      "citation_id": "55",
      "title": "Text data augmentation for deep learning",
      "authors": [
        "Connor Shorten",
        "M Taghi",
        "Borko Khoshgoftaar",
        "Furht"
      ],
      "year": "2021",
      "venue": "Journal of big Data"
    },
    {
      "citation_id": "56",
      "title": "An effective approach for emotion detection in multimedia text data using sequence based convolutional neural network",
      "authors": [
        "Kush Shrivastava",
        "Shishir Kumar",
        "Deepak Kumar"
      ],
      "year": "2019",
      "venue": "An effective approach for emotion detection in multimedia text data using sequence based convolutional neural network",
      "doi": "10.1007/s11042-019-07813-9"
    },
    {
      "citation_id": "57",
      "title": "Election prediction with automated speech emotion recognition",
      "authors": [
        "Kaja Prayla Shyry",
        "Kartheek",
        "Kn Rr Aravind"
      ],
      "year": "2020",
      "venue": "2020 4th International Conference on Trends in Electronics and Informatics (ICOEI)(48184)"
    },
    {
      "citation_id": "58",
      "title": "Using book dialogues to extract emotions from texts",
      "authors": [
        "Paweł Skórzewski"
      ],
      "year": "2022",
      "venue": "Language and Technology Conference"
    },
    {
      "citation_id": "59",
      "title": "Opinion mining in social media: Modeling, simulating, and forecasting political opinions in the web",
      "authors": [
        "Pawel Sobkowicz",
        "Michael Kaschesky",
        "Guillaume Bouchard"
      ],
      "year": "2012",
      "venue": "Opinion mining in social media: Modeling, simulating, and forecasting political opinions in the web"
    },
    {
      "citation_id": "60",
      "title": "Emotions, technology, and design",
      "authors": [
        "Sharon Tettegah",
        "Safiya Noble"
      ],
      "year": "2015",
      "venue": "Emotions, technology, and design"
    },
    {
      "citation_id": "61",
      "title": "End-to-end multimodal emotion recognition using deep neural networks",
      "authors": [
        "Panagiotis Tzirakis",
        "George Trigeorgis",
        "A Mihalis",
        "Björn Nicolaou",
        "Stefanos Schuller",
        "Zafeiriou"
      ],
      "year": "2017",
      "venue": "IEEE Journal of selected topics in signal processing"
    },
    {
      "citation_id": "62",
      "title": "Real-world automatic continuous affect recognition from audiovisual signals",
      "authors": [
        "Panagiotis Tzirakis",
        "Stefanos Zafeiriou",
        "Björn Schuller"
      ],
      "year": "2019",
      "venue": "Multimodal Behavior Analysis in the Wild"
    },
    {
      "citation_id": "63",
      "title": "Attention is all you need",
      "authors": [
        "Ashish Vaswani",
        "Noam Shazeer",
        "Niki Parmar",
        "Jakob Uszkoreit",
        "Llion Jones",
        "Aidan Gomez",
        "Łukasz Kaiser",
        "Illia Polosukhin"
      ],
      "year": "2017",
      "venue": "Advances in neural information processing systems"
    },
    {
      "citation_id": "64",
      "title": "Text messaging: A linguistic phenomenon",
      "authors": [
        "Mj Warsi"
      ],
      "year": "2021",
      "venue": "Interdisciplinary Journal of Linguistics"
    },
    {
      "citation_id": "65",
      "title": "Sarcasm detection: A comparative study",
      "authors": [
        "Hamed Yaghoobian",
        "Khaled Hamid R Arabnia",
        "Rasheed"
      ],
      "year": "2021",
      "venue": "Sarcasm detection: A comparative study",
      "arxiv": "arXiv:2107.02276"
    },
    {
      "citation_id": "66",
      "title": "Emotion recognition in persian speech using deep neural networks",
      "authors": [
        "Ali Yazdani",
        "Hossein Simchi",
        "Yasser Shekofteh"
      ],
      "year": "2021",
      "venue": "2021 11th International Conference on Computer Engineering and Knowledge (ICCKE)"
    },
    {
      "citation_id": "67",
      "title": "Improving multi-label emotion classification by integrating both general and domain knowledge",
      "authors": [
        "Wenhao Ying",
        "Rong Xiang",
        "Qin Lu"
      ],
      "year": "2019",
      "venue": "Proceedings of the 5th Workshop on Noisy User-Generated Text"
    },
    {
      "citation_id": "68",
      "title": "Grasp the implicit features: Hierarchical emotion classification based on topic model and svm",
      "authors": [
        "Fan Zhang",
        "Hua Xu",
        "Jiushuo Wang",
        "Xiaomin Sun",
        "Junhui Deng"
      ],
      "year": "2016",
      "venue": "2016 International joint conference on neural networks (IJCNN)"
    },
    {
      "citation_id": "69",
      "title": "A novel evaluation metric for deep learning-based side channel analysis and its extended application to imbalanced data",
      "authors": [
        "Jiajia Zhang",
        "Mengce Zheng",
        "Jiehui Nan",
        "Honggang Hu",
        "Nenghai Yu"
      ],
      "year": "2020",
      "venue": "IACR Transactions on Cryptographic Hardware and Embedded Systems"
    },
    {
      "citation_id": "70",
      "title": "Active learning for word sense disambiguation with methods for addressing the class imbalance problem",
      "authors": [
        "Jingbo Zhu",
        "Eduard Hovy"
      ],
      "year": "2007",
      "venue": "Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)"
    },
    {
      "citation_id": "71",
      "title": "Class weights random forest algorithm for processing class imbalanced medical data",
      "authors": [
        "Min Zhu",
        "Jing Xia",
        "Xiaoqing Jin",
        "Molei Yan",
        "Guolong Cai",
        "Jing Yan",
        "Gangmin Ning"
      ],
      "year": "2018",
      "venue": "IEEE Access"
    }
  ]
}