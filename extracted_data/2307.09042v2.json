{
  "paper_id": "2307.09042v2",
  "title": "Emotional Intelligence Of Large Language Models",
  "published": "2023-07-18T07:49:38Z",
  "authors": [
    "Xuena Wang",
    "Xueting Li",
    "Zi Yin",
    "Yue Wu",
    "Liu Jia"
  ],
  "keywords": [
    "Emotional Intelligence",
    "Emotional Understanding",
    "LLM",
    "human-likeness"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Large Language Models (LLMs) have demonstrated remarkable abilities across numerous disciplines, primarily assessed through tasks in language generation, knowledge utilization, and complex reasoning. However, their alignment with human emotions and values, which is critical for real-world applications, has not been systematically evaluated. Here, we assessed LLMs' Emotional Intelligence (EI), encompassing emotion recognition, interpretation, and understanding, which is necessary for effective communication and social interactions. Specifically, we first developed a novel psychometric assessment focusing on Emotion Understanding (EU), a core component of EI, suitable for both humans and LLMs. This test requires evaluating complex emotions (e.g., surprised, joyful, puzzled, proud) in realistic scenarios (e.g., despite feeling underperformed, John surprisingly achieved a top score). With a reference frame constructed from over 500 adults, we tested a variety of mainstream LLMs. Most achieved above-average EQ scores, with GPT-4 exceeding 89% of human participants with an EQ of 117. Interestingly, a multivariate pattern analysis revealed that some LLMs apparently did not reply on the human-like mechanism to achieve human-level performance, as their representational patterns were qualitatively distinct from humans. In addition, we discussed the impact of factors such as model size, training method, and architecture on LLMs' EQ. In summary, our study presents one of the first psychometric evaluations of the human-like characteristics of LLMs, which may shed light on the future development of LLMs aiming for both high intellectual and emotional intelligence. Project website: https://emotional-2 intelligence.github.io/",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Introduction",
      "text": "Imagine an ancient male making a necklace from a pile of shells as a gift for a female. This endeavor would require at least two distinct types of abilities. First, he would need the foresight to conceptualize that if a hole were punched in each shell and a string threaded through these holes, the shells could form a necklace. Second, he must possess a rudimentary level of empathy, inferring that the female recipient of the necklace would likely experience joy. The former ability is a manifestation of the Systemizing Mechanism  (Baron-Cohen, 2020) , enabling humans to become the scientific and technological masters of our physical world. The latter, on the other hand, is referred to as Emotional Intelligence (EI), which allows us to think about our own and others' thoughts and feelings, thereby aiding us in navigating the social world  (Mayer, Perkins, et al., 2001; Mayer, Salovey, et al., 2001; Salovey & Mayer, 1990) .\n\nIn recent years, Large Language Models (LLMs) have made substantial strides, showcasing their expertise across multiple disciplines including mathematics, coding, visual comprehension, medicine, law, and psychology  (Bubeck et al., 2023) . Their impressive performance in logic-based tasks implies that LLMs, such as GPT-4, might be equipped with the Systemizing Mechanism comparable to human intelligence. Indeed, GPT-4 outperformed 99% of human participants in a modified text-based IQ test, a feat aligning with the elite MENSA level of general intelligence  (King, 2023) .\n\nIn contrast, investigations into the empathy of LLMs are relatively scarce and less systematic. Previous studies have mainly used the Theory of Mind (ToM) task, which measures the ability to understand and interpret others' mental states. LLMs launched before 2022 showed virtually no ability of ToM  (Kosinski, 2023; Sap et al., 2023) , whereas more recent models have shown significant improvement. For example, LLM \"text-davinci-002\" (January 2022) achieved an accuracy of 70%, comparable to that of six-year-old children, while LLM \"text-davinci-003\" (November 2022) reached 93%, on pair with seven-year-old children  (Kosinski, 2023) . Specifically, the most advanced model, GPT-4, attained 100% accuracy with in-context learning  (Moghaddam & Honey, 2023) . While the ToM task provides valuable insights, it is not suitable to serve as a standardized test on EI for two reasons. First, ToM is a heterogeneous concept, spanning from false belief, the understanding that others can hold beliefs about the world that diverge from reality  (Baron-Cohen et al., 1985) , to pragmatic reasoning, the ability to incorporate contextual information and practical considerations when solving problems in real-world situations  (Sperber & Wilson, 2002) . Consequently, the heterogeneous nature of the ToM task may not meet the reliability and validity standards of psychometric tests. Second, the ToM task is simple for a typical human participant in general, rendering it more suitable to serve as a diagnostic tool for EI-related disorders such as the autism spectrum disorder rather than a discriminative test for general population. Consequently, standardized tests on EI, such as Mayer-Salovey-Caruso Emotional Intelligence Test (MSCEIT,  Mayer et al., 2003) , do not include the ToM task.\n\nAccording to EI theories  (Mayer et al., 2016; Mayer & Salovey, 1995; Salovey & Mayer, 1990) , emotion understanding (EU) is a fundamental component of EI, which serves as a subscale in MSCEIT. EU refers to the ability to recognize, interpret, and understand emotions in a social context, which lays the groundwork for effective communication, empathy, and social interaction  (Mayer et al., 2016) . Specifically, the test on EU is suitable for measuring the empathy of LLMs because they do not possess internal emotional states or experiences, and therefore they have to rely solely on accurately understanding and interpreting the social context to create more engaging and empathetic interactions.\n\nIn this study, we first developed a standardized EU test suitable for both humans and LLMs, termed the Situational Evaluation of Complex Emotional Understanding (SECEU). Data from more than 500 young adults were collected to establish a norm for the SECEU. Then, we evaluated a variety of mainstream and popular LLMs, including OpenAI GPT series (GPT-4,  Curie, Babbage, DaVinci, , Claude, LLaMA-based models (Alpaca, Koala, LLaMA, and Vicuna), Fastchat, Pythia-based models (Dolly and Oasst), GLM-based models (ChatGLM), and RWKV (Recurrent Weighted Key-Value) with the SECEU. Finally, we standardized the LLMs' scores against the norm, allowing for direct comparison with humans. We also compared the multivariate response patterns of the LLMs and human participants to compare their representation similarities.",
      "page_start": 3,
      "page_end": 5
    },
    {
      "section_name": "Results",
      "text": "",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "The Development Of A Standardized Test On Eu",
      "text": "The SECEU is designated to measure EU, which comprises 40 items (see https://emotional-intelligence.github.io/ for both English and Chinese versions). Each item describes a scenario set either in a school, family, or social context with twists and turns designed to evoke a mixture of positive and negative emotions (e.g., \"Wang participated in a mathematics competition but felt he had not performed to his full potential. However, when the results were announced, he found that he was in a position of top 10.\"). The scenarios feature a varying number of characters, and emotions can be self-directed, other-directed, or both. For each scenario, four of the most plausible emotions (e.g., surprised, joyful, puzzled, proud) are listed. Participants were asked to evaluate the intensity of each emotion with numbers that were added up to 10 (e.g., 3, 3, 1, 3, indicating a multifaceted emotion response comprising 30% surprise, 30% joy, 10% puzzlement, and 30% pride). Fig.  1  shows exemplars of the SECEU test and the standard scores by averaging answers across the participants. Under the assumption that groups possess collective knowledge of emotion  (Legree et al., 2005) , we adopted a consensus scoring method to standardize the SECEU  (Palmer et al., 2005) . To do this, we administered the SECEU to a large sample of undergraduate and postgraduate students (N = 541; females: 339, males: 202; mean age: 22.33, SD: 2.49, ranging from 17 to 30 years). Then, we calculated the standard score for each emotion of each item by averaging corresponding scores across the participants.\n\nAccordingly, we measured each participant's EU ability on each item by calculating the Euclidean distance between the participant's individual score and the standard score derived from the whole group for each item, with smaller distances indicating better EU ability. This analysis revealed significant variance in individual differences in EU ability (M = 2.79, SD = 0.822, range from 1.40 to 6.29), suggesting that the SECEU is well-suited to serve as a discriminative test for assessing EU in a general population.\n\nTo evaluate the reliability of the SECEU, we assessed the internal consistency of participants' performance (i.e., the Euclidean distance) across the 40 items, and revealed a high reliability of the test (Cronbach's Œ± = 0.94). We further examined the distribution of participants' performance on each item (Fig.  S1 ) and found no evidence of ceiling or floor effects, with mean distances varying from 2.19 to 3.32 and SD ranging from 1.13 to 1.82. In addition, there was no significant sex difference (male: 2.85, female: 2.76, t(539) = 1.34, p = 0.18).\n\nTo evaluate the validity of the SECEU, we invited three experts known for their high EI to take the test. All experts' performance exceeded at least 73% of the population, indicating that the test is effective in differentiating experts from the general population. Specifically, the average score of the three experts exceeded 99% of the whole population tested, further confirming the validity of using the consensus scoring method in standardizing the SECEU.\n\nFinally, we constructed the norm for EU by converting participants' raw scores in the SECEU into standard EQ (Emotional Quotient) scores, designed to follow a normal distribution with the average score set at 100 and standard deviation at 15. In practical terms, an individual with an EQ of 100 possesses an EU ability corresponding to the population average. Meanwhile, an individual with an EQ of 115 outperforms approximately 84% of the population (i.e., one SD above the population average), and an individual with an EQ score of 130 exceeds 97.7% of the population.",
      "page_start": 5,
      "page_end": 7
    },
    {
      "section_name": "The Assessment Of Llms' Eq",
      "text": "We evaluated a variety of mainstream LLMs using the SECEU, and then standardized their scores based on the norm of the human participants for a direct comparison between LLMs and humans. These LLMs included OpenAI GPT series (GPT-4,  Curie, Babbage, DaVinci, , Claude, as well as open-source models such as LLaMA-based models (Alpaca, Koala, LLaMA, and Vicuna), Pythia-based models (Dolly and Oasst), GLMbased models (ChatGLM), and Fastchat. Recurrent Weighted Key-Value (RWKV), which utilizes recurrent neural networks (RNNs) instead of transformers, was also included. Some models, including LLaMA, Fastchat, and RWKV-v4, were unable to complete the test even with the assistance of prompts (Table  1 ). A few LLMs, including DaVinci, Curie, Babbage, text-davinci-001, and text-davinci-002 managed to complete the test with prompts such as Two-shot Chain of Thought (COT) and Step-by-Step prompts (See Supplementary for the prompt engineering). In addition, other models, such as text-davinci-003 was able to complete the test but its performance was significantly improved with prompts. Here, we only included models' best performance to examine how closely they can approach human-level performance under ideal conditions (Table  1 ; see also Table  S1  & S2 ). To directly compare to human participants, the performance of each model was standardized by calculating the Euclidean distance between the model's responses and the standard scores of humans, which was then normalized into an EQ score (Table  1 ). Finally, these LLMs were categorized as either expert (above 115), normal (between 85 and 115), or poor (below 85) based on their EQ scores. EQ scores, with the y-axis indicating the EQ score and the x-axis showing the percentage of total participants. The grey kernel density estimation (KDE) line demonstrates the probability density of the EQ scores. Key points are highlighted with colored square markers for LLMs (e.g., GPT-4's EQ score is 117, marked by the purple square, exceeding 89% of the human participants). For simplicity, here we only present the performance from GPT-4, Vicuna, GPT-3.5-turbo, ChatGLM, and Koala. The results revealed a substantial variation in EU among the LLMs tested (Fig.  2 ).\n\nWithin the OpenAI GPT series, GPT-4 achieved the highest EQ of 117, exceeding 89% of humans. In contrast, DaVinci scored the lowest, with an EQ of 87, only outperforming 18% of humans.\n\nThe LLaMA-based models generally scored lower than the OpenAI GPT series, with Alpaca and Vicuna achieving the highest EQ of 104 and 105, respectively.\n\nConversely, Koala showed the poorest performance, with an EQ score of 83, only surpassing 13% of humans. The base model LLaMA was unable to complete the test.\n\nOther models, such as Oasst (EQ: 107), Dolly (EQ: 98), ChatGLM (EQ: 94), and Claude (EQ: 106), all fell within the normal range.\n\nIn short, the majority of the LLMs tested showed satisfactory EU scores, comparable to those of the average human population. Specifically, GPT-4 reached the expert level of humans.",
      "page_start": 7,
      "page_end": 8
    },
    {
      "section_name": "The Assessment Of Llms' Representational Pattern",
      "text": "The measurement of the LLMs' EQ scores provides an index of their EU ability within the reference frame of humans. A further question is whether they employ human-like mechanisms to evaluate complex emotions in scenarios. The univariate analysis used to compare EQ scores between human participants and LLMs only suggests weak equivalence, as a model could achieve a high EQ score using mechanisms that qualitatively differ from humans. Therefore, to establish strong equivalence between the LLMs and humans, we examined whether they employed similar representations to conduct the test.\n\nOne approach is to use the item-wise correlation analysis  (Izard & Spelke, 2009; Tian et al., 2020)  to compare response patterns between the LLMs and human participants. To do this, we first constructed a multi-item discriminability vector (i.e., an item-wise response pattern) for each participant by using the distance of each item to the standard score, and thus this vector's length corresponded to the number of items (i.e., 40). Then, we created a template of response patterns by averaging the multi-item discriminability patterns across all human participants, along with the distribution of the correlation coefficients between each participant's response pattern and the template (Human-to-Human similarity) to serve as a norm for pattern similarity (M = 0.199, SD = 0.166). Finally, we quantified the similarity in response patterns between the LLMs and humans by calculating the correlation coefficient between the multi-item discriminability vector of each LLM and the human template (LLM-to-Human, Table  1 ). An LLM that has an LLM-to-Human correlation coefficient one SD deviation below the mean of Human-to-Human distribution is considered as employing a qualitatively different mechanism from humans in EU. Surprisingly, despite its lower performance in the SECEU, Koala showed the highest similarity in representational patterns to humans (r = 0.43, p < 0.01, exceeding 93% of human participants) (Fig.  3 ). This suggests that Koala may represent emotions in the same way as humans do, as it performed well on items where humans excelled and struggled on items where humans faced challenges. That is, the discrepancies in understanding emotions between Koala and humans are rather quantitative than qualitative. On the other hand, the representational patterns of models such as Babbage, text-davinci-002, Alpaca, and Vicuna differed qualitatively from humans' representational patterns (Babbage: r = -0.12, > 4%; text-davinci-002: r = -0.04, > 8%;\n\nAlpaca: r = 0.03, > 15%; Vicuna: r = -0.02, > 10%). This suggests that, despite their above-average EQ scores, these models likely employed mechanisms that are qualitatively different from human processes.\n\nGPT-4, the most advanced model to date, showed high similarity in representational pattern (r = 0.28, > 67%). This result implies that GPT-4 may have significantly changed its architecture or implemented novel training methods to align its EU ability more closely to humans. Interestingly, prompts apparently played a critical role in improving representational similarity. With two-shot COT prompts,\n\nDaVinci and text-davinci-003 showed high similarity in representational pattern to humans (Davinci: r = 0.41, p < 0.01, > 91%; text-davinci-003: r = 0.31, p < 0.05, > 73%), higher than that of GPT-4. Note that without prompts, they failed to complete the SECEU test. In contrast, prompts had little effect on GPT-4 and ChatGPT-3.5.",
      "page_start": 9,
      "page_end": 13
    },
    {
      "section_name": "Discussion",
      "text": "Since the debut of ChatGPT, a great number of tasks and benchmarks have been developed to examine the capacities. These empirical evaluations and analyses mainly focus on language generation (e.g., conditional text generation), knowledge utilization (e.g., closed-book and open-book QAs), and complex reasoning (e.g., symbolic and mathematical reasoning)  (Zhao et al., 2023) . However, tests on human alignment of LLMs to human values and needs, a core ability for the broad use of LLMs in the real world, are relatively scarce. Here in this study, we used traditional psychometric methods to develop a valid and reliable test on emotional understanding, the SECEU, to evaluate the EI of LLMs. We found that a majority of the LLMs tested performed satisfactorily in the test, achieving above-average EQ scores, although significant individual differences were present across the LLMs. Critically, some LLMs apparently did not reply on the human-like representation to achieve human-level performance, as their representational patterns diverged significantly from human patterns, suggesting a qualitative difference in the underlying mechanisms. In summary, our study provides the first comprehensive psychometric examination of the emotional intelligence of LLMs, which may shed light on the development of future LLMs that embody high levels of both intellectual and emotional intelligence. Various factors appear to influence the EQ scores of the LLMs (Fig.  4 ). The most conspicuous one is the model size, which is essential to emergent abilities  (Bubeck et al., 2023) , making AI algorithms unprecedently powerful and effective. While the larger models generally scored higher in the test, certain smaller models such as Oasst and Alpaca still managed to achieve satisfactory EQ scores. This suggests that factors beyond the mere size may have a more profound influence on models' EU.\n\nThe effectiveness of various training methods, such as supervised training, reinforcement learning, self-supervised learning, and a combination thereof, likely substantially influences the EQ scores. For example, despite architectural differences (Pythia versus LLaMA), Oasst and Alpaca yielded similar scores in the test, demonstrating the potential of well-implemented fine-tuning techniques. In fact, these enhancements may be achieved through two main avenues. The first involves supervised fine-tuning (SFT), which allows for more structured and targeted fine-tuning, thereby improving models' linguistic ability and their grasp of contextual nuances  (K√∂pf et al., 2023; Taori et al., 2023a) . The other approach employs reinforcement learning from human feedback (RLHF), enabling the models to learn from human insights and thereby fostering more human-like responses. Indeed, there is a giant leap in EU seen between text-davinci-002 (>23%) to text-davinci-003 (>83%), two different versions of the same model with the latter employing RLHF.\n\nAnother influential factor is the model architecture. Models using the Transformer architecture, such as the GPT series and the LLaMA-based models, generally performed well in this test. In contrast, models using RNNs, such as RWKV-v4, failed to complete the test even with the help of various prompts. Besides, within the Transformer architecture, the \"decoder-only\" or causal decoder models (e.g., the GPT series), which generate sequences based solely on a self-attention mechanism  (Brown et al., 2020; Vaswani et al., 2017) , outperformed the \"encoder-decoder\" models (e.g., Fastchat-t5), which incorporate an extra step to interpret input data into meaningful representations  (Devlin et al., 2019; Zheng et al., 2023) .\n\nIn summary, our study provides novel evaluation on the human-like characteristics of LLMs, along with the tests on self-awareness  (Kosinski, 2023)  and affective computing  (Amin et al., 2023) . However, because only a limited number of LLMs were tested in this study (results on more LLMs will be continuously updated in https://emotional-intelligence.github.io/), our findings are biased and inconclusive.\n\nFurther, there are more questions that need to be explored in future studies. First, this study focused solely on the EU ability of the LLMs, while EI is a multi-faceted construct encompassing not only EU but also emotion perception, emotion facilitation, and emotion management (e.g.,  Mayer et al., 2016; Mayer & Salovey, 1995; Salovey & Mayer, 1990) . Therefore, future studies could design scenarios to examine whether LLMs can assist humans in leveraging emotions to facilitate cognitive processes and effectively manage their emotional responses.\n\nSecond, EI requires the integration of various facets to execute complex tasks, which necessitate not only an understanding of emotions, but also the comprehension of thoughts, beliefs, and intentions. Future studies should adopt broader scope assessments, akin to ToM tests, while avoiding their lack of discriminative power.\n\nBesides, with recent advancements, LLMs are now capable of processing multimodal information  (Wang et al., 2023) . Therefore, future studies should investigate how LLMs interpret complex emotions from multimodal inputs, such as text combined with facial expressions or the tone of voice. In short, tests that combine emotions with cognitive factors based on multimodal clues likely furnish a more comprehensive understanding of LLMs' EI, which is critical for LLMs' effective and ethically responsible deployment in real-world scenarios of mental health, interpersonal dynamics, work collaboration, and career achievement (e.g.,  Dulewicz & Higgs, 2000; Hanafi & Noor, 2016; Lea et al., 2019; Mayer et al., 2016; McCleskey, 2014; Warwick & Nettelbeck, 2004) .\n\nFinally, while the factors examined in this study contribute to our standing of LLM's EU, they are largely descriptive and thus do not establish causal relationships.\n\nWith the recent progress of open-source LLMs  (Bai et al., 2022; Chiang et al., 2023; Conover et al., 2023; Geng et al., 2023; K√∂pf et al., 2023; Peng et al., 2023; Taori et al., 2023b; Touvron et al., 2023; Zeng et al., 2022; Zheng et al., 2023) , direct manipulation of the potentially influential factors, such as training approaches and model size, has become plausible. Such manipulations will facilitate the establishment of causal relationships between these factors and models' EI ability, offering valuable insights for the development of future LLMs with better EI.",
      "page_start": 14,
      "page_end": 14
    },
    {
      "section_name": "Methods",
      "text": "",
      "page_start": 14,
      "page_end": 14
    },
    {
      "section_name": "Participants",
      "text": "A total of five hundred and forty-one human participants with valid responses were collected in this study. The participants (N = 541; females: 339, males: 202; mean age:\n\n22.33, SD: 2.49, ranging from 17 to 30 years) were all undergraduate and postgraduate college students in China. Informed consent was obtained prior to the SECEU test and participants were reimbursed after they completed the whole test. To ensure anonymity and data privacy, participants did not input any information that could identify them during the process. This study was approved by the Institutional Review Board at Tsinghua University.\n\nWe also invited three experts to take the SECEU test. Expert 1 is an accomplished Human Resources professional who has over 20 years of experience in navigating human emotions within diverse work environments, strengthening her discernment in emotional intelligence. Expert 2 is a renowned figure in psychometrics and her expertise in creating tests assessing psychological variables lends exceptional rigor to our process. Expert 3 is an associate professor of psychology, whose deep understanding of human emotions, backed by her extensive academic achievements, makes her especially suitable for this test.",
      "page_start": 18,
      "page_end": 18
    },
    {
      "section_name": "Procedure",
      "text": "",
      "page_start": 18,
      "page_end": 18
    },
    {
      "section_name": "The Seceu Test For Human Participants",
      "text": "The online SECEU test was built on the JATOS platform  (Lange et al., 2015)  based on the Jspsych plugin (de  Leeuw et al., 2023) , which was written in the React Framework (https://reactjs.org/). Each item was presented to the participants with a scenario and followed by four emotion options (40 items in total, see https://emotionalintelligence.github.io/ for both English and Chinese versions). Participants were instructed to read the scenario and then allocate a total of 10 points across the four emotion options based on the intensity of each emotion experienced by the person in the scenario. There were no correct or incorrect answers. Participants were encouraged to respond according to their own understanding and interpretation of the scenarios.",
      "page_start": 18,
      "page_end": 19
    },
    {
      "section_name": "The Seceu Test For Llms",
      "text": "A variety of mainstream LLMs, including the OpenAI GPT series (GPT-4, GPT-3.5turbo, Curie, Babbage, DaVinci, text-davinci-001, text-davinci-002, and text-davinci-003), Claude, LLaMA-based models (Alpaca, Koala, LLaMA, and Vicuna), Fastchat, Pythia-based models (Dolly and Oasst), GLM-based models (ChatGLM), and RNNbased models (RWKV), were evaluated by the SECEU test. Given that the majority of these models are primarily trained on English datasets, using the English version of the SECEU provides a more accurate assessment of their performance, allowing for a clearer comparison between their abilities and those of a human. As a result, the English version of SECEU was presented to the LLMs instead of the Chinese version.\n\nThe task was in a direct question-and-answer format. We asked, for example, \"Story: Wang participated in a mathematics competition but felt he had not performed to his full potential. However, when the results were announced, he found that he was in a position of top 10. He would feel: Options: (1) Surprised; (2) Joyful; (3) Puzzled;\n\n(4) Proud. Assign a score to each option based on the story, sum up to 10\". There could be very subtle changes of the direct prompt. For instance, we used \"provide a score for each emotion based on the emotion (sum of four options should be of 10 points)\" for Dolly. There were a set of paraphrases of the direct prompt to get the best performance.\n\nTo decrease the randomness, a constant temperature parameter was set to 0.1 and the top_p parameter was set to 1 across all these models. To dictate the maximum length of the generated text, the max_tokens parameter was set to 512.\n\nBefore being processed by the models, text data underwent several preprocessing steps to normalize it. This normalization process ensures that data fed into the models is in a consistent and appropriate format, enhancing the output's quality. If a model did not provide any meaningful response to an item, the response for this item was predefined as a null vector (0, 0, 0, 0). A few models failed to generate a response for a majority of items  (LLaMA: 40; Fastchat: 31; DaVinci: 40; Curie: 40; Babbage:40; ; text-davinci-002: 28; marked as \"FAILED\" in Table  S1 ). Several models were unable to provide the answer which the summation of the four scores was 10:\n\n(i) Answer vectors signifying null responses, i.e., (0, 0, 0, 0), were preserved as such (Alpaca: 1; ChatGLM: 1).\n\n(ii) For datasets encompassing negative values, an addition operation involving the absolute value of the lowest number was performed across all elements, followed by a subsequent normalization to maintain consistency with the original scale. For instance, an original data vector of (-4, -2, -2, 2) would be adjusted to (0, 2, 2, 6).\n\n(iii) The remaining answer vectors were normalized to achieve a cumulative score of 10. This involved proportionally distributing a score of 10 among the answer vector based on the contribution of each value to the total score on this item.",
      "page_start": 19,
      "page_end": 20
    },
    {
      "section_name": "Llms' Eq",
      "text": "The standard score (a 40 √ó 4 symmetric matrix, see https://emotionalintelligence.github.io/ for the standard score) for each emotion of each item in the SECEU test was calculated by averaging corresponding scores across the human participants. The performance of each LLM was standardized by calculating the Euclidean distance between the model's responses (LLM) and the standard scores of humans (SS) on each item i (from 1 to 40) and then averaged to yield the SECEU score.\n\nLower SECEU scores indicate greater alignment with human standards.\n\nThe SECEU score was then normalized into an EQ score which was designed to follow a normal distribution with the average score set at 100 and the standard deviation at 15. The standardization process involved the following steps: (1) the original SECEU score was subtracted from the mean value of the human norm and divided by its standard deviation, and (2) the resulting value was then multiplied by the new standard deviation (15) and added to the new mean value (100), yielding the EQ score. Thus, the EQ score represents a normalized measure of the LLM's EQ, permitting easier comparison across different models.\n\nLLM ' s EQ = 15 √ó M -SECEU score SD + 100",
      "page_start": 20,
      "page_end": 20
    },
    {
      "section_name": "Llms' Representational Pattern",
      "text": "To establish strong equivalence between the LLMs and humans, we examined whether they employed similar representations to conduct the test. Item-wise correlation analysis  (Izard & Spelke, 2009; Tian et al., 2020)  was applied to compare response patterns between the LLMs and human participants. The human template (a vector with a length of 40, see https://emotional-intelligence.github.io/ for the human pattern template) was generated by averaging the multi-item discriminability patterns across all human participants, where each pattern was constructed based on the distance of each item to the standard score. The multi-item discriminability pattern of a specific LLM was also calculated based on the distance of each item i (from 1 to 40) to the standard scores of humans (SS).\n\nWe calculated the Pearson correlation coefficient between the discriminability pattern of each participant and the human template (Human-to-Human similarity). To avoid the inflation in calculating correlation, the template was constructed excluding the individual whose Human-to-Human correlation coefficient was calculated. The distribution of the Human-to-Human similarity served as a norm for pattern similarity.\n\nThe Pearson correlation coefficient between the discriminability pattern of each LLM and the human template was calculated as the LLM-to-Human similarity.",
      "page_start": 21,
      "page_end": 22
    },
    {
      "section_name": "Llm -To -Human Similarity",
      "text": "Here, X i and Y i represent the item i of the \"Discriminability\" vector and the human template vector, respectively. The length of both vectors is 40. X ÔøΩ and Y ÔøΩ denote the mean of ùëãùëã ùëñùëñ and ùëåùëå ùëñùëñ , respectively. If the LLM-to-Human similarity is less than one SD below the population, such LLM is considered as employing a qualitatively different mechanism from humans in EU.",
      "page_start": 23,
      "page_end": 23
    },
    {
      "section_name": "Prompt Engineering",
      "text": "Prompt engineering-the meticulous development and choice of prompts-plays a pivotal role in the efficacy of LLMs  (Hebenstreit et al., 2023; Hendrycks et al., 2021; Nair et al., 2023; OpenAI, 2023; Shinn et al., 2023) . In essence, prompt engineering refers to the strategy of designing and selecting prompts that can substantially guide and influence the responses of LLMs. The necessity of prompt engineering lies in its potential to enhance the precision and relevance of the responses generated by these models, thereby leading to more effective and reliable outcomes. In the realm of emotional intelligence, prompts serve a crucial function. They provide a direction for the model, enabling it to understand and generate responses that are not just accurate but also emotionally intelligent. Given the nature of emotional intelligence that involves understanding, processing, and managing emotions, prompts can significantly aid the LLMs in identifying the correct context and producing responses that exhibit emotional understanding and empathy.\n\nTo examine the prompts' influence on EU ability, thereby optimizing model outputs, four kinds of prompt engineering techniques (see https://emotionalintelligence.github.io/ for prompts) were applied to the OpenAI GPT series (GPT-3.5turbo, Curie, Babbage, DaVinci, text-davinci-001, text-davinci-002, and text-davinci- To decease the randomness, a constant temperature parameter was set to 0 and the top_p parameter to was set to 0.9 across all these models. To dictates the maximum length of the generated text, the max_tokens parameter was set to 2048. The normalization process was the same as the one without prompts.",
      "page_start": 24,
      "page_end": 24
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: shows exemplars of the SECEU test and the",
      "page": 5
    },
    {
      "caption": "Figure 1: Exemplars of the SECEU test and the standard scores from the population. For the whole",
      "page": 6
    },
    {
      "caption": "Figure 2: LLMs‚Äô EQ. The light-grey histogram represents the distribution of human participants‚Äô",
      "page": 8
    },
    {
      "caption": "Figure 3: The pattern similarity between LLMs and humans. The light-grey histogram represents",
      "page": 12
    },
    {
      "caption": "Figure 3: ). This suggests that Koala may represent emotions",
      "page": 13
    },
    {
      "caption": "Figure 4: The family tree of LLMs. Each node in the tree represents an LLM, whose vertical",
      "page": 15
    },
    {
      "caption": "Figure 4: ). The most",
      "page": 15
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Emotional Intelligence of Large Language Models": "Xuena Wang1, Xueting Li2, Zi Yin1, Yue Wu1, & Liu Jia1*"
        },
        {
          "Emotional Intelligence of Large Language Models": "1\n Department of Psychology & Tsinghua Laboratory of Brain and Intelligence, Tsinghua"
        },
        {
          "Emotional Intelligence of Large Language Models": "University"
        },
        {
          "Emotional Intelligence of Large Language Models": "2 Department of Psychology, Renmin University of China"
        },
        {
          "Emotional Intelligence of Large Language Models": "*Correspondence to: liujiathu@tsinghua.edu.cn (J. Liu)"
        },
        {
          "Emotional Intelligence of Large Language Models": "Abstract"
        },
        {
          "Emotional Intelligence of Large Language Models": "Large  Language  Models \n(LLMs)  have  demonstrated \nremarkable  abilities  across"
        },
        {
          "Emotional Intelligence of Large Language Models": "numerous  disciplines,  primarily  assessed \nthrough \ntasks \nin \nlanguage  generation,"
        },
        {
          "Emotional Intelligence of Large Language Models": "knowledge utilization, and complex reasoning. However, their alignment with human"
        },
        {
          "Emotional Intelligence of Large Language Models": "emotions  and  values,  which \nis  critical  for  real-world  applications,  has  not  been"
        },
        {
          "Emotional Intelligence of Large Language Models": "systematically  evaluated.  Here,  we  assessed  LLMs‚Äô  Emotional  Intelligence  (EI),"
        },
        {
          "Emotional Intelligence of Large Language Models": "encompassing  emotion \nrecognition, \ninterpretation,  and  understanding,  which \nis"
        },
        {
          "Emotional Intelligence of Large Language Models": "necessary  for  effective  communication  and  social  interactions.  Specifically,  we  first"
        },
        {
          "Emotional Intelligence of Large Language Models": "developed a novel psychometric assessment focusing on Emotion Understanding (EU),"
        },
        {
          "Emotional Intelligence of Large Language Models": "a  core  component  of  EI,  suitable  for  both  humans  and  LLMs.  This  test  requires"
        },
        {
          "Emotional Intelligence of Large Language Models": "evaluating  complex  emotions  (e.g.,  surprised, \njoyful,  puzzled,  proud) \nin  realistic"
        },
        {
          "Emotional Intelligence of Large Language Models": "scenarios (e.g., despite feeling underperformed, John surprisingly achieved a top score)."
        },
        {
          "Emotional Intelligence of Large Language Models": "With  a  reference  frame  constructed  from  over  500  adults,  we  tested  a  variety  of"
        },
        {
          "Emotional Intelligence of Large Language Models": "mainstream LLMs. Most achieved above-average EQ scores, with GPT-4 exceeding 89%"
        },
        {
          "Emotional Intelligence of Large Language Models": "of human participants with an EQ of 117. Interestingly, a multivariate pattern analysis"
        },
        {
          "Emotional Intelligence of Large Language Models": "revealed that some LLMs apparently  did not reply on the human-like mechanism to"
        },
        {
          "Emotional Intelligence of Large Language Models": "achieve human-level performance, as their representational patterns were qualitatively"
        },
        {
          "Emotional Intelligence of Large Language Models": "distinct from humans. In addition, we discussed the impact of factors such as model"
        },
        {
          "Emotional Intelligence of Large Language Models": "size, training method, and architecture on LLMs‚Äô EQ. In summary, our study presents"
        },
        {
          "Emotional Intelligence of Large Language Models": "one of the first psychometric evaluations of the human-like characteristics of LLMs,"
        },
        {
          "Emotional Intelligence of Large Language Models": "which  may  shed  light  on  the  future  development  of  LLMs  aiming  for  both  high"
        },
        {
          "Emotional Intelligence of Large Language Models": "intellectual \nand \nemotional \nintelligence. \nProject \nwebsite: \nhttps://emotional-"
        },
        {
          "Emotional Intelligence of Large Language Models": "1"
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "intelligence.github.io/": "K\neywords: Emotional Intelligence, Emotional Understanding, LLM, human-likeness"
        },
        {
          "intelligence.github.io/": "2"
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Introduction": "Imagine an ancient male making a necklace from a pile of shells as a gift for a female."
        },
        {
          "Introduction": "This endeavor would require at least two distinct types of abilities. First, he would need"
        },
        {
          "Introduction": "the foresight to  conceptualize  that if  a hole were  punched in each shell and  a string"
        },
        {
          "Introduction": "threaded through these holes, the shells could form a necklace. Second, he must possess"
        },
        {
          "Introduction": "a  rudimentary  level  of  empathy,  inferring  that  the  female  recipient  of  the  necklace"
        },
        {
          "Introduction": "would likely experience joy. The former ability is a manifestation of the Systemizing"
        },
        {
          "Introduction": "Mechanism  (Baron-Cohen,  2020),  enabling  humans  to  become  the  scientific  and"
        },
        {
          "Introduction": "technological masters of our physical world. The latter, on the other hand, is referred to"
        },
        {
          "Introduction": "as  Emotional  Intelligence  (EI),  which  allows  us  to  think  about  our  own  and  others‚Äô"
        },
        {
          "Introduction": "thoughts and feelings, thereby aiding us in navigating the social world (Mayer, Perkins,"
        },
        {
          "Introduction": "et al., 2001; Mayer, Salovey, et al., 2001; Salovey & Mayer, 1990)."
        }
      ],
      "page": 3
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "2023). While the ToM task provides valuable insights, it is not suitable to serve as a": ""
        },
        {
          "2023). While the ToM task provides valuable insights, it is not suitable to serve as a": "from false belief, the understanding that others can hold beliefs about the world that"
        },
        {
          "2023). While the ToM task provides valuable insights, it is not suitable to serve as a": "diverge from reality (Baron-Cohen et al., 1985), to pragmatic reasoning, the ability to"
        },
        {
          "2023). While the ToM task provides valuable insights, it is not suitable to serve as a": "incorporate contextual information and practical considerations when solving problems"
        },
        {
          "2023). While the ToM task provides valuable insights, it is not suitable to serve as a": "in  real-world  situations  (Sperber  & Wilson,  2002).  Consequently,  the  heterogeneous"
        },
        {
          "2023). While the ToM task provides valuable insights, it is not suitable to serve as a": "the  ToM"
        },
        {
          "2023). While the ToM task provides valuable insights, it is not suitable to serve as a": "psychometric tests. Second, the ToM task is simple for a typical human participant in"
        },
        {
          "2023). While the ToM task provides valuable insights, it is not suitable to serve as a": "general, rendering it more suitable to serve as a diagnostic tool for EI-related disorders"
        },
        {
          "2023). While the ToM task provides valuable insights, it is not suitable to serve as a": "such  as  the  autism  spectrum  disorder  rather  than  a  discriminative  test  for  general"
        },
        {
          "2023). While the ToM task provides valuable insights, it is not suitable to serve as a": "population.  Consequently,  standardized  tests  on  EI,  such  as  Mayer-Salovey-Caruso"
        },
        {
          "2023). While the ToM task provides valuable insights, it is not suitable to serve as a": "Emotional Intelligence Test (MSCEIT, Mayer et al., 2003), do not include the ToM task."
        },
        {
          "2023). While the ToM task provides valuable insights, it is not suitable to serve as a": "According to EI theories (Mayer et al., 2016; Mayer & Salovey, 1995; Salovey &"
        },
        {
          "2023). While the ToM task provides valuable insights, it is not suitable to serve as a": "Mayer, 1990), emotion understanding (EU) is a fundamental component of EI, which"
        },
        {
          "2023). While the ToM task provides valuable insights, it is not suitable to serve as a": "serves as a subscale in MSCEIT. EU refers to the ability to recognize, interpret, and"
        },
        {
          "2023). While the ToM task provides valuable insights, it is not suitable to serve as a": "understand  emotions  in  a  social  context,  which  lays  the  groundwork  for  effective"
        },
        {
          "2023). While the ToM task provides valuable insights, it is not suitable to serve as a": "communication, empathy, and social interaction(Mayer et al., 2016). Specifically, the"
        },
        {
          "2023). While the ToM task provides valuable insights, it is not suitable to serve as a": "test on EU is suitable for measuring the empathy of LLMs because they do not possess"
        },
        {
          "2023). While the ToM task provides valuable insights, it is not suitable to serve as a": "internal  emotional  states  or  experiences,  and  therefore  they  have  to  rely  solely  on"
        },
        {
          "2023). While the ToM task provides valuable insights, it is not suitable to serve as a": "accurately understanding and interpreting the social context to create more engaging"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "SECEU.  Finally,  we  standardized  the  LLMs‚Äô  scores  against  the  norm,  allowing  for": "direct comparison with humans. We also compared the multivariate response patterns"
        },
        {
          "SECEU.  Finally,  we  standardized  the  LLMs‚Äô  scores  against  the  norm,  allowing  for": ""
        },
        {
          "SECEU.  Finally,  we  standardized  the  LLMs‚Äô  scores  against  the  norm,  allowing  for": "Results"
        },
        {
          "SECEU.  Finally,  we  standardized  the  LLMs‚Äô  scores  against  the  norm,  allowing  for": "The development of a standardized test on EU"
        },
        {
          "SECEU.  Finally,  we  standardized  the  LLMs‚Äô  scores  against  the  norm,  allowing  for": "The  SECEU"
        },
        {
          "SECEU.  Finally,  we  standardized  the  LLMs‚Äô  scores  against  the  norm,  allowing  for": "https://emotional-intelligence.github.io/ for both English and Chinese versions). Each"
        },
        {
          "SECEU.  Finally,  we  standardized  the  LLMs‚Äô  scores  against  the  norm,  allowing  for": ""
        },
        {
          "SECEU.  Finally,  we  standardized  the  LLMs‚Äô  scores  against  the  norm,  allowing  for": "turns  designed  to  evoke  a  mixture  of  positive  and  negative  emotions  (e.g.,  ‚ÄúWang"
        },
        {
          "SECEU.  Finally,  we  standardized  the  LLMs‚Äô  scores  against  the  norm,  allowing  for": "participated  in  a  mathematics  competition  but  felt  he  had  not  performed  to  his  full"
        },
        {
          "SECEU.  Finally,  we  standardized  the  LLMs‚Äô  scores  against  the  norm,  allowing  for": "potential. However, when the results were announced, he found that he was in a position"
        },
        {
          "SECEU.  Finally,  we  standardized  the  LLMs‚Äô  scores  against  the  norm,  allowing  for": "of top 10.‚Äù). The scenarios feature a varying number of characters, and emotions can"
        },
        {
          "SECEU.  Finally,  we  standardized  the  LLMs‚Äô  scores  against  the  norm,  allowing  for": ""
        },
        {
          "SECEU.  Finally,  we  standardized  the  LLMs‚Äô  scores  against  the  norm,  allowing  for": ""
        },
        {
          "SECEU.  Finally,  we  standardized  the  LLMs‚Äô  scores  against  the  norm,  allowing  for": ""
        },
        {
          "SECEU.  Finally,  we  standardized  the  LLMs‚Äô  scores  against  the  norm,  allowing  for": ""
        },
        {
          "SECEU.  Finally,  we  standardized  the  LLMs‚Äô  scores  against  the  norm,  allowing  for": ""
        },
        {
          "SECEU.  Finally,  we  standardized  the  LLMs‚Äô  scores  against  the  norm,  allowing  for": ""
        },
        {
          "SECEU.  Finally,  we  standardized  the  LLMs‚Äô  scores  against  the  norm,  allowing  for": "5"
        }
      ],
      "page": 5
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Figure 1: Exemplars of the SECEU test and the standard scores from the population. For the whole": "set of the test, see: https://emotional-intelligence.github.io/"
        },
        {
          "Figure 1: Exemplars of the SECEU test and the standard scores from the population. For the whole": "Under"
        },
        {
          "Figure 1: Exemplars of the SECEU test and the standard scores from the population. For the whole": "(Legree et al., 2005), we adopted a consensus scoring method to standardize the SECEU"
        },
        {
          "Figure 1: Exemplars of the SECEU test and the standard scores from the population. For the whole": "(Palmer  et  al.,  2005). To  do  this,  we  administered  the  SECEU  to  a  large  sample  of"
        },
        {
          "Figure 1: Exemplars of the SECEU test and the standard scores from the population. For the whole": "undergraduate and postgraduate students (N = 541; females: 339, males: 202; mean age:"
        },
        {
          "Figure 1: Exemplars of the SECEU test and the standard scores from the population. For the whole": "22.33, SD: 2.49, ranging from 17 to 30 years). Then, we calculated the standard score"
        },
        {
          "Figure 1: Exemplars of the SECEU test and the standard scores from the population. For the whole": "for each emotion of each item by averaging corresponding scores across the participants."
        },
        {
          "Figure 1: Exemplars of the SECEU test and the standard scores from the population. For the whole": "Accordingly, we measured each participant‚Äôs EU ability on each item by calculating the"
        },
        {
          "Figure 1: Exemplars of the SECEU test and the standard scores from the population. For the whole": "Euclidean distance between the  participant‚Äôs  individual  score  and the standard score"
        },
        {
          "Figure 1: Exemplars of the SECEU test and the standard scores from the population. For the whole": "derived from the whole group for each item, with smaller distances indicating better"
        },
        {
          "Figure 1: Exemplars of the SECEU test and the standard scores from the population. For the whole": ""
        },
        {
          "Figure 1: Exemplars of the SECEU test and the standard scores from the population. For the whole": ""
        },
        {
          "Figure 1: Exemplars of the SECEU test and the standard scores from the population. For the whole": ""
        },
        {
          "Figure 1: Exemplars of the SECEU test and the standard scores from the population. For the whole": ""
        },
        {
          "Figure 1: Exemplars of the SECEU test and the standard scores from the population. For the whole": ""
        },
        {
          "Figure 1: Exemplars of the SECEU test and the standard scores from the population. For the whole": ""
        }
      ],
      "page": 6
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "revealed a high reliability of the test (Cronbach‚Äôs Œ± = 0.94). We further examined the": "distribution of participants‚Äô performance on each item (Fig. S1) and found no evidence"
        },
        {
          "revealed a high reliability of the test (Cronbach‚Äôs Œ± = 0.94). We further examined the": "of  ceiling  or  floor  effects,  with  mean  distances  varying  from  2.19  to  3.32  and  SD"
        },
        {
          "revealed a high reliability of the test (Cronbach‚Äôs Œ± = 0.94). We further examined the": "ranging from 1.13 to 1.82. In addition, there was no significant sex difference (male:"
        },
        {
          "revealed a high reliability of the test (Cronbach‚Äôs Œ± = 0.94). We further examined the": "2.85, female: 2.76, t(539) = 1.34, p = 0.18)."
        }
      ],
      "page": 7
    },
    {
      "caption": "Table 1: ). A few LLMs, including",
      "data": [
        {
          "included.": "Some  models,"
        },
        {
          "included.": ""
        },
        {
          "included.": ""
        },
        {
          "included.": ""
        },
        {
          "included.": "prompts (See Supplementary for the prompt engineering). In addition, other models,"
        },
        {
          "included.": "such  as  text-davinci-003  was  able  to  complete  the  test  but  its  performance  was"
        },
        {
          "included.": ""
        },
        {
          "included.": ""
        },
        {
          "included.": ""
        },
        {
          "included.": ""
        },
        {
          "included.": ""
        },
        {
          "included.": ""
        },
        {
          "included.": "expert (above 115), normal (between 85 and 115), or poor (below 85) based on their"
        }
      ],
      "page": 8
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "participants. The grey kernel density estimation (KDE) line demonstrates the probability density of": "the EQ scores. Key points are highlighted with colored square markers for LLMs (e.g., GPT-4‚Äôs EQ"
        },
        {
          "participants. The grey kernel density estimation (KDE) line demonstrates the probability density of": "score is 117, marked by the purple square, exceeding 89% of the human participants). For simplicity,"
        },
        {
          "participants. The grey kernel density estimation (KDE) line demonstrates the probability density of": "here we only present the performance from GPT-4, Vicuna, GPT-3.5-turbo, ChatGLM, and Koala."
        },
        {
          "participants. The grey kernel density estimation (KDE) line demonstrates the probability density of": "9"
        }
      ],
      "page": 9
    },
    {
      "caption": "Table 1: LLMs‚Äô EQ, representational patterns, and properties",
      "data": [
        {
          "Table 1: LLMs‚Äô EQ, representational patterns, and properties": ""
        },
        {
          "Table 1: LLMs‚Äô EQ, representational patterns, and properties": "Based"
        },
        {
          "Table 1: LLMs‚Äô EQ, representational patterns, and properties": ""
        },
        {
          "Table 1: LLMs‚Äô EQ, representational patterns, and properties": "OpenAI GPT series"
        },
        {
          "Table 1: LLMs‚Äô EQ, representational patterns, and properties": ""
        },
        {
          "Table 1: LLMs‚Äô EQ, representational patterns, and properties": ""
        },
        {
          "Table 1: LLMs‚Äô EQ, representational patterns, and properties": ""
        },
        {
          "Table 1: LLMs‚Äô EQ, representational patterns, and properties": ""
        },
        {
          "Table 1: LLMs‚Äô EQ, representational patterns, and properties": ""
        },
        {
          "Table 1: LLMs‚Äô EQ, representational patterns, and properties": ""
        },
        {
          "Table 1: LLMs‚Äô EQ, representational patterns, and properties": ""
        },
        {
          "Table 1: LLMs‚Äô EQ, representational patterns, and properties": ""
        },
        {
          "Table 1: LLMs‚Äô EQ, representational patterns, and properties": "LLaMA"
        },
        {
          "Table 1: LLMs‚Äô EQ, representational patterns, and properties": ""
        },
        {
          "Table 1: LLMs‚Äô EQ, representational patterns, and properties": ""
        },
        {
          "Table 1: LLMs‚Äô EQ, representational patterns, and properties": ""
        },
        {
          "Table 1: LLMs‚Äô EQ, representational patterns, and properties": ""
        },
        {
          "Table 1: LLMs‚Äô EQ, representational patterns, and properties": "Flan-t5"
        },
        {
          "Table 1: LLMs‚Äô EQ, representational patterns, and properties": ""
        },
        {
          "Table 1: LLMs‚Äô EQ, representational patterns, and properties": "Pythia"
        },
        {
          "Table 1: LLMs‚Äô EQ, representational patterns, and properties": ""
        },
        {
          "Table 1: LLMs‚Äô EQ, representational patterns, and properties": ""
        },
        {
          "Table 1: LLMs‚Äô EQ, representational patterns, and properties": "GLM"
        },
        {
          "Table 1: LLMs‚Äô EQ, representational patterns, and properties": ""
        },
        {
          "Table 1: LLMs‚Äô EQ, representational patterns, and properties": "RWKV"
        },
        {
          "Table 1: LLMs‚Äô EQ, representational patterns, and properties": ""
        },
        {
          "Table 1: LLMs‚Äô EQ, representational patterns, and properties": "Claude"
        },
        {
          "Table 1: LLMs‚Äô EQ, representational patterns, and properties": ""
        }
      ],
      "page": 10
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Time: The launch time in the format YYYY/MM/DD.": "SFT: Supervised fine-tune; RLHF: Reinforcement learning from human feedback; ‚àö: yes; √ó: no."
        },
        {
          "Time: The launch time in the format YYYY/MM/DD.": ""
        },
        {
          "Time: The launch time in the format YYYY/MM/DD.": "Within the OpenAI GPT series, GPT-4 achieved the highest EQ of 117, exceeding 89%"
        },
        {
          "Time: The launch time in the format YYYY/MM/DD.": "of  humans. \nIn  contrast,  DaVinci  scored"
        },
        {
          "Time: The launch time in the format YYYY/MM/DD.": "outperforming 18% of humans."
        },
        {
          "Time: The launch time in the format YYYY/MM/DD.": ""
        },
        {
          "Time: The launch time in the format YYYY/MM/DD.": "with  Alpaca  and  Vicuna  achieving  the  highest  EQ  of  104  and  105,  respectively."
        },
        {
          "Time: The launch time in the format YYYY/MM/DD.": "Conversely,  Koala  showed  the  poorest  performance,  with  an  EQ  score  of  83,  only"
        },
        {
          "Time: The launch time in the format YYYY/MM/DD.": "surpassing 13% of humans. The base model LLaMA was unable to complete the test."
        },
        {
          "Time: The launch time in the format YYYY/MM/DD.": "Other  models,  such  as  Oasst  (EQ:  107),  Dolly  (EQ:  98),  ChatGLM  (EQ:  94),  and"
        },
        {
          "Time: The launch time in the format YYYY/MM/DD.": "Claude (EQ: 106), all fell within the normal range."
        },
        {
          "Time: The launch time in the format YYYY/MM/DD.": "In  short, \nthe  majority  of \nthe  LLMs"
        },
        {
          "Time: The launch time in the format YYYY/MM/DD.": "comparable to those of the average human population. Specifically, GPT-4 reached the"
        },
        {
          "Time: The launch time in the format YYYY/MM/DD.": "expert level of humans."
        },
        {
          "Time: The launch time in the format YYYY/MM/DD.": "The assessment of LLMs‚Äô representational pattern"
        },
        {
          "Time: The launch time in the format YYYY/MM/DD.": "The measurement of the LLMs‚Äô EQ scores provides an index of their EU ability within"
        },
        {
          "Time: The launch time in the format YYYY/MM/DD.": "the reference frame of humans. A further question is whether they employ human-like"
        },
        {
          "Time: The launch time in the format YYYY/MM/DD.": ""
        },
        {
          "Time: The launch time in the format YYYY/MM/DD.": ""
        },
        {
          "Time: The launch time in the format YYYY/MM/DD.": "equivalence,  as  a  model  could  achieve  a  high  EQ  score  using  mechanisms  that"
        },
        {
          "Time: The launch time in the format YYYY/MM/DD.": "qualitatively differ from humans. Therefore, to establish strong equivalence between"
        },
        {
          "Time: The launch time in the format YYYY/MM/DD.": "the LLMs and humans, we examined whether they employed similar representations to"
        },
        {
          "Time: The launch time in the format YYYY/MM/DD.": "conduct the test."
        },
        {
          "Time: The launch time in the format YYYY/MM/DD.": ""
        },
        {
          "Time: The launch time in the format YYYY/MM/DD.": "Tian  et  al.,  2020) \nto  compare  response  patterns  between"
        },
        {
          "Time: The launch time in the format YYYY/MM/DD.": "11"
        }
      ],
      "page": 11
    },
    {
      "caption": "Table 1: ). An LLM that has an LLM-to-Human correlation coefficient one SD deviation below",
      "data": [
        {
          "participants. To do this, we first constructed a multi-item discriminability vector (i.e.,": "an item-wise response pattern) for each participant by using the distance of each item"
        },
        {
          "participants. To do this, we first constructed a multi-item discriminability vector (i.e.,": ""
        },
        {
          "participants. To do this, we first constructed a multi-item discriminability vector (i.e.,": ""
        },
        {
          "participants. To do this, we first constructed a multi-item discriminability vector (i.e.,": "discriminability patterns across all human participants, along with the distribution of"
        },
        {
          "participants. To do this, we first constructed a multi-item discriminability vector (i.e.,": "the correlation coefficients between each participant‚Äôs response pattern and the template"
        },
        {
          "participants. To do this, we first constructed a multi-item discriminability vector (i.e.,": ""
        },
        {
          "participants. To do this, we first constructed a multi-item discriminability vector (i.e.,": ""
        },
        {
          "participants. To do this, we first constructed a multi-item discriminability vector (i.e.,": "and  humans  by  calculating"
        },
        {
          "participants. To do this, we first constructed a multi-item discriminability vector (i.e.,": ""
        },
        {
          "participants. To do this, we first constructed a multi-item discriminability vector (i.e.,": ""
        },
        {
          "participants. To do this, we first constructed a multi-item discriminability vector (i.e.,": ""
        },
        {
          "participants. To do this, we first constructed a multi-item discriminability vector (i.e.,": "different mechanism from humans in EU."
        }
      ],
      "page": 12
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "demonstrates \nthe  probability  density  of": "highlighted  with  colored  square  markers  for  LLMs.  For  simplicity,  here  we  only  present  the",
          "the  Pearson  correlation  coefficient.  Key  points  are": ""
        },
        {
          "demonstrates \nthe  probability  density  of": "performance from GPT-4, Vicuna, GPT-3.5-turbo, ChatGLM, and Koala. **: p < 0.01.",
          "the  Pearson  correlation  coefficient.  Key  points  are": ""
        },
        {
          "demonstrates \nthe  probability  density  of": "",
          "the  Pearson  correlation  coefficient.  Key  points  are": "Surprisingly,  despite  its  lower  performance  in  the  SECEU,  Koala  showed  the"
        },
        {
          "demonstrates \nthe  probability  density  of": "highest similarity in representational patterns to humans (r = 0.43, p < 0.01, exceeding",
          "the  Pearson  correlation  coefficient.  Key  points  are": ""
        },
        {
          "demonstrates \nthe  probability  density  of": "93% of human participants) (Fig. 3). This suggests that Koala may represent emotions",
          "the  Pearson  correlation  coefficient.  Key  points  are": ""
        },
        {
          "demonstrates \nthe  probability  density  of": "",
          "the  Pearson  correlation  coefficient.  Key  points  are": "in the same way as humans do, as it performed well on items where humans excelled"
        },
        {
          "demonstrates \nthe  probability  density  of": "",
          "the  Pearson  correlation  coefficient.  Key  points  are": "and struggled on items where humans faced challenges. That is, the discrepancies in"
        },
        {
          "demonstrates \nthe  probability  density  of": "understanding  emotions  between  Koala  and  humans  are  rather  quantitative",
          "the  Pearson  correlation  coefficient.  Key  points  are": "than"
        },
        {
          "demonstrates \nthe  probability  density  of": "",
          "the  Pearson  correlation  coefficient.  Key  points  are": "qualitative. On the other hand, the representational patterns of models such as Babbage,"
        },
        {
          "demonstrates \nthe  probability  density  of": "text-davinci-002,  Alpaca, \nand \nVicuna \ndiffered \nqualitatively \nfrom",
          "the  Pearson  correlation  coefficient.  Key  points  are": "humans‚Äô"
        },
        {
          "demonstrates \nthe  probability  density  of": "representational patterns (Babbage: r = -0.12, > 4%; text-davinci-002: r = -0.04, > 8%;",
          "the  Pearson  correlation  coefficient.  Key  points  are": ""
        },
        {
          "demonstrates \nthe  probability  density  of": "Alpaca: r = 0.03, > 15%; Vicuna: r = -0.02, > 10%). This suggests that, despite their",
          "the  Pearson  correlation  coefficient.  Key  points  are": ""
        },
        {
          "demonstrates \nthe  probability  density  of": "above-average  EQ \nscores, \nthese  models \nlikely  employed  mechanisms",
          "the  Pearson  correlation  coefficient.  Key  points  are": "that  are"
        },
        {
          "demonstrates \nthe  probability  density  of": "qualitatively different from human processes.",
          "the  Pearson  correlation  coefficient.  Key  points  are": ""
        },
        {
          "demonstrates \nthe  probability  density  of": "GPT-4, \nthe  most \nadvanced  model \nto \ndate, \nshowed \nhigh",
          "the  Pearson  correlation  coefficient.  Key  points  are": "similarity \nin"
        },
        {
          "demonstrates \nthe  probability  density  of": "representational pattern (r = 0.28,  > 67%). This  result implies  that GPT-4 may  have",
          "the  Pearson  correlation  coefficient.  Key  points  are": ""
        },
        {
          "demonstrates \nthe  probability  density  of": "significantly changed its architecture or implemented novel training methods to align",
          "the  Pearson  correlation  coefficient.  Key  points  are": ""
        },
        {
          "demonstrates \nthe  probability  density  of": "its  EU  ability  more  closely  to  humans.  Interestingly,  prompts  apparently  played  a",
          "the  Pearson  correlation  coefficient.  Key  points  are": ""
        },
        {
          "demonstrates \nthe  probability  density  of": "critical  role  in  improving  representational  similarity.  With  two-shot  COT  prompts,",
          "the  Pearson  correlation  coefficient.  Key  points  are": ""
        },
        {
          "demonstrates \nthe  probability  density  of": "DaVinci  and  text-davinci-003  showed  high  similarity  in  representational  pattern  to",
          "the  Pearson  correlation  coefficient.  Key  points  are": ""
        },
        {
          "demonstrates \nthe  probability  density  of": "humans (Davinci: r = 0.41, p < 0.01, > 91%; text-davinci-003: r = 0.31, p < 0.05, >",
          "the  Pearson  correlation  coefficient.  Key  points  are": ""
        },
        {
          "demonstrates \nthe  probability  density  of": "73%), higher than that of GPT-4. Note that without prompts, they failed to complete the",
          "the  Pearson  correlation  coefficient.  Key  points  are": ""
        },
        {
          "demonstrates \nthe  probability  density  of": "SECEU test. In contrast, prompts had little effect on GPT-4 and ChatGPT-3.5.",
          "the  Pearson  correlation  coefficient.  Key  points  are": ""
        },
        {
          "demonstrates \nthe  probability  density  of": "Discussion",
          "the  Pearson  correlation  coefficient.  Key  points  are": ""
        },
        {
          "demonstrates \nthe  probability  density  of": "13",
          "the  Pearson  correlation  coefficient.  Key  points  are": ""
        }
      ],
      "page": 13
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Since  the  debut  of  ChatGPT,  a  great  number  of  tasks  and  benchmarks  have  been": "developed to examine the capacities. These empirical evaluations and analyses mainly"
        },
        {
          "Since  the  debut  of  ChatGPT,  a  great  number  of  tasks  and  benchmarks  have  been": "focus on language generation (e.g., conditional text generation), knowledge utilization"
        },
        {
          "Since  the  debut  of  ChatGPT,  a  great  number  of  tasks  and  benchmarks  have  been": "(e.g.,  closed-book  and  open-book  QAs),  and  complex  reasoning  (e.g.,  symbolic  and"
        },
        {
          "Since  the  debut  of  ChatGPT,  a  great  number  of  tasks  and  benchmarks  have  been": "mathematical  reasoning)  (Zhao  et  al., 2023). However, tests on human  alignment  of"
        },
        {
          "Since  the  debut  of  ChatGPT,  a  great  number  of  tasks  and  benchmarks  have  been": "LLMs to human values and needs, a core ability for the broad use of LLMs in the real"
        },
        {
          "Since  the  debut  of  ChatGPT,  a  great  number  of  tasks  and  benchmarks  have  been": "world,  are  relatively  scarce.  Here  in  this  study,  we  used  traditional  psychometric"
        },
        {
          "Since  the  debut  of  ChatGPT,  a  great  number  of  tasks  and  benchmarks  have  been": "methods to develop a valid and reliable test on emotional understanding, the SECEU,"
        },
        {
          "Since  the  debut  of  ChatGPT,  a  great  number  of  tasks  and  benchmarks  have  been": "to evaluate the EI of LLMs. We found that a majority of the LLMs tested performed"
        },
        {
          "Since  the  debut  of  ChatGPT,  a  great  number  of  tasks  and  benchmarks  have  been": "satisfactorily  in  the  test,  achieving  above-average  EQ  scores,  although  significant"
        },
        {
          "Since  the  debut  of  ChatGPT,  a  great  number  of  tasks  and  benchmarks  have  been": "individual differences were present across the LLMs. Critically, some LLMs apparently"
        },
        {
          "Since  the  debut  of  ChatGPT,  a  great  number  of  tasks  and  benchmarks  have  been": "did not reply on the human-like representation to achieve human-level performance, as"
        },
        {
          "Since  the  debut  of  ChatGPT,  a  great  number  of  tasks  and  benchmarks  have  been": "their representational patterns diverged significantly from human patterns, suggesting"
        },
        {
          "Since  the  debut  of  ChatGPT,  a  great  number  of  tasks  and  benchmarks  have  been": "a qualitative difference in the underlying mechanisms. In summary, our study provides"
        },
        {
          "Since  the  debut  of  ChatGPT,  a  great  number  of  tasks  and  benchmarks  have  been": "the  first  comprehensive  psychometric  examination  of  the  emotional  intelligence  of"
        },
        {
          "Since  the  debut  of  ChatGPT,  a  great  number  of  tasks  and  benchmarks  have  been": "LLMs, which may shed  light on the development of future LLMs that embody high"
        },
        {
          "Since  the  debut  of  ChatGPT,  a  great  number  of  tasks  and  benchmarks  have  been": "levels of both intellectual and emotional intelligence."
        }
      ],
      "page": 14
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Figure  4:  The  family  tree  of  LLMs.  Each  node  in  the  tree  represents  an  LLM,  whose  vertical": "position  along  the  x-axis  indicates  the  launch  time.  The  size  of  each  node  corresponds  to  the"
        },
        {
          "Figure  4:  The  family  tree  of  LLMs.  Each  node  in  the  tree  represents  an  LLM,  whose  vertical": "parameter size of the LLM. Note that the size of GPT-4 and Claude was estimated based on publicly"
        },
        {
          "Figure  4:  The  family  tree  of  LLMs.  Each  node  in  the  tree  represents  an  LLM,  whose  vertical": "available information. Color donates the EQ scores, with red color for higher scores and blue color"
        },
        {
          "Figure  4:  The  family  tree  of  LLMs.  Each  node  in  the  tree  represents  an  LLM,  whose  vertical": "for lower scores. Note that white color shows that models failed to conduct the SECEU. The color"
        },
        {
          "Figure  4:  The  family  tree  of  LLMs.  Each  node  in  the  tree  represents  an  LLM,  whose  vertical": "of  the  branches  distinguishes  between  open-source  (light  gray)  and  closed-source  (dark  gray)"
        },
        {
          "Figure  4:  The  family  tree  of  LLMs.  Each  node  in  the  tree  represents  an  LLM,  whose  vertical": "models."
        }
      ],
      "page": 15
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "beyond the mere size may have a more profound influence on models‚Äô EU.": "The  effectiveness  of  various"
        },
        {
          "beyond the mere size may have a more profound influence on models‚Äô EU.": "reinforcement  learning,  self-supervised  learning,  and  a  combination  thereof,  likely"
        },
        {
          "beyond the mere size may have a more profound influence on models‚Äô EU.": "substantially influences the EQ scores. For example, despite architectural differences"
        },
        {
          "beyond the mere size may have a more profound influence on models‚Äô EU.": "(Pythia  versus  LLaMA),  Oasst  and  Alpaca  yielded"
        },
        {
          "beyond the mere size may have a more profound influence on models‚Äô EU.": ""
        },
        {
          "beyond the mere size may have a more profound influence on models‚Äô EU.": "enhancements  may  be  achieved"
        },
        {
          "beyond the mere size may have a more profound influence on models‚Äô EU.": ""
        },
        {
          "beyond the mere size may have a more profound influence on models‚Äô EU.": ""
        },
        {
          "beyond the mere size may have a more profound influence on models‚Äô EU.": ""
        },
        {
          "beyond the mere size may have a more profound influence on models‚Äô EU.": ""
        },
        {
          "beyond the mere size may have a more profound influence on models‚Äô EU.": ""
        },
        {
          "beyond the mere size may have a more profound influence on models‚Äô EU.": ""
        }
      ],
      "page": 16
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "study  focused  solely  on  the  EU  ability  of  the  LLMs,  while  EI  is  a  multi-faceted": "construct encompassing not only EU but also emotion perception, emotion facilitation,"
        },
        {
          "study  focused  solely  on  the  EU  ability  of  the  LLMs,  while  EI  is  a  multi-faceted": "and emotion management (e.g., Mayer et al., 2016; Mayer & Salovey, 1995; Salovey"
        },
        {
          "study  focused  solely  on  the  EU  ability  of  the  LLMs,  while  EI  is  a  multi-faceted": "& Mayer, 1990). Therefore, future studies could design scenarios to examine whether"
        },
        {
          "study  focused  solely  on  the  EU  ability  of  the  LLMs,  while  EI  is  a  multi-faceted": "LLMs can assist humans in leveraging emotions to facilitate cognitive processes and"
        },
        {
          "study  focused  solely  on  the  EU  ability  of  the  LLMs,  while  EI  is  a  multi-faceted": "effectively manage their emotional responses."
        }
      ],
      "page": 17
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Methods": "Participants"
        },
        {
          "Methods": "A  total  of  five  hundred  and  forty-one  human  participants  with  valid  responses  were"
        },
        {
          "Methods": "collected in this study. The participants (N = 541; females: 339, males: 202; mean age:"
        },
        {
          "Methods": "22.33, SD: 2.49, ranging from 17 to 30 years) were all undergraduate and postgraduate"
        },
        {
          "Methods": "college students in China. Informed consent was obtained prior to the SECEU test and"
        },
        {
          "Methods": "participants were reimbursed after they completed the whole test. To ensure anonymity"
        },
        {
          "Methods": "and data privacy, participants did not input any information that could identify them"
        },
        {
          "Methods": "during  the  process.  This  study  was  approved  by  the  Institutional  Review  Board  at"
        },
        {
          "Methods": "Tsinghua University."
        }
      ],
      "page": 18
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "emotion options based on the intensity of each emotion experienced by the person in": "the scenario. There were no correct or incorrect answers. Participants were encouraged"
        },
        {
          "emotion options based on the intensity of each emotion experienced by the person in": "to respond according to their own understanding and interpretation of the scenarios."
        },
        {
          "emotion options based on the intensity of each emotion experienced by the person in": "The SECEU test for LLMs"
        },
        {
          "emotion options based on the intensity of each emotion experienced by the person in": "A variety of mainstream LLMs, including the OpenAI GPT series (GPT-4, GPT-3.5-"
        },
        {
          "emotion options based on the intensity of each emotion experienced by the person in": "turbo, Curie, Babbage, DaVinci, text-davinci-001, text-davinci-002, and text-davinci-"
        },
        {
          "emotion options based on the intensity of each emotion experienced by the person in": "003), Claude, LLaMA-based models (Alpaca, Koala, LLaMA, and Vicuna), Fastchat,"
        },
        {
          "emotion options based on the intensity of each emotion experienced by the person in": "Pythia-based models (Dolly and Oasst), GLM-based models (ChatGLM), and RNN-"
        },
        {
          "emotion options based on the intensity of each emotion experienced by the person in": "based models (RWKV), were evaluated by the SECEU test. Given that the majority of"
        },
        {
          "emotion options based on the intensity of each emotion experienced by the person in": "these models are primarily trained on English datasets, using the English version of the"
        },
        {
          "emotion options based on the intensity of each emotion experienced by the person in": "SECEU  provides  a  more  accurate  assessment  of  their  performance,  allowing  for  a"
        },
        {
          "emotion options based on the intensity of each emotion experienced by the person in": "clearer comparison between their abilities and those of a human. As a result, the English"
        },
        {
          "emotion options based on the intensity of each emotion experienced by the person in": "version of SECEU was presented to the LLMs instead of the Chinese version."
        },
        {
          "emotion options based on the intensity of each emotion experienced by the person in": "The  task  was  in  a  direct  question-and-answer  format.  We  asked,  for  example,"
        },
        {
          "emotion options based on the intensity of each emotion experienced by the person in": "‚ÄúStory: Wang participated in a mathematics competition but felt he had not performed"
        },
        {
          "emotion options based on the intensity of each emotion experienced by the person in": "to his full potential. However, when the results were announced, he found that he was"
        },
        {
          "emotion options based on the intensity of each emotion experienced by the person in": "in a position of top 10. He would feel: Options: (1) Surprised; (2) Joyful; (3) Puzzled;"
        },
        {
          "emotion options based on the intensity of each emotion experienced by the person in": "(4) Proud. Assign a score to each option based on the story, sum up to 10‚Äù. There could"
        },
        {
          "emotion options based on the intensity of each emotion experienced by the person in": "be very subtle changes of the direct prompt. For instance, we used ‚Äúprovide a score for"
        },
        {
          "emotion options based on the intensity of each emotion experienced by the person in": "each emotion based on the emotion (sum of four options should be of 10 points)‚Äù for"
        },
        {
          "emotion options based on the intensity of each emotion experienced by the person in": "Dolly. There were a set of paraphrases of the direct prompt to get the best performance."
        },
        {
          "emotion options based on the intensity of each emotion experienced by the person in": "To decrease the randomness, a constant temperature parameter was set to 0.1 and"
        },
        {
          "emotion options based on the intensity of each emotion experienced by the person in": "the top_p parameter was set to 1 across all these models. To dictate the maximum length"
        },
        {
          "emotion options based on the intensity of each emotion experienced by the person in": "of the generated text, the max_tokens parameter was set to 512."
        },
        {
          "emotion options based on the intensity of each emotion experienced by the person in": "Before being processed by the models, text data underwent several preprocessing"
        },
        {
          "emotion options based on the intensity of each emotion experienced by the person in": "steps to normalize it. This normalization process ensures that data fed into the models"
        },
        {
          "emotion options based on the intensity of each emotion experienced by the person in": "is in a consistent and appropriate format, enhancing the output's quality. If a model did"
        },
        {
          "emotion options based on the intensity of each emotion experienced by the person in": "19"
        }
      ],
      "page": 19
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "not  provide  any  meaningful  response  to  an  item,  the  response  for  this  item  was": "predefined as a null vector (0, 0, 0, 0). A few models failed to generate a response for a"
        },
        {
          "not  provide  any  meaningful  response  to  an  item,  the  response  for  this  item  was": "majority of items (LLaMA: 40; Fastchat: 31; RWKV-v4: 31; DaVinci: 40; Curie: 40;"
        },
        {
          "not  provide  any  meaningful  response  to  an  item,  the  response  for  this  item  was": "Babbage:40; text-davinci-001: 26; text-davinci-002: 28; marked as ‚ÄúFAILED‚Äù in Table"
        },
        {
          "not  provide  any  meaningful  response  to  an  item,  the  response  for  this  item  was": "S1). Several models were unable to provide the answer which the summation of the"
        },
        {
          "not  provide  any  meaningful  response  to  an  item,  the  response  for  this  item  was": "four scores was 10:"
        }
      ],
      "page": 20
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "S1). Several models were unable to provide the answer which the summation of the": "four scores was 10:"
        },
        {
          "S1). Several models were unable to provide the answer which the summation of the": "(i) Answer vectors signifying null responses, i.e., (0, 0, 0, 0),  were preserved as"
        },
        {
          "S1). Several models were unable to provide the answer which the summation of the": "such (Alpaca: 1; ChatGLM: 1)."
        },
        {
          "S1). Several models were unable to provide the answer which the summation of the": "(ii) For datasets encompassing negative values, an addition operation involving the"
        },
        {
          "S1). Several models were unable to provide the answer which the summation of the": "absolute value of the lowest number was performed across all elements, followed"
        },
        {
          "S1). Several models were unable to provide the answer which the summation of the": "by a subsequent normalization to maintain consistency with the original scale. For"
        },
        {
          "S1). Several models were unable to provide the answer which the summation of the": "instance, an original data vector of (-4, -2, -2, 2) would be adjusted to (0, 2, 2, 6)."
        },
        {
          "S1). Several models were unable to provide the answer which the summation of the": "(iii) The remaining answer vectors were normalized to achieve a cumulative score"
        },
        {
          "S1). Several models were unable to provide the answer which the summation of the": "of 10. This involved proportionally distributing a score of 10 among the answer"
        },
        {
          "S1). Several models were unable to provide the answer which the summation of the": "vector based on the contribution of each value to the total score on this item."
        }
      ],
      "page": 20
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "follow a normal distribution with the average score set at 100 and the standard deviation": "at 15. The standardization process involved the following steps: (1) the original SECEU"
        },
        {
          "follow a normal distribution with the average score set at 100 and the standard deviation": "score  was  subtracted  from  the  mean  value  of  the  human  norm  and  divided  by  its"
        },
        {
          "follow a normal distribution with the average score set at 100 and the standard deviation": "standard deviation, and (2) the resulting value was then multiplied by the new standard"
        },
        {
          "follow a normal distribution with the average score set at 100 and the standard deviation": "deviation (15) and added to the new mean value (100), yielding the EQ score. Thus, the"
        },
        {
          "follow a normal distribution with the average score set at 100 and the standard deviation": "EQ  score  represents  a  normalized  measure  of"
        },
        {
          "follow a normal distribution with the average score set at 100 and the standard deviation": "comparison across different models."
        }
      ],
      "page": 21
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "and the human template was calculated as the LLM-to-Human similarity.": ""
        },
        {
          "and the human template was calculated as the LLM-to-Human similarity.": ""
        },
        {
          "and the human template was calculated as the LLM-to-Human similarity.": "LLM ‚àí to ‚àí Human similarity Pearson ="
        },
        {
          "and the human template was calculated as the LLM-to-Human similarity.": ""
        },
        {
          "and the human template was calculated as the LLM-to-Human similarity.": ""
        },
        {
          "and the human template was calculated as the LLM-to-Human similarity.": "Here,"
        },
        {
          "and the human template was calculated as the LLM-to-Human similarity.": "human template vector, respectively. The length of both vectors is 40."
        },
        {
          "and the human template was calculated as the LLM-to-Human similarity.": ""
        },
        {
          "and the human template was calculated as the LLM-to-Human similarity.": ""
        },
        {
          "and the human template was calculated as the LLM-to-Human similarity.": "SD  below  the  population,  such  LLM  is  considered  as  employing  a  qualitatively"
        },
        {
          "and the human template was calculated as the LLM-to-Human similarity.": ""
        },
        {
          "and the human template was calculated as the LLM-to-Human similarity.": "different mechanism from humans in EU."
        },
        {
          "and the human template was calculated as the LLM-to-Human similarity.": "Prompt engineering"
        },
        {
          "and the human template was calculated as the LLM-to-Human similarity.": "Prompt  engineering‚Äîthe  meticulous  development  and  choice  of  prompts‚Äîplays  a"
        },
        {
          "and the human template was calculated as the LLM-to-Human similarity.": "pivotal role in the efficacy of LLMs (Hebenstreit et al., 2023; Hendrycks et al., 2021;"
        },
        {
          "and the human template was calculated as the LLM-to-Human similarity.": "Nair et al., 2023; OpenAI, 2023; Shinn et al., 2023). In essence, prompt engineering"
        },
        {
          "and the human template was calculated as the LLM-to-Human similarity.": "refers to the strategy of designing and selecting prompts that can substantially guide"
        },
        {
          "and the human template was calculated as the LLM-to-Human similarity.": "and influence the responses of LLMs. The necessity of prompt engineering lies in its"
        },
        {
          "and the human template was calculated as the LLM-to-Human similarity.": "potential to enhance the precision and relevance of the responses generated by these"
        },
        {
          "and the human template was calculated as the LLM-to-Human similarity.": "models,  thereby  leading  to  more  effective  and  reliable  outcomes.  In  the  realm  of"
        },
        {
          "and the human template was calculated as the LLM-to-Human similarity.": "emotional intelligence, prompts serve a crucial function. They provide a direction for"
        },
        {
          "and the human template was calculated as the LLM-to-Human similarity.": "the model, enabling it to understand and generate responses that are not just accurate"
        },
        {
          "and the human template was calculated as the LLM-to-Human similarity.": "but also emotionally intelligent. Given the nature of emotional intelligence that involves"
        },
        {
          "and the human template was calculated as the LLM-to-Human similarity.": "understanding, processing, and managing emotions, prompts can significantly aid the"
        },
        {
          "and the human template was calculated as the LLM-to-Human similarity.": "LLMs in identifying the correct context and producing responses that exhibit emotional"
        },
        {
          "and the human template was calculated as the LLM-to-Human similarity.": "understanding and empathy."
        },
        {
          "and the human template was calculated as the LLM-to-Human similarity.": "To examine the prompts‚Äô influence on EU ability, thereby optimizing model outputs,"
        },
        {
          "and the human template was calculated as the LLM-to-Human similarity.": "kinds"
        },
        {
          "and the human template was calculated as the LLM-to-Human similarity.": "intelligence.github.io/ for prompts) were applied to the OpenAI GPT series (GPT-3.5-"
        },
        {
          "and the human template was calculated as the LLM-to-Human similarity.": "turbo, Curie, Babbage, DaVinci, text-davinci-001, text-davinci-002, and text-davinci-"
        },
        {
          "and the human template was calculated as the LLM-to-Human similarity.": ""
        }
      ],
      "page": 22
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "003): (1) Zero-shot Prompts, (2)": "Step Thinking, (3) Two-shot Chain of Thought Reasoning Approaches, and (4) Two-",
          "Enhanced Zero-shot Prompts Incorporating Step-by-": ""
        },
        {
          "003): (1) Zero-shot Prompts, (2)": "shot Chain of Thought Reasoning Approaches Augmented with Step-by-Step Thinking",
          "Enhanced Zero-shot Prompts Incorporating Step-by-": ""
        },
        {
          "003): (1) Zero-shot Prompts, (2)": "",
          "Enhanced Zero-shot Prompts Incorporating Step-by-": "To decease the randomness, a constant temperature parameter was set to 0 and the"
        },
        {
          "003): (1) Zero-shot Prompts, (2)": "top_p parameter to was set to 0.9 across all these models. To dictates the maximum",
          "Enhanced Zero-shot Prompts Incorporating Step-by-": ""
        },
        {
          "003): (1) Zero-shot Prompts, (2)": "length  of \nthe  generated \ntext,",
          "Enhanced Zero-shot Prompts Incorporating Step-by-": "the  max_tokens  parameter  was  set \nto  2048.  The"
        },
        {
          "003): (1) Zero-shot Prompts, (2)": "normalization process was the same as the one without prompts.",
          "Enhanced Zero-shot Prompts Incorporating Step-by-": ""
        },
        {
          "003): (1) Zero-shot Prompts, (2)": "Reference",
          "Enhanced Zero-shot Prompts Incorporating Step-by-": ""
        },
        {
          "003): (1) Zero-shot Prompts, (2)": "Amin, M. M., Cambria, E., & Schuller, B. W. (2023). Will Affective Computing Emerge",
          "Enhanced Zero-shot Prompts Incorporating Step-by-": ""
        },
        {
          "003): (1) Zero-shot Prompts, (2)": "",
          "Enhanced Zero-shot Prompts Incorporating Step-by-": "from  Foundation  Models  and  General  AI?  A  First  Evaluation  on  ChatGPT."
        },
        {
          "003): (1) Zero-shot Prompts, (2)": "https://doi.org/10.48550/ARXIV.2303.03186",
          "Enhanced Zero-shot Prompts Incorporating Step-by-": ""
        },
        {
          "003): (1) Zero-shot Prompts, (2)": "Bai, Y., Kadavath, S., Kundu, S., Askell, A., Kernion, J., Jones, A., Chen, A., Goldie,",
          "Enhanced Zero-shot Prompts Incorporating Step-by-": ""
        },
        {
          "003): (1) Zero-shot Prompts, (2)": "",
          "Enhanced Zero-shot Prompts Incorporating Step-by-": "A., Mirhoseini, A., McKinnon, C., Chen, C., Olsson, C., Olah, C., Hernandez,"
        },
        {
          "003): (1) Zero-shot Prompts, (2)": "",
          "Enhanced Zero-shot Prompts Incorporating Step-by-": "D., Drain, D., Ganguli, D., Li, D., Tran-Johnson, E., Perez, E., ‚Ä¶ Kaplan, J."
        },
        {
          "003): (1) Zero-shot Prompts, (2)": "",
          "Enhanced Zero-shot Prompts Incorporating Step-by-": "(2022). Constitutional AI: Harmlessness from AI Feedback (arXiv:2212.08073)."
        },
        {
          "003): (1) Zero-shot Prompts, (2)": "arXiv. http://arxiv.org/abs/2212.08073",
          "Enhanced Zero-shot Prompts Incorporating Step-by-": ""
        },
        {
          "003): (1) Zero-shot Prompts, (2)": "Baron-Cohen,  S.  (2020).  The  pattern  seekers:  How  autism  drives  human  invention.",
          "Enhanced Zero-shot Prompts Incorporating Step-by-": ""
        },
        {
          "003): (1) Zero-shot Prompts, (2)": "Basic Books.",
          "Enhanced Zero-shot Prompts Incorporating Step-by-": ""
        },
        {
          "003): (1) Zero-shot Prompts, (2)": "Baron-Cohen,  S.,  Leslie, A.  M.,  &  Frith,  U.  (1985).  Does  the  autistic  child  have  a",
          "Enhanced Zero-shot Prompts Incorporating Step-by-": ""
        },
        {
          "003): (1) Zero-shot Prompts, (2)": "",
          "Enhanced Zero-shot Prompts Incorporating Step-by-": "‚Äútheory  of  mind‚Äù‚ÄØ?  Cognition,  21(1),  37‚Äì46.  https://doi.org/10.1016/0010-"
        },
        {
          "003): (1) Zero-shot Prompts, (2)": "0277(85)90022-8",
          "Enhanced Zero-shot Prompts Incorporating Step-by-": ""
        },
        {
          "003): (1) Zero-shot Prompts, (2)": "Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan,",
          "Enhanced Zero-shot Prompts Incorporating Step-by-": ""
        },
        {
          "003): (1) Zero-shot Prompts, (2)": "",
          "Enhanced Zero-shot Prompts Incorporating Step-by-": "A., Shyam, P., Sastry, G., Askell, A., & others. (2020). Language models are"
        },
        {
          "003): (1) Zero-shot Prompts, (2)": "23",
          "Enhanced Zero-shot Prompts Incorporating Step-by-": ""
        }
      ],
      "page": 23
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "few-shot  learners.  Advances  in  Neural  Information  Processing  Systems,  33,": ""
        },
        {
          "few-shot  learners.  Advances  in  Neural  Information  Processing  Systems,  33,": ""
        },
        {
          "few-shot  learners.  Advances  in  Neural  Information  Processing  Systems,  33,": "Lee, Y. T., Li, Y., Lundberg, S., Nori, H., Palangi, H., Ribeiro, M. T., & Zhang,"
        },
        {
          "few-shot  learners.  Advances  in  Neural  Information  Processing  Systems,  33,": ".  (2023).  Sparks  of  Artificial  General  Intelligence:  Early  experiments  with"
        },
        {
          "few-shot  learners.  Advances  in  Neural  Information  Processing  Systems,  33,": "GPT-4. https://doi.org/10.48550/ARXIV.2303.12712"
        },
        {
          "few-shot  learners.  Advances  in  Neural  Information  Processing  Systems,  33,": ""
        },
        {
          "few-shot  learners.  Advances  in  Neural  Information  Processing  Systems,  33,": "Zhuang, Y., Gonzalez, J. E., Stoica, I., & Xing, E. P. (2023). Vicuna: An Open-"
        },
        {
          "few-shot  learners.  Advances  in  Neural  Information  Processing  Systems,  33,": "Chatbot"
        },
        {
          "few-shot  learners.  Advances  in  Neural  Information  Processing  Systems,  33,": "https://lmsys.org/blog/2023-03-30-vicuna/"
        },
        {
          "few-shot  learners.  Advances  in  Neural  Information  Processing  Systems,  33,": ""
        },
        {
          "few-shot  learners.  Advances  in  Neural  Information  Processing  Systems,  33,": "Wendell, P., Zaharia, M., & others. (2023). Free dolly: Introducing the world‚Äôs"
        },
        {
          "few-shot  learners.  Advances  in  Neural  Information  Processing  Systems,  33,": "first truly open instruction-tuned llm."
        },
        {
          "few-shot  learners.  Advances  in  Neural  Information  Processing  Systems,  33,": ""
        },
        {
          "few-shot  learners.  Advances  in  Neural  Information  Processing  Systems,  33,": "source  collaborative  ecosystem  of  behavioral  experiments.  Journal  of  Open"
        },
        {
          "few-shot  learners.  Advances  in  Neural  Information  Processing  Systems,  33,": "Source Software, 8(85), 5351. https://doi.org/10.21105/joss.05351"
        },
        {
          "few-shot  learners.  Advances  in  Neural  Information  Processing  Systems,  33,": ""
        },
        {
          "few-shot  learners.  Advances  in  Neural  Information  Processing  Systems,  33,": "Bidirectional Transformers for Language Understanding (arXiv:1810.04805)."
        },
        {
          "few-shot  learners.  Advances  in  Neural  Information  Processing  Systems,  33,": "arXiv. http://arxiv.org/abs/1810.04805"
        },
        {
          "few-shot  learners.  Advances  in  Neural  Information  Processing  Systems,  33,": ""
        },
        {
          "few-shot  learners.  Advances  in  Neural  Information  Processing  Systems,  33,": "Journal"
        },
        {
          "few-shot  learners.  Advances  in  Neural  Information  Processing  Systems,  33,": "https://doi.org/10.1108/02683940010330993"
        },
        {
          "few-shot  learners.  Advances  in  Neural  Information  Processing  Systems,  33,": ""
        }
      ],
      "page": 24
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Geng, X., Gudibande, A., Liu, H., Wallace, E., Abbeel, P., Levine, S., & Song, D. (2023).": "Koala: \nA"
        },
        {
          "Geng, X., Gudibande, A., Liu, H., Wallace, E., Abbeel, P., Levine, S., & Song, D. (2023).": ""
        },
        {
          "Geng, X., Gudibande, A., Liu, H., Wallace, E., Abbeel, P., Levine, S., & Song, D. (2023).": "Hanafi,  Z.,  &  Noor,  F.  (2016).  Relationship  between  Emotional  Intelligence  and"
        },
        {
          "Geng, X., Gudibande, A., Liu, H., Wallace, E., Abbeel, P., Levine, S., & Song, D. (2023).": "Academic  Achievement"
        },
        {
          "Geng, X., Gudibande, A., Liu, H., Wallace, E., Abbeel, P., Levine, S., & Song, D. (2023).": ""
        },
        {
          "Geng, X., Gudibande, A., Liu, H., Wallace, E., Abbeel, P., Levine, S., & Song, D. (2023).": ""
        },
        {
          "Geng, X., Gudibande, A., Liu, H., Wallace, E., Abbeel, P., Levine, S., & Song, D. (2023).": "Hebenstreit, K., Praas, R., Kiesewetter, L. P., & Samwald, M. (2023). An automatically"
        },
        {
          "Geng, X., Gudibande, A., Liu, H., Wallace, E., Abbeel, P., Levine, S., & Song, D. (2023).": ""
        },
        {
          "Geng, X., Gudibande, A., Liu, H., Wallace, E., Abbeel, P., Levine, S., & Song, D. (2023).": ""
        },
        {
          "Geng, X., Gudibande, A., Liu, H., Wallace, E., Abbeel, P., Levine, S., & Song, D. (2023).": ""
        },
        {
          "Geng, X., Gudibande, A., Liu, H., Wallace, E., Abbeel, P., Levine, S., & Song, D. (2023).": "(2021). \nMeasuring"
        },
        {
          "Geng, X., Gudibande, A., Liu, H., Wallace, E., Abbeel, P., Levine, S., & Song, D. (2023).": ""
        },
        {
          "Geng, X., Gudibande, A., Liu, H., Wallace, E., Abbeel, P., Levine, S., & Song, D. (2023).": ""
        },
        {
          "Geng, X., Gudibande, A., Liu, H., Wallace, E., Abbeel, P., Levine, S., & Song, D. (2023).": ""
        },
        {
          "Geng, X., Gudibande, A., Liu, H., Wallace, E., Abbeel, P., Levine, S., & Song, D. (2023).": ""
        },
        {
          "Geng, X., Gudibande, A., Liu, H., Wallace, E., Abbeel, P., Levine, S., & Song, D. (2023).": "different \nlarge"
        },
        {
          "Geng, X., Gudibande, A., Liu, H., Wallace, E., Abbeel, P., Levine, S., & Song, D. (2023).": ""
        },
        {
          "Geng, X., Gudibande, A., Liu, H., Wallace, E., Abbeel, P., Levine, S., & Song, D. (2023).": ""
        },
        {
          "Geng, X., Gudibande, A., Liu, H., Wallace, E., Abbeel, P., Levine, S., & Song, D. (2023).": ""
        },
        {
          "Geng, X., Gudibande, A., Liu, H., Wallace, E., Abbeel, P., Levine, S., & Song, D. (2023).": ""
        },
        {
          "Geng, X., Gudibande, A., Liu, H., Wallace, E., Abbeel, P., Levine, S., & Song, D. (2023).": "Preprint ArXiv:2304.07327."
        },
        {
          "Geng, X., Gudibande, A., Liu, H., Wallace, E., Abbeel, P., Levine, S., & Song, D. (2023).": ""
        }
      ],
      "page": 25
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Kosinski,  M.  (2023).  Theory  of  Mind  May  Have  Spontaneously  Emerged  in  Large": ""
        },
        {
          "Kosinski,  M.  (2023).  Theory  of  Mind  May  Have  Spontaneously  Emerged  in  Large": "Lange,  K.,  K√ºhn,  S.,  &  Filevich,  E.  (2015).  \"Just Another Tool  for  Online  Studies‚Äù"
        },
        {
          "Kosinski,  M.  (2023).  Theory  of  Mind  May  Have  Spontaneously  Emerged  in  Large": ""
        },
        {
          "Kosinski,  M.  (2023).  Theory  of  Mind  May  Have  Spontaneously  Emerged  in  Large": ""
        },
        {
          "Kosinski,  M.  (2023).  Theory  of  Mind  May  Have  Spontaneously  Emerged  in  Large": ""
        },
        {
          "Kosinski,  M.  (2023).  Theory  of  Mind  May  Have  Spontaneously  Emerged  in  Large": ""
        },
        {
          "Kosinski,  M.  (2023).  Theory  of  Mind  May  Have  Spontaneously  Emerged  in  Large": ""
        },
        {
          "Kosinski,  M.  (2023).  Theory  of  Mind  May  Have  Spontaneously  Emerged  in  Large": ""
        },
        {
          "Kosinski,  M.  (2023).  Theory  of  Mind  May  Have  Spontaneously  Emerged  in  Large": ""
        },
        {
          "Kosinski,  M.  (2023).  Theory  of  Mind  May  Have  Spontaneously  Emerged  in  Large": ""
        },
        {
          "Kosinski,  M.  (2023).  Theory  of  Mind  May  Have  Spontaneously  Emerged  in  Large": ""
        },
        {
          "Kosinski,  M.  (2023).  Theory  of  Mind  May  Have  Spontaneously  Emerged  in  Large": ""
        },
        {
          "Kosinski,  M.  (2023).  Theory  of  Mind  May  Have  Spontaneously  Emerged  in  Large": ""
        },
        {
          "Kosinski,  M.  (2023).  Theory  of  Mind  May  Have  Spontaneously  Emerged  in  Large": ""
        },
        {
          "Kosinski,  M.  (2023).  Theory  of  Mind  May  Have  Spontaneously  Emerged  in  Large": ""
        },
        {
          "Kosinski,  M.  (2023).  Theory  of  Mind  May  Have  Spontaneously  Emerged  in  Large": ""
        },
        {
          "Kosinski,  M.  (2023).  Theory  of  Mind  May  Have  Spontaneously  Emerged  in  Large": ""
        },
        {
          "Kosinski,  M.  (2023).  Theory  of  Mind  May  Have  Spontaneously  Emerged  in  Large": ""
        },
        {
          "Kosinski,  M.  (2023).  Theory  of  Mind  May  Have  Spontaneously  Emerged  in  Large": ""
        },
        {
          "Kosinski,  M.  (2023).  Theory  of  Mind  May  Have  Spontaneously  Emerged  in  Large": ""
        },
        {
          "Kosinski,  M.  (2023).  Theory  of  Mind  May  Have  Spontaneously  Emerged  in  Large": ""
        },
        {
          "Kosinski,  M.  (2023).  Theory  of  Mind  May  Have  Spontaneously  Emerged  in  Large": "26"
        }
      ],
      "page": 26
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "https://doi.org/10.1037/1528-3542.1.3.232": ""
        },
        {
          "https://doi.org/10.1037/1528-3542.1.3.232": "with"
        },
        {
          "https://doi.org/10.1037/1528-3542.1.3.232": "https://doi.org/10.1037/1528-3542.3.1.97"
        },
        {
          "https://doi.org/10.1037/1528-3542.1.3.232": ""
        },
        {
          "https://doi.org/10.1037/1528-3542.1.3.232": "controversy,  and  criticism.  International  Journal  of  Organizational Analysis,"
        },
        {
          "https://doi.org/10.1037/1528-3542.1.3.232": "22(1), 76‚Äì93. https://doi.org/10.1108/IJOA-03-2012-0568"
        },
        {
          "https://doi.org/10.1037/1528-3542.1.3.232": ""
        },
        {
          "https://doi.org/10.1037/1528-3542.1.3.232": ""
        },
        {
          "https://doi.org/10.1037/1528-3542.1.3.232": "https://doi.org/10.48550/ARXIV.2304.11490"
        },
        {
          "https://doi.org/10.1037/1528-3542.1.3.232": ""
        },
        {
          "https://doi.org/10.1037/1528-3542.1.3.232": "Language  Model  Completions  with  Dialog-Enabled"
        },
        {
          "https://doi.org/10.1037/1528-3542.1.3.232": "(arXiv:2303.17071). arXiv. http://arxiv.org/abs/2303.17071"
        },
        {
          "https://doi.org/10.1037/1528-3542.1.3.232": "GPT-4"
        },
        {
          "https://doi.org/10.1037/1528-3542.1.3.232": "http://arxiv.org/abs/2303.08774"
        },
        {
          "https://doi.org/10.1037/1528-3542.1.3.232": ""
        },
        {
          "https://doi.org/10.1037/1528-3542.1.3.232": "evaluation of the Mayer‚ÄìSalovey‚ÄìCaruso Emotional Intelligence Test Version"
        },
        {
          "https://doi.org/10.1037/1528-3542.1.3.232": "2.0. Intelligence, 33(3), 285‚Äì305. https://doi.org/10.1016/j.intell.2004.11.003"
        },
        {
          "https://doi.org/10.1037/1528-3542.1.3.232": ""
        },
        {
          "https://doi.org/10.1037/1528-3542.1.3.232": "Chung, M., Grella, M., GV, K. K., He, X., Hou, H., Kazienko, P., Kocon, J.,"
        },
        {
          "https://doi.org/10.1037/1528-3542.1.3.232": "Kong, J., Koptyra, B., Lau, H., Mantri, K. S. I., Mom, F., ‚Ä¶ Zhu, R.-J. (2023)."
        },
        {
          "https://doi.org/10.1037/1528-3542.1.3.232": "RWKV: Reinventing RNNs for the Transformer Era."
        },
        {
          "https://doi.org/10.1037/1528-3542.1.3.232": ""
        }
      ],
      "page": 27
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Salovey, P., & Mayer, J. D. (1990). Emotional Intelligence. Imagination, Cognition and": "Personality,"
        },
        {
          "Salovey, P., & Mayer, J. D. (1990). Emotional Intelligence. Imagination, Cognition and": "6CDG"
        },
        {
          "Salovey, P., & Mayer, J. D. (1990). Emotional Intelligence. Imagination, Cognition and": "Sap,  M.,  LeBras,  R.,  Fried,  D.,  &  Choi, Y.  (2023).  Neural  Theory-of-Mind?  On  the"
        },
        {
          "Salovey, P., & Mayer, J. D. (1990). Emotional Intelligence. Imagination, Cognition and": "Limits  of  Social"
        },
        {
          "Salovey, P., & Mayer, J. D. (1990). Emotional Intelligence. Imagination, Cognition and": ""
        },
        {
          "Salovey, P., & Mayer, J. D. (1990). Emotional Intelligence. Imagination, Cognition and": "Shinn, N., Cassano, F., Labash, B., Gopinath, A., Narasimhan, K., & Yao, S. (2023)."
        },
        {
          "Salovey, P., & Mayer, J. D. (1990). Emotional Intelligence. Imagination, Cognition and": "Reflexion:"
        },
        {
          "Salovey, P., & Mayer, J. D. (1990). Emotional Intelligence. Imagination, Cognition and": ""
        },
        {
          "Salovey, P., & Mayer, J. D. (1990). Emotional Intelligence. Imagination, Cognition and": "Sperber, D., & Wilson, D. (2002). Pragmatics, modularity and mind-reading. Mind &"
        },
        {
          "Salovey, P., & Mayer, J. D. (1990). Emotional Intelligence. Imagination, Cognition and": ""
        },
        {
          "Salovey, P., & Mayer, J. D. (1990). Emotional Intelligence. Imagination, Cognition and": ""
        },
        {
          "Salovey, P., & Mayer, J. D. (1990). Emotional Intelligence. Imagination, Cognition and": ""
        },
        {
          "Salovey, P., & Mayer, J. D. (1990). Emotional Intelligence. Imagination, Cognition and": ""
        },
        {
          "Salovey, P., & Mayer, J. D. (1990). Emotional Intelligence. Imagination, Cognition and": ""
        },
        {
          "Salovey, P., & Mayer, J. D. (1990). Emotional Intelligence. Imagination, Cognition and": ""
        },
        {
          "Salovey, P., & Mayer, J. D. (1990). Emotional Intelligence. Imagination, Cognition and": ""
        },
        {
          "Salovey, P., & Mayer, J. D. (1990). Emotional Intelligence. Imagination, Cognition and": "model. \nIn"
        },
        {
          "Salovey, P., & Mayer, J. D. (1990). Emotional Intelligence. Imagination, Cognition and": ""
        },
        {
          "Salovey, P., & Mayer, J. D. (1990). Emotional Intelligence. Imagination, Cognition and": ""
        },
        {
          "Salovey, P., & Mayer, J. D. (1990). Emotional Intelligence. Imagination, Cognition and": ""
        },
        {
          "Salovey, P., & Mayer, J. D. (1990). Emotional Intelligence. Imagination, Cognition and": ""
        },
        {
          "Salovey, P., & Mayer, J. D. (1990). Emotional Intelligence. Imagination, Cognition and": ""
        }
      ],
      "page": 28
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "https://doi.org/10.1093/cercor/bhz289": ""
        },
        {
          "https://doi.org/10.1093/cercor/bhz289": "B., Goyal, N., Hambro, E., Azhar, F., Rodriguez, A., Joulin, A., Grave, E., &"
        },
        {
          "https://doi.org/10.1093/cercor/bhz289": "Lample, G. (2023). LLaMA: Open and Efficient Foundation Language Models"
        },
        {
          "https://doi.org/10.1093/cercor/bhz289": "(arXiv:2302.13971). arXiv. http://arxiv.org/abs/2302.13971"
        },
        {
          "https://doi.org/10.1093/cercor/bhz289": ""
        },
        {
          "https://doi.org/10.1093/cercor/bhz289": "\\Lukasz, & Polosukhin, I. (2017). Attention is all you need. Advances in Neural"
        },
        {
          "https://doi.org/10.1093/cercor/bhz289": "Information Processing Systems, 30."
        },
        {
          "https://doi.org/10.1093/cercor/bhz289": ""
        },
        {
          "https://doi.org/10.1093/cercor/bhz289": "Individual"
        },
        {
          "https://doi.org/10.1093/cercor/bhz289": "https://doi.org/10.1016/j.paid.2003.12.003"
        },
        {
          "https://doi.org/10.1093/cercor/bhz289": ""
        },
        {
          "https://doi.org/10.1093/cercor/bhz289": "X., Tam, W. L., Ma, Z., Xue, Y., Zhai, J., Chen, W., Zhang, P., Dong, Y., & Tang,"
        },
        {
          "https://doi.org/10.1093/cercor/bhz289": "(2022)."
        },
        {
          "https://doi.org/10.1093/cercor/bhz289": "(arXiv:2210.02414). arXiv. http://arxiv.org/abs/2210.02414"
        },
        {
          "https://doi.org/10.1093/cercor/bhz289": ""
        },
        {
          "https://doi.org/10.1093/cercor/bhz289": "J., Dong, Z., Du, Y., Yang, C., Chen, Y., Chen, Z., Jiang, J., Ren, R., Li, Y., Tang,"
        },
        {
          "https://doi.org/10.1093/cercor/bhz289": "X.,  Liu,  Z.,  ‚Ä¶  Wen,  J.-R.  (2023).  A  Survey  of  Large  Language  Models"
        },
        {
          "https://doi.org/10.1093/cercor/bhz289": "(arXiv:2303.18223). arXiv. http://arxiv.org/abs/2303.18223"
        },
        {
          "https://doi.org/10.1093/cercor/bhz289": ""
        },
        {
          "https://doi.org/10.1093/cercor/bhz289": "D., Xing, E. P., Zhang, H., Gonzalez, J. E., & Stoica, I. (2023). Judging LLM-"
        },
        {
          "https://doi.org/10.1093/cercor/bhz289": "as-a-judge with MT-Bench and Chatbot Arena."
        },
        {
          "https://doi.org/10.1093/cercor/bhz289": ""
        }
      ],
      "page": 29
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Data availability": "The SECEU test (both English and Chinese Versions), the code for the test on human"
        },
        {
          "Data availability": "participants,  the  standardized  scores,  the  norm,  and  the  prompts  are  available  at"
        },
        {
          "Data availability": "https://emotional-intelligence.github.io/.  The"
        },
        {
          "Data availability": "available from the corresponding author upon reasonable request."
        }
      ],
      "page": 30
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Supplementary": "Prompt engineering"
        },
        {
          "Supplementary": "See Table S2 for the results of prompt engineering."
        },
        {
          "Supplementary": ""
        },
        {
          "Supplementary": ""
        },
        {
          "Supplementary": ""
        },
        {
          "Supplementary": ""
        },
        {
          "Supplementary": ""
        },
        {
          "Supplementary": ""
        },
        {
          "Supplementary": ""
        },
        {
          "Supplementary": "and generate emotionally intelligent responses with minimal guidance."
        },
        {
          "Supplementary": ""
        },
        {
          "Supplementary": ""
        },
        {
          "Supplementary": ""
        },
        {
          "Supplementary": ""
        },
        {
          "Supplementary": ""
        },
        {
          "Supplementary": ""
        },
        {
          "Supplementary": ""
        },
        {
          "Supplementary": ""
        },
        {
          "Supplementary": "Step  prompts  had  a  pronounced"
        },
        {
          "Supplementary": ""
        },
        {
          "Supplementary": ""
        },
        {
          "Supplementary": ""
        },
        {
          "Supplementary": ""
        },
        {
          "Supplementary": "davinci-001, and text-davinci-003. However, it did result in increased pattern similarity."
        },
        {
          "Supplementary": ""
        },
        {
          "Supplementary": ""
        },
        {
          "Supplementary": "also  suggests  that  these  models  have  the  potential  to  master  patterns  of  emotional"
        },
        {
          "Supplementary": "understanding that are similar to those used by humans."
        },
        {
          "Supplementary": "31"
        }
      ],
      "page": 31
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "The  variance \nin \nresponse \nto  different  prompting \ntechniques  among  models": "emphasizes \nthe \nimportance  of  a  deeper  understanding  of  factors  such  as  model"
        },
        {
          "The  variance \nin \nresponse \nto  different  prompting \ntechniques  among  models": "architecture, \ntraining  data,  fine-tuning  process,  and  optimization  objectives.  The"
        },
        {
          "The  variance \nin \nresponse \nto  different  prompting \ntechniques  among  models": "interplay  of  these  factors  might  influence  a  model's  receptiveness  and  response  to"
        },
        {
          "The  variance \nin \nresponse \nto  different  prompting \ntechniques  among  models": "different prompting techniques."
        },
        {
          "The  variance \nin \nresponse \nto  different  prompting \ntechniques  among  models": "Looking forward, there is a need for further exploration into the impact of various"
        },
        {
          "The  variance \nin \nresponse \nto  different  prompting \ntechniques  among  models": "types  of  prompts  on  LLMs  during  emotional \nintelligence \ntests, \nincluding \nthe"
        },
        {
          "The  variance \nin \nresponse \nto  different  prompting \ntechniques  among  models": "investigation of more diverse categories of prompts or hybrid prompts. In-depth studies"
        },
        {
          "The  variance \nin \nresponse \nto  different  prompting \ntechniques  among  models": "into why certain models respond more favorably to specific prompts can also inform"
        },
        {
          "The  variance \nin \nresponse \nto  different  prompting \ntechniques  among  models": "the \ndevelopment \nof  more \nadvanced  LLMs  with \nsuperior \nhuman \nemotional"
        },
        {
          "The  variance \nin \nresponse \nto  different  prompting \ntechniques  among  models": "understanding  capabilities.  These  studies  could  also  provide  valuable  insights  for"
        },
        {
          "The  variance \nin \nresponse \nto  different  prompting \ntechniques  among  models": "optimizing  the  instructive  fine-tuning  process  and  the  application  of  Reinforcement"
        },
        {
          "The  variance \nin \nresponse \nto  different  prompting \ntechniques  among  models": "Learning  from  Human  Feedback  (RLHF) \ntechniques.  Ultimately,  enhancing  our"
        },
        {
          "The  variance \nin \nresponse \nto  different  prompting \ntechniques  among  models": "understanding of the relationship between prompts and LLM performance in emotional"
        },
        {
          "The  variance \nin \nresponse \nto  different  prompting \ntechniques  among  models": "intelligence tests can significantly contribute to the ongoing evolution and refinement"
        },
        {
          "The  variance \nin \nresponse \nto  different  prompting \ntechniques  among  models": "of these models."
        }
      ],
      "page": 32
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Table S1: Results with the direct prompts": ""
        },
        {
          "Table S1: Results with the direct prompts": "Based"
        },
        {
          "Table S1: Results with the direct prompts": ""
        },
        {
          "Table S1: Results with the direct prompts": "OpenAI GPT series"
        },
        {
          "Table S1: Results with the direct prompts": ""
        },
        {
          "Table S1: Results with the direct prompts": ""
        },
        {
          "Table S1: Results with the direct prompts": ""
        },
        {
          "Table S1: Results with the direct prompts": ""
        },
        {
          "Table S1: Results with the direct prompts": ""
        },
        {
          "Table S1: Results with the direct prompts": ""
        },
        {
          "Table S1: Results with the direct prompts": ""
        },
        {
          "Table S1: Results with the direct prompts": ""
        },
        {
          "Table S1: Results with the direct prompts": "LLaMA"
        },
        {
          "Table S1: Results with the direct prompts": ""
        },
        {
          "Table S1: Results with the direct prompts": ""
        },
        {
          "Table S1: Results with the direct prompts": ""
        },
        {
          "Table S1: Results with the direct prompts": ""
        },
        {
          "Table S1: Results with the direct prompts": "Flan-t5"
        },
        {
          "Table S1: Results with the direct prompts": ""
        },
        {
          "Table S1: Results with the direct prompts": "Pythia"
        },
        {
          "Table S1: Results with the direct prompts": ""
        },
        {
          "Table S1: Results with the direct prompts": ""
        },
        {
          "Table S1: Results with the direct prompts": "GLM"
        },
        {
          "Table S1: Results with the direct prompts": ""
        },
        {
          "Table S1: Results with the direct prompts": "RWKV"
        },
        {
          "Table S1: Results with the direct prompts": ""
        },
        {
          "Table S1: Results with the direct prompts": "Claude"
        },
        {
          "Table S1: Results with the direct prompts": ""
        }
      ],
      "page": 33
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Table S2: Results with the assistance of prompt": ""
        },
        {
          "Table S2: Results with the assistance of prompt": "Models"
        },
        {
          "Table S2: Results with the assistance of prompt": ""
        },
        {
          "Table S2: Results with the assistance of prompt": "DaVinci"
        },
        {
          "Table S2: Results with the assistance of prompt": ""
        },
        {
          "Table S2: Results with the assistance of prompt": ""
        },
        {
          "Table S2: Results with the assistance of prompt": ""
        },
        {
          "Table S2: Results with the assistance of prompt": ""
        },
        {
          "Table S2: Results with the assistance of prompt": "Curie"
        },
        {
          "Table S2: Results with the assistance of prompt": ""
        },
        {
          "Table S2: Results with the assistance of prompt": ""
        },
        {
          "Table S2: Results with the assistance of prompt": ""
        },
        {
          "Table S2: Results with the assistance of prompt": ""
        },
        {
          "Table S2: Results with the assistance of prompt": "Babbage"
        },
        {
          "Table S2: Results with the assistance of prompt": ""
        },
        {
          "Table S2: Results with the assistance of prompt": ""
        },
        {
          "Table S2: Results with the assistance of prompt": ""
        },
        {
          "Table S2: Results with the assistance of prompt": ""
        },
        {
          "Table S2: Results with the assistance of prompt": "GPT-3.5-turbo"
        },
        {
          "Table S2: Results with the assistance of prompt": ""
        },
        {
          "Table S2: Results with the assistance of prompt": ""
        },
        {
          "Table S2: Results with the assistance of prompt": ""
        },
        {
          "Table S2: Results with the assistance of prompt": ""
        },
        {
          "Table S2: Results with the assistance of prompt": "text-davinci-001"
        },
        {
          "Table S2: Results with the assistance of prompt": ""
        },
        {
          "Table S2: Results with the assistance of prompt": ""
        },
        {
          "Table S2: Results with the assistance of prompt": ""
        },
        {
          "Table S2: Results with the assistance of prompt": ""
        },
        {
          "Table S2: Results with the assistance of prompt": "text-davinci-002"
        },
        {
          "Table S2: Results with the assistance of prompt": ""
        },
        {
          "Table S2: Results with the assistance of prompt": ""
        },
        {
          "Table S2: Results with the assistance of prompt": ""
        },
        {
          "Table S2: Results with the assistance of prompt": ""
        },
        {
          "Table S2: Results with the assistance of prompt": "text-davinci-003"
        },
        {
          "Table S2: Results with the assistance of prompt": ""
        },
        {
          "Table S2: Results with the assistance of prompt": ""
        },
        {
          "Table S2: Results with the assistance of prompt": ""
        },
        {
          "Table S2: Results with the assistance of prompt": ""
        }
      ],
      "page": 34
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Table S2 Footnote: Table S2 shows the SECEU scores, EQ scores, pattern similarity, and": "properties of OpenAI GPT series with the assistance of prompt."
        },
        {
          "Table S2 Footnote: Table S2 shows the SECEU scores, EQ scores, pattern similarity, and": "Failed: The LLMs cannot complete the test."
        },
        {
          "Table S2 Footnote: Table S2 shows the SECEU scores, EQ scores, pattern similarity, and": "%: The percent of humans whose performance was below that of an LLM in the test."
        },
        {
          "Table S2 Footnote: Table S2 shows the SECEU scores, EQ scores, pattern similarity, and": "Pattern Similarity: The degree of similarity is indexed Pearson correlation coefficient (r)."
        },
        {
          "Table S2 Footnote: Table S2 shows the SECEU scores, EQ scores, pattern similarity, and": "*: p < 0.05; **: p < 0.01."
        }
      ],
      "page": 35
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Figure S1: The distribution of individual performance (i.e., the Euclidean distance between the": "individual‚Äôs answer and the objective standards) on each item (M¬±SD)"
        },
        {
          "Figure S1: The distribution of individual performance (i.e., the Euclidean distance between the": "36"
        }
      ],
      "page": 36
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Will Affective Computing Emerge from Foundation Models and General AI? A First Evaluation on ChatGPT",
      "authors": [
        "M Amin",
        "E Cambria",
        "B Schuller"
      ],
      "year": "2023",
      "venue": "Will Affective Computing Emerge from Foundation Models and General AI? A First Evaluation on ChatGPT",
      "doi": "10.48550/ARXIV.2303.03186"
    },
    {
      "citation_id": "2",
      "title": "Constitutional AI: Harmlessness from AI Feedback",
      "authors": [
        "Y Bai",
        "S Kadavath",
        "S Kundu",
        "A Askell",
        "J Kernion",
        "A Jones",
        "A Chen",
        "A Goldie",
        "A Mirhoseini",
        "C Mckinnon",
        "C Chen",
        "C Olsson",
        "C Olah",
        "D Hernandez",
        "D Drain",
        "D Ganguli",
        "D Li",
        "E Tran-Johnson",
        "E Perez",
        "J Kaplan"
      ],
      "year": "2022",
      "venue": "Constitutional AI: Harmlessness from AI Feedback",
      "arxiv": "arXiv:2212.08073"
    },
    {
      "citation_id": "3",
      "title": "The pattern seekers: How autism drives human invention",
      "authors": [
        "S Baron-Cohen"
      ],
      "year": "2020",
      "venue": "The pattern seekers: How autism drives human invention"
    },
    {
      "citation_id": "4",
      "title": "Does the autistic child have a \"theory of mind",
      "authors": [
        "S Baron-Cohen",
        "A Leslie",
        "U Frith"
      ],
      "year": "1985",
      "venue": "Cognition",
      "doi": "10.1016/0010-0277"
    },
    {
      "citation_id": "5",
      "title": "Language models are few-shot learners",
      "authors": [
        "T Brown",
        "B Mann",
        "N Ryder",
        "M Subbiah",
        "J Kaplan",
        "P Dhariwal",
        "A Neelakantan",
        "P Shyam",
        "G Sastry",
        "A Askell",
        "Others"
      ],
      "year": "2020",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "6",
      "title": "Sparks of Artificial General Intelligence: Early experiments with GPT-4",
      "authors": [
        "S Bubeck",
        "V Chandrasekaran",
        "R Eldan",
        "J Gehrke",
        "E Horvitz",
        "E Kamar",
        "P Lee",
        "Y Lee",
        "Y Li",
        "S Lundberg",
        "H Nori",
        "H Palangi",
        "M Ribeiro",
        "Y Zhang"
      ],
      "year": "2023",
      "venue": "Sparks of Artificial General Intelligence: Early experiments with GPT-4",
      "doi": "10.48550/ARXIV.2303.12712"
    },
    {
      "citation_id": "7",
      "title": "Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality",
      "authors": [
        "W.-L Chiang",
        "Z Li",
        "Z Lin",
        "Y Sheng",
        "Z Wu",
        "H Zhang",
        "L Zheng",
        "S Zhuang",
        "Y Zhuang",
        "J Gonzalez",
        "I Stoica",
        "E Xing"
      ],
      "year": "2023",
      "venue": "Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality"
    },
    {
      "citation_id": "8",
      "title": "Free dolly: Introducing the world's first truly open instruction-tuned llm",
      "authors": [
        "M Conover",
        "M Hayes",
        "A Mathur",
        "X Meng",
        "J Xie",
        "J Wan",
        "S Shah",
        "A Ghodsi",
        "P Wendell",
        "M Zaharia",
        "Others"
      ],
      "year": "2023",
      "venue": "Free dolly: Introducing the world's first truly open instruction-tuned llm"
    },
    {
      "citation_id": "9",
      "title": "jsPsych: Enabling an opensource collaborative ecosystem of behavioral experiments",
      "authors": [
        "J De Leeuw",
        "R Gilbert",
        "B Luchterhandt"
      ],
      "year": "2023",
      "venue": "Journal of Open Source Software",
      "doi": "10.21105/joss.05351"
    },
    {
      "citation_id": "10",
      "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "authors": [
        "J Devlin",
        "M.-W Chang",
        "K Lee",
        "K Toutanova"
      ],
      "year": "2019",
      "venue": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "arxiv": "arXiv:1810.04805"
    },
    {
      "citation_id": "11",
      "title": "Emotional intelligence -A review and evaluation study",
      "authors": [
        "V Dulewicz",
        "M Higgs"
      ],
      "year": "2000",
      "venue": "Journal of Managerial Psychology",
      "doi": "10.1108/02683940010330993"
    },
    {
      "citation_id": "12",
      "title": "Koala: A Dialogue Model for Academic Research",
      "authors": [
        "X Geng",
        "A Gudibande",
        "H Liu",
        "E Wallace",
        "P Abbeel",
        "S Levine",
        "D Song"
      ],
      "year": "2023",
      "venue": "Koala: A Dialogue Model for Academic Research"
    },
    {
      "citation_id": "13",
      "title": "Relationship between Emotional Intelligence and Academic Achievement in Emerging Adults: A Systematic Review",
      "authors": [
        "Z Hanafi",
        "F Noor"
      ],
      "year": "2016",
      "venue": "International Journal of Academic Research in Business and Social Sciences",
      "doi": "10.6007/IJARBSS/v6-i6/2197"
    },
    {
      "citation_id": "14",
      "title": "An automatically discovered chain-of-thought prompt generalizes to novel models and datasets",
      "authors": [
        "K Hebenstreit",
        "R Praas",
        "L Kiesewetter",
        "M Samwald"
      ],
      "year": "2023",
      "venue": "An automatically discovered chain-of-thought prompt generalizes to novel models and datasets",
      "arxiv": "arXiv:2305.02897"
    },
    {
      "citation_id": "15",
      "title": "Measuring Massive Multitask Language Understanding",
      "authors": [
        "D Hendrycks",
        "C Burns",
        "S Basart",
        "A Zou",
        "M Mazeika",
        "D Song",
        "J Steinhardt"
      ],
      "year": "2021",
      "venue": "Measuring Massive Multitask Language Understanding",
      "arxiv": "arXiv:2009.03300"
    },
    {
      "citation_id": "16",
      "title": "Development of Sensitivity to Geometry in Visual Forms",
      "authors": [
        "V Izard",
        "E Spelke"
      ],
      "year": "2009",
      "venue": "Development of Sensitivity to Geometry in Visual Forms"
    },
    {
      "citation_id": "17",
      "title": "Administration of the text-based portions of a general IQ test to five different large language models",
      "authors": [
        "M King"
      ],
      "year": "2023",
      "venue": "Administration of the text-based portions of a general IQ test to five different large language models"
    },
    {
      "citation_id": "19",
      "title": "OpenAssistant Conversations-Democratizing Large Language Model Alignment",
      "authors": [
        "A K√∂pf",
        "Y Kilcher",
        "D Von R√ºtte",
        "S Anagnostidis",
        "Z.-R Tam",
        "K Stevens",
        "A Barhoum",
        "N Duc",
        "O Stanley",
        "R Nagyfi",
        "Others"
      ],
      "year": "2023",
      "venue": "OpenAssistant Conversations-Democratizing Large Language Model Alignment"
    },
    {
      "citation_id": "20",
      "title": "Theory of Mind May Have Spontaneously Emerged in Large Language Models",
      "authors": [
        "M Kosinski"
      ],
      "year": "2023",
      "venue": "Theory of Mind May Have Spontaneously Emerged in Large Language Models",
      "arxiv": "arXiv:2302.02083"
    },
    {
      "citation_id": "21",
      "title": "Just Another Tool for Online Studies\" (JATOS): An Easy Solution for Setup and Management of Web Servers Supporting Online Studies",
      "authors": [
        "K Lange",
        "S K√ºhn",
        "E Filevich"
      ],
      "year": "2015",
      "venue": "PLOS ONE",
      "doi": "10.1371/journal.pone.0130834"
    },
    {
      "citation_id": "22",
      "title": "Does Emotional Intelligence Buffer the Effects of Acute Stress? A Systematic Review",
      "authors": [
        "R Lea",
        "S Davis",
        "B Mahoney",
        "P Qualter"
      ],
      "year": "2019",
      "venue": "Frontiers in Psychology",
      "doi": "10.3389/fpsyg.2019.00810"
    },
    {
      "citation_id": "23",
      "title": "Using Consensus Based Measurement to Assess Emotional Intelligence",
      "authors": [
        "P Legree",
        "J Psotka",
        "T Tremble",
        "D Bourne"
      ],
      "year": "2005",
      "venue": "Using Consensus Based Measurement to Assess Emotional Intelligence"
    },
    {
      "citation_id": "24",
      "title": "The Ability Model of Emotional Intelligence: Principles and Updates",
      "authors": [
        "J Mayer",
        "D Caruso",
        "P Salovey"
      ],
      "year": "2016",
      "venue": "The Ability Model of Emotional Intelligence: Principles and Updates",
      "doi": "10.1177/1754073916639667"
    },
    {
      "citation_id": "25",
      "title": "Emotional intelligence and giftedness",
      "authors": [
        "J Mayer",
        "D Perkins",
        "D Caruso",
        "P Salovey"
      ],
      "year": "2001",
      "venue": "Roeper Review",
      "doi": "10.1080/02783190109554084"
    },
    {
      "citation_id": "26",
      "title": "Emotional intelligence and the construction and regulation of feelings",
      "authors": [
        "J Mayer",
        "P Salovey"
      ],
      "year": "1995",
      "venue": "Applied and Preventive Psychology",
      "doi": "10.1016/S0962-1849(05)80058-7"
    },
    {
      "citation_id": "27",
      "title": "Emotional intelligence as a standard intelligence",
      "authors": [
        "J Mayer",
        "P Salovey",
        "D Caruso",
        "G Sitarenios"
      ],
      "year": "2001",
      "venue": "Emotion",
      "doi": "10.1037/1528-3542.1.3.232"
    },
    {
      "citation_id": "28",
      "title": "Measuring emotional intelligence with the MSCEIT V2",
      "authors": [
        "J Mayer",
        "P Salovey",
        "D Caruso",
        "G Sitarenios"
      ],
      "year": "2003",
      "venue": "Emotion",
      "doi": "10.1037/1528-3542.3.1.97"
    },
    {
      "citation_id": "29",
      "title": "Emotional intelligence and leadership: A review of the progress, controversy, and criticism",
      "authors": [
        "J Mccleskey"
      ],
      "year": "2014",
      "venue": "International Journal of Organizational Analysis",
      "doi": "10.1108/IJOA-03-2012-0568"
    },
    {
      "citation_id": "30",
      "title": "Boosting Theory-of-Mind Performance in Large Language Models via Prompting",
      "authors": [
        "S Moghaddam",
        "C Honey"
      ],
      "year": "2023",
      "venue": "Boosting Theory-of-Mind Performance in Large Language Models via Prompting",
      "doi": "10.48550/ARXIV.2304.11490"
    },
    {
      "citation_id": "31",
      "title": "DERA: Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents",
      "authors": [
        "V Nair",
        "E Schumacher",
        "G Tso",
        "A Kannan"
      ],
      "year": "2023",
      "venue": "DERA: Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents",
      "arxiv": "arXiv:2303.17071"
    },
    {
      "citation_id": "32",
      "title": "",
      "authors": [
        "Openai"
      ],
      "year": "2023",
      "venue": "",
      "arxiv": "arXiv:2303.08774"
    },
    {
      "citation_id": "33",
      "title": "A psychometric evaluation of the Mayer-Salovey-Caruso Emotional Intelligence Test Version 2.0. Intelligence",
      "authors": [
        "B Palmer",
        "G Gignac",
        "R Manocha",
        "C Stough"
      ],
      "year": "2005",
      "venue": "A psychometric evaluation of the Mayer-Salovey-Caruso Emotional Intelligence Test Version 2.0. Intelligence",
      "doi": "10.1016/j.intell.2004.11.003"
    },
    {
      "citation_id": "34",
      "title": "",
      "authors": [
        "B Peng",
        "E Alcaide",
        "Q Anthony",
        "A Albalak",
        "S Arcadinho",
        "H Cao",
        "X Cheng",
        "M Chung",
        "M Grella",
        "K Gv",
        "X He",
        "H Hou",
        "P Kazienko",
        "J Kocon",
        "J Kong",
        "B Koptyra",
        "H Lau",
        "K Mantri",
        "F Mom",
        "R.-J Zhu"
      ],
      "year": "2023",
      "venue": ""
    },
    {
      "citation_id": "35",
      "title": "Emotional Intelligence. Imagination",
      "authors": [
        "P Salovey",
        "J Mayer"
      ],
      "year": "1990",
      "venue": "Cognition and Personality",
      "doi": "10.2190/DUGG-P24E-52WK-6CDG"
    },
    {
      "citation_id": "36",
      "title": "Neural Theory-of-Mind? On the Limits of Social Intelligence in Large LMs",
      "authors": [
        "M Sap",
        "R Lebras",
        "D Fried",
        "Y Choi"
      ],
      "year": "2023",
      "venue": "Neural Theory-of-Mind? On the Limits of Social Intelligence in Large LMs",
      "arxiv": "arXiv:2210.13312"
    },
    {
      "citation_id": "37",
      "title": "Reflexion: Language Agents with Verbal Reinforcement Learning",
      "authors": [
        "N Shinn",
        "F Cassano",
        "B Labash",
        "A Gopinath",
        "K Narasimhan",
        "S Yao"
      ],
      "year": "2023",
      "venue": "Reflexion: Language Agents with Verbal Reinforcement Learning",
      "doi": "10.48550/ARXIV.2303.11366"
    },
    {
      "citation_id": "38",
      "title": "Pragmatics, modularity and mind-reading",
      "authors": [
        "D Sperber",
        "D Wilson"
      ],
      "year": "2002",
      "venue": "Pragmatics, modularity and mind-reading",
      "doi": "10.1111/1468-0017.00186"
    },
    {
      "citation_id": "39",
      "title": "Alpaca: A strong, replicable instruction-following model. Stanford Center for Research on Foundation Models",
      "authors": [
        "R Taori",
        "I Gulrajani",
        "T Zhang",
        "Y Dubois",
        "X Li",
        "C Guestrin",
        "P Liang",
        "T Hashimoto"
      ],
      "year": "2023",
      "venue": "Alpaca: A strong, replicable instruction-following model. Stanford Center for Research on Foundation Models"
    },
    {
      "citation_id": "40",
      "title": "Stanford Alpaca: An Instruction-following LLaMA model",
      "authors": [
        "R Taori",
        "I Gulrajani",
        "T Zhang",
        "Y Dubois",
        "X Li",
        "C Guestrin",
        "P Liang",
        "T Hashimoto"
      ],
      "year": "2023",
      "venue": "GitHub repository. GitHub"
    },
    {
      "citation_id": "41",
      "title": "Multi-Item Discriminability Pattern to Faces in Developmental Prosopagnosia Reveals Distinct Mechanisms of Face Processing",
      "authors": [
        "X Tian",
        "R Wang",
        "Y Zhao",
        "Z Zhen",
        "Y Song",
        "J Liu"
      ],
      "year": "2020",
      "venue": "Cerebral Cortex",
      "doi": "10.1093/cercor/bhz289"
    },
    {
      "citation_id": "42",
      "title": "LLaMA: Open and Efficient Foundation Language Models",
      "authors": [
        "H Touvron",
        "T Lavril",
        "G Izacard",
        "X Martinet",
        "M.-A Lachaux",
        "T Lacroix",
        "B Rozi√®re",
        "N Goyal",
        "E Hambro",
        "F Azhar",
        "A Rodriguez",
        "A Joulin",
        "E Grave",
        "G Lample"
      ],
      "year": "2023",
      "venue": "LLaMA: Open and Efficient Foundation Language Models",
      "arxiv": "arXiv:2302.13971"
    },
    {
      "citation_id": "43",
      "title": "Attention is all you need",
      "authors": [
        "A Vaswani",
        "N Shazeer",
        "N Parmar",
        "J Uszkoreit",
        "L Jones",
        "A Gomez",
        "Kaiser",
        "I Polosukhin"
      ],
      "year": "2017",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "44",
      "title": "Emotional intelligence is‚Ä¶?",
      "authors": [
        "J Warwick",
        "T Nettelbeck"
      ],
      "year": "2004",
      "venue": "Personality and Individual Differences",
      "doi": "10.1016/j.paid.2003.12.003"
    },
    {
      "citation_id": "45",
      "title": "GLM-130B: An Open Bilingual Pre-trained Model",
      "authors": [
        "A Zeng",
        "X Liu",
        "Z Du",
        "Z Wang",
        "H Lai",
        "M Ding",
        "Z Yang",
        "Y Xu",
        "W Zheng",
        "X Xia",
        "W Tam",
        "Z Ma",
        "Y Xue",
        "J Zhai",
        "W Chen",
        "P Zhang",
        "Y Dong",
        "J Tang"
      ],
      "year": "2022",
      "venue": "GLM-130B: An Open Bilingual Pre-trained Model",
      "arxiv": "arXiv:2210.02414"
    },
    {
      "citation_id": "46",
      "title": "A Survey of Large Language Models",
      "authors": [
        "W Zhao",
        "K Zhou",
        "J Li",
        "T Tang",
        "X Wang",
        "Y Hou",
        "Y Min",
        "B Zhang",
        "J Zhang",
        "Z Dong",
        "Y Du",
        "C Yang",
        "Y Chen",
        "Z Chen",
        "J Jiang",
        "R Ren",
        "Y Li",
        "X Tang",
        "Z Liu",
        "J.-R Wen"
      ],
      "year": "2023",
      "venue": "A Survey of Large Language Models",
      "arxiv": "arXiv:2303.18223"
    },
    {
      "citation_id": "47",
      "title": "Judging LLMas-a-judge with MT-Bench and Chatbot Arena",
      "authors": [
        "L Zheng",
        "W.-L Chiang",
        "Y Sheng",
        "S Zhuang",
        "Z Wu",
        "Y Zhuang",
        "Z Lin",
        "Z Li",
        "D Li",
        "E Xing",
        "H Zhang",
        "J Gonzalez",
        "I Stoica"
      ],
      "year": "2023",
      "venue": "Judging LLMas-a-judge with MT-Bench and Chatbot Arena"
    },
    {
      "citation_id": "48",
      "title": "Table S2 shows the SECEU scores, EQ scores, pattern similarity, and properties of OpenAI GPT series with the assistance of prompt. Failed: The LLMs cannot complete the test. %: The percent of humans whose performance was below that of an LLM in the test. Pattern Similarity: The degree of similarity is indexed Pearson correlation coefficient (r)",
      "authors": [
        "Table",
        "Footnote"
      ],
      "venue": "Table S2 shows the SECEU scores, EQ scores, pattern similarity, and properties of OpenAI GPT series with the assistance of prompt. Failed: The LLMs cannot complete the test. %: The percent of humans whose performance was below that of an LLM in the test. Pattern Similarity: The degree of similarity is indexed Pearson correlation coefficient (r)"
    }
  ]
}