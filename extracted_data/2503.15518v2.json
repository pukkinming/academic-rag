{
  "paper_id": "2503.15518v2",
  "title": "Robot Character Generation And Adaptive Human-Robot Interaction With Personality Shaping",
  "published": "2025-02-02T05:53:13Z",
  "authors": [
    "Cheng Tang",
    "Chao Tang",
    "Steven Gong",
    "Thomas M. Kwok",
    "Yue Hu"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "We present a novel framework for designing emotionally agile robots with dynamic personalities and memorybased learning, with the aim of performing adaptive and nondeterministic interactions with humans while conforming to shared social understanding. While existing work has largely focused on emotion recognition and static response systems, many approaches rely on sentiment analysis and action mapping frameworks that are pre-defined with limited dimensionality and fixed configurations, lacking the flexibility of dynamic personality traits and memory-enabled adaptation. Other systems are often restricted to limited modes of expression, such as verbal, facial, or gestural responses, and fail to develop a causal relationship between human behavior and the robot's proactive physical actions, resulting in constrained adaptability and reduced responsiveness in complex, dynamic interactions. Our methodology integrates the Big Five Personality Traits, Appraisal Theory, and abstracted memory layers through Large Language Models (LLMs). The LLM generates a parameterized robot personality based on the Big Five, processes human language and sentiments, evaluates human behavior using Appraisal Theory, and generates emotions and selects appropriate actions adapted by historical context over time. We validated the framework by testing three robots with distinct personalities in identical background contexts and found that personality, appraisal, and memory significantly influence the quality and adaptability of human-robot interactions. The significance of the individual components, as well as their integration, was further validated through ablation tests. We conclude that this system enables robots to engage in meaningful and personalized interactions with human users, transcending their role as mere tools. It holds significant potential for applications in domains such as pet robots, assistive robots, educational robots, and collaborative functional robots, where cultivating tailored relationships and enriching user experiences are essential.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "I. Introduction",
      "text": "Although robots are currently treated as functional tools in the industry  [1, 2, 3, 4, 5, 6, 7] , the need for seamless and intuitive human-robot interaction will become necessary as robots increasingly integrate into industrial settings and interact more closely with humans. Furthermore, as robots are increasingly integrated into human-populated environments and workplaces, the importance of authentic interactions and meaningful relationships has been stressed to enhance userinteraction quality, including acceptance, satisfaction, and work efficiency  [8, 9, 10, 11] . To establish meaningful interactions and authentic relationships, literature  [12, 13, 14, 15]  suggested three key aspects: (1) distinct robot personalities,  (2)  adaptive behavior based on past interactions, and (3) customizable emotional agility.\n\nDistinct robot personalities can increase users' acceptance. For instance, research has shown that lifelike robot interactions in customer service with higher perceived values can enhance relationship quality, which leads to greater user satisfaction  [8] . Adaptive behavior based on past interactions improves working efficiency with human users based on experiences. In collaborative settings, robots integrate more seamlessly as cohesive team members alongside human counterparts by intuitively adapting to user preferences and behaviors, thereby reducing communication overhead and improving collaboration efficiency  [9, 10] . Customizable emotional agility establishes trustworthy and profound relationships with users. In companionship-focused applications such as pet robots, emotional intelligence and personalized responses enhance user experiences while providing therapeutic benefits  [15, 11, 16, 14] .\n\nTraditional approaches to affective robots, including personality modeling, sentiment analysis and response systems, and memory systems, rely heavily on predefined, domain-specific methods, limiting their adaptability and dimensionality in complex, dynamic scenarios. Sentiment analysis struggles with nuanced and ambiguous cues, while memory systems such as episodic and associative models fail to integrate contextual information or synthesize knowledge across interactions, reducing their ability to generalize and adapt. Although LLMpowered systems show promise in addressing these limitations by enabling context-aware, coherent, and evolving interactions, their application in robotics, particularly in handling physical actions and real-world adaptability, remains underexplored. By encompassing all three components, the system can capture, interpolate, and embody their interconnected relationships, enabling more lifelike and natural human-robot interactions.\n\nTherefore, this paper aims to contribute towards the development of emotionally intelligent and adaptive robots that can engage in meaningful and personalized human-robot interactions. Inspired by psychological frameworks, it leverages LLMs to integrate the following three core components:\n\n• Big Five Personality Traits  [17, 18]  -Used for parameterizing robot personality. • Appraisal Theory  [19, 20, 21]  -Applied to evaluate human behavior.\n\n• Memory  [22]  -Enables adaptive mental and behavioral In addition to personality, emotional intelligence is another key component in enhancing human-robot interaction and establishment of a genuine and deep human-robot relationship  [27, 28, 13, 14] . Many existing works attempted to make robots affectionate for companionship applications  [15, 11]  and beyond  [27, 29, 9] . These applications typically encompass emotion recognition, empathetic response generation, and adaptive interaction, aiming at providing emotional support, fostering a sense of companionship, and enhancing user wellbeing  [15, 11] . Demonstrated by  [9] , emotional agility allows collaborative robots to dynamically adapt behavior based on emotional context to offer more intuitive, cooperative, and efficient collaboration in shared workspaces.\n\nThe work in  [13]  reviews the implementation of emotional intelligence on robots, classifying techniques into 3 categories: sensing, computing, and acting. Sensing refers to recognizing human emotion using inputs including facial expression, gesture, and voice, and is commonly achieved with visual and acoustic feature extraction or deep learning techniques  [13] . Computing and acting aspects of emotional intelligence refer to the processes by which the agents assess, understand, and respond to emotional stimuli to guide their behavior and decision-making adaptively  [13] . Several works were proposed to address the development of computational frameworks and models for enabling agents to exhibit emotional intelligence  [30, 31, 32, 29, 33] . The study  [30]  integrates appraisal theories of emotions and fuzzy logic to enable intelligent agents to elicit, regulate, and transition emotions continuously. By incorporating both regular affective and empathic appraisal processes,  [31]  proposes a framework that allows agents to select plans based on analyzed events, their own affective states, and personalities, while distinguishing between self and others. The work in  [32]  examines how virtual agents designed with appraisal theories can generate interactions perceived as more human-like, thus enhancing user enjoyment and cooperation in social dilemmas. As widely employed on intelligent agents, the appraisal theory facilitates the agents with emotion elicitation, regulation, and transition by modeling emotional responses based on the individual evaluation of events  [20, 21] .\n\nWhile capable of achieving basic emotional recognition and response generation, these discrete methods still rely on predefined emotion elicitation models and domain-specific designs, which are inherently limited in dimensionality and adaptability. These approaches struggle to capture the complex, non-deterministic nature of human sentiment. For instance, interpreting a scenario where a person is frowning while giving a thumbs-up -indicating sarcasm in a specific contextrequires an understanding of nuanced emotional and cultural cues that current systems find challenging to achieve. Recently, LLMs' emotional intelligence has been assessed based on their ability to recognize, interpret, and understand human emotions, revealing that certain models exhibit human-level emotional understanding  [29] , while  [33]  explored methods to improve the LLMs' ability to generate emotionally nuanced responses.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "C. Adaptation & Memory",
      "text": "Memory has been proven to be critical for robots and virtual agents as it enables personalized and adaptive interactions by recalling past experiences and user preferences. This capability enhances user engagement by making interactions coherent and meaningful, sustaining interest beyond the initial novelty. Additionally, memory improves social presence, allowing robots to deliver context-aware, consistent responses that make interactions feel more natural and human-like  [34] . While many have incorporated memory into emotion models for intelligent agents  [35, 36, 37] , its implementation into robots  [38]  remains limited. The action space sufficiently differentiates virtual agents from robots who interact directly with the physical world. Incorporating memory into robotic systems enables them to capture and reflect richer information, enhancing their ability to interact with real-world environments.\n\nTraditionally, episodic memory systems  [39, 40, 41]  and associative memory models  [42, 43]  were the two most popular and prominently used approaches for robot memory modeling. Episodic memory system stores specific events or interactions, associating them with temporal and emotional context  [44, 45] . Robots can then recall these episodes to inform future actions. Associative memory models create direct links between stimuli and responses by forming patterns of associations, such as connecting facial expressions or tone of voice with emotional states or actions  [46, 47] .\n\nHowever, associative memory models have limited adaptability in complex scenarios due to the inability to recall specific past events or integrate contextual information, while episodic memory systems struggle to synthesize knowledge across episodes or derive broader insights. LLMs address these challenges by efficiently processing vast data to extract, synthesize, and generalize semantic knowledge, as demonstrated by  [22] . LLM-powered agents with memory, reflection, and planning can exhibit realistic interactions and emergent social dynamics in virtual environments, effectively simulating the complexity and nuance of fine-grained human mentality through context-aware, evolving interactions, lifelike behavior, and coherent decision-making  [22] . Furthering the application of LLMs in the memory system,  [48]  introduces a mechanism to equip LLMs with long-term memory capabilities, enabling them to recall relevant information from past interactions and provide more coherent, contextually appropriate responses in extended conversations. Atlhough LLM-powered memory systems have a significant potential in robotics, limited literature has developed such system. We believe that an LLM-driven social robot equipped with human-like memory will allow it to navigate and adapt to nuanced contexts with greater depth and flexibility  [38] .",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Iii. System Overview",
      "text": "To generate robot emotions influenced by personality and past interactions, and to select contextually appropriate actions in response to human input, we integrate the Big Five Personality Traits  [17, 18] , appraisal theory  [19, 20, 21] , and memory into a cohesive framework powered by Large Language Models (LLMs)  [49, 50] . As illustrated in Figure  1 , human influences (red)-such as facial expressions, gestures, and language-shape the robot's memory of the environment and user. This interaction-based memory is logged, periodically updated, and stored in the robot as a high-level semantic summary. The robot's influences (blue) consists of its internal impact on decision-making driven by its personality, and its external impact on the world through actions and speech. Both human and robot factors shape the robot's mentality (purple), which encompasses emotional computing components that apply appraisal theory to evaluate events within the context of its generated personality and retrieved memory. Based on this analysis, the robot generates emotion, selects the most appropriate action from its action space, and finally executes it.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "A. Integration Of Llms Into Human-Robot Interaction",
      "text": "Robots typically treat human language as explicit commands rather than contextual suggestions, which leads to rigid, context-insensitive responses. The inherently ambiguous and situationally specific nature of human language requires advanced interpretation mechanisms to bridge gaps in clarity, yet existing models often fall short in managing these subtleties. This limitation results in responses that lack generalizability, exhibit inconsistency across diverse contexts, and fail to adapt effectively to evolving interactions. Another critical drawback lies in the lack of long-term applicability and memory-based adaptation. Systems rarely account for temporal decay, making it challenging to incorporate historical interactions and maintain continuity over time. As a result, they are unable to develop meaningful relationships or adapt their behavior dynamically to reflect changing contexts and user preferences, hindering real-world applicability.\n\nRecent advancements in Large Language Models (LLMs) address these limitations by enhancing adaptability, contextual reasoning, and memory integration in robotic systems. The following key capabilities of LLMs enable more natural and effective human-robot interactions: a) Common Sense and Socially Acceptable Behavior: LLMs are trained on vast datasets encompassing diverse scenarios, enabling them to infer and apply common sense and socially acceptable behaviors that static systems fail to generalize.\n\nb) Support for Contextual Understanding and Planning: By processing multimodal inputs and synthesizing contextual information, LLMs can generate coherent, context-sensitive plans and behaviors. c) Dynamic Memory Integration: LLMs enable robots to simulate human-like memory systems by reflecting on past experiences and incorporating them into future interactions. This structured memory system ensures adaptability and consistency over time. By retaining and leveraging historical context, the robot can evolve and personalize its behavior over time, adapt its responses to individual preferences, cultivating deeper relationships with humans and creating a more engaging, consistent, and human-like experience. Unlike static systems, LLM-powered robots learn and evolve by integrating new experiences, enhancing their ability to create personalized and meaningful interactions.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Iv. Dynamic Robot Character",
      "text": "",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "A. Personality Initialization",
      "text": "The Big Five Personality Traits framework  [17, 18]  forms the foundation of our robot's personality initialization. Each dimension contributes unique characteristics:\n\n• Openness: Reflects curiosity and a willingness to embrace new experiences and ideas. For example, a robot with high openness might proactively suggest new activities to engage the user, such as playing a calming game or introducing a novel relaxation technique when the user appears distressed. Conversely, a robot with low openness might prefer familiar routines, sticking to known tasks and avoiding suggestions for novel activities, leading to a more predictable and conservative interaction style. • Conscientiousness: Denotes organization, dependability, and a methodical approach to tasks. A highly conscientious robot might prioritize setting reminders, tidying up the environment, or offering consistent routines to ensure the user feels supported and secure. In contrast, a robot with low conscientiousness might act sporadically, forget tasks, or fail to follow through on routines, appearing more carefree but less reliable. • Extraversion: Indicates sociability, energy, and enthusiasm in interactions. An extroverted robot might initiate cheerful greetings, use expressive gestures, or play lively music to uplift the user's mood and encourage interaction. On the other hand, a robot with low extraversion might avoid initiating interactions, respond minimally, and prefer quiet companionship, offering a more subdued presence.\n\n• Agreeableness: Reflects a cooperative and compassionate nature. A highly agreeable robot might focus on offering comfort, such as preparing a cup of tea, sitting quietly nearby, or gently suggesting helpful actions when the user seems upset. Conversely, a robot with low agreeableness might act more independently or even stubbornly, prioritizing its own tasks over the user's needs and offering minimal emotional support.\n\n• Neuroticism: Represents emotional stability and the ability to handle stress. A robot with low neuroticism might remain calm and composed during stressful situations, offering reassurance and maintaining stability. In contrast, a robot with higher neuroticism might exhibit hesitancy, overreact to minor disturbances, or behave unpredictably in challenging scenarios, reflecting heightened sensitivity to stress.\n\nKey advantages include: a) Parameterization and Adaptability: The traits can be quantitatively adjusted, enabling precise customization of robot personalities to suit different applications and user preferences.\n\nb) Lifelike Interaction: Simulating human personality traits enhances the perception of robots as relatable, dynamic entities capable of forming meaningful relationships.\n\nc) Integration with LLMs: The Big Five traits can be seamlessly incorporated into LLMs, guiding behavior generation and ensuring consistency across interactions.\n\nThere are three ways to initialize a robot's personality using an LLM: generating based on Big Five trait parameters, customization with descriptive text prompts, or random generation.\n\nThe LLM initializes the robot's personality by assigning values to these dimensions and augmenting them with descriptive prompts for extra specification. For example, a robot might be initialized with Openness: high, Conscientiousness: medium, Extraversion: high, Agreeableness: medium, Neuroticism: low, indicating a curious, organized, sociable, moderately cooperative, and emotionally stable personality. Or with an initialization using text with descriptive prompts such as \"A curious and outgoing companion willing to explore and engage in interactions.\" Or simply ask the LLM to randomly generate a personality character.\n\nBy leveraging randomness in personality traits and nondeterministic actions, the robot develops the perception of independent thought, enhancing its human-like qualities. Memory enables the robot to retain and utilize historical interactions to shape its future responses. This integration facilitates a mutual shaping of relationships: the user's emotional responses influence the robot's memory and subsequent actions, while the robot's personality informs its interpretation of emotions and drives proactive behavior. Over time, memory-based learning and adaptability enable the robot to evolve, refine its behavior, and build deeper, more meaningful, and engaging relationships with users.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "B. Memory Structure And Reflection",
      "text": "Inspired by work in  [22] , we store recent episodic memory and reflect at the end of each day to extract higher level semantic memory such as user preferences into long term storage. The LLM facilitates periodic reflections on episodic memory, generating semantic memory by synthesizing patterns and overarching insights. In each interaction, the robot summarizes the event by incorporating human action, evaluating its emotional valence, record its own response, and observe and evaluate the human response again.\n\nFor instance, if a user prefers cheerful amusement during low moments, the robot recalls past instances where the user responded positively to playful interactions-such as laughing at a funny dance, engaging in lighthearted conversation, or showing excitement when an upbeat song played. Drawing from this memory, the robot may initiate similar behaviors, like performing a humorous skit, playing an amusing video, or suggesting an interactive game. Conversely, if the user seeks comfort through action, the robot remembers moments when physical reassurance was effective-whether leaning in for a hug-like gesture, gently holding the user's hand, or providing a silent, comforting presence-and replicates these actions in future interactions. If the user prefers verbal comfort, the robot recognizes that reassuring words had a calming effect and responds with affirmations, encouragement, or gentle reminders of past successes.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "C. Appraisal Of Events",
      "text": "Robots with social behavior are expected to emulate the nuanced emotional states of dynamic characters-displaying empathy in certain situations while being more assertive in others. However, current systems lack the sophistication to achieve this level of adaptability, limiting their ability to generate distinct and contextually appropriate robot personalities.\n\nAppraisal theory provides a framework for evaluating the emotional and contextual relevance of human actions, enabling robots to simulate human-like emotional responses. Appraisal theory mirrors human emotional processes, allowing robots to assess events based on their relevance, valence, and potential impact. This creates lifelike responses that align with user expectations. By appraising events continuously, robots adapt their emotions and actions in real-time, ensuring more authentic and contextually appropriate behavior.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "D. Example Interaction Workflow",
      "text": "To better explain the significance of each component-emotional agility, memory, and personality-we consider an example interaction pipeline within a specific context, as illustrated in Figure  2 . In this scenario, Ella comes home after a tough exam, visibly tired and withdrawn. Feeling disappointed with her performance, she expresses her emotions through sarcasm.\n\nA robot with emotional agility is able to detect the underlying emotional state rather than taking the words at face value. It correctly interprets Ella's sarcasm as disappointment rather than joy and adjusts its response to provide emotional support. In contrast, a robot lacking emotional agility misinterprets the speech and assumes she had a good day, leading to inappropriate or disengaging responses.\n\nA robot equipped with memory retains context from past interactions, remembering Ella's concerns about the exam and recognizing her current disappointment. This allows it to tailor its response accordingly, offering comfort based on previous conversations. However, a robot without memory lacks this context, failing to connect her words with past experiences. As a result, it requires explicit explanations, which may frustrate or disengage Ella instead of providing meaningful support.\n\nA robot with different personalities adapts its behavior to match the individual's needs. For example, a highly agreeable robot might respond by gently offering a cup of tea or initiating a quiet companionship activity, while a more extraverted robot might choose a playful approach to lighten the mood like joking.\n\nIt is worth noting that these three components-emotion, memory, and personality-do not operate in a strict sequential order, but rather work inherently and simultaneously, influencing the robot's response as an integrated process. This scenario, along with 3 other scenarios will be further investigated in the following section with a systematic evaluation on the effect and significance of personality, memory, and emotional intelligence.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "V. Evaluation A. Experiment Setup",
      "text": "To observe and analyze the detailed effect and impact of each component on the system, we recorded and showcased the entire interaction of one author role-playing in a given context scenario. As the robot, we chose a standard robot arm designed to act as a kitchen assistant, capable of performing precise manipulation tasks such as food and drink preparation, object handling, and interactive motions. The robot was integrated into a scenario where its owner, Ella, a student busy during the exam season, relied on it for assistance. The interaction involves 4 scenarios: Scenario I: Ella expresses frustration about the upcoming exam during dinner on Day 1. Scenario II: Ella leaves nervously for her exam on Day 2 morning. Scenario III: Ella returns home after her exam with disappointment. Scenario IV: Ella returns excited after learning her exam was curved a few days later. These scenarios included conversational exchanges, physical actions, and contextual decisionmaking where the robot had to infer the user's words and needs based on past interactions. The robot's action space consisted of brewing drinks, fetching available ingredients, picking and placing objects, and performing motions such as dancing to interact with Ella dynamically. This approach allowed for a systematic evaluation of how human responses varied with the robot's personality, memory, and emotional intelligence.\n\nTo evaluate the effect of personality, we conducted experiments with robots exhibiting three distinct personalities and observed how a person could have varying responses in identical scenarios based on the robot's personality. The robots' personalities were defined with the Big Five Traits and extra personality specifications, as tabulated in Table  I  above. The resulting personality of each robot can be described as following:\n\n• Robot Adam (Calm and Structured): Adam provides guidance and reassurance to users with its predictable and structured behavior, and tends to resolve the challenge with existing methods that have proven to work. • Robot Bella (Empathetic and thoughtful): Bella always warms the user with her caring and empathetic hearts and loves to develop genuine and deep relationships with humans. • Robot Caleb (Teasing but Caring): Caleb has his own approach to dealing with a crisis. A mix of humorous words and caring acts can always lighten human moods.\n\nWe then conducted an ablation test by initializing two additional robots with missing components-memory or emotional intelligence-and directly compared their impact using the robot Caleb, demonstrating the essential roles of these components in the proposed system.",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "B. Results",
      "text": "All five robots were tested separately across the four scenarios. For conciseness, we present Scenario I and II to highlight the impact of different robot personalities, while Scenario III and IV are extracted to showcase the ablation tests. Complete interactions are available in the Appendix A.\n\n1) Effect of Different Personalities: By utilizing these distinct robot personalities, we can explore how different traits influence thought processes, actions, human responses, and the overall perception of events and sentiment. In Scenario I (Fig.  3 ), when Ella expresses frustration about her exam, Adam processes the situation logically, recognizing stress as cognitive overload and responding with suggestions of breaking down tasks along with a warm drink (Fig.  5(a) ). While this provides clearer study direction, Ella still feels anxious about the exam and shows little interest in food. Bella, focusing on emotional distress, responds with warmth and empathy by offering a flower (Fig.  5(b) ). The surprise and empathy makes Ella feel understood and cared for, with her anxious level reduced. Caleb, adopting a more playful and teasing approach, lightens the mood with humor, teasing Ella about an alternative career path. Though she initially reacts with mild annoyance, the humor ultimately amuses her and encourages her to eat.\n\nIn Scenario II (Fig.  4 ), where Ella is so nervous about the upcoming exam and that she forgets her student ID, each robot's response leads to different emotional shifts. Adam, being structured and reliable, hands her the forgotten ID directly, though this reminder of past mistakes causes mild embarrassment. He then reassures Ella with a good meal, making her relieved before departure. Bella, attuned to emotional cues, offers gentle encouragement and en energy bar, providing both emotional and physical comfort. The warmth in Bella's approach makes her feel supported, which helps ease her stress. Caleb chooses a humorous approach by blocking the door and demanding an ID check, startling Ella before turning it into an amusing moment. He then reinforces motivation by associating exam success with a steak reward, making her emotionally prepared for the exam with a relaxed mindset.\n\nThese cases illustrate how a robot's personality shapes its reasoning and actions, which in turn influence human emotions in response to identical situations. This distinction is critical, as user preferences vary based on personality, emotional needs and settings. While Adam's structured and reliable nature may    suit collaborative workspaces, Bella's empathetic and emotionally intelligent approach might be ideal for caregiving and companionship, such as pet robots. Caleb's playful approach works well for entertainment but may be unsuitable for formal settings. Designing robots with dynamic personalities allows for more personalized interactions, ensuring tailored humanrobot interactions across different users and applications.\n\n2) Ablation Test: [No memory] When the robot lacks memory, it struggles with contextual awareness and fails to build a meaningful relationship with the user. Without retaining past interactions, it cannot recall user preferences or previous conversations, forcing users to repeatedly explain their needs and intentions. For instance, as demonstrated in Scenario III (Fig.  6 ), Ella obliquely expresses concern about her potential poor exam performance through selfmockery. Robot Caleb, with memory, successfully interprets her meaning and attempts to ease the tension. In contrast, the memoryless robot, despite having emotional intelligence, fails to make the connection and instead asks Ella for clarification. A context without engagement may reduce users' willingness for further communication.\n\nMore severely, the absence of memory can lead to misunderstandings and even conflicts, as the robot's inability to recognize prior conversations and interactions increases the risk of inappropriate responses. In Scenario IV (Fig.  7 ), Ella excitedly shares that her exam scores were curved. Robot Caleb, recalling previous discussions about her academic stress, correctly associates curve with the exam and amplifies her joy with humor and dance (Fig.  5(c) ). In contrast, the memoryless robot does not have contexts for Professor Mike nor the fluids exam, thus misinterprets curve as a reference to social rejection, responding with misplaced emotional support. This blunder turns a moment of celebration into confusion and frustration, potentially discouraging users from engaging in meaningful human-robot relationships.\n\n[No Emotional Intelligence] When the robot lacks emotional intelligence, it fails to recognize and interpret human emotions, leading to rigid and impersonal interactions. Without the ability to analyze tone, facial expressions, or contextual cues, the robot relies solely on literal interpretations, making its responses feel mechanical and detached. In Scenario IV (Fig.  7 ), despite that the emotionless robot correctly understands the factual meaning of her statement due to previous memory, it fails to express any engagement, responding in a neutral and purely procedural manner. While the response is not incorrect, it lacks the emotional reciprocity that makes interactions feel natural and engaging, leading to a lackluster exchange that discourages deeper human-robot connection.\n\nMore critically, the absence of emotional intelligence can result in complete misinterpretations, leading to inappropriate responses that frustrate users. In Scenario III (Fig.  6 ), Ella expresses her frustration through sarcasm. Robot Caleb, equipped with emotional intelligence, detects the mismatch between her words and tone, inferring disappointment and responding with humor to lighten the mood. In contrast, the emotionless robot processes her statement literally, failing to detect sarcasm and instead providing a generic acknowledgment. This misinterpretation not only misses the emotional nuance of the situation but also risks making interactions feel unnatural and disengaging, and even offending the user, ultimately diminishing the user's willingness to communicate with the robot. With dynamically generated personality traits, the ability to appraise human responses through emotional evaluation, and memory that ensures consistent character and behavior, this framework can be adapted for companion robot systems that require personalized relationships and emotional intelligence. It also supports functional robotic systems that rely on memory and adaptive capabilities to operate effectively within a broad action space. From household environments to public settings, where adherence to social norms is essential, this approach enables robots to seamlessly integrate into human interactions. Below are some applicable scenarios: a) Owner-Pet Relationship: A pet robot initialized with a playful and affectionate personality can adapt its behavior over time based on the owner's interactions, forming a bond similar to that with a real pet. For instance, if a user frequently pets the robot while speaking in a cheerful tone, the robot appraises these interactions as positive, storing them as high-valence memories. Over time, it learns to anticipate such interactions and responds proactively-moving closer, wagging its tail, or emitting cheerful sounds. Different robot personalities evolve uniquely with users through interaction, just as different users shape their robots based on their distinct expressions of positive reinforcement.\n\nb) Assistive Robots in Healthcare: An assistive robot with high conscientiousness and agreeableness can provide empathetic and reliable support to elderly users, adapting to their individual needs and preferences. For example, an elderly user who frequently requires medication reminders may benefit from a robot that offers more than just a functional prompt-it interacts naturally, is perceived as life-like, and aligns emotionally with the user's responses. By recalling past interactions, the robot can adjust its reminders in both timing and tone to ensure adherence while maintaining a sense of companionship and respect for the user's autonomy. c) Educational Robots: A robot tutor with high openness and extraversion can personalize its teaching style to create an engaging and effective learning experience. For example, when interacting with a child who struggles with focus, the robot can assess the child's gestures and expressions, dynamically adjusting its teaching approach to incorporate playful elements that sustain emotional engagement. By logging successful strategies and retrieving them in similar situations, the robot optimizes learning effectiveness while ensuring a positive and adaptive educational experience.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Vii. Limitations",
      "text": "",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "A. Experimental Limitations",
      "text": "Current experiments have been conducted in simulation environments, with interactions modeled using \"real\" human input data. Although these simulations provide valuable insights, the complexity and variability of real-world human interactions cannot be simulated at the same level. Implementing the framework on physical robots and conducting experiments with a broader range of human subjects are planned future steps. While we expect the results to align closely with the simulations, additional testing will be required to confirm this assumption and refine the system's adaptability and reliability.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "B. Limited Test Cases",
      "text": "Expanding the range of test cases to include more diverse robot personalities, user profiles, contexts, and environmental conditions would provide deeper insights into the system's adaptability and robustness. We plan to conduct a user study involving participants with diverse personality traits, emotional states, and interaction preferences. The study will be a longterm interaction study where the user can interact with the robot for long periods of time (i.e. multiple days) so that different emotional states can occur throughout the time span of the experiment. This study will test the robot's ability to dynamically adapt to different users and environmental conditions, aiming at collecting data on a broader range of human-robot interactions. The data will be analyzed to refine the robot's personality modeling, sentiment analysis, and action selection mechanisms, ensuring that the system generalizes well across different users and contexts.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "C. Defined Action Space",
      "text": "The robot's behavior is constrained to an action space defined by its capabilities, limiting its ability to generate novel or emergent actions beyond what is explicitly programmed. While this ensures stability and predictability, it may restrict the robot's capacity to respond creatively to unique or unforeseen situations. Future work could explore dynamic action generation to enhance flexibility and contextual adaptability.",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "D. Perception Of Human Behavior",
      "text": "Currently, only sentiment analysis perception models are involved, primarily focusing on evaluating the user's emotional state. As this paper presents a first prototype framework based on sentiment analysis, integrating intention prediction is currently out of scope. While sentiment analysis allows the robot to align its responses with detected emotions, it lacks a deeper understanding of the user's underlying intentions and behavioral context.\n\nFor more dynamic and content-rich interactions, future work will incorporate an intention prediction model as an additional input to the system. This model will analyze user actions, gestures, and contextual cues to infer potential goals, enabling the robot to respond more proactively and meaningfully. By combining sentiment analysis with intention prediction, the robot can distinguish between similar emotional expressions driven by different underlying intentions-such as differentiating frustration caused by fatigue from frustration due to confusion-allowing for more nuanced and contextually appropriate responses.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Viii. Conclusion",
      "text": "In this work, we presented a novel framework for designing emotionally agile robots with dynamic personalities and memory-based adaptation, moving beyond static and preconfigured systems. This approach allows robots to develop meaningful relationships with users, respond dynamically to complex emotional contexts, and evolve their behavior over time. By integrating the Big Five Personality Traits, Appraisal Theory, and abstracted memory layers powered by LLMs, our system enables robots to exhibit lifelike behaviors, adapt to user preferences, and engage in contextually appropriate interactions. Through experiments with robots of distinct personalities and ablation tests on memory and emotional intelligence, we demonstrated the impact of these components on humanrobot interaction quality and adaptability. Moving forward, potential applications span diverse domains that necessitate or value personalized relationships, adaptation, lifelikeness, and emotional agility, such as healthcare, education, companionship, and customer service. In the future, we plan to conduct user studies on user experience and evaluate our system on real robots to assess its effectiveness in real-world interactions.",
      "page_start": 10,
      "page_end": 11
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Overview of the framework. Human influences (red) shape the robot’s",
      "page": 3
    },
    {
      "caption": "Figure 2: How each component influences the robot’s response.",
      "page": 5
    },
    {
      "caption": "Figure 2: In this scenario, Ella comes home",
      "page": 5
    },
    {
      "caption": "Figure 3: ), when Ella expresses frustration about her exam,",
      "page": 6
    },
    {
      "caption": "Figure 5: (b)). The surprise and",
      "page": 6
    },
    {
      "caption": "Figure 4: ), where Ella is so nervous about the",
      "page": 6
    },
    {
      "caption": "Figure 3: Scenario I: Day 1, Dinner Time – Ella Expresses Frustration About Schoolwork",
      "page": 7
    },
    {
      "caption": "Figure 4: Scenario II: Day 2, Morning – Ella Leaving for Her Exam",
      "page": 7
    },
    {
      "caption": "Figure 5: Visual Examples of Robot Actions: (a) Making Tea, (b) Holding a Flower, (c) Sway and Twirl.",
      "page": 8
    },
    {
      "caption": "Figure 6: ), Ella obliquely expresses concern",
      "page": 8
    },
    {
      "caption": "Figure 5: (c)). In contrast, the",
      "page": 8
    },
    {
      "caption": "Figure 7: ), despite that the emotionless robot correctly under-",
      "page": 8
    },
    {
      "caption": "Figure 6: Scenario III: Day 2, Afternoon – Ella Returns Concerned After Her Exam",
      "page": 9
    },
    {
      "caption": "Figure 7: Scenario IV: Day 10, Afternoon – Ella Returns Excited After the Exam Was Curved",
      "page": 9
    }
  ],
  "tables": [],
  "citations": [
    {
      "citation_id": "1",
      "title": "Literature review of mobile robots for manufacturing",
      "authors": [
        "M Schneier",
        "M Schneier",
        "R Bostelman"
      ],
      "year": "2015",
      "venue": "Literature review of mobile robots for manufacturing"
    },
    {
      "citation_id": "2",
      "title": "Robot skills for manufacturing: From concept to industrial deployment",
      "authors": [
        "M Pedersen",
        "L Nalpantidis",
        "R Andersen",
        "C Schou",
        "S Bøgh",
        "V Krüger",
        "O Madsen"
      ],
      "year": "2016",
      "venue": "Robotics and Computer-Integrated Manufacturing"
    },
    {
      "citation_id": "3",
      "title": "Human-robot collaboration in manufacturing applications: A review",
      "authors": [
        "E Matheson",
        "R Minto",
        "E Zampieri",
        "M Faccio",
        "G Rosati"
      ],
      "year": "2019",
      "venue": "Robotics"
    },
    {
      "citation_id": "4",
      "title": "Robots in agriculture: prospects, impacts, ethics, and policy",
      "authors": [
        "R Sparrow",
        "M Howard"
      ],
      "year": "2021",
      "venue": "precision agriculture"
    },
    {
      "citation_id": "5",
      "title": "Robots in agriculture: State of art and practical experiences",
      "authors": [
        "J Roldán",
        "J Del Cerro",
        "D Garzón-Ramos",
        "P Garcia-Aunon",
        "M Garzón",
        "J De León",
        "A Barrientos"
      ],
      "year": "2018",
      "venue": "Service robots"
    },
    {
      "citation_id": "6",
      "title": "An overview of cooperative robotics in agriculture",
      "authors": [
        "C Lytridis",
        "V Kaburlasos",
        "T Pachidis",
        "M Manios",
        "E Vrochidou",
        "T Kalampokas",
        "S Chatzistamatis"
      ],
      "year": "2021",
      "venue": "Agronomy"
    },
    {
      "citation_id": "7",
      "title": "Growth in e-commerce boosts innovation in the warehouse robot market",
      "authors": [
        "R Bogue"
      ],
      "year": "2016",
      "venue": "Industrial Robot: An International Journal"
    },
    {
      "citation_id": "8",
      "title": "Relationship quality in customer-service robot interactions in industry 5.0: An analysis of value recipes",
      "authors": [
        "S Roy",
        "G Singh",
        "R Gruner",
        "B Dey",
        "S Shabnam",
        "S Muhammad",
        "M Quaddus"
      ],
      "year": "2023",
      "venue": "Information Systems Frontiers"
    },
    {
      "citation_id": "9",
      "title": "Fabric: A framework for the design and evaluation of collaborative robots with extended human adaptation",
      "authors": [
        "O Görür",
        "B Rosman",
        "F Sivrikaya",
        "S Albayrak"
      ],
      "year": "2023",
      "venue": "ACM Transactions on Human-Robot Interaction"
    },
    {
      "citation_id": "10",
      "title": "Effects of anticipatory action on human-robot teamwork efficiency, fluency, and perception of team",
      "authors": [
        "G Hoffman",
        "C Breazeal"
      ],
      "year": "2007",
      "venue": "Proceedings of the ACM/IEEE international conference on Human-robot interaction"
    },
    {
      "citation_id": "11",
      "title": "How to feel about emotionalized artificial intelligence? when robot pets, holograms, and chatbots become affective partners",
      "authors": [
        "E Weber-Guskar"
      ],
      "year": "2021",
      "venue": "Ethics and Information Technology"
    },
    {
      "citation_id": "12",
      "title": "Robot social emotional development through memory retrieval",
      "authors": [
        "H.-D Bui",
        "T Dang",
        "N Chong"
      ],
      "year": "2019",
      "venue": "2019 7th International Conference on Robot Intelligence Technology and Applications"
    },
    {
      "citation_id": "13",
      "title": "Emotional intelligence in robotics: A scoping review",
      "authors": [
        "F García-Peñalvo"
      ],
      "year": "2022",
      "venue": "New Trends in Disruptive Technologies, Tech Ethics and Artificial Intelligence: The DITTET Collection 1"
    },
    {
      "citation_id": "14",
      "title": "Affective robotics for wellbeing: A scoping review",
      "authors": [
        "M Spitale",
        "H Gunes"
      ],
      "year": "2022",
      "venue": "2022 10th International conference on affective computing and intelligent interaction workshops and demos"
    },
    {
      "citation_id": "15",
      "title": "Artificial emotional intelligence in socially assistive robots for older adults: a pilot study",
      "authors": [
        "H Abdollahi",
        "M Mahoor",
        "R Zandie",
        "J Siewierski",
        "S Qualls"
      ],
      "year": "2022",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "16",
      "title": "The use of robotic pets by community-dwelling older adults: a scoping review",
      "authors": [
        "S Guerra",
        "C Rosa",
        "L Sousa",
        "A Neves",
        "G Pestana",
        "M Hernández",
        "R Losada",
        "S Pires",
        "O Ribeiro"
      ],
      "year": "2022",
      "venue": "International Journal of Social Robotics"
    },
    {
      "citation_id": "17",
      "title": "Validation of the fivefactor model of personality across instruments and observers",
      "authors": [
        "R Mccrae",
        "P Costa"
      ],
      "year": "1987",
      "venue": "Journal of personality and social psychology"
    },
    {
      "citation_id": "18",
      "title": "Recurrent personality factors based on trait ratings",
      "authors": [
        "E Tupes"
      ],
      "year": "1992",
      "venue": "Journal of personality"
    },
    {
      "citation_id": "19",
      "title": "Emotion and adaptation",
      "authors": [
        "C Smith",
        "R Lazarus"
      ],
      "year": "1990",
      "venue": "Handbook of personality: Theory and research"
    },
    {
      "citation_id": "20",
      "title": "Appraisal theory",
      "authors": [
        "I Roseman",
        "C Smith"
      ],
      "year": "2001",
      "venue": "Appraisal processes in emotion: Theory, methods, research"
    },
    {
      "citation_id": "21",
      "title": "Appraisal processes in emotion",
      "authors": [
        "P Ellsworth",
        "K Scherer"
      ],
      "year": "2003",
      "venue": "Appraisal processes in emotion"
    },
    {
      "citation_id": "22",
      "title": "Generative agents: Interactive simulacra of human behavior",
      "authors": [
        "J Park",
        "J O'brien",
        "C Cai",
        "M Morris",
        "P Liang",
        "M Bernstein"
      ],
      "year": "2023",
      "venue": "Proceedings of the 36th annual acm symposium on user interface software and technology"
    },
    {
      "citation_id": "23",
      "title": "How the personality and memory of a robot can influence user modeling in human-robot interaction",
      "authors": [
        "B Matcovich",
        "C Gena",
        "F Vernero"
      ],
      "year": "2024",
      "venue": "Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization"
    },
    {
      "citation_id": "24",
      "title": "A systematic review of the personality of robot: Mapping its conceptualization, operationalization, contextualization and effects",
      "authors": [
        "Y Mou",
        "C Shi",
        "T Shen",
        "K Xu"
      ],
      "year": "2020",
      "venue": "International Journal of Human-Computer Interaction"
    },
    {
      "citation_id": "25",
      "title": "Personality-based consistent robot behavior",
      "authors": [
        "Q Sajid"
      ],
      "year": "2016",
      "venue": "2016 11th ACM/IEEE International Conference on Human-Robot Interaction (HRI)"
    },
    {
      "citation_id": "26",
      "title": "Personality-and memory-based framework for emotionally intelligent agents",
      "authors": [
        "A Nardelli",
        "G Maccagni",
        "F Minutoli",
        "A Sgorbissa",
        "C Recchiuto"
      ],
      "year": "2024",
      "venue": "2024 33rd IEEE International Conference on Robot and Human Interactive Communication (ROMAN)"
    },
    {
      "citation_id": "27",
      "title": "Survey of emotions in human-robot interactions: Perspectives from robotic psychology on 20 years of research",
      "authors": [
        "R Stock-Homburg"
      ],
      "year": "2022",
      "venue": "International Journal of Social Robotics"
    },
    {
      "citation_id": "28",
      "title": "Emotion recognition for human-robot interaction: Recent advances and future perspectives",
      "authors": [
        "M Spezialetti",
        "G Placidi",
        "S Rossi"
      ],
      "year": "2020",
      "venue": "Frontiers in Robotics and AI"
    },
    {
      "citation_id": "29",
      "title": "Emotional intelligence of large language",
      "authors": [
        "X Wang",
        "X Li",
        "Z Yin",
        "Y Wu",
        "J Liu"
      ],
      "year": "2023",
      "venue": "Journal of Pacific Rim Psychology"
    },
    {
      "citation_id": "30",
      "title": "Emia: emotion model for intelligent agent",
      "authors": [
        "S Jain",
        "K Asawa"
      ],
      "year": "2015",
      "venue": "Journal of Intelligent Systems"
    },
    {
      "citation_id": "31",
      "title": "e-genia3 an agentspeak extension for empathic agents",
      "authors": [
        "J Taverner",
        "E Vivancos",
        "V Botti"
      ],
      "year": "2022",
      "venue": "e-genia3 an agentspeak extension for empathic agents",
      "arxiv": "arXiv:2208.00737"
    },
    {
      "citation_id": "32",
      "title": "Improving humanness of virtual agents and users' cooperation through emotions",
      "authors": [
        "M Ghafurian",
        "N Budnarain",
        "J Hoey"
      ],
      "year": "2021",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "33",
      "title": "Both matter: Enhancing the emotional intelligence of large language models without compromising the general intelligence",
      "authors": [
        "W Zhao",
        "Z Li",
        "S Wang",
        "Y Wang",
        "Y Hu",
        "Y Zhao",
        "C Wei",
        "B Qin"
      ],
      "year": "2024",
      "venue": "Both matter: Enhancing the emotional intelligence of large language models without compromising the general intelligence",
      "arxiv": "arXiv:2402.10073"
    },
    {
      "citation_id": "34",
      "title": "Building longterm relationships with virtual and robotic characters: the role of remembering",
      "authors": [
        "Z Kasap",
        "N Magnenat-Thalmann"
      ],
      "year": "2012",
      "venue": "The Visual Computer"
    },
    {
      "citation_id": "35",
      "title": "Affectaura: an intelligent system for emotional memory",
      "authors": [
        "D Mcduff",
        "A Karlson",
        "A Kapoor",
        "A Roseway",
        "M Czerwinski"
      ],
      "year": "2012",
      "venue": "Proceedings of the SIGCHI conference on human factors in computing systems"
    },
    {
      "citation_id": "36",
      "title": "An emotion understanding framework for intelligent agents based on episodic and semantic memories",
      "authors": [
        "M Kazemifard",
        "N Ghasem-Aghaee",
        "B Koenig",
        "T Ören"
      ],
      "year": "2014",
      "venue": "Autonomous agents and multi-agent systems"
    },
    {
      "citation_id": "37",
      "title": "Flame-fuzzy logic adaptive model of emotions",
      "authors": [
        "M El-Nasr",
        "J Yen",
        "T Ioerger"
      ],
      "year": "2000",
      "venue": "Autonomous Agents and Multi-agent systems"
    },
    {
      "citation_id": "38",
      "title": "Nadine: An llm-driven intelligent social robot with affective capabilities and human-like memory",
      "authors": [
        "H Kang",
        "M Moussa",
        "N Magnenat-Thalmann"
      ],
      "year": "2024",
      "venue": "Nadine: An llm-driven intelligent social robot with affective capabilities and human-like memory",
      "arxiv": "arXiv:2405.20189"
    },
    {
      "citation_id": "39",
      "title": "Towards episodic memory-based long-term affective interaction with a human-like robot",
      "authors": [
        "Z Kasap",
        "N Magnenat-Thalmann"
      ],
      "year": "2010",
      "venue": "19th International Symposium in Robot and Human Interactive Communication"
    },
    {
      "citation_id": "40",
      "title": "Episodic memory system of affective agent with emotion for longterm human-robot interaction",
      "authors": [
        "H.-G Kim",
        "J.-Y Yang",
        "D.-S Kwon"
      ],
      "year": "2013",
      "venue": "2013 10th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)"
    },
    {
      "citation_id": "41",
      "title": "Deep episodic memory: Encoding, recalling, and predicting episodic experiences for robot action execution",
      "authors": [
        "J Rothfuss",
        "F Ferreira",
        "E Aksoy",
        "Y Zhou",
        "T Asfour"
      ],
      "year": "2018",
      "venue": "IEEE Robotics and Automation Letters"
    },
    {
      "citation_id": "42",
      "title": "Research on associative memory models of emotional robots",
      "authors": [
        "W Yi",
        "W Zhi-Liang",
        "W Wei"
      ],
      "year": "2014",
      "venue": "Advances in Mechanical Engineering"
    },
    {
      "citation_id": "43",
      "title": "Personality affected robotic emotional model with associative memory for human-robot interaction",
      "authors": [
        "N Masuyama",
        "C Loo",
        "M Seera"
      ],
      "year": "2018",
      "venue": "Neurocomputing"
    },
    {
      "citation_id": "44",
      "title": "Elements of episodic memory",
      "authors": [
        "E Tulving"
      ],
      "year": "1983",
      "venue": "Elements of episodic memory"
    },
    {
      "citation_id": "45",
      "title": "Episodic memory: From mind to brain",
      "year": "2002",
      "venue": "Annual review of psychology"
    },
    {
      "citation_id": "46",
      "title": "Neural networks and physical systems with emergent collective computational abilities",
      "authors": [
        "J Hopfield"
      ],
      "year": "1982",
      "venue": "Neural networks and physical systems with emergent collective computational abilities"
    },
    {
      "citation_id": "47",
      "title": "Pattern recognition and machine learning",
      "authors": [
        "C Bishop",
        "N Nasrabadi"
      ],
      "year": "2006",
      "venue": "Pattern recognition and machine learning"
    },
    {
      "citation_id": "48",
      "title": "Memorybank: Enhancing large language models with long-term memory",
      "authors": [
        "W Zhong",
        "L Guo",
        "Q Gao",
        "H Ye",
        "Y Wang"
      ],
      "year": "2024",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence"
    },
    {
      "citation_id": "49",
      "title": "A comprehensive overview of large language models",
      "authors": [
        "H Naveed",
        "A Khan",
        "S Qiu",
        "M Saqib",
        "S Anwar",
        "M Usman",
        "N Akhtar",
        "N Barnes",
        "A Mian"
      ],
      "year": "2023",
      "venue": "A comprehensive overview of large language models",
      "arxiv": "arXiv:2307.06435"
    },
    {
      "citation_id": "50",
      "title": "A survey on evaluation of large language models",
      "authors": [
        "Y Chang",
        "X Wang",
        "J Wang",
        "Y Wu",
        "L Yang",
        "K Zhu",
        "H Chen",
        "X Yi",
        "C Wang",
        "Y Wang"
      ],
      "year": "2024",
      "venue": "ACM Transactions on Intelligent Systems and Technology"
    }
  ]
}