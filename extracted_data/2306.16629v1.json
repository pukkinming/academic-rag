{
  "paper_id": "2306.16629v1",
  "title": "Corae: A Tool For Intuitive And Continuous Retrospective Evaluation Of Interactions",
  "published": "2023-06-29T02:04:43Z",
  "authors": [
    "Michael J. Sack",
    "Maria Teresa Parreira",
    "Jenny Fu",
    "Asher Lipman",
    "Hifza Javed",
    "Nawid Jamali",
    "Malte Jung"
  ],
  "keywords": [
    "Affective computing",
    "interpersonal perception",
    "annotation tool",
    "continuous affect",
    "human-computer interaction"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "This paper introduces CORAE, a novel web-based open-source tool for COntinuous Retrospective Affect Evaluation, designed to capture continuous affect data about interpersonal perceptions in dyadic interactions. Grounded in behavioral ecology perspectives of emotion, this approach replaces valence as the relevant rating dimension with approach and withdrawal, reflecting the degree to which behavior is perceived as increasing or decreasing social distance. We conducted a study to experimentally validate the efficacy of our platform with 24 participants. The tool's effectiveness was tested in the context of dyadic negotiation, revealing insights about how interpersonal dynamics evolve over time. We find that the continuous affect rating method is consistent with individuals' perception of the overall interaction. This paper contributes to the growing body of research on affective computing and offers a valuable tool for researchers interested in investigating the temporal dynamics of affect and emotion in social interactions.",
      "page_start": 1,
      "page_end": 7
    },
    {
      "section_name": "I. Introduction",
      "text": "Affect is a dynamic phenomenon. Observable behavior, subjective experience, and physiology all dynamically evolve across time  [24] . In interactions, affective dynamics co-evolve with those of other interactants  [2] , correlating in ways that are yet to be fully explored. Understanding these temporal dynamics requires continuous data streams.\n\nWhile a growing body of work has addressed strategies and tools to capture affect data over time across physiology  [20] , subjective experience  [8, 33] , and observable behavior  [4, 22] , we lack continuous data about how affective perceptions of others develop dynamically over time.\n\nRetrospective analysis is an established method to collect continuous data regarding affect  [5, 6, 27, 29] . Following this approach, participants are typically video-recorded during an emotion-eliciting event and are later asked to continuously rate how they felt while watching the recording  [33] . This method relies on the phenomenon that individuals often reexperience emotions when reliving a situation  [16] . Traditionally, retrospective analysis has focused on collecting continuous data about subjective experience. For example, it was used prominently in couples research by Gottman and Levenson  [18] . In this paper, we expand on these works by introducing an approach and a tool that enables researchers to collect continuous affect data about interpersonal perceptions.\n\nOur approach is grounded in a behavioral ecology perspective of emotion, which posits that emotional expressions are primarily social tools used to influence and learn about others  [7, 13, 38] . In line with this perspective, rather than capturing valence when rating interactions, we focus on a dimension of approach and withdrawal, i.e., the degree to which behavior is seen as increasing or decreasing social distance  [1, 3, 23] . Fig.  1 : Annotation dashboard for CORAE version 0.15a. After interacting with another individual, participants are asked to retrospectively evaluate how the other person came across by reviewing the recording of the interaction with only the video from the other participant and audio of both.\n\nWe introduce CORAE, a novel browser-based tool for COntinuous Retrospective Affect Evaluation. This intuitive tool allows participants to retrospectively rank how another interactant came across immediately following an interaction, thus allowing us to capture interpersonal affective perceptions rather than feelings or affective state inferences. In other words, our system allows us to capture data about how people perceive each other emotionally continuously over time. We make this tool publicly available and test it in a dyadic interaction context, drawing insights about how interpersonal dynamics evolve over time.\n\nOur contributions include: first, an approach that extends existing affect rating approaches  [33]  to capture continuous self-report data about interpersonal affective perceptions. Second, a novel web-based tool (CORAE) that allows for such data to be captured easily and reliably. Third, an experimental study where dyads of participants interact and retrospectively rate each other in terms of social distance, which provides evidence that the self-report data captured with our system aligns with interpersonal perceptions people form of others.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Ii. Related Work",
      "text": "",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "A. Measuring Affect In Interactions",
      "text": "A growing body of research in affective computing is investigating how to develop and validate reliable measures of affect. Traditionally, affect is represented in two main ways: categorical or dimensional. The first categorizes affective states into discrete emotions (e.g., happiness, sadness)  [9, 10, 25] , while the second distinguishes affective states along dimensions such as valence or arousal  [28, 34] . Dimensional approaches have been shown to better capture the complexity and nuance of emotional experiences, and can be used to study affective states that do not fit neatly into discrete categories  [34] . To capture these affective states, continuous representations have been popularized  [19, 30] , as they allow for an understanding of how humans aggregate affect information across time, unveiling regions of \"emotional saliency\" which may be pivotal to assessing the emotional experience  [30] .\n\nThere is also growing interest in the social functions of emotions (e.g.,  [38] ). Emotional expressions are increasingly recognized as social tools that people use to influence others and learn about them  [7, 13] . From such a behavioral ecology perspective  [7, 13] , the expressive meaning of emotions is not pre-determined by specific behavior patterns or morphologies such as facial muscle movements or voice tone patterns, but rather constructed in interaction through a process of \"affective grounding\"  [23] . Affective grounding posits that participants of an interaction continuously coordinate on affect to build shared understanding about how behavior should be interpreted affectively and how interaction participants are socially positioned towards each other. This perspective therefore uses \"social distance\" as the relevant rating dimension, evaluating the degree to which social behaviors result in approach and withdrawal  [1, 3, 23, 26] . Truly understanding how affective grounding is built, however, requires the collection of interpersonal social distance measures  [1, 3, 23] , continuously. To the best of our knowledge, this is the first work which addresses retrospective interpersonal affect annotation.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "B. Tools For Coding Affect",
      "text": "Despite significant efforts to develop automated methods for affect recognition  [12, 39, 41] , many studies still rely on human annotators to label affective states in various modalities, such as speech, text, and images. Human annotators provide a level of accuracy and nuance that is difficult to achieve with automated methods, particularly when it comes to complex emotional experiences that may not fit neatly into discrete categories. Furthermore, human annotators can provide valuable insights into the subjective experiences of individuals, enabling researchers to better understand the cognitive and social factors that shape emotional responses.\n\nNonetheless, manual annotation brings about its own limitations, as several factors hinder validity and reliability. For example, annotators' experience and personal perceptions, the representations chosen, and even the design of the annotation tool  [30]  can affect the final labels. Consequently, a wide variety of tools have been developed to address these challenges, including different approaches for continuous affect annotation  [5, 6, 14, 15, 27, 29, 32, 40] .\n\nEach of these existing tools affords unique research applications and differs primarily in terms of complexity and accessibility. For example, solutions such as FeelTrace  [5] , its successor GTrace  [6] , and AffectRank  [40]  each aim to capture multiple dimensions of affect at once. However, these methods can be cognitively demanding  [29] , which is why other approaches, including RankTrace  [27] , PAGAN  [29] , and CARMA  [14]  focus more narrowly on a single affective dimension. Further, the mode of annotation for these platforms differ in their use of bounded  [5, 6]  and unbounded  [27, 29]  rating scales. Additionally, these solutions differ in terms of their affordance of in-person and remote data collection; of those mentioned above, all but PAGAN require the collocation of researchers and participants. Conversely, web-based solutions such as PAGAN may theoretically be deployed for remote data collection in addition to in-person contexts. III. SYSTEM DESIGN CORAE, related to the Latin word for \"heart\" and associated with the figurative image of affect, was developed through an iterative design process informed by numerous rounds of pilot testing and user feedback. Broadly, the CORAE platform enables individuals to intuitively evaluate how a person's behavior is interpreted emotionally during interactions. In its current iteration, the platform consists of two components, namely a frontend web interface for participants and a command-line-driven backend to facilitate project management for researchers. Section III-A details our motivations for various design decisions and situates CORAE in the broader design space. Section III-B details platform functionality implemented as of the experimental validation of CORAE described in Section IV. Finally, Section III-C discusses ongoing improvements made to the platform taking insights from researcher and participant feedback. We make CORAE publicly available 1  as a tool for other researchers.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "A. Design",
      "text": "Building upon existing tools, we sought to address features and applications under-served by the broader design space and incorporate those most aligned with an intuitive annotation experience. Due to their relative complexity, many existing annotation tools impose barriers to their effective use. Robust as such tools may be, they remain inaccessible to the greater population who lack the necessary training or resources to use them. Layout: We designed CORAE to be intuitive and visually minimal (see Figure  1 ) in its presentation. CORAE is deployed in a web browser with the central focus being a video of one's co-interactant, staged for annotation. This is to ensure participants are not distracted by their own image on the screen nor by other visual elements on the platform. Brief instructions above the video player describe keybindings to control the annotation dashboard (Spacebar to toggle playback and Left and Right Arrows to control the slider), as well as a brief description of the terms used for measuring interpersonal perception (Figure  2 ). In the released version of CORAE, the terms used and respective descriptions will be easily customizable, enlarging the use potential for this tool. An unobtrusive progress bar is displayed below the video player to inform participants what proportion remains of their evaluation. Finally, below the video player is displayed the annotation slider. A color gradient (from red to green) enables participants to more intuitively understand the meaning of each of the rating terms. The annotation bar is bounded and discretized (a total of 15 points, from -7 -Disagreeableto +7 -Agreeable). As mentioned above, this too will be customizable, as other scales may be interesting to explore, namely Comfortability  [26] . Participants may only change their rating during video playback and are constrained by the platform to do it 'continuously\" (i.e., they cannot instantaneously change the rating from Neutral (0) to Agreeable (7), but rather adjust to each value in sequence). Intuitiveness: By mitigating the need to train annotators on CORAE's use, our platform facilitates continuous retrospective annotation immediately following an interaction. The immediacy of this evaluation allows for stronger salience of affect compared to a delayed approach. Additionally, valuable time that might have otherwise been required to train novice annotators may instead be utilized for more productive ends such as data collection.\n\nMelhart et al.  [29]  suggest that a lack of intuitiveness can constitute a barrier for researchers such as in the case of tools like FeelTrace  [5] , GTrace  [6] , CARMA  [14] , and RankTrace  [27] . According to the Melhart, the complexity of platform deployment may dissuade researchers from using that platform. Melhart's solution, PAGAN  [29] , is a centralized platform accessible in theory to any interested researcher. In practice, however, the centralized nature of such platforms renders them dependent upon the continued upkeep of a central web server and database. Closed-source solutions further compound this issue by offering little-to-no recourse for researchers who might otherwise desire to deploy their own implementation locally or even to their own web server. Our platform addresses both of these concerns through a well-documented process for third-party deployment and the planned open-source release of our code repository. Affective Dimension: The complexity of annotating two or more concurrent affective dimensions imposes a nontrivial cognitive demand upon the annotator  [6] . This demand, in turn, may diminish the salience of user annotation along both dimensions. Similar to PAGAN  [29]  and others, our design aims to capture affect along a single dimension. Distributed Participation: Whereas existing solutions tend to rely heavily upon the collocation of researchers and participants for in-person data collection (Section II-B), we found this approach to be unnecessarily restrictive and rather limiting to the potential recruitment of more diverse populations. Conversely, remote studies are unable to guarantee consistency for factors such as participant system specifications and environmental distractors. We acknowledge the value afforded by both in-person and remote study formats and sought to develop a tool capable of facilitating either. To this end, CORAE may be deployed locally for in-person sessions as well as remotely for distributed participation.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "B. Functionality",
      "text": "We focused our early development efforts on creating an intuitive and seamless annotation experience for the user. To this end, we withheld several planned features with the intention of their inclusion in a subsequent release of the platform (Section III-C). When we refer to CORAE and its functionality in this section, it is in reference to build 0.15a unless otherwise noted. The features in this build were those we deemed critical for CORAE's experimental validation and ongoing user testing. Annotation Dashboard: A unique URL is generated for each participant to access their instance of CORAE's annotation dashboard (Fig.  1 ). Upon accessing their instance, participants are, by default, prompted to enter an identifier which is then logged by the platform and associated with their session. This prompt may be disabled by changing a parameter in the project template. CORAE's annotation dashboard contains three key components: the instruction panel, the video player, and the annotation slider. Platform instructions may be altered in the project template to suit the needs of a study. Dashboard elements responsively scale to account for differences in viewport size and the relative aspect ratio of uploaded media. The annotation slider is labeled at each extreme with the dimension of affect being evaluated.\n\nIn terms of interaction, the dashboard affords two primary actions: slider adjustment and playback control. Annotators may indicate their affect rating by adjusting the slider using Left and Right Arrow during playback. This affect rating by default is indicated using a continuous 15-point scale but may be changed in the project template to suit any granularity. Although some authors argue in favor of unbounded annotation  [27, 29] , we opted to bound ratings as a form of affective grounding across sections. Further, CORAE eliminates the need to hold input controls when adjusting ratings, which we found to cause fatigue among participants. Playback may be paused and resumed using Spacebar at any point. Our motivation for constraining interactability to these two actions was to minimize cognitive demand and eliminate any unnecessary sources of distraction during annotation. Data Logging: Data is logged for a session in two ways:\n\n(1) by default, the mode for data logging is set to predetermined intervals of one second, which may be adjusted to any granularity; and (2) to ensure accuracy in the annotation method, CORAE also logs data whenever a change in the rating occurs. Associated data points are the slider position (rating), time code, and video frame (in the format \"Slider-NumericalPosition\": \"Hours:Minutes:Seconds:VideoFrame\"), which are logged in a JSON file. Given that video is recorded at a rate of 30 frames-per-second, this allows for a resolution of up to 1/30 s in the annotated data streams.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "C. Release Version",
      "text": "We intend to continue the development of novel features that improve CORAE's overall utility. One of the most significant additions moving into the next release of our platform is the introduction of a more robust project management system. In the latest build of CORAE, project parameters may be modified, staged, and published using the administration panel both prior to and after deployment. Yet another improvement over our 0.15a release is a server-side pipeline for logging participant data. This data management system aggregates files generated by the platform within a predetermined directory on the web server.\n\nFinally, we note that allowing for the open-source modification of our platform enables researchers and developers to tailor its features to their specific needs beyond those we have anticipated. Further, the potential impact of deprecation is lessened by a public release of CORAE's source code. In the event that we were to discontinue development, CORAE's repository would remain available to access and modify indefinitely.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Iv. Experimental Validation Of Corae",
      "text": "We tested a use case for CORAE in the form of an experimental study on interpersonal dynamics during dyadic interactions. We briefly describe the study design below.\n\nOur study has two aims: a) understanding how participants interact with the platform and b) evaluating the tool's effectiveness in accurately capturing interpersonal affective evaluations over time. This study took place remotely, with two participants interacting digitally while completing a task. The study received IRB approval from Cornell University (IRB0143729).",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "A. Experimental Procedure",
      "text": "Participants were recruited through Prolific 2  . The study took place fully online. Before scheduling their slot, each participant read and signed a consent form. At the scheduled time for the experiment, both participants received a link to a call on Zencastr 3  , a video call platform that allows for highquality recording of each video and audio stream separately.\n\nParticipants read task instructions, including a description of the discussion topic (Reasons for Poverty task  [36] , detailed in Section IV-B). After this, participants were recorded while interacting to solve the task. When they reached an agreement, or after 10 minutes of discussion, participants were asked to stop discussing and fill out a survey. This survey collected demographic data, as well as measures of interpersonal affect. In the meantime, the researcher downloaded the data streams, merged the video stream with audio streams from both participants and uploaded them to CORAE. Each participant was then distributed a unique URL which opened an instance of CORAE's annotation platform in their browser. Participants were each presented with a video of their discussion partner were asked to continuously rate how their partner came across moment-to-moment. Once finished, participants were instructed to download the annotation file and upload it onto an encrypted database. Finally, after completing an exit survey, participants were compensated for their participation with US$14, through Prolific.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "B. Reasons For Poverty Task",
      "text": "To evaluate our tool, we needed a task that could elicit a broad range of emotions. We used a modified version of the Reasons for Poverty task  [36] . The task requires participants to rank order a list of \"reasons for poverty\" according to their \"accuracy\". Half of the items follow a reasoning that sees the source of poverty in peoples' situation, i.e., their circumstances, whereas the other half follows a reasoning that sees the source of poverty in peoples' disposition, i.e., their personality. By strategically recruiting participants with opposing beliefs about poverty, we aimed to elicit an emotionally engaging interaction. We used the following instructions:\n\nYou and the other participant must come to an agreement as to a rank of the 5 most relevant causes of poverty in order of the accuracy of each statement. The cause of poverty that is evaluated as being most accurate will be ranked as 1st, and the one that is evaluated as least accurate will be ranked as 5th.\n\n• Poor people lack the ability to manage money.\n\n• Poor people waste their money on inappropriate items.\n\n• Poor people do not actively seek to improve their lives.\n\n• Poor people lack talents and abilities.\n\n• Poor people are exploited by the rich.\n\n• The society lacks justice.\n\n• Distribution of wealth in society is uneven.\n\n• Poor people lack opportunities because they live in poor families.\n\n• Poor people live in places where there are not many opportunities.\n\n• Poor people have encountered personal misfortunes, which limit their opportunities.\n\n• Poor people are discriminated against in society.\n\n• Poor people have bad fate.\n\n• Poor people lack luck.\n\nParticipants were given a maximum of 10 minutes to discuss, to prevent individuals from getting disengaged when reviewing their discussion on CORAE.",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "C. Measures 1) User Interaction And Experience:",
      "text": "To evaluate how participants are interacting with the platform, we measured the Click Rate (interval of time between rating data points) and Rating Range (range of values for one retrospective annotation session). To measure user experience, we asked participants for feedback about their interactions with our tool in the exit survey.\n\n2) Evaluation Accuracy: In order to evaluate the effectiveness of our tool in accurately capturing an individual's assessment of the interaction, we compared measures of Interpersonal Agreeableness and Interpersonal Perception (IP). The Interpersonal Agreeableness measure was operationalized by asking participants \"How did the other participant come across?\" on a 7-point Likert scale (from disagreeable to agreeable) in the post-interaction survey. The Interpersonal Perception measure was operationalized from the continuous interpersonal rating data. First, we increased the resolution of the rating data to a 0.1s period (10Hz), to ease manipulation of the data within and across sessions. Then, to calculate the IP and in line with prior work  [17, 22] , for each participant, we took the cumulative sum of the ratings during the interaction and fitted a linear regression to that data. The Interpersonal Perception (IP) measure is given by the slope of that regression, providing an understanding of how the perception of the other interactant evolved over the interaction.\n\n3) Demographics: In the post-interaction survey, we collected demographic information (age, gender, nationality, race/ethnicity) and personality traits through the shortversion of the Big Five Inventory  [31] . Participants were also asked to rate their religiousness (not-at-all religious to very religious) and political leaning (very liberal to very conservative) with 7-point Likert scales.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "D. Participants",
      "text": "Participants were recruited through Prolific. To elicit disagreement during the interactions, participants were selected according to their political leaning (one conservative-and one liberal-leaning), which they disclose a priori on Prolific. Other recruitment criteria were proficiency in English and a computer device with a functioning camera and microphone.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "V. Results",
      "text": "",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "A. Participants",
      "text": "A total of 12 interaction sessions (24 participants) were used for this study, with an average interaction duration of 560.01 ± 111.39 s (total length of interaction data of 13440.22 s, around 224 minutes). Participants' age ranged from 20 -61 years (M ± SD : 39.75 ± 13.49). Out of the 24 participants, 13 identified as female, 11 as male. Race/ethnicity was mostly Caucasian/White (17), followed by Asian/Asian American (4), Hispanic/Latino (4) and African/African American/Black (2) Fig.  3 : Distribution of rating values in the dataset collected for this study.\n\n(participants could select multiple). Most participants were native speakers of English (  21 ), with 3 proficient users.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "B. User Interaction And Experience",
      "text": "We evaluated how participants interact with the platform during the retrospective annotation sessions. Participants' average Click Rate is 0.42 ± 0.02s. Each interaction had an average of 1116 ± 222 rating data points. The rating scale numerically ranges from -7 (disagreeable) to +7 (agreeable). For the sessions analyzed, the average Rating Range was 8.08. The distribution of ratings can be seen in Figure  3 . Feedback from participants: Voluntary open-response questions in our exit survey revealed an overall positive annotation experience as reported by users. Given that these questions were open-response and inquired broadly about experiences with the study, respondents, in general, detailed both positive and negative aspects of their interaction during the discussion task rather than with the platform itself. Three (3) participants spoke explicitly to CORAE's \"ease of use\", and seven  (7)  reported the platform design to be \"clear\", \"intuitive\", or some variation thereof. Two (2) participants reported technical difficulties using the playback feature, where the video would not load upon visiting their instance of the annotation dashboard. In both cases, the issue was found to be the result of an unreliable network connection between users and our web server, and the data was still deemed usable for our study.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "C. Evaluation Accuracy",
      "text": "In Figure  4 , we show examples of the retrospective annotation sessions data. Linear regression, used to calculate the Interpersonal Perception, was well-adjusted to the data for all sessions (R 2 : 0.88 ± 0.34 across the 24 cumulative rating curves). To understand if the retrospective annotation was accurately capturing the perception of the interactants, we calculated the Pearson correlation between the Interpersonal Perception and Interpersonal Agreeableness (assessed by asking the participant to rate in a single scale how the other participant came across). We found a strong correlation between the two measures (r = 0.72, p < 0.001), indicating good agreement between the continuous rating and the overall assessment of the other participant. VI. DISCUSSION This work introduces CORAE, a novel approach to the collection of interpersonal data. CORAE is an intuitive tool for continuous retrospective evaluation of one dimension of the affective content of interactions. Through an evaluation study, we further provide evidence that the tool is both accurate and intuitive/easy to use. Our results provide insights into individuals' ability to continuously recall affective perceptions of their interaction participant. We also unveil the intricate dynamics of interpersonal perception, with complex data streams that are captured with the use of CORAE as an annotation tool.\n\nCORAE was developed to be intuitive, cutting the need for training sessions and thus increasing the potential for capturing affective states continuously over time. The platform allows for the collection of high-resolution data, with participants changing ratings often and across a broad range of values of interpersonal distance. CORAE thus constitutes a valuable tool that is also easy to customize to other interactions or experimental contexts. We make this tool publicly available and will continue to expand on its functionality.\n\nFigure  4  demonstrates how different sessions (and different sets of participants) can entail disparate interpersonal ratings. The plots on the left reflect an interaction where individuals were perceived as mostly agreeable. Interesting synchronization in the ratings can be observed (e.g., the rating drops at around 250s and 300s), even though the annotation sessions took place individually. This indicates that a shared understanding of the interaction's affective content may have been established, in line with theories about affective grounding  [23] . The plots on the right show a session where one participant rated the other much more positively. This becomes particularly apparent when looking at the cumulative IR curves, which reinforces the applicability of the Interpersonal Perception measure as a good single-value indicator of the quality of an interaction as perceived by the individual. In line with this, we found that the IP was strongly correlated with the overall, \"static\" measure of Interpersonal Agreeableness. This shows that CORAE can accurately capture the affective content of an interaction as it relates to social distance.\n\nOur findings demonstrate the value of using continuous affect rating methods to capture the temporal dynamics of affect and emotion in social interactions. By allowing participants to rate their affective experience both continuously and retrospectively, our tool provides a more fine-grained understanding of the emotional experiences of individuals throughout an interaction. This can help researchers to better understand how affective experiences influence behavior and how behavior, in turn, shapes affective experiences  [30] .\n\nOur approach of replacing valence with approach and withdrawal as the relevant rating dimension reflects a shift towards a more ecologically valid perspective on emotion  [2, 13, 38] . This approach acknowledges that emotional experiences are not simply positive or negative but are shaped by the context in which they occur. By focusing on approach and withdrawal, our tool provides a more nuanced understanding of the social dynamics underlying emotional experiences and highlights the importance of considering the social context in which affective experiences occur.\n\nFinally, we believe that CORAE and its subsequent developments have great potential for studying the dynamics of affect and emotion in a range of social contexts beyond dyadic negotiation, such as team collaboration  [21] , or romantic relationships  [18, 22] . Expanding the tool beyond dyadic use could imply a longer annotation process, as each interactant would have to be annotated individually, or pairwise-annotation could occur, where each participant only evaluates one of the interactants; nonetheless, this could provide interesting insights into the differences between individual retrospective evaluation and group interpersonal perception, as the latter requires attention to be split among all the participants. The ability to capture continuous affect data in real-time and retrospectively provides a powerful tool for investigating the complex interplay between affect, behavior, and social context and has the potential to inform the development of more effective interventions and technologies for improving social interactions.",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "A. Limitations And Future Work",
      "text": "Despite yielding promising results through our experimental validation of CORAE, we recognize potential limitations to both the platform and broader generalizability of the dataset collected from these sessions.\n\n1) CORAE: Like any annotation tool, CORAE data might suffer from threats to validity that are common when using human annotators, such as anchoring  [35] , framing  [37]  and recency  [11]  effects. The use of a retrospective, rather than simultaneous, annotation method can be questioned in terms of validity. Continuous simultaneous rating has been used before  [17] , but the cognitive load and meta-affective analysis that needs to take place can hinder the authenticity of the social behaviors demonstrated. The retrospective annotation method addresses these challenges, although the ratings might be affected by future events in an interaction, as individuals may find it hard to abstract from their recalling of how the interaction developed. Nonetheless, our experimental results prove that CORAE ratings effectively reflect interpersonal perceptions of the interactions. Future work may compare simultaneous with retrospective use of the platform. Further, analyses of the affective data can take into account different horizons of the interaction, as insights about how we cognitively model social distance may emerge.\n\n2) Experimental Validation: On the matter of generalizability, constraints relating to participant recruitment skewed our sample heavily in favor of native English speakers from the United States. It would be interesting to see if different cultural backgrounds, which may be attached to different social signaling behaviors  [7] , also correlate with more disagreement in the ratings of interpersonal perceptions. While we kept the analysis of the data focused mostly on the validation of the platform, we see potential in this experiment to shed light on affective grounding mechanisms and implicit and explicit behaviors that signal social distance. For example, disagreement in the ratings may be measured with mean squared error or even inter-rater reliability measures. Future work may also look into personality traits similarities or differences and evaluate if these predict agreement between how participants rated the interaction. Finally, we see potential for the use of machine learning tools to predict interpersonal perception through social behaviors that can be captured through multimodal systems (e.g., audiovisual data).",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Vii. Conclusion",
      "text": "In this work, we introduced CORAE, a novel approach to capturing continuous affect data along an approach-withdrawal dimension, reflecting the degree to which behavior is perceived as increasing or decreasing social distance. Our work contributes to the growing body of research on affective computing and provides a valuable tool for investigating the temporal dynamics of affect and emotion in social interactions. By making our tool publicly available, we hope to promote the adoption of intuitive continuous affect rating methods and facilitate further research into the role of affect in social interactions, namely for machine learning applications. We believe that our tool has the potential to shed light on the complex and nuanced nature of human emotional experiences and inform the development of more effective interventions and technologies for improving social interactions.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Ethical Impact Statement",
      "text": "Our study involves human participants, and we have taken several steps to ensure that their privacy and well-being are protected. All participants provided informed consent before participating in the study, and we obtained ethical approval from our institution's ethics board. Participants were duly informed of privacy concerns and our steps to address them. According to Open Science practices, all of the anonymized data used in the current study is made available. In addition, we recognize that our tool has the potential to be used in a variety of contexts, and that its use could have ethical implications. Models developed from this tool could be used to monitor emotional experiences in workplace interactions, which could potentially lead to negative consequences for employees. We make the tool publicly available with the understanding that researchers who use it will abide by ethical guidelines and take steps to protect the privacy and well-being of their participants. We acknowledge concerns about the use of affective computing technologies and their potential impact. We hope that our research will contribute to a broader conversation about these issues and inform the development of ethical guidelines for the use of affective computing technologies in social interactions.",
      "page_start": 7,
      "page_end": 7
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Annotation dashboard for CORAE version 0.15a. After",
      "page": 1
    },
    {
      "caption": "Figure 1: ) in its presentation. CORAE is deployed",
      "page": 2
    },
    {
      "caption": "Figure 2: ). In the released version of CORAE,",
      "page": 3
    },
    {
      "caption": "Figure 2: Instruction panel for CORAE version 0.15a. The panel",
      "page": 3
    },
    {
      "caption": "Figure 1: ). Upon accessing their instance,",
      "page": 3
    },
    {
      "caption": "Figure 3: Distribution of rating values in the dataset collected",
      "page": 5
    },
    {
      "caption": "Figure 3: Feedback from participants: Voluntary open-response ques-",
      "page": 5
    },
    {
      "caption": "Figure 4: , we show examples of the retrospective an-",
      "page": 5
    },
    {
      "caption": "Figure 4: Examples of the dynamics of interpersonal ratings (IR) in two sessions (top) and respective cumulative sum of rated",
      "page": 6
    },
    {
      "caption": "Figure 4: demonstrates how different sessions (and differ-",
      "page": 6
    },
    {
      "caption": "Figure 1: Dynamics of interpersonal ratings (IR) in one session (left) and respective cumulative sum of rated values (right).",
      "page": 10
    },
    {
      "caption": "Figure 2: Dynamics of interpersonal ratings (IR) in one session (left) and respective cumulative sum of rated values (right).",
      "page": 10
    },
    {
      "caption": "Figure 3: Dynamics of interpersonal ratings (IR) in one session (left) and respective cumulative sum of rated values (right).",
      "page": 11
    },
    {
      "caption": "Figure 4: Dynamics of interpersonal ratings (IR) in one session (left) and respective cumulative sum of rated values (right).",
      "page": 11
    },
    {
      "caption": "Figure 5: Dynamics of interpersonal ratings (IR) in one session (left) and respective cumulative sum of rated values (right).",
      "page": 11
    },
    {
      "caption": "Figure 6: Dynamics of interpersonal ratings (IR) in one session (left) and respective cumulative sum of rated values (right).",
      "page": 12
    },
    {
      "caption": "Figure 7: Dynamics of interpersonal ratings (IR) in one session (left) and respective cumulative sum of rated values (right).",
      "page": 12
    },
    {
      "caption": "Figure 8: Dynamics of interpersonal ratings (IR) in one session (left) and respective cumulative sum of rated values (right).",
      "page": 12
    },
    {
      "caption": "Figure 9: Dynamics of interpersonal ratings (IR) in one session (left) and respective cumulative sum of rated values (right).",
      "page": 13
    },
    {
      "caption": "Figure 10: Dynamics of interpersonal ratings (IR) in one session (left) and respective cumulative sum of rated values (right).",
      "page": 13
    },
    {
      "caption": "Figure 11: Dynamics of interpersonal ratings (IR) in one session (left) and respective cumulative sum of rated values (right).",
      "page": 13
    },
    {
      "caption": "Figure 12: Dynamics of interpersonal ratings (IR) in one session (left) and respective cumulative sum of rated values (right).",
      "page": 14
    }
  ],
  "tables": [],
  "citations": [
    {
      "citation_id": "1",
      "title": "Principles of communication and emotion in social interaction",
      "authors": [
        "P Andersen",
        "L Guerrero"
      ],
      "year": "1996",
      "venue": "Handbook of communication and emotion"
    },
    {
      "citation_id": "2",
      "title": "Emotional coregulation in close relationships",
      "authors": [
        "E Butler",
        "A Randall"
      ],
      "year": "2013",
      "venue": "Emotion Review"
    },
    {
      "citation_id": "3",
      "title": "Toward a pragmatics of emotive communication",
      "authors": [
        "C Caffi",
        "R Janney"
      ],
      "year": "1994",
      "venue": "Journal of pragmatics"
    },
    {
      "citation_id": "4",
      "title": "The specific affect coding system (spaff). Handbook of emotion elicitation and assessment",
      "authors": [
        "J Coan",
        "J Gottman"
      ],
      "year": "2007",
      "venue": "The specific affect coding system (spaff). Handbook of emotion elicitation and assessment"
    },
    {
      "citation_id": "5",
      "title": "'feeltrace': An instrument for recording perceived emotion in real time",
      "authors": [
        "R Cowie",
        "E Douglas-Cowie",
        "S Savvidou",
        "E Mcmahon",
        "M Sawey",
        "M Schröder"
      ],
      "year": "2000",
      "venue": "'feeltrace': An instrument for recording perceived emotion in real time"
    },
    {
      "citation_id": "6",
      "title": "Gtrace: General trace program compatible with emotionml",
      "authors": [
        "R Cowie",
        "M Sawey",
        "C Doherty",
        "J Jaimovich",
        "C Fyans",
        "P Stapleton"
      ],
      "year": "2013",
      "venue": "2013 Humaine Association Conference on Affective Computing and Intelligent Interaction",
      "doi": "10.1109/ACII.2013.126"
    },
    {
      "citation_id": "7",
      "title": "Inside-out: From basic emotions theory to the behavioral ecology view",
      "authors": [
        "C Crivelli",
        "A Fridlund"
      ],
      "year": "2019",
      "venue": "Journal of Nonverbal Behavior"
    },
    {
      "citation_id": "8",
      "title": "Validity and reliability of the experience-sampling method. Flow and the foundations of positive psychology: The collected works of Mihaly Csikszentmihalyi",
      "authors": [
        "M Csikszentmihalyi",
        "M Csikszentmihalyi",
        "R Larson"
      ],
      "year": "2014",
      "venue": "Validity and reliability of the experience-sampling method. Flow and the foundations of positive psychology: The collected works of Mihaly Csikszentmihalyi"
    },
    {
      "citation_id": "9",
      "title": "An argument for basic emotions",
      "authors": [
        "P Ekman"
      ],
      "year": "1992",
      "venue": "Cognition and Emotion",
      "doi": "10.1080/02699939208411068"
    },
    {
      "citation_id": "10",
      "title": "Unmasking the Face: A Guide to Recognizing Emotions from Facial Clues",
      "authors": [
        "P Ekman",
        "W Friesen"
      ],
      "year": "2003",
      "venue": "Spectrum book"
    },
    {
      "citation_id": "11",
      "title": "Emotional context modulates subsequent memory effect",
      "authors": [
        "S Erk",
        "M Kiefer",
        "J Grothe",
        "A Wunderlich",
        "M Spitzer",
        "H Walter"
      ],
      "year": "2003",
      "venue": "NeuroImage",
      "doi": "10.1016/S1053-8119(02)00015-0"
    },
    {
      "citation_id": "12",
      "title": "Automated affective computing based on bio-signals analysis and deep learning approach",
      "authors": [
        "C Filippini",
        "A Di Crosta",
        "R Palumbo",
        "D Perpetuini",
        "D Cardone",
        "I Ceccato",
        "A Di",
        "A Domenico",
        "Merla"
      ],
      "year": "2022",
      "venue": "Sensors",
      "doi": "10.3390/s22051789"
    },
    {
      "citation_id": "13",
      "title": "Human facial expression: An evolutionary view",
      "authors": [
        "A Fridlund"
      ],
      "year": "2014",
      "venue": "Human facial expression: An evolutionary view"
    },
    {
      "citation_id": "14",
      "title": "Software for continuous affect rating and media annotation",
      "authors": [
        "J Girard",
        "Carma"
      ],
      "year": "2014",
      "venue": "Journal of Open Research Software",
      "doi": "10.5334/jors.ar"
    },
    {
      "citation_id": "15",
      "title": "A valid procedure for obtaining self-report of affect in marital interaction",
      "authors": [
        "J Gottman",
        "R Levenson"
      ],
      "year": "1985",
      "venue": "Journal of Consulting and Clinical Psychology"
    },
    {
      "citation_id": "16",
      "title": "A valid procedure for obtaining self-report of affect in marital interaction",
      "authors": [
        "J Gottman",
        "R Levenson"
      ],
      "year": "1985",
      "venue": "Journal of consulting and clinical psychology"
    },
    {
      "citation_id": "17",
      "title": "Marital processes predictive of later dissolution: behavior, physiology, and health",
      "authors": [
        "J Gottman",
        "R Levenson"
      ],
      "year": "1992",
      "venue": "Journal of personality and social psychology"
    },
    {
      "citation_id": "18",
      "title": "The timing of divorce: Predicting when a couple will divorce over a 14-year period",
      "authors": [
        "J Gottman",
        "R Levenson"
      ],
      "year": "2000",
      "venue": "Journal of Marriage and Family"
    },
    {
      "citation_id": "19",
      "title": "Categorical and dimensional affect analysis in continuous input: Current trends and future directions",
      "authors": [
        "H Gunes",
        "B Schuller"
      ],
      "year": "2013",
      "venue": "Image and Vision Computing",
      "doi": "10.1016/j.imavis.2012.06.016"
    },
    {
      "citation_id": "20",
      "title": "Detecting stress during real-world driving tasks using physiological sensors",
      "authors": [
        "J Healey",
        "R Picard"
      ],
      "year": "2005",
      "venue": "IEEE Transactions on intelligent transportation systems"
    },
    {
      "citation_id": "21",
      "title": "Group hedonic balance and pair programming performance: Affective interaction dynamics as indicators of performance",
      "authors": [
        "M Jung",
        "J Chong",
        "L Leifer"
      ],
      "year": "2012",
      "venue": "Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI '12",
      "doi": "10.1145/2207676.2208523"
    },
    {
      "citation_id": "22",
      "title": "Coupling interactions and performance: Predicting team performance from thin slices of conflict",
      "authors": [
        "M Jung"
      ],
      "year": "2016",
      "venue": "ACM Trans. Comput.-Hum. Interact",
      "doi": "10.1145/2753767"
    },
    {
      "citation_id": "23",
      "title": "Affective grounding in human-robot interaction",
      "authors": [
        "M Jung"
      ],
      "year": "2017",
      "venue": "Proceedings of the 2017 ACM/IEEE International Conference on Human-Robot Interaction"
    },
    {
      "citation_id": "24",
      "title": "Emotion dynamics. Current Opinion in Psychology",
      "authors": [
        "P Kuppens",
        "P Verduyn"
      ],
      "year": "2017",
      "venue": "Emotion dynamics. Current Opinion in Psychology"
    },
    {
      "citation_id": "25",
      "title": "Passion and Reason: Making Sense of Our Emotions",
      "authors": [
        "R Lazarus",
        "B Lazarus"
      ],
      "year": "1994",
      "venue": "Passion and Reason: Making Sense of Our Emotions"
    },
    {
      "citation_id": "26",
      "title": "Comfortability recognition from visual non-verbal cues",
      "authors": [
        "M Lechuga Redondo",
        "R Niewiadomski",
        "R Francesco",
        "A Sciutti"
      ],
      "year": "2022",
      "venue": "Proceedings of the 2022 International Conference on Multimodal Interaction, ICMI '22",
      "doi": "10.1145/3536221.3556631"
    },
    {
      "citation_id": "27",
      "title": "Ranktrace: Relative and unbounded affect annotation",
      "authors": [
        "P Lopes",
        "G Yannakakis",
        "A Liapis"
      ],
      "year": "2017",
      "venue": "2017 Seventh International Conference on Affective Computing and Intelligent Interaction (ACII)",
      "doi": "10.1109/ACII.2017.8273594"
    },
    {
      "citation_id": "28",
      "title": "Pleasure-arousal-dominance: A general framework for describing and measuring individual differences in temperament",
      "authors": [
        "A Mehrabian"
      ],
      "year": "1996",
      "venue": "Current Psychology"
    },
    {
      "citation_id": "29",
      "title": "Pagan: Video affect annotation made easy",
      "authors": [
        "D Melhart",
        "A Liapis",
        "G Yannakakis"
      ],
      "year": "2019",
      "venue": "IEEE",
      "doi": "10.1109/ACII.2019.8925434"
    },
    {
      "citation_id": "30",
      "title": "Annotation and processing of continuous emotional attributes: Challenges and opportunities",
      "authors": [
        "A Metallinou",
        "S Narayanan"
      ],
      "year": "2013",
      "venue": "2013 10th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG)",
      "doi": "10.1109/FG.2013.6553804"
    },
    {
      "citation_id": "31",
      "title": "Measuring personality in one minute or less: A 10-item short version of the big five inventory in english and german",
      "authors": [
        "B Rammstedt",
        "O John"
      ],
      "year": "2007",
      "venue": "Journal of Research in Personality",
      "doi": "10.1016/j.jrp.2006.02.001"
    },
    {
      "citation_id": "32",
      "title": "Continuous measurement of emotion: The affect rating dial",
      "authors": [
        "A Ruef",
        "R Levenson"
      ],
      "year": "2007",
      "venue": "Handbook of emotion elicitation and assessment"
    },
    {
      "citation_id": "33",
      "title": "Continuous measurement of emotion. Handbook of emotion elicitation and assessment",
      "authors": [
        "A Ruef",
        "R Levenson"
      ],
      "year": "2007",
      "venue": "Continuous measurement of emotion. Handbook of emotion elicitation and assessment"
    },
    {
      "citation_id": "34",
      "title": "A circumplex model of affect",
      "authors": [
        "J Russell"
      ],
      "venue": "Journal of Personality and Social Psychology",
      "doi": "10.1037/h0077714"
    },
    {
      "citation_id": "35",
      "title": "Anchors, scales and the relative coding of value in the brain",
      "authors": [
        "B Seymour",
        "S Mcclure"
      ],
      "year": "2008",
      "venue": "Current Opinion in Neurobiology",
      "doi": "10.1016/j.conb.2008.07.010"
    },
    {
      "citation_id": "36",
      "title": "Chinese adolescent' explanations of poverty: the perceived causes of poverty scale",
      "authors": [
        "D Shek"
      ],
      "year": "2002",
      "venue": "Adolescence"
    },
    {
      "citation_id": "37",
      "title": "The framing of decisions and the psychology of choice",
      "authors": [
        "A Tversky",
        "D Kahneman"
      ],
      "year": "1981",
      "venue": "Science",
      "doi": "10.1126/science.7455683"
    },
    {
      "citation_id": "38",
      "title": "The emerging view of emotion as social information",
      "authors": [
        "G Van Kleef"
      ],
      "year": "2010",
      "venue": "Social and Personality Psychology Compass"
    },
    {
      "citation_id": "39",
      "title": "Content-based video emotion tagging augmented by users' multiple physiological responses",
      "authors": [
        "S Wang",
        "S Chen",
        "Q Ji"
      ],
      "year": "2019",
      "venue": "IEEE Transactions on Affective Computing",
      "doi": "10.1109/TAFFC.2017.2702749"
    },
    {
      "citation_id": "40",
      "title": "Grounding truth via ordinal annotation",
      "authors": [
        "G Yannakakis",
        "H Martínez"
      ],
      "year": "2015",
      "venue": "2015 International Conference on Affective Computing and Intelligent Interaction (ACII)",
      "doi": "10.1109/ACIwI.2015.7344627"
    },
    {
      "citation_id": "41",
      "title": "An end-to-end visual-audio attention network for emotion recognition in user-generated videos",
      "authors": [
        "S Zhao",
        "Y Ma",
        "Y Gu",
        "J Yang",
        "T Xing",
        "P Xu",
        "R Hu",
        "H Chai",
        "K Keutzer"
      ],
      "year": "2020",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence",
      "doi": "10.1609/aaai.v34i01.5364"
    }
  ]
}