{
  "paper_id": "2102.02729v4",
  "title": "Adversarial Attacks And Defenses In Physiological Computing: A Systematic Review",
  "published": "2021-02-04T16:40:12Z",
  "authors": [
    "Dongrui Wu",
    "Jiaxin Xu",
    "Weili Fang",
    "Yi Zhang",
    "Liuqing Yang",
    "Xiaodong Xu",
    "Hanbin Luo",
    "Xiang Yu"
  ],
  "keywords": [
    "Physiological computing",
    "brain-computer interfaces",
    "health informatics",
    "biometrics",
    "machine learning",
    "adversarial attack Respiration Respiration 92",
    "300 Blood Pressure Blood Pressure 217",
    "000 Heart Rate Variability HRV OR Heart Rate Variability 40",
    "400 Electrodermal Activity EDA OR GSR OR EDR OR Electrodermal OR Galvanic Skin Response 17",
    "800 Eye Movement Eye Movement OR Eye Tracking 16",
    "900 Oxygen Saturation SpO2 OR Oxygen Saturation OR Blood Oxygen 26",
    "800 Skin Temperature Skin Temperature 7",
    "320 Photoplethysmogram"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Physiological computing uses human physiological data as system inputs in real time. It includes, or significantly overlaps with, brain-computer interfaces, affective computing, adaptive automation, health informatics, and physiological signal based biometrics. Physiological computing increases the communication bandwidth from the user to the computer, but is also subject to various types of adversarial attacks, in which the attacker deliberately manipulates the training and/or test examples to hijack the machine learning algorithm output, leading to possible user confusion, frustration, injury, or even death. However, the vulnerability of physiological computing systems has not been paid enough attention to, and there does not exist a comprehensive review on adversarial attacks to them. This paper fills this gap, by providing a systematic review on the main research areas of physiological computing, different types of adversarial attacks and their applications to physiological computing, and the corresponding defense strategies. We hope this review will attract more research interests on the vulnerability of physiological computing systems, and more importantly, defense strategies to make them more secure.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Ii. Physiological Computing",
      "text": "As physiological computing uses human physiological data as system inputs in real time, it includes, or significantly overlaps with, BCIs, affective computing, adaptive automation, health informatics, and physiological signal based biometrics. Although these five areas have different application scenarios and goals, they all need to build machine learning models for physiological signal classification or regression, and hence all are subject to adversarial attacks.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "A. Bcis",
      "text": "A BCI system establishes a direct communication pathway between the brain and an external device, e.g., a computer or a robot  [5] . Scalp and intracranial EEGs have been widely used in BCIs  [12] .\n\nThe flowchart of a closed-loop EEG-based BCI system is shown in Fig.  3 . After EEG signal acquisition, signal processing, usually including both temporal filtering and spatial filtering, is used to enhance the signal-to-noise ratio. Machine learning is next performed to understand what the EEG signal means, based on which a control command may be sent to an external device. There are three typical paradigms in EEG-based BCIs  [12] : 1) Motor imagery (MI)  [38] , which modifies neuronal activities in primary sensorimotor areas when the user imagines the movement of various body parts, e.g., the left (right) hemisphere for right-hand (left-hand) MIs and center for feet MIs. These MIs can be decoded to control external devices, e.g., a wheelchair, or in neural rehabilitation  [6]  to restore the functionality of hands after stroke. 2) Event-related potentials (ERPs)  [39] ,  [40] , which are stereotyped EEG responses to rare or expected visual, audio, or tactile stimuli. The most frequently used ERP component is P300  [41] , which is an increase of the EEG magnitude observed about 300 ms after a rare stimulus. 3) Steady-state visual evoked potential (SSVEP)  [42] ,\n\nwhich is brain's electrical response to repetitive visual stimulation, usually between 3.5 and 75 Hz  [43] . SSVEP can achieve very high information transfer rate in BCI spellers  [9] . EEG-based BCI spellers may be the only non-muscular communication devices for Amyotrophic Lateral Sclerosis (ALS) patients to express their opinions  [44] . In seizure treatment, responsive neurostimulation (RNS)  [45] ,  [46]  recognizes ECoG or intracranial EEG patterns prior to ictal onset, and delivers a high-frequency stimulation impulse to stop the seizure, improving the patient's quality-of-life.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "B. Affective Computing",
      "text": "Affective computing  [47]  is \"computing that relates to, arises from, or deliberately influences emotion or other affective phenomena.\"\n\nEmotion is the focus of affective computing. It can be represented by discrete categories, e.g., Ekman's six basic emotions  [48]  (Anger, Disgust, Fear, Happiness, Sadness, and Surprise), and by continuous values in the 2D space of Arousal and Pleasure (or Valence)  [49] , or the 3D space of Arousal, Pleasure (or Valence) and Dominance  [50] , as shown in Fig.  4 . Various inputs can be used in affective computing, e.g., videos, text, speech, etc. Physiological signals have also been extensively used  [51] . In bio-feedback based relaxation training  [52] , EDA can be used to detect the user's affective state, based on which a relaxation training application can provide the user with explicit feedbacks to learn how to change his/her physiological activities to improve health and performance. In software adaptation  [53] , the graphical interface, difficulty level, sound effects and/or contents are automatically adapted based on the user's real-time emotion estimated from various physiological signals, to keep the user more engaged.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "C. Adaptive Automation",
      "text": "Adaptive automation controls the number and/or types of tasks allocated to the operator to keep the workload within an appropriate level (avoiding both underload and overload), and hence to enhance the overall performance and safety of the human-machine system  [54] ,  [55] .\n\nBoeke et al.  [54]  expressed adaptive automation as a control system, shown in Fig.  5 . The task demand estimator maps each task to a cognitive demand. The dynamic task allocator allocates tasks to the operator based upon his/her available cognitive capacity and the incoming tasks' cognitive demands. The available cognitive capacity estimator estimates the operator's available cognitive capacity from his/her performance, physiology, or subjective measures. In air traffic management  [55] , an operator's EEG signal can be used to estimate the mental workload, and trigger specific adaptive automation solutions. This can significantly reduce the operator's workload during high-demanding conditions, and increase the task execution performance. A study  [56]  also showed that pupil diameter and fixation time, measured from an eye-tracking device, can be indicators of mental workload, and hence be used to trigger adaptive automation.\n\nPark and Zahabi  [57]  performed a review on cognitive workload assessment of prosthetic devices, which can be achieved using physiological, subjective, or task performance measures. The first includes EEG, EMG, ECG, EDA, respiration, eye-tracking, etc. They found that hybrid inputs, e.g., EMG plus inertial measurement unit (IMU), or EMG plus force myography (FMG), were less cognitively demanding than EMG or EEG alone. More specifically, the combination of EMG and IMU can improve the effectiveness, satisfaction and efficiency of prosthetic devices, and the combination of EMG and FMG achieved higher overall stability (lower variance) than EMG alone.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "D. Health Informatics",
      "text": "Health informatics studies information and communication processes and systems in healthcare  [58] .\n\nA single-lead short ECG recording (9-60 seconds), collected from the AliveCor personal ECG monitor, can be used by a convolutional neural network (CNN) to classify normal sinus rhythm, atrial fibrillation, an alternative rhythm, or noise, with an average test accuracy of 88% on the first three classes  [4] . A recent study  [59]  also showed that heart rate data from consumer smart watches, e.g., Apple, Fitbits and Garmin devices, can be used for pre-symptomatic detection of COVID-19, sometimes nine or more days earlier.\n\nMany smart watches or wristbands record the PPG signal, a measure of arterial blood volume fluctuating with each heartbeat  [60] . It is frequently used to monitor the heart rate, but also contains information on the cardiac, vascular, respiratory, and autonomic nervous systems. In clinics, wearable PPGs can be used for atrial fibrillation detection, obstructive sleep apnea identification, monitoring the spread of infectious diseases, sleep monitoring, mental stress assessment, vascular age assessment, clinical deterioration identification, cardiovascular risk prediction, response to exercise assessment, sepsis identification, heart failure identification, and preeclampsia identification  [60] . For example, Guo et al.  [61]  proposed a model fusion approach (Fig.  6 ) for PPG-based atrial fibrillation onset prediction, using Huawei smart watches and wristbands. It achieved 94.04% sensitivity, 96.35% specificity, and 94.04% recall.\n\nFig.  6 . A model fusion approach for PPG-based atrial fibrillation onset prediction  [61] .",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "E. Physiological Signal Based Biometrics",
      "text": "Physiological signal based biometrics  [62]  use physiological signals for biometric applications, e.g., digitally identify a person to grant access to systems, devices or data. They represent a paradigm shift from conventional \"something we know\" (e.g., a personal identification number) or \"something we have\" (e.g., an access card) policies to \"something we are\"  [63] .\n\nA biometric system typically includes three modes  [63] : enrollment, identification, and authentication, as shown in Fig.  7 . The enrollment mode converts each subject's physiological signals into a feature template and stores it in a database. The identification mode finds the best possible match for an incoming subject's template. The authentication mode verifies if a subject is indeed the person he/she claims to be. EEG  [63] , ECG  [64] , PPG  [65]  and multimodal physiological signals  [66]  have been used in user identification and authentication, with the advantages of universality, permanence, liveness detection, continuous authentication, etc. Thomas and Vinod  [63]  performed a review on EEG-based biometric systems, and found that EEGs from the resting state with eyes closed or open, motor imagination, visual evoked potentials, and mental tasks (e.g., math operation, letter composition) can all be used in biometrics. Agrafioti et al.  [64]  gave a comprehensive introduction of the theory, methods and applications of heart biometrics, pointing out their challenges, including time dependency, collection periods, privacy implications, and cardiac conditions. Bianco and Napoletano  [66]  performed multimodal biometric recognition using heart rate, breathing rate, palm EDA, and perinasal perspitation, achieving 90.54% top-1 accuracy and 99.69% top-5 accuracy.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Iii. Adversarial Attacks",
      "text": "Adversarial attacks generate various adversarial perturbations, which may be unnoticeable by human eyes or a computer program, to fool a machine learning model. There are different categorizations of adversarial attacks  [22] ,  [23] , as shown in Fig.  8 .",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "A. Targeted And Non-Targeted Attacks",
      "text": "According to the outcome, there are two types of adversarial attacks  [23] : targeted attacks and non-targeted (indiscriminate) attacks.\n\nTargeted attacks force a model to classify certain examples, or a certain region of the feature space, into a specific (usually wrong) class. Non-targeted attacks force a model to misclassify certain examples or feature space regions, but do not specify which class they should be misclassified into.\n\nFor example, in a 3-class classification problem, assume the class labels are A, B and C. Then, a targeted attack may force the input to be classified into Class A, no matter what its true class is. A non-targeted attack forces an input from Class A to be classified into Class B or C, but does not specify it must be B or C; as long as it is not A, then the non-targeted attack is successful.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "B. White-Box, Black-Box And Gray-Box Attacks",
      "text": "According to how much the attacker knows about the target model, there can be three types of attacks  [67] :\n\n1) White-box attacks, in which the attacker knows everything about the target model, including its architecture and parameters. This is the easiest attack scenario and could cause the maximum damage. It may correspond to the case that the attacker is an insider, or the model designer is evaluating the worst-case scenario when the model is under attack. Popular attack approaches include L-BFGS  [20] , DeepFool  [68] , the C&W method  [69] , the fast gradient sign method (FGSM)  [21] , the basic iterative method (BIM)  [70] , etc.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "C. Poisoning And Evasion Attacks",
      "text": "According to the stage that the adversarial attack is performed, there are two types of attacks: poisoning attacks and evasion attacks, as shown in Fig.  9 .\n\nPoisoning attacks  [72]    specifies. They are usually white-box or gray-box attacks, achieved by data injection, i.e., adding adversarial examples to the training set  [73] , or data modification, i.e., poisoning the training data by modifying their features or labels  [74] .\n\nEvasion attacks  [21]  happen at the test stage, by adding deliberately designed tiny perturbations to benign test examples to mislead the machine learning model. They are usually white-box or black-box attacks.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Iv. Adversarial Attacks In Physiological Computing",
      "text": "Most adversarial attack studies considered computer vision applications, where the inputs are 2D images. Physiological signals are continuous time series, which are quite different from images. There are relatively few adversarial attack studies on time series  [75] -  [78] , and even fewer on physiological signals. A summary of them is shown in Table  III .",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "A. Adversarial Attacks In Bcis",
      "text": "Attacking the machine learning models in BCIs could cause significant damages, ranging from user frustration to serious injuries. For example, in seizure treatment, attacks to RNS's  [45]  seizure recognition algorithm may quickly drain its battery or make it completely ineffective, significantly reducing the patient's quality-of-life. Adversarial attacks to an EEGbased BCI speller may hijack the user's true inputs and output wrong letters, leading to user frustration or misunderstanding. In BCI-based driver drowsiness estimation  [89] , adversarial attacks may make a drowsy driver look alert, increasing the risk of accidents.\n\nAlthough most BCI research so far focused on making BCIs faster and more accurate, pioneers in BCIs have started to consider neurosecurity. For example, Ienca et al.  [90]  pointed in a Nature Biotechnology Commentary in 2018 that \"greater safeguards are needed to address the personal safety, security and privacy risks arising from increasing adoption of neurotechnology in the consumer realm.\" Judy Illes pointed out in a Nature Biotechnology Focus article  [91]  in 2019 three concerns on the widespread use of brain recording and stimulation. The second is \"devices getting hacked and, by extension, behavior unwillfully and unknowingly manipulated for nefarious purposes (although this could conceivably lead to checked bad behavior too).\" A 2020 RAND Corporation report  [92]  pointed out that \"hacking BCI capabilities could theoretically provide adversaries with direct pathways into the emotional and cognitive centers of operators' brains to sow confusion or emotional distress. In the extreme, adversary hacking into BCI devices that influence the motor cortex of human operators could theoretically send false directions or elicit unintended actions, such as friendly fire, although such influence may be technically difficult to achieve in the near term. Even an attack that broadly degraded gross motor skills could prove debilitating during combat.\" In fact, as introduced below, adversarial attacks to EEG-based BCIs have become more and more practical.\n\nIn 2019, Zhang and Wu  [67]  first pointed out that adversarial examples exist in EEG-based BCIs, i.e., deep learning models in BCIs are vulnerable to adversarial attacks. They successfully performed white-box, gray-box and black-box non-targeted evasion attacks to three CNN classifiers, i.e., EEGNet  [14] , DeepCNN and ShallowCNN  [15] , in three different BCI paradigms, i.e., P300 evoked potential detection, feedback error-related negativity detection, and motor imagery classification. The basic idea, shown in Fig.  10 , is to add a jamming module between EEG signal processing and machine learning to generate adversarial examples, optimized by unsupervised FGSM. The generated adversarial perturbations are too small to be noticed by human eyes (an example is shown in Fig.  11 ), but can significantly reduce the classification accuracy.\n\nFig.  10 . The BCI evasion attack approach proposed in  [67] . A jamming module is inserted between signal preprocessing and machine learning to generate adversarial examples. It is important to note that the jamming module is implementable, as research  [93]  has shown that BtleJuice, a framework to perform Man-in-the-Middle attacks on Bluetooth devices, can be used to intercept the data from a consumer grade EEG-based BCI system, modify them, and then send them back to the headset. The RAND report  [92]  also pointed    12 . Compared with the original black-box attack approach in  [67] , the active learning based approach can improve the attack success rate with the same number of queries, or, equivalently, reduce the number of queries to achieve a desired attack performance. This is the first work that integrates active learning and adversarial attacks for EEG-based BCIs. The above two studies considered classification problems, as in most adversarial attack research. Adversarial attacks to regression problems were much less investigated in the literature. Meng et al.  [83]  were the first to study white-box targeted evasion attacks for BCI regression problems. They proposed two approaches, based on optimization and gradient, respectively, to design small perturbations to change the regression output by a pre-determined amount. Experiments on two BCI regression problems (EEG-based driver fatigue estimation, and EEG-based user reaction time estimation in the psychomotor vigilance task) verified their effectiveness: both approaches can craft adversarial EEG trials indistinguishable from the original ones, but can significantly change the outputs of the BCI regression model. Moreover, adversarial examples generated from both approaches are also transferable, i.e., adversarial examples generated from one known regression model can also be used to attack an unknown regression model in black-box settings.\n\nThe above three attack strategies are theoretically important, but there are some constraints in applying them to real-world BCIs:\n\n1) Trial-specificity, i.e., the attacker needs to generate different adversarial perturbations for different EEG trials. 2) Channel-specificity, i.e., the attacker needs to generate different adversarial perturbations for different EEG channels. 3) Non-causality, i.e., the complete EEG trial needs to be known in advance to compute the corresponding adversarial perturbation. 4) Synchronization, i.e., the exact starting time of the EEG trial needs to be known for the best attack performance. Some recent studies tried to overcome these constraints.\n\nZhang et al.  [34]  performed white-box targeted evasion attacks to P300 and SSVEP based BCI spellers (Fig.  13 ), and showed that a tiny perturbation to the EEG trial can mislead the speller to output any character the attacker wants, e.g., change the output from 'Y' to 'N', or vice versa. The most distinguishing characteristic of their approach is that it explicitly considers the causality in designing the perturbation, i.e., it should be generated before or as soon as the target EEG trial starts, so that it can be added to the EEG trial in realtime in practice. To achieve this, an adversarial perturbation template is constructed from the training set only and then fixed. So, there is no need to know the test EEG trial and compute the perturbation specifically for it. Their approach resolves the trial-specificity and non-causality constraints, but different EEG channels still need different perturbations, and it also requires the attacker to know the starting time of an EEG trial in advance to achieve the best attack performance, i.e., there are still channel-specificity and synchronization constraints. Fig.  13 . Workflow of a P300 speller and an SSVEP speller  [34] . For each speller, the user watches the stimulation interface, focusing on the character he/she wants to input, while EEG signals are recorded and analyzed by the speller. The P300 speller first identifies the row and the column that elicit the largest P300, and then outputs the letter at their intersection. The SSVEP speller identifies the output letter directly by matching the user's EEG oscillation frequency with the flickering frequency of each candidate letter.\n\nZhang et al.  [34]  considered targeted attacks to a traditional and most frequently used BCI speller pipeline, which has separate feature extraction and classification steps. Liu et al.  [80]  considered both targeted and non-targeted white-box evasion attacks to end-to-end deep learning models in EEGbased BCIs, and proposed a total loss minimization (TLM) approach to generate universal adversarial perturbations (UAPs) for them. Experimental results demonstrated its effectiveness on three popular CNN classifiers (EEGNet, ShallowCNN, and DeepCNN) in three BCI paradigms (P300, feedback error related negativity, and motor imagery). They also verified the transferability of UAPs in non-targeted gray-box evasion attacks.\n\nTo further simplify the implementation of TLM-UAP, Liu et al.  [80]  also considered smaller template size, i.e., mini TLM-UAP with a small number of channels and time domain samples, which can be added anywhere to an EEG trial. Mini TLM-UAPs are more practical and flexible, because they do not require the attacker to know the exact number of EEG channels and the exact length and starting time of an EEG trial. Liu et al.  [80]  showed that, generally, all mini TLM-UAPs were effective. However, their effectiveness decreased when the number of used channels and/or the template length decrease, which is intuitive. This is the first study on UAPs of CNN classifiers in EEG-based BCIs, and also the first on optimization based UAPs for targeted evasion attacks.\n\nIn summary, the TLM-UAP approach  [80]  resolves the trialspecificity and non-causality constraints, and mini TLM-UAPs further alleviate the channel-specificity and synchronization constraints.\n\nMore recently, Bian et al.  [82]  proposed square wave evasion attacks to two popular training-free models (canonical correlation analysis, and filter-bank canonical correlation analysis) in SSVEP-based BCI spellers. As shown in Fig.  14 , the attacker only needs to know the frequency of the target character; by adding a square wave of that frequency to any input SSVEP trial, the output character can be changed to the target character with almost 100% success rate. The proposed attack approach can resist EEG preprocessing, is robust to SSVEP trial length, and is insensitive to the phase of the square wave signal, i.e., the attacker can use any random initial phase. This represents so far the easiest implementation of evasion attacks to SSVEP-based BCI systems. Fig.  14 . Square wave evasion attack to SSVEP spellers  [82] .\n\nAll above studies focused on evasion attacks. Meng et al.  [81]  were the first to show that poisoning attacks can also be performed for EEG-based BCIs, as shown in Fig.  15 . They proposed a practically realizable backdoor key, narrow period pulse, for EEG signals, which can be inserted into the benign EEG signal during data acquisition, and demonstrated its effectiveness in black-box targeted poisoning attacks, i.e., the attacker does not know any information about the test EEG trial, including its starting time, and wants to classify the test trial into a specific class, regardless of its true class. In other words, it resolves the trial-specificity, channel-specificity, causality and synchronization constraints simultaneously. To our knowledge, this is to-date the most practical BCI attack approach. A summary of existing adversarial attack approaches in EEG-based BCIs is shown in Table  IV .",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "B. Adversarial Attacks In Health Informatics",
      "text": "Adversarial attacks in health informatics can also cause serious damages, even deaths. For example, adversarial attacks to the machine learning algorithms in implantable cardioverter defibrillators could lead to unnecessary painful shocks, damaging the cardiac tissue, and even worse therapy interruptions and sudden cardiac death  [94] .\n\nHan et al.  [4]  proposed both targeted and non-targeted white-box evasion attack approaches to construct smoothed adversarial examples for ECG trials that are invisible to one board-certified medicine specialist and one cardiac electrophysiology specialist, but can successfully fool a CNN classifier for arrhythmia detection. They achieved 74% attack success rate (74% of the test ECGs originally classified correctly were assigned a different diagnosis, after adversarial attacks) on atrial fibrillation classification from single-lead ECG collected from the AliveCor personal ECG monitor. This study suggests that it is important to check if ECGs have been altered before using them in medical machine learning models.\n\nAminifar  [84]  studied white-box targeted evasion attacks in EEG-based epileptic seizure detection, through UAPs. He computed the UAPs via solving an optimization problem, and showed that they can fool a support vector machine classifier to misclassify most seizure samples into non-seizure ones, with imperceptible amplitude.\n\nNewaz et al.  [85]  investigated adversarial attacks to machine learning-based smart healthcare systems, consisting of 10 vital signs, e.g., EEG, ECG, SpO 2 , respiration, blood pressure, blood glucose, blood hemoglobin, etc. They performed both targeted and non-targeted attacks, and both poisoning and evasion attacks. For evasion attacks, they also considered both white-box and black-box attacks. They showed that adversarial attacks can significantly degrade the performance of four different classifiers in smart health system in detecting diseases and normal activities, which may lead to to erroneous treatment.\n\nDeep learning has been extensively used in health informatics; however, generally it needs a large amount of training data for satisfactory performance. Transfer learning  [12]  can be used to alleviate this requirement, by making use of data or machine learning models from an auxiliary domain or task. Wang et al.  [86]  studied targeted backdoor attacks against transfer learning with pre-trained deep learning models on both image and time series (e.g., ECG). Three optimization strategies, i.e., ranking-based neuron selection, autoencoderpowered trigger generation and defense-aware retraining, were used to generate backdoors and retrain deep neural networks, to defeat pruning based, fine-tuning/retraining based and input pre-processing based defenses. They demonstrated their effectiveness in brain MRI image classification and ECG heartbeat type classification.",
      "page_start": 9,
      "page_end": 10
    },
    {
      "section_name": "C. Adversarial Attacks In Biometrics",
      "text": "Physiological signals, e.g., EEG, ECG and PPG, have recently been used in biometrics  [62] . However, they are subject to presentation attacks in such applications. In a physiological signal based presentation attack, the attacker tries to spoof the biometric sensors with a fake piece of physiological signal  [88] , which would be authenticated as from a specific victim user.\n\nMaiorana et al.  [87]  investigated the vulnerability of an EEG-based biometric system to hill-climbing attacks. They assumed that the attacker can access the matching scores of the biometric system, which can then be used to guide the generation of synthetic EEG templates until a successful authentication is achieved. This is essentially a black-box targeted evasion attack in the adversarial attack terminology: the synthetic EEG signal is the adversarial example, and the victim's identify is the target class. It's a black-box attack, because the attacker can only observe the output of the biometric system, but does not know anything else about it.\n\nEberz et al.  [88]  proposed an offline ECG biometrics presentation attack approach, illustrated in Fig.  16(a) . The basic idea was to find a mapping function to transform ECG trials recorded from the attacker so that they resemble the morphology of ECG trials from a specific victim. The transformed ECG trials can then be used to fool an ECG biometric system to obtain unauthorized access. They showed that the attacker ECG trials can be obtained from a device different from the one that the victim ECG trials are recorded from (i.e., cross-device attack), and there could be different approaches to present the transformed ECG trials to the biometric device under attack, the simplest being the playback of ECG trials encoded as .wav files using an off-the-shelf audio player.\n\nUnlike  [87] , the above approach is a gray-box targeted evasion attack in the adversarial attack terminology: the attacker's ECG signal can be viewed as the benign example, the transformed ECG signal is the adversarial example, and the victim's identity is the target class. The mapping function plays the role of the jamming module in Fig.  10 . It's a graybox attack, because the attacker needs to know the feature distributions of the victim ECGs in designing the mapping function.\n\nKarimian et al.  [36]  proposed an online ECG biometrics presentation attack approach, shown in Fig.  16(b ). Its procedure is very similar to the offline attack one in Fig.  16(a) , except that the online approach is simpler, because it only requires as few as one victim ECG segment to compute the mapping function, and the mapping function is linear. Karimian  [35]  also proposed a similar presentation attack approach to attack PPG-based biometrics. Again, these approaches can be viewed as gray-box targeted evasion attacks.\n\nMore recently, Karim et al.  [76]  utilized an adversarial transformation network on a distilled model to attack two classification models (1-nearest neighbor dynamic time warping, and a fully convolutional network) on 42 time series datasets. There were three ECG datasets on the classification of humans with heart conditions or Myocardial infarctions, and two EOG datasets on the classification of Japanese Katakana strokes. They performed both white-box and black-box non-targeted evasion attacks. However, they did not consider the causality of the time-series, i.e., the entire test trial was used in generating the adversarial perturbation. So, their approach may only be used offline.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "D. Discussion",
      "text": "Although we have not found adversarial attack studies on affective computing and adaptive automation in physiological computing, it does not mean that adversarial attacks cannot be performed in such applications. Machine learning models in affective computing and adaptive automation are not fundamentally different from those in BCIs; so, adversarial attacks in BCIs can easily be adapted to affective computing and adaptive automation. Particularly, Meng et al.  [83]  have shown that it is possible to attack the regression models in EEGbased driver fatigue estimation and EEG-based user reaction time estimation, whereas driver fatigue and user reaction time could be triggers in adaptive automation.\n\nIt is interesting to note that almost all aforementioned adversarial attacks focused on EEG and ECG, the 2nd and 3rd most popular physiological signals in Table  I . Blood pressure, the most popular physiological signal, was not attacked alone; it was considered only once in  [85] , together with EEG, ECG, etc. The reason may be that blood pressure consists of only two numbers (systolic and diastolic pressures) measured infrequently, so it is not easy and interesting to attack. The same reasoning may also apply to respiration and heart rate. Some other physiological signals, e.g., ECoG and EMG, are frequently used in human-machine interactions, and also may be complex and important enough to attract adversarial attacks.\n\nFinally, examining the current few studies on adversarial attacks of time series  [75] -  [77] , we found that all of them did not take the causality of the time series into consideration, i.e., their approaches utilized the entire test trial in computing the adversarial perturbation, so they can only be used offline. Additionally, they used generic classifiers for all time series, whereas in physiological computing, particularly BCIs  [12] , each paradigm has its own best feature extraction and classification/regression approach, according to the neurological basis of the corresponding paradigm. So, these generic time series attack approaches may not be used directly in physiological computing.",
      "page_start": 10,
      "page_end": 11
    },
    {
      "section_name": "V. Defense Against Adversarial Attacks",
      "text": "There are different adversarial defense strategies  [22] ,  [96] : 1) Data modification, which modifies the training set in the training stage or the input data in the test stage, through adversarial training  [20] , gradient hiding  [97] , transferability blocking  [98] , data compression  [99] , data randomization  [100] , etc. 2) Model modification, which modifies the target model directly to increase its robustness. This can be achieved through regularization  [74] , defensive distillation  [101] , feature squeezing  [102] , using a deep contractive network  [103]  or a mask layer  [104] , etc. 3) Auxiliary tools, which may be additional auxiliary machine learning models to robustify the primary model, e.g., adversarial detection models  [105] , or defense generative adversarial nets (defense-GAN)  [106] , high-level representation guided denoiser  [107] , etc. As researchers just started to investigate adversarial attacks in physiological computing, there were even fewer studies on defense strategies against them. A summary of them is shown in Table  V .",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "A. Adversarial Training",
      "text": "Adversarial training, which trains a robust machine learning model on normal plus adversarial examples, may be the most popular data modification based adversarial defense approach.\n\nHussein et al.  [108]  proposed an approach to augment deep learning models with adversarial training for robust prediction of epilepsy seizures. Though their goal was to overcome some challenges in EEG-based seizure classification, e.g., individual differences and shortage of pre-ictal labeled data,",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Reference",
      "text": "Application Data Model Adversarial Modification Modification Detection  [108]  BCI  [109]  BCI  [110]  Health Informatics  [111]  Health Informatics  [76]  Health Informatics  [36]  Biometrics their approach can also be used to defend against adversarial attacks. They first constructed a deep learning classifier from available limited amount of labeled EEG data, and then performed white-box attacks to the classifier to obtain adversarial examples, which were next combined with the original labeled data to retrain the deep learning classifier. Experiments on two public seizure datasets demonstrated that adversarial training increased both the classification accuracy and the classifier robustness.\n\nMore recently, Karim et al.  [76]  performed adversarial training for fully convolutional network classifiers, and tested the performance on 42 time series datasets, including three ECG datasets on heart conditions or Myocardial infarction classification, and two EOG datasets on Japanese Katakana stroke classification. They showed that even very simple adversarial training can improve the robustness of fully convolutional network classifiers to black-box and white-box non-targeted evasion attacks.\n\nAlthough adversarial training may be the most effective approach for enhancing the robustness of a model, it could lead to undesirable accuracy degradation on the benign examples  [112] . Additionally, it increases the computational cost 3-30 times  [113] .",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "B. Model Modification",
      "text": "Regularization based model modification to defend against adversarial attacks usually considers the model security (robustness) in the optimization objective function.\n\nSadeghi et al.  [109]  proposed an analytical framework for tuning the classifier parameters, to ensure simultaneously its accuracy and security. The optimal classifier parameters were determined by solving an optimization problem, which takes into account both the test accuracy and the robustness against adversarial attacks. For k-nearest neighbor (kNN) classifiers, the two parameters to be optimized are the number of neighbors and the distance metric type. Experiments on EEG-based eye state (open or close) recognition verified that it is possible to achieve both high classification accuracy and high robustness against black-box targeted evasion attacks.\n\nModel modification approaches are usually heuristic and empirical, without theoretical guarantees. They may be vulnerable to model-agnostic block-box attacks  [69] .",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "C. Adversarial Detection",
      "text": "Adversarial detection uses a separate module to detect if there is adversarial attack, and takes actions accordingly. The simplest is to discard adversarial examples directly.\n\nCai and Venkatasubramanian  [111]  proposed an approach to detect signal injection-based morphological alterations (evasion attack) of ECGs. Because multiple physiological signals based on the same underlying physiological process (e.g., cardiac process) are inherently related to each other, any adversarial alteration of one of the signals will lead to inconsistency in the other signal(s) in the group. Since both ECG and arterial blood pressure measurements are representations of the cardiac process, the latter can be used to detect morphological alterations in ECGs. They demonstrated over 90% accuracy in detecting even subtle ECG morphological alterations for both healthy subjects and patients. A similar idea  [110]  was also used to detect temporal alternations of ECGs, by making use of their correlations with arterial blood pressure and respiration measurements.\n\nKarimian et al.  [36]  proposed two strategies to protect ECG biometric authentication systems from spoofing, by evaluating if ECG signal characteristics match the corresponding heart rate variability or PPG features (pulse transit time and pulse arrival time). The idea is actually similar to Cai and Venkatasubramanian's  [111] . If there is a mismatch, then the system considers the input to be fake, and rejects it.\n\nAdversarial detection heavily relies on the difference between adversarial examples and benign examples. However, adversarial examples can fool not only the classifier but also the detector, so adversarial detection may be ineffective against adaptive attacks  [114] .",
      "page_start": 11,
      "page_end": 12
    },
    {
      "section_name": "D. Discussion",
      "text": "Although there have been many adversarial attack defense approaches  [23] , no one can withstand all existing attacks, not to mention new attacks that will for sure be discovered in the future. For example, Miller et al.'s experiments  [23]  showed that an adversarially trained robust deep neural network can accommodate small perturbations, at the cost of significant classification accuracy loss (about 10%) for benign inputs. Furthermore, as the attack strength increased, this robust classifier gradually became ineffective.\n\nAs proposed in  [23] , a promising new adversarial defense direction may be to combine robust classification with detection: robust classification forces the adversarial perturbations to be large for successful attacks, but this also makes the attacks more detectable. So, using robust classification and adversarial detection together may outperform each one alone.\n\nAnother idea is to use multi-modal inputs in physiological computing. Multi-modal signals are frequently used to increase the accuracy of physiological computing, e.g., using both EEG and EOG increased the emotion classification accuracy significantly  [115] . They can also be used to increase the robustness to adversarial attacks, as different physiological signals generally require different perturbations, which raises the difficulty of attacking. However, this may also increase the complexity and cost of the resulting physiological computing system. Thus, there should be a careful trade-off between accuracy/robustness and complexity/cost.",
      "page_start": 11,
      "page_end": 12
    },
    {
      "section_name": "Vi. Conclusions And Future Research",
      "text": "Physiological computing includes, or significantly overlaps with, BCIs, affective computing, adaptive automation, health informatics, and physiological signal based biometrics. It increases the communication bandwidth from the user to the computer, but is also subject to adversarial attacks. This paper has given a comprehensive review on adversarial attacks and their defense strategies in physiological computing, hopefully will bring more attention to the security of physiological computing systems.\n\nPromising future research directions in this area include: 1) Transfer learning has been extensively used in physiological computing  [12] , to alleviate the training data shortage problem by leveraging data from other subjects  [116]  or tasks  [117] , or to warm-start the training of a (deep) learning algorithm by borrowing parameters or knowledge from an existing algorithm  [86] , as shown in Fig.  17 . However, transfer learning is particularly susceptive to poisoning attacks  [81] ,  [86] . It's very important to develop strategies to check the integrity of data and models before using them in transfer learning. 2) Adversarial attacks to other components in the machine learning pipeline (an example on BCI is shown in Fig.  18 ), which includes signal processing, feature engineering, and classification/regression, and the corresponding defense strategies. So far all adversarial attack approaches in physiological computing considered the classification or regression model only, but not other components, e.g., signal processing and feature engineering. It has been shown that feature selection is also subjective to data poisoning attacks  [72] , and adversarial feature selection can be used to defend against evasion attacks  [119] . 3) Additional types of attacks in physiological computing  [96] ,  [120] -  [123] , and the corresponding defense strategies, as shown in Fig.  19 . For example, Paoletti et al.  [94]  performed parameter tampering attacks on Boston Scientific implantable cardioverter defibrillators, which use a discrimination tree to detect tachycardia episodes and then initiate the appropriate therapy. They slightly modified the parameters of the discrimination tree to achieve both attack effectiveness and stealthiness. These attacks are also very dangerous in physiological computing, and hence deserve adequate attention. 4) Adversarial attacks to affective computing and adaptive automation applications, which have not been studied yet, but are also possible and dangerous. Many existing attack approaches in BCIs, health informatics and biometrics can be extended to them, either directly or with slight modifications. However, there could also be unique attack approaches specific to these areas. For example, emotions are frequently represented as continuous numbers in the 3D space of valence, arousal and dominance in affective computing  [50] , and hence adversarial attacks to regression models in affective computing should be paid enough attention to. 5) Real-world demonstration of adversarial attacks and defenses. As mentioned in Section IV-D, current research on adversarial attacks of time series did not consider their causality, so the attacks may not be used in the most meaningful online applications. Adversarial attacks to BCIs have advanced rapidly in the past few years, and the attacks have become very easy to perform in theory. However, real-world experiments are still needed to demonstrate their practicableness, and more importantly, the necessity, feasibility and benefits of adversarial defenses. 6) Privacy of physiological computing systems. Adversarial attacked discussed in this review focused on manipulating the system outputs; however, privacy is another very important concern in physiological computing. For example, personal account, personal preferences, physical state and commercial models are privacy information that could be stolen from BCIs  [124] . Defending against these privacy attacks is also crucial for wide-spread applications of physiological computing systems. Finally, we need to emphasize that the goal of adversarial attack research in physiological computing should be discovering its vulnerabilities, and then finding solutions to make it more secure, instead of merely causing damages to it.",
      "page_start": 13,
      "page_end": 13
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Common signals in physiological computing, and their typical",
      "page": 1
    },
    {
      "caption": "Figure 2: In many clinical",
      "page": 2
    },
    {
      "caption": "Figure 2: Examples of common signals in physiological computing, and",
      "page": 2
    },
    {
      "caption": "Figure 3: After EEG signal acquisition, signal pro-",
      "page": 3
    },
    {
      "caption": "Figure 3: Flowchart of a closed-loop EEG-based BCI system.",
      "page": 3
    },
    {
      "caption": "Figure 4: Fig. 4. Ekman’s six basic emotions in the 3D space of Arousal, Pleasure and",
      "page": 3
    },
    {
      "caption": "Figure 5: The task demand estimator maps",
      "page": 4
    },
    {
      "caption": "Figure 5: Adaptive automation expressed as a control system [54].",
      "page": 4
    },
    {
      "caption": "Figure 6: ) for PPG-based atrial ﬁbrillation",
      "page": 4
    },
    {
      "caption": "Figure 6: A model fusion approach for PPG-based atrial ﬁbrillation onset",
      "page": 4
    },
    {
      "caption": "Figure 7: The enrollment mode converts each subject’s physiological",
      "page": 4
    },
    {
      "caption": "Figure 7: Enrollment, identiﬁcation and authentication in biometrics [63].",
      "page": 4
    },
    {
      "caption": "Figure 8: Fig. 8. Types of adversarial attacks.",
      "page": 5
    },
    {
      "caption": "Figure 9: Poisoning attacks [72] focus on the training stage, to create",
      "page": 5
    },
    {
      "caption": "Figure 9: Poisoning and evasion attacks.",
      "page": 6
    },
    {
      "caption": "Figure 10: , is to add a",
      "page": 6
    },
    {
      "caption": "Figure 11: ), but can signiﬁcantly reduce the classiﬁcation",
      "page": 6
    },
    {
      "caption": "Figure 10: The BCI evasion attack approach proposed in [67]. A jamming",
      "page": 6
    },
    {
      "caption": "Figure 11: Evasion attack in BCIs [67].",
      "page": 6
    },
    {
      "caption": "Figure 12: . Compared",
      "page": 7
    },
    {
      "caption": "Figure 12: Query synthesis based active learning in black-box evasion attack",
      "page": 7
    },
    {
      "caption": "Figure 13: Workﬂow of a P300 speller and an SSVEP speller [34]. For each",
      "page": 8
    },
    {
      "caption": "Figure 14: Square wave evasion attack to SSVEP spellers [82].",
      "page": 8
    },
    {
      "caption": "Figure 15: They proposed a practically realizable backdoor key, narrow",
      "page": 8
    },
    {
      "caption": "Figure 15: Poisoning attack in EEG-based BCIs [81]. Narrow period pulses can",
      "page": 8
    },
    {
      "caption": "Figure 10: It’s a gray-",
      "page": 9
    },
    {
      "caption": "Figure 16: (b). Its proce-",
      "page": 9
    },
    {
      "caption": "Figure 16: (a) Ofﬂine ECG biometrics presentation attack [88]; (b) Online ECG biometrics presentation attack [95].",
      "page": 10
    },
    {
      "caption": "Figure 17: However, transfer learning is particularly",
      "page": 12
    },
    {
      "caption": "Figure 17: A transfer learning pipeline in motor imagery based BCIs [118].",
      "page": 12
    },
    {
      "caption": "Figure 18: ), which includes signal processing, feature",
      "page": 12
    },
    {
      "caption": "Figure 19: For example, Paoletti",
      "page": 12
    },
    {
      "caption": "Figure 18: Adversarial attacks to the BCI machine learning pipeline.",
      "page": 12
    },
    {
      "caption": "Figure 19: Additional types of attacks in physiological computing.",
      "page": 12
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Classiﬁcation": "Regression",
          "[67]\n[79]\n[34]\n[80]\n[81]\n[82]": "[83]",
          "X\nX\nX\nX\nX\nX\nX": "X",
          "X\nX\nX\nX\nX\nX\nX\nX\nX": "X\nX",
          "X\nX\nX\nX\nX\nX": "X"
        }
      ],
      "page": 7
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Fundamentals of physiological computing",
      "authors": [
        "S Fairclough"
      ],
      "year": "2009",
      "venue": "Interacting with Computers"
    },
    {
      "citation_id": "2",
      "title": "The Society of Mind",
      "authors": [
        "M Minsky"
      ],
      "year": "1988",
      "venue": "The Society of Mind"
    },
    {
      "citation_id": "3",
      "title": "Physiological computing",
      "authors": [
        "G Jacucci",
        "S Fairclough",
        "E Solovey"
      ],
      "year": "2015",
      "venue": "Computer"
    },
    {
      "citation_id": "4",
      "title": "Deep learning models for electrocardiograms are susceptible to adversarial attack",
      "authors": [
        "X Han",
        "Y Hu",
        "L Foschini",
        "L Chinitz",
        "L Jankelson",
        "R Ranganath"
      ],
      "year": "2020",
      "venue": "Nature Medicine"
    },
    {
      "citation_id": "5",
      "title": "Brain-computer interface technologies in the coming decades",
      "authors": [
        "B Lance",
        "S Kerick",
        "A Ries",
        "K Oie",
        "K Mcdowell"
      ],
      "year": "2012",
      "venue": "Proc. of the IEEE"
    },
    {
      "citation_id": "6",
      "title": "Brain-computer interfaces in neurological rehabilitation",
      "authors": [
        "J Daly",
        "J Wolpaw"
      ],
      "year": "2008",
      "venue": "The Lancet Neurology"
    },
    {
      "citation_id": "7",
      "title": "An EEG-based brain computer interface for emotion recognition and its application in patients with disorder of consciousness",
      "authors": [
        "H Huang",
        "Q Xie",
        "J Pan",
        "Y He",
        "Z Wen",
        "R Yu",
        "Y Li"
      ],
      "year": "2019",
      "venue": "IEEE Trans. on Affective Computing"
    },
    {
      "citation_id": "8",
      "title": "Brain-machine interfaces from motor to mood",
      "authors": [
        "M Shanechi"
      ],
      "year": "2019",
      "venue": "Nature Neuroscience"
    },
    {
      "citation_id": "9",
      "title": "High-speed spelling with a noninvasive brain-computer interface",
      "authors": [
        "X Chen",
        "Y Wang",
        "M Nakanishi",
        "X Gao",
        "T.-P Jung",
        "S Gao"
      ],
      "year": "2015",
      "venue": "Proc. National Academy of Sciences"
    },
    {
      "citation_id": "10",
      "title": "Brain-computer interfaces for communication and control",
      "authors": [
        "J Wolpaw",
        "N Birbaumer",
        "D Mcfarland",
        "G Pfurtscheller",
        "T Vaughan"
      ],
      "year": "2002",
      "venue": "Clinical Neurophysiology"
    },
    {
      "citation_id": "11",
      "title": "EEG-based automatic Epilepsy detection: Review and outlook",
      "authors": [
        "R Peng",
        "J Jiang",
        "G Kuang",
        "H Du",
        "J Shao",
        "D Wu"
      ],
      "year": "2022",
      "venue": "Acta Automatica Sinica"
    },
    {
      "citation_id": "12",
      "title": "Transfer learning for EEG-based braincomputer interfaces: A review of progress made since 2016",
      "authors": [
        "D Wu",
        "Y Xu",
        "B.-L Lu"
      ],
      "year": "2022",
      "venue": "IEEE Trans. on Cognitive and Developmental Systems"
    },
    {
      "citation_id": "13",
      "title": "Deep learning in physiological signal data: A survey",
      "authors": [
        "B Rim",
        "N.-J Sung",
        "S Min",
        "M Hong"
      ],
      "year": "2020",
      "venue": "Sensors"
    },
    {
      "citation_id": "14",
      "title": "EEGNet: a compact convolutional neural network for EEG-based brain-computer interfaces",
      "authors": [
        "V Lawhern",
        "A Solon",
        "N Waytowich",
        "S Gordon",
        "C Hung",
        "B Lance"
      ],
      "year": "2018",
      "venue": "Journal of Neural Engineering"
    },
    {
      "citation_id": "15",
      "title": "Deep learning with convolutional neural networks for EEG decoding and visualization",
      "authors": [
        "R Schirrmeister",
        "J Springenberg",
        "L Fiederer",
        "M Glasstetter",
        "K Eggensperger",
        "M Tangermann",
        "F Hutter",
        "W Burgard",
        "T Ball"
      ],
      "year": "2017",
      "venue": "Human Brain Mapping"
    },
    {
      "citation_id": "16",
      "title": "Thinker invariance: enabling deep neural networks for BCI across more people",
      "authors": [
        "D Kostas",
        "F Rudzicz"
      ],
      "year": "2020",
      "venue": "Journal of Neural Engineering"
    },
    {
      "citation_id": "17",
      "title": "SeizureNet: Multi-spectral deep feature learning for seizure type classification",
      "authors": [
        "U Asif",
        "S Roy",
        "J Tang",
        "S Harrer"
      ],
      "year": "2020",
      "venue": "Machine Learning in Clinical Neuroimaging and Radiogenomics in Neurooncology"
    },
    {
      "citation_id": "18",
      "title": "Towards understanding ECG rhythm classification using convolutional neural networks and attention mappings",
      "authors": [
        "S Goodfellow",
        "A Goodwin",
        "R Greer",
        "P Laussen",
        "M Mazwi",
        "D Eytan"
      ],
      "year": "2018",
      "venue": "Proc. 3rd Machine Learning for Healthcare Conf"
    },
    {
      "citation_id": "19",
      "title": "Deep ECGNet: An optimal deep learning framework for monitoring mental stress using ultra short-term ECG signals",
      "authors": [
        "B Hwang",
        "J You",
        "T Vaessen",
        "I Myin-Germeys",
        "C Park",
        "B.-T Zhang"
      ],
      "year": "2018",
      "venue": "TELEMEDICINE and e-HEALTH"
    },
    {
      "citation_id": "20",
      "title": "Intriguing properties of neural networks",
      "authors": [
        "C Szegedy",
        "W Zaremba",
        "I Sutskever",
        "J Bruna",
        "D Erhan",
        "I Goodfellow",
        "R Fergus"
      ],
      "year": "2014",
      "venue": "Proc. Int'l Conf. on Learning Representations"
    },
    {
      "citation_id": "21",
      "title": "Explaining and harnessing adversarial examples",
      "authors": [
        "I Goodfellow",
        "J Shlens",
        "C Szegedy"
      ],
      "year": "2015",
      "venue": "Proc. Int'l Conf. on Learning Representations"
    },
    {
      "citation_id": "22",
      "title": "Review of artificial intelligence adversarial attack and defense technologies",
      "authors": [
        "S Qiu",
        "Q Liu",
        "S Zhou",
        "C Wu"
      ],
      "year": "2019",
      "venue": "Applied Sciences"
    },
    {
      "citation_id": "23",
      "title": "Adversarial learning targeting deep neural network classification: A comprehensive review of defenses against attacks",
      "authors": [
        "D Miller",
        "Z Xiang",
        "G Kesidis"
      ],
      "year": "2020",
      "venue": "Proc. IEEE"
    },
    {
      "citation_id": "24",
      "title": "Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition",
      "authors": [
        "M Sharif",
        "S Bhagavatula",
        "L Bauer",
        "M Reiter"
      ],
      "year": "2016",
      "venue": "Proc. ACM SIGSAC Conf. on Computer and Communications Security"
    },
    {
      "citation_id": "25",
      "title": "Adversarial patch",
      "authors": [
        "T Brown",
        "D Mané",
        "A Roy",
        "M Abadi",
        "J Gilmer"
      ],
      "year": "2017",
      "venue": "Proc. 31st Int'l Conf. on Neural Information Processing Systems"
    },
    {
      "citation_id": "26",
      "title": "Evolutionary multi-tasking single-objective optimization based on cooperative co-evolutionary memetic algorithm",
      "authors": [
        "Q Chen",
        "X Ma",
        "Z Zhu",
        "Y Sun"
      ],
      "year": "2017",
      "venue": "Proc. 13th Int'l Conf. on Computational Intelligence and Security"
    },
    {
      "citation_id": "27",
      "title": "Synthesizing robust adversarial examples",
      "authors": [
        "A Athalye",
        "L Engstrom",
        "A Ilyas",
        "K Kwok"
      ],
      "year": "2018",
      "venue": "Proc. 35th Int'l Conf. on Machine Learning"
    },
    {
      "citation_id": "28",
      "title": "Robust physical-world attacks on deep learning visual classification",
      "authors": [
        "I Evtimov",
        "K Eykholt",
        "E Fernandes",
        "T Kohno",
        "B Li",
        "A Prakash",
        "A Rahmati",
        "D Song"
      ],
      "year": "2018",
      "venue": "Proc. IEEE Conf. on Computer Vision and Pattern Recognition"
    },
    {
      "citation_id": "29",
      "title": "Adversarial attacks against medical deep learning systems",
      "authors": [
        "S Finlayson",
        "H Chung",
        "I Kohane",
        "A Beam"
      ],
      "year": "2018",
      "venue": "Adversarial attacks against medical deep learning systems",
      "arxiv": "arXiv:1804.05296"
    },
    {
      "citation_id": "30",
      "title": "Adversarial attacks on medical machine learning",
      "authors": [
        "S Finlayson",
        "J Bowers",
        "J Ito",
        "J Zittrain",
        "A Beam",
        "I Kohane"
      ],
      "year": "2019",
      "venue": "Science"
    },
    {
      "citation_id": "31",
      "title": "Adversarial examples -security threats to COVID-19 deep learning systems in medical IoT devices",
      "authors": [
        "A Rahman",
        "M Hossain",
        "N Alrajeh",
        "F Alsolami"
      ],
      "year": "2021",
      "venue": "IEEE Internet of Things Journal"
    },
    {
      "citation_id": "32",
      "title": "Understanding adversarial attacks on deep learning based medical image analysis systems",
      "authors": [
        "X Ma",
        "Y Niu",
        "L Gu",
        "Y Wang",
        "Y Zhao",
        "J Bailey",
        "F Lu"
      ],
      "year": "2020",
      "venue": "Pattern Recognition"
    },
    {
      "citation_id": "33",
      "title": "Secure, privacy-preserving and federated machine learning in medical imaging",
      "authors": [
        "G Kaissis",
        "M Makowski",
        "D Rückert",
        "R Braren"
      ],
      "year": "2020",
      "venue": "Nature Machine Intelligence"
    },
    {
      "citation_id": "34",
      "title": "Tiny noise, big mistakes: Adversarial perturbations induce errors in brain-computer interface spellers",
      "authors": [
        "X Zhang",
        "D Wu",
        "L Ding",
        "H Luo",
        "C.-T Lin",
        "T.-P Jung",
        "R Chavarriaga"
      ],
      "year": "2021",
      "venue": "National Science Review"
    },
    {
      "citation_id": "35",
      "title": "How to attack PPG biometric using adversarial machine learning",
      "authors": [
        "N Karimian"
      ],
      "year": "2019",
      "venue": "Autonomous Systems: Sensors, Processing, and Security for Vehicles and Infrastructure"
    },
    {
      "citation_id": "36",
      "title": "ECG biometric: Spoofing and countermeasures",
      "authors": [
        "N Karimian",
        "D Woodard",
        "D Forte"
      ],
      "year": "2020",
      "venue": "IEEE Trans. on Biometrics, Behavior, and Identity Science"
    },
    {
      "citation_id": "37",
      "title": "Cyberattacks on miniature brain implants to disrupt spontaneous neural signaling",
      "authors": [
        "S Bernal",
        "A Celdran",
        "L Maimó",
        "M Barros",
        "S Balasubramaniam",
        "G Pérez"
      ],
      "year": "2020",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "38",
      "title": "Motor imagery and direct braincomputer communication",
      "authors": [
        "G Pfurtscheller",
        "C Neuper"
      ],
      "year": "2001",
      "venue": "Proc. of the IEEE"
    },
    {
      "citation_id": "39",
      "title": "Event-related potentials: A methods handbook",
      "authors": [
        "T Handy"
      ],
      "year": "2005",
      "venue": "Event-related potentials: A methods handbook"
    },
    {
      "citation_id": "40",
      "title": "A review of rapid serial visual presentation-based braincomputer interfaces",
      "authors": [
        "S Lees",
        "N Dayan",
        "H Cecotti",
        "P Mccullagh",
        "L Maguire",
        "F Lotte",
        "D Coyle"
      ],
      "year": "2018",
      "venue": "Journal of Neural Engineering"
    },
    {
      "citation_id": "41",
      "title": "Evoked-potential correlates of stimulus uncertainty",
      "authors": [
        "S Sutton",
        "M Braren",
        "J Zubin",
        "E John"
      ],
      "year": "1965",
      "venue": "Science"
    },
    {
      "citation_id": "42",
      "title": "Multiple channel detection of steady-state visual evoked potentials for brain-computer interfaces",
      "authors": [
        "O Friman",
        "I Volosyak",
        "A Graser"
      ],
      "year": "2007",
      "venue": "IEEE Trans. on Biomedical Engineering"
    },
    {
      "citation_id": "43",
      "title": "User adaptive BCIs: SSVEP and P300 based interfaces",
      "authors": [
        "F Beverina",
        "G Palmas",
        "S Silvoni",
        "F Piccione",
        "S Giove"
      ],
      "year": "2003",
      "venue": "PsychNology Journal"
    },
    {
      "citation_id": "44",
      "title": "A P300-based brain-computer interface: initial tests by ALS patients",
      "authors": [
        "E Sellers",
        "E Donchin"
      ],
      "year": "2006",
      "venue": "Clinical Neurophysiology"
    },
    {
      "citation_id": "45",
      "title": "Responsive neurostimulation: review of clinical trials and insights into focal epilepsy",
      "authors": [
        "E Geller"
      ],
      "year": "2018",
      "venue": "Epilepsy & Behavior"
    },
    {
      "citation_id": "46",
      "title": "Expanding brain-computer interfaces for controlling epilepsy networks: novel thalamic responsive neurostimulation in refractory epilepsy",
      "authors": [
        "A Gummadavelli",
        "H Zaveri",
        "D Spencer",
        "J Gerrard"
      ],
      "year": "2018",
      "venue": "Frontiers in Neuroscience"
    },
    {
      "citation_id": "47",
      "title": "Affective Computing",
      "authors": [
        "R Picard"
      ],
      "year": "1997",
      "venue": "Affective Computing"
    },
    {
      "citation_id": "48",
      "title": "Constants across cultures in the face and emotion",
      "authors": [
        "P Ekman",
        "W Friesen"
      ],
      "year": "1971",
      "venue": "Journal of Personality and Social Psychology"
    },
    {
      "citation_id": "49",
      "title": "A circumplex model of affect",
      "authors": [
        "J Russell"
      ],
      "year": "1980",
      "venue": "Journal of Personality and Social Psychology"
    },
    {
      "citation_id": "50",
      "title": "Basic Dimensions for a General Psychological Theory: Implications for Personality, Social, Environmental, and Developmental Studies",
      "authors": [
        "A Mehrabian"
      ],
      "year": "1980",
      "venue": "Basic Dimensions for a General Psychological Theory: Implications for Personality, Social, Environmental, and Developmental Studies"
    },
    {
      "citation_id": "51",
      "title": "Physiological signals based affective computing: A systematic review",
      "authors": [
        "X Quan",
        "Z Zeng",
        "J Jiang",
        "Y Zhang",
        "B.-L Lv",
        "D Wu"
      ],
      "year": "2021",
      "venue": "Acta Automatica Sinica"
    },
    {
      "citation_id": "52",
      "title": "Affective computing vs. affective placebo: Study of a biofeedback-controlled game for relaxation training",
      "authors": [
        "L Chittaro",
        "R Sioni"
      ],
      "year": "2014",
      "venue": "Int'l Journal of Human-Computer Studies"
    },
    {
      "citation_id": "53",
      "title": "Adapting software with affective computing: a systematic review",
      "authors": [
        "R Aranha",
        "C Corrêa",
        "F Nunes"
      ],
      "year": "2021",
      "venue": "IEEE Trans. on Affective Computing"
    },
    {
      "citation_id": "54",
      "title": "Exploring individualized objective workload prediction with feedback for adaptive automation",
      "authors": [
        "D Boeke",
        "M Miller",
        "C Rusnock",
        "B Borghetti"
      ],
      "year": "2015",
      "venue": "Proc. Industrial and Systems Engineering Research Conf"
    },
    {
      "citation_id": "55",
      "title": "Adaptive automation triggered by EEG-based mental workload index: a passive brain-computer interface application in realistic air traffic control environment",
      "authors": [
        "P Aricò",
        "G Borghini",
        "G Di Flumeri",
        "A Colosimo",
        "S Bonelli",
        "A Golfetti",
        "S Pozzi",
        "J.-P Imbert",
        "G Granger",
        "R Benhacene"
      ],
      "year": "2016",
      "venue": "Frontiers in Human Neuroscience"
    },
    {
      "citation_id": "56",
      "title": "Eye movement as indicators of mental workload to trigger adaptive automation",
      "authors": [
        "T De Greef",
        "H Lafeber",
        "H Van Oostendorp",
        "J Lindenberg"
      ],
      "year": "2009",
      "venue": "Int'l Conf. on Foundations of Augmented Cognition"
    },
    {
      "citation_id": "57",
      "title": "Cognitive workload assessment of prosthetic devices: A review of literature and meta-analysis",
      "authors": [
        "J Park",
        "M Zahabi"
      ],
      "year": "2022",
      "venue": "IEEE Trans. on Human-Machine Systems"
    },
    {
      "citation_id": "58",
      "title": "Guide to Health Informatics",
      "authors": [
        "E Coiera"
      ],
      "year": "2015",
      "venue": "Guide to Health Informatics"
    },
    {
      "citation_id": "59",
      "title": "Pre-symptomatic detection of COVID-19 from smartwatch data",
      "authors": [
        "T Mishra",
        "M Wang",
        "A Metwally",
        "G Bogu",
        "A Brooks",
        "A Bahmani",
        "A Alavi",
        "A Celli",
        "E Higgs",
        "O Dagan-Rosenfeld"
      ],
      "year": "2020",
      "venue": "Nature Biomedical Engineering"
    },
    {
      "citation_id": "60",
      "title": "Wearable photoplethysmography for cardiovascular monitoring",
      "authors": [
        "P Charlton",
        "P Kyriacou",
        "J Mant",
        "V Marozas",
        "P Chowienczyk",
        "J Alastruey"
      ],
      "year": "2022",
      "venue": "Proc. of the IEEE"
    },
    {
      "citation_id": "61",
      "title": "Machine-learning fusion approach for the prediction of atrial fibrillation onset using photoplethysmographic-based smart device",
      "authors": [
        "Y Guo",
        "Y Cui",
        "C Zhao",
        "L Liu",
        "L Li",
        "M Chen"
      ],
      "year": "2021",
      "venue": "European Heart Journal"
    },
    {
      "citation_id": "62",
      "title": "Bioelectrical signals as emerging biometrics: Issues and challenges",
      "authors": [
        "Y Singh",
        "S Singh",
        "A Ray"
      ],
      "year": "2012",
      "venue": "Int'l Scholarly Research Notices"
    },
    {
      "citation_id": "63",
      "title": "Toward EEG-based biometric systems: The great potential of brain-wave-based biometrics",
      "authors": [
        "K Thomas",
        "A Vinod"
      ],
      "year": "2017",
      "venue": "IEEE Systems, Man, and Cybernetics Magazine"
    },
    {
      "citation_id": "64",
      "title": "Heart biometrics: Theory, methods and applications",
      "authors": [
        "F Agrafioti",
        "J Gao",
        "D Hatzinakos",
        "J Yang"
      ],
      "year": "2011",
      "venue": "Biometrics"
    },
    {
      "citation_id": "65",
      "title": "Evaluation of PPG biometrics for authentication in different states",
      "authors": [
        "U Yadav",
        "S Abbas",
        "D Hatzinakos"
      ],
      "year": "2018",
      "venue": "Proc. Int'l Conf. on Biometrics"
    },
    {
      "citation_id": "66",
      "title": "Biometric recognition using multimodal physiological signals",
      "authors": [
        "S Bianco",
        "P Napoletano"
      ],
      "year": "2019",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "67",
      "title": "On the vulnerability of CNN classifiers in EEG-based BCIs",
      "authors": [
        "X Zhang",
        "D Wu"
      ],
      "year": "2019",
      "venue": "IEEE Trans. on Neural Systems and Rehabilitation Engineering"
    },
    {
      "citation_id": "68",
      "title": "DeepFool: a simple and accurate method to fool deep neural networks",
      "authors": [
        "S.-M Moosavi-Dezfooli",
        "A Fawzi",
        "P Frossard"
      ],
      "year": "2016",
      "venue": "Proc. IEEE Conf. on Computer Vision and Pattern Recognition"
    },
    {
      "citation_id": "69",
      "title": "Towards evaluating the robustness of neural networks",
      "authors": [
        "N Carlini",
        "D Wagner"
      ],
      "year": "2017",
      "venue": "Proc. IEEE Symposium on Security and Privacy"
    },
    {
      "citation_id": "70",
      "title": "Adversarial examples in the physical world",
      "authors": [
        "A Kurakin",
        "I Goodfellow",
        "S Bengio"
      ],
      "year": "2017",
      "venue": "Proc. Int'l Conf. on Learning Representations"
    },
    {
      "citation_id": "71",
      "title": "Practical black-box attacks against machine learning",
      "authors": [
        "N Papernot",
        "P Mcdaniel",
        "I Goodfellow",
        "S Jha",
        "Z Celik",
        "A Swami"
      ],
      "year": "2017",
      "venue": "Proc. Asia Conf. on Computer and Communications Security"
    },
    {
      "citation_id": "72",
      "title": "Is feature selection secure against training data poisoning",
      "authors": [
        "H Xiao",
        "B Biggio",
        "G Brown",
        "G Fumera",
        "C Eckert",
        "F Roli"
      ],
      "year": "2015",
      "venue": "Proc. 32nd Int'l Conf. on Machine Learning"
    },
    {
      "citation_id": "73",
      "title": "Using machine teaching to identify optimal training-set attacks on machine learners",
      "authors": [
        "S Mei",
        "X Zhu"
      ],
      "year": "2015",
      "venue": "Proc. AAAI Conf. on Artificial Intelligence"
    },
    {
      "citation_id": "74",
      "title": "Support vector machines under adversarial label noise",
      "authors": [
        "B Biggio",
        "B Nelson",
        "P Laskov"
      ],
      "year": "2011",
      "venue": "Proc. Asian Conf. on Machine Learning"
    },
    {
      "citation_id": "75",
      "title": "Adversarial attacks on deep neural networks for time series classification",
      "authors": [
        "H Fawaz",
        "G Forestier",
        "J Weber",
        "L Idoumghar",
        "P.-A Muller"
      ],
      "year": "2019",
      "venue": "Proc. Int'l Joint Conf. on Neural Networks"
    },
    {
      "citation_id": "76",
      "title": "Adversarial attacks on time series",
      "authors": [
        "F Karim",
        "S Majumdar",
        "H Darabi"
      ],
      "year": "2021",
      "venue": "IEEE Trans. on Pattern Analysis and Machine Intelligence"
    },
    {
      "citation_id": "77",
      "title": "Generating adversarial samples on multivariate time series using variational autoencoders",
      "authors": [
        "S Harford",
        "F Karim",
        "H Darabi"
      ],
      "year": "2021",
      "venue": "IEEE/CAA Journal of Automatica Sinica"
    },
    {
      "citation_id": "78",
      "title": "Personal voice assistant security and privacy -a survey",
      "authors": [
        "P Cheng",
        "U Roedig"
      ],
      "year": "2022",
      "venue": "Proc. of the IEEE"
    },
    {
      "citation_id": "79",
      "title": "Active learning for black-box adversarial attacks in EEG-based brain-computer interfaces",
      "authors": [
        "X Jiang",
        "X Zhang",
        "D Wu"
      ],
      "year": "2019",
      "venue": "Proc. IEEE Symposium Series on Computational Intelligence"
    },
    {
      "citation_id": "80",
      "title": "Universal adversarial perturbations for CNN classifiers in EEG-based BCIs",
      "authors": [
        "Z Liu",
        "L Meng",
        "X Zhang",
        "W Fang",
        "D Wu"
      ],
      "year": "2021",
      "venue": "Journal of Neural Engineering"
    },
    {
      "citation_id": "81",
      "title": "EEGbased brain-computer interfaces are vulnerable to backdoor attacks",
      "authors": [
        "L Meng",
        "J Huang",
        "Z Zeng",
        "X Jiang",
        "S Yu",
        "T.-P Jung",
        "C.-T Lin",
        "R Chavarriaga",
        "D Wu"
      ],
      "year": "2022",
      "venue": "Engineering"
    },
    {
      "citation_id": "82",
      "title": "SSVEP-based brain-computer interfaces are vulnerable to square wave attacks",
      "authors": [
        "R Bian",
        "L Meng",
        "D Wu"
      ],
      "year": "2022",
      "venue": "Science China Information Sciences"
    },
    {
      "citation_id": "83",
      "title": "White-box target attack for EEG-based BCI regression problems",
      "authors": [
        "L Meng",
        "C.-T Lin",
        "T.-P Jung",
        "D Wu"
      ],
      "year": "2019",
      "venue": "Proc. Int'l Conf. on Neural Information Processing"
    },
    {
      "citation_id": "84",
      "title": "Universal adversarial perturbations in epileptic seizure detection",
      "authors": [
        "A Aminifar"
      ],
      "year": "2020",
      "venue": "Proc. Int'l Joint Conf. on Neural Networks"
    },
    {
      "citation_id": "85",
      "title": "Adversarial attacks to machine learning-based smart healthcare systems",
      "authors": [
        "A Newaz",
        "N Haque",
        "A Sikder",
        "M Rahman",
        "A Uluagac"
      ],
      "year": "2020",
      "venue": "Adversarial attacks to machine learning-based smart healthcare systems",
      "arxiv": "arXiv:2010.03671"
    },
    {
      "citation_id": "86",
      "title": "Backdoor attacks against transfer learning with pre-trained deep learning models",
      "authors": [
        "S Wang",
        "S Nepal",
        "C Rudolph",
        "M Grobler",
        "S Chen",
        "T Chen"
      ],
      "year": "2020",
      "venue": "IEEE Trans. on Services Computing"
    },
    {
      "citation_id": "87",
      "title": "On the vulnerability of an EEG-based biometric system to hill-climbing attacks algorithms' comparison and possible countermeasures",
      "authors": [
        "E Maiorana",
        "G Hine",
        "D Rocca",
        "P Campisi"
      ],
      "year": "2013",
      "venue": "Proc. IEEE 6th Int'l Conf. on Biometrics: Theory, Applications and Systems"
    },
    {
      "citation_id": "88",
      "title": "Broken hearted: How to attack ECG biometrics",
      "authors": [
        "S Eberz",
        "N Paoletti",
        "M Roeschlin",
        "M Kwiatkowska",
        "I Martinovic",
        "A Patané"
      ],
      "year": "2017",
      "venue": "Proc. Network and Distributed System Security Symposium"
    },
    {
      "citation_id": "89",
      "title": "Driver drowsiness estimation from EEG signals using online weighted adaptation regularization for regression (OwARR)",
      "authors": [
        "D Wu",
        "V Lawhern",
        "S Gordon",
        "B Lance",
        "C.-T Lin"
      ],
      "year": "2017",
      "venue": "IEEE Trans. on Fuzzy Systems"
    },
    {
      "citation_id": "90",
      "title": "Brain leaks and consumer neurotechnology",
      "authors": [
        "M Ienca",
        "P Haselager",
        "E Emanuel"
      ],
      "year": "2018",
      "venue": "Nature Biotechnology"
    },
    {
      "citation_id": "91",
      "title": "The ethics of neurotechnology",
      "authors": [
        "I Jarchum"
      ],
      "year": "2019",
      "venue": "Nature Biotechnology"
    },
    {
      "citation_id": "92",
      "title": "Brain-Computer Interfaces: U.S. Military Applications and Implications, An Initial Assessment",
      "authors": [
        "A Binnendijk",
        "T Marler",
        "E Bartels"
      ],
      "year": "2020",
      "venue": "Brain-Computer Interfaces: U.S. Military Applications and Implications, An Initial Assessment"
    },
    {
      "citation_id": "93",
      "title": "Privacy and security issues in brain computer interfaces",
      "authors": [
        "K Sundararajan"
      ],
      "year": "2017",
      "venue": "Privacy and security issues in brain computer interfaces"
    },
    {
      "citation_id": "94",
      "title": "Synthesizing stealthy reprogramming attacks on cardiac devices",
      "authors": [
        "N Paoletti",
        "Z Jiang",
        "M Islam",
        "H Abbas",
        "R Mangharam",
        "S Lin",
        "Z Gruber",
        "S Smolka"
      ],
      "year": "2019",
      "venue": "Proc. 10th ACM/IEEE Int'l Conf. on Cyber-Physical Systems"
    },
    {
      "citation_id": "95",
      "title": "On the vulnerability of ECG verification to online presentation attacks",
      "authors": [
        "N Karimian",
        "D Woodard",
        "D Forte"
      ],
      "year": "2017",
      "venue": "IEEE Int'l Joint Conf. on Biometrics"
    },
    {
      "citation_id": "96",
      "title": "Security in brain-computer interfaces: State-of-the-art, opportunities, and future challenges",
      "authors": [
        "S Bernal",
        "A Celdrán",
        "G Pérez",
        "M Barros",
        "S Balasubramaniam"
      ],
      "year": "2021",
      "venue": "ACM Computing Surveys"
    },
    {
      "citation_id": "97",
      "title": "Ensemble adversarial training: Attacks and defenses",
      "authors": [
        "F Tramèr",
        "A Kurakin",
        "N Papernot",
        "I Goodfellow",
        "D Boneh",
        "P Mcdaniel"
      ],
      "year": "2017",
      "venue": "Ensemble adversarial training: Attacks and defenses",
      "arxiv": "arXiv:1705.07204"
    },
    {
      "citation_id": "98",
      "title": "Blocking transferability of adversarial examples in black-box learning systems",
      "authors": [
        "H Hosseini",
        "Y Chen",
        "S Kannan",
        "B Zhang",
        "R Poovendran"
      ],
      "year": "2017",
      "venue": "Blocking transferability of adversarial examples in black-box learning systems",
      "arxiv": "arXiv:1703.04318"
    },
    {
      "citation_id": "99",
      "title": "Keeping the bad guys out: Protecting and vaccinating deep learning with JPEG compression",
      "authors": [
        "N Das",
        "M Shanbhogue",
        "S.-T Chen",
        "F Hohman",
        "L Chen",
        "M Kounavis",
        "D Chau"
      ],
      "year": "2017",
      "venue": "Keeping the bad guys out: Protecting and vaccinating deep learning with JPEG compression",
      "arxiv": "arXiv:1705.02900"
    },
    {
      "citation_id": "100",
      "title": "Adversarial examples for semantic segmentation and object detection",
      "authors": [
        "C Xie",
        "J Wang",
        "Z Zhang",
        "Y Zhou",
        "L Xie",
        "A Yuille"
      ],
      "year": "2017",
      "venue": "Proc. IEEE Int'l Conf. on Computer Vision"
    },
    {
      "citation_id": "101",
      "title": "Distillation as a defense to adversarial perturbations against deep neural networks",
      "authors": [
        "N Papernot",
        "P Mcdaniel",
        "X Wu",
        "S Jha",
        "A Swami"
      ],
      "year": "2016",
      "venue": "Proc. IEEE Symp. on Security and Privacy"
    },
    {
      "citation_id": "102",
      "title": "Feature squeezing: Detecting adversarial examples in deep neural networks",
      "authors": [
        "W Xu",
        "D Evans",
        "Y Qi"
      ],
      "year": "2017",
      "venue": "Feature squeezing: Detecting adversarial examples in deep neural networks",
      "arxiv": "arXiv:1704.01155"
    },
    {
      "citation_id": "103",
      "title": "Towards deep neural network architectures robust to adversarial examples",
      "authors": [
        "S Gu",
        "L Rigazio"
      ],
      "year": "2014",
      "venue": "Towards deep neural network architectures robust to adversarial examples",
      "arxiv": "arXiv:1412.5068"
    },
    {
      "citation_id": "104",
      "title": "DeepCloak: Masking deep neural network models for robustness against adversarial samples",
      "authors": [
        "J Gao",
        "B Wang",
        "Z Lin",
        "W Xu",
        "Y Qi"
      ],
      "year": "2017",
      "venue": "DeepCloak: Masking deep neural network models for robustness against adversarial samples",
      "arxiv": "arXiv:1702.06763"
    },
    {
      "citation_id": "105",
      "title": "Secure and robust machine learning for healthcare: A survey",
      "authors": [
        "A Qayyum",
        "J Qadir",
        "M Bilal",
        "A Al-Fuqaha"
      ],
      "year": "2021",
      "venue": "IEEE Reviews in Biomedical Engineering"
    },
    {
      "citation_id": "106",
      "title": "Defense-GAN: Protecting classifiers against adversarial attacks using generative models",
      "authors": [
        "P Samangouei",
        "M Kabkab",
        "R Chellappa"
      ],
      "year": "2018",
      "venue": "Defense-GAN: Protecting classifiers against adversarial attacks using generative models",
      "arxiv": "arXiv:1805.06605"
    },
    {
      "citation_id": "107",
      "title": "Defense against adversarial attacks using high-level representation guided denoiser",
      "authors": [
        "F Liao",
        "M Liang",
        "Y Dong",
        "T Pang",
        "X Hu",
        "J Zhu"
      ],
      "year": "2018",
      "venue": "Proc. IEEE Conf. on Computer Vision and Pattern Recognition"
    },
    {
      "citation_id": "108",
      "title": "Augmenting DL with adversarial training for robust prediction of epilepsy seizures",
      "authors": [
        "A Hussein",
        "M Djandji",
        "R Mahmoud",
        "M Dhaybi",
        "H Hajj"
      ],
      "year": "2020",
      "venue": "ACM Trans. on Computing for Healthcare"
    },
    {
      "citation_id": "109",
      "title": "An analytical framework for security-tuning of artificial intelligence applications under attack",
      "authors": [
        "K Sadeghi",
        "A Banerjee",
        "S Gupta"
      ],
      "year": "2019",
      "venue": "IEEE Int'l Conf. On Artificial Intelligence Testing"
    },
    {
      "citation_id": "110",
      "title": "Detecting malicious temporal alterations of ECG signals in body sensor networks",
      "authors": [
        "H Cai",
        "K Venkatasubramanian"
      ],
      "year": "2015",
      "venue": "Proc. Int'l Conf. on Network and System Security"
    },
    {
      "citation_id": "111",
      "title": "Detecting signal injection attack-based morphological alterations of ECG measurements",
      "authors": [
        "H Cai",
        "K Venkatasubramanian"
      ],
      "year": "2016",
      "venue": "Proc. Int'l Conf. on Distributed Computing in Sensor Systems, Washington"
    },
    {
      "citation_id": "112",
      "title": "Reducing excessive margin to achieve a better accuracy vs. robustness trade-off",
      "authors": [
        "R Rade",
        "S.-M Moosavi-Dezfooli"
      ],
      "year": "2022",
      "venue": "Proc. Int'l Conf. on Learning Representations"
    },
    {
      "citation_id": "113",
      "title": "Adversarial training for free",
      "authors": [
        "A Shafahi",
        "M Najibi",
        "A Ghiasi",
        "Z Xu",
        "J Dickerson",
        "C Studer",
        "L Davis",
        "G Taylor",
        "T Goldstein"
      ],
      "year": "2019",
      "venue": "Proc. Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "114",
      "title": "Adversarial examples are not easily detected: Bypassing ten detection methods",
      "authors": [
        "N Carlini",
        "D Wagner"
      ],
      "year": "2017",
      "venue": "Proc. Workshop on Artificial Intelligence and Security"
    },
    {
      "citation_id": "115",
      "title": "Emotion-Meter: A multimodal framework for recognizing human emotions",
      "authors": [
        "W.-L Zheng",
        "W Liu",
        "Y Lu",
        "B.-L Lu",
        "A Cichocki"
      ],
      "year": "2019",
      "venue": "IEEE Trans. on Cybernetics"
    },
    {
      "citation_id": "116",
      "title": "Transfer learning for brain-computer interfaces: A Euclidean space data alignment approach",
      "authors": [
        "H He",
        "D Wu"
      ],
      "year": "2020",
      "venue": "IEEE Trans. on Biomedical Engineering"
    },
    {
      "citation_id": "117",
      "title": "Switching EEG headsets made easy: Reducing offline calibration effort using active wighted adaptation regularization",
      "authors": [
        "D Wu",
        "V Lawhern",
        "W Hairston",
        "B Lance"
      ],
      "year": "2016",
      "venue": "IEEE Trans. on Neural Systems and Rehabilitation Engineering"
    },
    {
      "citation_id": "118",
      "title": "Transfer learning for motor imagery based brain-computer interfaces: A tutorial",
      "authors": [
        "D Wu",
        "X Jiang",
        "R Peng"
      ],
      "year": "2022",
      "venue": "Neural Networks"
    },
    {
      "citation_id": "119",
      "title": "Adversarial feature selection against evasion attacks",
      "authors": [
        "F Zhang",
        "P Chan",
        "B Biggio",
        "D Yeung",
        "F Roli"
      ],
      "year": "2016",
      "venue": "IEEE Trans. on Cybernetics"
    },
    {
      "citation_id": "120",
      "title": "Neurosecurity: security and privacy for neural devices",
      "authors": [
        "T Denning",
        "Y Matsuoka",
        "T Kohno"
      ],
      "year": "2009",
      "venue": "Neurosurgical Focus"
    },
    {
      "citation_id": "121",
      "title": "SoK: Security and privacy in implantable medical devices and body area networks",
      "authors": [
        "M Rushanan",
        "A Rubin",
        "D Kune",
        "C Swanson"
      ],
      "year": "2014",
      "venue": "Proc. IEEE Symposium on Security and Privacy"
    },
    {
      "citation_id": "122",
      "title": "Security and privacy issues in implantable medical devices: A comprehensive survey",
      "authors": [
        "C Camara",
        "P Peris-Lopez",
        "J Tapiador"
      ],
      "year": "2015",
      "venue": "Journal of Biomedical Informatics"
    },
    {
      "citation_id": "123",
      "title": "Brainjacking: implant security issues in invasive neuromodulation",
      "authors": [
        "L Pycroft",
        "S Boccard",
        "S Owen",
        "J Stein",
        "J Fitzgerald",
        "A Green",
        "T Aziz"
      ],
      "year": "2016",
      "venue": "World Neurosurgery"
    },
    {
      "citation_id": "124",
      "title": "Privacy-preserving brain-computer interfaces: A systematic review",
      "authors": [
        "K Xia",
        "W Duch",
        "Y Sun",
        "K Xu",
        "W Fang",
        "H Luo",
        "Y Zhang",
        "D Sang",
        "D Wu",
        "X Xu",
        "F.-Y Wang"
      ],
      "year": "2022",
      "venue": "IEEE Trans. on Computational Social Systems"
    }
  ]
}