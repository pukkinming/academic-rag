{
  "paper_id": "2208.04547v1",
  "title": "Emotion Detection From Tweets Using A Bert And Svm Ensemble Model",
  "published": "2022-08-09T05:32:29Z",
  "authors": [
    "Ionuţ-Alexandru Albu",
    "Stelian Spînu"
  ],
  "keywords": [
    "Emotion recognition",
    "Machine learning",
    "Natural language processing",
    "Sentiment analysis",
    "Twitter"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Automatic identification of emotions expressed in Twitter data has a wide range of applications. We create a well-balanced dataset by adding a neutral class to a benchmark dataset consisting of four emotions: fear, sadness, joy, and anger. On this extended dataset, we investigate the use of Support Vector Machine (SVM) and Bidirectional Encoder Representations from Transformers (BERT) for emotion recognition. We propose a novel ensemble model by combining the two BERT and SVM models. Experiments show that the proposed model achieves a state-of-the-art accuracy of 0.91 on emotion recognition in tweets.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Emotion detection is a subfield of sentiment analysis and is concerned with detecting the writer's emotion from text data. The main difference between the two is that, whereas sentiment analysis tries to classify a text as being positive or negative, emotion detection tries to identify the exact emotion of the writer, such as happiness, sadness, fear, etc. Emotion analysis of tweets is a very challenging task for natural language processing systems. Unlike traditional text, tweets are very short messages and contain spelling mistakes, slang, shortened forms, phrasal abbreviations, and expressive lengthening  [1] . Automatic identification of emotions expressed in Twitter data has a wide range of applications such as understanding consumer views regarding a product  [2] , stock market prediction  [3] , detection of depressive disorders  [4] , detecting bullying outbreaks  [5] , and identifying terrorist threats  [6] .\n\nThe contribution of this paper can be summarized as follows. We present an improved version of the WASSA dataset  [7]  for the task of emotion detection, that has been obtained through balancing and the addition of a new class, the neutral class. Our experimental results 3 show that SVM offers the best results when compared to other Machine Learning classifiers. Further, we fine-tune three BERT versions and present their performance on our dataset. Finally, we introduce a novel ensemble model which combines BERT and SVM models and achieves state-of-the-art results.  Wang et al. [8]  automatically created a large dataset containing about 2.5 million tweets, by leveraging the emotion hashtags. They applied two different classifiers, logistic regression and Naïve Bayes, to explore the effectiveness of various features such as n-grams, emotion lexicons, and part-of-speech information on the emotion identification task. The highest accuracy achieved was 0.6557.  Mohammad [9]  automatically created a corpus of about 21,000 emotionlabelled tweets using hashtags. He employed binary SVMs, one for each of the six basic emotions of  Ekman [10] , and used the presence or absence of unigrams and bigrams as binary features. The binary classifiers were able to predict the emotions with a balanced F1-score of 0.499.  Janssens et al. [11]  studied the impact of using weak labels compared to strong labels on emotion recognition for a corpus consisting of 341,931 tweets. The weak labels were created by employing the hashtags of the tweets and the strong labels by the use of crowdsourcing. The features extracted by combining ngrams and TF-IDF (Term Frequency-Inverse Document Frequency) were applied to five classification algorithms: Stochastic Gradient Descent, SVM, Naïve Bayes, Nearest Centroid, and Ridge. The results showed only a 9.25% decrease in F1score when using weak labels.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Related Work",
      "text": "Abdul-Mageed and Ungar  [12]  used distant supervision to automatically construct a large dataset of about 1.6 million labelled tweets and then trained Gated Recurrent Neural Networks for fine-grained emotion detection. They achieved an average accuracy of 0.8758 on 24 fine-grained types of emotions.  Felbo et al. [13]  employed a variant of the Long Short-Term Memory model for emoji prediction on a dataset consisting of 1.6 billion tweets. Then they fine-tuned the pretrained model for emotion, sentiment, and sarcasm detection.\n\nUsing their pretrained DeepMoji model, the highest averaged F1-score obtained in emotion analysis was 0.61.  Chiorrini et al. [14]  investigated the use of Bidirectional Encoder Representations from Transformers (BERT)  [15]  for both sentiment analysis and emotion recognition of Twitter data. They achieved an accuracy of 0.90 on emotion recognition task.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Proposed Method 3.1 Dataset",
      "text": "The dataset used for training and evaluation of emotion in tweets was partly extracted from the WASSA dataset, which was offered to the participants in the Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis (WASSA-2017)  [7] . We extracted 1,500 tweets for each of the four emotions: fear, sadness, joy and anger, without taking into account data containing emotion intensities. Next to these four classes, we added an extra class of 1,500 neutral tweets, as it has been shown in  [16]  that having a neutral class in the classification process is important, because in this way the neural network will not have to classify unknown emotions into one of the learnt classes of emotions. Neutral tweets were extracted from CrowdFlower 4  .\n\nThe reason we divided the dataset in this manner is the importance of having a well-balanced dataset. A well-balanced dataset contains an equal number of samples per class  [17] . This ensures that the model will not favour larger classes in the classification process.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Svm Model",
      "text": "The preprocessing phase of the SVM model involves traditional machine learning preprocessing operations: emoticon to word conversion, Unicode to ASCII conversion, stop words filtering, sentence tokenization and vectorization, and label encoding. We first preprocessed tweets by eliminating unnecessary words and artefacts from tweets (usernames, links, hashtag symbols) and afterwards translating emoticons into their meaning by using Demoji Python library 5  for Unicode emoticons and meanings extracted from Wikipedia 6  for western-style emoticons. Emoticons to words conversion was used due to the fact that emoticons may be relevant in detecting the emotion in a tweet, as they are frequently used in text messages for better conveying feelings  [18] .\n\nUnicode to ASCII conversion was deemed important as the ASCII character set is smaller compared to the Unicode one, therefore computation time is reduced, due to the fact that the word count will be reduced as well, which might result in a performance boost.\n\nStop words filtering in the dataset has been proven to improve performance and speed computation [19], so we used nltk's list of stopwords for this task. Stemming is another method of improving model performance by reducing derived words to a grammatical root called stem. In this article we used nltk's Snowball stemmer  7  .\n\nFor transforming each tweet into a numeric vector, we used tokenization alongside term-frequency times inverse document-frequency (tf-idf). Tf-idf  [20]  tries to estimate the importance of tokens in the dataset by computing two statistics: the term frequency, which means the appearance of a specific term in the tweet, and the inverse document frequency used to measure how much information that specific term provides relative to all the tweets in the corpus. The final result of the tf-idf is multiplication between the two frequencies.\n\nIn order to feed the data to the model, tweets, but also labels have to be preprocessed. Label encoding was achieved by using a numeric label encoder 8  for assigning to each emotion class a unique number.\n\nFor building the SVM model RBF (Radial Basis Function) kernel was chosen. The decision is based on the fact that its nonlinearity maps the data into a higher dimension space when compared to other kernels. It also has less hyperparameters and numerical difficulties than other kernels  [21] . The regularization factor (C) was set empirically to 1.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Bert Model",
      "text": "In this paper three versions of BERT were analysed, vanilla BERT, which is the first version [15], RoBERTa (Robustly Optimised BERT approach) which is an optimised version of  BERT [22] , and BERTweet  [23] , which is a RoBERTa model pretrained on tweets.\n\nFor the BERT versions a different preprocessing approach was used. Links and usernames were eliminated, as those are considered unimportant and keeping them could result in a biased model. On top of this, BERT specific preprocessing was used, which includes: • Word tokenization. Each sentence is split into its composing words and a unique word identifier is assigned. BERT uses a WordPiece tokenizer. • Padding. Each sentence is padded to the same number of tokens.\n\n• Building the attention mask. The attention mask will enable the model to distinguish between padding tokens and original tokens. • Adding BERT tokens. Those tokens are CLS, SEP, PAD, UKN, EOS, and are part of how the model was pretrained using Masked Language Modelling  [15] . Labels were encoded in the same manner as the SVM model, using a numeric label encoder.\n\nFor fine tuning the three BERT versions for the task of emotion detection, the base cased model was chosen for RoBERTa, BERTweet, and vanilla BERT. Also, a pooled output was used for the BERT models utilizing the position of the first token, the [CLS] token. A pooled output is represented by a word embedding vector of size 768, which represents the word embedding of the [CLS] token. This is usually done when classifying the entire sequence, not individual tokens. On top of this output a dense layer was added, with an input dimension of 768, and an output dimension equal to the number of emotion classes. For getting the probabilities LogSoftmax 9  activation function was used as it offers better numeric stability than Softmax. During training a dropout layer with a dropout rate of 30% is added to mitigate overfitting. An overview of this fine-tuning approach can be seen in Fig.  1 .",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "Bert And Svm Ensemble Model",
      "text": "Ensemble models have been historically used to produce state of the art results for various machine learning classification problems  [24] . Ensemble models offer better results as the advantages brought by each individual model are taken into account when producing an output. This usually works best when the composing models have different architectures, as this ensures that each model learns to look at different aspects of the training data  [24] .\n\nFor building the proposed ensemble model, we combine a BERTweet model, as this version seems to offer the best results, and a SVM model. Each model will use its specific preprocessing before making predictions.\n\nIn order to obtain the probabilities for each emotion class, the ensemble model computes the sum of the log probability vectors obtained from the two models. Because log probabilities have values in the interval (  , 0 - , when adding the two probability vectors bad results will get worse and good results will not be as affected, due to the fact that those are closer to 0.\n\nThe workflow of the ensemble model can be observed in Fig.  2 .",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Experimental Results",
      "text": "To gather insights upon our proposed model, first we check for the traditional machine learning model that has best performance on the dataset presented in Section 3. Afterwards we compare the three presented versions of BERT and finally we showcase the results of the ensemble model.\n\nAll models were trained using the same train-validation-test ratio of the data, which is: 1,200 samples for train, 150 for validation and 150 for testing, for each emotion.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Results For The Svm Model",
      "text": "From our results, the SVM classifier seems to offer best results for the task of emotion detection when compared to other machine learning classifiers such as Multinomial Naïve Bayes  [25]  and Gaussian Naïve Bayes  [26] , as seen in Table  1 . For training the Bayesian models, the same preprocessing technique was used as for the SVM model. For Multinomial Naïve Bayes an additive smoothing parameter of 1 was chosen, and for Gaussian Naïve Bayes a smoothing variable of 0.5. Those values were chosen empirically. Afterwards the models were fitted on the training set and tested. The results show that Multinomial Naïve Bayes is the better choice of the two models, with an accuracy of 0.80. During training the SVM model has been fitted on the training set after the preprocessing phase. On the validation set the model obtained an accuracy score of 0.87. In order to ensure that our model will perform well on previously unseen data, the model was tested on the test set. The accuracy score on the test set was 0.84, which shows that the model is reliable. In order to better understand how the model performs on detecting each emotion, a confusion matrix was computed on the test set, which can be seen in Fig.  3 .  The results show that the model performs worst when classifying the neutral emotion and best when detecting anger. This can be due to the fact that the neutral class has a different token distribution than all the other classes. This behaviour has been previously noted for Multinomial Naïve Bayes classifier as well.",
      "page_start": 7,
      "page_end": 8
    },
    {
      "section_name": "Results For The Proposed Bert Models",
      "text": "For training the proposed BERT models, a training time of 5 epochs and a batch size of 16 were used. The training time does not have to be long as the models will reach their maximum accuracy after relatively few epochs due to the fact that the models are pretrained.\n\nFor the vanilla BERT model, the tweets were padded during the preprocessing phase to a size of 85 tokens, which is the maximum size found in the presented dataset. For the validation set the model got an accuracy of 0.89, and for the testing set an accuracy of 0.87. This shows that a vanilla BERT model offers improved results compared to the SVM model.\n\nFor the RoBERTa model the tweets were padded during the preprocessing phase to a size of 170 tokens. This size increase is due to the fact that RoBERTa tokenizer will add extra spaces before emojis. The model got an accuracy of 0.87 for the testing and validation sets. This shows that a RoBERTa model does not bring any additional improvements when compared to the vanilla BERT model.\n\nFor the BERTweet model, the tweets were padded to a size of 90 tokens, which is the maximum size found in the presented dataset after the model applies its specific preprocessing. For the validation set the model got an accuracy of 0.89, and for the testing set an accuracy of 0.89. The confusion matrix on the test set can be seen in Fig.  4 . This shows that BERTweet performs slightly better than the vanilla version. Therefore, this BERT version was chosen for building the BERT-SVM ensemble model. A comparison between BERT versions on the presented dataset can be observed in Table  4 .",
      "page_start": 8,
      "page_end": 9
    },
    {
      "section_name": "Results For The Ensemble Model",
      "text": "For assessing the performance of the ensemble model, both the SVM and BERTweet models computed the log probability vectors for the validation set and the test set. Afterwards, the vectors of the two models were added in order to obtain the results of the ensemble model. The predicted emotion class for a tweet will be the one with the highest probability found in the corresponding probability vector. The ensemble model obtains an accuracy score of 0.91 for both validation and testing set. From the confusion matrix in Fig.  5 , we can conclude that the model performs well on all classes, the lowest accuracy score being 0.84 for the neutral emotion class.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Comparison Between Emotion Detection Models",
      "text": "As it can be seen in Table  6 , best results were obtained using the ensemble model. The model surpasses both SVM and BERT models with an accuracy of 0.91. This accuracy is high enough to consider the proposed model state-of-theart. However, the accuracy is slightly lower when compared to the accuracy of the same model trained on the initial dataset, without additional neutral tweets, which is 0.94. It is worth mentioning that the proposed model trained on the extended dataset is able to detect when tweets do not convey any emotion, which might prove useful in real life usage of the model.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Conclusions",
      "text": "From our results, we can conclude that using an ensemble model for the task of emotion detection offers the best results when compared to other approaches researched so far. When compared to [14], our results on the same dataset are slightly better, with an accuracy score of 0.94.\n\nThe highest F1-score was obtained for the anger class in the case of the SVM classifier and for the joy class, respectively, in the case of the BERTweet model. The SVM and BERTweet model seem to improve on each other's results when combined, which is an important discovery when considering the future development of other ensemble models.\n\nFor future research, the ensemble model can be improved by researching BERT versions with more parameters such as the large version, which might lead to better results.",
      "page_start": 10,
      "page_end": 10
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Fig. 1. The proposed BERT model",
      "page": 5
    },
    {
      "caption": "Figure 2: Fig. 2. Ensemble model workflow",
      "page": 6
    },
    {
      "caption": "Figure 3: Fig. 3. Confusion matrix for the SVM model on the test set",
      "page": 7
    },
    {
      "caption": "Figure 4: This shows that BERTweet performs slightly better than",
      "page": 8
    },
    {
      "caption": "Figure 4: Confusion matrix for the BERTweet model on the test set",
      "page": 8
    },
    {
      "caption": "Figure 5: , we can conclude that the",
      "page": 9
    },
    {
      "caption": "Figure 5: Confusion matrix for the BERTweet-SVM model on the test set",
      "page": 9
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Ionuţ-Alexandru ALBU1, Stelian SPÎNU2": "Automatic  identification  of  emotions  expressed  in  Twitter  data  has  a  wide"
        },
        {
          "Ionuţ-Alexandru ALBU1, Stelian SPÎNU2": "range of applications. We create a well-balanced dataset by adding a neutral class"
        },
        {
          "Ionuţ-Alexandru ALBU1, Stelian SPÎNU2": "to a benchmark dataset consisting of four emotions: fear, sadness, joy, and anger."
        },
        {
          "Ionuţ-Alexandru ALBU1, Stelian SPÎNU2": "On this extended dataset, we investigate the use of Support Vector Machine (SVM)"
        },
        {
          "Ionuţ-Alexandru ALBU1, Stelian SPÎNU2": "and Bidirectional Encoder Representations from Transformers (BERT) for emotion"
        },
        {
          "Ionuţ-Alexandru ALBU1, Stelian SPÎNU2": "recognition. We propose a novel ensemble model by  combining the two BERT and"
        },
        {
          "Ionuţ-Alexandru ALBU1, Stelian SPÎNU2": "SVM models. Experiments show that the proposed model achieves a state-of-the-art"
        },
        {
          "Ionuţ-Alexandru ALBU1, Stelian SPÎNU2": "accuracy of 0.91 on emotion recognition in tweets."
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Sentiment analysis, Twitter.": "1. Introduction"
        },
        {
          "Sentiment analysis, Twitter.": "Emotion detection is a subfield of sentiment analysis and is concerned with"
        },
        {
          "Sentiment analysis, Twitter.": "detecting the writer’s emotion from text data. The main difference between the two is"
        },
        {
          "Sentiment analysis, Twitter.": "that, whereas sentiment analysis tries to classify a text as being positive or negative,"
        },
        {
          "Sentiment analysis, Twitter.": "emotion detection tries to identify the exact emotion of the writer, such as happiness,"
        },
        {
          "Sentiment analysis, Twitter.": "sadness,  fear,  etc. Emotion analysis of tweets is  a  very  challenging task for natural"
        },
        {
          "Sentiment analysis, Twitter.": "language processing systems. Unlike traditional text, tweets are very short messages"
        },
        {
          "Sentiment analysis, Twitter.": "and  contain  spelling  mistakes,  slang,  shortened  forms,  phrasal  abbreviations,  and"
        },
        {
          "Sentiment analysis, Twitter.": "expressive lengthening [1]. Automatic identification of emotions expressed in Twitter"
        },
        {
          "Sentiment analysis, Twitter.": "data  has  a  wide  range  of  applications  such  as  understanding  consumer  views"
        },
        {
          "Sentiment analysis, Twitter.": "regarding a product [2], stock market prediction [3], detection of depressive disorders"
        },
        {
          "Sentiment analysis, Twitter.": "[4], detecting bullying outbreaks [5], and identifying terrorist threats [6]."
        },
        {
          "Sentiment analysis, Twitter.": "The contribution of this paper can be summarized as follows. We present"
        },
        {
          "Sentiment analysis, Twitter.": "an improved version of the WASSA dataset [7] for the task of emotion detection,"
        },
        {
          "Sentiment analysis, Twitter.": "that  has  been  obtained  through  balancing  and  the  addition  of  a  new  class,  the"
        },
        {
          "Sentiment analysis, Twitter.": "neutral  class.  Our  experimental  results3  show  that  SVM  offers  the  best  results"
        },
        {
          "Sentiment analysis, Twitter.": "when compared to other Machine Learning classifiers. Further, we fine-tune three"
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "64                                            Ionuţ-Alexandru Albu, Stelian Spînu": "BERT  versions  and  present"
        },
        {
          "64                                            Ionuţ-Alexandru Albu, Stelian Spînu": "introduce a novel ensemble model which combines BERT and SVM models and"
        },
        {
          "64                                            Ionuţ-Alexandru Albu, Stelian Spînu": "achieves state-of-the-art results."
        },
        {
          "64                                            Ionuţ-Alexandru Albu, Stelian Spînu": "2. Related Work"
        },
        {
          "64                                            Ionuţ-Alexandru Albu, Stelian Spînu": ""
        },
        {
          "64                                            Ionuţ-Alexandru Albu, Stelian Spînu": "million  tweets,  by  leveraging  the  emotion  hashtags.  They  applied  two  different"
        },
        {
          "64                                            Ionuţ-Alexandru Albu, Stelian Spînu": "classifiers,  logistic  regression  and  Naïve  Bayes,  to  explore  the  effectiveness  of"
        },
        {
          "64                                            Ionuţ-Alexandru Albu, Stelian Spînu": "various \nfeatures \nsuch \nas"
        },
        {
          "64                                            Ionuţ-Alexandru Albu, Stelian Spînu": "information on the emotion identification task. The highest accuracy achieved was"
        },
        {
          "64                                            Ionuţ-Alexandru Albu, Stelian Spînu": "0.6557."
        },
        {
          "64                                            Ionuţ-Alexandru Albu, Stelian Spînu": ""
        },
        {
          "64                                            Ionuţ-Alexandru Albu, Stelian Spînu": "labelled tweets using hashtags. He employed binary SVMs, one for each of the six"
        },
        {
          "64                                            Ionuţ-Alexandru Albu, Stelian Spînu": "basic emotions of Ekman [10], and used the presence or absence of unigrams and"
        },
        {
          "64                                            Ionuţ-Alexandru Albu, Stelian Spînu": "bigrams  as  binary"
        },
        {
          "64                                            Ionuţ-Alexandru Albu, Stelian Spînu": "emotions with a balanced F1-score of 0.499."
        },
        {
          "64                                            Ionuţ-Alexandru Albu, Stelian Spînu": ""
        },
        {
          "64                                            Ionuţ-Alexandru Albu, Stelian Spînu": "strong  labels  on  emotion  recognition  for  a  corpus  consisting  of  341,931  tweets."
        },
        {
          "64                                            Ionuţ-Alexandru Albu, Stelian Spînu": "The  weak  labels  were  created  by  employing  the  hashtags  of  the  tweets  and  the"
        },
        {
          "64                                            Ionuţ-Alexandru Albu, Stelian Spînu": "strong labels by the use of crowdsourcing. The features extracted by combining n-"
        },
        {
          "64                                            Ionuţ-Alexandru Albu, Stelian Spînu": "grams and TF-IDF (Term Frequency-Inverse Document Frequency) were applied"
        },
        {
          "64                                            Ionuţ-Alexandru Albu, Stelian Spînu": "to five classification algorithms: Stochastic Gradient Descent, SVM, Naïve Bayes,"
        },
        {
          "64                                            Ionuţ-Alexandru Albu, Stelian Spînu": "Nearest  Centroid,  and  Ridge.  The  results  showed  only  a  9.25%  decrease  in  F1-"
        },
        {
          "64                                            Ionuţ-Alexandru Albu, Stelian Spînu": "score when using weak labels."
        },
        {
          "64                                            Ionuţ-Alexandru Albu, Stelian Spînu": ""
        },
        {
          "64                                            Ionuţ-Alexandru Albu, Stelian Spînu": "construct  a  large  dataset  of  about  1.6  million  labelled  tweets  and  then  trained"
        },
        {
          "64                                            Ionuţ-Alexandru Albu, Stelian Spînu": "Gated  Recurrent  Neural  Networks"
        },
        {
          "64                                            Ionuţ-Alexandru Albu, Stelian Spînu": "achieved an average accuracy of 0.8758 on 24 fine-grained types of emotions."
        },
        {
          "64                                            Ionuţ-Alexandru Albu, Stelian Spînu": ""
        },
        {
          "64                                            Ionuţ-Alexandru Albu, Stelian Spînu": "model for emoji prediction on a dataset consisting of 1.6 billion tweets. Then they"
        },
        {
          "64                                            Ionuţ-Alexandru Albu, Stelian Spînu": "fine-tuned  the  pretrained  model  for  emotion,  sentiment,  and  sarcasm  detection."
        },
        {
          "64                                            Ionuţ-Alexandru Albu, Stelian Spînu": "Using their pretrained DeepMoji model, the highest averaged F1-score obtained in"
        },
        {
          "64                                            Ionuţ-Alexandru Albu, Stelian Spînu": "emotion analysis was 0.61."
        },
        {
          "64                                            Ionuţ-Alexandru Albu, Stelian Spînu": "Chiorrini \net \nal. \n[14]"
        },
        {
          "64                                            Ionuţ-Alexandru Albu, Stelian Spînu": "Representations from Transformers (BERT) [15] for both sentiment analysis and"
        },
        {
          "64                                            Ionuţ-Alexandru Albu, Stelian Spînu": "emotion  recognition  of  Twitter  data.  They  achieved  an  accuracy  of  0.90  on"
        },
        {
          "64                                            Ionuţ-Alexandru Albu, Stelian Spînu": "emotion recognition task."
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "3. Proposed Method": "3.1 Dataset"
        },
        {
          "3. Proposed Method": ""
        },
        {
          "3. Proposed Method": "partly extracted from the WASSA dataset, which was offered to the participants in"
        },
        {
          "3. Proposed Method": "the  Workshop  on  Computational  Approaches"
        },
        {
          "3. Proposed Method": "Social Media Analysis (WASSA-2017) [7]. We extracted 1,500 tweets for each of"
        },
        {
          "3. Proposed Method": "the four emotions: fear, sadness, joy and anger, without taking into account data"
        },
        {
          "3. Proposed Method": "containing emotion intensities. Next to these four classes, we added an extra class"
        },
        {
          "3. Proposed Method": "of 1,500 neutral tweets, as it has been shown in [16] that having a neutral class in"
        },
        {
          "3. Proposed Method": "the classification process is important, because in this way the neural network will"
        },
        {
          "3. Proposed Method": "not have to classify unknown emotions into one of the learnt classes of emotions."
        },
        {
          "3. Proposed Method": "Neutral tweets were extracted from CrowdFlower4."
        },
        {
          "3. Proposed Method": ""
        },
        {
          "3. Proposed Method": "having a well-balanced dataset. A well-balanced dataset contains an equal number"
        },
        {
          "3. Proposed Method": "of  samples  per  class  [17].  This  ensures  that  the  model  will  not  favour  larger"
        },
        {
          "3. Proposed Method": "classes in the classification process."
        }
      ],
      "page": 3
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "66                                            Ionuţ-Alexandru Albu, Stelian Spînu": "reducing derived words to a grammatical root called stem. In this article we used"
        },
        {
          "66                                            Ionuţ-Alexandru Albu, Stelian Spînu": "nltk’s Snowball stemmer7."
        },
        {
          "66                                            Ionuţ-Alexandru Albu, Stelian Spînu": ""
        },
        {
          "66                                            Ionuţ-Alexandru Albu, Stelian Spînu": "alongside  term-frequency  times  inverse  document-frequency  (tf-idf).  Tf-idf  [20]"
        },
        {
          "66                                            Ionuţ-Alexandru Albu, Stelian Spînu": "tries \nto  estimate"
        },
        {
          "66                                            Ionuţ-Alexandru Albu, Stelian Spînu": "statistics:  the  term  frequency,  which  means  the  appearance  of  a  specific  term  in"
        },
        {
          "66                                            Ionuţ-Alexandru Albu, Stelian Spînu": "the \ntweet,  and"
        },
        {
          "66                                            Ionuţ-Alexandru Albu, Stelian Spînu": "information that specific term provides relative to all the tweets in the corpus. The"
        },
        {
          "66                                            Ionuţ-Alexandru Albu, Stelian Spînu": "final result of the tf-idf is multiplication between the two frequencies."
        },
        {
          "66                                            Ionuţ-Alexandru Albu, Stelian Spînu": ""
        },
        {
          "66                                            Ionuţ-Alexandru Albu, Stelian Spînu": "preprocessed. Label encoding was achieved by using a numeric label encoder8 for"
        },
        {
          "66                                            Ionuţ-Alexandru Albu, Stelian Spînu": "assigning to each emotion class a unique number."
        },
        {
          "66                                            Ionuţ-Alexandru Albu, Stelian Spînu": ""
        },
        {
          "66                                            Ionuţ-Alexandru Albu, Stelian Spînu": "chosen. The decision is based on the fact that its nonlinearity maps the data into a"
        },
        {
          "66                                            Ionuţ-Alexandru Albu, Stelian Spînu": "higher  dimension"
        },
        {
          "66                                            Ionuţ-Alexandru Albu, Stelian Spînu": "hyperparameters"
        },
        {
          "66                                            Ionuţ-Alexandru Albu, Stelian Spînu": "regularization factor (C) was set empirically to 1."
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Emotion detection from tweets using a BERT and SVM ensemble model              67": ""
        },
        {
          "Emotion detection from tweets using a BERT and SVM ensemble model              67": ""
        },
        {
          "Emotion detection from tweets using a BERT and SVM ensemble model              67": ""
        },
        {
          "Emotion detection from tweets using a BERT and SVM ensemble model              67": ""
        },
        {
          "Emotion detection from tweets using a BERT and SVM ensemble model              67": ""
        },
        {
          "Emotion detection from tweets using a BERT and SVM ensemble model              67": "to"
        },
        {
          "Emotion detection from tweets using a BERT and SVM ensemble model              67": ""
        },
        {
          "Emotion detection from tweets using a BERT and SVM ensemble model              67": ""
        },
        {
          "Emotion detection from tweets using a BERT and SVM ensemble model              67": ""
        },
        {
          "Emotion detection from tweets using a BERT and SVM ensemble model              67": ""
        }
      ],
      "page": 5
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "68                                            Ionuţ-Alexandru Albu, Stelian Spînu": "models offer better results as the advantages brought by each individual model are"
        },
        {
          "68                                            Ionuţ-Alexandru Albu, Stelian Spînu": "taken into  account  when producing an output. This  usually works best  when  the"
        },
        {
          "68                                            Ionuţ-Alexandru Albu, Stelian Spînu": "composing  models  have  different  architectures,  as  this  ensures  that  each  model"
        },
        {
          "68                                            Ionuţ-Alexandru Albu, Stelian Spînu": "learns to look at different aspects of the training data [24]."
        },
        {
          "68                                            Ionuţ-Alexandru Albu, Stelian Spînu": ""
        },
        {
          "68                                            Ionuţ-Alexandru Albu, Stelian Spînu": "model,  as  this  version  seems  to  offer  the  best  results,  and  a  SVM  model.  Each"
        },
        {
          "68                                            Ionuţ-Alexandru Albu, Stelian Spînu": "model will use its specific preprocessing before making predictions."
        },
        {
          "68                                            Ionuţ-Alexandru Albu, Stelian Spînu": ""
        },
        {
          "68                                            Ionuţ-Alexandru Albu, Stelian Spînu": "model  computes  the  sum  of  the  log  probability  vectors  obtained  from  the  two"
        },
        {
          "68                                            Ionuţ-Alexandru Albu, Stelian Spînu": "models.  Because"
        },
        {
          "68                                            Ionuţ-Alexandru Albu, Stelian Spînu": "adding the two probability vectors bad results will get worse and good results will not"
        },
        {
          "68                                            Ionuţ-Alexandru Albu, Stelian Spînu": "be as affected, due to the fact that those are closer to 0."
        }
      ],
      "page": 6
    },
    {
      "caption": "Table 1: Comparison between machine learning classifiers",
      "data": [
        {
          "Multinomial Naïve Bayes": "Gaussian Naïve Bayes",
          "0.80": "0.73"
        },
        {
          "Multinomial Naïve Bayes": "SVM",
          "0.80": "0.84"
        },
        {
          "Multinomial Naïve Bayes": "or  training  the  Bayesian  models,  the  same  preprocessing  technique  was",
          "0.80": ""
        },
        {
          "Multinomial Naïve Bayes": "",
          "0.80": ""
        },
        {
          "Multinomial Naïve Bayes": "",
          "0.80": ""
        },
        {
          "Multinomial Naïve Bayes": "",
          "0.80": ""
        },
        {
          "Multinomial Naïve Bayes": "",
          "0.80": ""
        },
        {
          "Multinomial Naïve Bayes": "",
          "0.80": ""
        },
        {
          "Multinomial Naïve Bayes": "",
          "0.80": ""
        },
        {
          "Multinomial Naïve Bayes": "",
          "0.80": ""
        },
        {
          "Multinomial Naïve Bayes": "",
          "0.80": ""
        },
        {
          "Multinomial Naïve Bayes": "",
          "0.80": ""
        },
        {
          "Multinomial Naïve Bayes": "",
          "0.80": ""
        },
        {
          "Multinomial Naïve Bayes": "",
          "0.80": ""
        },
        {
          "Multinomial Naïve Bayes": "",
          "0.80": ""
        }
      ],
      "page": 7
    },
    {
      "caption": "Table 4: Fig. 4. Confusion matrix for the BERTweet model on the test set",
      "data": [
        {
          "70                                            Ionuţ-Alexandru Albu, Stelian Spînu": ""
        },
        {
          "70                                            Ionuţ-Alexandru Albu, Stelian Spînu": "neutral emotion and best when detecting anger. This can be due to the fact that the"
        },
        {
          "70                                            Ionuţ-Alexandru Albu, Stelian Spînu": "neutral  class  has  a  different  token  distribution  than  all  the  other  classes.  This"
        },
        {
          "70                                            Ionuţ-Alexandru Albu, Stelian Spînu": "behaviour  has  been  previously  noted  for  Multinomial  Naïve  Bayes  classifier  as"
        },
        {
          "70                                            Ionuţ-Alexandru Albu, Stelian Spînu": "well."
        },
        {
          "70                                            Ionuţ-Alexandru Albu, Stelian Spînu": ""
        },
        {
          "70                                            Ionuţ-Alexandru Albu, Stelian Spînu": ""
        },
        {
          "70                                            Ionuţ-Alexandru Albu, Stelian Spînu": "batch  size  of  16  were  used.  The  training  time  does  not  have  to  be  long  as  the"
        },
        {
          "70                                            Ionuţ-Alexandru Albu, Stelian Spînu": "models will reach their maximum accuracy after relatively few epochs due to the"
        },
        {
          "70                                            Ionuţ-Alexandru Albu, Stelian Spînu": "fact that the models are pretrained."
        },
        {
          "70                                            Ionuţ-Alexandru Albu, Stelian Spînu": ""
        },
        {
          "70                                            Ionuţ-Alexandru Albu, Stelian Spînu": "preprocessing phase to a size of 85 tokens, which is the maximum size found in"
        },
        {
          "70                                            Ionuţ-Alexandru Albu, Stelian Spînu": "the  presented  dataset.  For  the  validation  set  the  model  got  an  accuracy  of  0.89,"
        },
        {
          "70                                            Ionuţ-Alexandru Albu, Stelian Spînu": "and for the testing set an accuracy of 0.87. This shows that a vanilla BERT model"
        },
        {
          "70                                            Ionuţ-Alexandru Albu, Stelian Spînu": "offers improved results compared to the SVM model."
        },
        {
          "70                                            Ionuţ-Alexandru Albu, Stelian Spînu": ""
        },
        {
          "70                                            Ionuţ-Alexandru Albu, Stelian Spînu": "phase to a size of 170 tokens. This size increase is due to the fact that RoBERTa"
        },
        {
          "70                                            Ionuţ-Alexandru Albu, Stelian Spînu": "tokenizer will add extra spaces before emojis. The model got an accuracy of 0.87"
        },
        {
          "70                                            Ionuţ-Alexandru Albu, Stelian Spînu": "for  the  testing  and  validation  sets.  This  shows  that  a  RoBERTa  model  does  not"
        },
        {
          "70                                            Ionuţ-Alexandru Albu, Stelian Spînu": "bring any additional improvements when compared to the vanilla BERT model."
        },
        {
          "70                                            Ionuţ-Alexandru Albu, Stelian Spînu": ""
        },
        {
          "70                                            Ionuţ-Alexandru Albu, Stelian Spînu": "which is the maximum size found in the presented dataset after the model applies"
        },
        {
          "70                                            Ionuţ-Alexandru Albu, Stelian Spînu": "its  specific  preprocessing.  For  the  validation  set  the  model  got  an  accuracy  of"
        },
        {
          "70                                            Ionuţ-Alexandru Albu, Stelian Spînu": "0.89, and for the testing set an accuracy of 0.89. The confusion matrix on the test"
        },
        {
          "70                                            Ionuţ-Alexandru Albu, Stelian Spînu": "set can be seen in Fig. 4. This shows that BERTweet performs slightly better than"
        },
        {
          "70                                            Ionuţ-Alexandru Albu, Stelian Spînu": "the  vanilla  version.  Therefore,  this  BERT  version  was  chosen  for  building  the"
        },
        {
          "70                                            Ionuţ-Alexandru Albu, Stelian Spînu": "BERT-SVM  ensemble  model.  A  comparison  between  BERT  versions  on  the"
        },
        {
          "70                                            Ionuţ-Alexandru Albu, Stelian Spînu": "presented dataset can be observed in Table 4."
        },
        {
          "70                                            Ionuţ-Alexandru Albu, Stelian Spînu": ""
        }
      ],
      "page": 8
    },
    {
      "caption": "Table 3: Precision, recall, and F1-score for the BERTweet model on the test set",
      "data": [
        {
          "4\n.3 Results for the Ensemble Model": "For assessing the performance of the ensemble model, both the SVM and"
        },
        {
          "4\n.3 Results for the Ensemble Model": "BERTweet models computed the log probability vectors for the validation set and"
        },
        {
          "4\n.3 Results for the Ensemble Model": "the  test  set.  Afterwards,  the  vectors  of  the  two  models  were  added  in  order  to"
        },
        {
          "4\n.3 Results for the Ensemble Model": "obtain the results of the ensemble model. The predicted emotion class for a tweet"
        },
        {
          "4\n.3 Results for the Ensemble Model": "will be the one with the highest probability found in the corresponding probability"
        },
        {
          "4\n.3 Results for the Ensemble Model": "vector. The ensemble model obtains an accuracy score of 0.91 for both validation"
        },
        {
          "4\n.3 Results for the Ensemble Model": "and  testing  set.  From  the  confusion  matrix  in  Fig.  5,  we  can  conclude  that  the"
        },
        {
          "4\n.3 Results for the Ensemble Model": "model performs well on all classes, the lowest accuracy score being 0.84 for the"
        },
        {
          "4\n.3 Results for the Ensemble Model": "neutral emotion class."
        }
      ],
      "page": 9
    },
    {
      "caption": "Table 5: Precision, recall, and F1-score for the BERTweet-SVM model on the test set",
      "data": [
        {
          "Recall": "F1-score",
          "0.93 \n0.93": "0.92 \n0.92",
          "0.89 \n0.95": "0.89 \n0.94",
          "0.84": "0.86"
        },
        {
          "Recall": "",
          "0.93 \n0.93": "",
          "0.89 \n0.95": "",
          "0.84": "Table 6"
        },
        {
          "Recall": "",
          "0.93 \n0.93": "Comparison between selected emotion detection models",
          "0.89 \n0.95": "",
          "0.84": ""
        },
        {
          "Recall": "",
          "0.93 \n0.93": "Model",
          "0.89 \n0.95": "Accuracy",
          "0.84": ""
        },
        {
          "Recall": "",
          "0.93 \n0.93": "SVM",
          "0.89 \n0.95": "0.84",
          "0.84": ""
        },
        {
          "Recall": "",
          "0.93 \n0.93": "BERTweet",
          "0.89 \n0.95": "0.89",
          "0.84": ""
        },
        {
          "Recall": "",
          "0.93 \n0.93": "Proposed ensemble model",
          "0.89 \n0.95": "0.91",
          "0.84": ""
        },
        {
          "Recall": "",
          "0.93 \n0.93": "",
          "0.89 \n0.95": "",
          "0.84": "Table 7"
        },
        {
          "Recall": "",
          "0.93 \n0.93": "Results obtained for the data set without a neutral class",
          "0.89 \n0.95": "",
          "0.84": ""
        },
        {
          "Recall": "",
          "0.93 \n0.93": "Model",
          "0.89 \n0.95": "Accuracy",
          "0.84": ""
        },
        {
          "Recall": "",
          "0.93 \n0.93": "SVM",
          "0.89 \n0.95": "0.91",
          "0.84": ""
        },
        {
          "Recall": "",
          "0.93 \n0.93": "BERTweet",
          "0.89 \n0.95": "0.90",
          "0.84": ""
        },
        {
          "Recall": "",
          "0.93 \n0.93": "Proposed ensemble model",
          "0.89 \n0.95": "0.94",
          "0.84": ""
        }
      ],
      "page": 10
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "R E F E R E N C E S": "[1].  J.  Eisenstein,  What  to  Do  About  Bad  Language  on  The  Internet,  In  Proc.  of  the  2013"
        },
        {
          "R E F E R E N C E S": "Conference  of \nthe  North  American  Chapter  of \nthe  Association \nfor  Computational"
        },
        {
          "R E F E R E N C E S": "Linguistics: Human Language Technologies, Atlanta, Georgia, 2013, pp. 359-369."
        },
        {
          "R E F E R E N C E S": "[2].  B.  J.  Jansen,  M.  Zhang,  K.  Sobel,  and  A.  Chowdury,  Twitter  Power:  Tweets  as  Electronic"
        },
        {
          "R E F E R E N C E S": "Word of Mouth, Journal of the American Society for Information Science and Technology,"
        },
        {
          "R E F E R E N C E S": "vol. 60, no. 11, pp. 2169-2188, Nov. 2009. doi:10.1002/asi.21149"
        },
        {
          "R E F E R E N C E S": "[3].  J.  Bollen,  H.  Mao,  and  X.  Zeng,  Twitter  Mood  Predicts \nthe  Stock  Market,  Journal  of"
        },
        {
          "R E F E R E N C E S": "Computational Science, vol. 2, no. 1, pp. 1-8, Mar. 2011. doi:10.1016/j.jocs.2010.12.007"
        },
        {
          "R E F E R E N C E S": "[4]. M. Park, C. Cha, and M. Cha, Depressive Moods of Users Portrayed in Twitter, In Proc. of"
        },
        {
          "R E F E R E N C E S": "the ACM SIGKDD Workshop on Healthcare Informatics (HI-KDD), 2012, pp. 1-8."
        },
        {
          "R E F E R E N C E S": "[5]. J.-M. Xu, K.-S. Jun, X. Zhu, and A. Bellmore, Learning from Bullying Traces in Social Media,"
        },
        {
          "R E F E R E N C E S": "In  Proc.  of  the  2012  Conference  of  the  North  American  Chapter  of  the  Association  for"
        },
        {
          "R E F E R E N C E S": "Computational Linguistics: Human Language Technologies, 2012, pp. 656-666."
        },
        {
          "R E F E R E N C E S": "[6].  M.  Cheong  and  V.  C.  S.  Lee,  A  Microblogging-Based  Approach  to  Terrorism  Informatics:"
        },
        {
          "R E F E R E N C E S": "Exploration  and  Chronicling  Civilian  Sentiment  and  Response  to  Terrorism  Events  via"
        },
        {
          "R E F E R E N C E S": "Twitter, Information Systems Frontiers, vol. 13, no. 1 pp. 45-59, Mar. 2011."
        },
        {
          "R E F E R E N C E S": "[7]. S. M. Mohammad and F. Bravo-Marquez, WASSA-2017 Shared Task on Emotion Intensity,"
        },
        {
          "R E F E R E N C E S": "In Proc. of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and"
        },
        {
          "R E F E R E N C E S": "Social Media Analysis, Copenhagen, Denmark, 2017, pp. 34-49."
        },
        {
          "R E F E R E N C E S": "[8]. W. Wang, L. Chen, K. Thirunarayan, and A. P. Sheth, Harnessing Twitter ‘Big Data’ for Automatic"
        },
        {
          "R E F E R E N C E S": "Emotion Identification, In Proc. of the 2012 International Conference on Privacy, Security, Risk"
        },
        {
          "R E F E R E N C E S": "and Trust and 2012 International Conference on Social Computing, 2012, pp. 587-592."
        },
        {
          "R E F E R E N C E S": "[9]. S. M. Mohammad, #Emotional Tweets, In Proc. of the First Joint Conference on Lexical and"
        },
        {
          "R E F E R E N C E S": "Computational Semantics - Volume 1: Proceedings of the Main Conference and the Shared"
        },
        {
          "R E F E R E N C E S": "Task,  and  Volume  2:  Proceedings  of \nthe  Sixth  International  Workshop  on  Semantic"
        },
        {
          "R E F E R E N C E S": "Evaluation, 2012, pp. 246-255."
        },
        {
          "R E F E R E N C E S": "[10].  P.  Ekman,  An  Argument  for  Basic  Emotions,  Cognition  and  Emotion,  vol.  6,  no.  3-4,  pp."
        },
        {
          "R E F E R E N C E S": "169-200, May 1992. doi:10.1080/02699939208411068"
        },
        {
          "R E F E R E N C E S": "[11].  O.  Janssens,  S.  Verstockt,  E.  Mannens,  S.  Van  Hoecke,  and  R.  Van  de  Walle, Influence  of"
        },
        {
          "R E F E R E N C E S": "Weak  Labels \nfor  Emotion  Recognition \nof  Tweets, \nIn \nPrasath  R.,  O’Reilly \nP.,"
        },
        {
          "R E F E R E N C E S": "Kathirvalavakumar  T.  (Eds.),  Mining  Intelligence  and  Knowledge  Exploration,  Springer,"
        },
        {
          "R E F E R E N C E S": "2014, pp. 108-118. doi:10.1007/978-3-319-13817-6_12"
        },
        {
          "R E F E R E N C E S": "[12].  M.  Abdul-Mageed  and  L.  Ungar,  EmoNet:  Fine-Grained  Emotion  Detection  with  Gated"
        },
        {
          "R E F E R E N C E S": "Recurrent  Neural  Networks,  In  Proc.  of  the  55th  Annual  Meeting  of  the  Association  for"
        },
        {
          "R E F E R E N C E S": "Computational Linguistics (Volume 1: Long Papers), 2017, pp. 718-728."
        },
        {
          "R E F E R E N C E S": "[13].  B.  Felbo,  A.  Mislove,  A.  Søgaard,  I.  Rahwan,  and  S.  Lehmann,  Using  Millions  of  Emoji"
        },
        {
          "R E F E R E N C E S": "Occurrences to Learn Any-Domain Representations for Detecting Sentiment, Emotion and"
        },
        {
          "R E F E R E N C E S": "Sarcasm,  In  Proc.  of  the  2017  Conference  on  Empirical  Methods  in  Natural  Language"
        },
        {
          "R E F E R E N C E S": "Processing, 2017, pp. 1615-1625. doi:10.18653/v1/D17-1169"
        },
        {
          "R E F E R E N C E S": "[14].  A.  Chiorrini,  C.  Diamantini,  A.  Mircoli,  and  D.  Potena,  Emotion  and  Sentiment  Analysis  of"
        },
        {
          "R E F E R E N C E S": "Tweets Using BERT, In Proc. of the Workshops of the EDBT/ICDT Joint Conference, 2021."
        },
        {
          "R E F E R E N C E S": "[15].  J.  Devlin,  M.-W.  Chang,  K.  Lee,  and  K.  Toutanova,  BERT:  Pre-training  of  Deep"
        },
        {
          "R E F E R E N C E S": "Bidirectional  Transformers  for  Language  Understanding, In  Proc.  of  the  2019  Conference"
        },
        {
          "R E F E R E N C E S": "of  the  North  American  Chapter  of  the  Association  for  Computational  Linguistics:  Human"
        },
        {
          "R E F E R E N C E S": "Language Technologies, Volume 1 (Long and Short Papers), 2019, pp. 4171-4186."
        },
        {
          "R E F E R E N C E S": "[16].  M.  Koppel  and  J.  Schler,  The  Importance  of  Neutral  Examples  for  Learning  Sentiment,"
        },
        {
          "R E F E R E N C E S": "Computational Intelligence, vol. 22, no. 2, pp. 100-109, May 2006."
        }
      ],
      "page": 11
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "74                                            Ionuţ-Alexandru Albu, Stelian Spînu": "[17]. T. Borovicka, M. Jirina Jr., P. Kordik, and M. Jirina, Selecting Representative Data Sets, In"
        },
        {
          "74                                            Ionuţ-Alexandru Albu, Stelian Spînu": "Karahoca  A.  (Ed.),  Advances  in  Data  Mining  Knowledge  Discovery  and  Applications,"
        },
        {
          "74                                            Ionuţ-Alexandru Albu, Stelian Spînu": "IntechOpen, 2012, pp. 43-70. doi:10.5772/50787"
        },
        {
          "74                                            Ionuţ-Alexandru Albu, Stelian Spînu": "[18]. W. Wolny, Emotion Analysis of Twitter Data That Use Emoticons and Emoji Ideograms, In"
        },
        {
          "74                                            Ionuţ-Alexandru Albu, Stelian Spînu": "Gołuchowski  J.,  Pańkowska  M.,  Barry  C.,  Lang  M.,  Linger  H.,  and  Schneider  C.  (Eds.),"
        },
        {
          "74                                            Ionuţ-Alexandru Albu, Stelian Spînu": "Information  Systems  Development:  Complexity \nin \nInformation  Systems  Development"
        },
        {
          "74                                            Ionuţ-Alexandru Albu, Stelian Spînu": "(ISD2016 Proceedings), Katowice, Poland, 2016, pp. 476-483."
        },
        {
          "74                                            Ionuţ-Alexandru Albu, Stelian Spînu": "[19]. H. Saif, M. Fernandez, Y. He, and H. Alani, On Stopwords, Filtering and Data Sparsity  for"
        },
        {
          "74                                            Ionuţ-Alexandru Albu, Stelian Spînu": "Sentiment Analysis of Twitter, In Proc. of the Ninth International Conference on Language"
        },
        {
          "74                                            Ionuţ-Alexandru Albu, Stelian Spînu": "Resources and Evaluation (LREC’14), Reykjavik, Iceland, 2014, pp. 810-817."
        },
        {
          "74                                            Ionuţ-Alexandru Albu, Stelian Spînu": "[20].  C.  Sammut  and  G.  I.  Webb  (Eds.),  Encyclopedia  of  Machine  Learning.  Boston,  MA:"
        },
        {
          "74                                            Ionuţ-Alexandru Albu, Stelian Spînu": "Springer, 2010. doi:10.1007/978-0-387-30164-8"
        },
        {
          "74                                            Ionuţ-Alexandru Albu, Stelian Spînu": "[21]. Z. Liu, M. J. Zuo, X. Zhao, and H. Xu, An Analytical Approach to Fast Parameter Selection"
        },
        {
          "74                                            Ionuţ-Alexandru Albu, Stelian Spînu": "of Gaussian RBF Kernel for Support Vector Machine, Journal of Information Science and"
        },
        {
          "74                                            Ionuţ-Alexandru Albu, Stelian Spînu": "Engineering, vol. 31, no. 2, pp. 691-710, 2015."
        },
        {
          "74                                            Ionuţ-Alexandru Albu, Stelian Spînu": "[22]. Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis, L. Zettlemoyer, and V."
        },
        {
          "74                                            Ionuţ-Alexandru Albu, Stelian Spînu": "Stoyanov, \nRoBERTa: \nA \nRobustly \nOptimized \nBERT \nPretraining \nApproach,"
        },
        {
          "74                                            Ionuţ-Alexandru Albu, Stelian Spînu": "arXiv:1907.11692v1, 2019."
        },
        {
          "74                                            Ionuţ-Alexandru Albu, Stelian Spînu": "[23].  D.  Q.  Nguyen,  T.  Vu,  and  A.  T.  Nguyen,  BERTweet:  A  Pre-Trained  Language  Model  for"
        },
        {
          "74                                            Ionuţ-Alexandru Albu, Stelian Spînu": "English  Tweets, \nIn  Proc.  of \nthe  2020  Conference  on  Empirical  Methods \nin  Natural"
        },
        {
          "74                                            Ionuţ-Alexandru Albu, Stelian Spînu": "Language Processing: System Demonstrations, Nov. 2020, pp. 9-14."
        },
        {
          "74                                            Ionuţ-Alexandru Albu, Stelian Spînu": "[24]. F. Chollet, Deep Learning with Python. Shelter Island, NY: Manning Publications, 2017."
        },
        {
          "74                                            Ionuţ-Alexandru Albu, Stelian Spînu": "[25].  A.  Mccallum  and  K.  Nigam,  A  Comparison  of  Event  Models  for  Naive  Bayes  Text"
        },
        {
          "74                                            Ionuţ-Alexandru Albu, Stelian Spînu": "Classification,  In  Proc.  of  the  AAAI-98  Workshop  on  Learning  for  Text  categorization,"
        },
        {
          "74                                            Ionuţ-Alexandru Albu, Stelian Spînu": "1998, pp. 41-48."
        },
        {
          "74                                            Ionuţ-Alexandru Albu, Stelian Spînu": "[26]. I. H. Witten, E. Frank, M. A. Hall, and C. J. Pal, Data Mining: Practical Machine Learning"
        },
        {
          "74                                            Ionuţ-Alexandru Albu, Stelian Spînu": "Tools \nand  Techniques, \n4th  Edition.  Cambridge,  MA:  Morgan  Kaufmann, \n2017."
        },
        {
          "74                                            Ionuţ-Alexandru Albu, Stelian Spînu": "doi:10.1016/C2015-0-02071-8"
        }
      ],
      "page": 12
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "What to Do About Bad Language on The Internet",
      "authors": [
        "J Eisenstein"
      ],
      "year": "2013",
      "venue": "Proc. of the 2013 Conference of the North American Chapter"
    },
    {
      "citation_id": "2",
      "title": "Tweets as Electronic Word of Mouth",
      "authors": [
        "B Jansen",
        "M Zhang",
        "K Sobel",
        "A Chowdury",
        "Twitter Power"
      ],
      "year": "2009",
      "venue": "Journal of the American Society for Information Science and Technology",
      "doi": "10.1002/asi.21149"
    },
    {
      "citation_id": "3",
      "title": "Twitter Mood Predicts the Stock Market",
      "authors": [
        "J Bollen",
        "H Mao",
        "X Zeng"
      ],
      "year": "2011",
      "venue": "Journal of Computational Science",
      "doi": "10.1016/j.jocs.2010.12.007"
    },
    {
      "citation_id": "4",
      "title": "Depressive Moods of Users Portrayed in Twitter",
      "authors": [
        "M Park",
        "C Cha",
        "M Cha"
      ],
      "year": "2012",
      "venue": "Proc. of the ACM SIGKDD Workshop on Healthcare Informatics (HI-KDD"
    },
    {
      "citation_id": "5",
      "title": "Learning from Bullying Traces in Social Media",
      "authors": [
        "J.-M Xu",
        "K.-S Jun",
        "X Zhu",
        "A Bellmore"
      ],
      "year": "2012",
      "venue": "Proc. of the 2012 Conference of the North American Chapter"
    },
    {
      "citation_id": "6",
      "title": "A Microblogging-Based Approach to Terrorism Informatics: Exploration and Chronicling Civilian Sentiment and Response to Terrorism Events via Twitter",
      "authors": [
        "M Cheong",
        "V Lee"
      ],
      "year": "2011",
      "venue": "Information Systems Frontiers"
    },
    {
      "citation_id": "7",
      "title": "WASSA-2017 Shared Task on Emotion Intensity",
      "authors": [
        "S Mohammad",
        "F Bravo-Marquez"
      ],
      "year": "2017",
      "venue": "Proc. of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis"
    },
    {
      "citation_id": "8",
      "title": "Harnessing Twitter 'Big Data' for Automatic Emotion Identification",
      "authors": [
        "W Wang",
        "L Chen",
        "K Thirunarayan",
        "A Sheth"
      ],
      "year": "2012",
      "venue": "Proc. of the 2012 International Conference on Privacy, Security, Risk and Trust and 2012 International Conference on Social Computing"
    },
    {
      "citation_id": "9",
      "title": "#Emotional Tweets",
      "authors": [
        "S Mohammad"
      ],
      "year": "2012",
      "venue": "Proc. of the First Joint Conference on Lexical and Computational Semantics"
    },
    {
      "citation_id": "10",
      "title": "An Argument for Basic Emotions",
      "authors": [
        "P Ekman"
      ],
      "year": "1992",
      "venue": "Cognition and Emotion",
      "doi": "10.1080/02699939208411068"
    },
    {
      "citation_id": "11",
      "title": "Influence of Weak Labels for Emotion Recognition of Tweets",
      "authors": [
        "O Janssens",
        "S Verstockt",
        "E Mannens",
        "S Van Hoecke",
        "R Van De Walle"
      ],
      "year": "2014",
      "venue": "Mining Intelligence and Knowledge Exploration",
      "doi": "10.1007/978-3-319-13817-6_12"
    },
    {
      "citation_id": "12",
      "title": "EmoNet: Fine-Grained Emotion Detection with Gated Recurrent Neural Networks",
      "authors": [
        "M Abdul-Mageed",
        "L Ungar"
      ],
      "year": "2017",
      "venue": "Proc. of the 55th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "13",
      "title": "Using Millions of Emoji Occurrences to Learn Any-Domain Representations for Detecting Sentiment, Emotion and Sarcasm",
      "authors": [
        "B Felbo",
        "A Mislove",
        "A Søgaard",
        "I Rahwan",
        "S Lehmann"
      ],
      "year": "2017",
      "venue": "Proc. of the 2017 Conference on Empirical Methods in Natural Language Processing",
      "doi": "10.18653/v1/D17-1169"
    },
    {
      "citation_id": "14",
      "title": "Emotion and Sentiment Analysis of Tweets Using BERT",
      "authors": [
        "A Chiorrini",
        "C Diamantini",
        "A Mircoli",
        "D Potena"
      ],
      "year": "2021",
      "venue": "Proc. of the Workshops of the EDBT/ICDT Joint Conference"
    },
    {
      "citation_id": "15",
      "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "authors": [
        "J Devlin",
        "M.-W Chang",
        "K Lee",
        "K Toutanova"
      ],
      "year": "2019",
      "venue": "Proc. of the 2019 Conference of the North American Chapter"
    },
    {
      "citation_id": "16",
      "title": "The Importance of Neutral Examples for Learning Sentiment",
      "authors": [
        "M Koppel",
        "J Schler"
      ],
      "year": "2006",
      "venue": "Computational Intelligence"
    },
    {
      "citation_id": "17",
      "title": "Selecting Representative Data Sets",
      "authors": [
        "T Borovicka",
        "M Jirina",
        "P Kordik",
        "M Jirina"
      ],
      "year": "2012",
      "venue": "Advances in Data Mining Knowledge Discovery and Applications",
      "doi": "10.5772/50787"
    },
    {
      "citation_id": "18",
      "title": "Emotion Analysis of Twitter Data That Use Emoticons and Emoji Ideograms",
      "authors": [
        "W Wolny"
      ],
      "year": "2016",
      "venue": "Information Systems Development: Complexity in Information Systems Development (ISD2016 Proceedings)"
    },
    {
      "citation_id": "19",
      "title": "On Stopwords, Filtering and Data Sparsity for Sentiment Analysis of Twitter",
      "authors": [
        "H Saif",
        "M Fernandez",
        "Y He",
        "H Alani"
      ],
      "year": "2014",
      "venue": "Proc. of the Ninth International Conference on Language Resources and Evaluation (LREC'14)"
    },
    {
      "citation_id": "20",
      "title": "Encyclopedia of Machine Learning",
      "year": "2010",
      "venue": "Encyclopedia of Machine Learning",
      "doi": "10.1007/978-0-387-30164-8"
    },
    {
      "citation_id": "21",
      "title": "An Analytical Approach to Fast Parameter Selection of Gaussian RBF Kernel for Support Vector Machine",
      "authors": [
        "Z Liu",
        "M Zuo",
        "X Zhao",
        "H Xu"
      ],
      "year": "2015",
      "venue": "Journal of Information Science and Engineering"
    },
    {
      "citation_id": "22",
      "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach",
      "authors": [
        "Y Liu",
        "M Ott",
        "N Goyal",
        "J Du",
        "M Joshi",
        "D Chen",
        "O Levy",
        "M Lewis",
        "L Zettlemoyer",
        "V Stoyanov"
      ],
      "year": "2019",
      "venue": "RoBERTa: A Robustly Optimized BERT Pretraining Approach",
      "arxiv": "arXiv:1907.11692v1"
    },
    {
      "citation_id": "23",
      "title": "BERTweet: A Pre-Trained Language Model for English Tweets",
      "authors": [
        "D Nguyen",
        "T Vu",
        "A Nguyen"
      ],
      "year": "2020",
      "venue": "Proc. of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations"
    },
    {
      "citation_id": "24",
      "title": "Deep Learning with Python",
      "authors": [
        "F Chollet"
      ],
      "year": "2017",
      "venue": "Deep Learning with Python"
    },
    {
      "citation_id": "25",
      "title": "A Comparison of Event Models for Naive Bayes Text Classification",
      "authors": [
        "A Mccallum",
        "K Nigam"
      ],
      "year": "1998",
      "venue": "Proc. of the AAAI-98 Workshop on Learning for Text categorization"
    },
    {
      "citation_id": "26",
      "title": "Data Mining: Practical Machine Learning Tools and Techniques, 4th Edition",
      "authors": [
        "I Witten",
        "E Frank",
        "M Hall"
      ],
      "year": "2017",
      "venue": "Data Mining: Practical Machine Learning Tools and Techniques, 4th Edition",
      "doi": "10.1016/C2015-0-02071-8"
    }
  ]
}