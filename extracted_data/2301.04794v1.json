{
  "paper_id": "2301.04794v1",
  "title": "Litelstm Architecture Based On Weights Sharing For Recurrent Neural Networks",
  "published": "2023-01-12T03:39:59Z",
  "authors": [
    "Nelly Elsayed",
    "Zag ElSayed",
    "Anthony S. Maida"
  ],
  "keywords": [
    "LiteLSTM",
    "weights sharing",
    "LSTM",
    "recurrent neural networks",
    "IoT",
    "MNIST"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Long short-term memory (LSTM) is one of the robust recurrent neural network architectures for learning sequential data. However, it requires considerable computational power to learn and implement both software and hardware aspects. This paper proposed a novel LiteLSTM architecture based on reducing the LSTM computation components via the weights sharing concept to reduce the overall architecture computation cost and maintain the architecture performance. The proposed LiteL-STM can be significant for processing large data where time-consuming is crucial while hardware resources are limited, such as the security of IoT devices and medical data processing. The proposed model was evaluated and tested empirically on three different datasets from the computer vision, cybersecurity, speech emotion recognition domains. The proposed LiteLSTM has comparable accuracy to the other state-of-theart recurrent architecture while using a smaller computation budget.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Sequential data modeling such as text, univariate and multivariate time series, audio signals, biological signals, spatiotemporal sequences (videos), amino acid amd genetic sequences requires an apparatus that can recognize the temporal dependencies and relationships within the sequential data. In the early 1980s, the recurrent neural network (RNN) was designed as the first neural network approach that targeted sequential data problems  [1] [2] [3] . The RNN architecture can capture temporal dependencies due to the sense that it recursively integrates the current new input into its self-previous output  [4] . Since it has an unrestricted but fading memory for the past, it can employ the temporal dependencies to influence the learning of the structure within the data sequences  [5] . The RNN has been applied in different research areas such as handwriting recognition  [4, 6, 7] , speech recognition  [8] [9] [10] , language modeling  [11] [12] [13] , machine translation  [14] [15] [16] , action recognition  [17] [18] [19] , accident recognition  [20] [21] [22] , stock prediction  [23] [24] [25] , video classification  [26, 27] , intrusion detection systems  [28] , time series prediction  [29] , and mental disorder prediction  [30] .\n\nHowever, the RNN has a significant weakness: its ability to learn longterm dependencies is limited due to the vanishing/exploding gradient problem. There are several attempts to solve the RNN major design problem and enhance its overall performance, as the RNN loses the ability to learn when the error gradient is corrupted. To solve the vanishing/exploding gradient, extensions to the RNN architecture require adding an internal state (memory) that enforces a constant error flow through the RNN architecture stage. This constant error flow enhances the robustness of the error gradient over longer time scales. In addition, a gated control over the content of this internal state (memory) is also needed  [31] .\n\nNevertheless, this early LSTM model had significant weaknesses. When it was early designed by Hochreiter and Schmidhuber  [31] , the LSTM model input data was assumed to be prior segmented into subsequences with explicitly marked ends that the memory could reset between each irreverent subsequences processing  [31, 32] . Moreover, this LSTM architecture did not have an internal reset component in case of processing continual input streams. Therefore, when the LSTM processes continuous input streams, the state action may grow infinitely and ultimately cause the LSTM architecture to fail  [32] .\n\nIn 2000,  [32]  proposed a solution for the original LSTM problem that was proposed in  [31] .  [32]  added a forget gate beside the input and output gates into the LSTM architecture that resets the LSTM memory when the input is diversely different from the memory content and helps to remove the unnecessary information that the LSTM memory carries through the time. This LSTM approach  [32]  is widely used to solve various problems such as speech recognition  [8, [33] [34] [35] [36] , language modeling  [13, [37] [38] [39] , machine translation  [16, [40] [41] [42] , time series classification  [43, 44] , image segmentation  [45] [46] [47] , and video prediction  [40] .\n\nHowever, this model also has pivotal weaknesses. First, the architecture does not have a direct connection from the memory state to the forget, input, and output gates. Hence, there is no control from the memory to the gates that could assist in preventing the gradient from vanishing or exploding. Second, the Constant Error Carousel (CEC) does not have influential conduct over the forget and input gates when the output gate is closed (i.e. the output gate produces zero value output), which could negatively affect the model due to the lack of primary information flow within the model  [48, 49] .\n\nTo handle these problems in the standard LSTM, in 2002,  [48]  added the peephole connections from the memory state cell to each of the LSTM forget, input, and output gates. The peephole connections allowed the memory state to exert some control over the gates, reinforcing the LSTM architecture and preventing the lack of information flow through the model during the situation that leads to the output gate being closed  [48] .\n\nThe peephole added a generalization element to the standard LSTM  [50] . However, the major weakness of this architecture is that it becomes cost expensive due to the significant increase in the number of trainable parameters, memory, processing, and storage requirements to train the model and save the trained weights of the model and training time.\n\nHowever, there is still growing interest in studying and applying the LSTM architecture to solve various sequential problems in different research domains due to the LSTM outperforming the GRU in several tasks when problems have large training datasets  [51] . Moreover, Greff et al.  [51]  proposed research in 2017 showed that the LSTM exceeds the GRU performance in language modeling-related tasks. On the other hand, in some problems where the training datasets are small, the GRU outperforms the LSTM using a smaller computation budget  [52] .\n\nAs the era of big data requires robust tools to manipulate large data processing. In addition, it requires accelerated, time-consuming tools to process the data. Moreover, as the world tries to reduce the Carbon (CO2) footprint  [53]  by reducing the usage of high-performance hardware  [54] [55] [56] [57] , the LSTM implementation requirements cost is considered one of the significant LSTM drawbacks.\n\nSpatiotemporal prediction problems are challenging to solve, utilizing only a gated recurrent architecture. Implementing such models is quite expensive from both resources and value aspects as a large number of parameters, rapid processors, large processing memory, and memory storage are needed. In addition, such models demand considerable time to train, validate and test. Moreover, implementing such a model for real-time training is a challenge.\n\nThis paper attempts to evolve several computational aspects into a sophisticated performance level. This paper proposed a novel recurrent gated architecture using one gate: Lite Long Short-Term Memory (LiteLSTM). The proposed LiteLSTM employed the concept of sharing weight among the gates introduced in the GRU  [52]  to reduce the model computation budget. Also, it employs memory control over the gate using the peephole connection over Fig.  1  The RNN basic architecture and its corresponding unfolded in time representation  [61] .\n\nthe one gate. Beside Compared to the LSTM, Peephole LSTM, and GRU, the LiteLSTM has a smaller computation budget and implementation requirements, maintaining comparable accuracy. Due to its smaller computation budget, the LiteLSTM has a significant training time reduction compared to the LSTM. That allows the LiteLSTM to be implemented without a CO2 footprint requirement.\n\nThis paper is organized as follows: Section 2 provides a brief overview of the RNN, standard LSTM, peephole LSTM, and GRU architectures. Section 3 provides the LiteLSTM architecture design concept details, Section 4 shows empirical results for LiteLSTM implementation on three applications from three different research domains: computer vision (using MNIST  [58] , cybersecurity anomaly detection in IoT (IEEE IoT Network Intrusion Dataset)  [59] , and speech emotion recognition (TESS dataset  [60] ).",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Recurrent Neural Networks 2.1 Basic Rnn Architecture",
      "text": "The recurrent neural network (RNN) basic architecture is shown in Figure  1 . The left diagram shows the RNN architecture. The unfolded (unrolled) in time RNN representation is shown in the right diagram starting from the time step 0 to time step t. The RNN is transformed into a feedforward network that can be trained by backpropagation. This algorithm is called backpropagation through time (BPTT)  [62] . The RNN feeds its previous output vector h (t-1) at time step t -1vand the current input vector x (t) to calculate the RNN output h (t) at the current time step t. This method allows the RNN to identify and utilize temporal information to influence learning in the data sequences.\n\nThe basic RNN suffers from the vanishing/exploding gradient problem  [63] , limiting the model's ability to learn long-term dependencies within the sequential data. This is because the RNN does not have any element in its architecture design components that could maintain a constant error flow through the recurrent model. The principle of adding gates as supporting components into the recurrent architecture was proposed to solve this problem. At a given discrete time step t, the RNN output is calculated as follows:\n\nwhere x (t) is the RNN input at time step t. The h (t) and h (t-1) are the RNN outputs at time steps t and t -1. The feedforward and recurrent weights are represented by W and U , respectively. The weights are shared across time steps. b is the RNN model bias.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Standard Long Short-Term Memory (Lstm)",
      "text": "Gers et al.  [32]  proposed the standard LSTM architecture in 2000 as an improved version of the first LSTM architecture, which was proposed in 1997 by Hochreiter et al.  [31] . This standard LSTM aimed to solve the continuous input stream problem, which allowed the memory state cell values to grow in an unbounded fashion, causing saturation of the output squashing (activation) function. Gers et al.  [32]  proposed to add an additional gate to the LSTM architecture: forget gate f to reset the LSTM memory when the input is diversely different from the memory content and serves to remove the unnecessarily information that the LSTM memory holds through time.\n\nFigure  2  shows the standard LSTM unfolded architecture where c (t) , h (t) are the memory state cell and LSTM output at time t, respectively. The symbol denotes the element-wise (Hadamard) multiplication  [32, 64]  and σ denotes the logistic sigmoid function. b i , b g , b f , and b o are the biases of each gate. W 's are the feedforward weights and U 's are the recurrent weights.\n\nThe value of each component in the standard LSTM is calculated as follows:\n\nFig.  3  The standard LSTM unrolled architecture operation level that shows the components and their corresponding weights.\n\nwhere i (t) , f (t) , and o (t) are the input, forget, and output gates, respectively. The gates are constrained to have activation values between zero and one to indicate their status: open, closed, partially open, or partially closed. g (t) , is the input-update value. The model has two activation (squashing) units: inputupdate and output activation where the hyperbolic tangent tanh activation function is the preferable function to be used  [65] . The memory cell state at time t is c (t) and the output of the LSTM unit at time t is h (t) . Figure  3  shows the operation level of the standard LSTM where each component of the standard LSTM and its corresponding weights are given. The symbols × and denote matrix multiplication and element-wise multiplication, respectively.\n\nThe standard LSTM architectue is widely used in various problem-solving tasks and applications in different research fields. However, its architecture has major drawbacks. First, there is no direct connection from the memory to the gates which leads to the absence of CEC control over the gates  [48] . Second, if the output gate is closed, the CEC has no influence over the forget and input gates which could impair the model due to the lack of primary information flow within the model  [48] .",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "The Peephole-Based Lstm",
      "text": "Gers et al.  [48]  proposed in 2002 a solution for the standard LSTM major problems. A new connection component has been added to the LSTM architecture named the peephole connection, in which data flow connection from the memory state to each of the three LSTM gates to solve the standard LSTM main problems. The peephole connections allow the memory state value to exert control over the LSTM three gates. This assists in preventing the vanishing and/or exploding gradient problem that the standard LSTM could face.\n\nFigure  5  shows the operation level of the peephole-based LSTM. The equations to calculate the peephole LSTM are as follows:\n\nwhere the symbol denotes the elementwise (Hadamard) multiplication. W ci , W cf , and W co are the peephole connections weights between the memory state c t-1 and the input, forget, and output gates, respectively. Adding the peephole connection to the standard LSTM made the LSTM architecture a robust model to overcome the vanishing and/or exploding gradient problem. However, it caused a significant increase in the number of trainable parameters, training time, and memory requirements.",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "Gated Recurrent Unit (Gru)",
      "text": "The GRU model consists of two gates: the update gate z and the reset gate r, whereas the LSTM consists of three gates: input, output, and forget gates. In addition, the GRU does not contain the memory state cell that the LSTM model includes. Therefore, the GRU architecture is smaller than the LSTM by one gate and a memory state cell. The GRU integrates both the input gate and forget gate of the LSTM model into one update gate z  [51] , introducing the concept of the output of the same set of weights to reduce the model architecture. The unfolded GRU block architecture is shown in Figure  6 . Fig.  6  The GRU unfolder architecture.\n\nThe reset gate functionality operates similarly to the output gate of the LSTM. This GRU model eliminates the output squashing function, memory unit, and the CEC. The GRU yields a reduction in trainable parameters compared with the standard LSTM. However, this may lead to exploding and/or vanishing gradients.\n\nAt time step, t, the GRU unit output, h (t) , is calculated as follows  [52] :\n\nwhere the W xz , W xr , and W x are the feedforward weights of the update gate z (t) , the reset gate r (t) , and the output candidate activation h(t) , respectively.  The recurrent weights are U hz , U hr , U h for the update gate z (t) , the reset gate r (t) , and the output candidate activation h(t) , respectively. The biases of the update gate, reset gate, and the output candidate is denoted by b z , b r , and b, respectively. σ is the logistic sigmoid function and tanh is the hyperbolic tangent function. The elementwise (Hadamard) multiplication is denoted by . Figure  7  shows the operation level of the GRU architecture with weights and biases made explicit.",
      "page_start": 7,
      "page_end": 8
    },
    {
      "section_name": "Litelstm Architecture",
      "text": "The proposed LiteLSTM aims to: reduce the overall implementation cost of the LSTM, solve the LSTM significant problems, and maintain a comparable accuracy performance to the LSTM. The proposed LiteLSTM architecture appears in Figure  8 . The architecture of the LiteLSTM consists of only one trainable gated unit. We named the trainable gate the forget gate or network gate. This one gate behaves as a shared set of weights among the three gates of the standard LSTM gates. The LiteLSTM has a peephole connection from the memory state to the forget gate, which preserves the memory state from the LSTM and keeps the CEC to avoid vanishing and/or exploding gradients.\n\nThus, the proposed LiteLSTM preserves the critical components of the LSTM as stated by  [51]  while reducing much of the parameter redundancy in the LSTM architecture. The LiteLSTM has a significant reduction in the number of trainable parameters that are required to implement the model. Therefore, the LiteLSTM reduced the training time, memory, and hardware requirements compared to the standard LSTM, peephole-based LSTM, and GRU architectures. Furthermore, the proposed LiteLSTM architecture preserves comparable prediction accuracy results to the LSTM. Figure  9  shows a detailed architecture of the unrolled (unfolded) LiteLSTM assuming non-stacked input.\n\nThe LiteLSTM block architecture contains only one trainable gate that compensates the elimination of the other two gates of the standard LSTM by sharing its trainable weights. The LiteLSTM preserves the memory cell of the standard LSTM to process long data sequences and maintains the CEC to manage the vanishing/exploding gradient problem.\n\nThe LiteLSTM formulas are created as follows: During the forward pass within the LiteLSTM at time step t the total input (inp), inp (t) , to the single forget gate f (t) is calculated by:\n\nwhere inp (t) ∈ R η×1 , and η × 1 is the of input vector inp (t) . x (t) is the input at time t, x (t) ∈ R η×1 , h (t-1) is the output of the LiteLSTM architecture at time t -1, and the memory state cell at time t -1 denoted by c (t-1) . Both h (t-1) , c (t-1) ∈ R η×1 . W f x , U f h , and W f c are the weight sets. All three weight\n\nIn addition, we let I f = x (t) , h (t-1) , c (t-1) . By applying a squashing function G to the net input as follows:\n\nDepending on the application, the squaching function G can be either the logistic sigmoid (σ) or hard sigmoid (hardSig)  [66] . The logistic sigmoid is calculated by:\n\nwhere x is a real number, x ∈ (-∞, ∞), and σ(x) has the range of (0, 1). The hard sigmoid (hardSig) is calculated by: hardSig(x) = max(min(0.25x + 0.5, 1), 0)\n\nFigure  10  and Figure  11  shows the logistic sigmoid (σ) function and hard sigmoid (hardSig) function curves, respectively. The values of f t in Eqn. 19 falls in the range (0, 1) or [0, 1], depending on using the logistic sigmoid (σ) or hard sigmoid function, respectively  [65, 67] . Assuming that case of selection the function as σ, the gate value f t is calculated by:\n\nSelecting the logistic sigmoid or hard sigmoid functions is mainly based on the application. However, the hard sigmoid function is the preferred function to be used in the LiteLSTM gate to prevent the network gate from being closed (i.e., prevent the network gate from producing zero value output). The input update (memory activation) equation is calculated by:\n\nwhere W g = [W gx , U gh ], and 1) . The dimension in W g is matching the dimension of the W f that maintains the dimension compatability within the architecture design. Finally, the Lite LSTM output is calculated by:\n\nTable  1  shows a comparison between the architecture design and computation components of the RNN, GRU, standard LSTM, peephole-based LSTM (pLSTM), and the proposed LiteLSTM.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Emperical Evaluatuation And Analysis",
      "text": "In this paper, the LiteLSTM has been empirically tested and evaluated in three research domains: computer vision, anomaly detection in IoT, and speech emotion recognition. The MNIST  [58]  has been used as the computer vision experiment dataset, and the IEEE IoT Network Intrusion Dataset  [59]  is used for anomaly detection in IoT tasks. We used an Intel(R) Core(YM) i7-9700 CPU @3.00GHZ, 3000 Mhz processor, Microsoft Windows 10 OS, and 32 GB memory computer machine to perform our experiments. We used Python 3.7.6, Keras 2.0.4, and Tensorflow 1.15.0.  The first empirical evaluation of the LiteLSTM was performed using the MNIST dataset, which consists of 70, 000 images of handwritten digits between 0 and 9. The dataset is split into 60, 000 data samples for training and 10, 000 data samples for testing  [68] . The MNIST images were centered in a 28×28 image by computing the center of mass of the pixels. The model set 64-two layered architecture followed by a Softmax layer. For the training process, the batch size was set to 128 and the number of epochs to 20. The Adam optimizer with learning rate 10 -3 , β 1 = 0.9, β 2 = 0.999, and = 1e -07. Table  2  shows the accuracy results of the different recurrent architectures and the LiteLSTM, where the time is measured in minutes. The RNN shows a significantly shorter training time. However, it has the lowest performance compared to the other recurrent architectures. The LiteLSTM shows an improvement in accuracy compared to the other recurrent architectures. Figure  12  shows the accuracy plots for each of the LiteLSTM and the state-of-the-art recurrent models.\n\nThe second empirical evaluation of the LiteLSTM was performed using the IEEE IoT Network Intrusion Dataset. The dataset consists of 42 raw network packet files (pcap) at different time points. The IoT devices, namely SKT NUGU (NU 100) and EZVIZ Wi-Fi camera (C2C Mini O Plus 1080P) were used to generate traffic for IoT devices. The data contains normal traffic flow and different types of cyberattacks, namely: ARP spoofing attack, DoS (SYN flooding) attack, scan (host and port scan) attack, scan(port and OS scan) attack, (UDP/ACK/HTTP Flooding) of zombie PC compromised by Mirai malware, Mirai-ACK flooding attack, Mirai-HTTP flooding attack, and Telnet brute-force attack. In our experiments, we used a dataset to experiment with the LiteLSTM twice: first, to detect whether an attack occurred or not (as a binary dataset), and another experiment to detect the type of attack. We set the batch size to 32 and the number of epochs to 20. Table  3  shows the binary experimental results for the LiteLSTM and the recurrent architectures.   shows the detection results of the LiteLSTM and the recurrent architectures for detecting different types of cyberattacks.\n\nThe third empirical evaluation of the LiteLSTM was performed on a voice (audio) emotion recognition task. For this purpose, we used the Toronto Emotional Speech Set (TESS)  [60] , which is one of the emotion recognition dataset benchmarks that has been used in several emotion recognition applications and tasks  [69] [70] [71] . This dataset consists of 2800 stimuli and has seven different emotion categories: anger, disgust, fear, happiness, pleasant/surprise, sadness, and neutral. The major significance of this dataset is that the distribution between the number of stimuli per emotion category is equally likely  [60] . Similar to the previous experiments, we tested the proposed LiteLSTM with the other recurrent neural network architectures. For this empirical evaluation, we used the model described  [69] , which used the GRU as the learning model. We replaced the GRU with LiteLSTM, peephole LSTM, and RNN and evaluated the model performance each time. The dataset has been split into training, testing, and validation sets with a ratio of 70%, 20%, and 10%, respectively. Table  5  shows the empirical result of the proposed LiteLSTM and the recurrent architectures for emotion recognition from speech. Figure  13  shows the training versus validation accuracies for each of the recurrent architectures and LiteLSTM using Toronto Emotion Speech Set (TESS) dataset.",
      "page_start": 12,
      "page_end": 15
    },
    {
      "section_name": "Conclusion",
      "text": "The proposed LiteLSTM architecture novelty lies in the following aspects. First, the LiteLSTM consists of one gate that serves as a multifunctional gate via the weights-sharing concept. Thus, the overall number of training parameters is reduced by approximately one-third of the LSTM or the peephole-LSTM. In addition, maintaining the peephole connection from the memory state cell to the existing gate maintains the control of the memory over the gate in contrast to the LSTM. Therefore, the LiteLSTM handles the vanishing/exploding gradient problem.The overall budget for implementing the LiteLSTM, including the training time, memory footprint, memory storage, and processing power, is smaller than the LSTM by approximately one-third. We empirically evaluated the LiteLSTM using three datasets: MNIST, IEEE IoT Network Intrusion Detection datasets, and TESS speech emotion recognition dataset. The proposed LiteLSTM shows comparable results to the LSTM using a smaller computation budget. Due to the optimized LiteLSTM architecture design, we were able to complete the empirical tasks using a computer processor without involving the GPU in the computational process. Thus, the LiteLSTM architecture helps to reduce the CO2 footprint. The proposed LiteLSTM architecture is an attractive candidate for future hardware implementation on small and portable devices, especially IoT devices.",
      "page_start": 15,
      "page_end": 15
    },
    {
      "section_name": "Statements And Declarations",
      "text": "• Funding: N/A • Conflict of interest/Competing interests: The authors declare that they have no conflict of interest. • The authors did not receive support from any organization for the submitted work. • All authors certify that they have no affiliations with or involvement in any organization or entity with any financial interest or non-financial interest in the subject matter or materials discussed in this manuscript.\n\n• The authors have no financial or proprietary interests in any material discussed in this article.",
      "page_start": 16,
      "page_end": 16
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: The RNN basic architecture and its corresponding unfolded in time representa-",
      "page": 4
    },
    {
      "caption": "Figure 1: The left diagram shows the RNN architecture. The unfolded (unrolled) in time",
      "page": 4
    },
    {
      "caption": "Figure 2: The standard LSTM unrolled architecture.",
      "page": 5
    },
    {
      "caption": "Figure 2: shows the standard LSTM unfolded architecture where c(t), h(t)",
      "page": 5
    },
    {
      "caption": "Figure 3: The standard LSTM unrolled architecture operation level that shows the compo-",
      "page": 6
    },
    {
      "caption": "Figure 3: shows the operation level of the standard LSTM where each com-",
      "page": 6
    },
    {
      "caption": "Figure 4: Gers et al. [48] proposed peephole-based LSTM unrolled architecture.",
      "page": 7
    },
    {
      "caption": "Figure 5: shows the operation level of the peephole-based LSTM. The",
      "page": 7
    },
    {
      "caption": "Figure 5: The operation level of the peephole-LSTM unrolled architecture where its compo-",
      "page": 8
    },
    {
      "caption": "Figure 6: The GRU unfolder architecture.",
      "page": 8
    },
    {
      "caption": "Figure 7: The operation level of the GRU architecture showing the weights of each component.",
      "page": 9
    },
    {
      "caption": "Figure 8: The LiteLSTM unrolled architecture. The single network gate (output indicated by",
      "page": 9
    },
    {
      "caption": "Figure 7: shows the operation level of the GRU architecture with weights",
      "page": 9
    },
    {
      "caption": "Figure 9: The operation level of the LiteLSTM architecture showing the weights of each",
      "page": 10
    },
    {
      "caption": "Figure 9: shows a detailed architecture of the unrolled (unfolded) LiteLSTM assuming",
      "page": 10
    },
    {
      "caption": "Figure 10: The logistic sigmoid function curve.",
      "page": 11
    },
    {
      "caption": "Figure 11: The hardSigmoid function curve.",
      "page": 11
    },
    {
      "caption": "Figure 10: and Figure 11 shows the logistic sigmoid (σ) function and hard",
      "page": 11
    },
    {
      "caption": "Figure 12: The accuracy diagrams of the recurrent architectures and LiteLSTM using MNIST",
      "page": 13
    },
    {
      "caption": "Figure 12: shows the accuracy",
      "page": 13
    },
    {
      "caption": "Figure 13: The accuracy diagrams of the recurrent architectures and LiteLSTM using Toronto",
      "page": 14
    },
    {
      "caption": "Figure 13: shows the",
      "page": 15
    }
  ],
  "tables": [
    {
      "caption": "Table 1: Computational components comparison between the proposed LiteLSTM and",
      "page": 12
    },
    {
      "caption": "Table 1: shows a comparison between the architecture design and computa-",
      "page": 12
    },
    {
      "caption": "Table 2: Accuracy comparision between the LiteLSTM and the state-of-the-art recurrent",
      "page": 13
    },
    {
      "caption": "Table 3: shows the binary",
      "page": 13
    },
    {
      "caption": "Table 3: Accuracy comparision between the LiteLSTM and the state-of-the-art recurrent",
      "page": 14
    },
    {
      "caption": "Table 4: Accuracy comparison between the LiteLSTM and the state-of-the-art recurrent",
      "page": 14
    },
    {
      "caption": "Table 5: Accuracy comparison between the LiteLSTM and the state-of-the-art recurrent",
      "page": 15
    },
    {
      "caption": "Table 5: shows the empirical result of the proposed LiteLSTM and the recur-",
      "page": 15
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Speech dynamics and recurrent neural networks",
      "authors": [
        "H Bourlard",
        "C Wellekens"
      ],
      "year": "1989",
      "venue": "International Conference on Acoustics, Speech, and Signal Processing"
    },
    {
      "citation_id": "2",
      "title": "Recurrent neural networks",
      "authors": [
        "H Siegelmann"
      ],
      "year": "1995",
      "venue": "Computer Science Today"
    },
    {
      "citation_id": "3",
      "title": "Deep learning",
      "authors": [
        "I Goodfellow",
        "Y Bengio",
        "A Courville"
      ],
      "year": "2016",
      "venue": "Deep learning"
    },
    {
      "citation_id": "4",
      "title": "A novel connectionist system for unconstrained handwriting recognition",
      "authors": [
        "A Graves",
        "M Liwicki",
        "S Fernández",
        "R Bertolami",
        "H Bunke",
        "J Schmidhuber"
      ],
      "year": "2009",
      "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
    },
    {
      "citation_id": "5",
      "title": "Gated convolutional recurrent neural networks for predictive",
      "authors": [
        "N Elsayed"
      ],
      "year": "2019",
      "venue": "Gated convolutional recurrent neural networks for predictive"
    },
    {
      "citation_id": "6",
      "title": "Handwriting recognition using cohort of lstm and lexicon verification with extremely large lexicon",
      "authors": [
        "B Stuner",
        "C Chatelain",
        "T Paquet"
      ],
      "year": "2020",
      "venue": "Multimedia Tools and Applications"
    },
    {
      "citation_id": "7",
      "title": "Fast multi-language lstm-based online handwriting recognition",
      "authors": [
        "V Carbune",
        "P Gonnet",
        "T Deselaers",
        "H Rowley",
        "A Daryin",
        "M Calvo",
        "L.-L Wang",
        "D Keysers",
        "S Feuz",
        "P Gervais"
      ],
      "year": "2020",
      "venue": "International Journal on Document Analysis and Recognition (IJDAR)"
    },
    {
      "citation_id": "8",
      "title": "Long short-term memory recurrent neural network architectures for large scale acoustic modeling",
      "authors": [
        "H Sak",
        "A Senior",
        "F Beaufays"
      ],
      "year": "2014",
      "venue": "Fifteenth Annual Conference of the International Speech Communication Association"
    },
    {
      "citation_id": "9",
      "title": "Speech recognition with deep recurrent neural networks",
      "authors": [
        "A Graves",
        "A.-R Mohamed",
        "G Hinton"
      ],
      "year": "2013",
      "venue": "IEEE International Conference on Acoustics, Speech and Signal Processing"
    },
    {
      "citation_id": "10",
      "title": "A comprehensive study of deep bidirectional lstm rnns for acoustic modeling in speech recognition",
      "authors": [
        "A Zeyer",
        "P Doetsch",
        "P Voigtlaender",
        "R Schlüter",
        "H Ney"
      ],
      "year": "2017",
      "venue": "2017 IEEE International Conference on Acoustics, Speech and Signal Processing"
    },
    {
      "citation_id": "11",
      "title": "Recurrent neural network based language model",
      "authors": [
        "T Mikolov",
        "M Karafiát",
        "L Burget",
        "J Černockỳ",
        "S Khudanpur"
      ],
      "year": "2010",
      "venue": "Eleventh Annual Conference of the International Speech Communication Association"
    },
    {
      "citation_id": "12",
      "title": "Extensions of recurrent neural network language model",
      "authors": [
        "T Mikolov",
        "S Kombrink",
        "L Burget",
        "J Černockỳ",
        "S Khudanpur"
      ],
      "year": "2011",
      "venue": "Acoustics, Speech and Signal Processing (ICASSP), 2011 IEEE International Conference On"
    },
    {
      "citation_id": "13",
      "title": "Lstm neural networks for language modeling",
      "authors": [
        "M Sundermeyer",
        "R Schlüter",
        "H Ney"
      ],
      "year": "2012",
      "venue": "Thirteenth Annual Conference of the International Speech Communication Association"
    },
    {
      "citation_id": "14",
      "title": "The use of machine translation algorithm based on residual and lstm neural network in translation teaching",
      "authors": [
        "B Ren"
      ],
      "year": "2020",
      "venue": "Plos one"
    },
    {
      "citation_id": "15",
      "title": "Alpha-nets: A recurrent 'neural'network architecture with a hidden markov model interpretation",
      "authors": [
        "J Bridle"
      ],
      "year": "1990",
      "venue": "Speech Communication"
    },
    {
      "citation_id": "16",
      "title": "Neural machine translation by jointly learning to align and translate",
      "authors": [
        "D Bahdanau",
        "K Cho",
        "Y Bengio"
      ],
      "year": "2014",
      "venue": "Neural machine translation by jointly learning to align and translate",
      "arxiv": "arXiv:1409.0473"
    },
    {
      "citation_id": "17",
      "title": "Hierarchical recurrent neural network for skeleton based action recognition",
      "authors": [
        "Y Du",
        "W Wang",
        "L Wang"
      ],
      "year": "2015",
      "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition"
    },
    {
      "citation_id": "18",
      "title": "Action recognition in video sequences using deep bi-directional lstm with cnn features",
      "authors": [
        "A Ullah",
        "J Ahmad",
        "K Muhammad",
        "M Sajjad",
        "S Baik"
      ],
      "year": "2017",
      "venue": "IEEE access"
    },
    {
      "citation_id": "19",
      "title": "Baby physical safety monitoring in smart home using action recognition system",
      "authors": [
        "V Adewopo",
        "N Elsayed",
        "K Anderson"
      ],
      "year": "2022",
      "venue": "Baby physical safety monitoring in smart home using action recognition system",
      "arxiv": "arXiv:2210.12527"
    },
    {
      "citation_id": "20",
      "title": "Accident recognition via 3d cnns for automated traffic monitoring in smart cities",
      "authors": [
        "M Bortnikov",
        "A Khan",
        "A Khattak",
        "M Ahmad"
      ],
      "year": "2019",
      "venue": "Science and Information Conference"
    },
    {
      "citation_id": "21",
      "title": "Review on action recognition for accident detection in smart city transportation systems",
      "authors": [
        "V Adewopo",
        "N Elsayed",
        "Z Elsayed",
        "M Ozer",
        "A Abdelgawad",
        "M Bayoumi"
      ],
      "year": "2022",
      "venue": "Review on action recognition for accident detection in smart city transportation systems",
      "arxiv": "arXiv:2208.09588"
    },
    {
      "citation_id": "22",
      "title": "Global feature aggregation for accident anticipation",
      "authors": [
        "M Fatima",
        "M Khan",
        "C.-M Kyung"
      ],
      "year": "2020",
      "venue": "25th International Conference on Pattern Recognition (ICPR)"
    },
    {
      "citation_id": "23",
      "title": "Stock price pattern recognition-a recurrent neural network approach",
      "authors": [
        "K Kamijo",
        "-I",
        "T Tanigawa"
      ],
      "year": "1990",
      "venue": "IJCNN International Joint Conference On"
    },
    {
      "citation_id": "24",
      "title": "Intrusion detection system in smart home network using bidirectional lstm and convolutional neural networks hybrid model",
      "authors": [
        "N Elsayed",
        "Z Zaghloul",
        "S Azumah",
        "C Li"
      ],
      "year": "2021",
      "venue": "2021 IEEE International Midwest Symposium on Circuits and Systems (MWSCAS)"
    },
    {
      "citation_id": "25",
      "title": "A deep lstm based approach for intrusion detection iot devices network in smart home",
      "authors": [
        "S Azumah",
        "N Elsayed",
        "V Adewopo",
        "Z Zaghloul",
        "C Li"
      ],
      "year": "2021",
      "venue": "2021 IEEE 7th World Forum on Internet of Things (WF-IoT)"
    },
    {
      "citation_id": "26",
      "title": "Tensor-train recurrent neural networks for video classification",
      "authors": [
        "Y Yang",
        "D Krompass",
        "V Tresp"
      ],
      "year": "2017",
      "venue": "International Conference on Machine Learning"
    },
    {
      "citation_id": "27",
      "title": "Favorite video classification based on multimodal bidirectional lstm",
      "authors": [
        "T Ogawa",
        "Y Sasaka",
        "K Maeda",
        "M Haseyama"
      ],
      "year": "2018",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "28",
      "title": "An application of a recurrent network to an intrusion detection system",
      "authors": [
        "H Debar",
        "B Dorizzi"
      ],
      "year": "1992",
      "venue": "Proceedings 1992] IJCNN International Joint Conference on Neural Networks"
    },
    {
      "citation_id": "29",
      "title": "Prediction of chaotic time series based on the recurrent predictor neural network",
      "authors": [
        "M Han",
        "J Xi",
        "S Xu",
        "F.-L Yin"
      ],
      "year": "2004",
      "venue": "IEEE Transactions on Signal Processing"
    },
    {
      "citation_id": "30",
      "title": "Recurrent neural network-based approach for early recognition of alzheimer's disease in EEG",
      "authors": [
        "A Petrosian",
        "D Prokhorov",
        "W Lajara-Nanson",
        "R Schiffer"
      ],
      "year": "2001",
      "venue": "Clinical Neurophysiology"
    },
    {
      "citation_id": "31",
      "title": "Long short-term memory",
      "authors": [
        "S Hochreiter",
        "J Schmidhuber"
      ],
      "year": "1997",
      "venue": "Neural Computation"
    },
    {
      "citation_id": "32",
      "title": "Learning to forget: Continual prediction with LSTM",
      "authors": [
        "F Gers",
        "J Schmidhuber",
        "F Cummins"
      ],
      "year": "2000",
      "venue": "Neural Computation"
    },
    {
      "citation_id": "33",
      "title": "Neural speech recognizer: Acoustic-to-word LSTM model for large vocabulary speech recognition",
      "authors": [
        "H Soltau",
        "H Liao",
        "H Sak"
      ],
      "year": "2016",
      "venue": "Neural speech recognizer: Acoustic-to-word LSTM model for large vocabulary speech recognition",
      "arxiv": "arXiv:1610.09975"
    },
    {
      "citation_id": "34",
      "title": "End-to-end continuous speech recognition using attention-based recurrent NN: first results",
      "authors": [
        "J Chorowski",
        "D Bahdanau",
        "K Cho",
        "Y Bengio"
      ],
      "year": "2014",
      "venue": "End-to-end continuous speech recognition using attention-based recurrent NN: first results",
      "arxiv": "arXiv:1412.1602"
    },
    {
      "citation_id": "35",
      "title": "EESEN: End-to-end speech recognition using deep RNN models and WFST-based decoding",
      "authors": [
        "Y Miao",
        "M Gowayyed",
        "F Metze"
      ],
      "year": "2015",
      "venue": "Automatic Speech Recognition and Understanding (ASRU)"
    },
    {
      "citation_id": "36",
      "title": "Hybrid speech recognition with deep bidirectional LSTM",
      "authors": [
        "A Graves",
        "N Jaitly",
        "A.-R Mohamed"
      ],
      "year": "2013",
      "venue": "Automatic Speech Recognition and Understanding (ASRU), 2013 IEEE Workshop On"
    },
    {
      "citation_id": "37",
      "title": "Regularizing and optimizing LSTM language models",
      "authors": [
        "S Merity",
        "N Keskar",
        "R Socher"
      ],
      "year": "2017",
      "venue": "Regularizing and optimizing LSTM language models",
      "arxiv": "arXiv:1708.02182"
    },
    {
      "citation_id": "38",
      "title": "Sequence to sequence learning with neural networks",
      "authors": [
        "I Sutskever",
        "O Vinyals",
        "Q Le"
      ],
      "year": "2014",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "39",
      "title": "Gated word-character recurrent language model",
      "authors": [
        "Y Miyamoto",
        "K Cho"
      ],
      "year": "2016",
      "venue": "Gated word-character recurrent language model",
      "arxiv": "arXiv:1606.01700"
    },
    {
      "citation_id": "40",
      "title": "On the properties of neural machine translation: Encoder-decoder approaches",
      "authors": [
        "K Cho",
        "B Van Merriënboer",
        "D Bahdanau",
        "Y Bengio"
      ],
      "year": "2014",
      "venue": "On the properties of neural machine translation: Encoder-decoder approaches",
      "arxiv": "arXiv:1409.1259"
    },
    {
      "citation_id": "41",
      "title": "Addressing the rare word problem in neural machine translation",
      "authors": [
        "M.-T Luong",
        "I Sutskever",
        "Q Le",
        "O Vinyals",
        "W Zaremba"
      ],
      "year": "2014",
      "venue": "Addressing the rare word problem in neural machine translation",
      "arxiv": "arXiv:1410.8206"
    },
    {
      "citation_id": "42",
      "title": "Stanford neural machine translation systems for spoken language domains",
      "authors": [
        "M.-T Luong",
        "C Manning"
      ],
      "year": "2015",
      "venue": "Proceedings of the International Workshop on Spoken Language Translation"
    },
    {
      "citation_id": "43",
      "title": "LSTM fully convolutional networks for time series classification",
      "authors": [
        "F Karim",
        "S Majumdar",
        "H Darabi",
        "S Chen"
      ],
      "year": "2018",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "44",
      "title": "Multivariate LSTM-FCNs for time series classification",
      "authors": [
        "F Karim",
        "S Majumdar",
        "H Darabi",
        "S Harford"
      ],
      "year": "2018",
      "venue": "Multivariate LSTM-FCNs for time series classification",
      "arxiv": "arXiv:1801.04503"
    },
    {
      "citation_id": "45",
      "title": "Parallel multidimensional LSTM, with application to fast biomedical volumetric image segmentation",
      "authors": [
        "M Stollenga",
        "W Byeon",
        "M Liwicki",
        "J Schmidhuber"
      ],
      "year": "2015",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "46",
      "title": "Deeplab: Semantic image segmentation with deep convolutional nets, LiteLSTM Architecture Based on Weights Sharing for Recurrent Neural Networks atrous convolution, and fully connected crfs",
      "authors": [
        "L.-C Chen",
        "G Papandreou",
        "I Kokkinos",
        "K Murphy",
        "A Yuille"
      ],
      "year": "2018",
      "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
    },
    {
      "citation_id": "47",
      "title": "A combined LSTM-RNN-HMMapproach for meeting event segmentation and recognition",
      "authors": [
        "S Reiter",
        "B Schuller",
        "G Rigoll"
      ],
      "year": "2006",
      "venue": "ICASSP 2006 Proceedings. 2006 IEEE International Conference On"
    },
    {
      "citation_id": "48",
      "title": "Learning precise timing with LSTM recurrent networks",
      "authors": [
        "F Gers",
        "N Schraudolph",
        "J Schmidhuber"
      ],
      "year": "2002",
      "venue": "Journal of Machine Learning Research"
    },
    {
      "citation_id": "49",
      "title": "Recurrent nets that time and count",
      "authors": [
        "F Gers",
        "J Schmidhuber"
      ],
      "year": "2000",
      "venue": "Proceedings of the IEEE-INNS-ENNS International Joint Conference on Neural Networks. IJCNN 2000. Neural Computing: New Challenges and Perspectives for the New Millennium"
    },
    {
      "citation_id": "50",
      "title": "Reduced-gate convolutional long short-term memory using predictive coding for spatiotemporal prediction",
      "authors": [
        "N Elsayed",
        "A Maida",
        "M Bayoumi"
      ],
      "year": "2020",
      "venue": "Computational Intelligence"
    },
    {
      "citation_id": "51",
      "title": "LSTM: A search space odyssey",
      "authors": [
        "K Greff",
        "R Srivastava",
        "J Koutník",
        "B Steunebrink",
        "J Schmidhuber"
      ],
      "year": "2017",
      "venue": "IEEE Transactions on Neural Networks and Learning Systems"
    },
    {
      "citation_id": "52",
      "title": "Empirical evaluation of gated recurrent neural networks on sequence modeling",
      "authors": [
        "J Chung",
        "C Gulcehre",
        "K Cho",
        "Y Bengio"
      ],
      "year": "2014",
      "venue": "Empirical evaluation of gated recurrent neural networks on sequence modeling",
      "arxiv": "arXiv:1412.3555"
    },
    {
      "citation_id": "53",
      "title": "Strategies to reduce the carbon footprint of consumer goods by influencing stakeholders",
      "authors": [
        "N Bocken",
        "J Allwood"
      ],
      "year": "2012",
      "venue": "Journal of Cleaner Production"
    },
    {
      "citation_id": "54",
      "title": "Types of green innovations: Ways of implementation in a non-green industry",
      "authors": [
        "F Calza",
        "A Parmentola",
        "I Tutore"
      ],
      "year": "2017",
      "venue": "Sustainability"
    },
    {
      "citation_id": "55",
      "title": "Green iot system architecture for applied autonomous network cybersecurity monitoring",
      "authors": [
        "Z Zaghloul",
        "N Elsayed",
        "C Li",
        "M Bayoumi"
      ],
      "year": "2021",
      "venue": "2021 IEEE 7th World Forum on Internet of Things (WF-IoT)"
    },
    {
      "citation_id": "56",
      "title": "Green arithmetic logic unit",
      "authors": [
        "Al Haddad",
        "M Elsayed",
        "Z Bayoumi"
      ],
      "year": "2012",
      "venue": "2012 International Conference on Energy Aware Computing"
    },
    {
      "citation_id": "57",
      "title": "Autonomous low power iot system architecture for cybersecurity monitoring",
      "authors": [
        "Z Elsayed",
        "N Elsayed",
        "C Li",
        "M Bayoumi"
      ],
      "year": "2021",
      "venue": "Autonomous low power iot system architecture for cybersecurity monitoring"
    },
    {
      "citation_id": "58",
      "title": "The mnist database of handwritten digits",
      "authors": [
        "Y Lecun"
      ],
      "year": "1998",
      "venue": "The mnist database of handwritten digits"
    },
    {
      "citation_id": "59",
      "title": "IoT Network Intrusion Dataset",
      "authors": [
        "H Kang",
        "D Ahn",
        "G Lee",
        "J Yoo",
        "K Park",
        "H Kim"
      ],
      "venue": "IoT Network Intrusion Dataset",
      "doi": "10.21227/q70p-q449"
    },
    {
      "citation_id": "60",
      "title": "Toronto emotional speech set (TESS)younger talker happy",
      "authors": [
        "K Dupuis",
        "M Pichora-Fuller"
      ],
      "year": "2010",
      "venue": "Toronto emotional speech set (TESS)younger talker happy"
    },
    {
      "citation_id": "61",
      "title": "Understanding LSTM Networks",
      "authors": [
        "C Olah"
      ],
      "year": "2015",
      "venue": "Understanding LSTM Networks"
    },
    {
      "citation_id": "62",
      "title": "Backpropagation through time: what it does and how to do it",
      "authors": [
        "P Werbos"
      ],
      "year": "1990",
      "venue": "Proceedings of the IEEE"
    },
    {
      "citation_id": "63",
      "title": "Interpreting RNN behaviour via excitable network attractors",
      "authors": [
        "A Ceni",
        "P Ashwin",
        "L Livi"
      ],
      "year": "1807",
      "venue": "Interpreting RNN behaviour via excitable network attractors"
    },
    {
      "citation_id": "64",
      "title": "Reduced-gate convolutional lstm architecture for next-frame video prediction using predictive coding",
      "authors": [
        "N Elsayed",
        "A Maida",
        "M Bayoumi"
      ],
      "year": "2019",
      "venue": "2019 International Joint Conference on Neural Networks (ijcnn)"
    },
    {
      "citation_id": "65",
      "title": "Empirical activation function effects on unsupervised convolutional lstm learning",
      "authors": [
        "N Elsayed",
        "A Maida",
        "M Bayoumi"
      ],
      "year": "2018",
      "venue": "IEEE 30th International Conference on Tools with Artificial Intelligence (ICTAI)"
    },
    {
      "citation_id": "66",
      "title": "Noisy activation functions",
      "authors": [
        "C Gulcehre",
        "M Moczulski",
        "M Denil",
        "Y Bengio"
      ],
      "year": "2016",
      "venue": "International Conference on Machine Learning"
    },
    {
      "citation_id": "67",
      "title": "Effects of different activation functions for unsupervised convolutional lstm spatiotemporal learning",
      "authors": [
        "N Elsayed",
        "A Maida",
        "M Bayoumi"
      ],
      "year": "2019",
      "venue": "Technology and Engineering Systems Journal"
    },
    {
      "citation_id": "68",
      "title": "Litelstm architecture for deep recurrent neural networks",
      "authors": [
        "N Elsayed",
        "Z Elsayed",
        "A Maida"
      ],
      "year": "2022",
      "venue": "Litelstm architecture for deep recurrent neural networks",
      "arxiv": "arXiv:2201.11624"
    },
    {
      "citation_id": "69",
      "title": "Speech emotion recognition using supervised deep recurrent system for mental health monitoring",
      "authors": [
        "N Elsayed",
        "Z Elsayed",
        "N Asadizanjani",
        "M Ozer",
        "A Abdelgawad",
        "M Bayoumi"
      ],
      "year": "2022",
      "venue": "Speech emotion recognition using supervised deep recurrent system for mental health monitoring",
      "arxiv": "arXiv:2208.12812"
    },
    {
      "citation_id": "70",
      "title": "Ravdness, crema-d, tess based algorithm for emotion recognition using speech",
      "authors": [
        "M Gokilavani",
        "H Katakam",
        "S Basheer",
        "P Srinivas"
      ],
      "year": "2022",
      "venue": "2022 4th International Conference on Smart Systems and Inventive Technology (ICSSIT)"
    },
    {
      "citation_id": "71",
      "title": "Analysis of deep learning architectures for cross-corpus speech emotion recognition",
      "authors": [
        "J Parry",
        "D Palaz",
        "G Clarke",
        "P Lecomte",
        "R Mead",
        "M Berger",
        "G Hofer"
      ],
      "year": "2019",
      "venue": "Analysis of deep learning architectures for cross-corpus speech emotion recognition"
    }
  ]
}