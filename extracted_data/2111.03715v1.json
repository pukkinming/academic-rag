{
  "paper_id": "2111.03715v1",
  "title": "Leveraging Sentiment Analysis Knowledge To Solve Emotion Detection Tasks",
  "published": "2021-11-05T20:06:58Z",
  "authors": [
    "Maude Nguyen-The",
    "Guillaume-Alexandre Bilodeau",
    "Jan Rockemann"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Identifying and understanding underlying sentiment or emotions in text is a key component of multiple natural language processing applications. While simple polarity sentiment analysis is a well-studied subject, fewer advances have been made in identifying more complex, finer-grained emotions using only textual data. In this paper, we present a Transformer-based model with a Fusion of Adapter layers which leverages knowledge from more simple sentiment analysis tasks to improve the emotion detection task on large scale dataset, such as CMU-MOSEI, using the textual modality only. Results show that our proposed method is competitive with other approaches. We obtained state-of-the-art results for emotion recognition on CMU-MOSEI even while using only the textual modality.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Sentiment analysis is a subject that has long interested multiple researchers in the domain of natural language understanding. It is a task which aims to identify sentiment polarity for a given signal, which can be of the audio, visual or textual modality. Emotion recognition is a related task which consists of assigning more fine-grained labels, such as anger, joy, sadness, etc. This work focuses on analyzing textual inputs. The ability to recognize the sentiment or emotion behind a given sentence or paragraph can lead to multiple applications, such as empathetic dialogue agents and tools to assess the mental state of a patient.\n\nWhile sentiment analysis in the form of assigning polarities (positive, negative, and sometimes neutral) to text data is a task that is often studied and for which adequate results have already been obtained for multiple datasets, identifying finer-grained labels such as specific emotions is still a challenge. In addition to the task complexity, in most datasets available for this task, some emotions are much less represented than others, making the training data unbalanced. To address this issue, the model proposed in this work combines knowledge from less complex tasks and is trained using methods to counteract class imbalance. It is based on a Transformer-based model with a Fusion of Adapter layers to leverage knowledge from the more simple sentiment analysis task.\n\nThe results obtained are competitive with state-of-the-art multi-modal models on the CMU-MOSEI dataset  (Bagher Zadeh et al., 2018) , while only utilizing the textual modality. Our main contribution can be formulated as:\n\n• We designed a method that capitalizes on both pretrained Transformer language models and knowledge from complementary tasks to improve on the emotion recognition task, whilst arXiv:2111.03715v1 [cs.CL] 5 Nov 2021\n\nusing Adapter layers that require less training parameters than the conventional fine-tuning approach and taking into account class imbalance.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Prior Works And Background",
      "text": "There are multiple approaches that have been used to solve text-based sentiment analysis and emotion detection tasks, namely rule-based and machine learning approaches. Rule-based approaches consist of creating grammatical and logical rules to assign emotions and use lexicons to assign emotions or polarities to words. Previous works using this approach include the ones of  Udochukwu and He (2015) ,  Tan et al. (2015)  and  Seal et al. (2019) . These methods are limited by the size and contents of the lexicon used and by the ambiguity of some keywords.\n\nMost recent methods are based on the machine learning approach were the network is trained to learn the relationships between words and emotions. Methods such as those proposed by  Abdul-Mageed and Ungar (2017) ,  Tang et al. (2015)  and  Ma et al. (2019)  use recurrent neural networks to solve sentiment analysis tasks to break down sentences and understand the relationship between the succession of words and sentiments or emotions. Since the release of pretrained models, recent works  (Park et al., 2019; Acheampong et al., 2021)  have been focused on fine-tuning transformer models, which have consistently outperformed previous methods thanks to the multi-head attention applied on words. To improve previous textual emotion recognition methods, we believe that in addition to transfer learning, multi-task learning and class imbalance should be considered.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Transfer Learning",
      "text": "Transfer learning is a method where the weights of a model trained on a task are used as starting point to train a model for another task. The use of transfer learning with pretrained models has been, for the past few years, the way to obtain state-of-the-art results for multiple natural language understanding (NLU) tasks. Transformer-based pretrained models such as BERT  (Devlin et al., 2018) , RoBERTa  (Liu et al., 2019c) , XLNet  (Yang et al., 2019) , etc. have been dominating the field over previously used methods.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Multi-Task Learning",
      "text": "Multi-task learning is used to train one model to solve multiple tasks instead of fine-tuning separate models. Multiple approaches have been used to solve multi-task learning problems.  Liu et al. (2019a)  proposed a Multi-Task Deep Neural Network (MT-DNN) with a shared transformer encoder and task-specific heads.  Clark et al. (2019)  and  Liu et al. (2019b)  presented a new training procedure based on knowledge distillation to improve the performances of the MT-DNN. These approaches allow the model to learn a shared representation between all tasks.  Houlsby et al. (2019)  introduced a new model architecture using task-specific adapter layers and keeping the weights of the pretrained encoder frozen. This method, while preventing task interference and catastrophic forgetting, does not allow to transfer knowledge between tasks. To counter this weakness,  Pfeiffer et al. (2020a)  proposed AdapterFusion, a way to combine knowledge from multiple adapters.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Class Imbalance",
      "text": "Class imbalance is a challenge in resolving many artificial intelligence tasks. It occurs when one or multiple classes make up significantly less samples of the data than the majority class or classes, often leading to a poor predictive performance for those minority classes. Classic approaches to this problem include re-sampling minority class samples or weighting the loss function according to class frequency. In the field of computer vision,  Lin et al. (2018)  proposed a modified version of the cross-entropy loss called the focal loss to handle imbalance.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Proposed Approach",
      "text": "To improve over previous methods, we have based our method on transfer learning, multi-task learning and we specifically considered class imbalance. To capitalize on transfer learning, our method is based on a strong language model, BERT  (Devlin et al., 2018) . We motivate this choice by the fact that identifying emotion requires a good overall understanding of a language, as captured by BERT. Since, sentiment analysis and emotion detection are closely related, we propose a model that learns to combine knowledge from multiple tasks of that nature. This allows leveraging datasets that are annotated only with sentiment for the emotion detection task. Finally, our model is designed to consider class imbalance.\n\nOur method is described in detail in the following.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Model",
      "text": "The proposed model is based on the pretrained Transformer encoder BERT  (Devlin et al., 2018)  and of a fusion of separately trained Adapter layers. The overall architecture of the model can be seen in Figure  1 . We chose the BERT encoder (base size), which is comprised of a stack of twelve encoder layers, preceded by token, sentence and position embeddings. Following the encoder, the last hidden state corresponding to the special classification token ([CLS]) is fed to a classification head formed by two feed forward layers.\n\nFigure  1 : Architecture of the proposed model.\n\nAdapters are layers inserted in each of the encoder layers and are trained to adapt the encoder pretrained knowledge to a specific task, while the weights of the encoder are kept frozen (see Figure  2 ). In this work, each adapter layer trained for a specific task has the same structure, which is the one  Pfeiffer et al. (2020a)  found to be the best across multiple diverse tasks. They are composed of a feed forward layer that projects the encoder hidden state to a lower dimension, a non-linear function and a feed forward layer that projects it back up to the original hidden size. Pfeiffer et al.\n\n(2020a) also found that a reduction factor of 16 for the projection down layer adds a reasonable number of parameters per task whilst still achieving good results. All adapters were therefore trained using this reduction factor.\n\nThere are as many adapter layers as there are tasks. Figure  2  illustrates that there are several adapter layers that are used in parallel in our model. To combine the knowledge of each adapter, the AdapterFusion method is used  (Pfeiffer et al., 2020a) . This method consists of learning a composition of the knowledge of different trained adapters. In this stage of the learning, the weights of the pretrained encoder and of all single adapters are frozen, while the classification and fusion layers are trained. The architecture of the fusion layers is also presented in Figure  2 .",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Loss Function",
      "text": "The loss function used to counter the imbalance present in emotion detection datasets is a modified version of the classic Binary Cross-Entropy (BCE) Loss used for multi-label classification and can be defined as followed:\n\nwhere N is the number of samples in the batch, C is the number of classes, x n,c is the output of the classification layer of the model for class c of sample n, and w c is the positive answer weighting factor for class c defined as:  Adapting the focal loss to multi-label classification was also tested but did not significantly improve the performances of the model in comparison to using the classic BCE loss.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Experiments",
      "text": "Our proposed method was tested using three datasets. We also performed several ablation studies to assess the contribution of each component.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Datasets",
      "text": "CMU-MOSEI  (Bagher Zadeh et al., 2018) : This dataset is comprised of visual, acoustic and textual features for around 23,500 sentences extracted from videos. This dataset is meant to be used to train multi-modal models, but in this work, only the textual inputs were used. The dataset is labelled for sentiment on a scale of [-3,3] and for Ekman emotions  (Ekman, 1992)  of joy, sadness, anger, surprise, disgust and fear on a scale of [0, 3]. For binary sentiment classification, the labels are binarized to negative (labels lesser than 0) and non-negative (labels greater or equal to 0). The emotions are discretized to non-present (label equal to 0) or present (label greater than 0). Multiple emotions can be present for the same sample. The performance of models on this dataset is measured with standard binary accuracy (A) and F1 scores (F1) for each emotion, as well as an overall non-weighted mean accuracy score and an overall weighted F1 score.\n\nSST-2  (Socher et al., 2013)  & IMDB  (Maas et al., 2011) : SST-2 is comprised of over 60,000 sentences extracted from movie reviews. IMDB contains 50,000 movie reviews. Both are labelled for sentiment analysis in a 2-class split (positive or negative). These datasets were obtained using the HuggingFace Datasets library 1  . The performance of models on these datasets is measured with the same binary accuracy scores (A) as CMU-MOSEI.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Experimental Setup",
      "text": "All experiments use BERT base (cased)  (Devlin et al., 2018)  as the pretrained model, which has 12 encoder layers and a hidden size of 768. Adapter and AdapterFusion layers are added to each of those encoder layers. The classification heads are composed of two fully connected linear layers with sizes equal to the hidden size of the transformer layer (  768 ) and the number of labels (  6 ) respectively, and with tanh activation functions. The input of the first linear layer is the last hidden state of the BERT model corresponding to the classification token ([CLS]) at the beginning of the input sequence. All models were trained using AdamW  (Loshchilov and Hutter, 2017)  with a linear rate scheduler, a learning rate of 1e-5, and a weight decay of 1e-2. All models were trained for 10 epochs with early stopping after 3 epochs if the validation metric did not improve. The Adapter-Transformers library  (Pfeiffer et al., 2020b)  was used to incorporate the Adapter and AdapterFusion layers to the model. The results presented in the following section are averaged over 3 runs.\n\nTwo types of fusion models were trained: one using a fusion of only CMU-MOSEI tasks (Fusion 3 : binary sentiment, 7-class sentiment and emotion classification) and one using additional knowledge from the SST-2 and IMDB sentiment analysis tasks (Fusion 5 ).",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Results",
      "text": "The results for the emotion detection task of CMU-MOSEI are presented in Table  1 . The performance of the proposed model is compared to that of a fine-tuned BERT model and of a model using a single task specific adapter, both using the same classification head as our proposed model. The results of the current state-of-the art model for this dataset  (Delbrouck et al., 2020)  are also presented. Note that this state-of-the-art model is a Transformer-based model that utilizes both textual and audio modalities.  1 Accuracy scores obtained from  (Delbrouck et al., 2020) . F1 scores were computed using the two provided model checkpoints, as the ones presented in their paper were weighted F1 scores.\n\nAll models trained with our proposed loss function achieve better F1-scores than the current stateof-the-art. While a fully fine-tuned BERT model achieves better overall accuracy, the proposed Fusion model is the one that has best accuracy/F1-score trade-off for all emotions. As observed in Table  2 , given that all distributions of emotions, except for joy, are heavily imbalanced, accuracy is not an appropriate metric for this dataset as it does not fully represent the model ability to identify each emotion. Therefore, it is better to use the F1-score as a measurement basis. Single Adapter models are able to achieve good F1 scores, but do not reach accuracy scores that are comparable to Fusion models, which further proves that combining knowledge from multiple tasks improves the performance of the model. Capitalizing on knowledge from additional sentiment analysis tasks outside of the CMU-MOSEI dataset also allows the Fusion 5 model to perform slightly better than the Fusion 3 model, which only includes knowledge from the CMU-MOSEI tasks. The proposed model also requires a lot less parameters to train, as can be seen in Table  3 .  The difference in performance between the classic Binary Cross-Entropy loss and the Focal loss is not significant. While the use of the loss function proposed in this paper decreases to some extent the accuracy for most emotions, it greatly improves the F1-score for all emotions with the exception of joy.",
      "page_start": 5,
      "page_end": 6
    },
    {
      "section_name": "Performance Of Single Adapters",
      "text": "This section presents the performance of the single Adapters on the other tasks used for knowledge composition in the Fusion models. Tables  5  and 6  compare the results obtained by BERT trained with task-specific adapters (Adapter) to fully fine-tuned models and state-of-the-art models. Unless stated otherwise, all accuracy values were obtained by averaging the results over 3 runs using the experimental setup described in section 4.2. Base size versions of BERT, RoBERTa and XLNet models were used for a fair comparison.   (Delbrouck et al., 2020) .\n\nThe performances of the Adapter models are comparable to those of a fully fine-tuned BERT model.\n\nIn the case of CMU-MOSEI tasks, they performed on par with or better than state-of-the-art results.\n\nIn the case of SST-2 and IMDB tasks, they slightly underperformed compared to state-of-the-art fine-tuned language models. However, regardless of the dataset, this experiment shows that adapters can capture useful task-specific information at lower training cost. Furthermore, adapter fusion allows to combine the knowledge from these several good performing task-specific adapters. This explains why our proposed adapter fusion model benefits from the related tasks of sentiment analysis to improve emotion recognition.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Conclusion",
      "text": "The model presented in this work surpasses state-of-the-art results for emotion recognition on CMU-MOSEI even while using only the textual modality. There is still improvement needed for the rarer emotions in the dataset, but at of the time of producing this article, the results presented are substantially stronger than other contributions in terms of F1-scores. Due to the lack of large-scale datasets for emotion detection in text, testing the model on purely textual data will have to be done in further studies as the data will become available.",
      "page_start": 7,
      "page_end": 7
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: We chose the BERT encoder (base size), which is comprised of a stack of twelve encoder",
      "page": 3
    },
    {
      "caption": "Figure 1: Architecture of the proposed model.",
      "page": 3
    },
    {
      "caption": "Figure 2: ). In this work, each adapter layer trained for a speciﬁc task has the same structure, which is",
      "page": 3
    },
    {
      "caption": "Figure 2: illustrates that there are several",
      "page": 3
    },
    {
      "caption": "Figure 2: Modiﬁed encoder layer proposed in our method (middle), as deﬁned in Pfeiffer et al.",
      "page": 4
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Abstract": ""
        },
        {
          "Abstract": "language processing applications. While simple"
        },
        {
          "Abstract": ""
        },
        {
          "Abstract": "made in identifying more complex, ﬁner-grained emotions using only textual data."
        },
        {
          "Abstract": ""
        },
        {
          "Abstract": ""
        },
        {
          "Abstract": ""
        },
        {
          "Abstract": ""
        },
        {
          "Abstract": ""
        },
        {
          "Abstract": ""
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "1\nIntroduction": "Sentiment analysis is a subject that has long interested multiple researchers in the domain of natural"
        },
        {
          "1\nIntroduction": "language understanding.\nIt"
        },
        {
          "1\nIntroduction": "which can be of the audio, visual or textual modality. Emotion recognition is a related task which"
        },
        {
          "1\nIntroduction": "consists of assigning more ﬁne-grained labels, such as anger, joy, sadness, etc."
        },
        {
          "1\nIntroduction": "This work focuses on analyzing textual inputs. The ability to recognize the sentiment or emotion"
        },
        {
          "1\nIntroduction": "behind a given sentence or paragraph can lead to multiple applications, such as empathetic dialogue"
        },
        {
          "1\nIntroduction": "agents and tools to assess the mental state of a patient."
        },
        {
          "1\nIntroduction": "While sentiment analysis in the form of assigning polarities (positive, negative, and sometimes"
        },
        {
          "1\nIntroduction": "neutral) to text data is a task that is often studied and for which adequate results have already been"
        },
        {
          "1\nIntroduction": "obtained for multiple datasets,"
        },
        {
          "1\nIntroduction": "challenge. In addition to the task complexity, in most datasets available for this task, some emotions"
        },
        {
          "1\nIntroduction": ""
        },
        {
          "1\nIntroduction": "the model proposed in this work combines knowledge from less complex tasks and is trained using"
        },
        {
          "1\nIntroduction": "methods to counteract class imbalance. It is based on a Transformer-based model with a Fusion of"
        },
        {
          "1\nIntroduction": "Adapter layers to leverage knowledge from the more simple sentiment analysis task."
        },
        {
          "1\nIntroduction": "The results obtained are competitive with state-of-the-art multi-modal models on the CMU-MOSEI"
        },
        {
          "1\nIntroduction": "dataset (Bagher Zadeh et al., 2018), while only utilizing the textual modality. Our main contribution"
        },
        {
          "1\nIntroduction": "can be formulated as:"
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "approach and taking into account class imbalance.": "2\nPrior Works and Background"
        },
        {
          "approach and taking into account class imbalance.": "There are multiple approaches that have been used to solve text-based sentiment analysis and emotion"
        },
        {
          "approach and taking into account class imbalance.": "detection tasks, namely rule-based and machine learning approaches. Rule-based approaches consist"
        },
        {
          "approach and taking into account class imbalance.": "of creating grammatical and logical rules to assign emotions and use lexicons to assign emotions"
        },
        {
          "approach and taking into account class imbalance.": "or polarities to words. Previous works using this approach include the ones of Udochukwu and He"
        },
        {
          "approach and taking into account class imbalance.": "(2015), Tan et al. (2015) and Seal et al. (2019). These methods are limited by the size and contents of"
        },
        {
          "approach and taking into account class imbalance.": "the lexicon used and by the ambiguity of some keywords."
        },
        {
          "approach and taking into account class imbalance.": "Most recent methods are based on the machine learning approach were the network is trained to"
        },
        {
          "approach and taking into account class imbalance.": ""
        },
        {
          "approach and taking into account class imbalance.": "Mageed and Ungar (2017), Tang et al. (2015) and Ma et al. (2019) use recurrent neural networks to"
        },
        {
          "approach and taking into account class imbalance.": "solve sentiment analysis tasks to break down sentences and understand the relationship between the"
        },
        {
          "approach and taking into account class imbalance.": "succession of words and sentiments or emotions. Since the release of pretrained models, recent works"
        },
        {
          "approach and taking into account class imbalance.": "(Park et al., 2019; Acheampong et al., 2021) have been focused on ﬁne-tuning transformer models,"
        },
        {
          "approach and taking into account class imbalance.": "which have consistently outperformed previous methods thanks to the multi-head attention applied"
        },
        {
          "approach and taking into account class imbalance.": "on words. To improve previous textual emotion recognition methods, we believe that in addition to"
        },
        {
          "approach and taking into account class imbalance.": "transfer learning, multi-task learning and class imbalance should be considered."
        },
        {
          "approach and taking into account class imbalance.": "2.1\nTransfer Learning"
        },
        {
          "approach and taking into account class imbalance.": "Transfer learning is a method where the weights of a model trained on a task are used as starting point"
        },
        {
          "approach and taking into account class imbalance.": "to train a model for another task. The use of transfer learning with pretrained models has been, for the"
        },
        {
          "approach and taking into account class imbalance.": "past few years, the way to obtain state-of-the-art results for multiple natural language understanding"
        },
        {
          "approach and taking into account class imbalance.": "(NLU) tasks. Transformer-based pretrained models such as BERT (Devlin et al., 2018), RoBERTa"
        },
        {
          "approach and taking into account class imbalance.": "(Liu et al., 2019c), XLNet (Yang et al., 2019), etc. have been dominating the ﬁeld over previously"
        },
        {
          "approach and taking into account class imbalance.": "used methods."
        },
        {
          "approach and taking into account class imbalance.": "2.2\nMulti-Task Learning"
        },
        {
          "approach and taking into account class imbalance.": "Multi-task learning is used to train one model to solve multiple tasks instead of ﬁne-tuning separate"
        },
        {
          "approach and taking into account class imbalance.": "models. Multiple approaches have been used to solve multi-task learning problems. Liu et al. (2019a)"
        },
        {
          "approach and taking into account class imbalance.": "proposed a Multi-Task Deep Neural Network (MT-DNN) with a shared transformer encoder and"
        },
        {
          "approach and taking into account class imbalance.": "task-speciﬁc heads. Clark et al. (2019) and Liu et al. (2019b) presented a new training procedure"
        },
        {
          "approach and taking into account class imbalance.": "based on knowledge distillation to improve the performances of the MT-DNN. These approaches"
        },
        {
          "approach and taking into account class imbalance.": "allow the model to learn a shared representation between all tasks. Houlsby et al. (2019) introduced a"
        },
        {
          "approach and taking into account class imbalance.": "new model architecture using task-speciﬁc adapter layers and keeping the weights of the pretrained"
        },
        {
          "approach and taking into account class imbalance.": "encoder frozen. This method, while preventing task interference and catastrophic forgetting, does not"
        },
        {
          "approach and taking into account class imbalance.": "allow to transfer knowledge between tasks. To counter this weakness, Pfeiffer et al. (2020a) proposed"
        },
        {
          "approach and taking into account class imbalance.": "AdapterFusion, a way to combine knowledge from multiple adapters."
        },
        {
          "approach and taking into account class imbalance.": "2.3\nClass Imbalance"
        },
        {
          "approach and taking into account class imbalance.": "Class imbalance is a challenge in resolving many artiﬁcial intelligence tasks."
        },
        {
          "approach and taking into account class imbalance.": "or multiple classes make up signiﬁcantly less samples of the data than the majority class or classes,"
        },
        {
          "approach and taking into account class imbalance.": "often leading to a poor predictive performance for those minority classes. Classic approaches to"
        },
        {
          "approach and taking into account class imbalance.": "this problem include re-sampling minority class samples or weighting the loss function according to"
        },
        {
          "approach and taking into account class imbalance.": "class frequency. In the ﬁeld of computer vision, Lin et al. (2018) proposed a modiﬁed version of the"
        },
        {
          "approach and taking into account class imbalance.": "cross-entropy loss called the focal loss to handle imbalance."
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "the fact that identifying emotion requires a good overall understanding of a language, as captured by": "BERT. Since, sentiment analysis and emotion detection are closely related, we propose a model that"
        },
        {
          "the fact that identifying emotion requires a good overall understanding of a language, as captured by": "learns to combine knowledge from multiple tasks of that nature. This allows leveraging datasets that"
        },
        {
          "the fact that identifying emotion requires a good overall understanding of a language, as captured by": "are annotated only with sentiment for the emotion detection task. Finally, our model is designed to"
        },
        {
          "the fact that identifying emotion requires a good overall understanding of a language, as captured by": ""
        },
        {
          "the fact that identifying emotion requires a good overall understanding of a language, as captured by": ""
        },
        {
          "the fact that identifying emotion requires a good overall understanding of a language, as captured by": "Model"
        },
        {
          "the fact that identifying emotion requires a good overall understanding of a language, as captured by": ""
        },
        {
          "the fact that identifying emotion requires a good overall understanding of a language, as captured by": "of a fusion of separately trained Adapter layers. The overall architecture of the model can be seen in"
        },
        {
          "the fact that identifying emotion requires a good overall understanding of a language, as captured by": "Figure 1. We chose the BERT encoder (base size), which is comprised of a stack of twelve encoder"
        },
        {
          "the fact that identifying emotion requires a good overall understanding of a language, as captured by": "layers, preceded by token, sentence and position embeddings. Following the encoder, the last hidden"
        },
        {
          "the fact that identifying emotion requires a good overall understanding of a language, as captured by": "state corresponding to the special classiﬁcation token ([CLS]) is fed to a classiﬁcation head formed"
        },
        {
          "the fact that identifying emotion requires a good overall understanding of a language, as captured by": ""
        }
      ],
      "page": 3
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Figure 2: Modiﬁed encoder\nlayer proposed in our method (middle), as deﬁned in Pfeiffer et al.": "(2020a). On the left, architecture of an adapter layer. On the right, architecture of a fusion layer."
        },
        {
          "Figure 2: Modiﬁed encoder\nlayer proposed in our method (middle), as deﬁned in Pfeiffer et al.": "Adapting the focal loss to multi-label classiﬁcation was also tested but did not signiﬁcantly improve"
        },
        {
          "Figure 2: Modiﬁed encoder\nlayer proposed in our method (middle), as deﬁned in Pfeiffer et al.": "the performances of the model in comparison to using the classic BCE loss."
        },
        {
          "Figure 2: Modiﬁed encoder\nlayer proposed in our method (middle), as deﬁned in Pfeiffer et al.": "4\nExperiments"
        },
        {
          "Figure 2: Modiﬁed encoder\nlayer proposed in our method (middle), as deﬁned in Pfeiffer et al.": "Our proposed method was tested using three datasets. We also performed several ablation studies to"
        },
        {
          "Figure 2: Modiﬁed encoder\nlayer proposed in our method (middle), as deﬁned in Pfeiffer et al.": "assess the contribution of each component."
        },
        {
          "Figure 2: Modiﬁed encoder\nlayer proposed in our method (middle), as deﬁned in Pfeiffer et al.": "4.1\nDatasets"
        },
        {
          "Figure 2: Modiﬁed encoder\nlayer proposed in our method (middle), as deﬁned in Pfeiffer et al.": "CMU-MOSEI (Bagher Zadeh et al., 2018): This dataset is comprised of visual, acoustic and textual"
        },
        {
          "Figure 2: Modiﬁed encoder\nlayer proposed in our method (middle), as deﬁned in Pfeiffer et al.": "features for around 23,500 sentences extracted from videos. This dataset is meant to be used to train"
        },
        {
          "Figure 2: Modiﬁed encoder\nlayer proposed in our method (middle), as deﬁned in Pfeiffer et al.": "multi-modal models, but in this work, only the textual inputs were used. The dataset is labelled for"
        },
        {
          "Figure 2: Modiﬁed encoder\nlayer proposed in our method (middle), as deﬁned in Pfeiffer et al.": "sentiment on a scale of [-3,3] and for Ekman emotions (Ekman, 1992) of joy, sadness, anger, surprise,"
        },
        {
          "Figure 2: Modiﬁed encoder\nlayer proposed in our method (middle), as deﬁned in Pfeiffer et al.": "disgust and fear on a scale of [0, 3]. For binary sentiment classiﬁcation,\nthe labels are binarized"
        },
        {
          "Figure 2: Modiﬁed encoder\nlayer proposed in our method (middle), as deﬁned in Pfeiffer et al.": "to negative (labels lesser than 0) and non-negative (labels greater or equal to 0). The emotions are"
        },
        {
          "Figure 2: Modiﬁed encoder\nlayer proposed in our method (middle), as deﬁned in Pfeiffer et al.": "discretized to non-present (label equal to 0) or present (label greater than 0). Multiple emotions can"
        },
        {
          "Figure 2: Modiﬁed encoder\nlayer proposed in our method (middle), as deﬁned in Pfeiffer et al.": "be present for the same sample. The performance of models on this dataset is measured with standard"
        },
        {
          "Figure 2: Modiﬁed encoder\nlayer proposed in our method (middle), as deﬁned in Pfeiffer et al.": "binary accuracy (A) and F1 scores (F1) for each emotion, as well as an overall non-weighted mean"
        },
        {
          "Figure 2: Modiﬁed encoder\nlayer proposed in our method (middle), as deﬁned in Pfeiffer et al.": "accuracy score and an overall weighted F1 score."
        },
        {
          "Figure 2: Modiﬁed encoder\nlayer proposed in our method (middle), as deﬁned in Pfeiffer et al.": "SST-2 (Socher et al., 2013) & IMDB (Maas et al., 2011): SST-2 is comprised of over 60,000 sentences"
        },
        {
          "Figure 2: Modiﬁed encoder\nlayer proposed in our method (middle), as deﬁned in Pfeiffer et al.": "extracted from movie reviews. IMDB contains 50,000 movie reviews. Both are labelled for sentiment"
        },
        {
          "Figure 2: Modiﬁed encoder\nlayer proposed in our method (middle), as deﬁned in Pfeiffer et al.": "analysis in a 2-class split (positive or negative). These datasets were obtained using the HuggingFace"
        },
        {
          "Figure 2: Modiﬁed encoder\nlayer proposed in our method (middle), as deﬁned in Pfeiffer et al.": "Datasets library1. The performance of models on these datasets is measured with the same binary"
        },
        {
          "Figure 2: Modiﬁed encoder\nlayer proposed in our method (middle), as deﬁned in Pfeiffer et al.": "accuracy scores (A) as CMU-MOSEI."
        },
        {
          "Figure 2: Modiﬁed encoder\nlayer proposed in our method (middle), as deﬁned in Pfeiffer et al.": "4.2\nExperimental Setup"
        },
        {
          "Figure 2: Modiﬁed encoder\nlayer proposed in our method (middle), as deﬁned in Pfeiffer et al.": "All experiments use BERTbase (cased) (Devlin et al., 2018) as the pretrained model, which has 12"
        },
        {
          "Figure 2: Modiﬁed encoder\nlayer proposed in our method (middle), as deﬁned in Pfeiffer et al.": "encoder layers and a hidden size of 768. Adapter and AdapterFusion layers are added to each of"
        },
        {
          "Figure 2: Modiﬁed encoder\nlayer proposed in our method (middle), as deﬁned in Pfeiffer et al.": "1https://huggingface.co/datasets"
        },
        {
          "Figure 2: Modiﬁed encoder\nlayer proposed in our method (middle), as deﬁned in Pfeiffer et al.": "4"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table 1: Results on CMU-MOSEI for emotion detection. Adapter: BERT with task-specific",
      "data": [
        {
          "those encoder layers. The classiﬁcation heads are composed of two fully connected linear layers with": "sizes equal to the hidden size of the transformer layer (768) and the number of labels (6) respectively,"
        },
        {
          "those encoder layers. The classiﬁcation heads are composed of two fully connected linear layers with": "and with tanh activation functions. The input of the ﬁrst linear layer is the last hidden state of the"
        },
        {
          "those encoder layers. The classiﬁcation heads are composed of two fully connected linear layers with": "BERT model corresponding to the classiﬁcation token ([CLS]) at the beginning of the input sequence."
        },
        {
          "those encoder layers. The classiﬁcation heads are composed of two fully connected linear layers with": "All models were trained using AdamW (Loshchilov and Hutter, 2017) with a linear rate scheduler, a"
        },
        {
          "those encoder layers. The classiﬁcation heads are composed of two fully connected linear layers with": "learning rate of 1e-5, and a weight decay of 1e-2. All models were trained for 10 epochs with early"
        },
        {
          "those encoder layers. The classiﬁcation heads are composed of two fully connected linear layers with": "stopping after 3 epochs if the validation metric did not improve. The Adapter-Transformers library"
        },
        {
          "those encoder layers. The classiﬁcation heads are composed of two fully connected linear layers with": "(Pfeiffer et al., 2020b) was used to incorporate the Adapter and AdapterFusion layers to the model."
        },
        {
          "those encoder layers. The classiﬁcation heads are composed of two fully connected linear layers with": "The results presented in the following section are averaged over 3 runs."
        },
        {
          "those encoder layers. The classiﬁcation heads are composed of two fully connected linear layers with": "Two types of fusion models were trained: one using a fusion of only CMU-MOSEI tasks (Fusion3:"
        },
        {
          "those encoder layers. The classiﬁcation heads are composed of two fully connected linear layers with": "binary sentiment, 7-class sentiment and emotion classiﬁcation) and one using additional knowledge"
        },
        {
          "those encoder layers. The classiﬁcation heads are composed of two fully connected linear layers with": "from the SST-2 and IMDB sentiment analysis tasks (Fusion5)."
        }
      ],
      "page": 5
    },
    {
      "caption": "Table 1: Results on CMU-MOSEI for emotion detection. Adapter: BERT with task-specific",
      "data": [
        {
          "adapters, Fusion3: BERT with Fusion of adapters for CMU-MOSEI tasks (binary sentiment, 7-class": "sentiment and emotion classiﬁcation), Fusion5: BERT with fusion of adapters for tasks of all datasets"
        },
        {
          "adapters, Fusion3: BERT with Fusion of adapters for CMU-MOSEI tasks (binary sentiment, 7-class": "(CMU-MOSEI tasks and sentiment classiﬁcation tasks of SST-2 & IMDB)"
        },
        {
          "adapters, Fusion3: BERT with Fusion of adapters for CMU-MOSEI tasks (binary sentiment, 7-class": ""
        },
        {
          "adapters, Fusion3: BERT with Fusion of adapters for CMU-MOSEI tasks (binary sentiment, 7-class": "Joy"
        },
        {
          "adapters, Fusion3: BERT with Fusion of adapters for CMU-MOSEI tasks (binary sentiment, 7-class": "A/F1"
        },
        {
          "adapters, Fusion3: BERT with Fusion of adapters for CMU-MOSEI tasks (binary sentiment, 7-class": "66.0/71.7"
        },
        {
          "adapters, Fusion3: BERT with Fusion of adapters for CMU-MOSEI tasks (binary sentiment, 7-class": "66.3/69.0"
        },
        {
          "adapters, Fusion3: BERT with Fusion of adapters for CMU-MOSEI tasks (binary sentiment, 7-class": "67.3/69.4"
        },
        {
          "adapters, Fusion3: BERT with Fusion of adapters for CMU-MOSEI tasks (binary sentiment, 7-class": "67.5/70.5"
        },
        {
          "adapters, Fusion3: BERT with Fusion of adapters for CMU-MOSEI tasks (binary sentiment, 7-class": "67.5/70.7"
        },
        {
          "adapters, Fusion3: BERT with Fusion of adapters for CMU-MOSEI tasks (binary sentiment, 7-class": ""
        }
      ],
      "page": 5
    },
    {
      "caption": "Table 4: Results on CMU-MOSEI for emotion detection for different loss functions. BCE:",
      "data": [
        {
          "Table 3: Number of parameters per model": "All parameters"
        },
        {
          "Table 3: Number of parameters per model": "108.3 M"
        },
        {
          "Table 3: Number of parameters per model": "109.8 M"
        },
        {
          "Table 3: Number of parameters per model": "132.8 M"
        },
        {
          "Table 3: Number of parameters per model": "134.6 M"
        }
      ],
      "page": 6
    },
    {
      "caption": "Table 4: Results on CMU-MOSEI for emotion detection for different loss functions. BCE:",
      "data": [
        {
          "Table 4: Results on CMU-MOSEI for emotion detection for different": "",
          "loss functions. BCE:": ""
        },
        {
          "Table 4: Results on CMU-MOSEI for emotion detection for different": "",
          "loss functions. BCE:": ""
        },
        {
          "Table 4: Results on CMU-MOSEI for emotion detection for different": "Loss",
          "loss functions. BCE:": "Overall"
        },
        {
          "Table 4: Results on CMU-MOSEI for emotion detection for different": "",
          "loss functions. BCE:": "A/F1"
        },
        {
          "Table 4: Results on CMU-MOSEI for emotion detection for different": "BCE",
          "loss functions. BCE:": "81.7/42.8"
        },
        {
          "Table 4: Results on CMU-MOSEI for emotion detection for different": "FL",
          "loss functions. BCE:": "81.6/42.2"
        },
        {
          "Table 4: Results on CMU-MOSEI for emotion detection for different": "PL",
          "loss functions. BCE:": "75.5/53.7"
        }
      ],
      "page": 6
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "This work was supported by Mitacs through the Mitacs Accelerate program and by Airudi.": "References"
        },
        {
          "This work was supported by Mitacs through the Mitacs Accelerate program and by Airudi.": "Muhammad Abdul-Mageed and Lyle Ungar. EmoNet: Fine-grained emotion detection with gated"
        },
        {
          "This work was supported by Mitacs through the Mitacs Accelerate program and by Airudi.": "the 55th Annual Meeting of\nthe Association for\nrecurrent neural networks.\nIn Proceedings of"
        },
        {
          "This work was supported by Mitacs through the Mitacs Accelerate program and by Airudi.": "Computational Linguistics (Volume 1: Long Papers), pages 718–728, Vancouver, Canada, July"
        },
        {
          "This work was supported by Mitacs through the Mitacs Accelerate program and by Airudi.": "2017. Association for Computational Linguistics.\ndoi: 10.18653/v1/P17-1067. URL https:"
        },
        {
          "This work was supported by Mitacs through the Mitacs Accelerate program and by Airudi.": "//aclanthology.org/P17-1067."
        },
        {
          "This work was supported by Mitacs through the Mitacs Accelerate program and by Airudi.": "Francisca Adoma Acheampong, Henry Nunoo-Mensah, and Wenyu Chen. Transformer models for"
        },
        {
          "This work was supported by Mitacs through the Mitacs Accelerate program and by Airudi.": "text-based emotion detection: a review of bert-based approaches. Artiﬁcial Intelligence Review,"
        },
        {
          "This work was supported by Mitacs through the Mitacs Accelerate program and by Airudi.": "Feb 2021.\nISSN 1573-7462. doi: 10.1007/s10462-021-09958-2. URL https://doi.org/10."
        },
        {
          "This work was supported by Mitacs through the Mitacs Accelerate program and by Airudi.": "1007/s10462-021-09958-2."
        },
        {
          "This work was supported by Mitacs through the Mitacs Accelerate program and by Airudi.": "AmirAli Bagher Zadeh, Paul Pu Liang, Soujanya Poria, Erik Cambria, and Louis-Philippe Morency."
        },
        {
          "This work was supported by Mitacs through the Mitacs Accelerate program and by Airudi.": "Multimodal language analysis in the wild: CMU-MOSEI dataset and interpretable dynamic fusion"
        },
        {
          "This work was supported by Mitacs through the Mitacs Accelerate program and by Airudi.": "graph. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics"
        },
        {
          "This work was supported by Mitacs through the Mitacs Accelerate program and by Airudi.": "(Volume 1: Long Papers), pages 2236–2246, Melbourne, Australia, July 2018. Association for"
        },
        {
          "This work was supported by Mitacs through the Mitacs Accelerate program and by Airudi.": "Computational Linguistics. doi: 10.18653/v1/P18-1208. URL https://aclanthology.org/"
        },
        {
          "This work was supported by Mitacs through the Mitacs Accelerate program and by Airudi.": "P18-1208."
        },
        {
          "This work was supported by Mitacs through the Mitacs Accelerate program and by Airudi.": "Kevin Clark, Minh-Thang Luong, Urvashi Khandelwal, Christopher D. Manning, and Quoc V. Le."
        },
        {
          "This work was supported by Mitacs through the Mitacs Accelerate program and by Airudi.": "Bam! born-again multi-task networks for natural language understanding. CoRR, abs/1907.04829,"
        },
        {
          "This work was supported by Mitacs through the Mitacs Accelerate program and by Airudi.": "2019. URL http://arxiv.org/abs/1907.04829."
        },
        {
          "This work was supported by Mitacs through the Mitacs Accelerate program and by Airudi.": "Jean-Benoit Delbrouck, Noé Tits, Mathilde Brousmiche, and Stéphane Dupont. A transformer-based"
        },
        {
          "This work was supported by Mitacs through the Mitacs Accelerate program and by Airudi.": "joint-encoding for emotion recognition and sentiment analysis. CoRR, abs/2006.15955, 2020."
        },
        {
          "This work was supported by Mitacs through the Mitacs Accelerate program and by Airudi.": "URL https://arxiv.org/abs/2006.15955."
        },
        {
          "This work was supported by Mitacs through the Mitacs Accelerate program and by Airudi.": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: pre-training of deep"
        },
        {
          "This work was supported by Mitacs through the Mitacs Accelerate program and by Airudi.": "bidirectional\ntransformers for\nlanguage understanding.\nCoRR, abs/1810.04805, 2018.\nURL"
        },
        {
          "This work was supported by Mitacs through the Mitacs Accelerate program and by Airudi.": "http://arxiv.org/abs/1810.04805."
        },
        {
          "This work was supported by Mitacs through the Mitacs Accelerate program and by Airudi.": "Paul Ekman. An argument for basic emotions. Cognition and Emotion, 6(3-4):169–200, 1992. doi:"
        }
      ],
      "page": 7
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "Gesmundo, Mona Attariyan, and Sylvain Gelly. Parameter-efﬁcient\ntransfer learning for NLP."
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "CoRR, abs/1902.00751, 2019. URL http://arxiv.org/abs/1902.00751."
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Dollár. Focal loss for dense object"
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "detection, 2018."
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "Xiaodong Liu, Pengcheng He, Weizhu Chen, and Jianfeng Gao. Multi-task deep neural networks for"
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "natural language understanding. CoRR, abs/1901.11504, 2019a. URL http://arxiv.org/abs/"
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "1901.11504."
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "Xiaodong Liu, Pengcheng He, Weizhu Chen, and Jianfeng Gao.\nImproving multi-task deep neural"
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "networks via knowledge distillation for natural language understanding. CoRR, abs/1904.09482,"
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "2019b. URL http://arxiv.org/abs/1904.09482."
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike"
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized BERT pretraining"
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "approach. CoRR, abs/1907.11692, 2019c. URL http://arxiv.org/abs/1907.11692."
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "Ilya Loshchilov and Frank Hutter. Fixing weight decay regularization in adam. CoRR, abs/1711.05101,"
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "2017. URL http://arxiv.org/abs/1711.05101."
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "Luyao Ma, Long Zhang, Wei Ye, and Wenhui Hu. PKUSE at SemEval-2019 task 3: Emotion detection"
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "with emotion-oriented neural attention network. In Proceedings of the 13th International Workshop"
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "on Semantic Evaluation, pages 287–291, Minneapolis, Minnesota, USA, June 2019. Association"
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "for Computational Linguistics.\ndoi: 10.18653/v1/S19-2049. URL https://aclanthology."
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "org/S19-2049."
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher"
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "Potts. Learning word vectors for sentiment analysis.\nIn Proceedings of the 49th Annual Meeting of"
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "the Association for Computational Linguistics: Human Language Technologies, pages 142–150,"
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "Portland, Oregon, USA, June 2011. Association for Computational Linguistics. URL https:"
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "//aclanthology.org/P11-1015."
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "Sungjoon Park, Jiseon Kim, Jaeyeol Jeon, Heeyoung Park, and Alice Oh.\nToward dimensional"
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "emotion detection from categorical emotion annotations. CoRR, abs/1911.02499, 2019. URL"
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "http://arxiv.org/abs/1911.02499."
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "Jonas Pfeiffer, Aishwarya Kamath, Andreas Rücklé, Kyunghyun Cho, and Iryna Gurevych. Adapter-"
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "fusion: Non-destructive task composition for transfer learning. CoRR, abs/2005.00247, 2020a."
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "URL https://arxiv.org/abs/2005.00247."
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "Jonas Pfeiffer, Andreas Rücklé, Clifton Poth, Aishwarya Kamath,\nIvan Vuli´c, Sebastian Ruder,"
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "Kyunghyun Cho, and Iryna Gurevych. Adapterhub: A framework for adapting transformers.\nIn"
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "Proceedings of\nthe 2020 Conference on Empirical Methods in Natural Language Processing:"
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "System Demonstrations, pages 46–54, 2020b."
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "Sentence-Level Emotion Detection from Text\nDibyendu Seal, Uttam Roy,\nand Rohini Basak."
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "Based\non\nSemantic Rules,\npages\n423–430.\n06\n2019.\nISBN 978-981-13-7165-3.\ndoi:"
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "10.1007/978-981-13-7166-0_42."
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, Andrew Ng, and"
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "Christopher Potts. Recursive deep models for semantic compositionality over a sentiment treebank."
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,"
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "pages 1631–1642, Seattle, Washington, USA, October 2013. Association for Computational"
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "Linguistics. URL https://aclanthology.org/D13-1170."
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "Li Im Tan, Wai San Phang, Kim On Chin, and Anthony Patricia. Rule-based sentiment analysis for"
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "ﬁnancial news.\nIn 2015 IEEE International Conference on Systems, Man, and Cybernetics, pages"
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "1601–1606, 2015. doi: 10.1109/SMC.2015.283."
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "Duyu Tang, Bing Qin, Xiaocheng Feng, and Ting Liu. Target-dependent sentiment classiﬁcation with"
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "long short term memory. CoRR, abs/1512.01100, 2015. URL http://arxiv.org/abs/1512."
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "01100."
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "Orizu Udochukwu and Yulan He. A rule-based approach to implicit emotion detection in text.\nIn"
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "NLDB, 2015."
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "Zhilin Yang, Zihang Dai, Yiming Yang, Jaime G. Carbonell, Ruslan Salakhutdinov, and Quoc V. Le."
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "Xlnet: Generalized autoregressive pretraining for language understanding. CoRR, abs/1906.08237,"
        },
        {
          "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea": "2019. URL http://arxiv.org/abs/1906.08237."
        }
      ],
      "page": 8
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "EmoNet: Fine-grained emotion detection with gated recurrent neural networks",
      "authors": [
        "Muhammad Abdul",
        "Lyle Ungar"
      ],
      "year": "2017",
      "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/P17-1067"
    },
    {
      "citation_id": "2",
      "title": "Transformer models for text-based emotion detection: a review of bert-based approaches",
      "authors": [
        "Francisca Adoma",
        "Henry Nunoo-Mensah",
        "Wenyu Chen"
      ],
      "year": "2021",
      "venue": "Artificial Intelligence Review",
      "doi": "10.1007/s10462-021-09958-2"
    },
    {
      "citation_id": "3",
      "title": "Multimodal language analysis in the wild: CMU-MOSEI dataset and interpretable dynamic fusion graph",
      "authors": [
        "Amirali Bagher Zadeh",
        "Paul Liang",
        "Soujanya Poria",
        "Erik Cambria",
        "Louis-Philippe Morency"
      ],
      "year": "2018",
      "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/P18-1208"
    },
    {
      "citation_id": "4",
      "title": "Bam! born-again multi-task networks for natural language understanding",
      "authors": [
        "Kevin Clark",
        "Minh-Thang Luong",
        "Urvashi Khandelwal",
        "Christopher Manning",
        "V Quoc",
        "Le"
      ],
      "year": "2019",
      "venue": "Bam! born-again multi-task networks for natural language understanding"
    },
    {
      "citation_id": "5",
      "title": "A transformer-based joint-encoding for emotion recognition and sentiment analysis",
      "authors": [
        "Jean-Benoit Delbrouck",
        "Noé Tits",
        "Mathilde Brousmiche",
        "Stéphane Dupont"
      ],
      "year": "2006",
      "venue": "A transformer-based joint-encoding for emotion recognition and sentiment analysis"
    },
    {
      "citation_id": "6",
      "title": "BERT: pre-training of deep bidirectional transformers for language understanding",
      "authors": [
        "Jacob Devlin",
        "Ming-Wei Chang",
        "Kenton Lee",
        "Kristina Toutanova"
      ],
      "year": "2018",
      "venue": "BERT: pre-training of deep bidirectional transformers for language understanding"
    },
    {
      "citation_id": "7",
      "title": "An argument for basic emotions",
      "authors": [
        "Paul Ekman"
      ],
      "year": "1992",
      "venue": "Cognition and Emotion",
      "doi": "10.1080/02699939208411068"
    },
    {
      "citation_id": "8",
      "title": "Parameter-efficient transfer learning for NLP",
      "authors": [
        "Neil Houlsby",
        "Andrei Giurgiu",
        "Stanislaw Jastrzebski",
        "Bruna Morrone",
        "Quentin De Laroussilhe",
        "Andrea Gesmundo",
        "Mona Attariyan",
        "Sylvain Gelly"
      ],
      "year": "2019",
      "venue": "Parameter-efficient transfer learning for NLP"
    },
    {
      "citation_id": "9",
      "title": "Focal loss for dense object detection",
      "authors": [
        "Tsung-Yi Lin",
        "Priya Goyal",
        "Ross Girshick",
        "Kaiming He",
        "Piotr Dollár"
      ],
      "year": "2018",
      "venue": "Focal loss for dense object detection"
    },
    {
      "citation_id": "10",
      "title": "Multi-task deep neural networks for natural language understanding",
      "authors": [
        "Xiaodong Liu",
        "Pengcheng He",
        "Weizhu Chen",
        "Jianfeng Gao"
      ],
      "year": "2019",
      "venue": "Multi-task deep neural networks for natural language understanding"
    },
    {
      "citation_id": "11",
      "title": "Improving multi-task deep neural networks via knowledge distillation for natural language understanding",
      "authors": [
        "Xiaodong Liu",
        "Pengcheng He",
        "Weizhu Chen",
        "Jianfeng Gao"
      ],
      "year": "2019",
      "venue": "Improving multi-task deep neural networks via knowledge distillation for natural language understanding"
    },
    {
      "citation_id": "12",
      "title": "Roberta: A robustly optimized BERT pretraining approach",
      "authors": [
        "Yinhan Liu",
        "Myle Ott",
        "Naman Goyal",
        "Jingfei Du",
        "Mandar Joshi",
        "Danqi Chen",
        "Omer Levy",
        "Mike Lewis",
        "Luke Zettlemoyer",
        "Veselin Stoyanov"
      ],
      "year": "2019",
      "venue": "Roberta: A robustly optimized BERT pretraining approach"
    },
    {
      "citation_id": "13",
      "title": "Fixing weight decay regularization in adam",
      "authors": [
        "Ilya Loshchilov",
        "Frank Hutter"
      ],
      "year": "2017",
      "venue": "Fixing weight decay regularization in adam"
    },
    {
      "citation_id": "14",
      "title": "PKUSE at SemEval-2019 task 3: Emotion detection with emotion-oriented neural attention network",
      "authors": [
        "Luyao Ma",
        "Long Zhang",
        "Wei Ye",
        "Wenhui Hu"
      ],
      "year": "2019",
      "venue": "Proceedings of the 13th International Workshop on Semantic Evaluation",
      "doi": "10.18653/v1/S19-2049"
    },
    {
      "citation_id": "15",
      "title": "Learning word vectors for sentiment analysis",
      "authors": [
        "Andrew Maas",
        "Raymond Daly",
        "Peter Pham",
        "Dan Huang",
        "Andrew Ng",
        "Christopher Potts"
      ],
      "year": "2011",
      "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies"
    },
    {
      "citation_id": "16",
      "title": "Toward dimensional emotion detection from categorical emotion annotations",
      "authors": [
        "Sungjoon Park",
        "Jiseon Kim",
        "Jaeyeol Jeon",
        "Heeyoung Park",
        "Alice Oh"
      ],
      "year": "2019",
      "venue": "Toward dimensional emotion detection from categorical emotion annotations"
    },
    {
      "citation_id": "17",
      "title": "Adapterfusion: Non-destructive task composition for transfer learning",
      "authors": [
        "Jonas Pfeiffer",
        "Aishwarya Kamath",
        "Andreas Rücklé",
        "Kyunghyun Cho",
        "Iryna Gurevych"
      ],
      "year": "2020",
      "venue": "Adapterfusion: Non-destructive task composition for transfer learning"
    },
    {
      "citation_id": "18",
      "title": "Adapterhub: A framework for adapting transformers",
      "authors": [
        "Jonas Pfeiffer",
        "Andreas Rücklé",
        "Clifton Poth",
        "Aishwarya Kamath",
        "Ivan Vulić",
        "Sebastian Ruder",
        "Kyunghyun Cho",
        "Iryna Gurevych"
      ],
      "year": "2020",
      "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations"
    },
    {
      "citation_id": "19",
      "title": "Sentence-Level Emotion Detection from Text Based on Semantic Rules",
      "authors": [
        "Dibyendu Seal",
        "Uttam Roy",
        "Rohini Basak"
      ],
      "year": "2019",
      "venue": "Sentence-Level Emotion Detection from Text Based on Semantic Rules",
      "doi": "10.1007/978-981-13-7166-0_42"
    },
    {
      "citation_id": "20",
      "title": "Recursive deep models for semantic compositionality over a sentiment treebank",
      "authors": [
        "Richard Socher",
        "Alex Perelygin",
        "Jean Wu",
        "Jason Chuang",
        "Christopher Manning",
        "Andrew Ng",
        "Christopher Potts"
      ],
      "year": "2013",
      "venue": "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "21",
      "title": "Rule-based sentiment analysis for financial news",
      "authors": [
        "Li Im",
        "Wai San Phang",
        "Kim On Chin",
        "Anthony Patricia"
      ],
      "year": "2015",
      "venue": "2015 IEEE International Conference on Systems, Man, and Cybernetics",
      "doi": "10.1109/SMC.2015.283"
    },
    {
      "citation_id": "22",
      "title": "Orizu Udochukwu and Yulan He. A rule-based approach to implicit emotion detection in text",
      "authors": [
        "Duyu Tang",
        "Bing Qin",
        "Xiaocheng Feng",
        "Ting Liu"
      ],
      "year": "2015",
      "venue": "NLDB"
    },
    {
      "citation_id": "23",
      "title": "Xlnet: Generalized autoregressive pretraining for language understanding",
      "authors": [
        "Zhilin Yang",
        "Zihang Dai",
        "Yiming Yang",
        "Jaime Carbonell",
        "Ruslan Salakhutdinov",
        "V Quoc",
        "Le"
      ],
      "year": "2019",
      "venue": "Xlnet: Generalized autoregressive pretraining for language understanding"
    }
  ]
}