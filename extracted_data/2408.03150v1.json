{
  "paper_id": "2408.03150v1",
  "title": "Conditioning Llms With Emotion In Neural Machine Translation",
  "published": "2024-08-06T12:49:33Z",
  "authors": [
    "Charles Brazier",
    "Jean-Luc Rouas"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Large Language Models (LLMs) have shown remarkable performance in Natural Language Processing tasks, including Machine Translation (MT). In this work, we propose a novel MT pipeline that integrates emotion information extracted from a Speech Emotion Recognition (SER) model into LLMs to enhance translation quality. We first fine-tune five existing LLMs on the Libri-trans dataset and select the most performant model. Subsequently, we augment LLM prompts with different dimensional emotions and train the selected LLM under these different configurations. Our experiments reveal that integrating emotion information, especially arousal, into LLM prompts leads to notable improvements in translation quality.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Large Language Models (LLMs) are transformerbased  (Vaswani et al., 2017)  deep learning models designed to understand and generate natural language text by predicting the probability of the next token in a sequence. LLMs excel across various Natural Language Processing (NLP) tasks, such as information retrieval  (Zhu et al., 2023b) , instruction following  (Ouyang et al., 2022) , or engaging in chatbot discussions  (OpenAI, 2022) .\n\nAmong NLP tasks, LLMs have shown great capacities in Machine Translation (MT)  (Zhu et al., 2023a) , the task of translating a text from one language to another. Previous research has enhanced LLM performance in MT through various strategies, including optimized prompting techniques  (Zhang et al., 2023) , in-context learning features  (Brown et al., 2020)  to improve translation quality over time  (Moslem et al., 2023a,b) , and a two-stage fine-tuning method composed of a first fine-tuning on monolingual data to learn general linguistic knowledge followed by a second fine-tuning on parallel data  (Xu et al., 2023)  that establishes the current state-of-the-art method in MT.\n\nApart from LLMs, previous works in MT have demonstrated the possibility of controlling the translation by adding extra information to the model that is not explicitly specified in the source sentence to be translated, and that can influence the translation. Existing works in that direction focused on the control of politeness  (Sennrich et al., 2019) , gender  (Vanmassenhove et al., 2018; Gaido et al., 2023) , or emotion  (Brazier and Rouas, 2024)  of the translation and showed that this extra information helps improve translation quality.\n\nIn this work, we propose to improve translation performances of an LLM-based model by adding emotion as extra information in the prompt of the model to condition the translation. This work relies on the fact that words can be classified into emotion categories, leading to affective word lists  (Pennebaker et al., 2001) . Thus, conditioning the translation with a specific emotion would use a suitable vocabulary in the translation. In  Brazier and Rouas (2024) , authors showed that adding arousal information, reflecting the level of stimulation (ranging from calm to excited), extracted from the voice and added at the start of each input text sentence, helps improve translation performances. In the following, we study the behavior of several LLMs for the task of MT when emotion dimensions are added to input prompts.\n\nTo address this problem, we first fine-tune several existing LLMs for the task of English-to-French text-to-text translation. Then, after selecting the best model as baseline for our experiments, we compute for each input sentence its emotional dimensions with the help of a state-of-the-art Speech Emotion Recognition (SER) model applied to audio recordings. Finally, we compare translation performance with and without the addition of each emotional dimension as extra information added to each input prompt. We show that emotion improves translation (BLEU and COMET), especially in the case of arousal.\n\nIn this work, we aim at combining an LLM-based MT model with emotion information to improve translation performances. In the following, we first describe a close work that performs this combination without the use of an LLM. Then, we list several existing LLMs that can be used as a baseline for our MT task.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Machine Translation With Emotion",
      "text": "To our knowledge, the only work that combines an MT model with emotion information is described in  Brazier and Rouas (2024) . In this study, the authors utilize a state-of-the-art Speech Emotion Recognition (SER) model  (Wagner et al., 2023)  to automatically estimate dimensional emotion values, including arousal, dominance, and valence, for each audio recording associated with text sentence. These values are then transformed into unique emotion tokens, either positive or negative, which are added at the beginning of tokenized input text sentences. The authors report an increase in translation BLEU score, especially when adding arousal tokens at the start of input sentences.\n\nThe MT model used for their experiments is a transformer-based encoder-decoder architecture, comprising 6 layers for the encoder, 6 layers for the decoder, and 4 attention heads in each selfattention layer. The model is trained on the Libritrans dataset  (Kocabiyikoglu et al., 2018) , which includes triplets of English recordings, English texts, and French texts, totaling 235 hours of data (230h for train, 2h for dev, and 3.5h for test). The model performs English-to-French translation.\n\nIn this work, we propose to use the same translation pipeline, but instead of using a specific MT model, we replace it with a fine-tuned LLM. Since LLMs have more trainable parameters, we anticipate improved translation performances. However, our objective is to observe how LLMs behave when augmented with emotion information in the input prompt.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Llm Selection For Mt",
      "text": "Recent advances in Large Language Modeling have significantly expanded the capabilities of LLMs across various tasks, such as reasoning, coding, or mathematics. Among the numerous existing LLMs  (Chiang et al., 2024) , the best-performing models are  GPT-4 (OpenAI, 2023) , LLaMA 3 (AI@Meta, 2024), Gemini 1.5  (Team, 2024) , or Claude 3  (An-thropic, 2024) .\n\nFor the task of MT, we restrict our LLM selection to models that are open-source, promising (high rank in the LLM arena 1  , or already fine-tuned to the MT task), and that only contain 7 billion (7B) of parameters. We select 5 different models that are described in the following.\n\nThe first selected LLM is Mistral-7B-v0.1 2  , an open-source model  (Jiang et al., 2023)  which ranks among the best 7B-parameter models.\n\nAs the second model, we select Mistral-7B-Instruct-v0.2 3  . The model is similar to the previous model but has been fine-tuned to follow instructions.\n\nOur third selected model is TowerBase-7B-v0.1 4  . This model (Alves et al., 2024) is based on LLaMA 2 (AI@Meta, 2023) and its training has been continued on multilingual data (including English and French monolingual data, as well as bilingual data).\n\nSimilarly to Mistral, we select TowerInstruct-7B-v0.2 5  as our fourth model. This model is a variant of the previous one that has been fine-tuned to follow instructions including translations.\n\nFinally, as our fifth model, we select the SOTA MT model ALMA-7B-R 6  , which is based on LLaMA 2 (AI@Meta, 2023), and fine-tuned on monolingual and parallel data. However, the data used for fine-tuning does not include French.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Experiments And Results",
      "text": "In this section, we describe our experiments for the task of English-to-French text-to-text translation. We conduct two successive experiments. Firstly, we fine-tune five existing LLMs on the Libri-trans dataset  (Kocabiyikoglu et al., 2018)  and consider the best model as a foundation for our second experiment. Secondly, we fine-tune the selected LLM on the same task but under different configurations. Henceforth, prompts used for translation include each emotion dimension that is automatically estimated from the SER model.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Fine-Tuning Llms On Libri-Trans",
      "text": "To perform MT with LLMs, the task needs to be converted into a language modeling problem with the use of prompts. In this work, we perform zeroshot prompting and follow two different templates.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Model",
      "text": "The first template will be applied to Mistral-7B-v0.1 and TowerBase-7B-v0.1:\n\nEnglish: <src txt> \\n French: <tgt txt>\n\n(1)\n\nwhere <src txt> and <tgt txt> refer to the English source sentence and the French target sentence respectively.\n\nThe second template will be applied to models that follow instructions, namely Mistral-7B-Instruct-v0.2, TowerInstruct-7B-v0.2, and ALMA-7B-R: (2) To fine-tune LLMs, we employ QLoRA  (Hu et al., 2022; Dettmers et al., 2023) , a Parameter Efficient Fine-Tuning method  (Mangrulkar et al., 2022 ) that allows training with significantly fewer parameters. Additionally, we apply a 4-bit quantization to reduce memory usage while maintaining 16-bit precision during computation.\n\nWe provide two distinct metrics to evaluate our MT models. The first metric is the BLEU score computed using sacrebleu  (Post, 2018) . It reflects the degree of lexical matches (number of common n-grams) between the proposed translation and its corresponding reference. The second metric is the COMET score 7  (Rei et al., 2022) . It is computed from a trained model and reflects translation quality between translation, reference, and also the source sentence. According to the metric ranking presented in  Freitag et al. (2022) , we rely more on the COMET score than on the BLEU score.\n\nTable  1  showcases the results of our first experiment. In this table, we report BLEU and COMET scores of the five selected LLMs on both the dev and test sets of the Libri-trans dataset.\n\n7 https://huggingface.co/Unbabel/wmt22-comet-da\n\nThe table highlights three models, Mistral-7B-v0.1, Mistral-7B-Instruct-v0.2, and TowerBase-7B-v0.1, that attain high BLEU and COMET scores. They obtain COMET scores ranging from 72.1 to 73.8 on the dev set and from 71.9 to 72.9 on the test set. Additionally, their BLEU scores ranged from 16.0 to 24.0 on the dev set and from 16.7 to 20.6 on the test set. While COMET scores are not meant to be interpretable (but enable the comparison between models), BLEU scores indicate, on average, a translation that is more or less clear with numerous grammatical errors. These low BLEU scores are comparable to performances of previous works on this dataset  (Zhao et al., 2021; Brazier and Rouas, 2024)  and are mainly caused by the nature of the data (audiobooks with literary vocabulary).\n\nAlso, it is worth noting that two models, TowerInstruct-7B-v0.2 and ALMA-7B-R, exhibit poor performances in MT when fine-tuned on Libritrans. In the case of ALMA-7B-R, this can be explained by the fact that French is not among the languages included in the data used to pre-train the model. Thus, the model fails at predicting French text.\n\nAs additional training information, all LLMs have obtained their optimal state in a maximum of 5 epochs. This represents a training time of 3 hours on a GPU NVIDIA A100 for each model. This fast fine-tuning time is due to QLoRA and 4-bit quantization strategies.\n\nTo summarize, the best machine translation performances were achieved with the TowerBase-7B-v0.1. This LLM serves as a baseline and foundation model for the following experiment.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Fine-Tuning Llms With Emotion",
      "text": "The second experiment aims at observing the behavior of our LLM-based TowerBase-7B-v0.1 model on the task of English-to-French Machine Translation when emotion information is added to the prompt before translation.\n\nAs a first step, we estimate the emotion of each English recording present in the Libri-trans dataset. Following the same methodology as  Brazier and Rouas (2024) , we compute dimensional emotion values for arousal, dominance, and valence with the help of a trained SER model  (Wagner et al., 2023) . Emotion values range between 0 and 1 and are correctly balanced (medians between 0.4 and 0.6, see  Brazier and Rouas (2024) ).\n\nAs a second step, we create specific prompts that include the emotion information in the text. For this purpose, we propose 3 different templates. The first template adds emotion information before the source sentence:\n\nEnglish <status> <emotion>: <src txt> \\n French: <tgt txt>\n\n(3) where status is replaced by either with or without if the emotion value is higher or lower than 0.5 respectively, emotion is replaced by either arousal, dominance, or valence, src txt represents the English source sentence, and tgt txt represents the French target translation.\n\nThe second template adds emotion information before the target sentence:\n\nEnglish: <src txt> \\n French <status> <emotion>: <tgt txt> (4) The third template is inspired from  Brazier and Rouas (2024) , where emotion information is added as a discrete token at the start of the source sentence:\n\nEnglish: [<emotion> <polarity>] <src txt> \\n French: <tgt txt> (5) where polarity is replaced by either positive or negative if the emotion value is higher or lower than 0.5 respectively.\n\nIn this experiment, the TowerBase-7B-v0.1 model is retrained from its initial state and not from the training checkpoint obtained after the previous experiment. In the following, all models obtain their best performances in less than 5 training epochs.\n\nTable  2  showcases the results of our second experiment. It reports BLEU and COMET scores of the selected TowerBase-7B-v0.1 model on the dev and test sets of the Libri-trans dataset under different configurations. The first line mentions the score of the LLM obtained in the previous experiment and serves as a baseline for the second experiment. The other lines correspond to the model trained with different emotions (arousal, dominance, or valence), and with different prompts (the numbers 3, 4, and 5 refer to their equation number).\n\nWe first remark that, except in the case of dom-inance5, all COMET scores improved, compared to their baseline. This reflects a better translation quality when adding emotion information to the prompts. The best COMET scores are obtained when arousal information is added to the prompt using Equation 3. In this configuration, COMET scores are increased by +1.1 and +1.4 for the dev and test sets of Libri-trans respectively. Secondly, we observe that BLEU scores show improvements only for specific models. The best BLEU scores are obtained when arousal information is added to the prompt using Equation  4 . In this configuration, BLEU scores increase by +1.6 and +3.5 for the dev and test sets of Libri-trans respectively. However, due to the low ranking of BLEU  (Freitag et al., 2022) , we do not conduct further analysis based on this metric.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Model",
      "text": "In summary, incorporating emotion information into the translation process appears to enhance translation quality. The highest scores are achieved when utilizing the arousal dimension with Equation 3 or 4. This finding aligns with the results reported in  Brazier and Rouas (2024) .",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Conclusion",
      "text": "We proposed a new MT pipeline that combines an LLM-based model and emotion information extracted from a SER model to improve translation performances. We obtain the best performances when the arousal value is added to the LLM prompt.\n\nAs future work, we will apply our method to other multilingual datasets including  Must-C (Di Gangi et al., 2019) . Unlike the Libri-trans dataset, which consists of literary text read by speakers, Must-C encompasses various speech types, such as TED talks, which can offer more emotional variability and therefore further enhance translation performance. We also plan to extend our method to the speech-to-text task, also known as Speech translation.",
      "page_start": 6,
      "page_end": 6
    }
  ],
  "figures": [],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "pecially arousal,\ninto LLM prompts leads to": "notable improvements in translation quality.",
          "model to condition the translation. This work relies": ""
        },
        {
          "pecially arousal,\ninto LLM prompts leads to": "",
          "model to condition the translation. This work relies": "on the fact that words can be classified into emo-"
        },
        {
          "pecially arousal,\ninto LLM prompts leads to": "",
          "model to condition the translation. This work relies": "tion categories, leading to affective word lists (Pen-"
        },
        {
          "pecially arousal,\ninto LLM prompts leads to": "1\nIntroduction",
          "model to condition the translation. This work relies": ""
        },
        {
          "pecially arousal,\ninto LLM prompts leads to": "",
          "model to condition the translation. This work relies": "nebaker et al., 2001). Thus, conditioning the trans-"
        },
        {
          "pecially arousal,\ninto LLM prompts leads to": "Large Language Models (LLMs) are transformer-",
          "model to condition the translation. This work relies": "lation with a specific emotion would use a suitable"
        },
        {
          "pecially arousal,\ninto LLM prompts leads to": "based (Vaswani et al., 2017) deep learning models",
          "model to condition the translation. This work relies": "vocabulary in the translation. In Brazier and Rouas"
        },
        {
          "pecially arousal,\ninto LLM prompts leads to": "designed to understand and generate natural\nlan-",
          "model to condition the translation. This work relies": "(2024), authors showed that adding arousal infor-"
        },
        {
          "pecially arousal,\ninto LLM prompts leads to": "guage text by predicting the probability of the next",
          "model to condition the translation. This work relies": "mation, reflecting the level of stimulation (ranging"
        },
        {
          "pecially arousal,\ninto LLM prompts leads to": "token in a sequence. LLMs excel across various",
          "model to condition the translation. This work relies": "from calm to excited), extracted from the voice and"
        },
        {
          "pecially arousal,\ninto LLM prompts leads to": "Natural Language Processing (NLP) tasks, such as",
          "model to condition the translation. This work relies": "added at the start of each input text sentence, helps"
        },
        {
          "pecially arousal,\ninto LLM prompts leads to": "information retrieval (Zhu et al., 2023b),\ninstruc-",
          "model to condition the translation. This work relies": "improve translation performances.\nIn the follow-"
        },
        {
          "pecially arousal,\ninto LLM prompts leads to": "tion following (Ouyang et al., 2022), or engaging",
          "model to condition the translation. This work relies": "ing, we study the behavior of several LLMs for the"
        },
        {
          "pecially arousal,\ninto LLM prompts leads to": "in chatbot discussions (OpenAI, 2022).",
          "model to condition the translation. This work relies": "task of MT when emotion dimensions are added to"
        },
        {
          "pecially arousal,\ninto LLM prompts leads to": "Among NLP tasks, LLMs have shown great ca-",
          "model to condition the translation. This work relies": "input prompts."
        },
        {
          "pecially arousal,\ninto LLM prompts leads to": "pacities in Machine Translation (MT) (Zhu et al.,",
          "model to condition the translation. This work relies": "To address this problem, we first fine-tune sev-"
        },
        {
          "pecially arousal,\ninto LLM prompts leads to": "2023a), the task of translating a text from one lan-",
          "model to condition the translation. This work relies": "eral\nexisting LLMs\nfor\nthe\ntask of English-to-"
        },
        {
          "pecially arousal,\ninto LLM prompts leads to": "guage to another. Previous research has enhanced",
          "model to condition the translation. This work relies": "French text-to-text\ntranslation.\nThen,\nafter\nse-"
        },
        {
          "pecially arousal,\ninto LLM prompts leads to": "LLM performance in MT through various strate-",
          "model to condition the translation. This work relies": "lecting the best model as baseline for our experi-"
        },
        {
          "pecially arousal,\ninto LLM prompts leads to": "gies,\nincluding optimized prompting techniques",
          "model to condition the translation. This work relies": "ments, we compute for each input sentence its emo-"
        },
        {
          "pecially arousal,\ninto LLM prompts leads to": "(Zhang et al., 2023),\nin-context\nlearning features",
          "model to condition the translation. This work relies": "tional dimensions with the help of a state-of-the-art"
        },
        {
          "pecially arousal,\ninto LLM prompts leads to": "(Brown et al., 2020) to improve translation quality",
          "model to condition the translation. This work relies": "Speech Emotion Recognition (SER) model applied"
        },
        {
          "pecially arousal,\ninto LLM prompts leads to": "over time (Moslem et al., 2023a,b), and a two-stage",
          "model to condition the translation. This work relies": "to audio recordings.\nFinally, we compare trans-"
        },
        {
          "pecially arousal,\ninto LLM prompts leads to": "fine-tuning method composed of a first fine-tuning",
          "model to condition the translation. This work relies": "lation performance with and without the addition"
        },
        {
          "pecially arousal,\ninto LLM prompts leads to": "on monolingual data to learn general\nlinguistic",
          "model to condition the translation. This work relies": "of each emotional dimension as extra information"
        },
        {
          "pecially arousal,\ninto LLM prompts leads to": "knowledge followed by a second fine-tuning on",
          "model to condition the translation. This work relies": "added to each input prompt. We show that emo-"
        },
        {
          "pecially arousal,\ninto LLM prompts leads to": "parallel data (Xu et al., 2023) that establishes the",
          "model to condition the translation. This work relies": "tion improves translation (BLEU and COMET),"
        },
        {
          "pecially arousal,\ninto LLM prompts leads to": "current state-of-the-art method in MT.",
          "model to condition the translation. This work relies": "especially in the case of arousal."
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Abstract": "",
          "Apart from LLMs, previous works in MT have": "demonstrated the possibility of\ncontrolling the"
        },
        {
          "Abstract": "Large Language Models (LLMs) have shown",
          "Apart from LLMs, previous works in MT have": ""
        },
        {
          "Abstract": "",
          "Apart from LLMs, previous works in MT have": "translation by adding extra\ninformation to the"
        },
        {
          "Abstract": "remarkable performance in Natural Language",
          "Apart from LLMs, previous works in MT have": ""
        },
        {
          "Abstract": "",
          "Apart from LLMs, previous works in MT have": "model that is not explicitly specified in the source"
        },
        {
          "Abstract": "Processing tasks,\nincluding Machine Transla-",
          "Apart from LLMs, previous works in MT have": ""
        },
        {
          "Abstract": "",
          "Apart from LLMs, previous works in MT have": "sentence to be translated, and that can influence"
        },
        {
          "Abstract": "tion (MT). In this work, we propose a novel MT",
          "Apart from LLMs, previous works in MT have": ""
        },
        {
          "Abstract": "pipeline that integrates emotion information ex-",
          "Apart from LLMs, previous works in MT have": "the translation. Existing works in that direction fo-"
        },
        {
          "Abstract": "tracted from a Speech Emotion Recognition",
          "Apart from LLMs, previous works in MT have": "cused on the control of politeness (Sennrich et al.,"
        },
        {
          "Abstract": "(SER) model into LLMs to enhance translation",
          "Apart from LLMs, previous works in MT have": ""
        },
        {
          "Abstract": "",
          "Apart from LLMs, previous works in MT have": "2019), gender (Vanmassenhove et al., 2018; Gaido"
        },
        {
          "Abstract": "quality. We first fine-tune five existing LLMs",
          "Apart from LLMs, previous works in MT have": ""
        },
        {
          "Abstract": "",
          "Apart from LLMs, previous works in MT have": "et al., 2023), or emotion (Brazier and Rouas, 2024)"
        },
        {
          "Abstract": "on the Libri-trans dataset and select\nthe most",
          "Apart from LLMs, previous works in MT have": ""
        },
        {
          "Abstract": "",
          "Apart from LLMs, previous works in MT have": "of the translation and showed that this extra infor-"
        },
        {
          "Abstract": "performant model. Subsequently, we augment",
          "Apart from LLMs, previous works in MT have": ""
        },
        {
          "Abstract": "",
          "Apart from LLMs, previous works in MT have": "mation helps improve translation quality."
        },
        {
          "Abstract": "LLM prompts with different dimensional emo-",
          "Apart from LLMs, previous works in MT have": ""
        },
        {
          "Abstract": "",
          "Apart from LLMs, previous works in MT have": "In this work, we propose to improve translation"
        },
        {
          "Abstract": "tions and train the selected LLM under these",
          "Apart from LLMs, previous works in MT have": ""
        },
        {
          "Abstract": "different configurations. Our experiments re-",
          "Apart from LLMs, previous works in MT have": "performances of an LLM-based model by adding"
        },
        {
          "Abstract": "veal\nthat\nintegrating emotion information, es-",
          "Apart from LLMs, previous works in MT have": "emotion as extra information in the prompt of the"
        },
        {
          "Abstract": "pecially arousal,\ninto LLM prompts leads to",
          "Apart from LLMs, previous works in MT have": "model to condition the translation. This work relies"
        },
        {
          "Abstract": "notable improvements in translation quality.",
          "Apart from LLMs, previous works in MT have": ""
        },
        {
          "Abstract": "",
          "Apart from LLMs, previous works in MT have": "on the fact that words can be classified into emo-"
        },
        {
          "Abstract": "",
          "Apart from LLMs, previous works in MT have": "tion categories, leading to affective word lists (Pen-"
        },
        {
          "Abstract": "1\nIntroduction",
          "Apart from LLMs, previous works in MT have": ""
        },
        {
          "Abstract": "",
          "Apart from LLMs, previous works in MT have": "nebaker et al., 2001). Thus, conditioning the trans-"
        },
        {
          "Abstract": "Large Language Models (LLMs) are transformer-",
          "Apart from LLMs, previous works in MT have": "lation with a specific emotion would use a suitable"
        },
        {
          "Abstract": "based (Vaswani et al., 2017) deep learning models",
          "Apart from LLMs, previous works in MT have": "vocabulary in the translation. In Brazier and Rouas"
        },
        {
          "Abstract": "designed to understand and generate natural\nlan-",
          "Apart from LLMs, previous works in MT have": "(2024), authors showed that adding arousal infor-"
        },
        {
          "Abstract": "guage text by predicting the probability of the next",
          "Apart from LLMs, previous works in MT have": "mation, reflecting the level of stimulation (ranging"
        },
        {
          "Abstract": "token in a sequence. LLMs excel across various",
          "Apart from LLMs, previous works in MT have": "from calm to excited), extracted from the voice and"
        },
        {
          "Abstract": "Natural Language Processing (NLP) tasks, such as",
          "Apart from LLMs, previous works in MT have": "added at the start of each input text sentence, helps"
        },
        {
          "Abstract": "information retrieval (Zhu et al., 2023b),\ninstruc-",
          "Apart from LLMs, previous works in MT have": "improve translation performances.\nIn the follow-"
        },
        {
          "Abstract": "tion following (Ouyang et al., 2022), or engaging",
          "Apart from LLMs, previous works in MT have": "ing, we study the behavior of several LLMs for the"
        },
        {
          "Abstract": "in chatbot discussions (OpenAI, 2022).",
          "Apart from LLMs, previous works in MT have": "task of MT when emotion dimensions are added to"
        },
        {
          "Abstract": "Among NLP tasks, LLMs have shown great ca-",
          "Apart from LLMs, previous works in MT have": "input prompts."
        },
        {
          "Abstract": "pacities in Machine Translation (MT) (Zhu et al.,",
          "Apart from LLMs, previous works in MT have": "To address this problem, we first fine-tune sev-"
        },
        {
          "Abstract": "2023a), the task of translating a text from one lan-",
          "Apart from LLMs, previous works in MT have": "eral\nexisting LLMs\nfor\nthe\ntask of English-to-"
        },
        {
          "Abstract": "guage to another. Previous research has enhanced",
          "Apart from LLMs, previous works in MT have": "French text-to-text\ntranslation.\nThen,\nafter\nse-"
        },
        {
          "Abstract": "LLM performance in MT through various strate-",
          "Apart from LLMs, previous works in MT have": "lecting the best model as baseline for our experi-"
        },
        {
          "Abstract": "gies,\nincluding optimized prompting techniques",
          "Apart from LLMs, previous works in MT have": "ments, we compute for each input sentence its emo-"
        },
        {
          "Abstract": "(Zhang et al., 2023),\nin-context\nlearning features",
          "Apart from LLMs, previous works in MT have": "tional dimensions with the help of a state-of-the-art"
        },
        {
          "Abstract": "(Brown et al., 2020) to improve translation quality",
          "Apart from LLMs, previous works in MT have": "Speech Emotion Recognition (SER) model applied"
        },
        {
          "Abstract": "over time (Moslem et al., 2023a,b), and a two-stage",
          "Apart from LLMs, previous works in MT have": "to audio recordings.\nFinally, we compare trans-"
        },
        {
          "Abstract": "fine-tuning method composed of a first fine-tuning",
          "Apart from LLMs, previous works in MT have": "lation performance with and without the addition"
        },
        {
          "Abstract": "on monolingual data to learn general\nlinguistic",
          "Apart from LLMs, previous works in MT have": "of each emotional dimension as extra information"
        },
        {
          "Abstract": "knowledge followed by a second fine-tuning on",
          "Apart from LLMs, previous works in MT have": "added to each input prompt. We show that emo-"
        },
        {
          "Abstract": "parallel data (Xu et al., 2023) that establishes the",
          "Apart from LLMs, previous works in MT have": "tion improves translation (BLEU and COMET),"
        },
        {
          "Abstract": "current state-of-the-art method in MT.",
          "Apart from LLMs, previous works in MT have": "especially in the case of arousal."
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "2\nRelated works": "",
          "thropic, 2024).": "For\nthe task of MT, we restrict our LLM se-"
        },
        {
          "2\nRelated works": "In this work, we aim at combining an LLM-based",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "lection to models that are open-source, promising"
        },
        {
          "2\nRelated works": "MT model with emotion information to improve",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "(high rank in the LLM arena1, or already fine-tuned"
        },
        {
          "2\nRelated works": "translation performances. In the following, we first",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "to the MT task), and that only contain 7 billion (7B)"
        },
        {
          "2\nRelated works": "describe a close work that performs this combi-",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "of parameters. We select 5 different models that"
        },
        {
          "2\nRelated works": "nation without\nthe use of an LLM. Then, we list",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "are described in the following."
        },
        {
          "2\nRelated works": "several existing LLMs that can be used as a base-",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "The first selected LLM is Mistral-7B-v0.12, an"
        },
        {
          "2\nRelated works": "line for our MT task.",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "open-source model (Jiang et al., 2023) which ranks"
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "among the best 7B-parameter models."
        },
        {
          "2\nRelated works": "2.1\nMachine Translation with Emotion",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "As\nthe\nsecond model, we\nselect Mistral-7B-"
        },
        {
          "2\nRelated works": "To our knowledge, the only work that combines an",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "Instruct-v0.23. The model is similar to the previous"
        },
        {
          "2\nRelated works": "MT model with emotion information is described",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "model but has been fine-tuned to follow instruc-"
        },
        {
          "2\nRelated works": "in Brazier and Rouas (2024).\nIn this study,\nthe",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "tions."
        },
        {
          "2\nRelated works": "authors utilize a state-of-the-art Speech Emotion",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "Our third selected model is TowerBase-7B-v0.14."
        },
        {
          "2\nRelated works": "Recognition (SER) model (Wagner et al., 2023) to",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "This model (Alves et al., 2024) is based on LLaMA"
        },
        {
          "2\nRelated works": "automatically estimate dimensional emotion val-",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "2 (AI@Meta, 2023) and its training has been con-"
        },
        {
          "2\nRelated works": "ues, including arousal, dominance, and valence, for",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "tinued on multilingual data (including English and"
        },
        {
          "2\nRelated works": "each audio recording associated with text sentence.",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "French monolingual data, as well as bilingual data)."
        },
        {
          "2\nRelated works": "These values are then transformed into unique emo-",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "Similarly to Mistral, we select TowerInstruct-"
        },
        {
          "2\nRelated works": "tion tokens, either positive or negative, which are",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "7B-v0.25 as our\nfourth model.\nThis model\nis a"
        },
        {
          "2\nRelated works": "added at the beginning of tokenized input text sen-",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "variant of the previous one that has been fine-tuned"
        },
        {
          "2\nRelated works": "tences. The authors report an increase in translation",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "to follow instructions including translations."
        },
        {
          "2\nRelated works": "BLEU score, especially when adding arousal\nto-",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "Finally, as our fifth model, we select the SOTA"
        },
        {
          "2\nRelated works": "kens at the start of input sentences.",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "MT model ALMA-7B-R6, which\nis\nbased\non"
        },
        {
          "2\nRelated works": "The MT model used for\ntheir experiments is",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "LLaMA 2 (AI@Meta, 2023), and fine-tuned on"
        },
        {
          "2\nRelated works": "a transformer-based encoder-decoder architecture,",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "monolingual and parallel data. However, the data"
        },
        {
          "2\nRelated works": "comprising 6 layers for the encoder, 6 layers for",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "used for fine-tuning does not include French."
        },
        {
          "2\nRelated works": "the decoder, and 4 attention heads in each self-",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "attention layer. The model is trained on the Libri-",
          "thropic, 2024).": "3\nExperiments and results"
        },
        {
          "2\nRelated works": "trans dataset (Kocabiyikoglu et al., 2018), which in-",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "In this section, we describe our experiments for the"
        },
        {
          "2\nRelated works": "cludes triplets of English recordings, English texts,",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "task of English-to-French text-to-text\ntranslation."
        },
        {
          "2\nRelated works": "and French texts, totaling 235 hours of data (230h",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "We conduct\ntwo successive experiments. Firstly,"
        },
        {
          "2\nRelated works": "for train, 2h for dev, and 3.5h for test). The model",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "we fine-tune five existing LLMs on the Libri-trans"
        },
        {
          "2\nRelated works": "performs English-to-French translation.",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "dataset (Kocabiyikoglu et al., 2018) and consider"
        },
        {
          "2\nRelated works": "In this work, we propose to use the same trans-",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "the best model as a foundation for our second ex-"
        },
        {
          "2\nRelated works": "lation pipeline, but instead of using a specific MT",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "periment. Secondly, we fine-tune the selected LLM"
        },
        {
          "2\nRelated works": "model, we replace it with a fine-tuned LLM. Since",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "on the same task but under different configurations."
        },
        {
          "2\nRelated works": "LLMs have more trainable parameters, we antici-",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "Henceforth, prompts used for translation include"
        },
        {
          "2\nRelated works": "pate improved translation performances. However,",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "each emotion dimension that is automatically esti-"
        },
        {
          "2\nRelated works": "our objective is to observe how LLMs behave when",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "mated from the SER model."
        },
        {
          "2\nRelated works": "augmented with emotion information in the input",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "prompt.",
          "thropic, 2024).": "3.1\nFine-tuning LLMs on Libri-trans"
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "To perform MT with LLMs,\nthe task needs to be"
        },
        {
          "2\nRelated works": "2.2\nLLM selection for MT",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "converted into a language modeling problem with"
        },
        {
          "2\nRelated works": "Recent advances in Large Language Modeling have",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "1http://chat.lmsys.org/?leaderboard"
        },
        {
          "2\nRelated works": "significantly expanded the capabilities of LLMs",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "2http://huggingface.co/mistralai/Mistral-7B-v0.1"
        },
        {
          "2\nRelated works": "across various tasks, such as reasoning, coding, or",
          "thropic, 2024).": "3http://huggingface.co/mistralai/"
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "Mistral-7B-Instruct-v0.2"
        },
        {
          "2\nRelated works": "mathematics. Among the numerous existing LLMs",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "4http://huggingface.co/Unbabel/TowerBase-7B-v0.1"
        },
        {
          "2\nRelated works": "(Chiang et al., 2024), the best-performing models",
          "thropic, 2024).": ""
        },
        {
          "2\nRelated works": "",
          "thropic, 2024).": "5http://huggingface.co/Unbabel/"
        },
        {
          "2\nRelated works": "are GPT-4 (OpenAI, 2023), LLaMA 3 (AI@Meta,",
          "thropic, 2024).": "TowerInstruct-7B-v0.2"
        },
        {
          "2\nRelated works": "2024), Gemini 1.5 (Team, 2024), or Claude 3 (An-",
          "thropic, 2024).": "6http://huggingface.co/haoranxu/ALMA-7B-R"
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "24.0\n20.6\n73.8\n72.9\nTowerBase": "TowerInstruct\n6.4\n6.1\n35.5\n35.5",
          "73.8 on the dev set and from 71.9 to 72.9 on the": "test set. Additionally,\ntheir BLEU scores ranged"
        },
        {
          "24.0\n20.6\n73.8\n72.9\nTowerBase": "ALMA\n7.1\n7.5\n52.1\n52.8",
          "73.8 on the dev set and from 71.9 to 72.9 on the": "from 16.0 to 24.0 on the dev set and from 16.7 to"
        },
        {
          "24.0\n20.6\n73.8\n72.9\nTowerBase": "",
          "73.8 on the dev set and from 71.9 to 72.9 on the": "20.6 on the test set. While COMET scores are not"
        },
        {
          "24.0\n20.6\n73.8\n72.9\nTowerBase": "Table 1: BLEU and COMET scores of our five selected",
          "73.8 on the dev set and from 71.9 to 72.9 on the": ""
        },
        {
          "24.0\n20.6\n73.8\n72.9\nTowerBase": "",
          "73.8 on the dev set and from 71.9 to 72.9 on the": "meant to be interpretable (but enable the compar-"
        },
        {
          "24.0\n20.6\n73.8\n72.9\nTowerBase": "LLMs on dev and test sets of Libri-trans.",
          "73.8 on the dev set and from 71.9 to 72.9 on the": ""
        },
        {
          "24.0\n20.6\n73.8\n72.9\nTowerBase": "",
          "73.8 on the dev set and from 71.9 to 72.9 on the": "ison between models), BLEU scores indicate, on"
        },
        {
          "24.0\n20.6\n73.8\n72.9\nTowerBase": "",
          "73.8 on the dev set and from 71.9 to 72.9 on the": "average, a translation that is more or less clear with"
        },
        {
          "24.0\n20.6\n73.8\n72.9\nTowerBase": "the use of prompts. In this work, we perform zero-",
          "73.8 on the dev set and from 71.9 to 72.9 on the": "numerous grammatical errors. These low BLEU"
        },
        {
          "24.0\n20.6\n73.8\n72.9\nTowerBase": "shot prompting and follow two different templates.",
          "73.8 on the dev set and from 71.9 to 72.9 on the": "scores are comparable to performances of previous"
        },
        {
          "24.0\n20.6\n73.8\n72.9\nTowerBase": "The first\ntemplate will be applied to Mistral-7B-",
          "73.8 on the dev set and from 71.9 to 72.9 on the": "works on this dataset (Zhao et al., 2021; Brazier and"
        },
        {
          "24.0\n20.6\n73.8\n72.9\nTowerBase": "v0.1 and TowerBase-7B-v0.1:",
          "73.8 on the dev set and from 71.9 to 72.9 on the": "Rouas, 2024) and are mainly caused by the nature"
        },
        {
          "24.0\n20.6\n73.8\n72.9\nTowerBase": "",
          "73.8 on the dev set and from 71.9 to 72.9 on the": "of the data (audiobooks with literary vocabulary)."
        }
      ],
      "page": 3
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Model\nBLEU\nCOMET": "dev\ntest\ndev\ntest",
          "The table highlights three models, Mistral-7B-": "v0.1, Mistral-7B-Instruct-v0.2, and TowerBase-7B-"
        },
        {
          "Model\nBLEU\nCOMET": "Mistral\n16.4\n16.7\n73.2\n72.5",
          "The table highlights three models, Mistral-7B-": "v0.1,\nthat attain high BLEU and COMET scores."
        },
        {
          "Model\nBLEU\nCOMET": "MistralInstruct\n16.0\n17.9\n72.1\n71.9",
          "The table highlights three models, Mistral-7B-": "They obtain COMET scores ranging from 72.1 to"
        },
        {
          "Model\nBLEU\nCOMET": "24.0\n20.6\n73.8\n72.9\nTowerBase",
          "The table highlights three models, Mistral-7B-": "73.8 on the dev set and from 71.9 to 72.9 on the"
        },
        {
          "Model\nBLEU\nCOMET": "TowerInstruct\n6.4\n6.1\n35.5\n35.5",
          "The table highlights three models, Mistral-7B-": "test set. Additionally,\ntheir BLEU scores ranged"
        },
        {
          "Model\nBLEU\nCOMET": "ALMA\n7.1\n7.5\n52.1\n52.8",
          "The table highlights three models, Mistral-7B-": "from 16.0 to 24.0 on the dev set and from 16.7 to"
        },
        {
          "Model\nBLEU\nCOMET": "",
          "The table highlights three models, Mistral-7B-": "20.6 on the test set. While COMET scores are not"
        },
        {
          "Model\nBLEU\nCOMET": "Table 1: BLEU and COMET scores of our five selected",
          "The table highlights three models, Mistral-7B-": ""
        },
        {
          "Model\nBLEU\nCOMET": "",
          "The table highlights three models, Mistral-7B-": "meant to be interpretable (but enable the compar-"
        },
        {
          "Model\nBLEU\nCOMET": "LLMs on dev and test sets of Libri-trans.",
          "The table highlights three models, Mistral-7B-": ""
        },
        {
          "Model\nBLEU\nCOMET": "",
          "The table highlights three models, Mistral-7B-": "ison between models), BLEU scores indicate, on"
        },
        {
          "Model\nBLEU\nCOMET": "",
          "The table highlights three models, Mistral-7B-": "average, a translation that is more or less clear with"
        },
        {
          "Model\nBLEU\nCOMET": "the use of prompts. In this work, we perform zero-",
          "The table highlights three models, Mistral-7B-": "numerous grammatical errors. These low BLEU"
        },
        {
          "Model\nBLEU\nCOMET": "shot prompting and follow two different templates.",
          "The table highlights three models, Mistral-7B-": "scores are comparable to performances of previous"
        },
        {
          "Model\nBLEU\nCOMET": "The first\ntemplate will be applied to Mistral-7B-",
          "The table highlights three models, Mistral-7B-": "works on this dataset (Zhao et al., 2021; Brazier and"
        },
        {
          "Model\nBLEU\nCOMET": "v0.1 and TowerBase-7B-v0.1:",
          "The table highlights three models, Mistral-7B-": "Rouas, 2024) and are mainly caused by the nature"
        },
        {
          "Model\nBLEU\nCOMET": "",
          "The table highlights three models, Mistral-7B-": "of the data (audiobooks with literary vocabulary)."
        },
        {
          "Model\nBLEU\nCOMET": "English: <src txt> \\n\nFrench:\n<tgt\ntxt>\n(1)",
          "The table highlights three models, Mistral-7B-": "Also,\nit\nis worth\nnoting\nthat\ntwo models,"
        },
        {
          "Model\nBLEU\nCOMET": "",
          "The table highlights three models, Mistral-7B-": "TowerInstruct-7B-v0.2 and ALMA-7B-R, exhibit"
        },
        {
          "Model\nBLEU\nCOMET": "where <src\ntxt> and <tgt\ntxt> refer to the En-",
          "The table highlights three models, Mistral-7B-": ""
        },
        {
          "Model\nBLEU\nCOMET": "",
          "The table highlights three models, Mistral-7B-": "poor performances in MT when fine-tuned on Libri-"
        },
        {
          "Model\nBLEU\nCOMET": "glish source sentence and the French target sen-",
          "The table highlights three models, Mistral-7B-": ""
        },
        {
          "Model\nBLEU\nCOMET": "",
          "The table highlights three models, Mistral-7B-": "trans.\nIn the case of ALMA-7B-R,\nthis can be ex-"
        },
        {
          "Model\nBLEU\nCOMET": "tence respectively.",
          "The table highlights three models, Mistral-7B-": ""
        },
        {
          "Model\nBLEU\nCOMET": "",
          "The table highlights three models, Mistral-7B-": "plained by the fact\nthat French is not among the"
        },
        {
          "Model\nBLEU\nCOMET": "The second template will be applied to mod-",
          "The table highlights three models, Mistral-7B-": ""
        },
        {
          "Model\nBLEU\nCOMET": "",
          "The table highlights three models, Mistral-7B-": "languages included in the data used to pre-train the"
        },
        {
          "Model\nBLEU\nCOMET": "els\nthat\nfollow instructions, namely Mistral-7B-",
          "The table highlights three models, Mistral-7B-": ""
        },
        {
          "Model\nBLEU\nCOMET": "",
          "The table highlights three models, Mistral-7B-": "model. Thus, the model fails at predicting French"
        },
        {
          "Model\nBLEU\nCOMET": "Instruct-v0.2, TowerInstruct-7B-v0.2, and ALMA-",
          "The table highlights three models, Mistral-7B-": ""
        },
        {
          "Model\nBLEU\nCOMET": "",
          "The table highlights three models, Mistral-7B-": "text."
        },
        {
          "Model\nBLEU\nCOMET": "7B-R:",
          "The table highlights three models, Mistral-7B-": ""
        },
        {
          "Model\nBLEU\nCOMET": "",
          "The table highlights three models, Mistral-7B-": "As additional\ntraining information, all LLMs"
        },
        {
          "Model\nBLEU\nCOMET": "",
          "The table highlights three models, Mistral-7B-": "have obtained their optimal state in a maximum of"
        },
        {
          "Model\nBLEU\nCOMET": "[INST]\nTranslate\nfrom\nEnglish\nto\nFrench:\n<src\ntxt>\n[/INST]\n\\n <tgt\ntxt>",
          "The table highlights three models, Mistral-7B-": ""
        },
        {
          "Model\nBLEU\nCOMET": "",
          "The table highlights three models, Mistral-7B-": "5 epochs. This represents a training time of 3 hours"
        },
        {
          "Model\nBLEU\nCOMET": "(2)",
          "The table highlights three models, Mistral-7B-": ""
        },
        {
          "Model\nBLEU\nCOMET": "",
          "The table highlights three models, Mistral-7B-": "on a GPU NVIDIA A100 for each model. This"
        },
        {
          "Model\nBLEU\nCOMET": "To fine-tune LLMs, we employ QLoRA (Hu",
          "The table highlights three models, Mistral-7B-": ""
        },
        {
          "Model\nBLEU\nCOMET": "",
          "The table highlights three models, Mistral-7B-": "fast fine-tuning time is due to QLoRA and 4-bit"
        },
        {
          "Model\nBLEU\nCOMET": "et al., 2022; Dettmers et al., 2023), a Parameter",
          "The table highlights three models, Mistral-7B-": ""
        },
        {
          "Model\nBLEU\nCOMET": "",
          "The table highlights three models, Mistral-7B-": "quantization strategies."
        },
        {
          "Model\nBLEU\nCOMET": "Efficient Fine-Tuning method (Mangrulkar et al.,",
          "The table highlights three models, Mistral-7B-": ""
        },
        {
          "Model\nBLEU\nCOMET": "",
          "The table highlights three models, Mistral-7B-": "To summarize, the best machine translation per-"
        },
        {
          "Model\nBLEU\nCOMET": "2022) that allows training with significantly fewer",
          "The table highlights three models, Mistral-7B-": ""
        },
        {
          "Model\nBLEU\nCOMET": "",
          "The table highlights three models, Mistral-7B-": "formances were achieved with the TowerBase-7B-"
        },
        {
          "Model\nBLEU\nCOMET": "parameters. Additionally, we apply a 4-bit quanti-",
          "The table highlights three models, Mistral-7B-": ""
        },
        {
          "Model\nBLEU\nCOMET": "",
          "The table highlights three models, Mistral-7B-": "v0.1. This LLM serves as a baseline and foundation"
        },
        {
          "Model\nBLEU\nCOMET": "zation to reduce memory usage while maintaining",
          "The table highlights three models, Mistral-7B-": ""
        },
        {
          "Model\nBLEU\nCOMET": "",
          "The table highlights three models, Mistral-7B-": "model for the following experiment."
        },
        {
          "Model\nBLEU\nCOMET": "16-bit precision during computation.",
          "The table highlights three models, Mistral-7B-": ""
        },
        {
          "Model\nBLEU\nCOMET": "We provide two distinct metrics to evaluate our",
          "The table highlights three models, Mistral-7B-": "3.2\nFine-tuning LLMs with Emotion"
        },
        {
          "Model\nBLEU\nCOMET": "MT models. The first metric is the BLEU score",
          "The table highlights three models, Mistral-7B-": ""
        },
        {
          "Model\nBLEU\nCOMET": "",
          "The table highlights three models, Mistral-7B-": "The\nsecond\nexperiment\naims\nat\nobserving\nthe"
        },
        {
          "Model\nBLEU\nCOMET": "computed using sacrebleu (Post, 2018). It reflects",
          "The table highlights three models, Mistral-7B-": ""
        },
        {
          "Model\nBLEU\nCOMET": "",
          "The table highlights three models, Mistral-7B-": "behavior of our LLM-based TowerBase-7B-v0.1"
        },
        {
          "Model\nBLEU\nCOMET": "the degree of lexical matches (number of common",
          "The table highlights three models, Mistral-7B-": ""
        },
        {
          "Model\nBLEU\nCOMET": "",
          "The table highlights three models, Mistral-7B-": "model on the task of English-to-French Machine"
        },
        {
          "Model\nBLEU\nCOMET": "n-grams) between the proposed translation and its",
          "The table highlights three models, Mistral-7B-": ""
        },
        {
          "Model\nBLEU\nCOMET": "",
          "The table highlights three models, Mistral-7B-": "Translation when emotion information is added to"
        },
        {
          "Model\nBLEU\nCOMET": "corresponding reference. The second metric is the",
          "The table highlights three models, Mistral-7B-": ""
        },
        {
          "Model\nBLEU\nCOMET": "",
          "The table highlights three models, Mistral-7B-": "the prompt before translation."
        },
        {
          "Model\nBLEU\nCOMET": "COMET score 7 (Rei et al., 2022). It is computed",
          "The table highlights three models, Mistral-7B-": ""
        },
        {
          "Model\nBLEU\nCOMET": "",
          "The table highlights three models, Mistral-7B-": "As a first step, we estimate the emotion of each"
        },
        {
          "Model\nBLEU\nCOMET": "from a trained model and reflects translation quality",
          "The table highlights three models, Mistral-7B-": ""
        },
        {
          "Model\nBLEU\nCOMET": "",
          "The table highlights three models, Mistral-7B-": "English recording present in the Libri-trans dataset."
        },
        {
          "Model\nBLEU\nCOMET": "between translation, reference, and also the source",
          "The table highlights three models, Mistral-7B-": ""
        },
        {
          "Model\nBLEU\nCOMET": "",
          "The table highlights three models, Mistral-7B-": "Following the same methodology as Brazier and"
        },
        {
          "Model\nBLEU\nCOMET": "sentence.\nAccording to the metric ranking pre-",
          "The table highlights three models, Mistral-7B-": ""
        },
        {
          "Model\nBLEU\nCOMET": "",
          "The table highlights three models, Mistral-7B-": "Rouas (2024), we compute dimensional emotion"
        },
        {
          "Model\nBLEU\nCOMET": "sented in Freitag et al. (2022), we rely more on the",
          "The table highlights three models, Mistral-7B-": ""
        },
        {
          "Model\nBLEU\nCOMET": "",
          "The table highlights three models, Mistral-7B-": "values for arousal, dominance, and valence with"
        },
        {
          "Model\nBLEU\nCOMET": "COMET score than on the BLEU score.",
          "The table highlights three models, Mistral-7B-": ""
        },
        {
          "Model\nBLEU\nCOMET": "",
          "The table highlights three models, Mistral-7B-": "the help of a trained SER model\n(Wagner et al.,"
        },
        {
          "Model\nBLEU\nCOMET": "Table 1 showcases the results of our first experi-",
          "The table highlights three models, Mistral-7B-": ""
        },
        {
          "Model\nBLEU\nCOMET": "",
          "The table highlights three models, Mistral-7B-": "2023). Emotion values range between 0 and 1 and"
        },
        {
          "Model\nBLEU\nCOMET": "ment. In this table, we report BLEU and COMET",
          "The table highlights three models, Mistral-7B-": ""
        },
        {
          "Model\nBLEU\nCOMET": "",
          "The table highlights three models, Mistral-7B-": "are correctly balanced (medians between 0.4 and"
        },
        {
          "Model\nBLEU\nCOMET": "scores of the five selected LLMs on both the dev",
          "The table highlights three models, Mistral-7B-": ""
        },
        {
          "Model\nBLEU\nCOMET": "",
          "The table highlights three models, Mistral-7B-": "0.6, see Brazier and Rouas (2024))."
        },
        {
          "Model\nBLEU\nCOMET": "and test sets of the Libri-trans dataset.",
          "The table highlights three models, Mistral-7B-": ""
        },
        {
          "Model\nBLEU\nCOMET": "",
          "The table highlights three models, Mistral-7B-": "As a second step, we create specific prompts that"
        },
        {
          "Model\nBLEU\nCOMET": "7https://huggingface.co/Unbabel/wmt22-comet-da",
          "The table highlights three models, Mistral-7B-": "include the emotion information in the text. For"
        }
      ],
      "page": 3
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "this purpose, we propose 3 different templates. The": "first template adds emotion information before the",
          "Model": "",
          "BLEU": "dev",
          "COMET": "dev"
        },
        {
          "this purpose, we propose 3 different templates. The": "source sentence:",
          "Model": "TowerBase",
          "BLEU": "24.0",
          "COMET": "73.8"
        },
        {
          "this purpose, we propose 3 different templates. The": "",
          "Model": "+arousal3",
          "BLEU": "22.1",
          "COMET": "74.9"
        },
        {
          "this purpose, we propose 3 different templates. The": "English\n<status>\n<emotion>:\n<src\ntxt>\n\\n\nFrench:\n<tgt\ntxt>",
          "Model": "",
          "BLEU": "",
          "COMET": ""
        },
        {
          "this purpose, we propose 3 different templates. The": "",
          "Model": "+arousal4",
          "BLEU": "25.6",
          "COMET": "74.8"
        },
        {
          "this purpose, we propose 3 different templates. The": "(3)",
          "Model": "",
          "BLEU": "",
          "COMET": ""
        },
        {
          "this purpose, we propose 3 different templates. The": "",
          "Model": "+arousal5",
          "BLEU": "19.3",
          "COMET": "74.2"
        },
        {
          "this purpose, we propose 3 different templates. The": "where status is replaced by either with or without",
          "Model": "",
          "BLEU": "",
          "COMET": ""
        },
        {
          "this purpose, we propose 3 different templates. The": "",
          "Model": "+dominance3",
          "BLEU": "19.9",
          "COMET": "74.4"
        },
        {
          "this purpose, we propose 3 different templates. The": "if\nthe emotion value is higher or\nlower\nthan 0.5",
          "Model": "",
          "BLEU": "",
          "COMET": ""
        },
        {
          "this purpose, we propose 3 different templates. The": "",
          "Model": "+dominance4",
          "BLEU": "18.9",
          "COMET": "74.9"
        },
        {
          "this purpose, we propose 3 different templates. The": "respectively, emotion is replaced by either arousal,",
          "Model": "",
          "BLEU": "",
          "COMET": ""
        },
        {
          "this purpose, we propose 3 different templates. The": "",
          "Model": "+dominance5",
          "BLEU": "16.5",
          "COMET": "73.4"
        },
        {
          "this purpose, we propose 3 different templates. The": "dominance, or valence, src\ntxt represents the",
          "Model": "",
          "BLEU": "",
          "COMET": ""
        },
        {
          "this purpose, we propose 3 different templates. The": "",
          "Model": "+valence3",
          "BLEU": "21.5",
          "COMET": "74.1"
        },
        {
          "this purpose, we propose 3 different templates. The": "English source sentence, and tgt\ntxt represents",
          "Model": "",
          "BLEU": "",
          "COMET": ""
        },
        {
          "this purpose, we propose 3 different templates. The": "",
          "Model": "+valence4",
          "BLEU": "18.3",
          "COMET": "74.6"
        },
        {
          "this purpose, we propose 3 different templates. The": "the French target translation.",
          "Model": "",
          "BLEU": "",
          "COMET": ""
        },
        {
          "this purpose, we propose 3 different templates. The": "",
          "Model": "+valence5",
          "BLEU": "17.2",
          "COMET": "74.5"
        },
        {
          "this purpose, we propose 3 different templates. The": "The second template adds emotion information",
          "Model": "",
          "BLEU": "",
          "COMET": ""
        },
        {
          "this purpose, we propose 3 different templates. The": "before the target sentence:",
          "Model": "Table 2: BLEU and COMET scores of the TowerBase",
          "BLEU": "",
          "COMET": ""
        },
        {
          "this purpose, we propose 3 different templates. The": "",
          "Model": "model on dev and test sets of Libri-trans.",
          "BLEU": "",
          "COMET": ""
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "guistics: Human Language Technologies (NAACL-"
        },
        {
          "5\nAcknowledgements": "The research presented in this paper is conducted",
          "Chapter of\nthe Association for Computational Lin-": "HLT), pages 20122017, Minneapolis, MN, USA."
        },
        {
          "5\nAcknowledgements": "as part of the project FVLLMONTI, which has re-",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "Markus Freitag, Ricardo Rei, Nitika Mathur, Chi-kiu Lo,"
        },
        {
          "5\nAcknowledgements": "ceived funding from the European Unions Horizon",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "Craig Stewart, Eleftherios Avramidis, Tom Kocmi,"
        },
        {
          "5\nAcknowledgements": "2020 Research and Innovation action under grant",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "George Foster, Alon Lavie, and Andr F. T. Mar-"
        },
        {
          "5\nAcknowledgements": "agreement No 101016776.",
          "Chapter of\nthe Association for Computational Lin-": "tins. 2022. Results of WMT22 Metrics Shared Task:"
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "Stop Using BLEU  Neural Metrics Are Better and"
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "More Robust.\nIn Proc. of the Conference on Machine"
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "Translation (WMT), pages 4668, Abu Dhabi, United"
        },
        {
          "5\nAcknowledgements": "References",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "Arab Emirates."
        },
        {
          "5\nAcknowledgements": "AI@Meta. 2023. LLaMA 2: Open Foundation and Fine-",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "tuned Chat Models. Preprint, arXiv:2307.09288.",
          "Chapter of\nthe Association for Computational Lin-": "Marco Gaido, Dennis Fucci, Matteo Negri, and Luisa"
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "Bentivogli. 2023. How to Build Competitive Multi-"
        },
        {
          "5\nAcknowledgements": "AI@Meta. 2024. LLaMA 3 Model Card.",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "gender Speech Translation Models for Controlling"
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "Speaker Gender Translation.\nIn Proc. of the Italian"
        },
        {
          "5\nAcknowledgements": "Duarte M. Alves, Jos Pombal, Nuno M. Guerreiro, Pe-",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "Conference on Computational Linguistics (CLiC-it)."
        },
        {
          "5\nAcknowledgements": "dro H. Martins, Joo Alves, Amin Farajian, Ben Pe-",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "ters, Ricardo Rei, Patrick Fernandes, Sweta Agrawal,",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan"
        },
        {
          "5\nAcknowledgements": "Pierre Colombo, Jos G.C. de Souza, and Andr F.T.",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and"
        },
        {
          "5\nAcknowledgements": "Martins.\n2024.\nTower:\nAn Open Multilingual",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "Weizhu Chen. 2022. LoRA: Low-Rank Adaptation"
        },
        {
          "5\nAcknowledgements": "Large Language Model for Translation-Related Tasks.",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "the Inter-\nof Large Language Models.\nIn Proc. of"
        },
        {
          "5\nAcknowledgements": "Preprint, arXiv:2402.17733.",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "national Conference on Learning Representations"
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "(ICLR), Virtual."
        },
        {
          "5\nAcknowledgements": "Anthropic. 2024. Claude 3: Introducing the Next Gen-",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "eration of Claude.",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "Albert Q. Jiang, Alexandre Sablayrolles, Arthur Men-"
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "sch, Chris Bamford, Devendra Singh Chaplot, Diego"
        },
        {
          "5\nAcknowledgements": "Charles Brazier and Jean-Luc Rouas. 2024. Usefulness",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "de las Casas, Florian Bressand, Gianna Lengyel, Guil-"
        },
        {
          "5\nAcknowledgements": "of Emotional Prosody in Neural Machine Translation.",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "laume Lample, Lucile Saulnier, Llio Renard Lavaud,"
        },
        {
          "5\nAcknowledgements": "In Proc. of the International Conference on Speech",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "Marie-Anne Lachaux, Pierre Stock, Teven Le Scao,"
        },
        {
          "5\nAcknowledgements": "Prosody (SP), Leiden, The Netherlands.",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "Thibaut Lavril, Thomas Wang, Timothe Lacroix,"
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "and William El Sayed. 2023. Mistral 7B. Preprint,"
        },
        {
          "5\nAcknowledgements": "Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "arXiv:2310.06825."
        },
        {
          "5\nAcknowledgements": "Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "Neelakantan, Pranav Shyam, Girish Sastry, Amanda",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "Ali Can Kocabiyikoglu, Laurent Besacier, and Olivier"
        },
        {
          "5\nAcknowledgements": "Askell,\nSandhini Agarwal,\nAriel Herbert-Voss,",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "Kraif. 2018. Augmenting Librispeech with French"
        },
        {
          "5\nAcknowledgements": "Gretchen Krueger, Tom Henighan, Rewon Child,",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "Translations:\nA Multimodal Corpus\nfor Direct"
        },
        {
          "5\nAcknowledgements": "Daniel M. Ramesh, Aditya ans Ziegler, Jeffrey Wu,",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "the In-\nSpeech Translation Evaluation.\nIn Proc. of"
        },
        {
          "5\nAcknowledgements": "Clemens Winter, Christopher Hesse, Mark Chen, Eric",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "ternational Conference on Language Resources and"
        },
        {
          "5\nAcknowledgements": "Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess,",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "Evaluation (LREC), Miyazaki, Japan."
        },
        {
          "5\nAcknowledgements": "Jack Clark, Christopher Bernet, Sam McCandlish,",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "Alec Radford,\nIlya Sutskever, and Dario Amodei.",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "Sourab Mangrulkar, Sylvain Gugger, Lysandre De-"
        },
        {
          "5\nAcknowledgements": "2020. Language Models are Few-shot Learners.\nIn",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "but, Younes Belkada, Sayak Paul,\nand Benjamin"
        },
        {
          "5\nAcknowledgements": "Proc. of the Annual Conference on Neural Informa-",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "Bossan. 2022.\nPEFT: State-of-the-art Parameter-"
        },
        {
          "5\nAcknowledgements": "tion Processing Systems (NeurIPS), volume 33, pages",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "https://github.\nEfficient Fine-Tuning methods."
        },
        {
          "5\nAcknowledgements": "18771901, Virtual.",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "com/huggingface/peft."
        },
        {
          "5\nAcknowledgements": "Wei-Lin Chiang, Lianmin Zheng, Ying Sheng, Anasta-",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "Yasmin Moslem, Rejwanul Haque, John D. Kelleher,"
        },
        {
          "5\nAcknowledgements": "sios Nikolas Angelopoulos, Tianle Li, Dacheng Li,",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "and Andy Way. 2023a. Adaptive Machine Transla-"
        },
        {
          "5\nAcknowledgements": "Hao Zhang, Banghua Zhu, Michael Jordan, Joseph E.",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "the\ntion with Large Language Models.\nIn Proc. of"
        },
        {
          "5\nAcknowledgements": "Gonzalez, and Ion Stoica. 2024. Chatbot Arena: An",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "Annual Conference of the European Association for"
        },
        {
          "5\nAcknowledgements": "Open Platform for Evaluating LLMs by Human Pref-",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "Machine Translation (EAMT), pages 227237, Tam-"
        },
        {
          "5\nAcknowledgements": "erence. Preprint, arXiv:2403.04132.",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "",
          "Chapter of\nthe Association for Computational Lin-": "pere, Finland."
        },
        {
          "5\nAcknowledgements": "Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and",
          "Chapter of\nthe Association for Computational Lin-": ""
        },
        {
          "5\nAcknowledgements": "Luke Zettlemoyer. 2023. Qlora: Efficient Finetuning",
          "Chapter of\nthe Association for Computational Lin-": "Yasmin Moslem, Rejwanul Haque,\nand Andy Way."
        },
        {
          "5\nAcknowledgements": "the Annual Con-\nof Quantized LLMs.\nIn Proc. of",
          "Chapter of\nthe Association for Computational Lin-": "2023b.\nFine-tuning\nLarge\nLanguage Models"
        },
        {
          "5\nAcknowledgements": "ference on Neural Information Processing Systems",
          "Chapter of\nthe Association for Computational Lin-": "for Adaptive Machine\nTranslation.\nPreprint,"
        },
        {
          "5\nAcknowledgements": "(NeurIPS), volume 36, New Orleans, LA, USA.",
          "Chapter of\nthe Association for Computational Lin-": "arXiv:2312.12740."
        }
      ],
      "page": 5
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "Carroll L. Wainwright, Pamela Mishkin, Chong",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": "2023.\nPrompting Large Language Model\nfor Ma-"
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray,",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": "chine Translation:\nA Case Study.\nIn Proc. of"
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "John Schulman, Jacob Hilton, Fraser Kelton, Luke",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": "the International Conference on Machine Learning"
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "Miller, Maddie Simens, Amanda Askell, Peter Welin-",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": "(ICML), pages 4109241110, Edinburgh, Scotland."
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "der, Paul F. Christiano, Jan Leike, and Ryan Lowe.",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "2022. Training Language Models to Follow Instruc-",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": "Chengqi Zhao, Mingxuan Wang, Qianqian Dong, Rong"
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "the An-\ntions with Human Feedback.\nIn Proc. of",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": "Ye, and Lei Li. 2021. NeurST: Neural speech transla-"
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "nual Conference on Neural Information Processing",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": "tion toolkit.\nIn Proc. of the Joint Conference of the"
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": "Annual Meeting of the Association for Computational"
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "Systems (NeurIPS), volume 35, pages 2773027744,",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": "Linguistics and the International Joint Conference on"
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "New Orleans, LA, USA.",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": "Natural Language Processing (ACL), pages 5562,"
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "J.W. Pennebaker, M.E. Francis, and R.J. Booth. 2001.",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": "Online."
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "Linguistic Inquiry and Word Count: LIWC 2001.",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "Mahway: Lawrence Erlbaum Associates, 71.",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": "Wenhao Zhu, Hongyi Liu, Qingxiu Dong, Jingjing Xu,"
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": "Shujian Huang, Lingpeng Kong, Jiajun Chen, and"
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "Matt Post. 2018. A Call for Clarity in Reporting BLEU",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": "Lei Li. 2023a. Multilingual Machine Translation"
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "Scores.\nIn Proc. of the Conference on Machine Trans-",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": "with Large Language Models: Empirical Results and"
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "lation:\nResearch Papers\n(WMT), pages 186191,",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": "Analysis. Preprint, arXiv:2304.04675."
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "Brussels, Belgium.",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": "Yutao Zhu, Huaying Yuan, Shuting Wang,\nJiongnan"
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "Ricardo Rei, Jos G. C. de Souza, Duarte M. Alves,",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": "Liu, Wenhan Liu, Chenlong Deng, Zhicheng Dou,"
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "Chrysoula Zerva, Ana C Farinha, Taisiya Glushkova,",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": "and Ji-Rong Wen. 2023b.\nLarge Language Mod-"
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "Alon Lavie, Luisa Coheur, and Andr F. T. Martins.",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": "els for Information Retrieval: A Survey. Preprint,"
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "2022. COMET-22: Unbabel-IST 2022 Submission",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": "arXiv:2308.07107."
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "for the Metrics Shared Task.\nIn Proc. of the Confer-",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "ence on Machine Translation (WMT), pages 578585,",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "Abu Dhabi, United Arab Emirates.",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "Rico Sennrich, Barry Haddow, and Alexandra Birch.",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "2019.\nControlling Politeness\nin Neural Machine",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "the\nTranslation via Side Constraints.\nIn Proc. of",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "Conference of\nthe North American Chapter of\nthe",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "Association for Computational Linguistics: Human",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "Language Technologies (NAACL-HLT), pages 3540,",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "San Diego, USA.",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "Gemini Team. 2024. Gemini 1.5: Unlocking Multi-",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "modal Understanding across Millions of Tokens of",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "Context. Preprint, arXiv:2403.05530.",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "Eva Vanmassenhove, Christian Hardmeier, and Andy",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "Way. 2018.\nGetting Gender Right\nin Neural Ma-",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "the Conference on\nchine Translation.\nIn Proc. of",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "Empirical Methods in Natural Language Processing",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "(CEMNLP), pages 30033008, Brussels, Belgium.",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "Uszkoreit, Llion Jones, Aidan N Gomez, ukasz",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "Kaiser, and Illia Polosukhin. 2017. Attention is All",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "you Need.\nIn Proc. of the Annual Conference on Neu-",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "ral Information Processing Systems (NIPS), pages",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "59986008, Long Beach, USA.",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "Johannes Wagner, Andreas Triantafyllopoulos, Hagen",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "Wierstorf, Maximilian Schmitt, Felix Burkhardt, Flo-",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "rian Eyben, and Bjrn W Schuller. 2023. Dawn of",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "the Transformer Era in Speech Emotion Recognition:",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "IEEE Transactions on Pat-\nClosing the Valence Gap.",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "tern Analysis and Machine Intelligence, 45:10745",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "10759.",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "Haoran Xu, Young Jin Kim, Amr Sharaf, and Hany Has-",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "san Awadalla. 2023.\nA Paradigm Shift\nin Ma-",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "chine Translation:\nBoosting Translation\nPerfor-",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "mance\nof\nLarge\nLanguage Models.\nPreprint,",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        },
        {
          "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,": "arXiv:2309.11674.",
          "Biao Zhang, Barry Haddow,\nand Alexandra Birch.": ""
        }
      ],
      "page": 6
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "LLaMA 2: Open Foundation and Finetuned Chat Models",
      "authors": [
        "Ai@meta"
      ],
      "year": "2023",
      "venue": "LLaMA 2: Open Foundation and Finetuned Chat Models",
      "arxiv": "arXiv:2307.09288"
    },
    {
      "citation_id": "2",
      "title": "LLaMA 3 Model Card",
      "authors": [
        "Ai@meta"
      ],
      "year": "2024",
      "venue": "LLaMA 3 Model Card"
    },
    {
      "citation_id": "3",
      "title": "Tower: An Open Multilingual Large Language Model for Translation-Related Tasks",
      "authors": [
        "M Duarte",
        "Jos Alves",
        "Pombal",
        "M Nuno",
        "Pedro Guerreiro",
        "Joo Martins",
        "Amin Alves",
        "Ben Farajian",
        "Ricardo Peters",
        "Patrick Rei",
        "Sweta Fernandes",
        "Pierre Agrawal",
        "Colombo",
        "G Jos",
        "De Souza",
        "F Andr",
        "Martins"
      ],
      "year": "2024",
      "venue": "Tower: An Open Multilingual Large Language Model for Translation-Related Tasks",
      "arxiv": "arXiv:2402.17733"
    },
    {
      "citation_id": "4",
      "title": "Claude 3: Introducing the Next Generation of Claude",
      "authors": [
        "Anthropic"
      ],
      "year": "2024",
      "venue": "Claude 3: Introducing the Next Generation of Claude"
    },
    {
      "citation_id": "5",
      "title": "Usefulness of Emotional Prosody in Neural Machine Translation",
      "authors": [
        "Charles Brazier",
        "Jean-Luc Rouas"
      ],
      "year": "2024",
      "venue": "Proc. of the International Conference on Speech Prosody (SP)"
    },
    {
      "citation_id": "6",
      "title": "Alec Radford, Ilya Sutskever, and Dario Amodei",
      "authors": [
        "B Tom",
        "Benjamin Brown",
        "Nick Mann",
        "Melanie Ryder",
        "Jared Subbiah",
        "Prafulla Kaplan",
        "Arvind Dhariwal",
        "Pranav Neelakantan",
        "Girish Shyam",
        "Amanda Sastry",
        "Sandhini Askell",
        "Ariel Agarwal",
        "Gretchen Herbert-Voss",
        "Tom Krueger",
        "Rewon Henighan",
        "Daniel Child",
        "Aditya Ramesh",
        "Jeffrey Ziegler",
        "Clemens Wu",
        "Christopher Winter",
        "Mark Hesse",
        "Eric Chen",
        "Mateusz Sigler",
        "Scott Litwin",
        "Benjamin Gray",
        "Jack Chess",
        "Christopher Clark",
        "Sam Bernet",
        "Mccandlish"
      ],
      "year": "2020",
      "venue": "Proc. of the Annual Conference on Neural Information Processing Systems (NeurIPS)"
    },
    {
      "citation_id": "7",
      "title": "Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference",
      "authors": [
        "Wei-Lin Chiang",
        "Lianmin Zheng",
        "Ying Sheng",
        "Anastasios Nikolas Angelopoulos",
        "Tianle Li",
        "Dacheng Li",
        "Hao Zhang",
        "Banghua Zhu",
        "Michael Jordan",
        "Joseph Gonzalez",
        "Ion Stoica"
      ],
      "year": "2024",
      "venue": "Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference",
      "arxiv": "arXiv:2403.04132"
    },
    {
      "citation_id": "8",
      "title": "Qlora: Efficient Finetuning of Quantized LLMs",
      "authors": [
        "Tim Dettmers",
        "Artidoro Pagnoni",
        "Ari Holtzman",
        "Luke Zettlemoyer"
      ],
      "year": "2023",
      "venue": "Proc. of the Annual Conference on Neural Information Processing Systems (NeurIPS)"
    },
    {
      "citation_id": "9",
      "title": "MuST-C: a Multilingual Speech Translation Corpus",
      "authors": [
        "Mattia Antonino",
        "Di Gangi",
        "Roldano Cattoni",
        "Luisa Bentivogli",
        "Matteo Negri",
        "Marco Turchi"
      ],
      "year": "2019",
      "venue": "Proc. of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)"
    },
    {
      "citation_id": "10",
      "title": "Results of WMT22 Metrics Shared Task: Stop Using BLEU -Neural Metrics Are Better and More Robust",
      "authors": [
        "Markus Freitag",
        "Ricardo Rei",
        "Nitika Mathur",
        "Chi-Kiu Lo",
        "Craig Stewart",
        "Eleftherios Avramidis",
        "Tom Kocmi",
        "George Foster",
        "Alon Lavie",
        "F Andr"
      ],
      "year": "2022",
      "venue": "Proc. of the Conference on Machine Translation (WMT)"
    },
    {
      "citation_id": "11",
      "title": "How to Build Competitive Multigender Speech Translation Models for Controlling Speaker Gender Translation",
      "authors": [
        "Marco Gaido",
        "Dennis Fucci",
        "Matteo Negri",
        "Luisa Bentivogli"
      ],
      "year": "2023",
      "venue": "Proc. of the Italian Conference on Computational Linguistics (CLiC-it)"
    },
    {
      "citation_id": "12",
      "title": "LoRA: Low-Rank Adaptation of Large Language Models",
      "authors": [
        "Edward Hu",
        "Yelong Shen",
        "Phillip Wallis",
        "Zeyuan Allen-Zhu",
        "Yuanzhi Li",
        "Shean Wang",
        "Lu Wang",
        "Weizhu Chen"
      ],
      "year": "2022",
      "venue": "Proc. of the International Conference on Learning Representations (ICLR)"
    },
    {
      "citation_id": "13",
      "title": "Mistral",
      "authors": [
        "Albert Jiang",
        "Alexandre Sablayrolles",
        "Arthur Mensch",
        "Chris Bamford",
        "Devendra Singh Chaplot",
        "Diego De Las Casas",
        "Florian Bressand",
        "Gianna Lengyel",
        "Guillaume Lample",
        "Lucile Saulnier",
        "Renard Llio",
        "Marie-Anne Lavaud",
        "Pierre Lachaux",
        "Teven Stock",
        "Thibaut Le Scao",
        "Thomas Lavril",
        "Timothe Wang",
        "William Lacroix",
        "Sayed"
      ],
      "year": "2023",
      "venue": "Mistral",
      "arxiv": "arXiv:2310.06825"
    },
    {
      "citation_id": "14",
      "title": "Augmenting Librispeech with French Translations: A Multimodal Corpus for Direct Speech Translation Evaluation",
      "authors": [
        "Laurent Ali Can Kocabiyikoglu",
        "Olivier Besacier",
        "Kraif"
      ],
      "year": "2018",
      "venue": "Proc. of the International Conference on Language Resources and Evaluation (LREC)"
    },
    {
      "citation_id": "15",
      "title": "PEFT: State-of-the-art Parameter-Efficient Fine-Tuning methods",
      "authors": [
        "Sourab Mangrulkar",
        "Sylvain Gugger",
        "Lysandre Debut",
        "Younes Belkada",
        "Sayak Paul",
        "Benjamin Bossan"
      ],
      "year": "2022",
      "venue": "PEFT: State-of-the-art Parameter-Efficient Fine-Tuning methods"
    },
    {
      "citation_id": "16",
      "title": "2023a. Adaptive Machine Translation with Large Language Models",
      "authors": [
        "Yasmin Moslem",
        "Rejwanul Haque",
        "John Kelleher",
        "Andy Way"
      ],
      "venue": "Proc. of the Annual Conference of the European Association for Machine Translation (EAMT)"
    },
    {
      "citation_id": "17",
      "title": "2023b. Fine-tuning Large Language Models for Adaptive Machine Translation",
      "authors": [
        "Yasmin Moslem",
        "Rejwanul Haque",
        "Andy Way"
      ],
      "venue": "2023b. Fine-tuning Large Language Models for Adaptive Machine Translation",
      "arxiv": "arXiv:2312.12740"
    },
    {
      "citation_id": "18",
      "title": "",
      "authors": [
        "Openai"
      ],
      "year": "2022",
      "venue": ""
    },
    {
      "citation_id": "19",
      "title": "",
      "authors": [
        "Openai"
      ],
      "year": "2023",
      "venue": "",
      "arxiv": "arXiv:2303.08774"
    },
    {
      "citation_id": "20",
      "title": "Training Language Models to Follow Instructions with Human Feedback",
      "authors": [
        "Long Ouyang",
        "Jeffrey Wu",
        "Xu Jiang",
        "Diogo Almeida",
        "Carroll Wainwright",
        "Pamela Mishkin",
        "Chong Zhang",
        "Sandhini Agarwal",
        "Katarina Slama",
        "Alex Ray",
        "John Schulman",
        "Jacob Hilton",
        "Fraser Kelton",
        "Luke Miller",
        "Maddie Simens",
        "Amanda Askell",
        "Peter Welinder",
        "Paul Christiano",
        "Jan Leike",
        "Ryan Lowe"
      ],
      "year": "2022",
      "venue": "Proc. of the Annual Conference on Neural Information Processing Systems (NeurIPS)"
    },
    {
      "citation_id": "21",
      "title": "Linguistic Inquiry and Word Count: LIWC",
      "authors": [
        "J Pennebaker",
        "M Francis",
        "R Booth"
      ],
      "year": "2001",
      "venue": "Linguistic Inquiry and Word Count: LIWC"
    },
    {
      "citation_id": "22",
      "title": "A Call for Clarity in Reporting BLEU Scores",
      "authors": [
        "Matt Post"
      ],
      "year": "2018",
      "venue": "Proc. of the Conference on Machine Translation: Research Papers (WMT)"
    },
    {
      "citation_id": "23",
      "title": "COMET-22: Unbabel-IST 2022 Submission for the Metrics Shared Task",
      "authors": [
        "Ricardo Rei",
        "G Jos",
        "De Souza",
        "M Duarte",
        "Chrysoula Alves",
        "Ana Zerva",
        "Taisiya Farinha",
        "Alon Glushkova",
        "Luisa Lavie",
        "Coheur",
        "F Andr",
        "Martins"
      ],
      "year": "2022",
      "venue": "Proc. of the Conference on Machine Translation (WMT)"
    },
    {
      "citation_id": "24",
      "title": "Controlling Politeness in Neural Machine Translation via Side Constraints",
      "authors": [
        "Rico Sennrich",
        "Barry Haddow",
        "Alexandra Birch"
      ],
      "year": "2019",
      "venue": "Proc. of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)"
    },
    {
      "citation_id": "25",
      "title": "Gemini 1.5: Unlocking Multimodal Understanding across Millions of Tokens of Context",
      "authors": [
        "Gemini Team"
      ],
      "year": "2024",
      "venue": "Gemini 1.5: Unlocking Multimodal Understanding across Millions of Tokens of Context",
      "arxiv": "arXiv:2403.05530"
    },
    {
      "citation_id": "26",
      "title": "Getting Gender Right in Neural Machine Translation",
      "authors": [
        "Eva Vanmassenhove",
        "Christian Hardmeier",
        "Andy Way"
      ],
      "year": "2018",
      "venue": "Proc. of the Conference on Empirical Methods in Natural Language Processing (CEMNLP)"
    },
    {
      "citation_id": "27",
      "title": "Attention is All you Need",
      "authors": [
        "Ashish Vaswani",
        "Noam Shazeer",
        "Niki Parmar",
        "Jakob Uszkoreit",
        "Llion Jones",
        "Aidan Gomez",
        "ukasz Kaiser",
        "Illia Polosukhin"
      ],
      "year": "2017",
      "venue": "Proc. of the Annual Conference on Neural Information Processing Systems (NIPS)"
    },
    {
      "citation_id": "28",
      "title": "Dawn of the Transformer Era in Speech Emotion Recognition: Closing the Valence Gap",
      "authors": [
        "Johannes Wagner",
        "Andreas Triantafyllopoulos",
        "Hagen Wierstorf",
        "Maximilian Schmitt",
        "Felix Burkhardt",
        "Florian Eyben",
        "Bjrn Schuller"
      ],
      "year": "2023",
      "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
    },
    {
      "citation_id": "29",
      "title": "A Paradigm Shift in Machine Translation: Boosting Translation Performance of Large Language Models",
      "authors": [
        "Haoran Xu",
        "Jin Kim",
        "Amr Sharaf",
        "Hany Hassan Awadalla"
      ],
      "year": "2023",
      "venue": "Proc. of the International Conference on Machine Learning (ICML)",
      "arxiv": "arXiv:2309.11674"
    },
    {
      "citation_id": "30",
      "title": "NeurST: Neural speech translation toolkit",
      "authors": [
        "Chengqi Zhao",
        "Mingxuan Wang",
        "Qianqian Dong",
        "Rong Ye",
        "Lei Li"
      ],
      "year": "2021",
      "venue": "Proc. of the Joint Conference of the Annual Meeting of the Association for Computational Linguistics and the International Joint Conference on Natural Language Processing (ACL)"
    },
    {
      "citation_id": "31",
      "title": "2023a. Multilingual Machine Translation with Large Language Models: Empirical Results and Analysis",
      "authors": [
        "Wenhao Zhu",
        "Hongyi Liu",
        "Qingxiu Dong",
        "Jingjing Xu",
        "Shujian Huang",
        "Lingpeng Kong",
        "Jiajun Chen",
        "Lei Li"
      ],
      "venue": "2023a. Multilingual Machine Translation with Large Language Models: Empirical Results and Analysis",
      "arxiv": "arXiv:2304.04675"
    },
    {
      "citation_id": "32",
      "title": "Large Language Models for Information Retrieval: A Survey",
      "authors": [
        "Yutao Zhu",
        "Huaying Yuan",
        "Shuting Wang",
        "Jiongnan Liu",
        "Wenhan Liu",
        "Chenlong Deng",
        "Zhicheng Dou",
        "Ji-Rong Wen"
      ],
      "year": "2023",
      "venue": "Large Language Models for Information Retrieval: A Survey",
      "arxiv": "arXiv:2308.07107"
    }
  ]
}