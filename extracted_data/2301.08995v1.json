{
  "paper_id": "2301.08995v1",
  "title": "Redaffectivelm : Leveraging Affect Enriched Embedding And Transformer-Based Neural Language Model For Readers' Emotion Detection",
  "published": "2023-01-21T19:28:25Z",
  "authors": [
    "Anoop Kadan",
    "Deepak P.",
    "Manjary P. Gangan",
    "Savitha Sam Abraham",
    "Lajish V. L"
  ],
  "keywords": [
    "Readers' Emotion Detection",
    "Textual Emotion Detection",
    "Affective Computing",
    "Affect Enriched Embedding",
    "Language Model",
    "Deep Learning"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Technological advancements in web platforms allow people to express and share emotions towards textual write-ups written and shared by others. This brings about different interesting domains for analysis; emotion expressed by the writer and emotion elicited from the readers. In this paper, we propose a novel approach for Readers' Emotion Detection from short-text documents using a deep learning model called REDAf-fectiveLM. Within state-of-the-art NLP tasks, it is well understood that utilizing context-specific representations from transformer-based pretrained language models helps achieve improved performance. Within this affective computing task, we explore how incorporating affective information can further enhance performance. Towards this, we leverage context-specific and affect enriched representations by using a transformer-based pre-trained language model in tandem with affect enriched Bi-LSTM+Attention. For empirical evaluation, we procure a new dataset REN-20k, besides using RENh-4k and SemEval-2007. We evaluate the performance of our REDAffectiveLM rigorously across",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Social media advancements fueled by rapid developments in information technology have become an effective medium for expressing emotions across a wide variety of topics. New conventions that heavily use affective symbols like emojis and emotion reactions (e.g., emotion reactions in Facebook, Twitter, etc.) within text-based communication have enriched the density of emotion expression within social media. This deluge of social interactions provides two different perspectives for textual emotion detection research i.e., through 'Writer Emotion', emotion expressed by the writer and 'Readers' Emotion', emotion elicited from the readers. This poses an interesting dichotomy in textual emotion detection, as the writer's intended emotions may not always be identical or in sync with the emotions generated for the readers. This makes readers' emotion detection an interesting arena for research. Considering the readers' perspective helps to infer emotion influence of the writer on readers', and also to understand other determinants of readers' emotions such as lexical word combinations or patterns in a document. These would enable novel applications such as emotion enabled information retrieval for creation of emotion-aware search engines/recommendation systems  [1] , emotion enriched article generation using syntactic and semantic rules of language along with its emotional impact  [2] , article auditing and writer influence forecasting for automatically modulating emotionally sensitive contents, evaluating and regulating the provocation potential of articles, modeling of aesthetic emotion in poetry  [3]  and other tasks that can be conceptualized.\n\nThe works in literature that specifically address readers' perspective of emotion detection  [4] [5] [6] [7]  are very few among the vast area of textual emotion detection. Methods for this may be categorized into three streams viz., lexicon based  [4, 8] , classical machine learning  [5, 9]  and deep learning  [6, 7] . A major set of works are seen to be built over the backdrop of conventional semantic word embeddings  [6, 7] , which are powerful enough to identify similarities between words in near context; but a notable limitation due to the smaller window of neighboring words enables many times the contradictory affective words (emotion words) to share almost similar word representations (e.g. 'good' and 'bad') while learning these word embeddings  [10] . This leads to degradation in performance among the affective computing related tasks such as sentiment analysis and emotion detection, and brings more suitable ways of word embeddings to encode affective information such as sentiment-specific  [11]  and affect enriched  [12, 13]  embeddings. But even though an affective computing task, there has rarely been any work in text emotion detection that utilizes affect enriched word embedding  [14]  and none specific to readers' emotion detection, to our best knowledge. Textual emotion detection works in this context would be that of Chatterjee et al.  [14]  proposing SS-BED, a sentiment specific word embedding, and Kratzwald et al.  [15]  proposing sent2affect, a sentiment aided transfer learning from source network trained for sentiment analysis task to a target textual emotion detection network without direct affect enrichment in embedding; but both these works consider coarse-grained sentiment enrichment rather than affect enrichment required to suit the much fine-grained task of detecting diverse emotion classes. Even though the above mentioned representations/embeddings provide useful advancements, they are only capable of encoding the syntactic information and the word sense, but mostly miss to represent different meanings of the same word as a function of its context (e.g. the word 'bank' have different meanings in the context of words such as 'river' and 'finance'). The recent transformer-based autoregressive and autoencoding pre-trained neural language models like BERT  [16] , GPT  [17] , XLNet  [18] , etc., have explored representing context specific, deeper and generic linguistic characteristics, thereby improving the performance, with the capability to fine-tune the architecture according to different NLP downstream tasks. These transformer-based language models are recently used in textual emotion detection  [19] , even though not specifically in readers' emotion detection, and are seen to obtain improved predictions. There are also works in textual emotion detection that combines transformer-based language model with graph convolutional network  [2] , and Bi-LSTM learned from language-model  [20] ; these works predominantly rely on context-specific representations learned from the transformer-based language models. These context-specific representations from the pre-trained language models lack an explicit orientation towards representing affective information, something that is quite critical for affective computing tasks. We believe that utilizing affective information along with these context-specific representations would be highly beneficial for the task of readers' emotion detection, as they are seen to produce better results when utilized in affective computing related tasks such as sentiment analysis, personality detection, etc.,  [13] . The t-SNE visualizations 1 of d-dimensional word representations of a few affective words, for conventional semantic embedding (GloVe  [21] ) and affect enriched embedding (proposed in  [12] ) shown in figure  1  demonstrates that compared to conventional semantic embedding, affect enrichment helps to cluster emotionally similar words into neighboring spaces. That is, affect enriched word embedding can encode affective information efficiently over conventional semantic embedding, which makes it more preferable for our task of readers' emotion detection than conventional semantic embedding. Therefore, we, to the best of our knowledge, for the first time attempt to leverage the utility of both the context-specific and affect enriched representations for the task of readers' emotion detection by proposing a deep learning based model REDAf-fectiveLM built by fusing a transformer-based pre-trained language model with an affect enriched Bi-LSTM+Attention network. Our readers' emotion detection methodology is inspired from state-of-theart research for natural language processing and affective computing that explores the combination of pre-trained language models with various networks to improve the overall model performance  [2, 20] . The choice of transformerbased pre-trained language model XLNet  [18] , as we will detail, is motivated by its efficacy to combine the qualities of both autoregressive (e.g. GPT  [17] ) and autoencoding (e.g. BERT  [16] ) pre-trained language models and produce improved performance over affective computing related tasks like sentiment analysis  [18] . The choice of affect enriched Bi-LSTM+Attention as the deep learning model is motivated by the pre-eminence of Bi-LSTM within related tasks and from the work proposed in  [13]  that demonstrates affect enrichment can improve performance of affective computing tasks. Bi-LSTM has the capability to learn long-term dependencies without keeping duplicate context representations and perform sequential modeling in both directions  [22, 23] ,\n\nand attention has the potential to enrich model performance  [24]  while also improving transparency of decision making and emerging as a prominent way of infusing interpretability within neural black box models  [25] .\n\nOur study is conducted over news documents that are short-text in nature, and we follow multi-target regression settings  [6, 26]  that, beyond emotion classes, also provide information on emotion intensities, unlike the major category of single/multi-class or multi-label classification settings that only work on predicting emotion classes  [5, 9, 27] . Towards representing readers' emotions, similar to the works  [7, 14, 15, 28] , we utilize Paul Ekman's discrete basic emotions anger, disgust, fear, joy, sadness, and surprise  [29] , the frequently discussed emotions among the theorists in discrete emotion models, that also matches emotions provided in most online platforms for the readers to cast their emotions towards a post or news. The major contributions of this work are:\n\n• We propose a novel deep learning approach for Readers' Emotion Detection called REDAffectiveLM to predict readers' emotion profiles from short-text documents. This, in a novel direction, leverages both context-specific and affect enriched representations by fusing a transformer-based pre-trained neural language model and a Bi-LSTM+Attention network that utilizes affect enriched embedding. • We evaluate the performance of our REDAffectiveLM rigorously against a vast set of state-of-the-art baselines, where our method consistently outperforms baselines belonging to different categories of textual emotion detection, providing statistically significant improvements on fine-grained and coarse-grained evaluation measures. We also conduct a detailed analysis over the affect enriched Bi-LSTM+Attention network to understand the impact of affect enrichment specifically in readers' emotion detection using qualitative and quantitative behavior evaluation techniques. • We procure a new Readers' Emotion News dataset REN-20k, with more than 20000 news documents and associated readers' emotion profiles, to conduct our study. As our dataset also includes genre information of news documents, it can also be utilized for heterogeneous tasks such as document summarization and genre classification at various scales i.e., short-text and log-text. We shall contribute REN-20k at https://dcs.uoc.ac.in/cida/resources/ren-20k. html publicly as soon as this work is accepted for publication.\n\nThe rest of the paper is organized as, section 2 provides the detailed description of our proposed deep learning model for readers' emotion detection followed by section 3 explaining the empirical study including details of the datasets, experimental settings, description of baselines and performance evaluation measures. The results and discussion in section 4 initially discuss the performance evaluation of our proposed model by comparing against the baselines, followed by the behavior analysis of affect enrichment in readers' emotion detection. Finally, section 5 draws the conclusions.",
      "page_start": 2,
      "page_end": 5
    },
    {
      "section_name": "Methodology",
      "text": "This section presents our method for detecting Readers' Emotions from textual documents. We first discuss the problem settings followed by the architecture of our proposed model, REDAffectiveLM.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Problem Setting",
      "text": "We formulate our task of readers' emotions detection as a multi-target regression problem. In other words, for each document, the model predicts readers' emotion profile i.e., intensities of the emotion classes anger, fear, joy, sadness, and surprise. Each document d consists of a sequence of N words, d = w 1 , w 2 , . . . , w N , where each word w i is taken from the vocabulary of V unique words denoted by, V = {w 1 , w 2 , . . . , w V }. The readers' emotion profile for each document, which forms the gold-standard labelled data for training, is formed from votes cast by multiple readers', which is normalized for E distinct emotions, represented as, ep r (d) = {e 1 , e 2 , . . . , e E }, where, e i ∈ [0, 1] and E i=1 e i = 1. Thus, the labelled corpus\n\nrepresents M documents along with their corresponding emotion profiles. We then follow a deep neural network based methodology to find the best fit mapping function f : H → ep r (d), that predicts readers' emotion profile, ep r (d), for document vector H of the document d.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Proposed Model",
      "text": "We propose a deep learning based readers' emotion detection system, REDAf-fectiveLM by parallely fusing two different networks, where the first emoBi-LSTM+Attention network is meant to produce affect enriched document representation and the second XLNet network for context-specific representation. We start by discussing the two networks in detail and later outline the complete architecture of our fused model, REDAffectiveLM. An overall sketch of our proposed model is illustrated in figure 2.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Emobi-Lstm+Attention For Affect Enriched Document Representation",
      "text": "In the emoBi-LSTM+Attention network, input documents are initially subject to Affect Enriched Word Embedding. To construct affect enriched word representations, denoted as emoGloVe, we utilize the state-of-the-art method using counter-fitting and emotional constraints 2  proposed by Seyeditabari et al.  [12]  over a pre-trained conventional semantic embedding GloVe  [21] . After generating affect enriched word representations, towards producing affect enriched document representations, we utilize Bi-LSTM  [30] , a prominent RNN based Fig.  2 : The proposed readers' emotion detection system, REDAffectiveLM architecture in combination with an Attention layer  [31] . The choice of Bi-LSTM network is motivated by its advantages such as the ability to learn long term dependencies  [22]  and to perform sequential modeling in both left to right ( ------→ f orward) and right to left ( ←-----backward) directions which helps in producing excellent performance gains  [23] . In addition, Attention on top of the Bi-LSTM network is observed to increase the overall model performance for the task of readers' emotion detection  [7]  and also the related task of sentiment analysis  [24] . Attention's mechanism of assigning corresponding weightages to words in the documents based on their relevance in emotion prediction also helps yet another objective of analyzing behavior of our network towards readers' emotion detection. That is, in total, our choice of affect enriched word embedding and Bi-LSTM+Attention network, is based on the motivation that this combination should significantly contribute towards improving the overall model performance and moreover, allows to investigate the network behavior systematically to analyze the impact of affect enrichment in readers' emotion detection. As we will see later (in section 4.2), we also analyze whether the attentions are influenced by emotion words and named entities, which are categories of words that we believe, hold much sway in determining affect.\n\nBi-LSTM network is initially fed with the affect enriched word representations -→ w i of input document d, and it processes these sequential inputs in both forward and backward directions producing affect enriched contextual representation of the document as output vector. That is, a single layer h l in the Bi-LSTM network is defined as [ -→ h l ; ←h l ], a concatenation of forward processing ( -→ h l ) and backward processing ( ←h l ) hidden layers with parameters Θ f and Θ b respectively, denoted as,\n\nTo build Attention on top of Bi-LSTM, we adopt the popular mechanism proposed in  [31] , where the final hidden layer of Bi-LSTM h n taken as the document summary vector Z is passed to an alignment model, a feedforward network which is trained along with the model. With the learnable weight parameters W h , W Z ∈ R a×b and v ∈ R a , the alignment model generates a scalar value u i , which on application of softmax function delivers the set of word weightages α i indicating the significance of each hidden state h i as, i.e.,\n\nThen, the final affect enriched document representation H 1 is computed as,",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "Xlnet For Context-Specific Document Representation",
      "text": "Transformer-based pre-trained language models are popular due to their efficacy in modeling linguistic relations and generating efficient context-specific document representations from various unlabelled text corpora; their effectiveness is evidenced by the promising results achieved for several downstream NLP tasks  [16, 18] . To learn such a document representation for our task, we adopt a popular transformer-based pre-trained language model, XLNet  [18] , as the second network of our model. The choice of XLNet is motivated from its capability to enable bi-directional context representation through permutation of the factorization order, overcomes pretrain-finetune-discrepancy of autoencoding language models like BERT  [16] , and produces remarkable results for the very related affective computing task of sentiment analysis  [18] .\n\nIn the second network, initially, the text document, d with a sequence of N words, d = w 1 , w 2 , . . . , w N , is converted to encoded-word tokens, EW = Ew 1 , Ew 2 , . . . , Ew m , using the popular SentencePiece language-independent subword tokenization and detokenization module  [32] , where, |m| = |N |, and Ew i indicates encoded subword representation obtained by subdividing a single word into several subword units. The encoded data EW is then fed to the pre-trained XLNet, which enables to fine-tune the architecture weights and hence to learn task-specific contextual document representations H 2 denoted as,",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Redaffectivelm : The Fused Model For Readers' Emotion Detection",
      "text": "To build our Readers' Emotion Detection model, REDAffectiveLM, that leverages the utility of Affect Enriched Document Representation and Context-specific Document Representation, we fuse the two networks, emoBi-LSTM+Attention and XLNet. In the fused model, the affect enriched document vector H 1 from emoBi-LSTM+Attention and context-specific document vector H 2 from XLNet are concatenated to form a single document vector H, defined as,\n\nFinally, to predict readers' emotion profiles, we feed the concatenated document vector H to a fully connected neural network module. Our neural network module that consists of a Multi-Layer Perceptron (MLP) having two fully connected dense hidden layers with 1224 neurons in each layer and an output layer with 5 neurons predicts normalized probability distribution of readers' emotion profiles ep r (d), given as,\n\nThe learning process, computes and back propagates the loss between predicted emotion profile ep r (d) and labelled vector ep r (d). After model training, we empirically evaluate emotion prediction performance and later evaluate the impact of affect enrichment qualitatively and quantitatively using document attention maps precipitated from the emoBi-LSTM+Attention network.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Empirical Study",
      "text": "In this section we first describe the details of datasets used in our study, followed by the experimental settings, baselines and evaluation measures used for model performance analysis.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Dataset",
      "text": "To conduct experiments we utilize three datasets, SemEval-2007  [28] , RENh-4k  [7]  and a newly curated Readers' Emotion News Dataset, REN-20k. We detail these herewith.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Semeval-2007",
      "text": "SemEval-2007  [28]  is a popularly used short-text benchmark dataset collected from online news portals The New York Times, CNN, BBC and Google News. This is an annotated dataset with 1250 documents, where each document that comprises news headlines is annotated by six readers to obtain the scores of Anger, Disgust, Fear, Joy, Sadness and Surprise emotion classes.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Renh-4K",
      "text": "RENh-4k  [7]  is a Readers' Emotion News headlines dataset with 4000 news documents belonging to the year span 2015 to 2018 collected from the news portal Rappler 3  . RENh-4k is short-text in nature, where each document comprises headlines and abstract of the news, and the corresponding emotion profiles of Afraid, Angry, Happy, Inspired, and Sad emotion classes are collected from the Mood Meter widget on the portal that records the percentage of votes cast by the readers for each emotion.",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Ren-20K",
      "text": "",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Dataset Pre-Processing",
      "text": "Since we utilize Paul Ekman's basic emotions  [29]  anger, disgust, fear, joy, sadness, and surprise in our study, we perform an initial dataset preprocessing as followed in  [7, 33] , where emotion labels of RENh-4k and REN-20k taken from Rappler Mood Meter are mapped to basic emotions. That is, we map Angry→Anger, Sad →Sadness, Afraid →Fear, Happy→Joy and Inspired →Surprise, and discard other Mood Meter emotions such as Don't care, Inspired, Amused, and Annoyed. As followed by  [7, 33] , we exclude Paul Ekman's basic emotion Disgust in our study as it does not have a matching emotion in the Rappler Mood Meter and for keeping a common set of five basic emotion labels across all the three datasets. We then perform a data normalization procedure where readers' emotion profiles are represented as a distribution of the chosen five basic emotions, by adopting the technique in  [34] . For better text representations, we perform data cleaning that removes frequently occurring noisy and unnecessary terms in the documents such as survey, report, (UPDATED), new-review and Midday-wRa, followed by other general set of pre-processing techniques such as text normalization and removal of punctuations and unknown symbols using NLTK toolkits  4  . Table  1  shows the detailed dataset statistics after pre-processing where, to compute the number of annotations in RENh-4k and REN-20k we utilize the procedure in  [35] , as the number of annotators or readers' are not known accurately, unlike six annotators explicitly mentioned in SemEval-2007.",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Baselines",
      "text": "To evaluate our REDAffectiveLM model, we compare its performance using various measures (detailed in 3.5) against popular and state-of-the-art baselines belonging to lexicon based, classical machine learning and deep learning categories (even though deep learning belongs under the umbrella of machine learning, we maintain deep learning baselines separately due to many notable contributions in the literature). Details of the baselines are as follows:\n\n• Deep Learning Baselines: In our set of deep learning baselines we reproduce a vast number of works that follow a wide variety of methodology. That is our choice of deep learning baselines include a recent readers' emotion detection work Readers'Affect  [7]  that utilizes Bi-LSTM+Attention architecture, textual emotion detection works sent2affect  [15]  that employs sentiment aided transfer learning and SS-BED  [14]  that utilize sentiment and semantic word embedding, a popular text classification architecture Kim's CNN  [36] , naïve RNN architectures, GRU, LSTM and Bi-LSTM used as baselines in various textual emotion detection works  [7, 14, 15] , and individual networks emoBi-LSTM+Attention and XLNet  [18]  used to construct our fused model (serving, implicitly as a form of ablation study). • Lexicon based Baselines: In this category of baselines we reproduce readers' emotion detection systems, SWAT  [8]  popular among the top three systems of shared task 'SemEval-2007 Task 14: Affective Text'  [28]  that utilize predefined sets of emotion words and Emotion Term Model  [4]  built over Naïve Bayes by incorporating emotion rating information and term independent assumption, and a promising textual emotion detection system Synesketch  [37]  that utilizes word-level lexicon and an emoticon lexicon in hybrid with several heuristic rule sets. • Classical Machine Learning Baselines: In this category of baselines, we reproduce the textual emotion detection method proposed in  [38]  that utilizes Word Mover's Distance (WMD) as a feature computed with the help of pre-trained word embeddings and provided to an SVM classifier (to implement this work, we instead use Support Vector Regression (SVR)  6  that suits our multi-target regression task). We also reproduce a wide variety of linguistic and affective features that are used in several textual emotion detection studies along with various multi-target regression models. The features considered are TF-IDF  [15, 38] , N-Grams  [14, 39] , General Purpose Emotion Lexicon Features  [39]  that includes Total Emotion Count (TEC), Total Emotion Intensity (TEI), Max Emotion Intensity (MEI), Graded Emotion Count (GEC), and Graded Emotion Intensity (GEI), extracted using the general purpose emotion lexicon DepecheMood++  [40] , Sentiment word count feature  [39, 41]  computed using VADER  [42] , Embedding Features  [11, 14]  that includes the semantic embeddings Word2Vec, GloVe and Fast-Text, and Sentiment Specific Word Embedding, SSWE u proposed in  [11] . For implementing the multi-target regression models, we adopt both problem transformation and algorithm adaptation techniques. In problem transformation approach we use Ridge Regression  7  and in algorithm adaptation we use MLP  8  .\n\nThe hyper-parameters used to implement/reproduce the baselines GRU, LSTM, Bi-LSTM, Readers' Affect (Bi-LSTM+Attention) and emoBi-LSTM+Attention are, a single RNN stack, 100 neurons in a stack, pre-trained GloVe embedding with dimension 100, MSE loss function, Adam optimizer, softmax activation function in dense layer and 100 epochs. Except GRU for the other above-mentioned baselines regularizer is l2(0.001), dropout is 0.5, learning rate is 0.0005 and batch size is 128, whereas, for GRU, regularizer is l2(0.01), dropout is 0.25, learning rate is 0.005 and batch size is 64. For Kim's CNN the number of filters are 100, filter sizes are 3, 4 and 5, dropout is 0.5, learning rate is 0.0005, and all other hyper-parameters are the same as GRU.\n\nFor MLP, in the algorithm adaptation approach, we use a hidden layer with 128 neurons, ReLU activation, batch size of 64 and all other hyper-parameters are the same as LSTM.",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "Performance Evaluation Measures",
      "text": "We choose various performance evaluation measures that are popularly used to evaluate textual emotion detection models  [4, 14, 34, 43] . Accordingly, for evaluating the performance of readers' emotion detection we consider coarsegrained measures that look at correctness of our regression task by mapping predicted emotions to 0/1 classes, and fine-grained measures that look at nearness of predicted emotions to the ground truth at a finer granularity  [7, 44] .\n\nFor coarse-grained evaluation, we use Acc@1  [4, 7, 34, 43] , i.e., accuracy of the top first emotion prediction, representing micro-averaged F1 measure  [45] .\n\nFor fine-grained evaluations, we use correlation based measures AP document and AP emotion  [7, 43]  computing similarity of predicted emotion profiles with ground-truth, over emotions and documents respectively, and error/distance measures Root Mean Square Error (RMSE)  [7, 14]  and Wasserstein Distance (WD)  [7, 46]  computing the distance of predicted emotion profiles from ground-truth.\n\n• Acc@1 of a corpus is an average of Acc d @1 computed for all documents in the corpus. i.e., Acc\n\nSince Acc@1 measures the accuracy, higher values are better. • AP document of a corpus is the Average Pearson's correlation coefficient of all documents in the corpus obtained by averaging Pearson's correlation coefficient P d between prediction and ground-truth of each document d, over |E| number of emotion classes.\n\nwhere, -\n\n• RMSE D of the corpus is an error metric computed by averaging RMSE of all documents. RMSE of a document d is given by,\n\nSince RMSE D measures the deviation between prediction and ground-truth, lower values are better. • WD D of a corpus is a distance metric obtained by averaging WD of all documents in the corpus. WD of a document d is the infimum for any transport plane computed as,\n\nwhere, π(X d , Y d ) is the set of all possible joint probability distribution γ(x, y) whose marginals are X d and Y d , respectively. Lower values of WD D indicate good performance.",
      "page_start": 13,
      "page_end": 14
    },
    {
      "section_name": "Results And Discussions",
      "text": "In this section we present the results of our experimental evaluations. Initially, we present the performance analysis of our proposed REDAffectiveLM model by comparing against a vast set of baselines from across families of lexicon based, classical machine learning, and deep learning including the individual emoBi-LSTM+Attention and XLNet networks of our model (that implicitly serves as a form of ablation study) to understand the gains achieved by our proposed model. We then perform statistical significance tests between our model and the best baseline. Finally, we also conduct behavior analysis of the emoBi-LSTM+Attention network through a set of qualitative and quantitative experiments to identify the impact of affect enrichment for the task of readers' emotion detection.    and 5 .97 percentage points compared to algorithm adaptation best results for the same set of measures, respectively. The entire results over the three datasets thus consolidate that our REDAffectiveLM model achieves best performance results when considering the top-ranked readers' emotion prediction (Acc@1) and overall readers' emotion profile prediction (AP document and AP emotion ), and also obtains lower error/distance values (RMSE D and WD D ).",
      "page_start": 15,
      "page_end": 15
    },
    {
      "section_name": "Model Performance Evaluation",
      "text": "Across the three datasets, XLNet and emoBi-LSTM+Attention, individual networks of our model are the top two performing baselines in the deep learning category and even among the entire set of baselines belonging to the other categories. We believe this is because XLNet is a promising transformer based pre-trained language model that generates powerful contextual representations and, emoBi-LSTM+Attention enriches the conventional semantic representations with 'affect' that is evidently visible through the gains achieved by emoBi-LSTM+Attention (affect enriched) over Bi-LSTM+Attention (conventional) across the three datasets, for all the evaluation measures. But when comparing these individual networks with our model, the lowest among the gains achieved by our model, across the three datasets, are itself noteworthy. That is our model obtains a minimum gain of 7.38, 4.68, 2.96, 5.29 and 2.48 percentage points over XLNet and 8.77, 6.36, 5.97, 5.96, and 3.75 percentage points over emoBi-LSTM+Attention, for measures Acc@1, AP document , AP emotion , RMSE D and WD D , respectively. This indicates the promising nature of our REDAffectiveLM model towards readers' emotion detection, over these ablation or individual networks, leveraging both affect enriched document representation and contextual representation from transformer based pre-trained language model, effectively.\n\nTrends of evaluation results across the three datasets illustrate another point that the dataset SemEval-2007 obtains performance slightly better than RENh-4k even though it has comparably less data. This might be because SemEval-2007 being labeled by only six annotators is less complex in nature, whereas RENh-4k with 242680 and REN-20k with 2556654 minimum number of annotators make their ground truth emotion profiles complex in nature with several real-world contradictory readers' votings. Therefore, we analyze the complexity of datasets in terms of the number of reader annotations by computing Pearson's correlation  [26]  between emotions and plot these correlations in figure  3 , where dark and light colors indicate high and low correlations respectively. SemEval-2007 shows many natural correlations, for e.g., high correlations that exist between anger -fear, anger -sadness, etc., but such correlations are less in RENh-4k and REN-20k. Similarly, in RENh-4k and REN-20k for contradictory emotion pairs, for e.g., joy-fear the correlations are comparatively higher than SemEval-2007. Such complex irregularities that emerge due to real-world scenario of differences in emotion expression among the readers might make it difficult for a model to generalize the learning process, thereby comparatively reducing performance for RENh-4k; but the vast amount of data in REN-20k, i.e., almost 5 times larger than RENh-4k, might be the reason for the model to overcome this difficulty in learning complex patterns, eventually obtaining noteworthy gains. Besides looking into the performance gain obtained by our model over the baselines, we also analyze the statistical significance of our model performance with respect to Acc@1 and RMSE, the coarse-grained and fine-grained measures that ideally represent classification and regression task characteristics, respectively. We compute statistical significance between our REDAffectiveLM model and the best performing baseline by conducting McNemar's and Kolmogorov-Smirnov tests over Acc@1 and RMSE, respectively with conventional significance level (i.e., p-value 0.05). The p-values obtained for REN-20k, RENh-4k, and SemEval-2007 are 1.64E-5, 2.15E-3 and 5.07E-3 for Acc@1 and 1.80E-6, 3.47E-4 and 6.19E-4 for RMSE, respectively, indicating statistical significance of our model REDAffectiveLM over the best baselines.",
      "page_start": 17,
      "page_end": 17
    },
    {
      "section_name": "Behavior Analysis Of Affect Enrichment",
      "text": "In this section, we analyze the impact of affect enrichment specifically for our task of readers' emotion detection, to verify its effectiveness over conventional semantic embedding. Besides the performance comparison of emoBi-LSTM+Attention (Bi-LSTM+Attention fed with affect enriched embedding) and Bi-LSTM+Attention (Bi-LSTM+Attention fed with conventional semantic embedding), in the above section 4.1 by considering them as baselines in our empirical evaluation, here, we analyze the behavior of these networks. Our set of qualitative and quantitative behavior analysis compares the Attention Maps of emoBi-LSTM+Attention and Bi-LSTM+Attention precipitated from these attention based models along with readers' emotion profiles that highlight key terms with corresponding weightage based on their role in readers' emotion prediction (or decision making). That is, specifically, we look at the behavior of emoBi-LSTM+Attention network to understand whether the network has efficiently identified and assigned weightage to the key terms responsible for readers' emotion detection (i.e., emotion words and named entities  [7] ) to obtain significant performance gains in the predictions over Bi-LSTM+Attention.",
      "page_start": 18,
      "page_end": 18
    },
    {
      "section_name": "Qualitative Evaluation",
      "text": "In qualitative behavior evaluation, we manually compare the key terms (emotion words and named entities) highlighted in the attention maps and their associated weightage, of both Bi-LSTM+Attention and emoBi-LSTM+Attention. Table  5  shows pairs of attention maps for five sample documents, where in each pair, the first attention map is the one generated by Bi-LSTM+Attention and second by emoBi-LSTM+Attention, along with their associated ground-truth emotion profiles (ep r ) and predicted emotion profiles of both Bi-LSTM+Attention ( ep r ) and emoBi-LSTM+Attention ( ep rEmo ). In the attention maps, differing color intensities over the words represent weightage assigned to the words by the attention, i.e., dark red for high weightage and for lower weightage color intensities become lighter.\n\nIn the first pair, the attention map from Bi-LSTM+Attention significantly assigns weightage to an emotion word 'protest' and a named entity 'Pakistan'. Whereas, the attention map from emoBi-LSTM+Attention shows improvements in the prediction, i.e., nearness of prediction to ground truth, especially visible in the case of emotions fear and surprise by assigning significant weightage to the emotion word 'demolition'. In the second and third pair of attention maps, we can observe high improvements in prediction for emoBi-LSTM+Attention over Bi-LSTM+Attention, especially visible in the case of emotion anger by identifying the emotion word 'attackers' in the second pair, and emotion joy by identifying the emotion word 'sweet' in the third pair. Bi-LSTM+Attention, apart from failing to identify key terms (emotion words and named entities) such as 'demolition' in the first pair, 'attackers' in the second pair, 'sweet' in the third pair, etc., also are mostly seen to assign uniform weightage to the attention identified words. For example, in the fourth pair, the words 'car' and 'teenager' are given almost the same high intensity as the words 'danger' and 'health'. But in the case of emoBi-LSTM+Attention, weightage for the words 'car' and 'teenager' are seen to be diminished than 'danger' and 'health'. Similarly in the fifth pair, emoBi-LSTM+Attention assigns different weightage for the words 'within', 'completed', 'year', etc., whereas Bi-LSTM+Attention assigns almost similar weightage to these words. Hence the entire set of qualitative evaluations indicates that better than the Bi-LSTM+Attention that utilizes conventional semantic embedding, the affect enriched embedding based network emoBi-LSTM+Attention, can effectively identify and assign weightage to the key terms responsible for readers' emotion detection thereby improving nearness of predictions to the ground-truth.",
      "page_start": 21,
      "page_end": 22
    },
    {
      "section_name": "Quantitative Evaluation",
      "text": "Apart from the above mentioned qualitative behavior evaluation, we perform quantitative behavior analysis comparing capabilities of emoBi-LSTM+Attention and Bi-LSTM+Attention models in identifying key terms responsible for readers' emotion detection. For quantitative analysis, we follow the approach similar to  [7]  that checks the similarity between the External Attention Map representing the set of all emotion words and named entities in a document, and the Hybrid Attention Map representing the set of all emotion words and named entities in a document assigned with a weightage by attention mechanism; where high similarity between these attention maps indicate that the model efficiently utilizes key terms for decision making. External attention maps are binary maps created by highlighting only the emotion words and named entities in a document with a weightage of one and the rest with a zero weightage. Whereas, the hybrid attention map highlights only the emotion words and named entities in a document that have acquired non-zero attention weightage in both the model generated attention map and the external attention map, with weightage of the word copied from model generated maps; it can also be represented as binary maps by replacing the non-zero weightage with one. To create these attention maps, we use the popular emotion lexicons DepecheMood++  [40]  and EmoWordNet  [33]  and Named Entity Recognizer (NER) from spaCy  10  . We generate external (EAM) and hybrid (HAM) attention maps for both emoBi-LSTM+Attention and Bi-LSTM+Attention models where for each model we contrast the extent of deviation between these attention maps using the similarity measures behavioral similarity, word similarity, and word probability  [7] , discussed below.\n\n• Behavioral Similarity of a corpus D is the average of pair-wise similarity between HAM (taken as continuous) and EAM for each document d in the corpus.\n\nwhere, AU C is Area Under Curve that ranges from 0 (indicating negative similarity) to 1 (indicating perfect similarity)  [25] . • Word Similarity between is the average document cosine similarity  11 between HAM (taken as binary) and EAM.\n\nwhere, |D | is the total number of documents without any emotion words or named entities. • Word Probability of a corpus finds boolean intersection between binary HAM and EAM, averaged over the documents, to quantify how much among the total number of emotion words and named entities in the document are identified by attention.\n\nwhere, λ = 1 for EAM = 0, and λ = 0 for EAM = 0.\n\nThe results of quantitative analysis shown in table  6  illustrate that for all the three datasets emoBi-LSTM+Attention obtains higher similarity scores between external and hybrid attention maps when compared to Bi-LSTM+Attention, for both the lexicons, which indicates that compared to Bi-LSTM+Attention model, emoBi-LSTM+Attention has improved ability to identify emotion words and named entities. Against the backdrop of  [7]  that demonstrates emotion words and named entities are important for emotion detection, this validates emoBi-LSTM+Attention's improved suitability for emotion identification. Thus, the qualitative and quantitative behavior analysis on emoBi-LSTM+Attention together establishes that affect enrichment increases the ability of the model to effectively identify emotion words, and assign weightage to the key terms responsible for readers' emotion detection to improve prediction.",
      "page_start": 23,
      "page_end": 23
    },
    {
      "section_name": "Conclusion",
      "text": "Context-specific representations from transformer-based pre-trained language models help textual emotion detection systems to achieve improved performance which, being an affective computing task, can be further enhanced by incorporating affective information. Inspired by this line of thought, in this paper, we proposed a novel deep learning model, REDAffec-tiveLM that leverages context-specific and affect enriched representations by fusing a transformer-based pre-trained language model XLNet with, Bi-LSTM+Attention that utilizes affect enriched embedding, to predict readers' emotion profiles from short-text documents. The performance of our proposed model was evaluated using coarse-grained and fine-grained measures, across three datasets, the benchmark SemEval-2007, RENh-4k and our newly procured REN-20k, where our model consistently outperformed a vast set of deep learning, lexicon based, and classical machine learning baselines in textual emotion detection and obtained statistically significant results. The evaluation results of our fused model REDAffectiveLM when compared with the individual affect enriched Bi-LSTM+Attention and XLNet networks, obtained high gains in performance for all the evaluation measures, across all three datasets. This establishes that our REDAffectiveLM model that utilizes highly efficient contextual representation from transformer-based pretrained language model along with affect enriched document representation can significantly improve the performance of readers' emotion detection. We also performed a detailed qualitative and quantitative behavior analysis over affect enriched Bi-LSTM+Attention to study the impact of affect enrichment specifically in readers' emotion detection. We observed that compared to conventional semantic embedding, affect enrichment obtained higher performance and helped to increase the ability of the network to effectively identify and assign weightage to key terms (emotion words and named entities) responsible for readers' emotion detection. To aid future research, the datasets and other relevant materials, including the source code will be made publicly available at https://dcs.uoc.ac.in/cida/projects/ac/redaffectivelm.html and https: //github.com/anoopkdcs/REDAffectiveLM soon as this work is accepted for publication. In the future, we are planning to explore the possibilities of developing affect enriched transformer-based language models. We are also planning to explore the applicability of affect enriched transformer-based language models in affective well-being tasks such as early detection of anxiety and depression from social networks.\n\nAcknowledgments. The authors thankfully acknowledge the popular leading digital media company RAPPLER for the data source of news data along with associated emotions from their online portal that very relevantly helped to conduct this research. The authors thankfully acknowledge Arjun K. Sreedhar, Dheeraj K., Sarath Kumar P. S., and Vishnu S.",
      "page_start": 24,
      "page_end": 25
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: t-SNE visualization of few aﬀective words related to basic emotions",
      "page": 4
    },
    {
      "caption": "Figure 2: The proposed readers’ emotion detection system, REDAﬀectiveLM",
      "page": 7
    },
    {
      "caption": "Figure 3: Emotion proﬁle correlations in the datasets",
      "page": 20
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "lajish@uoc.ac.in;": "Abstract"
        },
        {
          "lajish@uoc.ac.in;": "Technological advancements\nin web platforms allow people\nto express"
        },
        {
          "lajish@uoc.ac.in;": "and share\nemotions\ntowards\ntextual write-ups written and shared by"
        },
        {
          "lajish@uoc.ac.in;": "others. This brings about diﬀerent interesting domains for analysis; emo-"
        },
        {
          "lajish@uoc.ac.in;": "tion expressed by the writer and emotion elicited from the readers.\nIn"
        },
        {
          "lajish@uoc.ac.in;": "this paper, we propose a novel approach for Readers’ Emotion Detection"
        },
        {
          "lajish@uoc.ac.in;": "from short-text documents using a deep learning model called REDAf-"
        },
        {
          "lajish@uoc.ac.in;": "fectiveLM. Within state-of-the-art NLP tasks,\nit is well understood that"
        },
        {
          "lajish@uoc.ac.in;": "utilizing\ncontext-speciﬁc\nrepresentations\nfrom transformer-based\npre-"
        },
        {
          "lajish@uoc.ac.in;": "trained language models helps achieve\nimproved performance. Within"
        },
        {
          "lajish@uoc.ac.in;": "this\naﬀective\ncomputing\ntask, we\nexplore how incorporating\naﬀective"
        },
        {
          "lajish@uoc.ac.in;": "information can further enhance performance. Towards\nthis, we lever-"
        },
        {
          "lajish@uoc.ac.in;": "age\ncontext-speciﬁc\nand\naﬀect\nenriched\nrepresentations\nby\nusing\na"
        },
        {
          "lajish@uoc.ac.in;": "transformer-based pre-trained language model\nin tandem with aﬀect"
        },
        {
          "lajish@uoc.ac.in;": "enriched Bi-LSTM+Attention. For\nempirical\nevaluation, we procure a"
        },
        {
          "lajish@uoc.ac.in;": "new dataset REN-20k, besides using RENh-4k and SemEval-2007. We"
        },
        {
          "lajish@uoc.ac.in;": "evaluate\nthe\nperformance\nof\nour REDAﬀectiveLM rigorously\nacross"
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "REDAﬀectiveLM": "these datasets,\nagainst\na vast\nset\nof"
        },
        {
          "REDAﬀectiveLM": "our model\nconsistently outperforms baselines and obtains"
        },
        {
          "REDAﬀectiveLM": "signiﬁcant results. Our results establish that utilizing aﬀect enriched rep-"
        },
        {
          "REDAﬀectiveLM": "resentation along with context-speciﬁc"
        },
        {
          "REDAﬀectiveLM": "architecture can considerably enhance readers’ emotion detection. Since"
        },
        {
          "REDAﬀectiveLM": "the impact of aﬀect enrichment speciﬁcally in readers’ emotion detection"
        },
        {
          "REDAﬀectiveLM": "isn’t well explored, we conduct a detailed analysis over aﬀect enriched"
        },
        {
          "REDAﬀectiveLM": "Bi-LSTM+Attention using qualitative and quantitative model behav-"
        },
        {
          "REDAﬀectiveLM": "ior\nevaluation techniques. We observe\nthat"
        },
        {
          "REDAﬀectiveLM": "semantic\nembedding,\naﬀect\nenriched embedding\nincreases"
        },
        {
          "REDAﬀectiveLM": "of\nthe network to eﬀectively identify and assign weightage"
        },
        {
          "REDAﬀectiveLM": "terms responsible for readers’ emotion detection to improve prediction."
        },
        {
          "REDAﬀectiveLM": "Keywords: Readers’ Emotion Detection, Textual Emotion Detection,"
        },
        {
          "REDAﬀectiveLM": "Aﬀective Computing, Aﬀect Enriched Embedding, Language Model, Deep"
        },
        {
          "REDAﬀectiveLM": "Learning"
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Learning": "1 Introduction"
        },
        {
          "Learning": "Social media advancements fueled by rapid developments in information tech-"
        },
        {
          "Learning": "nology have become an eﬀective medium for\nexpressing emotions across a"
        },
        {
          "Learning": "wide variety of topics. New conventions that heavily use aﬀective symbols like"
        },
        {
          "Learning": "emojis and emotion reactions\n(e.g., emotion reactions\nin Facebook, Twitter,"
        },
        {
          "Learning": "etc.) within text-based communication have enriched the density of emotion"
        },
        {
          "Learning": "expression within social media. This deluge\nof\nsocial\ninteractions provides"
        },
        {
          "Learning": "two diﬀerent perspectives for textual emotion detection research i.e., through"
        },
        {
          "Learning": "‘Writer Emotion’, emotion expressed by the writer and ‘Readers’ Emotion’,"
        },
        {
          "Learning": "emotion elicited from the readers. This poses an interesting dichotomy in tex-"
        },
        {
          "Learning": "tual emotion detection, as the writer’s intended emotions may not always be"
        },
        {
          "Learning": "identical or in sync with the emotions generated for the readers. This makes"
        },
        {
          "Learning": "readers’ emotion detection an interesting arena for research. Considering the"
        },
        {
          "Learning": "readers’ perspective helps\nto infer\nemotion inﬂuence of\nthe writer on read-"
        },
        {
          "Learning": "ers’, and also to understand other determinants of readers’ emotions such as"
        },
        {
          "Learning": "lexical word combinations or patterns\nin a document. These would enable"
        },
        {
          "Learning": "novel applications such as emotion enabled information retrieval\nfor creation of"
        },
        {
          "Learning": "emotion-aware search engines/recommendation systems [1], emotion enriched"
        },
        {
          "Learning": "article generation using syntactic and semantic rules of\nlanguage along with"
        },
        {
          "Learning": "its emotional\nimpact [2], article auditing and writer inﬂuence forecasting\nfor"
        },
        {
          "Learning": "automatically modulating emotionally sensitive contents, evaluating and reg-"
        },
        {
          "Learning": "ulating the provocation potential of articles, modeling of aesthetic emotion in"
        },
        {
          "Learning": "poetry [3] and other tasks that can be conceptualized."
        },
        {
          "Learning": "The works\nin literature\nthat\nspeciﬁcally address\nreaders’ perspective of"
        },
        {
          "Learning": "emotion detection [4–7] are very few among the vast area of textual emotion"
        },
        {
          "Learning": "detection. Methods for this may be categorized into three streams viz.,\nlexicon"
        },
        {
          "Learning": "based [4, 8], classical machine learning [5, 9] and deep learning [6, 7]. A major"
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "REDAﬀectiveLM\n3": "set of works are seen to be built over\nthe backdrop of conventional\nseman-"
        },
        {
          "REDAﬀectiveLM\n3": "tic word embeddings [6, 7], which are powerful enough to identify similarities"
        },
        {
          "REDAﬀectiveLM\n3": "between words in near context; but a notable limitation due to the smaller win-"
        },
        {
          "REDAﬀectiveLM\n3": "dow of neighboring words enables many times the contradictory aﬀective words"
        },
        {
          "REDAﬀectiveLM\n3": "(emotion words) to share almost similar word representations (e.g.\n‘good’ and"
        },
        {
          "REDAﬀectiveLM\n3": "‘bad’) while learning these word embeddings\n[10]. This\nleads\nto degradation"
        },
        {
          "REDAﬀectiveLM\n3": "in performance among the aﬀective computing related tasks such as sentiment"
        },
        {
          "REDAﬀectiveLM\n3": "analysis and emotion detection, and brings more suitable ways of word embed-"
        },
        {
          "REDAﬀectiveLM\n3": "dings to encode aﬀective information such as sentiment-speciﬁc [11] and aﬀect"
        },
        {
          "REDAﬀectiveLM\n3": "enriched [12, 13] embeddings. But even though an aﬀective computing task,"
        },
        {
          "REDAﬀectiveLM\n3": "there has rarely been any work in text emotion detection that utilizes aﬀect"
        },
        {
          "REDAﬀectiveLM\n3": "enriched word embedding [14] and none speciﬁc to readers’ emotion detection,"
        },
        {
          "REDAﬀectiveLM\n3": "to our best knowledge. Textual emotion detection works in this context would"
        },
        {
          "REDAﬀectiveLM\n3": "be that of Chatterjee et al.\n[14] proposing SS-BED, a sentiment speciﬁc word"
        },
        {
          "REDAﬀectiveLM\n3": "embedding, and Kratzwald et al.\n[15] proposing sent2aﬀect, a sentiment aided"
        },
        {
          "REDAﬀectiveLM\n3": "transfer\nlearning from source network trained for\nsentiment analysis\ntask to"
        },
        {
          "REDAﬀectiveLM\n3": "a target\ntextual emotion detection network without direct aﬀect enrichment"
        },
        {
          "REDAﬀectiveLM\n3": "in embedding; but both these works consider coarse-grained sentiment enrich-"
        },
        {
          "REDAﬀectiveLM\n3": "ment rather than aﬀect enrichment required to suit the much ﬁne-grained task"
        },
        {
          "REDAﬀectiveLM\n3": "of detecting diverse emotion classes. Even though the above mentioned rep-"
        },
        {
          "REDAﬀectiveLM\n3": "resentations/embeddings provide useful advancements, they are only capable"
        },
        {
          "REDAﬀectiveLM\n3": "of encoding the syntactic information and the word sense, but mostly miss to"
        },
        {
          "REDAﬀectiveLM\n3": "represent diﬀerent meanings of the same word as a function of its context (e.g."
        },
        {
          "REDAﬀectiveLM\n3": "the word ‘bank’ have diﬀerent meanings in the context of words such as ‘river’"
        },
        {
          "REDAﬀectiveLM\n3": "and ‘ﬁnance’). The recent transformer-based autoregressive and autoencoding"
        },
        {
          "REDAﬀectiveLM\n3": "pre-trained neural\nlanguage models\nlike BERT [16], GPT [17], XLNet\n[18],"
        },
        {
          "REDAﬀectiveLM\n3": "etc., have explored representing context\nspeciﬁc, deeper and generic linguis-"
        },
        {
          "REDAﬀectiveLM\n3": "tic characteristics, thereby improving the performance, with the capability to"
        },
        {
          "REDAﬀectiveLM\n3": "ﬁne-tune the architecture according to diﬀerent NLP downstream tasks. These"
        },
        {
          "REDAﬀectiveLM\n3": "transformer-based language models are recently used in textual emotion detec-"
        },
        {
          "REDAﬀectiveLM\n3": "tion [19], even though not speciﬁcally in readers’ emotion detection, and are"
        },
        {
          "REDAﬀectiveLM\n3": "seen to obtain improved predictions. There are also works in textual emotion"
        },
        {
          "REDAﬀectiveLM\n3": "detection that combines\ntransformer-based language model with graph con-"
        },
        {
          "REDAﬀectiveLM\n3": "volutional network [2], and Bi-LSTM learned from language-model\n[20]; these"
        },
        {
          "REDAﬀectiveLM\n3": "works predominantly rely on context-speciﬁc representations learned from the"
        },
        {
          "REDAﬀectiveLM\n3": "transformer-based language models."
        },
        {
          "REDAﬀectiveLM\n3": "These context-speciﬁc representations from the pre-trained language mod-"
        },
        {
          "REDAﬀectiveLM\n3": "els\nlack\nan explicit\norientation towards\nrepresenting\naﬀective\ninformation,"
        },
        {
          "REDAﬀectiveLM\n3": "something that is quite critical\nfor aﬀective computing tasks. We believe that"
        },
        {
          "REDAﬀectiveLM\n3": "utilizing\naﬀective\ninformation along with these\ncontext-speciﬁc\nrepresenta-"
        },
        {
          "REDAﬀectiveLM\n3": "tions would be highly beneﬁcial\nfor\nthe\ntask of\nreaders’\nemotion detection,"
        },
        {
          "REDAﬀectiveLM\n3": "as\nthey are\nseen to produce better\nresults when utilized in aﬀective\ncom-"
        },
        {
          "REDAﬀectiveLM\n3": "puting related tasks\nsuch as\nsentiment analysis, personality detection,\netc.,"
        },
        {
          "REDAﬀectiveLM\n3": "[13]. The t-SNE visualizations1 of d-dimensional word representations of a few"
        }
      ],
      "page": 3
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "4\nREDAﬀectiveLM": "aﬀective words,\nfor conventional semantic embedding (GloVe [21]) and aﬀect"
        },
        {
          "4\nREDAﬀectiveLM": "enriched embedding (proposed in [12])\nshown in ﬁgure 1 demonstrates\nthat"
        },
        {
          "4\nREDAﬀectiveLM": "compared to conventional semantic embedding, aﬀect enrichment helps to clus-"
        },
        {
          "4\nREDAﬀectiveLM": "ter emotionally similar words into neighboring spaces. That is, aﬀect enriched"
        },
        {
          "4\nREDAﬀectiveLM": "word embedding can encode aﬀective information eﬃciently over conventional"
        },
        {
          "4\nREDAﬀectiveLM": "semantic embedding, which makes it more preferable for our task of readers’"
        },
        {
          "4\nREDAﬀectiveLM": "emotion detection than conventional\nsemantic embedding. Therefore, we,\nto"
        },
        {
          "4\nREDAﬀectiveLM": "the best of our knowledge,\nfor\nthe ﬁrst\ntime attempt\nto leverage the utility"
        },
        {
          "4\nREDAﬀectiveLM": "of both the context-speciﬁc and aﬀect enriched representations for the task of"
        },
        {
          "4\nREDAﬀectiveLM": "readers’ emotion detection by proposing a deep learning based model REDAf-"
        },
        {
          "4\nREDAﬀectiveLM": "fectiveLM built by fusing a transformer-based pre-trained language model with"
        },
        {
          "4\nREDAﬀectiveLM": "an aﬀect enriched Bi-LSTM+Attention network."
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "REDAﬀectiveLM\n5": "and attention has\nthe potential\nto enrich model performance [24] while also"
        },
        {
          "REDAﬀectiveLM\n5": "improving transparency of decision making and emerging as a prominent way"
        },
        {
          "REDAﬀectiveLM\n5": "of\ninfusing interpretability within neural black box models [25]."
        },
        {
          "REDAﬀectiveLM\n5": "Our study is conducted over news documents that are short-text in nature,"
        },
        {
          "REDAﬀectiveLM\n5": "and we\nfollow multi-target\nregression settings\n[6, 26]\nthat, beyond emotion"
        },
        {
          "REDAﬀectiveLM\n5": "classes, also provide information on emotion intensities, unlike the major cat-"
        },
        {
          "REDAﬀectiveLM\n5": "egory of single/multi-class or multi-label classiﬁcation settings that only work"
        },
        {
          "REDAﬀectiveLM\n5": "on predicting emotion classes\n[5, 9, 27]. Towards\nrepresenting readers’ emo-"
        },
        {
          "REDAﬀectiveLM\n5": "tions, similar to the works [7, 14, 15, 28], we utilize Paul Ekman’s discrete basic"
        },
        {
          "REDAﬀectiveLM\n5": "emotions anger, disgust,\nfear,\njoy,\nsadness, and surprise\n[29],\nthe frequently"
        },
        {
          "REDAﬀectiveLM\n5": "discussed emotions among the theorists in discrete emotion models, that also"
        },
        {
          "REDAﬀectiveLM\n5": "matches emotions provided in most online platforms\nfor\nthe readers\nto cast"
        },
        {
          "REDAﬀectiveLM\n5": "their emotions towards a post or news."
        },
        {
          "REDAﬀectiveLM\n5": "The major contributions of this work are:"
        },
        {
          "REDAﬀectiveLM\n5": "• We propose a novel deep learning approach for Readers’ Emotion Detection"
        },
        {
          "REDAﬀectiveLM\n5": "called REDAﬀectiveLM to predict readers’ emotion proﬁles from short-text"
        },
        {
          "REDAﬀectiveLM\n5": "documents. This,\nin a novel direction,\nleverages both context-speciﬁc and"
        },
        {
          "REDAﬀectiveLM\n5": "aﬀect\nenriched representations by fusing a transformer-based pre-trained"
        },
        {
          "REDAﬀectiveLM\n5": "neural\nlanguage model\nand a Bi-LSTM+Attention network that utilizes"
        },
        {
          "REDAﬀectiveLM\n5": "aﬀect enriched embedding."
        },
        {
          "REDAﬀectiveLM\n5": "• We evaluate the performance of our REDAﬀectiveLM rigorously against a"
        },
        {
          "REDAﬀectiveLM\n5": "vast\nset of\nstate-of-the-art baselines, where our method consistently out-"
        },
        {
          "REDAﬀectiveLM\n5": "performs\nbaselines\nbelonging\nto\ndiﬀerent\ncategories\nof\ntextual\nemotion"
        },
        {
          "REDAﬀectiveLM\n5": "detection, providing statistically signiﬁcant\nimprovements on ﬁne-grained"
        },
        {
          "REDAﬀectiveLM\n5": "and coarse-grained evaluation measures. We also conduct a detailed analy-"
        },
        {
          "REDAﬀectiveLM\n5": "sis over the aﬀect enriched Bi-LSTM+Attention network to understand the"
        },
        {
          "REDAﬀectiveLM\n5": "impact of aﬀect enrichment speciﬁcally in readers’ emotion detection using"
        },
        {
          "REDAﬀectiveLM\n5": "qualitative and quantitative behavior evaluation techniques."
        },
        {
          "REDAﬀectiveLM\n5": "• We procure a new Readers’ Emotion News dataset REN-20k, with more than"
        },
        {
          "REDAﬀectiveLM\n5": "20000 news documents and associated readers’ emotion proﬁles, to conduct"
        },
        {
          "REDAﬀectiveLM\n5": "our study. As our dataset also includes genre information of news documents,"
        },
        {
          "REDAﬀectiveLM\n5": "it can also be utilized for heterogeneous tasks such as document summariza-"
        },
        {
          "REDAﬀectiveLM\n5": "tion and genre classiﬁcation at various scales i.e., short-text and log-text. We"
        },
        {
          "REDAﬀectiveLM\n5": "shall contribute REN-20k at https://dcs.uoc.ac.in/cida/resources/ren-20k."
        },
        {
          "REDAﬀectiveLM\n5": "html publicly as soon as this work is accepted for publication."
        },
        {
          "REDAﬀectiveLM\n5": "The\nrest\nof\nthe paper\nis\norganized as,\nsection 2 provides\nthe detailed"
        },
        {
          "REDAﬀectiveLM\n5": "description of our proposed deep learning model\nfor\nreaders’ emotion detec-"
        },
        {
          "REDAﬀectiveLM\n5": "tion followed by section 3 explaining the empirical study including details of"
        },
        {
          "REDAﬀectiveLM\n5": "the datasets, experimental settings, description of baselines and performance"
        },
        {
          "REDAﬀectiveLM\n5": "evaluation measures. The results and discussion in section 4 initially discuss"
        },
        {
          "REDAﬀectiveLM\n5": "the performance evaluation of our proposed model by comparing against the"
        },
        {
          "REDAﬀectiveLM\n5": "baselines,\nfollowed by the behavior analysis of aﬀect enrichment\nin readers’"
        },
        {
          "REDAﬀectiveLM\n5": "emotion detection. Finally, section 5 draws the conclusions."
        }
      ],
      "page": 5
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "6\nREDAﬀectiveLM": "2 Methodology"
        },
        {
          "6\nREDAﬀectiveLM": "This section presents our method for detecting Readers’ Emotions from textual"
        },
        {
          "6\nREDAﬀectiveLM": "documents. We ﬁrst discuss the problem settings followed by the architecture"
        },
        {
          "6\nREDAﬀectiveLM": "of our proposed model, REDAﬀectiveLM."
        },
        {
          "6\nREDAﬀectiveLM": "2.1 Problem setting"
        },
        {
          "6\nREDAﬀectiveLM": "We\nformulate\nour\ntask\nof\nreaders’\nemotions\ndetection\nas\na multi-target"
        },
        {
          "6\nREDAﬀectiveLM": "regression\nproblem.\nIn\nother words,\nfor\neach\ndocument,\nthe model\npre-"
        },
        {
          "6\nREDAﬀectiveLM": "dicts\nreaders’\nemotion proﬁle\ni.e.,\nintensities\nof\nthe\nemotion classes anger,"
        },
        {
          "6\nREDAﬀectiveLM": "fear,\njoy,\nsadness,\nand surprise. Each document\nd\nconsists\nof\na\nsequence"
        },
        {
          "6\nREDAﬀectiveLM": "of N words,\nis\ntaken from the\nd = w1, w2, . . . , wN , where\neach word wi"
        },
        {
          "6\nREDAﬀectiveLM": "vocabulary\nof\nV\nunique words\ndenoted\nby,\nV\n= {w1, w2, . . . , wV }. The"
        },
        {
          "6\nREDAﬀectiveLM": "readers’\nemotion proﬁle\nfor\neach document, which forms\nthe gold-standard"
        },
        {
          "6\nREDAﬀectiveLM": "labelled\ndata\nfor\ntraining,\nis\nformed\nfrom votes\ncast\nby multiple\nread-"
        },
        {
          "6\nREDAﬀectiveLM": "ers’, which is normalized for E distinct\nemotions,\nrepresented as, epr(d) ="
        },
        {
          "6\nREDAﬀectiveLM": "{e1, e2, . . . , eE}, where, ei ∈ [0, 1] and (cid:80)E\ni=1 ei = 1. Thus, the labelled corpus"
        },
        {
          "6\nREDAﬀectiveLM": "D = {(d1, epr(d1)), (d2, epr(d2)), . . . , (dM , epr(dM ))}, represents M documents"
        },
        {
          "6\nREDAﬀectiveLM": "along with their corresponding emotion proﬁles. We then follow a deep neu-"
        },
        {
          "6\nREDAﬀectiveLM": "ral network based methodology to ﬁnd the best ﬁt mapping function f : H →"
        },
        {
          "6\nREDAﬀectiveLM": "for document vector H\nepr(d), that predicts readers’ emotion proﬁle, epr(d),"
        },
        {
          "6\nREDAﬀectiveLM": "of the document d."
        },
        {
          "6\nREDAﬀectiveLM": "2.2 Proposed Model"
        },
        {
          "6\nREDAﬀectiveLM": "We propose a deep learning based readers’ emotion detection system, REDAf-"
        },
        {
          "6\nREDAﬀectiveLM": "fectiveLM by parallely fusing two diﬀerent networks, where the ﬁrst emoBi-"
        },
        {
          "6\nREDAﬀectiveLM": "LSTM+Attention\nnetwork\nis meant\nto\nproduce\naﬀect\nenriched\ndocument"
        },
        {
          "6\nREDAﬀectiveLM": "representation and the second XLNet network for context-speciﬁc representa-"
        },
        {
          "6\nREDAﬀectiveLM": "tion. We start by discussing the two networks in detail and later outline the"
        },
        {
          "6\nREDAﬀectiveLM": "complete architecture of our fused model, REDAﬀectiveLM. An overall sketch"
        },
        {
          "6\nREDAﬀectiveLM": "of our proposed model\nis illustrated in ﬁgure 2."
        },
        {
          "6\nREDAﬀectiveLM": "2.2.1\nemoBi-LSTM+Attention for Aﬀect Enriched"
        },
        {
          "6\nREDAﬀectiveLM": "Document Representation"
        },
        {
          "6\nREDAﬀectiveLM": "In the emoBi-LSTM+Attention network, input documents are initially subject"
        },
        {
          "6\nREDAﬀectiveLM": "to Aﬀect Enriched Word Embedding. To construct aﬀect enriched word repre-"
        },
        {
          "6\nREDAﬀectiveLM": "sentations, denoted as emoGloVe, we utilize the state-of-the-art method using"
        },
        {
          "6\nREDAﬀectiveLM": "counter-ﬁtting and emotional constraints2 proposed by Seyeditabari et al.\n[12]"
        },
        {
          "6\nREDAﬀectiveLM": "over a pre-trained conventional semantic embedding GloVe [21]. After gener-"
        },
        {
          "6\nREDAﬀectiveLM": "ating aﬀect enriched word representations, towards producing aﬀect enriched"
        },
        {
          "6\nREDAﬀectiveLM": "document representations, we utilize Bi-LSTM [30], a prominent RNN based"
        },
        {
          "6\nREDAﬀectiveLM": "2we have\nrewritten the\ncode\nin https://github.com/armintabari/Emotional-Embedding from"
        },
        {
          "6\nREDAﬀectiveLM": "python 2.x to python 3.x to avoid compatibility issues with our implementations"
        }
      ],
      "page": 6
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Fig. 2: The proposed readers’ emotion detection system, REDAﬀectiveLM": "architecture in combination with an Attention layer\n[31]. The choice of Bi-"
        },
        {
          "Fig. 2: The proposed readers’ emotion detection system, REDAﬀectiveLM": "LSTM network is motivated by its advantages\nsuch as\nthe ability to learn"
        },
        {
          "Fig. 2: The proposed readers’ emotion detection system, REDAﬀectiveLM": "long term dependencies [22] and to perform sequential modeling in both left"
        },
        {
          "Fig. 2: The proposed readers’ emotion detection system, REDAﬀectiveLM": "−\n−−−−−→\n←−−−−−−"
        },
        {
          "Fig. 2: The proposed readers’ emotion detection system, REDAﬀectiveLM": "to right (\nf orward) and right to left (\nbackward) directions which helps in pro-"
        },
        {
          "Fig. 2: The proposed readers’ emotion detection system, REDAﬀectiveLM": "ducing excellent performance gains [23].\nIn addition, Attention on top of the"
        },
        {
          "Fig. 2: The proposed readers’ emotion detection system, REDAﬀectiveLM": "Bi-LSTM network is observed to increase the overall model performance for"
        },
        {
          "Fig. 2: The proposed readers’ emotion detection system, REDAﬀectiveLM": "the task of readers’ emotion detection [7] and also the related task of sentiment"
        },
        {
          "Fig. 2: The proposed readers’ emotion detection system, REDAﬀectiveLM": "analysis [24]. Attention’s mechanism of assigning corresponding weightages to"
        },
        {
          "Fig. 2: The proposed readers’ emotion detection system, REDAﬀectiveLM": "words\nin the documents based on their\nrelevance in emotion prediction also"
        },
        {
          "Fig. 2: The proposed readers’ emotion detection system, REDAﬀectiveLM": "helps yet another objective of analyzing behavior of our network towards read-"
        },
        {
          "Fig. 2: The proposed readers’ emotion detection system, REDAﬀectiveLM": "ers’ emotion detection. That\nis,\nin total, our choice of aﬀect enriched word"
        },
        {
          "Fig. 2: The proposed readers’ emotion detection system, REDAﬀectiveLM": "embedding and Bi-LSTM+Attention network,\nis based on the motivation that"
        },
        {
          "Fig. 2: The proposed readers’ emotion detection system, REDAﬀectiveLM": "this combination should signiﬁcantly contribute towards improving the overall"
        },
        {
          "Fig. 2: The proposed readers’ emotion detection system, REDAﬀectiveLM": "model performance and moreover, allows to investigate the network behavior"
        },
        {
          "Fig. 2: The proposed readers’ emotion detection system, REDAﬀectiveLM": "systematically to analyze\nthe\nimpact of aﬀect\nenrichment\nin readers’\nemo-"
        },
        {
          "Fig. 2: The proposed readers’ emotion detection system, REDAﬀectiveLM": "tion detection. As we will see later (in section 4.2), we also analyze whether"
        },
        {
          "Fig. 2: The proposed readers’ emotion detection system, REDAﬀectiveLM": "the attentions are inﬂuenced by emotion words and named entities, which are"
        },
        {
          "Fig. 2: The proposed readers’ emotion detection system, REDAﬀectiveLM": "categories of words that we believe, hold much sway in determining aﬀect."
        },
        {
          "Fig. 2: The proposed readers’ emotion detection system, REDAﬀectiveLM": "Bi-LSTM network is initially fed with the aﬀect enriched word representa-"
        },
        {
          "Fig. 2: The proposed readers’ emotion detection system, REDAﬀectiveLM": "inputs in both\ntions −→w i of input document d, and it processes these sequential"
        },
        {
          "Fig. 2: The proposed readers’ emotion detection system, REDAﬀectiveLM": "forward and backward directions producing aﬀect enriched contextual repre-"
        },
        {
          "Fig. 2: The proposed readers’ emotion detection system, REDAﬀectiveLM": "in the\nsentation of the document as output vector. That is, a single layer hl"
        }
      ],
      "page": 7
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "8\nREDAﬀectiveLM": "−\n←"
        },
        {
          "8\nREDAﬀectiveLM": "Bi-LSTM network is deﬁned as [\nforward process-\nl;\nl], a concatenation of"
        },
        {
          "8\nREDAﬀectiveLM": "−\n←"
        },
        {
          "8\nREDAﬀectiveLM": "ing (\nl) and backward processing (\nl) hidden layers with parameters Θf and"
        },
        {
          "8\nREDAﬀectiveLM": "Θb respectively, denoted as,"
        },
        {
          "8\nREDAﬀectiveLM": "−\n−"
        },
        {
          "8\nREDAﬀectiveLM": "→h\n→h\n(1)\nl = LST M (\nl−1, −→w i, Θf )"
        },
        {
          "8\nREDAﬀectiveLM": "←\n←"
        },
        {
          "8\nREDAﬀectiveLM": "−h\n−h\n(2)\nl = LST M (\nl+1, −→w i, Θb)"
        },
        {
          "8\nREDAﬀectiveLM": "To build Attention on top of Bi-LSTM, we adopt\nthe popular mechanism"
        },
        {
          "8\nREDAﬀectiveLM": "the\nproposed in [31], where the ﬁnal hidden layer of Bi-LSTM hn taken as"
        },
        {
          "8\nREDAﬀectiveLM": "document summary vector Z is passed to an alignment model, a feedforward"
        },
        {
          "8\nREDAﬀectiveLM": "network which is\ntrained along with the model. With the\nlearnable weight"
        },
        {
          "8\nREDAﬀectiveLM": "the alignment model generates a\nparameters Wh, WZ ∈ Ra×b and v ∈ Ra,"
        },
        {
          "8\nREDAﬀectiveLM": "softmax\nfunction delivers\nthe set of\nscalar value ui, which on application of"
        },
        {
          "8\nREDAﬀectiveLM": "word weightages αi\nindicating the signiﬁcance of each hidden state hi as,"
        },
        {
          "8\nREDAﬀectiveLM": "(3)\ni.e., ui = v(cid:62) tanh(Whhi + WZZ)"
        },
        {
          "8\nREDAﬀectiveLM": "exp(ui)"
        },
        {
          "8\nREDAﬀectiveLM": "(4)\nαi ="
        },
        {
          "8\nREDAﬀectiveLM": "(cid:80)n"
        },
        {
          "8\nREDAﬀectiveLM": "j=1 exp(uj)"
        }
      ],
      "page": 8
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "REDAﬀectiveLM\n9": "as,"
        },
        {
          "REDAﬀectiveLM\n9": "(6)\nH2 = XLNet(EW )"
        },
        {
          "REDAﬀectiveLM\n9": "2.2.3 REDAﬀectiveLM : The fused model\nfor Readers’"
        },
        {
          "REDAﬀectiveLM\n9": "Emotion Detection"
        },
        {
          "REDAﬀectiveLM\n9": "To\nbuild\nour Readers’ Emotion Detection model, REDAﬀectiveLM,\nthat"
        },
        {
          "REDAﬀectiveLM\n9": "leverages\nthe\nutility\nof Aﬀect\nEnriched Document\nRepresentation\nand"
        },
        {
          "REDAﬀectiveLM\n9": "Context-speciﬁc Document Representation, we fuse the two networks, emoBi-"
        },
        {
          "REDAﬀectiveLM\n9": "LSTM+Attention and XLNet.\nIn the fused model,\nthe aﬀect enriched docu-"
        },
        {
          "REDAﬀectiveLM\n9": "ment vector H1 from emoBi-LSTM+Attention and context-speciﬁc document"
        },
        {
          "REDAﬀectiveLM\n9": "vector H2 from XLNet are concatenated to form a single document vector H,"
        },
        {
          "REDAﬀectiveLM\n9": "deﬁned as,"
        },
        {
          "REDAﬀectiveLM\n9": "(7)\nH = H1 ⊕ H2"
        },
        {
          "REDAﬀectiveLM\n9": "Finally,\nto predict\nreaders’ emotion proﬁles, we feed the concatenated docu-"
        },
        {
          "REDAﬀectiveLM\n9": "ment vector H to a fully connected neural network module. Our neural network"
        },
        {
          "REDAﬀectiveLM\n9": "module that consists of a Multi-Layer Perceptron (MLP) having two fully con-"
        },
        {
          "REDAﬀectiveLM\n9": "nected dense hidden layers with 1224 neurons\nin each layer and an output"
        },
        {
          "REDAﬀectiveLM\n9": "layer with 5 neurons predicts normalized probability distribution of\nreaders’"
        },
        {
          "REDAﬀectiveLM\n9": "emotion proﬁles (cid:92)epr(d), given as,"
        },
        {
          "REDAﬀectiveLM\n9": "(cid:92)"
        },
        {
          "REDAﬀectiveLM\n9": "(8)\nepr(d) = softmax (MLP(H))"
        },
        {
          "REDAﬀectiveLM\n9": "The\nlearning process,\ncomputes and back propagates\nthe\nloss between pre-"
        },
        {
          "REDAﬀectiveLM\n9": "dicted emotion proﬁle (cid:92)epr(d) and labelled vector epr(d). After model training,"
        },
        {
          "REDAﬀectiveLM\n9": "we empirically evaluate emotion prediction performance and later evaluate the"
        },
        {
          "REDAﬀectiveLM\n9": "impact of aﬀect enrichment qualitatively and quantitatively using document"
        },
        {
          "REDAﬀectiveLM\n9": "attention maps precipitated from the emoBi-LSTM+Attention network."
        },
        {
          "REDAﬀectiveLM\n9": "3 Empirical Study"
        },
        {
          "REDAﬀectiveLM\n9": "In this\nsection we ﬁrst describe\nthe details of datasets used in our\nstudy,"
        },
        {
          "REDAﬀectiveLM\n9": "followed by the experimental settings, baselines and evaluation measures used"
        },
        {
          "REDAﬀectiveLM\n9": "for model performance analysis."
        },
        {
          "REDAﬀectiveLM\n9": "3.1 Dataset"
        },
        {
          "REDAﬀectiveLM\n9": "To conduct experiments we utilize three datasets, SemEval-2007 [28], RENh-"
        },
        {
          "REDAﬀectiveLM\n9": "4k [7] and a newly curated Readers’ Emotion News Dataset, REN-20k. We"
        },
        {
          "REDAﬀectiveLM\n9": "detail these herewith."
        }
      ],
      "page": 9
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "10\nREDAﬀectiveLM": "3.1.1 SemEval-2007"
        },
        {
          "10\nREDAﬀectiveLM": "SemEval-2007 [28]\nis a popularly used short-text benchmark dataset collected"
        },
        {
          "10\nREDAﬀectiveLM": "from online news portals The New York Times, CNN, BBC and Google News."
        },
        {
          "10\nREDAﬀectiveLM": "This is an annotated dataset with 1250 documents, where each document that"
        },
        {
          "10\nREDAﬀectiveLM": "comprises news headlines is annotated by six readers to obtain the scores of"
        },
        {
          "10\nREDAﬀectiveLM": "Anger, Disgust, Fear, Joy, Sadness and Surprise emotion classes."
        },
        {
          "10\nREDAﬀectiveLM": "3.1.2 RENh-4k"
        },
        {
          "10\nREDAﬀectiveLM": "RENh-4k [7]\nis a Readers’ Emotion News headlines dataset with 4000 news"
        },
        {
          "10\nREDAﬀectiveLM": "documents belonging to the year span 2015 to 2018 collected from the news"
        },
        {
          "10\nREDAﬀectiveLM": "portal Rappler3. RENh-4k is short-text in nature, where each document com-"
        },
        {
          "10\nREDAﬀectiveLM": "prises headlines\nand abstract\nof\nthe news,\nand the\ncorresponding\nemotion"
        },
        {
          "10\nREDAﬀectiveLM": "proﬁles of Afraid, Angry, Happy,\nInspired, and Sad emotion classes are col-"
        },
        {
          "10\nREDAﬀectiveLM": "lected from the Mood Meter widget on the portal that records the percentage"
        },
        {
          "10\nREDAﬀectiveLM": "of votes cast by the readers for each emotion."
        },
        {
          "10\nREDAﬀectiveLM": "3.1.3 REN-20k"
        },
        {
          "10\nREDAﬀectiveLM": "REN-20k is our newly curated Readers’ Emotion News dataset procured in a"
        },
        {
          "10\nREDAﬀectiveLM": "similar\nfashion of RENh-4k from the popular online news network Rappler,"
        },
        {
          "10\nREDAﬀectiveLM": "where we collect news articles manually,\nfrom the year span 2014 to 2019, by"
        },
        {
          "10\nREDAﬀectiveLM": "checking articles with high emotion votings in the Mood Meter widget of Rap-"
        },
        {
          "10\nREDAﬀectiveLM": "pler indicating high popularity and social reach of these articles. But it is an"
        },
        {
          "10\nREDAﬀectiveLM": "advanced version containing 20474 numbers of documents with correspond-"
        },
        {
          "10\nREDAﬀectiveLM": "ing readers’ emotion proﬁles collected for diverse classes of emotions Afraid,"
        },
        {
          "10\nREDAﬀectiveLM": "Amused, Angry, Annoyed, Don’t care, Happy,\nInspired, and Sad. Also, each"
        },
        {
          "10\nREDAﬀectiveLM": "document\nconsists of\nthe whole news\ncontent\nincluding headlines, abstract"
        },
        {
          "10\nREDAﬀectiveLM": "and full-length news story excluding images and videos, making it a long-text"
        },
        {
          "10\nREDAﬀectiveLM": "dataset with average words per document as 527.84. With the help of genre"
        },
        {
          "10\nREDAﬀectiveLM": "information available in the portal and by manual annotations, we assign each"
        },
        {
          "10\nREDAﬀectiveLM": "document to a diverse set of genres, Business, Entertainment, Lifestyle, Sports,"
        },
        {
          "10\nREDAﬀectiveLM": "Technology and Others, unlike RENh-4k that\nconsiders\nonly three\ngenres,"
        },
        {
          "10\nREDAﬀectiveLM": "Health & well-being, Social issues and Others. Since our work focuses on short-"
        },
        {
          "10\nREDAﬀectiveLM": "text documents, we choose only the headlines and abstract of news articles"
        },
        {
          "10\nREDAﬀectiveLM": "from each whole news document, to form the short-text version of REN-20k."
        },
        {
          "10\nREDAﬀectiveLM": "3.2 Dataset Pre-processing"
        },
        {
          "10\nREDAﬀectiveLM": "Since we utilize Paul Ekman’s basic\nemotions\n[29] anger, disgust,\nfear,\njoy,"
        },
        {
          "10\nREDAﬀectiveLM": "sadness,\nand\nsurprise\nin\nour\nstudy, we\nperform an\ninitial\ndataset\npre-"
        },
        {
          "10\nREDAﬀectiveLM": "processing\nas\nfollowed\nin\n[7,\n33], where\nemotion\nlabels\nof RENh-4k\nand"
        },
        {
          "10\nREDAﬀectiveLM": "REN-20k taken from Rappler Mood Meter are mapped to basic\nemotions."
        },
        {
          "10\nREDAﬀectiveLM": "That\nis, we map Angry→Anger, Sad →Sadness, Afraid →Fear, Happy→Joy"
        },
        {
          "10\nREDAﬀectiveLM": "and Inspired →Surprise, and discard other Mood Meter emotions such as Don’t"
        }
      ],
      "page": 10
    },
    {
      "caption": "Table 1: Dataset statistics after pre-processing",
      "data": [
        {
          "REDAﬀectiveLM\n11": "care, Inspired, Amused, and Annoyed. As followed by [7, 33], we exclude Paul"
        },
        {
          "REDAﬀectiveLM\n11": "Ekman’s basic emotion Disgust\nin our study as it does not have a matching"
        },
        {
          "REDAﬀectiveLM\n11": "emotion in the Rappler Mood Meter and for keeping a common set of ﬁve"
        },
        {
          "REDAﬀectiveLM\n11": "basic\nemotion labels across all\nthe\nthree datasets. We\nthen perform a data"
        },
        {
          "REDAﬀectiveLM\n11": "normalization procedure where readers’ emotion proﬁles are represented as a"
        },
        {
          "REDAﬀectiveLM\n11": "distribution of\nthe chosen ﬁve basic emotions, by adopting the technique in"
        },
        {
          "REDAﬀectiveLM\n11": "[34]. For better text representations, we perform data cleaning that removes"
        },
        {
          "REDAﬀectiveLM\n11": "frequently occurring noisy and unnecessary terms\nin the documents\nsuch as"
        },
        {
          "REDAﬀectiveLM\n11": "survey, report, (UPDATED), new-review and Midday-wRa,\nfollowed by other"
        },
        {
          "REDAﬀectiveLM\n11": "general set of pre-processing techniques such as text normalization and removal"
        },
        {
          "REDAﬀectiveLM\n11": "of punctuations and unknown symbols using NLTK toolkits4. Table 1 shows"
        },
        {
          "REDAﬀectiveLM\n11": "the detailed dataset statistics after pre-processing where, to compute the num-"
        },
        {
          "REDAﬀectiveLM\n11": "ber of annotations in RENh-4k and REN-20k we utilize the procedure in [35],"
        },
        {
          "REDAﬀectiveLM\n11": "as the number of annotators or readers’ are not known accurately, unlike six"
        },
        {
          "REDAﬀectiveLM\n11": "annotators explicitly mentioned in SemEval-2007."
        }
      ],
      "page": 11
    },
    {
      "caption": "Table 1: Dataset statistics after pre-processing",
      "data": [
        {
          "Table 1: Dataset statistics after pre-processing": "REN-20k"
        },
        {
          "Table 1: Dataset statistics after pre-processing": "10807161"
        },
        {
          "Table 1: Dataset statistics after pre-processing": "172243"
        },
        {
          "Table 1: Dataset statistics after pre-processing": "29.612"
        },
        {
          "Table 1: Dataset statistics after pre-processing": "1.1826"
        },
        {
          "Table 1: Dataset statistics after pre-processing": "2556654"
        },
        {
          "Table 1: Dataset statistics after pre-processing": "Anger: 0.2253"
        },
        {
          "Table 1: Dataset statistics after pre-processing": "Fear: 0.0626"
        },
        {
          "Table 1: Dataset statistics after pre-processing": "Joy: 0.4222"
        },
        {
          "Table 1: Dataset statistics after pre-processing": "Sadness: 0.1441"
        },
        {
          "Table 1: Dataset statistics after pre-processing": "Surprise: 0.1459"
        },
        {
          "Table 1: Dataset statistics after pre-processing": "Anger: 14419"
        },
        {
          "Table 1: Dataset statistics after pre-processing": "Fear: 8678"
        },
        {
          "Table 1: Dataset statistics after pre-processing": "Joy: 18104"
        },
        {
          "Table 1: Dataset statistics after pre-processing": "Sadness: 12841"
        },
        {
          "Table 1: Dataset statistics after pre-processing": "Surprise: 12749"
        }
      ],
      "page": 11
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "12\nREDAﬀectiveLM": "between Bi-LSTM and Attention layer\nset as 0.5. To implement\nthe XLNet"
        },
        {
          "12\nREDAﬀectiveLM": "architecture we utilize XLNet-Large-Cased from the AI community Hugging"
        },
        {
          "12\nREDAﬀectiveLM": "Face5, where the hyperparameters are number of\nlayers set as 24, hidden size"
        },
        {
          "12\nREDAﬀectiveLM": "as 1024, number of attention heads as 16, dropout as 0.1, and altogether 360M"
        },
        {
          "12\nREDAﬀectiveLM": "trainable parameters ﬁne-tune the network. In the fused model, aﬀect enriched"
        },
        {
          "12\nREDAﬀectiveLM": "from emoBi-LSTM+Attention network with dimension\ndocument vector H1"
        },
        {
          "12\nREDAﬀectiveLM": "200 and context-speciﬁc document vector H2 from XLNet network with dimen-"
        },
        {
          "12\nREDAﬀectiveLM": "sion 1024, on concatenation,\nforms a single ﬁnal document vector H with"
        },
        {
          "12\nREDAﬀectiveLM": "dimension 1224, which is then fed to a fully connected MLP. To build the MLP,"
        },
        {
          "12\nREDAﬀectiveLM": "we\nconsider various number of\nlayers having diﬀerent\ncombinations of neu-"
        },
        {
          "12\nREDAﬀectiveLM": "rons, such as, {1224→512→256→128→64→5}, {1224→1224→5}, {1224→5},"
        },
        {
          "12\nREDAﬀectiveLM": "etc., and ﬁnally choose two hidden layers with 1224 neurons followed by the"
        },
        {
          "12\nREDAﬀectiveLM": "output layer with 5 neurons as a representative setting. The hyperparameters"
        },
        {
          "12\nREDAﬀectiveLM": "of our fused model REDAﬀectiveLM are Adam optimizer with learning rate"
        },
        {
          "12\nREDAﬀectiveLM": "0.000015, Mean Squared Error (MSE ) as loss function, batch size as 64 and 200"
        },
        {
          "12\nREDAﬀectiveLM": "epochs. REDAﬀectiveLM consists of 363,762,235 number of total parameters,"
        },
        {
          "12\nREDAﬀectiveLM": "where 363,434,735 are trainable and 327,500 are non-trainable parameters."
        },
        {
          "12\nREDAﬀectiveLM": "3.4 Baselines"
        },
        {
          "12\nREDAﬀectiveLM": "To evaluate our REDAﬀectiveLM model, we compare its performance using"
        },
        {
          "12\nREDAﬀectiveLM": "various measures\n(detailed in 3.5) against popular and state-of-the-art base-"
        },
        {
          "12\nREDAﬀectiveLM": "lines belonging to lexicon based, classical machine learning and deep learning"
        },
        {
          "12\nREDAﬀectiveLM": "categories (even though deep learning belongs under the umbrella of machine"
        },
        {
          "12\nREDAﬀectiveLM": "learning, we maintain deep learning baselines separately due to many notable"
        },
        {
          "12\nREDAﬀectiveLM": "contributions in the literature). Details of the baselines are as follows:"
        },
        {
          "12\nREDAﬀectiveLM": "• Deep Learning Baselines: In our set of deep learning baselines we reproduce a"
        },
        {
          "12\nREDAﬀectiveLM": "vast number of works that follow a wide variety of methodology. That is our"
        }
      ],
      "page": 12
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "categories (even though deep learning belongs under the umbrella of machine": "learning, we maintain deep learning baselines separately due to many notable"
        },
        {
          "categories (even though deep learning belongs under the umbrella of machine": "contributions in the literature). Details of the baselines are as follows:"
        },
        {
          "categories (even though deep learning belongs under the umbrella of machine": "• Deep Learning Baselines: In our set of deep learning baselines we reproduce a"
        },
        {
          "categories (even though deep learning belongs under the umbrella of machine": "vast number of works that follow a wide variety of methodology. That is our"
        },
        {
          "categories (even though deep learning belongs under the umbrella of machine": "choice of deep learning baselines include a recent readers’ emotion detection"
        },
        {
          "categories (even though deep learning belongs under the umbrella of machine": "work Readers’Aﬀect [7] that utilizes Bi-LSTM+Attention architecture, tex-"
        },
        {
          "categories (even though deep learning belongs under the umbrella of machine": "tual emotion detection works sent2aﬀect [15] that employs sentiment aided"
        },
        {
          "categories (even though deep learning belongs under the umbrella of machine": "transfer learning and SS-BED [14] that utilize sentiment and semantic word"
        },
        {
          "categories (even though deep learning belongs under the umbrella of machine": "embedding, a popular text classiﬁcation architecture Kim’s CNN [36], na¨ıve"
        },
        {
          "categories (even though deep learning belongs under the umbrella of machine": "RNN architectures, GRU, LSTM and Bi-LSTM used as baselines\nin var-"
        },
        {
          "categories (even though deep learning belongs under the umbrella of machine": "ious\ntextual emotion detection works\n[7, 14, 15], and individual networks"
        },
        {
          "categories (even though deep learning belongs under the umbrella of machine": "emoBi-LSTM+Attention and XLNet [18] used to construct our fused model"
        },
        {
          "categories (even though deep learning belongs under the umbrella of machine": "(serving,\nimplicitly as a form of ablation study)."
        },
        {
          "categories (even though deep learning belongs under the umbrella of machine": "• Lexicon based Baselines: In this category of baselines we reproduce readers’"
        },
        {
          "categories (even though deep learning belongs under the umbrella of machine": "emotion detection systems, SWAT [8] popular among the top three systems"
        },
        {
          "categories (even though deep learning belongs under the umbrella of machine": "of shared task ‘SemEval-2007 Task 14: Aﬀective Text’\n[28] that utilize pre-"
        },
        {
          "categories (even though deep learning belongs under the umbrella of machine": "deﬁned sets of emotion words and Emotion Term Model\n[4] built over Na¨ıve"
        },
        {
          "categories (even though deep learning belongs under the umbrella of machine": "Bayes by incorporating emotion rating information and term independent"
        },
        {
          "categories (even though deep learning belongs under the umbrella of machine": "assumption, and a promising textual emotion detection system Synesketch"
        }
      ],
      "page": 12
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "REDAﬀectiveLM\n13": "[37] that utilizes word-level\nlexicon and an emoticon lexicon in hybrid with"
        },
        {
          "REDAﬀectiveLM\n13": "several heuristic rule sets."
        },
        {
          "REDAﬀectiveLM\n13": "• Classical Machine Learning Baselines: In this category of baselines, we repro-"
        },
        {
          "REDAﬀectiveLM\n13": "duce the textual emotion detection method proposed in [38]\nthat utilizes"
        },
        {
          "REDAﬀectiveLM\n13": "Word Mover’s Distance\n(WMD) as a feature\ncomputed with the help of"
        },
        {
          "REDAﬀectiveLM\n13": "pre-trained word embeddings and provided to an SVM classiﬁer (to imple-"
        },
        {
          "REDAﬀectiveLM\n13": "ment\nthis work, we\ninstead use Support Vector Regression (SVR)6\nthat"
        },
        {
          "REDAﬀectiveLM\n13": "suits our multi-target\nregression task). We also reproduce a wide variety"
        },
        {
          "REDAﬀectiveLM\n13": "of\nlinguistic and aﬀective features that are used in several textual emotion"
        },
        {
          "REDAﬀectiveLM\n13": "detection studies along with various multi-target regression models. The fea-"
        },
        {
          "REDAﬀectiveLM\n13": "tures considered are TF-IDF [15, 38], N-Grams\n[14, 39], General Purpose"
        },
        {
          "REDAﬀectiveLM\n13": "Emotion Lexicon Features [39] that includes Total Emotion Count (TEC),"
        },
        {
          "REDAﬀectiveLM\n13": "Total Emotion Intensity (TEI), Max Emotion Intensity (MEI), Graded Emo-"
        },
        {
          "REDAﬀectiveLM\n13": "tion Count\n(GEC), and Graded Emotion Intensity (GEI), extracted using"
        },
        {
          "REDAﬀectiveLM\n13": "the general purpose emotion lexicon DepecheMood++ [40], Sentiment word"
        },
        {
          "REDAﬀectiveLM\n13": "count\nfeature [39, 41] computed using VADER [42], Embedding Features"
        },
        {
          "REDAﬀectiveLM\n13": "[11, 14] that includes the semantic embeddings Word2Vec, GloVe and Fast-"
        },
        {
          "REDAﬀectiveLM\n13": "Text, and Sentiment Speciﬁc Word Embedding, SSWEu proposed in [11]. For"
        },
        {
          "REDAﬀectiveLM\n13": "implementing the multi-target\nregression models, we adopt both problem"
        },
        {
          "REDAﬀectiveLM\n13": "transformation and algorithm adaptation techniques.\nIn problem transfor-"
        },
        {
          "REDAﬀectiveLM\n13": "mation approach we use Ridge Regression7and in algorithm adaptation we"
        },
        {
          "REDAﬀectiveLM\n13": "use MLP8."
        },
        {
          "REDAﬀectiveLM\n13": "The\nhyper-parameters\nused\nto\nimplement/reproduce\nthe\nbaselines GRU,"
        },
        {
          "REDAﬀectiveLM\n13": "LSTM,\nBi-LSTM,\nReaders’\nAﬀect\n(Bi-LSTM+Attention)\nand\nemoBi-"
        },
        {
          "REDAﬀectiveLM\n13": "LSTM+Attention are, a single RNN stack, 100 neurons in a stack, pre-trained"
        },
        {
          "REDAﬀectiveLM\n13": "GloVe embedding with dimension 100, MSE loss\nfunction, Adam optimizer,"
        },
        {
          "REDAﬀectiveLM\n13": "softmax activation function in dense layer and 100 epochs. Except GRU for"
        },
        {
          "REDAﬀectiveLM\n13": "the other above-mentioned baselines\nregularizer\nis\nl2(0.001), dropout\nis 0.5,"
        },
        {
          "REDAﬀectiveLM\n13": "learning rate is 0.0005 and batch size is 128, whereas,\nfor GRU, regularizer is"
        },
        {
          "REDAﬀectiveLM\n13": "l2(0.01), dropout is 0.25,\nlearning rate is 0.005 and batch size is 64. For Kim’s"
        },
        {
          "REDAﬀectiveLM\n13": "CNN the number of ﬁlters are 100, ﬁlter sizes are 3, 4 and 5, dropout is 0.5,"
        },
        {
          "REDAﬀectiveLM\n13": "learning rate is 0.0005, and all other hyper-parameters are the same as GRU."
        },
        {
          "REDAﬀectiveLM\n13": "For MLP,\nin the algorithm adaptation approach, we use a hidden layer with"
        },
        {
          "REDAﬀectiveLM\n13": "128 neurons, ReLU activation, batch size of 64 and all other hyper-parameters"
        },
        {
          "REDAﬀectiveLM\n13": "are the same as LSTM."
        }
      ],
      "page": 13
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "14\nREDAﬀectiveLM": "predicted emotions to 0/1 classes, and ﬁne-grained measures that look at near-"
        },
        {
          "14\nREDAﬀectiveLM": "ness of predicted emotions to the ground truth at a ﬁner granularity [7, 44]."
        },
        {
          "14\nREDAﬀectiveLM": "For coarse-grained evaluation, we use Acc@1 [4, 7, 34, 43],\ni.e., accuracy of"
        },
        {
          "14\nREDAﬀectiveLM": "the top ﬁrst emotion prediction, representing micro-averaged F1 measure [45]."
        },
        {
          "14\nREDAﬀectiveLM": "For ﬁne-grained evaluations, we use\ncorrelation based measures APdocument"
        },
        {
          "14\nREDAﬀectiveLM": "and APemotion [7, 43] computing similarity of predicted emotion proﬁles with"
        },
        {
          "14\nREDAﬀectiveLM": "ground-truth, over emotions and documents\nrespectively, and error/distance"
        },
        {
          "14\nREDAﬀectiveLM": "measures Root Mean Square Error\n(RMSE)\n[7,\n14]\nand Wasserstein Dis-"
        },
        {
          "14\nREDAﬀectiveLM": "tance (WD) [7, 46] computing the distance of predicted emotion proﬁles from"
        },
        {
          "14\nREDAﬀectiveLM": "ground-truth."
        },
        {
          "14\nREDAﬀectiveLM": "• Acc@1 of a corpus\nis an average of Accd@1 computed for all documents"
        },
        {
          "14\nREDAﬀectiveLM": "in the corpus. For the predicted emotion proﬁle Xd (shorthand for (cid:92)epr(d))"
        },
        {
          "14\nREDAﬀectiveLM": "and\n(shorthand\nfor\nof\na\ndocument\nground-truth Yd\nepr(d))\nd, Accd@1"
        },
        {
          "14\nREDAﬀectiveLM": "checks whether\nthe\ntop-ranked emotion is\nthe\nsame\nfor both prediction"
        },
        {
          "14\nREDAﬀectiveLM": "(cid:0)i.e. arg max\nXd[i](cid:1) as well as ground-truth (cid:0)i.e. arg max\nYd[i](cid:1)."
        }
      ],
      "page": 14
    },
    {
      "caption": "Table 2: From the results we can observe that our REDAffectiveLM model",
      "data": [
        {
          "REDAﬀectiveLM": "",
          "15": ""
        },
        {
          "REDAﬀectiveLM": "",
          "15": ""
        },
        {
          "REDAﬀectiveLM": "",
          "15": ""
        },
        {
          "REDAﬀectiveLM": "",
          "15": "(12)"
        },
        {
          "REDAﬀectiveLM": "|E|",
          "15": ""
        },
        {
          "REDAﬀectiveLM": "",
          "15": ""
        },
        {
          "REDAﬀectiveLM": "",
          "15": ""
        },
        {
          "REDAﬀectiveLM": "",
          "15": ""
        },
        {
          "REDAﬀectiveLM": "",
          "15": ""
        },
        {
          "REDAﬀectiveLM": "",
          "15": ""
        },
        {
          "REDAﬀectiveLM": "",
          "15": ""
        },
        {
          "REDAﬀectiveLM": "E(x,y)∼γ[(cid:107) x − y (cid:107)]",
          "15": "(13)"
        },
        {
          "REDAﬀectiveLM": "",
          "15": ""
        },
        {
          "REDAﬀectiveLM": "",
          "15": ""
        },
        {
          "REDAﬀectiveLM": "",
          "15": ""
        },
        {
          "REDAﬀectiveLM": "",
          "15": ""
        }
      ],
      "page": 15
    },
    {
      "caption": "Table 2: EvaluationresultsoverREN-20k(Bestresultsamongallthemodels,",
      "data": [
        {
          "16\nREDAﬀectiveLM": ""
        },
        {
          "16\nREDAﬀectiveLM": ""
        },
        {
          "16\nREDAﬀectiveLM": ""
        },
        {
          "16\nREDAﬀectiveLM": ""
        },
        {
          "16\nREDAﬀectiveLM": ""
        },
        {
          "16\nREDAﬀectiveLM": ""
        },
        {
          "16\nREDAﬀectiveLM": ""
        },
        {
          "16\nREDAﬀectiveLM": "respectively."
        },
        {
          "16\nREDAﬀectiveLM": ""
        },
        {
          "16\nREDAﬀectiveLM": ""
        },
        {
          "16\nREDAﬀectiveLM": "Model"
        },
        {
          "16\nREDAﬀectiveLM": "REDAﬀectiveLM (Our Method)"
        },
        {
          "16\nREDAﬀectiveLM": ""
        },
        {
          "16\nREDAﬀectiveLM": "sent2aﬀect [15]"
        },
        {
          "16\nREDAﬀectiveLM": "SS-BED [14]"
        },
        {
          "16\nREDAﬀectiveLM": "Kim’s CNN [36]"
        },
        {
          "16\nREDAﬀectiveLM": "GRU [7]"
        },
        {
          "16\nREDAﬀectiveLM": "LSTM [14]"
        },
        {
          "16\nREDAﬀectiveLM": "Bi-LSTM [15]"
        },
        {
          "16\nREDAﬀectiveLM": "Bi-LSTM+Attention [7]"
        },
        {
          "16\nREDAﬀectiveLM": "emoBi-LSTM+Attention"
        },
        {
          "16\nREDAﬀectiveLM": "XLNet [18]"
        },
        {
          "16\nREDAﬀectiveLM": ""
        },
        {
          "16\nREDAﬀectiveLM": "SWAT [8]"
        },
        {
          "16\nREDAﬀectiveLM": "Emotion Term Model\n[4]"
        },
        {
          "16\nREDAﬀectiveLM": "Synesketch [37]"
        },
        {
          "16\nREDAﬀectiveLM": ""
        },
        {
          "16\nREDAﬀectiveLM": "WMD [38]"
        },
        {
          "16\nREDAﬀectiveLM": "TF-IDF [15, 38]"
        },
        {
          "16\nREDAﬀectiveLM": "N-Grams [14, 39] (N = 1)"
        },
        {
          "16\nREDAﬀectiveLM": "TEC [39]"
        },
        {
          "16\nREDAﬀectiveLM": "TEI [39]"
        },
        {
          "16\nREDAﬀectiveLM": "MEI [39]"
        },
        {
          "16\nREDAﬀectiveLM": "GEC (δ = 0.25) [39]"
        },
        {
          "16\nREDAﬀectiveLM": "GEI (δ = 0.25) [39]"
        },
        {
          "16\nREDAﬀectiveLM": "Sentiment word count [39, 41]"
        },
        {
          "16\nREDAﬀectiveLM": "SSWE [11] (d = 50)"
        },
        {
          "16\nREDAﬀectiveLM": "GloVe [14] (d = 100)"
        },
        {
          "16\nREDAﬀectiveLM": ""
        },
        {
          "16\nREDAﬀectiveLM": "TF-IDF [15, 38]"
        },
        {
          "16\nREDAﬀectiveLM": "N-Grams [14, 39] (N = 1)"
        },
        {
          "16\nREDAﬀectiveLM": "TEC [39]"
        },
        {
          "16\nREDAﬀectiveLM": "TEI [39]"
        },
        {
          "16\nREDAﬀectiveLM": "MEI [39]"
        },
        {
          "16\nREDAﬀectiveLM": "GEC (δ = 0.25) [39]"
        },
        {
          "16\nREDAﬀectiveLM": "GEI (δ = 0.25) [39]"
        },
        {
          "16\nREDAﬀectiveLM": "Sentiment word count [39, 41]"
        },
        {
          "16\nREDAﬀectiveLM": "SSWE [11] (d = 50)"
        },
        {
          "16\nREDAﬀectiveLM": "GloVe [14] (d = 100)"
        }
      ],
      "page": 16
    },
    {
      "caption": "Table 3: and SemEval-",
      "data": [
        {
          "REDAﬀectiveLM\n17": "Results of\nthe models over RENh-4k illustrated in table 3 and SemEval-"
        },
        {
          "REDAﬀectiveLM\n17": "2007 illustrated in table 4 show trends similar to REN-20k.\nIn the results of"
        },
        {
          "REDAﬀectiveLM\n17": "RENh-4k, our model achieves signiﬁcant gains of 7.38, 6.99, 6.22, 5.29 and 2.48"
        },
        {
          "REDAﬀectiveLM\n17": "percentage points when compared to best\nresults\nin deep learning category"
        },
        {
          "REDAﬀectiveLM\n17": "of baselines, 16.65, 18.35, 28.04, 13.56, and 8.47 percentage points compared"
        },
        {
          "REDAﬀectiveLM\n17": "to best\nlexicon based baseline\nresults,\n16.38, 17.85,\n22.77, 12.04,\nand 5.55"
        },
        {
          "REDAﬀectiveLM\n17": "percentage points compared to best problem transformation baseline results"
        },
        {
          "REDAﬀectiveLM\n17": "and 16, 16.64, 22.81, 12.01, and 5.82 compared to best algorithm adaptation"
        },
        {
          "REDAﬀectiveLM\n17": "baseline results for Acc@1, APdocument, APemotion, RMSED and WDD, respec-"
        },
        {
          "REDAﬀectiveLM\n17": "tively. Similarly for SemEval-2007, the gains achieved by our model are 7.56,"
        },
        {
          "REDAﬀectiveLM\n17": "6.13, 2.96, 6.90, and 3.75 percentage points compared to deep learning best"
        },
        {
          "REDAﬀectiveLM\n17": "results 17.56, 25.93, 25.21, 15.51, and 8.29 percentage points compared to best"
        },
        {
          "REDAﬀectiveLM\n17": "results in lexicon based baselines, 21.36, 23.35, 18.67, 11.26, and 6.1 percent-"
        },
        {
          "REDAﬀectiveLM\n17": "age points compared to problem transformation best results and 17.36, 22.01,"
        },
        {
          "REDAﬀectiveLM\n17": "15.09, 11.03, and 5.97 percentage points compared to algorithm adaptation"
        },
        {
          "REDAﬀectiveLM\n17": "best results for the same set of measures, respectively. The entire results over"
        },
        {
          "REDAﬀectiveLM\n17": "the three datasets thus consolidate that our REDAﬀectiveLM model achieves"
        },
        {
          "REDAﬀectiveLM\n17": "best performance\nresults when considering the\ntop-ranked readers’\nemotion"
        },
        {
          "REDAﬀectiveLM\n17": "prediction (Acc@1) and overall readers’ emotion proﬁle prediction (APdocument"
        },
        {
          "REDAﬀectiveLM\n17": "lower\nerror/distance values\nand APemotion), and also obtains\n(RMSED and"
        },
        {
          "REDAﬀectiveLM\n17": "WDD)."
        },
        {
          "REDAﬀectiveLM\n17": "Across\nthe three datasets, XLNet and emoBi-LSTM+Attention,\nindivid-"
        },
        {
          "REDAﬀectiveLM\n17": "ual networks of our model are the top two performing baselines\nin the deep"
        },
        {
          "REDAﬀectiveLM\n17": "learning category and even among the entire set of baselines belonging to the"
        },
        {
          "REDAﬀectiveLM\n17": "other categories. We believe this is because XLNet is a promising transformer"
        },
        {
          "REDAﬀectiveLM\n17": "based pre-trained language model\nthat generates powerful contextual\nrepre-"
        },
        {
          "REDAﬀectiveLM\n17": "sentations and, emoBi-LSTM+Attention enriches\nthe conventional\nsemantic"
        },
        {
          "REDAﬀectiveLM\n17": "representations with ‘aﬀect’ that is evidently visible through the gains achieved"
        },
        {
          "REDAﬀectiveLM\n17": "by emoBi-LSTM+Attention (aﬀect enriched) over Bi-LSTM+Attention (con-"
        },
        {
          "REDAﬀectiveLM\n17": "ventional) across the three datasets, for all the evaluation measures. But when"
        },
        {
          "REDAﬀectiveLM\n17": "comparing these individual networks with our model,\nthe lowest among the"
        },
        {
          "REDAﬀectiveLM\n17": "gains achieved by our model, across the three datasets, are itself noteworthy."
        },
        {
          "REDAﬀectiveLM\n17": "That is our model obtains a minimum gain of 7.38, 4.68, 2.96, 5.29 and 2.48"
        },
        {
          "REDAﬀectiveLM\n17": "percentage points over XLNet and 8.77, 6.36, 5.97, 5.96, and 3.75 percent-"
        },
        {
          "REDAﬀectiveLM\n17": "age points over\nemoBi-LSTM+Attention,\nfor measures Acc@1, APdocument,"
        },
        {
          "REDAﬀectiveLM\n17": "respectively. This\nindicates\nthe\npromising\nAPemotion, RMSED\nand WDD,"
        },
        {
          "REDAﬀectiveLM\n17": "nature of our REDAﬀectiveLM model\ntowards\nreaders’\nemotion detection,"
        },
        {
          "REDAﬀectiveLM\n17": "over these ablation or individual networks, leveraging both aﬀect enriched doc-"
        },
        {
          "REDAﬀectiveLM\n17": "ument\nrepresentation and contextual\nrepresentation from transformer based"
        },
        {
          "REDAﬀectiveLM\n17": "pre-trained language model, eﬀectively."
        },
        {
          "REDAﬀectiveLM\n17": "Trends of\nevaluation results across\nthe\nthree datasets\nillustrate another"
        },
        {
          "REDAﬀectiveLM\n17": "point that the dataset SemEval-2007 obtains performance slightly better than"
        },
        {
          "REDAﬀectiveLM\n17": "RENh-4k even though it has\ncomparably less data. This might be because"
        },
        {
          "REDAﬀectiveLM\n17": "SemEval-2007 being labeled by only six annotators is less complex in nature,"
        }
      ],
      "page": 17
    },
    {
      "caption": "Table 3: EvaluationresultsoverRENh-4k(Bestresultsamongallthemodels,",
      "data": [
        {
          "18\nREDAﬀectiveLM": ""
        },
        {
          "18\nREDAﬀectiveLM": ""
        },
        {
          "18\nREDAﬀectiveLM": "Model"
        },
        {
          "18\nREDAﬀectiveLM": "REDAﬀectiveLM (Our Method)"
        },
        {
          "18\nREDAﬀectiveLM": ""
        },
        {
          "18\nREDAﬀectiveLM": "sent2aﬀect [15]"
        },
        {
          "18\nREDAﬀectiveLM": "SS-BED [14]"
        },
        {
          "18\nREDAﬀectiveLM": "Kim’s CNN [36]"
        },
        {
          "18\nREDAﬀectiveLM": "GRU [7]"
        },
        {
          "18\nREDAﬀectiveLM": "LSTM [14]"
        },
        {
          "18\nREDAﬀectiveLM": "Bi-LSTM [15]"
        },
        {
          "18\nREDAﬀectiveLM": "Bi-LSTM+Attention [7]"
        },
        {
          "18\nREDAﬀectiveLM": "emoBi-LSTM+Attention"
        },
        {
          "18\nREDAﬀectiveLM": "XLNet [18]"
        },
        {
          "18\nREDAﬀectiveLM": ""
        },
        {
          "18\nREDAﬀectiveLM": "SWAT [8]"
        },
        {
          "18\nREDAﬀectiveLM": "Emotion Term Model\n[4]"
        },
        {
          "18\nREDAﬀectiveLM": "Synesketch [37]"
        },
        {
          "18\nREDAﬀectiveLM": ""
        },
        {
          "18\nREDAﬀectiveLM": "WMD [38]"
        },
        {
          "18\nREDAﬀectiveLM": "TF-IDF [15, 38]"
        },
        {
          "18\nREDAﬀectiveLM": "N-Grams [14, 39] (N = 1)"
        },
        {
          "18\nREDAﬀectiveLM": "TEC [39]"
        },
        {
          "18\nREDAﬀectiveLM": "TEI [39]"
        },
        {
          "18\nREDAﬀectiveLM": "MEI [39]"
        },
        {
          "18\nREDAﬀectiveLM": "GEC (δ = 0.25) [39]"
        },
        {
          "18\nREDAﬀectiveLM": "GEI (δ = 0.25) [39]"
        },
        {
          "18\nREDAﬀectiveLM": "Sentiment word count [39, 41]"
        },
        {
          "18\nREDAﬀectiveLM": "SSWEu [11] (d = 50)"
        },
        {
          "18\nREDAﬀectiveLM": "GloVe [14] (d = 100)"
        },
        {
          "18\nREDAﬀectiveLM": ""
        },
        {
          "18\nREDAﬀectiveLM": "TF-IDF [15, 38]"
        },
        {
          "18\nREDAﬀectiveLM": "N-Grams [14, 39] (N = 1)"
        },
        {
          "18\nREDAﬀectiveLM": "TEC [39]"
        },
        {
          "18\nREDAﬀectiveLM": "TEI [39]"
        },
        {
          "18\nREDAﬀectiveLM": "MEI [39]"
        },
        {
          "18\nREDAﬀectiveLM": "GEC (δ = 0.25) [39]"
        },
        {
          "18\nREDAﬀectiveLM": "GEI (δ = 0.25) [39]"
        },
        {
          "18\nREDAﬀectiveLM": "Sentiment word count [39, 41]"
        },
        {
          "18\nREDAﬀectiveLM": "SSWEu [11] (d = 50)"
        },
        {
          "18\nREDAﬀectiveLM": "GloVe [14] (d = 100)"
        },
        {
          "18\nREDAﬀectiveLM": ""
        },
        {
          "18\nREDAﬀectiveLM": ""
        },
        {
          "18\nREDAﬀectiveLM": ""
        },
        {
          "18\nREDAﬀectiveLM": "the complexity of datasets"
        },
        {
          "18\nREDAﬀectiveLM": ""
        },
        {
          "18\nREDAﬀectiveLM": ""
        },
        {
          "18\nREDAﬀectiveLM": "respectively. SemEval-2007"
        },
        {
          "18\nREDAﬀectiveLM": ""
        },
        {
          "18\nREDAﬀectiveLM": ""
        }
      ],
      "page": 18
    },
    {
      "caption": "Table 4: Evaluation results over SemEval-2007 (Best results among all the",
      "data": [
        {
          "REDAﬀectiveLM": "results among all",
          "19": "the"
        },
        {
          "REDAﬀectiveLM": "",
          "19": ""
        },
        {
          "REDAﬀectiveLM": "",
          "19": ""
        },
        {
          "REDAﬀectiveLM": "0.0902",
          "19": "0.0525"
        },
        {
          "REDAﬀectiveLM": "",
          "19": ""
        },
        {
          "REDAﬀectiveLM": "0.2241",
          "19": "0.1428"
        },
        {
          "REDAﬀectiveLM": "0.1771",
          "19": "0.1090"
        },
        {
          "REDAﬀectiveLM": "0.1987",
          "19": "0.1200"
        },
        {
          "REDAﬀectiveLM": "0.2005",
          "19": "0.1098"
        },
        {
          "REDAﬀectiveLM": "0.1842",
          "19": "0.1089"
        },
        {
          "REDAﬀectiveLM": "0.1812",
          "19": "0.1074"
        },
        {
          "REDAﬀectiveLM": "0.1700",
          "19": "0.0915"
        },
        {
          "REDAﬀectiveLM": "0.1592",
          "19": "0.0900"
        },
        {
          "REDAﬀectiveLM": "0.1739",
          "19": "0.0913"
        },
        {
          "REDAﬀectiveLM": "",
          "19": ""
        },
        {
          "REDAﬀectiveLM": "0.2453",
          "19": "0.1354"
        },
        {
          "REDAﬀectiveLM": "0.3031",
          "19": "0.1975"
        },
        {
          "REDAﬀectiveLM": "0.2470",
          "19": "0.1510"
        },
        {
          "REDAﬀectiveLM": "",
          "19": ""
        },
        {
          "REDAﬀectiveLM": "0.2430",
          "19": "0.1143"
        },
        {
          "REDAﬀectiveLM": "0.2080",
          "19": "0.1135"
        },
        {
          "REDAﬀectiveLM": "0.2089",
          "19": "0.1189"
        },
        {
          "REDAﬀectiveLM": "0.2028",
          "19": "0.1219"
        },
        {
          "REDAﬀectiveLM": "0.2985",
          "19": "0.1228"
        },
        {
          "REDAﬀectiveLM": "0.2051",
          "19": "0.1257"
        },
        {
          "REDAﬀectiveLM": "0.2113",
          "19": "0.1251"
        },
        {
          "REDAﬀectiveLM": "0.2136",
          "19": "0.1291"
        },
        {
          "REDAﬀectiveLM": "0.2089",
          "19": "0.1208"
        },
        {
          "REDAﬀectiveLM": "0.2300",
          "19": "0.1272"
        },
        {
          "REDAﬀectiveLM": "0.2378",
          "19": "0.1152"
        },
        {
          "REDAﬀectiveLM": "",
          "19": ""
        },
        {
          "REDAﬀectiveLM": "0.2059",
          "19": "0.1206"
        },
        {
          "REDAﬀectiveLM": "0.2027",
          "19": "0.1171"
        },
        {
          "REDAﬀectiveLM": "0.2021",
          "19": "0.1204"
        },
        {
          "REDAﬀectiveLM": "0.2005",
          "19": "0.1122"
        },
        {
          "REDAﬀectiveLM": "0.2062",
          "19": "0.1306"
        },
        {
          "REDAﬀectiveLM": "0.2089",
          "19": "0.1229"
        },
        {
          "REDAﬀectiveLM": "0.2099",
          "19": "0.1248"
        },
        {
          "REDAﬀectiveLM": "0.2023",
          "19": "0.1193"
        },
        {
          "REDAﬀectiveLM": "0.4032",
          "19": "0.1641"
        },
        {
          "REDAﬀectiveLM": "0.4022",
          "19": "0.1643"
        },
        {
          "REDAﬀectiveLM": "",
          "19": ""
        },
        {
          "REDAﬀectiveLM": "",
          "19": ""
        },
        {
          "REDAﬀectiveLM": "",
          "19": ""
        },
        {
          "REDAﬀectiveLM": "",
          "19": ""
        },
        {
          "REDAﬀectiveLM": "",
          "19": ""
        },
        {
          "REDAﬀectiveLM": "",
          "19": ""
        },
        {
          "REDAﬀectiveLM": "",
          "19": ""
        },
        {
          "REDAﬀectiveLM": "",
          "19": ""
        }
      ],
      "page": 19
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Fig. 3: Emotion proﬁle correlations in the datasets": "Besides looking into the performance gain obtained by our model over the"
        },
        {
          "Fig. 3: Emotion proﬁle correlations in the datasets": "baselines, we also analyze the statistical signiﬁcance of our model performance"
        },
        {
          "Fig. 3: Emotion proﬁle correlations in the datasets": "with respect to Acc@1 and RMSE, the coarse-grained and ﬁne-grained mea-"
        },
        {
          "Fig. 3: Emotion proﬁle correlations in the datasets": "sures\nthat\nideally represent classiﬁcation and regression task characteristics,"
        },
        {
          "Fig. 3: Emotion proﬁle correlations in the datasets": "respectively. We compute statistical signiﬁcance between our REDAﬀectiveLM"
        },
        {
          "Fig. 3: Emotion proﬁle correlations in the datasets": "model\nand\nthe\nbest\nperforming\nbaseline\nby\nconducting McNemar’s\nand"
        },
        {
          "Fig. 3: Emotion proﬁle correlations in the datasets": "Kolmogorov-Smirnov tests over Acc@1 and RMSE, respectively with conven-"
        },
        {
          "Fig. 3: Emotion proﬁle correlations in the datasets": "tional signiﬁcance level (i.e., p-value 0.05). The p-values obtained for REN-20k,"
        },
        {
          "Fig. 3: Emotion proﬁle correlations in the datasets": "RENh-4k, and SemEval-2007 are 1.64E-5, 2.15E-3 and 5.07E-3 for Acc@1 and"
        },
        {
          "Fig. 3: Emotion proﬁle correlations in the datasets": "1.80E-6, 3.47E-4 and 6.19E-4 for RMSE,\nrespectively,\nindicating statistical"
        },
        {
          "Fig. 3: Emotion proﬁle correlations in the datasets": "signiﬁcance of our model REDAﬀectiveLM over the best baselines."
        }
      ],
      "page": 20
    },
    {
      "caption": "Table 5: shows pairs of attention maps for five sample",
      "data": [
        {
          "REDAﬀectiveLM\n21": "from these attention based models along with readers’ emotion proﬁles\nthat"
        },
        {
          "REDAﬀectiveLM\n21": "highlight key terms with corresponding weightage based on their role in read-"
        },
        {
          "REDAﬀectiveLM\n21": "ers’\nemotion prediction (or decision making). That\nis,\nspeciﬁcally, we\nlook"
        },
        {
          "REDAﬀectiveLM\n21": "at\nthe behavior of emoBi-LSTM+Attention network to understand whether"
        },
        {
          "REDAﬀectiveLM\n21": "the network has eﬃciently identiﬁed and assigned weightage to the key terms"
        },
        {
          "REDAﬀectiveLM\n21": "responsible\nfor\nreaders’\nemotion detection (i.e.,\nemotion words and named"
        },
        {
          "REDAﬀectiveLM\n21": "entities\n[7])\nto obtain signiﬁcant performance gains\nin the predictions over"
        },
        {
          "REDAﬀectiveLM\n21": "Bi-LSTM+Attention."
        },
        {
          "REDAﬀectiveLM\n21": "4.2.1 Qualitative Evaluation"
        },
        {
          "REDAﬀectiveLM\n21": "In\nqualitative\nbehavior\nevaluation, we manually\ncompare\nthe\nkey\nterms"
        },
        {
          "REDAﬀectiveLM\n21": "(emotion words\nand\nnamed\nentities)\nhighlighted\nin\nthe\nattention maps"
        },
        {
          "REDAﬀectiveLM\n21": "and\ntheir\nassociated weightage,\nof\nboth Bi-LSTM+Attention\nand\nemoBi-"
        },
        {
          "REDAﬀectiveLM\n21": "LSTM+Attention. Table\n5\nshows pairs\nof\nattention maps\nfor ﬁve\nsample"
        },
        {
          "REDAﬀectiveLM\n21": "documents, where in each pair, the ﬁrst attention map is the one generated by"
        },
        {
          "REDAﬀectiveLM\n21": "Bi-LSTM+Attention and second by emoBi-LSTM+Attention, along with their"
        },
        {
          "REDAﬀectiveLM\n21": "associated ground-truth emotion proﬁles (epr) and predicted emotion proﬁles"
        },
        {
          "REDAﬀectiveLM\n21": "of both Bi-LSTM+Attention ( (cid:98)epr) and emoBi-LSTM+Attention ( (cid:98)eprEmo). In"
        },
        {
          "REDAﬀectiveLM\n21": "the attention maps, diﬀering color intensities over the words represent weigh-"
        },
        {
          "REDAﬀectiveLM\n21": "tage assigned to the words by the attention,\ni.e., dark red for high weightage"
        },
        {
          "REDAﬀectiveLM\n21": "and for lower weightage color intensities become lighter."
        },
        {
          "REDAﬀectiveLM\n21": "In the ﬁrst pair, the attention map from Bi-LSTM+Attention signiﬁcantly"
        },
        {
          "REDAﬀectiveLM\n21": "assigns weightage to an emotion word ‘protest’ and a named entity ‘Pakistan’."
        },
        {
          "REDAﬀectiveLM\n21": "Whereas,\nthe attention map from emoBi-LSTM+Attention shows\nimprove-"
        },
        {
          "REDAﬀectiveLM\n21": "ments in the prediction,\ni.e., nearness of prediction to ground truth, especially"
        },
        {
          "REDAﬀectiveLM\n21": "visible\nin the\ncase\nof\nemotions\nfear\nand surprise\nby\nassigning\nsigniﬁcant"
        },
        {
          "REDAﬀectiveLM\n21": "weightage to the emotion word ‘demolition’.\nIn the second and third pair of"
        },
        {
          "REDAﬀectiveLM\n21": "attention maps, we can observe high improvements\nin prediction for emoBi-"
        },
        {
          "REDAﬀectiveLM\n21": "LSTM+Attention over Bi-LSTM+Attention, especially visible in the case of"
        },
        {
          "REDAﬀectiveLM\n21": "emotion anger by identifying the emotion word ‘attackers’\nin the second pair,"
        },
        {
          "REDAﬀectiveLM\n21": "and emotion joy by identifying the emotion word ‘sweet’\nin the third pair."
        },
        {
          "REDAﬀectiveLM\n21": "Bi-LSTM+Attention, apart from failing to identify key terms (emotion words"
        },
        {
          "REDAﬀectiveLM\n21": "and named entities)\nsuch as\n‘demolition’\nin the ﬁrst pair,\n‘attackers’\nin the"
        },
        {
          "REDAﬀectiveLM\n21": "second pair,\n‘sweet’\nin the third pair, etc., also are mostly seen to assign uni-"
        },
        {
          "REDAﬀectiveLM\n21": "form weightage to the attention identiﬁed words. For example,\nin the fourth"
        },
        {
          "REDAﬀectiveLM\n21": "pair, the words ‘car’ and ‘teenager’ are given almost the same high intensity as"
        },
        {
          "REDAﬀectiveLM\n21": "the words ‘danger’ and ‘health’. But in the case of emoBi-LSTM+Attention,"
        },
        {
          "REDAﬀectiveLM\n21": "weightage for\nthe words\n‘car’ and ‘teenager’ are seen to be diminished than"
        },
        {
          "REDAﬀectiveLM\n21": "‘danger’\nand ‘health’. Similarly\nin the ﬁfth pair,\nemoBi-LSTM+Attention"
        },
        {
          "REDAﬀectiveLM\n21": "assigns diﬀerent weightage\nfor\nthe words\n‘within’,\n‘completed’,\n‘year’,\netc.,"
        },
        {
          "REDAﬀectiveLM\n21": "whereas Bi-LSTM+Attention assigns almost similar weightage to these words."
        },
        {
          "REDAﬀectiveLM\n21": "Hence the entire set of qualitative evaluations indicates that better than the"
        },
        {
          "REDAﬀectiveLM\n21": "Bi-LSTM+Attention that utilizes conventional semantic embedding, the aﬀect"
        },
        {
          "REDAﬀectiveLM\n21": "enriched embedding based network emoBi-LSTM+Attention, can eﬀectively"
        }
      ],
      "page": 21
    },
    {
      "caption": "Table 5: Sample attention maps",
      "data": [
        {
          "Table 5: Sample attention maps": ""
        },
        {
          "Table 5: Sample attention maps": "[anger,"
        },
        {
          "Table 5: Sample attention maps": ""
        },
        {
          "Table 5: Sample attention maps": ""
        },
        {
          "Table 5: Sample attention maps": ""
        },
        {
          "Table 5: Sample attention maps": ""
        },
        {
          "Table 5: Sample attention maps": ""
        },
        {
          "Table 5: Sample attention maps": ""
        },
        {
          "Table 5: Sample attention maps": ""
        },
        {
          "Table 5: Sample attention maps": ""
        },
        {
          "Table 5: Sample attention maps": ""
        },
        {
          "Table 5: Sample attention maps": ""
        },
        {
          "Table 5: Sample attention maps": ""
        },
        {
          "Table 5: Sample attention maps": ""
        },
        {
          "Table 5: Sample attention maps": ""
        },
        {
          "Table 5: Sample attention maps": ""
        },
        {
          "Table 5: Sample attention maps": ""
        }
      ],
      "page": 22
    },
    {
      "caption": "Table 6: illustrate that",
      "data": [
        {
          "REDAﬀectiveLM\n23": "with one. To create these attention maps, we use the popular emotion lexicons"
        },
        {
          "REDAﬀectiveLM\n23": "DepecheMood++ [40] and EmoWordNet\n[33] and Named Entity Recognizer"
        },
        {
          "REDAﬀectiveLM\n23": "(NER) from spaCy10. We generate external (EAM) and hybrid (HAM) atten-"
        },
        {
          "REDAﬀectiveLM\n23": "tion maps for both emoBi-LSTM+Attention and Bi-LSTM+Attention models"
        },
        {
          "REDAﬀectiveLM\n23": "where for each model we contrast the extent of deviation between these atten-"
        },
        {
          "REDAﬀectiveLM\n23": "tion maps using the similarity measures behavioral similarity, word similarity,"
        },
        {
          "REDAﬀectiveLM\n23": "and word probability [7], discussed below."
        },
        {
          "REDAﬀectiveLM\n23": "• Behavioral Similarity of a corpus D is\nthe average of pair-wise similarity"
        },
        {
          "REDAﬀectiveLM\n23": "between HAM (taken as continuous) and EAM for each document d in the"
        },
        {
          "REDAﬀectiveLM\n23": "corpus."
        },
        {
          "REDAﬀectiveLM\n23": "|D|"
        },
        {
          "REDAﬀectiveLM\n23": "1 D\n(cid:88) d\n(14)\nBehSimD =\nAU C(HAMd, EAMd)"
        },
        {
          "REDAﬀectiveLM\n23": "=1"
        },
        {
          "REDAﬀectiveLM\n23": "where, AU C is Area Under Curve that ranges from 0 (indicating negative"
        },
        {
          "REDAﬀectiveLM\n23": "similarity) to 1 (indicating perfect similarity) [25]."
        },
        {
          "REDAﬀectiveLM\n23": "• Word\nSimilarity\nbetween\nis\nthe\naverage\ndocument\ncosine\nsimilarity11"
        },
        {
          "REDAﬀectiveLM\n23": "between HAM (taken as binary) and EAM."
        },
        {
          "REDAﬀectiveLM\n23": "|D|−|D(cid:48)|"
        },
        {
          "REDAﬀectiveLM\n23": "1"
        },
        {
          "REDAﬀectiveLM\n23": "(cid:88) d\n(15)\nWordSimD =\ncos (HAMd, EAMd)"
        },
        {
          "REDAﬀectiveLM\n23": "|D| − |D(cid:48)|"
        },
        {
          "REDAﬀectiveLM\n23": "=1"
        },
        {
          "REDAﬀectiveLM\n23": "where,\n|D(cid:48)|\nis the total number of documents without any emotion words or"
        },
        {
          "REDAﬀectiveLM\n23": "named entities."
        },
        {
          "REDAﬀectiveLM\n23": "• Word Probability of\na\ncorpus ﬁnds boolean intersection between binary"
        },
        {
          "REDAﬀectiveLM\n23": "HAM and EAM, averaged over the documents, to quantify how much among"
        },
        {
          "REDAﬀectiveLM\n23": "the total number of emotion words and named entities in the document are"
        },
        {
          "REDAﬀectiveLM\n23": "identiﬁed by attention."
        },
        {
          "REDAﬀectiveLM\n23": "|D|−|D(cid:48)|"
        },
        {
          "REDAﬀectiveLM\n23": "1\n(cid:80)(EAMd ∩ HAMd)"
        },
        {
          "REDAﬀectiveLM\n23": "(16)\nWordProbD ="
        },
        {
          "REDAﬀectiveLM\n23": "(cid:88) d\n|D| − |D(cid:48)|\n(cid:80)(EAMd) + λ"
        },
        {
          "REDAﬀectiveLM\n23": "=1"
        },
        {
          "REDAﬀectiveLM\n23": "where, λ = 1 for EAM = 0, and λ = 0 for EAM (cid:54)= 0."
        },
        {
          "REDAﬀectiveLM\n23": "The\nresults\nof\nquantitative\nanalysis\nshown\nin\ntable\n6\nillustrate\nthat"
        },
        {
          "REDAﬀectiveLM\n23": "for all\nthe three datasets emoBi-LSTM+Attention obtains higher\nsimilarity"
        },
        {
          "REDAﬀectiveLM\n23": "scores between external and hybrid attention maps when compared to Bi-"
        },
        {
          "REDAﬀectiveLM\n23": "LSTM+Attention,\nfor both the\nlexicons, which indicates\nthat\ncompared to"
        },
        {
          "REDAﬀectiveLM\n23": "Bi-LSTM+Attention model, emoBi-LSTM+Attention has improved ability to"
        },
        {
          "REDAﬀectiveLM\n23": "identify emotion words and named entities. Against the backdrop of\n[7] that"
        },
        {
          "REDAﬀectiveLM\n23": "demonstrates emotion words and named entities are important\nfor emotion"
        },
        {
          "REDAﬀectiveLM\n23": "detection,\nthis validates\nemoBi-LSTM+Attention’s\nimproved suitability for"
        }
      ],
      "page": 23
    },
    {
      "caption": "Table 6: Quantitative evaluation results",
      "data": [
        {
          "24\nREDAﬀectiveLM": "emotion identiﬁcation. Thus, the qualitative and quantitative behavior anal-"
        },
        {
          "24\nREDAﬀectiveLM": "ysis on emoBi-LSTM+Attention together establishes"
        },
        {
          "24\nREDAﬀectiveLM": "increases\nthe ability of\nthe model"
        },
        {
          "24\nREDAﬀectiveLM": "assign weightage to the key terms responsible for readers’ emotion detection"
        },
        {
          "24\nREDAﬀectiveLM": "to improve prediction."
        }
      ],
      "page": 24
    },
    {
      "caption": "Table 6: Quantitative evaluation results",
      "data": [
        {
          "DepecheMood++": "RENh-",
          "EmoWordNet": "RENh-"
        },
        {
          "DepecheMood++": "",
          "EmoWordNet": ""
        },
        {
          "DepecheMood++": "4k",
          "EmoWordNet": "4k"
        },
        {
          "DepecheMood++": "Behavioral similarity scores (↑)",
          "EmoWordNet": ""
        },
        {
          "DepecheMood++": "0.7096",
          "EmoWordNet": "0.6988"
        },
        {
          "DepecheMood++": "0.8182",
          "EmoWordNet": "0.8104"
        },
        {
          "DepecheMood++": "Word similarity scores (↑)",
          "EmoWordNet": ""
        },
        {
          "DepecheMood++": "0.6851",
          "EmoWordNet": "0.6606"
        },
        {
          "DepecheMood++": "0.8636",
          "EmoWordNet": "0.8128"
        },
        {
          "DepecheMood++": "Word probability scores (↑)",
          "EmoWordNet": ""
        },
        {
          "DepecheMood++": "0.7648",
          "EmoWordNet": "0.7205"
        },
        {
          "DepecheMood++": "0.8071",
          "EmoWordNet": "0.7551"
        }
      ],
      "page": 24
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "REDAﬀectiveLM\n25": "aﬀect enriched Bi-LSTM+Attention to study the impact of aﬀect enrichment"
        },
        {
          "REDAﬀectiveLM\n25": "speciﬁcally in readers’ emotion detection. We observed that compared to con-"
        },
        {
          "REDAﬀectiveLM\n25": "ventional semantic embedding, aﬀect enrichment obtained higher performance"
        },
        {
          "REDAﬀectiveLM\n25": "and helped to increase the ability of\nthe network to eﬀectively identify and"
        },
        {
          "REDAﬀectiveLM\n25": "assign weightage to key terms (emotion words and named entities) responsi-"
        },
        {
          "REDAﬀectiveLM\n25": "ble for\nreaders’ emotion detection. To aid future research,\nthe datasets and"
        },
        {
          "REDAﬀectiveLM\n25": "other relevant materials, including the source code will be made publicly avail-"
        },
        {
          "REDAﬀectiveLM\n25": "able at https://dcs.uoc.ac.in/cida/projects/ac/redaﬀectivelm.html and https:"
        },
        {
          "REDAﬀectiveLM\n25": "//github.com/anoopkdcs/REDAﬀectiveLM soon as this work is accepted for"
        },
        {
          "REDAﬀectiveLM\n25": "publication.\nIn the\nfuture, we\nare planning\nto\nexplore\nthe possibilities\nof"
        },
        {
          "REDAﬀectiveLM\n25": "developing aﬀect\nenriched transformer-based language models. We are also"
        },
        {
          "REDAﬀectiveLM\n25": "planning to explore the applicability of aﬀect enriched transformer-based lan-"
        },
        {
          "REDAﬀectiveLM\n25": "guage models\nin aﬀective well-being tasks\nsuch as early detection of anxiety"
        },
        {
          "REDAﬀectiveLM\n25": "and depression from social networks."
        },
        {
          "REDAﬀectiveLM\n25": "Acknowledgments.\nThe authors thankfully acknowledge the popular lead-"
        },
        {
          "REDAﬀectiveLM\n25": "ing digital media company RAPPLER for the data source of news data along"
        },
        {
          "REDAﬀectiveLM\n25": "with associated emotions from their online portal that very relevantly helped"
        },
        {
          "REDAﬀectiveLM\n25": "to conduct this research. The authors thankfully acknowledge Arjun K. Sreed-"
        },
        {
          "REDAﬀectiveLM\n25": "har, Dheeraj K., Sarath Kumar P. S., and Vishnu S., the postgraduate students"
        },
        {
          "REDAﬀectiveLM\n25": "of the Department of Computer Science, University of Calicut, who have been"
        },
        {
          "REDAﬀectiveLM\n25": "involved in dataset procurement. Manjary P Gangan was\nsupported by the"
        },
        {
          "REDAﬀectiveLM\n25": "Women Scientist Scheme-A (WOS-A), Department of Science and Technol-"
        },
        {
          "REDAﬀectiveLM\n25": "ogy (DST) of the Government of India for Research in Basic/Applied Science"
        },
        {
          "REDAﬀectiveLM\n25": "under the Grant SR/WOS-A/PM-62/2018."
        },
        {
          "REDAﬀectiveLM\n25": "Declarations"
        },
        {
          "REDAﬀectiveLM\n25": "• Funding: Not applicable"
        },
        {
          "REDAﬀectiveLM\n25": "• Conﬂict of interest/Competing interests: The authors declare that they have"
        },
        {
          "REDAﬀectiveLM\n25": "no competing interests"
        },
        {
          "REDAﬀectiveLM\n25": "• Ethics approval: Not applicable"
        },
        {
          "REDAﬀectiveLM\n25": "• Consent to participate: Not applicable"
        },
        {
          "REDAﬀectiveLM\n25": "• Consent for publication: The authors give the Publisher the permission to"
        },
        {
          "REDAﬀectiveLM\n25": "publish the work"
        },
        {
          "REDAﬀectiveLM\n25": "• Availability of data and materials: The dataset procured during the current"
        },
        {
          "REDAﬀectiveLM\n25": "study is available from the authors on reasonable request and also publicly"
        },
        {
          "REDAﬀectiveLM\n25": "available at https://dcs.uoc.ac.in/cida/resources/ren-20k.html"
        },
        {
          "REDAﬀectiveLM\n25": "• Code availability: Relevant materials, including the source code and datasets"
        },
        {
          "REDAﬀectiveLM\n25": "will be made publicly available at https://dcs.uoc.ac.in/cida/projects/ac/"
        },
        {
          "REDAﬀectiveLM\n25": "redaﬀectivelm.html and https://github.com/anoopkdcs/REDAﬀectiveLM"
        },
        {
          "REDAﬀectiveLM\n25": "• Authors’ contributions: Anoop Kadan, Deepak P, and Lajish V L initiated"
        },
        {
          "REDAﬀectiveLM\n25": "the work. Anoop Kadan and Deepak P played key roles in conceptualization."
        },
        {
          "REDAﬀectiveLM\n25": "Anoop Kadan, Deepak P, Manjary P Gangan and Savitha Sam Abraham"
        },
        {
          "REDAﬀectiveLM\n25": "designed the algorithm and experimental workﬂow. Anoop Kadan and Man-"
        },
        {
          "REDAﬀectiveLM\n25": "jary P Gangan obtained the datasets\nfor\nthe\nresearch,\nimplemented and"
        }
      ],
      "page": 25
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "26\nREDAﬀectiveLM": "managed the\ncoding. The\nrich experience\nof Deepak P was\ninstrumen-"
        },
        {
          "26\nREDAﬀectiveLM": "tal\nin reﬁning the work. The manuscript was collaboratively authored by"
        },
        {
          "26\nREDAﬀectiveLM": "Anoop Kadan and Manjary P Gangan under the supervision of Deepak P."
        },
        {
          "26\nREDAﬀectiveLM": "All authors contributed to the editing and proofreading. All authors\nread"
        },
        {
          "26\nREDAﬀectiveLM": "and approved the ﬁnal manuscript."
        }
      ],
      "page": 26
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "References": "[1] Chang, Y.-C., Chu, C.-H., Chen, C.C., Hsu, W.-L.: Linguistic template"
        },
        {
          "References": "extraction for\nrecognizing reader-emotion.\nIn:\nInternational Journal of"
        },
        {
          "References": "Computational Linguistics & Chinese Language Processing, Volume 21,"
        },
        {
          "References": "Number 1, June 2016 (2016). https://aclanthology.org/O16-2002"
        },
        {
          "References": "[2] Heaton, C.T., Schwartz, D.M.: Language models as emotional classiﬁers"
        },
        {
          "References": "for textual conversation. In: Proceedings of the 28th ACM International"
        },
        {
          "References": "Conference on Multimedia. MM ’20, pp. 2918–2926. Association for Com-"
        },
        {
          "References": "puting Machinery, New York, NY, USA (2020). https://doi.org/10.1145/"
        },
        {
          "References": "3394171.3413755"
        },
        {
          "References": "[3] Haider, T., Eger,\nS., Kim, E., Klinger, R., Menninghaus, W.: PO-"
        },
        {
          "References": "EMO: Conceptualization,\nannotation,\nand modeling\nof\naesthetic\nemo-"
        },
        {
          "References": "tions\nin German\nand\nEnglish\npoetry.\nIn:\nProceedings\nof\nthe\n12th"
        },
        {
          "References": "Language Resources and Evaluation Conference, pp. 1652–1663. Euro-"
        },
        {
          "References": "pean Language Resources Association, Marseille, France\n(2020). https:"
        },
        {
          "References": "//aclanthology.org/2020.lrec-1.205"
        },
        {
          "References": "[4] Bao, S., Xu, S., Zhang, L., Yan, R., Su, Z., Han, D., Yu, Y.: Mining"
        },
        {
          "References": "social\nemotions\nfrom aﬀective\ntext.\nIEEE Transactions\non Knowledge"
        },
        {
          "References": "and Data Engineering 24(9), 1658–1670 (2011). https://doi.org/10.1109/"
        },
        {
          "References": "TKDE.2011.188"
        },
        {
          "References": "[5] Ye, L., Xu, R.-F., Xu, J.: Emotion prediction of news articles from reader’s"
        },
        {
          "References": "perspective based on multi-label classiﬁcation. In: 2012 International Con-"
        },
        {
          "References": "ference\non Machine Learning\nand Cybernetics,\nvol.\n5, pp.\n2019–2024"
        },
        {
          "References": "(2012). https://doi.org/10.1109/ICMLC.2012.6359686. IEEE"
        },
        {
          "References": "[6] Krebs., F., Lubascher., B., Moers., T., Schaap., P., Spanakis., G.: Social"
        },
        {
          "References": "Emotion Mining Techniques for Facebook Posts Reaction Prediction. In:"
        },
        {
          "References": "Proceedings of the 10th International Conference on Agents and Artiﬁcial"
        },
        {
          "References": "Intelligence (ICAART), vol. 1, pp. 211–220. SciTePress, INSTICC (2018)."
        },
        {
          "References": "https://doi.org/10.5220/0006656002110220"
        },
        {
          "References": "[7] Anoop, K., Deepak, P.,\nSavitha,\nS.A.,\nLajish, V.L., Manjary, P.G.:"
        },
        {
          "References": "Readers’\naﬀect:\npredicting\nand\nunderstanding\nreaders’\nemotions with"
        },
        {
          "References": "deep learning. J Big Data 9(82), 1–31 (2022). https://doi.org/10.1186/"
        },
        {
          "References": "s40537-022-00614-2"
        }
      ],
      "page": 26
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "REDAﬀectiveLM\n27": "[8] Katz, P., Singleton, M., Wicentowski, R.: SWAT-MP:the SemEval-2007"
        },
        {
          "REDAﬀectiveLM\n27": "systems for task 5 and task 14. In: Proceedings of the Fourth International"
        },
        {
          "REDAﬀectiveLM\n27": "Workshop on Semantic Evaluations (SemEval-2007), pp. 308–313. Asso-"
        },
        {
          "REDAﬀectiveLM\n27": "ciation for Computational Linguistics, Prague, Czech Republic\n(2007)."
        },
        {
          "REDAﬀectiveLM\n27": "https://aclanthology.org/S07-1067"
        },
        {
          "REDAﬀectiveLM\n27": "[9] Bhowmick, P.K., Basu, A., Mitra, P.: Reader perspective emotion anal-"
        },
        {
          "REDAﬀectiveLM\n27": "ysis in text through ensemble based multi-label classiﬁcation framework."
        },
        {
          "REDAﬀectiveLM\n27": "Computer and Information Science 2(4), 64–74 (2009). https://doi.org/"
        },
        {
          "REDAﬀectiveLM\n27": "10.5539/cis.v2n4p64"
        },
        {
          "REDAﬀectiveLM\n27": "[10] Socher, R., Pennington, J., Huang, E.H., Ng, A.Y., Manning, C.D.: Semi-"
        },
        {
          "REDAﬀectiveLM\n27": "supervised recursive autoencoders for predicting sentiment distributions."
        },
        {
          "REDAﬀectiveLM\n27": "In: Proceedings of\nthe 2011 Conference on Empirical Methods\nin Nat-"
        },
        {
          "REDAﬀectiveLM\n27": "ural Language Processing, pp. 151–161. Association for Computational"
        },
        {
          "REDAﬀectiveLM\n27": "Linguistics, Edinburgh, Scotland, UK. (2011). https://aclanthology.org/"
        },
        {
          "REDAﬀectiveLM\n27": "D11-1014"
        },
        {
          "REDAﬀectiveLM\n27": "[11] Tang, D., Wei, F., Yang, N., Zhou, M., Liu, T., Qin, B.: Learning"
        },
        {
          "REDAﬀectiveLM\n27": "sentiment-speciﬁc word embedding for Twitter\nsentiment\nclassiﬁcation."
        },
        {
          "REDAﬀectiveLM\n27": "In: Proceedings\nof\nthe\n52nd Annual Meeting\nof\nthe Association\nfor"
        },
        {
          "REDAﬀectiveLM\n27": "Computational Linguistics\n(Volume\n1: Long Papers),\npp.\n1555–1565."
        },
        {
          "REDAﬀectiveLM\n27": "Association for Computational Linguistics, Baltimore, Maryland (2014)."
        },
        {
          "REDAﬀectiveLM\n27": "https://doi.org/10.3115/v1/P14-1146"
        },
        {
          "REDAﬀectiveLM\n27": "[12] Seyeditabari, A., Tabari, N., Gholizade, S., Zadrozny, W.: Emotional"
        },
        {
          "REDAﬀectiveLM\n27": "embeddings: Reﬁning word embeddings to capture emotional content of"
        },
        {
          "REDAﬀectiveLM\n27": "words. arXiv preprint arXiv:1906.00112 (2019). https://doi.org/10.48550/"
        },
        {
          "REDAﬀectiveLM\n27": "ARXIV.1906.00112"
        },
        {
          "REDAﬀectiveLM\n27": "[13] Khosla, S., Chhaya, N., Chawla, K.: Aﬀ2Vec: Aﬀect–enriched distribu-"
        },
        {
          "REDAﬀectiveLM\n27": "tional word representations.\nIn: Proceedings\nof\nthe\n27th International"
        },
        {
          "REDAﬀectiveLM\n27": "Conference on Computational Linguistics, pp. 2204–2218. Association for"
        },
        {
          "REDAﬀectiveLM\n27": "Computational Linguistics, Santa Fe, New Mexico, USA (2018). https:"
        },
        {
          "REDAﬀectiveLM\n27": "//www.aclweb.org/anthology/C18-1187"
        },
        {
          "REDAﬀectiveLM\n27": "[14] Chatterjee, A., Gupta, U., Chinnakotla, M.K., Srikanth, R., Galley, M.,"
        },
        {
          "REDAﬀectiveLM\n27": "Agrawal, P.: Understanding emotions in text using deep learning and big"
        },
        {
          "REDAﬀectiveLM\n27": "data. Computers\nin Human Behavior 93, 309–317 (2019). https://doi."
        },
        {
          "REDAﬀectiveLM\n27": "org/10.1016/j.chb.2018.12.029"
        },
        {
          "REDAﬀectiveLM\n27": "[15] Kratzwald, B.,\nIli´c, S., Kraus, M., Feuerriegel, S., Prendinger, H.: Deep"
        },
        {
          "REDAﬀectiveLM\n27": "learning for aﬀective computing: Text-based emotion recognition in deci-"
        },
        {
          "REDAﬀectiveLM\n27": "sion support. Decision Support Systems 115, 24–35 (2018). https://doi."
        },
        {
          "REDAﬀectiveLM\n27": "org/10.1016/j.dss.2018.09.002"
        },
        {
          "REDAﬀectiveLM\n27": "[16] Devlin, J., Chang, M.-W., Lee, K., Toutanova, K.: BERT: Pre-training"
        }
      ],
      "page": 27
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "28\nREDAﬀectiveLM": "of deep bidirectional\ntransformers\nfor\nlanguage understanding.\nIn: Pro-"
        },
        {
          "28\nREDAﬀectiveLM": "ceedings of\nthe 2019 Conference of\nthe North American Chapter of\nthe"
        },
        {
          "28\nREDAﬀectiveLM": "Association for Computational Linguistics: Human Language Technolo-"
        },
        {
          "28\nREDAﬀectiveLM": "gies, Volume\n1\n(Long\nand Short Papers), pp.\n4171–4186. Association"
        },
        {
          "28\nREDAﬀectiveLM": "for Computational Linguistics, Minneapolis, Minnesota\n(2019).\nhttps:"
        },
        {
          "28\nREDAﬀectiveLM": "//doi.org/10.18653/v1/N19-1423"
        },
        {
          "28\nREDAﬀectiveLM": "[17] Radford, A., Narasimhan, K., Salimans, T., Sutskever, I.: Improving lan-"
        },
        {
          "28\nREDAﬀectiveLM": "guage understanding by generative pre-training.\n(2018). https://openai."
        },
        {
          "28\nREDAﬀectiveLM": "com/blog/language-unsupervised/"
        },
        {
          "28\nREDAﬀectiveLM": "[18] Yang, Z., Dai, Z., Yang, Y., Carbonell, J., Salakhutdinov, R., Le, Q.V.:"
        },
        {
          "28\nREDAﬀectiveLM": "XLNet: Generalized Autoregressive Pretraining\nfor Language Under-"
        },
        {
          "28\nREDAﬀectiveLM": "standing. Curran Associates\nInc., Red Hook, NY, USA (2019). https:"
        },
        {
          "28\nREDAﬀectiveLM": "//dl.acm.org/doi/10.5555/3454287.3454804"
        },
        {
          "28\nREDAﬀectiveLM": "[19] Adoma, A.F., Henry, N.-M., Chen, W.: Comparative analyses of bert,"
        },
        {
          "28\nREDAﬀectiveLM": "roberta, distilbert, and xlnet for text-based emotion recognition. In: 2020"
        },
        {
          "28\nREDAﬀectiveLM": "17th International Computer Conference on Wavelet Active Media Tech-"
        },
        {
          "28\nREDAﬀectiveLM": "nology and Information Processing (ICCWAMTIP), pp. 117–121 (2020)."
        },
        {
          "28\nREDAﬀectiveLM": "https://doi.org/10.1109/ICCWAMTIP51612.2020.9317379"
        },
        {
          "28\nREDAﬀectiveLM": "[20] Adoma, A.F., Henry, N.-M., Chen, W., Rubungo Andre, N.: Recogniz-"
        },
        {
          "28\nREDAﬀectiveLM": "ing\nemotions\nfrom texts\nusing\na\nbert-based\napproach.\nIn:\n2020\n17th"
        },
        {
          "28\nREDAﬀectiveLM": "International Computer Conference on Wavelet Active Media Technol-"
        },
        {
          "28\nREDAﬀectiveLM": "ogy and Information Processing (ICCWAMTIP), pp. 62–66 (2020). https:"
        },
        {
          "28\nREDAﬀectiveLM": "//doi.org/10.1109/ICCWAMTIP51612.2020.9317523"
        },
        {
          "28\nREDAﬀectiveLM": "[21] Pennington,\nJ.,\nSocher, R., Manning, C.: GloVe: Global\nvectors\nfor"
        },
        {
          "28\nREDAﬀectiveLM": "word representation.\nIn: Proceedings of the 2014 Conference on Empiri-"
        },
        {
          "28\nREDAﬀectiveLM": "cal Methods in Natural Language Processing (EMNLP), pp. 1532–1543."
        },
        {
          "28\nREDAﬀectiveLM": "Association for Computational Linguistics, Doha, Qatar\n(2014). https:"
        },
        {
          "28\nREDAﬀectiveLM": "//doi.org/10.3115/v1/D14-1162"
        },
        {
          "28\nREDAﬀectiveLM": "[22] Liang, D.,\nZhang, Y.: AC-BLSTM: Asymmetric Convolutional Bidi-"
        },
        {
          "28\nREDAﬀectiveLM": "rectional\nLSTM Networks\nfor\nText\nClassiﬁcation.\narXiv\npreprint"
        },
        {
          "28\nREDAﬀectiveLM": "arXiv:1611.01884 (2016). https://doi.org/10.48550/arXiv.1611.01884"
        },
        {
          "28\nREDAﬀectiveLM": "[23] Jang, B., Kim, M., Harerimana, G., Kang, S.-u., Kim, J.W.: Bi-LSTM"
        },
        {
          "28\nREDAﬀectiveLM": "model\nto increase accuracy in text\nclassiﬁcation: Combining word2vec"
        },
        {
          "28\nREDAﬀectiveLM": "CNN and attention mechanism. Applied Sciences 10(17)\n(2020). https:"
        },
        {
          "28\nREDAﬀectiveLM": "//doi.org/10.3390/app10175841"
        },
        {
          "28\nREDAﬀectiveLM": "[24] Kardakis, S., Perikos, I., Grivokostopoulou, F., Hatzilygeroudis, I.: Exam-"
        },
        {
          "28\nREDAﬀectiveLM": "ining attention mechanisms in deep learning models for sentiment analy-"
        },
        {
          "28\nREDAﬀectiveLM": "sis. Applied Sciences 11(9) (2021). https://doi.org/10.3390/app11093883"
        }
      ],
      "page": 28
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "REDAﬀectiveLM\n29": "[25] Sen, C., Hartvigsen, T., Yin, B., Kong, X., Rundensteiner, E.: Human"
        },
        {
          "REDAﬀectiveLM\n29": "attention maps\nfor\ntext classiﬁcation: Do humans and neural networks"
        },
        {
          "REDAﬀectiveLM\n29": "focus on the same words? In: Proceedings of\nthe 58th Annual Meeting"
        },
        {
          "REDAﬀectiveLM\n29": "of\nthe Association for Computational Linguistics, pp. 4596–4608. Asso-"
        },
        {
          "REDAﬀectiveLM\n29": "ciation for Computational Linguistics, Online (2020). https://doi.org/10."
        },
        {
          "REDAﬀectiveLM\n29": "18653/v1/2020.acl-main.419"
        },
        {
          "REDAﬀectiveLM\n29": "[26] Tang, D., Zhang, Z., He, Y., Lin, C., Zhou, D.: Hidden topic–emotion tran-"
        },
        {
          "REDAﬀectiveLM\n29": "sition model\nfor multi-level\nsocial emotion detection. Knowledge-Based"
        },
        {
          "REDAﬀectiveLM\n29": "Systems 164, 426–435 (2019). https://doi.org/10.1016/j.knosys.2018.11."
        },
        {
          "REDAﬀectiveLM\n29": "014"
        },
        {
          "REDAﬀectiveLM\n29": "[27] Cabrera-Diego, L.A., Bessis, N., Korkontzelos,\nI.: Classifying emotions"
        },
        {
          "REDAﬀectiveLM\n29": "in\nstack\noverﬂow and\njira\nusing\na multi-label\napproach. Knowledge-"
        },
        {
          "REDAﬀectiveLM\n29": "Based\nSystems\n195,\n105633\n(2020).\nhttps://doi.org/10.1016/j.knosys."
        },
        {
          "REDAﬀectiveLM\n29": "2020.105633"
        },
        {
          "REDAﬀectiveLM\n29": "[28] Strapparava, C., Mihalcea, R.: SemEval-2007\ntask\n14: Aﬀective\ntext."
        },
        {
          "REDAﬀectiveLM\n29": "In: Proceedings\nof\nthe Fourth\nInternational Workshop\non\nSemantic"
        },
        {
          "REDAﬀectiveLM\n29": "Evaluations\n(SemEval-2007), pp. 70–74. Association for Computational"
        },
        {
          "REDAﬀectiveLM\n29": "Linguistics, Prague, Czech Republic\n(2007).\nhttps://aclanthology.org/"
        },
        {
          "REDAﬀectiveLM\n29": "S07-1013"
        },
        {
          "REDAﬀectiveLM\n29": "[29] Ekman, P.: Basic\nemotions.\nIn: Handbook of Cognition and Emotion,"
        },
        {
          "REDAﬀectiveLM\n29": "John Wiley & Sons, Ltd, pp. 45–60 (1999). Chap. 3. https://doi.org/10."
        },
        {
          "REDAﬀectiveLM\n29": "1002/0470013494.ch3"
        },
        {
          "REDAﬀectiveLM\n29": "[30] Schuster, M., Paliwal, K.K.: Bidirectional\nrecurrent\nneural\nnetworks."
        },
        {
          "REDAﬀectiveLM\n29": "IEEE Transactions on Signal Processing 45(11), 2673–2681 (1997). https:"
        },
        {
          "REDAﬀectiveLM\n29": "//doi.org/10.1109/78.650093"
        },
        {
          "REDAﬀectiveLM\n29": "[31] Bahdanau, D., Cho, K., Bengio, Y.: Neural machine translation by jointly"
        },
        {
          "REDAﬀectiveLM\n29": "learning to align and translate. arXiv preprint arXiv:1409.0473 (2014)."
        },
        {
          "REDAﬀectiveLM\n29": "https://doi.org/10.48550/arXiv.1409.0473"
        },
        {
          "REDAﬀectiveLM\n29": "[32] Kudo, T., Richardson, J.: SentencePiece: A simple and language\ninde-"
        },
        {
          "REDAﬀectiveLM\n29": "pendent\nsubword tokenizer and detokenizer\nfor neural\ntext processing."
        },
        {
          "REDAﬀectiveLM\n29": "In: Proceedings of the 2018 Conference on Empirical Methods in Natural"
        },
        {
          "REDAﬀectiveLM\n29": "Language Processing: System Demonstrations, pp. 66–71. Association for"
        },
        {
          "REDAﬀectiveLM\n29": "Computational Linguistics, Brussels, Belgium (2018). https://doi.org/10."
        },
        {
          "REDAﬀectiveLM\n29": "18653/v1/D18-2012"
        },
        {
          "REDAﬀectiveLM\n29": "[33] Badaro, G., Jundi, H., Hajj, H., El-Hajj, W.: EmoWordNet: Automatic"
        },
        {
          "REDAﬀectiveLM\n29": "expansion of\nemotion lexicon using English WordNet.\nIn: Proceedings"
        },
        {
          "REDAﬀectiveLM\n29": "of\nthe Seventh Joint Conference on Lexical and Computational Seman-"
        },
        {
          "REDAﬀectiveLM\n29": "tics, pp. 86–93. Association for Computational Linguistics, New Orleans,"
        },
        {
          "REDAﬀectiveLM\n29": "Louisiana (2018). https://doi.org/10.18653/v1/S18-2009"
        }
      ],
      "page": 29
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "30": "[34] Lei,",
          "REDAﬀectiveLM": "J., Rao, Y., Li, Q., Quan, X., Wenyin, L.: Towards\nbuilding\na"
        },
        {
          "30": "",
          "REDAﬀectiveLM": "social emotion detection system for online news. Future Generation Com-"
        },
        {
          "30": "",
          "REDAﬀectiveLM": "puter Systems 37, 438–448 (2014). https://doi.org/10.1016/j.future.2013."
        },
        {
          "30": "",
          "REDAﬀectiveLM": "09.024"
        },
        {
          "30": "",
          "REDAﬀectiveLM": "[35] Guerini, M., Staiano, J.: Deep feelings: A massive cross-lingual study on"
        },
        {
          "30": "",
          "REDAﬀectiveLM": "the relation between emotions and virality.\nIn: Proceedings of\nthe 24th"
        },
        {
          "30": "",
          "REDAﬀectiveLM": "International Conference on World Wide Web. WWW ’15 Companion,"
        },
        {
          "30": "",
          "REDAﬀectiveLM": "pp. 299–305. Association for Computing Machinery, New York, NY, USA"
        },
        {
          "30": "",
          "REDAﬀectiveLM": "(2015). https://doi.org/10.1145/2740908.2743058"
        },
        {
          "30": "[36] Kim, Y.: Convolutional neural networks",
          "REDAﬀectiveLM": "for\nsentence\nclassiﬁcation.\nIn:"
        },
        {
          "30": "",
          "REDAﬀectiveLM": "Proceedings of\nthe 2014 Conference on Empirical Methods\nin Natural"
        },
        {
          "30": "",
          "REDAﬀectiveLM": "Language Processing\n(EMNLP), pp.\n1746–1751. Association for Com-"
        },
        {
          "30": "",
          "REDAﬀectiveLM": "putational Linguistics, Doha, Qatar (2014). https://doi.org/10.3115/v1/"
        },
        {
          "30": "",
          "REDAﬀectiveLM": "D14-1181"
        },
        {
          "30": "[37] Krcadinac, U., Pasquier, P., Jovanovic, J., Devedzic, V.: Synesketch: An",
          "REDAﬀectiveLM": ""
        },
        {
          "30": "",
          "REDAﬀectiveLM": "open source library for sentence-based emotion recognition. IEEE Trans-"
        },
        {
          "30": "",
          "REDAﬀectiveLM": "actions on Aﬀective Computing 4(3), 312–325 (2013). https://doi.org/10."
        },
        {
          "30": "",
          "REDAﬀectiveLM": "1109/T-AFFC.2013.18"
        },
        {
          "30": "[38] Ren, F., Liu, N.: Emotion computing using word mover’s distance features",
          "REDAﬀectiveLM": ""
        },
        {
          "30": "",
          "REDAﬀectiveLM": "based on ren cecps. PLOS ONE 13(4), 1–17 (2018). https://doi.org/10."
        },
        {
          "30": "",
          "REDAﬀectiveLM": "1371/journal.pone.0194136"
        },
        {
          "30": "[39] Bandhakavi, A., Wiratunga, N., Padmanabhan, D., Massie, S.: Lexicon",
          "REDAﬀectiveLM": ""
        },
        {
          "30": "",
          "REDAﬀectiveLM": "based feature extraction for emotion text classiﬁcation. Pattern Recog-"
        },
        {
          "30": "",
          "REDAﬀectiveLM": "nition Letters 93, 133–142 (2017). https://doi.org/10.1016/j.patrec.2016."
        },
        {
          "30": "",
          "REDAﬀectiveLM": "12.009"
        },
        {
          "30": "[40] Araque, O., Gatti, L., Staiano, J., Guerini, M.: Depechemood++: a bilin-",
          "REDAﬀectiveLM": ""
        },
        {
          "30": "",
          "REDAﬀectiveLM": "gual emotion lexicon built through simple yet powerful techniques. IEEE"
        },
        {
          "30": "",
          "REDAﬀectiveLM": "Transactions\non Aﬀective Computing\n(2019). https://doi.org/10.1109/"
        },
        {
          "30": "",
          "REDAﬀectiveLM": "TAFFC.2019.2934444"
        },
        {
          "30": "[41] Suharshala, R., Anoop, K., Lajish, V.L.: Cross-domain sentiment analysis",
          "REDAﬀectiveLM": ""
        },
        {
          "30": "",
          "REDAﬀectiveLM": "on social media interactions using senti-lexicon based hybrid features. In:"
        },
        {
          "30": "",
          "REDAﬀectiveLM": "2018 3rd International Conference on Inventive Computation Technologies"
        },
        {
          "30": "",
          "REDAﬀectiveLM": "(ICICT), pp. 772–777. IEEE, Coimbatore, India (2018). https://doi.org/"
        },
        {
          "30": "",
          "REDAﬀectiveLM": "10.1109/ICICT43934.2018.9034272"
        },
        {
          "30": "[42] Hutto, C., Gilbert, E.: Vader: A parsimonious rule-based model",
          "REDAﬀectiveLM": "for sen-"
        },
        {
          "30": "",
          "REDAﬀectiveLM": "timent analysis of social media text. In: Proceedings of the International"
        },
        {
          "30": "",
          "REDAﬀectiveLM": "AAAI Conference on Web and Social Media, vol. 8, pp. 216–225 (2014)."
        },
        {
          "30": "",
          "REDAﬀectiveLM": "https://ojs.aaai.org/index.php/ICWSM/article/view/14550"
        }
      ],
      "page": 30
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "REDAﬀectiveLM\n31": "[43] Liang, W., Xie, H., Rao, Y., Lau, R.Y., Wang, F.L.: Universal aﬀective"
        },
        {
          "REDAﬀectiveLM\n31": "model for readers’ emotion classiﬁcation over short texts. Expert Systems"
        },
        {
          "REDAﬀectiveLM\n31": "with Applications 114, 322–333 (2018). https://doi.org/10.1016/j.eswa."
        },
        {
          "REDAﬀectiveLM\n31": "2018.07.027"
        },
        {
          "REDAﬀectiveLM\n31": "[44] Strapparava, C., Mihalcea, R.: Learning to identify emotions in text. In:"
        },
        {
          "REDAﬀectiveLM\n31": "Proceedings of the 2008 ACM Symposium on Applied Computing. SAC"
        },
        {
          "REDAﬀectiveLM\n31": "’08, pp. 1556–1560. Association for Computing Machinery, New York, NY,"
        },
        {
          "REDAﬀectiveLM\n31": "USA (2008). https://doi.org/10.1145/1363686.1364052"
        },
        {
          "REDAﬀectiveLM\n31": "[45] Manning, C.D., Raghavan, P., Sch¨utze, H.:\nIntroduction to information"
        },
        {
          "REDAﬀectiveLM\n31": "retrieval. Cambridge University Press (2008). https://books.google.co.in/"
        },
        {
          "REDAﬀectiveLM\n31": "books?id=t1PoSh4uwVcC"
        },
        {
          "REDAﬀectiveLM\n31": "[46] Ghoshal, B., Tucker, A.: Estimating Uncertainty and Interpretability in"
        },
        {
          "REDAﬀectiveLM\n31": "Deep Learning for Coronavirus\n(COVID-19) Detection. arXiv preprint"
        },
        {
          "REDAﬀectiveLM\n31": "arXiv:2003.10769 (2020). https://doi.org/10.48550/arXiv.2003.10769"
        }
      ],
      "page": 31
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Linguistic template extraction for recognizing reader-emotion",
      "authors": [
        "Y.-C Chang",
        "C.-H Chu",
        "C Chen",
        "W.-L Hsu"
      ],
      "year": "2016",
      "venue": "International Journal of Computational Linguistics & Chinese Language Processing"
    },
    {
      "citation_id": "2",
      "title": "Language models as emotional classifiers for textual conversation",
      "authors": [
        "C Heaton",
        "D Schwartz"
      ],
      "year": "2020",
      "venue": "Proceedings of the 28th ACM International Conference on Multimedia. MM '20",
      "doi": "10.1145/3394171.3413755"
    },
    {
      "citation_id": "3",
      "title": "PO-EMO: Conceptualization, annotation, and modeling of aesthetic emotions in German and English poetry",
      "authors": [
        "T Haider",
        "S Eger",
        "E Kim",
        "R Klinger",
        "W Menninghaus"
      ],
      "year": "2020",
      "venue": "Proceedings of the 12th Language Resources and Evaluation Conference"
    },
    {
      "citation_id": "4",
      "title": "Mining social emotions from affective text",
      "authors": [
        "S Bao",
        "S Xu",
        "L Zhang",
        "R Yan",
        "Z Su",
        "D Han",
        "Y Yu"
      ],
      "year": "2011",
      "venue": "IEEE Transactions on Knowledge and Data Engineering",
      "doi": "10.1109/TKDE.2011.188"
    },
    {
      "citation_id": "5",
      "title": "Emotion prediction of news articles from reader's perspective based on multi-label classification",
      "authors": [
        "L Ye",
        "R.-F Xu",
        "J Xu"
      ],
      "year": "2012",
      "venue": "2012 International Conference on Machine Learning and Cybernetics",
      "doi": "10.1109/ICMLC.2012.6359686"
    },
    {
      "citation_id": "6",
      "title": "Social Emotion Mining Techniques for Facebook Posts Reaction Prediction",
      "authors": [
        "F Krebs",
        "B Lubascher",
        "T Moers",
        "P Schaap",
        "G Spanakis"
      ],
      "year": "2018",
      "venue": "Proceedings of the 10th International Conference on Agents and Artificial Intelligence (ICAART)",
      "doi": "10.5220/0006656002110220"
    },
    {
      "citation_id": "7",
      "title": "Readers' affect: predicting and understanding readers' emotions with deep learning",
      "authors": [
        "K Anoop",
        "P Deepak",
        "S Savitha",
        "V Lajish",
        "P Manjary"
      ],
      "year": "2022",
      "venue": "J Big Data",
      "doi": "10.1186/s40537-022-00614-2"
    },
    {
      "citation_id": "8",
      "title": "SWAT-MP:the SemEval-2007 systems for task 5 and task 14",
      "authors": [
        "P Katz",
        "M Singleton",
        "R Wicentowski"
      ],
      "year": "2007",
      "venue": "Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007)"
    },
    {
      "citation_id": "9",
      "title": "Reader perspective emotion analysis in text through ensemble based multi-label classification framework",
      "authors": [
        "P Bhowmick",
        "A Basu",
        "P Mitra"
      ],
      "year": "2009",
      "venue": "Computer and Information Science",
      "doi": "10.5539/cis.v2n4p64"
    },
    {
      "citation_id": "10",
      "title": "Semisupervised recursive autoencoders for predicting sentiment distributions",
      "authors": [
        "R Socher",
        "J Pennington",
        "E Huang",
        "A Ng",
        "C Manning"
      ],
      "year": "2011",
      "venue": "Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "11",
      "title": "Learning sentiment-specific word embedding for Twitter sentiment classification",
      "authors": [
        "D Tang",
        "F Wei",
        "N Yang",
        "M Zhou",
        "T Liu",
        "B Qin"
      ],
      "year": "2014",
      "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.3115/v1/P14-1146"
    },
    {
      "citation_id": "12",
      "title": "Emotional embeddings: Refining word embeddings to capture emotional content of words",
      "authors": [
        "A Seyeditabari",
        "N Tabari",
        "S Gholizade",
        "W Zadrozny"
      ],
      "year": "2019",
      "venue": "Emotional embeddings: Refining word embeddings to capture emotional content of words",
      "doi": "10.48550/ARXIV.1906.00112",
      "arxiv": "arXiv:1906.00112"
    },
    {
      "citation_id": "13",
      "title": "Aff2Vec: Affect-enriched distributional word representations",
      "authors": [
        "S Khosla",
        "N Chhaya",
        "K Chawla"
      ],
      "year": "2018",
      "venue": "Proceedings of the 27th International Conference on Computational Linguistics"
    },
    {
      "citation_id": "14",
      "title": "Understanding emotions in text using deep learning and big data",
      "authors": [
        "A Chatterjee",
        "U Gupta",
        "M Chinnakotla",
        "R Srikanth",
        "M Galley",
        "P Agrawal"
      ],
      "year": "2019",
      "venue": "Computers in Human Behavior",
      "doi": "10.1016/j.chb.2018.12.029"
    },
    {
      "citation_id": "15",
      "title": "Deep learning for affective computing: Text-based emotion recognition in decision support",
      "authors": [
        "B Kratzwald",
        "S Ilić",
        "M Kraus",
        "S Feuerriegel",
        "H Prendinger"
      ],
      "year": "2018",
      "venue": "Decision Support Systems",
      "doi": "10.1016/j.dss.2018.09.002"
    },
    {
      "citation_id": "16",
      "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "authors": [
        "J Devlin",
        "M.-W Chang",
        "K Lee",
        "K Toutanova"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
      "doi": "10.18653/v1/N19-1423"
    },
    {
      "citation_id": "17",
      "title": "Improving language understanding by generative pre-training",
      "authors": [
        "A Radford",
        "K Narasimhan",
        "T Salimans",
        "I Sutskever"
      ],
      "year": "2018",
      "venue": "Improving language understanding by generative pre-training"
    },
    {
      "citation_id": "18",
      "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding",
      "authors": [
        "Z Yang",
        "Z Dai",
        "Y Yang",
        "J Carbonell",
        "R Salakhutdinov",
        "Q Le"
      ],
      "year": "2019",
      "venue": "XLNet: Generalized Autoregressive Pretraining for Language Understanding",
      "doi": "10.5555/3454287.3454804"
    },
    {
      "citation_id": "19",
      "title": "Comparative analyses of bert, roberta, distilbert, and xlnet for text-based emotion recognition",
      "authors": [
        "A Adoma",
        "N.-M Henry",
        "W Chen"
      ],
      "year": "2020",
      "venue": "2020 17th International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP)",
      "doi": "10.1109/ICCWAMTIP51612.2020.9317379"
    },
    {
      "citation_id": "20",
      "title": "Recognizing emotions from texts using a bert-based approach",
      "authors": [
        "A Adoma",
        "N.-M Henry",
        "W Chen",
        "N Rubungo Andre"
      ],
      "year": "2020",
      "venue": "2020 17th International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP)",
      "doi": "10.1109/ICCWAMTIP51612.2020.9317523"
    },
    {
      "citation_id": "21",
      "title": "GloVe: Global vectors for word representation",
      "authors": [
        "J Pennington",
        "R Socher",
        "C Manning"
      ],
      "year": "2014",
      "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
      "doi": "10.3115/v1/D14-1162"
    },
    {
      "citation_id": "22",
      "title": "AC-BLSTM: Asymmetric Convolutional Bidirectional LSTM Networks for Text Classification",
      "authors": [
        "D Liang",
        "Y Zhang"
      ],
      "year": "2016",
      "venue": "AC-BLSTM: Asymmetric Convolutional Bidirectional LSTM Networks for Text Classification",
      "doi": "10.48550/arXiv.1611.01884",
      "arxiv": "arXiv:1611.01884"
    },
    {
      "citation_id": "23",
      "title": "Bi-LSTM model to increase accuracy in text classification: Combining word2vec CNN and attention mechanism",
      "authors": [
        "B Jang",
        "M Kim",
        "G Harerimana",
        "S.-U Kang",
        "J Kim"
      ],
      "year": "2020",
      "venue": "Applied Sciences",
      "doi": "10.3390/app10175841"
    },
    {
      "citation_id": "24",
      "title": "Examining attention mechanisms in deep learning models for sentiment analysis",
      "authors": [
        "S Kardakis",
        "I Perikos",
        "F Grivokostopoulou",
        "I Hatzilygeroudis"
      ],
      "year": "2021",
      "venue": "Applied Sciences",
      "doi": "10.3390/app11093883"
    },
    {
      "citation_id": "25",
      "title": "Human attention maps for text classification: Do humans and neural networks focus on the same words?",
      "authors": [
        "C Sen",
        "T Hartvigsen",
        "B Yin",
        "X Kong",
        "E Rundensteiner"
      ],
      "year": "2020",
      "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/2020.acl-main.419"
    },
    {
      "citation_id": "26",
      "title": "Hidden topic-emotion transition model for multi-level social emotion detection",
      "authors": [
        "D Tang",
        "Z Zhang",
        "Y He",
        "C Lin",
        "D Zhou"
      ],
      "year": "2019",
      "venue": "Knowledge-Based Systems",
      "doi": "10.1016/j.knosys.2018.11.014"
    },
    {
      "citation_id": "27",
      "title": "Classifying emotions in stack overflow and jira using a multi-label approach",
      "authors": [
        "L Cabrera-Diego",
        "N Bessis",
        "I Korkontzelos"
      ],
      "year": "2020",
      "venue": "Knowledge-Based Systems",
      "doi": "10.1016/j.knosys.2020.105633"
    },
    {
      "citation_id": "28",
      "title": "Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007)",
      "authors": [
        "C Strapparava",
        "R Mihalcea"
      ],
      "year": "2007",
      "venue": "Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007)"
    },
    {
      "citation_id": "29",
      "title": "Basic emotions",
      "authors": [
        "P Ekman"
      ],
      "year": "1999",
      "venue": "Handbook of Cognition and Emotion",
      "doi": "10.1002/0470013494.ch3"
    },
    {
      "citation_id": "30",
      "title": "Bidirectional recurrent neural networks",
      "authors": [
        "M Schuster",
        "K Paliwal"
      ],
      "year": "1997",
      "venue": "IEEE Transactions on Signal Processing",
      "doi": "10.1109/78.650093"
    },
    {
      "citation_id": "31",
      "title": "Neural machine translation by jointly learning to align and translate",
      "authors": [
        "D Bahdanau",
        "K Cho",
        "Y Bengio"
      ],
      "year": "2014",
      "venue": "Neural machine translation by jointly learning to align and translate",
      "doi": "10.48550/arXiv.1409.0473",
      "arxiv": "arXiv:1409.0473"
    },
    {
      "citation_id": "32",
      "title": "SentencePiece: A simple and language independent subword tokenizer and detokenizer for neural text processing",
      "authors": [
        "T Kudo",
        "J Richardson"
      ],
      "year": "2018",
      "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
      "doi": "10.18653/v1/D18-2012"
    },
    {
      "citation_id": "33",
      "title": "EmoWordNet: Automatic expansion of emotion lexicon using English WordNet",
      "authors": [
        "G Badaro",
        "H Jundi",
        "H Hajj",
        "W El-Hajj"
      ],
      "year": "2018",
      "venue": "Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics",
      "doi": "10.18653/v1/S18-2009"
    },
    {
      "citation_id": "34",
      "title": "Towards building a social emotion detection system for online news",
      "authors": [
        "J Lei",
        "Y Rao",
        "Q Li",
        "X Quan",
        "L Wenyin"
      ],
      "year": "2014",
      "venue": "Future Generation Computer Systems",
      "doi": "10.1016/j.future.2013.09.024"
    },
    {
      "citation_id": "35",
      "title": "Deep feelings: A massive cross-lingual study on the relation between emotions and virality",
      "authors": [
        "M Guerini",
        "J Staiano"
      ],
      "year": "2015",
      "venue": "Proceedings of the 24th International Conference on World Wide Web. WWW '15 Companion",
      "doi": "10.1145/2740908.2743058"
    },
    {
      "citation_id": "36",
      "title": "Convolutional neural networks for sentence classification",
      "authors": [
        "Y Kim"
      ],
      "year": "2014",
      "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing",
      "doi": "10.3115/v1/D14-1181"
    },
    {
      "citation_id": "37",
      "title": "Synesketch: An open source library for sentence-based emotion recognition",
      "authors": [
        "U Krcadinac",
        "P Pasquier",
        "J Jovanovic",
        "V Devedzic"
      ],
      "year": "2013",
      "venue": "IEEE Transactions on Affective Computing",
      "doi": "10.1109/T-AFFC.2013.18"
    },
    {
      "citation_id": "38",
      "title": "Emotion computing using word mover's distance features based on ren cecps",
      "authors": [
        "F Ren",
        "N Liu"
      ],
      "year": "2018",
      "venue": "PLOS ONE",
      "doi": "10.1371/journal.pone.0194136"
    },
    {
      "citation_id": "39",
      "title": "Lexicon based feature extraction for emotion text classification",
      "authors": [
        "A Bandhakavi",
        "N Wiratunga",
        "D Padmanabhan",
        "S Massie"
      ],
      "year": "2017",
      "venue": "Pattern Recognition Letters",
      "doi": "10.1016/j.patrec.2016.12.009"
    },
    {
      "citation_id": "40",
      "title": "Depechemood++: a bilingual emotion lexicon built through simple yet powerful techniques",
      "authors": [
        "O Araque",
        "L Gatti",
        "J Staiano",
        "M Guerini"
      ],
      "year": "2019",
      "venue": "IEEE Transactions on Affective Computing",
      "doi": "10.1109/TAFFC.2019.2934444"
    },
    {
      "citation_id": "41",
      "title": "Cross-domain sentiment analysis on social media interactions using senti-lexicon based hybrid features",
      "authors": [
        "R Suharshala",
        "K Anoop",
        "V Lajish"
      ],
      "year": "2018",
      "venue": "2018 3rd International Conference on Inventive Computation Technologies (ICICT)",
      "doi": "10.1109/ICICT43934.2018.9034272"
    },
    {
      "citation_id": "42",
      "title": "Vader: A parsimonious rule-based model for sentiment analysis of social media text",
      "authors": [
        "C Hutto",
        "E Gilbert"
      ],
      "year": "2014",
      "venue": "Proceedings of the International AAAI Conference on Web and Social Media"
    },
    {
      "citation_id": "43",
      "title": "Universal affective model for readers' emotion classification over short texts",
      "authors": [
        "W Liang",
        "H Xie",
        "Y Rao",
        "R Lau",
        "F Wang"
      ],
      "year": "2018",
      "venue": "Expert Systems with Applications",
      "doi": "10.1016/j.eswa.2018.07.027"
    },
    {
      "citation_id": "44",
      "title": "Learning to identify emotions in text",
      "authors": [
        "C Strapparava",
        "R Mihalcea"
      ],
      "year": "2008",
      "venue": "Proceedings of the 2008 ACM Symposium on Applied Computing. SAC '08",
      "doi": "10.1145/1363686.1364052"
    },
    {
      "citation_id": "45",
      "title": "Introduction to information retrieval",
      "authors": [
        "C Manning",
        "P Raghavan",
        "H Schütze"
      ],
      "year": "2008",
      "venue": "Introduction to information retrieval"
    },
    {
      "citation_id": "46",
      "title": "Estimating Uncertainty and Interpretability in Deep Learning for Coronavirus (COVID-19) Detection",
      "authors": [
        "B Ghoshal",
        "A Tucker"
      ],
      "year": "2020",
      "venue": "Estimating Uncertainty and Interpretability in Deep Learning for Coronavirus (COVID-19) Detection",
      "doi": "10.48550/arXiv.2003.10769",
      "arxiv": "arXiv:2003.10769"
    }
  ]
}