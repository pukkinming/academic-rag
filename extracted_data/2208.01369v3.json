{
  "paper_id": "2208.01369v3",
  "title": "The Face Of Affective Disorders",
  "published": "2022-08-02T11:28:17Z",
  "authors": [
    "Christian S. Pilz",
    "Benjamin Clemens",
    "Inka C. Hiss",
    "Christoph Weiss",
    "Ulrich Canzler",
    "Jarek Krajewski",
    "Ute Habel",
    "Steffen Leonhardt"
  ],
  "keywords": [
    "Opto-Electronic Encephalography (OEG)",
    "Vigilance",
    "Affective Symptoms",
    "Depression",
    "Schizophrenia",
    "Face Dynamics",
    "Shape Geodesic",
    "Coherence",
    "Sequence Kernel",
    "Transdiagnostic Analysis",
    "Personalized Medicine"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "We study the statistical properties of facial behaviour altered by the regulation of brain arousal in the clinical domain of psychiatry. The underlying mechanism is linked to the empirical interpretation of the vigilance continuum as behavioral surrogate measurement for certain states of mind. Referring to the classical scalp-based obtrusive measurements, we name the presented method Opto-Electronic Encephalography (OEG) which solely relies on modern camera-based real-time signal processing and computer vision. Based upon a stochastic representation as coherence of the face dynamics, reflecting the hemifacial asymmetry in emotion expressions, we demonstrate an almost flawless distinction between patients and healthy controls as well as between the mental disorders depression and schizophrenia and the symptom severity. In contrast to the standard diagnostic process, which is time-consuming, subjective and does not incorporate neurobiological data such as real-time face dynamics, the objective stochastic modeling of the affective responsiveness only requires a few minutes of video-based facial recordings. We also highlight the potential of the methodology as a causal inference model in transdiagnostic analysis to predict the outcome of pharmacological treatment. All results are obtained on a clinical longitudinal data collection with an amount of 99 patients and 43 controls.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "M ental disorders are among the top ten leading causes of public health burden, worldwide and there has been no evidence of a global reduction of this burden in the last 30 years  [1] . The global number of disability adjusted life years (DALYS) and the proportion of global DALYS attributed to mental disorders increased. It has become clear that the classification of mental disorders by taxonomies such as the Diagnostic and Statistical Manual of Mental Disorders (DSM) or the International Classification of Diseases (ICD) is not sufficient as they do not reflect relevant neurobiological and behavioural mechanisms. Therefore, in the US the National Institute of Mental Health started the Research Domain Criteria (RDoC) project to establish a research classification system for mental disorders that is based on neurobiological findings and observational behaviour  [2] . In Europe, the Roadmap for Mental Health Research in Europe (ROAMER) project paved the way for developing a comprehensive and integrated mental health research agenda which is successfully featured by the German Federal Ministry of Research and Education initiative e:Med (for example: IntegraMent -Integrated Understanding of Causes and Mechanisms in Mental Disorders)  [3] . Today, we have access to ground-breaking advances in biological and brain sciences; biomarkers from '-omics' research, developments in brain mapping such as the connectome, fast genome-wide association Manuscript received  April 19, 2005 ; revised August 26, 2015.\n\nstudies, next generation DNA sequencing, affective computing, eHealth, cognitive behavioural therapy and large scale research infrastructures  [4] . Taking advantage of such developments will produce a larger body of evidence along the entire translational pipeline starting from biological mechanisms to behavioural systems, resulting in new clinical approaches and preventative interventions, leading to more sustainable and individualized treatments  [5] . However, for the moment patient-tailored treatment has not yet arrived in the clinical setting. The analysis of genetic factors and their interaction with environmental factors has delivered valuable sets of predictors. Utilizing genetic profiles, together with the environmental factors including lifestyle, it is possible to develop predictors classifying individuals at risk; this way, establishing preventive strategies to reduce the risk of developing a mental disorder  [6] . Classical statistical concepts like null-hypothesis testing have struggled in dealing with objectively measurable endophenotypes derived from huge datasets and in extrapolating patterns from one set of data to another. While these tests often determine differences between affected versus healthy subjects or treatment versus placebo group, it turned out that they do not help in finding a differential diagnosis or the right treatment among numerous competing treatment groups  [7] . In contrast, machine learning uncovers general concepts underlying a series of observations without explicit instructions to reveal biological subgroups in patients  [7] ,  [8] . In mental disorders with complex possible treatment combinations, where differential diagnosis and disease trajectories may fall into more than two categories, multiclass learning approaches must be used. Unique combinations of behavioral, genetic, neural, hormonal and environmental characteristics play a role in the pathogenesis of mental illness. Fusing all these types of data and levels of analysis to produce statistically robust large-scale models is an important challenge for the future. Machine learning has been successfully applied in various research areas in recent years, such as language processing, speech recognition or computer vision and is suitable to offer a framework of mechanisms to enable clinical prediction Fig.  1 . The neutral mean faces of the healthy control group and the patients are visualized. The left face corresponds to the control group and the right face to the patient group. The mean face of individuals diagnosed with affective disorders were perceived as having more hanging mouth corners, raised eye browns, more swollen pale faces and a dull gaze. Affective disorders also were associated with female gender, sad emotion, less trustworthy, less leadership quality and less attractive face appearance. As a whole, this was also associated with illness. The detailed results of the corresponding questionnaire are described in subsection 5.2.1 on an individual level  [9] . It is expected that the combination of genetic data with physiological biomarkers, behaviour and clinical factors with the concept of learning algorithms may enable the identification of disease-specific biological aspects that help to allocate patient subgroups to specific treatment options, and to identify subjects at risk. In this way, using artificial intelligence could provide specific treatment options or preventive strategies tailored to the individual person, across the common mental disease classifications.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Contribution",
      "text": "In this context, this study pays particular attention to the behavioural manifestations of affective disorders, and primarily in what is probably the most pronounced modality in everyday life, especially with respect to unconscious behaviour, that of facial expression. Going beyond machine diagnosis of depression in affective computing, which has been developed in previous studies  [14] ,  [15] , we show that the measurable affective state estimated by means of computer vision contains far more information than the pure categorical classification. It is a further objective to emphasize that, in the overall context of mental illness, the patient's emotional state is an essential key factor to understanding the underlying disease. Although this appears to be known in the clinical field, we believe that a broader and more public awareness of this issue and its background can lead to constructive problemsolving approaches. In a general and interdisciplinary sense, this work with its theoretical background and technical realisation attempts to contribute in trying to understand affective syndromes by experiential measures and multimodal affectives responses, in the spirit of the rise of affectivism  [16] . First, we review the connection between facial behaviour and the psychiatric field.\n\nNext, we show that the facial expression manifestation of affective disorders can be attributed to classical brain arousal regulation (a phenomenon formerly known as vigilance). Thereafter, we explain how behavioural face dynamics can be formulated mathematically. Here, we expand the terminology of shape geodesics to further take into account the temporal dimension, which until now has not received much consideration. Thus, we look not only at what the person is doing at a given moment, but also how they do it and what the connections between the individual components of the observable process are  [17] . This assumption is based on the theory of hemifacial asymmetry in emotion expressions  [18] . Quoting Aristotle, \"The whole is more than the sum of its parts\". To evaluate the algorithms empirically 1 , we present a new clinical data collection 2 . The visual differences between the patients and the healthy controls are examined and presented using the collected video data. We also show how they are perceived by other people (see Fig.  1  for the corresponding mean faces). Based on the clinical diagnosis the classic categorical classification will be presented. This is followed by the computer vision-based measurement of the human face, whose construction we justify and compare to known methods. In contrast to the static observation of facial expressions, the dynamic behaviour can also distinguish between the disease categories of depression and schizophrenia and not only between healthy controls and patients. In further experiments, the connection between facial dynamics and symptom severity will be examined. In the final 1. We published the code for reproducing all results on the corresponding author's public repository.\n\n2. The data collection will be made available upon request in compliance with the underlying data protection policies to qualified individuals our groups to support broader research and enable collaboration in this field. Fig.  2 . Brain arousal regulation of the vigilance continuum as synopsis of defined classifications of the EEG-stages occurring between relaxed wakefulness during closed eyes and deep sleep  [10] . The stages A1 to B2 have first been introduced by Bente and Roth  [11] . A decrease in vigilance can lead to two different behaviors, 1) the organism decides to go to sleep and the vigilance reverts to sleep stages or, 2) the organism exhibits auto-stabilization behavior to counter regulate their vigilance level. If this natural physiological regulation is permanently disturbed, pathological symptoms can develop. The rigid regulation is often observed during depressive episodes and the labile regulation during manic episodes  [12] . A statistical link to facial dynamics was studied recently  [13] .\n\nset of experiments, a model of causal inference is evaluated to obtain patient-tailored drug treatment recommendations.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Background",
      "text": "",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "The Facial Expressions",
      "text": "Attempts to define the concept of feelings or emotions go back at least to Aristotle, who described them as situation-specific perceptual interpretations  [19] . Darwin also dealt with the expression of emotions in humans and animals. He found that certain expressive movements could be explained through protective functions or deterrence  [20] . Later theories emphasized the role of central nervous processes and regarded emotional excitement or arousal as a function and interaction of cortical and subcortical processes. More recent theories also assume cognitive states that are independent of physiological arousal as a sufficient criterion for the expression of emotions  [21] . In the seminal work The biology of human behaviour, Eibl-Eibesfeldt claimed that the expressive movements associated with emotions are the same in all cultures  [22] . Some authors assume the existence of so-called basic emotions  [23] ,  [24] ,  [25] . Among these, Ekman also posits that expression and meaning are culture-independent, with a strong reference to Darwin's universality of facial expressions of emotion. However, current views regard these findings rather critically and show that emotions tend not to be cross-cultural constants  [26] . The evolution of emotions, in a genuine biological sense, can be better traced back to the fight or flight response. Essentially, this reduces the possible set of base emotions, with more complex emotions reflecting specific cultural idiosyncrasies  [27] ,  [28] . Regardless of cultural characteristics, it is beyond doubt that one's facial expression-interplay of eye, mouth and face musclesreflects one's feelings, emotions and thoughts: it is a window to one's inner state. Leonhard has described facial expression as the language of expression of the soul  [29] . As recognized very early on, affects are expressed in the motor system, consequently also in facial expressions, gestures, gait and posture  [30] . A change in a person's emotional world or psyche is therefore also reflected in a change of facial expression. Pideret also described the role of facial expression in neuropsychiatry as well as in psychology as one of the most important sources for the detection of pathological of mental states  [31] . Psychiatrists usually judge the affect in patients as more flattened, labile or inadequate. The facial expression behaviour seems partly impoverished, bizarre or uncontrolled up to the point of given stereotypes. Numerous studies exist today that have attempted to use computer vision and machine learning to investigate affective disorders via facial expressions  [32] . Current research focuses on the dynamic interpretation of facial features and also predicting the symptom severity of the disease  [33] .",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "The Vigilance",
      "text": "Many biological systems can be described relatively well as open thermodynamic processes  [34] . The alternation between determinism and complexity of this autopoietic system  [35]  by means of its dissipative structures  [36]  on an abstract level involves merely certain different states of energy  [13] . The transformation of energy into a new state is nothing more than information  [37] . There is a mutual relationship between physical, psychological, and social aspects of health. It is evident that health is closely linked to individual and collective value systems and behavior patterns that manifest in personal lifestyles. Life is a continuum of maintaining equilibrium  [38] . Continuous disturbances, however, can lead to certain diseases. The key question is which information indicates an unbalanced metabolism at all and whether it is possible to use Fig.  3 . Illustration of the computational pipeline for the shape-based coherence sequence kernel. Given a set of registered facial landmarks the trajectory of the shape geodesic will be modeled as VAR model over sliding blocks. Each block is gradually accumulated into the pre-computed background mixture model. At the end the kernel is then calculated via an adaptation step and fed to the Gaussian process regression. A subspace projection was carried out between the computation steps in order to reduce the overall complexity.\n\nthis to make objective statements about the possible course of the disease, suitable treatments and the chances of recovery. Affective disorders belong to the clinical discipline of neuropsychiatry. Attempts have been made to understand the complex nature of these diseases and their causes for a long time. In many cases, these are processes that have developed over many years and which have often become profoundly consolidated through ongoing difficult emotional and social circumstances. Biologically, the local protein synthesis inside the brain gets thrown out of balance, which leads to a drastic change in brain arousal regulation. This physiological phenomenon is known as vigilance, whose origin dates back to the seminal work of Head  [39] . In its original formulation, vigilance is neither a function nor a performance, but is rather described as a continuum. It has more a semantic meaning like the explanatory principles  [40]  and therefore can be regarded as a theoretical construct  [41] . Accordingly this construct is primarily conceived for scientists, who are interested in the reality behind the empirical phenomena. Vigilance is often used as a summarizing term in an interdisciplinary context for discrete measurements like sustained attention, selective attention or alertness. However, these terms reflect certain measurable performances and the mechanism of enabling a certain performance respectively. This is also represented by the early protagonists and it should be explicitly pointed out in order to avoid corresponding misinterpretations  [10] ,  [42] . Electroencephalography (EEG) changes of vigilance by a complex spatio-temporal process were first presented by Loomis and Davis  [43] ,  [44] . In this early perspective, a distinction was initially only made between the two states of wakefulness and sleep. Some decades later, Bente and Roth  [11] ,  [45]  explained the states in a more detailed representation by dividing these into substages (see Figure  2 ). With the rapid development and increasing performance of the semiconductor industry the first machine learning approach for the classification of these stages was realized given the work of Ulrich, Olbrich and Hegerl  [10] ,  [12] ,  [46] . Basically, vigilance is usually measured as the connectivity between the visual cortex and the frontal lobe in terms of EEG alpha waves in the classical sense. Alpha waves are known to be involved in the deactivation of the corresponding brain region  [10] . However, there are also several surrogate measurements linked to this arousal dynamic since it is not always possible to incorporate obtrusive sensor like EEG or the more popular stationary sensing devices like Magnetic resonance imaging (MRI) technology  [47] . More recent studies have analyzed vigilance regulation while one's eyes are open. Here the statistical relation between the facial behaviour, the vegetative nervous system and performance-based vigilance measurements are used as a multivariate construct to directly predict brain arousal regulation as an indicator for estimating tiredness  [13] . In this paper, the term vigilance will be also used as a surrogate measure which is further investigated in the domain of observable behaviour from the human face. In essence, if there exists a labile regulation which is associated to affective disorders like depression, then the facial dynamics should be also significant different compared to the state of natural physiological regulation found in healthy people (see Figure  2  for the regulation schematics).",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "The Model Space",
      "text": "Observing the human face in interpersonal communication sending signals which one would like to interpret. Signals in the proper sense are nothing more than functions in mathematical spaces. Functions, on the other hand, can be described by the changes in their variables. For a given problem, the resulting question will be which kind of functional can describe a suitable solution. For the registration of the face shape, a solution via the representation as an inverse problem yields to a nonlinear least square problem which has proven to be powerful. In general, a shape is a point in a high-dimensional, nonlinear manifold, called a shape space sharing the properties of the Riemannian geometry. Kendall pioneered the study of shape for labeled point sets  [48] . Therefore, the properties of such a representation are relatively well understood. The Riemannian structure can only be considered locally as Euclidean. The temporal consideration of the shape on the manifold is a geodesic path represented by the corresponding Lie algebra. In essence, we are seeking an analytic solution for the face shape as equivalence class describing the space of diffeomorphisms as function of time. A schematic overview of the model space which can solve this problem is illustrated in Fig.  3  and will be described in the following two subsections.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Shape Geodesic",
      "text": "Given a sequence of vectors representing the shape of an object with a certain fixed amount of landmarks. Arguably, the intrinsic change of the shape representation, the shape dynamic, needs to be invariant to the action of the special Euclidean group SE(3) in order to be able to execute any kind of comparison usually done with a propriety distance measurement. Consider an arbitrary sequence of landmark configurations X := {X i : i = 1, ..., τ } representing the non-rigid motion of the object's shape as a function of time, where each X i (0 ≤ i ≤ τ ) is an n × d matrix of rank d encoding the positions of the n distinct landmark points p ∈ R d . Usually with d ∈ {2, 3}, the two-or threedimensional Euclidean space. At each time step i, a common choice to incorporate certain necessary invariance properties to the shape representation would yield to the matrix of pairwise distances between the landmarks of the same shape augmented by the distances between all the landmarks and their center of mass p 0 .\n\nThe Euclidean distance matrices are related to Gram matrices  [49]  where • denotes the norm associated to the l 2 -inner product •, • . The entries of the Gram matrix G := XX T are the pairwise inner products of the points p 1 , . . . , p n ,\n\nwith the linear relationship given the equality\n\nGram matrices are n × n positive semidefinite matrices of rank d.\n\nThe Riemannian geometry of the space of such matrices is given by the positive semidefinite cone S + (d, n). The Grassmann manifold G(d, n) of d-dimensional subspaces in R n is invariant under transformations of the special Euclidean group SE(3) resulting in an affine invariant shape representation given by the subspace U spanned by the columns of X [50]\n\nFor two subspaces\n\nand\n\nthe geodesic curve connecting them is given by\n\nwhere Θ is a d × d diagonal matrix formed by the principal angles between U 1 and U 2 . The matrix M is given by the formula M = (I n -U 1 U T 1 )U 2 F and F is the pseudoinverse diag(sin(θ 1 ), sin(θ 2 )). The Riemannian distance between the subspaces U 1 and U 2 is given by\n\nThe polar decomposition of a n × d matrix X of rank d,\n\nyields to the Gram matrix XX T as U R 2 U T . The columns of the matrix U are orthonormal and the matrix R is postive-definite.\n\nThe polar decomposition maps from the product of the Stiefel manifold V and the cone of the positive-definite. matrix P to the manifold S + (d, n)\n\nwith\n\n1 and R 2 2 , and U (t) defining the geodesic in G(d, n) given by Eq. (  8 ). The distance d S + (G 1 , G 2 ) between the two Gram matrices G 1 and G 2 results in the square of the length of the curve on S + (d, n)\n\nThe parameter k controls the influence of the squared Grassmann distance d 2 G and the squared Riemannian distance d 2 P d . Figure  4  illustrates a graphical interpretation of this distance measurement. The detailed derivation is described in  [51] . Some first application scenarios for this can be studied in  [52] .",
      "page_start": 5,
      "page_end": 6
    },
    {
      "section_name": "Coherence Sequence Kernel",
      "text": "Now consider the evolution of the shape geodesic C G ( t-1)→Gt (t) as a stationary random process X t . The frequency specific characteristics of the process can be described by a vector auto-regressive (VAR) model of order p reflecting its coherence and causality  [17]  written as\n\nwith the intercept c, noise ε and the coefficients ϕ i of the lags of X till order p. This model shares the properties of a bounded linear convolution operator on a normed sequence space defined with respect to the inner product of its underlying Hilbert space. In case the Hilbert space is associated with a valid kernel that reproduces every function in the space one speaks of a reproducing kernel Hilbert space widely used in structural risk minimization as principals of machine learning  [53] . Suppose any system's impulse response Φ of the process in general can be represented as part of an universal prior given by a multivariate Gaussian mixture model\n\nwhere λ c are the priors of the Gaussians N () and μc and σc are the mean and covariance respectively. Given a set of observed responses Φ = {ϕ i }, µ can be estimated by the classical a posterior adaptation (MAP) given the universal prior g(Φ)  [54] .\n\nEach sample response ϕ j contributes to a particular Gaussian component N c with respect to the posterior probability that ϕ i belongs to\n\nwith the sufficient statistics\n\nand the resulting MAP estimation\n\nThis assumes identical priors and a diagonal covariance for the mixture components. The distance d KL (g(Φ), g( Φ)) between the universal prior g(Φ) and the adapted distribution g( Φ) can be expressed by a symmetric approximation of the Kullback-Leibler (KL) divergence  [55]\n\nThe resulting inner product\n\nyields to a linear kernel function. The kernel is a simple scaled version of the vectorized means. A major advantage of such kind of kernel is that the dimension is constant across different observed sequence lengths.",
      "page_start": 5,
      "page_end": 6
    },
    {
      "section_name": "Experiments",
      "text": "",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Data Collection",
      "text": "The longitudinal data was collected at the University Hospital, Aachen, Germany ). The first measurement took place immediately after they got hospitalized and the second short before their in-patient discharge. The time interval between these two measurements is 8 weeks on average. All participants of the control group were arbitrary recruited from the local population but interviewed and recorded with the same time interval between the measurements.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Clinical Data",
      "text": "The clinical diagnoses were confirmed using the Structured Clinical Interview for DSM-5 Clinician Version (SCID-5-CV) and Structured Clinical Interview for DSM-5 Personality Disorders (SCID-5-PD)  [57] . Symptom severity was assessed using the Brief Symptom Inventory (BSI)  [58] , the Beck Depression Inventory (BDI-II)  [59]  and the GRID Hamilton Depression Rating Scale (GRID-HAMD 21)  [60] . A psychomotor vigilance task (PVT) battery was carried out assessing alertness, sustained attention and divided attention  [61] . All participants of the control group were screened for a lifetime DSM-IV diagnosis (SCID-light)  [57] , neurological illness or current substance misuse.\n\n3. This work involved human subjects in its research. Approval of all ethical and experimental procedures and protocols was granted by the Ethics Committee of the Medical Faculty of RWTH Aachen (Application No.: 356/19), and performed in line with the Declaration of Helsinki (World Medical Association, 2013  [56] ). All participants of this study were financially reimbursed and gave their written informed consent for participation.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Video Recordings",
      "text": "All patients were interviewed and simultaneously recorded with a standard consumer webcam (Logitech c270, 25 fps). Each single measurement consists of three phases with an average recording duration of 90 minutes. Phase I includes the entire Hamilton interview between the participants and the clinican. During phase II all participants were shown videos of different facial expressions alternating with a neutral one which they were asked to imitate respectively. For every imitated mimic video they reported their own emotional state and intensity. The facial expression videos were taken from the Binghamton 3D Dynamic Facial Expression Database (BU-4DFE)  [62] . The average duration of this phase is 10 minutes. In phase III all participants were presented with portrait-shot video clips of actors telling different short-stories. The general condition of the stories reflects emotionality in all channels while the other conditions either provided neutral speech content, facial expression, or prosody, respectively. Stimuli consist of 96 evaluated videos (duration, mean 10.93 s, s.d = 0.93), alternating a male (n = 44) or female (n = 52) protagonist who told a self-related story of disgusting, fearful, happy, sad or neutral situations. All actors had been instructed to imagine their story as vividly as possible, and to remember an emotionally corresponding life experience. The participants judged and reported the emotion and intensity presented, as well as their own emotional state and intensity  [63] . The average duration of the third phase is 15 minutes. All video recordings were manually checked for consistency. A manual segmentation of the measurement conditions was also carried out.",
      "page_start": 7,
      "page_end": 8
    },
    {
      "section_name": "Mean Faces",
      "text": "In Figure  1  the neutral mean faces of the patients and the healthy control group are visualized. The left face corresponds to the control group and the right face to the patient group. To calculate the mean faces a standard landmark fitting of the faces was carried out using the EmoNet framework  [64] . The selection of the neutral emotional face was done during phase II when the participants are instructed to imitate the specific facial expression. Procrustes analysis is applied to all fitted landmark shapes of the neutral face images. Piecewise affine transformation  [65]  from the face shape to the mean face shape is determined in order to warp the face image to match the average shape and finally the mean for every pixel is computed.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Feature Extraction",
      "text": "For each individual video recording landmark fitting, dimensional emotion recognition  [64]  and eye gaze prediction was carried out  [66] . The shape geodesic (Eq. 12) was computed on a frame by frame basis and standard SVD based dimension reduction was applied. The resulting shape geodesic time series was concatenated with the rigid head pose and eye gaze vector and frame blocked with a windows size of ten seconds and an overlap of one second. Each block was modelled as VAR process of order three (Eq. 14). The vectorized coefficient matrix ϕ was further reduced in its dimension once again by utilizing SVD. Over the entire database, for all ϕ an universal background model (Eq. 16) was computed using the standard expectation maximization algorithm. MAP adaptation was performed for the different available segmentation phases of the recordings to obtain the final kernels as feature representation. In Figure  3  the processing schematic is illustrated. For better reproducibility of the results, the individual dimensions of the vectors are shown here. VAR modeling and sequence kernel computation was also accomplished for the valence and arousal values of the EmoNet network  [64] .",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Statistical Analysis",
      "text": "Various experiments were conducted to investigate fundamental issues related to the objectivity of current clinical diagnosis and treatment practices and how machine learning could contribute constructively in this area. This was realized in the broadest sense via statistical evaluations and finally by applying a schematic of causal inference. The first objective was to find out how affective disorders are generally perceived during social interaction and how accurate the clinical assessments really are. Secondly, we looked at how to automatically determine the most objective diagnosis possible as well as prognosis for treatment with the highest probability of success. The described model of facial dynamics serves as primary surrogate measurement for the underlying disturbed vigilance regulation and will be opposed to the discrete reaction time surrogate measurement of attention. The parameterized form of the facial dynamic is used as a predictor variable for several different clinical targets. In order to depict the respective statistical relationship, a regression model was trained using a standard Gaussian process with dot product covariance function over the sequence kernel (Eq. 22). The performance is measured utilizing a leave-one-subject-out cross validation over the entire database. Unless otherwise indicated, all results are presented in terms of the Pearson correlation coefficients obtained during the separate experiments. There was no violation of the statistical significance (e.g. p-values) in the obtained results, therefore this will be not stated explicitly further.",
      "page_start": 7,
      "page_end": 8
    },
    {
      "section_name": "Cues Of Affective Disorders",
      "text": "The face contains a lot of information on which humans base their interactions with each other. Affective disorders may influence how others behave toward patients. To give a small impression how these people are perceived by their fellow human beings, 40 participants were surveyed to rate the mean faces with respect to several questions reflecting character traits and facial appearance. The participants were not informed that these faces are part of a clinical study including control subjects and patients. The following list shows the selected cues. In Figure  5  the box plots representing the distribution of the answers are visualized. These results show that the faces of individuals diagnosed with affective disorders were perceived as having more hanging mouth corners, raised eye browns, more swollen pale faces and a dull gaze. Affective disorders also were associated with female gender, sad emotion, less trustworthy, less leadership quality and less attractive face appearance. As a whole, this was also associated with illness.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Clinical Data",
      "text": "Apparently the mere static appearance of the facial expression already entails indications of a possible mental illness. The next logical question to be asked is which information the clinical interview contains. The common clinical interview is usually conducted in one session and lasts between 45 and 90 minutes. The duration varies depending on the complexity of the psychiatric history and can be up to three hours in complex cases. In order to give a basic insight into the general problem of categorical clinical diagnostics, an attempt is made to determine the statistical predictive power using the results of the common observer based questionnaires. The symptom severity was used as concatenated feature vector including the BSI, the BDI and the HAMD scores. The target variable was selected as the overall patient status and patient type (e.q. depressive or schizophrenic) given by the SCID-5-CV assessment. As another target variable the treatment response given by an improvement of the symptom severity (HAMD solely) by at least 30 percent between the first and the second measurement was selected. The results of the cross validation are shown in Figure  6 . The prediction of the patient status based upon the symptom severity features achieved an expected correlation of 0.82. However, the distinction between patient types only achieved an expected correlation of -0.03. And the prediction of the treatment response achieved an expected correlation of 0.39. In essence, the patient status can be determined relatively well using the usual questionnaires. However, that is essentially all that can be concluded from it. Whether someone is depressed or rather schizophrenic is not indicated. The same applies to the treatment response. The results of the machine based interpretation and predictions utilizing the human facial behavior are described and presented in the following paragraphs.",
      "page_start": 8,
      "page_end": 9
    },
    {
      "section_name": "Patient Status",
      "text": "The first machine based prediction using the face dynamics solely was conducted for the general patient status. To show a comparison, not only the proposed modeling of the face shape coherence was taken into account but also two other methods from this technical field. The first alternative method is a deep learning approach based feature extraction methods (EmoNet) which projects the image based face regions to the Russel's circumplex model of emotion  [64] ,  [67] . This dimensional representation is characterized by its valence and arousal values located on the unite circle. Figure  7  visualizes the valence and arousal distributions by its mean and covariance computed over the three different measurement conditions for the patients and controls group. The yellow tone ellipses (p1, p2 and p3) correspond to the patients group and the blue tone ellipses (c1, c2 and c3) to the controls group. The patients show lower arousal and lower valence expectations. This means patients are less activated and are showing a more negative mood. Overall, the controls group has a much higher dynamic range of valence which reflects a more pronounced regulation of their emotional behavior. The valence and arousal distributions represent a static point of view of the facial behavior. Nevertheless, the patients already show a difference here compared to the controls, analogous to the snapshot of the presented mean faces (see Figure  1 ). In the next step VAR modeling and sequence kernels were computed for the shape geodesic as well as for the valence and arousal time series. As second alternative method a fisher vector encoding is computed over the barycentric representation of the face shape  [14] . The feature computation for all three methods was accomplished once for the entire measurement and then for each of the three individual phases of the measurements (in the following Figures labeled by full, interview, mimic and story). For each method, each set of features and the patient status as the target, the cross-validation for the Gaussian process regression was executed. The number of components for the mixture models is set to 2048 for both sequence kernel variants and set to 16 for the fisher vectors. The comparison of scored correlations is represented in Figure  8 . For the complete Fig.  8 . The prediction of the patient status (e.q. healthy control or patient) given the coherence sequence kernel for the shape geodesic and the EmoNet valence-arousal time series compared to the Fisher vectors. The correlations are obtained at time of the hospitalization for the different measurement conditions (full, interview, mimic and story) respectively.\n\nmeasurement the prediction of the patient status based upon the coherence sequence kernel (labeled as shape geodesic) achieved an expected correlation of 0.85, the EmoNet kernel an expected correlation of 0.89 and the fisher vector an expected correlation of 0.67. For the interview phase the coherence sequence kernel achieved an expected correlation of 0.93, the EmoNet kernel an expected correlation of 0.92 and the fisher vector an expected correlation of 0.72. For the mimic phase the coherence sequence kernel achieved an expected correlation of 0.99, the EmoNet kernel an expected correlation of 0.98 and the fisher vector an expected correlation of 0.77. For the story phase the coherence sequence kernel achieved an expected correlation of 0.991, the EmoNet kernel an expected correlation of 0.998 and the fisher vector an expected correlation of 0.76. Both sequence kernels show a show similar performance which is almost flawless. The fisher vector shows a slightly weaker performance. However, it must be mentioned here that the EmoNet network has to be trained on the basis of around 450,000 manually annotated face images in order to be able to predict emotions at all. In a further evaluation the scalability of the coherence sequence kernel was examined. For this purpose, the complexity of the Gaussian components was increased. The comparison of scored correlations for different numbers of mixture components is visualized in Figure  9 . It is  clear that predictive performance increases as components become more complex. Full saturation of performance is evident in the mimic phase. To emphasize this explicitly, the mimic phase shows the best performing correlations overall. And the measuring time is approximately 10 minutes which is relatively short compared to the rather lengthy clinical measurements. In addition, the distance between the adapted prior probabilities and the prior probabilities of background mixture model was calculated by the Wasserstein distance. This measure of the frequency of specific regulation of facial dynamics is compared to the reaction times of the attention test. In Figure  10  this comparison is shown for both groups, patients and controls. The larger the distances become, the more likely it is to be able to observe a longer reaction time. Reaction times are often associated with severity of symptoms and are also linked to vigilance regulation  [47] .",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Patient Type",
      "text": "Studies have shown that a plain static observation of facial expressions does not distinguish between depressive and schizophrenic patients  [68] . However, on the other hand it could already be demonstrated by means of a rather rough observer based assessment of non-verbal behaviors that the schizophrenics differed by a decreased number of head movements, the depressive by a decreased eyebrow raising and both patient groups, but especially the depressed, by an overall reduction of the facial expressions associated with laughter  [69] . Now the question is whether a dynamic embedding of the facial expressions yields to a machine based distinction in this case. The procedure for this is the same as for estimating the patient status. Only the target variable is different here and set to the corresponding patient type. The crossvalidation was only carried out over the entire patient group. Only the coherence sequence kernel was used as a feature vector, with different Gaussian components in order to check the scalability. The comparison of the calculated correlations is visualized in Figure  11 . The scalability is very similar to the previous estimation of the patient status and reaches almost complete saturation for the mimic phase of the measurements again. Apart from that, all measurement conditions achieved a correlation of more than 0.98, which shows an almost error-free estimation of patient type.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Treatment Responder",
      "text": "A pharmacological treatment corresponds to a large extent to the standard procedure for patients during their inpatient stay. One of the aims is to initially reduce the acute symptoms, at least temporarily, so that other therapeutic measures can be carried out at all. However, this is also often the method of choice for longer therapeutic intervention. The local protein synthesis of the neurotransmitters is a very complex process. The interaction of the individual components has not been fully clarified to the greatest possible extent in order to always be able to achieve an optimal effect in the treatment of patients. The availability of active substances is also limited. The phenomenon of nonresponse is therefore one of the main problems when selecting the pharmacological agent to be used. Prevalence estimates of treatment resistance vary from 20 to 60 percent of all patients  [70] . As already pointed out in sub-chapter 7.2, the purely empirical clinical observer ratings including BSI, BDI and HAMD as predictior variables can only be used to very vaguely estimate response to drug treatment. It is now appropriate to specify the influence that machine-interpreted facial dynamics may have on the prediction of therapy response. First, it should be evaluated if the treatment response can be predicted generally. Next, whether an individual drug treatment recommendation by means of the sensor-based monitoring of the face behavior can lead to an objective and more successful approach tailored to the patients needs.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Clinical",
      "text": "To estimate the treatment response the HAMD-17 is used as target variable for the cross-validation of the Gaussian process regression. Consequently, it was evaluated here whether the facial dynamics monitored during the inpatient admission can provide information about the possible severity of symptoms at the future time of discharge. For a given symptom severity at the beginning of the treatment, the responder behavior can be derived. The corresponding comparison of the calculated correlations is shown in Figure  12 . Again the scalability was determined by the model complexity, varying the number of mixture components for the background model. What immediately becomes apparent is that scalability has been lost. The expectation of the correlations ranges between 0.63 and 0.69 over the different measurement conditions. This is noticeably less compared to the two previous evaluations. At this point one would assume that if the clinical assessment changes or the symptoms improve, then the face dynamics as a surrogate measurement of the underlying vigilance regulation should change accordingly.\n\nThis can be checked very easily by calculating the dot product of the feature vectors with respect to the mean vector computed over the control group, once for the in-patient admission (in) and another time for the discharge (out). In Figure  13  the dot products for the patients (red) and the control group (blue) are visualized. As expected the distances for the controls tend not to change. However, this is also the case with the patients. Wouldn't one logically expect the distances to move towards the healthy ones? It is remarkable that the reaction times of the attention test also show a similar development.",
      "page_start": 10,
      "page_end": 11
    },
    {
      "section_name": "Causal Inference",
      "text": "The last experiment evaluates the performance of the face dynamics as a linear model of causal inference for the treatment selection. Recalling causality in the original sense is questioning cause and effect in order to justify action. In intelligence, causality is more about questioning options for action. Put simply, we ask the question: what if? Consequently, a counterfactual. We put a condition on a possible action and check what would happen based on empirical experience  [71] . The empirical prior knowledge is Fig.  14 . The measurement space including the face behavior, the clinical diagnosis and the treatment as a schematic vector space. Each mode of the measurements is associated with its own subspace.\n\navailable in the form of the behavioural face dynamics (U 1 ), the medication as treatment (U 2 ) and the diagnosis with its symptom severity (U 3 ). In trivial terms, all components of the behavioural\n\nwith Z the core tensor and U 1 , U 2 and U 3 the corresponding mode matrices. For a given projection of the face dynamics, we alter the treatment preserving the identity of the face dynamics until a clinically relevant improvement in depressive symptonmatology, assess via the HAMD, reached. This can be expressed and solved as a standard constrained optimization problem. We defined a reduction of the HAMD by at least 50 percent as constrained for the model. Figure  14  illustrates the measurements as a schematic vector space. In Table  1  the pharmacological treatment types prescribed during the study are listed. In Figure  15  the difference in symptom severity (HAMD delta) for the classical clinical assessment and the computed causal obtained ones is visualized. The expected improvement of symptom severity during the clinical treatment (clinical) is a reduction of the HAMD score of four points. For the synthetic altered treatment (causal) based upon the linear causal inference model the expected improvement of symptom severity is a reduced HAMD score of 22 points in the mean.\n\nIn Figure  16  the difference of the average prescribed treatment per category between the clinical assessment and the predicted causal recommendation is opposed. It can be observed that the causal model completely rejects the prescription of anxiolytika as needed and instead selected daily usage, if at all. Also the model rejects the prescription of the reuptake-inhibitors (SSRI and SNRI). Instead, the model proposed antipsychotics and tricyclic antidepressants. Using the facial dynamics achieved through the synthetic changed treatment, a cross-validation was used for estimating the treatment response once again. For this evaluation only the mimic phase of the video measurements was examined. However, value was placed on the scalability by increasing the number of components of the background model. In Figure  17  the scored correlations are visualized.  better estimate can be observed here. Finally, for the synthesized treatment, the dot products over both measurement times was calculated. Figure  18  shows these for the patients and the controls.\n\nIt should be noted here that the patient distances are now moving towards the controls. That would mean, at the time of discharge, there is a noticeable reduction in the affective flattening. In essence a return to a physiological regulation of the vigilance.    electroconvulsive therapy, light therapy, occupational therapy and physical therapy. Hence, conclusions or recommendations for clinical practice cannot be made based solely on the data presented here.",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Future Work",
      "text": "Future studies in this domain will help to recognize additional factors, such as gender or comorbidity, that further contribute to the enormous complexity of psychiatric disorders and the therapeutic mechanisms. While our results might be preliminary, they exemplify the huge potential of incorporating advanced machinelearning techniques and predictive modelling in psychiatric research via an interdisciplinary approach. Treatment response is often very limited in psychiatry, and more personalized approaches, enabling treatment prediction at the single-subject level are urgently needed. These automatically collected and processed data might offer a cost-effective means to generate clinically relevant, personalized insights and predictions, thereby capturing novel digital markers of behavior. If confirmed in future studies, causal inference models such as the one presented here will make such predictions more personalized with respect to potential outcomes and disease course.",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Conclusion",
      "text": "We have studied the human facial appearance and behavior in the clinical field of affective disorders and introduced a coherence sequence kernel based on the theory of hemifacial asymmetry. We were able to show that facial dynamics are affected when clinically diagnosed as a state which can be linked to rigid regulation of vigilance. This shows a pathological behavior which not only differs significantly from healthy people, but is also clear between the two mental disorders depression and schizophrenia. We have further demonstrated that the change in facial dynamics over a longer period of time contains information about the response to pharmacological treatment. Overall, the results predicted by the machine show better correlations compared to the pure clinical observer rating based questionnaires and are also objective. The relatively short measurement period of a few minutes for the computer vision approaches is also noteworthy, whereas hours are sometimes required for the clinical interviews or questionnaires. However, it is important to emphasize that any human diagnosis involves much more modalities and also involves very associative skills. For this reason, it is still too early to speak of a better general diagnosis option through machine vision at this point. The causal inference over the empirical prior knowledge of the data collection adjusted the pharmacological treatment in order observe a return to the physiological regulation of the facial dynamics. Such a return couldn't be observed during the clinical prescription. At the moment it is not clear whether such a machine based recommendation would indeed result to a significant better success of therapy. Further studies, incorporating well controlled, interventional study designs as well as larger patient samples, are needed to corroborate the present results. However, such kind of patient-tailored approaches would break the barriers of the common categorical classification schematic still dominantly used in daily life. We hope to report about a successful alignment of the presented methodology in one of our future works. Nevertheless, this still requires some further research before the method we named Opto-Electronic Encephalography (OEG) will be fully suitable for everyday use.",
      "page_start": 13,
      "page_end": 14
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: The neutral mean faces of the healthy control group and the patients are visualized. The left face corresponds to the control group and",
      "page": 2
    },
    {
      "caption": "Figure 1: for the corresponding mean",
      "page": 2
    },
    {
      "caption": "Figure 2: Brain arousal regulation of the vigilance continuum as synopsis of deﬁned classiﬁcations of the EEG-stages occurring between relaxed",
      "page": 3
    },
    {
      "caption": "Figure 3: Illustration of the computational pipeline for the shape-based coherence sequence kernel. Given a set of registered facial landmarks the",
      "page": 4
    },
    {
      "caption": "Figure 2: ). With the rapid development and increasing performance",
      "page": 4
    },
    {
      "caption": "Figure 2: for the regulation",
      "page": 4
    },
    {
      "caption": "Figure 3: and will be described in the following two",
      "page": 5
    },
    {
      "caption": "Figure 4: illustrates a graphical interpretation of this distance measurement.",
      "page": 5
    },
    {
      "caption": "Figure 4: A graphical top-down view of the positive semi-deﬁnite cone",
      "page": 6
    },
    {
      "caption": "Figure 5: The box plots for the mean face questionnaire. The individual questions are described in the list of subsection 5.2.1. The ratings of the",
      "page": 7
    },
    {
      "caption": "Figure 1: the neutral mean faces of the patients and the healthy",
      "page": 7
    },
    {
      "caption": "Figure 3: the processing schematic is illustrated.",
      "page": 7
    },
    {
      "caption": "Figure 5: the box plots representing the distribution of the",
      "page": 8
    },
    {
      "caption": "Figure 6: The prediction of the patient status based upon",
      "page": 8
    },
    {
      "caption": "Figure 6: The prediction of the patient status, type and treatment responder",
      "page": 8
    },
    {
      "caption": "Figure 7: visualizes the valence and arousal distributions",
      "page": 8
    },
    {
      "caption": "Figure 1: ). In the next step VAR modeling and",
      "page": 8
    },
    {
      "caption": "Figure 7: The valence and arousal distributions predicted by the EmoNet",
      "page": 9
    },
    {
      "caption": "Figure 8: For the complete",
      "page": 9
    },
    {
      "caption": "Figure 8: The prediction of the patient status (e.q. healthy control or",
      "page": 9
    },
    {
      "caption": "Figure 9: The prediction of the patient status (e.q. healthy controls or",
      "page": 9
    },
    {
      "caption": "Figure 10: The reaction times (RT) of the attention test versus the Wasser-",
      "page": 9
    },
    {
      "caption": "Figure 10: this comparison is shown for both groups,",
      "page": 10
    },
    {
      "caption": "Figure 11: The scalability is very similar to the previous estimation",
      "page": 10
    },
    {
      "caption": "Figure 11: The prediction of the patient type (e.q. depressive or",
      "page": 10
    },
    {
      "caption": "Figure 12: Again the scalability was determined by the model",
      "page": 10
    },
    {
      "caption": "Figure 12: The prediction of the symptom severity (HAMD-17) for the in-",
      "page": 10
    },
    {
      "caption": "Figure 13: The dot products of the sequence kernel with respect to the",
      "page": 11
    },
    {
      "caption": "Figure 13: the dot products",
      "page": 11
    },
    {
      "caption": "Figure 14: The measurement space including the face behavior, the clinical",
      "page": 11
    },
    {
      "caption": "Figure 14: illustrates the measurements as a schematic",
      "page": 11
    },
    {
      "caption": "Figure 15: the difference",
      "page": 11
    },
    {
      "caption": "Figure 16: the difference of the average prescribed treatment",
      "page": 11
    },
    {
      "caption": "Figure 17: the scored correlations are visualized. For the model with 2048",
      "page": 11
    },
    {
      "caption": "Figure 15: The difference in symptom severity (HAMD-17 delta) between",
      "page": 12
    },
    {
      "caption": "Figure 18: shows these for the patients and the controls.",
      "page": 12
    },
    {
      "caption": "Figure 16: The comparison of the average prescribed pharmacological",
      "page": 12
    },
    {
      "caption": "Figure 17: The prediction of the symptom severity (HAMD-17) for the in-",
      "page": 12
    },
    {
      "caption": "Figure 18: The dot products of the causal predicted sequence kernel with",
      "page": 12
    }
  ],
  "tables": [
    {
      "caption": "Table 1: the pharmacological treatment types",
      "data": [
        {
          "ID": "1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11",
          "Category": "Antipsychotica\nAntikonvulsiva/-epileptica\nAnxiolytica (upon need)\nAnxiolytica (daily)\nOpiode\nSSRI\nSNRI\nSNDRI\nTetracyclic AD\nTricyclic AD\nMAO"
        }
      ],
      "page": 11
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Global, regional, and national burden of 12 mental disorders in 204 countries and territories, 1990-2019: a systematic analysis for the global burden of disease study 2019",
      "authors": [
        "G Collaborators"
      ],
      "year": "2022",
      "venue": "The Lancet Psychiatry"
    },
    {
      "citation_id": "2",
      "title": "Toward the future of psychiatric diagnosis: the seven pillars of rdoc",
      "authors": [
        "B Cuthbert",
        "T Insel"
      ],
      "year": "2013",
      "venue": "BMC Med"
    },
    {
      "citation_id": "3",
      "title": "Roamer: roadmap for mental health research in europe",
      "year": "2014",
      "venue": "Int J Methods Psychiatr Res"
    },
    {
      "citation_id": "4",
      "title": "The new century of the brain",
      "authors": [
        "R Chruch"
      ],
      "year": "2014",
      "venue": "Sci Am"
    },
    {
      "citation_id": "5",
      "title": "Mental health research priorities for europe",
      "year": "2015",
      "venue": "The Lancet Psychatry"
    },
    {
      "citation_id": "6",
      "title": "Individualized medicine from prewomb to tomb",
      "authors": [
        "E Topol"
      ],
      "year": "2014",
      "venue": "Cell"
    },
    {
      "citation_id": "7",
      "title": "Machine learning for precision psychiatry: opportunities and challenges",
      "authors": [
        "D Bzdok",
        "A Meyer-Lindenberg"
      ],
      "year": "2018",
      "venue": "Biol Psychiatry Cogn Neurosci Neuroimaging"
    },
    {
      "citation_id": "8",
      "title": "Predictive analytics in mental health: applications, guidelines, challenges and perspectives",
      "year": "2017",
      "venue": "Mol Psychiatry"
    },
    {
      "citation_id": "9",
      "title": "Machine learning for clinical outcome prediction",
      "authors": [
        "F Shamout",
        "T Zhu",
        "D Clifton"
      ],
      "year": "2021",
      "venue": "IEEE Reviews in Biomedical Engineering"
    },
    {
      "citation_id": "10",
      "title": "The theoretical interpretation of electroencephalography (eeg)",
      "authors": [
        "G Ulrich"
      ],
      "year": "2013",
      "venue": "The theoretical interpretation of electroencephalography (eeg)"
    },
    {
      "citation_id": "11",
      "title": "Die Insuffizienz des Vigilitästonus",
      "authors": [
        "D Bente"
      ],
      "year": "1964",
      "venue": "Habilitationsschrift"
    },
    {
      "citation_id": "12",
      "title": "The vigilance regulation model of affective disorders and adhd",
      "authors": [
        "U Hegerl",
        "S Olbrich"
      ],
      "year": "2014",
      "venue": "Neuroscience and Biobehavioral Reviews"
    },
    {
      "citation_id": "13",
      "title": "Predicting brainwaves from face videos",
      "authors": [
        "C Pilz",
        "I Makhlouf",
        "U Habel",
        "S Leonhardt"
      ],
      "year": "2020",
      "venue": "The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops"
    },
    {
      "citation_id": "14",
      "title": "Detecting depression severity by interpretable representations of motion dynamics",
      "authors": [
        "A Kacem",
        "Z Hammal",
        "M Daoudi",
        "J Cohn"
      ],
      "year": "2018",
      "venue": "The IEEE International Conference on Automatic Face and Gesture Recognition (FG 2018)"
    },
    {
      "citation_id": "15",
      "title": "Classifying depression severity in recovery from major depressive disorder via dynamic facial features",
      "authors": [
        "S Harati",
        "A Crowell",
        "Y Huang",
        "H Mayberg",
        "S Nemati"
      ],
      "year": "2020",
      "venue": "IEEE Journal of Biomedical and Health Informatics"
    },
    {
      "citation_id": "16",
      "title": "The rise of affectivism",
      "authors": [
        "D Dukes",
        "K Abrams"
      ],
      "year": "2021",
      "venue": "Nature Human Behaviour"
    },
    {
      "citation_id": "17",
      "title": "Investigating causal relations by econometric models and cross-spectral methods",
      "authors": [
        "C Granger"
      ],
      "year": "1969",
      "venue": "Econometrica"
    },
    {
      "citation_id": "18",
      "title": "Hemifacial asymmetry in emotion expressions",
      "authors": [
        "H Asthana"
      ],
      "year": "1998",
      "venue": "Behav Modif"
    },
    {
      "citation_id": "19",
      "title": "The works of Aristotle",
      "authors": [
        "Aristoteles"
      ],
      "year": "1913",
      "venue": "The works of Aristotle"
    },
    {
      "citation_id": "20",
      "title": "The expression of the emotions in man and animals",
      "authors": [
        "C Darwin"
      ],
      "venue": "John Murray"
    },
    {
      "citation_id": "21",
      "title": "Cognitive therapy: A humanistic approach",
      "authors": [
        "H Werner"
      ],
      "year": "1982",
      "venue": "Cognitive therapy: A humanistic approach"
    },
    {
      "citation_id": "22",
      "title": "Die Biologie des menschlichen Verhaltens",
      "authors": [
        "I Eibl-Eibesfeldt"
      ],
      "year": "1975",
      "venue": "Die Biologie des menschlichen Verhaltens"
    },
    {
      "citation_id": "23",
      "title": "Affect, imagery, consciousness",
      "authors": [
        "S Tomkins"
      ],
      "year": "1962",
      "venue": "Affect, imagery, consciousness"
    },
    {
      "citation_id": "24",
      "title": "Human emotions",
      "authors": [
        "C Izzard"
      ],
      "year": "1977",
      "venue": "Human emotions"
    },
    {
      "citation_id": "25",
      "title": "An argument for basic emotions",
      "authors": [
        "P Ekman"
      ],
      "year": "1992",
      "venue": "Cogn Emot"
    },
    {
      "citation_id": "26",
      "title": "Dynamic facial expressions of emotion transmit an evolving hierarchy of signals over time",
      "authors": [
        "R Jack",
        "O Garrod",
        "P Schyns"
      ],
      "year": "2014",
      "venue": "Current Biology"
    },
    {
      "citation_id": "27",
      "title": "Bodily changes in pain, hunger, fear and rage",
      "authors": [
        "W Cannon"
      ],
      "year": "1929",
      "venue": "Bodily changes in pain, hunger, fear and rage"
    },
    {
      "citation_id": "28",
      "title": "Freeze, flight, fight, fright, faint: Adaptationist perspectives on the acute stress response spectrum",
      "authors": [
        "S Bracha"
      ],
      "year": "2004",
      "venue": "CNS Spectrums"
    },
    {
      "citation_id": "29",
      "title": "Der menschliche ausdruck",
      "authors": [
        "K Leonhard"
      ],
      "year": "1968",
      "venue": "Johann Ambrosius Barth"
    },
    {
      "citation_id": "30",
      "title": "Lehrbuch der Psychiatrie",
      "authors": [
        "E Bleuler"
      ],
      "year": "1911",
      "venue": "Lehrbuch der Psychiatrie"
    },
    {
      "citation_id": "31",
      "title": "Mimik und Physiognomik",
      "authors": [
        "T Pideret"
      ],
      "year": "1896",
      "venue": "Meyersche Hofbuchhandlung"
    },
    {
      "citation_id": "32",
      "title": "Emotional expression in psychiatric conditions: New technology for clinicians",
      "authors": [
        "K Grabowski",
        "A Rynkiewicz",
        "A Lassalle",
        "S Baron-Cohen",
        "B Schuller",
        "N Cummins",
        "A Baird",
        "J Podgorska-Bednarz",
        "A Pieniazek",
        "I Lucka"
      ],
      "year": "2019",
      "venue": "Psychiatry Clin Neurosci"
    },
    {
      "citation_id": "33",
      "title": "Spectral representation of behaviour primitives for depression analysis",
      "authors": [
        "S Song",
        "S Jaiswal",
        "L Shen",
        "M Valstar"
      ],
      "year": "2022",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "34",
      "title": "What is Life? The Physical Aspect of the Living Cell",
      "authors": [
        "E Schrödinger"
      ],
      "year": "1944",
      "venue": "What is Life? The Physical Aspect of the Living Cell"
    },
    {
      "citation_id": "35",
      "title": "Autopoiesis and cognition: The realization of the living",
      "authors": [
        "H Maturana",
        "F Varela"
      ],
      "year": "1973",
      "venue": "Boston Studies in the Philosophy of Science"
    },
    {
      "citation_id": "36",
      "title": "Time, structure and fluctuations",
      "authors": [
        "I Prigogine"
      ],
      "year": "1977",
      "venue": "Time, structure and fluctuations"
    },
    {
      "citation_id": "37",
      "title": "A mathematical theory of communication",
      "authors": [
        "C Shannon"
      ],
      "year": "1948",
      "venue": "Bell System Technical Journal"
    },
    {
      "citation_id": "38",
      "title": "Human development and health",
      "authors": [
        "K Hurrelmann"
      ],
      "year": "1989",
      "venue": "Human development and health"
    },
    {
      "citation_id": "39",
      "title": "The conception of nervous and mental energy -vigilance: a physiological state of the nervous system",
      "authors": [
        "H Head"
      ],
      "year": "1923",
      "venue": "British Journal of Psychology"
    },
    {
      "citation_id": "40",
      "title": "Mind and nature: A necessary unity",
      "authors": [
        "G Bateson"
      ],
      "year": "1979",
      "venue": "Mind and nature: A necessary unity"
    },
    {
      "citation_id": "41",
      "title": "The methodological character of theoretical concepts",
      "authors": [
        "R Carnap"
      ],
      "year": "1956",
      "venue": "The Foundations of Science and the Concepts of Psychology and Psychoanalysis"
    },
    {
      "citation_id": "42",
      "title": "Addendum to: The importance of the concept of vigilance for psychophysiological research. Held at University of Leipzig 2008",
      "authors": [
        "G Ulrich"
      ],
      "year": "1988",
      "venue": "Medical Hypotheses"
    },
    {
      "citation_id": "43",
      "title": "Changes in human brain potentials during the onset of sleep",
      "authors": [
        "H Davis",
        "P Davis",
        "A Loomis",
        "E Harvey",
        "G Hobart"
      ],
      "year": "1938",
      "venue": "Journal of Experimental Psychology"
    },
    {
      "citation_id": "44",
      "title": "Celebral states during sleep as studied by human brain potentials",
      "authors": [
        "A Loomis",
        "E Harvey",
        "G Hobart"
      ],
      "year": "1937",
      "venue": "Journal of Experimental Psychology"
    },
    {
      "citation_id": "45",
      "title": "The clinical and theoretical importance of eeg rhythms corresponding to states of lowered vigilance",
      "authors": [
        "B Roth"
      ],
      "year": "1961",
      "venue": "Clinical Neurophysiology"
    },
    {
      "citation_id": "46",
      "title": "A new quantitative approach to the assessment of stages of vigilance as defined by spatiotemporal eeg patterning",
      "authors": [
        "G Ulrich",
        "K Frick"
      ],
      "year": "1986",
      "venue": "Perceptual and Motor Skills"
    },
    {
      "citation_id": "47",
      "title": "Revisiting the concept of vigilance",
      "authors": [
        "G Klösch",
        "J Zeitlhofer",
        "O Ipsiroglu"
      ],
      "year": "2022",
      "venue": "Front Psychiatry"
    },
    {
      "citation_id": "48",
      "title": "A survey of the statistical theory of shape",
      "authors": [
        "D Kendall"
      ],
      "year": "1993",
      "venue": "Statist Sci"
    },
    {
      "citation_id": "49",
      "title": "Euclidean distance geometry",
      "authors": [
        "J Gower"
      ],
      "year": "1982",
      "venue": "Mathematical Scientist"
    },
    {
      "citation_id": "50",
      "title": "Affine invariance revisited",
      "authors": [
        "E Begelfor",
        "M Werman"
      ],
      "year": "2006",
      "venue": "IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
    },
    {
      "citation_id": "51",
      "title": "Riemannian metric and geometric mean for positive semidefinite matrices of fixed rank",
      "authors": [
        "S Bonnabel",
        "R Sepulchre"
      ],
      "year": "2009",
      "venue": "SIAM Journal on Matrix Analysis and Applications"
    },
    {
      "citation_id": "52",
      "title": "A novel geometric framework on gram matrix trajectories for human behavior understanding",
      "authors": [
        "A Kacem",
        "M Daoudi",
        "B Amor",
        "S Berreti",
        "J Alvarez-Paiva"
      ],
      "year": "2020",
      "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
    },
    {
      "citation_id": "53",
      "title": "The nature of statistical learning theory",
      "authors": [
        "V Vapnik"
      ],
      "year": "2000",
      "venue": "Information Science and Statistics"
    },
    {
      "citation_id": "54",
      "title": "Speaker verification using adapted gaussian mixture models",
      "authors": [
        "D Reynolds",
        "T Quatieri",
        "R Dunn"
      ],
      "year": "2000",
      "venue": "Digital Signal Processing"
    },
    {
      "citation_id": "55",
      "title": "Support vector machines using gmm supervectors for speaker verification",
      "authors": [
        "W Campbell",
        "D Sturim",
        "D Reynolds"
      ],
      "year": "2006",
      "venue": "IEEE Signal Processing Letters"
    },
    {
      "citation_id": "56",
      "title": "World medical association declaration of helsinki: ethical principles for medical research involving human subjects",
      "year": "2013",
      "venue": "JAMA"
    },
    {
      "citation_id": "57",
      "title": "Structured clinical interview for dsm-5 (scid-5)",
      "year": "2017",
      "venue": "Structured clinical interview for dsm-5 (scid-5)"
    },
    {
      "citation_id": "58",
      "title": "The brief symptom inventory: an introductory report",
      "authors": [
        "L Melisaratos"
      ],
      "year": "1983",
      "venue": "Psychological medicine"
    },
    {
      "citation_id": "59",
      "title": "An inventory for measuring depression",
      "authors": [
        "A Beck",
        "C Ward",
        "M Mendelson",
        "J Mocj",
        "J Erbaugh"
      ],
      "year": "1961",
      "venue": "Archives of General Psychiatry"
    },
    {
      "citation_id": "60",
      "title": "The grid-hamd: standardization of the hamilton depression rating scale",
      "year": "2008",
      "venue": "International clinical psychopharmacology"
    },
    {
      "citation_id": "61",
      "title": "Microcomputer analysis of performance on a portable, simple visual reaction time task sustained operations",
      "authors": [
        "I Dinges",
        "J Powell"
      ],
      "year": "1985",
      "venue": "Behavior Research Methods, Instrumentation, and Computers"
    },
    {
      "citation_id": "62",
      "title": "A 3d facial expression database for facial behavior research",
      "authors": [
        "L Yin",
        "X Wei",
        "Y Sun",
        "J Wang",
        "M Rosato"
      ],
      "year": "2006",
      "venue": "The IEEE Conference on Automatic Face and Gesture Recognition"
    },
    {
      "citation_id": "63",
      "title": "The differential contribution of facial expressions, prosody, and speech content to empathy",
      "authors": [
        "C Regenbogen",
        "D Schneider",
        "A Finkelmeyer",
        "N Kohn",
        "B Derntl",
        "T Kellermann",
        "R Gur",
        "F Schneider",
        "U Habel"
      ],
      "year": "2012",
      "venue": "Cognition and Emotion"
    },
    {
      "citation_id": "64",
      "title": "Estimation of continuous valence and arousal levels from faces in naturalistic conditions",
      "authors": [
        "A Toisoul",
        "J Kossaifi",
        "A Bulat",
        "G Tzimiropoulos",
        "M Pantic"
      ],
      "year": "2021",
      "venue": "Nature Machine Intelligence"
    },
    {
      "citation_id": "65",
      "title": "Active appearance models revisited",
      "authors": [
        "I Matthews",
        "S Baker"
      ],
      "year": "2004",
      "venue": "International Journal of Computer Vision"
    },
    {
      "citation_id": "66",
      "title": "Learning to find eye region landmarks for remote gaze estimation in unconstrained settings",
      "authors": [
        "S Park",
        "X Zhang",
        "A Bulling",
        "O Hilliges"
      ],
      "year": "2018",
      "venue": "Proceedings of the 2018 ACM Symposium on Eye Tracking Research and Applications"
    },
    {
      "citation_id": "67",
      "title": "A circumplex model of affect",
      "authors": [
        "J Russell"
      ],
      "year": "1980",
      "venue": "Journal of Personality and Social Psychology"
    },
    {
      "citation_id": "68",
      "title": "Facial expressivity in the course of schizophrenia and depression",
      "authors": [
        "W Gaebel",
        "W Woelwer"
      ],
      "year": "2004",
      "venue": "Archives of Psychiatry and Clinical Neurosciences"
    },
    {
      "citation_id": "69",
      "title": "Some nonverbal aspects of depression and schizophrenia occurring during the interview",
      "authors": [
        "I Jones",
        "M Pansa"
      ],
      "year": "1979",
      "venue": "The Journal of Nervous and Mental Disease"
    },
    {
      "citation_id": "70",
      "title": "Treatment resistance in psychiatry: state of the art and new directions",
      "authors": [
        "O Howes",
        "M Thas",
        "T Pillinger"
      ],
      "year": "2022",
      "venue": "Mol Psychiatry"
    },
    {
      "citation_id": "71",
      "title": "The book of why: The new science of cause and effect",
      "authors": [
        "J Pearl",
        "D Mackenzie"
      ],
      "year": "2018",
      "venue": "The book of why: The new science of cause and effect"
    },
    {
      "citation_id": "72",
      "title": "Multilinear analysis of image ensembles: Tensorfaces",
      "authors": [
        "M Vasilescu",
        "D Terzopoulos"
      ],
      "year": "2002",
      "venue": "Proc 7th European Conference on Computer Vision"
    }
  ]
}