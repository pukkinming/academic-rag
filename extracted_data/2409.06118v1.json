{
  "paper_id": "2409.06118v1",
  "title": "Apex: Attention On Personality Based Emotion Rexgnition Framework",
  "published": "2024-09-10T00:03:42Z",
  "authors": [
    "Ruijie Fang",
    "Ruoyu Zhang",
    "Elahe Hosseini",
    "Chongzhou Fang",
    "Mahdi Eslaminehr",
    "Setareh Rafatirad",
    "Houman Homayoun"
  ],
  "keywords": [
    "Affective Computing",
    "Machine Learning",
    "Emotion Recognition"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Automated emotion recognition has applications in various fields, such as human-machine interaction, healthcare, security, education, and emotion-aware recommendation/feedback systems. Developing methods to analyze human emotions accurately is essential to enable such diverse applications. Multiple studies have been conducted to explore the possibility of using physiological signals and machine-learning techniques to evaluate human emotions. Furthermore, internal factors such as personality have been considered and involved in emotion recognition. However, integrating personality that is user specific within traditional machine-learning methods that use useragnostic large data sets has become a critical problem. This study proposes the APEX: attention on personality-based emotion recognition framework, in which multiple weak classifiers are trained on physiological signals of each participant's data, and the classification results are reweighed based on the personality correlations between corresponding subjects and test subjects. Experiments have been conducted on the ASCERTAIN dataset, and the results show that the proposed framework outperforms existing studies.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "I. Introduction",
      "text": "Emotion is a mental state caused by neurophysiological changes associated with thoughts, feelings, and behavioral responses, which play an essential role in human life  [1] . From the perspective of evolution, emotion is a product of natural selection as it helps humans survive. For example, fear causes humans to avoid harm, joy makes us repeat what works, sadness nudges us to ask for help, and the emotion of disgust makes us spit up accidentally eaten foreign objects. In modern society, emotion is essential as it directly influences people's activity and productivity. Positive emotions can promote coordination and organization, which is conducive to improving productivity. In contrast, negative emotions can make people feel bored, depressed, and dull and negatively affect people's creative thinking  [2] ,  [3] .\n\nEmotion has three distinct components: a subjective experience, external behaviors, and physiological arousal. Subjective experience is an individual's self-feeling of different emotional states  [4] -  [6] . External behaviors of emotions, often called expressions, is the quantified form of actions of various parts of the body when an emotional state occurs, including facial expressions, gesture expressions, and intonation expressions  [7] ,  [8] . Physiological arousal refers to the physiological response to emotion, including a series of responses in the autonomic nervous system (ANS). Multiple studies have been conducted to automatically recognize emotion based on external behaviors or physiological signals. These methods exploit the connections between emotions, external behaviors, and physiological arousal to automatically recognize emotion and apply it in different applications e.g. human-machine interface, neuro-marketing, and healthcare  [9] ,  [10] .\n\nAutomated emotion recognition can be categorized into behavior-based and physiological signal-based approaches. The behavior-based approach captures various body activities, including facial expressions, body posture, gestures, and voice tone. The physiological signal-based approach collects physiological signals, including Electroencephalography (EEG), Electrocardiography (ECG), Galvanic Skin Response (GSR), Heart Rate Variability (HRV), Respiration Rate (RR), Skin Temperature, and Electromyogram (EMG). In both methods, the collected data is processed using a machine learning pipeline that performs data pre-processing, feature extraction, training, and validating to make predictions  [11] . The predicted targets are binary classification tasks derived from 2D or 3D models of emotion. These classifiers split emotion into different dimensions, e.g., arousal, valence, and dominance (if using 3 dimensions)  [12] . In the past decade, multiple studies have explored the feasibility of such automated emotion recognition approaches, and several datasets have been published, including ASCERTAIN  [13] , MAHNOB-HCI  [14] , etc.\n\nRecent research has proposed using additional contextual and psychological factors, including personality, in automated emotion recognition. The relationship between personality and effect is first proposed in Eysenck's personality model  [15]   and further validated. By using functional magnetic resonance imaging (fMRI), the blood oxygenation level dependent (BOLD) signal was examined to indicate arousal and valence level which further proved the correlation between personality and emotion responses. Different databases have been released for personality-involved automated emotion recognition, including ASCERTAIN  [13] . These data sets used emotional videos as stimuli and captured physiological signals while subjects were watching videos. Also, the big-five traits for personality were used to evaluate subjects' personalities. Subramanian et al.  [13]  deployed traditional machine learning algorithms including support vector machine (SVM) and naive Bayes (NB)  [16] , to classify emotions and obtained averaged f1-score of 0.7 for Valence and 0.655 for Arousal. Shao et al.  [17]  proposed a hypergraph neural network where both a modality and a personality derive hypergraphs, and the vertices in the hypergraphs are subject-video pairs. The hypergraphs output to a fully-connected layer to yield the final prediction. Results on ASCERTAIN dataset showed 80.57% accuracy in classifying high/low valence and 73.67% accuracy in classifying high/low arousal. Tian et al.  [18]  first cluster subjects of ASCERTAIN dataset in different groups based on their personality using K-means and applied deep neural network to do classification. However, the former studies have treated personality too lightly or arbitrarily. This study proposes a novel framework that embeds the personality attention mechanism from natural language processing to ensemble learning, specifically, bagging. A personality score is calculated by the inner product of two 5D personality traits. It is used as the reweighing factor of different weak classifiers to yield a more personalized and adapted prediction for the specific subject.\n\nThe main contributions of this paper can be summarized as follows:\n\n• We propose a scoring system to calculate the similarity between the personalities of two subjects. • A novel framework that embeds the personality score to ensemble learning is proposed. • We conducted experiments on the ASCERTAIN dataset to verify the feasibility of the proposed framework. Results showed that our proposed method overperforms existing studies. The remainder of this paper is organized as follows. Section II introduces the dataset used in the study and provides a detailed description of the proposed approaches. In section III, we present the experiments conducted and the evaluation results. Section IV discusses this study's merits, potential, weaknesses, and future directions. Lastly, Section V concludes this study and summarizes the key learnings.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Ii. Method",
      "text": "The pipeline of the proposed framework is presented in Fig.  1 . It contains two parts: the bagging part and the personality attention part.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "A. Dataset",
      "text": "We used ASCERTAIN dataset  [13]  to validate the feasibility of this study. ASCERTAIN dataset is a multimodal dataset for emotion recognition that uses physiological sensors. Fiftyeight subjects were involved in the study and were tested for their big-five personality traits. Subjects were instructed to report their emotional self-ratings of \"Arousal,\" \"Valence,\" \"Engagement,\" \"Liking,\" and \"Familiarity\" after watching 36 videos that evoke emotion, such as \"The Shining.\" Physiological signals were recorded while the subjects watched the videos. The recorded signals included EEG, ECG, GSR, and facial activity. In this study, we adopted the 2D emotion model, which has two dimensions \"Arousal\" and \"Valence.\" Thus, we designate two classification tasks: arousal and valence. In addition, we adopted two physiological signals, ECG and GSR, because these two signals reveal critical information and can be deployed on wearable devices.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "B. Apex Framework",
      "text": "Fig.  1  shows the APEX framework, which consists of Bagging and Personalized attention. The critical assumption of this framework is that personality and emotional response are correlated; hence participants with similar personalities evoke similar emotional responses. Thus, when doing emotion recognition for a particular participant, we want the training data with a similar personality to contribute more to the classification and reduce the weights of data with less personality similarity.\n\nTo do so, we treat each participant as an independent training sub-set. Assume the total number of participants in the training set is N, then N training sub-sets are used. Each training sub-set S i is used to train a weak classifier and in total, there are N weak classifiers, where i is the index for a training sub-set. We use decision trees as the weak classifier in this study, but this choice is highly flexible. After all the weak classifiers are trained, they can be used to infer a new subject's data S x . This will yield N classification results I i in probability form, i.e., a possibility number ranging in [0, 1], where i is the index of the weak classifier.\n\nOn the other hand, each training sub-set has fivedimensional personality traits, represented as a fivedimensional data vector p i and the test subject also has personality traits p x . To calculate the score, we use the inner product of between each training sub-set p i and the testing subject p x to yield N products product i :\n\nAll products are pushed to normalization to re-scale to [0, 1]. Then, they were transformed to probability scores score i by being imported to a softmax function. After softmax function, the sum of score i is 1. The scores are calculated as:\n\nTo embed the personality attention to bagging model, the inferences are multiplied with scores one by one and summed up to yield the final prediction:\n\nNote that the output inferences are probability values indicating the possibility of the predicted label, and it is a fraction ranging in [0, 1]. Thus, in order to transform the probability value into a binary classes, a binary step activation function is deployed here, where the function is described as:\n\nIn the end, the final prediction is a class which embodies wellweighed decisions from all training sub-sets.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Iii. Experiments And Results",
      "text": "To validate the feasibility of the proposed framework, we conducted experiments on the ASCERTAIN dataset. We used ECG and GSR data in this study. In the pre-processing stage, a low-pass filter with a 0.2 Hz cut-off frequency was used to obtain the low-pass GSR signal. Next, a band-pass filter with 0.67 to 40 Hz cut-off frequencies was applied to the ECG signals. Then, a five seconds time window with a five seconds window shift is used to extract features. In total, 42 features are extracted. Feature selection is applied, including variance threshold, SelectKbest, and tree-based selecter, to optimize the feature space. After feature selection, the ten most important features are kept, as shown in Table  II .\n\nThen, the data were normalized to the scale of [0, 1]. This is because we hypothesize that different subjects have different vital signs baselines and have different physiological responses to emotional videos. In order to lessen the bias among subjects, normalization was applied. Afterward, data were imported into the APEX framework. Each subject's feature set becomes a training subset S i to train a weak classifier.\n\nWe used Decision Tree as the weak classifier as it overperformed other classifiers in our preliminary experiments. Decision tree, support vector machine (SVM), k-NN, linear discriminative analysis have been tested and decision tree overperformed the second best classifiers, SVM by 0.9% in accuracy. We consider this is due to the advantages of the decision tree algorithm itself, as it can be considered a collection of if-then rules, which are highly interpretable, and fast in prediction. In addition, for a decision tree, there is no need to consider whether the features are interdependent. However, when using the decision tree algorithm alone, it is prone to overfitting. Through various methods, the complexity of the decision tree is suppressed, the fitting ability of a single decision tree is reduced, and multiple decision trees are integrated by the ensemble method, which can solve the problem of overfitting. Thus, the ensemble learning method and the decision tree learning algorithm can complement each other and are a perfect pair.\n\nThere are 58 participants in the ASCERTAIN dataset. However, due to the quality of the physiological signals, ten subjects with relatively low data quality were removed from the study. Thus, 48 weak classifiers were trained. For testing, we set each subject as the testing set at a time, excluded this particular test subject from the weak classifiers, and used the other 47 weak classifiers to infer the test subject. This process was repeated 48 times for all subjects in the dataset. We reported the averaged system's performance from all subjects.\n\nTo assess the effectiveness of our novel framework, we conducted a comprehensive evaluation by replicating three seminal studies that tackled emotion recognition, both with and without the incorporation of personality traits. In contrast to these established works, our proposed framework was implemented and compared against their methodologies. In the study by Santamaria et al.  [19] , a convolutional neural network was employed to classify arousal and valence using the AMIGOS dataset. Their deep learning model demonstrated substantial efficacy in emotion recognition through physiological signals in the absence of personality integration. Shao et al.  [17]  pursued a distinctive approach by employing a hyperedge algorithm to establish connections between personality attributes, physiological signals, and emotions. Their work highlighted the potential synergy between these facets, showcasing the intricate interplay between personality and emotional states. In a similar vein, Tian et al.  [18]  leveraged K-means clustering to categorize participants based on their personality traits. Subsequently, deep neural networks were trained for each personality subgroup. Our framework reproduced and extended their signal processing, feature extraction, and model deployment procedures on the ASCERTAIN dataset, utilizing the same participant cohort. The outcomes of our endeavors are meticulously presented in Table  I , underscoring the advancements brought about by our proposed framework.\n\nThe results showed our proposed framework overperformed existing studies. Our proposed framework achieved 77.1% and 76.9% accuracy on arousal and valence tasks, respectively, which overperformed 6% and 4% compared with the best results from baseline studies. Fig.  2  shows the receiver operating characteristic curve of APEX working on the Arousal task from ASCERTAIN dataset. As we have 48 different classifier sets and individual testing sets, 48 ROC curves were produced. We averaged the ROC curves by the y-axis. All ROC curves lay within the gray zone and the boundaries represent the best and worst test cases of the area under curves equal to 0.78 and 0.89, respectively.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Iv. Discussion",
      "text": "This study proposes a novel framework that integrates personality score into ensemble learning so that when inferencing, the decision pay more attention to subjects with similar personality. The APEX framework has a core of re-weight, it not only consider the personality similarity to adjust and pay more attention to more corelatted training samples while also keep decisions from physiological signals as dominant. We consider this is the main reason APEX is more accurate when compared with state-of-the-art approaches involving personality in emotion recognition where personality is treated arbitrarily (e.g., cluster subjects into personality groups) or considered slightly (e.g., a modality in parallel with other physiological signal modalities). This idea enables the APEX framework to progress more than the baseline (without personality) on a higher hierarchy.\n\nIn the personality attention part, several products are produced after the inner product of two personality vectors. We add a normalization process before sending them to softmax. This is because a personality vector is 5-dimensional with values ranging from  [1, 7]  and the average personality trait value in the ASCERTAIN dataset is 4.7. Thus, the output inner products usually range in hundred scales which is quite a large number when importing to softmax. In such case, the output probability will be concentrated to the highest value, i.e., 0.99 for the highest subject and 0.01 for all rest subjects' summation. Thus, the decision will almost all depend on that  specific subject with the 0.99 score. This is not the ideal case, so a normalization process is added to prevent the such phenomenon.\n\nIn the proposed study, decision tree is selected as the weak classifier in the framework from four classifiers. However, other models can also be embedded such as linear classifiers, shallow neoral networks, etc. They may have different performances on different problems consider the type of data, the complexity of relationships and the potential challenges and computation time requirments.\n\nTo extend this study, other factors that may influence emotion recognition other than personality can be taken into consideration, for example, demographic information. Exploring more factors and finding out the influential group of factors can lead emotion recognition to a more personalized and accurate stage. In addition, other algorithms can be used. This could include modifying the training process of neural networks by letting fewer score subjects only contribute to the first few epochs.",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "V. Conclusion",
      "text": "This study proposes the APEX framework that combines attention mechanism and ensemble learning to perform personalized emotion recognition. In the proposed framework, personality scores are calculated and used to re-weigh the outputs from weak classifiers. We conducted experiments on 48 subjects from ASCERTAIN dataset, and the results showed that the proposed framework performed better than the current state-of-the-art studies. We obtained classification accuracies for valence and arousal were 76.9% and 77.1%, respectively.",
      "page_start": 5,
      "page_end": 5
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: The proposed APEX framework.",
      "page": 2
    },
    {
      "caption": "Figure 1: It contains two parts: the bagging part and the personality",
      "page": 2
    },
    {
      "caption": "Figure 1: shows the APEX framework, which consists of",
      "page": 3
    },
    {
      "caption": "Figure 2: shows the receiver operating",
      "page": 4
    },
    {
      "caption": "Figure 2: The ROC curve of APEX framework on Arousal task from ASCER-",
      "page": 4
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "CA, USA": "CA, USA\nmahdi@quandarypeak.com"
        },
        {
          "CA, USA": "Abstract—Automated emotion recognition has applications\nin"
        },
        {
          "CA, USA": "various fields, such as human-machine interaction, healthcare, se-"
        },
        {
          "CA, USA": ""
        },
        {
          "CA, USA": "curity, education, and emotion-aware recommendation/feedback"
        },
        {
          "CA, USA": ""
        },
        {
          "CA, USA": "systems. Developing methods\nto\nanalyze\nhuman\nemotions\nac-"
        },
        {
          "CA, USA": ""
        },
        {
          "CA, USA": "curately\nis\nessential\nto\nenable\nsuch diverse\napplications. Mul-"
        },
        {
          "CA, USA": "tiple\nstudies have been conducted to explore\nthe possibility of"
        },
        {
          "CA, USA": "using physiological\nsignals and machine-learning techniques\nto"
        },
        {
          "CA, USA": "evaluate human emotions. Furthermore,\ninternal\nfactors\nsuch"
        },
        {
          "CA, USA": ""
        },
        {
          "CA, USA": "as personality have been considered and involved in emotion"
        },
        {
          "CA, USA": ""
        },
        {
          "CA, USA": "recognition. However,\nintegrating personality\nthat\nis user\nspe-"
        },
        {
          "CA, USA": ""
        },
        {
          "CA, USA": "cific within traditional machine-learning methods that use user-"
        },
        {
          "CA, USA": "agnostic\nlarge\ndata\nsets has\nbecome\na\ncritical\nproblem. This"
        },
        {
          "CA, USA": "study proposes the APEX: attention on personality-based emotion"
        },
        {
          "CA, USA": "recognition framework,\nin which multiple weak classifiers\nare"
        },
        {
          "CA, USA": ""
        },
        {
          "CA, USA": "trained on physiological\nsignals of each participant’s data, and"
        },
        {
          "CA, USA": ""
        },
        {
          "CA, USA": "the classification results are reweighed based on the personality"
        },
        {
          "CA, USA": ""
        },
        {
          "CA, USA": "correlations between corresponding\nsubjects\nand test\nsubjects."
        },
        {
          "CA, USA": "Experiments have been conducted on the ASCERTAIN dataset,"
        },
        {
          "CA, USA": "and the results show that\nthe proposed framework outperforms"
        },
        {
          "CA, USA": "existing studies."
        },
        {
          "CA, USA": ""
        },
        {
          "CA, USA": "Index Terms—Affective Computing, Machine Learning, Emo-"
        },
        {
          "CA, USA": ""
        },
        {
          "CA, USA": "tion Recognition"
        },
        {
          "CA, USA": ""
        },
        {
          "CA, USA": ""
        },
        {
          "CA, USA": "I.\nINTRODUCTION"
        },
        {
          "CA, USA": ""
        },
        {
          "CA, USA": "Emotion\nis\na mental\nstate\ncaused\nby\nneurophysiological"
        },
        {
          "CA, USA": "changes\nassociated with\nthoughts,\nfeelings,\nand\nbehavioral"
        },
        {
          "CA, USA": "responses, which\nplay\nan\nessential\nrole\nin\nhuman\nlife\n[1]."
        },
        {
          "CA, USA": "From the perspective of\nevolution,\nemotion is\na product of"
        },
        {
          "CA, USA": "natural selection as it helps humans survive. For example, fear"
        },
        {
          "CA, USA": "causes humans to avoid harm, joy makes us repeat what works,"
        },
        {
          "CA, USA": "sadness nudges us to ask for help, and the emotion of disgust"
        },
        {
          "CA, USA": "makes us spit up accidentally eaten foreign objects. In modern"
        },
        {
          "CA, USA": "society, emotion is essential as it directly influences people’s"
        },
        {
          "CA, USA": "activity and productivity. Positive emotions can promote co-"
        },
        {
          "CA, USA": "ordination and organization, which is conducive to improving"
        },
        {
          "CA, USA": "productivity.\nIn contrast, negative emotions can make people"
        },
        {
          "CA, USA": "feel bored, depressed, and dull and negatively affect people’s"
        },
        {
          "CA, USA": "creative thinking [2],\n[3]."
        },
        {
          "CA, USA": "Emotion has three distinct components: a subjective experi-"
        },
        {
          "CA, USA": "ence, external behaviors, and physiological arousal. Subjective"
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Fig. 1.\nThe proposed APEX framework.": "and\nfurther\nvalidated. By\nusing\nfunctional magnetic\nreso-\nreweighing factor of different weak classifiers to yield a more"
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "personalized and adapted prediction for\nthe specific subject.\nnance\nimaging (fMRI),\nthe blood oxygenation level depen-"
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "The main contributions of this paper can be summarized as\ndent\n(BOLD)\nsignal was\nexamined\nto\nindicate\narousal\nand"
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "follows:\nvalence\nlevel which further proved the\ncorrelation between"
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "personality and emotion responses. Different databases have\n• We propose a scoring system to calculate the similarity"
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "been\nreleased\nfor\npersonality-involved\nautomated\nemotion\nbetween the personalities of\ntwo subjects."
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "recognition, including ASCERTAIN [13]. These data sets used\n• A novel\nframework that embeds the personality score to"
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "emotional videos as stimuli and captured physiological signals\nensemble learning is proposed."
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "while subjects were watching videos. Also,\nthe big-five traits\n• We conducted experiments on the ASCERTAIN dataset to"
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "for personality were used to evaluate subjects’ personalities.\nverify the feasibility of\nthe proposed framework. Results"
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "Subramanian et al. [13] deployed traditional machine learning\nshowed that our proposed method overperforms existing"
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "algorithms including support vector machine (SVM) and naive\nstudies."
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "Bayes (NB)\n[16],\nto classify emotions and obtained averaged"
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "The remainder of this paper is organized as follows. Section"
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "f1-score of 0.7 for Valence\nand 0.655 for Arousal. Shao et"
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "II\nintroduces\nthe\ndataset\nused\nin\nthe\nstudy\nand\nprovides\na"
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "al.\n[17] proposed a hypergraph neural network where both a"
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "detailed description of\nthe proposed approaches.\nIn section"
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "modality and a personality derive hypergraphs, and the vertices"
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "III, we present\nthe experiments conducted and the evaluation"
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "in the hypergraphs are subject-video pairs. The hypergraphs"
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "results. Section\nIV discusses\nthis\nstudy’s merits,\npotential,"
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "output\nto a fully-connected layer\nto yield the final prediction."
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "weaknesses, and future directions. Lastly, Section V concludes"
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "Results on ASCERTAIN dataset showed 80.57% accuracy in"
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "this study and summarizes the key learnings."
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "classifying high/low valence and 73.67% accuracy in classi-"
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "II. METHOD"
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "fying high/low arousal. Tian et al.\n[18] first cluster\nsubjects"
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "The pipeline of the proposed framework is presented in Fig.\nof ASCERTAIN dataset\nin\ndifferent\ngroups\nbased\non\ntheir"
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "1.\nIt contains two parts:\nthe bagging part and the personality\npersonality using K-means and applied deep neural network"
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "attention part.\nto do classification. However,\nthe former studies have treated"
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "personality too lightly or\narbitrarily. This\nstudy proposes\na"
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "A. Dataset"
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "novel\nframework that embeds the personality attention mech-"
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "We used ASCERTAIN dataset [13] to validate the feasibility"
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "anism from natural\nlanguage processing to ensemble learning,"
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "of\nthis\nstudy. ASCERTAIN dataset\nis\na multimodal dataset"
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "specifically, bagging. A personality score is calculated by the"
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "for emotion recognition that uses physiological sensors. Fifty-"
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "inner product of\ntwo 5D personality traits.\nIt\nis used as\nthe"
        },
        {
          "Fig. 1.\nThe proposed APEX framework.": "eight\nsubjects were\ninvolved\nin\nthe\nstudy\nand were\ntested"
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "to report\ntheir emotional self-ratings of ”Arousal,” ”Valence,”",
          "Note that\nthe output\ninferences are probability values indicat-": "ing the possibility of\nthe predicted label, and it\nis a fraction"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "”Engagement,” ”Liking,” and ”Familiarity” after watching 36",
          "Note that\nthe output\ninferences are probability values indicat-": "ranging in [0, 1]. Thus,\nin order\nto transform the probability"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "videos\nthat\nevoke\nemotion,\nsuch as\n”The Shining.” Physio-",
          "Note that\nthe output\ninferences are probability values indicat-": "value into a binary classes, a binary step activation function"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "logical signals were recorded while the subjects watched the",
          "Note that\nthe output\ninferences are probability values indicat-": "is deployed here, where the function is described as:"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "videos. The recorded signals included EEG, ECG, GSR, and",
          "Note that\nthe output\ninferences are probability values indicat-": "(cid:40)"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "",
          "Note that\nthe output\ninferences are probability values indicat-": "0,\nif x < 0.5"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "facial activity. In this study, we adopted the 2D emotion model,",
          "Note that\nthe output\ninferences are probability values indicat-": "BinaryStep(x) =\n(4)"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "",
          "Note that\nthe output\ninferences are probability values indicat-": "1,\nif x ≥ 0.5"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "which has\ntwo dimensions\n”Arousal”\nand ”Valence.” Thus,",
          "Note that\nthe output\ninferences are probability values indicat-": ""
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "we\ndesignate\ntwo\nclassification\ntasks:\narousal\nand\nvalence.",
          "Note that\nthe output\ninferences are probability values indicat-": ""
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "",
          "Note that\nthe output\ninferences are probability values indicat-": "In the end, the final prediction is a class which embodies well-"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "In addition, we adopted two physiological\nsignals, ECG and",
          "Note that\nthe output\ninferences are probability values indicat-": ""
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "",
          "Note that\nthe output\ninferences are probability values indicat-": "weighed decisions from all\ntraining sub-sets."
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "GSR, because these two signals reveal critical information and",
          "Note that\nthe output\ninferences are probability values indicat-": ""
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "",
          "Note that\nthe output\ninferences are probability values indicat-": "III. EXPERIMENTS AND RESULTS"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "can be deployed on wearable devices.",
          "Note that\nthe output\ninferences are probability values indicat-": ""
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "",
          "Note that\nthe output\ninferences are probability values indicat-": "To validate the feasibility of\nthe proposed framework, we"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "B. APEX framework",
          "Note that\nthe output\ninferences are probability values indicat-": ""
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "",
          "Note that\nthe output\ninferences are probability values indicat-": "conducted experiments on the ASCERTAIN dataset. We used"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "Fig.\n1\nshows\nthe APEX framework, which\nconsists\nof",
          "Note that\nthe output\ninferences are probability values indicat-": ""
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "",
          "Note that\nthe output\ninferences are probability values indicat-": "ECG and GSR data in this study. In the pre-processing stage,"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "Bagging and Personalized attention. The critical assumption",
          "Note that\nthe output\ninferences are probability values indicat-": ""
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "",
          "Note that\nthe output\ninferences are probability values indicat-": "a low-pass filter with a 0.2 Hz cut-off\nfrequency was used to"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "of\nthis framework is that personality and emotional\nresponse",
          "Note that\nthe output\ninferences are probability values indicat-": ""
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "",
          "Note that\nthe output\ninferences are probability values indicat-": "obtain the low-pass GSR signal. Next, a band-pass filter with"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "are\ncorrelated;\nhence\nparticipants with\nsimilar\npersonalities",
          "Note that\nthe output\ninferences are probability values indicat-": ""
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "",
          "Note that\nthe output\ninferences are probability values indicat-": "0.67 to 40 Hz\ncut-off\nfrequencies was\napplied to the ECG"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "evoke similar emotional responses. Thus, when doing emotion",
          "Note that\nthe output\ninferences are probability values indicat-": ""
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "",
          "Note that\nthe output\ninferences are probability values indicat-": "signals. Then, a five seconds time window with a five seconds"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "recognition for a particular participant, we want\nthe training",
          "Note that\nthe output\ninferences are probability values indicat-": ""
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "",
          "Note that\nthe output\ninferences are probability values indicat-": "window shift\nis used to extract\nfeatures.\nIn total, 42 features"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "data with a similar personality to contribute more to the clas-",
          "Note that\nthe output\ninferences are probability values indicat-": ""
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "",
          "Note that\nthe output\ninferences are probability values indicat-": "are extracted. Feature selection is applied,\nincluding variance"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "sification and reduce the weights of data with less personality",
          "Note that\nthe output\ninferences are probability values indicat-": ""
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "",
          "Note that\nthe output\ninferences are probability values indicat-": "threshold, SelectKbest, and tree-based selecter, to optimize the"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "similarity.",
          "Note that\nthe output\ninferences are probability values indicat-": ""
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "",
          "Note that\nthe output\ninferences are probability values indicat-": "feature space. After\nfeature selection,\nthe ten most\nimportant"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "To\ndo\nso, we\ntreat\neach\nparticipant\nas\nan\nindependent",
          "Note that\nthe output\ninferences are probability values indicat-": ""
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "",
          "Note that\nthe output\ninferences are probability values indicat-": "features are kept, as shown in Table II."
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "training sub-set. Assume the total number of participants\nin",
          "Note that\nthe output\ninferences are probability values indicat-": ""
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "",
          "Note that\nthe output\ninferences are probability values indicat-": "Then, the data were normalized to the scale of [0, 1]. This is"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "the training set\nis N,\nthen N training sub-sets are used. Each",
          "Note that\nthe output\ninferences are probability values indicat-": ""
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "",
          "Note that\nthe output\ninferences are probability values indicat-": "because we hypothesize that different subjects have different"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "is used to train a weak classifier and in\ntraining sub-set Si",
          "Note that\nthe output\ninferences are probability values indicat-": ""
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "",
          "Note that\nthe output\ninferences are probability values indicat-": "vital signs baselines and have different physiological responses"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "total,\nthere are N weak classifiers, where i\nis the index for a",
          "Note that\nthe output\ninferences are probability values indicat-": ""
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "",
          "Note that\nthe output\ninferences are probability values indicat-": "to emotional videos. In order to lessen the bias among subjects,"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "training sub-set. We use decision trees as the weak classifier",
          "Note that\nthe output\ninferences are probability values indicat-": ""
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "",
          "Note that\nthe output\ninferences are probability values indicat-": "normalization was applied. Afterward, data were imported into"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "in this\nstudy, but\nthis choice is highly flexible. After all\nthe",
          "Note that\nthe output\ninferences are probability values indicat-": ""
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "",
          "Note that\nthe output\ninferences are probability values indicat-": "the APEX framework. Each subject’s\nfeature set becomes a"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "weak classifiers are trained,\nthey can be used to infer a new",
          "Note that\nthe output\ninferences are probability values indicat-": ""
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "",
          "Note that\nthe output\ninferences are probability values indicat-": "to train a weak classifier.\ntraining subset Si"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "in\nsubject’s data Sx. This will yield N classification results Ii",
          "Note that\nthe output\ninferences are probability values indicat-": ""
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "",
          "Note that\nthe output\ninferences are probability values indicat-": "We used Decision Tree\nas\nthe weak classifier\nas\nit over-"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "probability form,\ni.e., a possibility number\nranging in [0, 1],",
          "Note that\nthe output\ninferences are probability values indicat-": ""
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "",
          "Note that\nthe output\ninferences are probability values indicat-": "performed\nother\nclassifiers\nin\nour\npreliminary\nexperiments."
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "where i\nis the index of\nthe weak classifier.",
          "Note that\nthe output\ninferences are probability values indicat-": ""
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "",
          "Note that\nthe output\ninferences are probability values indicat-": "Decision tree,\nsupport vector machine\n(SVM), k-NN,\nlinear"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "On\nthe\nother\nhand,\neach\ntraining\nsub-set\nhas\nfive-",
          "Note that\nthe output\ninferences are probability values indicat-": ""
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "",
          "Note that\nthe output\ninferences are probability values indicat-": "discriminative\nanalysis\nhave\nbeen\ntested\nand\ndecision\ntree"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "dimensional\npersonality\ntraits,\nrepresented\nas\na\nfive-",
          "Note that\nthe output\ninferences are probability values indicat-": ""
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "",
          "Note that\nthe output\ninferences are probability values indicat-": "overperformed\nthe\nsecond\nbest\nclassifiers,\nSVM by\n0.9%"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "dimensional\ndata\nvector\nand\nthe\ntest\nsubject\nalso\nhas\npi",
          "Note that\nthe output\ninferences are probability values indicat-": ""
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "",
          "Note that\nthe output\ninferences are probability values indicat-": "in\naccuracy. We\nconsider\nthis\nis\ndue\nto\nthe\nadvantages\nof"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "personality traits px. To calculate the score, we use the inner",
          "Note that\nthe output\ninferences are probability values indicat-": "the decision tree\nalgorithm itself,\nas\nit\ncan be\nconsidered a"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "and the\ntesting\nproduct of between each training sub-set pi",
          "Note that\nthe output\ninferences are probability values indicat-": ""
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "",
          "Note that\nthe output\ninferences are probability values indicat-": "collection of if-then rules, which are highly interpretable, and"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "subject px to yield N products producti:",
          "Note that\nthe output\ninferences are probability values indicat-": "fast\nin prediction.\nIn addition,\nfor\na decision tree,\nthere\nis"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "",
          "Note that\nthe output\ninferences are probability values indicat-": "no need to consider whether\nthe features are interdependent."
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "(1)\n, px⟩\nproducti = ⟨pi",
          "Note that\nthe output\ninferences are probability values indicat-": ""
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "",
          "Note that\nthe output\ninferences are probability values indicat-": "However, when using the decision tree algorithm alone,\nit\nis"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "All products are pushed to normalization to re-scale to [0, 1].",
          "Note that\nthe output\ninferences are probability values indicat-": "prone to overfitting. Through various methods,\nthe complexity"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "Then,\nthey were transformed to probability scores scorei by",
          "Note that\nthe output\ninferences are probability values indicat-": "of\nthe\ndecision\ntree\nis\nsuppressed,\nthe\nfitting\nability\nof\na"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "being imported to a softmax function. After softmax function,",
          "Note that\nthe output\ninferences are probability values indicat-": "single decision tree\nis\nreduced,\nand multiple decision trees"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "is 1. The scores are calculated as:\nthe sum of scorei",
          "Note that\nthe output\ninferences are probability values indicat-": "are integrated by the ensemble method, which can solve the"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "",
          "Note that\nthe output\ninferences are probability values indicat-": "problem of overfitting. Thus,\nthe\nensemble\nlearning method"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "scorei = softmax(producti)",
          "Note that\nthe output\ninferences are probability values indicat-": ""
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "",
          "Note that\nthe output\ninferences are probability values indicat-": "and the decision tree learning algorithm can complement each"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "(2)\nexp(producti)",
          "Note that\nthe output\ninferences are probability values indicat-": ""
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "∈ R.\n=",
          "Note that\nthe output\ninferences are probability values indicat-": "other and are a perfect pair."
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "(cid:80)m",
          "Note that\nthe output\ninferences are probability values indicat-": ""
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "j=1 exp(productj)",
          "Note that\nthe output\ninferences are probability values indicat-": "There\nare\n58\nparticipants\nin\nthe ASCERTAIN dataset."
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "To embed the personality attention to bagging model,\nthe",
          "Note that\nthe output\ninferences are probability values indicat-": "However, due to the quality of\nthe physiological signals,\nten"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "inferences are multiplied with scores one by one and summed",
          "Note that\nthe output\ninferences are probability values indicat-": "subjects with relatively low data quality were removed from"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "up to yield the final prediction:",
          "Note that\nthe output\ninferences are probability values indicat-": "the study. Thus, 48 weak classifiers were trained. For\ntesting,"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "",
          "Note that\nthe output\ninferences are probability values indicat-": "we set each subject as the testing set at a time, excluded this"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "",
          "Note that\nthe output\ninferences are probability values indicat-": "particular\ntest subject\nfrom the weak classifiers, and used the"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "N(cid:88) i\nF inalP rediction = BinaryStep(\n(3)\nscorei × Ii)",
          "Note that\nthe output\ninferences are probability values indicat-": ""
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "",
          "Note that\nthe output\ninferences are probability values indicat-": "other 47 weak classifiers to infer the test subject. This process"
        },
        {
          "for\ntheir big-five personality traits. Subjects were\ninstructed": "=1",
          "Note that\nthe output\ninferences are probability values indicat-": ""
        }
      ],
      "page": 3
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "reported the averaged system’s performance from all subjects."
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "To\nassess\nthe\neffectiveness\nof\nour\nnovel\nframework, we"
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "conducted\na\ncomprehensive\nevaluation\nby\nreplicating\nthree"
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "seminal studies that tackled emotion recognition, both with and"
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "without\nthe incorporation of personality traits.\nIn contrast\nto"
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "these established works, our proposed framework was imple-"
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "mented and compared against their methodologies. In the study"
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "by Santamaria et al. [19], a convolutional neural network was"
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "employed to classify arousal and valence using the AMIGOS"
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "dataset. Their deep learning model demonstrated substantial"
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "efficacy in emotion recognition through physiological signals"
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "in\nthe\nabsence\nof\npersonality\nintegration. Shao\net\nal.\n[17]"
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "pursued a distinctive approach by employing a hyperedge algo-"
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "rithm to establish connections between personality attributes,"
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "physiological\nsignals,\nand emotions. Their work highlighted"
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "the\npotential\nsynergy\nbetween\nthese\nfacets,\nshowcasing\nthe"
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "intricate\ninterplay between personality and emotional\nstates."
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "In a\nsimilar vein, Tian et\nal.\n[18]\nleveraged K-means\nclus-"
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "tering\nto\ncategorize\nparticipants\nbased\non\ntheir\npersonality"
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": ""
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "traits. Subsequently, deep neural networks were\ntrained for"
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "each\npersonality\nsubgroup. Our\nframework\nreproduced\nand"
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "extended their signal processing, feature extraction, and model"
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": ""
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "deployment procedures on the ASCERTAIN dataset, utilizing"
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": ""
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "the same participant cohort. The outcomes of our endeavors"
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": ""
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "are meticulously presented in Table\nI, underscoring the\nad-"
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": ""
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "vancements brought about by our proposed framework."
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": ""
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "The results showed our proposed framework overperformed"
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": ""
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "existing studies. Our proposed framework achieved 77.1% and"
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": ""
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "76.9% accuracy on arousal\nand valence\ntasks,\nrespectively,"
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": ""
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "which overperformed 6% and 4% compared with the best\nre-"
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": ""
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "sults from baseline studies. Fig. 2 shows the receiver operating"
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": ""
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "characteristic\ncurve of APEX working on the Arousal\ntask"
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": ""
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "from ASCERTAIN dataset. As we have 48 different classifier"
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": ""
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "sets and individual testing sets, 48 ROC curves were produced."
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": ""
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "We averaged the ROC curves by the y-axis. All ROC curves"
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": ""
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "lay within the gray zone and the boundaries represent\nthe best"
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": ""
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "and worst\ntest cases of\nthe area under curves equal\nto 0.78"
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": ""
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "and 0.89,\nrespectively."
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": ""
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "IV. DISCUSSION"
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": ""
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "This\nstudy\nproposes\na\nnovel\nframework\nthat\nintegrates"
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "personality\nscore\ninto\nensemble\nlearning\nso\nthat when\nin-"
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "ferencing,\nthe decision pay more\nattention to subjects with"
        },
        {
          "was\nrepeated\n48\ntimes\nfor\nall\nsubjects\nin\nthe\ndataset. We": "similar\npersonality.\nThe APEX framework\nhas\na\ncore\nof"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "TABLE I": "COMPARISON OF APEX AND EXISTING STUDIES PERFORMANCE"
        },
        {
          "TABLE I": "Model"
        },
        {
          "TABLE I": ""
        },
        {
          "TABLE I": "SVM/NB (no personality)"
        },
        {
          "TABLE I": ""
        },
        {
          "TABLE I": ""
        },
        {
          "TABLE I": "Hypergraph Neural Network"
        },
        {
          "TABLE I": ""
        },
        {
          "TABLE I": ""
        },
        {
          "TABLE I": "K-mean and Deep Neural Networks"
        },
        {
          "TABLE I": ""
        },
        {
          "TABLE I": ""
        },
        {
          "TABLE I": "Attention-based Bagging"
        },
        {
          "TABLE I": ""
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "GSR": "VAR\nVariance",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": ""
        },
        {
          "GSR": "",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": "and Biomedicine (BIBM), pages 1125–1131.\nIEEE, 2023."
        },
        {
          "GSR": "MeanFreq\nMean Frequency",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": ""
        },
        {
          "GSR": "",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": "[7] Ruijie Fang, Ruoyu Zhang, Sayed M Hosseini, Mahya Faghih, Soheil"
        },
        {
          "GSR": "",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": "Rafatirad,\nSetareh Rafatirad,\nand Houman Homayoun.\nPain\nlevel"
        },
        {
          "GSR": "",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": "modeling of intensive care unit patients with machine learning methods:"
        },
        {
          "GSR": "specific\nsubject with\nthe\n0.99\nscore. This\nis\nnot\nthe\nideal",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": "An effective congeneric clustering-based approach.\nIn 2022 4th Interna-"
        },
        {
          "GSR": "",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": "tional Conference on Intelligent Medicine and Image Processing, pages"
        },
        {
          "GSR": "case, so a normalization process is added to prevent\nthe such",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": ""
        },
        {
          "GSR": "",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": "89–95, 2022."
        },
        {
          "GSR": "phenomenon.",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": "[8] Ruoyu Zhang, Ruijie Fang, Zhichao Zhang, Elahe Hosseini, Mahdi"
        },
        {
          "GSR": "In the proposed study, decision tree is selected as the weak",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": "Orooji, Houman Homayoun, and Gozde Goncu-Berk. Short: Real-time"
        },
        {
          "GSR": "",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": "bladder monitoring by bio-impedance\nanalysis\nto aid urinary inconti-"
        },
        {
          "GSR": "classifier\nin\nthe\nframework\nfrom four\nclassifiers. However,",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": ""
        },
        {
          "GSR": "",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": "nence. In Proceedings of the 8th ACM/IEEE International Conference on"
        },
        {
          "GSR": "other models can also be embedded such as linear classifiers,",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": "Connected Health: Applications, Systems and Engineering Technologies,"
        },
        {
          "GSR": "shallow neoral networks, etc. They may have different perfor-",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": "pages 138–142, 2023."
        },
        {
          "GSR": "",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": "[9]\nLin Shu,\nJinyan Xie, Mingyue Yang, Ziyi Li, Zhenqi Li, Dan Liao,"
        },
        {
          "GSR": "mances on different problems consider\nthe type of data,\nthe",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": ""
        },
        {
          "GSR": "",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": "Xiangmin Xu, and Xinyi Yang. A review of emotion recognition using"
        },
        {
          "GSR": "complexity of\nrelationships and the potential challenges and",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": "physiological signals. Sensors, 18(7):2074, 2018."
        },
        {
          "GSR": "computation time requirments.",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": "[10] Ruoyu Zhang, Ruijie Fang, Chongzhou Fang, Houman Homayoun, and"
        },
        {
          "GSR": "",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": "Gozde Goncu Berk. Privee: A wearable for real-time bladder monitoring"
        },
        {
          "GSR": "To extend this study, other\nfactors that may influence emo-",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": ""
        },
        {
          "GSR": "",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": "the 2023 ACM International Joint\nsystem.\nIn Adjunct Proceedings of"
        },
        {
          "GSR": "tion recognition other\nthan personality can be taken into con-",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": "Conference on Pervasive and Ubiquitous Computing & the 2023 ACM"
        },
        {
          "GSR": "",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": "International Symposium on Wearable Computing, pages 291–295, 2023."
        },
        {
          "GSR": "sideration,\nfor example, demographic information. Exploring",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": ""
        },
        {
          "GSR": "",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": "[11] Ruijie Fang, Ruoyu Zhang, Elahe Hosseini, Anna M Parenteau, Sally"
        },
        {
          "GSR": "more factors and finding out the influential group of factors can",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": ""
        },
        {
          "GSR": "",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": "Hang,\nSetareh Rafatirad, Camelia\nE Hostinar, Mahdi Orooji,\nand"
        },
        {
          "GSR": "lead emotion recognition to a more personalized and accurate",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": "Houman Homayoun.\nPrevent over-fitting and redundancy in physio-"
        },
        {
          "GSR": "",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": "logical signal analyses for stress detection.\nIn 2022 IEEE International"
        },
        {
          "GSR": "stage.\nIn addition, other algorithms can be used. This could",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": ""
        },
        {
          "GSR": "",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": "Conference on Bioinformatics and Biomedicine\n(BIBM), pages 2585–"
        },
        {
          "GSR": "include modifying the training process of neural networks by",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": ""
        },
        {
          "GSR": "",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": "2588.\nIEEE, 2022."
        },
        {
          "GSR": "letting fewer\nscore\nsubjects only contribute\nto the first\nfew",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": "[12] Ruijie Fang, Ruoyu Zhang, Elahe Hosseini, Chongzhou Fang, Setareh"
        },
        {
          "GSR": "",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": "Rafatirad, and Houman Homayoun.\nIntroducing an open-source python"
        },
        {
          "GSR": "epochs.",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": ""
        },
        {
          "GSR": "",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": "toolkit\nfor machine\nlearning\nresearch\nin\nphysiological\nsignal\nbased"
        },
        {
          "GSR": "",
          "health care.\nIn 2023 IEEE International Conference on Bioinformatics": "affective computing.\nIn 2023 IEEE International Conference on Bioin-"
        }
      ],
      "page": 5
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "TABLE II": "FEATURE LIST",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "IEEE, 2022."
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "[4]\nJianhua Zhang, Zhong Yin, Peng Chen, and Stefano Nichele. Emotion"
        },
        {
          "TABLE II": "Category\nFeature\nDescription",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "recognition using multi-modal data and machine learning techniques: A"
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "tutorial and review.\nInformation Fusion, 59:103–126, 2020."
        },
        {
          "TABLE II": "MAV\nMean Absolute Value",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "[5] Ruijie Fang, Ruoyu Zhang, Elahe Hosseini, Anna M Parenteau, Sally"
        },
        {
          "TABLE II": "Range\nRange",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "Hang,\nSetareh Rafatirad, Camelia\nE Hostinar, Mahdi Orooji,\nand"
        },
        {
          "TABLE II": "SDNN\nStandard deviation of NN intervals",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "HRV",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "Houman Homayoun.\nTowards\ngeneralized ml model\nin\nautomated"
        },
        {
          "TABLE II": "Root mean square of successive",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "RMSSD",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "physiological\narousal\ncomputing: A transfer\nlearning-based\ndomain"
        },
        {
          "TABLE II": "RR interval differences",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "generalization approach.\nIn 2022 IEEE International Conference on"
        },
        {
          "TABLE II": "Percentage of successive RR intervals that",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "pNN50",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "Bioinformatics and Biomedicine (BIBM), pages 2577–2584. IEEE, 2022."
        },
        {
          "TABLE II": "differ by more than 50 ms",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "[6]\nElahe Hosseini, Ruijie\nFang, Ruoyu Zhang,\nSetareh Rafatirad,\nand"
        },
        {
          "TABLE II": "TINN\nBaseline width of\nthe RR interval histogram",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "Houman Homayoun. Emotion and stress recognition utilizing galvanic"
        },
        {
          "TABLE II": "MAV\nMean Absolute Value",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "skin response and wearable technology: A real-time approach for mental"
        },
        {
          "TABLE II": "P2P\nPeak to Peak Amplitude",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "GSR",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "health care.\nIn 2023 IEEE International Conference on Bioinformatics"
        },
        {
          "TABLE II": "VAR\nVariance",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "and Biomedicine (BIBM), pages 1125–1131.\nIEEE, 2023."
        },
        {
          "TABLE II": "MeanFreq\nMean Frequency",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "[7] Ruijie Fang, Ruoyu Zhang, Sayed M Hosseini, Mahya Faghih, Soheil"
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "Rafatirad,\nSetareh Rafatirad,\nand Houman Homayoun.\nPain\nlevel"
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "modeling of intensive care unit patients with machine learning methods:"
        },
        {
          "TABLE II": "specific\nsubject with\nthe\n0.99\nscore. This\nis\nnot\nthe\nideal",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "An effective congeneric clustering-based approach.\nIn 2022 4th Interna-"
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "tional Conference on Intelligent Medicine and Image Processing, pages"
        },
        {
          "TABLE II": "case, so a normalization process is added to prevent\nthe such",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "89–95, 2022."
        },
        {
          "TABLE II": "phenomenon.",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "[8] Ruoyu Zhang, Ruijie Fang, Zhichao Zhang, Elahe Hosseini, Mahdi"
        },
        {
          "TABLE II": "In the proposed study, decision tree is selected as the weak",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "Orooji, Houman Homayoun, and Gozde Goncu-Berk. Short: Real-time"
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "bladder monitoring by bio-impedance\nanalysis\nto aid urinary inconti-"
        },
        {
          "TABLE II": "classifier\nin\nthe\nframework\nfrom four\nclassifiers. However,",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "nence. In Proceedings of the 8th ACM/IEEE International Conference on"
        },
        {
          "TABLE II": "other models can also be embedded such as linear classifiers,",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "Connected Health: Applications, Systems and Engineering Technologies,"
        },
        {
          "TABLE II": "shallow neoral networks, etc. They may have different perfor-",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "pages 138–142, 2023."
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "[9]\nLin Shu,\nJinyan Xie, Mingyue Yang, Ziyi Li, Zhenqi Li, Dan Liao,"
        },
        {
          "TABLE II": "mances on different problems consider\nthe type of data,\nthe",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "Xiangmin Xu, and Xinyi Yang. A review of emotion recognition using"
        },
        {
          "TABLE II": "complexity of\nrelationships and the potential challenges and",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "physiological signals. Sensors, 18(7):2074, 2018."
        },
        {
          "TABLE II": "computation time requirments.",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "[10] Ruoyu Zhang, Ruijie Fang, Chongzhou Fang, Houman Homayoun, and"
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "Gozde Goncu Berk. Privee: A wearable for real-time bladder monitoring"
        },
        {
          "TABLE II": "To extend this study, other\nfactors that may influence emo-",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "the 2023 ACM International Joint\nsystem.\nIn Adjunct Proceedings of"
        },
        {
          "TABLE II": "tion recognition other\nthan personality can be taken into con-",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "Conference on Pervasive and Ubiquitous Computing & the 2023 ACM"
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "International Symposium on Wearable Computing, pages 291–295, 2023."
        },
        {
          "TABLE II": "sideration,\nfor example, demographic information. Exploring",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "[11] Ruijie Fang, Ruoyu Zhang, Elahe Hosseini, Anna M Parenteau, Sally"
        },
        {
          "TABLE II": "more factors and finding out the influential group of factors can",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "Hang,\nSetareh Rafatirad, Camelia\nE Hostinar, Mahdi Orooji,\nand"
        },
        {
          "TABLE II": "lead emotion recognition to a more personalized and accurate",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "Houman Homayoun.\nPrevent over-fitting and redundancy in physio-"
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "logical signal analyses for stress detection.\nIn 2022 IEEE International"
        },
        {
          "TABLE II": "stage.\nIn addition, other algorithms can be used. This could",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "Conference on Bioinformatics and Biomedicine\n(BIBM), pages 2585–"
        },
        {
          "TABLE II": "include modifying the training process of neural networks by",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "2588.\nIEEE, 2022."
        },
        {
          "TABLE II": "letting fewer\nscore\nsubjects only contribute\nto the first\nfew",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "[12] Ruijie Fang, Ruoyu Zhang, Elahe Hosseini, Chongzhou Fang, Setareh"
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "Rafatirad, and Houman Homayoun.\nIntroducing an open-source python"
        },
        {
          "TABLE II": "epochs.",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "toolkit\nfor machine\nlearning\nresearch\nin\nphysiological\nsignal\nbased"
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "affective computing.\nIn 2023 IEEE International Conference on Bioin-"
        },
        {
          "TABLE II": "V. CONCLUSION",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "formatics and Biomedicine (BIBM), pages 1890–1894.\nIEEE, 2023."
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "[13] Ramanathan\nSubramanian,\nJulia Wache, Mojtaba Khomami Abadi,"
        },
        {
          "TABLE II": "This\nstudy proposes\nthe APEX framework that\ncombines",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "Radu L Vieriu, Stefan Winkler, and Nicu Sebe. Ascertain: Emotion and"
        },
        {
          "TABLE II": "attention mechanism and ensemble learning to perform per-",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "IEEE Transactions\npersonality recognition using commercial\nsensors."
        },
        {
          "TABLE II": "sonalized\nemotion\nrecognition.\nIn\nthe\nproposed\nframework,",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "on Affective Computing, 9(2):147–160, 2016."
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "[14] Mohammad\nSoleymani,\nJeroen Lichtenauer, Thierry\nPun,\nand Maja"
        },
        {
          "TABLE II": "personality\nscores\nare\ncalculated\nand\nused\nto\nre-weigh\nthe",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "Pantic.\nA multimodal\ndatabase\nfor\naffect\nrecognition\nand\nimplicit"
        },
        {
          "TABLE II": "outputs from weak classifiers. We conducted experiments on",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "tagging.\nIEEE transactions on affective computing, 3(1):42–55, 2011."
        },
        {
          "TABLE II": "48 subjects from ASCERTAIN dataset, and the results showed",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "[15] Hans J Eysenck. Biological dimensions of personality. 1990."
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "[16]\nFaruk Enes O˘guz, Ahmet Alkan, and Thorsten Sch¨oler. Emotion detec-"
        },
        {
          "TABLE II": "that\nthe proposed framework performed better than the current",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "tion from ecg signals with different\nlearning algorithms and automated"
        },
        {
          "TABLE II": "state-of-the-art\nstudies. We obtained classification accuracies",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "Signal,\nfeature engineering.\nImage and Video Processing, pages 1–9,"
        },
        {
          "TABLE II": "for valence and arousal were 76.9% and 77.1%,\nrespectively.",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "2023."
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "[17]\nJingzhi Shao,\nJunjie Zhu, Yuxuan Wei, Yifan Feng,\nand Xibin Zhao."
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "Emotion recognition by edge-weighted hypergraph neural network.\nIn"
        },
        {
          "TABLE II": "REFERENCES",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "2019 IEEE International Conference on Image Processing (ICIP), pages"
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "2144–2148.\nIEEE, 2019."
        },
        {
          "TABLE II": "[1] Andrius Dzedzickis, Art¯uras Kaklauskas, and Vytautas Bucinskas. Hu-",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "[18]\nZhihang Tian, Dongmin Huang, Sijin Zhou, Zhidan Zhao, and Dazhi"
        },
        {
          "TABLE II": "man emotion recognition: Review of\nsensors\nand methods.\nSensors,",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "Jiang.\nPersonality\nfirst\nin\nemotion:\na\ndeep\nneural\nnetwork\nbased"
        },
        {
          "TABLE II": "20(3):592, 2020.",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "on\nelectroencephalogram channel\nattention\nfor\ncross-subject\nemotion"
        },
        {
          "TABLE II": "[2] W Michael Vanderlind, Yael Millgram, Arielle R Baskin-Sommers,",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "recognition. Royal Society open science, 8(8):201976, 2021."
        },
        {
          "TABLE II": "Margaret S Clark, and Jutta Joormann. Understanding positive emotion",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "[19]\nLuz Santamaria-Granados, Mario Munoz-Organero, Gustavo Ramirez-"
        },
        {
          "TABLE II": "deficits in depression: From emotion preferences to emotion regulation.",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "Gonzalez, Enas Abdulhay, and NJIA Arunkumar. Using deep convolu-"
        },
        {
          "TABLE II": "Clinical Psychology Review, 76:101826, 2020.",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "tional neural network for emotion detection on a physiological signals"
        },
        {
          "TABLE II": "[3] Ruijie Fang, Ruoyu Zhang, Elahe Hosseini, Mahdi Orooji, Houman",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": "dataset\n(amigos).\nIEEE Access, 7:57–67, 2018."
        },
        {
          "TABLE II": "Homayoun, Sayed Mohammad Hosseini, Mahya Faghih, Soheil Rafati-",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "rad, and Setareh Rafatirad. Atlas: An adaptive transfer\nlearning based",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "pain\nassessment\nsystem: A real\nlife\nunsupervised\npain\nassessment",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        },
        {
          "TABLE II": "International Conference of\nthe IEEE\nsolution.\nIn 2022 44th Annual",
          "Engineering in Medicine & Biology Society (EMBC), pages 1331–1337.": ""
        }
      ],
      "page": 5
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Human emotion recognition: Review of sensors and methods",
      "authors": [
        "Andrius Dzedzickis",
        "Artūras Kaklauskas",
        "Vytautas Bucinskas"
      ],
      "year": "2020",
      "venue": "Sensors"
    },
    {
      "citation_id": "2",
      "title": "Understanding positive emotion deficits in depression: From emotion preferences to emotion regulation",
      "authors": [
        "Yael Michael Vanderlind",
        "Arielle Millgram",
        "Margaret Baskin-Sommers",
        "Jutta Clark",
        "Joormann"
      ],
      "year": "2020",
      "venue": "Clinical Psychology Review"
    },
    {
      "citation_id": "3",
      "title": "Atlas: An adaptive transfer learning based pain assessment system: A real life unsupervised pain assessment solution",
      "authors": [
        "Ruijie Fang",
        "Ruoyu Zhang",
        "Elahe Hosseini",
        "Mahdi Orooji",
        "Houman Homayoun",
        "Mohammad Sayed",
        "Mahya Hosseini",
        "Faghih"
      ],
      "year": "2022",
      "venue": "2022 44th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)"
    },
    {
      "citation_id": "4",
      "title": "Emotion recognition using multi-modal data and machine learning techniques: A tutorial and review",
      "authors": [
        "Jianhua Zhang",
        "Zhong Yin",
        "Peng Chen",
        "Stefano Nichele"
      ],
      "year": "2020",
      "venue": "Information Fusion"
    },
    {
      "citation_id": "5",
      "title": "Towards generalized ml model in automated physiological arousal computing: A transfer learning-based domain generalization approach",
      "authors": [
        "Ruijie Fang",
        "Ruoyu Zhang",
        "Elahe Hosseini",
        "Anna Parenteau",
        "Sally Hang",
        "Setareh Rafatirad",
        "Camelia Hostinar",
        "Mahdi Orooji",
        "Houman Homayoun"
      ],
      "year": "2022",
      "venue": "2022 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)"
    },
    {
      "citation_id": "6",
      "title": "Emotion and stress recognition utilizing galvanic skin response and wearable technology: A real-time approach for mental health care",
      "authors": [
        "Elahe Hosseini",
        "Ruijie Fang",
        "Ruoyu Zhang",
        "Setareh Rafatirad",
        "Houman Homayoun"
      ],
      "year": "2023",
      "venue": "2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)"
    },
    {
      "citation_id": "7",
      "title": "Pain level modeling of intensive care unit patients with machine learning methods: An effective congeneric clustering-based approach",
      "authors": [
        "Ruijie Fang",
        "Ruoyu Zhang",
        "M Sayed",
        "Mahya Hosseini",
        "Soheil Faghih",
        "Setareh Rafatirad",
        "Houman Rafatirad",
        "Homayoun"
      ],
      "year": "2022",
      "venue": "2022 4th International Conference on Intelligent Medicine and Image Processing"
    },
    {
      "citation_id": "8",
      "title": "Real-time bladder monitoring by bio-impedance analysis to aid urinary incontinence",
      "authors": [
        "Ruoyu Zhang",
        "Ruijie Fang",
        "Zhichao Zhang",
        "Elahe Hosseini",
        "Mahdi Orooji",
        "Houman Homayoun",
        "Gozde Goncu-Berk",
        "Short"
      ],
      "year": "2023",
      "venue": "Proceedings of the 8th ACM/IEEE International Conference on Connected Health: Applications, Systems and Engineering Technologies"
    },
    {
      "citation_id": "9",
      "title": "A review of emotion recognition using physiological signals",
      "authors": [
        "Lin Shu",
        "Jinyan Xie",
        "Mingyue Yang",
        "Ziyi Li",
        "Zhenqi Li",
        "Dan Liao",
        "Xiangmin Xu",
        "Xinyi Yang"
      ],
      "year": "2018",
      "venue": "Sensors"
    },
    {
      "citation_id": "10",
      "title": "Privee: A wearable for real-time bladder monitoring system",
      "authors": [
        "Ruoyu Zhang",
        "Ruijie Fang",
        "Chongzhou Fang",
        "Houman Homayoun",
        "Gozde Goncu"
      ],
      "year": "2023",
      "venue": "Adjunct Proceedings of the 2023 ACM International Joint Conference on Pervasive and Ubiquitous Computing & the 2023 ACM International Symposium on Wearable Computing"
    },
    {
      "citation_id": "11",
      "title": "Prevent over-fitting and redundancy in physiological signal analyses for stress detection",
      "authors": [
        "Ruijie Fang",
        "Ruoyu Zhang",
        "Elahe Hosseini",
        "Anna Parenteau",
        "Sally Hang",
        "Setareh Rafatirad",
        "Camelia Hostinar",
        "Mahdi Orooji",
        "Houman Homayoun"
      ],
      "year": "2022",
      "venue": "2022 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)"
    },
    {
      "citation_id": "12",
      "title": "Introducing an open-source python toolkit for machine learning research in physiological signal based affective computing",
      "authors": [
        "Ruijie Fang",
        "Ruoyu Zhang",
        "Elahe Hosseini",
        "Chongzhou Fang",
        "Setareh Rafatirad",
        "Houman Homayoun"
      ],
      "year": "2023",
      "venue": "2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)"
    },
    {
      "citation_id": "13",
      "title": "Ascertain: Emotion and personality recognition using commercial sensors",
      "authors": [
        "Ramanathan Subramanian",
        "Julia Wache",
        "Mojtaba Khomami Abadi",
        "L Radu",
        "Stefan Vieriu",
        "Nicu Winkler",
        "Sebe"
      ],
      "year": "2016",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "14",
      "title": "A multimodal database for affect recognition and implicit tagging",
      "authors": [
        "Mohammad Soleymani",
        "Jeroen Lichtenauer",
        "Maja Thierry Pun",
        "Pantic"
      ],
      "year": "2011",
      "venue": "IEEE transactions on affective computing"
    },
    {
      "citation_id": "15",
      "title": "Biological dimensions of personality",
      "authors": [
        "J Hans",
        "Eysenck"
      ],
      "year": "1990",
      "venue": "Biological dimensions of personality"
    },
    {
      "citation_id": "16",
      "title": "Emotion detection from ecg signals with different learning algorithms and automated feature engineering. Signal, Image and Video Processing",
      "authors": [
        "Enes Faruk",
        "Ahmet Oguz",
        "Thorsten Alkan",
        "Schöler"
      ],
      "year": "2023",
      "venue": "Emotion detection from ecg signals with different learning algorithms and automated feature engineering. Signal, Image and Video Processing"
    },
    {
      "citation_id": "17",
      "title": "Emotion recognition by edge-weighted hypergraph neural network",
      "authors": [
        "Jingzhi Shao",
        "Junjie Zhu",
        "Yuxuan Wei",
        "Yifan Feng",
        "Xibin Zhao"
      ],
      "year": "2019",
      "venue": "2019 IEEE International Conference on Image Processing (ICIP)"
    },
    {
      "citation_id": "18",
      "title": "Personality first in emotion: a deep neural network based on electroencephalogram channel attention for cross-subject emotion recognition",
      "authors": [
        "Zhihang Tian",
        "Dongmin Huang",
        "Sijin Zhou",
        "Zhidan Zhao",
        "Dazhi Jiang"
      ],
      "year": "2021",
      "venue": "Royal Society open science"
    },
    {
      "citation_id": "19",
      "title": "Using deep convolutional neural network for emotion detection on a physiological signals dataset (amigos)",
      "authors": [
        "Luz Santamaria-Granados",
        "Mario Munoz-Organero",
        "Gustavo Ramirez-Gonzalez",
        "Enas Abdulhay",
        "Arunkumar"
      ],
      "year": "2018",
      "venue": "IEEE Access"
    }
  ]
}