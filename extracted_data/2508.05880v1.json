{
  "paper_id": "2508.05880v1",
  "title": "Do Machines Think Emotionally? Cognitive Appraisal Analysis Of Large Language Models",
  "published": "2025-08-07T22:19:15Z",
  "authors": [
    "Sree Bhattacharyya",
    "Lucas Craig",
    "Tharun Dilliraj",
    "Jia Li",
    "James Z. Wang"
  ],
  "keywords": [
    "Main Categories Pleasantness Attentional Activity Control Certainty Goal-Path Obstacle Legitimacy Responsibility Anticipated Effort Dimensions pleasantness",
    "enjoyment attention",
    "consideration self-control",
    "other-control",
    "situational-control certainty problem",
    "obstacle legitimacy-fair",
    "legitimacy-cheated self-responsibility",
    "other-responsibility effort",
    "exertion"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Affective Computing has been established as a crucial field of inquiry to advance the holistic development of Artificial Intelligence (AI) systems. Foundation models-especially Large Language Models (LLMs)-have been evaluated, trained, or instruction-tuned in several past works, to become better predictors or generators of emotion. Most of these studies, however, approach emotion-related tasks in a supervised manner, assessing or training the capabilities of LLMs using discrete emotion labels associated with stimuli (e.g., text, images, video, audio). Evaluation studies, in particular, have often been limited to standard and superficial emotion-related tasks, such as the recognition of evoked or expressed emotions. In this paper, we move beyond surface-level emotion tasks to investigate how LLMs reason about emotions through cognitive dimensions. Drawing from cognitive appraisal theory, we examine whether LLMs produce coherent and plausible cognitive reasoning when reasoning about emotionally charged stimuli. We introduce a large-scale benchmark on Cognitive Reasoning for Emotions -CoRE -to evaluate internal cognitive structures implicitly used by LLMs for emotional reasoning. Through a plethora of evaluation experiments and analysis, we seek to answer: (a) Are models more likely to implicitly rely on specific cognitive appraisal dimensions?, (b) What cognitive dimensions are important for characterizing specific emotions?, and, (c) Can the internal representations of different emotion categories in LLMs be interpreted through cognitive appraisal dimensions? Our results and analyses reveal diverse reasoning patterns across different LLMs. Our benchmark and code will be made publicly available.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Introduction",
      "text": "Emotional Intelligence forms an integral aspect of human life. Equipping artificial intelligence systems with the ability to process, understand, and respond in an emotionally coherent manner has profound implications for user-facing systems  (Kołakowska et al. 2014; Wang et al. 2023; Ivanović et al. 2014; Yellapantula and Ayachit 2019) . With the growing popularity of LLMs and their deployment in everyday settings, it has become essential that they not only recognize human emotions but also behave in an emotionally coherent manner themselves, simulating aspects of human cognition. This requires LLMs to operate anthropomorphically  (Reinecke et al. 2025) . Anthropomorphic LLMs have found several applications, such as acting as simulators for human subject studies  (Aher, Arriaga, and Kalai 2023; Mannekote et al. 2025; Lin 2025; Anthis et al. 2025) , reproducing or comprehending complex aspects of human intelligence  (Turing 2022) , and effective conversational agents  (Giudici et al. 2025; Wei, Li, and Ding 2025) .\n\nIn the space of affective computing, creating systems capable of true emotional reasoning necessitates moving beyond surface-level tasks like predicting emotions from given stimuli  (Liu et al. 2024; Bhattacharyya and Wang 2025) . Models trained solely for such tasks, supervised with paired examples of emotional stimuli and corresponding desired outputs, have limited practical utility. Such systems often fail to generalize to novel, ambiguous, or culturally nuanced scenarios where emotional responses depend on an agent's interpretation of goals, norms, and responsibilities  (Ahmad et al. 2024) . Advancing toward emotionally intelligent systems thus requires evaluating whether models can engage in structured, interpretable reasoning that mirrors human affective cognition. To address this challenge, we leverage the cognitive appraisal theory of emotions-a foundational framework in psychology explaining how emotions are elicited and differentiated  (Smith and Kirby 2010) .\n\nAppraisal theory of emotions suggests that emotional experiences vary depending on how individuals appraise aspects of a given situation, such as goal-congruence, selfresponsibility, or pleasantness  (Smith and Ellsworth 1985; Frijda, Kuipers, and Ter Schure 1989; Scherer 2014) . Using this  (Smith and Ellsworth 1985) , we create a large-scale benchmark, CoRE, Cognitive, Reasoning for Emotions, to systematically study how LLMs inherently form cognitive understanding about emotions. Though some previous studies have leveraged appraisal theory (or similar frameworks  (Clore and Ortony 2013) ) for emotional reasoning  (Tak and Gratch 2023; Tak, Gratch, and Scherer 2025; Yongsatianchot, Torshizi, and Marsella 2023; Broekens et al. 2023) , there has remained a notable lack of large-scale systematic analysis of internal appraisal structures implicitly constructed by LLMs. For example,  Tak and Gratch (2023) ;  Tak, Gratch, and Scherer (2025) ;  Broekens et al. (2023)  focus on the proprietary GPT models, and on limited, commonly used appraisal dimensions such as Valence, Arousal, and Dominance  (Broekens et al. 2023) . Besides, all past studies focus on using LLMs to predict emotions and appraisals for other agents  (other-appraisal) . While other-appraisal has several applications, such as in perspective-taking, it inherently requires the model to infer the emotional state of an external agent-potentially introducing confounds related to implicit assumptions or biases about that agent's attributes (e.g., demographics, personality, or context). As a result, such tasks may reflect social priors or learned stereotypes rather than the model's underlying emotional reasoning processes  (Gupta et al. 2024; Dudy et al. 2025) . Consequently, otherappraisal does not offer a direct window into the model's internal emotion representations or its implicit cognitive appraisal structure. Besides, research in affective computing has also highlighted the significant difference between selfexpression of emotion and prediction of the same by a third party  (Li et al. 2025) . Therefore, in this paper, we present the first benchmark and large-scale analysis of cognitive selfappraisals for emotions, asking: How do LLMs internally represent emotions through cognitive dimensions? Our key contributions are:\n\n• We introduce CoRE, a large-scale benchmark for evaluating LLMs' cognitive reasoning in emotion-laden scenarios. Covering 15 emotion categories, 16 appraisal dimensions, and ≈ 20 scenarios per emotion, CoRE comprises 4928 prompts and over 34,000 model-generated appraisals across 7 open-source and proprietary models. • We develop a rigorous experimental framework to probe LLMs' implicit appraisal strategies, the relevance of specific dimensions for individual emotions, and both intraand inter-model variation in emotional representations via cognitive dimensions. • We uncover both shared and divergent appraisal structures across LLMs. While models largely preserve interrelationships between different emotions, they differ in how they appraise individual emotions, revealing the absence of a universal or transferable representation of emotions.\n\nWe plan to release all of the data and analysis code publicly, with a dedicated benchmarking platform for cognitive appraisals of emotions.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Related Work",
      "text": "LLMs are increasingly evaluated on a range of abstract reasoning tasks, such as social, emotional, cultural, or cognitive intelligence. Improving LLMs' capabilities in such subjective, human-centered domains has broad implications: from empathetic dialogue systems  (Bai et al. 2025) , to personalizing content or user recommendations in social networks  (Bhattacharyya, Yang, and Wang 2024) . Advancing performance on these inherently subjective tasks-where no single correct answer may exist-is also a key milestone toward modeling artificial general intelligence. Cognitive Reasoning. Several recent studies evaluate LLMs for cognitive reasoning tasks. This includes evaluating cognitive biases in diverse settings  (Malberg et al. 2025; Coda-Forno et al. 2024) , causal reasoning  (Binz and Schulz 2023) , critical thinking using multimodality  (Pandya et al. 2025) , often through novel evaluation frameworks and metrics  (de Langis et al. 2025) . This has been a part of the broader wave of research that transfers human studies in psychology and social studies to LLMs  (Lampinen et al. 2024; Binz and Schulz 2023; Echterhoff et al. 2024; Hosseini and Khanna 2025) .\n\nEmotional Reasoning. Several recent studies have also focused specifically on evaluating emotion reasoning capabilities in large foundation models  (Liu et al. 2024; Wang et al. 2023; Bhattacharyya and Wang 2025; Sabour et al. 2024) , investigating high-level standard emotion understanding tasks, such as direct prediction of target emotion labels, predicting emotion intensity, or rating emotions on the standard Valence-Arousal-Dominance (VAD) scale  (Tak and Gratch 2023) . Although a few recent works use more in-depth or application-oriented tasks for evaluation  (Sabour et al. 2024) , studying the underlying cognition for emotional reasoning has remained significantly underexplored. Some recent research has explored the capabilities of LLMs to predict appraisals for others (other-appraisal)  (Yeo and Jaidka 2025) , but has been limited in terms of the number of models studied -  Tak and Gratch (2023) ;  Tak, Gratch, and Scherer (2025)  study the proprietary GPT models -or the appraisal dimensions studied, or conduct task-specific analysis, lacking systematic, comprehensive exploration of the relationship between different appraisal dimensions and emotions.\n\nTo the best of our knowledge, we present the first largescale benchmark and evaluation study for self-appraisal of LLMs: studying broad alignment with theoretical expectations, and inherent world models for emotional reasoning in LLMs.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Core: A Benchmark For Cognitive",
      "text": "Reasoning for Emotions\n\nIn this section, we describe the data and evaluation setup used for our benchmark.\n\nDataset. Inspired by the landmark psychological study by  Smith and Ellsworth (1985) , we construct a dataset of emotion-related scenarios designed to elicit cognitive self-appraisals across 15 emotion categories: Happiness, Pride, Hope, Interest, Surprise, Challenge, Boredom, Disgust, Contempt, Shame, Guilt, Anger, Frustration, Fear, and Sadness. Each scenario is paired with 16 appraisal questions targeting 8 core cognitive dimensions (listed in Table  1 ).\n\nTo create the scenarios, we use a three-stage process: (1) crafting 2-3 seed examples per emotion for emotionallyrich scenarios from daily life; (2) generating 30 scenarios per category via few-shot prompting with GPT-4o  (Hurst et al. 2024) ; and (3) manually filtering for ambiguity, specificity, and demographic bias. This results in 308 high-quality scenarios across all emotions. Each is appended with one question per appraisal dimension, yielding a total of 4,928 prompts. Rating scales follow  Smith and Ellsworth (1985) , with most dimensions rated on a 1-11 scale and some on a -5 to 5 scale. Additional dataset details are provided in Supplementary Section A.1.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Benchmarking Setup.",
      "text": "We evaluate several open-source and proprietary models on the task of generating cognitive   Smith and Ellsworth (1985) , and the actual fine-grained appraisal dimensions used to create our dataset.\n\nappraisals. Specifically, we include DeepSeek R1 (671B)  (Guo et al. 2025) , GPT-o4-mini (OpenAI 2025), Gemini 2.5 Flash  (Comanici et al. 2025) , LLaMA 3 (8B)  (Dubey et al. 2024) , Phi 4 (14B)  (Abdin et al. 2024) , Qwen 3 (32B)  (Yang et al. 2025) , and Qwen QwQ (32B)  (Yang et al. 2025) . Models are given two question types per scenario: (i) identifying the emotion that would be experienced and (ii) responding to cognitive appraisal dimension-specific questions.\n\nEmotion identification is open-ended, while appraisal dimension responses include both open-ended text and numerical ratings aligned to specific scales 1  . Overall, this generates nearly 35,000 responses from the evaluated models, forming the basis for our analysis.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Evaluating Cognitive Appraisals By Llms",
      "text": "As discussed earlier, we focus on evaluating self-appraisals in LLMs-how models reason about their own emotional responses in hypothetical scenarios, in contrast with prior work  (Tak and Gratch 2023; Tak, Gratch, and Scherer 2025; Broekens et al. 2023 ) that assesses alignment through appraisals of human agents. Building on evidence that LLMs can generate broadly human-like responses to emotionrelated queries  (Broekens et al. 2023; Yongsatianchot, Torshizi, and Marsella 2023; Tak and Gratch 2023; Tak, Gratch, and Scherer 2025; Zhan, Ong, and Li 2023) , we shift focus directly to a fine-grained examination of the underlying cognitive appraisal dimensions that drive these responses. A statistical reliability test of the models' use of appraisal scales is provided in the Supplementary (Section A.2).",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "What Drives Emotion? Latent And Predictive Appraisal Structures In Llms",
      "text": "In this section, we describe our experiments that shed light on the cognitive dimensions inherent to each of the considered models. We approach this by two complementary methods. First, we analyze cognitive appraisal ratings generated by models in an unsupervised manner (i.e., without considering the emotion label attached to each scenario), recovering latent, uncorrelated dimensions for each model, similar to the human study  (Smith and Ellsworth 1985) . This is achieved through extracting six principal components (PCs) using Principal Component Analysis (PCA) and then interpreting how each cognitive dimension feature loads onto each principal component using Varimax Rotation. Second, we examine the correlation between cognitive appraisal ratings and the target emotion for each situation, utilizing regression-based analysis. Our results are presented below.\n\nLatent Cognitive Dimensions. Table  2  details the top two cognitive features for each model, for each principal component, compared broadly with human data from  Smith and Ellsworth (1985) . The six principal components cumulatively explain over 81% variance in most cases (except for LlaMa 3, Qwen 3, and QwQ, each around 54%). The following general themes emerge from an analysis of the principal components:\n\n• Valence Comes First: As seen in Table  2 , the first principal component (PC 1), for both models and humans alike, is dominated by valence-related features. While models like LLaMA 3, Phi 4, Qwen 3, and QwQ all use enjoyment and pleasantness, DeepSeek R1, Gemini, and GPT prioritize effort, exertion, or obstacle-based features. Unlike humans, however, most models use features depicting positive valence (positive loadings for pleasantness or negative loadings for problem/obstacle). • Exerting the Effort: Effort-related features are observed to be highly important for most models across multiple components (mainly PCs 1 and 2, occasionally PC 5), in contrast to humans, where it appears at PC 5. For most of the reasoning models, effort and obstacle-based features are seen to be the most important. Most models also associate effort positively with self-control and obstacle. • Internal vs. External Agency: Agency emerges as the next strongest latent dimension for most models. Selfagency appears through positive loadings of both selfresponsibility and self-control, often in PCs 2 and 3. DeepSeek R1 and Gemini 2.5 also associate features of legitimacy and responsibility inversely, suggesting that the fairness of a situation is inversely related to otherresponsibility. Similar associations are also found in PC 6, both for models and humans, showing that models encode plausible cause-based interpretations, differentiating internal and external blame. • Higher-Order Reasoning: Fine-grained reasoning about emotional situations, such as through certainty, attention, and consideration, appears consistently in PC 4, and sparsely in PCs 3 and 5. Associations between the features of attention, consideration, and certainty also appear in varying patterns in these components. For example, several models depict a direct relationship between consideration and attention (e.g., GPT o4-mini in PC 3, Phi 4 in PC 4), similar to humans 2  . Certainty is also inversely associated with other-responsibility or control, and in some cases, with the perception of legitimacy.  Thus, models broadly align with each other and human data in terms of recovered latent dimensions. They also show plausible associations between different cognitive features, largely reproducing latent psychological structures of human appraisal. However, they differ in the latent importance of each dimension (in terms of explained variance), with valence, effort, and agency-related dimensions appearing as consistent contenders for the top three components.\n\nPredictive Cognitive Dimensions. Our previous analysis reveals latent dimensions implicitly important to each of the models studied. In this section, we perform a regressionbased analysis, identifying the cognitive dimensions that best predict specific emotion classes. The appraisal ratings from each model are treated as independent variables predicting the corresponding emotion label for each scenario. We apply logistic regression with an L2 penalty and investigate the feature coefficients associated with each emotion. Fig.  1  shows the most influential features (with the highest average coefficients across all models) for selected representative emotions, and each model. Detailed results, including complete coefficient maps and top features for all emotions, are presented in the Supplementary (Section A.4). We uncover several notable insights: in general, the observed correlations between appraisal dimensions and emotions are consistent with established cognitive appraisal theories, reinforcing that appraisals generated by LLMs are grounded in realistic interpretations  (Smith and Ellsworth 1985; Frijda, Kuipers, and Ter Schure 1989) . For instance, across all models, Happiness is reliably predicted by high positive weights on enjoyment and the absence of obstacles, aligning closely with classical appraisal theory. Similarly, the other positive emotions, Interest and Pride, both associate with strong positive weights on pleasantness. However, distinctions emerge through other appraisals: Interest uniquely links to low certainty, reflecting elements of curiosity and novelty, while Pride is characterized by the perceived lack of external control, underscoring its nature as an independent and self-focused emotion. These findings support theoretical accounts that classify Pride as a disengaging, autonomy-oriented positive emotion  (Tangney and Fischer 1995) .\n\nAmong negative emotions, Fear predictably shows strong negative associations with pleasantness. However, across all models, the strongest positive predictor of Fear is effort, suggesting fearful situations are commonly appraised as demanding significant physical or mental effort. Contrary to expectations, valence (pleasantness or enjoyment) does not emerge as the strongest predictor for Anger, a \"universal\" negative emotion  (Ekman, Friesen, and Ellsworth 1972) . Instead, perceptions of unfairness emerge as the dominant factor, evidenced by strong positive correlations with legitimacy-cheated and strong negative correlations with legitimacy-fair, consistently across all models. This underscores the role of moral judgment in anger appraisals. Given that perceived fairness can vary based on culture, personality, background, or other contexts  (Murphy-Berman et al. 1984; Tyler et al. 2019 ), the consistent emphasis on unfairness in LLM representations of Anger suggests that these models might treat Anger not as a universal emotion but rather as one contingent on context and perceived injustice.\n\nContempt exhibits another distinctive appraisal profile characterized by positive associations with certainty, indicating that contempt-inducing situations are perceived as highly unambiguous. At the same time, it is negatively associated with self-responsibility, suggesting that contempt arises in contexts involving external blame rather than introspection. In contrast, Guilt shows the opposite pattern, strongly predicted by high self-responsibility and low enjoyment, reflecting an unpleasant, self-evaluative emotional Happiness, Interest, Pride, Fear, Anger, Contempt, Guilt, Challenge), the cognitive feature with the strongest average positive and negative coefficients, across all models, is shown. Plots for all other emotions and complete coefficients are present in the Supplementary (Section A.4). state. Finally, Challenge presents a compelling contrast to Interest. Both emotions negatively correlate with certainty, highlighting the role of ambiguity or novelty. However, Challenge is uniquely characterized by a strong positive association with self-control, indicating that models appraise challenging situations as uncertain yet manageable, suggesting internal agency in navigating difficult circumstances.",
      "page_start": 3,
      "page_end": 5
    },
    {
      "section_name": "What Do Emotions Look Like? Cognitive Representation Of Emotions",
      "text": "In this section, we analyze whether meaning can be inferred from the cognitive representations of emotions for each LLM. Precisely, we first explore how each particular emotion is expressed by a given LLM, and how that compares across different LLMs.\n\nEmotion Representation Within Models. Formally, let E = {e i } 15 i=1 denote the set of emotion categories, each associated with a set of scenarios S i , such that 15 i=1 |S i | = 308. Each scenario is annotated with a 16-dimensional appraisal vector A ∈ R 16 , where each dimension corresponds to a distinct cognitive feature (e.g., pleasantness, effort, control). For each emotion e i , this yields a set of appraisal vectors {A ij } |Si| j=1 , forming an empirical distribution over the appraisal space. We compute pairwise Wasserstein distances  (Kantorovich 1960)   3  between these distributions to quantify fine-grained psychological proximities between emotions. Fig.  2  presents Wasserstein distance matrices for three representative models (full results in Supplementary Section A.5). We observe the following trends:\n\n• Valence-Based Separation: All models exhibit clear valence-based separation, visible in the light blocks at the top-left and bottom-right of the distance matrices. Among negative emotions, anger-frustration and angercontempt consistently appear close (distance ≤ 10), reflecting a shared high-agency, high-obstacle appraisal.\n\nDisgust often aligns with this negative cluster. Similarly, guilt, shame, and sadness are tightly grouped (distance ≤ 12), indicating a low-control, self-evaluative profile.\n\nOn the positive side, happiness, interest, hope, and surprise form a coherent cluster across models, characterized by positive valence and anticipatory appraisals. • Calibration of Scales: As can be noted in Fig.  2 , the overall range of Wasserstein distances is the widest for Gemini 2.5 Flash (≈ 32.0). Gemini 2.5 Flash conflates the appraisal space compared to other models, while clustering positive and negative emotions extremely tightly together. This hints that the scale for the appraisal distribution is less well-calibrated for Gemini 2.5 Flash, which can make it unsuitable or too coarse for relatively fine-grained practical applications. • Blurring Boundaries: While fear is consistently distinct from positive emotions, it remains closely aligned with frustration and anger, suggesting models may conflate high-arousal negative states, making them unsuitable for safety-critical applications requiring detection of emotional threats. Similarly, surprise and challenge occupy ambiguous positions across models: surprise often shifts closer to negative emotions due to mixed-valence scenarios, while challenge, though negatively appraised, shows partial similarity to positive emotions. Gemini 2.5 Flash, further shows identical representations for Hope and Interest, placing both away from all other emotions. Boredom also appears closer to certain positive emotions for Gemini 2.5 Flash, demonstrating that its appraisal is not valence-centric.\n\nIn summary, our analysis shows that despite architectural and training differences, LLMs converge on a shared latent appraisal structure, capturing broad human-like emotional topologies-such as valence-based groupings. However, models often struggle with more ambiguous emotions like hope, interest, or challenge, revealing gaps in finegrained affective reasoning. These findings call into question the value of supervised fine-tuning framed as single-label classification, suggesting that future work should instead focus on better aligning models with individual value systems and emotional nuance.\n\nEmotion Representation Across Models Our analysis in the previous section was limited to within-model com-   0 14 11 11 13 21 21 23 20 25 22 19 22 19 21   14 0 15 12 11 16 15 18 17 18 18 14 16 15 15   11 15 0 14 13 20 20 21 16 22 18 17 20 16 19   11 12 14 0 11 19 18 21 20 22 21 17 19 18 19   13 11 13 11 0 16 17 19 17 19 18 15 18 15 16   21 16 20 19 16 0 11 13 15 13 13 12 11 13 9.9   21 15 20 18 17 11 0 12 14 13 14 12 11 13 11   23 18 21 21 19 13 12 0 16 14 14 13 7.3 13 10   20 17 16 20 17 15 14 16 0 15 10 12 15 11 13   25 18 22 22 19 13 13 14 15 0 13 12 12 12 10   22 18 18 21 18 13 14 14 10 13 0 11 14 11 12   19 14 17 17 15 12 12 13 12 12 11 0 12 9.5 10   22 16 20 19 18 11 11 7.3 15 12 14 12 0 12 8.4   19 15 16 18 15 13 13 13 11 12 11 9.5 12 0 11   21 15 19 19 16 9.9 11 10 13 10 12 10 8.4 11     0 13 16 27 27 20 23 24 23 24 24 22 23 21 23   13 0 22 31 31 25 22 22 22 23 23 21 22 21 21   16 22 0 19 19 14 26 25 24 25 24 23 25 21 24   27 31 19 0 0 16 29 28 28 27 28 26 28 25 27   27 31 19 0 0 16 29 28 28 27 28 26 28 25 27   20 25 14 16 16 0 24 23 24 23 23 22 23 21 22   23 22 26 29 29 24 0 13 18 15 16 16 13 16 14   24 22 25 28 28 23 13 0 19 14 15 14 10 16 11   23 22 24 28 28 24 18 19 0 19 12 16 20 16 18   24 23 25 27 27 23 15 14 19 0 15 12 13 13 10   24 23 24 28 28 23 16 15 12 15 0 12 16 13 14   22 21 23 26 26 22 16 14 16 12 12 0 14 9.9 11   23 22 25 28 28 23 13 10 20 13 16 14 0 15 8.8   21 21 21 25 25 21 16 16 16 13 13 9.9 15 0 12   23 21 24 27 27 22 14 11 18 10 14 11 8.8 12      19 14 18 17 16 11 12 11 10 10 0 11 10 11 9.7   16 12 15 15 14 10 11 11 9.4 10 11 0 9.6 9.3 9.6   18 14 18 16 16 9.7 10 9.3 10 9.5 10 9.6 0 10 9.3   15 12 14 14 13 10 12 12 10 11 11 9.3 10 0 10   17 13 17 16 15 9.7 11 10 9.7 9.8 9.7 9.6 9.3 10    Kendall's Tau 0.28 ± 0.15 0.24 ± 0.20 0.24 ± 0.12 0.23 ± 0.14 0.17 ± 0.20 0.16 ± 0.17 0.14 ± 0.18 0.13 ± 0.16 0.13 ± 0.20 0.11 ± 0.16 0.10 ± 0.20 0.08 ± 0.17 0.06 ± 0.17 0.03 ± 0.21 0.02 ± 0.17  models are evaluated in isolation. In this section, we extend our analysis to examine cross-model variation: How consistent are emotion representations between different models? Specifically, do LLMs share a transferable or potentially universal appraisal structure? To address this, we adopt three complementary approaches: (i) statistical tests of the similarity between distributions of cognitive appraisal across models, (ii) comparison of top predictive cognitive features for each emotion, and (iii) visualization of how different models position emotions along key cognitive dimensions.\n\nNo Universal Appraisal Distribution. First, we investigate whether emotions are similarly represented across models in terms of the distribution of appraisal ratings. For each model M , we use appraisal ratings as emotion representa-tions. With a scenario set S i for emotion e i , each model yields a unique appraisal distribution {A ij } |Si| j=1 . We then compare, for all 7 2 model pairs, and each emotion, the distributional similarity of A i , using their high-dimensional Wasserstein distances  (Kantorovich 1960) . We perform permutation tests to determine whether the chosen pair of distributions is more or less similar than would be expected by chance. Fig.  3  shows the distributional similarities for Happiness and Sadness (results for all categories are in Supplementary Section A.6). Generally, distributions of emotions differ substantially across models, for all emotion categories. This challenges the possibility that universal emotional representations exist across LLMs.\n\nGuilt Appraised Most Similarly, Surprise Most Differently. In the second step, we assess cross-model consistency by comparing the most predictive cognitive dimensions for each emotion, identified in Section 4.1. For each model, and each emotion, we construct a ranked list of appraisal dimensions and evaluate the rank agreement across all 7 2 model pairs, using Kendall's Tau. Table  3  reports the average and standard deviation for each emotion. Guilt shows the highest agreement, indicating a stable appraisal profile across models, followed by Disgust and Contempt, which are also negatively-valenced, moral emotions  (Tangney, Stuewig, and Mashek 2007; Rozin et al. 1999) . In contrast, Surprise, Sadness, Interest, and Challenge exhibit low agreement and high variability, suggesting inconsistent prioritization of appraisal cues, especially for emotions characterized by uncertainty. These results reinforce our distribution-based findings: while LLMs share global emotional structure, they diverge in the fine-grained appraisals used to represent specific emotions, limiting the transferability of appraisal-based emotion modeling across models.\n\nModels May Display Biased Appraisals. Finally, we examine specific model divergences in emotion appraisal, going from scale to detail. Fig.  4  shows how models position emotions along chosen cognitive dimensions, like pleasantness, effort, certainty, legitimacy-cheated, selfresponsibility, and other-control. We choose four representative models (2 reasoning, and 2 non-reasoning models) and plot only emotions for which the corresponding cognitive dimensions are strong predictors (as also seen in Fig.  1 ). Firstly, when plotted along the dimensions of pleasantness and effort, valence reliably separates positive and negative emotions across models. However, notable modelspecific divergences emerge. Gemini 2.5 Flash appraises both Interest and Happiness relatively higher on effort, deviating from other models and theoretical expectations. In contrast, LLaMA 3 and Phi 4 show near-identical distributions for positive emotions, suggesting a shared representation of affective experiences in this subspace. Among negative emotions, Fear consistently stands out as the most effort-intensive emotion across most models.\n\nSecond, we look at the dimensions of certainty and legitimacy. DeepSeek R1 and Phi 4 produce nearly identical emotion distributions, closely aligned with theoretical expectations. For example, all positive emotions have lower values for legitimacy-cheated, while hope and interest have lower values for certainty than happiness. Similarly, challenge is midway on the legitimacy scale, and scores low on certainty, in line with their conceptual association with ambiguity and novelty. The chosen negative emotions score high on both certainty and legitimacy-cheated, as expected. However, LLaMA 3 displays a notable shift: it consistently appraises emotions with lower certainty, suggesting a tendency to interpret emotional situations as ambiguous. It treats even strong negative emotions as highly uncertain. Gemini 2.5 Flash demonstrates the most idiosyncratic behavior out of all models, positioning Interest and Hope in isolation from other emotions, both high in uncertainty and perceived unfairness. It also shows a tendency to appraise most emotions as high on perceived unfairness.\n\nFinally, the cognitive dimensions of self-responsibility and other-control show relatively coherent trends. DeepSeek and Phi 4 again provide similar, theoretically plausible distributions. LLaMA 3 shows a tighter distribution for these two cognitive dimensions, recording relatively lower scores of self-responsibility for highly individual emotions like shame and guilt. Gemini 2.5 Flash largely aligns with others, except for Pride, which is inconsistently shown to have higher other-control.\n\nThese analyses demonstrate that, while LLMs broadly preserve emotion-appraisal structures at a high level, modelspecific nuances or biases emerge along more abstract dimensions and emotions -suggesting variability in the suitability of LLMs for simulating or understanding humanlike appraisal of emotions, especially in nuanced or morally complex contexts.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Concluding Remarks",
      "text": "Our fine-grained analysis reveals that while most LLMs exhibit broadly human-like cognitive appraisal structures, they often struggle with nuanced emotions such as challenge, hope, or surprise, and show inconsistencies across abstract cognitive dimensions. Emotion-specific biases also emerge: for instance, anger is often construed primarily through fairness appraisals, while some models interpret all emotions as inherently uncertain. These patterns point to implicit biases in internal emotional representations. Future work could investigate how equipping models with controllable attributes known to influence human appraisals (such as culture, mental health conditions, etc.) might expose deeper structure or bias. Overall, our findings raise important questions about whether current paradigms, such as next-token prediction, supervised fine-tuning, or Reinforcement Learning with Human Feedback, are adequate for instilling coherent world models of emotion. We hope our benchmark and analyses serve as a foundation for further research in cognitively grounded affective modeling. Nabende, J.; Shutova, E.; and Pilehvar, M. T., eds., Findings of the Association for Computational Linguistics: ACL",
      "page_start": 7,
      "page_end": 10
    },
    {
      "section_name": "A Additional Details About Results",
      "text": "",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "A.1 Details About The Benchmark",
      "text": "We present some additional details about our created benchmark here. Table  4  shows the number of scenarios per emotion category in the benchmark.\n\nNext, we also provide the list of questions used, for each cognitive dimension, as follows:\n\n• Pleasantness: How pleasant or unpleasant was it to be in the situation? Answer with a text explanation, and a number from -5 to 5, with -5 for extremely unpleasant and 5 extremely pleasant. • Enjoyment: How enjoyable was it to be in the situation?\n\nAnswer with a text explanation, and a number from 1-11, with 1 for not at all enjoyable and 11 for extremely enjoyable. Answer with a text explanation, and a number between -5 and 5, with -5 denoting strongly diverted attention, and 5 denoting strongly devoted attention. tion in this situaion? How fair was the cause? Answer with a text explanation and a number between 1-11, with 1 denoting that you felt that the cause was extremely unfair, and 11 denoting that you felt the cause was absolutely fair. • Responsibility-self: When you were feeling the said emotion, how responsible did you feel for having brought about the events that were making you feel the emotion in this situation? Answer with a text explanation and a number between 1-11, with 1 denoting that you felt you were not responsible at all, and 11 denoting that you were the most responsible. something other than yourself was for having brought about the events in this situation? Answer with a text explanation and a number between 1-11, with 1 denoting that you felt no external entity was responsible, and 11 denoting that some external entity or entities were entirely responsible.\n\n• Exert: When you were feeling the said emotion, to what extent did you feel that you needed to exert yourself to deal with this situation? Answer with a text explanation and a number between 1-11, with 1 denoting that you did not need exert yourself at all, and 11 denoting that you needed to exert yourself a great deal.\n\n• Effort: When you were feeling the said emotion, how much effort (mental or physical) did you feel this situation required you to expend? Answer with a text explanation and a number between 1-11, with 1 denoting that you did not need to expend any effort at all, and 11 denoting that you needed to expend significant effort.\n\nThe entire dataset of scenarios, and resulting LLM generations, will be made publicly available upon acceptance. We provide here an example of a complete prompt, considering a scenario from the emotion category of happiness, including the format requirements:\n\n\"Imagine that you are a person, capable of feeling emotions. Respond to the following prompt as the person. Imagine that you recently ate your favorite food. Answer the following questions. Question 1: What emotion would you feel in the situation? Answer using a single sentence. Question 2: How pleasant or unpleasant was it to be in the situation? Answer with a text explanation, and a number from -5 to 5, with -5 for extremely unpleasant and 5 for extremely pleasant. Answer in a JSON format as follows: \"Question 1\": <single sentence response about emotion felt>, \"Question 2\": [<text response for question 2>, <number response for question 2 with number between 1-10>]\"\n\nAlong with this, we also provide single examples of the types of scenarios created for each emotion category.\n\n• Happiness: \"Imagine that you recently ate your favorite food.\"\n\n• Surprise: \"Imagine that you recently got an unexpected text or call from an old friend.\"\n\n• Hope: \"Imagine that you recently enrolled in night classes after years away from school to pursue a new career path.\"\n\n• Interest: \"Imagine that you recently explored a new city you always wanted to visit.\"\n\n• Pride: \"Imagine that you recently completed a challenging project at work or school that required perseverance.\" • Boredom: \"Imagine that you recently attended a class on a subject you had already mastered and had nothing new to learn.\" • Disgust: \"Imagine that you recently entered a hoarder's apartment where the floor was covered in trash and bugs.\" • Contempt: \"Imagine that you recently found out a friend had been cheating on their partner for months without any guilt.\" • Shame: \"Imagine that you recently broke a promise to someone who truly trusted you.\" • Guilt: \"Imagine that you recently accidentally hurt a friend's feelings by making a careless joke.\" • Challenge: \"Imagine that you recently dealt with a chronic illness or were in the process of recovering from an injury.\" • Frustration: \"Imagine that you recently dealt with slow or unresponsive behavior from someone in a position of authority.\" • Anger: \"Imagine that you recently discovered that something important to you had been stolen or vandalized.\" • Fear: \"Imagine that you recently choked on a piece of food and couldn't breathe for a few seconds.\" • Sadness: \"Imagine that you recently failed at something worked hard for.\"",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "A.2 Sanity Checks: Predicting Emotions And Reliability",
      "text": "In this section, we provide additional details on how reliably models predict emotions and how well they are capable of utilizing appraisal rating scales.\n\nEmotion Prediction. As discussed in Section 3 and 4, we prompt all models to also provide a description of the emotion they imagine would be experienced in the given scenario. Using the open-ended descriptions provided by each model, we use another small-sized LLM (DeepSeek R1 Distilled LLaMA 8B  (Guo et al. 2025 )) as a judge to retrieve the top 3 categories that the open-ended description provides the closest match to. We use the LLM as-a-judge paradigm  (Gu et al. 2024 ) in this case, as the task is simply matching a sentence to a few categorical labels, and does not involve significant reasoning about affect. The prompt used for the LLM to obtain the emotion matches is as follows: \"You will be given a piece of text, that talks about feeling some emotion. Your task is to answer which emotion category does the text most closely talk about. You can We manually verify 100 total samples, across all models, and find that the predictions are coherent. However, to further account for the use of similar synonyms in predicting specific emotion categories, we expand the label set to include specific emotion keywords. For example, we allow the following predicted words to also be accounted for each emotion category: Using this, we calculate the accuracy with which each model responds with the same or a similar emotion, as the target emotion associated with the scenario when it is created. Table  5  shows the degree to which the model descriptions match the target emotion categories.\n\nReliable Use of Appraisal Rating Scales. To assess whether the models use the appraisal distribution rating scales coherently, we utilize permutation tests using a split-Wasserstein distance test statistic. Precisely, to investigate how consistent the appraisal distributions are within each model, we create multiple half-splits of the entire distribution vector from each model, and repeatedly calculate the distance between the halves. This is then compared with a randomly generated distribution matrix. Intuitively, it provides an idea of whether the model provides ratings from roughly the same distribution, suggesting consistent and reliable use of the rating scales. Fig.  5  shows the overall range of distances between different split-halves of each model's distribution matrix, compared to a random baseline. Most models show significantly shorter distances (p = 0 for all models) compared to the random distribution matrix. Gemini shows the highest variation, pointing at the possibility of using the rating scales inconsistently. We find similar examples for Gemini also in Sections 4.2 and 4.2.",
      "page_start": 11,
      "page_end": 12
    },
    {
      "section_name": "Alignment Of Textual And Numerical Appraisal Ratings.",
      "text": "As mentioned in Section 3, we obtain appraisal ratings from all models both in the form of an open-ended description and a numerical rating. Using a similar LLM-as-a-judge paradigm, we map the open-ended text descriptions loosely into the rating scale by obtaining shorter phrases from the full-text descriptions. An example (from the pleasantness dimension) of the prompting pattern is as follows:\n\n\"Does the user say that the situation was pleasant or unpleasant for them? Answer using a single phrase, strictly in the required JSON format. Choose from the phrases: [highly unpleasant, moderately unpleasant, ambiguous/neutral, moderately pleasant, highly pleasant].\"\n\nTable  6  shows the average percentage, for each model, for the fidelity of text and numerical outputs. Gemini and LLaMA show the lowest agreement, while even powerful models like GPT o4-mini and DeepSeek R1 show the highest agreement of 68%. This shows that there may remain gaps or inconsistencies when models are asked to respond in multiple formats, requiring them to ensure a coherent response over a longer context window. For all of our experiments, however, we use only the numerical ratings provided Model DeepSeek R1 GPT o4-mini Gemini 2.5 Flash LLaMA 3 Phi 4 Qwen 3 QwQ Agreement (%) 68 69 56 52 61 63 62\n\nTable  6 : Average percentage of agreement between the open-text appraisal rating and the numerical appraisal rating.\n\nby the models. An interesting follow-up would be to use the last-layer token probabilities to retrieve the numerical ratings, but it would limit the analysis to only models for which such intermediate information is available.",
      "page_start": 12,
      "page_end": 13
    },
    {
      "section_name": "A.3 Recovering Latent Dimensions For Llms",
      "text": "In this section, we provide the full PCA-Varimax feature loadings to supplement our results shown in Table  2 . Fig.  6  shows the full loadings for all of the models. The broad trends hold throughout, beyond the top 3 features for each principal component (denoted as Factor 1-6 in the plots).",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "A.4 Predictive Cognitive Dimensions",
      "text": "We provide additional results, in this section, to supplement our findings in Section 4.1. We provide the full feature importances, as obtained using L2 Logistic Regression, in Fig.  7 . As can be noted, the major trends for the representative emotions shown in Fig.  1  hold here as well, with some nuanced differences appearing between different emotions.\n\nHope and Interest, for example, although largely similar in terms of predictive cognitive dimensions, are seen to be different in terms of Certainty. Interest is predicted by strong negative coefficients for certainty, while the same effect is less pronounced for Hope. Similarly, hope is seen to have a strong positive correlation with situational control, signaling that hopeful emotions emerge along with anticipationusually about something that is beyond control. On the contrary, the relationship between situational control and interest is relatively milder, or even unclear, as interest represents curiosity.\n\nChallenge, along with self-control and lack of certainty, also shows a strong positive correlation with effort and exertion. Three of the evaluated reasoning models-Gemini, GPT, and DeepSeek, also interestingly show that a strong negative coefficient for pleasantness is predictive of Challenge, while at the same time, having positive coefficient weights for enjoyment. This brings out a unique distinction between pleasantness and enjoyment, where even a so-called unpleasant situation can be enjoyable (for eg., pushing out of one's comfort zone to achieve something, or going through an adventure).\n\nComparing Anger and Frustration also presents a unique insight. Although largely similar negative emotions, Frustration shows a higher positive correlation with situational control, depicting that frustration often emerges in situations one cannot escape by choice. Contempt, as also shown in Section 4.1, shows a strong positive correlation with certainty, as well as control-other, different from situational control. This denotes that contempt usually can be defined in situations where a different individual (as opposed to circumstance) is interpreted to be responsible.",
      "page_start": 13,
      "page_end": 14
    },
    {
      "section_name": "A.5 Emotion Representation Within Models",
      "text": "In this section, we provide the full Wasserstein distance matrices for all models, to supplement our results in Section 4.2. Fig.  8  shows the emotion distance matrices for the remaining models studied in our benchmark, showing that the representative results presented in the main body hold for the remaining models as well.\n\nAlong with this, we also use the Wasserstein distances, to plot the emotion representations on a 2D map, using multidimensional scaling (MDS). Fig.  9  shows the results. Interestingly, two types of clusters emerge-positive emotions on top left and negative emotions on bottom right, or the reverse. The first type of distribution is shared by Phi 4, Gemini, and LLaMA, while all of the other models (also all reasoning models) show the reverse structure. Gemini 2.5 seems to struggle in the placement of Hope and Interest, separating them from all other positive emotions.",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "A.6 Emotion Distribution Across Models",
      "text": "In this section, we provide an additional plot (Fig.  10 ) to show the distributional differences across different models, for each emotion category. Across most emotion categories, distributions from two different models are more often significantly different. Similarities are seen only in a very few cases, such as for Interest, Hope, and Sadness. Further, we also show how the other models place emotions on the chosen axes of pleasantness-effort, certainty-legitimacy, and responsibility-control in Figures  11, 12 , and 13. Similar to the results shown in the main body, the plots on the dimensions of Pleasantness and Effort (Fig.  12 ) are relatively more coherent for all three models. However, Qwen 3 notably shows lower values for effort, especially for fear. The axes of Legitimacy (cheated) and Certainty (Fig.  12 ) show increased differences among models. GPT o4 shows a very spread-out distribution for emotions, while Qwen 3 places most emotions low in certainty as well as legitimacy (as indicated by the presence of most emotions in the lower left part of the graph). Other than contempt, it appraises all other emotions as uncertain. Finally, for Responsibility (self) and Control (other) (Fig.  13 ), most models capture the expected inverse relationship, with GPT o4-mini providing the clearest distinctions between different emotions. Qwen 3 also distinctly appraises surprise, sadness, frustration, and challenge as low on other-control.\n\nWe also show the results on another axis of attention versus problem in Fig.  14 . The distributions are seen to be significantly different for some of the models-Gemini 2.5 and Qwen 3 show completely different structures. In contrast, LLaMA 3 shows a highly compact version of the broadly similar distribution displayed by DeepSeek, Phi, and QwQ. LLaMA 3 also seems unable to use the dimensions of prob-",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "B Additional Methodological Details",
      "text": "In this section, we provide additional details about our methodology that may be relevant for reproducing our results.",
      "page_start": 14,
      "page_end": 14
    },
    {
      "section_name": "B.1 Prompting Llms",
      "text": "All open-source LLMs are prompted either using the vllm library  (Kwon et al. 2023) , or directly using the Huggingface Transformers library 5 . When prompting using vllm, we use the following hyperparameters:\n\n• Max. Model Length: 2048 • GPU Memory Utilization: between 0.70 -0.97 • Tensor Parallel Size: between 2 -4 • Temperature: 0.5 • Max Output Tokens: 1000 • Batch Size: 2048 5 https://huggingface.co/ When using Huggingface, the default parameters are used, and the maximum tokens to be output is set to 1000. All of the inferences take place on A40 and A100 GPUs, using 2-4 GPUs at a time, and take 1 hour with vllm, and 3-4 hours with Huggingface.\n\nFor the proprietary models, the respective APIs are used. The results are sampled a single time from each model.",
      "page_start": 14,
      "page_end": 14
    },
    {
      "section_name": "B.2 Statistical Analysis",
      "text": "For all of our analysis, we use the scikit-learn library  (Pedregosa et al. 2011) . For the Logistic Regression process, we use the L2 penalty, tolerance of 0.001, the lbfgs solver, and run for 10000 iterations. We also perform 3-fold stratified cross-validation, and report the average feature importances from the 3 folds.\n\nTo compute Wasserstein distances, we use a customwritten function, using the Python Optimal Transport package, that calculates the distance between two complete distributions, using multiple samples within the same emotion as the support.\n\nFor all permutation tests, we use 1000 iterations or permutations. Dee pSe ek R1 GPT Qw Q Gem ini Phi LLa MA 3 Qw en 3 0.85 0.66 -0.39 0.06 -0.36 0.34 -0.1 0.35 -0.61 -0.55 -0.3 0.054 -0.15 -0.03 0.63 -0.8 0.22 1 -0.00140.12 0.029 0.89 -0.028 0.7 -0.15 -0.76 -0.43 0.21 0.62 0.32 -0.009-0.46 0.5 0.97 -0.51-0.086 0.12 0.27 0.025 0.27 -0.4 -0.37-0.00480.35 0.79 0.61 -0.48 0.028 0.97 0.2 -0.51 0.34 -0.17 0.06 0.33 -0.28 -0.45 -0.18-0.041-0.064 0.76 0.31 -0.6 -0.29 0.5 1.3 0.55 0.27 0.17 0.52 -0.084 0.38 -0.210.0048-0.055-0.024 0.76 0.062 -0.48 -0.7 0.79 0.12 -0.25 0.36 -0.32 0.8 0.051 0.13 -0.12 -0.33 -0.36 0.24 0.051 -0. 1.2 -0.31 0.096 -0.27 0.75 0.16 0.46 -0.18 1 -0.088-0.63 0.27 0.055 -0.48 -0.79 -0.34 0.87 0.4 -0.22 0.021 0.85 -0.19-0.022 0.13 0.73 -0.29 -0.92 0.57 -0.37 0.089 0.44 -0.12 0.89 0.69 -0.15 -0.46 0.78 -0.29 -0.35 -0.11 0.73 0.19 -0.26 0.8 -0.14-0.094-0.41 0.25 0.44 0.36 0.39 0.4 0.24 0.29 0.21 0.15 0.26 0.17 0.4 0.22 0.26 0.24 0.33 0.35 0.92 0.14 -0.41 0.058 0.66 0.13 0.22 -0.095 0.88 0.39 -0.51 1.1 -0.03-0.069-0.16 -0.2 0.54 0.96 -0.43 0.12 0.2 -0.29 -0.26 -0.23 -0.31 0.64 -0.15 0.091 -0.03 0.12 -0.085 0.15 0.86 0.075 -0.36 0.41 0.62 0.023 -0.11 -0.31 0.36 0.39 -0.43 0.025 -0.2 -0.15 -0.4 -0.045 Feature Importance for Hope Dee pSe ek R1 GPT Qw Q Gem ini Phi LLa MA 3 Qw en 3 0.13 0.15 -0.42 0.44 -0.18 0.14 -0.21 -0.7 0.093 0.35 -0.62 0.59 -0.83 0.085 -0.61 -0.73 0.046 0.86 -0.76 0.14 -0.32 -0.49 -0.22 -1.3 0.52 0.046 -0.37 0.034 -0.12 0.12 -0.83 -0.53 1.1 0.23 -0.13 0.71 -0.36 0.12 -0.41 -0.81 0.23 0.48 -0.34 0.36 -1.4 0.52 0.14 -0.75 0.45 0.36 0.39 0.4 0.22 0.28 0.2 0.14 0.25 0.15 0.4 0.22 0.26 0.22 0.32 0.34 0.27 0.33 -0.25 0.35 -0.77 -0.88 -0.74 -0.86 -0.14 -0.47 -0.6 0.22 -0.79-0.014-0.16 0.027 0.81 0.88 -0.85 -0.12 0.11 -0.54 0.270.00051-0.3 -0.4 0.13 0.13 -0.36 0.16 0.11 -0.59 1.1 0.39 0.38 0.55 -0.3 -0.12 0.17 -0.48 -0.13 0.55 -0.62 0.12 -0.720.0064-0.73 -0.22 Feature Importance for Interest",
      "page_start": 14,
      "page_end": 15
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: shows the most influential features (with the highest",
      "page": 4
    },
    {
      "caption": "Figure 1: The feature weights/coefficients for Logistic Regression with L2 regularization. For each emotion shown (left-right:",
      "page": 5
    },
    {
      "caption": "Figure 2: presents Wasserstein distance matrices for three",
      "page": 5
    },
    {
      "caption": "Figure 2: Distances between distributions of each emotion category, shown for each LLM studied. Darker colors indicate less",
      "page": 6
    },
    {
      "caption": "Figure 3: Comparison of emotion distributions (shown",
      "page": 6
    },
    {
      "caption": "Figure 3: shows the distributional similarities for",
      "page": 6
    },
    {
      "caption": "Figure 4: Map of different emotion categories on specific chosen appraisal dimensions.",
      "page": 7
    },
    {
      "caption": "Figure 4: shows how mod-",
      "page": 7
    },
    {
      "caption": "Figure 5: shows the overall range",
      "page": 12
    },
    {
      "caption": "Figure 5: Violin plot showing the spread of Wasserstein dis-",
      "page": 12
    },
    {
      "caption": "Figure 6: shows the full loadings for all of the models. The broad",
      "page": 13
    },
    {
      "caption": "Figure 7: As can be noted, the major trends for the representative",
      "page": 13
    },
    {
      "caption": "Figure 1: hold here as well, with some nu-",
      "page": 13
    },
    {
      "caption": "Figure 8: shows the emotion distance matrices for the re-",
      "page": 13
    },
    {
      "caption": "Figure 9: shows the results. Inter-",
      "page": 13
    },
    {
      "caption": "Figure 12: ) are relatively",
      "page": 13
    },
    {
      "caption": "Figure 13: ), most models capture the expected",
      "page": 13
    },
    {
      "caption": "Figure 14: The distributions are seen to be sig-",
      "page": 13
    },
    {
      "caption": "Figure 6: The complete feature loadings, as obtained using Varimax Rotation, onto the first 6 Principal Components obtained",
      "page": 14
    },
    {
      "caption": "Figure 7: The complete feature importance coefficients for all emotion categories, as obtained from Multi-class Logistic Re-",
      "page": 15
    },
    {
      "caption": "Figure 8: Wasserstein distance matrices, denoting the representation of each emotion, within each model, for the models not",
      "page": 16
    },
    {
      "caption": "Figure 9: The emotion representations, within each model, plotted using multi-dimensional scaling and the Wasserstein dis-",
      "page": 17
    },
    {
      "caption": "Figure 10: Comparison of cross-model representations, for each emotion, computed across all model pairs.",
      "page": 18
    },
    {
      "caption": "Figure 11: Map of Emotions on the dimensions of Pleasantness and Effort for additional models evaluated.",
      "page": 19
    },
    {
      "caption": "Figure 12: Map of Emotions on the dimensions of Certainty and Legitimacy for additional models evaluated.",
      "page": 19
    },
    {
      "caption": "Figure 13: Map of Emotions on the dimensions of Responsibility and Control for additional models evaluated.",
      "page": 19
    },
    {
      "caption": "Figure 14: Map of Emotions on the dimensions of Attention and Problem for all models.",
      "page": 20
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "happiness\nshame": "surprise\nguilt\npride\ninterest\ncontempt\nhope\nboredom\nanger\ndisgust\ncontempt\nsadness\nguilt\ndisgust\nsurprise\nfear\nfrustration\nshame"
        },
        {
          "happiness\nshame": "challenge\nsadness\npride\nanger\nchallenge\nfear\nfrustration\nboredom\nhope\nhappiness"
        },
        {
          "happiness\nshame": "interest"
        }
      ],
      "page": 17
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "happiness": "hope\npride\nhappiness\nsurprise\npride\ninterest\nhope\nboredom\nchallenge\ndisgust\ncontempt\nguilt\nfear\nguilt\nshame\nsadness\nanger\nshame\nchallenge\nfrustration",
          "interest": "surprise\nboredom\nsadness\nanger\nfrustration\nfear\ncontempt"
        }
      ],
      "page": 17
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "disgust\nboredom\nfear\nhope": "",
          "shame\ncontempt\nsadness\nanger\nfrustration\nchallenge": "",
          "guilt\nsurprise": "interest",
          "happiness\nsurprise\npride\ninterest\nhope\nboredom\ndisgust\ncontempt\nguilt\nfear\nshame\npride\nsadness\nanger\nchallenge\nfrustration": ""
        }
      ],
      "page": 17
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "shame": "contempt\nfrustration\nanger\nfear",
          "happiness": "surprise\npride\ninterest\nhope\nboredom\ndisgust\ncontempt\nguilt\nfear"
        },
        {
          "shame": "boredom",
          "happiness": "shame\npride\nsadness\nanger\nchallenge\nfrustration"
        },
        {
          "shame": "",
          "happiness": ""
        },
        {
          "shame": "",
          "happiness": ""
        }
      ],
      "page": 17
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "shame": "guilt\ncontempt\nchallenge\nanger\nsadness\nfrustration",
          "happiness": "surprise\npride\ninterest\nhope\nboredom\ndisgust\ncontempt\nguilt\nfear\npride\nshame\nsadness\nanger\nchallenge\nfrustration"
        },
        {
          "shame": "boredom\ndisgust\nsurprise",
          "happiness": ""
        },
        {
          "shame": "hope",
          "happiness": "interest"
        }
      ],
      "page": 17
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "pride": "boredom"
        },
        {
          "pride": ""
        },
        {
          "pride": ""
        }
      ],
      "page": 17
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "happiness": "hope\ninterest\npride"
        },
        {
          "happiness": "happiness\nsurprise\npride\ninterest\nhope\nboredom\ndisgust\ncontempt\nguilt\nfear\nshame\nsadness\nanger\nchallenge\nfrustration"
        }
      ],
      "page": 17
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Phi-4 technical report",
      "authors": [
        "M Abdin",
        "J Aneja",
        "H Behl",
        "S Bubeck",
        "R Eldan",
        "S Gunasekar",
        "M Harrison",
        "R Hewett",
        "M Javaheripi",
        "P Kauffmann"
      ],
      "year": "2024",
      "venue": "Phi-4 technical report",
      "arxiv": "arXiv:2412.08905"
    },
    {
      "citation_id": "2",
      "title": "Using large language models to simulate multiple humans and replicate human subject studies",
      "authors": [
        "G Aher",
        "R Arriaga",
        "A Kalai"
      ],
      "year": "2023",
      "venue": "International Conference on Machine Learning"
    },
    {
      "citation_id": "3",
      "title": "Are Generative Language Models Multicultural? A Study on Hausa Culture and Emotions using ChatGPT",
      "authors": [
        "I Ahmad",
        "S Dudy",
        "R Ramachandranpillai",
        "K Church"
      ],
      "year": "2024",
      "venue": "Proceedings of the 2nd Workshop on Cross-Cultural Considerations in NLP"
    },
    {
      "citation_id": "4",
      "title": "Llm social simulations are a promising research method",
      "authors": [
        "J Anthis",
        "R Liu",
        "S Richardson",
        "A Kozlowski",
        "B Koch",
        "J Evans",
        "E Brynjolfsson",
        "M Bernstein"
      ],
      "year": "2025",
      "venue": "Llm social simulations are a promising research method",
      "arxiv": "arXiv:2504.02234"
    },
    {
      "citation_id": "5",
      "title": "A holistic comparative study of large language models as emotional support dialogue systems",
      "authors": [
        "X Bai",
        "G Chen",
        "T He",
        "C Zhou",
        "C Guo"
      ],
      "year": "2025",
      "venue": "Cognitive Computation"
    },
    {
      "citation_id": "6",
      "title": "Evaluating Vision-Language Models for Emotion Recognition",
      "authors": [
        "S Bhattacharyya",
        "J Wang"
      ],
      "year": "2025",
      "venue": "Findings of the Association for Computational Linguistics: NAACL 2025"
    },
    {
      "citation_id": "7",
      "title": "A heterogeneous multimodal graph learning framework for recognizing user emotions in social networks",
      "authors": [
        "S Bhattacharyya",
        "S Yang",
        "J Wang"
      ],
      "year": "2024",
      "venue": "2024 12th International Conference on Affective Computing and Intelligent Interaction (ACII)"
    },
    {
      "citation_id": "8",
      "title": "Using cognitive psychology to understand GPT-3",
      "authors": [
        "M Binz",
        "E Schulz"
      ],
      "year": "2023",
      "venue": "Proceedings of the National Academy of Sciences"
    },
    {
      "citation_id": "9",
      "title": "Fine-grained affective processing capabilities emerging from large language models",
      "authors": [
        "J Broekens",
        "B Hilpert",
        "S Verberne",
        "K Baraka",
        "P Gebhard",
        "A Plaat"
      ],
      "year": "2023",
      "venue": "11th International Conference on Affective Computing and Intelligent Interaction (ACII)"
    },
    {
      "citation_id": "10",
      "title": "Psychological construction in the OCC model of emotion",
      "authors": [
        "G Clore",
        "A Ortony"
      ],
      "year": "2013",
      "venue": "Emotion Review"
    },
    {
      "citation_id": "11",
      "title": "CogBench: a large language model walks into a psychology lab",
      "authors": [
        "J Coda-Forno",
        "M Binz",
        "J Wang",
        "E Schulz"
      ],
      "year": "2024",
      "venue": "Proceedings of the 41st International Conference on Machine Learning"
    },
    {
      "citation_id": "12",
      "title": "Gemini 2.5: Pushing the frontier with advanced reasoning, multimodality, long context, and next generation agentic capabilities",
      "authors": [
        "G Comanici",
        "E Bieber",
        "M Schaekermann",
        "I Pasupat",
        "N Sachdeva",
        "I Dhillon",
        "M Blistein",
        "O Ram",
        "D Zhang",
        "E Rosen"
      ],
      "year": "2025",
      "venue": "Gemini 2.5: Pushing the frontier with advanced reasoning, multimodality, long context, and next generation agentic capabilities",
      "arxiv": "arXiv:2507.06261"
    },
    {
      "citation_id": "13",
      "title": "A Framework for Robust Cognitive Evaluation of LLMs",
      "authors": [
        "K De Langis",
        "J Park",
        "B Hu",
        "K Le",
        "A Schramm",
        "M Mensink",
        "A Elfenbein",
        "D Kang"
      ],
      "year": "2025",
      "venue": "A Framework for Robust Cognitive Evaluation of LLMs",
      "arxiv": "arXiv:2504.02789"
    },
    {
      "citation_id": "14",
      "title": "The llama 3 herd of models",
      "authors": [
        "A Dubey",
        "A Jauhri",
        "A Pandey",
        "A Kadian",
        "A Al-Dahle",
        "A Letman",
        "A Mathur",
        "A Schelten",
        "A Yang",
        "A Fan"
      ],
      "year": "2024",
      "venue": "The llama 3 herd of models"
    },
    {
      "citation_id": "15",
      "title": "Unequal Opportunities: Examining the Bias in Geographical Recommendations by Large Language Models",
      "authors": [
        "S Dudy",
        "T Tholeti",
        "R Ramachandranpillai",
        "M Ali",
        "T Li",
        "-J Baeza-Yates"
      ],
      "year": "2025",
      "venue": "Proceedings of the 30th International Conference on Intelligent User Interfaces"
    },
    {
      "citation_id": "16",
      "title": "Cognitive Bias in Decision-Making with LLMs",
      "authors": [
        "J Echterhoff",
        "Y Liu",
        "A Alessa",
        "J Mcauley",
        "Z He"
      ],
      "year": "2024",
      "venue": "Findings of the"
    },
    {
      "citation_id": "17",
      "title": "Emotion in the Human Face: Guidelines for Research and an Integration of Findings",
      "authors": [
        "P Ekman",
        "W Friesen",
        "P Ellsworth"
      ],
      "year": "1972",
      "venue": "Emotion in the Human Face: Guidelines for Research and an Integration of Findings"
    },
    {
      "citation_id": "18",
      "title": "Relations among emotion, appraisal, and emotional action readiness",
      "authors": [
        "N Frijda",
        "P Kuipers",
        "E Ter Schure"
      ],
      "year": "1989",
      "venue": "Journal of Personality and Social Psychology"
    },
    {
      "citation_id": "19",
      "title": "Exploring Anthropomorphism in Conversational Agents for Environmental Sustainability",
      "authors": [
        "M Giudici",
        "S Scherini",
        "P Chaussumier",
        "S Ginocchio",
        "F Garzotto"
      ],
      "year": "2025",
      "venue": "Proceedings of the 2025 ACM Designing Interactive Systems Conference"
    },
    {
      "citation_id": "20",
      "title": "A survey on llm-as-ajudge",
      "authors": [
        "J Gu",
        "X Jiang",
        "Z Shi",
        "H Tan",
        "X Zhai",
        "C Xu",
        "W Li",
        "Y Shen",
        "S Ma",
        "H Liu"
      ],
      "year": "2024",
      "venue": "A survey on llm-as-ajudge",
      "arxiv": "arXiv:2411.15594"
    },
    {
      "citation_id": "21",
      "title": "Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning",
      "authors": [
        "D Guo",
        "D Yang",
        "H Zhang",
        "J Song",
        "R Zhang",
        "R Xu",
        "Q Zhu",
        "S Ma",
        "P Wang",
        "X Bi"
      ],
      "year": "2025",
      "venue": "Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning",
      "arxiv": "arXiv:2501.12948"
    },
    {
      "citation_id": "22",
      "title": "Sociodemographic Bias in Language Models: A Survey and Forward Path",
      "authors": [
        "V Gupta",
        "P Venkit",
        "S Wilson",
        "R Passonneau"
      ],
      "year": "2024",
      "venue": "5th Workshop on Gender Bias in Natural Language Processing, GeBNLP 2024, held in conjunction with the 62nd Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "23",
      "title": "Distributive fairness in large language models: Evaluating alignment with human values",
      "authors": [
        "H Hosseini",
        "S Khanna"
      ],
      "year": "2025",
      "venue": "Distributive fairness in large language models: Evaluating alignment with human values",
      "arxiv": "arXiv:2502.00313"
    },
    {
      "citation_id": "24",
      "title": "Gpt-4o system card",
      "authors": [
        "A Hurst",
        "A Lerer",
        "A Goucher",
        "A Perelman",
        "A Ramesh",
        "A Clark",
        "A Ostrow",
        "A Welihinda",
        "A Hayes",
        "A Radford"
      ],
      "year": "2024",
      "venue": "Gpt-4o system card",
      "arxiv": "arXiv:2410.21276"
    },
    {
      "citation_id": "25",
      "title": "Emotional intelligence and agents: Survey and possible applications",
      "authors": [
        "M Ivanović",
        "M Radovanović",
        "Z Budimac",
        "D Mitrović",
        "V Kurbalija",
        "W Dai",
        "W Zhao"
      ],
      "year": "2014",
      "venue": "Proceedings of the 4th International Conference on Web Intelligence, Mining and Semantics"
    },
    {
      "citation_id": "26",
      "title": "Mathematical methods of organizing and planning production",
      "authors": [
        "L Kantorovich"
      ],
      "year": "1960",
      "venue": "Management Science"
    },
    {
      "citation_id": "27",
      "title": "Emotion Recognition And Its Applications. Human-computer Systems Interaction: Backgrounds and applications",
      "authors": [
        "A Kołakowska",
        "A Landowska",
        "M Szwoch",
        "W Szwoch",
        "M Wrobel"
      ],
      "year": "2014",
      "venue": "Emotion Recognition And Its Applications. Human-computer Systems Interaction: Backgrounds and applications"
    },
    {
      "citation_id": "28",
      "title": "Efficient Memory Management for Large Language Model Serving with PagedAttention",
      "authors": [
        "W Kwon",
        "Z Li",
        "S Zhuang",
        "Y Sheng",
        "L Zheng",
        "C Yu",
        "J Gonzalez",
        "H Zhang",
        "I Stoica",
        "A Lampinen",
        "I Dasgupta",
        "S Chan",
        "H Sheahan",
        "A Creswell",
        "D Kumaran",
        "J Mcclelland",
        "F Hill"
      ],
      "year": "2023",
      "venue": "Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles"
    },
    {
      "citation_id": "29",
      "title": "Can Third Parties Read Our Emotions",
      "authors": [
        "J Li",
        "Y Zhou",
        "P Narayanan Venkit",
        "H Islam",
        "S Arya",
        "S Wilson",
        "S Rajtmajer"
      ],
      "year": "2025",
      "venue": "Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "30",
      "title": "Large Language Models as Psychological Simulators: A Methodological Guide",
      "authors": [
        "Z Lin"
      ],
      "year": "2025",
      "venue": "Large Language Models as Psychological Simulators: A Methodological Guide",
      "arxiv": "arXiv:2506.16702"
    },
    {
      "citation_id": "31",
      "title": "Emollms: A series of emotional large language models and annotation tools for comprehensive affective analysis",
      "authors": [
        "Z Liu",
        "K Yang",
        "Q Xie",
        "T Zhang",
        "S Ananiadou"
      ],
      "year": "2024",
      "venue": "Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining"
    },
    {
      "citation_id": "32",
      "title": "A Comprehensive Evaluation of Cognitive Biases in LLMs",
      "authors": [
        "S Malberg",
        "R Poletukhin",
        "C Schuster",
        "G Groh"
      ],
      "year": "2025",
      "venue": "Proceedings of the 5th International Conference on Natural Language Processing for Digital Humanities"
    },
    {
      "citation_id": "33",
      "title": "Can llms reliably simulate human learner actions? a simulation authoring framework for open-ended learning environments",
      "authors": [
        "A Mannekote",
        "A Davies",
        "J Kang",
        "K Boyer"
      ],
      "year": "2025",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence"
    },
    {
      "citation_id": "34",
      "title": "Factors affecting allocation to needy and meritorious recipients: A cross-cultural comparison",
      "authors": [
        "V Murphy-Berman",
        "J Berman",
        "P Singh",
        "A Pachauri",
        "P Kumar"
      ],
      "year": "1984",
      "venue": "Journal of Personality and Social Psychology"
    },
    {
      "citation_id": "35",
      "title": "",
      "authors": [
        "Openai"
      ],
      "year": "2025",
      "venue": ""
    },
    {
      "citation_id": "36",
      "title": "NTSEBENCH: Cognitive Reasoning Benchmark for Vision Language Models",
      "authors": [
        "P Pandya",
        "V Gupta",
        "A Talwarr",
        "T Kataria",
        "D Roth",
        "V Gupta"
      ],
      "year": "2025",
      "venue": "Findings of the Association for Computational Linguistics: NAACL 2025"
    },
    {
      "citation_id": "37",
      "title": "Scikit-learn: Machine learning in Python",
      "authors": [
        "F Pedregosa",
        "G Varoquaux",
        "A Gramfort",
        "V Michel",
        "B Thirion",
        "O Grisel",
        "M Blondel",
        "P Prettenhofer",
        "R Weiss",
        "V Dubourg"
      ],
      "year": "2011",
      "venue": "Journal of machine Learning research"
    },
    {
      "citation_id": "38",
      "title": "The double-edged sword of anthropomorphism in LLMs",
      "authors": [
        "M Reinecke",
        "F Ting",
        "J Savulescu",
        "I Singh"
      ],
      "year": "2025",
      "venue": "Proceedings"
    },
    {
      "citation_id": "39",
      "title": "The CAD triad hypothesis: a mapping between three moral emotions (contempt, anger, disgust) and three moral codes (community, autonomy, divinity)",
      "authors": [
        "P Rozin",
        "L Lowery",
        "S Imada",
        "J Haidt"
      ],
      "year": "1999",
      "venue": "Journal of Personality and Social Psychology"
    },
    {
      "citation_id": "40",
      "title": "EmoBench: Evaluating the Emotional Intelligence of Large Language Models",
      "authors": [
        "S Sabour",
        "S Liu",
        "Z Zhang",
        "J Liu",
        "J Zhou",
        "A Sunaryo",
        "T Lee",
        "R Mihalcea",
        "M Huang"
      ],
      "year": "2024",
      "venue": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "41",
      "title": "On the nature and function of emotion: A component process approach",
      "authors": [
        "K Scherer"
      ],
      "year": "2014",
      "venue": "Approaches to Emotion"
    },
    {
      "citation_id": "42",
      "title": "Patterns of Cognitive Appraisal in Emotion",
      "authors": [
        "C Smith",
        "P Ellsworth"
      ],
      "year": "1985",
      "venue": "Journal of Personality and Social Psychology"
    },
    {
      "citation_id": "43",
      "title": "The Role of Appraisal and Emotion in Coping and Adaptation",
      "authors": [
        "C Smith",
        "L Kirby"
      ],
      "year": "2010",
      "venue": "The Handbook of Stress Science: Biology, psychology, and health"
    },
    {
      "citation_id": "44",
      "title": "Aware yet Biased: Investigating Emotional Reasoning and Appraisal Bias in Large Language Models",
      "authors": [
        "A Tak",
        "J Gratch",
        "A Tak",
        "J Gratch",
        "K Scherer"
      ],
      "year": "2023",
      "venue": "2023 11th International Conference on Affective Computing and Intelligent Interaction (ACII)"
    },
    {
      "citation_id": "45",
      "title": "Moral emotions and moral behavior",
      "authors": [
        "J Tangney",
        "J Stuewig",
        "D Mashek"
      ],
      "year": "2007",
      "venue": "Annu. Rev. Psychol"
    },
    {
      "citation_id": "46",
      "title": "Self-conscious Emotions: The psychology of shame, guilt, embarrassment, and pride",
      "authors": [
        "J Tangney",
        "K Fischer"
      ],
      "year": "1995",
      "venue": "Self-conscious Emotions: The psychology of shame, guilt, embarrassment, and pride"
    },
    {
      "citation_id": "47",
      "title": "The Turing Trap: The Promise & Peril of Human-Like Artificial Intelligence",
      "authors": [
        "A Turing"
      ],
      "year": "2022",
      "venue": "Journal of the American Academy of Arts & Sciences"
    },
    {
      "citation_id": "48",
      "title": "Emotional intelligence of large language models",
      "authors": [
        "T Tyler",
        "R Boeckmann",
        "H Smith",
        "Y Huo",
        "Routledge",
        "X Wang",
        "X Li",
        "Z Yin",
        "Y Wu",
        "J Liu"
      ],
      "year": "2019",
      "venue": "Journal of Pacific Rim Psychology"
    },
    {
      "citation_id": "49",
      "title": "Towards Anthropomorphic Conversational AI Part I: A Practical Framework",
      "authors": [
        "F Wei",
        "Y Li",
        "B Ding"
      ],
      "year": "2025",
      "venue": "Towards Anthropomorphic Conversational AI Part I: A Practical Framework",
      "arxiv": "arXiv:2503.04787"
    },
    {
      "citation_id": "50",
      "title": "Significance of emotional intelligence in the era of artificial intelligence: a study on the application of artificial intelligence in financial and educational services sector",
      "authors": [
        "A Yang",
        "A Li",
        "B Yang",
        "B Zhang",
        "B Hui",
        "B Zheng",
        "B Yu",
        "C Gao",
        "C Huang",
        "C Lv"
      ],
      "year": "2019",
      "venue": "Qwen3 technical report",
      "arxiv": "arXiv:2505.09388"
    },
    {
      "citation_id": "51",
      "title": "Beyond Context to Cognitive Appraisal: Emotion Reasoning as a Theory of Mind Benchmark for Large Language Models",
      "authors": [
        "G Yeo",
        "K Jaidka"
      ],
      "year": "2025",
      "venue": "Beyond Context to Cognitive Appraisal: Emotion Reasoning as a Theory of Mind Benchmark for Large Language Models"
    }
  ]
}