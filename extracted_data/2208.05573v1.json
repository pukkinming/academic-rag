{
  "paper_id": "2208.05573v1",
  "title": "Data Augmentation For Improving Emotion Recognition In Software Engineering Communication",
  "published": "2022-08-10T21:50:14Z",
  "authors": [
    "Mia Mohammad Imran",
    "Yashasvi Jain",
    "Preetha Chatterjee",
    "Kostadin Damevski"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Emotions (e.g., Joy, Anger) are prevalent in daily software engineering (SE) activities, and are known to be significant indicators of work productivity (e.g., bug fixing efficiency). Recent studies have shown that directly applying general purpose emotion classification tools to SE corpora is not effective. Even within the SE domain, tool performance degrades significantly when trained on one communication channel and evaluated on another (e.g, StackOverflow vs. GitHub comments). Retraining a tool with channel-specific data takes significant effort since manually annotating a large dataset of ground truth data is expensive. In this paper, we address this data scarcity problem by automatically creating new training data using a data augmentation technique. Based on an analysis of the types of errors made by popular SE-specific emotion recognition tools, we specifically target our data augmentation strategy in order to improve the performance of emotion recognition. Our results show an average improvement of 9.3% in micro F1-Score for three existing emotion classification tools (ESEM-E, EMTk, SEntiMoji) when trained with our best augmentation strategy.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Emotions can strongly impact activities that are collaborative in nature and require creativity and problem-solving skills, such as software development  [1] . Recent research has shown that positive emotions (e.g., Joy) are associated with increased productivity and job satisfaction in software engineering teams  [25, 27, 30, 46, 53] .\n\nOn the other hand, negative emotions (e.g., Frustration) can cause developers to lose motivation and exhibit lower participation, ultimately leading to team attrition  [29] . Negative emotions, which are known to impact cognitive processes, could also serve as an obstacle to learning a new programming language, code comprehension, etc.  [59] . Thus, for quite a while, software engineering researchers have studied developer emotions and how they impact software development activities  [60, 75, 79] . The goals of the research have been to empirically understand the causes and the impact of different emotional states on the productivity of an individual developer or a team  [28, 29, 31, 50]  and to design techniques that automatically detect developer emotion and provide recommendations to developers  [11, 21, 26, 35, 39, 59, 70] . Success in achieving these goals is predicated on the ability to detect emotions with high accuracy.\n\nWhile several approaches that target emotion detection in software developers' written text have been proposed, they have not been evaluated extensively due to the limited availability of manually annotated ground truth data  [42] . Manual annotation of emotions in text is time consuming and requires additional effort to ensure annotator subjectivity is minimized  [33, 42] . At the same time, there is ample evidence that emotion classifiers trained on general purpose data (i.e., not from software engineering) perform poorly in the software engineering domain, likely due to the specific vocabulary and characteristics of software engineering communication (e.g., occasional presence of short snippets of code)  [8, 56] . In fact, emotion classification performance appears to be optimal when trained and evaluated on each specific software engineering channel separately, e.g., GitHub issue comments, StackOverflow comments  [57] .\n\nIn this paper, our aim is to understand the current limitations and improve emotion classification in software engineering written communication. More specifically, we address the following two research questions: RQ1: How effective are existing emotion classifiers in detecting emotions in GitHub comments? What types of emotions are most likely to be misclassified?\n\nTo answer this RQ, we first create a new dataset for emotion classification based on GitHub issue and pull request discussions. We annotate the dataset based on the six emotion categories first introduced by Shaver  [73] , while also going beyond this categorization to a finer grained division using secondary and tertiary emotions. Using our dataset, we evaluate three of the most commonly used tools for software engineering emotion classification (ESEM-E  [51] , EMTk  [9] , SEntiMoji  [13] ), showing that their accuracy is further reduced compared to the original datasets that the tools were built and evaluated for. We perform an error analysis focused on the instances that all of the three tools got wrong, in order to understand the limitations of the current generation of approaches. Our results indicate that a large number of the errors (the majority) are due to a simple inability of the tools to recognize clear lexical cues that are present in the text, and not due to more hard-to-discern causes, such as the emotion being implicitly expressed.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Rq2: Can Automatic Data Augmentation Techniques Be Used To Improve The Effectiveness Of Existing Emotion Classifiers?",
      "text": "To answer this RQ, we explore three different strategies for data augmentation. Each of the strategies significantly increases the training set size, generating 10x more training data than what we had at the outset. The strategies contrast between unconstrained augmentation, where we modify the original text in random places and without additional checks, and augmentation with a number of constraints that ensure it does not perturb the original emotion in the text. Our experimental results show that the best strategy focuses on preserving the emotional polarity of the text, which is positive for emotions like Joy and Love and negative for emotions like Anger. Focusing the augmentation directly on individual emotions is not as profitable, as we lack sufficiently large software engineering-specific lexicons that can be used to generate a large and diverse number of augmented instances.\n\nContributions: Improved emotion recognition taxonomy in developer written communication can impact empirical research as well as motivate new tools that improve emotion awareness in software engineering projects. To the best of our knowledge, we are the first to explore data augmentation strategies in order to deal with the scarcity of high quality annotated data and improve emotion recognition in software engineering-related text. A similar approach to ours could potentially also be leveraged to improve related tasks in software engineering, such as automatic generation of training data for sentiment analysis.\n\nWe publish the annotation instructions, annotated dataset, and source code to facilitate the replication of our study at: https:// anonymous.4open.science/r/SE-Emotion-Study-0141/",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Background",
      "text": "Over the years, emotions have been conceptualized in different ways by software engineering researchers. We begin by providing background on measuring emotions and the existing annotated datasets. We then introduce data augmentation, a technique for dealing with data scarcity in machine learning by increasing the training set size.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Emotions In Software Artifacts",
      "text": "Leveraging research in psychology, over the years researchers have used several categorizations of emotions in written text. For instance, Ekman et al.  [22]  categorized emotions into six basic categories: Anger, Disgust, Fear, Joy, Sadness, and Surprise. On the other hand, Shaver et al.  [73]  identified six basic emotion categories: Love, Joy, Anger, Sadness, Surprise, and Fear. Shaver et al. expanded the basic set of emotions to secondary and tertiary levels in a tree-like structure. Shaver's emotional structure was refined in the work of Parrott et al.  [62] . Plutchik  [63]  proposed a wheel-like structure of three layers of emotions with eight basic categories: Anger, Disgust, Fear, Joy, Sadness, Surprise, Trust, and Anticipation. Studies conducted by Cowen et al. identified 27 distinct categories based on 2185 short videos  [16] , 28 categories using facial expressions  [17] , and 24 using human vocalization  [15] . Based on Cowen et al. 's studies, Demszky et al. devised 27 categories for text-based emotion recognition  [19] . They also provided a mapping between these 27 categories and Ekman et al. 's six basic categories  [22] . Although, it is widely accepted that emotions are comprised of basic categories that are combined to form more complex emotions (e.g, Frustration), there is no consensus on the complete list of categories that accommodate the wide-range of emotions observed in the software engineering domain  [69] .\n\nAvailable Datasets. To conduct studies of software developer emotions in various communication channels and software artifacts, researchers have created a few manually annotated datasets (i.e., gold sets) that leverage the categories described above. For instance, Ortu et al.  [61]  annotated a JIRA dataset that contained 5992 issue samples in three groups: group 1 contained 392 issue comments labeled with emotions Love, Joy, Surprise, Anger, Fear and Sadness; group 2 contained 1600 issue comments labeled with emotions Love, Joy, and Sadness; and group 3 contained 4000 issue sentences labeled with emotions Love, Joy, Anger, and Sadness. Novielli et al.  [55]  annotated a gold set from 4800 StackOverflow questions, answers, and comments. They labeled the sentences with Shaver et al  [73] 's six basic categories. Venigalla et al.  [82]  analyzed 10996 commit messages related to software documentation update from 998 GitHub projected and mapped them into Plutchik's eight emotion categories  [63] .",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Data Augmentation",
      "text": "Data augmentation (DA)  [24, 41]  is a technique for increasing training data diversity by targeted modification of the existing data. Insufficient quantity of high-quality training data is a common problem in machine learning, especially with the emergence of more complex models, e.g., deep learning. The concept of DA originates in image processing, where researchers observed that, e.g., rotating an image by 90 degrees produces a new training instance for image classification tasks that increases the robustness of the model. Applying DA to written text has recently gained popularity despite the fact that this is usually a more difficult problem due to the complex relationship among written words. More specifically, DA has to maintain label invariance, that is, the augmented instance needs to have the same label as the original instance.\n\nData augmentation works by applying augmentation operators, one or more times to each training set instance. Popular and simple DA operators for text are word insertion, word substitution, sentence shuffling, word deletion, etc. Figure  1  shows an example data augmentation of an utterance from a GitHub issue comment using these operators. However, research shows that operators that target the specific classification task (i.e., emotion detection) are significantly more effective than generic ones  [37] . Researchers also often use backtranslation (i.e., automatically translating to another language and back to English) and large language models (e.g., BERT) as DA operators, which are more likely to significantly change the original text, but with more risk towards perturbing the classification label.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Methodology 3.1 Data Selection",
      "text": "We selected four popular GitHub repositories, with each repository containing at least 50K stars. The repositories are: Flutter/flutter, Webpack/webpack, Microsoft/TypeScript, and Angular/angular. From each repository, we collected the last 10K comments (until 11 November, 2021) from pull requests and issues (5K pull request comments and 5K issue comments).",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Preprocessing And Dataset Creation",
      "text": "We preprocessed each issue and pull request comment to replace the url, user mentions, and code with '<url>', '<username>', and '<code>' respectively. Consistent with previous research  [8, 69] , we did not remove stop words. We also did not include any additional preprocessing, since the emotion classification tools we use (ESEM-E  [51] , EMTk  [9] , SEntiMoji  [13] ) have their own preprocessing steps.\n\nIn a preliminary analysis, we observed that many instances in the GitHub comments are neutral, i.e., do not contain any emotion  [52] . Our goal is to avoid creating a sparse dataset with mostly neutral instances, which would be inefficient and time-consuming to annotate. Novielli et al. also made a similar observation and performed selective sampling in creating their dataset of StackOverflow comments  [55] . Hence, to avoid including too many neutral instances, we applied a software engineering-specific sentiment analysis tool  [4]  to label the preprocessed instances into 'positive', 'negative', and 'neutral'. For each of the four repositories, we randomly selected 250 pull request comments (125 'positive' comments and 125 'negative' comments), 250 issue comments (125 'positive' comments and 125 'negative' comments), to reach a total of 2000 instances.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Emotion Categories",
      "text": "As our primary emotion model, we use Shaver's framework  [73]  of emotion which has been commonly used in several software engineering studies  [9, 51] . As shown in Table  1 , Shaver's framework is a hierarchical (tree-structured) emotion representation model. There are three levels. At the top level, there are 6 basic emotion categories: Anger, Love, Fear, Joy, Sadness, and Surprise. For each of the basic emotions, there are secondary and tertiary level emotions, which refine the granularity of the previous level. For example, Optimism and Hope are the secondary and tertiary level emotions for Joy, respectively.\n\nWe observed that some commonly expressed emotions in developer communications, such as Approval, Disapproval, Confusion, Curiosity, etc., are missing from Shaver's framework, which was not designed for emotions expressed in text. For example, the following GitHub comment can be categorized with the emotion Curiosity, \"I'm curious about this -can you give more context on what exactly goes wrong? Perhaps if that causes bugs this should be prohibited instead?\", but it does not clearly fit into any of Shaver's existing categories. Therefore, to accommodate a wider range of emotions observed in our dataset, we use the recent text-based emotion classification framework by Demszky et al., known as GoEmotions  [19] . GoEmotions uses 27 emotions to annotate Reddit comments, which are mapped to Ekman's  [22]  6 basic emotion categories. Note that, 5 of Shaver's basic emotions (Anger, Fear, Joy, Sadness, and Surprise) are the same as Ekman's basic categories. Ekman's basic category Disgust is a secondary emotion of Anger in Shaver's categories, and Shaver's basic category Love is a subcategory of Joy in Ekman's basic categories.\n\nTo enhance Shaver's categories, we include selected emotions from GoEmotions  [19]  (as shown in Table  1 ). We adopted GoEmotions's definitions and mapping only when an emotion is missing and does not conflict with Shaver's framework. The six additional secondary emotion categories that we adopted from GoEmotions  [19]  are highlighted in blue in Table  1 . Note that all the tertiary level emotions we used come directly from Shaver's framework  [73] ; we did not add additional tertiary level emotions.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Data Annotation",
      "text": "Pull request and issue comments in GitHub usually consist of multiple sentences. While sometimes each sentence may express different emotions, more often, the comment as a whole conveys an unique emotion. Therefore, in this study, we consider comment-level granularity for data annotation.\n\nTwo human judges (authors of this paper) were provided a set of GitHub comments with annotation instructions as follows: \"You will use the coding schema reported in You can use the second and third levels in the schema as a reference for choosing the primary emotion, but the annotation should be only for the primary emotions. Please mention the second and third-level emotions whenever they are prevalent, and provide a rationale for each annotation. Make sure you consider the emotion(s) of the entire The judges initially annotated a shared set of 400 comments. The sample size of 400 is sufficient to compute the annotator agreement measure with high confidence  [6] . The two annotators manually labeled the comments and measured Cohen's Kappa inter-rater agreement for the six basic emotions. For each of the emotions, they found agreement greater than 0.8, which is considered to be sufficient (> 0.6)  [77] . The annotators further discussed their annotations until all disagreements were resolved. Afterwards, the annotators separately annotated 800 instances each to reach a total of 2000 utterances. Figure  2  shows the distribution of basic emotion categories per project in the final annotated set. In total, our dataset consists of 310 instances of Anger, 220 instances of Love, 198 instances of Fear, 422 instances of Joy, 274 instances of Sadness, and 328 instances of Surprise.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Studied Emotion Classification Tools",
      "text": "We investigate three existing software engineering-specific emotion classification tools, which we describe as follows:\n\nESEM-E [51]: Murgia et al. proposed a emotion classification tool, which was later referred to as ESEM-E. ESEM-E used Parrott's emotion categories as classification targets  [62] , which are also featured in Shaver et al.'s model  [73] . While the source code of ESEM-E is not publicly available, we carefully read the descriptions detailed in the paper and implemented it. ESEM-E uses unigram and bigram features and machine learning (ML) models such as SVM, Random Forest, KNN, etc. As recommended by the authors, we use the SVM model.\n\nEMTk  [9] : Calefato et al. proposed EMTk (also known as EmoTxt), which was designed to identify developer emotions from textual communication channels. EMTk identifies six primary emotions according to Shaver's framework  [73] . The implemented tool is publicly available on GitHub. EMTk provides two types of data sampling, 'NoDownSampling' and 'DownSampling'; 'DownSampling' randomly samples the majority class to balance the amount of instances between the majority and minority class, while 'NoDown-Sampling' does not change the training data. We use 'NoDownSampling' to ensure that all of the three tools use the same training data set.\n\nSEntiMoji  [13] : Chen et al. proposed SEntiMoji, a transfer learning approach for emotion detection in software engineering (SE) text based on emojis. They concluded that SEntiMoji can significantly outperform existing emotion detection methods (e.g., DEVA  [35] , EMTk  [9] , MarValous  [34] , ESEM-E  [51] ) in software engineering. The SEntiMoji source code is publicly available in GitHub. SEntiMoji is developed based on DeepMoji  [23]  which is an existing deep learning based emoji representation model. The SEntiMoji model can identify various different emotion categorization schemas including Shaver's framework  [73] .",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "Metrics",
      "text": "We choose popular metrics used to evaluate a classification task: Precision, Recall and F1-score, which aggregates the prior two. In places where we present combined results across all emotions, we use the micro-averaged variants each of the metrics, as they are responsive to the frequency of occurrence of each constituent emotion.\n\n• Precision: Precision is the ratio of true positive observations to the total predicted positive observations.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Classification Results",
      "text": "To answer this RQ, we evaluate three well-known tools for software engineering emotion classification (ESEM-E  [51] , EMTk  [9] , SEntiMoji  [13] ), on our dataset of GitHub issue and pull request discussions (described in Section 3). The per-emotion performance of the emotion detection tools is summarized in Table  2 . The overall trend among all tools is for precision to be significantly higher than recall. In other words, the tools are acting conservatively, choosing to predict more utterances as negative (lacking a certain emotion) than positive, which leads to lower recall. Based on the aggregate  Results across all emotions are summarized in the bottom part of Table  2 . Here, on the micro-averaged F1-score metric, ESEM-E improves over the next best tool EMTk by 0.018 (4.3%). On microaveraged precision, EMTk improves over SEntiMoji by 0.036 (5.0%), while on micro-averaged recall, ESEM-E improves the next best tool EMTk by 0.073 (25.0%). While ESEM-E performs best by far on recall, its performance on precision is worse than EMTk by 0.206 (37.3%) and SEntiMoji by 0.17 (30.7%). Overall, across three tools, the average micro F1-score is 0.421.\n\nTo examine whether the tools tend to struggle on the same instances or if they have complementary strengths, we plot Venn diagrams of the false positive and false negative instances in Figure  3 . While the false positive instances seem to be broadly spread across different tools, the vast majority of false negatives instances are shared among the three tools. In total, 176/301 (58%) false negative instances across all emotions were misclassified by all three tools.",
      "page_start": 5,
      "page_end": 6
    },
    {
      "section_name": "Error Analysis Of Fns",
      "text": "Because of the unusually high agreement between the tools on the false negative (FN) instances, we focus our error analysis there, i.e., on the 176 FN instances.\n\nFirst, we examine the secondary emotions (as listed in Table  1 ) that are present in the FNs with the goal of understanding if specific emotions are particularly difficult to classify. We create a visualization in Figure  4  to understand the distribution of FN instances, i.e., to create the mapping of secondary emotion categories (right side of image) to the six basic level emotions (left side of image) in the FN instances. In this visualization, we only consider secondary emotion categories which has at least 5 FNs. The width of the ribbons of top level emotions represent their proportions in the dataset, while the width of the ribbons on the right side represent their proportion of FNs. We observe that some secondary emotions like Irritation, Nervousness and Zest have a significant number of FNs and represent the majority of FNs for basic emotions like Anger, Fear and Joy. For instance, Irritation expressed via comments like \"oh my god, explanation of official documents waste eight hours of me. Why isn't there a case to explain this\", was misclassified (as FN) 23 out of the 34 times (67.6%) it appeared in the test set. Nervousness, e.g., \"I guess my concern is that it sets a precedent where somebody could see it and think that it would be fine to use in core\", was also difficult to recognize as it was misclassified 21 out of 32 times (65.6%), while Zest was also mistaken often, with a misclassification frequency of 14/18 (77.8%). Relative to these hard to recognize emotions, Affection, which is part of the Love basic emotion, was a FN only 5 out of 35 times (14.3%).\n\nSecond, to understand the specific difficulties that the tools encountered, we performed a manual qualitative analysis of the 176 FNs. To perform this analysis, we use the error categories defined by Novielli et al.  [58]  to understand sentiment classification errors in software engineering text.\n\nFor each of the FN instances in our dataset, one of authors of this paper performed the initial error mapping, while another author reviewed it and indicated disagreements that were resolved via a discussion. In Table  3 , we report the distribution of error categories assigned to our FN instances. During the analysis, we observed that multiple error categories can be assigned to some of the FN instances in our dataset. Hence, we chose more than one (i.e., two) error categories for 16 FN instances, while the rest 160 (176 -16) instances were assigned one error category each.\n\nThe most frequent error category found in the FNs is General error, which indicates an inability to recognize lexical cues that occur in the text. For instance, in the comment \"that's awesome, I've been needing this for a while\", annotated as Joy, the tools likely missed clear lexical cues (e.g., the word \"awesome\"). Similarly for \"oh my god, explanation of official documents waste eight hours of me, Why isn't there a case to explain this\", annotated as Anger, the tools likely missed the idiomatic expression \"waste N hours of me\". In other cases, the classifiers miss due to misspellings or broken syntax, as in \"It's anoying me specifically when I want to set it as default value in constructors\", which is annotated as Anger. General error is also the most prevalent in 10 of the 13 secondary categories that are shown in Figure  4 .\n\nIn 61 cases, the tools failed because of the presence of Implicit sentiment polarity in texts. Often, humans use common knowledge to recognize emotions that the tools miss. Consider the following example \"Specifically, I'm less confident in the second commit than the first. AFAICT, it could only return true if a recursive call to itself returned true and all of the recursive base cases returned false. \". This was annotated as Fear (annotators perceived it as an expression of Worry -a 3rd level emotion that maps to Fear, see Table  1 ), but the emotion is not present explicitly. Sometimes, annotators inferred an emotion based on external knowledge. For instance, \"In that case I would advise you to please file a separate issue with the exact steps and logs to reproduce the issue. Because this issue is about existing apps. Thanks\", was annotated as Anger since the speaker is expressing a violation of the community rules (Irritation as the secondary emotion). Implicit sentiment polarity is the most prevalent in 4 our of the 13 secondary emotions in Figure  4  (one category was a tie with General error). As reported by Novielli et al.  [56] , hostile attitude is often implicit and indirect, which we observe in the error for Anger's secondary emotions like Exasperation and Irritation. Demszky et al.  [19]  noted that the Nervousness emotion is likely expressed implicitly, which we also observe in our data; the top error category of comments marked with Nervousness is Implicit sentiment polarity.\n\nIn 15 cases, we notice that the tools were not able to correctly classify utterances due to Pragmatics. This type of error occurs when the annotators consider the context of the comment. In the comment \"hmm, even after a push I still see this test on github, but not locally\", the author seems to have encountered something unexpected, which the annotators marked as Surprise.\n\nSometimes, the use of Figurative language, such as humor, irony, sarcasm, or metaphors, causes difficulties for the classifiers to identify emotions correctly. Often this type of utterances use neutral words to express an emotion. For example, \"Well, if you tried it you'd know\". In other cases, the lexical presence of Politeness, such as \"thank you\", \"please\", etc., may cause misclassification. For instance, consider the following example, \"Hi, thanks for your contribution, but we can't review this because you didn't follow the contributing instructions [...]\", which is marked as Anger due to the violation of community rules (secondary emotion -Irritation). In other cases, the utterances involve Polar facts, that is the utterance invokes an emotion for most people, i.e., the annotators consider the reported situation to invoke an emotion. For instance, in \"I blame the autoformatter. \", the annotators marked this comment as Anger as they considered the author was irritated for facing same problem (second level emotion -Irritation). Overall, we observe that Figurative language, Politeness and Polar facts usually occur in negative emotions (i.e., Anger, Sadness, Fear). The annotation in emotion and sentiment is a subjective task  [71]  as the perception of emotions varies depending on personality trait and personal relevant dispositions. We observe this in 3.1% cases in our error distribution. For instance, \"Do you understand that it is impossible in some cases or can lead to increase size of bundle?\" was considered as Regret (3rd level Sadness) by one annotator, however, the other annotator considered it \"Neutral\".\n\nTakeaway: Towards improving or designing new emotion classification tools, some types of errors could be more difficult to address than others. We hypothesize that tools should be able to improve on the most prevalent category of General error the most, as the lexical cues can be introduced via better training data, which could then be recognized by the tools. Towards that goal, we next investigate if Data Augmentation can be an effective strategy to automatically build better training data.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Rq2: Data Augmentation",
      "text": "RQ2: Can automatic data augmentation techniques be used to improve the effectiveness of existing emotion classifiers?",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Augmentation Strategies",
      "text": "We explore three different data augmentation strategies that target emotion classification in software engineering. For each strategy, we use augmentation operators that transform each instance from the training set into a number of augmented instances, each introducing a slightly different vocabulary or idioms into the training set. In fact, we augment by applying a randomly chosen set of our augmentation operators, one after the other in a \"stacked\" fashion. In some of the augmentation operators, we rely on recently-introduced generative techniques that are capable of introducing realistic word spans  [18, 38] .\n\nVia the different augmentation strategies we propose, we explore unconstrained vs. constrained choices of augmented data. For instance, we examine software-specific vs. generic choices of words to augment with, and how to ensure the original emotions are preserved (or enhanced) by the augmentation. Specifically, we introduce the following three data augmentation strategies: Unconstrained, Lexicon-based, and Polarity-based.\n\nUnconstrained Strategy. The unconstrained strategy uses augmentation operators that have been previously shown to be effective in NLP and applies them at a randomly chosen location in the text. Inspired by Kumar et al. 's  [38]  work where they found that a BART-based  [40]  generative model outperformed other strategies, we use BART to create generative augmentation operations such as Word Insertion and Word Substitution. The Unconstrained Strategy uses the following four operators:\n\n• Word Insertion using BART: We insert a word at any position in the original utterance. • Word Substitution using BART: We substitute a word at any position. • Word Deletion: We randomly delete a word at any position.\n\n• Sentence Shuffling: When an utterance has more than one sentence, we randomly shuffle the sentences.\n\nLexicon-based Strategy. We observe that sometimes the Unconstrained Strategy produces utterances that may not preserve the original emotion. Note that one of the primary requirements of data augmentation is label invariance, i.e., for the original label to be preserved through the transformation. To deal with this problem, we leverage a software engineering-specific emotion lexicon  [45]  in order to validate the augmented words generated through the Unconstrained Strategy. Specifically, for each augmented utterance produced by the Unconstrained Strategy, we check if the augmented words exhibit an emotion and if the word's emotion does not match the original emotion. In that case, we replace the word with a software engineering emotion-specific word that preserves the original emotion of the instance. If an utterance is annotated as Joy, and an augmented word exhibits a different emotion (and not Joy), we replace the word with a word from the Joy category of a software engineering-specific lexicon. For example, the Unconstrained Strategy augments the following utterance, which is annotated as Love, \"This looks good, thanks for clarifying the docs. \" to \"This looks worse, thanks for reviewing the docs.\". Here the introduction of the word \"worse\" changes the emotion of the original. However, if \"worse\" is replaced with a Love-specific word, i.e., \"wonderful\", the text becomes \"This looks wonderful, thanks for reviewing the docs. \", which preserves the original label.\n\nAs a lexicon, we use NRC's  [48]  emotion lexicon combined with the software engineering-specific emotional lexicon from Mäntylä et al. 's work  [45] , which contains a total of 428 words. Since Mäntylä et al.'s lexicon is not annotated with Shaver's basic emotion categories, we use NRC's emotion lexicon to map each word from Mäntylä et al.'s lexicon to Shaver's basic categories. For example, Mäntylä et al.'s lexicon contains the word afraid, which is also available in the NRC emotion lexicon. Since each word in the NRC lexicon is annotated with a specific category (e.g., the word afraid is annotated under the emotion category Fear), we map these words to Mäntylä et al. 's lexicon to get a lexicon that is software engineeringspecific and also has associated emotion categories.\n\nNote that, as the NRC emotion lexicon uses Plutchik's  [63]  emotion categories which has 8 basic emotions, we make two adjustments. First, their basic emotion Disgust is a subcategory in Shaver's basic emotion Anger. Therefore, we combine NRC's Disgust module with Anger module and use it in our Anger lexicon. Second, Plutchik's categories do not contain Shaver's basic category Love, therefore we use NRC's positive module instead as Love; the positive module contains words with positive polarity.\n\nPolarity-based Strategy. While the Lexicon-based Strategy removes some of the noise that is introduced by the Unconstrained Strategy, we believe the process can be streamlined and the augmentation quality further improved. For instance, a significant problem with the Lexicon-based Strategy is that it uses a lexicon with a very limited number of words. To overcome this constraint, instead of specific emotions, we focus on increasing the polarity words in the augmented instances. Inspired by GoEmotions'  [19]  grouping of emotions with sentiment polarity, we formulate three rules that augmented instances have to follow: 1) preserve (or increase) positive polarity words when the annotated utterance is Love and Joy, 2) preserve (or increase) negative polarity words when the annotated utterance is Anger, Fear and Sadness, and 3) preserve the original utterance polarity when the annotated utterance is Surprise.\n\nTo identify words that exhibit positive polarity, negative polarity or no polarity, we use SentiWordNet 3.0  [3] . While ensuring that each valid instance follows the above criteria, we generate new augmented instances using the same operators as for the Unconstrained Dataset. The only modification is that for Word Deletion, we only randomly delete a word if it does not exhibit sentiment polarity.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Augmentation Process",
      "text": "For all three of the above data augmentation strategies, for each instance in our training set, we generate 10 augmented instances, which is considered a reasonable augmentation ratio in the literature  [66] . For each generated instance, if Sentence Shuffling is used, we only apply it once. We apply n augmentation operations to each instance, where n = max(2, 20% of the length (i.e., number of words in the instance))  [87] . We use nlpaug  [44]  for the generative operations and use bart-base  [40]  as our BART model's weights. To further ensure that the augmented instance does not change the meaning of the original instance, we added an additional quality check where we ensure that the cosine similarity of BERTOverflow  [78]  vectors computed from the augmented and original instance are (>= 0.9) apart  [65] . BERTOverflow is software engineering-specific version of BERT  [20] , pre-trained on the StackOverflow data dump. We load BERTOverflow using the huggingface library  [84] .",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Augmentation Results And Discussion",
      "text": "Overall, across all three tools, all of the augmentation strategies improved performance over the original results (Table  4 ). The average micro F1-score improvement with the Unconstrained Strategy is 4.8% (0.441), with the Lexicon Strategy is 7.8% (0.455), and with the Polarity Strategy is 9.3% (0.461). Considering the three tools separately, we observe improved F1-score across the board, with EMTk benefiting the most using the Polarity Strategy with an improvement in F1-score of 13.7%.\n\nThe Unconstrained Strategy worked best with SEntiMoji by improving the F1-score by 7.7%. Both Lexicon Strategy and Polarity Strategy improved most with EMTk by 10.7% and 13.7% respectively. The reasons likely lie behind the feature extraction methods of EMTk, as its classification features are based on an emotion lexicon and polarity.\n\nESEM-E performed best with the Lexicon Strategy, outperforming the original dataset by 6.8%. As ESEM-E directly uses unigrams and bigrams as its features, it is likely that the repetition of lexical cues produced by the Lexicon Strategy significantly helped this tool. EMTk performed most effectively with the Polarity Strategy (13.7% improvement) as positive and negative sentiment polarity scores are one of its features. SEntiMoji performed best with the Polarity Strategy as well, outperforming the original dataset by 8.0%; however, SEntiMoji's performance did not vary significantly over all three augmentation approaches.\n\nThe emotions that are improved most with data augmentation strategies are Sadness and Joy, which is consistent with Murgia et al. 's  [52]  findings that they are easier to identify compared to other basic emotions. The reason is likely because data augmentation helped to introduce more lexical cues that were missing in the original dataset. In our analysis for RQ1, we observed that the most prevalent error category for Sadness and Joy FNs was General Error. Sadness achieved maximum F1-score of 0.557 in Unconstrained Strategy with SEntiMoji, and Joy achieved a maximum F1-score of 0.406 with the Polarity Strategy and ESEM-E. Surprise performed best with the Polarity Strategy where all three tools improved the F1-score with EMTk producing the best result, an F1-score of 0.630. Previous research shows that Surprise in SE is generally hard to detect, since it is not very frequent  [7, 42] . However, with the addition of GoEmotions's categories and data augmentation, detection of Surprise improved significantly. As noted in previous research  [7, 52] , Anger and Fear are difficult to predict, as they often depend on the message context. During our error analysis, we saw that most Implicit sentiment polarity errors occur with Anger and Fear. These type of errors were difficult to identify even after data augmentation. SEntiMoji did not improve Anger performance in any of the strategies; while EMTk improved, its performance with the initial dataset was very low. In the case of Fear, ESEM-E did not improve with any of the strategies. However, Fear performed significantly better with the Polarity Strategy in EMTk, achieving F1-score of 0.473. Further research on what caused EMTk to perform better for Fear may help to pinpoint how to further improve classifying this emotion.\n\nOne interesting case is that with the original dataset, Love performed best across all three tools, however, with data augmentation, the performance of Love did not improve significantly. This points to a limitation of data augmentation in that it can only be of a limited benefit, i.e., useful only in cases where sufficient lexical cues are not already present in the data.\n\nTakeaway: Overall, we observe that Data Augmentation generally improves emotion classification performance across different emotions and tools. We observe improvements especially when the initial dataset has insufficient lexical cues for a specific emotion. Out of the three augmentation strategies we experimented with, the Polarity Strategy worked really well, as it provided a balance between completely unconstrained augmentation (which introduces noise) and highly constrained augmentation (which fails to increase size and diversity). Data augmentation is likely only able to improve performance up to point, as our current augmentation operators do not seem to help in identifying implicit emotions, such as Sarcasm.",
      "page_start": 8,
      "page_end": 9
    },
    {
      "section_name": "Related Work",
      "text": "Below, we describe the related work sourced from two different domains: emotion analysis of software artifacts, and data augmentation in the domain of Natural Language Processing (NLP).",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Emotion Analysis Of Software Artifacts",
      "text": "One of the earliest emotion analysis of software artifacts can be found in Murgia et al. 's work  [52] , where they manually analyzed 800 issue comments and concluded that some basic emotions such as Love, Joy and Sadness are easier to identify in text. In their later work, Murgia et al.  [51]  proposed an automated approach (namely, ESEM-E) to detect emotions in software artifacts. Motivated by their earlier work, they only focused on automatically identifying Love, Joy and Sadness in Ortu el al.'s JIRA-based dataset  [61] . Calefato et al.  [9]  developed a feature extraction-based machine learning technique EMTk (also known as EmoTxt). They evaluated EMTk on the StackOverflow dataset initially developed by Novielli et. al.  [55] , which was annotated with Shaver's six basic emotions  [73] . Neupane et al.  [54]  investigated emotion dynamics in GitHub repositories, using EMTk as their primary model. Cabrera-Diego et al.  [7]  used the multi-label classifiers HOMER  [80]  and RAkEL  [81]  on the above mentioned JIRA and StackOverflow datasets, observing that HOMER and RAkEL achieved a better micro F1-score than EMTk on the JIRA dataset and similar performance on the StackOverflow dataset. They concluded that EMTk is a conservative tool in general. Both the JIRA and StackOverflow dataset, however, have a limited number of utterances in certain emotion categories. The JIRA dataset only focuses on four categories of emotions (Love, Sadness, Joy, and Anger), while the StackOverflow dataset has a prevalence of Love compared to other categories and has a very limited number of Surprise instances. One of our focus areas in this paper has been on curating a dataset where all the emotion categories are represented in sufficient quantity.\n\nVenigalla et al.  [82]  analyzed software developers' emotions towards software documentation using the NRC emotion analyzer module  [48]  of the Syuzhet package  [36] . In our work, we also use the NRC's emotion module, but for data augmentation. Another thread of research in this area is based on the VAD (Valence, Arousal, and Dominance) model  [68] , where specific emotions are represented as a mixture of these three numerically-expressed quantities. For instance, VAD can express emotions such as, Excitement and EMTk  [9]  on the JIRA and StackOverflow dataset, it showed overall improvement across all six basic emotions. SEntiMoji was also compared against DEVA  [35]  and MarValous  [34] , and was shown to achieve better performance than these two tools as well.\n\nIn our research, we compare the tools that use Shaver's emotion categories, SEntiMoji, EMSM-E, and EMTk, using a GitHub-based dataset that we curate. We consider data augmentation as the means to improve performance in all three of these tools.",
      "page_start": 9,
      "page_end": 10
    },
    {
      "section_name": "Data Augmentation In Nlp",
      "text": "The augmentation of textual data (i.e., in NLP) has been an area of considerable interest in recent years to address the data scarcity problem related to different tasks such as, subjectivity detection  [32] , question understanding and summarization  [49] . Early techniques of interest in data augmentation included synonym replacement  [89] , i.e., replacing a word with its synonym, and BackTranslation  [72] , i.e., paraphrasing a text by converting to a second language and then converting back to original language. Inspired by similar approaches in computer vision, researchers also devised MixUp augmentation  [74, 88] , which meshes together existing examples in order to create new augmented instances. Another recent research direction is Unsupervised Data Augmentation  [86]  (UDA) which is a semi-supervised model that outperformed state-of-the-art methods using only 20 labeled instances. Wei el al.  [83]  proposed a method -Easy Data Augmentation (EDA) which worked surprisingly well for smaller datasets despite being a simple technique that uses straightforward operators, e.g., synonym replacement using WordNet  [47] , random insertion, random swap, and random deletion. As software artifact datasets are often small  [64] , we were inspired by EDA in devising our data augmentation technique. A recent research thread in data augmentation is contextual augmentation  [74] , using various large language models such as CBERT  [85] , BART  [38] , GPT-2  [2] , etc. Kumer at al.  [38]  showed that for classification tasks, BART outperforms other models due to its ability to generate longer sequences of text in context. In this paper, we also leverage the BART model as part of our augmentation operators.",
      "page_start": 10,
      "page_end": 11
    },
    {
      "section_name": "Threats To Validity",
      "text": "Several limitations may impact the interpretation of our findings. We categorize and list each of them below. Construct validity. Construct validity concerns the relationship between theory and observation. Shaver's emotions model  [73]  and the GoEmotions model by Demszky et al.  [19]  are two different schema. We use a combination of the two, which may violate their original design. To mitigate this risk, we carefully read both of the original researches and used Shaver's model as our primary schema, integrating GoEmotions' categories only when they are complementary and do not conflict with Shaver's in any part of their definitions. Furthermore, the error analysis in RQ1 shows that none of the emotion categories that integrated GoEmotions are among the worse performing. Instead, the addition of GoEmotions secondary emotion categories specifically improves the performance of the basic category Surprise, which has exhibited relatively low F1-score in previous research in software engineering emotion classification  [42] .\n\nInternal validity. Internal validity concerns the study design factors that may influence the results. One such threat to our study is not doing cross validation, which would have improved the reliability of the results. We mitigate this threat by using stratified sampling and a reasonable train-test data split of 80%-20% respectively. Another threat is that, to conduct our experiments we use existing tools and their released code, except for ESEM-E  [51] . It is possible that we have incorrectly implemented ESEM-E, although, we explicitly followed the authors' instructions to mitigate this threat. The subjectivity of annotating emotions (and in the error analysis) presents another threat to internal validity. However, the use of a three tiered emotion structure and high inter rater agreement (> 0.8) ensure the reliability of the annotation procedure.\n\nExternal validity. External validity concerns the generalization of our findings. Our study shows that data augmentation improves emotion classification across the three tools we experimented with. However, the specific augmentation strategies may not generalize beyond the three tools we studied and our dataset extracted from GitHub comments. More specifically, our findings may not generalize over other types of artifacts in software engineering, such as StackOverflow, JIRA, etc. While our results introduce the potential of data augmentation for emotion classification, further investigation is needed in other to validate our results beyond the tools and the data used in our study.",
      "page_start": 10,
      "page_end": 11
    },
    {
      "section_name": "Conclusion And Future Work",
      "text": "In this paper, we first conduct a qualitative study to understand the limitations of the existing machine learning-based tools for classifying emotions in software engineering-related text. Specifically, we evaluate ESEM-E  [51] , EMTk  [9] , SEntiMoji  [13]  on our curated dataset of 2000 GitHub pull requests and issue comments. We observe that some types of errors could be more difficult to address than others, however there is a scope to improve the performance of the existing tools by creating better training data. Thus, next we investigate three types of data augmentation strategies that could be leveraged to improve emotion detection in software-related text. Our results indicate that augmentation operators that target words with specific polarity are significantly more effective than generic augmentation operators. Using polarity-based augmentation shows an average improvement of 9.3% in micro F1-Score across the three existing emotion classification tools.\n\nOur immediate next steps focus on investigating more diverse data sources, including other types of software artifacts such as StackOverflow, Slack chats, etc. We are also interested in exploring new data augmentation techniques based on large language models that are pre-trained on software engineering corpora and fine-tuned to emotion and sentiment-type tasks. Finally, we would like to explore if polarity based data augmentation strategies could improve other related tasks in software engineering, such as sentiment analysis.",
      "page_start": 10,
      "page_end": 11
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Example of data augmentation using four opera-",
      "page": 2
    },
    {
      "caption": "Figure 1: shows an example",
      "page": 3
    },
    {
      "caption": "Figure 2: Frequency of emotions per project.",
      "page": 4
    },
    {
      "caption": "Figure 2: shows the distribution of basic emo-",
      "page": 4
    },
    {
      "caption": "Figure 3: Distribution of FPs and FNs across different tools.",
      "page": 5
    },
    {
      "caption": "Figure 4: FNs mapped to their secondary emotions (𝑛>= 5).",
      "page": 6
    },
    {
      "caption": "Figure 4: to understand the distribution of FN instances, i.e.,",
      "page": 6
    },
    {
      "caption": "Figure 4: In 61 cases, the tools failed because of the presence of Implicit",
      "page": 6
    },
    {
      "caption": "Figure 4: (one category was a",
      "page": 6
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Anger": "",
          "Irritation": "Exasperation",
          "Annoyance, Agitation, Grumpiness, Aggra-\nvation, Grouchiness": "Frustration"
        },
        {
          "Anger": "",
          "Irritation": "Rage",
          "Annoyance, Agitation, Grumpiness, Aggra-\nvation, Grouchiness": "Anger, Fury, Hate, Dislike, Resentment,\nOutrage, Wrath, Hostility, Bitterness, Fe-\nrocity, Loathing, Scorn, Spite, Vengefulness"
        },
        {
          "Anger": "",
          "Irritation": "Envy",
          "Annoyance, Agitation, Grumpiness, Aggra-\nvation, Grouchiness": "Jealousy"
        },
        {
          "Anger": "",
          "Irritation": "Disgust",
          "Annoyance, Agitation, Grumpiness, Aggra-\nvation, Grouchiness": "Revulsion, Contempt, Loathing"
        },
        {
          "Anger": "",
          "Irritation": "Torment",
          "Annoyance, Agitation, Grumpiness, Aggra-\nvation, Grouchiness": "-"
        },
        {
          "Anger": "",
          "Irritation": "Disapproval",
          "Annoyance, Agitation, Grumpiness, Aggra-\nvation, Grouchiness": "-"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Joy": "",
          "Cheerfulness": "Zest",
          "Happiness, Amusement, Satisfaction, Bliss,\nGaiety, Glee,\nJolliness,\nJoviality,\nJoy, De-\nlight, Enjoyment, Gladness, Jubilation, Ela-\ntion, Ecstasy, Euphoria": "Enthusiasm, Excitement, Thrill, Zeal, Ex-\nhilaration"
        },
        {
          "Joy": "",
          "Cheerfulness": "Contentment",
          "Happiness, Amusement, Satisfaction, Bliss,\nGaiety, Glee,\nJolliness,\nJoviality,\nJoy, De-\nlight, Enjoyment, Gladness, Jubilation, Ela-\ntion, Ecstasy, Euphoria": "Pleasure"
        },
        {
          "Joy": "",
          "Cheerfulness": "Optimism",
          "Happiness, Amusement, Satisfaction, Bliss,\nGaiety, Glee,\nJolliness,\nJoviality,\nJoy, De-\nlight, Enjoyment, Gladness, Jubilation, Ela-\ntion, Ecstasy, Euphoria": "Eagerness, Hope"
        },
        {
          "Joy": "",
          "Cheerfulness": "Pride",
          "Happiness, Amusement, Satisfaction, Bliss,\nGaiety, Glee,\nJolliness,\nJoviality,\nJoy, De-\nlight, Enjoyment, Gladness, Jubilation, Ela-\ntion, Ecstasy, Euphoria": "Triumph"
        },
        {
          "Joy": "",
          "Cheerfulness": "Enthrallment",
          "Happiness, Amusement, Satisfaction, Bliss,\nGaiety, Glee,\nJolliness,\nJoviality,\nJoy, De-\nlight, Enjoyment, Gladness, Jubilation, Ela-\ntion, Ecstasy, Euphoria": "Enthrallment, Rapture"
        },
        {
          "Joy": "",
          "Cheerfulness": "Relief",
          "Happiness, Amusement, Satisfaction, Bliss,\nGaiety, Glee,\nJolliness,\nJoviality,\nJoy, De-\nlight, Enjoyment, Gladness, Jubilation, Ela-\ntion, Ecstasy, Euphoria": "-"
        },
        {
          "Joy": "",
          "Cheerfulness": "Approval",
          "Happiness, Amusement, Satisfaction, Bliss,\nGaiety, Glee,\nJolliness,\nJoviality,\nJoy, De-\nlight, Enjoyment, Gladness, Jubilation, Ela-\ntion, Ecstasy, Euphoria": "-"
        },
        {
          "Joy": "",
          "Cheerfulness": "Admiration",
          "Happiness, Amusement, Satisfaction, Bliss,\nGaiety, Glee,\nJolliness,\nJoviality,\nJoy, De-\nlight, Enjoyment, Gladness, Jubilation, Ela-\ntion, Ecstasy, Euphoria": "-"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Sadness": "",
          "Suffering": "Sadness",
          "Hurt, Anguish, Agony": "Depression, Sorrow, Despair, Gloom, Hope-\nlessness, Glumness, Unhappiness, Grief,\nWoe, Misery, Melancholy"
        },
        {
          "Sadness": "",
          "Suffering": "Disappoint",
          "Hurt, Anguish, Agony": "Displeasure, Dismay"
        },
        {
          "Sadness": "",
          "Suffering": "Shame",
          "Hurt, Anguish, Agony": "Guilt, Regret, Remorse"
        },
        {
          "Sadness": "",
          "Suffering": "Neglect",
          "Hurt, Anguish, Agony": "Embarrassment,\nInsecurity,\nInsult,\nRe-\njection, Alienation,\nIsolation, Loneliness,\nHomesickness, Defeat, Dejection, Humilia-\ntion"
        },
        {
          "Sadness": "",
          "Suffering": "Sympathy",
          "Hurt, Anguish, Agony": "Pity"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Anger": "Love",
          "ESEM-E\nEMTk\nSEntiMoji": "ESEM-E\nEMTk\nSEntiMoji",
          "0.405\n0.571\n0.600": "0.651\n0.786\n0.733",
          "0.250\n0.118\n0.265": "0.636\n0.500\n0.500",
          "0.309\n0.200\n0.367": "0.644\n0.611\n0.595"
        },
        {
          "Anger": "Fear",
          "ESEM-E\nEMTk\nSEntiMoji": "ESEM-E\nEMTk\nSEntiMoji",
          "0.405\n0.571\n0.600": "0.533\n1.00\n0.714",
          "0.250\n0.118\n0.265": "0.200\n0.200\n0.125",
          "0.309\n0.200\n0.367": "0.291\n0.333\n0.213"
        },
        {
          "Anger": "Joy",
          "ESEM-E\nEMTk\nSEntiMoji": "ESEM-E\nEMTk\nSEntiMoji",
          "0.405\n0.571\n0.600": "0.458\n0.640\n0.609",
          "0.250\n0.118\n0.265": "0.321\n0.190\n0.167",
          "0.309\n0.200\n0.367": "0.378\n0.294\n0.262"
        },
        {
          "Anger": "Sadness",
          "ESEM-E\nEMTk\nSEntiMoji": "ESEM-E\nEMTk\nSEntiMoji",
          "0.405\n0.571\n0.600": "0.759\n0.778\n0.857",
          "0.250\n0.118\n0.265": "0.400\n0.382\n0.327",
          "0.309\n0.200\n0.367": "0.524\n0.512\n0.474"
        },
        {
          "Anger": "Surprise",
          "ESEM-E\nEMTk\nSEntiMoji": "ESEM-E\nEMTk\nSEntiMoji",
          "0.405\n0.571\n0.600": "0.596\n0.823\n0.846",
          "0.250\n0.118\n0.265": "0.431\n0.446\n0.338",
          "0.309\n0.200\n0.367": "0.500\n0.580\n0.484"
        }
      ],
      "page": 5
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Anger": "",
          "Unconstrained": "Lexicon",
          "ESEM-E\nEMTk\nSEntiMoji": "ESEM-E\nEMTk\nSEntiMoji",
          "0.567\n0.571\n0.630": "0.581\n0.531\n0.625",
          "0.250\n0.235\n0.250": "0.265\n0.250\n0.221",
          "0.347 (12.3%)\n0.333 (66.5%)\n0.358 (-2.5%)": "0.364 (17.8%)\n0.340 (70.0%)\n0.326 (-11.2%)"
        },
        {
          "Anger": "",
          "Unconstrained": "Polarity",
          "ESEM-E\nEMTk\nSEntiMoji": "ESEM-E\nEMTk\nSEntiMoji",
          "0.567\n0.571\n0.630": "0.500\n0.609\n0.615",
          "0.250\n0.235\n0.250": "0.235\n0.206\n0.235",
          "0.347 (12.3%)\n0.333 (66.5%)\n0.358 (-2.5%)": "0.320 (3.6%)\n0.308 (54.0%)\n0.340 (-7.4%)"
        },
        {
          "Anger": "Love",
          "Unconstrained": "Unconstrained",
          "ESEM-E\nEMTk\nSEntiMoji": "ESEM-E\nEMTk\nSEntiMoji",
          "0.567\n0.571\n0.630": "0.596\n0.703\n0.719",
          "0.250\n0.235\n0.250": "0.636\n0.591\n0.523",
          "0.347 (12.3%)\n0.333 (66.5%)\n0.358 (-2.5%)": "0.615 (-4.5%)\n0.642 (5.1%)\n0.605 (1.7%)"
        },
        {
          "Anger": "",
          "Unconstrained": "Lexicon",
          "ESEM-E\nEMTk\nSEntiMoji": "ESEM-E\nEMTk\nSEntiMoji",
          "0.567\n0.571\n0.630": "0.630\n0.659\n0.710",
          "0.250\n0.235\n0.250": "0.659\n0.614\n0.500",
          "0.347 (12.3%)\n0.333 (66.5%)\n0.358 (-2.5%)": "0.644 (0.0%)\n0.635 (3.9%)\n0.587 (-1.3%)"
        },
        {
          "Anger": "",
          "Unconstrained": "Polarity",
          "ESEM-E\nEMTk\nSEntiMoji": "ESEM-E\nEMTk\nSEntiMoji",
          "0.567\n0.571\n0.630": "0.667\n0.727\n0.733",
          "0.250\n0.235\n0.250": "0.682\n0.545\n0.500",
          "0.347 (12.3%)\n0.333 (66.5%)\n0.358 (-2.5%)": "0.674 (4.7%)\n0.623 (2.0%)\n0.595 (0.0%)"
        },
        {
          "Anger": "Fear",
          "Unconstrained": "Unconstrained",
          "ESEM-E\nEMTk\nSEntiMoji": "ESEM-E\nEMTk\nSEntiMoji",
          "0.567\n0.571\n0.630": "0.545\n0.600\n0.700",
          "0.250\n0.235\n0.250": "0.150\n0.225\n0.175",
          "0.347 (12.3%)\n0.333 (66.5%)\n0.358 (-2.5%)": "0.235 (-19.2%)\n0.327 (-1.8%)\n0.280 (31.5%)"
        },
        {
          "Anger": "",
          "Unconstrained": "Lexicon",
          "ESEM-E\nEMTk\nSEntiMoji": "ESEM-E\nEMTk\nSEntiMoji",
          "0.567\n0.571\n0.630": "0.600\n0.818\n0.636",
          "0.250\n0.235\n0.250": "0.150\n0.225\n0.175",
          "0.347 (12.3%)\n0.333 (66.5%)\n0.358 (-2.5%)": "0.231 (-20.6%)\n0.353 (6.0%)\n0.275 (29.1%)"
        },
        {
          "Anger": "",
          "Unconstrained": "Polarity",
          "ESEM-E\nEMTk\nSEntiMoji": "ESEM-E\nEMTk\nSEntiMoji",
          "0.567\n0.571\n0.630": "0.500\n0.867\n0.600",
          "0.250\n0.235\n0.250": "0.150\n0.325\n0.150",
          "0.347 (12.3%)\n0.333 (66.5%)\n0.358 (-2.5%)": "0.231 (-20.6%)\n0.473 (42.0%)\n0.240 (12.7%)"
        },
        {
          "Anger": "Joy",
          "Unconstrained": "Unconstrained",
          "ESEM-E\nEMTk\nSEntiMoji": "ESEM-E\nEMTk\nSEntiMoji",
          "0.567\n0.571\n0.630": "0.456\n0.486\n0.477",
          "0.250\n0.235\n0.250": "0.310\n0.214\n0.250",
          "0.347 (12.3%)\n0.333 (66.5%)\n0.358 (-2.5%)": "0.369 (-2.4%)\n0.298 (1.4%)\n0.328 (25.2%)"
        },
        {
          "Anger": "",
          "Unconstrained": "Lexicon",
          "ESEM-E\nEMTk\nSEntiMoji": "ESEM-E\nEMTk\nSEntiMoji",
          "0.567\n0.571\n0.630": "0.500\n0.590\n0.526",
          "0.250\n0.235\n0.250": "0.321\n0.274\n0.238",
          "0.347 (12.3%)\n0.333 (66.5%)\n0.358 (-2.5%)": "0.391 (3.4%)\n0.374 (27.2%)\n0.328 (25.2%)"
        },
        {
          "Anger": "",
          "Unconstrained": "Polarity",
          "ESEM-E\nEMTk\nSEntiMoji": "ESEM-E\nEMTk\nSEntiMoji",
          "0.567\n0.571\n0.630": "0.492\n0.613\n0.575",
          "0.250\n0.235\n0.250": "0.345\n0.226\n0.274",
          "0.347 (12.3%)\n0.333 (66.5%)\n0.358 (-2.5%)": "0.406 (7.4%)\n0.330 (12.2%)\n0.371 (41.6%)"
        },
        {
          "Anger": "Sadness",
          "Unconstrained": "Unconstrained",
          "ESEM-E\nEMTk\nSEntiMoji": "ESEM-E\nEMTk\nSEntiMoji",
          "0.567\n0.571\n0.630": "0.767\n0.909\n0.917",
          "0.250\n0.235\n0.250": "0.418\n0.364\n0.400",
          "0.347 (12.3%)\n0.333 (66.5%)\n0.358 (-2.5%)": "0.541 (3.2%)\n0.519 (1.4%)\n0.557 (17.5%)"
        },
        {
          "Anger": "",
          "Unconstrained": "Lexicon",
          "ESEM-E\nEMTk\nSEntiMoji": "ESEM-E\nEMTk\nSEntiMoji",
          "0.567\n0.571\n0.630": "0.759\n0.719\n0.875",
          "0.250\n0.235\n0.250": "0.400\n0.418\n0.382",
          "0.347 (12.3%)\n0.333 (66.5%)\n0.358 (-2.5%)": "0.524 (0.0%)\n0.529 (3.3%)\n0.532 (12.2%)"
        },
        {
          "Anger": "",
          "Unconstrained": "Polarity",
          "ESEM-E\nEMTk\nSEntiMoji": "ESEM-E\nEMTk\nSEntiMoji",
          "0.567\n0.571\n0.630": "0.710\n0.821\n0.913",
          "0.250\n0.235\n0.250": "0.400\n0.418\n0.382",
          "0.347 (12.3%)\n0.333 (66.5%)\n0.358 (-2.5%)": "0.512 (-2.3%)\n0.554 (8.2%)\n0.538 (13.5%)"
        },
        {
          "Anger": "Surprise",
          "Unconstrained": "Unconstrained",
          "ESEM-E\nEMTk\nSEntiMoji": "ESEM-E\nEMTk\nSEntiMoji",
          "0.567\n0.571\n0.630": "0.646\n0.784\n0.767",
          "0.250\n0.235\n0.250": "0.477\n0.446\n0.354",
          "0.347 (12.3%)\n0.333 (66.5%)\n0.358 (-2.5%)": "0.549 (9.8%)\n0.569 (-1.9%)\n0.484 (0.0%)"
        },
        {
          "Anger": "",
          "Unconstrained": "Lexicon",
          "ESEM-E\nEMTk\nSEntiMoji": "ESEM-E\nEMTk\nSEntiMoji",
          "0.567\n0.571\n0.630": "0.667\n0.732\n0.857",
          "0.250\n0.235\n0.250": "0.523\n0.462\n0.369",
          "0.347 (12.3%)\n0.333 (66.5%)\n0.358 (-2.5%)": "0.586 (17.2%)\n0.566 (-2.4%)\n0.516 (6.6%)"
        },
        {
          "Anger": "",
          "Unconstrained": "Polarity",
          "ESEM-E\nEMTk\nSEntiMoji": "ESEM-E\nEMTk\nSEntiMoji",
          "0.567\n0.571\n0.630": "0.654\n0.791\n0.852",
          "0.250\n0.235\n0.250": "0.523\n0.523\n0.354",
          "0.347 (12.3%)\n0.333 (66.5%)\n0.358 (-2.5%)": "0.581 (16.2%)\n0.630 (8.6%)\n0.500 (3.3%)"
        }
      ],
      "page": 9
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Overall": "",
          "Unconstrained": "Lexicon",
          "ESEM-E\nEMTk\nSEntiMoji\nAverage": "ESEM-E\nEMTk\nSEntiMoji\nAverage",
          "0.587\n0.659\n0.681\n0.642": "0.610\n0.658\n0.699\n0.656",
          "0.368\n0.326\n0.317\n0.337": "0.382\n0.362\n0.306\n0.350",
          "0.453 (3.0%)\n0.436 (3.3%)\n0.433 (7.7%)\n0.441 (4.8%)": "0.470 (6.8%)\n0.467 (10.7%)\n0.426 (6.0%)\n0.454 (7.8%)"
        },
        {
          "Overall": "",
          "Unconstrained": "Polarity",
          "ESEM-E\nEMTk\nSEntiMoji\nAverage": "ESEM-E\nEMTk\nSEntiMoji\nAverage",
          "0.587\n0.659\n0.681\n0.642": "0.593\n0.734\n0.712\n0.680",
          "0.368\n0.326\n0.317\n0.337": "0.385\n0.357\n0.312\n0.351",
          "0.453 (3.0%)\n0.436 (3.3%)\n0.433 (7.7%)\n0.441 (4.8%)": "0.467 (6.1%)\n0.480 (13.7%)\n0.434 (8.0%)\n0.460 (9.3%)"
        }
      ],
      "page": 9
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Affect and Creativity at Work",
      "authors": [
        "T Amabile",
        "G Sigal",
        "J Barsade",
        "B Mueller",
        "Staw"
      ],
      "year": "2005",
      "venue": "Administrative Science Quarterly"
    },
    {
      "citation_id": "2",
      "title": "Do Not Have Enough Data? Deep Learning to the Rescue!",
      "authors": [
        "Ateret Anaby-Tavor",
        "Boaz Carmeli",
        "Esther Goldbraich",
        "Amir Kantor",
        "George Kour",
        "Segev Shlomov",
        "N Tepper",
        "Naama Zwerdling"
      ],
      "year": "2020",
      "venue": "AAAI"
    },
    {
      "citation_id": "3",
      "title": "Sentiwordnet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining",
      "authors": [
        "Stefano Baccianella",
        "Andrea Esuli",
        "Fabrizio Sebastiani"
      ],
      "year": "2010",
      "venue": "Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC'10)"
    },
    {
      "citation_id": "4",
      "title": "Achieving Reliable Sentiment Analysis in the Software Engineering Domain using BERT",
      "authors": [
        "Eeshita Biswas",
        "Mehmet Karabulut",
        "Lori Pollock",
        "K Vijay-Shanker"
      ],
      "year": "2020",
      "venue": "2020 IEEE International Conference on Software Maintenance and Evolution (ICSME)"
    },
    {
      "citation_id": "5",
      "title": "Variance reduction",
      "authors": [
        "Zdravko Botev",
        "Ad Ridder"
      ],
      "year": "2017",
      "venue": "Wiley statsRef: Statistics reference online"
    },
    {
      "citation_id": "6",
      "title": "A Simplified Guide to Determination of Sample Size Requirements for Estimating the Value of Intraclass Correlation Coefficient: a Review",
      "authors": [
        "Mohamad Adam",
        "Nurakmal Baharum"
      ],
      "year": "2017",
      "venue": "Archives of Orofacial Science"
    },
    {
      "citation_id": "7",
      "title": "Classifying emotions in Stack Overflow and JIRA using a multi-label approach",
      "authors": [
        "Luis Adrián Cabrera-Diego",
        "Nik Bessis",
        "Ioannis Korkontzelos"
      ],
      "year": "2020",
      "venue": "Knowledge-Based Systems"
    },
    {
      "citation_id": "8",
      "title": "Sentiment Polarity Detection for Software Development",
      "authors": [
        "Fabio Calefato",
        "Filippo Lanubile",
        "Federico Maiorano",
        "Nicole Novielli"
      ],
      "year": "2017",
      "venue": "Empirical Software Engineering"
    },
    {
      "citation_id": "9",
      "title": "EMTk -The Emotion Mining Toolkit",
      "authors": [
        "Fabio Calefato",
        "Filippo Lanubile",
        "Nicole Novielli",
        "Luigi Quaranta"
      ],
      "year": "2019",
      "venue": "IEEE/ACM 4th International Workshop on Emotion Awareness in Software Engineering"
    },
    {
      "citation_id": "10",
      "title": "Automatically Identifying the Quality of Developer Chats for Post Hoc Use",
      "authors": [
        "P Chatterjee",
        "K Damevski",
        "N Kraft",
        "L Pollock"
      ],
      "year": "2020",
      "venue": "In Transactions on Software Engineering and Methodology"
    },
    {
      "citation_id": "11",
      "title": "Automatic Extraction of Opinion-based Q&A from Online Developer Chats",
      "authors": [
        "Preetha Chatterjee",
        "Kostadin Damevski",
        "Lori Pollock"
      ],
      "year": "2021",
      "venue": "Proceedings of the 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)",
      "doi": "10.1109/ICSE43902.2021.00115"
    },
    {
      "citation_id": "12",
      "title": "Exploratory Study of Slack Q&A Chats as a Mining Source for Software Engineering Tools",
      "authors": [
        "P Chatterjee",
        "K Damevski",
        "L Pollock",
        "V Augustine",
        "N Kraft"
      ],
      "year": "2019",
      "venue": "Proceedings of the 16th International Conference on Mining Software Repositories (MSR'19",
      "doi": "10.1109/MSR.2019.00075"
    },
    {
      "citation_id": "13",
      "title": "SEntiMoji: An Emoji-Powered Learning Approach for Sentiment Analysis in Software Engineering",
      "authors": [
        "Zhenpeng Chen",
        "Yanbin Cao",
        "Xuan Lu",
        "Qiaozhu Mei",
        "Xuanzhe Liu"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering",
      "doi": "10.1145/3338906.3338977"
    },
    {
      "citation_id": "14",
      "title": "Emoji-Powered Sentiment and Emotion Detection from Software Developers' Communication Data",
      "authors": [
        "Zhenpeng Chen",
        "Yanbin Cao",
        "Huihan Yao",
        "Xuan Lu",
        "Xin Peng",
        "Hong Mei",
        "Xuanzhe Liu"
      ],
      "year": "2021",
      "venue": "ACM Trans. Softw. Eng. Methodol",
      "doi": "10.1145/3424308"
    },
    {
      "citation_id": "15",
      "title": "Mapping 24 emotions conveyed by brief human vocalization",
      "authors": [
        "Alan Cowen",
        "Hillary Anger Elfenbein",
        "Petri Laukka",
        "Dacher Keltner"
      ],
      "year": "2019",
      "venue": "American Psychologist"
    },
    {
      "citation_id": "16",
      "title": "Self-report captures 27 distinct categories of emotion bridged by continuous gradients",
      "authors": [
        "Alan Cowen",
        "Dacher Keltner"
      ],
      "year": "2017",
      "venue": "Self-report captures 27 distinct categories of emotion bridged by continuous gradients"
    },
    {
      "citation_id": "17",
      "title": "What the face displays: Mapping 28 emotions conveyed by naturalistic expression",
      "authors": [
        "Alan Cowen",
        "Dacher Keltner"
      ],
      "year": "2020",
      "venue": "American Psychologist"
    },
    {
      "citation_id": "18",
      "title": "Generative Adversarial Networks: An Overview",
      "authors": [
        "Antonia Creswell",
        "Tom White",
        "Vincent Dumoulin",
        "Kai Arulkumaran",
        "Biswa Sengupta",
        "Anil Bharath"
      ],
      "year": "2018",
      "venue": "IEEE Signal Processing Magazine",
      "doi": "10.1109/MSP.2017.2765202"
    },
    {
      "citation_id": "19",
      "title": "GoEmotions: A Dataset of Fine-Grained Emotions",
      "authors": [
        "Dorottya Demszky",
        "Dana Movshovitz-Attias",
        "Jeongwoo Ko",
        "Alan Cowen",
        "Gaurav Nemade",
        "Sujith Ravi"
      ],
      "year": "2020",
      "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020",
      "doi": "10.18653/v1/2020.acl-main.372"
    },
    {
      "citation_id": "20",
      "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "authors": [
        "Jacob Devlin",
        "Ming-Wei Chang",
        "Kenton Lee",
        "Kristina Toutanova"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies"
    },
    {
      "citation_id": "21",
      "title": "An exploratory study on confusion in code reviews",
      "authors": [
        "Felipe Ebert",
        "Fernando Castor",
        "Nicole Novielli",
        "Alexander Serebrenik"
      ],
      "year": "2021",
      "venue": "Empirical Software Engineering"
    },
    {
      "citation_id": "22",
      "title": "Basic Emotions",
      "authors": [
        "Paul Ekman"
      ],
      "year": "1999",
      "venue": "Handbook of Cognition and Emotion"
    },
    {
      "citation_id": "23",
      "title": "Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm",
      "authors": [
        "Bjarke Felbo",
        "Alan Mislove",
        "Anders Søgaard",
        "Iyad Rahwan",
        "Sune Lehmann"
      ],
      "year": "2017",
      "venue": "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "24",
      "title": "A Survey of Data Augmentation Approaches for NLP",
      "authors": [
        "Varun Steven Y Feng",
        "Jason Gangal",
        "Sarath Wei",
        "Soroush Chandar",
        "Teruko Vosoughi",
        "Eduard Mitamura",
        "Hovy"
      ],
      "year": "2021",
      "venue": "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021"
    },
    {
      "citation_id": "25",
      "title": "The SPACE of Developer Productivity: There's More to It than You Think",
      "authors": [
        "Nicole Forsgren",
        "Margaret-Anne Storey",
        "Chandra Maddila",
        "Thomas Zimmermann",
        "Brian Houck",
        "Jenna Butler"
      ],
      "year": "2021",
      "venue": "The SPACE of Developer Productivity: There's More to It than You Think"
    },
    {
      "citation_id": "26",
      "title": "Waiting Around or job Half-Done? Sentiment in Self-Admitted Technical Debt",
      "authors": [
        "G Fucci",
        "N Cassee",
        "F Zampetti",
        "N Novielli",
        "A Serebrenik",
        "M Di Penta"
      ],
      "year": "2021",
      "venue": "2021 2021 IEEE/ACM 18th International Conference on Mining Software Repositories (MSR) (MSR)",
      "doi": "10.1109/MSR52588.2021.00052"
    },
    {
      "citation_id": "27",
      "title": "Recognizing Developers' Emotions While Programming",
      "authors": [
        "Daniela Girardi",
        "Nicole Novielli",
        "Davide Fucci",
        "Filippo Lanubile"
      ],
      "year": "2020",
      "venue": "Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering"
    },
    {
      "citation_id": "28",
      "title": "On the Unhappiness of Software Developers",
      "authors": [
        "Fabian Daniel Graziotin",
        "Xiaofeng Fagerholm",
        "Pekka Wang",
        "Abrahamsson"
      ],
      "year": "2017",
      "venue": "Proceedings of the 21st International Conference on Evaluation and Assessment in Software Engineering",
      "doi": "10.1145/3084226.3084242"
    },
    {
      "citation_id": "29",
      "title": "What happens when software developers are (un)happy",
      "authors": [
        "Fabian Daniel Graziotin",
        "Fagerholm"
      ],
      "year": "2018",
      "venue": "Journal of Systems and Software",
      "doi": "10.1016/j.jss.2018.02.041"
    },
    {
      "citation_id": "30",
      "title": "Are Happy Developers More Productive?",
      "authors": [
        "Xiaofeng Daniel Graziotin",
        "Pekka Wang",
        "Abrahamsson"
      ],
      "year": "2013",
      "venue": "Product-Focused Software Process Improvement"
    },
    {
      "citation_id": "31",
      "title": "Do Feelings Matter? On the Correlation of Affects and the Self-Assessed Productivity in Software Engineering",
      "authors": [
        "Xiaofeng Daniel Graziotin",
        "Pekka Wang",
        "Abrahamsson"
      ],
      "year": "2015",
      "venue": "Do Feelings Matter? On the Correlation of Affects and the Self-Assessed Productivity in Software Engineering"
    },
    {
      "citation_id": "32",
      "title": "Augmenting Data with Mixup for Sentence Classification: An Empirical Study",
      "authors": [
        "Hongyu Guo",
        "Yongyi Mao",
        "Richong Zhang"
      ],
      "year": "2019",
      "venue": "Augmenting Data with Mixup for Sentence Classification: An Empirical Study"
    },
    {
      "citation_id": "33",
      "title": "Sentiment and Politeness Analysis Tools on Developer Discussions Are Unreliable, but so Are People",
      "authors": [
        "Nasif Imtiaz",
        "Justin Middleton",
        "Peter Girouard",
        "Emerson Murphy-Hill"
      ],
      "year": "2018",
      "venue": "Sentiment and Politeness Analysis Tools on Developer Discussions Are Unreliable, but so Are People"
    },
    {
      "citation_id": "34",
      "title": "MarValous: Machine Learning Based Detection of Emotions in the Valence-Arousal Space in Software Engineering Text",
      "authors": [
        "Md Rakibul Islam",
        "Md Kauser Ahmmed",
        "Minhaz Zibran"
      ],
      "year": "2019",
      "venue": "MarValous: Machine Learning Based Detection of Emotions in the Valence-Arousal Space in Software Engineering Text"
    },
    {
      "citation_id": "35",
      "title": "DEVA: Sensing Emotions in the Valence Arousal Space in Software Engineering Text",
      "authors": [
        "Rakibul Md",
        "Minhaz Islam",
        "Zibran"
      ],
      "year": "2018",
      "venue": "DEVA: Sensing Emotions in the Valence Arousal Space in Software Engineering Text"
    },
    {
      "citation_id": "36",
      "title": "Syuzhet: Extract Sentiment and Plot Arcs from Text",
      "authors": [
        "L Matthew",
        "Jockers"
      ],
      "year": "2015",
      "venue": "Syuzhet: Extract Sentiment and Plot Arcs from Text"
    },
    {
      "citation_id": "37",
      "title": "Can vectors read minds better than experts? Comparing data augmentation strategies for the automated scoring of children's mindreading ability",
      "authors": [
        "Venelin Kovatchev",
        "Phillip Smith",
        "Mark Lee",
        "Rory Devine"
      ],
      "year": "2021",
      "venue": "ACL"
    },
    {
      "citation_id": "38",
      "title": "Data Augmentation using Pre-trained Transformer Models",
      "authors": [
        "Varun Kumar",
        "Ashutosh Choudhary",
        "Eunah Cho"
      ],
      "year": "2020",
      "venue": "Proceedings of the 2nd Workshop on Life-long Learning for Spoken Language Systems"
    },
    {
      "citation_id": "39",
      "title": "Chat activity is a better predictor than chat sentiment on software developers productivity",
      "authors": [
        "M Miikka Kuutila",
        "Maëlick Mäntylä",
        "Claes"
      ],
      "year": "2020",
      "venue": "Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops"
    },
    {
      "citation_id": "40",
      "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension",
      "authors": [
        "Mike Lewis",
        "Yinhan Liu",
        "Naman Goyal",
        "Marjan Ghazvininejad",
        "Abdelrahman Mohamed",
        "Omer Levy",
        "Veselin Stoyanov",
        "Luke Zettlemoyer"
      ],
      "year": "2020",
      "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "41",
      "title": "Data augmentation approaches in natural language processing: A survey",
      "authors": [
        "Bohan Li",
        "Yutai Hou",
        "Wanxiang Che"
      ],
      "year": "2022",
      "venue": "AI Open"
    },
    {
      "citation_id": "42",
      "title": "Opinion Mining for Software Development: A Systematic Literature Review",
      "authors": [
        "Bin Lin",
        "Nathan Cassee",
        "Alexander Serebrenik",
        "Gabriele Bavota",
        "Nicole Novielli",
        "Michele Lanza"
      ],
      "year": "2022",
      "venue": "ACM Trans. Softw. Eng. Methodol"
    },
    {
      "citation_id": "43",
      "title": "A first look at emoji usage on github: An empirical study",
      "authors": [
        "Xuan Lu",
        "Yanbin Cao",
        "Zhenpeng Chen",
        "Xuanzhe Liu"
      ],
      "year": "2018",
      "venue": "A first look at emoji usage on github: An empirical study",
      "arxiv": "arXiv:1812.04863"
    },
    {
      "citation_id": "44",
      "title": "",
      "authors": [
        "Edward Ma"
      ],
      "year": "2019",
      "venue": ""
    },
    {
      "citation_id": "45",
      "title": "Bootstrapping a lexicon for emotional arousal in software engineering",
      "authors": [
        "Nicole Mika V Mäntylä",
        "Filippo Novielli",
        "Maëlick Lanubile",
        "Miikka Claes",
        "Kuutila"
      ],
      "year": "2017",
      "venue": "th International Conference on Mining Software Repositories (MSR)"
    },
    {
      "citation_id": "46",
      "title": "Today Was a Good Day: The Daily Life of Software Developers",
      "authors": [
        "N André",
        "Earl Meyer",
        "Christian Barr",
        "Thomas Bird",
        "Zimmermann"
      ],
      "year": "2021",
      "venue": "IEEE Transactions on Software Engineering"
    },
    {
      "citation_id": "47",
      "title": "WordNet: a lexical database for English",
      "authors": [
        "George Miller"
      ],
      "year": "1995",
      "venue": "Commun. ACM"
    },
    {
      "citation_id": "48",
      "title": "Nrc emotion lexicon",
      "authors": [
        "M Saif",
        "Peter Mohammad",
        "Turney"
      ],
      "year": "2013",
      "venue": "National Research Council, Canada"
    },
    {
      "citation_id": "49",
      "title": "A Gradually Soft Multi-Task and Data-Augmented Approach to Medical Question Understanding",
      "authors": [
        "Franck Khalil Mrini",
        "Seunghyun Dernoncourt",
        "Trung Yoon",
        "Walter Bui",
        "Emilia Chang",
        "Ndapa Farcas",
        "Nakashole"
      ],
      "year": "2021",
      "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing"
    },
    {
      "citation_id": "50",
      "title": "Stuck and Frustrated or in Flow and Happy: Sensing Developers' Emotions and Progress",
      "authors": [
        "Sebastian Müller",
        "Thomas Fritz"
      ],
      "year": "2015",
      "venue": "Proceedings of the 37th International Conference on Software Engineering -Volume"
    },
    {
      "citation_id": "51",
      "title": "An Exploratory Qualitative and Quantitative Analysis of Emotions in Issue Report Comments of Open Source Systems",
      "authors": [
        "Alessandro Murgia",
        "Marco Ortu",
        "Parastou Tourani",
        "Bram Adams",
        "Serge Demeyer"
      ],
      "year": "2018",
      "venue": "Empirical Softw. Engg",
      "doi": "10.1007/s10664-017-9526-0"
    },
    {
      "citation_id": "52",
      "title": "Do developers feel emotions? an exploratory analysis of emotions in software artifacts",
      "authors": [
        "A Murgia",
        "Parastou Tourani",
        "B Adams",
        "Marco Ortu"
      ],
      "year": "2014",
      "venue": "Do developers feel emotions? an exploratory analysis of emotions in software artifacts"
    },
    {
      "citation_id": "53",
      "title": "Stuck and Frustrated or in Flow and Happy: Sensing Developers' Emotions and Progress",
      "authors": [
        "Sebastian Müller",
        "Thomas Fritz"
      ],
      "year": "2015",
      "venue": "2015 IEEE/ACM 37th IEEE International Conference on Software Engineering",
      "doi": "10.1109/ICSE.2015.334"
    },
    {
      "citation_id": "54",
      "title": "EmoD: An endto-end approach for investigating emotion dynamics in software development",
      "authors": [
        "Krishna Prasad Neupane",
        "Kabo Cheung",
        "Yi Wang"
      ],
      "year": "2019",
      "venue": "2019 IEEE International Conference on Software Maintenance and Evolution (ICSME)"
    },
    {
      "citation_id": "55",
      "title": "A gold standard for emotion annotation in stack overflow",
      "authors": [
        "Nicole Novielli",
        "Fabio Calefato",
        "Filippo Lanubile"
      ],
      "year": "2018",
      "venue": "2018 IEEE/ACM 15th International Conference on Mining Software Repositories (MSR)"
    },
    {
      "citation_id": "56",
      "title": "Assessment of off-the-shelf SE-specific sentiment analysis tools: An extended replication study",
      "authors": [
        "Nicole Novielli",
        "Fabio Calefato",
        "Filippo Lanubile",
        "Alexander Serebrenik"
      ],
      "year": "2021",
      "venue": "Empirical Software Engineering",
      "doi": "10.1007/s10664-021-09960-w"
    },
    {
      "citation_id": "57",
      "title": "A Benchmark Study on Sentiment Analysis for Software Engineering Research",
      "authors": [
        "Nicole Novielli",
        "Daniela Girardi",
        "Filippo Lanubile"
      ],
      "year": "2018",
      "venue": "th International Conference on Mining Software Repositories (MSR)"
    },
    {
      "citation_id": "58",
      "title": "A benchmark study on sentiment analysis for software engineering research",
      "authors": [
        "Nicole Novielli",
        "Daniela Girardi",
        "Filippo Lanubile"
      ],
      "year": "2018",
      "venue": "2018 IEEE/ACM 15th International Conference on Mining Software Repositories (MSR)"
    },
    {
      "citation_id": "59",
      "title": "Sentiment and Emotion in Software Engineering",
      "authors": [
        "Nicole Novielli",
        "Alexander Serebrenik"
      ],
      "year": "2019",
      "venue": "IEEE Software"
    },
    {
      "citation_id": "60",
      "title": "Are Bullies More Productive? Empirical Study of Affectiveness vs. Issue Fixing Time",
      "authors": [
        "M Ortu",
        "B Adams",
        "G Destefanis",
        "P Tourani",
        "M Marchesi",
        "R Tonelli"
      ],
      "year": "2015",
      "venue": "IEEE/ACM 12th Working Conference on Mining Software Repositories"
    },
    {
      "citation_id": "61",
      "title": "The Emotional Side of Software Developers in JIRA",
      "authors": [
        "Marco Ortu",
        "Alessandro Murgia",
        "Giuseppe Destefanis",
        "Parastou Tourani",
        "Roberto Tonelli",
        "Michele Marchesi",
        "Bram Adams"
      ],
      "year": "2016",
      "venue": "Proceedings of the 13th International Conference on Mining Software Repositories",
      "doi": "10.1145/2901739.2903505"
    },
    {
      "citation_id": "62",
      "title": "Emotions in social psychology: Essential readings",
      "authors": [
        "Gerrod Parrott"
      ],
      "year": "2001",
      "venue": "Emotions in social psychology: Essential readings"
    },
    {
      "citation_id": "63",
      "title": "A general psychoevolutionary theory of emotion",
      "authors": [
        "Robert Plutchik"
      ],
      "year": "1980",
      "venue": "Theories of emotion"
    },
    {
      "citation_id": "64",
      "title": "Making the most of small Software Engineering datasets with modern machine learning",
      "authors": [
        "Julian Aron",
        "Aron Prenner",
        "Romain Robbes"
      ],
      "year": "2021",
      "venue": "IEEE Transactions on Software Engineering"
    },
    {
      "citation_id": "65",
      "title": "Textual data augmentation for efficient active learning on tiny datasets",
      "authors": [
        "Husam Quteineh",
        "Spyridon Samothrakis",
        "Richard Sutcliffe"
      ],
      "year": "2020",
      "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "66",
      "title": "Language models are unsupervised multitask learners",
      "authors": [
        "Alec Radford",
        "Jeffrey Wu",
        "Rewon Child",
        "David Luan",
        "Dario Amodei",
        "Ilya Sutskever"
      ],
      "year": "2019",
      "venue": "OpenAI blog"
    },
    {
      "citation_id": "67",
      "title": "An empirical study of emoji use in software development communication",
      "authors": [
        "Shiyue Rong",
        "Weisheng Wang",
        "Umme Ayda Mannan",
        "Eduardo Santana De Almeida",
        "Shurui Zhou",
        "Iftekhar Ahmed"
      ],
      "year": "2022",
      "venue": "Information and Software Technology"
    },
    {
      "citation_id": "68",
      "title": "Evidence for a three-factor theory of emotions",
      "authors": [
        "A James",
        "Albert Russell",
        "Mehrabian"
      ],
      "year": "1977",
      "venue": "Journal of research in Personality"
    },
    {
      "citation_id": "69",
      "title": "The Impacts of Sentiments and Tones in Community-Generated Issue Discussions",
      "authors": [
        "Arghavan Sanei",
        "Jinghui Cheng",
        "Bram Adams"
      ],
      "year": "2021",
      "venue": "2021 IEEE/ACM 13th International Workshop on Cooperative and Human Aspects of Software Engineering (CHASE)"
    },
    {
      "citation_id": "70",
      "title": "Socio-Technical Work-Rate Increase Associates with Changes in Work Patterns in Online Projects",
      "authors": [
        "Farhana Sarker",
        "Bogdan Vasilescu",
        "Kelly Blincoe",
        "Vladimir Filkov"
      ],
      "year": "2019",
      "venue": "Socio-Technical Work-Rate Increase Associates with Changes in Work Patterns in Online Projects"
    },
    {
      "citation_id": "71",
      "title": "Emotions in everyday life: Probability of occurrence, risk factors, appraisal and reaction patterns",
      "authors": [
        "Klaus Scherer",
        "Tanja Wranik",
        "Janique Sangsue",
        "Véronique Tran",
        "Ursula Scherer"
      ],
      "year": "2004",
      "venue": "Social Science Information"
    },
    {
      "citation_id": "72",
      "title": "Improving Neural Machine Translation Models with Monolingual Data",
      "authors": [
        "Rico Sennrich",
        "Barry Haddow",
        "Alexandra Birch"
      ],
      "year": "2016",
      "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "73",
      "title": "Emotion knowledge: further exploration of a prototype approach",
      "authors": [
        "Phillip Shaver",
        "Judith Schwartz",
        "Donald Kirson",
        "Cary O' Connor"
      ],
      "year": "1987",
      "venue": "Journal of personality and social psychology"
    },
    {
      "citation_id": "74",
      "title": "Text data augmentation for deep learning",
      "authors": [
        "Connor Shorten",
        "M Taghi",
        "Borko Khoshgoftaar",
        "Furht"
      ],
      "year": "2021",
      "venue": "Journal of big Data"
    },
    {
      "citation_id": "75",
      "title": "Analyzing Developer Sentiment in Commit Logs",
      "authors": [
        "V Sinha",
        "A Lazar",
        "B Sharif"
      ],
      "year": "2016",
      "venue": "2016 IEEE/ACM 13th Working Conference on Mining Software Repositories (MSR)"
    },
    {
      "citation_id": "76",
      "title": "More Than React: Investigating The Role of EmojiReaction in GitHub Pull Requests",
      "authors": [
        "Teyon Son",
        "Tao Xiao",
        "Dong Wang",
        "Raula Gaikovina Kula",
        "Takashi Ishio",
        "Kenichi Matsumoto"
      ],
      "year": "2021",
      "venue": "More Than React: Investigating The Role of EmojiReaction in GitHub Pull Requests",
      "arxiv": "arXiv:2108.08094"
    },
    {
      "citation_id": "77",
      "title": "A comparison of consensus, consistency, and measurement approaches to estimating interrater reliability",
      "authors": [
        "E Steven",
        "Stemler"
      ],
      "year": "2004",
      "venue": "A comparison of consensus, consistency, and measurement approaches to estimating interrater reliability"
    },
    {
      "citation_id": "78",
      "title": "Code and Named Entity Recognition in StackOverflow",
      "authors": [
        "Jeniya Tabassum",
        "Mounica Maddela",
        "Wei Xu",
        "Alan Ritter"
      ],
      "year": "2020",
      "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "79",
      "title": "Monitoring Sentiment in Open Source Mailing Lists: Exploratory Study on the Apache Ecosystem",
      "authors": [
        "Parastou Tourani",
        "Yujuan Jiang",
        "Bram Adams"
      ],
      "year": "2014",
      "venue": "Proceedings of 24th Annual International Conference on Computer Science and Software Engineering"
    },
    {
      "citation_id": "80",
      "title": "Effective and efficient multilabel classification in domains with large number of labels",
      "authors": [
        "Grigorios Tsoumakas",
        "Ioannis Katakis",
        "Ioannis Vlahavas"
      ],
      "year": "2008",
      "venue": "Proc. ECML/PKDD 2008 Workshop on Mining Multidimensional Data (MMD'08)"
    },
    {
      "citation_id": "81",
      "title": "Random k-labelsets for multilabel classification",
      "authors": [
        "Grigorios Tsoumakas",
        "Ioannis Katakis",
        "Ioannis Vlahavas"
      ],
      "year": "2010",
      "venue": "IEEE transactions on knowledge and data engineering"
    },
    {
      "citation_id": "82",
      "title": "Understanding Emotions of Developer Community Towards Software Documentation",
      "authors": [
        "Akhila Sri",
        "Manasa Venigalla",
        "Sridhar Chimalakonda"
      ],
      "year": "2021",
      "venue": "2021 IEEE/ACM 43rd International Conference on Software Engineering: Software Engineering in Society (ICSE-SEIS"
    },
    {
      "citation_id": "83",
      "title": "EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks",
      "authors": [
        "Jason Wei",
        "Kai Zou"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)"
    },
    {
      "citation_id": "84",
      "title": "Transformers: State-of-the-Art Natural Language Processing",
      "authors": [
        "Thomas Wolf",
        "Lysandre Debut",
        "Victor Sanh",
        "Julien Chaumond",
        "Clement Delangue",
        "Anthony Moi",
        "Pierric Cistac",
        "Tim Rault",
        "Rémi Louf",
        "Morgan Funtowicz",
        "Joe Davison",
        "Sam Shleifer",
        "Clara Patrick Von Platen",
        "Yacine Ma",
        "Julien Jernite",
        "Canwen Plu",
        "Teven Xu",
        "Sylvain Le Scao",
        "Mariama Gugger",
        "Quentin Drame",
        "Alexander Lhoest",
        "Rush"
      ],
      "year": "2020",
      "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations"
    },
    {
      "citation_id": "85",
      "title": "Conditional bert contextual augmentation",
      "authors": [
        "Xing Wu",
        "Shangwen Lv",
        "Liangjun Zang",
        "Jizhong Han",
        "Songlin Hu"
      ],
      "year": "2019",
      "venue": "International Conference on Computational Science"
    },
    {
      "citation_id": "86",
      "title": "Unsupervised data augmentation for consistency training",
      "authors": [
        "Qizhe Xie",
        "Zihang Dai",
        "Eduard Hovy",
        "Thang Luong",
        "Quoc Le"
      ],
      "year": "2020",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "87",
      "title": "Supporting Clustering with Contrastive Learning",
      "authors": [
        "Dejiao Zhang",
        "Feng Nan",
        "Xiaokai Wei",
        "Shang-Wen Li",
        "Henghui Zhu",
        "Kathleen Mckeown",
        "Ramesh Nallapati",
        "Andrew Arnold",
        "Bing Xiang"
      ],
      "year": "2021",
      "venue": "Proceedings of the 2021 Conference of the North American Chapter"
    },
    {
      "citation_id": "88",
      "title": "mixup: Beyond empirical risk minimization",
      "authors": [
        "Hongyi Zhang",
        "Moustapha Cisse",
        "David Yann N Dauphin",
        "Lopez-Paz"
      ],
      "year": "2017",
      "venue": "mixup: Beyond empirical risk minimization",
      "arxiv": "arXiv:1710.09412"
    },
    {
      "citation_id": "89",
      "title": "Character-level convolutional networks for text classification",
      "authors": [
        "Xiang Zhang",
        "Junbo Zhao",
        "Yann Lecun"
      ],
      "year": "2015",
      "venue": "Advances in neural information processing systems"
    }
  ]
}