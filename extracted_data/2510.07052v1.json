{
  "paper_id": "2510.07052v1",
  "title": "Enhancing Speech Emotion Recognition Via Fine-Tuning Pre-Trained Models And Hyper-Parameter Optimisation",
  "published": "2025-10-08T14:20:43Z",
  "authors": [
    "Aryan Golbaghi",
    "Shuo Zhou"
  ],
  "keywords": [
    "speech emotion recognition",
    "pre-trained model",
    "hyperparameter optimisation"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "We propose a workflow for speech emotion recognition (SER) that combines pre-trained representations with automated hyperparameter optimisation (HPO). Using SpeechBrain's wav2vec2-base model fine-tuned on IEMOCAP as the encoder, we compare two HPO strategies, Gaussian Process Bayesian Optimisation (GP-BO) and Tree-structured Parzen Estimators (TPE), under an identical four-dimensional search space and 15-trial budget, with balanced class accuracy (BCA) on the German EmoDB corpus as the objective. All experiments run on 8 CPU cores with 32 GB RAM. GP-BO achieves 96.0% BCA in 11 minutes, and TPE (Hyperopt implementation) attains 97.0% in 15 minutes. In contrast, grid search requires 143 trials and 1,680 minutes to exceed 90% BCA, and the best AutoSpeech 2020 baseline reports only 85% in 30 minutes on GPU. For cross-lingual generalisation, an EmoDB-trained HPO-tuned model improves zero-shot accuracy by 25% on CREMA-D and 26% on RAVDESS. Results show that efficient HPO with pre-trained encoders delivers competitive SER on commodity CPUs.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Speech emotion recognition (SER) plays a key role in humancomputer interaction, mental health monitoring, and social robotics  [1, 2] . Strong accuracy has typically relied on GPU resources and extensive manual tuning of hyperparameters. We target a low-cost, CPU-only pipeline that remains competitive with recent SER systems while requiring minimal expert intervention. To our knowledge, this is the first SER approach that combines a self-supervised backbone with automated machine learning (AutoML) to achieve state-of-the-art performance on commodity hardware.\n\nEarly SER systems relied on handcrafted acoustic and prosodic features such as MFCCs, pitch, and energy, paired with classical classifiers  [3, 4] . In the 2010s, deep neural networks, including CNNs, RNNs, and hybrid architectures, became dominant by learning hierarchical time-frequency patterns directly from spectrograms  [5, 6] . More recently, self-supervised pre-training has enabled general-purpose audio representations that can be fine-tuned for SER, with notable examples including wav2vec 2.0  [7] , HuBERT  [8] , and ExHuBERT  [9] .\n\nIn parallel, automated machine learning (AutoML) techniques including hyperparameter optimisation (HPO) such as Gaussain Process Bayesian optimisation (GP-BO)  [10]  and tree-structured Parzen estimators (TPE)  [11]  have reduced the burden of manual tuning in many domains, but remain underexplored in SER. The AutoSpeech 2020 challenge  [12]  demonstrated the potential of automated pipelines for speech classification, though its reliance on GPU resources limited accessibility for low-cost or CPU-only deployments.\n\nDespite these advances, three key challenges persist: (i) the high computational cost of model selection, (ii) the difficulty of optimising many interdependent hyperparameters, and (iii) limited cross-corpus and cross-language generalisability  [13, 14] . HPO methods such as GP-BO and TPE offer a principled way to mitigate these issues by reducing manual search effort while preserving competitive accuracy.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Architecture",
      "text": "We propose an AutoML fine-tuning workflow for SER, as demonstrated in Fig.  1 . The inputs are: (i) a dataset split into training and validation sets, (ii) a pre-trained speech model, (iii) a k-dimensional hyperparameter vector, and (iv) an HPO algorithm.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Problem Formulation",
      "text": "Let D train = {(x i , y i )} Ntr i=1 and D val = {(x j , y j )} Nval j=1 denote training and validation sets. The encoder is initialised from a pre-trained network f (•; θ 0 ). A hyperparameter vector λ ∈ Λ ⊂ R k controls fine-tuning parameters such as learning rate, weight decay, scheduler settings, batch size, and dropout. For a given λ, parameters are obtained as Performance is measured by a validation metric M val (balanced class accuracy, BCA), and the optimal configuration is selected as\n\nFor a classification problem with C classes, BCA is\n\nwhere TP c and FN c are true positives and false negatives for class c.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Hpo Algorithms",
      "text": "We incorporate two families of sequential model-based optimisation (SMBO, Algorithm 1) as HPO candidates in our workflow and compare their performance (i) Gaussian process Bayesian optimisation (GP-BO)  [10] , and (ii) Treestructured Parzen estimators (TPE)  [11] . At iteration t, a surrogate is fit on history D t-1 , candidate hyperparameters λ t are selected by maximising an acquisition function, and the objective is evaluated as y t = f (λ t ). The history is then updated, and the process repeats.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Gp-Bo. Assume Noisy Scores Y",
      "text": "Algorithm 1 Sequential Model-Based Optimisation (SMBO) Require: Search space Λ, budget T , initial design size n 0 , acquisition α(•)\n\nFit surrogate s t on D t-1 ▷ e.g., GP posterior or TPE densities 5:\n\n▷ maximize acquisition 6:\n\nλ ⋆ ← arg min (λ,y)∈Dt y 9: end for 10: return λ ⋆ ▷ best configuration found where µ t is the GP mean and σ t the predictive variance. Acquisition functions such as Expected Improvement (EI)  [15]  or GP-UCB  [16]  balance exploration and exploitation.\n\nTPE. Instead of modelling p(y|λ) directly, TPE estimates densities over configurations:\n\nwhere y ⋆ is a quantile threshold. Candidates are chosen by maximising ℓ(λ)/g(λ), which is proportional to expected improvement under this model.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Experiments",
      "text": "",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Experimental Setup",
      "text": "",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Dataset",
      "text": "We use the Berlin EmoDB corpus  [17] , a standard benchmark for SER containing 535 utterances from 10 speakers across 7 emotions. EmoDB has featured in community challenges such as AutoSpeech 2020  [12] , making it suitable for comparison with published baselines. All recordings are converted to mono, resampled to 16 kHz, and either right-padded or truncated to a fixed length of T samples. Acoustic features are extracted on-the-fly using a pre-trained speech emotion encoder. Data are split via stratified partition, with the 80% for fine-tuning and the held-out 20% used once as the test set.\n\nTo assess cross-lingual generalisation, we additionally evaluate the EmoDB-trained model in a zero-shot setting on two English corpora: CREMA-D  [18]  and RAVDESS  [19] . Since these datasets use different emotion taxonomies, we map their labels to a unified set aligned with EmoDB, as summarised in Table  1 .",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Dataset",
      "text": "Emotion RAVDESS  [19]  Angry, Disgust, Fearful, Happy, Neutral, Sad, Calm, Surprised CREMA-D  [18]  Anger, Disgust, Fear, Happy, Neutral, Sad Mapped EMO-DB  [17]  Anger, Disgust, Fear, Happiness, Neutral, Sadness, Boredom Table  1 . Emotion label sets in RAVDESS  [19] , CREMA-D  [18] , and the unified mapping aligned to EMO-DB  [17] . The \"Surprised\" class from RAVDESS is excluded, as it is not present in EMO-DB, , which our model was fine-tuned on.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Backbone & Classifier",
      "text": "Architecture. We adopt the EncoderClassifier module from SpeechBrain  [20]  with a wav2vec 2.0 encoder  [7]  pretrained in a self-supervised fashion and fine-tuned on IEMOCAP  [21]  for categorical emotion. This checkpoint has not been exposed to EmoDB, preventing leakage and ensuring fair evaluation on the German target corpus. The encoder produces frame-level representations, which are temporally pooled into z ∈ R d and projected through a linear layer aligned with EmoDB's taxonomy:\n\nTraining schedule. Training follows a two-stage strategy: the feature extractor is frozen for the initial epochs to stabilise learning on the small corpus, and then unfrozen at an HPO-controlled epoch u ∈ {0, . . . , 5} to enable task-specific adaptation once the classifier has converged. Optimisation uses cross-entropy loss, AdamW  [22] , and a cosine-annealed learning rate schedule.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Hpo Engines And Search Space",
      "text": "We compare GP-BO  [10]  and TPE  [11] , implemented in three AutoML engines: Ax  [23]  (for GP-BO), Hyperopt  [24]  (for TPE), and Optuna  [25]  (for TPE). All engines optimise the same compact four-dimensional space tailored to lowresource SER fine-tuning, which is summarised in Table  2 .\n\nGP-BO in Ax. Ax fits a Gaussian process surrogate over observed (λ, BCA) pairs and selects new configurations via an acquisition function (Expected Improvement by default). The search is seeded with a Sobol design and alternates surrogate fitting with acquisition maximisation. Ax also supports multi-point criteria (qEI/qUCB) and schedulers for early stopping and parallel evaluation.\n\nTPE in Hyperopt. Hyperopt partitions past trials at a quantile threshold y ⋆ into \"good\" and \"bad\" sets, fits kernel density estimates ℓ(x) and g(x) to each, and samples new configurations by maximising ℓ(x)/g(x), proportional to expected improvement. unfreeze is the epoch index at which the pretrained encoder is unfrozen. maxlen is the per-utterance cap in samples (truncate/pad). We sample lr log-uniformly, #epochs and unfreeze uniformly over their ranges, and maxlen uniformly over its categorical set. Batch size is fixed to 1 to avoid LR-batch size interactions on the small corpus. Each engine is allocated 15 trials under identical seeds and training code. Learning rate is ; epochs and unfreeze are sampled uniformly over their discrete ranges; and max length is drawn uniformly from the categorical set.\n\nTPE in Optuna. Optuna allows programmatic search space definitions at runtime in TPE, supporting dynamic and hierarchical spaces. It further integrates asynchronous pruning with built-in strategies such as Median, Successive Halving  [26, 27] , and Hyperband  [28] . We use Optuna's default TPE sampler in the experiments.\n\nThe selected HPO methods implemented in the three engines are compared against standard grid search, while the overall workflow is benchmarked against the best-performing solution from the AutoSpeech 2020 challenge  [12] .",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Hardware Setup",
      "text": "All HPO experiments were executed on a cluster with 8 CPU cores and 32 GB RAM; no GPU was used. The grid search baseline was run on a larger server with 64 CPU cores and 128 GB RAM. This \"commodity\" environment is the target deployment setting for our pipeline and was applied uniformly across Ax, Hyperopt, and Optuna so that the optimiser was the only varying factor.\n\nFor comparison, the best performed solution in Au-toSpeech 2020  [12]  entry on EmoDB reported results on a Tesla P100 GPU with 26 GB RAM, whereas our pipeline operates entirely on an 8-core CPU with 32 GB RAM. In raw compute throughput, the P100 is roughly 10-20× faster, but also about 5-10× more costly in resource terms.   [11] ; and GP-BO denotes Gaussian process Bayesian optimisation  [10] . Optuna  [25] , Hyperopt  [24] , and Ax  [23]   longer (185 min). The corresponding hyperparameter settings (Table  4 ) show convergence to similar learning rates and sequence lengths, with differences mainly in unfreeze epoch and number of training epochs. To quantify speed-accuracy trade-offs, we define an efficiency metric E = BCA wall-clock minutes to reach that BCA  (8)  with results summarised in Table  5 . Despite running entirely on an 8-core CPU (no GPU), GP-BO (Ax) delivered the best balance of speed (11 min) and accuracy (0.96 BCA), while Hyperopt achieved slightly higher BCA (0.97) at modest extra cost (15 min). Both approaches substantially outperform the best AutoSpeech 2020 EmoDB solution (0.85 BCA in ∼30 min on GPU), yielding a ∼3× efficiency improvement. Moreover, our fine-tuned model attained 98.3% raw accuracy on EmoDB, surpassing the reported performance of native German listeners (84%)  [29] . In summary, GP-BO (Ax) provides the best speed-accuracy trade-off for rapid iteration, while TPE (Hyperopt) achieves the top accuracy with only slightly higher time cost, establishing our CPU-only workflow as both more efficient and more accurate than prior GPU-based baselines. (0.18). In contrast, HPO-tuning on EmoDB (using GP-BO in Ax) substantially improves cross-lingual generalisation, raising BCA to 0.38 on CREMA-D and 0.44 on RAVDESS. On the source corpus EmoDB, BCA increased to 0.96 after tuning, confirming the effectiveness of the proposed workflow.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Classification And Efficiency Performances",
      "text": "",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Zero-Shot Transfer Across Corpora",
      "text": "",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Conclusion",
      "text": "We proposed a CPU-only SER workflow that combines a pretrained wav2vec 2.0 encoder with automated hyperparameter optimisation (HPO). Two HPO methods, GP-BO and TPE, were evaluated through three engines: Ax, Hyperopt, and Optuna. On the German SER corpus EmoDB, Ax and Hyperopt achieved over 96% balanced class accuracy within minutes, outperforming the best AutoSpeech 2020 solution (85% in 30 min on GPU) while avoiding the 100× cost of grid search. HPO-tuning also improved cross-lingual transfer, increasing the SER accuracy of an EmoDB-trained model by 25% on CREMA-D and 26% on RAVDESS compared to the baseline. These results demonstrate that pre-trained encoders coupled with efficient HPO can deliver state-of-the-art SER performance without GPUs. Future work will extend to multilingual corpora, explore parameter-efficient fine-tuning, and integrate energy and latency objectives for deployment in resource-constrained settings.",
      "page_start": 4,
      "page_end": 4
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: The inputs are: (i) a dataset split into",
      "page": 1
    },
    {
      "caption": "Figure 1: Proposed AutoML fine-tuning workflow for SER. A",
      "page": 2
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "{agolbaghi1,\nshuo.zhou}@sheffield.ac.uk"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "ABSTRACT\nbecame dominant by learning hierarchical\ntime–frequency"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "patterns directly from spectrograms\n[5, 6]. More recently,"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "We propose a workflow for speech emotion recognition (SER)"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "self-supervised pre-training has enabled general-purpose au-"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "that\ncombines\npre-trained\nrepresentations with\nautomated"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "dio\nrepresentations\nthat\ncan\nbe fine-tuned\nfor SER, with"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "hyperparameter\noptimisation\n(HPO). Using SpeechBrain’s"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "notable examples including wav2vec 2.0 [7], HuBERT [8],"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "wav2vec2-base model fine-tuned on IEMOCAP as\nthe en-"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "and ExHuBERT [9]."
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "coder, we compare\ntwo HPO strategies, Gaussian Process"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "In parallel, automated machine learning (AutoML) tech-"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "Bayesian Optimisation (GP-BO) and Tree-structured Parzen"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "niques including hyperparameter optimisation (HPO) such as"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "Estimators (TPE), under an identical four-dimensional search"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "Gaussain Process Bayesian optimisation (GP-BO)\n[10] and"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "space\nand\n15-trial\nbudget, with\nbalanced\nclass\naccuracy"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "tree-structured Parzen estimators (TPE) [11] have reduced the"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "(BCA) on the German EmoDB corpus as the objective. All"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "burden of manual\ntuning in many domains, but\nremain un-"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "experiments run on 8 CPU cores with 32 GB RAM. GP-BO"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "derexplored in SER. The AutoSpeech 2020 challenge [12]"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "achieves 96.0% BCA in 11 minutes, and TPE (Hyperopt\nim-"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "demonstrated the potential of automated pipelines for speech"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "plementation) attains 97.0% in 15 minutes.\nIn contrast, grid"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "classification,\nthough its reliance on GPU resources limited"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "search requires 143 trials and 1,680 minutes to exceed 90%"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "accessibility for low-cost or CPU-only deployments."
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "BCA, and the best AutoSpeech 2020 baseline reports only"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "Despite these advances,\nthree key challenges persist:\n(i)"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "85% in 30 minutes on GPU. For cross-lingual generalisation,"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "the high computational cost of model selection,\n(ii)\nthe dif-"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "an EmoDB-trained HPO-tuned model\nimproves\nzero-shot"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "ficulty of optimising many interdependent hyperparameters,"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "accuracy by 25% on CREMA-D and 26% on RAVDESS."
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "and (iii)\nlimited cross-corpus and cross-language generalis-"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "Results\nshow that efficient HPO with pre-trained encoders"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "ability [13, 14]. HPO methods such as GP-BO and TPE offer"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "delivers competitive SER on commodity CPUs. Source code"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "a principled way to mitigate these issues by reducing manual"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "https://github.com/\nto\nthis work\nis\navailable\nat:"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "search effort while preserving competitive accuracy."
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "youngaryan/speechbrain-emotion-hpo."
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "Index Terms— speech emotion recognition, pre-trained"
        },
        {
          "School of Computer Science, University of Sheffield, Sheffield, UK": "2. ARCHITECTURE\nmodel, hyperparameter optimisation"
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Algorithm 1 Sequential Model-Based Optimisation (SMBO)": ""
        },
        {
          "Algorithm 1 Sequential Model-Based Optimisation (SMBO)": "Require: Search space Λ, budget T ,\ninitial design size n0,"
        },
        {
          "Algorithm 1 Sequential Model-Based Optimisation (SMBO)": ""
        },
        {
          "Algorithm 1 Sequential Model-Based Optimisation (SMBO)": "acquisition α(·)"
        },
        {
          "Algorithm 1 Sequential Model-Based Optimisation (SMBO)": "1:\n=\nby\nevaluating\nyi\nInitialize D0 ← {(λi, yi)}n0"
        },
        {
          "Algorithm 1 Sequential Model-Based Optimisation (SMBO)": "i=1"
        },
        {
          "Algorithm 1 Sequential Model-Based Optimisation (SMBO)": "f (λi) + εi on a diverse design over Λ"
        },
        {
          "Algorithm 1 Sequential Model-Based Optimisation (SMBO)": "▷ incumbent\n2: λ⋆ ← arg min(λ,y)∈D0 y"
        },
        {
          "Algorithm 1 Sequential Model-Based Optimisation (SMBO)": "3:\nfor t = 1 to T do"
        },
        {
          "Algorithm 1 Sequential Model-Based Optimisation (SMBO)": "4:\n▷ e.g., GP posterior or TPE\nFit surrogate st on Dt−1"
        },
        {
          "Algorithm 1 Sequential Model-Based Optimisation (SMBO)": ""
        },
        {
          "Algorithm 1 Sequential Model-Based Optimisation (SMBO)": "densities"
        },
        {
          "Algorithm 1 Sequential Model-Based Optimisation (SMBO)": ""
        },
        {
          "Algorithm 1 Sequential Model-Based Optimisation (SMBO)": "5:\n▷ maximize\nλt ← arg maxλ∈Λ α(λ; st, Dt−1)"
        },
        {
          "Algorithm 1 Sequential Model-Based Optimisation (SMBO)": ""
        },
        {
          "Algorithm 1 Sequential Model-Based Optimisation (SMBO)": "acquisition"
        },
        {
          "Algorithm 1 Sequential Model-Based Optimisation (SMBO)": "6:\nEvaluate yt ← f (λt) + εt"
        },
        {
          "Algorithm 1 Sequential Model-Based Optimisation (SMBO)": "7:\nDt ← Dt−1 ∪ {(λt, yt)}"
        },
        {
          "Algorithm 1 Sequential Model-Based Optimisation (SMBO)": ""
        },
        {
          "Algorithm 1 Sequential Model-Based Optimisation (SMBO)": "8:\nλ⋆ ← arg min(λ,y)∈Dt y"
        },
        {
          "Algorithm 1 Sequential Model-Based Optimisation (SMBO)": "9:\nend for"
        },
        {
          "Algorithm 1 Sequential Model-Based Optimisation (SMBO)": ""
        },
        {
          "Algorithm 1 Sequential Model-Based Optimisation (SMBO)": "10:\nreturn λ⋆\n▷ best configuration found"
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Evaluate / Select": "Mval (BCA)"
        },
        {
          "Evaluate / Select": ""
        },
        {
          "Evaluate / Select": ""
        },
        {
          "Evaluate / Select": "Fig. 1. Proposed AutoML fine-tuning workflow for SER. A"
        },
        {
          "Evaluate / Select": ""
        },
        {
          "Evaluate / Select": "pre-trained model\nis fine-tuned on Dtrain, with HPO guiding"
        },
        {
          "Evaluate / Select": "hyperparameter search and Mval used for model selection."
        },
        {
          "Evaluate / Select": ""
        },
        {
          "Evaluate / Select": ""
        },
        {
          "Evaluate / Select": "(bal-\nPerformance is measured by a validation metric Mval"
        },
        {
          "Evaluate / Select": "anced class accuracy, BCA), and the optimal configuration is"
        },
        {
          "Evaluate / Select": ""
        },
        {
          "Evaluate / Select": "selected as"
        },
        {
          "Evaluate / Select": "λ⋆ = arg max\n(2)\nMval(θ⋆(λ))."
        },
        {
          "Evaluate / Select": "λ∈Λ"
        },
        {
          "Evaluate / Select": ""
        },
        {
          "Evaluate / Select": "For a classification problem with C classes, BCA is"
        },
        {
          "Evaluate / Select": ""
        }
      ],
      "page": 2
    },
    {
      "caption": "Table 1: Emotion label sets in RAVDESS [19], CREMA-D maxlen {32k,48k,64k,80k,112k,160k}",
      "data": [
        {
          "Dataset\nEmotion": ""
        },
        {
          "Dataset\nEmotion": "RAVDESS [19]\nAngry, Disgust, Fearful, Happy, Neutral, Sad, Calm, Surprised"
        },
        {
          "Dataset\nEmotion": "Anger, Disgust, Fear, Happy, Neutral, Sad\nCREMA-D [18]"
        },
        {
          "Dataset\nEmotion": "Mapped EMO-DB [17]\nAnger, Disgust, Fear, Happiness, Neutral, Sadness, Boredom"
        },
        {
          "Dataset\nEmotion": ""
        },
        {
          "Dataset\nEmotion": ""
        },
        {
          "Dataset\nEmotion": "Table 1. Emotion label sets in RAVDESS [19], CREMA-D"
        },
        {
          "Dataset\nEmotion": ""
        },
        {
          "Dataset\nEmotion": "[18], and the unified mapping aligned to EMO-DB [17]. The"
        },
        {
          "Dataset\nEmotion": "“Surprised” class from RAVDESS is excluded, as it\nis not"
        },
        {
          "Dataset\nEmotion": ""
        },
        {
          "Dataset\nEmotion": "present in EMO-DB,\n, which our model was fine-tuned on."
        },
        {
          "Dataset\nEmotion": ""
        },
        {
          "Dataset\nEmotion": ""
        },
        {
          "Dataset\nEmotion": ""
        },
        {
          "Dataset\nEmotion": "3.1.2. Backbone & classifier"
        },
        {
          "Dataset\nEmotion": ""
        },
        {
          "Dataset\nEmotion": "Architecture.\nWe adopt the EncoderClassifier mod-"
        },
        {
          "Dataset\nEmotion": "ule from SpeechBrain [20] with a wav2vec 2.0 encoder\n[7]"
        },
        {
          "Dataset\nEmotion": "pretrained\nin\na\nself-supervised\nfashion\nand fine-tuned\non"
        },
        {
          "Dataset\nEmotion": "IEMOCAP [21] for categorical emotion. This checkpoint has"
        },
        {
          "Dataset\nEmotion": "not been exposed to EmoDB, preventing leakage and ensur-"
        },
        {
          "Dataset\nEmotion": "ing fair evaluation on the German target corpus. The encoder"
        },
        {
          "Dataset\nEmotion": "produces\nframe-level\nrepresentations, which are temporally"
        },
        {
          "Dataset\nEmotion": "pooled into z ∈ Rd\nand projected through a\nlinear\nlayer"
        },
        {
          "Dataset\nEmotion": "aligned with EmoDB’s taxonomy:"
        },
        {
          "Dataset\nEmotion": ""
        },
        {
          "Dataset\nEmotion": "z = Pool(cid:0)f (x; θ)(cid:1),\n(6)"
        },
        {
          "Dataset\nEmotion": ""
        },
        {
          "Dataset\nEmotion": "y = Wz + b ∈ RC,\nC = 7.\n(7)"
        },
        {
          "Dataset\nEmotion": ""
        },
        {
          "Dataset\nEmotion": ""
        },
        {
          "Dataset\nEmotion": "Training schedule.\nTraining follows a two-stage strategy:"
        },
        {
          "Dataset\nEmotion": ""
        },
        {
          "Dataset\nEmotion": "the feature extractor\nis\nfrozen for\nthe initial epochs\nto sta-"
        },
        {
          "Dataset\nEmotion": ""
        },
        {
          "Dataset\nEmotion": "bilise learning on the small corpus, and then unfrozen at an"
        },
        {
          "Dataset\nEmotion": ""
        },
        {
          "Dataset\nEmotion": "HPO-controlled epoch u ∈ {0, . . . , 5} to enable task-specific"
        },
        {
          "Dataset\nEmotion": ""
        },
        {
          "Dataset\nEmotion": "adaptation once the classifier has converged.\nOptimisation"
        },
        {
          "Dataset\nEmotion": ""
        },
        {
          "Dataset\nEmotion": "uses cross-entropy loss, AdamW [22], and a cosine-annealed"
        },
        {
          "Dataset\nEmotion": "learning rate schedule."
        },
        {
          "Dataset\nEmotion": ""
        },
        {
          "Dataset\nEmotion": "3.1.3. HPO engines and search space"
        },
        {
          "Dataset\nEmotion": ""
        },
        {
          "Dataset\nEmotion": "We\ncompare GP-BO [10]\nand TPE [11],\nimplemented in"
        },
        {
          "Dataset\nEmotion": ""
        },
        {
          "Dataset\nEmotion": "three AutoML engines: Ax [23] (for GP-BO), Hyperopt [24]"
        },
        {
          "Dataset\nEmotion": ""
        },
        {
          "Dataset\nEmotion": "(for TPE), and Optuna [25] (for TPE). All engines optimise"
        },
        {
          "Dataset\nEmotion": ""
        },
        {
          "Dataset\nEmotion": "the same compact\nfour-dimensional\nspace tailored to low-"
        },
        {
          "Dataset\nEmotion": ""
        },
        {
          "Dataset\nEmotion": "resource SER fine-tuning, which is summarised in Table 2."
        },
        {
          "Dataset\nEmotion": ""
        },
        {
          "Dataset\nEmotion": ""
        },
        {
          "Dataset\nEmotion": "GP-BO in Ax.\nAx fits a Gaussian process surrogate over"
        },
        {
          "Dataset\nEmotion": ""
        },
        {
          "Dataset\nEmotion": "observed (λ, BCA) pairs and selects new configurations via"
        },
        {
          "Dataset\nEmotion": ""
        },
        {
          "Dataset\nEmotion": "an acquisition function (Expected Improvement by default)."
        },
        {
          "Dataset\nEmotion": ""
        },
        {
          "Dataset\nEmotion": "The search is seeded with a Sobol design and alternates sur-"
        },
        {
          "Dataset\nEmotion": ""
        },
        {
          "Dataset\nEmotion": "rogate fitting with acquisition maximisation. Ax also supports"
        },
        {
          "Dataset\nEmotion": ""
        },
        {
          "Dataset\nEmotion": "multi-point criteria (qEI/qUCB) and schedulers for early stop-"
        },
        {
          "Dataset\nEmotion": "ping and parallel evaluation."
        },
        {
          "Dataset\nEmotion": ""
        },
        {
          "Dataset\nEmotion": "TPE in Hyperopt.\nHyperopt partitions past trials at a quan-"
        },
        {
          "Dataset\nEmotion": "tile threshold y⋆ into “good” and “bad” sets, fits kernel den-"
        },
        {
          "Dataset\nEmotion": "sity estimates ℓ(x) and g(x) to each, and samples new config-"
        },
        {
          "Dataset\nEmotion": "urations by maximising ℓ(x)/g(x), proportional\nto expected"
        },
        {
          "Dataset\nEmotion": "improvement."
        }
      ],
      "page": 3
    },
    {
      "caption": "Table 3: Comparison of time to reach accuracy thresholds",
      "data": [
        {
          "Method": "Grid search",
          "> 0.80 BCA": "1056 min (trial 101)",
          "> 0.90 BCA": "1680 min (trial 143)",
          "Framework": "Grid Search",
          "Best BCA": "0.98",
          "Time to Best": "1680 min",
          "Ebest ↑": "0.0005"
        },
        {
          "Method": "TPE (Optuna)",
          "> 0.80 BCA": "7.8 min (trial 4)",
          "> 0.90 BCA": "185.3 min (trial 15)",
          "Framework": "AutoSpeech 2020 [12]",
          "Best BCA": "0.85",
          "Time to Best": "30 min",
          "Ebest ↑": "0.0280"
        },
        {
          "Method": "TPE (Hyperopt)",
          "> 0.80 BCA": "6.4 min (trial 5)",
          "> 0.90 BCA": "15 min (trial 11)",
          "Framework": "TPE (Optuna)",
          "Best BCA": "0.93",
          "Time to Best": "185 min",
          "Ebest ↑": "0.0050"
        },
        {
          "Method": "GP-BO (Ax)",
          "> 0.80 BCA": "2.4 min (trial 2)",
          "> 0.90 BCA": "2.4 min (trial 2)",
          "Framework": "TPE (Hyperopt)",
          "Best BCA": "0.97",
          "Time to Best": "15 min",
          "Ebest ↑": "0.0646"
        },
        {
          "Method": "",
          "> 0.80 BCA": "",
          "> 0.90 BCA": "",
          "Framework": "GP-BO (AX)",
          "Best BCA": "0.96",
          "Time to Best": "11 min",
          "Ebest ↑": "0.0872"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table 3: Comparison of time to reach accuracy thresholds",
      "data": [
        {
          "TPE (Optuna)": "TPE (Hyperopt)",
          "7.8 min (trial 4)": "6.4 min (trial 5)",
          "185.3 min (trial 15)": "15 min (trial 11)",
          "AutoSpeech 2020 [12]": "TPE (Optuna)",
          "0.85": "0.93",
          "30 min\n0.0280": "185 min\n0.0050"
        },
        {
          "TPE (Optuna)": "GP-BO (Ax)",
          "7.8 min (trial 4)": "2.4 min (trial 2)",
          "185.3 min (trial 15)": "2.4 min (trial 2)",
          "AutoSpeech 2020 [12]": "TPE (Hyperopt)",
          "0.85": "0.97",
          "30 min\n0.0280": "15 min\n0.0646"
        },
        {
          "TPE (Optuna)": "",
          "7.8 min (trial 4)": "",
          "185.3 min (trial 15)": "",
          "AutoSpeech 2020 [12]": "GP-BO (AX)",
          "0.85": "0.96",
          "30 min\n0.0280": "11 min\n0.0872"
        },
        {
          "TPE (Optuna)": "Table 3.",
          "7.8 min (trial 4)": "Comparison of",
          "185.3 min (trial 15)": "time to reach accuracy thresholds",
          "AutoSpeech 2020 [12]": "",
          "0.85": "",
          "30 min\n0.0280": ""
        },
        {
          "TPE (Optuna)": "",
          "7.8 min (trial 4)": "",
          "185.3 min (trial 15)": "",
          "AutoSpeech 2020 [12]": "",
          "0.85": "Table 5. Best balanced class accuracy (BCA),",
          "30 min\n0.0280": "time to reach"
        },
        {
          "TPE (Optuna)": "across different HPO engines. BCA denotes balanced class",
          "7.8 min (trial 4)": "",
          "185.3 min (trial 15)": "",
          "AutoSpeech 2020 [12]": "",
          "0.85": "",
          "30 min\n0.0280": ""
        },
        {
          "TPE (Optuna)": "",
          "7.8 min (trial 4)": "",
          "185.3 min (trial 15)": "",
          "AutoSpeech 2020 [12]": "",
          "0.85": "it, and efficiency (Ebest) across search methods. GP-BO (Ax)",
          "30 min\n0.0280": ""
        },
        {
          "TPE (Optuna)": "accuracy;",
          "7.8 min (trial 4)": "TPE refers\nto",
          "185.3 min (trial 15)": "tree-structured Parzen\nestimators",
          "AutoSpeech 2020 [12]": "",
          "0.85": "",
          "30 min\n0.0280": ""
        },
        {
          "TPE (Optuna)": "",
          "7.8 min (trial 4)": "",
          "185.3 min (trial 15)": "",
          "AutoSpeech 2020 [12]": "",
          "0.85": "provides the best trade-off between accuracy and time, while",
          "30 min\n0.0280": ""
        },
        {
          "TPE (Optuna)": "[11];",
          "7.8 min (trial 4)": "and GP-BO denotes Gaussian process Bayesian opti-",
          "185.3 min (trial 15)": "",
          "AutoSpeech 2020 [12]": "",
          "0.85": "",
          "30 min\n0.0280": ""
        },
        {
          "TPE (Optuna)": "",
          "7.8 min (trial 4)": "",
          "185.3 min (trial 15)": "",
          "AutoSpeech 2020 [12]": "",
          "0.85": "TPE (Hyperopt) achieves the highest peak BCA.",
          "30 min\n0.0280": ""
        },
        {
          "TPE (Optuna)": "misation [10]. Optuna [25], Hyperopt [24], and Ax [23] are",
          "7.8 min (trial 4)": "",
          "185.3 min (trial 15)": "",
          "AutoSpeech 2020 [12]": "",
          "0.85": "",
          "30 min\n0.0280": ""
        },
        {
          "TPE (Optuna)": "engines (implementations) of these methods. The best result",
          "7.8 min (trial 4)": "",
          "185.3 min (trial 15)": "",
          "AutoSpeech 2020 [12]": "",
          "0.85": "",
          "30 min\n0.0280": ""
        },
        {
          "TPE (Optuna)": "",
          "7.8 min (trial 4)": "",
          "185.3 min (trial 15)": "",
          "AutoSpeech 2020 [12]": "Corpus",
          "0.85": "BCA (Zero-shot)",
          "30 min\n0.0280": "BCA (HPO-tuned)"
        },
        {
          "TPE (Optuna)": "is highlighted in bold.",
          "7.8 min (trial 4)": "",
          "185.3 min (trial 15)": "",
          "AutoSpeech 2020 [12]": "",
          "0.85": "",
          "30 min\n0.0280": ""
        },
        {
          "TPE (Optuna)": "",
          "7.8 min (trial 4)": "",
          "185.3 min (trial 15)": "",
          "AutoSpeech 2020 [12]": "EmoDB",
          "0.85": "0.11",
          "30 min\n0.0280": "0.96"
        },
        {
          "TPE (Optuna)": "",
          "7.8 min (trial 4)": "",
          "185.3 min (trial 15)": "",
          "AutoSpeech 2020 [12]": "CREMA-D",
          "0.85": "0.13",
          "30 min\n0.0280": "0.38"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "classification schemes, and databases,” Pattern Recog-": "nition, vol. 44, no. 3, pp. 572–587, 2011.",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "Journal of Global\nof expensive black-box functions,”"
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "Optimization, vol. 13, no. 4, pp. 455–492, 1998."
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "[2] Bj¨orn W Schuller,\n“Speech emotion recognition: Two",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": ""
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "decades in a nutshell, benchmarks, and ongoing trends,”",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "[16] Niranjan Srinivas et al.,\n“Gaussian process optimiza-"
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "Communications of the ACM, vol. 61, no. 5, pp. 90–99,",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "tion in the bandit setting: No regret and experimental"
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "2018.",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "design,” in ICML, 2010."
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "[3] Bj¨orn Schuller, Stefan Steidl, and Anton Batliner, “The",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "[17] Felix Burkhardt et al., “A database of german emotional"
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "interspeech 2009 emotion challenge,”\nin Interspeech,",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "speech.,” in Interspeech, 2005, vol. 5, pp. 1517–1520."
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "2009.",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": ""
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "[18] Houwei Cao et al.,\n“Crema-d: Crowd-sourced emo-"
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "[4] Florian Eyben et al., “The geneva minimalistic acoustic",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "tional multimodal actors dataset,” IEEE Transactions on"
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "parameter set (gemaps) for voice research and affective",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "Affective Computing, vol. 5, no. 4, pp. 377–390, 2014."
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "IEEE Transactions on Affective Comput-\ncomputing,”",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": ""
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "[19] Steven R Livingstone and Frank A Russo,\n“The ryer-"
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "ing, vol. 7, no. 2, pp. 190–202, 2015.",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": ""
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "son audio-visual database of emotional speech and song"
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "[5] Kun Han, Dong Yu, and Ivan Tashev,\n“Speech emo-",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "(ravdess): A dynamic, multimodal set of facial and vo-"
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "tion recognition using deep neural network and extreme",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "cal expressions in north american english,”\nPloS One,"
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "learning machine,” in Interspeech, 2014.",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "vol. 13, no. 5, pp. e0196391, 2018."
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "[6] George Trigeorgis et al.,\n“Adieu features?\nend-to-end",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "[20] Mirco Ravanelli et al.,\n“Open-source conversational ai"
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "speech emotion recognition using a deep convolutional",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "with speechbrain 1.0,” JMLR, vol. 25, no. 333, 2024."
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "recurrent network,”\nin ICASSP. IEEE, 2016, pp. 5200–",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": ""
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "[21] Carlos Busso et al.,\n“Iemocap:\nInteractive emotional"
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "5204.",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": ""
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "dyadic motion capture database,” Language Resources"
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "[7] Alexei Baevski et al.,\n“wav2vec 2.0: A framework for",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "and Evaluation, vol. 42, no. 4, pp. 335–359, 2008."
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "self-supervised learning of speech representations,”\nin",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": ""
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "[22]\nIlya Loshchilov and Frank Hutter,\n“Decoupled weight"
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "NeurIPS, 2020, vol. 33, pp. 12449–12460.",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": ""
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "decay regularization,” in ICLR, 2019."
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "[8] Wei-Ning Hsu et al.,\n“Hubert: Self-supervised speech",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": ""
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "[23] Miles Olson et al., “Ax: a platform for adaptive experi-"
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "representation learning by masked prediction of hidden",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": ""
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "mentation,” in AutoML 2025 ABCD Track, 2025."
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "IEEE/ACM Transactions on Audio, Speech, and\nunits,”",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": ""
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "Language Processing, vol. 29, pp. 3451–3460, 2021.",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": ""
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "[24]\nJames Bergstra, Daniel Yamins, and David Cox, “Mak-"
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "ing a science of model\nsearch: Hyperparameter opti-"
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "[9] Shahin Amiriparian et al., “Exhubert: Enhancing hubert",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": ""
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "mization in hundreds of dimensions for vision architec-"
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "through block extension and fine-tuning on 37 emotion",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": ""
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "tures,” in ICML. PMLR, 2013, pp. 115–123."
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "datasets,” in Interspeech, 2024, pp. 2635–2639.",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": ""
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "[25] Takuya Akiba et al., “Optuna: A next-generation hyper-"
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "[10]\nJasper Snoek, Hugo Larochelle,\nand Ryan P Adams,",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": ""
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "parameter optimization framework,” in KDD, 2019."
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "“Practical bayesian optimization of machine learning al-",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": ""
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "gorithms,” in NeurIPS, 2012, vol. 25.",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": ""
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "[26] Zohar Karnin, Tomer Koren, and Oren Somekh,\n“Al-"
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "most optimal exploration in multi-armed bandits,”\nin"
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "[11]\nJames Bergstra, R´emi Bardenet, Yoshua Bengio,\nand",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": ""
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "ICML. PMLR, 2013, pp. 1238–1246."
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "Bal´azs K´egl,\n“Algorithms\nfor hyper-parameter opti-",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": ""
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "mization,” in NeurIPS, 2011, vol. 24.",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": ""
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "[27] Kevin Jamieson and Ameet Talwalkar, “Non-stochastic"
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "[12]\nJingsong Wang et\nal.,\n“Autospeech 2020:\nThe\nsec-",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "best\narm identification and hyperparameter optimiza-"
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "ond automated machine learning challenge for classifi-",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "tion,” in AISTATS. PMLR, 2016, pp. 240–248."
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "cation,” in Interspeech, 2020.",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": ""
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "[28] Lisha Li et al.,\n“Hyperband: A novel bandit-based ap-"
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "[13] Bj¨orn Schuller et al.,\n“Recognising realistic emotions",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "proach to hyperparameter optimization,” JMLR, vol. 18,"
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "and affect\nin speech: State of the art and lessons learnt",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "no. 185, pp. 1–52, 2018."
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "from the first challenge,”\nSpeech Communication, vol.",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": ""
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "[29] Sefik Emre Eskimez\net\nal.,\n“Emotion classification:"
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "53, no. 9-10, pp. 1062–1087, 2011.",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": ""
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "how does an automated system compare to naive human"
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "[14] Taiba Majid Wani et al.,\n“A comprehensive review of",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": "coders?,” in ICASSP. IEEE, 2016, pp. 2274–2278."
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "speech emotion recognition systems,” IEEE Access, vol.",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": ""
        },
        {
          "classification schemes, and databases,” Pattern Recog-": "9, pp. 47795–47814, 2021.",
          "[15] Donald R Jones et al.,\n“Efficient global optimization": ""
        }
      ],
      "page": 5
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "",
      "authors": [
        "References"
      ],
      "venue": ""
    },
    {
      "citation_id": "2",
      "title": "Survey on speech emotion recognition: Features, classification schemes, and databases",
      "authors": [
        "Moataz Ayadi",
        "Mohamed Kamel",
        "Fakhri Karray"
      ],
      "year": "2011",
      "venue": "Pattern Recognition"
    },
    {
      "citation_id": "3",
      "title": "Speech emotion recognition: Two decades in a nutshell, benchmarks, and ongoing trends",
      "authors": [
        "W Björn",
        "Schuller"
      ],
      "year": "2018",
      "venue": "Communications of the ACM"
    },
    {
      "citation_id": "4",
      "title": "The interspeech 2009 emotion challenge",
      "authors": [
        "Björn Schuller",
        "Stefan Steidl",
        "Anton Batliner"
      ],
      "year": "2009",
      "venue": "The interspeech 2009 emotion challenge"
    },
    {
      "citation_id": "5",
      "title": "The geneva minimalistic acoustic parameter set (gemaps) for voice research and affective computing",
      "authors": [
        "Florian Eyben"
      ],
      "year": "2015",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "6",
      "title": "Speech emotion recognition using deep neural network and extreme learning machine",
      "authors": [
        "Kun Han",
        "Dong Yu",
        "Ivan Tashev"
      ],
      "year": "2014",
      "venue": "Speech emotion recognition using deep neural network and extreme learning machine"
    },
    {
      "citation_id": "7",
      "title": "Adieu features? end-to-end speech emotion recognition using a deep convolutional recurrent network",
      "authors": [
        "George Trigeorgis"
      ],
      "year": "2016",
      "venue": "ICASSP"
    },
    {
      "citation_id": "8",
      "title": "wav2vec 2.0: A framework for self-supervised learning of speech representations",
      "authors": [
        "Alexei Baevski"
      ],
      "year": "2020",
      "venue": "NeurIPS"
    },
    {
      "citation_id": "9",
      "title": "Hubert: Self-supervised speech representation learning by masked prediction of hidden units",
      "authors": [
        "Wei-Ning Hsu"
      ],
      "year": "2021",
      "venue": "IEEE/ACM Transactions on Audio, Speech, and Language Processing"
    },
    {
      "citation_id": "10",
      "title": "Exhubert: Enhancing hubert through block extension and fine-tuning on 37 emotion datasets",
      "authors": [
        "Shahin Amiriparian"
      ],
      "year": "2024",
      "venue": "Exhubert: Enhancing hubert through block extension and fine-tuning on 37 emotion datasets"
    },
    {
      "citation_id": "11",
      "title": "Practical bayesian optimization of machine learning algorithms",
      "authors": [
        "Jasper Snoek",
        "Hugo Larochelle",
        "Ryan Adams"
      ],
      "year": "2012",
      "venue": "NeurIPS"
    },
    {
      "citation_id": "12",
      "title": "Algorithms for hyper-parameter optimization",
      "authors": [
        "James Bergstra",
        "Rémi Bardenet",
        "Yoshua Bengio",
        "Balázs Kégl"
      ],
      "year": "2011",
      "venue": "NeurIPS"
    },
    {
      "citation_id": "13",
      "title": "Autospeech 2020: The second automated machine learning challenge for classification",
      "authors": [
        "Jingsong Wang"
      ],
      "year": "2020",
      "venue": "Autospeech 2020: The second automated machine learning challenge for classification"
    },
    {
      "citation_id": "14",
      "title": "Recognising realistic emotions and affect in speech: State of the art and lessons learnt from the first challenge",
      "authors": [
        "Björn Schuller"
      ],
      "year": "2011",
      "venue": "Speech Communication"
    },
    {
      "citation_id": "15",
      "title": "A comprehensive review of speech emotion recognition systems",
      "authors": [
        "Taiba Majid"
      ],
      "year": "2021",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "16",
      "title": "Efficient global optimization of expensive black-box functions",
      "authors": [
        "Donald R Jones"
      ],
      "year": "1998",
      "venue": "Journal of Global Optimization"
    },
    {
      "citation_id": "17",
      "title": "Gaussian process optimization in the bandit setting: No regret and experimental design",
      "authors": [
        "Niranjan Srinivas"
      ],
      "year": "2010",
      "venue": "ICML"
    },
    {
      "citation_id": "18",
      "title": "A database of german emotional speech",
      "authors": [
        "Felix Burkhardt"
      ],
      "year": "2005",
      "venue": "A database of german emotional speech"
    },
    {
      "citation_id": "19",
      "title": "Crema-d: Crowd-sourced emotional multimodal actors dataset",
      "authors": [
        "Houwei Cao"
      ],
      "year": "2014",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "20",
      "title": "The ryerson audio-visual database of emotional speech and song (ravdess): A dynamic, multimodal set of facial and vocal expressions in north american english",
      "authors": [
        "R Steven",
        "Frank Livingstone",
        "Russo"
      ],
      "year": "2018",
      "venue": "PloS One"
    },
    {
      "citation_id": "21",
      "title": "Open-source conversational ai with speechbrain 1.0",
      "authors": [
        "Mirco Ravanelli"
      ],
      "year": "2024",
      "venue": "JMLR"
    },
    {
      "citation_id": "22",
      "title": "Iemocap: Interactive emotional dyadic motion capture database",
      "authors": [
        "Carlos Busso"
      ],
      "year": "2008",
      "venue": "Language Resources and Evaluation"
    },
    {
      "citation_id": "23",
      "title": "Decoupled weight decay regularization",
      "authors": [
        "Ilya Loshchilov",
        "Frank Hutter"
      ],
      "year": "2019",
      "venue": "ICLR"
    },
    {
      "citation_id": "24",
      "title": "Ax: a platform for adaptive experimentation",
      "authors": [
        "Miles Olson"
      ],
      "year": "2025",
      "venue": "AutoML 2025 ABCD Track"
    },
    {
      "citation_id": "25",
      "title": "Making a science of model search: Hyperparameter optimization in hundreds of dimensions for vision architectures",
      "authors": [
        "James Bergstra",
        "Daniel Yamins",
        "David Cox"
      ],
      "year": "2013",
      "venue": "ICML"
    },
    {
      "citation_id": "26",
      "title": "Optuna: A next-generation hyperparameter optimization framework",
      "authors": [
        "Takuya Akiba"
      ],
      "year": "2019",
      "venue": "KDD"
    },
    {
      "citation_id": "27",
      "title": "Almost optimal exploration in multi-armed bandits",
      "authors": [
        "Zohar Karnin",
        "Tomer Koren",
        "Oren Somekh"
      ],
      "year": "2013",
      "venue": "ICML"
    },
    {
      "citation_id": "28",
      "title": "Non-stochastic best arm identification and hyperparameter optimization",
      "authors": [
        "Kevin Jamieson",
        "Ameet Talwalkar"
      ],
      "year": "2016",
      "venue": "AISTATS"
    },
    {
      "citation_id": "29",
      "title": "Hyperband: A novel bandit-based approach to hyperparameter optimization",
      "authors": [
        "Lisha Li"
      ],
      "year": "2018",
      "venue": "JMLR"
    },
    {
      "citation_id": "30",
      "title": "Emotion classification: how does an automated system compare to naive human coders?",
      "authors": [
        "Sefik Emre"
      ],
      "year": "2016",
      "venue": "ICASSP"
    }
  ]
}