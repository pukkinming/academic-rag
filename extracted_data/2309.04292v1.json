{
  "paper_id": "2309.04292v1",
  "title": "Fuzzy Fingerprinting Transformer Language-Models For Emotion Recognition In Conversations",
  "published": "2023-09-08T12:26:01Z",
  "authors": [
    "Patrícia Pereira",
    "Rui Ribeiro",
    "Helena Moniz",
    "Luisa Coheur",
    "Joao Paulo Carvalho"
  ],
  "keywords": [
    "Fuzzy Fingerprints",
    "Large Language models",
    "RoBERTa",
    "Emotion Recognition in Conversations"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Fuzzy Fingerprints have been successfully used as an interpretable text classification technique, but, like most other techniques, have been largely surpassed in performance by Large Pre-trained Language Models, such as BERT or RoBERTa. These models deliver state-of-the-art results in several Natural Language Processing tasks, namely Emotion Recognition in Conversations (ERC), but suffer from the lack of interpretability and explainability. In this paper, we propose to combine the two approaches to perform ERC, as a means to obtain simpler and more interpretable Large Language Models-based classifiers. We propose to feed the utterances and their previous conversational turns to a pre-trained RoBERTa, obtaining contextual embedding utterance representations, that are then supplied to an adapted Fuzzy Fingerprint classification module. We validate our approach on the widely used DailyDialog ERC benchmark dataset, in which we obtain state-of-the-art level results using a much lighter model.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "I. Introduction",
      "text": "Emotion Recognition in Conversations (ERC) has become increasingly important with the widespread use of conversational agents. Recognizing emotions is essential for communication, being a crucial component in the development of effective and empathetic conversational agents. ERC is also used for automatic opinion mining and therapeutic practices.\n\nThere is thus a growing interest in endowing machines with efficient emotion recognition modules.\n\nFuzzy Fingerprints (FFP) have been successfully used as an interpretable text classification technique  [6]    [18] , but, like",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Fuzzify Fingerprint Library",
      "text": "Class A Class B Class C … Fuzzy Similarity Function Fig.  1 . Model architecture. In this example input, an utterance, u i , and its conversational context, u i-1 , are fed to RoBERTa encoder, of which the [CLS] token of the last layer goes through the Fuzzy Fingerprint module.\n\nmost other text classification techniques, have been largely surpassed in performance by Pre-trained Language-Models (PLMs), which are the current state-of-the-art in most Text Classification tasks, including ERC. However, PLMs are massively complex black boxes that lack interpretability, and explaining the obtained outcomes from these models is still a challenge. Like other deep neural-based models, despite being able of state-of-the-art performance, they can also fail catastrophically in situations of apparent simplicity  [5] .\n\nIn this paper, we propose to combine our ERC contextdependent embedding representation from the RoBERTa PLM  [13]  with an adapted Fuzzy Fingerprint classification module  [16]  in order to introduce some interpretability to RoBERTa, while maintaining PLMs performance levels. To test the proposed approach we resort to Daily Dialog  [9] , a widely used benchmark ERC dataset, and we find that the addition of FFP not only allows for result interpretability but also results in a performance increase that gives a state-of-the-art comparable performance with much heavier models.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Ii. Related Work",
      "text": "",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "A. Emotion Recognition In Conversations",
      "text": "Knowledge and understanding of the conversational context, i.e., the previous conversational turns, are extremely valuable for identifying the emotions of the interlocutors  [15]    [12] . Therefore, in this section, we describe approaches that leverage the conversational context in ERC.\n\nAmongst the first works considering contextual interdependences among utterances is the one by Poria et al.  [14] , which leverages Long Short-Term Memory networks (LSTMs) to extract contextual features from the utterances. A more elaborate model is DialogueRNN  [11] , which uses three Gated Recurring Units (GRU) in the classification module to model several aspects of the conversation.\n\nOne major problem in using RNNs is the long path of information flow, that difficults the capture of long-term dependencies. These dependencies can be better captured with the Transformer architecture which has a shorter path of information flow. Its introduction in 2017  [21]  led to a new state-of-the-art in several Natural Language Processing (NLP) tasks. Amongst the first works leveraging the Transformer is the Knowledge-Enriched Transformer (KET)  [23] .\n\nFollowing the emergence of Transformers, new encoder PLMs based on this architecture (such as BERT  [2]  and RoBERTa  [10] ) were introduced and achieved state-of-theart in various NLP benchmarks. Since their emergence, most state-of-the-art ERC works resorted to encoder PLMs.\n\nCOSMIC  [4]  leverages RoBERTa to encode utterances. Furthermore, it makes use of the commonsense transformer model COMET  [1] , a large knowledge base, in order to extract commonsense features. Five bi-directional GRUs model several aspects of the conversation in the classification module. Psychological  [8]  also uses RoBERTa for utterance encoding and the large external knowledge base COMET. It introduces a graph of utterances for conversation-level encoding that needs to be processed with a graph transformer.\n\nContrarily to the aforementioned approaches, we produce RoBERTa context-dependent embedding representations of each utterance, discarding the need for such complex classification modules.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "B. Pre-Trained Transformer Encoder Language-Models",
      "text": "A very popular large pre-trained model is BERT  [2] , a multilayer bidirectional Transformer encoder trained to perform language modeling and next-sentence prediction. BERT was trained on English Wikipedia and the BooksCorpus during a computationally expensive process, where it learns deep contextual embeddings, i.e, vectors representing the semantics of each word or sequence of words.\n\nRoBERTa  [10] , a successor to BERT, contains the same architecture as BERT but is pre-trained with more data and for a longer period of time, uses larger mini-batches and a larger learning rate, and discards BERT's task of next-sentence prediction.\n\nRoBERTa has outperformed BERT in various tasks using the same amount of data.\n\nPLMs are pre-trained on certain NLP tasks, and in order to be adapted to specific tasks, they just need to be fine-tuned to the task at hand. The process of fine-tuning consists of supervised training of the PLM in the target dataset, after appending a classification module to fit the dataset characteristics, namely the set of classification labels. During this process, the PLM's weights adjust to deliver maximal performance in the target dataset.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "C. Fuzzy Fingerprints",
      "text": "Fingerprint identification is a well-known and widely documented technique in forensic sciences. In Computer Science, a fingerprint is a procedure that maps an arbitrarily large data item to a much more compact information block (a fingerprint) that uniquely identifies the original data for all practical purposes.\n\nFuzzy Fingerprints (FFP), as used in this work, were introduced as a technique to identify one-out-of-many-suspects in tasks such as Web User Identification  [7]  or Text Authorship Identification  [6] . For this purpose, FFP are built based on feature frequency. For example, for text classification purposes, we consider a set of texts associated with a given class to build the class fingerprint and can use the frequency of each word in each text to build the fingerprint for that class.\n\nFuzzy Fingerprints have been further used and adapted for several tasks involving text classification, such as Tweet Topic Detection  [17]  or cyberbullying detection in social networks  [18] .\n\n1) Fuzzy Fingerprint Creation and Fuzzy Fingerprint Libraries: The training set is processed to compute the top-K feature list for each class. Consider F j as the set of events of class j (simplistic example: the set of all words for all texts belonging to class j). The result consists of a list of K pairs {v i , n i }, 1 < i ≤ K, where v i is the i-th most frequent feature and n i the corresponding count. The next step consists in fuzzifying each top-K list: a membership value is assigned to each feature in the set based on the order in the list (the rank). The more frequent features will have a higher membership value. The FFP (Φ), consists of a size-K fuzzy vector where each position i contains element v i and a membership value µ i . A class j will be represented by its fingerprint Φ j = Φ(F j ).\n\nFormally, a fingerprint\n\nThe set of all class fingerprints will constitute the fingerprint library.\n\n2) Fuzzy Fingerprint Detection: In order to find the class of an unknown instance, for example, a text T , we start by computing the size-K fingerprint of T , Φ T . Then we compare the fingerprint of T with the fingerprints Φ j of all classes present in the fingerprint library. The unknown text is classified as j if it has the most similar fingerprint to Φ j . Fingerprint similarity, sim(Φ T , Φ j ), is calculated using\n\nwhere µ v (Φ x ) is the membership value associated with the rank of element v in fingerprint x. This function is based on the fuzzy AND (here we use the minimum or Gōdel t-norm).\n\nN is a constant that can be used for normalization purposes.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Iii. Fuzzy Fingerprinting Roberta For Erc",
      "text": "",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "A. Task Definition",
      "text": "Given a conversation composed of a sequence of u i utterances with corresponding emotion i from a predefined set of emotions, the aim of ERC is to correctly assign an emotion to each utterance of the conversation. An utterance consists of a sequence of w it tokens representing its T i words:",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "B. Context-Dependent Embedding Utterance Representations",
      "text": "The most common approach for ERC has been to produce context-independent representations of each utterance (using PLMs), and subsequently perform contextual modeling of the obtained representations with classification modules comprising gated and graph neural networks. In a recent work  [13] , we proposed to produce context-dependent representations of each utterance that represent not only the utterance but also a given number of previous utterances from the conversation. This context-based approach allowed us to discard the need for complex classification modules: a single fully connected linear softmax layer appended to this variation of RoBERTa, is enough to achieve state-of-the-art level performance.\n\nWhen pooling the embeddings, we chose the first embedding from the last layer L, the [CLS] token which is used for classification, as in Equation  3 .\n\nThis embedding is then fed to a fully connected linear layer with softmax so that the complete model maximizes the probability of the correct labels.\n\nFor this work, we use the fully connected layer to finetune RoBERTa, but discard and replace it afterward with a Fuzzy Fingerprint classification module, as detailed in the next section and represented in Figure  1 .",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "C. Fuzzy Fingerprinting Roberta",
      "text": "Fuzzy Fingerprints are based on the concept of feature frequencies (section II-C1). In order to fingerprint RoBERTa, we must find a way to adapt this concept to the RoBERTa's output, i.e., to the final hidden state of the [CLS] classification token, which is a real-valued vector (with dimension 768) where each element does not have a known meaning.\n\nA solution to address this issue, is to use the intensity of the activation of each element from the RoBERTa's output as a proxy for feature frequency.\n\nUnlike traditional FFP, where the size of the universe of discourse is finite but unknown (e.g. the number of all existing words), here the fingerprint size is limited to 768. Hence it is possible to define a RoBERTa FFP as a discrete Fuzzy Set (in the discrete universe of the RoBERTa outputs), where each of the 768 outputs has an associated membership value that is computed based on its activation rank. Only the top-K elements have a membership greater than zero, and for practical purposes, the set is ordered by the membership function of its elements.\n\nThe process to create the fingerprint of a specific emotion can be therefore succinctly described as \"ranking and fuzzifying the activation of the RoBERTa's outputs through the training set (of that emotion)\". The procedure is described as follows:\n\n1) The training data is used to create fuzzy fingerprints for each emotion (class).\n\n2) The fingerprint for each emotion begins as a 2D vector of size 768, where each position contains an index and a value initialized to 0.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "3) The Fine-Tuned Context-Based Roberta Is Fed With All",
      "text": "the training examples of a given emotion (one by one). 4) The RoBERTa output for each example consists of a 768-sized vector of real values. The real-valued outputs are added to the fingerprint. Hence, after all the training examples (of a given emotion) are fed into RoBERTa, the fingerprint of the emotion consists of the 2D vector, where each position contains an index and the accumulated value of the RoBERTa output for all the examples. 5) Order the fingerprint vector by the accumulated value (in descending order). 6) Reduce the 2D vector to a single dimension by discarding the column containing the accumulated values (only the rank matters). As a result, we have, for each emotion, a vector of dimension 768, containing the indexes of the mostly activated RoBERTa outputs for that emotion, i.e., the RoBERTa outputs are ranked by activation on the training set. 7) The fingerprint will only use the top-K RoBERTa outputs for classification purposes (instead of the whole 768 RoBERTa outputs). K is selected on the validation set. 8) The FFP is obtained by fuzzifying the top-K sized vector according to the following function:\n\nin which i is the index of the element in the sorted vector, K, is the fingerprint size, and a adjusts the slope of the function. The function gives higher-ranked items a larger membership. Other functions were tested on a validation set. This is the function that provided the best score.\n\nAfter obtaining the fingerprints for all possible emotions (the Fingerprint Library), classification can be performed. Given a sequence of u i utterances to be classified: 1) Pass u i through RoBERTa.\n\n2) Create the fingerprint of u i using the same procedure used to create the fingerprint of an emotion (i.e. rank the activation of the output vector, select the Top-K elements and fuzzify the resulting vector). 3) Check the similarity of the fingerprint of u i against the fingerprint of each emotion using the Fuzzy Fingerprint similarity function from Equation  1 , and select the emotion with the highest similarity.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Iv. Experimental Setup",
      "text": "",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "A. Training Details",
      "text": "To obtain the context-dependent embedding utterance representations we leverage RoBERTa-base from the Transformers library by Hugging Face  [22] , trained with the cross-entropy loss with logits. We use the Adam optimizer, with an initial learning rate of 1e-5 and 5e-5, for the encoder and the classification head, respectively with a layer-wise decay rate of 0.95 after each training epoch for the encoder, which is frozen for the first epoch. The batch size is set to 4. Gradient clipping is set to 1.0. Early stopping is used to terminate training if there is no improvement after 5 consecutive epochs on the validation set over macro-F1, for a maximum of 10 epochs. The checkpoint used in testing is the one that achieves the highest macro-F1 score on the validation set. The Fuzzy Fingerprint module was proposed and coded by us.\n\nFrom Table  II  it can be observed the DailyDialog dataset is imbalanced, not only for its dominant majority neutral class but also for the relative imbalance between minority classes. To promote consistent performance across all classes we have opted to use the macro-F1 score for model selection.\n\nWith regards to the parameter a we have observed experimentally that 0.8 is a suitable value.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "B. Evaluation",
      "text": "The reported results are an average of 5 runs corresponding to 5 distinct random seeds that are kept for a meaningful comparison of all experiments. This average is motivated by the fact that results for the same experiment obtained with different random seeds can have high variability in the macro F1-score, comparable to the improvements that we report regarding state-of-the-art models. This procedure is also in line with several authors that also resort to 5 run averages in ERC tasks  [8]    [23]  [19]  [20] .",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "C. Dataset",
      "text": "DailyDialog  [9]  is built from websites used to practice English dialogue in daily life. Table I resumes its main statistics. It is labeled with the six Ekman's basic emotions  [3] , anger, disgust, fear, happiness, sadness and surprise, or neutral. The publicly available splits of Yanran are used and the label distribution is presented in Table  II . V. RESULTS AND ANALYSIS In this section, we present some experimental results and compare our approach to current state-of-the-art models. We start by checking the effect of the FFP size K on the performance. From Table  III  and the graph in Figure  2  we can see that, for K larger than 150, the performance of our proposed model is comparable to using all the 768 RoBERTa outputs (and within state-of-the-art performance level). It is therefore possible to conclude that it is not necessary to use all the RoBERTa outputs to obtain high performance and that it is possible to use a smaller and less computationally demanding model once K is decided. This also hints that it is possible to train a smaller base model for this task.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "A. Fuzzy Fingerprint",
      "text": "It can be observed that the peak of performance happens for K=300, which yields an F1-score of 51.89.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "B. Comparison Without The Fuzzy Fingerprint Module",
      "text": "When using the same RoBERTa representation for the Fuzzy Fingerprint module but resorting only to the simple fully connected linear layer as a classification module both for training and prediction, we obtain an F1-score of 51.23  [13] . Given that performance differences from state-of-the-art approaches can consist in improvements of the magnitude of less than 1 F1-score, as it can be seen in Table  V , our improvement of 0.66 in F1-score is considered significant (results are an average of 5 runs to preserve statistical significance).",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "C. Performance On Each Emotion Label",
      "text": "We report the F1-score on each individual emotion label with the best value for K=300 in Table  IV  (5 runs average). From Table  IV  it can be observed that the classifier performs better at the most represented classes in the dataset, having an F1 score of above 60 for the well-represented class Happiness and an even higher F1 score of around 90 for the overrepresented Neutral class.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "D. Comparison With State-Of-The-Art",
      "text": "We compare our approach to other state-of-the-art works that also resort to RoBERTa. This allows for a fair comparison between approaches given that using this PLM brings great performance increases when compared to using other means of utterance feature extraction.\n\nWe compare our approach to COSMIC  [4] , RoBERTa and RoBERTa DialogueRNN, implemented by the authors of COSMIC, and the Psychological model  [8] , all models described in Section II. Results are displayed in table V and are an average of 5 runs.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Table V Comparison With State-Of-The-Art Works",
      "text": "macro-F1 RoBERTa  [4]  48.20 RoBERTa + DialogueRNN  [4]  49.65 COSMIC  [4]  51.05 Contextual RoBERTa  [13]  51.23 Psychological  [8]  51.95 Contextual RoBERTa + FFP 51.89\n\nOur approach outperforms not only the simple RoBERTa, but also RoBERTa in a more elaborate gated neural network model such as DialogueRNN and COSMIC. The Psychological model has a slightly higher performance than ours, but it uses RoBERTa Large, needs a heavy commonsense knowledge base, COMET  [1] , and a complex graph of utterances as a conversational level encoder that needs to be processed with a graph transformer. In comparison, our model uses RoBERTa base fine-tuned using context, and a minimalist fuzzy fingerprint classification model.\n\nWe have also performed experiments with ChatGPT 3 and 4, with the introduction of a variable number of context turns in the prompt, and observed that both ChatGPT versions do not outperform our context-dependent embedding utterance representation approach  [13] , which is outperformed by our proposed fuzzy fingerprints approach.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "E. Ffp Interpretability/Explainability Examples",
      "text": "We claim that using FFP can add some much-needed interpretability and explainability to PLMs. Here we present three examples that help to support our claim. We use small fingerprints for visualization and exemplification purposes. Table VI presents the generated Emotion FFP for K=10.\n\nThe first noticeable aspect is how output 588 is present at the top of 5 out of the 7 classes. This can be potentially leveraged to improve ERC performance using a multistage classifier, since 588 is not present in the Neutral FFP, which is the majority class and where most misclassifications end up.\n\nIn Table  VII  three examples of utterance and class fingerprints, and the respective similarity results (considering N = 1), are presented.\n\nThe first example shows that there are many elements in common between the utterance and the class FFP and there is no doubt that we have a correct classification.\n\nThe second and third examples show an interesting case of an incorrect classification and how the FFP can explain such error. The FFP of the utterance \"You still have not given me those files I've asked you for\" clearly indicates a strong similarity to the Angry emotion, with many important features in common between the fingerprints. Yet, according to the dataset annotation, the utterance is supposed to be Neutral. This misclassification cannot be explained by the FFP, however, it could certainly be argued by a native English speaker that the utterance has a definite negative meaning. Due to the negative meaning, the most present emotion is probably more Anger than Neutral, revealing either an annotation error or some hidden knowledge from the annotator that cannot be extracted from the utterance. A more polite and neutral way of expressing the same message would be, for example, \"Don't forget to give me the files I've asked you for\" (the third example on the table). Here we see that the FFP clearly indicates a Neutral emotion despite the sentence expressing the same message, albeit with a different tone.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Vi. Conclusion And Future Work",
      "text": "In this paper, we proposed to combine pre-trained Transformer Language Models with Fuzzy Fingerprints. Concretely,",
      "page_start": 5,
      "page_end": 5
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Model architecture. In this example input, an utterance, ui, and its",
      "page": 1
    },
    {
      "caption": "Figure 1: C. Fuzzy Fingerprinting RoBERTa",
      "page": 3
    },
    {
      "caption": "Figure 2: Variation of the F1-score with the fingerprint size K. Other models",
      "page": 4
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": ""
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": ""
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": "an interpretable text classification technique, but,\nlike most other"
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": "techniques, have been largely surpassed in performance by Large"
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": ""
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": "Pre-trained Language Models,\nsuch\nas BERT or RoBERTa."
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": "These models deliver\nstate-of-the-art\nresults\nin several Natural"
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": ""
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": "Language\nProcessing\ntasks,\nnamely\nEmotion Recognition\nin"
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": "Conversations (ERC), but suffer from the lack of interpretability"
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": "and explainability.\nIn this paper, we propose\nto\ncombine\nthe"
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": "two approaches\nto perform ERC, as a means\nto obtain simpler"
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": ""
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": "and more interpretable Large Language Models-based classifiers."
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": "We propose\nto feed the utterances and their previous\nconver-"
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": "sational\nturns\nto a pre-trained RoBERTa, obtaining contextual"
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": "embedding utterance representations,\nthat are then supplied to"
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": "an adapted Fuzzy Fingerprint classification module. We validate"
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": "our approach on the widely used DailyDialog ERC benchmark"
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": "dataset,\nin which we obtain state-of-the-art\nlevel results using a"
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": "much lighter model."
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": "Index Terms—Fuzzy Fingerprints, Large Language models,"
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": ""
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": "RoBERTa, Emotion Recognition in Conversations"
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": "I.\nINTRODUCTION"
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": "Emotion Recognition in Conversations\n(ERC) has become"
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": "increasingly important with the widespread use of conversa-"
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": "tional agents. Recognizing emotions\nis essential\nfor commu-"
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": "nication, being a\ncrucial\ncomponent\nin the development of"
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": "effective\nand empathetic\nconversational\nagents. ERC is\nalso"
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": "used for automatic opinion mining and therapeutic practices."
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": ""
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": "There is thus a growing interest\nin endowing machines with"
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": ""
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": "efficient emotion recognition modules."
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": "Fuzzy Fingerprints\n(FFP) have been successfully used as"
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": "an interpretable text classification technique [6] [18], but,\nlike"
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": ""
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": "This work was supported by Fundac¸ ˜ao para a Ciˆencia e a Tecnologia (FCT),"
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": "through Portuguese national funds Ref. UIDB/50021/2020, Agˆencia Nacional"
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": ""
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": "de Inovac¸ ˜ao (ANI),\nthrough the project CMU-PT MAIA Ref. 045909, RRP"
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": ""
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": "and Next Generation EU project Center for Responsible AI Ref. C645008882-"
        },
        {
          "Abstract—Fuzzy Fingerprints have been successfully used as": "00000055, and the COST Action Multi3Generation Ref. CA18231."
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "a\nchallenge. Like\nother\ndeep\nneural-based models,\ndespite",
          "B. Pre-trained Transformer Encoder Language-Models": ""
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "",
          "B. Pre-trained Transformer Encoder Language-Models": "A very popular large pre-trained model is BERT [2], a multi-"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "being able of\nstate-of-the-art performance,\nthey can also fail",
          "B. Pre-trained Transformer Encoder Language-Models": ""
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "",
          "B. Pre-trained Transformer Encoder Language-Models": "layer\nbidirectional Transformer\nencoder\ntrained\nto\nperform"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "catastrophically in situations of apparent simplicity [5].",
          "B. Pre-trained Transformer Encoder Language-Models": ""
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "",
          "B. Pre-trained Transformer Encoder Language-Models": "language modeling and next-sentence prediction. BERT was"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "In this paper, we propose\nto combine our ERC context-",
          "B. Pre-trained Transformer Encoder Language-Models": ""
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "",
          "B. Pre-trained Transformer Encoder Language-Models": "trained\non English Wikipedia\nand\nthe BooksCorpus\nduring"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "dependent embedding representation from the RoBERTa PLM",
          "B. Pre-trained Transformer Encoder Language-Models": ""
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "",
          "B. Pre-trained Transformer Encoder Language-Models": "a\ncomputationally\nexpensive\nprocess, where\nit\nlearns\ndeep"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "[13] with an adapted Fuzzy Fingerprint classification module",
          "B. Pre-trained Transformer Encoder Language-Models": ""
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "",
          "B. Pre-trained Transformer Encoder Language-Models": "contextual embeddings,\ni.e, vectors representing the semantics"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "[16]\nin order\nto introduce some interpretability to RoBERTa,",
          "B. Pre-trained Transformer Encoder Language-Models": ""
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "",
          "B. Pre-trained Transformer Encoder Language-Models": "of each word or sequence of words."
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "while maintaining PLMs performance levels. To test\nthe pro-",
          "B. Pre-trained Transformer Encoder Language-Models": ""
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "",
          "B. Pre-trained Transformer Encoder Language-Models": "RoBERTa\n[10],\na\nsuccessor\nto BERT,\ncontains\nthe\nsame"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "posed approach we resort\nto Daily Dialog [9], a widely used",
          "B. Pre-trained Transformer Encoder Language-Models": ""
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "",
          "B. Pre-trained Transformer Encoder Language-Models": "architecture as BERT but\nis pre-trained with more data and"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "benchmark ERC dataset, and we find that\nthe addition of FFP",
          "B. Pre-trained Transformer Encoder Language-Models": ""
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "",
          "B. Pre-trained Transformer Encoder Language-Models": "for\na\nlonger period of\ntime, uses\nlarger mini-batches\nand a"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "not only allows for\nresult\ninterpretability but also results in a",
          "B. Pre-trained Transformer Encoder Language-Models": ""
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "",
          "B. Pre-trained Transformer Encoder Language-Models": "larger learning rate, and discards BERT’s task of next-sentence"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "performance increase that gives a state-of-the-art comparable",
          "B. Pre-trained Transformer Encoder Language-Models": ""
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "",
          "B. Pre-trained Transformer Encoder Language-Models": "prediction."
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "performance with much heavier models.",
          "B. Pre-trained Transformer Encoder Language-Models": ""
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "",
          "B. Pre-trained Transformer Encoder Language-Models": "RoBERTa has outperformed BERT in various\ntasks using"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "",
          "B. Pre-trained Transformer Encoder Language-Models": "the same amount of data."
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "II. RELATED WORK",
          "B. Pre-trained Transformer Encoder Language-Models": ""
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "",
          "B. Pre-trained Transformer Encoder Language-Models": "PLMs are pre-trained on certain NLP tasks, and in order to"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "A. Emotion Recognition in Conversations",
          "B. Pre-trained Transformer Encoder Language-Models": "be adapted to specific tasks,\nthey just need to be fine-tuned to"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "",
          "B. Pre-trained Transformer Encoder Language-Models": "the task at hand. The process of fine-tuning consists of super-"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "Knowledge and understanding of the conversational context,",
          "B. Pre-trained Transformer Encoder Language-Models": ""
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "",
          "B. Pre-trained Transformer Encoder Language-Models": "vised training of the PLM in the target dataset, after appending"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "i.e.,\nthe previous conversational\nturns, are extremely valuable",
          "B. Pre-trained Transformer Encoder Language-Models": ""
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "",
          "B. Pre-trained Transformer Encoder Language-Models": "a classification module to fit the dataset characteristics, namely"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "for\nidentifying\nthe\nemotions\nof\nthe\ninterlocutors\n[15]\n[12].",
          "B. Pre-trained Transformer Encoder Language-Models": ""
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "",
          "B. Pre-trained Transformer Encoder Language-Models": "the set of classification labels. During this process,\nthe PLM’s"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "Therefore, in this section, we describe approaches that leverage",
          "B. Pre-trained Transformer Encoder Language-Models": ""
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "",
          "B. Pre-trained Transformer Encoder Language-Models": "weights adjust\nto deliver maximal performance in the target"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "the conversational context\nin ERC.",
          "B. Pre-trained Transformer Encoder Language-Models": ""
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "",
          "B. Pre-trained Transformer Encoder Language-Models": "dataset."
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "Amongst\nthe first works considering contextual\ninterdepen-",
          "B. Pre-trained Transformer Encoder Language-Models": ""
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "dences\namong\nutterances\nis\nthe\none\nby\nPoria\net\nal.\n[14],",
          "B. Pre-trained Transformer Encoder Language-Models": "C. Fuzzy Fingerprints"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "which leverages Long Short-Term Memory networks (LSTMs)",
          "B. Pre-trained Transformer Encoder Language-Models": ""
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "",
          "B. Pre-trained Transformer Encoder Language-Models": "Fingerprint\nidentification is a well-known and widely docu-"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "to\nextract\ncontextual\nfeatures\nfrom the\nutterances. A more",
          "B. Pre-trained Transformer Encoder Language-Models": ""
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "",
          "B. Pre-trained Transformer Encoder Language-Models": "mented technique in forensic sciences.\nIn Computer Science,"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "elaborate model is DialogueRNN [11], which uses three Gated",
          "B. Pre-trained Transformer Encoder Language-Models": ""
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "",
          "B. Pre-trained Transformer Encoder Language-Models": "a fingerprint\nis\na\nprocedure\nthat maps\nan\narbitrarily\nlarge"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "Recurring Units (GRU)\nin the classification module to model",
          "B. Pre-trained Transformer Encoder Language-Models": ""
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "",
          "B. Pre-trained Transformer Encoder Language-Models": "data\nitem to\na much more\ncompact\ninformation\nblock\n(a"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "several aspects of\nthe conversation.",
          "B. Pre-trained Transformer Encoder Language-Models": ""
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "",
          "B. Pre-trained Transformer Encoder Language-Models": "fingerprint)\nthat uniquely identifies\nthe original data\nfor\nall"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "One major\nproblem in\nusing RNNs\nis\nthe\nlong\npath\nof",
          "B. Pre-trained Transformer Encoder Language-Models": "practical purposes."
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "information flow,\nthat difficults\nthe capture of\nlong-term de-",
          "B. Pre-trained Transformer Encoder Language-Models": "Fuzzy Fingerprints (FFP), as used in this work, were intro-"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "pendencies. These dependencies can be better captured with",
          "B. Pre-trained Transformer Encoder Language-Models": "duced as a technique to identify one-out-of-many-suspects in"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "the Transformer\narchitecture which\nhas\na\nshorter\npath\nof",
          "B. Pre-trained Transformer Encoder Language-Models": "tasks such as Web User\nIdentification [7] or Text Authorship"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "information flow.\nIts\nintroduction in 2017 [21]\nled to a new",
          "B. Pre-trained Transformer Encoder Language-Models": "Identification [6]. For this purpose, FFP are built based on fea-"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "state-of-the-art\nin several Natural Language Processing (NLP)",
          "B. Pre-trained Transformer Encoder Language-Models": "ture frequency. For example,\nfor\ntext classification purposes,"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "tasks. Amongst\nthe first works leveraging the Transformer\nis",
          "B. Pre-trained Transformer Encoder Language-Models": "we consider a set of texts associated with a given class to build"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "the Knowledge-Enriched Transformer\n(KET)\n[23].",
          "B. Pre-trained Transformer Encoder Language-Models": "the class fingerprint and can use the frequency of each word"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "Following\nthe\nemergence\nof Transformers,\nnew encoder",
          "B. Pre-trained Transformer Encoder Language-Models": "in each text\nto build the fingerprint\nfor\nthat class."
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "PLMs\nbased\non\nthis\narchitecture\n(such\nas BERT [2]\nand",
          "B. Pre-trained Transformer Encoder Language-Models": "Fuzzy Fingerprints have been further used and adapted for"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "RoBERTa\n[10]) were\nintroduced\nand\nachieved\nstate-of-the-",
          "B. Pre-trained Transformer Encoder Language-Models": "several\ntasks involving text classification, such as Tweet Topic"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "art\nin various NLP benchmarks. Since their emergence, most",
          "B. Pre-trained Transformer Encoder Language-Models": "Detection [17] or cyberbullying detection in social networks"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "state-of-the-art ERC works resorted to encoder PLMs.",
          "B. Pre-trained Transformer Encoder Language-Models": "[18]."
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "COSMIC [4]\nleverages RoBERTa\nto\nencode\nutterances.",
          "B. Pre-trained Transformer Encoder Language-Models": "1) Fuzzy Fingerprint Creation and Fuzzy Fingerprint Li-"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "Furthermore,\nit makes use of\nthe\ncommonsense\ntransformer",
          "B. Pre-trained Transformer Encoder Language-Models": "braries: The training set\nis processed to compute the top-K"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "model COMET [1], a large knowledge base,\nin order\nto ex-",
          "B. Pre-trained Transformer Encoder Language-Models": "feature list for each class. Consider Fj as the set of events of"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "tract commonsense features. Five bi-directional GRUs model",
          "B. Pre-trained Transformer Encoder Language-Models": "class j\n(simplistic example:\nthe set of all words for all\ntexts"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "several aspects of the conversation in the classification module.",
          "B. Pre-trained Transformer Encoder Language-Models": "belonging to class j). The result consists of a list of K pairs"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "Psychological\n[8] also uses RoBERTa for utterance encoding",
          "B. Pre-trained Transformer Encoder Language-Models": "is the i-th most frequent feature\n{vi, ni}, 1 < i ≤ K, where vi"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "and the large external knowledge base COMET. It introduces a",
          "B. Pre-trained Transformer Encoder Language-Models": "the\ncorresponding\ncount. The\nnext\nstep\nconsists\nin\nand ni"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "graph of utterances for conversation-level encoding that needs",
          "B. Pre-trained Transformer Encoder Language-Models": "fuzzifying each top-K list: a membership value is assigned to"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "to be processed with a graph transformer.",
          "B. Pre-trained Transformer Encoder Language-Models": "each feature in the set based on the order in the list (the rank)."
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "Contrarily to the\naforementioned approaches, we produce",
          "B. Pre-trained Transformer Encoder Language-Models": "The more\nfrequent\nfeatures will have\na higher membership"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "RoBERTa\ncontext-dependent\nembedding\nrepresentations\nof",
          "B. Pre-trained Transformer Encoder Language-Models": "value. The FFP (Φ), consists of a size-K fuzzy vector where"
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "each utterance, discarding the need for\nsuch complex clas-",
          "B. Pre-trained Transformer Encoder Language-Models": "each position i contains element vi and a membership value µi."
        },
        {
          "explaining the obtained outcomes\nfrom these models\nis\nstill": "sification modules.",
          "B. Pre-trained Transformer Encoder Language-Models": "A class j will be represented by its fingerprint Φj = Φ(Fj)."
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "length kj, with Sj = {vji\n| i = 1 . . . kj} representing the set",
          "C. Fuzzy Fingerprinting RoBERTa": ""
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "",
          "C. Fuzzy Fingerprinting RoBERTa": "Fuzzy Fingerprints\nare\nbased\non\nthe\nconcept\nof\nfeature"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "of v’s\nin Φj. The set of all class fingerprints will constitute",
          "C. Fuzzy Fingerprinting RoBERTa": ""
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "",
          "C. Fuzzy Fingerprinting RoBERTa": "frequencies (section II-C1).\nIn order\nto fingerprint RoBERTa,"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "the fingerprint\nlibrary.",
          "C. Fuzzy Fingerprinting RoBERTa": ""
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "",
          "C. Fuzzy Fingerprinting RoBERTa": "we must find a way to adapt\nthis concept\nto the RoBERTa’s"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "2) Fuzzy Fingerprint Detection:\nIn order\nto find the class",
          "C. Fuzzy Fingerprinting RoBERTa": ""
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "",
          "C. Fuzzy Fingerprinting RoBERTa": "output, i.e., to the final hidden state of the [CLS] classification"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "of an unknown instance,\nfor example, a text T , we start by",
          "C. Fuzzy Fingerprinting RoBERTa": ""
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "",
          "C. Fuzzy Fingerprinting RoBERTa": "token, which\nis\na\nreal-valued\nvector\n(with\ndimension\n768)"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "computing the size-K fingerprint of T , ΦT . Then we compare",
          "C. Fuzzy Fingerprinting RoBERTa": ""
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "",
          "C. Fuzzy Fingerprinting RoBERTa": "where each element does not have a known meaning."
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "of\nall\nclasses\nthe fingerprint of T with the fingerprints Φj",
          "C. Fuzzy Fingerprinting RoBERTa": ""
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "",
          "C. Fuzzy Fingerprinting RoBERTa": "A solution to address\nthis\nissue,\nis\nto use the intensity of"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "present in the fingerprint library. The unknown text is classified",
          "C. Fuzzy Fingerprinting RoBERTa": ""
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "",
          "C. Fuzzy Fingerprinting RoBERTa": "the activation of each element\nfrom the RoBERTa’s output as"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "j\nas\nif\nit has\nthe most\nsimilar fingerprint\nto Φj. Fingerprint",
          "C. Fuzzy Fingerprinting RoBERTa": ""
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "",
          "C. Fuzzy Fingerprinting RoBERTa": "a proxy for\nfeature frequency."
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "is calculated using\nsimilarity, sim(ΦT , Φj),",
          "C. Fuzzy Fingerprinting RoBERTa": ""
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "",
          "C. Fuzzy Fingerprinting RoBERTa": "Unlike\ntraditional FFP, where\nthe\nsize of\nthe universe of"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "",
          "C. Fuzzy Fingerprinting RoBERTa": "discourse is finite but unknown (e.g. the number of all existing"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "min(µv(ΦT ), µv(Φj))\n(cid:88)",
          "C. Fuzzy Fingerprinting RoBERTa": ""
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": ",\n(1)\nsim(ΦT , Φj) =",
          "C. Fuzzy Fingerprinting RoBERTa": ""
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "",
          "C. Fuzzy Fingerprinting RoBERTa": "words), here the fingerprint\nsize is\nlimited to 768. Hence it"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "N",
          "C. Fuzzy Fingerprinting RoBERTa": ""
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "v∈ST ∪Sj",
          "C. Fuzzy Fingerprinting RoBERTa": ""
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "",
          "C. Fuzzy Fingerprinting RoBERTa": "is\npossible\nto\ndefine\na RoBERTa FFP as\na\ndiscrete Fuzzy"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "",
          "C. Fuzzy Fingerprinting RoBERTa": "Set\n(in the discrete universe of\nthe RoBERTa outputs), where"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "is\nthe membership value\nassociated with the\nwhere µv(Φx)",
          "C. Fuzzy Fingerprinting RoBERTa": ""
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "",
          "C. Fuzzy Fingerprinting RoBERTa": "each of\nthe 768 outputs has an associated membership value"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "rank of element v in fingerprint x. This function is based on",
          "C. Fuzzy Fingerprinting RoBERTa": ""
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "",
          "C. Fuzzy Fingerprinting RoBERTa": "that\nis computed based on its activation rank. Only the top-"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "the fuzzy AND (here we use the minimum or G¯odel\nt-norm).",
          "C. Fuzzy Fingerprinting RoBERTa": ""
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "",
          "C. Fuzzy Fingerprinting RoBERTa": "K elements have\na membership greater\nthan zero,\nand for"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "N is a constant\nthat can be used for normalization purposes.",
          "C. Fuzzy Fingerprinting RoBERTa": ""
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "",
          "C. Fuzzy Fingerprinting RoBERTa": "practical\npurposes,\nthe\nset\nis\nordered\nby\nthe membership"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "III. FUZZY FINGERPRINTING ROBERTA FOR ERC",
          "C. Fuzzy Fingerprinting RoBERTa": "function of\nits elements."
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "",
          "C. Fuzzy Fingerprinting RoBERTa": "The process to create the fingerprint of a specific emotion"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "A. Task Definition",
          "C. Fuzzy Fingerprinting RoBERTa": ""
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "",
          "C. Fuzzy Fingerprinting RoBERTa": "can be therefore succinctly described as “ranking and fuzzi-"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "Given a conversation composed of a sequence of ui utter-",
          "C. Fuzzy Fingerprinting RoBERTa": "fying the\nactivation of\nthe RoBERTa’s outputs\nthrough the"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "from a predefined set of\nances with corresponding emotioni",
          "C. Fuzzy Fingerprinting RoBERTa": "training set\n(of\nthat emotion)”. The procedure is described as"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "emotions,\nthe aim of ERC is to correctly assign an emotion to",
          "C. Fuzzy Fingerprinting RoBERTa": "follows:"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "each utterance of\nthe conversation. An utterance consists of a",
          "C. Fuzzy Fingerprinting RoBERTa": ""
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "",
          "C. Fuzzy Fingerprinting RoBERTa": "1) The training data is used to create fuzzy fingerprints for"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "sequence of wit\ntokens representing its Ti words:",
          "C. Fuzzy Fingerprinting RoBERTa": ""
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "",
          "C. Fuzzy Fingerprinting RoBERTa": "each emotion (class)."
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "",
          "C. Fuzzy Fingerprinting RoBERTa": "2) The fingerprint\nfor each emotion begins as a 2D vector"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "(2)\nui = (wi1, wi2, ..., wiTi).",
          "C. Fuzzy Fingerprinting RoBERTa": ""
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "",
          "C. Fuzzy Fingerprinting RoBERTa": "of size 768, where each position contains an index and"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "",
          "C. Fuzzy Fingerprinting RoBERTa": "a value initialized to 0."
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "B. Context-Dependent Embedding Utterance Representations",
          "C. Fuzzy Fingerprinting RoBERTa": ""
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "",
          "C. Fuzzy Fingerprinting RoBERTa": "3) The fine-tuned context-based RoBERTa is\nfed with all"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "The most common approach for ERC has been to produce",
          "C. Fuzzy Fingerprinting RoBERTa": "the training examples of a given emotion (one by one)."
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "context-independent\nrepresentations of each utterance (using",
          "C. Fuzzy Fingerprinting RoBERTa": "4) The RoBERTa output\nfor\neach example\nconsists of\na"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "PLMs), and subsequently perform contextual modeling of the",
          "C. Fuzzy Fingerprinting RoBERTa": "768-sized vector of real values. The real-valued outputs"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "obtained representations with classification modules compris-",
          "C. Fuzzy Fingerprinting RoBERTa": "are added to the fingerprint. Hence, after all\nthe training"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "ing gated and graph neural networks.\nIn a recent work [13],",
          "C. Fuzzy Fingerprinting RoBERTa": "examples\n(of a given emotion) are fed into RoBERTa,"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "we proposed to produce context-dependent\nrepresentations of",
          "C. Fuzzy Fingerprinting RoBERTa": "the fingerprint of the emotion consists of the 2D vector,"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "each utterance that\nrepresent not only the utterance but also",
          "C. Fuzzy Fingerprinting RoBERTa": "where each position contains an index and the accumu-"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "a given number of previous utterances from the conversation.",
          "C. Fuzzy Fingerprinting RoBERTa": "lated value of the RoBERTa output for all\nthe examples."
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "This context-based approach allowed us\nto discard the need",
          "C. Fuzzy Fingerprinting RoBERTa": "5) Order\nthe fingerprint vector by the accumulated value"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "for complex classification modules: a single fully connected",
          "C. Fuzzy Fingerprinting RoBERTa": "(in descending order)."
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "linear softmax layer appended to this variation of RoBERTa,",
          "C. Fuzzy Fingerprinting RoBERTa": "6) Reduce the 2D vector to a single dimension by discard-"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "is enough to achieve state-of-the-art\nlevel performance.",
          "C. Fuzzy Fingerprinting RoBERTa": "ing the column containing the accumulated values (only"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "When pooling the embeddings, we chose the first embed-",
          "C. Fuzzy Fingerprinting RoBERTa": "the rank matters). As a result, we have, for each emotion,"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "ding from the last\nlayer L,\nthe [CLS] token which is used",
          "C. Fuzzy Fingerprinting RoBERTa": "a vector of dimension 768, containing the indexes of the"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "for classification, as in Equation 3.",
          "C. Fuzzy Fingerprinting RoBERTa": "mostly activated RoBERTa outputs for that emotion, i.e.,"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "",
          "C. Fuzzy Fingerprinting RoBERTa": "the RoBERTa outputs are ranked by activation on the"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "(3)\npooledi = RoBERT aL,[CLS](inputi).",
          "C. Fuzzy Fingerprinting RoBERTa": ""
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "",
          "C. Fuzzy Fingerprinting RoBERTa": "training set."
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "",
          "C. Fuzzy Fingerprinting RoBERTa": "7) The fingerprint will only use the top-K RoBERTa out-"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "This\nembedding\nis\nthen\nfed\nto\na\nfully\nconnected\nlinear",
          "C. Fuzzy Fingerprinting RoBERTa": ""
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "",
          "C. Fuzzy Fingerprinting RoBERTa": "puts for classification purposes (instead of the whole 768"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "layer with softmax so that\nthe complete model maximizes the",
          "C. Fuzzy Fingerprinting RoBERTa": ""
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "",
          "C. Fuzzy Fingerprinting RoBERTa": "RoBERTa outputs). K is selected on the validation set."
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "probability of\nthe correct\nlabels.",
          "C. Fuzzy Fingerprinting RoBERTa": ""
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "",
          "C. Fuzzy Fingerprinting RoBERTa": "8) The\nFFP\nis\nobtained\nby\nfuzzifying\nthe\ntop-K sized"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "For\nthis work, we use\nthe\nfully connected layer\nto fine-",
          "C. Fuzzy Fingerprinting RoBERTa": ""
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "",
          "C. Fuzzy Fingerprinting RoBERTa": "vector according to the following function:"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "tune RoBERTa, but discard and replace\nit\nafterward with a",
          "C. Fuzzy Fingerprinting RoBERTa": ""
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "Fuzzy Fingerprint classification module, as detailed in the next",
          "C. Fuzzy Fingerprinting RoBERTa": ""
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "",
          "C. Fuzzy Fingerprinting RoBERTa": "a × i"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "section and represented in Figure 1.",
          "C. Fuzzy Fingerprinting RoBERTa": ", ∀a ∈ [0, 1]\n(4)\nµi = 1 −"
        },
        {
          "|\nFormally, a fingerprint Φj = {(vji, µji)\ni = 1 . . . kj} has": "",
          "C. Fuzzy Fingerprinting RoBERTa": "K"
        }
      ],
      "page": 3
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "in which i\nis\nthe\nindex of\nthe\nelement\nin the\nsorted": "vector, K,\nis the fingerprint size, and a adjusts the slope",
          "C. Dataset": ""
        },
        {
          "in which i\nis\nthe\nindex of\nthe\nelement\nin the\nsorted": "",
          "C. Dataset": "DailyDialog"
        },
        {
          "in which i\nis\nthe\nindex of\nthe\nelement\nin the\nsorted": "of\nthe function. The function gives higher-ranked items",
          "C. Dataset": ""
        },
        {
          "in which i\nis\nthe\nindex of\nthe\nelement\nin the\nsorted": "",
          "C. Dataset": "English\ndialogue"
        },
        {
          "in which i\nis\nthe\nindex of\nthe\nelement\nin the\nsorted": "a larger membership. Other\nfunctions were tested on a",
          "C. Dataset": ""
        },
        {
          "in which i\nis\nthe\nindex of\nthe\nelement\nin the\nsorted": "",
          "C. Dataset": "statistics.\nIt\nis"
        },
        {
          "in which i\nis\nthe\nindex of\nthe\nelement\nin the\nsorted": "validation set. This is the function that provided the best",
          "C. Dataset": ""
        },
        {
          "in which i\nis\nthe\nindex of\nthe\nelement\nin the\nsorted": "",
          "C. Dataset": "[3],\nanger, disgust,"
        },
        {
          "in which i\nis\nthe\nindex of\nthe\nelement\nin the\nsorted": "score.",
          "C. Dataset": ""
        },
        {
          "in which i\nis\nthe\nindex of\nthe\nelement\nin the\nsorted": "",
          "C. Dataset": ""
        },
        {
          "in which i\nis\nthe\nindex of\nthe\nelement\nin the\nsorted": "After obtaining the fingerprints\nfor\nall possible\nemotions",
          "C. Dataset": ""
        },
        {
          "in which i\nis\nthe\nindex of\nthe\nelement\nin the\nsorted": "(the\nFingerprint Library),\nclassification\ncan\nbe\nperformed.",
          "C. Dataset": ""
        },
        {
          "in which i\nis\nthe\nindex of\nthe\nelement\nin the\nsorted": "",
          "C. Dataset": ""
        },
        {
          "in which i\nis\nthe\nindex of\nthe\nelement\nin the\nsorted": "Given a sequence of ui utterances to be classified:",
          "C. Dataset": ""
        },
        {
          "in which i\nis\nthe\nindex of\nthe\nelement\nin the\nsorted": "",
          "C. Dataset": ""
        },
        {
          "in which i\nis\nthe\nindex of\nthe\nelement\nin the\nsorted": "1)\nthrough RoBERTa.\nPass ui",
          "C. Dataset": ""
        },
        {
          "in which i\nis\nthe\nindex of\nthe\nelement\nin the\nsorted": "",
          "C. Dataset": ""
        },
        {
          "in which i\nis\nthe\nindex of\nthe\nelement\nin the\nsorted": "2) Create the fingerprint of ui using the same procedure",
          "C. Dataset": ""
        },
        {
          "in which i\nis\nthe\nindex of\nthe\nelement\nin the\nsorted": "",
          "C. Dataset": ""
        },
        {
          "in which i\nis\nthe\nindex of\nthe\nelement\nin the\nsorted": "used to create the fingerprint of an emotion (i.e. rank the",
          "C. Dataset": ""
        },
        {
          "in which i\nis\nthe\nindex of\nthe\nelement\nin the\nsorted": "",
          "C. Dataset": ""
        },
        {
          "in which i\nis\nthe\nindex of\nthe\nelement\nin the\nsorted": "activation of the output vector, select the Top-K elements",
          "C. Dataset": ""
        },
        {
          "in which i\nis\nthe\nindex of\nthe\nelement\nin the\nsorted": "and fuzzify the resulting vector).",
          "C. Dataset": ""
        },
        {
          "in which i\nis\nthe\nindex of\nthe\nelement\nin the\nsorted": "3) Check the similarity of\nthe\nthe fingerprint of ui against",
          "C. Dataset": ""
        },
        {
          "in which i\nis\nthe\nindex of\nthe\nelement\nin the\nsorted": "",
          "C. Dataset": ""
        },
        {
          "in which i\nis\nthe\nindex of\nthe\nelement\nin the\nsorted": "fingerprint of each emotion using the Fuzzy Fingerprint",
          "C. Dataset": ""
        },
        {
          "in which i\nis\nthe\nindex of\nthe\nelement\nin the\nsorted": "similarity\nfunction\nfrom Equation\n1,\nand\nselect\nthe",
          "C. Dataset": "Ang\nDisg"
        },
        {
          "in which i\nis\nthe\nindex of\nthe\nelement\nin the\nsorted": "emotion with the highest similarity.",
          "C. Dataset": "1.0%\n0.3%"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "compare our approach to current state-of-the-art models.": ""
        },
        {
          "compare our approach to current state-of-the-art models.": "A. Fuzzy Fingerprint Size - K"
        },
        {
          "compare our approach to current state-of-the-art models.": ""
        },
        {
          "compare our approach to current state-of-the-art models.": ""
        },
        {
          "compare our approach to current state-of-the-art models.": ""
        },
        {
          "compare our approach to current state-of-the-art models.": "50"
        },
        {
          "compare our approach to current state-of-the-art models.": ""
        },
        {
          "compare our approach to current state-of-the-art models.": ""
        },
        {
          "compare our approach to current state-of-the-art models.": ""
        },
        {
          "compare our approach to current state-of-the-art models.": "40"
        },
        {
          "compare our approach to current state-of-the-art models.": ""
        },
        {
          "compare our approach to current state-of-the-art models.": "F1"
        },
        {
          "compare our approach to current state-of-the-art models.": ""
        },
        {
          "compare our approach to current state-of-the-art models.": "30"
        },
        {
          "compare our approach to current state-of-the-art models.": ""
        },
        {
          "compare our approach to current state-of-the-art models.": ""
        },
        {
          "compare our approach to current state-of-the-art models.": ""
        },
        {
          "compare our approach to current state-of-the-art models.": "20"
        },
        {
          "compare our approach to current state-of-the-art models.": ""
        },
        {
          "compare our approach to current state-of-the-art models.": ""
        },
        {
          "compare our approach to current state-of-the-art models.": ""
        },
        {
          "compare our approach to current state-of-the-art models.": ""
        },
        {
          "compare our approach to current state-of-the-art models.": "10"
        },
        {
          "compare our approach to current state-of-the-art models.": ""
        },
        {
          "compare our approach to current state-of-the-art models.": ""
        },
        {
          "compare our approach to current state-of-the-art models.": ""
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "TABLE III": "VARIATION OF THE F1-SCORE WITH THE FINGERPRINT SIZE K",
          "model such as DialogueRNN and COSMIC. The Psychologi-": ""
        },
        {
          "TABLE III": "",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "cal model has a slightly higher performance than ours, but\nit"
        },
        {
          "TABLE III": "K\n1\n5\n10\n25\n50",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "uses RoBERTa Large, needs a heavy commonsense knowledge"
        },
        {
          "TABLE III": "F1\n11.67\n17.22\n20.04\n27.21\n33.78",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "base, COMET [1],\nand\na\ncomplex\ngraph\nof\nutterances\nas"
        },
        {
          "TABLE III": "K\n100\n150\n200\n300\n400",
          "model such as DialogueRNN and COSMIC. The Psychologi-": ""
        },
        {
          "TABLE III": "",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "a\nconversational\nlevel\nencoder\nthat\nneeds\nto\nbe\nprocessed"
        },
        {
          "TABLE III": "F1\n51.89\n47.52\n51.17\n51.34\n51.60",
          "model such as DialogueRNN and COSMIC. The Psychologi-": ""
        },
        {
          "TABLE III": "",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "with\na\ngraph\ntransformer.\nIn\ncomparison,\nour model\nuses"
        },
        {
          "TABLE III": "F1 without\nthe Fingerprints module:\n51.23",
          "model such as DialogueRNN and COSMIC. The Psychologi-": ""
        },
        {
          "TABLE III": "",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "RoBERTa\nbase fine-tuned\nusing\ncontext,\nand\na minimalist"
        },
        {
          "TABLE III": "",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "fuzzy fingerprint classification model."
        },
        {
          "TABLE III": "B. Comparison without\nthe Fuzzy Fingerprint module",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "We have also performed experiments with ChatGPT 3 and"
        },
        {
          "TABLE III": "When using the same RoBERTa representation for the Fuzzy",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "4, with the introduction of a variable number of context\nturns"
        },
        {
          "TABLE III": "Fingerprint module but resorting only to the simple fully con-",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "in the prompt, and observed that both ChatGPT versions do"
        },
        {
          "TABLE III": "nected linear layer as a classification module both for training",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "not\noutperform our\ncontext-dependent\nembedding\nutterance"
        },
        {
          "TABLE III": "and prediction, we obtain an F1-score of 51.23 [13]. Given",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "representation approach [13], which is outperformed by our"
        },
        {
          "TABLE III": "that performance differences from state-of-the-art approaches",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "proposed fuzzy fingerprints approach."
        },
        {
          "TABLE III": "can consist\nin improvements of\nthe magnitude of\nless\nthan",
          "model such as DialogueRNN and COSMIC. The Psychologi-": ""
        },
        {
          "TABLE III": "",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "E. FFP Interpretability/Explainability Examples"
        },
        {
          "TABLE III": "1 F1-score, as\nit can be seen in Table V, our\nimprovement",
          "model such as DialogueRNN and COSMIC. The Psychologi-": ""
        },
        {
          "TABLE III": "of 0.66 in F1-score\nis\nconsidered significant\n(results\nare\nan",
          "model such as DialogueRNN and COSMIC. The Psychologi-": ""
        },
        {
          "TABLE III": "",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "We\nclaim that\nusing\nFFP\ncan\nadd\nsome much-needed"
        },
        {
          "TABLE III": "average of 5 runs to preserve statistical significance).",
          "model such as DialogueRNN and COSMIC. The Psychologi-": ""
        },
        {
          "TABLE III": "",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "interpretability and explainability to PLMs. Here we present"
        },
        {
          "TABLE III": "",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "three examples that help to support our claim. We use small"
        },
        {
          "TABLE III": "C. Performance on each emotion label",
          "model such as DialogueRNN and COSMIC. The Psychologi-": ""
        },
        {
          "TABLE III": "",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "fingerprints\nfor\nvisualization\nand\nexemplification\npurposes."
        },
        {
          "TABLE III": "We\nreport\nthe F1-score on each individual\nemotion label",
          "model such as DialogueRNN and COSMIC. The Psychologi-": ""
        },
        {
          "TABLE III": "",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "Table VI presents the generated Emotion FFP for K=10."
        },
        {
          "TABLE III": "with the best value for K=300 in Table IV (5 runs average).",
          "model such as DialogueRNN and COSMIC. The Psychologi-": ""
        },
        {
          "TABLE III": "",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "The first noticeable aspect\nis how output 588 is present at"
        },
        {
          "TABLE III": "",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "the\ntop\nof\n5\nout\nof\nthe\n7\nclasses. This\ncan\nbe\npotentially"
        },
        {
          "TABLE III": "TABLE IV",
          "model such as DialogueRNN and COSMIC. The Psychologi-": ""
        },
        {
          "TABLE III": "MODEL PERFORMANCE ON EACH INDIVIDUAL EMOTION LABEL",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "leveraged to\nimprove ERC performance using\na multistage"
        },
        {
          "TABLE III": "",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "classifier, since 588 is not present\nin the Neutral FFP, which"
        },
        {
          "TABLE III": "Ang\nDisg\nFear\nHap\nSad\nSur\nNeu",
          "model such as DialogueRNN and COSMIC. The Psychologi-": ""
        },
        {
          "TABLE III": "",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "is the majority class and where most misclassifications end up."
        },
        {
          "TABLE III": "F1\n43.22\n32.89\n42.12\n61.38\n39.45\n52.89\n91.30",
          "model such as DialogueRNN and COSMIC. The Psychologi-": ""
        },
        {
          "TABLE III": "",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "In Table VII\nthree\nexamples\nof\nutterance\nand\nclass fin-"
        },
        {
          "TABLE III": "",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "gerprints,\nand\nthe\nrespective\nsimilarity\nresults\n(considering"
        },
        {
          "TABLE III": "From Table IV it can be observed that the classifier performs",
          "model such as DialogueRNN and COSMIC. The Psychologi-": ""
        },
        {
          "TABLE III": "",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "N = 1), are presented."
        },
        {
          "TABLE III": "better at\nthe most represented classes in the dataset, having an",
          "model such as DialogueRNN and COSMIC. The Psychologi-": ""
        },
        {
          "TABLE III": "",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "The first example shows\nthat\nthere are many elements\nin"
        },
        {
          "TABLE III": "F1 score of above 60 for the well-represented class Happiness",
          "model such as DialogueRNN and COSMIC. The Psychologi-": ""
        },
        {
          "TABLE III": "",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "common between the utterance and the class FFP and there is"
        },
        {
          "TABLE III": "and\nan\neven\nhigher\nF1\nscore\nof\naround\n90\nfor\nthe\nover-",
          "model such as DialogueRNN and COSMIC. The Psychologi-": ""
        },
        {
          "TABLE III": "",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "no doubt\nthat we have a correct classification."
        },
        {
          "TABLE III": "represented Neutral class.",
          "model such as DialogueRNN and COSMIC. The Psychologi-": ""
        },
        {
          "TABLE III": "",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "The\nsecond and third examples\nshow an interesting case"
        },
        {
          "TABLE III": "D. Comparison with state-of-the-art",
          "model such as DialogueRNN and COSMIC. The Psychologi-": ""
        },
        {
          "TABLE III": "",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "of\nan incorrect\nclassification and how the FFP can explain"
        },
        {
          "TABLE III": "We\ncompare our\napproach to other\nstate-of-the-art works",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "such\nerror. The\nFFP\nof\nthe\nutterance\n”You\nstill\nhave\nnot"
        },
        {
          "TABLE III": "that also resort to RoBERTa. This allows for a fair comparison",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "given me those files\nI’ve asked you for” clearly indicates a"
        },
        {
          "TABLE III": "between approaches given that using this PLM brings great",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "strong similarity to the Angry emotion, with many important"
        },
        {
          "TABLE III": "performance increases when compared to using other means",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "features\nin common between the fingerprints. Yet, according"
        },
        {
          "TABLE III": "of utterance feature extraction.",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "to\nthe\ndataset\nannotation,\nthe\nutterance\nis\nsupposed\nto\nbe"
        },
        {
          "TABLE III": "We\ncompare\nour\napproach\nto COSMIC [4], RoBERTa",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "Neutral. This misclassification\ncannot\nbe\nexplained\nby\nthe"
        },
        {
          "TABLE III": "and RoBERTa DialogueRNN,\nimplemented\nby\nthe\nauthors",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "FFP, however,\nit could certainly be argued by a native English"
        },
        {
          "TABLE III": "of COSMIC,\nand\nthe Psychological model\n[8],\nall models",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "speaker that the utterance has a definite negative meaning. Due"
        },
        {
          "TABLE III": "described in Section II. Results are displayed in table V and",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "to the negative meaning,\nthe most present emotion is probably"
        },
        {
          "TABLE III": "are an average of 5 runs.",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "more Anger than Neutral, revealing either an annotation error"
        },
        {
          "TABLE III": "",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "or\nsome\nhidden\nknowledge\nfrom the\nannotator\nthat\ncannot"
        },
        {
          "TABLE III": "TABLE V",
          "model such as DialogueRNN and COSMIC. The Psychologi-": ""
        },
        {
          "TABLE III": "",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "be\nextracted from the utterance. A more polite\nand neutral"
        },
        {
          "TABLE III": "COMPARISON WITH STATE-OF-THE-ART WORKS",
          "model such as DialogueRNN and COSMIC. The Psychologi-": ""
        },
        {
          "TABLE III": "",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "way of expressing the same message would be,\nfor example,"
        },
        {
          "TABLE III": "macro-F1",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "”Don’t\nforget\nto give me\nthe files\nI’ve\nasked you for”\n(the"
        },
        {
          "TABLE III": "RoBERTa [4]\n48.20",
          "model such as DialogueRNN and COSMIC. The Psychologi-": ""
        },
        {
          "TABLE III": "",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "third example on the table). Here we see that\nthe FFP clearly"
        },
        {
          "TABLE III": "RoBERTa + DialogueRNN [4]\n49.65",
          "model such as DialogueRNN and COSMIC. The Psychologi-": ""
        },
        {
          "TABLE III": "",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "indicates\na Neutral\nemotion despite\nthe\nsentence\nexpressing"
        },
        {
          "TABLE III": "COSMIC [4]\n51.05",
          "model such as DialogueRNN and COSMIC. The Psychologi-": ""
        },
        {
          "TABLE III": "Contextual RoBERTa [13]\n51.23",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "the same message, albeit with a different\ntone."
        },
        {
          "TABLE III": "51.95\nPsychological\n[8]",
          "model such as DialogueRNN and COSMIC. The Psychologi-": ""
        },
        {
          "TABLE III": "Contextual RoBERTa + FFP\n51.89",
          "model such as DialogueRNN and COSMIC. The Psychologi-": ""
        },
        {
          "TABLE III": "",
          "model such as DialogueRNN and COSMIC. The Psychologi-": "VI. CONCLUSION AND FUTURE WORK"
        }
      ],
      "page": 5
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "F F PN eu =": "F F PAng =",
          "{(217,1),": "{(8,1),",
          "(644,0.9),": "(679,0.9),",
          "(541,0.8),": "(204,0.8),",
          "(718,0.7),": "(292,0.7),",
          "(401,0.6),": "(651,0.6),",
          "(330,0.5),": "(573,0.5),",
          "(426,0.4),": "(111,0.4),",
          "(78,0.3),": "(624,0.3),",
          "(580,0.2),": "(184,0.2),",
          "(114,0.1)}": "(309,0.1)}"
        },
        {
          "F F PN eu =": "F F PDis =",
          "{(217,1),": "{(588,1),",
          "(644,0.9),": "(573,0.9),",
          "(541,0.8),": "(27,0.8),",
          "(718,0.7),": "(154,0.7),",
          "(401,0.6),": "(331,0.6),",
          "(330,0.5),": "(67,0.5),",
          "(426,0.4),": "(561,0.4),",
          "(78,0.3),": "(5,0.3),",
          "(580,0.2),": "(503,0.2),",
          "(114,0.1)}": "(446,0.1)}"
        },
        {
          "F F PN eu =": "F F PF ear =",
          "{(217,1),": "{(588,1),",
          "(644,0.9),": "(313,0.9),",
          "(541,0.8),": "(655,0.8),",
          "(718,0.7),": "(406,0.7),",
          "(401,0.6),": "(736,0.6),",
          "(330,0.5),": "(349,0.5),",
          "(426,0.4),": "(624,0.4),",
          "(78,0.3),": "(371,0.3),",
          "(580,0.2),": "(292,0.2),",
          "(114,0.1)}": "(8,0.1)}"
        },
        {
          "F F PN eu =": "F F PHap =",
          "{(217,1),": "{(588,1),",
          "(644,0.9),": "(585,0.9),",
          "(541,0.8),": "(388,0.8),",
          "(718,0.7),": "(600,0.7),",
          "(401,0.6),": "(767,0.6),",
          "(330,0.5),": "(319,0.5),",
          "(426,0.4),": "(741,0.4),",
          "(78,0.3),": "(561,0.3),",
          "(580,0.2),": "(473,0.2),",
          "(114,0.1)}": "(139,0.1)}"
        },
        {
          "F F PN eu =": "F F PSad =",
          "{(217,1),": "{(371,1),",
          "(644,0.9),": "(588,0.9),",
          "(541,0.8),": "(5,0.8),",
          "(718,0.7),": "(156,0.7),",
          "(401,0.6),": "(4,0.6),",
          "(330,0.5),": "(93,0.5),",
          "(426,0.4),": "(550,0.4),",
          "(78,0.3),": "(402,0.3),",
          "(580,0.2),": "(519,0.2),",
          "(114,0.1)}": "(422,0.1)}"
        },
        {
          "F F PN eu =": "F F PSur =",
          "{(217,1),": "{(691,1),",
          "(644,0.9),": "(588,0.9),",
          "(541,0.8),": "(97,0.8),",
          "(718,0.7),": "(573,0.7),",
          "(401,0.6),": "(530,0.6),",
          "(330,0.5),": "(535,0.5),",
          "(426,0.4),": "(654,0.4),",
          "(78,0.3),": "(384,0.3),",
          "(580,0.2),": "(366,0.2),",
          "(114,0.1)}": "(613,0.1)}"
        },
        {
          "F F PN eu =": "",
          "{(217,1),": "",
          "(644,0.9),": "",
          "(541,0.8),": "",
          "(718,0.7),": "",
          "(401,0.6),": "TABLE VI",
          "(330,0.5),": "",
          "(426,0.4),": "",
          "(78,0.3),": "",
          "(580,0.2),": "",
          "(114,0.1)}": ""
        }
      ],
      "page": 6
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "F F PSur =": "",
          "{(691,1),": "",
          "(588,0.9),": "",
          "(97,0.8),": "",
          "(573,0.7),\n(530,0.6),\n(535,0.5),\n(654,0.4),\n(384,0.3),\n(366,0.2),\n(613,0.1)}": "TABLE VI"
        },
        {
          "F F PSur =": "",
          "{(691,1),": "",
          "(588,0.9),": "",
          "(97,0.8),": "",
          "(573,0.7),\n(530,0.6),\n(535,0.5),\n(654,0.4),\n(384,0.3),\n(366,0.2),\n(613,0.1)}": "CLASS FINGERPRINTS (K=10)"
        },
        {
          "F F PSur =": "Text:",
          "{(691,1),": "Sorry , sir",
          "(588,0.9),": "It’s the sale price .",
          "(97,0.8),": "",
          "(573,0.7),\n(530,0.6),\n(535,0.5),\n(654,0.4),\n(384,0.3),\n(366,0.2),\n(613,0.1)}": ""
        },
        {
          "F F PSur =": "F F PSample =",
          "{(691,1),": "{(5,1),",
          "(588,0.9),": "(371,0.9),",
          "(97,0.8),": "(156,0.8),",
          "(573,0.7),\n(530,0.6),\n(535,0.5),\n(654,0.4),\n(384,0.3),\n(366,0.2),\n(613,0.1)}": "(550,0.7),\n(93,0.6),\n(4,0.5),\n(232,0.4),\n(424,0.3),\n(402,0.2),\n(442,0.1)}"
        },
        {
          "F F PSur =": "Class Similarity:",
          "{(691,1),": "N eu = 0",
          "(588,0.9),": "Ang = 0",
          "(97,0.8),": "Dis = 0.3",
          "(573,0.7),\n(530,0.6),\n(535,0.5),\n(654,0.4),\n(384,0.3),\n(366,0.2),\n(613,0.1)}": "F ear\nHap = 0\nSur = 0\nSad = 1.3"
        },
        {
          "F F PSur =": "Text:",
          "{(691,1),": "",
          "(588,0.9),": "",
          "(97,0.8),": "",
          "(573,0.7),\n(530,0.6),\n(535,0.5),\n(654,0.4),\n(384,0.3),\n(366,0.2),\n(613,0.1)}": "’ Ve asked you for\n."
        },
        {
          "F F PSur =": "F F PSample =",
          "{(691,1),": "{(8,1),",
          "(588,0.9),": "(679,0.9),",
          "(97,0.8),": "(309,0.8),",
          "(573,0.7),\n(530,0.6),\n(535,0.5),\n(654,0.4),\n(384,0.3),\n(366,0.2),\n(613,0.1)}": "(624,0.7),\n(292,0.6),\n(76,0.5),\n(134,0.4),\n(204,0.3),\n(560,0.2),\n(459,0.1)}"
        },
        {
          "F F PSur =": "Class Similarity:",
          "{(691,1),": "N eu = 0",
          "(588,0.9),": "Ang = 1",
          "(97,0.8),": "Dis = 0",
          "(573,0.7),\n(530,0.6),\n(535,0.5),\n(654,0.4),\n(384,0.3),\n(366,0.2),\n(613,0.1)}": "F ear = 0.1\nHap = 0\nSad = 0\nSur = 0"
        },
        {
          "F F PSur =": "Text:",
          "{(691,1),": "Don’t",
          "(588,0.9),": "",
          "(97,0.8),": "to give me the files I’ve asked you for",
          "(573,0.7),\n(530,0.6),\n(535,0.5),\n(654,0.4),\n(384,0.3),\n(366,0.2),\n(613,0.1)}": ""
        },
        {
          "F F PSur =": "F F PSample =",
          "{(691,1),": "{(330,1),",
          "(588,0.9),": "(644,0.9),",
          "(97,0.8),": "(541,0.8),",
          "(573,0.7),\n(530,0.6),\n(535,0.5),\n(654,0.4),\n(384,0.3),\n(366,0.2),\n(613,0.1)}": "(217,0.7),\n(114,0.6),\n(426,0.5),\n(211,0.4),\n(718,0.3),\n(401,0.2),\n(553,0.1)}"
        },
        {
          "F F PSur =": "Class Similarity:",
          "{(691,1),": "N eu = 1.4",
          "(588,0.9),": "Ang = 0",
          "(97,0.8),": "Dis = 0",
          "(573,0.7),\n(530,0.6),\n(535,0.5),\n(654,0.4),\n(384,0.3),\n(366,0.2),\n(613,0.1)}": "F ear = 0\nHap = 0\nSad = 0\nSur = 0"
        },
        {
          "F F PSur =": "",
          "{(691,1),": "",
          "(588,0.9),": "",
          "(97,0.8),": "",
          "(573,0.7),\n(530,0.6),\n(535,0.5),\n(654,0.4),\n(384,0.3),\n(366,0.2),\n(613,0.1)}": "TABLE VII"
        }
      ],
      "page": 6
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "CLASSIFICATION EXAMPLES (K=10)": "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-"
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "cea, Alexander Gelbukh, and Erik Cambria. Dialoguernn: An attentive"
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": ""
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "the AAAI\nrnn for emotion detection in conversations.\nIn Proceedings of"
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": ""
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "Conference\non Artificial\nIntelligence,\nvolume\n33,\npages\n6818–6825,"
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "2019."
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "[12]\nPatr´ıcia\nPereira, Helena Moniz,\nand\nJoao\nPaulo Carvalho.\nDeep"
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": ""
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "arXiv preprint\nemotion recognition in textual conversations: A survey."
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": ""
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "arXiv:2211.09172, 2022."
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "[13]\nPatr´ıcia Pereira, Helena Moniz,\nIsabel Dias, and Joao Paulo Carvalho."
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "Context-dependent\nembedding\nutterance\nrepresentations\nfor\nemotion"
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": ""
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "the 13th Workshop on\nrecognition in conversations.\nIn Proceedings of"
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": ""
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "Computational Approaches\nto Subjectivity, Sentiment & Social Media"
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "Analysis. Association for Computational Linguistics, 2023."
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "[14]\nSoujanya\nPoria, Erik Cambria, Devamanyu Hazarika, Navonil Ma-"
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "jumder, Amir Zadeh, and Louis-Philippe Morency. Context-dependent"
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": ""
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "the 55th\nsentiment analysis in user-generated videos.\nIn Proceedings of"
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "annual meeting of\nthe association for computational\nlinguistics (volume"
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "1: Long papers), pages 873–883, 2017."
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "[15]\nSoujanya Poria, Navonil Majumder, Rada Mihalcea, and Eduard Hovy."
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "Emotion recognition in conversation: Research challenges, datasets, and"
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "recent advances.\nIEEE Access, 7:100943–100953, 2019."
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "[16] Rui Ribeiro, Patr´ıcia Pereira, Luisa Coheur, Helena Moniz, and Joao P"
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "Carvalho. Fuzzy fingerprinting large pre-trained models.\nIn Proceedings"
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "of\nthe 13th Conference of\nthe European Society for Fuzzy Logic and"
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "Technology (EUSFLAT 2023). EUSFLAT, 2023."
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "[17] Hugo Rosa, Fernando Batista, and Joao Paulo Carvalho. Twitter\ntopic"
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "fuzzy fingerprints.\nIn 2014 IEEE International Conference on Fuzzy"
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "Systems (FUZZ-IEEE), pages 776–783.\nIEEE, 2014."
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "[18] Hugo Rosa,\nJoao P Carvalho, P´avel Calado, Bruno Martins, Ricardo"
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "Ribeiro, and Luisa Coheur. Using fuzzy fingerprints for cyberbullying"
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "detection in social networks.\nIn 2018 IEEE international conference on"
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "fuzzy systems (FUZZ-IEEE), pages 1–7.\nIEEE, 2018."
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "[19] Weizhou Shen, Junqing Chen, Xiaojun Quan, and Zhixian Xie. Dialogxl:"
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "All-in-one xlnet for multi-party conversation emotion recognition. arXiv"
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "preprint arXiv:2012.08695, 2020."
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "[20] Weizhou Shen, Siyue Wu, Yunyi Yang, and Xiaojun Quan.\nDirected"
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "arXiv\nacyclic graph network for\nconversational\nemotion recognition."
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "preprint arXiv:2105.12907, 2021."
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "[21] Ashish Vaswani, Noam Shazeer, Niki Parmar,\nJakob Uszkoreit, Llion"
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention"
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "is all you need. arXiv preprint arXiv:1706.03762, 2017."
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "[22]\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement"
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "Delangue, Anthony Moi, Pierric Cistac, Tim Rault, R´emi Louf, Morgan"
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "Funtowicz,\net\nal.\nHuggingface’s\ntransformers: State-of-the-art natural"
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "language processing. arXiv preprint arXiv:1910.03771, 2019."
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "[23]\nPeixiang Zhong, Di Wang,\nand Chunyan Miao.\nKnowledge-enriched"
        },
        {
          "CLASSIFICATION EXAMPLES (K=10)": "arXiv\ntransformer\nfor\nemotion\ndetection\nin\ntextual\nconversations."
        }
      ],
      "page": 6
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "we obtained context-dependent embedding utterance represen-": "",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "cea, Alexander Gelbukh, and Erik Cambria. Dialoguernn: An attentive"
        },
        {
          "we obtained context-dependent embedding utterance represen-": "tations\nfrom the RoBERTa PLM that were\nthen\nfed\nto\nan",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": ""
        },
        {
          "we obtained context-dependent embedding utterance represen-": "",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "the AAAI\nrnn for emotion detection in conversations.\nIn Proceedings of"
        },
        {
          "we obtained context-dependent embedding utterance represen-": "adapted FFP classification module. We validated our approach",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": ""
        },
        {
          "we obtained context-dependent embedding utterance represen-": "",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "Conference\non Artificial\nIntelligence,\nvolume\n33,\npages\n6818–6825,"
        },
        {
          "we obtained context-dependent embedding utterance represen-": "on the DailyDialog dataset of ERC, for which our architecture",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "2019."
        },
        {
          "we obtained context-dependent embedding utterance represen-": "",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "[12]\nPatr´ıcia\nPereira, Helena Moniz,\nand\nJoao\nPaulo Carvalho.\nDeep"
        },
        {
          "we obtained context-dependent embedding utterance represen-": "clearly competes with state-of-the-art\nclassifier\narchitectures",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": ""
        },
        {
          "we obtained context-dependent embedding utterance represen-": "",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "arXiv preprint\nemotion recognition in textual conversations: A survey."
        },
        {
          "we obtained context-dependent embedding utterance represen-": "that resort to much more complex classification modules while",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": ""
        },
        {
          "we obtained context-dependent embedding utterance represen-": "",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "arXiv:2211.09172, 2022."
        },
        {
          "we obtained context-dependent embedding utterance represen-": "adding some interpretability and explainability.",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "[13]\nPatr´ıcia Pereira, Helena Moniz,\nIsabel Dias, and Joao Paulo Carvalho."
        },
        {
          "we obtained context-dependent embedding utterance represen-": "",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "Context-dependent\nembedding\nutterance\nrepresentations\nfor\nemotion"
        },
        {
          "we obtained context-dependent embedding utterance represen-": "In future work, we plan to perform a more detailed study",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": ""
        },
        {
          "we obtained context-dependent embedding utterance represen-": "",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "the 13th Workshop on\nrecognition in conversations.\nIn Proceedings of"
        },
        {
          "we obtained context-dependent embedding utterance represen-": "of\nthe interpretability and explainability potential and explore",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": ""
        },
        {
          "we obtained context-dependent embedding utterance represen-": "",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "Computational Approaches\nto Subjectivity, Sentiment & Social Media"
        },
        {
          "we obtained context-dependent embedding utterance represen-": "model size reductions based on Fuzzy Fingerprints.",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "Analysis. Association for Computational Linguistics, 2023."
        },
        {
          "we obtained context-dependent embedding utterance represen-": "",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "[14]\nSoujanya\nPoria, Erik Cambria, Devamanyu Hazarika, Navonil Ma-"
        },
        {
          "we obtained context-dependent embedding utterance represen-": "",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "jumder, Amir Zadeh, and Louis-Philippe Morency. Context-dependent"
        },
        {
          "we obtained context-dependent embedding utterance represen-": "REFERENCES",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": ""
        },
        {
          "we obtained context-dependent embedding utterance represen-": "",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "the 55th\nsentiment analysis in user-generated videos.\nIn Proceedings of"
        },
        {
          "we obtained context-dependent embedding utterance represen-": "[1] Antoine Bosselut, Hannah Rashkin, Maarten Sap, Chaitanya Malaviya,",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "annual meeting of\nthe association for computational\nlinguistics (volume"
        },
        {
          "we obtained context-dependent embedding utterance represen-": "Asli\nCelikyilmaz,\nand Yejin\nChoi.\nComet:\nCommonsense\ntrans-",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "1: Long papers), pages 873–883, 2017."
        },
        {
          "we obtained context-dependent embedding utterance represen-": "arXiv preprint\nformers\nfor\nautomatic knowledge graph construction.",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "[15]\nSoujanya Poria, Navonil Majumder, Rada Mihalcea, and Eduard Hovy."
        },
        {
          "we obtained context-dependent embedding utterance represen-": "arXiv:1906.05317, 2019.",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "Emotion recognition in conversation: Research challenges, datasets, and"
        },
        {
          "we obtained context-dependent embedding utterance represen-": "[2]\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "recent advances.\nIEEE Access, 7:100943–100953, 2019."
        },
        {
          "we obtained context-dependent embedding utterance represen-": "Bert: Pre-training of deep bidirectional\ntransformers\nfor\nlanguage un-",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "[16] Rui Ribeiro, Patr´ıcia Pereira, Luisa Coheur, Helena Moniz, and Joao P"
        },
        {
          "we obtained context-dependent embedding utterance represen-": "derstanding. arXiv preprint arXiv:1810.04805, 2018.",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "Carvalho. Fuzzy fingerprinting large pre-trained models.\nIn Proceedings"
        },
        {
          "we obtained context-dependent embedding utterance represen-": "Handbook of\n[3]\nPaul Ekman.\nBasic\nemotions.\ncognition and emotion,",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "of\nthe 13th Conference of\nthe European Society for Fuzzy Logic and"
        },
        {
          "we obtained context-dependent embedding utterance represen-": "98(45-60):16, 1999.",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "Technology (EUSFLAT 2023). EUSFLAT, 2023."
        },
        {
          "we obtained context-dependent embedding utterance represen-": "[4] Deepanway Ghosal, Navonil Majumder, Alexander Gelbukh, Rada Mi-",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "[17] Hugo Rosa, Fernando Batista, and Joao Paulo Carvalho. Twitter\ntopic"
        },
        {
          "we obtained context-dependent embedding utterance represen-": "halcea, and Soujanya Poria. Cosmic: Commonsense knowledge for emo-",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "fuzzy fingerprints.\nIn 2014 IEEE International Conference on Fuzzy"
        },
        {
          "we obtained context-dependent embedding utterance represen-": "tion identification in conversations.\narXiv preprint arXiv:2010.02795,",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "Systems (FUZZ-IEEE), pages 776–783.\nIEEE, 2014."
        },
        {
          "we obtained context-dependent embedding utterance represen-": "2020.",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "[18] Hugo Rosa,\nJoao P Carvalho, P´avel Calado, Bruno Martins, Ricardo"
        },
        {
          "we obtained context-dependent embedding utterance represen-": "[5]\nIan J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "Ribeiro, and Luisa Coheur. Using fuzzy fingerprints for cyberbullying"
        },
        {
          "we obtained context-dependent embedding utterance represen-": "and harnessing adversarial examples.\narXiv preprint arXiv:1412.6572,",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "detection in social networks.\nIn 2018 IEEE international conference on"
        },
        {
          "we obtained context-dependent embedding utterance represen-": "2014.",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "fuzzy systems (FUZZ-IEEE), pages 1–7.\nIEEE, 2018."
        },
        {
          "we obtained context-dependent embedding utterance represen-": "[6] Nuno Homem and Joao Paulo Carvalho. Authorship identification and",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "[19] Weizhou Shen, Junqing Chen, Xiaojun Quan, and Zhixian Xie. Dialogxl:"
        },
        {
          "we obtained context-dependent embedding utterance represen-": "2011 Annual Meeting\nof\nthe North\nauthor\nfuzzy\n“fingerprints”.\nIn",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "All-in-one xlnet for multi-party conversation emotion recognition. arXiv"
        },
        {
          "we obtained context-dependent embedding utterance represen-": "American Fuzzy Information Processing Society, pages 1–6. IEEE, 2011.",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "preprint arXiv:2012.08695, 2020."
        },
        {
          "we obtained context-dependent embedding utterance represen-": "[7] Nuno Homem and Joao Paulo Carvalho. Web user\nidentification with",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "[20] Weizhou Shen, Siyue Wu, Yunyi Yang, and Xiaojun Quan.\nDirected"
        },
        {
          "we obtained context-dependent embedding utterance represen-": "fuzzy fingerprints.\nIn 2011 IEEE International Conference on Fuzzy",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "arXiv\nacyclic graph network for\nconversational\nemotion recognition."
        },
        {
          "we obtained context-dependent embedding utterance represen-": "Systems (FUZZ-IEEE 2011), pages 2622–2629.\nIEEE, 2011.",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "preprint arXiv:2105.12907, 2021."
        },
        {
          "we obtained context-dependent embedding utterance represen-": "[8]\nJiangnan Li, Zheng Lin, Peng Fu, and Weiping Wang.\nPast, present,",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "[21] Ashish Vaswani, Noam Shazeer, Niki Parmar,\nJakob Uszkoreit, Llion"
        },
        {
          "we obtained context-dependent embedding utterance represen-": "and future: Conversational emotion recognition through structural mod-",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention"
        },
        {
          "we obtained context-dependent embedding utterance represen-": "the Association for\neling of psychological knowledge.\nIn Findings of",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "is all you need. arXiv preprint arXiv:1706.03762, 2017."
        },
        {
          "we obtained context-dependent embedding utterance represen-": "Computational Linguistics: EMNLP 2021, pages 1204–1214, 2021.",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "[22]\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement"
        },
        {
          "we obtained context-dependent embedding utterance represen-": "[9] Yanran Li, Hui Su, Xiaoyu Shen, Wenjie Li, Ziqiang Cao, and Shuzi",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "Delangue, Anthony Moi, Pierric Cistac, Tim Rault, R´emi Louf, Morgan"
        },
        {
          "we obtained context-dependent embedding utterance represen-": "Niu. Dailydialog: A manually labelled multi-turn dialogue dataset. arXiv",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "Funtowicz,\net\nal.\nHuggingface’s\ntransformers: State-of-the-art natural"
        },
        {
          "we obtained context-dependent embedding utterance represen-": "preprint arXiv:1710.03957, 2017.",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "language processing. arXiv preprint arXiv:1910.03771, 2019."
        },
        {
          "we obtained context-dependent embedding utterance represen-": "[10] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "[23]\nPeixiang Zhong, Di Wang,\nand Chunyan Miao.\nKnowledge-enriched"
        },
        {
          "we obtained context-dependent embedding utterance represen-": "Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov.",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "arXiv\ntransformer\nfor\nemotion\ndetection\nin\ntextual\nconversations."
        },
        {
          "we obtained context-dependent embedding utterance represen-": "Roberta: A robustly optimized bert pretraining approach. arXiv preprint",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": "preprint arXiv:1909.10681, 2019."
        },
        {
          "we obtained context-dependent embedding utterance represen-": "arXiv:1907.11692, 2019.",
          "[11] Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihal-": ""
        }
      ],
      "page": 6
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Comet: Commonsense transformers for automatic knowledge graph construction",
      "authors": [
        "Antoine Bosselut",
        "Hannah Rashkin",
        "Maarten Sap",
        "Chaitanya Malaviya",
        "Asli Celikyilmaz",
        "Yejin Choi"
      ],
      "year": "2019",
      "venue": "Comet: Commonsense transformers for automatic knowledge graph construction",
      "arxiv": "arXiv:1906.05317"
    },
    {
      "citation_id": "2",
      "title": "Pre-training of deep bidirectional transformers for language understanding",
      "authors": [
        "Jacob Devlin",
        "Ming-Wei Chang",
        "Kenton Lee",
        "Kristina Toutanova",
        "Bert"
      ],
      "year": "2018",
      "venue": "Pre-training of deep bidirectional transformers for language understanding",
      "arxiv": "arXiv:1810.04805"
    },
    {
      "citation_id": "3",
      "title": "Basic emotions. Handbook of cognition and emotion",
      "authors": [
        "Paul Ekman"
      ],
      "year": "1999",
      "venue": "Basic emotions. Handbook of cognition and emotion"
    },
    {
      "citation_id": "4",
      "title": "Cosmic: Commonsense knowledge for emotion identification in conversations",
      "authors": [
        "Deepanway Ghosal",
        "Navonil Majumder",
        "Alexander Gelbukh",
        "Rada Mihalcea",
        "Soujanya Poria"
      ],
      "year": "2020",
      "venue": "Cosmic: Commonsense knowledge for emotion identification in conversations",
      "arxiv": "arXiv:2010.02795"
    },
    {
      "citation_id": "5",
      "title": "Explaining and harnessing adversarial examples",
      "authors": [
        "Ian Goodfellow",
        "Jonathon Shlens",
        "Christian Szegedy"
      ],
      "year": "2014",
      "venue": "Explaining and harnessing adversarial examples",
      "arxiv": "arXiv:1412.6572"
    },
    {
      "citation_id": "6",
      "title": "Authorship identification and author fuzzy \"fingerprints",
      "authors": [
        "Nuno Homem",
        "Joao Carvalho"
      ],
      "year": "2011",
      "venue": "2011 Annual Meeting of the North American Fuzzy Information Processing Society"
    },
    {
      "citation_id": "7",
      "title": "Web user identification with fuzzy fingerprints",
      "authors": [
        "Nuno Homem",
        "Joao Carvalho"
      ],
      "year": "2011",
      "venue": "2011 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE 2011)"
    },
    {
      "citation_id": "8",
      "title": "Past, present, and future: Conversational emotion recognition through structural modeling of psychological knowledge",
      "authors": [
        "Jiangnan Li",
        "Zheng Lin",
        "Peng Fu",
        "Weiping Wang"
      ],
      "year": "2021",
      "venue": "Findings of the Association for Computational Linguistics: EMNLP 2021"
    },
    {
      "citation_id": "9",
      "title": "Dailydialog: A manually labelled multi-turn dialogue dataset",
      "authors": [
        "Yanran Li",
        "Hui Su",
        "Xiaoyu Shen",
        "Wenjie Li",
        "Ziqiang Cao",
        "Shuzi Niu"
      ],
      "year": "2017",
      "venue": "Dailydialog: A manually labelled multi-turn dialogue dataset",
      "arxiv": "arXiv:1710.03957"
    },
    {
      "citation_id": "10",
      "title": "A robustly optimized bert pretraining approach",
      "authors": [
        "Yinhan Liu",
        "Myle Ott",
        "Naman Goyal",
        "Jingfei Du",
        "Mandar Joshi",
        "Danqi Chen",
        "Omer Levy",
        "Mike Lewis",
        "Luke Zettlemoyer",
        "Veselin Stoyanov",
        "Roberta"
      ],
      "year": "2019",
      "venue": "A robustly optimized bert pretraining approach",
      "arxiv": "arXiv:1907.11692"
    },
    {
      "citation_id": "11",
      "title": "Dialoguernn: An attentive rnn for emotion detection in conversations",
      "authors": [
        "Navonil Majumder",
        "Soujanya Poria",
        "Devamanyu Hazarika"
      ],
      "year": "2019",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence"
    },
    {
      "citation_id": "12",
      "title": "Deep emotion recognition in textual conversations: A survey",
      "authors": [
        "Patrícia Pereira",
        "Helena Moniz",
        "Joao Carvalho"
      ],
      "year": "2022",
      "venue": "Deep emotion recognition in textual conversations: A survey",
      "arxiv": "arXiv:2211.09172"
    },
    {
      "citation_id": "13",
      "title": "Context-dependent embedding utterance representations for emotion recognition in conversations",
      "authors": [
        "Patrícia Pereira",
        "Helena Moniz",
        "Isabel Dias",
        "Joao Carvalho"
      ],
      "year": "2023",
      "venue": "Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment & Social Media Analysis"
    },
    {
      "citation_id": "14",
      "title": "Context-dependent sentiment analysis in user-generated videos",
      "authors": [
        "Soujanya Poria",
        "Erik Cambria",
        "Devamanyu Hazarika",
        "Navonil Majumder",
        "Amir Zadeh",
        "Louis-Philippe Morency"
      ],
      "year": "2017",
      "venue": "Proceedings of the 55th annual meeting of the association for computational linguistics"
    },
    {
      "citation_id": "15",
      "title": "Emotion recognition in conversation: Research challenges, datasets, and recent advances",
      "authors": [
        "Soujanya Poria",
        "Navonil Majumder",
        "Rada Mihalcea",
        "Eduard Hovy"
      ],
      "year": "2019",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "16",
      "title": "Fuzzy fingerprinting large pre-trained models",
      "authors": [
        "Rui Ribeiro",
        "Patrícia Pereira",
        "Luisa Coheur",
        "Helena Moniz",
        "Joao Carvalho"
      ],
      "year": "2023",
      "venue": "Proceedings of the 13th Conference of the European Society for Fuzzy Logic and Technology"
    },
    {
      "citation_id": "17",
      "title": "Twitter topic fuzzy fingerprints",
      "authors": [
        "Hugo Rosa",
        "Fernando Batista",
        "Joao Carvalho"
      ],
      "year": "2014",
      "venue": "2014 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)"
    },
    {
      "citation_id": "18",
      "title": "Using fuzzy fingerprints for cyberbullying detection in social networks",
      "authors": [
        "Hugo Rosa",
        "Joao Carvalho",
        "Pável Calado",
        "Bruno Martins",
        "Ricardo Ribeiro",
        "Luisa Coheur"
      ],
      "year": "2018",
      "venue": "2018 IEEE international conference on fuzzy systems (FUZZ-IEEE)"
    },
    {
      "citation_id": "19",
      "title": "Dialogxl: All-in-one xlnet for multi-party conversation emotion recognition",
      "authors": [
        "Weizhou Shen",
        "Junqing Chen",
        "Xiaojun Quan",
        "Zhixian Xie"
      ],
      "year": "2020",
      "venue": "Dialogxl: All-in-one xlnet for multi-party conversation emotion recognition",
      "arxiv": "arXiv:2012.08695"
    },
    {
      "citation_id": "20",
      "title": "Directed acyclic graph network for conversational emotion recognition",
      "authors": [
        "Weizhou Shen",
        "Siyue Wu",
        "Yunyi Yang",
        "Xiaojun Quan"
      ],
      "year": "2021",
      "venue": "Directed acyclic graph network for conversational emotion recognition",
      "arxiv": "arXiv:2105.12907"
    },
    {
      "citation_id": "21",
      "title": "Attention is all you need",
      "authors": [
        "Ashish Vaswani",
        "Noam Shazeer",
        "Niki Parmar",
        "Jakob Uszkoreit",
        "Llion Jones",
        "Aidan Gomez",
        "Lukasz Kaiser",
        "Illia Polosukhin"
      ],
      "year": "2017",
      "venue": "Attention is all you need",
      "arxiv": "arXiv:1706.03762"
    },
    {
      "citation_id": "22",
      "title": "Huggingface's transformers: State-of-the-art natural language processing",
      "authors": [
        "Thomas Wolf",
        "Lysandre Debut",
        "Victor Sanh",
        "Julien Chaumond",
        "Clement Delangue",
        "Anthony Moi",
        "Pierric Cistac",
        "Tim Rault",
        "Rémi Louf",
        "Morgan Funtowicz"
      ],
      "year": "2019",
      "venue": "Huggingface's transformers: State-of-the-art natural language processing",
      "arxiv": "arXiv:1910.03771"
    },
    {
      "citation_id": "23",
      "title": "Knowledge-enriched transformer for emotion detection in textual conversations",
      "authors": [
        "Peixiang Zhong",
        "Di Wang",
        "Chunyan Miao"
      ],
      "year": "2019",
      "venue": "Knowledge-enriched transformer for emotion detection in textual conversations",
      "arxiv": "arXiv:1909.10681"
    }
  ]
}