{
  "paper_id": "2504.16573v1",
  "title": "Psycounassist: A Full-Cycle Ai-Powered Psychological Counseling Assistant System",
  "published": "2025-04-23T09:49:05Z",
  "authors": [
    "Xianghe Liu",
    "Jiaqi Xu",
    "Tao Sun"
  ],
  "keywords": [
    "Psychological counseling",
    "Multimodal emotion recognition",
    "Photoplethysmography (PPG)",
    "Large language models (LLM)",
    "AI-assisted counseling",
    "Human-centered AI"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Psychological counseling is a highly personalized and dynamic process that requires therapists to continuously monitor emotional changes, document session insights, and maintain therapeutic continuity. In this paper, we introduce PsyCounAssist, a comprehensive AI-powered counseling assistant system specifically designed to augment psychological counseling practices. PsyCounAssist integrates multimodal emotion recognition combining speech and photoplethysmography (PPG) signals for accurate real-time affective analysis, automated structured session reporting using large language models (LLMs), and personalized AI-generated follow-up support. Deployed on Android-based tablet devices, the system demonstrates practical applicability and flexibility in real-world counseling scenarios. Experimental evaluation confirms the reliability of PPG-based emotional classification and highlights the system's potential for non-intrusive, privacy-aware emotional support. PsyCounAssist represents a novel approach to ethically and effectively integrating AI into psychological counseling workflows. \n CCS Concepts: ‚Ä¢ Computing methodologies ‚Üí Artificial intelligence; ‚Ä¢ Applied computing ‚Üí Life and medical sciences; ‚Ä¢ Security and privacy ‚Üí Human and societal aspects of security and privacy.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Psychological counseling is increasingly recognized as a crucial service amid the growing global prevalence of mental health disorders, yet the field continues to face significant resource constraints, notably shortages of trained therapists  [2] . To bridge this gap, artificial intelligence (AI) technologies, particularly AI chatbots and automated systems, have been widely explored and implemented to support or even partially replace traditional counseling practices  [4]   [7] . However, these approaches frequently aim at substituting therapists with conversational agents, which introduces significant ethical concerns, including the lack of empathy, potential biases, and insufficient personalization  [11] .\n\nRecent research highlights the limitations of existing AI-based counseling systems, specifically their inability to adequately understand nuanced human emotions, respond empathically, and address individual differences in emotional expression  [7] . Moreover, current solutions rarely consider the needs of therapists who require effective, reliable tools to enhance their clinical workflows and reduce administrative burdens, while also safeguarding clients' privacy  [2] .\n\nIn response to these gaps, we introduce PsyCounAssist, a novel AI-powered full-cycle psychological counseling assistant system designed explicitly to support, rather than replace, therapists and their clients. Our system focuses on three distinct yet interconnected modules aligned with actual counseling scenarios: real-time emotion prediction (REP), automated structured session reporting (ASSR), and personalized follow-up support (PFS).\n\nPsyCounAssist leverages a multimodal fusion approach combining speech and photoplethysmography (PPG) signals, thereby significantly enhancing the accuracy of real-time emotion recognition compared to traditional unimodal methods  [8]   [5] . Beyond realtime emotional monitoring, PsyCounAssist integrates an innovative session documentation system powered by large language models (LLMs), automating the structured reporting process and substantially decreasing therapists' documentation workloads. Additionally, our system provides a personalized conversational agent that supports clients between counseling sessions. Clients can choose between general or individualized chatbots, the latter leveraging previous session insights to deliver more tailored emotional support and self-help interventions.\n\nCritically, PsyCounAssist emphasizes ethical considerations and privacy protection. Unlike conventional AI counseling systems, our design explicitly allows emotional monitoring without obligatory audio recording or transcription, thus ensuring clients' confidentiality and data security  [2] .\n\nIn summary, the primary contributions of this work include: (1) proposing PsyCounAssist, a novel system designed explicitly as a therapist-support tool rather than a replacement, addressing key ethical and practical limitations of existing approaches; (2) introducing an advanced multimodal fusion method for emotion recognition that combines speech and PPG signals to enhance accuracy and privacy protection; and (3) demonstrating practical, deployable tools such as automated structured reporting and personalized follow-up support, aimed at significantly improving therapeutic efficiency and client engagement.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Related Work",
      "text": "AI-Assisted Mental Health Counseling. In recent years, artificial intelligence (AI) has been successfully applied across various domains, including image recognition and text analysis, progressively merging with psychology to address practical challenges. Within psychological research, AI applications predominantly focus on affective computing, leveraging multi-source data to predict emotional states, valence levels, or mental health indicators. In mental health counseling, notable implementations include chatbot systems and diagnostic recommendation tools designed to simulate certain aspects of human counselor interactions. For instance, PsyDT  [10]  employs large-scale corpora emulating professional therapists' conversational styles to train large language models (LLMs), effectively replicating specific counseling dialogues and interaction logic. Similarly, XiaoIce  [12] , an AI-based companionship system, provides emotional support through everyday conversations tailored to user preferences, accommodating sustained emotional engagement. However, despite significant progress, these systems generally fail to integrate seamlessly into actual counseling practices, neglecting the intrinsic human-to-human empathetic interaction essential to effective psychological counseling. Hence, constructing supportive rather than substitutive AI systems is vital to genuinely empower psychological counseling. Additionally, real-world counseling sessions often involve privacy concerns and expression constraints, leading clients to resist providing complete textual or facial data. Thus, incorporating non-verbal cues as a low-intrusiveness supplement to assist therapists in real-time emotional detection becomes imperative.\n\nMultimodal Emotion Recognition in Mental Health. Multimodal modeling, particularly combining speech and physiological signals, is becoming mainstream for non-invasive, real-time emotion recognition in psychological applications. In speech-based emotion recognition, significant advancements such as the Emotion2Vec model have demonstrated outstanding performance on multimodal datasets like RECOLA  [9] , achieving state-of-the-art Weighted Accuracy (WA) of 79.4 %, making it suitable for dynamic assessment and real-time assistance during therapy sessions. Regarding physiological signals, photoplethysmography (PPG) has emerged as a practical, wearable approach extensively used for emotion recognition. PPGderived features, including heart rate (HR) and heart rate variability (HRV), are strongly correlated with autonomic nervous system activities, effectively indicating fluctuations in anxiety, stress, and other emotional states. These physiological indicators provide reliable data for developing non-invasive multimodal emotion recognition systems. Hence, future psychological counseling AI systems should transition from single-modal simulations toward multimodal fusion approaches, significantly enhancing their capacity to perceive and understand complex human emotional behaviors.\n\nLLM-based Automated Counseling Support. Large language models (LLMs), such as GPT-4, have demonstrated exceptional reasoning and summarization capabilities in language understanding and generation tasks, making them highly suitable for structuring and summarizing counseling session content. Typically, counselors must manually document key conversational insights, a process prone to omission and inefficiency. Automated structured documentation from session recordings substantially reduces counselor workload, enhancing productivity and service quality. Current leading LLMs, including GPT-4, excel in extracting critical information from lengthy counseling sessions (45-60 minutes) and generating organized summaries. Nonetheless, cloud-deployed models pose potential risks regarding user privacy, particularly sensitive within mental health contexts. To address privacy concerns, locally deployable open-source models like DeepSeek present more appropriate alternatives. These models facilitate voice transcription and structured conversation extraction without external servers, simultaneously ensuring privacy and intelligent performance, thus providing practical solutions for counseling support. Additionally, although companion AI systems like XiaoICE are not classified under formal psychological counseling, their emotional support role is significant. Advanced customization utilizing clients' historical counseling summaries and stylistic preferences could create familiar, personalized digital companions, aiding emotional continuity and psychological stability. Technologically, with client authorization, structured counseling records and tailored prompt engineering can generate personalized supportive content. Combined with advanced voice cloning models such as SparkTTS and Bark, these AI systems can emulate specific counselor voices, offering more authentic and trustworthy interactive experiences for clients.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "System Overview",
      "text": "We propose PsyCounAssist, an integrated AI-driven framework for enhancing psychological counseling through real-time affective assessment, automated session documentation, and personalized post-session support. The system consists of three functionally distinct yet interconnected modules: (1) Real-time Emotion Prediction (REP), (2) Automated Structured Session Reporting (ASSR), and (3) Personalized Follow-up Support (PFS). The overall system workflow is illustrated in Figure  1 .",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Real-Time Emotion Prediction (Rep)",
      "text": "3.1.1 Data Collection. The Real-time Emotion Prediction (REP) module is designed to infer the client's emotional state during active counseling sessions using multi-modal input. To accommodate varying session contexts and privacy considerations, the system flexibly supports emotion recognition based on speech signals, physiological signals (i.e., photoplethysmography, PPG), or their combination. The specific modality or fusion strategy is determined according to the client's informed consent and device availability.\n\nSpeech data is captured via in-room or pad microphones, while PPG signals are collected through wearable sensors such as wristbands. When both modalities are available and permitted, their outputs are integrated via a decision-level fusion mechanism to improve prediction robustness. This flexible configuration ensures broad applicability while aligning with ethical and privacy-preserving principles.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Emotion Prediction.",
      "text": "Speech-based Emotion Recognition. For the audio modality, we adopt Emotion2Vec  [6]  as the core emotion recognition model. The model projects speech segments into a continuous affective vector space and has demonstrated strong generalization across several public affective speech corpora. In our use case, the model is finetuned for three primary emotional classes: sad, neutral, and positive, which are aligned with typical affective states in therapeutic dialogue.\n\nThe audio processing pipeline includes: Voice Activity Detection (VAD): applied to segment effective speech intervals from ambient noise and silence; KMeans++ Clustering: used for unsupervised partitioning of speech segments, aiding in speaker differentiation; Speaker Attribution: achieved by comparing cluster characteristics with a pre-constructed database of counselor voice samples, allowing extraction of client-only speech for emotion inference.\n\nThis preprocessing ensures the downstream model focuses on client expressions, filtering out therapist utterances and irrelevant segments.\n\nPhysiological Modeling via PPG. To complement the limitations of speech signals-e.g., suppressed affect expression or deceptive tone-we incorporate photoplethysmography (PPG) as a secondary modality. PPG signals are acquired via non-invasive wrist-worn devices and analyzed in terms of: Heart Rate (HR),Heart Rate Variability (HRV).\n\nTo build a reliable mapping between physiological responses and emotional states, we design and implement a controlled emotion elicitation experiment. Participants are exposed to audiovisual stimuli curated to induce specific affective states (e.g., sadness, calmness), during which real-time PPG signals were collected. After each elicitation block, participants self-reported their experienced emotions using a valence-arousal grid, which served as ground truth for supervised learning.The collected data were then used to train a set of machine learning models (e.g., SVM, LightGBM) to classify emotional states based on HR and HRV features. This rule accounts for low-energy or ambiguous speech that may be misclassified as neutral while still containing affective signals (e.g., sadness).\n\nPPG-only Condition. Let ùúá ùë° denote the mean SCR (skin conductance response) at time ùë°, computed from GSR features derived from the PPG signal. We define a cumulative affect score ùëÜ ùëù ‚àà R, updated heuristically as:\n\nwhere ùúÜ is a fixed update constant (default: 0.5), ùúÉ is the SCR reactivity threshold (default: 0.3), and ùëö ‚àà [0, 1] is a confidence coefficient.\n\nThe final emotional label is assigned as:\n\nwith ùõø 1 = 1.0 by default.\n\nMulti-modal Condition. When both modalities are available, a weighted average is used to compute the final emotional distribution:\n\n, ‚àÄùëê ‚àà C Here, ùëÉ ùë° ùë† (ùëê) and ùëÉ ùë° ùëù (ùëê) are the class probabilities from speech and PPG models respectively, and ùõº ‚àà [0, 1] is the fusion weight. In default settings:\n\n‚Ä¢ ùõº = 0.7 when speech quality is high,\n\n‚Ä¢ ùõº = 0.3 when speech is noisy or unavailable.\n\nThe final label is computed as ≈∑ùë° ùëì = arg max ùëê ùëÉ ùë° ùëì (ùëê).",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Output Interface And Alert Mechanism.",
      "text": "To support therapist awareness and real-time adaptation during counseling sessions, the REP module outputs emotional predictions via an integrated visualization interface in the counselor's application (e.g., tablet or workstation). Affective states are updated at fixed intervals (e.g., every 60 seconds) and presented in the following manner:\n\n‚Ä¢ Color-coded status bar: representing discrete emotional states, such as blue (sad), green (neutral), and yellow (positive); ‚Ä¢ Trend indicators: displaying affective changes over time (e.g., upward/downward arrows); ‚Ä¢ Popup alerts: triggered under two specific conditions:\n\n(1) sustained low-valence states (e.g., continuous sadness predictions), or (2) abrupt emotional shifts (e.g., valence change exceeding a predefined threshold).\n\nThe interface is designed to be minimally intrusive and contextaware, ensuring that the counselor's focus remains primarily on the client, while still benefiting from dynamic affective feedback.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Module Innovations And Ethical Considerations. The Rep Module Introduces Multiple Design Innovations And Adheres To Ethical Principles Relevant To Real-World Psychological Counseling:",
      "text": "‚Ä¢ Flexible modality selection: The system supports unimodal or multimodal emotion inference depending on data availability and user consent, enabling personalization per client or institution. ‚Ä¢ Decision-level fusion: Instead of feature-level fusion, we adopt a rule-based strategy that enhances interpretability and robustness, particularly under missing or low-quality signals.\n\n‚Ä¢ Low-latency prediction: All computations are optimized for real-time inference with latency under 1 second, allowing in-session feedback without disrupting counselor flow. ‚Ä¢ Privacy-preserving deployment: All raw signal processing is performed locally or within secure institutional infrastructure. Neither speech nor biometric data is transmitted externally. ‚Ä¢ Human-in-the-loop design: The system provides emotion predictions as decision support rather than definitive labels. Final interpretations and actions remain entirely under the therapist's discretion.\n\nThese features ensure that the REP module remains clinically relevant, ethically sound, and adaptable to diverse therapeutic contexts.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Automated Structured Session Reporting (Assr)",
      "text": "The Automated Structured Session Reporting (ASSR) module is responsible for summarizing and structuring the contents of each counseling session using large language models (LLMs). It aims to reduce the post-session documentation burden for counselors and enhance the traceability and interpretability of psychological processes.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Input And Model",
      "text": "Architecture. Upon completion of a counseling session, the audio content is either transcribed via an automatic speech recognition (ASR) system or annotated manually. The resulting textual transcript serves as input to a few-shot prompted LLM (e.g., GPT-4  [1] , DeepSeek  [3] ,), which is fine-tuned through prompt engineering to generate structured session reports. Key functions include:\n\n‚Ä¢ Summarizing the overall dialogue content;\n\n‚Ä¢ Extracting emotionally salient segments and critical discussion points; ‚Ä¢ Highlighting psychological markers such as emotional regulation, relationship dynamics, and cognitive shifts. The model utilizes template-driven prompts with role context (e.g., \"counselor\", \"client\") and time-tagged content to ensure factual consistency and structured output.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Output",
      "text": "Format. The generated report consists of standardized sections designed to capture both clinical observations and client narratives. These typically include:\n\n‚Ä¢ Session Context: client background and presenting issues;\n\n‚Ä¢ Exploration Highlights: key dialogue threads, emotional responses, and therapeutic reflections; ‚Ä¢ Observed Progress: behavioral, emotional, and cognitive shifts since previous sessions; ‚Ä¢ Follow-up Suggestions: therapist recommendations for individual or systemic intervention; ‚Ä¢ Summary: synthesis of therapeutic status and engagement outlook.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Personalized Follow-Up Support (Pfs)",
      "text": "The Personalized Follow-up Support (PFS) module enables postsession engagement through AI-generated, context-aware followup messages. These messages are designed to provide continued emotional support and therapeutic continuity outside of scheduled sessions, without requiring real-time counselor input.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Dialogue Framework And Context",
      "text": "Conditioning. PFS utilizes a large language model (LLM)-driven response generation framework tailored for mental health scenarios. To ensure contextual relevance and therapeutic consistency, each response is conditioned on:\n\n‚Ä¢ Structured session summaries produced by the ASSR module; ‚Ä¢ Recent emotional trends inferred from REP output; ‚Ä¢ Client-specific therapeutic goals (e.g., emotional regulation, cognitive reframing). Responses are generated using customized prompt templates that align with common therapeutic paradigms such as cognitive behavioral therapy (CBT) or supportive counseling.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Natural Ai Voice And Delivery",
      "text": "Channel. The generated messages are converted to audio using a generic AI voice synthesis engine, which produces neutral and emotionally consistent spoken messages. This approach avoids direct replication of counselor identity while preserving the benefits of natural-sounding speech.\n\nClients receive these voice messages via a secure mobile or web interface, supporting:\n\n‚Ä¢ Asynchronous delivery, allowing users to engage at their own pace; ‚Ä¢ Audio and textual formats, enabling flexible consumption; ‚Ä¢ Minimal interaction burden, with passive reception of supportive prompts.\n\n3.3.3 Application Scenarios. PFS supports various use cases, including daily check-ins, reminders for emotion regulation techniques, and motivational messages. A sample output may resemble:\n\n\"Hi, just checking in with you today. Remember to take a few minutes to breathe and slow down if you're feeling overwhelmed. You're doing your best-and that matters. \"\n\nAll outputs are based on predefined ethical triggers and clientapproved conditions. Messages are short, emotionally supportive, and aligned with the tone of previous sessions.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "System Properties And Ethical Design.",
      "text": "‚Ä¢ Low-intrusion, high-relevance: Offers continued presence without replicating human counselors; ‚Ä¢ Therapeutically aligned: Integrates prior interaction history and session intent into each response; ‚Ä¢ Privacy-first design: All processing occurs locally or within secured clinical infrastructure; ‚Ä¢ Non-identifiable AI voice: Prevents anthropomorphizing or confusion about human involvement; ‚Ä¢ Scalable and configurable: Frequency, tone, and content type can be adjusted per user preferences.\n\nThrough these features, the PFS module extends therapeutic engagement into everyday contexts, reinforcing psychological safety and continuity while respecting ethical and emotional boundaries.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Pilot Experiment 4.1 Dataset And Setup",
      "text": "To evaluate the feasibility of emotion recognition using physiological signals alone, we conducted a binary classification experiment leveraging photoplethysmography (PPG) data. The dataset was collected from 30 participants (22 male, 8 female; average age: 33 ¬± 1.25 years), each equipped with a wrist-worn wearable device sampling at 100 Hz.\n\nParticipants were exposed to audiovisual stimuli designed to elicit distinct emotional states, specifically \"sad\" and \"relax\" conditions. After each stimulus block, participants self-reported their emotional state using a valence-arousal grid, which served as ground-truth annotation. The dataset was then labeled accordingly and split into training (70%), validation (20%), and testing (10%) sets.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Model And Feature Engineering",
      "text": "We extracted key physiological features from the raw PPG signals, focusing on heart rate (HR) and heart rate variability (HRV) metrics known to correlate with autonomic nervous system activity and affective states. A variety of traditional machine learning classifiers were evaluated, including Random Forest, Gradient Boosting, AdaBoost, Support Vector Machine, and Naive Bayes.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Results",
      "text": "The top-performing models on validation and test sets are summarized in Table  1 . Notably, the Random Forest classifier achieved the highest performance, with F1 scores of 0.957 and 0.964 on the validation and test sets, respectively. This indicates a strong discriminative power of PPG signals in distinguishing between low-valence and baseline affective states.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Discussion",
      "text": "The development and deployment of PsyCounAssist highlight the growing potential of AI technologies to augment psychological counseling, rather than replace human therapists. Our system embraces a therapist-centric design philosophy, prioritizing decision support, interpretability, and ethical integrity.\n\nOne of the key strengths of PsyCounAssist lies in its modular, privacy-preserving architecture. By supporting flexible modality configurations-speech-only, PPG-only, or multimodal-the system can adapt to various client contexts, privacy constraints, and hardware limitations. This flexibility is particularly valuable in real-world scenarios where environmental noise, cultural hesitancy toward verbal expression, or data sensitivity may limit traditional approaches.\n\nFurthermore, our adoption of decision-level fusion enhances robustness and transparency. Unlike feature-level fusion, which often lacks interpretability, decision-level fusion allows therapists to better understand and validate the system's outputs. The inclusion of a human-in-the-loop framework ensures that emotional inferences are always presented as assistive suggestions, not automated diagnoses, preserving clinical judgment and ethical responsibility.\n\nHowever, several challenges remain:",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Future Work",
      "text": "To further enhance PsyCounAssist's effectiveness and applicability, several directions are proposed for future development:\n\n6.1 Short-Term Goals sualizations (e.g., attention heatmaps, rationale generation) for emotion predictions and LLM outputs to increase therapist trust and system transparency. ‚Ä¢ Real-time Risk Detection: Design dynamic crisis detection protocols to identify high-risk affective states (e.g., signs of acute distress), with escalation options such as supervisor alerts or emergency contact prompts.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Long-Term Goals",
      "text": "‚Ä¢ Cross-cultural and Multilingual Adaptation: Train emotion and language models on geographically and culturally diverse datasets to ensure inclusiveness and global usability. ‚Ä¢ Longitudinal Progress Tracking: Leverage multi-session data to monitor therapy progress over time and support predictive modeling of therapeutic outcomes, such as relapse risk or emotional stagnation. ‚Ä¢ EHR Integration: Enable seamless export of structured session summaries to electronic health record (EHR) platforms, enhancing interoperability and clinical documentation efficiency.\n\nThrough these enhancements, PsyCounAssist aims to evolve from a demo-stage prototype into a clinically validated, ethically grounded, and globally scalable solution for intelligent mental health care.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Conclusion",
      "text": "We present PsyCounAssist, a full-cycle, AI-powered assistant system designed to support psychological counseling through real-time emotion tracking, automated session documentation, and personalized follow-up communication. Unlike conventional AI systems that attempt to replace human therapists, PsyCounAssist adopts a therapist-centric approach-augmenting professional judgment with ethically designed, privacy-aware tools.\n\nOur system integrates multimodal emotion recognition using speech and PPG signals, structured reporting powered by large language models (LLMs), and AI-generated post-session messages tailored to each client's emotional history. Deployed on portable Android tablets, the system demonstrates practical applicability in real-world counseling scenarios.\n\nThe proposed framework offers a scalable and ethically aligned solution for enhancing therapy quality, therapist productivity, and client engagement. Future iterations aim to expand PsyCounAssist's capabilities to include text-based emotion sensing, cross-cultural adaptation, and longitudinal outcome tracking-bringing us closer to a new paradigm of intelligent, accessible, and trustworthy mental health care.",
      "page_start": 6,
      "page_end": 6
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Overview of proposed PsyCounAssist framework.",
      "page": 2
    }
  ],
  "tables": [
    {
      "caption": "Table 1: Notably, the Random Forest classifier achieved the",
      "page": 5
    },
    {
      "caption": "Table 1: Performance of top 5 models on validation and test sets (PPG only,",
      "page": 5
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Shyamal Anadkat, et al. 2023. Gpt-4 technical report",
      "authors": [
        "Josh Achiam",
        "Steven Adler",
        "Sandhini Agarwal",
        "Lama Ahmad",
        "Ilge Akkaya",
        "Florencia Leoni Aleman",
        "Diogo Almeida",
        "Janko Altenschmidt",
        "Sam Altman"
      ],
      "year": "2023",
      "venue": "Shyamal Anadkat, et al. 2023. Gpt-4 technical report",
      "arxiv": "arXiv:2303.08774"
    },
    {
      "citation_id": "2",
      "title": "Challenges of large language models for mental health counseling",
      "authors": [
        "Neo Christopher",
        "George Dyer",
        "Lennart Brocki"
      ],
      "year": "2023",
      "venue": "Challenges of large language models for mental health counseling",
      "arxiv": "arXiv:2311.13857"
    },
    {
      "citation_id": "3",
      "title": "DeepSeek-V3",
      "year": "2024",
      "venue": "DeepSeek-V3",
      "arxiv": "arXiv:2412.19437[cs.CL"
    },
    {
      "citation_id": "4",
      "title": "Delivering cognitive behavior therapy to young adults with symptoms of depression and anxiety using a fully automated conversational agent (Woebot): a randomized controlled trial",
      "authors": [
        "Kathleen Fitzpatrick",
        "Alison Darcy",
        "Molly Vierhile"
      ],
      "year": "2017",
      "venue": "JMIR mental health"
    },
    {
      "citation_id": "5",
      "title": "Mental Health Counseling & Therapy via Artificial Intelligence-Enabled Approaches. Authorea Preprints",
      "authors": [
        "Amogh Gyaneshwar",
        "Hruditha Punugoti",
        "Devanshi Chaubey",
        "Aditya Raj",
        "Lakshita Gupta",
        "Meghna Goel",
        "Kunal Kulkarni",
        "Agoorukasetty Adithya",
        "Manasi Gupta",
        "Utkarsh Chadha"
      ],
      "year": "2024",
      "venue": "Mental Health Counseling & Therapy via Artificial Intelligence-Enabled Approaches. Authorea Preprints"
    },
    {
      "citation_id": "6",
      "title": "2024. emotion2vec: Self-Supervised Pre-Training for Speech Emotion Representation",
      "authors": [
        "Ziyang Ma",
        "Zhisheng Zheng",
        "Jiaxin Ye",
        "Jinchao Li",
        "Zhifu Gao",
        "Shiliang Zhang",
        "Xie Chen"
      ],
      "year": "2024",
      "venue": "Proc. ACL 2024 Findings"
    },
    {
      "citation_id": "7",
      "title": "Effect of AI chatbot emotional disclosure on user satisfaction and reuse intention for mental health counseling: A serial mediation model",
      "authors": [
        "Gain Park",
        "Jiyun Chung",
        "Seyoung Lee"
      ],
      "year": "2023",
      "venue": "Current Psychology"
    },
    {
      "citation_id": "8",
      "title": "Experience in psychological counseling supported by artificial intelligence technology",
      "authors": [
        "Yuxia Ping"
      ],
      "year": "2024",
      "venue": "Technology and Health Care"
    },
    {
      "citation_id": "9",
      "title": "Introducing the RECOLA multimodal corpus of remote collaborative and affective interactions",
      "authors": [
        "Fabien Ringeval",
        "Andreas Sonderegger",
        "Juergen Sauer",
        "Denis Lalanne"
      ],
      "year": "2013",
      "venue": "2013 10th IEEE international conference and workshops on automatic face and gesture recognition (FG)"
    },
    {
      "citation_id": "10",
      "title": "PsyDT: Using LLMs to Construct the Digital Twin of Psychological Counselor with Personalized Counseling Style for Psychological Counseling",
      "authors": [
        "Haojie Xie",
        "Yirong Chen",
        "Xiaofen Xing",
        "Jingkai Lin",
        "Xiangmin Xu"
      ],
      "year": "2024",
      "venue": "PsyDT: Using LLMs to Construct the Digital Twin of Psychological Counselor with Personalized Counseling Style for Psychological Counseling",
      "arxiv": "arXiv:2412.13660"
    },
    {
      "citation_id": "11",
      "title": "Can AI replace psychotherapists? Exploring the future of mental health care",
      "authors": [
        "Zhihui Zhang",
        "Jing Wang"
      ],
      "year": "2024",
      "venue": "Frontiers in Psychiatry"
    },
    {
      "citation_id": "12",
      "title": "The design and implementation of xiaoice, an empathetic social chatbot",
      "authors": [
        "Li Zhou",
        "Jianfeng Gao",
        "Di Li",
        "Heung-Yeung Shum"
      ],
      "year": "2020",
      "venue": "Computational Linguistics"
    }
  ]
}