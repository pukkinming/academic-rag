{
  "paper_id": "2507.17450v1",
  "title": "Persistent Patterns In Eye Movements: A Topological Approach To Emotion Recognition A Preprint",
  "published": "2025-07-23T12:14:17Z",
  "authors": [
    "Arsha Niksa",
    "Hooman Zare",
    "Ali Shahrabi",
    "Hanieh Hatami",
    "Mohammadreza Razvan"
  ],
  "keywords": [
    "Persistent homology",
    "Eye-tracking data",
    "Circumplex Model of Affect"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "We present a topological pipeline for automated multiclass emotion recognition from eye-tracking data. Delay embeddings of gaze trajectories are analyzed using persistent homology. From the resulting persistence diagrams, we extract shape-based features such as mean persistence, maximum persistence, and entropy. A random forest classifier trained on these features achieves up to 75.6% accuracy on four emotion classes, which are the quadrants the Circumplex Model of Affect. The results demonstrate that persistence diagram geometry effectively encodes discriminative gaze dynamics, suggesting a promising topological approach for affective computing and human behavior analysis.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Eye movements carry information about underlying cognitive and emotional states  [Tabbaa et al., 2022] . For example, gaze direction influences facial emotion perception: direct gaze facilitates recognition of approach-oriented emotions (anger, joy) while averted gaze facilitates avoidance-oriented emotions (fear, sadness)  [Adams and Kleck, 2003a] . Eye movements not only reflect where attention is directed but also convey information about underlying cognitive and emotional processes  [Adams and Kleck, 2003b, 2005] . Eye-tracking provides a window into a user's visual and affective processes  [Tabbaa et al., 2022] .\n\nGaze metrics such as fixations, saccades and pupil size have thus been used as affective cues in many studies  [Kaisler et al., 2020 , Zhao et al., 2021] . In emotion recognition research, common practice is to extract statistical features from gaze trajectories (e.g., fixation duration, saccade amplitude, pupil diameter)  [Tarnowski et al., 2020] . For instance,  Tarnowski et al. computed  18 eye movement features and achieved approximately 80% classification accuracy (three emotion classes, SVM)  [Tarnowski et al., 2020] . Such handcrafted features can perform well  [Schurgin et al., 2014 , Bediou et al., 2022] , but they may fail to capture complex nonlinear patterns and temporal dynamics in the gaze data. An example of why these methods might generaly fail to capture nonlinearities are discussed in the following article  [Rouhani et al., 2025]  Topological data analysis (TDA) offers a different perspective by examining the shape of data across scales  [Ichinomiya, 2025] . Persistent homology, a key TDA method, identifies features such as connected components and loops that persist over a range of scales  [Carlsson, 2009] . A standard approach for time series is to form a point cloud via time-delay (Takens) embedding and then compute the persistence diagram of that cloud. Delay embeddings recover the geometry of the underlying dynamical attractor  [Chung et al., 2021a] , and the resulting topological features are invariant to the speed of traversal and robust to noise. This method has been successfully applied to various domains, including time series analysis and spatial data clustering  [Pereira and de Mello, 2015] .\n\nIn this study, we apply these ideas to eye-gaze trajectories for emotion classification. We model the gaze as a 2D time series and embed it in higher-dimensional space using a sliding-window delay embedding (inspired by Takens' theorem  [Chung et al., 2021a] ). We then compute Vietoris-Rips persistence diagrams (homology dimensions 0 and 1) of the embedded point cloud. Each diagram is vectorized by calculating summary statistics of its persistence values (for example mean, max, standard deviation, skewness, kurtosis, quartiles, and persistent entropy; though not all are used in our methodology)  [Mishra and Motta, 2023] . These persistence statistics form a fixed-length feature vector representing the topological structure of the eye movement.\n\nWe evaluate our method on the VREED (VR Eyes: Emotions) dataset  [Tabbaa et al., 2022] . VREED contains eyetracking (and physiological) data from 34 participants exposed to 12 immersive 360°video environments, selected to span the four quadrants of the circumplex model of affect  [Tabbaa et al., 2022] . Participants reported valence and arousal using the Self-Assessment Manikin (SAM) and discrete emotions via a visual-analog scale, providing labels for supervised learning.\n\nOur results show that the proposed topological features improve emotion classification accuracy compared to conventional gaze features. This suggests that persistent homology can capture subtle spatiotemporal patterns in gaze behavior linked to affect. The remainder of the paper is organized as follows. Section 2 describes the VREED dataset and its emotion labels. Section 3 details the methodology (delay embedding, persistent homology, feature extraction). Section 4 presents classification experiments and performance analysis. Section 5 discusses the implications and outlines future work. Code and supplementary materials are provided in Section 6 Please note that OpenAI's ChatGPT has been used to assist in editing the English text of this paper and in generating parts of the code for feature engineering and classification.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Data",
      "text": "We utilized the VREED dataset, a multimodal affective dataset designed for emotion recognition in immersive virtual reality (VR) environments  [Tabbaa et al., 2022] . VREED includes behavioral (eye-tracking) and physiological (ECG and GSR) recordings, as well as self-reported affective states from 34 participants exposed to 12 emotion-eliciting 360°virtual environments (360-VEs). These VEs were pre-selected through a pilot study and mapped to quadrants of the Circumplex Model of Affect (CMA)  [Posner et al., 2005] . Participants reported their valence-arousal states using the Self-Assessment Manikin (SAM), discrete emotions using a Visual Analog Scale (VAS), and presence levels via validated presence questionnaires.\n\nThe eye-tracking data, sampled at 60 Hz, include gaze coordinates and blink indicators for both eyes, pre-processed and available in both raw and feature-extracted forms. Physiological signals were sampled at high frequencies (2000 Hz for GSR and 1000 Hz for ECG) and aligned with emotional labels corresponding to each stimulus. Extracted feature datasets contain 312 labeled samples for both modalities. Labels reflect four emotional states based on the valence-arousal plane: High Arousal High Valence, Low Arousal High Valence, Low Arousal Low Valence, and High Arousal Low Valence.\n\nAs shown in Table  1 , the dataset exhibits a high degree of class balance across the four emotional quadrants defined by the Circumplex Model of Affect. Each quadrant contains approximately 99-102 samples, indicating strong class homogeneity. This minimizes the risk of classifier bias due to class imbalance and enables more reliable evaluation of model performance across the entire emotional spectrum. Each subject was exposed to 12 videos, each designed to elicit a distinct emotional response. For the purposes of this analysis, we focused solely on the gaze trajectory of the left eye. All trajectories were concatenated into a single dataset and shuffled, resulting in a total of 399 time series samples. To mitigate computational costs in subsequent topological computations, we downsampled each trajectory by selecting every 20 th index.\n\nFor evaluation, we adopted a three-way split of the dataset. First, 20% of the data was held out as a final validation set. The remaining 80% was further divided into training and testing sets with an 80/20 split, respectively. This setup ensures that model performance can be reliably assessed while retaining enough data for learning robust features.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Methodologies",
      "text": "",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Topological Representation Of Gaze Trajectories",
      "text": "Let T = {(x t , y t ) ∈ R 2 | t = 1, . . . , N } denote a discrete eye-gaze trajectory. We equip T with the Euclidean metric ∥ • ∥ 2 . A filtration {K ϵ } ϵ≥0 is a nested family of simplicial complexes indexed by a scale parameter ϵ. For T , we construct the Vietoris-Rips complex VR ϵ (T ), where a k-simplex spans k + 1 points in T with pairwise distances ≤ ϵ.\n\nThe persistent homology of this filtration captures topological features across scales. For each homological dimension p ∈ N 0 , we consider the persistence module {H p (K ϵ )} ϵ≥0 and its decomposition:\n\nwhere I[b i , d i ) is an interval module corresponding to a p-dimensional topological feature (e.g., connected components for p = 0, loops for p = 1) born at scale b i and dying at\n\nThe horizontal axis encodes the scale at which a feature appears (birth), and the vertical axis shows when it disappears (death). Features that lie far from the diagonal are typically more meaningful, as they persist over longer ranges of the filtration. An example persistence diagram computed from the gaze trajectory of a subject is shown in Figure  1 . Readers seeking a formal introduction to these concepts are referred to  [Edelsbrunner and Harer, 2010] .\n\nFor computational efficiency, we downsample T by reduction factor r:\n\nwhere r = 20 balances temporal resolution and computational complexity.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "State Space Reconstruction Via Takens Embedding",
      "text": "We reconstruct the state space dynamics of gaze trajectories using Takens' embedding theorem. For each coordinate time series {x t } N t=1 and {y t } N t=1 , define delay embeddings ϕ x , ϕ y : R → R d with embedding dimension d and delay τ : ϕ x (t) = x t , x t+τ , . . . , x t+(d-1)τ , ϕ y (t) = y t , y t+τ , . . . , y t+(d-1)τ .\n\nThe full state space embedding is then Φ : R → R 2d :\n\nParameters (d, τ ) are usually optimized per subject via mutual information minimization for τ and false nearest neighbors analysis for d  [Kantz and Schreiber, 2003] . In this paper, however, we fixed parameters d = 3, τ = 10, which were determined empirically. This yields three point clouds:",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Persistent Homology Computation",
      "text": "For each point cloud P ∈ {P raw , P x , P y }, we compute the Vietoris-Rips filtration {VR ϵ (P)} ϵ≥0 . The persistence module is:\n\n, ϵ ≤ ϵ ′ with p-dimensional persistent homology groups decomposed as i∈I I[b i , d i ). We compute persistence diagrams D 0 (connected components) and D 1 (loops) using the Ripser package.\n\nReaders seeking a formal introduction to these concepts are referred to  [Edelsbrunner and Harer, 2010] .  1. Mean:\n\nEntropy:\n\nWe apply persistent homology to the trajectory and compute the features above from the resulting diagrams. The resulting vector is similar to a concept referred to as persistence statistics, introduced in  [Chung et al., 2021b] .",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Classification Framework",
      "text": "Let {(f i , y i )} K i=1 be labeled samples with y i ∈ C = {0, 1, 2, 3} (emotional states). We implement a Random Forest classifier: ŷ = mode ({h k (f )} ntrees k=1 ) where h k are decision trees trained on bootstrap samples with feature subset size ⌊ √ m⌋. Hyperparameters: n trees = 100, Gini impurity splitting.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Computational Implementation",
      "text": "Persistence diagrams were computed using Ripser.py  [Tralie et al., 2018] . The classification pipeline was implemented in scikit-learn  [Pedregosa et al., 2011] .",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Results",
      "text": "We evaluated our topological feature-based classification model (Random Forest) against a baseline model trained on processed features provided in the VREED dataset  [Tabbaa et al., 2022] . Both models were evaluated on a 4-class emotion recognition task using eye trajectory data.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Topological Features (Our Method)",
      "text": "Our method achieved a test accuracy of 75.0%, with a validation accuracy of 75.7%. The performance across classes was relatively balanced, with F1-scores ranging from 0.56 to 0.84. Notably, classes 0 and 1 achieved the highest F1-scores (0.84 and 0.79, respectively), while class 2 was the most difficult to classify. The detailed classification report is shown in Table  2 , and the corresponding confusion matrix is visualized in Figure  2 .",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Baseline: Processed Features",
      "text": "The baseline model trained on standard processed features reached a lower accuracy of 57.1%. Performance was notably weaker for classes 2 and 3, with F1-scores of 0.44 and 0.50, respectively. The full classification report is provided in Table  3 , and the confusion matrix is shown in Figure  3 .",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Findings",
      "text": "The use of persistent homology-derived topological features significantly improved classification performance across all metrics. The average F1-score increased from 0.56 (baseline) to 0.74 (our method), with the biggest gains observed in classes with more distinctive trajectory dynamics. This demonstrates the utility of topological signal processing in emotion recognition from eye movement data.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Discussion",
      "text": "Persistent homology provides a robust approach to extracting useful geometric and topological information from time series, and our results suggest that it is able to effectively discriminate between emotional states from eye movement records. Clearly, it must be possible for the different emotional quadrants to be distinguished by having different geometric patterns and consequently different homology groups. This is in accord with the comparatively different visual characters of each of the quadrants, as shown in Figure  4 .\n\nThe classification issue within this study is a toy problem. It seems there is potential to broaden the use of topological data analysis into many more fields of psychology and neurology. Persistent homology, for example, could be applied to the issues of ADHD diagnosis, default mode network analysis, and lie detection. Moreover, this hardware is not limited to gaze trajectories, it can be reused for face motion capture data, hand gestures, or even higher-dimensional representations of speech or text.\n\nAn intriguing theoretical direction is to use persistent homology on discrete event-based time series. One example is eye blinking: we can calculate the blink rate over time and embed the resulting sequences in higher-dimensional space (e.g., by using delay embeddings). By constructing simplicial complexes between adjacent points, we obtain ordered and often highly structured geometric objects. Such blink frequency embedding complexes are illustrated in Figure  5 . Although our original experiment did not discover that adding persistence features from blink information assisted in classification, this line of inquiry may be theoretically rich in importance for describing the topological structure of lean event-driven dynamics.",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "Resources",
      "text": "The code used for this study is available on GitHub and consists of two main Jupyter notebooks:\n\n• PersistentHomology.ipynb -Implements the proposed method using time-delay embeddings and persistent homology to extract features from eye movement trajectories.\n\n• NormalML.ipynb -Implements a baseline machine learning method using conventional statistical features derived from the same dataset.\n\nThe notebooks are available at: GitHub Repository.\n\nNote: To execute the notebooks, users must download the dataset and correctly configure the data directory paths. The dataset used in this study is not included in the repository and should be downloaded separately. Please ensure that the directory structure matches the assumptions made in the notebooks before running the code. Figure  5 : Simplicial complexes derived from blink frequency embeddings. These geometric structures, while not yielding performance improvements here, may provide insights into the topological properties of discrete temporal phenomena.",
      "page_start": 7,
      "page_end": 7
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Readers seeking a formal introduction to these concepts are referred to",
      "page": 3
    },
    {
      "caption": "Figure 1: Persistence diagram of a subject’s gaze trajectory. Each point corresponds to a topological feature, with birth",
      "page": 4
    },
    {
      "caption": "Figure 2: Table 2: Classification report for our method (Random Forest on topological features)",
      "page": 5
    },
    {
      "caption": "Figure 2: Confusion matrix for the test set using our method (topological features).",
      "page": 5
    },
    {
      "caption": "Figure 3: Confusion matrix for the baseline method.",
      "page": 6
    },
    {
      "caption": "Figure 4: The classification issue within this study is a toy problem. It seems there is potential to broaden the use of topological",
      "page": 6
    },
    {
      "caption": "Figure 5: Although our original experiment did not discover that adding persistence features from blink information assisted in",
      "page": 6
    },
    {
      "caption": "Figure 4: Examples of gaze trajectories for each emotional quadrant. Each class exhibits a distinct geometric character,",
      "page": 7
    },
    {
      "caption": "Figure 5: Simplicial complexes derived from blink frequency embeddings. These geometric structures, while not",
      "page": 8
    }
  ],
  "tables": [
    {
      "caption": "Table 1: , the dataset exhibits a high degree of class balance across the four emotional quadrants defined",
      "page": 2
    },
    {
      "caption": "Table 1: Emotion Class Distribution in VREED Eye-Tracking Data",
      "page": 2
    },
    {
      "caption": "Table 2: , and the corresponding confusion matrix is visualized in Figure 2.",
      "page": 5
    },
    {
      "caption": "Table 2: Classification report for our method (Random Forest on topological features)",
      "page": 5
    },
    {
      "caption": "Table 3: , and the confusion matrix is shown in Figure 3.",
      "page": 5
    },
    {
      "caption": "Table 3: Classification report for baseline method (processed features)",
      "page": 6
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Vreed: Virtual reality emotion recognition dataset using eye tracking & physiological measures",
      "authors": [
        "Luma Tabbaa",
        "Ryan Searle",
        "Mirzaee Saber",
        "Md Bafti",
        "Jittrapol Moinul Hossain",
        "Maxine Intarasisrisawat",
        "Chee Glancy",
        "Ang Siang"
      ],
      "year": "2022",
      "venue": "Proc. ACM Interact. Mob. Wearable Ubiquitous Technol",
      "doi": "10.1145/3495002"
    },
    {
      "citation_id": "2",
      "title": "Perceived Gaze Direction and the Processing of Facial Displays of Emotion",
      "authors": [
        "Reginald Adams",
        "Robert Kleck"
      ],
      "year": "2003",
      "venue": "Psychological science",
      "doi": "10.1046/j.0956-7976.2003.psci_1479.x"
    },
    {
      "citation_id": "3",
      "title": "Effects of gaze on amygdala sensitivity to anger and fear faces",
      "authors": [
        "B Reginald",
        "Robert Adams",
        "Kleck"
      ],
      "year": "2003",
      "venue": "Science"
    },
    {
      "citation_id": "4",
      "title": "Effects of direct and averted gaze on the perception of facially communicated emotion",
      "authors": [
        "B Reginald",
        "Robert Adams",
        "Kleck"
      ],
      "year": "2005",
      "venue": "Emotion"
    },
    {
      "citation_id": "5",
      "title": "Effects of emotional expressions, gaze, and head orientation on person perception in social situations",
      "authors": [
        "Raphaela Kaisler",
        "Manuela Marin",
        "Helmut Leder"
      ],
      "year": "2020",
      "venue": "SAGE Open"
    },
    {
      "citation_id": "6",
      "title": "Emotional gaze: The effects of gaze direction on the perception of facial emotions",
      "authors": [
        "X Zhao",
        "Y Li",
        "Y Wang",
        "Wang"
      ],
      "year": "2021",
      "venue": "Frontiers in Psychology"
    },
    {
      "citation_id": "7",
      "title": "Eye-tracking analysis for emotion recognition",
      "authors": [
        "Paweł Tarnowski",
        "Marcin Kołodziej",
        "Andrzej Majkowski",
        "Jan Remigiusz",
        "Rak"
      ],
      "year": "2020",
      "venue": "Computational Intelligence and Neuroscience",
      "doi": "10.1155/2020/2909267"
    },
    {
      "citation_id": "8",
      "title": "Eye movements during emotion recognition in faces",
      "authors": [
        "James Mark W Schurgin",
        "Shinobu Nelson",
        "Hideki Iida",
        "Joan Ohira",
        "Steven Chiao",
        "Franconeri"
      ],
      "year": "2014",
      "venue": "Journal of Vision"
    },
    {
      "citation_id": "9",
      "title": "Eye-gaze strategies during facial emotion recognition in neurodegenerative diseases and links with neuropsychiatric disorders",
      "authors": [
        "Benoît Bediou",
        "Isabelle Ryff",
        "Béatrice Mercier",
        "Gabor Allali",
        "Frederic Assal",
        "Lucie Chouiter",
        "Martial Van Der Linden",
        "Jean-Marie Annoni"
      ],
      "year": "2022",
      "venue": "Journal of Neurology"
    },
    {
      "citation_id": "10",
      "title": "Crypto-fiat exchange rates network as indicator of macroeconomic dynamics",
      "authors": [
        "Shahin Rouhani",
        "Yaghub Shahmari",
        "Hooman Zare",
        "Hanie Hatami"
      ],
      "year": "2025",
      "venue": "Transactions in Theoretical and Mathematical Physics",
      "doi": "10.30511/ttmp.2025.2053798.1048"
    },
    {
      "citation_id": "11",
      "title": "Machine learning of time series data using persistent homology",
      "authors": [
        "Takashi Ichinomiya"
      ],
      "year": "2025",
      "venue": "Scientific Reports",
      "doi": "10.1038/s41598-025-06551-3"
    },
    {
      "citation_id": "12",
      "title": "A persistent homology approach to heart rate variability analysis with an application to sleep-wake classification",
      "authors": [
        "Gunnar Carlsson",
        "; Yu-Min",
        "Chuan-Shen Chung",
        "Yu-Lun Hu",
        "Hau-Tieng Lo",
        "Wu"
      ],
      "year": "2009",
      "venue": "Topology and data",
      "doi": "10.3389/fphys.2021.637684"
    },
    {
      "citation_id": "13",
      "title": "Persistent homology for time series and spatial data clustering",
      "authors": [
        "M Cássio",
        "Rodrigo F De Pereira",
        "Mello"
      ],
      "year": "2015",
      "venue": "Expert Systems with Applications"
    },
    {
      "citation_id": "14",
      "title": "Stability and machine learning applications of persistent homology using the delaunay-rips complex",
      "authors": [
        "Amish Mishra",
        "Francis Motta"
      ],
      "year": "2023",
      "venue": "Frontiers in Applied Mathematics and Statistics",
      "doi": "10.3389/fams.2023.1179301"
    },
    {
      "citation_id": "15",
      "title": "The circumplex model of affect: An integrative approach to affective neuroscience, cognitive development, and psychopathology",
      "authors": [
        "Jonathan Posner",
        "James Russell",
        "Bradley Peterson"
      ],
      "year": "2005",
      "venue": "Development and Psychopathology",
      "doi": "10.1017/S0954579405050340"
    },
    {
      "citation_id": "16",
      "title": "Computational Topology: An Introduction",
      "authors": [
        "Herbert Edelsbrunner",
        "John Harer",
        "Holger Kantz",
        "Thomas Schreiber"
      ],
      "year": "2003",
      "venue": "Nonlinear Time Series Analysis"
    },
    {
      "citation_id": "17",
      "title": "Persistence statistics for time series with applications to brain, cardiovascular, and climate data",
      "authors": [
        "K Moo",
        "Hyejin Chung",
        "Alessandra Lee",
        "Hernando Dichristofano",
        "Victor Ombao",
        "Solo"
      ],
      "year": "2021",
      "venue": "Frontiers in Physiology",
      "doi": "10.3389/fphys.2021.637684"
    },
    {
      "citation_id": "18",
      "title": "py: A lean persistent homology library for python",
      "authors": [
        "Christopher Tralie",
        "Nathaniel Saul",
        "Rann Bar-On",
        "Ripser"
      ],
      "year": "2018",
      "venue": "The Journal of Open Source Software",
      "doi": "10.21105/joss.00925"
    },
    {
      "citation_id": "19",
      "title": "Scikit-learn: Machine learning in Python",
      "authors": [
        "F Pedregosa",
        "G Varoquaux",
        "A Gramfort",
        "V Michel",
        "B Thirion",
        "O Grisel",
        "M Blondel",
        "P Prettenhofer",
        "R Weiss",
        "V Dubourg",
        "J Vanderplas",
        "A Passos",
        "D Cournapeau",
        "M Brucher",
        "M Perrot",
        "E Duchesnay"
      ],
      "year": "2011",
      "venue": "Journal of Machine Learning Research"
    }
  ]
}