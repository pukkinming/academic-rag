{
  "paper_id": "2503.03335v2",
  "title": "Inews: A Multimodal Dataset For Modeling Personalized Affective Responses To News",
  "published": "2025-03-05T10:09:53Z",
  "authors": [
    "Tiancheng Hu",
    "Nigel Collier"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Understanding how individuals perceive and react to information is fundamental for advancing social and behavioral sciences and developing human-centered AI systems. Current approaches often lack the granular data needed to model these personalized responses, relying instead on aggregated labels that obscure the rich variability driven by individual differences. We introduce iNews, a novel large-scale dataset specifically designed to facilitate the modeling of personalized affective responses to news content. Our dataset comprises annotations from 291 demographically diverse UK participants across 2,899 multimodal Facebook news posts from major UK outlets, with an average of 5.18 annotators per sample. For each post, annotators provide multifaceted labels including valence, arousal, dominance, discrete emotions, content relevance judgments, sharing likelihood, and modality importance ratings. Crucially, we collect comprehensive annotator persona information covering demographics, personality, media trust, and consumption patterns, which explain 15.2% of annotation variance -substantially higher than existing NLP datasets. Incorporating this information yields a 7% accuracy gain in zero-shot prediction and remains beneficial even with 32-shot in-context learning. iNews opens new possibilities for research in LLM personalization, subjectivity, affective computing, and human behavior simulation. \n Geographically Diverse UK Annotators Persona Profile Survey ... ğŸ‘µğŸ» ğŸ‘©ğŸ» ğŸ‘¨ğŸ¦° ğŸ§‘ğŸ¾ Disagree strongly Agree a little Agree a strongly Disagree a little ğŸ‘µğŸ» ğŸ‘©ğŸ» ğŸ‘¨ğŸ¦° ğŸ§‘ğŸ¾ >2 hours 15-30 minutes <15 minutes 15-30 minutes 1. In the past week, on average, how much time per day did you spend consuming news from all sources (online, TV, print, radio, etc.)? 2. How well do the following statements describe your personality: I see myself as someone who is reserved ğŸ‘µğŸ» ğŸ‘¨ğŸ¦° ğŸ‘©ğŸ» ğŸ§‘ğŸ¾ 1. On a scale of 1 (very clam) -7 (very active), how calm vs. active do you feel after reading this news (Arousal)?",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Understanding and predicting individual human behavior represents a central challenge across social and behavioral sciences, with applications ranging from public health interventions to economic policy design. Researchers have long recognized that individual characteristics, including personality traits, demographics, cultural backgrounds, and personal experiences, fundamentally shape how people respond to identical stimuli  (Kring and Gordon, 1998; Costa and McCrae, 2008; Mesquita and Frijda, 1992) . However, computational approaches to modeling human responses in natural language processing (NLP) have largely overlooked this rich individual variability, instead relying on aggregated labels that obscure the person-specific patterns that drive real-world behavioral phenomena  (Plank, 2022; Cabitza et al., 2023) .\n\nThis limitation becomes particularly problematic in NLP applications that aim to understand or predict human responses to textual content. Current approaches typically rely on generic group-level models that ignore individual differences in how people interpret and emotionally respond to identical texts. The emergence of large language models (LLMs), to which psychological theories are increasingly applied for analysis and development  (Zhu et al., 2024; Liu et al., 2025; Hu et al., 2025) , presents new opportunities for modeling these individuallevel differences, but requires datasets that capture both behavioral outcomes and the personal characteristics that drive them.\n\nAffective responses to news content represent an ideal testing ground for benchmarking and developing individual-level behavioral simulation models. This domain offers several key advantages: (1) emotional reactions are observable behavioral outcomes with established measurement frameworks  (Mehrabian and Russell, 1974; Bradley and Lang, 1994; Ekman, 1992) , (2) individual differences in affective news processing are well-documented in psychology and media studies  (Oliver, 2002; Valkenburg and Peter, 2013; Soroka et al., 2019) , (3) the task involves real-world stimuli that people encounter daily. Furthermore, news consumption behavior has direct societal relevance for understanding information processing, media effects, and the development of responsible information systems.\n\nWe introduce iNews, a novel large-scale dataset  (2) annotators complete a persona profile survey capturing demographics, ideology, news consumption, cognitive traits, personality, and emotional characteristics; and (3) annotators provide affective response annotations for Facebook news posts, including valence, arousal, dominance, discrete emotions, modality influence, personal relevance, and sharing likelihood.\n\nspecifically designed to capture the inherent subjectivity of affective responses to real-world news content (overview in Figure  1 ). Our dataset comprises fine-grained affective responses from 291 annotators to 2,899 Facebook posts from leading UK media outlets. The annotations include: valencearousal-dominance (VAD) ratings  (Mehrabian and Russell, 1974; Bradley and Lang, 1994 ), Ekman's basic emotions  (Ekman, 1992) , perceived post relevance, modality importance, and sharing likelihood. In addition, we collect a comprehensive set of annotator characteristics 1  (e.g. demographics, personality, media consumption habits), drawing upon insights from the differential media effects literature.\n\nOur regression analysis confirms that annotator characteristics explain a substantial portion of the annotation variance (15.2% -higher than observed in any NLP dataset to date), highlighting the importance of incorporating individual differences when modeling subjective phenomena like affect. Furthermore, through an open-ended questionnaire with a subset of annotators (N = 20), we identify nuanced patterns in how individuals experience and articulate their emotional reactions to news content, extending beyond the scope of our structured annotations and survey.\n\nIn a case study demonstrating the practical value of this rich persona information, we show that incorporating annotator characteristics can improve LLM predictions of individual-level affective responses by up to 7% in accuracy in zero-shot set-tings, although overall accuracy remains relatively modest (around 40%). When comparing input modalities (image vs. text), we find that image inputs typically outperform text in zero-shot scenarios but this advantage diminishes in few-shot settings. In the few-shot setting, we observe the \"early ascent phenomenon\"  (Lin and Lee, 2024; Agarwal et al., 2024) , where performance initially dips below zero-shot levels with very few examples before improving as the number of shots increases. We ultimately reach 44.4% accuracy at 32-shot. Even at this level, incorporating persona information yields additional performance gains, suggesting that persona-based and example-based approaches provide complementary signals for modeling individual differences.\n\nThe iNews dataset benefits a wide range of research areas: affective computing researchers modeling emotion recognition while accounting for individual differences; LLM developers advancing personalization and subjective phenomena handling; human behavior simulation researchers modeling individual-level information processing; social computing scholars investigating demographic effects in content presentation; and AI alignment researchers studying preference diversity across human populations.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Related Work",
      "text": "",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "News, Emotion, And Individual Differences",
      "text": "The interplay between news content, emotional responses, and downstream cognitive and behavioral effects is often an area of focus in communication and psychology. Prior research establishes that news often exhibits a negativity bias, eliciting negative emotions and heightened arousal in readers  (Soroka et al., 2019) . However, individual responses vary considerably based on demographic factors, pre-existing political attitudes and identities, personality traits, and other individual and group-level characteristics  (Oliver, 2002; Valkenburg and Peter, 2013; Soroka et al., 2019) . This heterogeneity carries significance beyond immediate emotional experiences, fundamentally influencing information processing and behavior. Emotions provide evaluative feedback, impacting veracity judgments  (Martel et al., 2020)  and shaping reasoning and decision-making  (Marcus et al., 2000; Storbeck and Clore, 2008) .\n\nExisting research on the affective dimension of news perception predominantly focuses on the emotional tone of the news content itself, rather than the induced emotional responses of individual readers  (de Hoog and Verboon, 2020) . Much of this work relies on aggregate-level analysis, obscuring individual-level variation. Our work addresses these limitations by redirecting attention to finegrained reader responses. We present a large-scale dataset designed to capture and analyze the spectrum of individual affective responses to news headlines, facilitating a more nuanced understanding of the relationship between news, emotion, and individual differences.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Emotion Detection In Nlp",
      "text": "Emotion detection has been a long-standing focus within NLP  (Strapparava and Mihalcea, 2007; Plaza-del Arco et al., 2024) . Recent years have seen a large number of valuable resources on the task (see  Demszky et al. (2020) ;  OberlÃ¤nder et al. (2020) ; Plaza del  Arco et al. (2020)  for a overview). These efforts have significantly advanced the field, leading to more accurate and robust emotion detection systems.\n\nHowever, most existing datasets rely on aggregated \"gold labels\", overlooking the inherent subjectivity and variation in human emotional perception  (Ovesdotter Alm, 2011; Plank, 2022; Cabitza et al., 2023) . Extensive psychological research demonstrates the significant influence of both individual characteristics (e.g., age, gender, personality traits) and group-level factors (e.g., cultural background) on how we perceive and interpret emotions  (Mesquita and Frijda, 1992; Kring and Gor-don, 1998; Costa and McCrae, 2008; Charles and Carstensen, 2010) . Consequently, models trained on datasets with aggregated labels inevitably fail to capture the nuanced, individualized nature of affective responses. This limits their effectiveness in real-world applications that demand personalized understanding and responsiveness to diverse emotional expressions.\n\nLimited attempts have been made to incorporate annotator background information  (Plaza-del Arco et al., 2024) . For instance,  Diaz et al. (2018)  provide demographic data alongside sentiment annotations in an online community dataset; however, this work is limited by its focus on sentiment (rather than fine-grained emotions), its restriction to a specific online community, and its lack of multifaceted affective response measures. To our knowledge, no existing dataset combines comprehensive individual difference variables, fine-grained affective responses, and annotations of real-world news content, as ours does.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Dataset Collection Protocol",
      "text": "To address the limitations of existing emotion detection datasets and move towards more nuanced individual-level modeling, we develop a two-stage data collection protocol to capture individualized affective responses to news headlines (Figure  1 ). Our protocol emphasizes ecological validity and the collection of rich persona variables to enable the study of how personal characteristics influence affective responses.\n\nSampling Our dataset comprises annotations of Facebook news posts, collected in three phases to capture diverse news contexts surrounding the 2024 UK general election and the Paris Olympics (see Figure  2 ). These phases are: Phase 1 (April 1-20), the pre-election period; Phase 2 (June 5-25), the election campaign period after Parliament's dissolution; and Phase 3 (July 9-29), the post-election and pre-Olympics period.\n\nThis three-phase design ensures temporal diversity and mitigates the influence of any single major event on our findings. We initially used random sampling (Phase 1) to gather a broad sample. Recognizing that some outlets are far more prolific but have lower engagement, we transitioned to stratified sampling (Phases 2 and 3) proportional to each outlet's follower count. This approach maximizes ecological validity by ensuring our sample reflects the news content that readers are actually likely to  encounter.\n\nFor each phase, we collect news posts via Crowd-Tangle. While social media content may not represent an outlet's entire output, we posit that these posts reflect editorial choices and the outlet's intended public image. Each post typically includes an image, a short description, and the headline, with the image linking to the full article (see Figure  12  for an example). To ensure maximal ecological validity and minimize bias, we present screenshots instead of text of the posts to annotators, capturing reaction counts but excluding comments to avoid influencing annotator responses. The decision to use screenshots rather than just headlines is also supported by a pilot study (Section A.2) demonstrating significant differences in affective responses based on presentation modality.\n\nAnnotator Recruitment We recruit annotators through Prolific, using quota sampling to ensure a relatively balanced representation across gender, age, political leaning, and UK geographical regions (see Figure  6  and Table  4  for details). Each of the 291 annotators contribute annotations for approximately 50 headlines. The annotation process takes around 45 minutes. Annotators are compensated Â£8.58, in accordance with the UK National Living Wage at the time of the data collection.\n\nStage 1: Persona Profile Survey This stage, implemented in Qualtrics, gathers background information (\"persona variables\") about each annotator. The survey incorporates validated items from wellestablished questionnaires  (Ofcom, 2024a; Reuters Institute, 2024) , alongside standard psychological instruments. These variables (detailed in Table 4) are selected to capture individual differences known to influence news interpretation and emotional responses, enabling us to study how these factors mediate affective reactions.\n\nThe collected variables span five key areas:   (Frederick, 2005) . Personality Traits are measured using the 10-item Big Five Inventory (BFI-10)  (Rammstedt and John, 2007) . Emotional Characteristics are evaluated using both the Perth Emotional Reactivity Scale (PERS)  (Preece et al., 2018)  and the Positive and Negative Affect Schedule (PANAS)  (Crawford and Henry, 2004) .\n\nStage 2: Headline Annotation Annotators are provided with detailed guidelines (see Section A.4), adapted from  Bradley and Lang (2007) , which are accessible throughout the annotation process 2  . The annotation interface is built using the Potato annotation tool  (Pei et al., 2022) .\n\nWe then present annotators with news posts public Facebook pages of major UK outlets (see Table  6 ). For each news post screenshot (see Figure  8  for exact question wording), annotators provide five types of responses: Dimensional Emotion Ratings capture valence, arousal, and dominance on a Likert scale of 1-7 using the Self-Assessment Manikin (SAM)  (Bradley and Lang, 1994) . Discrete Emotion Classifications involve categorizing into one of Ekman's basic emotion  (Ekman, 1992) . Modality Influence assesses the relative influence of the image versus the text on their emotional response. Personal Relevance rates the headline's personal relevance. Sharing Likelihood measures the likelihood they would share the post. We randomize the order of the news posts.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Quality Control",
      "text": "We recruit our annotators from Prolific, a platform recognized for having high participant attention and comprehension  (Peer et al., 2022) . To further ensure data quality, we implement several procedural checks.\n\nAnnotators are required to spend at least 2 minutes on the instruction page (enforced by not showing the continuation button until 2 minutes' time). The average time spent reviewing the instructions is 4.67 minutes, suggesting reasonable engagement beyond the minimum requirement.\n\nWe incorporate a comprehension check at the very beginning of the annotation task. Specifically, we present an excerpt from the annotation manual and ask two questions to see whether the annotators can actually understand our task. Those who fail to answer either one correctly are not allowed to proceed.\n\nWe include two attention check questions in our annotation job. Only 7 out of 291 annotators (2.4%) fail either one of these checks, with several contacting us afterward acknowledging their errors. While these annotators are not excluded in the analysis, their IDs are flagged, allowing dataset users to filter them if desired.\n\nTo empirically validate that annotators understand and correctly apply the annotation guidelines and the annotation scales, we include three standardized Affective Norms for English Text (ANET) sentences as calibration items  (Bradley and Lang, 2007)  in the annotation. Comparing our annotators' ratings on these items to the original ANET norms (converted to a 7-point scale) provides a direct measure of their ability to use the SAM scales consistently with the established protocol. Due to ANET licensing restrictions, the specific sentences cannot be disclosed. Table  1  presents a comparison of mean scores and standard deviations.\n\nAs shown in Table  1 , VAD scores from our UKbased annotator pool demonstrate strong correspondence with the original US-based ANET norms for these standardized stimuli. Mean differences are generally minor (typically <0.5 on the 7-point scale). This close alignment indicates that our annotators understand and apply the SAM scales in a manner consistent with established psychometric standards. While minor variations are expected due to demographic differences between our diverse UK sample and the original US university student sample, the overall consistency validates the integrity of our collected affective ratings.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Descriptive Analysis",
      "text": "Our dataset comprises 2,899 annotated news posts, with an average of 5.18 annotations per post from 291 distinct annotators.\n\nAnnotator Demographics Our annotator pool exhibits diversity across gender, political ideology, ethnicity, education levels, and other key demographic variables. Crucially, we have annotators from 97 out of 124 UK postcode areas, ensuring substantial geographic diversity within the UK. See Table  4  for a comprehensive breakdown of annotator characteristics.\n\nDistribution of Annotations Figure  7  presents the distributions of the collected annotation variables. Key observations include: The neutral value (4) is the most frequent for all three dimensions. As expected, the valence scores tend to skew negatively, arousal scores are predominantly high, and dominance scores skew slightly low. For discrete emotions, \"neutral\" is the most commonly selected emotion, followed by \"sad\". Interestingly, the next most frequent emotion is \"happy,\" which is likely due to the limitation of having only one category for positive emotions. Further details, including distributions for relevance, sharing likelihood, and modality influence, are available in Appendix Section A.5.1. Additionally, we analyze interannotator agreement in Section A.6, finding Krippendorff's Î± values comparable to existing emotion annotation datasets, with moderate agreement for valence (Î± = 0.468) and lower agreement for arousal (Î± = 0.145) and dominance (Î± = 0.203).",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Outlet-Level Analysis",
      "text": "We present the summary statistics of affect annotations across news outlets in Table  6 . All outlets are on average more negative content (low valence; with discrete emotions predominantly categorized as either neutral or sad/angry) while maintaining higher-than-neutral levels of arousal. See Section A.5.2 for a comparison between broadsheet and tabloid outlets.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "News Post Characteristics",
      "text": "To analyze the topical composition of news posts, we employ the IPTC NewsCode taxonomy (International Press Telecommunications Council, 2024), a widely-adopted industry standard for news categorization. We choose this established taxonomy over topic modeling given the well-defined nature of news categorization as a task. We classify news post using zeroshot with Gemini 1.5 Pro (prompt in Section A.7). Figure  10  shows the topic distribution, and Figure  11  shows mean arousal per topic. The most frequent categories are arts/culture/entertainment/media (25.4%), crime/law/justice (12.9%), and politics (9.6%). This prevalence of hard news over soft news aligns with prior research on media organizations' social media strategies  (Lamot, 2022)  and platform-specific characteristics of Facebook  (Newman et al., 2015) . As expected, arousal is higher for topics like conflict/war (4.83) and disasters/accidents (4.77) compared to arts/culture (3.85), consistent with previous findings  (Soroka et al., 2019) .",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Regression Analysis",
      "text": "To quantify the influence of individual differences on affective responses, and to assess the effectiveness of our collected persona variables in capturing these differences, we conduct a regression analysis using linear mixed-effects models, focusing on the arousal dimension as a case study (Likert scale, 1-7).\n\nModels We construct three models to systematically decompose the variance in affective responses: (1) a Null Model with only news text as a random effect, serving as our baseline;\n\n(2) a Persona Model adding 47 persona variables as fixed effects while controlling for text effects; and\n\n(3) a User Model incorporating both news text and user ID as random effects to capture all user-level variance, including unobserved individual differences.\n\nWe evaluate each model using both marginal R 2 (variance explained by fixed effects) and conditional R 2 (variance explained by fixed and random effects) show the results in Table  2 .\n\nStrong explanatory power of persona variables. News content alone explains 13.1% of the variance in arousal ratings (null model, conditional R 2 = 0.131). Incorporating our collected persona variables significantly increases the explained variance to 28.6%. This improvement, higher than that observed in existing NLP datasets with annotator characteristics  (Diaz et al., 2018; Hu and Collier, 2024) , underscores the importance of individual differences in modeling subjective phenomena and validates the richness of the persona information collected in iNews.",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "Unobserved Individual Factors Still Matters.",
      "text": "Despite explicitly modeling a comprehensive set of persona variables, the User model explains more variance than the Persona model (0.317 vs. 0.286). This gap suggests the presence of additional unobserved individual factors that modulate affective responses-factors that remain unaccounted for even with our extensive variable collection.\n\nPersona information matter in modeling affective responses. Our findings demonstrate that modeling individual differences is crucial for understanding affective responses to text. The persona variables collected in our iNews dataset capture a large portion of this individual variability, validating our data collection protocol and demonstrating the dataset's value for advancing personalized language technologies. The remaining unexplained variance highlights both the inherent complexity of human affect and the potential for future research to contextualize additional contributing factors.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Qualitative Analysis Of Post-Annotation Questionnaire",
      "text": "To complement our quantitative analysis of persona variables and gain a richer understanding of how individual differences shape emotional responses, we conduct a post-annotation qualitative study. Twenty annotators from our main study complete an open-ended questionnaire (administered via Qualtrics/Prolific), consisting of six open-ended questions probing how readers process and respond to news content (see Section A.9 for questions and expanded analysis).\n\nWe perform a thematic analysis of the responses, employing a systematic coding approach facilitated by an LLM. The analysis reveals insights that help contextualize the individual differences observed in our survey data. For instance, one annotator describe the influence of growing up during the cold war on their emotional responses. Another highlights how their working-class background leads them to be \"kind of numb to some types of news,\" while still emphasizing the emotional impact of \"people getting hurt for no reason.\" The news platform itself emerges as a mediating factor, with one participant stating, \"I don't really buy what I see on Facebook, so it doesn't get to me as much.\" These rich self-narratives, combined with structured per-",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Predicting Individual Affective Arousal",
      "text": "Building on our regression analysis, we now investigate the capacity of current LLMs to predict individual-level affective response. We continue to focus on the emotional arousal dimension as a case study, examining how well models estimate specific annotators' responses under various zero-shot and few-shot conditions.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Experimental Setup",
      "text": "We randomly sample 30 annotators from iNews dataset. For each annotator, we reserve 32 of their annotated posts for potential few-shot demonstrations and utilize the remaining posts (579 samples total) for testing. For evaluation, we employ three complementary metrics that capture different aspects of prediction quality: Mean Absolute Error (MAE) to measure overall prediction accuracy, Exact Accuracy to identify precise matches with annotator ratings, and Â±1 Accuracy (the percentage of predictions falling within one point of the ground truth) to account for the inherent subjectivity in emotional assessment by allowing slight variations.\n\nOur evaluation compares model predictions against each individual annotator's ratings.\n\nWe conduct experiments across seven frontier models, including both API-based models [Gemini 1.5 Pro  (Team et al., 2024) ,  GPT-4o (Hurst et al., 2024 ), Grok-2 (xAI, 2025) ] and open-weight models [Llama-3.2-90B-Vision (Meta AI, 2024a), Qwen2.5-VL-72B-Instruct (QwenLM, 2025), Llama-3.3-70B-Instruct  (Meta AI, 2024b) , Llama-3.1-405B-Instruct  (Meta AI, 2024c) ], with all except the last two capable of processing multimodal inputs. In rare cases where formatting or safety concerns prevents a model from generating a prediction, we assign -1 as the prediction to penalize such behavior. As we decode only a single token for the answer, temperature settings and sampling parameters are not relevant to this process.\n\nWe examine four input conditions. The text-only condition provides a detailed textual description of each news post, while the image-only condition uses the original news screenshot. We then augment each of these base conditions with persona information, creating text-with-persona and imagewith-persona conditions where annotator characteristics are incorporated into the system prompt. Since our annotators originally rated news screenshots, we leverage Gemini 1.5 Pro to generate comprehensive textual descriptions for the text-only conditions, enriching these with headline text and engagement metrics. The complete prompt templates and an illustrative news post image-text pair are provided in Sections A.11 and A.10, respectively. We present our zero-shot evaluation results in Table  3 .\n\nWhile persona variables provide valuable signals for personalization, they inevitably offer an incomplete view of individual preferences and behaviors, as the richness and complexity of human experience extends far beyond what can be captured through demographic and personality questionnaires  (Dong et al., 2024) . We hypothesize that incorporating behavioral data, specifically, an individual's prior annotations, could provide complementary information for modeling affective responses. To test this hypothesis, we conduct k-shot experiments (k âˆˆ {4, 8, 16, 32}) with and without persona information across both text and image modalities. Figure  3  presents the Exact Accuracy results for Gemini 1.5 Pro, our top-performing zeroshot model (complete results in Table  10  and Figure 13 ). Due to resource constraints, we are only able to conduct few-shot experiments with Gemini 1.5 Pro.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Zero-Shot Evaluation",
      "text": "Current LLMs demonstrate reasonable default zero-shot alignment with UK annotators. Without personalization, models achieve seemingly en-couraging baseline performance with Â±1 accuracy exceeding 70%. However, this metric alone can be misleading -a naive predictor that simply outputs the population mean would likely achieve similar Â±1 accuracy given the roughly Gaussian distribution of arousal ratings (see Figure  7 ). The consistently low exact accuracy (< 40%) across all models provides a more stringent evaluation of true personalization capability. This substantial gap between Â±1 and exact accuracy suggests that while models can broadly approximate the range of typical responses, they struggle to capture individual-specific variations in emotional reactions.\n\nIncorporating persona information consistently improves performance. The improvements are particularly large for Gemini 1.5 Pro, where persona information reduces MAE by 11.6% (1.034 â†’ 0.914) for text input and 10.1% (0.936 â†’ 0.841) for image input. These substantial gains demonstrate that current LLMs can effectively leverage explicit persona variables to better simulate individual annotators, validating our persona variable collection strategy. This result aligns with prior work on the effectiveness of persona prompting  (Rescala et al., 2024; Dong et al., 2024; Hu and Collier, 2024) .\n\nImage inputs consistently outperform textual inputs. Our analysis reveals a clear advantage for image-based prediction across all vision-language models except Llama-3.2-90B-Vision. The optimal performance is achieved by Gemini 1.5 Pro with image input and persona information (MAE: 0.841, Â±1 Accuracy: 82.04%), surpassing the best textonly configuration from Llama-3.1-405B-Instruct (MAE: 0.885, Â±1 Accuracy: 81.17%). This superiority of visual inputs aligns with prior working documenting stronger affective responses to images versus text in psychology and communication literature  (Iyer and Oldmeadow, 2006; Powell et al., 2015) . Even our high-quality textual descriptions (example in Section A.10), appear unable to fully capture the affective richness encoded in visual stimuli. This observation is echoed by annotators who report particularly intense emotional reactions to images of suffering or tragedy (see Section A.9.2).\n\nModels exhibit varying degrees of steerability through persona prompting. Gemini 1.5 Pro, Grok-2, Qwen2.5-VL-72B-Instruct and the Llama family show high responsiveness to persona information, while GPT-4o maintains more consistent behavior with and without persona information. This variation suggests fundamental differences in these models' capacity for steerably pluralistic alignment  (Sorensen et al., 2024) .",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Few-Shot Evaluation",
      "text": "Few-shot learning demonstrates a consistent pattern of initial performance degradation followed by gradual recovery. For both text and image modalities, we observe performance drop when transitioning from zero-shot to 4-shot setting. Performance gradually recovers with increasing demonstrations, with text-input models surpassing zero-shot performance at 8 shots (no persona) or 16 shots (with persona), continuing to improve up to 32 shots. However, the image modality shows a sharper initial decline and slower recovery, only matching zero-shot performance at 32 shots for exact accuracy and still lagging in Â±1 Accuracy and MAE. This initial deterioration aligns with the early ascent (in terms of risk) phenomenon in in-context learning  (Lin and Lee, 2024; Agarwal et al., 2024) , where models initially struggle to effectively integrate limited demonstrations. We hypothesize that the inherent subjectivity and noise in emotional arousal annotations may exacerbate this effect, leading to overfitting with sparse examples before models learn to extract robust user-specific patterns.\n\nPersona information provides consistent benefits across few-shot regimes. Even at 32 shot, persona information yields substantial improvements (text: MAE 0.812 â†’ 0.782, accuracy 0.421 â†’ 0.444; image: MAE 0.926 â†’ 0.858, accuracy 0.392 â†’ 0.428). This persistent benefit suggests that explicit persona information captures complementary signals to those learned from demonstration examples. Drawing parallels to recommender systems literature, our few-shot approach is analogous to item-based recommendation, while persona prompting resembles natural-language-based recommendation  [See Sanner et al. (2023)  for an overview]. Our results contribute to this line of research by demonstrating the potential value of hybrid approaches: while past behavior reveals specific preferences, persona information provides a broader context that may not be readily inferable from a limited set of behavioral examples.\n\nImage few-shot prompting scales worse than text, despite zero-shot advantages. While image inputs yield the best zero-shot performance, they exhibit both steeper initial performance degradation and more limited few-shot scaling compared to text inputs. Despite showing consistent improvements with additional demonstrations, image performance does not surpass the zero-shot level even at 32 shots. This pattern likely reflects both the increased complexity of visual processing and limitations of current vision-language models in few-shot learning scenarios. Although images contain the complete information available to human annotators, current VLMs appear unable to fully leverage this rich visual information in few-shot contexts, suggesting an area for future work.  Platform Coverage. We focused our data collection on Facebook posts, as Facebook remains the dominant social media news source in the UK as of 2024  (Ofcom, 2024b) . While platform-specific effects may exist, our findings provide valuable insights into how users engage with news on a major distribution channel. Future work could extend this analysis to other platforms to understand platformspecific effects.\n\nData Quality Although we implemented multiple quality control measures (attention checks, Captcha verification) and used Prolific's platform, which claims to provide 100% genuine human participants 3 , we cannot completely rule out the possibility of AI-generated responses. Our modeling results support the high quality of the collected annotations, though as with any large-scale annotation effort, maintaining perfect attention throughout all responses cannot be guaranteed.",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Ethical Considerations",
      "text": "This study was conducted with the approval of our institutional ethics review board. All annotators provided informed consent before participation and were compensated fairly according to UK National Living Wage. No personally identifiable information was collected in our dataset. To protect participant privacy, we paraphrase open-ended responses quoted in this paper while preserving their essential meaning. During data collection, Prolific IDs were temporarily used to link annotations with persona data, but the publicly released dataset will 3 https://www.prolific.com/participant-pool contain only newly generated, anonymized participant IDs. Given our focus on UK-based annotators and news sources, we recognize the inherent limitations in global generalizability. However, we made conscious efforts to ensure demographic diversity within our annotator pool through Prolific's stratified sampling features. We acknowledge that emotional responses to news can be culturally specific and have thoroughly documented our annotator demographics to enable future researchers to account for potential demographic skews in their analyses. Personality traits are assessed using the BFI-10 scale  (Rammstedt and John, 2007) . For the Perth Emotional Reactivity Scale  (Preece et al., 2018) , we include one question each from four dimensions (negative-activation, negative-intensity, positiveactivation, positive-intensity) due to questionnaire length constraint  (Preece et al., 2018) . Additionally, we include net positive scores calculated from ten items on the Positive and Negative Affect Schedule  (Crawford and Henry, 2004)   Personality traits are assessed using the BFI-10 scale  (Rammstedt and John, 2007) . For the Perth Emotional Reactivity Scale  (Preece et al., 2018) , we include one question each from four dimensions (negative-activation, negative-intensity, positiveactivation, positive-intensity) due to questionnaire length constraint  (Preece et al., 2018) . Additionally, we include net positive scores calculated from ten items on the Positive and Negative Affect Schedule  (Crawford and Henry, 2004)   Personality traits are assessed using the BFI-10 scale  (Rammstedt and John, 2007) . For the Perth Emotional Reactivity Scale  (Preece et al., 2018) , we include one question each from four dimensions (negative-activation, negative-intensity, positiveactivation, positive-intensity) due to questionnaire length constraint  (Preece et al., 2018) . Additionally, we include net positive scores calculated from ten items on the Positive and Negative Affect Schedule  (Crawford and Henry, 2004)   Personality traits are assessed using the BFI-10 scale  (Rammstedt and John, 2007) . For the Perth Emotional Reactivity Scale  (Preece et al., 2018) , we include one question each from four dimensions (negative-activation, negative-intensity, positiveactivation, positive-intensity) due to questionnaire length constraint  (Preece et al., 2018) . Additionally, we include net positive scores calculated from ten items on the Positive and Negative Affect Schedule  (Crawford and Henry, 2004) . Our dataset includes a wide range of persona variables at both group and individual levels.  Personality traits are assessed using the BFI-10 scale  (Rammstedt and John, 2007) . For the Perth Emotional Reactivity Scale  (Preece et al., 2018) , we include one question each from four dimensions (negative-activation, negative-intensity, positiveactivation, positive-intensity) due to questionnaire length constraint  (Preece et al., 2018) . Additionally, we include net positive scores calculated from ten items on the Positive and Negative Affect Schedule  (Crawford and Henry, 2004) . Our dataset includes a wide range of persona variables at both group and individual levels.\n\nExtraversion  Personality traits are assessed using the BFI-10 scale  (Rammstedt and John, 2007) . For the Perth Emotional Reactivity Scale  (Preece et al., 2018) , we include one question each from four dimensions (negative-activation, negative-intensity, positiveactivation, positive-intensity) due to questionnaire length constraint  (Preece et al., 2018) . Additionally, we include net positive scores calculated from ten items on the Positive and Negative Affect Schedule (Crawford and Henry, 2004). Our dataset includes a wide range of persona variables at both group and individual levels.\n\nPerth",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "A.2 Pilot Study: Stimulus Modality Selection",
      "text": "We conducted a pilot study to determine whether to use full Facebook news post screenshots or text-only headlines as stimuli. This decision involves several trade-offs. Text-only stimuli are simpler to process with current language models and sufficient for many breaking news posts that use generic images. However, full screenshots offer greater ecological validity, as social media users typically encounter both text and images simultaneously. Prior research suggests that visual stimuli are processed more rapidly than text  (Azizian et al., 2006)  and are more memorable  (Shepard, 1967) , though current open-source vision-language models still face significant performance and robustness challenges  (Li et al., 2024; Sterz et al., 2024) .\n\nTo empirically inform this decision, we collect annotations from 40 UK-based participants (20 per condition) for 10 paired news posts from March 2024, present either as textonly headlines or full screenshots. Participants rated valence, arousal, and dominance (VAD) and provide discrete emotion categories.\n\nWe then analyze the aggregated ratings across all 10 posts for each condition. Table  5  presents the descriptive and inferential statistics for the dimensional emotions (VAD). Mann-Whitney U tests indicate significant differences in valence (p = 0.016) and dominance (p = 0.019), though with small effect sizes (RBC ranging from -0.032 to -0.136). For discrete emotions, a chi-square test indicates marginally significant differences in emotion distribution between conditions (Ï‡ 2 = 14.93, p = 0.060). We additionally visually show the distribution of VAD and discrete ratings in Figures  4  and 5 .\n\nThe distribution patterns of VAD and discrete ratings are visualized in Figures  4  and 5 . While VAD distributions remain broadly similar across conditions, the image condition elicits more negative valence ratings and more neutral dominance ratings. The differences in discrete emotion ratings are more noticeable, with substantially fewer neutral emotions reported in the image condition. We interpret this as evidence that images help disambiguate emotional content -since the image condition includes both visual and textual information, it may provide richer context for emotional interpretation.\n\nBased on these findings and theoretical considerations, we decide to use full screenshots for our main study. This choice is driven by observed differences in emotional annotations, the ecological validity of multimodal news consumption on social media, and the additional contextual information provided by images. While current vision-language models face technical limitations, we anticipate rapid advancement in multimodal processing capabilities and prioritize capturing more naturalistic news consumption experiences over immediate computational convenience.",
      "page_start": 21,
      "page_end": 22
    },
    {
      "section_name": "A.3 Geographic Representation Of Annotators",
      "text": "We present the geographic distribution of annotators across UK postcode areas in Figure  6 . Our dataset includes annotators from 97 of the 124 postcode areas in the UK, demonstrating broad geographical coverage. To assess the representativeness of our sample, we compute the Pearson correlation coefficient between the number of annotators per postcode area and the corresponding 2011 Census population figures.\n\nThe resulting correlation of 0.662 indicates a moderate positive relationship between population density and annotator distribution. To further quantify geographic representation, we calculate a representativeness ratio for each postcode area by dividing the percentage of annotators in each area by the percentage of the UK population in that same area. The mean ratio of 1.26 indicates that most areas are well-represented, often exceeding proportional representation. While there is some variation (standard deviation of 1.05 and median of 0.95), the overall distribution suggests we achieved strong geographic diversity in our sample.",
      "page_start": 21,
      "page_end": 21
    },
    {
      "section_name": "Number Of Annotators",
      "text": "",
      "page_start": 21,
      "page_end": 21
    },
    {
      "section_name": "Introduction",
      "text": "Thank you very much for participating in this academic study. In this study, we would like to ask you to describe your emotion after seeing a news headline (or a brief sentence). We will first give you an instruction and then present some examples. While we will provide some examples below for your reference, it is reflective of someone else's emotional experience and please report your own intuitive emotional response after seeing the news headline. Please don't try to analyse the headline, report your intuitive feeling and proceed at a fast pace and don't overthink.\n\nInstruction SAM Below, you can see three rows of figures which we call SAM. SAM shows three different kinds of feelings: negative vs. positive (\"Pleasure\"), calm vs. active (\"Arousal\") and weak vs. strong (\"Control\"). You will be using three independent multiple-choice scales (corresponding to these three panels below) to indicate your emotion after reading each news title.\n\nThe first panel shows the positive-negative (pleasure) scale, which ranges from a frown on the left Please, take a moment to familiarise yourself with the pictograms of the Control scale.",
      "page_start": 22,
      "page_end": 23
    },
    {
      "section_name": "Discrete Emotions",
      "text": "You will additionally be asked to choose your most salient emotion in terms of the following options.",
      "page_start": 23,
      "page_end": 23
    },
    {
      "section_name": "Additional Annotation Distributions Analysis",
      "text": "We show the distributions of the collected annotation variables in Figure  7 . In addition to the discussions in Section 4, regarding relevance (Figure  7e ), almost half of the annotations (44%) indicate \"Not at all\" relevant, with only 3.8% marked as \"extremely relevant.\" For sharing inclination (Figure  7f ), the distribution is even more skewed, with 54.5% of the annotations indicating \"very unlikely\" to share. The majority of annotations (52.3%, Figure  7g ) suggest that both the text and image significantly influence emotional reactions to news headlines. In contrast, approximately a third (36.7%) highlight the text alone as the primary factor. This indicates the importance of considering both the image and the text when modeling affective responses to news headlines on social media, rather than focusing solely on one or the other.",
      "page_start": 30,
      "page_end": 30
    },
    {
      "section_name": "A.5.2 Outlet-Level Analysis",
      "text": "To examine the traditional distinction between broadsheet and tabloid publications 4  , we conduct Welch's t-tests comparing their affect scores. Interestingly, we find no significant differences in valence (p = 0.83) or dominance (p = 0.64) between the two types of outlets. However, there is a marginally significant difference in arousal (p = 0.052), with broadsheet publications eliciting slightly higher arousal responses (M = 4.34) compared to tabloids (M = 4.09). While the digital transformation of news media might have blurred many traditional distinctions between tabloids and broadsheets, these findings suggest that different editorial standards may still influence readers' affective responses, particularly in terms of emotional arousal.",
      "page_start": 30,
      "page_end": 30
    },
    {
      "section_name": "A.5.3 Relationship Between Arousal And Valence",
      "text": "We calculate the average valence and arousal for each headline and present the results in Figure  9 . Point opacity indicates overlapping points, suggesting a higher density of images.\n\nThe distribution follows a V-shaped pattern, where arousal levels are high at both low and high extremes of valence, and this pattern aligns with established findings in affective science  (Lang et al., 1997; Kurdi et al., 2017) . However, our data also present notable deviations. Specifically, we observe a higher concentration of headlines exhibiting elevated arousal levels (above 6) in both the first and second quadrants (low valence/high arousal and high valence/high arousal, respectively). This concentration is particularly pronounced in the second quadrant, characterized by very low valence and very high arousal. We also see a concentration of density along the central region, around arousal â‰ˆ 4 and valence â‰ˆ 4, with a slight skew towards the upper-left quadrant. Finally, the overall distribution in our dataset encompasses a broader region of the valence-arousal space compared to that of  Kurdi et al. (2017) . We hypothesize that this discrepancy arises from the inherently negative nature of news headlines, in contrast to the more emotionally diverse stimuli typically employed in prior studies comprising images of scenes and objects.",
      "page_start": 30,
      "page_end": 30
    },
    {
      "section_name": "A.6 Inter-Annotator Agreement",
      "text": "We measure Krippendorff's Î± for each of the annotated variables and present the results in Table  7 . Among the core emotional dimensions, valence shows moderate agreement (Î± = 0.468), while arousal and dominance exhibit lower agreement levels (Î± = 0.145 and Î± = 0.203, respectively). Discrete emotion categories demonstrate comparable levels of agreement. The auxiliary variables-modality importance, relevance, and sharing intent-show particularly low agreement (Î± < 0.1). These findings align with previous research in emotion and affect annotation. The relatively low inter-annotator agreement is consistent with similar datasets  (Strapparava and Mihalcea, 2007; Busso et al., 2008; Demszky et al., 2020; OberlÃ¤nder et al., 2020) , and the pattern of higher agreement for valence compared to arousal and dominance mirrors observations in prior work  (Busso et al., 2008; Buechel and Hahn, 2017) . These low agreement levels highlight a crucial insight: emotional responses to news content are inherently subjective and individualized. This observation strengthens our argument for modeling personalized affective responses rather than pursuing consensus annotations.",
      "page_start": 31,
      "page_end": 31
    },
    {
      "section_name": "A.7 Topic Classification Details",
      "text": "We apply the following prompt in JSON mode with the gemini-1.5-pro endpoint. -politics: Local, regional, national and international exercise of power, or struggle for power, and the relationships between governing bodies and states.",
      "page_start": 33,
      "page_end": 33
    },
    {
      "section_name": "A.8 Regression Analysis Details",
      "text": "This section provides additional details on the regression models used in the main text (Section 5), including full model specifications, results for additional models, and a discussion of variable importance.",
      "page_start": 35,
      "page_end": 35
    },
    {
      "section_name": "Model Specifications And Estimation",
      "text": "We employ linear mixed-effects models (LMMs) to analyze the influence of persona variables and other factors on annotators' arousal ratings. LMMs are appropriate for this analysis because they account for the nested structure of the data (multiple annotations per news post and per annotator) and allow for both fixed effects (e.g., persona variables) and random effects (e.g., individual differences between annotators and news posts). All models are estimated using the lme4 package  (Bates et al., 2015)  in R. The dependent variable in all models is the annotator's arousal rating for a given news post (ranging from 1 to 7).\n\nThe following models are estimated in the main text in Section 5:\n\n1. Null Model: Baseline model with only a random intercept for news text.\n\n2. Persona Model: Includes 47 persona variables as fixed effects and a random intercept for news text.",
      "page_start": 36,
      "page_end": 36
    },
    {
      "section_name": "Arousal ~Personavariables + (1 | Text)",
      "text": "where PersonaVariables represents the full set of 47 persona variables.\n\n3. User Model: Includes random intercepts for both news text and annotator ID.\n\nAdditional Models To explore the contributions of other contexual factors, we estimate these additional models:\n\n4. Outlet Model: Adds news outlet as a fixed effect.",
      "page_start": 35,
      "page_end": 35
    },
    {
      "section_name": "Arousal ~Personavariables + Outlet",
      "text": "",
      "page_start": 35,
      "page_end": 35
    },
    {
      "section_name": "Full Regression Results",
      "text": "Table  8  presents the full results for all models, including marginal and conditional R 2 values, calculated using the method described by  Nakagawa and Schielzeth (2013) .\n\nVariable Importance What are the most important persona variables? Is it more the case that some specific persona variables explain the vast majority of variance or is it rather spread out across all variables? To answer this question, we analyze the Persona model and calculated the Eta-squared (Î· 2 ), a commonly used measure representing the proportion of the total variance in the dependent variable accounted for by a given independent variable. The calculations are performed using the effectsize package (Ben-Shachar et al., 2020) in R.\n\nBased on effect sizes, the individual contributions of the persona variables to explaining variance in arousal are generally modest. The majority of persona variables have small effect sizes, below 0.005. We show the top 10 persona variable with highest effect sizes in Table  9 . Despite this overall trend, a subset of variables exhibit somewhat larger effect sizes. These included factors related to socioeconomic status, such as personal income (Î· 2 = 0.010) and education level (Î· 2 = 0.008), as well as employment status (Î· 2 = 0.008). Personality traits also demonstrate notable influence, particularly Agreeableness (Î· 2 = 0.009) and Neuroticism (Î· 2 = 0.008). Among media consumption patterns, television viewing habits stand out (Î· 2 = 0.008), while current emotional state also show meaningful effects (Î· 2 = 0.007).\n\nThese findings suggest that while the regression model as a whole demonstrates a reasonable ability to predict arousal (as indicated by the R 2 values discussed previously), the influence of individual persona variables is, for the most part, limited. The observed model fit likely stems from the cumulative effect of numerous variables with small individual contributions. This pattern aligns with the complex, multifaceted nature of affective responses to news content, where multiple personal characteristics interact to shape individual reactions (also see the quantitative interview analysis in Section A.9. The distributed nature of these effects underscores the importance of considering a broad spectrum of persona variables in modeling affective responses, rather than focusing on a limited set of characteristics.",
      "page_start": 36,
      "page_end": 36
    },
    {
      "section_name": "Analysis Of Content And Behavioral Effects",
      "text": "While our analyses in the main paper focus on modeling individual differences through user-level variables, our dataset contains rich metadata about the content itself: news topics, headline image categories (see Section A.7), and source outlets. We also collected calibration data by having annotators respond to three standardized items from the ANET dataset. To understand the relative importance of these factors, we first The Outlet and Topic models, which incorporate static content features, achieve similar total explanatory power (conditional R 2 ) to the Persona model but with higher fixed-effect contributions (marginal R 2 ). This suggests these contentbased features capture some of the variance previously attributed to random effects, without improving overall prediction. In contrast, the Calibration model shows higher total explanatory power (R 2 = 0.328 vs. 0.286), indicating that annotators' annotation behavior on the calibration items may potentially capture variance unexplained by our carefully selected persona variables.\n\nThe All model, despite incorporating numerous fixed effects, maintains approximately the same conditional R 2 as the Calibration model. However, it demonstrates a substantial shift in R 2 distribution, with marginal R 2 reaching 0.261-exceptional for annotator modeling in NLP  (Hu and Collier, 2024) . Notably, we achieve better conditional R 2 compared to the User model (random-effects only), which only includes random intercepts for text stimuli. This improvement likely stems from two factors: first, the inherently conservative nature of random-effects fitting, which employs regularization to prevent overfitting; and second, random effects' limitation in capturing structural information within the data. While random effects excel at modeling individual-level variation, they treat such variation as purely stochastic, potentially overlooking systematic patterns that our comprehensive set of fixed effects can capture. Our results demonstrate that affective responses to news content, though complex, exhibit structural patterns that can be systematically modeled through carefully selected persona variables, including demographic characteristics, psychological traits, and news consumption behaviors.",
      "page_start": 35,
      "page_end": 36
    },
    {
      "section_name": "Analysis Of User Random Effects",
      "text": "Given the previous results, we then investigate whether adding user-level random effects benefits models with rich fixed effects. In theory, perfect fixed effects would eliminate the need for user-level random effects. In practice, however, adding user-level random effects improves model fit for both the Persona (Personal + User model) and All (All + User model) models, though with diminishing returns. The improvement is smaller for the All model (âˆ† = 0.057) compared to the Persona model (âˆ† = 0.091), suggesting we may be approaching a ceiling for random effects gains. This asymptotic behavior indicates that while better fixed effects reduce the potential contribution of random effects, our current setup has not yet exhausted all relevant fixed effect variables, leaving room for future data collection and modeling improvements.",
      "page_start": 37,
      "page_end": 37
    },
    {
      "section_name": "Discussion Of Regression Results",
      "text": "Our findings connect to a fundamental question in psychology: do people's reactions come from who they are  (their personality, beliefs, demographics)  or from what they're responding to (in our case, the news content)? Our results indicate both, support-ing an interactionist perspective  (Mischel and Shoda, 1995)  person-level variables and stimulus (the news posts) both contribute meaningfully to explaining affective responses, with their combination yielding higher explanatory power.\n\nThe persistent benefit of including user-level random effects, even in our most comprehensive model (âˆ†R 2 = 0.057 ), aligns with contemporary personality theory  (Fleeson and Jayawickreme, 2015)  which conceptualizes individual differences through density distributions. This framework suggests that while considerable behavioral variability exists within each individual, the parameters of these distributions may be stable across. In our case, this means that while a person's affective responses to news may vary substantially across different stories, their pattern of variation itself could be characteristic and predictable. This theoretical perspective helps explain why both fixed effects (capturing systematic individual differences) and random effects (accounting for personspecific response patterns) contribute uniquely to our model's predictive power.",
      "page_start": 38,
      "page_end": 38
    },
    {
      "section_name": "A.9 Post-Annotation Questionnaire",
      "text": "To better understand how annotators approached the task and complement the quantitative analysis of persona variables, we conduct a post-annotation qualitative study using a detailed questionnaire. The questionnaire is shown below. Following the questionnaire, we present an in-depth analysis of the responses for each question. A.9.1 Q1\n\nRegarding the influence of personal background (Q1), annotators demonstrate a keen awareness of how factors including age and lived experiences, political affiliations, educational background, media literacy and consumption habits and personal values shape their emotional processing of news. For instance, one annotator reflects on how their generation's ex-perience during the cold war impacts their reactions to current events, stating that they \"get this pit in my stomach when I read these stories\" due to specific events experienced during their lifetime, which differs from the experiences of younger people. Another annotator emphasizes the impact of political views on their emotional responses, noting that they feel \"really frustrated and annoyed\" towards content that conflicted with their political ideology. These examples illustrate how personal history and deeply held beliefs create unique perspectives and biases, coloring readers' emotional engagement with the news. Additionally, many annotators report becoming desensitized due to constant exposure to negative news and recognized modern phenomena like clickbait. There is a notable awareness of how different news sources operate, with some annotators expressing inherent distrust of certain outlets.",
      "page_start": 37,
      "page_end": 38
    },
    {
      "section_name": "A.9.2 Q2",
      "text": "When analyzing the types of headlines that elicit stronger responses (RQ2), we observe a clear distinction between contentdriven and presentation-driven factors. Regarding content, annotators consistently identify news related to harm, suffering, and threats to vulnerable populations as powerful emotional triggers. One annotator's comment captures this pattern: \"I really feel it more when the story is about people getting hurt, especially when it's kids or families.\" Contemporary societal issues also generate intense responses, with annotators citing topics such as COVID-19, immigration, healthcare systems, and international conflicts. Personal relevance emerges as another crucial content factor, with annotators responding more intensely to news that mirrors their experiences or aligns with their values. As one annotator puts it: \"when it's something I've been through myself, or it reminds me of my own family, it really gets to me.\"\n\nIn terms of presentation, visual elements significantly influence emotional intensity. Multiple annotators report that headlines accompanied by images, especially those depicting suffering or tragedy, elicit stronger emotional reactions, with some finding certain visual content overwhelming. This finding validates our research design's inclusion of complete news post screenshots rather than headlines alone. Source credibility also shapes emotional engagement, with annotators expressing greater trust in established news sources (e.g., BBC) compared to social media, and demonstrating skepticism toward tabloids and sensationalized content.",
      "page_start": 37,
      "page_end": 38
    },
    {
      "section_name": "A.9.3 Q3",
      "text": "In exploring potential differences between their responses and those of the \"general public\" (Q3), responses mention both universality and divergence. While there is acknowledgment of shared emotional ground, particularly regarding responses to tragedy, suffering, and social norm violations, these mentions are often qualified by extensive discussion of individual variations. A strong theme emerges around the recognition of response variability, with one annotator articulating that \"everyone's got their own way of feeling about things -you can't expect two people to react exactly the same.\" Participants frequently discuss how their personal characteristics -including educational background, socioeconomic status, professional experience, and neurodiversity -shape their responses. Many believe their reactions deviate from the perceived norm, either describing themselves as more analytical compared to a generally more \"empathetic\" public, or reporting stronger emotional engagement than average. Notably, several participants challenge the very concept of a \"general public,\" emphasizing the diversity of perspectives and questioning such generalizations, with one observing that readers of certain newspapers are \"conditioned\" to react with greater anger to headlines.",
      "page_start": 37,
      "page_end": 37
    },
    {
      "section_name": "A.9.4 Q4",
      "text": "When asked about the influence of their media consumption habits (Q4), an interesting disconnect emerges. Many annotators explicitly state that their media consumption patterns do not affect their responses, yet their explanations reveal deepseated attitudes toward different news sources. This apparent contradiction stems from annotators viewing their skepticism toward certain platforms and outlets not as a \"consumption pattern\" but as a fundamental approach to information processing. Many annotators express a high degree of distrust towards social media platforms such as Facebook as a primary news source and towards tabloid outlets, contrasting these with more trusted, traditional sources like the BBC. One annotator, highlighting their distrust of certain outlets, states that they avoid tabloids because they are \"just nonsense really, proper biased\" while another express a general suspicion of Facebook posts, viewing the platform as more for social interaction than trustworthy news. However, they do not view these preferences as biasing their responses, but rather as applying consistent critical evaluation. Additionally, annotators broadly fall into two groups regarding their approach to source evaluation. The first group reports that source credibility significantly influence their emotional engagement, with one noting they \"don't get as worked up about stories from dodgy sources.\" The second group emphasizes prioritizing content over source, with one explaining they \"only consider the content, not the publisher.\"\n\nA.9.5 Q5\n\nReflecting on the most salient factors shaping their emotional responses (Q5), annotators frequently emphasize an interplay of several key elements. Personal background such as upbringing and professional experience emerge as particularly important. Similar numbers of annotations mention news content, with annotators particularly responsive to stories involving injustice, vulnerable populations (especially children), and issues of immediate personal relevance. One annotator powerfully illustrate this interaction between these two factors, explaining how \"growing up working class\" might have instilled a certain resilience, yet emphasizing that this does not diminish their emotional response to the suffering of innocent individuals, especially children. The perceived credibility of news sources is also a factor, with one annotator articulating how \"I take proper news sources more seriously.\" The presentation style of news content -including emotional language, imagery, and formatting -also influence responses, with several annotators demonstrating awareness of \"sensationalised\" content and clickbait tactics. Notably, these factors often operate interactively rather than in isolation.",
      "page_start": 38,
      "page_end": 38
    },
    {
      "section_name": "A.9.6 Q6",
      "text": "Finally, when considering their experience with the annotation task itself (Q6), many annotators report that the task heighten their awareness of emotional responses to news. Some note that the annotation process make them more consciously aware of their emotional responses, prompting deeper reflection on the quality and factual nature of the news. As one annotator puts it, \"I found myself properly thinking about how each story affected me.\" Participants frequently discuss their news evaluation strategies, considering multiple factors including source credibility, visual elements, and headline framing. Notably, contrary to common assumptions about social media engagement, many annotators express reluctance to share news on social platforms, with one annotator stating that they \"don't share news on social media at all.\"\n\nThe responses reveal important individual differences in emotional engagement with news. Some annotators, particularly those identifying as neurodivergent, describe carefully managing their emotional engagement to avoid exhaustion, noting that news stories can trigger intense, lasting emotional responses. Others report preferring to reserve emotional energy for personal relationships rather than news content. Content preferences emerge as another key theme, with participants expressing greater interest in positive news, scientific developments, and locally relevant stories, while showing less engagement with celebrity news or sensationalized content.",
      "page_start": 38,
      "page_end": 38
    },
    {
      "section_name": "A.9.7 Methodological Limitation",
      "text": "While our qualitative analysis provides valuable insights, several methodological limitations warrant discussion. First, resource constraints necessitate written questionnaires rather than in-depth interviews, potentially limiting the nuance and richness of responses. Second, the opt-in nature of the interview participation may introduce selection bias, as annotators willing to provide detailed written responses might not fully represent our broader annotator population. Third, since the interviews are conducted after both the main annotation task and the persona variable survey, participants' responses might have been influenced by these prior experiences.\n\nThese design elements ultimately strengthen rather than compromise our findings. The post-task timing of the interviews prove advantageous, allowing annotators to develop more nuanced reflections on their annotation process and emotional responses. While our participants may represent more engaged annotators, their detailed accounts provide exactly the kind of rich, experiential data needed to complement our structured persona variables. The qualitative insights thus serve their intended purpose: providing crucial context that enriches our understanding of the quantitative patterns observed in our regression analysis.",
      "page_start": 38,
      "page_end": 38
    },
    {
      "section_name": "A.10 Example Image Textual Description",
      "text": "We show an example news post as well as the textual description generated with the prompt in A.7. The image shows a small shark being held by a person wearing gloves. The shark is facing the camera and appears to be alive. The person holding the shark is slightly out of focus, with only the lower part of their face and body visible. The background is a blurry expanse of ocean. The BBC News logo is overlaid on the bottom left corner of the image. The text and image work together to tell the story of sharks testing positive for cocaine off the coast of Brazil. The image provides a visual representation of the subject matter, while the text gives context and further information. The visual element that grabs attention is the shark itself. Its size and proximity to the camera create a sense of immediacy and make the story feel more tangible. The contrast between the small, seemingly harmless shark and the serious implications of it testing positive for cocaine adds a layer of complexity to the image.",
      "page_start": 38,
      "page_end": 38
    },
    {
      "section_name": "A.11 Predicting Individual Affective Arousal Prompt",
      "text": "For textual input: System prompt (for the condition with persona);",
      "page_start": 39,
      "page_end": 39
    },
    {
      "section_name": "â†’",
      "text": "If few-shot: messages.append(\"role\": \"user\", \"content\": {headline_input}) â†’ messages.append({\"role\": \"assistant\", \"content\": {label}) â†’ messages.append({\"role\": \"user\", \"content\": {headline_input})",
      "page_start": 40,
      "page_end": 40
    },
    {
      "section_name": "â†’",
      "text": "For image-input condition, the prompt is the same except that the post-specific textual description is replaced by the news post screenshot.",
      "page_start": 39,
      "page_end": 39
    },
    {
      "section_name": "A.12 Additional Few-Shot Learning Results",
      "text": "We present additional few-shot results in",
      "page_start": 39,
      "page_end": 39
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Overview of the data collection process. The process involves three main stages: (1) we recruit",
      "page": 2
    },
    {
      "caption": "Figure 1: ). Our dataset com-",
      "page": 2
    },
    {
      "caption": "Figure 2: ). These phases are: Phase 1 (April 1-20),",
      "page": 3
    },
    {
      "caption": "Figure 2: Data collection timeline, with the 2024 UK",
      "page": 4
    },
    {
      "caption": "Figure 6: and Table 4 for details). Each of the",
      "page": 4
    },
    {
      "caption": "Figure 8: for exact question wording), annotators provide",
      "page": 4
    },
    {
      "caption": "Figure 10: shows the topic distribution, and Fig-",
      "page": 5
    },
    {
      "caption": "Figure 3: presents the Exact Accuracy",
      "page": 7
    },
    {
      "caption": "Figure 7: ). The consis-",
      "page": 8
    },
    {
      "caption": "Figure 3: Few-shot learning performance, measured by",
      "page": 9
    },
    {
      "caption": "Figure 4: Distribution of VAD scores across modality",
      "page": 21
    },
    {
      "caption": "Figure 6: Our dataset includes anno-",
      "page": 21
    },
    {
      "caption": "Figure 6: Geographic distribution of annotators across",
      "page": 21
    },
    {
      "caption": "Figure 5: Distribution of discrete emotions across",
      "page": 30
    },
    {
      "caption": "Figure 7: In addition to the discussions in Section 4, re-",
      "page": 30
    },
    {
      "caption": "Figure 7: e), almost half of the annotations",
      "page": 30
    },
    {
      "caption": "Figure 7: g) suggest",
      "page": 30
    },
    {
      "caption": "Figure 9: Point opacity indicates",
      "page": 30
    },
    {
      "caption": "Figure 7: Distribution of Annotations",
      "page": 31
    },
    {
      "caption": "Figure 8: A screenshot of the annotation interface.",
      "page": 32
    },
    {
      "caption": "Figure 9: Distribution of affective responses to news",
      "page": 33
    },
    {
      "caption": "Figure 10: Distribution of news articles across topic categories.",
      "page": 34
    },
    {
      "caption": "Figure 11: Average arousal scores by topic category, with error bars indicating one standard deviation from the",
      "page": 34
    },
    {
      "caption": "Figure 12: An example news headline.",
      "page": 38
    },
    {
      "caption": "Figure 13: Few-shot learning performance, measured by MAE, exact match accuracy (%), and Â±1 accuracy (%), as",
      "page": 41
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "1. On a scale of 1 (very clam) -7 (very active),\nhow calm vs. active do you feel after reading\nthis news (Arousal)?",
          "Column_2": ""
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "",
          "Modali\nText\nImage": "Person\nNo Per\nWith P",
          "ty": "a\nsona\nersona",
          "Column_4": "",
          "Column_5": "",
          "Column_6": ""
        }
      ],
      "page": 9
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "18-24yearsold": "25-34yearsold",
          "23": "89",
          "Column_3": "",
          "Column_4": "",
          "7.9%": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "30.6%"
        },
        {
          "18-24yearsold": "35-44yearsold",
          "23": "77",
          "Column_3": "",
          "Column_4": "",
          "7.9%": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "26.5%",
          "Column_9": ""
        },
        {
          "18-24yearsold": "45-54yearsold",
          "23": "49",
          "Column_3": "",
          "Column_4": "",
          "7.9%": "",
          "Column_6": "",
          "Column_7": "16.8%",
          "Column_8": "",
          "Column_9": ""
        },
        {
          "18-24yearsold": "55-64yearsold",
          "23": "37",
          "Column_3": "",
          "Column_4": "",
          "7.9%": "",
          "Column_6": "12.7%",
          "Column_7": "",
          "Column_8": "",
          "Column_9": ""
        },
        {
          "18-24yearsold": "65+yearsold",
          "23": "16",
          "Column_3": "",
          "Column_4": "",
          "7.9%": "5.5%",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": ""
        }
      ],
      "page": 14
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "Male": "Female",
          "152": "139",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "47.8%",
          "52.2%": ""
        }
      ],
      "page": 14
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "Yes": "No",
          "253": "38",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "13.1%",
          "86.9%": ""
        }
      ],
      "page": 14
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "White": "Mixed",
          "239": "20",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "6.9%",
          "82.1%": ""
        },
        {
          "White": "Asian",
          "239": "17",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "5.8%",
          "82.1%": ""
        },
        {
          "White": "Black",
          "239": "15",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "5.2%",
          "82.1%": ""
        }
      ],
      "page": 14
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "LessthanÂ£10,000": "Â£10,000-Â£19,999",
          "57": "60",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "",
          "19.6%": "20.6%",
          "Column_8": ""
        },
        {
          "LessthanÂ£10,000": "Â£20,000-Â£29,999",
          "57": "72",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "",
          "19.6%": "",
          "Column_8": "24.7%"
        },
        {
          "LessthanÂ£10,000": "Â£30,000-Â£39,999",
          "57": "49",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "16.8%",
          "19.6%": "",
          "Column_8": ""
        },
        {
          "LessthanÂ£10,000": "Â£40,000-Â£49,999",
          "57": "24",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "8.25%",
          "Column_6": "",
          "19.6%": "",
          "Column_8": ""
        },
        {
          "LessthanÂ£10,000": "Â£50,000-Â£59,999",
          "57": "12",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "4.12%",
          "Column_6": "",
          "19.6%": "",
          "Column_8": ""
        },
        {
          "LessthanÂ£10,000": "Â£60,000-Â£69,999",
          "57": "6",
          "Column_3": "",
          "Column_4": "2.06%",
          "Column_5": "",
          "Column_6": "",
          "19.6%": "",
          "Column_8": ""
        },
        {
          "LessthanÂ£10,000": "Â£70,000-Â£79,999",
          "57": "3",
          "Column_3": "",
          "Column_4": "1.03%",
          "Column_5": "",
          "Column_6": "",
          "19.6%": "",
          "Column_8": ""
        },
        {
          "LessthanÂ£10,000": "Â£80,000-Â£89,999",
          "57": "5",
          "Column_3": "",
          "Column_4": "1.72%",
          "Column_5": "",
          "Column_6": "",
          "19.6%": "",
          "Column_8": ""
        },
        {
          "LessthanÂ£10,000": "Â£90,000-Â£99,999",
          "57": "2",
          "Column_3": "",
          "Column_4": "0.687%",
          "Column_5": "",
          "Column_6": "",
          "19.6%": "",
          "Column_8": ""
        },
        {
          "LessthanÂ£10,000": "MorethanÂ£150,000",
          "57": "1",
          "Column_3": "0.344%",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "",
          "19.6%": "",
          "Column_8": ""
        }
      ],
      "page": 14
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "Noformalqualifications": "Secondaryeducation(e.g.GED/GCSE)",
          "3": "24",
          "Column_3": "",
          "1.03%": "",
          "Column_5": "8.25%",
          "Column_6": "",
          "Column_7": "",
          "Column_8": ""
        },
        {
          "Noformalqualifications": "Highschooldiploma/A-levels",
          "3": "49",
          "Column_3": "",
          "1.03%": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "16.8%",
          "Column_8": ""
        },
        {
          "Noformalqualifications": "Technical/communitycollege",
          "3": "38",
          "Column_3": "",
          "1.03%": "",
          "Column_5": "",
          "Column_6": "13.1%",
          "Column_7": "",
          "Column_8": ""
        },
        {
          "Noformalqualifications": "Undergraduatedegree(BA/BSc/other)",
          "3": "124",
          "Column_3": "",
          "1.03%": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "42.6%"
        },
        {
          "Noformalqualifications": "Graduatedegree(MA/MSc/MPhil/other)",
          "3": "49",
          "Column_3": "",
          "1.03%": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "16.8%",
          "Column_8": ""
        },
        {
          "Noformalqualifications": "Doctoratedegree(PhD/other)",
          "3": "4",
          "Column_3": "",
          "1.03%": "1.37%",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": ""
        }
      ],
      "page": 14
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "Yes": "No",
          "34": "246",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "11.7%": "",
          "Column_7": "84.5%"
        },
        {
          "Yes": "DATAEXPIRED",
          "34": "11",
          "Column_3": "",
          "Column_4": "3",
          "Column_5": ".8%",
          "11.7%": "",
          "Column_7": ""
        }
      ],
      "page": 14
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "Duetostartanewjobwithinthenextmonth": "Other",
          "3": "6",
          "Column_3": "",
          "1.03%": "2.06%"
        }
      ],
      "page": 14
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "DATAEXPIRED": "Unemployed(andjobseeking)",
          "12": "13",
          "Column_3": "",
          "4.12%": "4.47%",
          "Column_5": "",
          "Column_6": ""
        },
        {
          "DATAEXPIRED": "Not in paid work (e.g. homemaker, retired or\ndisabled)",
          "12": "36",
          "Column_3": "12.4%",
          "4.12%": "",
          "Column_5": "",
          "Column_6": ""
        },
        {
          "DATAEXPIRED": "Part-Time",
          "12": "50",
          "Column_3": "",
          "4.12%": "",
          "Column_5": "17.2%",
          "Column_6": ""
        },
        {
          "DATAEXPIRED": "Full-Time",
          "12": "171",
          "Column_3": "",
          "4.12%": "",
          "Column_5": "",
          "Column_6": "58.8%"
        }
      ],
      "page": 15
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "England": "Scotland",
          "232": "30",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "10.3%",
          "79.7%": ""
        },
        {
          "England": "Wales",
          "232": "18",
          "Column_3": "",
          "Column_4": "6.19%",
          "Column_5": "",
          "79.7%": ""
        },
        {
          "England": "NorthernIreland",
          "232": "11",
          "Column_3": "",
          "Column_4": "3.78%",
          "Column_5": "",
          "79.7%": ""
        }
      ],
      "page": 15
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "Centre": "Right",
          "118": "84",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "28.9%",
          "40.5%": ""
        },
        {
          "Centre": "Left",
          "118": "82",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "28.2%",
          "40.5%": ""
        },
        {
          "Centre": "DATAEXPIRED",
          "118": "7",
          "Column_3": "",
          "Column_4": "2.4%",
          "Column_5": "",
          "40.5%": ""
        }
      ],
      "page": 15
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "Notatallinterested": "Notveryinterested",
          "3": "30",
          "Column_3": "",
          "1.03%": "",
          "Column_5": "10.3%",
          "Column_6": "",
          "Column_7": "",
          "Column_8": ""
        },
        {
          "Notatallinterested": "Somewhatinterested",
          "3": "113",
          "Column_3": "",
          "1.03%": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "38.8%"
        },
        {
          "Notatallinterested": "Veryinterested",
          "3": "102",
          "Column_3": "",
          "1.03%": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "35.1%",
          "Column_8": ""
        },
        {
          "Notatallinterested": "Extremelyinterested",
          "3": "43",
          "Column_3": "",
          "1.03%": "",
          "Column_5": "",
          "Column_6": "14.8%",
          "Column_7": "",
          "Column_8": ""
        }
      ],
      "page": 15
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "Lessthan15minutes": "15minutestolessthan30minutes",
          "14": "45",
          "Column_3": "",
          "4.81%": "",
          "Column_5": "15.5%",
          "Column_6": "",
          "Column_7": "",
          "Column_8": ""
        },
        {
          "Lessthan15minutes": "30minutestolessthan1hour",
          "14": "94",
          "Column_3": "",
          "4.81%": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "32.3%"
        },
        {
          "Lessthan15minutes": "1hourtolessthan2hours",
          "14": "77",
          "Column_3": "",
          "4.81%": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "26.5%",
          "Column_8": ""
        },
        {
          "Lessthan15minutes": "2hoursormore",
          "14": "61",
          "Column_3": "",
          "4.81%": "",
          "Column_5": "",
          "Column_6": "21.0%",
          "Column_7": "",
          "Column_8": ""
        }
      ],
      "page": 15
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "Notatallconfident": "Slightlyconfident",
          "3": "37",
          "Column_3": "",
          "1.03%": "",
          "Column_5": "12.7%",
          "Column_6": "",
          "Column_7": ""
        },
        {
          "Notatallconfident": "Moderatelyconfident",
          "3": "109",
          "Column_3": "",
          "1.03%": "",
          "Column_5": "",
          "Column_6": "37.5%",
          "Column_7": ""
        },
        {
          "Notatallconfident": "Quiteconfident",
          "3": "123",
          "Column_3": "",
          "1.03%": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "42.3%"
        },
        {
          "Notatallconfident": "Completelyconfident",
          "3": "19",
          "Column_3": "",
          "1.03%": "6.5%",
          "Column_5": "",
          "Column_6": "",
          "Column_7": ""
        }
      ],
      "page": 15
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "Never": "Rarely",
          "14": "55",
          "Column_3": "",
          "4.81%": "",
          "Column_5": "18.9%",
          "Column_6": "",
          "Column_7": ""
        },
        {
          "Never": "Often",
          "14": "84",
          "Column_3": "",
          "4.81%": "",
          "Column_5": "",
          "Column_6": "28.9%",
          "Column_7": ""
        },
        {
          "Never": "Sometimes",
          "14": "132",
          "Column_3": "",
          "4.81%": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "45.4%"
        },
        {
          "Never": "Always",
          "14": "6",
          "Column_3": "",
          "4.81%": "2.06%",
          "Column_5": "",
          "Column_6": "",
          "Column_7": ""
        }
      ],
      "page": 15
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "Never": "Rarely",
          "3": "27",
          "Column_3": "",
          "1.03%": "",
          "Column_5": "9.28%"
        }
      ],
      "page": 15
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "Often": "Sometimes",
          "112": "105",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "36.1%",
          "38.5%": ""
        },
        {
          "Often": "Always",
          "112": "44",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "15.1%",
          "Column_6": "",
          "38.5%": ""
        }
      ],
      "page": 16
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "Disagree": "Agree",
          "47": "157",
          "Column_3": "",
          "Column_4": "",
          "16.2%": "",
          "Column_6": "54.0%"
        }
      ],
      "page": 16
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "Radio": "Website",
          "270": "263",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "",
          "Column_10": "90.4%",
          "92.8%": ""
        },
        {
          "Radio": "Socialmedia",
          "270": "217",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "74.6%",
          "Column_10": "",
          "92.8%": ""
        },
        {
          "Radio": "Television",
          "270": "203",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "69.8%",
          "Column_9": "",
          "Column_10": "",
          "92.8%": ""
        },
        {
          "Radio": "Wordofmouth",
          "270": "164",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "56.4%",
          "Column_8": "",
          "Column_9": "",
          "Column_10": "",
          "92.8%": ""
        },
        {
          "Radio": "Podcasts",
          "270": "88",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "30.2%",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "",
          "Column_10": "",
          "92.8%": ""
        },
        {
          "Radio": "Printnewspaper/magazines",
          "270": "75",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "25.8%",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "",
          "Column_10": "",
          "92.8%": ""
        },
        {
          "Radio": "Idonâ€™t",
          "270": "0",
          "Column_3": "0%",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "",
          "Column_10": "",
          "92.8%": ""
        }
      ],
      "page": 16
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "Youtube": "Facebook",
          "243": "218",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "",
          "Column_10": "",
          "Column_11": "",
          "Column_12": "74.9%",
          "83.5%": ""
        },
        {
          "Youtube": "Instagram",
          "243": "171",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "",
          "Column_10": "",
          "Column_11": "58.8%",
          "Column_12": "",
          "83.5%": ""
        },
        {
          "Youtube": "Twitter",
          "243": "150",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "",
          "Column_10": "51.5%",
          "Column_11": "",
          "Column_12": "",
          "83.5%": ""
        },
        {
          "Youtube": "Reddit",
          "243": "119",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "40.9%",
          "Column_10": "",
          "Column_11": "",
          "Column_12": "",
          "83.5%": ""
        },
        {
          "Youtube": "Linkedin",
          "243": "97",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "33.3%",
          "Column_9": "",
          "Column_10": "",
          "Column_11": "",
          "Column_12": "",
          "83.5%": ""
        },
        {
          "Youtube": "TikTok",
          "243": "69",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "23.7%",
          "Column_8": "",
          "Column_9": "",
          "Column_10": "",
          "Column_11": "",
          "Column_12": "",
          "83.5%": ""
        },
        {
          "Youtube": "Pinterest",
          "243": "62",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "21.3%",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "",
          "Column_10": "",
          "Column_11": "",
          "Column_12": "",
          "83.5%": ""
        },
        {
          "Youtube": "Snapchat",
          "243": "48",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "16.5%",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "",
          "Column_10": "",
          "Column_11": "",
          "Column_12": "",
          "83.5%": ""
        },
        {
          "Youtube": "GooglePlus",
          "243": "15",
          "Column_3": "",
          "Column_4": "5.15%",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "",
          "Column_10": "",
          "Column_11": "",
          "Column_12": "",
          "83.5%": ""
        },
        {
          "Youtube": "Tumblr",
          "243": "13",
          "Column_3": "",
          "Column_4": "4.47%",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "",
          "Column_10": "",
          "Column_11": "",
          "Column_12": "",
          "83.5%": ""
        },
        {
          "Youtube": "Meetup",
          "243": "9",
          "Column_3": "",
          "Column_4": "3.09%",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "",
          "Column_10": "",
          "Column_11": "",
          "Column_12": "",
          "83.5%": ""
        },
        {
          "Youtube": "Flickr",
          "243": "5",
          "Column_3": "",
          "Column_4": "1.72%",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "",
          "Column_10": "",
          "Column_11": "",
          "Column_12": "",
          "83.5%": ""
        },
        {
          "Youtube": "Medium",
          "243": "3",
          "Column_3": "",
          "Column_4": "1.03%",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "",
          "Column_10": "",
          "Column_11": "",
          "Column_12": "",
          "83.5%": ""
        },
        {
          "Youtube": "VK",
          "243": "3",
          "Column_3": "",
          "Column_4": "1.03%",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "",
          "Column_10": "",
          "Column_11": "",
          "Column_12": "",
          "83.5%": ""
        },
        {
          "Youtube": "Vine.co",
          "243": "2",
          "Column_3": "",
          "Column_4": "0.687%",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "",
          "Column_10": "",
          "Column_11": "",
          "Column_12": "",
          "83.5%": ""
        }
      ],
      "page": 16
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "Veryuntrustworthy": "Neithertrustworthynoruntrustworthy",
          "43": "28",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "9.3%",
          "14.4%": "",
          "Column_7": ""
        },
        {
          "Veryuntrustworthy": "Verytrustworthy",
          "43": "52",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "14.4%": "",
          "Column_7": "17.3%"
        }
      ],
      "page": 16
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "Column_1": "Veryuntrustworthy",
          "Column_2": "11",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "3.78%",
          "Column_6": "",
          "Column_7": ""
        },
        {
          "Column_1": "Neithertrustworthynoruntrustworthy",
          "Column_2": "49",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "16.8%"
        },
        {
          "Column_1": "Verytrustworthy",
          "Column_2": "38",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "13.1%",
          "Column_7": ""
        }
      ],
      "page": 17
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "Column_1": "Veryuntrustworthy",
          "Column_2": "24",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "8.25%",
          "Column_6": ""
        },
        {
          "Column_1": "Neithertrustworthynoruntrustworthy",
          "Column_2": "55",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "18.9%"
        },
        {
          "Column_1": "Verytrustworthy",
          "Column_2": "24",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "8.25%",
          "Column_6": ""
        }
      ],
      "page": 17
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "Column_1": "Veryuntrustworthy",
          "Column_2": "17",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "5.84%",
          "Column_6": ""
        },
        {
          "Column_1": "Neithertrustworthynoruntrustworthy",
          "Column_2": "75",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "25.8%"
        },
        {
          "Column_1": "Verytrustworthy",
          "Column_2": "17",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "5.84%",
          "Column_6": ""
        }
      ],
      "page": 17
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "Column_1": "Veryuntrustworthy",
          "Column_2": "13",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "4.47%",
          "Column_6": ""
        },
        {
          "Column_1": "Neithertrustworthynoruntrustworthy",
          "Column_2": "79",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "27.1%"
        },
        {
          "Column_1": "Verytrustworthy",
          "Column_2": "15",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "5.15%",
          "Column_6": ""
        }
      ],
      "page": 17
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "Donâ€™tknow": "Untrustworthy",
          "7": "59",
          "Column_3": "",
          "2": "",
          ".41%": "",
          "Column_6": "20.3%",
          "Column_7": ""
        },
        {
          "Donâ€™tknow": "Trustworthy",
          "7": "98",
          "Column_3": "",
          "2": "",
          ".41%": "",
          "Column_6": "",
          "Column_7": "33.7%"
        }
      ],
      "page": 17
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "Veryuntrustworthy": "Neithertrustworthynoruntrustworthy",
          "10": "69",
          "Column_3": "",
          "3": "",
          ".44%": "",
          "Column_6": "23.7%"
        }
      ],
      "page": 17
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "Donâ€™tknow": "Untrustworthy",
          "13": "47",
          "Column_3": "",
          "Column_4": "",
          "4.47%": "",
          "Column_6": "16.2%",
          "Column_7": ""
        },
        {
          "Donâ€™tknow": "Trustworthy",
          "13": "100",
          "Column_3": "",
          "Column_4": "",
          "4.47%": "",
          "Column_6": "",
          "Column_7": "34.4%"
        }
      ],
      "page": 18
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "Column_1": "Veryuntrustworthy",
          "Column_2": "39",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "13.4%",
          "Column_6": ""
        },
        {
          "Column_1": "Neithertrustworthynoruntrustworthy",
          "Column_2": "111",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "38.1%"
        },
        {
          "Column_1": "Verytrustworthy",
          "Column_2": "5",
          "Column_3": "",
          "Column_4": "1.72%",
          "Column_5": "",
          "Column_6": ""
        }
      ],
      "page": 18
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "Donâ€™tknow": "Veryuntrustworthy",
          "Column_2": "91",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "31.3%"
        },
        {
          "Donâ€™tknow": "Untrustworthy",
          "Column_2": "72",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": ""
        },
        {
          "Donâ€™tknow": "Neithertrustworthynoruntrustworthy",
          "Column_2": "69",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "23.7%",
          "Column_6": ""
        },
        {
          "Donâ€™tknow": "Trustworthy",
          "Column_2": "36",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": ""
        },
        {
          "Donâ€™tknow": "Verytrustworthy",
          "Column_2": "6",
          "Column_3": "",
          "Column_4": "2.06%",
          "Column_5": "",
          "Column_6": ""
        }
      ],
      "page": 18
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "Veryuntrustworthy": "Neithertrustworthynoruntrustworthy",
          "125": "47",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "16.2%",
          "43.0%": ""
        },
        {
          "Veryuntrustworthy": "Verytrustworthy",
          "125": "5",
          "Column_3": "",
          "Column_4": "1.72%",
          "Column_5": "",
          "43.0%": ""
        }
      ],
      "page": 18
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "Donâ€™tknow": "Veryuntrustworthy",
          "Column_2": "101",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "34.7%"
        },
        {
          "Donâ€™tknow": "Neithertrustworthynoruntrustworthy",
          "Column_2": "57",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "19.6%",
          "Column_6": ""
        },
        {
          "Donâ€™tknow": "Verytrustworthy",
          "Column_2": "3",
          "Column_3": "",
          "Column_4": "1.03%",
          "Column_5": "",
          "Column_6": ""
        }
      ],
      "page": 18
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "Column_1": "1",
          "Column_2": "44",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "15.1%"
        }
      ],
      "page": 18
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "1": "",
          "37": "",
          "Column_3": "",
          "Column_4": "8.",
          "12.7%": "",
          "Column_6": ""
        },
        {
          "1": "2",
          "37": "43",
          "Column_3": "",
          "Column_4": "",
          "12.7%": "14.8%",
          "Column_6": ""
        },
        {
          "1": "3",
          "37": "59",
          "Column_3": "",
          "Column_4": "",
          "12.7%": "",
          "Column_6": "20.3%"
        }
      ],
      "page": 19
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "2": "",
          "23": "",
          "Column_3": "",
          "7.": "8.",
          "90%": "",
          "Column_6": ""
        },
        {
          "2": "3",
          "23": "59",
          "Column_3": "",
          "7.": "",
          "90%": "",
          "Column_6": "20.3%"
        },
        {
          "2": "4",
          "23": "42",
          "Column_3": "",
          "7.": "",
          "90%": "14.4%",
          "Column_6": ""
        },
        {
          "2": "5",
          "23": "26",
          "Column_3": "",
          "7.": "8",
          "90%": ".93%",
          "Column_6": ""
        }
      ],
      "page": 19
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "2.5": "3.5",
          "12": "54",
          "Column_3": "",
          "4.12%": "",
          "Column_5": "18.6%"
        },
        {
          "2.5": "4.5",
          "12": "44",
          "Column_3": "",
          "4.12%": "",
          "Column_5": "15.1%"
        }
      ],
      "page": 19
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "1": "7.",
          "30": "",
          "Column_3": "",
          "0.3%": ""
        },
        {
          "1": "",
          "30": "34",
          "Column_3": "",
          "0.3%": "11.7%"
        },
        {
          "1": "",
          "30": "52",
          "Column_3": "",
          "0.3%": "17.9%"
        },
        {
          "1": "9",
          "30": "",
          "Column_3": "",
          "0.3%": ""
        },
        {
          "1": "",
          "30": "43",
          "Column_3": "",
          "0.3%": "14.8%"
        },
        {
          "1": "9",
          "30": "",
          "Column_3": "",
          "0.3%": ""
        },
        {
          "1": "6.19%",
          "30": "18",
          "Column_3": "",
          "0.3%": ""
        }
      ],
      "page": 19
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "2": "",
          "18": "",
          "Column_3": "",
          "6.19%": "8.",
          "Column_5": ""
        },
        {
          "2": "3",
          "18": "51",
          "Column_3": "",
          "6.19%": "",
          "Column_5": "17.5%"
        },
        {
          "2": "4",
          "18": "47",
          "Column_3": "",
          "6.19%": "",
          "Column_5": "16.2%"
        }
      ],
      "page": 19
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "Veryunlikeme": "Neitherlikeorunlikeme",
          "24": "67",
          "Column_3": "",
          "Column_4": "",
          "8.25%": "",
          "Column_6": "23.0%"
        },
        {
          "Veryunlikeme": "Verylikeme",
          "24": "28",
          "Column_3": "",
          "Column_4": "",
          "8.25%": "9.62%",
          "Column_6": ""
        }
      ],
      "page": 20
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "Veryunlikeme": "Neitherlikeorunlikeme",
          "14": "63",
          "Column_3": "",
          "Column_4": "",
          "4.81%": "",
          "Column_6": "",
          "Column_7": "21.6%"
        },
        {
          "Veryunlikeme": "Verylikeme",
          "14": "36",
          "Column_3": "",
          "Column_4": "",
          "4.81%": "",
          "Column_6": "12.4%",
          "Column_7": ""
        }
      ],
      "page": 20
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "Somewhatlikeme": "Neitherlikeorunlikeme",
          "101": "47",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "16.2%",
          "34.7%": ""
        },
        {
          "Somewhatlikeme": "Veryunlikeme",
          "101": "25",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "8.59%",
          "Column_6": "",
          "34.7%": ""
        }
      ],
      "page": 20
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "Somewhatlikeme": "Verylikeme",
          "94": "55",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "18.9%",
          "32.3%": ""
        },
        {
          "Somewhatlikeme": "Veryunlikeme",
          "94": "33",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "11.3%",
          "Column_6": "",
          "32.3%": ""
        }
      ],
      "page": 20
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "Positive and Negative Affect Schedule - Net\nPositiveScore": "<-10",
          "Count": "1",
          "Percentage": "",
          "Column_4": "0.344%"
        }
      ],
      "page": 20
    },
    {
      "caption": "Table 4: Full Persona Variables Breakdowns. Counts and percentages of participants by persona variables. Big-Five",
      "data": [
        {
          "-5to0": "5to10",
          "23": "112",
          "Column_3": "",
          "Column_4": "",
          "7.90%": "",
          "Column_6": "38.5%"
        }
      ],
      "page": 20
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "8 Condition\nImage\n7 Text\n6\n5\nerocS\n4\n3\n2\n1\n0\nV A D\nDimension": "",
          "Condition": "",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "Image\nText"
        }
      ],
      "page": 21
    },
    {
      "caption": "Table 7: Among the core",
      "data": [
        {
          "Emotions\n70 anger\ncontempt\ndisgust\n60 fear\nhappy\nneutral\n50 other\nsad\n40 tnuoC surprise\n30\n20\n10\n0 Image Text\nCondition": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "",
          "Column_10": "",
          "Column_11": "",
          "Column_12": "",
          "Column_13": "",
          "Column_14": "",
          "Column_15": "",
          "Column_16": "",
          "Column_17": "happy\nneutral\nother\nsad\nsurprise",
          "Column_18": "",
          "Emotions\nanger\ncontempt\ndisgust\nfear": "",
          "Column_20": ""
        }
      ],
      "page": 30
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "Not at all Slig\n)Releva",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "",
          "Column_10": ""
        }
      ],
      "page": 31
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "%",
          "Column_5": ""
        }
      ],
      "page": 34
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "3.",
          "Column_5": "85",
          "Column_6": "",
          "Column_7": ""
        },
        {
          "Column_1": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": ".80"
        },
        {
          "Column_1": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "4.18",
          "Column_6": "",
          "Column_7": ""
        },
        {
          "Column_1": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "3",
          "Column_5": ".94",
          "Column_6": "",
          "Column_7": ""
        },
        {
          "Column_1": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "77"
        },
        {
          "Column_1": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "4.10",
          "Column_6": "",
          "Column_7": ""
        },
        {
          "Column_1": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "4.25",
          "Column_6": "",
          "Column_7": ""
        },
        {
          "Column_1": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "4.24",
          "Column_6": "",
          "Column_7": ""
        },
        {
          "Column_1": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "4.45",
          "Column_7": ""
        },
        {
          "Column_1": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "4.49",
          "Column_7": ""
        },
        {
          "Column_1": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "4.40",
          "Column_7": ""
        },
        {
          "Column_1": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "4.23",
          "Column_6": "",
          "Column_7": ""
        }
      ],
      "page": 34
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Modality\nText\nImage": "Persona\nNo Person\nWith Perso",
          "Column_7": "a\nna"
        }
      ],
      "page": 41
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Modal\nText\nImage": "Perso\nNo Pe\nWith P",
          "ity": "na\nrsona\nersona",
          "Column_3": "",
          "Column_4": "",
          "Column_5": ""
        }
      ],
      "page": 41
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "Modality\nText\nImage\nPersona",
          "Column_6": ""
        },
        {
          "Column_1": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "No Person\nWith Perso",
          "Column_6": "a\nna"
        }
      ],
      "page": 41
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Many-shot in-context learning",
      "authors": [
        "Rishabh Agarwal",
        "Avi Singh",
        "M Lei",
        "Bernd Zhang",
        "Luis Bohnet",
        "Rosias",
        "C Stephanie",
        "Biao Chan",
        "Aleksandra Zhang",
        "Hugo Faust",
        "Larochelle"
      ],
      "year": "2024",
      "venue": "ICML 2024 Workshop on In-Context Learning"
    },
    {
      "citation_id": "2",
      "title": "Time course of processes underlying picture and word evaluation: An event-related potential approach",
      "authors": [
        "Allen Azizian",
        "Todd Watson",
        "Muhammad Parvaz",
        "Nancy Squires"
      ],
      "year": "2006",
      "venue": "Brain Topography",
      "doi": "10.1007/s10548-006-0270-9"
    },
    {
      "citation_id": "3",
      "title": "This is an Accepted Manuscript of a book chapter published by Routledge in The Routledge Companion to",
      "authors": [
        "M Bastos"
      ],
      "year": "2016",
      "venue": "The Routledge Companion to Digital Journalism Studies"
    },
    {
      "citation_id": "4",
      "title": "Fitting linear mixed-effects models using lme4",
      "authors": [
        "Douglas Bates",
        "Martin MÃ¤chler",
        "Ben Bolker",
        "Steve Walker"
      ],
      "year": "2015",
      "venue": "Journal of Statistical Software",
      "doi": "10.18637/jss.v067.i01"
    },
    {
      "citation_id": "5",
      "title": "effectsize: Estimation of effect size indices and standardized parameters",
      "authors": [
        "S Mattan",
        "Daniel Ben-Shachar",
        "Dominique LÃ¼decke",
        "Makowski"
      ],
      "year": "2020",
      "venue": "Journal of Open Source Software",
      "doi": "10.21105/joss.02815"
    },
    {
      "citation_id": "6",
      "title": "Measuring emotion: the self-assessment manikin and the semantic differential",
      "authors": [
        "M Margaret",
        "Peter Bradley",
        "Lang"
      ],
      "year": "1994",
      "venue": "Journal of behavior therapy and experimental psychiatry"
    },
    {
      "citation_id": "7",
      "title": "Affective norms for english text (anet): Affective ratings of text and instruction manual",
      "authors": [
        "Margaret Bradley",
        "Peter Lang"
      ],
      "year": "2007",
      "venue": "Affective norms for english text (anet): Affective ratings of text and instruction manual"
    },
    {
      "citation_id": "8",
      "title": "EmoBank: Studying the impact of annotation perspective and representation format on dimensional emotion analysis",
      "authors": [
        "Sven Buechel",
        "Udo Hahn"
      ],
      "year": "2017",
      "venue": "Proceedings of the 15th Conference of the European Chapter"
    },
    {
      "citation_id": "9",
      "title": "IEMOCAP: interactive emotional dyadic motion capture database",
      "authors": [
        "Carlos Busso",
        "Murtaza Bulut",
        "Chi-Chun Lee",
        "Abe Kazemzadeh",
        "Emily Mower",
        "Samuel Kim",
        "Jeannette Chang",
        "Sungbok Lee",
        "Shrikanth Narayanan"
      ],
      "year": "2008",
      "venue": "Language Resources and Evaluation",
      "doi": "10.1007/s10579-008-9076-6"
    },
    {
      "citation_id": "10",
      "title": "Toward a perspectivist turn in ground truthing for predictive computing",
      "authors": [
        "Federico Cabitza",
        "Andrea Campagner",
        "Valerio Basile"
      ],
      "year": "2023",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence",
      "doi": "10.1609/aaai.v37i6.25840"
    },
    {
      "citation_id": "11",
      "title": "Social and emotional aging",
      "authors": [
        "T Susan",
        "Laura Charles",
        "Carstensen"
      ],
      "year": "2010",
      "venue": "Annual review of psychology"
    },
    {
      "citation_id": "12",
      "title": "The revised neo personality inventory (neo-pi-r)",
      "authors": [
        "T Paul",
        "Robert Costa",
        "Mccrae"
      ],
      "year": "2008",
      "venue": "The SAGE handbook of personality theory and assessment"
    },
    {
      "citation_id": "13",
      "title": "The positive and negative affect schedule (panas): Construct validity, measurement properties and normative data in a large non-clinical sample",
      "authors": [
        "R John",
        "Julie Crawford",
        "Henry"
      ],
      "year": "2004",
      "venue": "British journal of clinical psychology"
    },
    {
      "citation_id": "14",
      "title": "Is the news making us unhappy? the influence of daily news exposure on emotional states",
      "authors": [
        "Natascha De",
        "Peter Verboon"
      ],
      "year": "2020",
      "venue": "British Journal of Psychology"
    },
    {
      "citation_id": "15",
      "title": "GoEmotions: A dataset of fine-grained emotions",
      "authors": [
        "Dorottya Demszky",
        "Dana Movshovitz-Attias",
        "Jeongwoo Ko",
        "Alan Cowen",
        "Gaurav Nemade",
        "Sujith Ravi"
      ],
      "year": "2020",
      "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/2020.acl-main.372"
    },
    {
      "citation_id": "16",
      "title": "Addressing agerelated bias in sentiment analysis",
      "authors": [
        "Mark Diaz",
        "Isaac Johnson",
        "Amanda Lazar",
        "Anne Piper",
        "Darren Gergle"
      ],
      "year": "2018",
      "venue": "Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems, CHI '18",
      "doi": "10.1145/3173574.3173986"
    },
    {
      "citation_id": "17",
      "title": "Can LLM be a personalized judge?",
      "authors": [
        "Yijiang River",
        "Tiancheng Hu",
        "Nigel Collier"
      ],
      "year": "2024",
      "venue": "Findings of the Association for Computational Linguistics: EMNLP 2024",
      "doi": "10.18653/v1/2024.findings-emnlp.592"
    },
    {
      "citation_id": "18",
      "title": "An argument for basic emotions",
      "authors": [
        "Paul Ekman"
      ],
      "year": "1992",
      "venue": "Cognition and Emotion",
      "doi": "10.1080/02699939208411068"
    },
    {
      "citation_id": "19",
      "title": "Whole trait theory",
      "authors": [
        "William Fleeson",
        "Eranda Jayawickreme"
      ],
      "year": "2015",
      "venue": "Journal of Research in Personality",
      "doi": "10.1016/j.jrp.2014.10.009"
    },
    {
      "citation_id": "20",
      "title": "Cognitive reflection and decision making",
      "authors": [
        "Shane Frederick"
      ],
      "year": "2005",
      "venue": "Journal of Economic perspectives"
    },
    {
      "citation_id": "21",
      "title": "Quantifying the persona effect in LLM simulations",
      "authors": [
        "Tiancheng Hu",
        "Nigel Collier"
      ],
      "year": "2024",
      "venue": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/2024.acl-long.554"
    },
    {
      "citation_id": "22",
      "title": "Generative language models exhibit social identity biases",
      "authors": [
        "Tiancheng Hu",
        "Yara Kyrychenko",
        "Steve Rathje",
        "Nigel Collier",
        "Jon Sander Van Der Linden",
        "Roozenbeek"
      ],
      "year": "2025",
      "venue": "Nature Computational Science"
    },
    {
      "citation_id": "23",
      "title": "Gpt-4o system card",
      "authors": [
        "Aaron Hurst",
        "Adam Lerer",
        "Adam Goucher",
        "Adam Perelman",
        "Aditya Ramesh",
        "Aidan Clark",
        "Akila Ostrow",
        "Alan Welihinda",
        "Alec Hayes",
        "Radford"
      ],
      "year": "2024",
      "venue": "Gpt-4o system card",
      "arxiv": "arXiv:2410.21276"
    },
    {
      "citation_id": "24",
      "title": "Picture this: emotional and political responses to photographs of the kenneth bigley kidnapping",
      "year": "2006",
      "venue": "Media topics: Subject taxonomy for the media -the successor to the subject codes",
      "doi": "10.1002/ejsp.316"
    },
    {
      "citation_id": "25",
      "title": "Sex differences in emotion: expression, experience, and physiology",
      "authors": [
        "Ann Kring",
        "Albert Gordon"
      ],
      "year": "1998",
      "venue": "Journal of personality and social psychology"
    },
    {
      "citation_id": "26",
      "title": "Introducing the open affective standardized image set (oasis)",
      "authors": [
        "Shayn Benedek Kurdi",
        "Mahzarin Lozano",
        "Banaji"
      ],
      "year": "2017",
      "venue": "Behavior Research Methods",
      "doi": "10.3758/s13428-016-0715-3"
    },
    {
      "citation_id": "27",
      "title": "What the metrics say. the softening of news on the facebook pages of mainstream media outlets",
      "authors": [
        "Kenza Lamot"
      ],
      "year": "2022",
      "venue": "Digital Journalism",
      "doi": "10.1080/21670811.2021.1974917"
    },
    {
      "citation_id": "28",
      "title": "International affective picture system (iaps): Technical manual and affective ratings",
      "authors": [
        "Margaret Peter J Lang",
        "Bruce Bradley",
        "Cuthbert"
      ],
      "year": "1997",
      "venue": "International affective picture system (iaps): Technical manual and affective ratings"
    },
    {
      "citation_id": "29",
      "title": "TopViewRS: Vision-language models as top-view spatial reasoners",
      "authors": [
        "Chengzu Li",
        "Caiqi Zhang",
        "Han Zhou",
        "Nigel Collier",
        "Anna Korhonen",
        "Ivan VuliÄ‡"
      ],
      "year": "2024",
      "venue": "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
      "doi": "10.18653/v1/2024.emnlp-main.106"
    },
    {
      "citation_id": "30",
      "title": "Dual operating modes of in-context learning",
      "authors": [
        "Ziqian Lin",
        "Kangwook Lee"
      ],
      "year": "2024",
      "venue": "ICLR 2024 Workshop on Mathematical and Empirical Understanding of Foundation Models"
    },
    {
      "citation_id": "31",
      "title": "The mind in the machine: A survey of incorporating psychological theories in llms",
      "authors": [
        "Zizhou Liu",
        "Ziwei Gong",
        "Lin Ai",
        "Zheng Hui",
        "Run Chen",
        "Colin Leach",
        "Michelle Greene",
        "Julia Hirschberg"
      ],
      "year": "2025",
      "venue": "The mind in the machine: A survey of incorporating psychological theories in llms",
      "arxiv": "arXiv:2505.00003"
    },
    {
      "citation_id": "32",
      "title": "Affective intelligence and political judgment",
      "authors": [
        "W George E Marcus",
        "Michael Russell Neuman",
        "Mackuen"
      ],
      "year": "2000",
      "venue": "Affective intelligence and political judgment"
    },
    {
      "citation_id": "33",
      "title": "Reliance on emotion promotes belief in fake news",
      "authors": [
        "Cameron Martel",
        "Gordon Pennycook",
        "David Rand"
      ],
      "year": "2020",
      "venue": "Cognitive Research: Principles and Implications",
      "doi": "10.1186/s41235-020-00252-3"
    },
    {
      "citation_id": "34",
      "title": "An approach to environmental psychology",
      "authors": [
        "Albert Mehrabian",
        "James Russell"
      ],
      "year": "1974",
      "venue": "An approach to environmental psychology"
    },
    {
      "citation_id": "35",
      "title": "Cultural variations in emotions: a review",
      "authors": [
        "Batja Mesquita",
        "Nico Frijda"
      ],
      "year": "1992",
      "venue": "Psychological bulletin"
    },
    {
      "citation_id": "36",
      "title": "Llama 3.2: Revolutionizing edge AI and vision with open multimodal models",
      "authors": [
        "A Meta"
      ],
      "year": "2024",
      "venue": "Llama 3.2: Revolutionizing edge AI and vision with open multimodal models"
    },
    {
      "citation_id": "37",
      "title": "Meta AI. 2024b. Llama 3.3: Model Cards and Prompt Formats",
      "venue": "Meta AI. 2024b. Llama 3.3: Model Cards and Prompt Formats"
    },
    {
      "citation_id": "38",
      "title": "Meta Llama 3.1: Pushing the Boundaries of AI Research",
      "authors": [
        "A Meta"
      ],
      "year": "2024",
      "venue": "Meta Llama 3.1: Pushing the Boundaries of AI Research"
    },
    {
      "citation_id": "39",
      "title": "A cognitiveaffective system theory of personality: reconceptualizing situations, dispositions, dynamics, and invariance in personality structure",
      "authors": [
        "Walter Mischel",
        "Yuichi Shoda"
      ],
      "year": "1995",
      "venue": "Psychological Review",
      "doi": "10.1037/0033-295X.102.2.246"
    },
    {
      "citation_id": "40",
      "title": "A general and simple method for obtaining r2 from generalized linear mixed-effects models",
      "authors": [
        "Shinichi Nakagawa",
        "Holger Schielzeth"
      ],
      "year": "2013",
      "venue": "Methods in Ecology and Evolution",
      "doi": "10.1111/j.2041-210x.2012.00261.x"
    },
    {
      "citation_id": "41",
      "title": "Reuters Institute digital news report 2015: Tracking the future of news",
      "authors": [
        "Nic Newman",
        "David Levy",
        "Nielsen"
      ],
      "year": "2015",
      "venue": "Reuters Institute digital news report 2015: Tracking the future of news"
    },
    {
      "citation_id": "42",
      "title": "Goodnewseveryone: A corpus of news headlines annotated with emotions, semantic roles, and reader perception",
      "authors": [
        "Laura Ana",
        "Maria OberlÃ¤nder",
        "Evgeny Kim",
        "Roman Klinger"
      ],
      "year": "2020",
      "venue": "Proceedings of the Twelfth Language Resources and Evaluation Conference"
    },
    {
      "citation_id": "43",
      "title": "2024a. Adults news consumption survey -online questionnaire",
      "authors": [
        "Ofcom"
      ],
      "venue": "2024a. Adults news consumption survey -online questionnaire"
    },
    {
      "citation_id": "44",
      "title": "2024b. News consumption in the uk: 2024",
      "authors": [
        "Ofcom"
      ],
      "venue": "2024b. News consumption in the uk: 2024"
    },
    {
      "citation_id": "45",
      "title": "Individual differences in media effects",
      "authors": [
        "Mary Beth"
      ],
      "year": "2002",
      "venue": "Media effects"
    },
    {
      "citation_id": "46",
      "title": "Subjective natural language problems: Motivations, applications, characterizations, and implications",
      "authors": [
        "Cecilia Ovesdotter"
      ],
      "year": "2011",
      "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies"
    },
    {
      "citation_id": "47",
      "title": "Generative agent simulations of 1,000 people",
      "authors": [
        "Sung Joon",
        "Carolyn Park",
        "Aaron Zou",
        "Benjamin Shaw",
        "Carrie Hill",
        "Meredith Cai",
        "Robb Morris",
        "Percy Willer",
        "Michael Liang",
        "Bernstein"
      ],
      "year": "2024",
      "venue": "Generative agent simulations of 1,000 people",
      "arxiv": "arXiv:2411.10109"
    },
    {
      "citation_id": "48",
      "title": "Dan Aramaki, Yphtach Lelkes, and Sharad Goel. 2022. Data quality of platforms and panels for online behavioral research",
      "authors": [
        "Eyal Peer",
        "David Rothschild",
        "Andrew Gordon"
      ],
      "venue": "Behavior Research Methods",
      "doi": "10.3758/s13428-021-01694-3"
    },
    {
      "citation_id": "49",
      "title": "POTATO: The portable text annotation tool",
      "authors": [
        "Jiaxin Pei",
        "Aparna Ananthasubramaniam",
        "Xingyao Wang",
        "Naitian Zhou",
        "Apostolos Dedeloudis",
        "Jackson Sargent",
        "David Jurgens"
      ],
      "year": "2022",
      "venue": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
      "doi": "10.18653/v1/2022.emnlp-demos.33"
    },
    {
      "citation_id": "50",
      "title": "The \"problem\" of human label variation: On ground truth in data, modeling and evaluation",
      "authors": [
        "Barbara Plank"
      ],
      "year": "2022",
      "venue": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
      "doi": "10.18653/v1/2022.emnlp-main.731"
    },
    {
      "citation_id": "51",
      "title": "Emotion analysis in NLP: Trends, gaps and roadmap for future directions",
      "authors": [
        "Flor Miriam",
        "Plaza-Del Arco",
        "Alba Curry",
        "Amanda Curry",
        "Dirk Hovy"
      ],
      "year": "2024",
      "venue": "Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)"
    },
    {
      "citation_id": "52",
      "title": "Emo-Event: A multilingual emotion corpus based on different events",
      "authors": [
        "Flor Miriam",
        "Plaza Del Arco",
        "Carlo Strapparava",
        "L Alfonso Urena",
        "Maite Lopez",
        "Martin"
      ],
      "year": "2020",
      "venue": "Proceedings of the Twelfth Language Resources and Evaluation Conference"
    },
    {
      "citation_id": "53",
      "title": "A clearer picture: The contribution of visuals and text to framing effects",
      "authors": [
        "Thomas Powell",
        "G Hajo",
        "Knut Boomgaarden",
        "Claes De Swert",
        "De Vreese"
      ],
      "year": "2015",
      "venue": "Journal of Communication",
      "doi": "10.1111/jcom.12184"
    },
    {
      "citation_id": "54",
      "title": "Assessing emotional reactivity: Psychometric properties of the perth emotional reactivity scale and the development of a short form",
      "authors": [
        "David Preece",
        "Rodrigo Becerra",
        "Guillermo Campitelli"
      ],
      "year": "2018",
      "venue": "Journal of Personality Assessment"
    },
    {
      "citation_id": "55",
      "title": "Qwen2.5-VL: A Vision-Language Model",
      "authors": [
        "Qwenlm"
      ],
      "year": "2025",
      "venue": "Qwen2.5-VL: A Vision-Language Model"
    },
    {
      "citation_id": "56",
      "title": "Measuring personality in one minute or less: A 10-item short version of the big five inventory in english and german",
      "authors": [
        "Beatrice Rammstedt",
        "Oliver John"
      ],
      "year": "2007",
      "venue": "Journal of Research in Personality",
      "doi": "10.1016/j.jrp.2006.02.001"
    },
    {
      "citation_id": "57",
      "title": "Can language models recognize convincing arguments?",
      "authors": [
        "Paula Rescala",
        "Manoel Horta Ribeiro",
        "Tiancheng Hu",
        "Robert West"
      ],
      "year": "2024",
      "venue": "Findings of the Association for Computational Linguistics: EMNLP 2024",
      "doi": "10.18653/v1/2024.findings-emnlp.515"
    },
    {
      "citation_id": "58",
      "title": "Digital news report 2024 uk questionnaire",
      "year": "2024",
      "venue": "Digital news report 2024 uk questionnaire"
    },
    {
      "citation_id": "59",
      "title": "Large language models are competitive near cold-start recommenders for language-and item-based preferences",
      "authors": [
        "Scott Sanner",
        "Krisztian Balog",
        "Filip Radlinski",
        "Ben Wedin",
        "Lucas Dixon"
      ],
      "year": "2023",
      "venue": "Proceedings of the 17th ACM Conference on Recommender Systems, RecSys '23",
      "doi": "10.1145/3604915.3608845"
    },
    {
      "citation_id": "60",
      "title": "Recognition memory for words, sentences, and pictures",
      "authors": [
        "Roger Shepard"
      ],
      "year": "1967",
      "venue": "Journal of Verbal Learning and Verbal Behavior",
      "doi": "10.1016/S0022-5371(67)80067-7"
    },
    {
      "citation_id": "61",
      "title": "Position: A roadmap to pluralistic alignment",
      "authors": [
        "Taylor Sorensen",
        "Jared Moore",
        "Jillian Fisher",
        "Niloofar Mitchell L Gordon",
        "Christopher Mireshghallah",
        "Andre Michael Rytting",
        "Liwei Ye",
        "Ximing Jiang",
        "Nouha Lu",
        "Tim Dziri",
        "Yejin Althoff",
        "Choi"
      ],
      "year": "2024",
      "venue": "Forty-first International Conference on Machine Learning"
    },
    {
      "citation_id": "62",
      "title": "Cross-national evidence of a negativity bias in psychophysiological reactions to news",
      "authors": [
        "Stuart Soroka",
        "Patrick Fournier",
        "Lilach Nir"
      ],
      "year": "2019",
      "venue": "Proceedings of the National Academy of Sciences"
    },
    {
      "citation_id": "63",
      "title": "Affective arousal as information: How affective arousal influences judgments, learning, and memory. Social and personality psychology compass",
      "authors": [
        "Hannah Sterz",
        "Jonas Pfeiffer",
        "Ivan VuliÄ‡"
      ],
      "year": "2008",
      "venue": "Affective arousal as information: How affective arousal influences judgments, learning, and memory. Social and personality psychology compass",
      "arxiv": "arXiv:2409.18023"
    },
    {
      "citation_id": "64",
      "title": "Semeval-2007 task 14: Affective text",
      "authors": [
        "Carlo Strapparava",
        "Rada Mihalcea"
      ],
      "year": "2007",
      "venue": "Proceedings of the fourth international workshop on semantic evaluations (SemEval-2007)"
    },
    {
      "citation_id": "65",
      "title": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
      "authors": [
        "Gemini Team",
        "Petko Georgiev",
        "Ian Ving",
        "Ryan Lei",
        "Libin Burnell",
        "Anmol Bai",
        "Garrett Gulati",
        "Damien Tanzer",
        "Zhufeng Vincent",
        "Shibo Pan",
        "Wang"
      ],
      "year": "2024",
      "venue": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
      "arxiv": "arXiv:2403.05530"
    },
    {
      "citation_id": "66",
      "title": "The differential susceptibility to media effects model",
      "authors": [
        "M Patti",
        "Jochen Valkenburg",
        "Peter"
      ],
      "year": "2013",
      "venue": "Journal of communication"
    },
    {
      "citation_id": "67",
      "title": "Nigel Collier, and Andreas Vlachos. 2024. Conformity in large language models",
      "authors": [
        "Xiaochen Zhu",
        "Caiqi Zhang",
        "Tom Stafford"
      ],
      "venue": "Nigel Collier, and Andreas Vlachos. 2024. Conformity in large language models",
      "arxiv": "arXiv:2410.12428"
    }
  ]
}