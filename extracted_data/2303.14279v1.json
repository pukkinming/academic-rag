{
  "paper_id": "2303.14279v1",
  "title": "Depression Detection In Social Media Posts Using Affective And Social Norm Features",
  "published": "2023-03-24T21:26:27Z",
  "authors": [
    "Ilias Triantafyllopoulos",
    "Georgios Paraskevopoulos",
    "Alexandros Potamianos"
  ],
  "keywords": [
    "Depression detection",
    "BERT",
    "Feature fusion",
    "Emotion recognition",
    "profanity",
    "morality"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "We propose a deep architecture for depression detection from social media posts. The proposed architecture builds upon BERT to extract language representations from social media posts and combines these representations using an attentive bidirectional GRU network. We incorporate affective information, by augmenting the text representations with features extracted from a pretrained emotion classifier. Motivated by psychological literature we propose to incorporate profanity and morality features of posts and words in our architecture using a late fusion scheme. Our analysis indicates that morality and profanity can be important features for depression detection. We apply our model for depression detection on Reddit posts on the Pirina dataset, and further consider the setting of detecting depressed users, given multiple posts per user, proposed in the Reddit RSDD dataset. The inclusion of the proposed features yields state-of-the-art results in both settings, namely 2.65% and 6.73% absolute improvement in F1 score respectively.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Depression is a mental health disorder which affects a large portion of society. More specifically,  [1]  records 322 million people worldwide suffering from depression, which corresponds to 4.4% of the world population. Interestingly, the number of depressed people increased by 18.4% from 2005 to 2015  [2] .\n\nIn recent years, social media have become pervasive platforms, where people share information, opinions, thoughts and feelings. For many people, social media platforms are places where they turn for support and self-disclose about their mental health. According to  [3]  and  [4] , there is a close association between depressive young adults and the excessive use of social media. De Choudhury et al  [5]  find that depressed social media users have different online activity and behavior patterns than non-depressed users. These studies indicate the feasibility of depression detection from social media posts. Automatic depression detection could enable positive applications for the users, from suicide prevention to the development of effective, (semi-)automated mental health resources.\n\nPsychological studies indicate that depressive disorders influence the affected people's language use. In  [6] , depression is considered as a disorder of \"concern for others\", as depressed individuals have often elevated levels of empathy. The authors bring evidence from neuroscience and psychology that demonstrate a connection between morality and depression. In  [7] , the authors find a positive correlation between offensive language and depressed individuals in their social media posts. Vingerhoets et al  [8]  argue that excessive swearing can lead to isolation, and therefore feelings of rejection and depressive disorder.\n\nEmotive language is also correlated with depression, as mental health issues affect the emotional state of people. It is empirically established that depressed individuals express more negative thoughts, emotions and perspectives  [9, 10, 11] .\n\nDepression detection from social media can be performed either at the individual post level or at the user level, given a collection of posts by said user. In  [12] , authors classify depression-related LiveJournal posts, while in  [5]  authors focus on Twitter post classification. In  [13] , a shared task for CLPsych 2015 is proposed for clinical diagnoses from Twitter posts. In  [14] , authors manually collect 200 college students' posts from a one year timespan and perform user level depression classification. In  [15] , the authors analyze the social attitudes of users who indicate intention to commit suicide in public comments.\n\nLinguistic features have been previously shown to improve depression detection models  [11, 16, 17] . One popular resource is the LIWC lexicon  [18] , which contains word scores across multiple linguistic (e.g. morality, functions etc) and affective dimensions. Specifically,  [16]  investigate the use of LIWC features for detecting a range of mental health conditions in Twitter posts.  [17]  perform a similar analysis in forum posts, both at the user and at the post level. Xezonaki et al  [11]  detect depression from transcribed clinical interviews, injecting affective features from lexica. In  [19] , Yadav et al use emotion, sarcasm, personality and sentiment as features to identify medical conditions in online health fora, while in  [20]  they explore the importance of figurative language for detecting depressive symptoms. In  [21] , the authors have utilized demographic features for depression and PTSD detection from Twitter data.\n\nIn this work, we consider depression detection in social media posts, both at the individual post level and at the user level. We propose a hierarchical, two-level architecture based on BERT. We combine BERT representations with features extracted from a pretrained emotion detector. Our key contribution is the inclusion of additional features related to the profanity and morality scores of individual posts and users, motivated by works in the psychology domain. Our extensive data analysis and ablation studies indicate that emotion, profanity and morality can improve depression detection both at the post and at the user level. The proposed architecture achieves state-of-the-art results for both tasks. Our code is publicly available 1  .  the BERT and Emotion representations are fused, along with the profanity and morality features.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Methodology",
      "text": "",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "First Level",
      "text": "Base Model: We extract semantic representations from input text using a pretrained BERT model (bert-base-uncased)  [22] . Assume a post\n\n, where w k i,j is the j-th word of the i-th post, n is the maximum number of words and k is an optional user annotation for the post (if we perform user level classification). We extract word representations u k i,j from BERT (f ) as in Eq. 1.\n\nIn the case of post-level classification ui,j are passed to the Bi-GRU at the next architecture level. In the case of user-level classification, given m posts per user, we average u k i,j to produce u k i , the i-th post representation for the k-th user. We pass then u k i , i ∈ {1, .., m} posts, related to user k, to the BiGRU. Emotion Dectector: We use a pretrained emotion detector, g, to extract affective information from the input text. In the post level classification, we extract the representation of the j-th word of the i-th post vi,j as shown in Eq. 2.\n\nvi,j = g(wi,j)\n\nIn the case of user level classification, the representation of the i-th post from the k-th user v k i is produced from the emotion detector as in Eq. 3.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Second Level",
      "text": "In the second level, we create the unified representation from the representations created in the first level. As it is presented in Fig.  1 , a Bi-directional Gated Recurrent Unit (Bi-GRU) network  [23]  is used on top of BERT and the emotion detector. Let -→ hi be the i-th forward hidden state obtained by GRU associated with the BERT representations and ←hi the corresponding backward hidden state. We concatenate -→ hi and ←hi to obtain the hidden states ci for the BERT branch:\n\nSimilarly, let -→ ki and ←ki be the i-th forward and backward hidden states of the BiGRU associated with the emotion detector. Then, we obtain ei, the hidden states for the emotion branch, as follows:\n\nWe aggregate the hidden states ci and ei into the final representations c and e for the BERT and emotion branches respectively using an Attention Mechanism  [24] , on top of each of the respective GRUs. Given the hidden states ci, we obtain the unified representation c for the BERT branch as the weighted sum of ci and the attention weights ai:\n\nwhere q is a learnable mapping. We obtain the unified representation e for the emotion branch in a similar manner.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Fusion Layer",
      "text": "In this architecture level, given the representations c and e, we combine them, in order to extract the final representation. Inspired by  [25] , we use a gating mechanism. Specifically, a mask-vector is generated from e (the representation associated with the emotion detector) with values between 0 and 1 and selects the salient dimensions of c (the representation associated with BERT). Concretely,\n\nwhere W l , b l are learnable parameters, σ is the sigmoid function and z is the final representation, which is fed into the classifier.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Additional Features",
      "text": "In the last level of our architecture, we add additional features, as shown in Fig.  1 . These features are chosen through our data analysis and they can be profanity, morality or both. They will be explained further in Section 3. We construct a vector x that includes the features related to the second level entity. In the case of post classification, the entity is a post, whereas in the user classification it is a user. We integrate the x vector to our architecture right before the classifier. Specifically, we concatenate, , the x vector with the representation extracted from the fusion layer, z as in Eq. 8.\n\n3. Datasets and Analysis  have been removed. Every user in the dataset has approximately 900 posts. In Table  1 , we present the average number of posts per user, as well as the average number of words that are used in the posts for both classes, in the training set. We notice that depressed users post twice as much as the non-depressed and they use more words per post in a rate of 5 : 3. Pirina dataset was built by Inna Pirina et al.  [27]  and contains 1, 841 posts extracted from users in Reddit. Among these posts, 1293 are annotated as \"depressionindicative\" posts, whereas the remaining 548 are annotated as \"standard\" posts. In Fig.  2 , we present one sample of the depression-indicative posts and one standard post. We see that the depression-indicative post is more emotional, as it contains more affective words, e.g. \"hurt\" and \"pain\". Moreover, in Table 1, we provide statistics about the average number of words per posts that are used in both classes. We observe that, in contrast with the RSDD Dataset, standard posts include more words than the depression-indicative posts.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Emobank-2017:",
      "text": "The emotion detector has been trained on the EmoBank-2017 dataset  [28] , examining the posts on fine-grained emotions (\"valence\", \"arousal\" and \"dominance\"). EmoBank-2017 dataset consists of 10,062 posts, annotated in terms of valence, arousal and dominance in a 5-point scale. For the architecture of the emotion detector, we leverage a CNN network, similar to the one proposed in  [29] .",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Profanity",
      "text": "There are signs that indicate higher usage of offensive language from depressed individuals. We decide to measure the profanity score of a sentence, e.g. its profanity probability. To this purpose, we use the profanity-check tool, as proposed by  [30] . For the RSDD, we associate a profanity score with each user and use it as feature. This score is calculated as the average profanity score of user's posts. For the Pirina dataset, we use the post's profanity score as feature. The average profanity scores of depressed and non-depressed users/posts for the RSDD/Pirina dataset are presented in Table  2 . For both datasets we observe higher profanity scores for the depressed category, and especially in the case of the Pirina. In the first sample of Fig.  2 , we see that the profane word \"f***ing\" determines the high profanity score of the sentence (0.949), while the second sentence does not contain a profane word and its score is low (0.021).",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Social Norms",
      "text": "To extract social norm features, we leverage the moral dimensions of Moral Foundations Dictionary (MFD)  [31]  that was used together with LIWC  [18] , and its expansion  [32] . In particular,  [32]  introduce the \"moral strength\" value, by providing a score in a 9-point scale, which declares the moral valence of a word that belongs to a moral category. We focus on 5 moral dimensions of the expanded MFD: Harm/Care, Cheating/Fairness, Betrayal/Loyalty, Subversion/Authority, Degradation/Purity. When a word is scored with 9, it belongs exclusively to the good option of the dimension, e.g. to \"Care\" if it is in Care/Harm, while when it is scored with 1, it belongs to the bad option, e.g. to \"Harm\". In the samples of Fig.  2 , we observe that the depression-indicative post has more words that belong to the moral vocabulary than the standard post. In Table 3 we see the statistics of two features that are developed, in the RSDD dataset for both classes. These features are the average moral strength of the user and the percentage of user's posts that contain at least one word, which belongs to this moral dimension. We see that the main difference concerns the second feature, concluding that depressed users use, indeed, more moral vocabulary than the non-depressed. These are concatenated as global features. In Fig.  3  we see the overall histograms of the dimension Care/Harm for the Pirina dataset. We notice that depression-indicative posts contain more words that belong to the Care/Harm dimension, as also that the distribution on this dimension differs. More words tend to extreme values (near 1 and 9), while the standard posts are concentrated mainly on values between 4 and 6. Both differences are remarked on all dimensions.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Experimental Setup",
      "text": "For user-level classification in the RSDD dataset, we extract post representations at the first level of the proposed architecture, and at the second level we combine post representations into user representations. For each user, we utilize 600 posts. The models are trained for 10 epochs using Adam with learning rate 10 -3 and Cross Entropy Loss, with class weight ratio 1 : 7.\n\nFor post-level classification in the Pirina dataset, at the first  For all models we use Dropout 0.2. All Bi-GRUs have 128 hidden size. We use PyTorch  [33]  in our implementation.\n\nFor both datasets, we compare the performance of the BERT-only baseline (B) with the models that take into consideration the emotion detector (E), profanity (P) and morality (M). Thus, we experiment with (B+E) and then we add profanity (B+E+P), morality (B+E+M) and both (B+E+P+M). For both datasets, we report F1-score (F1), Recall (Re) and Precision (Pr). For the Pirina dataset, we also report Accuracy (Acc).",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Results And Discussion",
      "text": "In Table  4 , we present the results of our models in the RSDD Dataset compared with the best models of  [34]  and  [35] . B+E model achieves a better F1-score and Recall than the previous best models, while adding profanity (B+E+P) we reach at the best overall improvement. B+E has approximately 24% higher Recall than B, as more depressed users were classified as depressed. On the contrary, the Precision decreases when we add the emotion detector. This can be explained by the fact that the model draws strong associations between the expression of negative emotions and depression. By integrating profanity (B+E+P) and morality (B+E+M) we observe further improvements in performance. Furthermore, we observe more balanced precision and recall scores. Surprisingly, we observe that adding both Profanity and Morality (B+E+P+M) does not improve the results further. This issue is attributed to difficulties in hyperparameter tuning and the simplicity of the fusion method. In Table  5  we present the results of our models in the Pirina Dataset compared with the best models of  [36]  and  [37] . Here, also, emotion, profanity and morality improve the overall performance. The combination of BERT, emotion and profanity (B+E+P) achieves the best overall results, similar to the RSDD.\n\nOverall, we note that affective and social norms features improve performance, both in the case of user-level classification in the RSDD dataset and the case of post-level classification in the Pirina dataset. We also note that this improvement is observed both in the case of a large dataset (RSDD), where approximately 28 million posts are used for training, and a very small dataset (Pirina) with under 2, 000 posts.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Conclusions",
      "text": "In this work we apply affective and social norm features for the task of depression detection from social media posts. The affective features are extracted from a pretrained emotion detector and fused with semantic representations, extracted from BERT. We fuse the combined BERT and affective representations with social norm features related to profanity and morality dimensions in a hierarchical architecture. The inclusion of social norm features is supported by our data analysis, which indicates their importance for depression detection. The profanity scores are found to be especially important. Interestingly, social norm features improve results irrespective of dataset size. The proposed feature combination and architecture is evaluated for post-level and user-level depression detection, yielding state-of-the-art results in the RSDD and Pirina datasets. In the future we plan to explore more elaborate fusion techniques for inclusion of social norm features. Furthermore, we plan to explore probing techniques and the interpretability of proposed architectures.",
      "page_start": 4,
      "page_end": 4
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: illustrates an overview of the system architecture. The",
      "page": 1
    },
    {
      "caption": "Figure 1: The proposed multi-level architecture.",
      "page": 2
    },
    {
      "caption": "Figure 1: , a Bi-directional Gated Recurrent Unit (Bi-GRU) network",
      "page": 2
    },
    {
      "caption": "Figure 1: These features are chosen through our data",
      "page": 2
    },
    {
      "caption": "Figure 2: Examples of the Pirina dataset for (a) depression-indicative post, (b) standard post. Green: profane words, Orange: words",
      "page": 3
    },
    {
      "caption": "Figure 2: , we present one sample of the",
      "page": 3
    },
    {
      "caption": "Figure 2: , we see that the profane word “f***ing” determines the",
      "page": 3
    },
    {
      "caption": "Figure 3: we see the overall histograms",
      "page": 3
    },
    {
      "caption": "Figure 3: Histograms from the Pirina dataset, indicating the",
      "page": 4
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "2Institute for Speech and Language Processing, Greece": "hliastriant1@gmail.com, {geopar,potam}@central.ntua.gr"
        },
        {
          "2Institute for Speech and Language Processing, Greece": "Abstract"
        },
        {
          "2Institute for Speech and Language Processing, Greece": "We propose a deep architecture for depression detection from"
        },
        {
          "2Institute for Speech and Language Processing, Greece": "social media posts.\nThe proposed architecture builds upon"
        },
        {
          "2Institute for Speech and Language Processing, Greece": "BERT to extract\nlanguage representations\nfrom social media"
        },
        {
          "2Institute for Speech and Language Processing, Greece": "posts\nand combines\nthese\nrepresentations using an attentive"
        },
        {
          "2Institute for Speech and Language Processing, Greece": "bidirectional GRU network. We incorporate affective informa-"
        },
        {
          "2Institute for Speech and Language Processing, Greece": "tion, by augmenting the text\nrepresentations with features ex-"
        },
        {
          "2Institute for Speech and Language Processing, Greece": "tracted from a pretrained emotion classiﬁer. Motivated by psy-"
        },
        {
          "2Institute for Speech and Language Processing, Greece": "chological\nliterature we propose to incorporate profanity and"
        },
        {
          "2Institute for Speech and Language Processing, Greece": "morality features of posts and words in our architecture using a"
        },
        {
          "2Institute for Speech and Language Processing, Greece": "late fusion scheme.\nOur analysis indicates that morality and"
        },
        {
          "2Institute for Speech and Language Processing, Greece": "profanity can be important\nfeatures\nfor depression detection."
        },
        {
          "2Institute for Speech and Language Processing, Greece": "We apply our model for depression detection on Reddit posts on"
        },
        {
          "2Institute for Speech and Language Processing, Greece": "the Pirina dataset, and further consider the setting of detecting"
        },
        {
          "2Institute for Speech and Language Processing, Greece": "depressed users, given multiple posts per user, proposed in the"
        },
        {
          "2Institute for Speech and Language Processing, Greece": "Reddit RSDD dataset. The inclusion of the proposed features"
        },
        {
          "2Institute for Speech and Language Processing, Greece": "yields\nstate-of-the-art\nresults\nin both settings, namely 2.65%"
        },
        {
          "2Institute for Speech and Language Processing, Greece": "and 6.73% absolute improvement in F1 score respectively."
        },
        {
          "2Institute for Speech and Language Processing, Greece": "Index Terms: Depression detection, BERT, Feature\nfusion,"
        },
        {
          "2Institute for Speech and Language Processing, Greece": "Emotion recognition, profanity, morality"
        },
        {
          "2Institute for Speech and Language Processing, Greece": ""
        },
        {
          "2Institute for Speech and Language Processing, Greece": ""
        },
        {
          "2Institute for Speech and Language Processing, Greece": "1.\nIntroduction"
        },
        {
          "2Institute for Speech and Language Processing, Greece": ""
        },
        {
          "2Institute for Speech and Language Processing, Greece": "Depression is a mental health disorder which affects a large por-"
        },
        {
          "2Institute for Speech and Language Processing, Greece": "tion of society. More speciﬁcally, [1] records 322 million peo-"
        },
        {
          "2Institute for Speech and Language Processing, Greece": "ple worldwide suffering from depression, which corresponds to"
        },
        {
          "2Institute for Speech and Language Processing, Greece": "4.4% of the world population.\nInterestingly,\nthe number of de-"
        },
        {
          "2Institute for Speech and Language Processing, Greece": "pressed people increased by 18.4% from 2005 to 2015 [2]."
        },
        {
          "2Institute for Speech and Language Processing, Greece": "In recent years, social media have become pervasive plat-"
        },
        {
          "2Institute for Speech and Language Processing, Greece": "forms, where people share information, opinions,\nthoughts and"
        },
        {
          "2Institute for Speech and Language Processing, Greece": ""
        },
        {
          "2Institute for Speech and Language Processing, Greece": "feelings.\nFor many people, social media platforms are places"
        },
        {
          "2Institute for Speech and Language Processing, Greece": ""
        },
        {
          "2Institute for Speech and Language Processing, Greece": "where they turn for support and self-disclose about\ntheir men-"
        },
        {
          "2Institute for Speech and Language Processing, Greece": ""
        },
        {
          "2Institute for Speech and Language Processing, Greece": "tal health. According to [3] and [4], there is a close association"
        },
        {
          "2Institute for Speech and Language Processing, Greece": ""
        },
        {
          "2Institute for Speech and Language Processing, Greece": "between depressive young adults and the excessive use of so-"
        },
        {
          "2Institute for Speech and Language Processing, Greece": ""
        },
        {
          "2Institute for Speech and Language Processing, Greece": "cial media. De Choudhury et al [5] ﬁnd that depressed social"
        },
        {
          "2Institute for Speech and Language Processing, Greece": ""
        },
        {
          "2Institute for Speech and Language Processing, Greece": "media users have different online activity and behavior patterns"
        },
        {
          "2Institute for Speech and Language Processing, Greece": ""
        },
        {
          "2Institute for Speech and Language Processing, Greece": "than non-depressed users. These studies indicate the feasibil-"
        },
        {
          "2Institute for Speech and Language Processing, Greece": ""
        },
        {
          "2Institute for Speech and Language Processing, Greece": "ity of depression detection from social media posts. Automatic"
        },
        {
          "2Institute for Speech and Language Processing, Greece": ""
        },
        {
          "2Institute for Speech and Language Processing, Greece": "depression detection could enable positive applications for the"
        },
        {
          "2Institute for Speech and Language Processing, Greece": ""
        },
        {
          "2Institute for Speech and Language Processing, Greece": "users, from suicide prevention to the development of effective,"
        },
        {
          "2Institute for Speech and Language Processing, Greece": ""
        },
        {
          "2Institute for Speech and Language Processing, Greece": "(semi-)automated mental health resources."
        },
        {
          "2Institute for Speech and Language Processing, Greece": ""
        },
        {
          "2Institute for Speech and Language Processing, Greece": "Psychological studies indicate that depressive disorders in-"
        },
        {
          "2Institute for Speech and Language Processing, Greece": "ﬂuence the affected people’s language use. In [6], depression is"
        },
        {
          "2Institute for Speech and Language Processing, Greece": ""
        },
        {
          "2Institute for Speech and Language Processing, Greece": "considered as a disorder of “concern for others”, as depressed"
        },
        {
          "2Institute for Speech and Language Processing, Greece": "individuals have often elevated levels of empathy. The authors"
        },
        {
          "2Institute for Speech and Language Processing, Greece": "bring evidence from neuroscience and psychology that demon-"
        },
        {
          "2Institute for Speech and Language Processing, Greece": "strate a connection between morality and depression. In [7], the"
        },
        {
          "2Institute for Speech and Language Processing, Greece": "authors ﬁnd a positive correlation between offensive language"
        },
        {
          "2Institute for Speech and Language Processing, Greece": "and depressed individuals in their social media posts. Vinger-"
        },
        {
          "2Institute for Speech and Language Processing, Greece": "hoets et al [8] argue that excessive swearing can lead to isola-"
        },
        {
          "2Institute for Speech and Language Processing, Greece": "tion, and therefore feelings of rejection and depressive disorder."
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "−h\n←": "the BERT representations and\nthe corresponding backward\ni"
        },
        {
          "−h\n←": "→h\n−h\n−\n←"
        },
        {
          "−h\n←": "hidden state. We concatenate\nand\nto obtain the hidden\ni\ni"
        },
        {
          "−h\n←": "states ci for the BERT branch:"
        },
        {
          "−h\n←": "−\n←"
        },
        {
          "−h\n←": "(4)\nci =\ni (cid:107)\ni"
        },
        {
          "−h\n←": "−\n←"
        },
        {
          "−h\n←": "Similarly,\nlet\ni and\ni be the i-th forward and backward"
        },
        {
          "−h\n←": "hidden states of\nthe BiGRU associated with the emotion de-"
        },
        {
          "−h\n←": "tector.\nthe hidden states for\nthe emotion\nThen, we obtain ei,"
        },
        {
          "−h\n←": "branch, as follows:"
        },
        {
          "−h\n←": "−\n←"
        },
        {
          "−h\n←": "(5)\nei =\ni (cid:107)\ni"
        },
        {
          "−h\n←": "into the ﬁnal rep-\nWe aggregate the hidden states ci and ei"
        },
        {
          "−h\n←": "resentations c and e for the BERT and emotion branches respec-"
        },
        {
          "−h\n←": "tively using an Attention Mechanism [24], on top of each of the"
        },
        {
          "−h\n←": "respective GRUs. Given the hidden states ci, we obtain the uni-"
        },
        {
          "−h\n←": "ﬁed representation c for the BERT branch as the weighted sum"
        },
        {
          "−h\n←": "of ci and the attention weights ai:"
        },
        {
          "−h\n←": "eti"
        },
        {
          "−h\n←": "c =\nti = q(ci)\nαi =\nαiti\n(6)"
        },
        {
          "−h\n←": "(cid:88) i\n(cid:80)"
        },
        {
          "−h\n←": "i eti"
        },
        {
          "−h\n←": "where q is a learnable mapping. We obtain the uniﬁed represen-"
        },
        {
          "−h\n←": "tation e for the emotion branch in a similar manner."
        },
        {
          "−h\n←": ""
        },
        {
          "−h\n←": "2.3. Fusion Layer"
        },
        {
          "−h\n←": "In this architecture level, given the representations c and e, we"
        },
        {
          "−h\n←": "combine them,\nin order to extract\nthe ﬁnal representation.\nIn-"
        },
        {
          "−h\n←": "spired by [25], we use a gating mechanism.\nSpeciﬁcally,\na"
        },
        {
          "−h\n←": "mask-vector is generated from e (the representation associated"
        },
        {
          "−h\n←": "with the emotion detector) with values between 0 and 1 and se-"
        },
        {
          "−h\n←": ""
        },
        {
          "−h\n←": "lects the salient dimensions of c (the representation associated"
        },
        {
          "−h\n←": ""
        },
        {
          "−h\n←": "with BERT). Concretely,"
        },
        {
          "−h\n←": ""
        },
        {
          "−h\n←": ""
        },
        {
          "−h\n←": "(7)\nz = c (cid:12) σ(Wl · e + bl)"
        },
        {
          "−h\n←": ""
        },
        {
          "−h\n←": "where Wl, bl are learnable parameters, σ is the sigmoid function"
        },
        {
          "−h\n←": "and z is the ﬁnal representation, which is fed into the classiﬁer."
        },
        {
          "−h\n←": "2.4. Additional Features"
        },
        {
          "−h\n←": "In the last\nlevel of our architecture, we add additional features,"
        },
        {
          "−h\n←": "as shown in Fig. 1. These features are chosen through our data"
        },
        {
          "−h\n←": "analysis and they can be profanity, morality or both. They will"
        },
        {
          "−h\n←": "be explained further in Section 3. We construct a vector x that"
        },
        {
          "−h\n←": ""
        },
        {
          "−h\n←": "includes the features related to the second level entity.\nIn the"
        },
        {
          "−h\n←": ""
        },
        {
          "−h\n←": "case of post classiﬁcation,\nthe entity is a post, whereas in the"
        },
        {
          "−h\n←": ""
        },
        {
          "−h\n←": "user classiﬁcation it is a user."
        },
        {
          "−h\n←": ""
        },
        {
          "−h\n←": "We integrate the x vector to our architecture right before the"
        },
        {
          "−h\n←": ""
        },
        {
          "−h\n←": "classiﬁer. Speciﬁcally, we concatenate, (cid:107), the x vector with the"
        },
        {
          "−h\n←": ""
        },
        {
          "−h\n←": "representation extracted from the fusion layer, z as in Eq. 8."
        },
        {
          "−h\n←": ""
        },
        {
          "−h\n←": "p = x (cid:107) z\n(8)"
        },
        {
          "−h\n←": ""
        },
        {
          "−h\n←": ""
        },
        {
          "−h\n←": "3. Datasets and Analysis"
        },
        {
          "−h\n←": ""
        },
        {
          "−h\n←": "3.1. Datasets"
        },
        {
          "−h\n←": ""
        },
        {
          "−h\n←": "Reddit Self-reported Depression Diagnosis (RSDD) dataset:"
        },
        {
          "−h\n←": "RSDD dataset [26] consists of Reddit posts. Multiple posts are"
        },
        {
          "−h\n←": ""
        },
        {
          "−h\n←": "included per user, and users are labeled as depressed when the"
        },
        {
          "−h\n←": ""
        },
        {
          "−h\n←": "poster self-reports that they suffer from depression. RSDD con-"
        },
        {
          "−h\n←": ""
        },
        {
          "−h\n←": "sists of\ntraining, validation and testing data and each of\nthem"
        },
        {
          "−h\n←": "3, 000\n35, 000"
        },
        {
          "−h\n←": "contains\napproximately\ndepressed\nusers\nand"
        },
        {
          "−h\n←": ""
        },
        {
          "−h\n←": "matched control users.\nPosts\nthat contain depression-related"
        },
        {
          "−h\n←": "keywords or are published in mental health-related subreddits"
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Figure 2: Examples of the Pirina dataset for (a) depression-indicative post, (b) standard post. Green: profane words, Orange: words": "related to social norms (morality) as found in the expanded LIWC."
        },
        {
          "Figure 2: Examples of the Pirina dataset for (a) depression-indicative post, (b) standard post. Green: profane words, Orange: words": "have been removed. Every user in the dataset has approximately"
        },
        {
          "Figure 2: Examples of the Pirina dataset for (a) depression-indicative post, (b) standard post. Green: profane words, Orange: words": "900 posts.\nIn Table 1, we present\nthe average number of posts"
        },
        {
          "Figure 2: Examples of the Pirina dataset for (a) depression-indicative post, (b) standard post. Green: profane words, Orange: words": "per user, as well as the average number of words that are used"
        },
        {
          "Figure 2: Examples of the Pirina dataset for (a) depression-indicative post, (b) standard post. Green: profane words, Orange: words": "in the posts for both classes,\nin the training set. We notice that"
        },
        {
          "Figure 2: Examples of the Pirina dataset for (a) depression-indicative post, (b) standard post. Green: profane words, Orange: words": "depressed users post\ntwice as much as the non-depressed and"
        },
        {
          "Figure 2: Examples of the Pirina dataset for (a) depression-indicative post, (b) standard post. Green: profane words, Orange: words": "they use more words per post in a rate of 5 : 3.2"
        },
        {
          "Figure 2: Examples of the Pirina dataset for (a) depression-indicative post, (b) standard post. Green: profane words, Orange: words": "Table 1: Datasets statistics for posts by depressed (D) and not"
        },
        {
          "Figure 2: Examples of the Pirina dataset for (a) depression-indicative post, (b) standard post. Green: profane words, Orange: words": "depressed (ND) individuals."
        },
        {
          "Figure 2: Examples of the Pirina dataset for (a) depression-indicative post, (b) standard post. Green: profane words, Orange: words": ""
        },
        {
          "Figure 2: Examples of the Pirina dataset for (a) depression-indicative post, (b) standard post. Green: profane words, Orange: words": ""
        }
      ],
      "page": 3
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "percentage of posts containing language related to these dimen-": "sions per class in the RSDD dataset."
        },
        {
          "percentage of posts containing language related to these dimen-": ""
        },
        {
          "percentage of posts containing language related to these dimen-": "Moral Dimension"
        },
        {
          "percentage of posts containing language related to these dimen-": ""
        },
        {
          "percentage of posts containing language related to these dimen-": ""
        },
        {
          "percentage of posts containing language related to these dimen-": "Harm/Care"
        },
        {
          "percentage of posts containing language related to these dimen-": ""
        },
        {
          "percentage of posts containing language related to these dimen-": ""
        },
        {
          "percentage of posts containing language related to these dimen-": "Cheating/Fairness"
        },
        {
          "percentage of posts containing language related to these dimen-": ""
        },
        {
          "percentage of posts containing language related to these dimen-": ""
        },
        {
          "percentage of posts containing language related to these dimen-": "Betrayal/Loyalty"
        },
        {
          "percentage of posts containing language related to these dimen-": ""
        },
        {
          "percentage of posts containing language related to these dimen-": ""
        },
        {
          "percentage of posts containing language related to these dimen-": "Subversion/Authority"
        },
        {
          "percentage of posts containing language related to these dimen-": ""
        },
        {
          "percentage of posts containing language related to these dimen-": ""
        },
        {
          "percentage of posts containing language related to these dimen-": "Degradation/Purity"
        },
        {
          "percentage of posts containing language related to these dimen-": ""
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "level of our architecture we extract word representations, while": "at the second level we combine the word representations to ob-",
          "Table 5: Results of different architectures on the Pirina Dataset.": ""
        },
        {
          "level of our architecture we extract word representations, while": "tain post representations. We evaluate the model using 10-fold",
          "Table 5: Results of different architectures on the Pirina Dataset.": ""
        },
        {
          "level of our architecture we extract word representations, while": "",
          "Table 5: Results of different architectures on the Pirina Dataset.": "Acc"
        },
        {
          "level of our architecture we extract word representations, while": "cross-validation on 90/10 train/test splits,\nfollowing the state-",
          "Table 5: Results of different architectures on the Pirina Dataset.": ""
        },
        {
          "level of our architecture we extract word representations, while": "of-the-art.\nFor each fold we train a model for 5 epochs using",
          "Table 5: Results of different architectures on the Pirina Dataset.": "91"
        },
        {
          "level of our architecture we extract word representations, while": "Cross entropy loss and Adam with learning rate 5 · 10−5.",
          "Table 5: Results of different architectures on the Pirina Dataset.": "91.30"
        },
        {
          "level of our architecture we extract word representations, while": "For all models we use Dropout 0.2. All Bi-GRUs have 128",
          "Table 5: Results of different architectures on the Pirina Dataset.": "91.89"
        },
        {
          "level of our architecture we extract word representations, while": "hidden size. We use PyTorch [33] in our implementation.",
          "Table 5: Results of different architectures on the Pirina Dataset.": "92.07"
        },
        {
          "level of our architecture we extract word representations, while": "For\nboth\ndatasets, we\ncompare\nthe\nperformance\nof\nthe",
          "Table 5: Results of different architectures on the Pirina Dataset.": "93.87"
        },
        {
          "level of our architecture we extract word representations, while": "BERT-only baseline (B) with the models\nthat\ntake into con-",
          "Table 5: Results of different architectures on the Pirina Dataset.": "92.79"
        },
        {
          "level of our architecture we extract word representations, while": "sideration the emotion detector (E), profanity (P) and morality",
          "Table 5: Results of different architectures on the Pirina Dataset.": "92.61"
        },
        {
          "level of our architecture we extract word representations, while": "(M). Thus, we experiment with (B+E) and then we add pro-",
          "Table 5: Results of different architectures on the Pirina Dataset.": ""
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "J. Schumm, “Identifying depressive symptoms from tweets: Fig-"
        },
        {
          "7. References": "[1] W. H. Organization et al., “Depression and other common mental",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "urative language enabled multitask learning framework,” in Proc."
        },
        {
          "7. References": "disorders:\nglobal health estimates,” World Health Organization,",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "28th COLING.\nInternational Committee on Computational Lin-"
        },
        {
          "7. References": "Tech. Rep., 2017.",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "guistics, Dec. 2020, pp. 696–709."
        },
        {
          "7. References": "[2]\nT. Vos, C. Allen, M. Arora, R. M. Barber, Z. A. Bhutta, A. Brown,",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "[21]\nS. Amir, M. Dredze, and J. W. Ayers, “Mental health surveillance"
        },
        {
          "7. References": "A. Carter, D. C. Casey, F. J. Charlson, A. Z. Chen et al., “Global,",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "over social media with digital cohorts,” in Proc. 6th Workshop on"
        },
        {
          "7. References": "regional, and national incidence, prevalence, and years lived with",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "CLPsych, 2019."
        },
        {
          "7. References": "disability for 310 diseases and injuries, 1990–2015: a systematic",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "[22]\nJ. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “BERT: Pre-"
        },
        {
          "7. References": "analysis for the global burden of disease study 2015,” The lancet,",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "training of deep bidirectional\ntransformers\nfor\nlanguage under-"
        },
        {
          "7. References": "2016.",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "standing,” in Proc. NAACL.\nAssociation for Computational Lin-"
        },
        {
          "7. References": "[3]\nL. Y. Lin, J. E. Sidani, A. Shensa, A. Radovic, E. Miller, J. B.",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "guistics, Jun. 2019."
        },
        {
          "7. References": "Colditz, B. L. Hoffman, L. M. Giles, and B. A. Primack, “Asso-",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "[23] K.\nCho,\nB.\nvan Merri¨enboer,\nC. Gulcehre,\nD.\nBahdanau,"
        },
        {
          "7. References": "ciation between social media use and depression among us young",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "F. Bougares, H. Schwenk, and Y. Bengio, “Learning phrase rep-"
        },
        {
          "7. References": "adults,” Depression and anxiety, 2016.",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "resentations using RNN encoder–decoder for statistical machine"
        },
        {
          "7. References": "[4] B. Keles, N. McCrae, and A. Grealish, “A systematic review:\nthe",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "translation,” in Proc EMNLP.\nAssociation for Computational"
        },
        {
          "7. References": "inﬂuence of social media on depression, anxiety and psychologi-",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "Linguistics, Oct. 2014."
        },
        {
          "7. References": "cal distress in adolescents,” International Journal of Adolescence",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "[24] D. Bahdanau, K. Cho, and Y. Bengio, “Neural machine translation"
        },
        {
          "7. References": "and Youth, 2020.",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "by jointly learning to align and translate,” 2016."
        },
        {
          "7. References": "[5] M. De Choudhury, M. Gamon, S. Counts, and E. Horvitz, “Pre-",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "[25] K. Margatina, C. Baziotis, and A. Potamianos, “Attention-based"
        },
        {
          "7. References": "dicting depression via social media,” in Proc. AAAI, 2013.",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "conditioning methods\nfor\nexternal\nknowledge\nintegration,”\nin"
        },
        {
          "7. References": "[6]\nL. E. O’Connor,\nJ. W. Berry, T. Lewis, K. Mulherin, and P. S.",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "Proc. 57th ACL.\nAssociation for Computational Linguistics, Jul."
        },
        {
          "7. References": "Crisostomo, “Empathy and depression:\nthe moral system on over-",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "2019."
        },
        {
          "7. References": "drive,” Empathy in mental illness, 2007.",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "[26] A. Yates, A. Cohan, and N. Goharian, “Depression and self-harm"
        },
        {
          "7. References": "[7] A.-M. Bucur, M. Zampieri, and L. P. Dinu, “An exploratory analy-",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "risk assessment in online forums,” in Proc. EMNLP.\nAssociation"
        },
        {
          "7. References": "sis of the relation between offensive language and mental health,”",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "for Computational Linguistics, Sep. 2017."
        },
        {
          "7. References": "in Findings ACL-IJCNLP 2021, Aug. 2021, pp. 3600–3606.",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "[27]\nI. Pirina and C¸ . C¸ ¨oltekin, “Identifying depression on reddit: The"
        },
        {
          "7. References": "[8] A. J. Vingerhoets, L. M. Bylsma, and C. De Vlam, “Swearing: A",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "effect of training data,” in Proc. EMNLP Workshop SMM4H: The"
        },
        {
          "7. References": "biopsychosocial perspective,” Psihologijske teme, 2013.",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "3rd Social Media Mining for Health Applications Workshop &"
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "Shared Task, 2018."
        },
        {
          "7. References": "[9]\nS. Rude, E.-M. Gortner, and J. Pennebaker, “Language use of de-",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "[28]\nS. Buechel and U. Hahn, “Emobank: Studying the impact of anno-"
        },
        {
          "7. References": "pressed and depression-vulnerable college students,” Cognition &",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "tation perspective and representation format on dimensional emo-"
        },
        {
          "7. References": "Emotion, 2004.",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "tion analysis,” in Proc. 15th ACL, 2017."
        },
        {
          "7. References": "[10]\nE. W. Hamilton and L. Y. Abramson, “Cognitive patterns and ma-",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "[29] Y. Chen, “Convolutional neural network for sentence classiﬁca-"
        },
        {
          "7. References": "jor depressive disorder: a longitudinal study in a hospital setting.”",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "tion,” Master’s thesis, University of Waterloo, 2015."
        },
        {
          "7. References": "Journal of Abnormal Psychology, 1983.",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "[30]\n“Building\na\nbetter\nprofanity\ndetection\nlibrary"
        },
        {
          "7. References": "[11] D.\nXezonaki,\nG.\nParaskevopoulos,\nA.\nPotamianos,\nand",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "with\nscikit-learn,”\nhttps://victorzhou.com/blog/"
        },
        {
          "7. References": "S. Narayanan, “Affective conditioning on hierarchical attention",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "better-profanity-detection-with-scikit-learn/."
        },
        {
          "7. References": "networks applied to depression detection from transcribed clini-",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "cal interviews,” Interspeech 2020, 2020.",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "[31]\nJ. Graham, J. Haidt, and B. A. Nosek, “Liberals and conservatives"
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "rely on different sets of moral foundations.” Journal of personality"
        },
        {
          "7. References": "[12]\nT. Nguyen, D. Phung, B. Dao, S. Venkatesh, and M. Berk, “Af-",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "and social psychology, 2009."
        },
        {
          "7. References": "fective and content analysis of online depression communities,”",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "IEEE Transactions on Affective Computing, 2014.",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "[32] O. Araque, L. Gatti, and K. Kalimeri, “Moralstrength: Exploiting"
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "a moral\nlexicon and embedding similarity for moral foundations"
        },
        {
          "7. References": "[13] G. Coppersmith, M. Dredze, C. Harman, K. Hollingshead, and",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "prediction,” Knowledge-based systems, 2020."
        },
        {
          "7. References": "M. Mitchell, “Clpsych 2015 shared task: Depression and ptsd on",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "twitter,” in Proc. 2nd Workshop on CLPsych, 2015.",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "[33] A. Paszke, S. Gross, S. Chintala, G. Chanan, E. Yang, Z. DeVito,"
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "Z. Lin, A. Desmaison, L. Antiga, and A. Lerer, “Automatic differ-"
        },
        {
          "7. References": "[14] M. A. Moreno, L. A. Jelenchick, K. G. Egan, E. Cox, H. Young,",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "entiation in pytorch,” 2017."
        },
        {
          "7. References": "K. E. Gannon, and T. Becker, “Feeling bad on facebook: Depres-",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "sion disclosures by college students on a social networking site,”",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "[34] G. Rao, Y. Zhang, L. Zhang, Q. Cong, and Z. Feng, “Mgl-cnn: A"
        },
        {
          "7. References": "Depression and anxiety, 2011.",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "hierarchical posts representations model for identifying depressed"
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "individuals in online forums,” IEEE Access, 2020."
        },
        {
          "7. References": "[15] A. Li, X. Huang, B. Hao, B. O’Dea, H. Christensen, and T. Zhu,",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "[35] G. Rao, C. Peng, L. Zhang, X. Wang, and Z. Feng, “A knowledge"
        },
        {
          "7. References": "“Attitudes towards suicide attempts broadcast on social media: an",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "enhanced ensemble learning model for mental disorder detection"
        },
        {
          "7. References": "exploratory study of chinese microblogs,” PeerJ, 2015.",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "on social media,” in KSEM.\nSpringer, 2020."
        },
        {
          "7. References": "[16] G. Coppersmith, M. Dredze, C. Harman, and K. Hollingshead,",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "[36] M. M. Tadesse, H. Lin, B. Xu,\nand L. Yang,\n“Detection of"
        },
        {
          "7. References": "“From adhd to sad: Analyzing the language of mental health on",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "depression-related posts in reddit social media forum,” IEEE Ac-"
        },
        {
          "7. References": "twitter\nthrough self-reported diagnoses,” in Proc. 2nd workshop",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "cess, 2019."
        },
        {
          "7. References": "on CLPsych, 2015.",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "[37]\nL. Ren, H. Lin, B. Xu, S. Zhang, L. Yang, S. Sun et al., “Depres-"
        },
        {
          "7. References": "[17] M. Lyons, N. D. Aksayli, and G. Brewer, “Mental distress and lan-",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "sion detection on reddit with an emotion-based attention network:"
        },
        {
          "7. References": "guage use: Linguistic analysis of discussion forum posts,” Com-",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "algorithm development and validation,” JMIR Medical Informat-"
        },
        {
          "7. References": "puters in Human Behavior, 2018.",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": "ics, 2021."
        },
        {
          "7. References": "[18]\nJ. W. Pennebaker, M. E. Francis, and R. J. Booth, “Linguistic in-",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "quiry and word count: Liwc 2001,” Mahway: Lawrence Erlbaum",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "Associates, 2001.",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "[19]\nS. Yadav,\nJ. P. Sain, A. Sheth, A. Ekbal, S. Saha, and P. Bhat-",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "tacharyya, “Assessing the severity of health states based on social",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        },
        {
          "7. References": "media posts,” 01 2021.",
          "[20]\nS. Yadav, J. Chauhan, J. P. Sain, K. Thirunarayan, A. Sheth, and": ""
        }
      ],
      "page": 5
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "",
      "authors": [
        "References"
      ],
      "venue": ""
    },
    {
      "citation_id": "2",
      "title": "Depression and other common mental disorders: global health estimates",
      "authors": [
        "W Organization"
      ],
      "year": "2017",
      "venue": "World Health Organization, Tech. Rep"
    },
    {
      "citation_id": "3",
      "title": "Global, regional, and national incidence, prevalence, and years lived with disability for 310 diseases and injuries, 1990-2015: a systematic analysis for the global burden of disease study 2015",
      "authors": [
        "T Vos",
        "C Allen",
        "M Arora",
        "R Barber",
        "Z Bhutta",
        "A Brown",
        "A Carter",
        "D Casey",
        "F Charlson",
        "A Chen"
      ],
      "year": "2016",
      "venue": "The lancet"
    },
    {
      "citation_id": "4",
      "title": "Association between social media use and depression among us young adults",
      "authors": [
        "L Lin",
        "J Sidani",
        "A Shensa",
        "A Radovic",
        "E Miller",
        "J Colditz",
        "B Hoffman",
        "L Giles",
        "B Primack"
      ],
      "year": "2016",
      "venue": "Depression and anxiety"
    },
    {
      "citation_id": "5",
      "title": "A systematic review: the influence of social media on depression, anxiety and psychological distress in adolescents",
      "authors": [
        "B Keles",
        "N Mccrae",
        "A Grealish"
      ],
      "year": "2020",
      "venue": "International Journal of Adolescence and Youth"
    },
    {
      "citation_id": "6",
      "title": "Predicting depression via social media",
      "authors": [
        "M Choudhury",
        "M Gamon",
        "S Counts",
        "E Horvitz"
      ],
      "year": "2013",
      "venue": "Proc. AAAI"
    },
    {
      "citation_id": "7",
      "title": "Empathy and depression: the moral system on overdrive",
      "authors": [
        "L O'connor",
        "J Berry",
        "T Lewis",
        "K Mulherin",
        "P Crisostomo"
      ],
      "year": "2007",
      "venue": "Empathy and depression: the moral system on overdrive"
    },
    {
      "citation_id": "8",
      "title": "An exploratory analysis of the relation between offensive language and mental health",
      "authors": [
        "A.-M Bucur",
        "M Zampieri",
        "L Dinu"
      ],
      "year": "2021",
      "venue": "Findings ACL-IJCNLP 2021"
    },
    {
      "citation_id": "9",
      "title": "Swearing: A biopsychosocial perspective",
      "authors": [
        "A Vingerhoets",
        "L Bylsma",
        "C Vlam"
      ],
      "year": "2013",
      "venue": "Swearing: A biopsychosocial perspective"
    },
    {
      "citation_id": "10",
      "title": "Language use of depressed and depression-vulnerable college students",
      "authors": [
        "S Rude",
        "E.-M Gortner",
        "J Pennebaker"
      ],
      "year": "2004",
      "venue": "Cognition & Emotion"
    },
    {
      "citation_id": "11",
      "title": "Cognitive patterns and major depressive disorder: a longitudinal study in a hospital setting",
      "authors": [
        "E Hamilton",
        "L Abramson"
      ],
      "year": "1983",
      "venue": "Journal of Abnormal Psychology"
    },
    {
      "citation_id": "12",
      "title": "Affective conditioning on hierarchical attention networks applied to depression detection from transcribed clinical interviews",
      "authors": [
        "D Xezonaki",
        "G Paraskevopoulos",
        "A Potamianos",
        "S Narayanan"
      ],
      "year": "2020",
      "venue": "Affective conditioning on hierarchical attention networks applied to depression detection from transcribed clinical interviews"
    },
    {
      "citation_id": "13",
      "title": "Affective and content analysis of online depression communities",
      "authors": [
        "T Nguyen",
        "D Phung",
        "B Dao",
        "S Venkatesh",
        "M Berk"
      ],
      "year": "2014",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "14",
      "title": "Clpsych 2015 shared task: Depression and ptsd on twitter",
      "authors": [
        "G Coppersmith",
        "M Dredze",
        "C Harman",
        "K Hollingshead",
        "M Mitchell"
      ],
      "year": "2015",
      "venue": "Proc. 2nd Workshop on CLPsych"
    },
    {
      "citation_id": "15",
      "title": "Feeling bad on facebook: Depression disclosures by college students on a social networking site",
      "authors": [
        "M Moreno",
        "L Jelenchick",
        "K Egan",
        "E Cox",
        "H Young",
        "K Gannon",
        "T Becker"
      ],
      "year": "2011",
      "venue": "Depression and anxiety"
    },
    {
      "citation_id": "16",
      "title": "Attitudes towards suicide attempts broadcast on social media: an exploratory study of chinese microblogs",
      "authors": [
        "A Li",
        "X Huang",
        "B Hao",
        "B O'dea",
        "H Christensen",
        "T Zhu"
      ],
      "year": "2015",
      "venue": "PeerJ"
    },
    {
      "citation_id": "17",
      "title": "From adhd to sad: Analyzing the language of mental health on twitter through self-reported diagnoses",
      "authors": [
        "G Coppersmith",
        "M Dredze",
        "C Harman",
        "K Hollingshead"
      ],
      "year": "2015",
      "venue": "Proc. 2nd workshop on CLPsych"
    },
    {
      "citation_id": "18",
      "title": "Mental distress and language use: Linguistic analysis of discussion forum posts",
      "authors": [
        "M Lyons",
        "N Aksayli",
        "G Brewer"
      ],
      "year": "2018",
      "venue": "Computers in Human Behavior"
    },
    {
      "citation_id": "19",
      "title": "Linguistic inquiry and word count: Liwc",
      "authors": [
        "J Pennebaker",
        "M Francis",
        "R Booth"
      ],
      "year": "2001",
      "venue": "Linguistic inquiry and word count: Liwc"
    },
    {
      "citation_id": "20",
      "title": "Assessing the severity of health states based on social media posts",
      "authors": [
        "S Yadav",
        "J Sain",
        "A Sheth",
        "A Ekbal",
        "S Saha",
        "P Bhattacharyya"
      ],
      "venue": "Assessing the severity of health states based on social media posts"
    },
    {
      "citation_id": "21",
      "title": "Identifying depressive symptoms from tweets: Figurative language enabled multitask learning framework",
      "authors": [
        "S Yadav",
        "J Chauhan",
        "J Sain",
        "K Thirunarayan",
        "A Sheth",
        "J Schumm"
      ],
      "year": "2020",
      "venue": "Proc. 28th COLING. International Committee on Computational Linguistics"
    },
    {
      "citation_id": "22",
      "title": "Mental health surveillance over social media with digital cohorts",
      "authors": [
        "S Amir",
        "M Dredze",
        "J Ayers"
      ],
      "year": "2019",
      "venue": "Proc. 6th Workshop on CLPsych"
    },
    {
      "citation_id": "23",
      "title": "BERT: Pretraining of deep bidirectional transformers for language understanding",
      "authors": [
        "J Devlin",
        "M.-W Chang",
        "K Lee",
        "K Toutanova"
      ],
      "year": "2019",
      "venue": "Proc. NAACL. Association for Computational Linguistics"
    },
    {
      "citation_id": "24",
      "title": "Learning phrase representations using RNN encoder-decoder for statistical machine translation",
      "authors": [
        "K Cho",
        "B Van Merriënboer",
        "C Gulcehre",
        "D Bahdanau",
        "F Bougares",
        "H Schwenk",
        "Y Bengio"
      ],
      "year": "2014",
      "venue": "Proc EMNLP"
    },
    {
      "citation_id": "25",
      "title": "Neural machine translation by jointly learning to align and translate",
      "authors": [
        "D Bahdanau",
        "K Cho",
        "Y Bengio"
      ],
      "year": "2016",
      "venue": "Neural machine translation by jointly learning to align and translate"
    },
    {
      "citation_id": "26",
      "title": "Attention-based conditioning methods for external knowledge integration",
      "authors": [
        "K Margatina",
        "C Baziotis",
        "A Potamianos"
      ],
      "year": "2019",
      "venue": "Proc. 57th ACL"
    },
    {
      "citation_id": "27",
      "title": "Depression and self-harm risk assessment in online forums",
      "authors": [
        "A Yates",
        "A Cohan",
        "N Goharian"
      ],
      "year": "2017",
      "venue": "Proc. EMNLP"
    },
    {
      "citation_id": "28",
      "title": "Identifying depression on reddit: The effect of training data",
      "authors": [
        "I Pirina",
        "C ¸öltekin"
      ],
      "year": "2018",
      "venue": "Proc. EMNLP Workshop SMM4H: The 3rd Social Media Mining for Health Applications Workshop & Shared Task"
    },
    {
      "citation_id": "29",
      "title": "Emobank: Studying the impact of annotation perspective and representation format on dimensional emotion analysis",
      "authors": [
        "S Buechel",
        "U Hahn"
      ],
      "year": "2017",
      "venue": "Proc. 15th ACL"
    },
    {
      "citation_id": "30",
      "title": "Convolutional neural network for sentence classification",
      "authors": [
        "Y Chen"
      ],
      "year": "2015",
      "venue": "Convolutional neural network for sentence classification"
    },
    {
      "citation_id": "31",
      "title": "Building a better profanity detection library with scikit-learn",
      "venue": "Building a better profanity detection library with scikit-learn"
    },
    {
      "citation_id": "32",
      "title": "Liberals and conservatives rely on different sets of moral foundations",
      "authors": [
        "J Graham",
        "J Haidt",
        "B Nosek"
      ],
      "year": "2009",
      "venue": "Journal of personality and social psychology"
    },
    {
      "citation_id": "33",
      "title": "Moralstrength: Exploiting a moral lexicon and embedding similarity for moral foundations prediction",
      "authors": [
        "O Araque",
        "L Gatti",
        "K Kalimeri"
      ],
      "year": "2020",
      "venue": "Moralstrength: Exploiting a moral lexicon and embedding similarity for moral foundations prediction"
    },
    {
      "citation_id": "34",
      "title": "Automatic differentiation in pytorch",
      "authors": [
        "A Paszke",
        "S Gross",
        "S Chintala",
        "G Chanan",
        "E Yang",
        "Z Devito",
        "Z Lin",
        "A Desmaison",
        "L Antiga",
        "A Lerer"
      ],
      "year": "2017",
      "venue": "Automatic differentiation in pytorch"
    },
    {
      "citation_id": "35",
      "title": "Mgl-cnn: A hierarchical posts representations model for identifying depressed individuals in online forums",
      "authors": [
        "G Rao",
        "Y Zhang",
        "L Zhang",
        "Q Cong",
        "Z Feng"
      ],
      "year": "2020",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "36",
      "title": "A knowledge enhanced ensemble learning model for mental disorder detection on social media",
      "authors": [
        "G Rao",
        "C Peng",
        "L Zhang",
        "X Wang",
        "Z Feng"
      ],
      "year": "2020",
      "venue": "A knowledge enhanced ensemble learning model for mental disorder detection on social media"
    },
    {
      "citation_id": "37",
      "title": "Detection of depression-related posts in reddit social media forum",
      "authors": [
        "M Tadesse",
        "H Lin",
        "B Xu",
        "L Yang"
      ],
      "year": "2019",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "38",
      "title": "Depression detection on reddit with an emotion-based attention network: algorithm development and validation",
      "authors": [
        "L Ren",
        "H Lin",
        "B Xu",
        "S Zhang",
        "L Yang",
        "S Sun"
      ],
      "year": "2021",
      "venue": "JMIR Medical Informatics"
    }
  ]
}