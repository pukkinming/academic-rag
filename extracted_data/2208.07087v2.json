{
  "paper_id": "2208.07087v2",
  "title": "Estimating Personal Model Parameters From Utterances In Model-Based Reminiscence",
  "published": "2022-08-15T09:33:23Z",
  "authors": [
    "Shoki Sakai",
    "Kazuki Itabashi",
    "Junya Morita"
  ],
  "keywords": [
    "model-based reminiscence",
    "cognitive modeling",
    "cognitive architecture",
    "ACT-R",
    "interactive system",
    "parameter estimation"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Reminiscence therapy is mental health care based on the recollection of memories. However, the effectiveness of this method varies amongst individuals. To solve this problem, it is necessary to provide more personalized support; therefore, this study utilized a computational model of personal memory recollection based on a cognitive architecture adaptive control of thought-rational (ACT-R). An ACT-R memory model reflecting the state of users is expected to facilitate personal recollection. In this study, we proposed a method for estimating the internal states of users through repeated interactions with the memory model. The model, which contains the lifelog of the user, presents a memory item (stimulus) to the user, and receives the response of the user to the stimulus, based on which it adjusts the internal parameters of the model. Through the repetition of these processes, the parameters of the model will reflect the internal states of the user. To confirm the feasibility of the proposed method, we analyzed utterances of users when using a system that incorporates this model. The results confirmed the ability of the method to estimate the memory retrieval parameters of the model from the utterances of the user. In addition, the ability of the method to estimate changes in the mood of the user caused by using the system was confirmed. These results support the feasibility of the interactive method for estimating human internal states, which will eventually contribute to the ability to induce memory and emotions recall for our well-being.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "I. Introduction",
      "text": "Happiness or health is one of our universal and constant desires. According to the WHO Charter, \"health is a state of complete physical, mental, and social well-being and not merely the absence of disease or infirmity  [1] .\" This definition suggests the importance of being mentally and socially, as well as physically fit. One of the ways to improve one's mental well-being is by recollecting pleasant memories from the past. The emotion that arises from recalling pleasant memories of the past is known as nostalgia across various cultures  [2] , and has been reported to principally be a positive emotion, although it also includes bittersweet feelings  [3] .\n\nThe effect of nostalgia has been applied to mental health care. For example, Butler proposed the use of psychotherapies, in which people discuss their old experiences and memories from past photographs, music, and other media related to This work was supported by JSPS KAKENHI Grant Numbers 20H05560 and 22H04861. them, for mental health care  [4] . Such memory-based therapies include life review and reminiscence. The former aims to reevaluate one's life by reflecting on the past, whereas the latter aims to achieve psychological stability by evoking nostalgic memories. Reminiscence therapy has been demonstrated to promote positive emotions and suppress negative emotions for all age groups  [5] ,  [6]  not only to improve cognitive function in the elderly and patients with dementia  [7] ,  [8] .\n\nAmong several types of reminiscence therapies, this study mainly focused on the use of personal recollections, rather than group recollection  [9] , to resolve large individual differences in emotional factors involved in memory contents. In addition, we assumed two axes of core affect (arousal and valence)  [10]  as the internal factors affecting the memory recollection of an individual  [11] . This assumption suggests that encouraging memory recollection based on the state of these internal variables should provide appropriate support for the reminiscence of an individual.\n\nTo achieve this personalized support, this study utilized a computational model that represents the recollection process of personal memory. There is considerable research on the simulation of human cognitive processes using cognitive architectures  [12] ,  [13] , which is a modeling approach that employs a standardized structure to represent an individual process occurring during a specific task. In addition, these structures can interact with humans by providing a stimulus to the user and receiving a response to it. Accordingly, the model reflects the internal state of the user by adjusting the parameters of the cognitive model through repeated interactions.\n\nWe believe that building a cognitive model that simulates the memory recollection of the user can provide support for personalized reminiscence. To date, the authors have explored the method of tracing the user's internal state during memory recall. Based on these previous studies, this study proposed an interaction design for a cognitive model that can trace the human internal state. To confirm the feasibility of the proposed design, we analyzed the utterance data obtained when a reminiscence support system equipped with the cognitive model was used.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Ii. Related Works",
      "text": "This section reviews previous research relating to the memory recollection support method investigated in this study.\n\nSection II-A describes the framework of the cognitive architecture. Section II-B introduces research on systems that support individual memory recollections as the precedents of this study. Following this review, Section II-C clarifies the limitations of the previous studies, which necessitated the goal of this study.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "A. Cognitive Architecture And Memory Models",
      "text": "As mentioned previously, cognitive architecture is a structure that represents general human cognitive processes. This structure can simulate diverse cognitive functions for various tasks and individuals by constructing cognitive models on a common foundation. Among the various cognitive architectures (see  [14]  as a review), adaptive control of thoughtrational (ACT-R) has been employed in various studies  [15] . The essential components of ACT-R have been implemented as a production system, and are composed of various modules for vision, motor movements, memory storage, and goal management. The system can capture various aspects of human cognition by communicating information between the modules that correspond to each part of the human brain, indicating the ability of ACT-R to reproduce the human internal process.\n\nSome studies have modeled individual humans using the ACT-R. For example, Somer et al proposed the concept of the \"Cognitive Twin\"  [16]  and demonstrated the efficacy of ACT-R for personalized decision support by constructing and using a decision-making model of an individual. Such individualization of cognitive functions in the ACT-R was realized by the knowledge (memory) and the parameters involved in the use of knowledge. By manipulating these factors, the ACT-R model generates a variety of behaviors related to the same task. The knowledge incorporated in the ACT-R consists of declarative and procedural knowledge. Declarative knowledge comprises units known as \"chunk\", and individual chunks are linked to form a semantic network through attributes. Production rules, which involve procedural knowledge, are necessary for serially exploring such semantic networks. Accordingly, the ACT-R model selects one of the attributes linked to the currently recalled knowledge, and induces its to the next unit of knowledge.\n\nThis memory retrieval process can be diversified by manipulating the numerical parameters attached to the knowledge. Chunks and production rules have parameters called the activation and the utility, respectively. The activations are affected by the frequency of memory recall and memory decay, whereas the utilities are affected by rewards and the learning rate. When invoking declarative knowledge using a semantic network, the utility of the production rule is used in selecting attributes, and the activation determines the chunk to be retrieved when there are multiple available candidates among the selected attributes.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "B. Memory Support Systems Using Cognitive Models",
      "text": "This study follows a series of ACT-R based memory support systems developed by the authors' group. First, Morita et al  [17]  developed a photo slideshow system that supports reminiscence therapy and utilized the memory mechanism of the ACT-R described in Section II-A. This slide-show system includes a collection of private photos of users as a lifelog, and these photos are connected to each other via semantic links classified into four attributes: Who (person appearing in the photos), What (results of image recognition), When (timestamp), and Where (GPS information). The ACT-R model sequentially recollects photos by following these semantic links based on the utilities of each attribute and the activation of each memory item. The authors asserted that such memory transitions simulate mental time travel, which is vivid recalling of experiences in a time that is not the current time, as if experiencing time travel  [18] . Based on this assumption, they proposed a model-based reminiscence using visualizations generated by this mental time travel model.\n\nThe model-based reminiscence involves the recollection of past memory based on dynamically changing photos in the form of a slideshow. This method is considered to learn the cognitive and emotional states of the user, and present photos based on the learning (personalized) results. To utilize a user's reaction for such learning, Itabashi et al developed an interactive method based on an emotional model for monitoring the state of the user  [19] . In this system, the authors assembled time-series data based on heart rate variability (HRV) and online subjective mood rating 1  as interactive parameters. The feedback from the HRV (arousal) was directly mapped to a noise assigned to the activation of the photo, whereas the online subjective mood rating (valence) was mapped to the reward related to the rule for retrieving the photo.\n\nACT-R theoretically assumes that activation-based memory retrieval causes a concentration of retrieval on the most recent memory  [20] ,  [21] . Therefore, the activation is considered to reflect the physiological arousal  [22] . By applying this assumption and utilizing HRV, the photo retrieval of the system proposed by Itabashi et al concentrates on a specific photo when the user is in a stress state (i.e., small HRV). Contrary, retrieval is not limited to recent photos but also older photos when arousal is low and a relaxed state is induced (i.e., high HRV).\n\nIn addition, the interactive memory retrieval proposed by Itabashi et al has been applied in other contexts beyond a photo slideshow. For example, Morita et al  [23]  developed a web extension that mitigates negative emotions when using the Internet by building a model of memory and emotion using the ACT-R. They focused on web advertising, including behavioral targeting, to naturally apply memory models in a web environment. Their system displays regularly changing images on web pages, and these images affect the implicit memory process of the user. They confirmed inhibition of negative memory recall during web use using a memory and emotion model, as well as physiological sensing to modulate memory retrieval.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "C. Limitations Of The Past Studies",
      "text": "As discussed above, cognitive model-based personalized memory supports have been developed. However, the reliance of previous systems on physiological data (i.e., HRV) that can only be measured using dedicated equipment has limited its application in various fields. In addition, the mood state rating used by Itabashi et al  [19]  requires the user to intentionally operate the interface every time a picture is changed, which may inhibit natural reminiscence. To solve these limitations, this study proposed and tested an interaction design that indirectly estimates the internal states of the user by applying the machine-learning method to naturally produced user responses measured using a conventional device.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Iii. Interactive Estimation Of User Model Parameters",
      "text": "The general framework of the human-model interaction adopted in this study is described in Fig.  1 . In this framework, the model consists of several parameters for simulating memory recall as the internal states (I ). Based on the current I , the model provides stimuli (S) to humans and receives their responses (R). Subsequently, based on the human response, the model updates its internal state I and determines the next stimulus S based on the updated I . By repeating this interaction, we expect that the internal state of the model (I ) will eventually reflect the human internal state (I).\n\nThis framework is applied to the model-based reminiscence described in the previous section: the stimulus (S) corresponds to the display photo, and the human response (R) corresponds to verbal/nonverbal reactions to the photo. Although a human internal state (I) cannot be directly observed, the self-rating of the mood state by the user can be obtained. In contrast, the internal state of the model (I ) is considered a parameter that can be observed by the modeler. The parameters consisted in the model-based reminiscence include the activation A i and the utility U i , which are defined as follows:\n\n• Utility: As mentioned in Section II-B, each of the photos in the declarative knowledge of the model consists of four types of attributes, Who (p: person), What (o: object), Where (l: location), and When (t: time). Fig.  2  shows an example of a network created from the attributes attached to photos. As shown in the image, the photos form a network connected by common attributes, and attributes to be used to move to the next photos are determined by the utility of the rule i corresponding to the attribute. The utility for the rule i can be expressed as:\n\nwhere U i n is calculated from the previous utility U i n-1 , the learning rate α, and the reward R i n provided by the self-rating of mood by the user.\n\n• Activation: Based on the original ACT-R setting  [15] , the activation A i in this study is calculated as:\n\nwhere n, t j , and d are the frequency of the recollection of chunk i, the time passed since the jth recall, and the decay rate, respectively. These parameters induce the concentration on a specific photo  [21] , whereas Sa i indicates a term representing the effects of contexts (see  [17]  for details). i is a transient noise parameter that mitigates the concentration on a specific photo, which was mapped to the HRV of the user in the previous studies  [19] ,  [23] . In this study, we assumed that the stimulus (S) provided by the model is determined according to the internal state of the model (I ), which indirectly affects the human internal state (I). Based on this relationship, this study assumed that the estimation of the internal state of the model (I ) using the human response (R) is a means of estimating the human internal state (I). Thus, this study proposed a method that interactively estimates the human internal states based on the model's internal states and human responses to stimuli. To verify the practicability of this proposed method, we investigated the possibility of estimating the two internal states (i.e., the human and model internal states) from the human response (R). To achieve this, we set two research questions (RQs): RQ 1 (R → I ) Is it possible to estimate the internal state of the model from human responses to stimuli? RQ 2 (R → I) Is it possible to estimate the human internal state (obtained by self-reports) from human responses? Fig.  3 . Interface for mood state rating. Users rate their mood state using the interface in the red square.\n\nThese questions were examined based on the verbal utterances as R obtained during the experiment where the ACT-R memory model presented lifelog photos (S) to participants.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Iv. Method",
      "text": "This section presents the investigation method for the feasibility of the proposed estimation method. First, the experiment using the model-based reminiscence system is described. Next, the dataset constructed from the experiment is presented. Lastly, the analytical methods are explained.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "A. Experiment",
      "text": "To examine the effect of the different internal states of the model on the human internal states, we compared the behavior of participants under four conditions (within participants): 1) no activation and no reward, 2) no activation with reward, 3) activation with no reward, 4) activation with reward.\n\nAs described in Section II-A, the activation of ACT-R is affected by the frequency of memory recall and by memory decay. Therefore, under the condition in which the activation was calculated, intensive retrieval of recent and frequently retrieved photos is expected to occur owing to the characteristics of the memories simulated by ACT-R. In contrast, when the activation was not calculated, not only recent but also older photos are retrieved. In addition, as described in Section II-A and II-B, the utility value determines which attributes are used to retrieve the photos. Therefore, the condition with the reward induces the retrieval of photos that reflect the mood towards the currently displayed photo. From the combination of the effects of these parameters, the model can be assumed to exhibit the behavior listed in Table  I , where each factor corresponds to the two axes of core affect  [10] .\n\nFor the experiment, twenty-four participants aged 21-61 consisting of 13 males and 11 females were recruited through the crowdsourcing service Lancers 2  , and the experiment was conducted using the video chat tool Zoom 3  . Before participating in the experiment, they provided their personal photos, whose minimum number of photos required to participate in the experiment was 200.\n\nParticipants watched all four conditions of the slideshow in the experiment. As there were four experimental conditions, 24 possible patterns of viewing orders existed. The 24 participants were assigned to each pattern in order to counterbalance the viewing order of the experimental conditions. The viewing duration for each condition was 5 min.\n\nTo evaluate the changes in the mood state caused by viewing the photo slideshow, a mood state survey was conducted using the Japanese version of the Profile of Mood States 2nd Edition (POMS-2)  [24]  before and after viewing each photo slideshow condition. The participants were also asked to verbalize their thoughts while viewing the photos  [25]  and rate their current mood on a 6-point scale in response to the photos displayed on the user interface, as indicated by the red boxed position in Fig.  3 .",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "B. Data Set",
      "text": "Both the text and voice data of the participants' utterances were used for the analysis. The text data was constructed using the software tool Vrew 4  , which enables the automatic transcription of recorded audio through voice recognition. After the automatic transcription, typographical errors were corrected manually, and tags indicating the start and end of the experiment and the time the photos were switched were inserted.\n\nReferring to the photo switching time tag, the recorded audio data was segmented. Following this first segmentation, segments longer than 11 s were further divided into collections of 11 s segments (11 s is the approximate unit time to switch the display photos). The ACT-R model used in this experiment is programmed to retrieve a photo every 11 s. If the model failed in retrieving an image or retrieved the same photo as the previous trial, the displayed photos were not switched.\n\nTo estimate the internal states of the model and participants, we extracted prosodic features from the divided audio files using openSMILE, which is an open-source toolkit that can automatically extract features from audio signals and is primarily used for automatic emotion recognition  [26] . Particularly, we utilized a feature vector known as the eGeMAPS feature set, which consists of a total of 88 features: 62 minimalistic parameter sets and 26 extended parameter sets  [27] . Subsequently, a score obtained from the sentiments analysis using Google's Cloud Natural Language API 5  applied to the transcribed texts was added to the features and an 89-dimensional feature vector was constructed for the analysis.\n\nThe total number of utterance feature vectors created by the aforementioned procedure was 2403 (an average of 100.125 for the 24 participants). These feature vectors were standardized before analysis.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "C. Analysis Method",
      "text": "Using the as-obtained feature vectors, the internal states of both the model and the participants were classified, and RQs described in Section III were addressed using the results as follows:\n\n• Analysis for RQ 1: The experimental conditions were classified according to the utterances of the participants.   As the parameters of the internal state of the model were manipulated as the experimental condition, which involves the activation and the reward, we assumed that RQ 1 answered \"yes\" if this classification is successful.\n\n• Analysis for RQ 2: Compared to that of the model, the human internal state cannot be directly observed. Therefore, we classified the data obtained by indirect means (i.e., the self-reports and the self-rating of their moods using the user interface). This analysis was composed of two types of analyses: the first analysis is on the change in the mood ratings measured after the end of each condition, and the other is on the change in the mood ratings for each photo assigned as a task during the photo viewing. The latter analysis is expected to better reflect the real-time changes in the mood of participants. For this analysis, a support vector machine (SVM) was used with the parameters optimized by the grid search. The kernel and parameter ranges are shown in Table  II . The evaluation was based on the accuracy and F-measure of the 5-fold crossvalidation. According to the classification results shown in Table III, the accuracy was calculated using:\n\nThe F-measure was calculated 2•P recision•Recall P recision+Recall using Precision ( T P T P +F P ) and Recall ( T P T P +F N ).",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "V. Result",
      "text": "This section presents the results of our analysis regarding the two RQs. Sections V-B and V-C present the results of the analyses of RQ 1 (i.e., estimating the model's internal state from human responses) and RQ 2 (i.e., estimating the human internal state from his / her reactions), respectively. Before presenting these analyses, Section V-A presents the basic data on the model and human behavior obtained in the experiment.  A. Basic Results of the Experiment 1) Model behavior: Fig.  4  shows the results of the number of photos (types) for each of the experimental conditions. In this graph, the photos that were displayed more than once were counted as one to eliminate duplicates, implying that a smaller value indicates that the model focused on smaller photo sets. A two-way (the activation vs. the reward) analysis of variance (ANOVA) was conducted using the number of photos presented as the dependent variable. The analysis revealed that there was a significant difference in the activation (F (1, 23) = 95.48, p < .01). This result confirmed the effect of activation explained in Section III. The analysis in Section V-B presents the examination of the detectability of such model difference from the utterance during the task.\n\n2) Mood changes of the participants: Fig.  5  shows the total mood disturbance (TMD) scores, which is a measure of the overall mood state in POMS-2. The dashed line in the figure corresponds to the TMD score when measured prior to the start of the experiment. A two-way (the activation vs.the reward) ANOVA with the TMD scores as the dependent variable indicated a significant main effect in the reward (F (1, 23) = 4.59, p < .05). As the TMD score indicates that the negativity of a mood increases with an increase in the score, these results suggest that the participants were induced to feel more positive under the reward calculation condition than under the no reward condition by reflecting the mood of the participants to the model. The possibility of detecting such mood changes from the utterance during the task is explored in Section V-C.",
      "page_start": 5,
      "page_end": 6
    },
    {
      "section_name": "B. Classification Of The Internal States Of The Model 1) Combination Of The Two Parameters:",
      "text": "To address RQ 1, the four conditions, which involve the presence or absence of activation and rewards, were classified. The result revealed that the classification performance exceeded chance level (Accuracy conditions = 0.456, F conditions = 0.457). These results and the heat map shown in Fig.  6  suggest the possibility of estimating differences in the internal state of the model using utterances from the user.\n\n2) Independent parameters: Next, we further examined how well each of the internal states of the model (activation and reward) can be classified from the response of the participants. Thus, the analysis consisted of two classifications: classification of the \"calculated\" or \"not calculated\" activation, and classification of the \"calculated\" or \"not calculated\" the reward. The confusion matrices of these classifications are shown in Figs.  7  and 8 . Both matrices exhibited moderate classification results (Accuracy A = 0.640, F A = 0.640, Accuracy R = 0.680, F R = 0.679). From these results and the relationships discussed in Section III, the differences in the stimuli provided by the model were considered to affect the human internal state, and those differences in the internal state were reflected in the responses (utterance).",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "C. Classification Of Human Internal States",
      "text": "1) Classification based on post-hoc self-report: This analysis investigated the feasibility of estimating the human internal state from their utterances (RQ2). In this analysis, we classified whether the TMD scores of the POMS-2, which were answered after viewing the photos, were higher or lower than those before viewing or after viewing one of the previous conditions. However, two participants whose scores kept decreasing during the experiment were excluded from this analysis. The results are shown in Fig.  9 , and they indicate that the classification performance for the human internal state was better than that for the internal state of the model (Accuracy T M D = 0.738, F T M D = 0.738). This result  suggests the possibility of estimating changes in the mood of users from their utterances.\n\n2) Classification based on real-time self-report: Next, we examined the possibility of the real-time estimation of the human internal state. This analysis classified the changes in the mood rating during the photo presentation. Each utterance segment was labeled with \"up\" and \"down\" direction tags to indicate whether the participants reported that their feeling moved positively or negatively, respectively. Data segments in which there was no change were excluded. The resulting confusion matrix is shown in Fig.  10 . The classification performance was not better than that of chance (Accuracy M oodRating = 0.511, F M oodRating = 0.505). This result may be partly attributed to the fact that some participants made few moves on the user interface during the experiment.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "D. Classification For Individual Participants",
      "text": "The previous classification included all utterance segments without distinguishing participants. Considering the characteristics of prosody and emotion change, it is reasonable to assume that individual differences distorted the classification results. Therefore, in this section, we presented the classification results for each participant. Table  IV  summarizes the results of the model and human internal states for all participants. As indicated in the mean scores, although there was no difference in the general patterns of the performance, there were improvements in the classification results in this analysis. The classification results for POMS-2 (post-hoc selfreports) were higher than those for the two model parameters (activation and reward). The classification for the real-time human internal states exhibited the worst classification performance.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Vi. Conclusion",
      "text": "In the first section, we discussed the importance of providing support matched to the human internal state to obtain the appropriate effect of reminiscence therapy. In this study, we employed a model-based reminiscence with a cognitive architecture to support personalized reminiscence. To personalize the model, the parameters of the model should be mapped to the human internal state during memory recollection. Although previous studies have directly mapped physiological indices to corresponding model parameters, the application of these methods under various settings is limited. Therefore, to estimate the human internal state when using model-based reminiscence, we proposed a machine-learning based method, in which the model interactively estimates the human internal state using naturally produced user response (utterance).\n\nTo verify the feasibility of the proposed method, we classified internal states using the utterances of participants during photo observation. In this analysis, we attempted to classify the internal state of the model (experimental conditions) and the human internal state (POMS-2, mood rating). The first classification revealed that although the performance was not high, the internal states of the model can be estimated from human reactions (R → I in Fig.  1 ). The second analysis revealed that the POMS-2 classification results exhibited better classification than the classification of the internal states of the model. This result suggests that it is possible to estimate changes in the human mood state from prosodic features, and indicates the possibility of estimating human internal states from the human responses (R → I in Fig.  1 ).\n\nThese results indicate that the two RQs described in this study can be answered. In addition, these classification results also support the effectiveness of the model-based reminiscence. Particularly, the fact that we were able to classify differences in the internal state of the model from the human responses indicates that different internal states of the model caused differences in the human responses. This implies that differences in the internal parameters of the model affected the human internal state. Thus, this study successfully advanced the interactive memory support approach based on cognitive models. We believe that this approach will contribute to the control of memory recall accompanied with emotions.\n\nHowever, some limitations should be noted. This study did not consider how the estimation of the internal state of humans and models can be utilized to improve the humanmodel interaction. Particularly, although the fact that the success of this classification reflects the effectiveness of the model parameter in stimulating the human internal state was considered, the use of the estimation of the internal state of the model was not described. In the future study, a design for implementing the indices in the framework of interactive memory support should be developed.\n\nFinally, it should also be noted that the classification of the human internal state is based on indirect indicators. Regarding the means of observing human internal states, posthoc measurements cannot address changes in the internal state depending on the situation, and real-time rating is problematic in terms of user load. Although these limitations are some of our motivations to utilize natural user response (verbalization), as an experimental study, it is better to collect more accurate user responses in real-time. Future studies should collect physiological data to support the result obtained in this study.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Ethical Impact Statement",
      "text": "The experiment was reviewed and approved by Shizuoka University Research Ethics Committee. In the experiments of this study, we informed the participants fully about the handling of their personal data in advance, and collected the data after obtaining their free-will consent. If participants request that all photos uploaded to the server be deleted, they are informed that they can be completely deleted from the server.",
      "page_start": 7,
      "page_end": 7
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Scheme of the Human-Model interaction. The model provides a",
      "page": 3
    },
    {
      "caption": "Figure 1: In this framework,",
      "page": 3
    },
    {
      "caption": "Figure 2: Example of photos network. The number A given to each photo",
      "page": 3
    },
    {
      "caption": "Figure 3: Interface for mood state rating. Users rate their mood state using the",
      "page": 4
    },
    {
      "caption": "Figure 3: B. Data Set",
      "page": 4
    },
    {
      "caption": "Figure 4: Number of photos pre-",
      "page": 5
    },
    {
      "caption": "Figure 5: TMD scores for POMS-2",
      "page": 5
    },
    {
      "caption": "Figure 4: shows the results of the number",
      "page": 5
    },
    {
      "caption": "Figure 5: shows the",
      "page": 5
    },
    {
      "caption": "Figure 6: Classiﬁcation results of the experimental conditions. (A: Activation,",
      "page": 6
    },
    {
      "caption": "Figure 7: Activation classiﬁed result.",
      "page": 6
    },
    {
      "caption": "Figure 8: Reward classiﬁed result.",
      "page": 6
    },
    {
      "caption": "Figure 6: suggest the possibility",
      "page": 6
    },
    {
      "caption": "Figure 9: , and they",
      "page": 6
    },
    {
      "caption": "Figure 9: Classiﬁcation of changes in",
      "page": 6
    },
    {
      "caption": "Figure 10: Classiﬁcation of changes",
      "page": 6
    },
    {
      "caption": "Figure 10: The classiﬁcation performance was",
      "page": 6
    },
    {
      "caption": "Figure 1: ). The second analysis",
      "page": 7
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Reward (Valence)": "Not calculated\nCalculated"
        },
        {
          "Reward (Valence)": "Biased search toward some photos.\nBiased search toward some photos.\nNot\nreact\nto participants’ moods\nReact\nto participants’ moods\nWide search reaching to a variety of photos.\nWide search reaching to a variety of photos.\nNot\nreact\nto participants’ moods.\nReact\nto participants’ moods."
        }
      ],
      "page": 5
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "True Value": "True\nFalse"
        },
        {
          "True Value": "TP\nFP\n(True Positive)\n(False Positive)\nFN\nTF\n(False Negative)\n(True Negative)"
        }
      ],
      "page": 5
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Constitution of the world health organization. 1946",
      "year": "2002",
      "venue": "International Health Conference"
    },
    {
      "citation_id": "2",
      "title": "Pancultural nostalgia: prototypical conceptions across cultures",
      "authors": [
        "E Hepper",
        "T Wildschut",
        "C Sedikides",
        "T Ritchie",
        "Y.-F Yung",
        "N Hansen",
        "G Abakoumkin",
        "G Arikan",
        "S Cisek",
        "D Demassosso"
      ],
      "year": "2014",
      "venue": "Emotion"
    },
    {
      "citation_id": "3",
      "title": "Nostalgia: Conceptual issues and existential functions",
      "authors": [
        "C Sedikides",
        "T Wildschut",
        "D Baden"
      ],
      "year": "2004",
      "venue": "Nostalgia: Conceptual issues and existential functions"
    },
    {
      "citation_id": "4",
      "title": "The life review: An interpretation of reminiscence in the aged",
      "authors": [
        "R Butler"
      ],
      "year": "1963",
      "venue": "Psychiatry"
    },
    {
      "citation_id": "5",
      "title": "Remembering for resilience: Brief cognitive-reminiscence therapy improves psychological resources and mental well-being in young adults",
      "authors": [
        "D Hallford",
        "S Hardgrove",
        "M Sanam",
        "S Oliveira",
        "M Pilon",
        "T Duran"
      ],
      "year": "2021",
      "venue": "Remembering for resilience: Brief cognitive-reminiscence therapy improves psychological resources and mental well-being in young adults"
    },
    {
      "citation_id": "6",
      "title": "Using the past to enhance the present: Boosting happiness through positive reminiscence",
      "authors": [
        "F Bryant",
        "C Smart",
        "S King"
      ],
      "year": "2005",
      "venue": "Journal of Happiness Studies"
    },
    {
      "citation_id": "7",
      "title": "Effect of reminiscence on cognitive status and memory of the elderly people",
      "authors": [
        "G Akhoondzadeh",
        "S Jalalmanesh",
        "H Hojjati"
      ],
      "year": "2014",
      "venue": "Iranian Journal of Psychiatry and Behavioral Sciences"
    },
    {
      "citation_id": "8",
      "title": "Reminiscence and dementia: a therapeutic intervention",
      "authors": [
        "J Gonzalez",
        "T Mayordomo",
        "M Torres",
        "A Sales",
        "J Meléndez"
      ],
      "year": "2015",
      "venue": "International Psychogeriatrics"
    },
    {
      "citation_id": "9",
      "title": "Coimagination method: Communication support system with collected images and its evaluation via memory task",
      "authors": [
        "M Otake",
        "M Kato",
        "T Takagi",
        "H Asama"
      ],
      "year": "2009",
      "venue": "International Conference on Universal Access in Human-Computer Interaction"
    },
    {
      "citation_id": "10",
      "title": "Core affect and the psychological construction of emotion",
      "authors": [
        "J Russell"
      ],
      "year": "2003",
      "venue": "Psychological Review"
    },
    {
      "citation_id": "11",
      "title": "Remembering pictures: pleasure and arousal in memory",
      "authors": [
        "M Bradley",
        "M Greenwald",
        "M Petry",
        "P Lang"
      ],
      "year": "1992",
      "venue": "Journal of Experimental Psychology: Learning, Memory, and Cognition"
    },
    {
      "citation_id": "12",
      "title": "A cognitive model of selective processing in anxiety",
      "authors": [
        "A Mathews",
        "B Mackintosh"
      ],
      "year": "1998",
      "venue": "Cognitive Therapy and Research"
    },
    {
      "citation_id": "13",
      "title": "The cognitive modeling of human behavior: Why a model is (sometimes) better than 10,000 words",
      "authors": [
        "D Fum",
        "F Del",
        "A Missier",
        "Stocco"
      ],
      "year": "2007",
      "venue": "Cognitive Systems Research"
    },
    {
      "citation_id": "14",
      "title": "A review of 40 years of cognitive architecture research: Focus on perception, attention, learning and applications",
      "authors": [
        "I Kotseruba",
        "J Tsotsos"
      ],
      "year": "2020",
      "venue": "AI Review"
    },
    {
      "citation_id": "15",
      "title": "How Can the Human Mind Occur in the Physical Universe",
      "authors": [
        "J Anderson"
      ],
      "year": "2007",
      "venue": "How Can the Human Mind Occur in the Physical Universe"
    },
    {
      "citation_id": "16",
      "title": "Cognitive twin: A personal assistant embedded in a cognitive architecture",
      "authors": [
        "S Somers",
        "A Oltramari",
        "C Lebiere"
      ],
      "year": "2020",
      "venue": "Proceedings of the 18th International Conference on Cognitive Modelling"
    },
    {
      "citation_id": "17",
      "title": "Model-based reminiscence: Guiding mental time travel by cognitive modeling",
      "authors": [
        "J Morita",
        "T Hirayama",
        "K Mase",
        "K Yamada"
      ],
      "year": "2016",
      "venue": "Proceedings of the Fourth International Conference on Human Agent Interaction, ser. HAI '16"
    },
    {
      "citation_id": "18",
      "title": "Remembering the past to imagine the future: the prospective brain",
      "authors": [
        "D Schacter",
        "D Addis",
        "R Buckner"
      ],
      "year": "2007",
      "venue": "Nature Reviews Neuroscience"
    },
    {
      "citation_id": "19",
      "title": "Interactive model-based reminiscence using a cognitive model and physiological indices",
      "authors": [
        "K Itabashi",
        "J Morita",
        "T Hirayama",
        "K Mase",
        "K Yamada"
      ],
      "year": "2020",
      "venue": "Proceedings of the 18th International Conference on Cognitive Modelling"
    },
    {
      "citation_id": "20",
      "title": "Reflections of the environment in memory",
      "authors": [
        "J Anderson",
        "L Schooler"
      ],
      "year": "1991",
      "venue": "Psychological Science"
    },
    {
      "citation_id": "21",
      "title": "Balancing long-term reinforcement and shortterm inhibition",
      "authors": [
        "C Lebiere",
        "B Best"
      ],
      "year": "2009",
      "venue": "Proceedings of the 31st Annual Conference of the Cognitive Science Society"
    },
    {
      "citation_id": "22",
      "title": "Using a cognitive architecture with a physiological substrate to represent effects of a psychological stressor on cognition",
      "authors": [
        "C Dancy",
        "F Ritter",
        "K Berry",
        "L Klein"
      ],
      "year": "2015",
      "venue": "Computational and Mathematical Organization Theory"
    },
    {
      "citation_id": "23",
      "title": "Regulating ruminative web browsing based on the counterbalance modeling approach",
      "authors": [
        "J Morita",
        "T Pitakchokchai",
        "G Raj",
        "Y Yamamoto",
        "H Yuhashi",
        "T Koguchi"
      ],
      "year": "2022",
      "venue": "Frontiers in Artificial Intelligence"
    },
    {
      "citation_id": "24",
      "title": "Production of the Japanese edition of profile of mood states (POMS): assessment of reliability and validity",
      "authors": [
        "K Yokoyama",
        "S Araki",
        "N Kawakami",
        "T Tkakeshita"
      ],
      "year": "1990",
      "venue": "Japanese journal of public health"
    },
    {
      "citation_id": "25",
      "title": "Verbal reports as data",
      "authors": [
        "K Ericsson",
        "H Simon"
      ],
      "year": "1980",
      "venue": "Psychological Review"
    },
    {
      "citation_id": "26",
      "title": "OpenSmile: the munich versatile and fast open-source audio feature extractor",
      "authors": [
        "F Eyben",
        "M Wöllmer",
        "B Schuller"
      ],
      "year": "2010",
      "venue": "Proceedings of the 18th ACM International Conference on Multimedia"
    },
    {
      "citation_id": "27",
      "title": "The Geneva minimalistic acoustic parameter set (GeMAPS) for voice research and affective computing",
      "authors": [
        "F Eyben",
        "K Scherer",
        "B Schuller",
        "J Sundberg",
        "E André",
        "C Busso",
        "L Devillers",
        "J Epps",
        "P Laukka",
        "S Narayanan"
      ],
      "year": "2015",
      "venue": "IEEE Transactions on Affective Computing"
    }
  ]
}