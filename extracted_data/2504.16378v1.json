{
  "paper_id": "2504.16378v1",
  "title": "Cyberoception: Finding A Painlessly-Measurable New Sense In The Cyberworld Towards Emotion-Awareness In Computing",
  "published": "2025-04-23T02:56:55Z",
  "authors": [
    "Tadashi Okoshi",
    "Zexiong Gao",
    "Tan Yi Zhen",
    "Takumi Karasawa",
    "Takeshi Miki",
    "Wataru Sasaki",
    "Rajesh K. Balan"
  ],
  "keywords": [
    "Emotion / Affective Computing",
    "Cyberoception",
    "Interoception",
    "Sensing",
    "Mobile Devices",
    "Wearable Devices",
    "Personalization"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "In Affective computing, recognizing users' emotions accurately is the basis of affective human-computer interaction. Understanding users' interoception contributes to a better understanding of individually different emotional abilities, which is essential for achieving inter-individually accurate emotion estimation. However, existing interoception measurement methods, such as the heart rate discrimination task, have several limitations, including their dependence on a well-controlled laboratory environment and precision apparatus, making monitoring users' interoception challenging. This study aims to determine other forms of data that can explain users' interoceptive or similar states in their real-world lives and propose a novel hypothetical concept \"cyberoception,\" a new sense (1) which has properties similar to interoception in terms of the correlation with other emotion-related abilities, and (2) which can be measured only by the sensors embedded inside commodity smartphone devices in users' daily lives. Results from a 10-day-long in-lab/in-the-wild hybrid experiment reveal a specific cyberoception type \"Turn On\" (users' subjective sensory perception about the frequency of turning-on behavior on their smartphones) significantly related to participants' emotional valence. We anticipate that cyberoception to serve as a fundamental building block for developing more \"emotion-aware\", user-friendly applications and services. \n CCS Concepts ‚Ä¢ Human-centered computing ‚Üí Human computer interaction (HCI); ‚Ä¢ Applied computing;",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "\"Interoception is scientifically defined as the processing of internal bodily stimuli by the nervous system\"  [31] . In simpler terms, interoception is defined as \"the ability to be aware of internal sensations in the body, including heart rate, respiration, hunger, fullness, temperature, and pain, as well as emotion sensations\"  [57] . Recent advance in interoception's role in mental health have underscored its significance in conditions such as anxiety, mood disorders, disordered eating, addiction, and somatic symptom-related issues  [31] . In particular, the psychology community is currently actively measuring and using interoception data in their clinical studies, which has proven useful for understanding and improving mental health and other conditions  [31] .\n\nHowever, measuring interoception is difficult in our real-world daily computing lives as it requires access to many low-level bodily functions such as heart rate, respiration, temperature, etc. For example, measuring the heart rate or body temperature requires dedicated physiological sensors, which are not as common as ubiquitous mobile devices such as smartphones. Moreover, it is difficult and virtually not possible to conduct heart-beat-based measurement of interoception since existing methodologies (e.g., counting the number of heartbeats) typically require a controlled in-lab environment and are not suitable for the user's real-world live situations with various types of possible noise source for such physiological states.\n\nTo overcome such limitations, we present the first (to the best of our knowledge) attempt to find the existence of our novel hypothetical concept \"cyberoception.\" Cyberoception is defined as subjective sensory perception about the user's basic manipulation behavior with their commodity mobile computing devices such as smartphones, being measured through the embedded sensors in such devices, and acts as the same role as interoception in terms of its correlation with emotional ability (particularly the emotional experience in this study). In particular, we do not use any data or sensor that is not already being collected by the phone due to the user's regular phone usage patterns -we did this consciously to ensure that any solution we produced can be easily integrated into existing mobile apps and workflows.\n\nMore specifically, we focused on the basic operations in computing behavior where people access cyberspace by manipulating their smartphones throughout the day. The basic operations, such as unlocking the phone and turning on the phone, occur in their daily lives so often and so unconsciously that we hypothesized that such operations could be used as a target operation to question the user's subjective perception of the frequency. If we can discover a similar sense of interception, which can be measured only using the sensors embedded inside our commodity smartphones used daily, the mobile system, along with various types of applications and services, can obtain and utilize such status for their adaptive behaviors toward the realization of \"emotion-aware\" kind services. We see our cyberoception service as a key building block for many other apps that use the data to improve the health outcomes of mobile phone users.\n\nIn the rest of this paper, we first present more background information about the use of interoception data in the psychology community and then provide our design process to identify existing data sources that can be used to infer cyberoception. We conducted a hybrid experiment for 10 days, including a daily-life study and an in-lab emotional psychology experiment with 25 participants. Based on the detailed analysis of the data from 22 participants, we examined participants' perceptions of cyberspace activities, interoceptive abilities, and individual emotional traits. As the highlight of our findings, we found a correlation between a specific type of cyberoception, \"Turning On.\" and the experience of emotional valence.\n\nThe main contributions of this paper are:\n\n‚Ä¢ We introduce the novel hypothetical sense of \"cyberoception, \" based on daily smartphone interactions. The concept is defined as having properties similar to interoception, particularly in its correlation with emotional experience. ‚Ä¢ We propose a methodology to measure cyberoception using embedded sensors in smartphones without requiring specialized physiological sensors or controlled laboratory environments. This approach enables continuous, non-invasive sensing in real-world settings. ‚Ä¢ Through a 10-day hybrid experiment, the study demonstrates for the first time that the specific cyberoception type \"Turning On\" is significantly correlated with participants' emotional valence.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Background",
      "text": "This section introduces our research background, namely the concept of interoception and the existing methodologies of measuring interoceptive abilities. Additionally, we highlight the limitations of these traditional methods, paving the way for introducing a novel concept \"Cyberoception\" as an alternative approach.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Interoception",
      "text": "interoception is defined as one's perception, and therefore awareness and understanding, of the physiological state of the body including changes therein  [9] . In more layman's terms, interoception is defined as \"the ability to be aware of internal sensations in the body, including heart rate, respiration, hunger, fullness, temperature, and pain, as well as emotion sensations\"  [57] .\n\nInteroception was first proposed by the British physiologist Charles Sherrington  [49] . Sherrington classified the senses based on the location of their receptors, categorize them into (1) interoception, (2) exteroception, and (3) proprioception. According to Sherrington, (1) interoception refers to the sense originating from the interoceptive surface, the internal surface of the body, while (2) exteroception is the sensation produced by receptors close to the body surface that are in direct contact with the external environment, including the following senses: sight, hearing, smell, and taste. Furthermore,  (3)  proprioception is the sensation produced by the movement of one's own body. The sensation of whether a body part is at rest or in motion is  (3)  proprioceptive sensation.\n\nMore recent research  [7]  discusses expanding Sherrington's original physiology-bound concept of interoception. Damasio  [10]  built on Sherrington's viewpoint that interoception forms the foundation of the sense of physical self but proposed that interoception should include proprioception, visceral perception, and the sense of the internal milieu (e.g., temperature and pain), distinguishing it from exteroception. A similar opinion is also supported by Craig  [9] . The latest researches use this revised definition  [8] .",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Relationship Between Interoception And Emotion",
      "text": "Many existing studies have shown the relationship between one's interoception and other emotional abilities. A study by Stefan Wiens et al.  [59]  found a positive correlation between interoceptive error in a heartbeat discrimination task and the intensity of categorized emotional experiences. Katkin  [30]  reported that people who are accurate at interoception report greater distress in response to noxious stimulation. Barrett's experiment revealed that individuals with greater sensitivity to their heartbeats emphasized feelings of activation and deactivation when reporting their experiences of emotion over time more than those with lower sensitivity. \"  [2] . Moreover, the relationship between the interoceptive ability and the ability to recognize and respond to other person's emotion is confirmed. A study by  Terasawa et al.  showed a positive correlation between performance on a heartbeat counting task and the ability to recognize facial expressions of others  [52, 53] , suggesting a correlation between the interoceptive ability and the ability to recognize emotional experiences. Georgiou et al. reported that heartbeatsensitive individuals recognize others' facial expressions of sadness and fear better than individuals who are less sensitive  [16] . Imafuku et al. revealed that people with good interoception act more spontaneous facial mimicry than people with poor interoception  [25] .",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Measurement Of Interoception",
      "text": "Thus far, several experimental methodologies related to the state of human internal organs have been proposed to measure the interoception ability. Interoception is strongly related to the autonomic nervous system, which mainly unconsciously maintains homeostasis by the antagonistic function of the sympathetic and parasympathetic nervous systems. Thus, the various states of internal organs are controlled by these sympathetic and parasympathetic nerves.\n\nThe heartbeat counting is the most well-known method for measuring interoception. The \"heart rate counting task\" proposed by Schandry in 1981  [47] , in which the heart rate data (ùëÅ ùëüùëíùëéùëô ) from an electrocardiogram (ECG) or pulse sensor is used as the ground truth. Simultaneously, the participant is asked to report their subjective answer on the heartbeat count (ùëÅ ùëüùëíùëùùëúùëüùë° ) and not to touch any part of their body. The calculated error rate between ùëÅ ùëüùëíùëùùëúùëüùë° against ùëÅ ùëüùëíùëéùëô , shown in Equation  1 , is defined as \"Interoceptive Error\" and is often used as a metric to evaluate how accurate participant can count their heart rate. Since participants are required to provide subjective responses without physically touching their bodies, the Interoceptive Error effectively reflects their internal bodily awareness rather than relying on haptic sensations.\n\nThe visceral sensation is another well-known approach for measuring interoception. The visceral sensation is a type of sensation inside the body and is considered a typical interoception  [7] . Many methodologies were proposed to measure the interoception ability by measuring the accuracy of sensation to different viscera, including but not limited to gastric signals  [51, 55] , colon  [58]  and bladder  [27] .",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Limitation In Existing Methodologies Of Interoception Measurement",
      "text": "However, the measurement of interoception statuses introduced above usually requires a well-controlled laboratory environment and physiological sensors since it is mainly based on a behavioral experiment of cardiac perception. For example, in the heart rate counting task introduced in the previous section, the participant's gesture (not to touch the body during counting), precise ECG sensor, and soundproof environment need to be appropriately controlled to achieve accurate measurement. Moreover, the instructor must be well-trained to explain the procedure clearly and in detail to ensure the participant can understand the procedure and do as required. Furthermore, even with the support from the instructor and the use of professional-grade accurate devices, we cannot avoid collecting some noises from the ECG sensor.\n\nIn contrast, daily computing involving various information services, such as social networking platforms, occurs not in wellcontrolled laboratory settings but in dynamic, \"wild\" environments. This computing takes place continuously throughout the day, from morning to night, amidst the noise and complexity of real-world conditions.\n\nDespite the importance of measuring interoception status to understand better the users' emotion-related abilities (e.g., how well the users can estimate each other's emotions), the existing methodologies do not match such computing environment in our real lives. In other words, when we aim to construct a system that measures the user's interoceptive ability continuously and repeatedly in such an environment, the aforementioned requirements of the existing methodologies are significant hurdles to the actual implementation.\n\n3 Related Work 3.1 Measurement Error in Self-Reported Smartphone Usage\n\nSeveral studies have highlighted a gap in users' self-reported smartphone usage and actual smartphone usage. This discrepancy inspired the experiment design of cyberoception, which aims to measure users' unconscious intuition about their smartphone habits. Focusing on communication-oriented smartphone usage, a previous study compared users' self-reports on the frequency of voice calls, SMS, and Gmail with actual logs  [33] . The users were found to subjectively overestimate the frequency of such voice calls, SMS, and Gmail. Although factors that contribute to overestimation remain unclear, this study argues that such measurement error is not random. However, multiple studies have shown that screen time tends to be subjectively underestimated  [11, 13, 39] . The mixed results of overestimation and underestimation suggest that we should analyze the various smartphone usage types separately rather than treating them uniformly.\n\nSeveral studies have endeavored to identify demographic factors that affect the individual measurement error of self-report in smartphone usage. However, the effects of gender, age, marital/nonmarital status, job, and educational status were found to be insignificant  [3, 50] . One critical oversight in these studies is the potential role of affective states in shaping individual perceptions of smartphone use.\n\nPrevious studies have collected self-reported data on smartphone usage at weekly or daily intervals. For our experiment, we decided to collect self-reports on smartphone usage every 30 minutes to estimate their intuition better.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Estimating Mental And Physical States Using Smartphone Data",
      "text": "The ubiquitous nature of smartphones offers the opportunity to gain valuable insights into people's mental and physical states using data collected from these devices. Numerous studies have mostly used data collected from smartphones to estimate users' emotions, mood, engagement, and physical health. Our study leverages smartphone data to ewxplore interoception, which is related to but different from concepts such as emotion and mood. An early work by LiKamwa  [37]  showed the feasibility of mood inference from patterns in application usage, phone calls, SMSs, emails, web browsing history, and location. This was expanded with a system called \"MoodScope\" which linked the self-reported mood of the user with their smartphone usage patterns.  [38]  Beyond basic emotions, \"MoodExplorer\" also examined smartphone usage patterns and sensing data to automatically detect compound emotion, defined as a combination of different basic emotions.  [62]  In addition, engagement with a task can also be inferred through the user's expression using acoustic sensing from a smartphone.  [28]  Other than estimating mental states, numerous studies have also measured physical health indicators such as heart rate variability and blood pressure using data from a smartphone's built-in accelerometer and camera  [24, 56]  There is growing evidence that the various data generated with smartphones can effectively reflect users' mental and physical states. As such, our study aims to explore the potential of using people's perception of smartphone usage can be used to assess interception.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Measurement Of Interoception On Smartphones",
      "text": "There is a pre-existing literature on measuring interoception using a smartphone, smartphone-based phase adjustment task (PAT) by Plans  [44] . PAT is a novel smartphone-based method for assessing interoception by requiring participants to synchronize auditory tones with their heartbeats. In this task, tones are presented at a heart rate-matched frequency but deliberately out of phase with the heartbeats, and participants adjust the phase until they perceive synchrony. The method is robust against physiological or strategic confounds and demonstrates variability in performance across individuals.\n\nWhile PAT provides a novel method of measuring interception on the phone, it still relies on actual heartbeat data of the user sensed through a physiological sensor. Meanwhile, our research approach does not focus on directly measuring interception. Rather, we aim to explore new senses that can be measured through nonphysiological sensors.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Cyberoception",
      "text": "To overcome the aforementioned limitation in existing methodologies for measuring interception, we propose our novel hypothetical concept of \"cyberoception\" and investigate its possibility.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Cyberoception: Our Proposing Concept",
      "text": "We define our hypothetical concept of \"cyberoception\" as follows.\n\nCyberoception is a sense in humans related to their almost unconscious manipulation of a computing device, and can be measured through embedded sensors in such devices without relying on physiological sensors. It serves the same role as interoception in terms of its correlation with emotional ability.\n\nThe following subsections will explain, step by step, the background that led to this concept.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Use Of Embedded",
      "text": "Sensors in Mobile Devices. As described in Section 2, in the user's real-world daily computing situations that we are targeting in this research, the existing interoception measurement methodologies with physiological sensing have limitations. Instead, we can see newer opportunities for using embedded sensors in users' mobile devices such as smartphones. If we could use such sensors for measuring interoception, that would be a significant step forward in enabling continuous, non-invasive emotion-aware services in real-world settings, leveraging widely accessible mobile devices.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Focusing On User'S Sensory Perception Of Device Interaction.",
      "text": "But at the same time, we need to carefully consider \"what to measure\" by using such embedded sensors. If we were to strictly adhere to measuring original interoceptive senses, we would ultimately need to measure internal bodily states, such as heart rate, by some means, thereby reverting the discussion to its initial scope.\n\nOn the other hand, looking at real-world computing in our daily life with widespread commodity mobile devices, we see our continuous interaction with these devices throughout our daily lives from morning to night. Heavy phone users carry and use their smartphones literally \"always\" throughout their lives, manipulating the phone interfaces and experiencing their interaction with the cyber world.\n\nRegarding this highly continuous and frequent smartphone usage, we consider the possibility that these operational manipulations have become, to some extent, \"unconscious behavior\" for us. (For instance, people may be unaware of how often they lock/unlock their smartphones in a single day, as this behavior is performed so frequently and unconsciously.)\n\nThus, when we think about their subjective \"sense\" around such almost-unconscious manipulation, we consider if such sense may have some similarity with the existing sense of interoception in terms of the correlation with the user's ability to regulate the emotion.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Properties Similar To Those Of Interoception.",
      "text": "As an additional idea, from a different perspective, we hypothesize that devices like smartphones, which serve as interfaces connecting us to cyberspace, could be seen as extensions of our bodies.\n\nAs presented in Section 2, recent research  [7, 9, 10]  discuss expanding Sherrington's original physiology-bound concept of interoception and suggests that interoception should encompass proprioception, visceral sensation, and the perception of the internal milieu. The evolution of this series of discussions inspired us to discuss whether a further conceptual extension of interoception (including proprioception) was possible even to the cyber world.\n\nAs we review the related literature, we see that the flexibility and extendability of body schema have been extensively demonstrated in studies on the concept of the extended self  [22] . In this context, various tools and objects, including smartphones, have been investigated as extensions of the \"self\", with findings indicating effects comparable to those observed in the \"rubber hand illusion.\"  [36]  Notably, psychological research has consistently shown that smartphones (not limited to their usage but their existence itself) are perceived as an extension of the self  [17, 42] . Moreover, in recent research, interoception is revealed to be the core element of the cognitive process of self  [45] .\n\nBased on this discussion, we have reached the idea that we could possibly hypothesize that cyberoception can be treated as one type of interoception and that it can be inferred to share the emotionrelated properties  [10, 54]  similar to interoception. More concretely, since we are focusing on interoception's specific property in terms of the correlation against other emotional abilities (e.g., the ability to recognize and respond to other persons' emotions), we hypothesize that cyberoception holds such similar property.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Research Questions",
      "text": "As the very first step of our interoception research, the research questions in this paper are the following two.\n\n‚Ä¢ RQ1: Does cyberoception have similar emotion-related property to interoception? : Interoception has long been studied in the fields of psychology and physiology. Various important relationships have been observed, including one's emotion formation, emotion recognition, and estimation of others' emotions. In this study, we focus on emotional experience and investigate whether the emotional experience of each individual is correlated to his/her cyberoception. We also discuss whether it has properties similar to those of interoception. ‚Ä¢ RQ2: Can cyberoception replace the existing physiological sensor-based measurement methodology of interoception? : Assuming that cyberoception has similar emotion-related properties to interoception, additionally, we want to know if cyberoception can be an alternative smartphone-sensor-based measurement methodology of pre-existing interoception which until now has required physiological sensors and a strictly controlled environment. We investigate the relationship between interoception and various types of candidates of cyberoception by comparing interoception measured using a heartbeat counting task with our proposed cyberoception.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Measurement Of Cyberoception",
      "text": "Cyberoception and interoception share a fundamental goal: to capture the user's internal states, although through different means.\n\nInteroception gathers physiological signals that are indicative of emotional and cognitive states. However, cyberoception leverages non-physiological data derived from daily interactions with mobile devices to estimate similar internal states. The measurement of cyberoception in this study is inspired by the typical gauge of interoception.\n\nAccording to the basic approach of cyberoception, which relies on the (non-physiological) available data on the user's mobile devices, the basic approach to estimating the user's states is based on the collection of (1) the data related to the user's device operation, along with (2) the user's subjective sense on such an operation.\n\nWhat specific sensations related to smartphones should we measure? After an extensive discussion among the research team, we selected the following six types of operations based on the following criteria: (1) they are operations and actions that users perform daily on their smartphones, and (2) they are extremely daily operations and actions, there is a considerable possibility that they are performed almost unconsciously.\n\ninteroception is closely tied to the autonomic nervous system, encompassing sensations such as heartbeat, respiration, and gastrointestinal activity, which are processed almost unconsciously. In proposing Cyberoception as a concept analogous to interoception, it is crucial to account for this characteristic of almost unconscious processing inherent in interoceptive sensations. Therefore, we adopted the criterion that operations and actions selected for Cyberoception metrics should be those that are extremely daily and thus likely to be performed almost unconsciously. Pragmatically, focusing on extremely daily operations makes Cyberoception measurable and feasible to study. These frequent and routine actions provide a practical foundation for collecting consistent data, enabling researchers to capture patterns of user behavior that reflect internal states without requiring invasive or burdensome methods.\n\nThe selected six types are (1) Turning On, (2) Unlocking, (3) Screen Use Duration, (4) Micro-usage, (5) Most-used App and (  6 ) Typo (Typographical Error). We call each of these six types the candidates of Cyberoception Metric for the rest of the paper.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Turning On",
      "text": "Turning On represents a user's activity to turn on the smartphone screen. Turning On represents the user intentionally switching the smartphone screen on for full user interaction (not ambient display or other non-interactive state) and is a good indicator of the frequency of smartphone use. Turning On activity hypothetically may reflect two types of emotional states: (1)aroused and motivated affect with the attention towards to smartphone (2)acquiring a sense of reassurance or calm by escaping negative emotions based on the attachment theory.\n\nOn the concrete methodology of collecting Turning On activity data, they can be sensed by an API on the smartphone OS, such as android.app.usage API, which records the type of usage activity and timestamp.\n\nFor clarification, (non-manual) automatic activation of the phone display to show the time and/or weather during the sleep mode is excluded from the definition of Turning On since it does not represent the user's intentional switching on activity.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Unlocking",
      "text": "Unlocking measures the frequency of a user unlocking the phone. Unlocking requires the user to intentionally enter the PIN, face, or fingerprint authentication to unlock the screen.\n\nFor the data collection methodology, Unlocking activity can be sensed by an API on the smartphone OS, such as by monitoring keyguard hidden activity in the Android platform.\n\nTurning On and Unlocking are different operations, although they are related. Unlocking often occurs immediately after Turning On when the user turns on and unlocks the phone in one sequence. Thus, the number of times the screen is turned on is significantly related to the number of times the screen is unlocked, and the emotion accompanied by Unlocking should be similar to Turning On. Despite this, there are some cases where a user turns on the screen, checks the time, and turns off the screen without unlocking it. Compared to Turning On, the Unlocking operation should be affectively more conscious.\n\nWe hypothesize that the users initiate such Turning On and Unlocking operations so frequently and almost unconsciously  [60]  in their daily lives that the measurement of such operations can be good candidates for the cyberoceptive measurement methodology.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Screen Use Duration",
      "text": "Screen Use Duration is the user's cumulative use time of the smartphone screen within one session. In a typical case, this is the duration that starts from turning-on the phone, unlocking, one or multiple application usages, and finishing with locking and/or turning-off the phone.\n\nThe APIs provided by the smartphone OSs and used to record Unlocking and Turning On can be combinedly used for the calculation of Screen Use Duration.\n\nScreen Use Duration is a metric often considered when using smartphones. The perception of screen time could be partly determined by time perception ability. But more importantly, it should be related to their sense of smartphone use. The discrepancy between self-reported Screen Use Duration and objective usage data may suggest signs of smartphone addiction. Emotions commonly associated with smartphone addiction, such as guilt, frustration, or anxiety, could potentially play a role in this context.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Micro-Usage",
      "text": "Micro-usage is defined as a user's application usage session under 5 seconds. The usage sessions that end within 5 seconds of the user's application launch are recorded as micro-usage.\n\nFor Micro-usage data collection, we can leverage the APIs provided by the smartphone OSs, for instance, UsageEvents.Event on Android. Via such APIs, the user's application launching and ending activities can be recorded continuously. If the duration of the session specified by launching and ending activities is less than 5 s, such usage sessions are marked as Micro-usage.\n\nResearch on smartphone usage trends has focused on sessions with short usage times (Micro-Usage), particularly regarding application usage time. In an extensive survey of 4125 people in 2011, it was found that Android smartphone users surprisingly used applications for less than 5 seconds in 49.9% of their sessions  [4] . The average duration of sessions with social networking applications is short  [14] , accounting for most of the sessions less than 5 s. However, it is infeasible to interpret all the sessions used for less than 5 s with only social networking app use.\n\nIn a study of 21 subjects, Ferreira et al. used 15 seconds as a boundary line in their analysis since nearly 50% of the collected sessions were less than 15 seconds long. However, Shepard et al. study of 25 subjects  [48, 61]  and Andrews et al. study of 23 subjects  [1]  found that 30-second sessions accounted for half of the sessions. The distribution of smartphone use sessions was influenced by the bias of the subjects selected for the experiment. Natureally, the general trend of smartphone use at the time of the experiment changes constantly and that experiments conducted over different periods lead to different conclusions. furthermore, usage of less than 15 s was claimed as habitual checking behavior, and the frequency of such usage was proposed as an indicator to evaluate smartphone addiction  [1, 60] . Such habitual checking behavior of Micro-usage hypothetically indicates emotion states related to smartphone addiction.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Most-Used App",
      "text": "The Most-used App represents the launching activity of the user's self-reported most frequently used application. Specifically, the user's launching operation and move-to-foreground operation of the most used application are counted as the Most-used App.\n\nMost-used App can be sensed when android.app.Activities is moved to the foreground.\n\nThe application launch includes multiple launches within a single screen turn-on. Therefore, the sensation of application launches is a more sensitive sensation. However, it is challenging to capture the number of times all applications launch, and it can be assumed that most participants cannot capture the number of times all applications launch correctly. Therefore, in the demographic survey before the start of the experiment, we obtained the names of the \"most frequently used applications, \" and measured the participants' perception of the application's launch. The emotion accompanied by \"Most-used App\" is hypothetically similar to \"Turn On\" but in a more micro scope.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Typo (Typographical Error)",
      "text": "Typo (Typographical Error) is a typical fundamental operation in smartphone use, representing a mistake made while typing on a smartphone keyboard. Generally, the user will correct Typo by pressing the backspace key or using the auto-correction feature.\n\nMany studies have estimated emotion from typing patterns, including mistyping on smartphones, and the number of backspace key presses (delete key) was entered into an emotion estimation model as representative of mistyping  [18] [19] [20] . The number of typographical error recorded by pressing the backspace key was a good representation of the user's emotional state. In this study, we sensed backspace key presses as the representation of Typo activity in participants' daily lives. However, auto-correction and predictive text features may affect the accuracy of the typographical error detection. To obtain data that closely reflects users' daily smartphone usage, we refrained from giving any instructions that could alter their daily typing habits. Furthermore, participants' Typo activities were detected more precisely though non-daily in-lab experiment.\n\nIn this study, we developed an application that counts and records the number of presses of the delete key, and collected data on the number of Typo (Typographical Errors).",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "System And Experiment Design",
      "text": "This section details our design of the experiment along with the original system design developed for this experiment. After we introduce the overview of the experiment procedure in Section 6.1, we describe the details of 10-day-long data collection/survey study in Section 6.2, and finally, we present the detailed design of three in-lab experiments in Section 6.3, 6.4, and 6.5).",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Overview Of Experiment Procedure",
      "text": "To measure participants' cyberoception represented by the perception of various basic smartphone operations in daily use and to clarify the relationship between participants' daily cyberoception and their psychological traits, we designed a 10-day experiment. Figure  1  shows the overview of this study containing both (a) a 10-day long data collection/survey period in the user's daily life environment and (b) in-lab experiments on Day 3 and Day 10. The (a) task and (b) experiment are designed separately but analyzed together after the entire survey.   On Day 10, to clarify the variation of participant's interoceptive and emotional traits during the study, we again conducted Interoception Experiment and Affective Picture Rating Experiment at the end of the experiment period.\n\nIn each in-lab experiment, the order of the experiments is randomized and well-counterbalanced. There was a break of at least 5 min (forced 5-minute rest and participant-determined further rest) between experiments to eliminate learning effects and tiredness.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Daily Cyberoception Measuring Survey",
      "text": "Since the purpose of this study is to measure participants' cyberoception, the perception of various basic smartphone operations in daily use, an experimental environment set back to the participants' everyday lives is expected to collect objective usage data and subjective self-reports of the participants' daily use.\n\n6.2.1 Obtaining Participant's Subjective Perception. In the Daily Cyberoception Measuring Survey, as shown in Figure  3 , we used the experience sampling method (ESM). The trends of smartphone usage vary widely throughout the day  [1] , and it is necessary to collect usage data from different time periods. In addition, we utilized a randomized ESM method that randomizes the timing of each survey transmission  [46]  in a specific time window rather than specific fixed transmission timings (noon, 2:00p.m. etc.). We send five notifications to subjects throughout the day and collect their responses to the cyberoception metrics. Each notification is sent during five-time windows: 7:00~10:00, 10:00~13:00, 13:00~16:00, 16:00~19:00, and 19:00~22:00. The specific transmission time in each window is determined randomly, by delaying the actual delivery for a random period. To measure cyberoception as a perception, we ask participants to report their subjective intuition. Furthermore, we set the duration of each sampling session to be as short as 30 minutes immediately before answering the survey form.\n\nTo prevent participants from easily guessing the next survey questions, three of the five Cyberoception Metrics were randomly extracted for each survey form by shuffling with the Fisher-Yates algorithm  [12] .",
      "page_start": 7,
      "page_end": 8
    },
    {
      "section_name": "Evaluation Metrics Of Cyberoception. Our Evaluation Metrics Of Cyberoception Contain Both Quantitative And Qualitative Ones.",
      "text": "Cyberoceptive Error: The quantitative metric of the evaluation is called Cyberoceptive Error shown in Equation 2 designed in the same way as Interoceptive Error previously presented in Section 2.3. Cyberoceptive Error is the calculated error rate between the selfreport usage data from the participant(ùëÅ ùëüùëíùëùùëúùëüùë° ) against the sensordata-based true usage data as ground truth(ùëÅ ùëüùëíùëéùëô ).\n\nQualitative Cyberoceptive Accuracy: We also designed a qualitative cyberoception measure to account for the fact that participants may have difficulty quantitatively sensing smartphone use. Participants were asked to rate their smartphone usage subjectively and qualitatively by responding to a Likert scale of 1 to 5 for smartphone usage during a 30-minute session.\n\nFor instance, as the measure of participants' cyberoception on Unlocking, participants will receive a questionnaire as below:\n\nBased on your daily experience with your smartphone use, during the period from 30 minutes ago to the present time, what do you think about your smartphone unlocking while using this smartphone? Please answer based on your own perception/feeling, and do not dwell on your answer. Participants can choose one item from 1 to 5, where option \"1\" represents \"No Unlocking\" and option \"5\" represents \"Most Ever\".\n\nAll detailed questions of the survey are listed in the Appendix A.\n\nParticipants with good cyberoception can specify the level of their smartphone usage, which means that the ascending level should correspond to usage sensing data in ascending order. Thus, to evaluate the participants' cyberoception, we calculate the Spearman correlation between the rank of Likert responses and the rank of corresponding averaged usage sensing data and named this value Qualitative Cyberoceptive Accuracy.",
      "page_start": 7,
      "page_end": 8
    },
    {
      "section_name": "System Design.",
      "text": "To collect the smartphone data and the participant's subjective answer on the context, we designed a smartphone application to be installed on each participant's smartphone. As shown in Figure  4 , the experimental application has two main features, namely (1) usage data sensing and (2) self-report survey form.\n\nAs a concrete smartphone platform, we chose the Android platform, which allows us to easily collect various types of data from the sensors and APIs. More specifically, the application utilizes Android AppUsage Framework and Accessibility Framework to collect such data. The application is implemented as a \"foreground service\" on the Android platform to ensure that the application can collect the data continuously during the participant's smartphone daily use. As the overall sensing framework of the smartphone application along with the data collection server (to which the data will be uploaded periodically), we used a sensing framework AWARE  [15, 40]  and its plugin  [29] .\n\nFollowing the discussion in Section 5, the application collects the data regarding the six types Cyberoception Metrics, namely (1) Turning On, (2) Unlocking, (3) Screen Use Duration, (4) Micro-usage, (5) Most-used App, and (6)   1  shows the concrete data/event names used to collect the data on each metric. To obtain the data for Metric (1) to (  5 ), we used UsageEvents.Event API, and created a filter to sense five types of events: ACTIVITY_PAUSED, ACTIVITY_RESUMED, SCREEN_INTERACTIVE, SCREEN_NON_INTERACTIVE, and KEYGUARD_HIDDEN. To collect typographical error data for Metric (6), we monitored backspace pressing activity from Accessibility API.\n\n‚Ä¢ Turning On Turning On operations are detected by the application through SCREEN_INTERACTIVE event and stored in the usage data database. The participants' numerical response to the Turning On metric in the survey form is collected as self-report usage data.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "‚Ä¢ Unlocking",
      "text": "Unlocking operations are detected by the application through KEYGUARD_HIDDEN event and stored in the database. The participant's numerical response to the Unlocking metric in the survey form is collected as self-report usage data. ‚Ä¢ Screen Use Duration SCREEN_INTERACTIVE and SCREEN_NON_INTERACTIVE sensing events are paired into screen usage sessions. The duration of each screen usage session is calculated from the timestamps of SCREEN_INTERACTIVE event and SCREEN_NON_INTERACTIVE event. The accumulation of screen usage session duration within a 30-minute sampling session is treated as the sensing usage data of screen use duration. Meanwhile, the participant's numerical response to the screen use duration metric in the survey form is treated as self-report usage data of screen use duration.\n\n‚Ä¢ Micro-usage ACTIVITY_PAUSED and ACTIVITY_RESUMED sensing events are obtained by the application as a pair. The time difference from an application's ACTIVITY_RESUMED timestamp to the ACTIVITY_PAUSED timestamp is calculated as a duration of one application usage. An application usage session of less than 5 s is counted and interpreted as a microusage. Meanwhile, the self-report usage data of micro-usage refers to the user's numerical response to the Micro-usage metric in the survey form.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Single Trial Of Heartbeat Counting Task",
      "text": "Count your heartbeat ...",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "User Interface",
      "text": "Figure  5 : Procedure of Heartbeat Counting Task\n\n‚Ä¢ Most-used App The information on the Most-used App for each participant was obtained during the demographic survey on Day 1. During the data collection period, the application keeps track of and records the number of usage sessions of each application on the phone by using the outputs from the AC-TIVITY_PAUSED and ACTIVITY_RESUMED sensing events. Simultaneously, the participant's numerical response to the Most-used App metric in the survey form is collected as the self-report usage data.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "‚Ä¢ Typo",
      "text": "Typo is recognized from the participant's Delete key-pressing activities. During the data collection period, the application continuously collects data from TYPE_VIEW_TEXT_CHANGED events of Accessibility API. This event will be issued whenever the text value of a text field changes. Thus, by comparing the text value before and after such an event, the application can detect when the participant presses the Delete key. Specifically, we calculated the Levenshtein distance and the length difference between 2 texts. When the length of text decreases, and the Levenshtein distance between 2 texts divided by the length difference is smaller than 1, the TYPE_VIEW_TEXT_CHANGED will be interpreted as once Delete key pressing activity. Meanwhile, similarly to other metrics, the participant's manual numerical response to the Typo metric in the survey form is handled as the self-report usage data on the Typo metric.",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Interoception Experiment",
      "text": "Among different modalities of interoception, we focused on the most cross-examined and extensively-researched cardiac axis. Following the commonly-used approach in the previous literature and avoiding the floor effect in other methods  [6, 21] , we measured participants' Interoceptive Error (presented in Section 2.3) by the heartbeat counting task (HCT) that evaluates the participants' cardiac perception ability to their heartbeats. We calculate Interoceptive Error based on the heart rate figure from the ECG sensor (as the ground truth) (ùëÅ ùëüùëíùëéùëô ), and the self-report number from the participant(ùëÅ ùëüùëíùëùùëúùëüùë° ). For our experiment, used Polar H10 N ECG sensor [26].\n\n6.3.1 Procedure. Figure  5  shows the overview of the heartbeat counting task. 1 trial consists of 3 steps, literally (1) Stand-By, (\n\nHeartbeat Counting, and (3) Count Reporting. Following the user interface on the PC screen, each participant proceeds the steps from (1) to  (3) . Each participant will do six trials. The duration of (2) heartbeat counting steps in the six trials are 25 seconds, 30 s, 35 s, 40 s, 45 s, and 50 s, respectively. The information on these time durations is not told to the subjects, making it difficult for them to guess the heart rate from the time duration. (For example, when the participant is asked to count the heartbeat for 60 s, they can actually estimate the number based on the knowledge and common sense about the human's typical heart rate.) The order of the trials is rearranged randomly to ensure that subjects cannot easily guess the time duration of each trial. Subjects are asked to count their own heartbeat without touching their wrists or any other body part. They are also instructed to keep their hands on the desk during the experiment.",
      "page_start": 9,
      "page_end": 10
    },
    {
      "section_name": "Affective Picture Rating Experiment",
      "text": "The participant's personal affective traits are measured in the Affective Picture Rating Experiment. The Affective Picture Rating Experiment presents emotional images to the participant in the experiment. Subsequently, the participant rates them on two dimensions of emotional experience: emotional valence and arousal levels. The same stimulus, an image, is used to evoke the same emotional state in the participants.",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Stimulus.",
      "text": "The experiment in this study is designed with reference to the experiment by Lang, P.J., et al  [35] , and the International Affective Picture System (IAPS) is used as the stimulus.\n\nThe IAPS is useful for assessing state emotion but can also be applied to evaluate trait emotion. Many prior studies, particularly those exploring the relationship between trait emotion and interoception, have employed the IAPS  [43] . In this study, we analyze trait emotion by exposing different participants to the same controlled environment and evaluating their emotional responses. Here, the IAPS is valuable for maintaining a consistent environment.\n\nThis study created a subset from IAPS in which pictures rated inconsistently are excluded (standard deviation larger than 2). Furthermore, images with a high possibility of violating ethics were subjectively excluded. After the exclusion, stimuli were extracted in consideration of balance: 8 images for each of 9 categories of valence/arousal values, (1) low-valence low-arousal, (2) low-valence neutral-arousal, (3) low-valence high-arousal, (4) neutral-valence low-arousal, (5) neutral-valence neutral-arousal, (6) neural-valence high-arousal, (7) high-valence low-arousal, (8) high-valence neutralarousal, and (  9 ) high-valence high-arousal. The valence labeling score of the subset ranges from 2.43 to 7.57(M = 4.98, SD = 1.33). The arousal labeling score of the subset ranges from 1.72 to 6.99(M = 4.48, SD = 1.29). 6.4.2 Scale. Self assessment Manikin (S.A.M) (Fig.  6 ) is used in the affective picture rating task. S.A.M. is a scale for measuring emotion proposed by Lang  [5]  and is widely used in emotion estimation research. The reliability and validity of S.A.M. have been demonstrated in numerous studies. For instance, both within-and between-subject reliability is reported by Lang  [34] . The validity of S.A.M, particularly in research on interception and emotion, is also supported by numerous studies  [43] . The present study uses   The subjects are asked to choose the option that best matches their current emotional experience. The vertical order of the two scales is randomized. The selected option is converted into numerical data from 1 to 9.",
      "page_start": 9,
      "page_end": 10
    },
    {
      "section_name": "Procedure.",
      "text": "As shown in Fig.  7 , each trial of the Affective Picture Rating Task consists of screens of three steps: (1) Stand by, (2) \"See and Feel\", and (3) Evaluation. First, a 5-second preparation period is given before each picture is presented. During this time, a white cross is presented. In the (2) \"See and Feel\" period, each affective picture is presented for 6 s. After that, the screen switches to a 15-second (3) \"Evaluation\" screen. The evaluation screen uses a two-dimensional S.A.M. scale with nine choices for each dimension. The subjects are instructed to observe the facial expressions of the scale mannequins before answering the questions. These trials are repeated 36 times for each participant.",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Typing Experiment",
      "text": "To acquire the participant's sense of Typographical Error in an in-lab environment, we conduct Typing Experiment.",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Content.",
      "text": "We selected text content to be typed from general news articles. The criterion for article selection is that the content is as ordinary as possible to minimize the variance in the difficulty of understanding among the participants. In this study, we chose a short text on the topic of weather, with a length of 253 words (1376 keystrokes).\n\n6.5.2 Procedure. We show the content on a piece of paper and ask each participant to type on a mailing application on the smartphone. During the experiment, auto-capitalization, auto-correction, and predictive-text features of the keyboard on the phone are turned off (the instruction to do so is given by the experimenter to the participant) and are also prohibited from being used. In other words, participants are set in an environment where they must press every keystroke to input the displayed text.",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "Novelty Of The Methodology",
      "text": "The proposed methodology incorporates a novel integration of interoceptive and cyberoceptive measures to understand emotional traits. Unlike traditional methods that rely solely on self-reported data or physiological measures, our approach combines subjective perception metrics (cyberoception) with objective in-lab experiments designed to measure emotional traits and interoceptive abilities. This dual approach enables a more comprehensive evaluation of the relationship between daily smartphone usage and emotional states.\n\nThe novelty of our method also lies in the randomized ESM combined with a smartphone application that continuously collects real-world interaction data. By employing statistic analysis methods, we quantitatively measure the cyberoception of participants. Additionally, the in-lab experiments are carefully designed to assess emotional and interoceptive traits, allowing for a robust analysis of their relationship with daily cyberoception.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Participants",
      "text": "The participants were recruited inside our university, where the experiment was approved by the IRB (Institutional Review Board). The recruitment was done via email from the university office to all students in our information science department. Twenty-five participants majoring in information science and related disciplines were recruited.\n\nAll participants are daily smartphone (Android OS version 9 or above) users. The participants were paid SGD60 for their full participation.\n\nAt the study briefing, the participants answered demographic survey forms after obtaining informed consent.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Demographics",
      "text": "Twenty-five participants (19 men and 6 women) range in age from 19 to 34 years (M = 23.1, SD = 2.9). While the number of participants is modest, participants were recruited from a homogeneous group with similar age ranges and backgrounds, which minimizes variability in the dataset. Given the low inter-participant variability, it is feasible to conduct a statistically valid analysis with a relatively small sample size.\n\nMost participants were using English while typing on their smartphones (Always = 20, Usually = 3, Often = 1, Sometimes = 1).\n\nAuto-correction refers to the feature implemented in the Android keyboard, which can correct typos, including capitalization errors, misspelled words, and missing pieces of text. Fifteen participants were using the auto-correction feature in high frequency (Always, Usually, and Often) while typing on their smartphones. The predictive text refers to another feature in the keyboard, which predicts and suggests the text the user may wish to insert. 19 participants were using the predictive text features at low frequency (Sometimes, Hardly ever, and Never).\n\nBrands of participants' smartphones include Samsung (N = 12), OPPO (N = 3), Google (N = 3), One Plus (N = 2), Xiaomi (N = 2), Sony (N = 1), Poco (N = 1), and Huawei (N = 1). Android versions of the smartphones include 13 (N = 19), 12 (N = 3), 11 (N = 1), 10 (N = 1), and EMUI 12 (Android-based mobile operating system of Huawei smartphone, N = 1).\n\nIndividually, the most frequently used applications are collected from the participants' subjective reports: Telegram (N = 12), TikTok (N = 3), Instagram (N = 2), Whatsapp (N = 2), Twitter (N = 1), Pinterest (N = 1), YouTube (N = 1), Netflix (N = 1), WeChat (N = 1), Google News (N = 1).",
      "page_start": 10,
      "page_end": 11
    },
    {
      "section_name": "Acquired Data",
      "text": "Out of 25 participants, one received an invalid survey form due to a network communication problem, and two reported their screen usage duration longer than 30 minutes within 30 minutes, whose data are labeled as low credibility. Data from the above participants are excluded from data analysis, and the remaining data from the other 22 are used.\n\nThe acquired data include data from 2 parts: Daily Cyberoception Measuring Survey and In-lab Experiments (Interoception Experiment, Affective Picture Rating Experiment, and Typing Experiment).",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Daily Cyberoception Measuring Survey",
      "text": "",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "In-Lab Experiments",
      "text": "During the Interoception Experiment, participants' average heart rates ranged from 58.65 to 98.64 (M = 74.52, SD = 10.95).\n\nIn the Affective Picture Rating Experiment mentioned, the participants rated affective pictures from two aspects: arousal and valence. Their average valence rating scores range from 3.56 to 5.80 (M = 5.12, SD = 0.51), and the average arousal rating scores range from 1.00 to 6.28 (M = 3.79, SD = 1.34).\n\nIn the Typing Experiment, participants' delete key pressing count ranges from 0 to 304 (M = 102.8, SD = 77.95).",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Sensing Usage Data",
      "text": "On the six types of Sensing Usage Data collected from each participant's smartphone API, as \"objective\" observation on each Cyberoception Metric, here we introduce some statistical summary, such as distribution and variation among the participants.",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Distribution. The Distribution Of Each Type Of Cyberoception",
      "text": "Metric sensing data during the 30-minute sessions is shown in Figure  8 .     2 ). As mentioned in 6.2.1, the participants were required to answer survey forms sent by notifications several times a day. The questions in each form are randomly selected from six types of cyberoception metrics. For some metrics, only a few valid data were successfully collected occasionally since the participants might have missed some responses to the notifications. For each participant, after excluding metrics that were responded less than three times, the Cyberoceptive Errors of six metrics were calculated. Correlation between the Metrics. Correlational analysis among Cyberoceptive Errors of six metrics was performed. Although Turning On is often accompanied by an Unlocking operation, the Cyperoceptive Error of Unlocking and Cyperoceptive Error of Turning On are found to be hardly correlated (r = 0.22, p = 0.36). Overall correlations among Cyberoceptive Errors of metrics are not significant but positive.   2 .",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Interoception",
      "text": "Based on the results of the participants' interoception collected through the in-lab experiment, most participants performed highly accurate interoception (M = 0.32, SD = 0.11). 21 out of 22 participants counted their heartbeat correctly with an Interoceptive Error lower than 0.5.",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Gender Difference",
      "text": "Despite the unbalanced amount of collected data between men and women, we attempted to analyze differences in the results between genders using ANOVA. The result shows that men tended to report higher emotional arousal than women (ùëÄ ùë§ùëúùëöùëíùëõ = 0.394, ùëÄ ùëöùëíùëõ = 0.591, ùëù = 0.031). No significant differences between genders were found in Cyberoceptive and Interoceptive Errors. To more directly address our research questions, we conduct two types of correlation analysis, namely the analysis between (1) cyberoception and emotion and another between (2) cyberoception and interoception, The analysis found a statistically significant correlation between the \"Turning On\" Cyberoception metric and emotional valence rating.   3 .\n\nApparently, the Cyberoceptive Error of metrics is positively correlated to valence. Especially, between the \"Turning On\" and valence, we found a correlation score of 0.452 (with statistical significance ùëù < 0.052). It shows that the participants who are more sensitive on \"Turnin On\" Cyberoception tend to experience emotions negatively, even if the same stimulus is provided. To the best of our knowledge, we are the first to establish a correlation between the person's emotional valence value and their sense of smartphone usage.\n\nCompared to valence, Cyberoception metrics showed a less significant correlation with arousal. We would like to further discuss in Section 11.",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Regression Analysis.",
      "text": "A linear relationship between Cyberoception metrics and two emotional experience factors is established. The unit of analysis is each participant. We found that \"Turning On -Valence\" tends to be significant([ùõΩ = 0.208, ùë° = 2.089, ùëù = 0.052]). The linear regression between Turning On and Valence is shown in Fig.  11 .\n\n10.1.3 Two-Split Analyses. We split participants into two groups using the average Cyberoceptive Error of their Turning On( M = 1.49 ). The unit of analysis is each participant. Among the Good Perception Group, the relationship between Turning On and Valence is significantly highly positive([ùõΩ = 1.25, ùë° = 3.56, ùëù = 0.005]). However, Among the Poor Perception Group, such a significant correlation was not observed([ùõΩ = 0.03, ùë° = 0.15, ùëù = 0.88]).",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "Conclusion Regarding",
      "text": "Research Question 1. Our experimental result revealed that some of the cyberoception metrics we proposed (especially \"Turn On\" cyberoception) can work similarly    Regarding whether cyberoception can be replaced by interoception, we could not conclude that our proposed Cyberoceptive Metrics can replace interoception measurement. Though we could not confirm significant differences, for some of the proposed cyberoception metrics, we found weak correlations between the accuracy of cyberoception and that of interoception. These results show that the cyberoception for Turning On and micro-usage could be substituted to replace the interoception measurement.",
      "page_start": 14,
      "page_end": 14
    },
    {
      "section_name": "Emotion And Operation Data",
      "text": "We additionally analyzed all possible relations between six types of operation usage data obtained from smartphone API (not the \"sense\" of the operation but the operation itself) and the emotional and interoceptive data acquired in the in-lab experiment mentioned in 6.3 and 6.4. Interestingly, the \"Unlocking\" operation were correlated to arousal rating (r = 0.46, p = 0.05). Individuals who unlock their smartphones more frequently feel more excited or aroused than those who less frequent unlock. (For other combinations, we did not have statistically significant relations.)",
      "page_start": 14,
      "page_end": 14
    },
    {
      "section_name": "Discussion",
      "text": "This study introduces the concept of cyberoception, which can be an alternative to interoception as a factor of emotional ability. For the concrete operations representing Cyberoception, we proposed six types of Cyberoception metrics. Through a ten-day daily-life study and in-lab emotional psychology experiment, we analyzed participants' perception of activities in cyberspace, specifically via their smartphones, interoceptive ability, and emotional individual characteristics. As the answer of RQ1, we revealed that the \"Turn On\" cyberoception metrics can function similarly to interoception, performing as an affective factor that is intimately connected to an individual's emotional experience The result evidentiary supports the correlation between cyberoception and experience of emotional valence. However, As the answer of RQ2, though cyberoception was hypothesized as a replacement for interoception measurement, the experimental result rejected such a hypothesis and discriminated between cyberoception and interoception measurement.\n\nAlthough the experimental result did not support cyberoception to replace interoception measurement, it is a valuable discovery that implies the unique characteristics that our proposed concept \"cyberoception\" holds.\n\nOne explanation for our result is that cyberoception, referring to the sense of the condition within cyberspace and parallels interoception, is crucial in users' personality traits on core affect and composes users' emotional experience. Future research explores the connection between cyberoception and varied emotions in users' daily lives, including long-term mood and short-term affective response.\n\nIn previous literature  [2, 59] , valence was demonstrated to be less related to interoception. Our findings of the correlation between the Cyberoceptive Error of Turning On and valence imply that cyberoception is connected to users' emotional experience through a different approach. Therefore, cyberoception can eliminate the blind point of interoception studies and provide a futuristic point of view toward users' affective states.\n\nInteroception is a unified sensation for each viscera, and it has been shown that visceral sensation to the stomach is consistent with that to the heart  [23] . In our study, we found a positive correlation among Cyberoception metrics. Although not statistically significant, such a positive correlation could imply a common nature among different Cyberoception metrics, which warrants further investigation. Cyberoception should be positioned as a meta concept that includes multiple perceptions towards activities and conditions within cyberspace.\n\nCyberoception employs usage data obtained from a user's daily smartphone activities, without any additional biometric sensors or well-controlled experimental environment. Thus, cyberoception enables real-time and non-invasive monitoring of user's emotional characteristics. Cyberoception, as a building block in other applications (such as a linked library), middleware, and even the operating system, contributes to understanding the affective context of users and providing more human-centered information services.\n\nIn \"measurement error in self-reported smartphone usage, \" previous studies have consistently highlighted discrepancies between self-reported smartphone usage and actual usage  [11, 13, 39] . While these studies have shown that measurement errors are non-random, the factors underlying these discrepancies remain underexplored. Most notably, demographic factors such as sex, age, marital status, and educational background have demonstrated limited or insignificant effects  [3, 50] . By shifting the focus to affective states, this study uncovers a previously overlooked dimension, emphasizing the importance of emotional valence in shaping individuals' perceptions of their smartphone use.",
      "page_start": 14,
      "page_end": 14
    },
    {
      "section_name": "Limitation And Future Work",
      "text": "There are limitations in this study, which leaves room for further research. In this study, we recruited participants from a university where many participants were underage (< 21). Therefore, the stimulus we showed them was strictly limited. We avoided using erotic, violent, or grotesque pictures, which made the sampled pictures from IAPS tend to lean more toward a low-arousing distribution.\n\nSince the participants were all university students, the inference of our experimental results is limited to the younger age group. Since it is common for interoception to decline with age  [32] , our participants had better interoceptive ability than Schandry's study  [47] . This biased age distribution can explain the difficulty encountered when investigating the relationship between interoception and other factors. Conducting experiments with all age groups would be essential for future work.\n\nThis study focuses only on the cardiac axes of interoception. Considering that much is still unknown about interoception, further research is required across other modalities, such as respiratory, gastric, colonic, and rectal axes.\n\nAs it is challenging to fully understand emotions based solely on the physiological-based interoception, it is similarly difficult to comprehensively explain emotions independently through cyberoception. The relationship between cyberoception and emotions demonstrated in this study represents only a partial aspect of the broader emotional experience. Further work is required in this area.\n\nWe conducted trials randomly orders within each in-lab experiment and forced adequate breaks between experiments. There is hardly any possibility of learning effects among the Affective Picture Rating Experiment, Interoception Experiment, and Typing Experiment because they are different tasks that follow distinctly different procedures. Future works could include investigating the effect of the mentioned in-lab experiments.\n\nOne might argue that the method used in this experiment, which requires self-reporting every half hour, is not as non-invasive as measuring interoceptive sensation, which measures heart rate using a camera in daily or weekly intervals. However, in the experiment in this paper, asking the subjects to self-report with such interval was one particular setting in the experiment to discover whether there was a correlation, given that it is still unknown how much each specific cyberoception metric correlates with emotional experience and interoception. After cyberoception is discovered because of this research, it may be more effective to use a time interval other than 30 minutes for this sensation. Discovering a more effective time interval is outside the scope of this paper itself and can be considered in future.\n\nOne notable limitation of this study, is the potential maladaptive consequences of heightened awareness of feelings. While this research aims to improve understanding of Cyberoception, psychology research suggests that consistently encouraging individuals to become acutely aware of their feelings can have unintended negative effects  [41] . Furthermore, the coping techniques involving smartphone usage should be developed in future studies.\n\nIn addition, there are potential risks associated with viewing smartphones as extensions of the body, a concept explored in this study. Excessive smartphone use is likely to intensify the phenomenon of the smartphone being perceived as an extension of the self, which may harm users' well-being. Given the widespread use of smartphones in contemporary society, there is an urgent need to accelerate research on the implications and dynamics of the \"smartphone as an extension of the self. \" In this context, research on cyberoception becomes crucial, and further studies are essential.",
      "page_start": 15,
      "page_end": 15
    },
    {
      "section_name": "Conclusion",
      "text": "In this study, we introduced the concept of cyberoception, which is expected to replace interoception as a factor of emotional ability. Through a 10-day daily-life study and an in-lab emotional psychology experiment, we analyzed 22 participants' perceptions of activities in cyberspace, interoceptive ability, and individual emotional characteristics. The result evidentiary support the correlation between the experience of emotional valence and a specific Cyberoception, \"Turning On\". Cyberoception can eliminate the blind point of interoception studies and provide a futuristic point of view toward users' affective states. We treat cyberoception as a key building block for many other apps that use the data to improve the health outcomes of mobile phone users.",
      "page_start": 15,
      "page_end": 15
    },
    {
      "section_name": "A Questions In Daily Cyberoception Measuring Survey",
      "text": "",
      "page_start": 15,
      "page_end": 15
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: shows the overview of this study containing both (a) a",
      "page": 6
    },
    {
      "caption": "Figure 1: Tasks and Schedule of the study",
      "page": 7
    },
    {
      "caption": "Figure 2: Laboratory Environment",
      "page": 7
    },
    {
      "caption": "Figure 3: Daily Cyberoception Measuring Survey Procedure",
      "page": 7
    },
    {
      "caption": "Figure 4: System Design of Daily Cyberoception Measuring",
      "page": 8
    },
    {
      "caption": "Figure 4: , the experimental application has two main",
      "page": 8
    },
    {
      "caption": "Figure 5: Procedure of Heartbeat Counting Task",
      "page": 9
    },
    {
      "caption": "Figure 5: shows the overview of the heartbeat",
      "page": 9
    },
    {
      "caption": "Figure 6: ) is used in",
      "page": 9
    },
    {
      "caption": "Figure 6: S.A.M Scale Used to Evaluate Paticipant‚Äôs Emotional",
      "page": 10
    },
    {
      "caption": "Figure 7: Procedure of Affective Picture Rating Task",
      "page": 10
    },
    {
      "caption": "Figure 6: a, the scale varies from",
      "page": 10
    },
    {
      "caption": "Figure 7: , each trial of the Affective",
      "page": 10
    },
    {
      "caption": "Figure 8: Distribution of Usage Sensing Data",
      "page": 11
    },
    {
      "caption": "Figure 9: Box Plot of Each Cyberoception Metric",
      "page": 12
    },
    {
      "caption": "Figure 10: Individual Difference of Participants‚Äô Cyberocep-",
      "page": 12
    },
    {
      "caption": "Figure 11: Correlation between Cyberoceptive Error of Turn-",
      "page": 13
    },
    {
      "caption": "Figure 12: Two-Split Analyses on Cyberoceptive Error of",
      "page": 13
    }
  ],
  "tables": [
    {
      "caption": "Table 1: shows the concrete data/event",
      "data": [
        {
          "(1) Turning On": "(2) Unlocking",
          "SCREEN_INTERACTIVE": "KEYGUARD_HIDDEN"
        },
        {
          "(1) Turning On": "(3) Screen Use Duration",
          "SCREEN_INTERACTIVE": "SCREEN_INTERACTIVE\nSCREEN_NON_INTERACTIVE"
        },
        {
          "(1) Turning On": "(4) Micro-usage",
          "SCREEN_INTERACTIVE": "ACTIVITY_PAUSED\nACTIVITY_RESUMED"
        },
        {
          "(1) Turning On": "(5) Most-used App",
          "SCREEN_INTERACTIVE": "ACTIVITY_RESUMED"
        },
        {
          "(1) Turning On": "(6) Typo",
          "SCREEN_INTERACTIVE": "TYPE_VIEW_TEXT_CHANGED"
        }
      ],
      "page": 8
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Turning On": "Unlocking",
          "Based on your daily experience\nwith your smartphone use, during\nthe period from 30 minutes ago\nto the present time, what do you\nthink about your screen switch-\ning on while using this\nsmart-\nphone? Please answer based on\nyour own perception/feeling and\ndo not dwell on your answer.": "Based on your daily experience\nwith your smartphone use, dur-\ning the period from 30 minutes\nago to the present time, what do\nyou think about your smartphone\nunlocking while using this smart-\nphone? Please answer based on\nyour own perception/feeling and\ndo not dwell on your answer.",
          "Specifically,\nhow\nmany\ntimes\ndid\nyou\nswitch\nthe screen on\nduring\nthis\n30min?": "Specifically,\nhow\nmany\ntimes did you\nunlock\nthis\nsmartphone\nduring\nthis\n30min?"
        },
        {
          "Turning On": "Screen Use Duration",
          "Based on your daily experience\nwith your smartphone use, during\nthe period from 30 minutes ago\nto the present time, what do you\nthink about your screen switch-\ning on while using this\nsmart-\nphone? Please answer based on\nyour own perception/feeling and\ndo not dwell on your answer.": "Based on your daily experience\nwith your smartphone use, during\nthe period from 30 minutes ago\nto the present time, what do you\nthink about your screen usage du-\nration? Please answer based on\nyour own perception/feeling and\ndo not dwell on your answer.",
          "Specifically,\nhow\nmany\ntimes\ndid\nyou\nswitch\nthe screen on\nduring\nthis\n30min?": "Specifically,\nhow\nlong\ndid\nyou\nuse\nyour\nscreen\nduring\nthis\n30min?"
        },
        {
          "Turning On": "Micro-usage",
          "Based on your daily experience\nwith your smartphone use, during\nthe period from 30 minutes ago\nto the present time, what do you\nthink about your screen switch-\ning on while using this\nsmart-\nphone? Please answer based on\nyour own perception/feeling and\ndo not dwell on your answer.": "Based on your daily experience\nwith your smartphone use, dur-\ning the period from 30 minutes\nago to the present time, what do\nyou think about your application\nusage under 5s, which means that\nyou shut down an application in\n5s\nfrom launching the\napplica-\ntion? Please answer based on your\nown perception/feeling and do\nnot dwell on your answer.",
          "Specifically,\nhow\nmany\ntimes\ndid\nyou\nswitch\nthe screen on\nduring\nthis\n30min?": "Specifically,\nhow\nmany\ntimes did you\nshut down an\napplication\nin\n5s\nfrom\nlaunching\nthe\napplica-\ntion?"
        },
        {
          "Turning On": "Most-used App",
          "Based on your daily experience\nwith your smartphone use, during\nthe period from 30 minutes ago\nto the present time, what do you\nthink about your screen switch-\ning on while using this\nsmart-\nphone? Please answer based on\nyour own perception/feeling and\ndo not dwell on your answer.": "Based on your daily experience\nwith your smartphone use, during\nthe period from 30 minutes ago\nto the present time, what do you\nthink about your Most Used Ap-\nplication Name launching? Please\nanswer based on your own per-\nception/feeling and do not dwell\non your answer.",
          "Specifically,\nhow\nmany\ntimes\ndid\nyou\nswitch\nthe screen on\nduring\nthis\n30min?": "Specifically,\nhow\nmany\ntimes did you\nlaunch\nthis\napplication?"
        },
        {
          "Turning On": "Typo\n(daily-life)",
          "Based on your daily experience\nwith your smartphone use, during\nthe period from 30 minutes ago\nto the present time, what do you\nthink about your screen switch-\ning on while using this\nsmart-\nphone? Please answer based on\nyour own perception/feeling and\ndo not dwell on your answer.": "Based on your daily experience\nwith your smartphone use, dur-\ning\nthe\nperiod\nfrom 30 min-\nutes\nago\nto\nthe\npresent\ntime,\nwhat\ndo\nyou\nthink\nabout\nthe\ntypo(Typographical Error) made\nby yourself on your smartphone?\nPlease base on your own percep-\ntion/feeling and do not dwell on\nyour answer.",
          "Specifically,\nhow\nmany\ntimes\ndid\nyou\nswitch\nthe screen on\nduring\nthis\n30min?": "Specifically,\nhow\nmany\ntimes did you\nmake a typo\nduring\nthis\n30min?"
        }
      ],
      "page": 17
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Beyond self-report: Tools to compare estimated and real-world smartphone use",
      "authors": [
        "Sally Andrews",
        "David Ellis",
        "Heather Shaw",
        "Lukasz Piwek"
      ],
      "year": "2015",
      "venue": "PloS one"
    },
    {
      "citation_id": "2",
      "title": "Interoceptive sensitivity and self-reports of emotional experience",
      "authors": [
        "Lisa Feldman",
        "Karen Quigley",
        "Eliza Bliss-Moreau",
        "Keith R Aronson"
      ],
      "year": "2004",
      "venue": "Journal of personality and social psychology"
    },
    {
      "citation_id": "3",
      "title": "Measuring mobile phone use: Self-report versus log data",
      "authors": [
        "Jeffrey Boase",
        "Rich Ling"
      ],
      "year": "2013",
      "venue": "Journal of Computer-Mediated Communication"
    },
    {
      "citation_id": "4",
      "title": "Falling asleep with Angry Birds, Facebook and Kindle: a large scale study on mobile application usage",
      "authors": [
        "Matthias B√∂hmer",
        "Brent Hecht",
        "Johannes Sch√∂ning",
        "Antonio Kr√ºger",
        "Gernot Bauer"
      ],
      "year": "2011",
      "venue": "Proceedings of the 13th international conference on Human computer interaction with mobile devices and services"
    },
    {
      "citation_id": "5",
      "title": "Measuring emotion: the selfassessment manikin and the semantic differential",
      "authors": [
        "M Margaret",
        "Peter Bradley",
        "Lang"
      ],
      "year": "1994",
      "venue": "Journal of behavior therapy and experimental psychiatry"
    },
    {
      "citation_id": "6",
      "title": "Interoceptive discrimination in intact humans: Detection of cardiac activity",
      "authors": [
        "Jasper Brener",
        "J Michael"
      ],
      "year": "1974",
      "venue": "Physiology & Behavior"
    },
    {
      "citation_id": "7",
      "title": "On the origin of interoception",
      "authors": [
        "Erik Ceunen",
        "Johan Vlaeyen",
        "Ilse Van Diest"
      ],
      "year": "2016",
      "venue": "Frontiers in psychology"
    },
    {
      "citation_id": "8",
      "title": "",
      "authors": [
        "Dana Wen G Chen",
        "Angela Schloesser",
        "Janine Arensdorf",
        "Changhai Simmons",
        "Rita Cui",
        "James Valentino",
        "Lisbeth Gnadt",
        "Nielsen"
      ],
      "venue": ""
    },
    {
      "citation_id": "9",
      "title": "The emerging science of interoception: sensing, integrating, interpreting, and regulating signals within the self",
      "authors": [
        "Victoria Spruance"
      ],
      "year": "2021",
      "venue": "Trends in neurosciences"
    },
    {
      "citation_id": "10",
      "title": "How do you feel? Interoception: the sense of the physiological condition of the body",
      "authors": [
        "Craig Arthur"
      ],
      "year": "2002",
      "venue": "Nature reviews neuroscience"
    },
    {
      "citation_id": "11",
      "title": "Feelings of Emotion and the Self",
      "authors": [
        "Antonio Damasio"
      ],
      "year": "2003",
      "venue": "Annals of the New York Academy of Sciences",
      "doi": "10.1196/annals.1279.014"
    },
    {
      "citation_id": "12",
      "title": "Digital devices, distraction, and student performance: Does in-class cell phone use reduce learning?",
      "authors": [
        "Duncan Douglas",
        "Hoekstra Angel",
        "Wilcox Bethany"
      ],
      "year": "2012",
      "venue": "Astronomy education review"
    },
    {
      "citation_id": "13",
      "title": "Algorithm 235: random permutation",
      "authors": [
        "Richard Durstenfeld"
      ],
      "year": "1964",
      "venue": "Commun. ACM"
    },
    {
      "citation_id": "14",
      "title": "Cell phone usage and academic performance: An experiment",
      "authors": [
        "Daniel Darghan",
        "Alexandra Strommer"
      ],
      "year": "2018",
      "venue": "Computers & Education"
    },
    {
      "citation_id": "15",
      "title": "Contextual experience sampling of mobile application micro-usage",
      "authors": [
        "Denzil Ferreira",
        "Jorge Goncalves",
        "Vassilis Kostakos",
        "Louise Barkhuus",
        "Anind Dey"
      ],
      "year": "2014",
      "venue": "Proceedings of the 16th international conference on Human-computer interaction with mobile devices & services"
    },
    {
      "citation_id": "16",
      "title": "AWARE: mobile context instrumentation framework",
      "authors": [
        "Denzil Ferreira",
        "Vassilis Kostakos",
        "Anind Dey"
      ],
      "year": "2015",
      "venue": "Frontiers in ICT"
    },
    {
      "citation_id": "17",
      "title": "2018. I see neither your Fear, nor your Sadness-Interoception in adolescents",
      "authors": [
        "Eleana Georgiou",
        "Sandra Mai",
        "Katya Fernandez",
        "Olga Pollatos"
      ],
      "year": "2018",
      "venue": "Consciousness and cognition"
    },
    {
      "citation_id": "18",
      "title": "Smartphone and the self: Experimental investigation of self-incorporation of and attachment to smartphones",
      "authors": [
        "Marlene Gertz",
        "Simone Sch√ºtz-Bosbach",
        "Sarah Diefenbach"
      ],
      "year": "2021",
      "venue": "Multimodal Technologies and Interaction"
    },
    {
      "citation_id": "19",
      "title": "Tapsense: Combining self-report patterns and typing characteristics for smartphone based emotion detection",
      "authors": [
        "Surjya Ghosh",
        "Niloy Ganguly",
        "Bivas Mitra",
        "Pradipta De"
      ],
      "year": "2017",
      "venue": "Proceedings of the 19th International Conference on Human-Computer Interaction with Mobile Devices and Services"
    },
    {
      "citation_id": "20",
      "title": "Representation learning for emotion recognition from smartphone keyboard interactions",
      "authors": [
        "Surjya Ghosh",
        "Shivam Goenka",
        "Niloy Ganguly",
        "Bivas Mitra",
        "Pradipta De"
      ],
      "year": "2019",
      "venue": "2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII)"
    },
    {
      "citation_id": "21",
      "title": "AffectPro: Towards Constructing Affective Profile Combining Smartphone Typing Interaction and Emotion Self-reporting Pattern",
      "authors": [
        "Satchit Hari",
        "Sayan Sarcar",
        "Sougata Sen",
        "Surjya Ghosh"
      ],
      "year": "2022",
      "venue": "Proceedings of the 2022 International Conference on Multimodal Interaction"
    },
    {
      "citation_id": "22",
      "title": "Emotional regulation and bodily sensation: interoceptive awareness is intact in borderline personality disorder",
      "authors": [
        "Nova Hart",
        "John Mcgowan",
        "Ludovico Minati",
        "Hugo Critchley"
      ],
      "year": "2013",
      "venue": "Journal of personality disorders"
    },
    {
      "citation_id": "23",
      "title": "Varieties of the extended self",
      "authors": [
        "Richard Heersmink"
      ],
      "year": "2020",
      "venue": "Consciousness and Cognition"
    },
    {
      "citation_id": "24",
      "title": "Interoception across modalities: on the relationship between cardiac awareness and the sensitivity for gastric functions",
      "authors": [
        "M Beate",
        "Eric Herbert",
        "Olga Muth",
        "Cornelia Pollatos",
        "Herbert"
      ],
      "year": "2012",
      "venue": "PloS one"
    },
    {
      "citation_id": "25",
      "title": "VitaMon: measuring heart rate variability using smartphone front camera",
      "authors": [
        "Sinh Huynh",
        "Rajesh Krishna Balan",
        "Jeonggil Ko",
        "Youngki Lee"
      ],
      "year": "2019",
      "venue": "Proceedings of the 17th Conference on Embedded Networked Sensor Systems"
    },
    {
      "citation_id": "26",
      "title": "Interoception is associated with the impact of eye contact on spontaneous facial mimicry",
      "authors": [
        "Masahiro Imafuku",
        "Hirokata Fukushima",
        "Yuko Nakamura",
        "Masako Myowa",
        "Shinsuke Koike"
      ],
      "year": "2020",
      "venue": "Scientific Reports"
    },
    {
      "citation_id": "27",
      "title": "",
      "authors": [
        "Sensor"
      ],
      "year": "2024",
      "venue": ""
    },
    {
      "citation_id": "28",
      "title": "Differential functional brain network connectivity during visceral interoception as revealed by independent component analysis of fMRI time-series",
      "authors": [
        "Behnaz Jarrahi",
        "Dante Mantini",
        "Joshua Balsters",
        "Lars Michels",
        "Thomas Kessler",
        "Ulrich Mehnert",
        "Spyros Kollias"
      ],
      "year": "2015",
      "venue": "Human brain mapping"
    },
    {
      "citation_id": "29",
      "title": "ExpresSense: Exploring a Standalone Smartphone to Sense Engagement of Users from Facial Expressions Using Acoustic Sensing",
      "authors": [
        "Pragma Kar",
        "Shyamvanshikumar Singh",
        "Avijit Mandal",
        "Samiran Chattopadhyay",
        "Sandip Chakraborty"
      ],
      "year": "2023",
      "venue": "Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems"
    },
    {
      "citation_id": "30",
      "title": "",
      "authors": [
        "Takumi Karasawa"
      ],
      "year": "2022",
      "venue": ""
    },
    {
      "citation_id": "31",
      "title": "Blood, sweat, and tears: Individual differences in autonomic self-perception",
      "authors": [
        "Edward S Katkin"
      ],
      "year": "1985",
      "venue": "Psychophysiology"
    },
    {
      "citation_id": "32",
      "title": "Interoception and mental health: a roadmap",
      "authors": [
        "Ralph Sahib S Khalsa",
        "Adolphs",
        "Hugo Oliver G Cameron",
        "Paul Critchley",
        "Justin Davenport",
        "Jamie Feinstein",
        "Sarah Feusner",
        "Richard Garfinkel",
        "Wolf Lane",
        "Mehling"
      ],
      "year": "2018",
      "venue": "Biological psychiatry: cognitive neuroscience and neuroimaging"
    },
    {
      "citation_id": "33",
      "title": "Interoceptive awareness declines with age",
      "authors": [
        "David Sahib S Khalsa",
        "Daniel Rudrauf",
        "Tranel"
      ],
      "year": "2009",
      "venue": "Interoceptive awareness declines with age"
    },
    {
      "citation_id": "34",
      "title": "No such effect? The implications of measurement error in self-report measures of mobile communication use",
      "authors": [
        "Tetsuro Kobayashi",
        "Jeffrey Boase"
      ],
      "year": "2012",
      "venue": "Communication Methods and Measures"
    },
    {
      "citation_id": "35",
      "title": "International affective picture system (IAPS): Technical manual and affective ratings",
      "authors": [
        "Margaret Peter J Lang",
        "Bruce Bradley",
        "Cuthbert"
      ],
      "year": "1997",
      "venue": "International affective picture system (IAPS): Technical manual and affective ratings"
    },
    {
      "citation_id": "36",
      "title": "International affective picture system (IAPS): Affective ratings of pictures and instruction manual. NIMH, Center for the Study of Emotion & Attention",
      "authors": [
        "Margaret Peter J Lang",
        "Bruce Bradley",
        "Cuthbert"
      ],
      "year": "2005",
      "venue": "International affective picture system (IAPS): Affective ratings of pictures and instruction manual. NIMH, Center for the Study of Emotion & Attention"
    },
    {
      "citation_id": "37",
      "title": "Self-perception beyond the body: the role of past agency",
      "authors": [
        "Roman Liepelt",
        "Thomas Dolk",
        "Bernhard Hommel"
      ],
      "year": "2017",
      "venue": "Psychological research"
    },
    {
      "citation_id": "38",
      "title": "Can your smartphone infer your mood",
      "authors": [
        "Robert Likamwa",
        "Yunxin Liu",
        "Nicholas Lane",
        "Lin Zhong"
      ],
      "year": "2011",
      "venue": "In PhoneSense workshop. Citeseer"
    },
    {
      "citation_id": "39",
      "title": "Moodscope: Building a mood sensor from smartphone usage patterns",
      "authors": [
        "Robert Likamwa",
        "Yunxin Liu",
        "Nicholas Lane",
        "Lin Zhong"
      ],
      "year": "2013",
      "venue": "Proceeding of the 11th annual international conference on Mobile systems, applications, and services"
    },
    {
      "citation_id": "40",
      "title": "Time distortion associated with smartphone addiction: Identifying smartphone addiction via a mobile application (App)",
      "authors": [
        "Yu-Hsuan Lin",
        "Yu-Cheng Lin",
        "Yang-Han Lee",
        "Po-Hsien Lin",
        "Sheng-Hsuan Lin",
        "Li-Ren Chang",
        "Hsien-Wei Tseng",
        "Liang-Yu Yen",
        "Cheryl Ch Yang",
        "Terry Bj Kuo"
      ],
      "year": "2015",
      "venue": "Journal of psychiatric research"
    },
    {
      "citation_id": "41",
      "title": "iOS crowd-sensing won't hurt a bit!: AWARE Framework and Sustainable Study Guideline for iOS Platform",
      "authors": [
        "Yuuki Nishiyama",
        "Denzil Ferreira",
        "Yusaku Eigen",
        "Wataru Sasaki",
        "Tadashi Okoshi",
        "Jin Nakazawa",
        "Anind Dey",
        "Kaoru Sezaki"
      ],
      "year": "2020",
      "venue": "International Conference on Human-Computer Interaction"
    },
    {
      "citation_id": "42",
      "title": "Rethinking rumination",
      "authors": [
        "Susan Nolen-Hoeksema",
        "Blair Wisco",
        "Sonja Lyubomirsky"
      ],
      "year": "2008",
      "venue": "Perspectives on psychological science"
    },
    {
      "citation_id": "43",
      "title": "Smartphone and self-extension: Functionally, anthropomorphically, and ontologically extending self via the smartphone",
      "authors": [
        "Chang Sup",
        "Barbara Kaye"
      ],
      "year": "2019",
      "venue": "Mobile Media & Communication"
    },
    {
      "citation_id": "44",
      "title": "Embodied feelings-A meta-analysis on the relation of emotion intensity perception and interoceptive accuracy",
      "authors": [
        "Noemie Parrinello",
        "Jessica Napieralski",
        "Alexander Gerlach",
        "Anna Pohl"
      ],
      "year": "2022",
      "venue": "Physiology & Behavior"
    },
    {
      "citation_id": "45",
      "title": "Measuring interoception: The phase adjustment task",
      "authors": [
        "D Plans",
        "S Ponzo",
        "D Morelli",
        "M Cairo",
        "C Ring",
        "C Keating",
        "A Cunningham",
        "C Catmur",
        "J Murphy",
        "G Bird"
      ],
      "year": "2021",
      "venue": "Biological Psychology",
      "doi": "10.1016/j.biopsycho.2021.108171"
    },
    {
      "citation_id": "46",
      "title": "Functions of interoception: From energy regulation to experience of the self",
      "authors": [
        "Karen Quigley",
        "Scott Kanoski",
        "Warren Grill",
        "Lisa Barrett",
        "Manos Tsakiris"
      ],
      "year": "2021",
      "venue": "Trends in neurosciences"
    },
    {
      "citation_id": "47",
      "title": "Comparing ESM timings for emotional estimation model with fine temporal granularity",
      "authors": [
        "Wataru Sasaki",
        "Jin Nakazawa",
        "Tadashi Okoshi"
      ],
      "year": "2018",
      "venue": "Proceedings of the 2018 ACM International Joint Conference and 2018 International Symposium on Pervasive and Ubiquitous Computing and Wearable Computers"
    },
    {
      "citation_id": "48",
      "title": "Heart beat perception and emotional experience",
      "authors": [
        "Rainer Schandry"
      ],
      "year": "1981",
      "venue": "Psychophysiology"
    },
    {
      "citation_id": "49",
      "title": "LiveLab: measuring wireless networks and smartphone users in the field",
      "authors": [
        "Clayton Shepard",
        "Ahmad Rahmati",
        "Chad Tossell",
        "Lin Zhong",
        "Phillip Kortum"
      ],
      "year": "2011",
      "venue": "ACM SIGMETRICS Performance Evaluation Review"
    },
    {
      "citation_id": "50",
      "title": "The integrative action of the nervous system",
      "authors": [
        "Charles Scott"
      ],
      "year": "1906",
      "venue": "The integrative action of the nervous system"
    },
    {
      "citation_id": "51",
      "title": "An evaluation of self-reported mobile phone use compared to billing records among a group of engineers and scientists",
      "authors": [
        "Mona Shum",
        "Michael Kelsh",
        "Ke Asher R Sheppard",
        "Zhao"
      ],
      "year": "2011",
      "venue": "Bioelectromagnetics"
    },
    {
      "citation_id": "52",
      "title": "Gut inference: A computational modelling approach",
      "authors": [
        "Ryan Smith",
        "Ahmad Mayeli",
        "Samuel Taylor",
        "Obada Al Zoubi",
        "Jessyca Naegele",
        "Sahib Khalsa"
      ],
      "year": "2021",
      "venue": "Biological psychology"
    },
    {
      "citation_id": "53",
      "title": "Attenuated sensitivity to the emotions of others by insular lesion",
      "authors": [
        "Yuri Terasawa",
        "Yoshiko Kurosaki",
        "Yukio Ibata",
        "Yoshiya Moriguchi",
        "Satoshi Umeda"
      ],
      "year": "2015",
      "venue": "Frontiers in Psychology"
    },
    {
      "citation_id": "54",
      "title": "Interoceptive sensitivity predicts sensitivity to the emotions of others",
      "authors": [
        "Yuri Terasawa",
        "Yoshiya Moriguchi",
        "Saiko Tochizawa",
        "Satoshi Umeda"
      ],
      "year": "2014",
      "venue": "Cognition and Emotion"
    },
    {
      "citation_id": "55",
      "title": "Interoception. Biological psychology",
      "authors": [
        "Dieter Vaitl"
      ],
      "year": "1996",
      "venue": "Interoception. Biological psychology"
    },
    {
      "citation_id": "56",
      "title": "The water load test as a measure of gastric interoception: Development of a two-stage protocol and application to a healthy female population",
      "authors": [
        "Zo√© Van Dyck",
        "Claus V√∂gele",
        "Jens Blechert",
        "Annika Lutz",
        "Andr√© Schulz",
        "Beate M Herbert"
      ],
      "year": "2016",
      "venue": "PloS one"
    },
    {
      "citation_id": "57",
      "title": "Seismo: Blood pressure monitoring using built-in smartphone accelerometer and camera",
      "authors": [
        "Edward Jay",
        "Junyi Zhu",
        "Mohit Jain",
        "Tien-Jui Lee",
        "Elliot Saba"
      ],
      "year": "2018",
      "venue": "Proceedings of the 2018 CHI conference on human factors in computing Systems"
    },
    {
      "citation_id": "58",
      "title": "What is interoception, and how does it affect mental health? 5 questions for April Smith",
      "authors": [
        "Kirsten Weir"
      ],
      "year": "2023",
      "venue": "What is interoception, and how does it affect mental health? 5 questions for April Smith"
    },
    {
      "citation_id": "59",
      "title": "Tolerance for rectosigmoid distention in irritable bowel syndrome",
      "authors": [
        "Beate William E Whitehead",
        "Paul Holtkotter",
        "Rupert Enck",
        "Kim Hoelzl",
        "James Holmes",
        "Anthony",
        "Marvin Harry S Shabsin",
        "Schuster"
      ],
      "year": "1990",
      "venue": "Gastroenterology"
    },
    {
      "citation_id": "60",
      "title": "Heartbeat detection and the experience of emotions",
      "authors": [
        "Stefan Wiens",
        "Elizabeth Mezzacappa",
        "Edward Katkin"
      ],
      "year": "2000",
      "venue": "Cognition and Emotion",
      "doi": "10.1080/026999300378905"
    },
    {
      "citation_id": "61",
      "title": "Determining typical smartphone usage: What data do we need?",
      "authors": [
        "David Thomas Dw Wilcockson",
        "Heather Ellis",
        "Shaw"
      ],
      "year": "2018",
      "venue": "Cyberpsychology, Behavior, and Social Networking"
    },
    {
      "citation_id": "62",
      "title": "Fast app launching for mobile devices using predictive user context",
      "authors": [
        "Tingxin Yan",
        "David Chu",
        "Deepak Ganesan",
        "Aman Kansal",
        "Jie Liu"
      ],
      "year": "2012",
      "venue": "Proceedings of the 10th international conference on Mobile systems, applications, and services"
    },
    {
      "citation_id": "63",
      "title": "Moodexplorer: Towards compound emotion detection via smartphone sensing",
      "authors": [
        "Xiao Zhang",
        "Wenzhong Li",
        "Xu Chen",
        "Sanglu Lu"
      ],
      "year": "2018",
      "venue": "Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies"
    }
  ]
}