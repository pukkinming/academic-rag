{
  "paper_id": "2504.21154v1",
  "title": "Emotion Recognition In Contemporary Dance Performances Using Laban Movement Analysis",
  "published": "2025-04-29T20:17:27Z",
  "authors": [
    "Muhammad Turab",
    "Philippe Colantoni",
    "Damien Muselet",
    "Alain Tremeau"
  ],
  "keywords": [
    "Laban Movement Analysis",
    "Emotion Recognition",
    "Explainable AI",
    "3D Body Pose Estimation"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "This paper presents a novel framework for emotion recognition in contemporary dance by improving existing Laban Movement Analysis (LMA) feature descriptors and introducing robust, novel descriptors that capture both quantitative and qualitative aspects of the movement. Our approach extracts expressive characteristics from 3D keypoints data of professional dancers performing contemporary dance under various emotional states, and train multiple classifiers, including Random Forests and Support Vector Machines. Additionally, provide in-depth explanation of features and their impact on model predictions using explainable machine learning methods. Overall, our study improves emotion recognition in contemporary dance and offers promising applications in performance analysis, dance training, and human-computer interaction with highest accuracy of 96.85%.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "In recent years, human emotion recognition has become an important research direction in the field of motion analysis and human-computer interaction. Emotion recognition involves the analysis of various emotional data by extracting features that describe the emotion and their relationship to classify the emotional state. It has been widely used in many fields including emotions in facial expressions  [11] , speech recognition  [16] , text  [2]  and psychological signals  [15] . Emotion analysis is not limited to these fields, but it can expand to any field that involves movements. For instance, dance is a form of body movements that is used to express various emotions. Dance has been an integral part of human history, traditions, and cultures to express, tell stories, and convey emotions. Over the years, dance styles have evolved greatly reflecting cultural, social, and artistic changes. One of the new styles that has emerged is contemporary dance that combines elements of jazz, ballet, and modern dance. It originates from a desire to break away from the rigid structures of traditional ballet and modern dance. Unlike traditional dance, it allows dancers to explore novel forms of movement and emotional expression without setting strict rules. Due to the free-form structure of the contemporary dance style, it becomes challenging to recognize emotions.\n\nFor such challenges, Laban Movement analysis (LMA)  [17]  provides a comprehensive framework for the evaluation and interpretation of human body movements. It is divided into four main components including Body, Effort, Shape, and Space. These components describe the structural, geometrical, and dynamic properties of motion. Body and Space components describe how the human body moves, either within the body or in relation with the 3D space surrounding the body. The Shape component describes the shape morphology of the body during the motion, whereas the Effort component focuses on the qualitative aspects of the movement in terms of dynamics, energy, and intent. LMA is more qualitative than quantitative, and a few studies have tried to propose feature descriptors that quantify the qualities of LMA to some extent. However, there are still a few challenges including capturing temporal dynamics of movement, and clear explanation of feature descriptors. Many current feature descriptors for movement analysis may not fully capture the dynamic characteristics without temporal dynamics. To address these challenges, we propose robust feature descriptors with temporal dynamics to capture the dynamic nuances of LMA qualities with their explanation on model predictions and individual performance. The main contributions of this study are as follows:\n\n-We improve existing feature descriptors by adding temporal dynamics to accurately capture movement trends and behaviors within short time windows. -We propose new feature descriptors for the four LMA components that capture rich representations of movements. -We perform a comprehensive evaluation on a contemporary dance dataset using Machine Learning (ML) methods, and analyze the interpretability of our descriptors with eXplainable AI methods.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Related Work",
      "text": "Emotion recognition in dance movements has been an active field due to its applications in human-computer interaction  [9] , performance analysis  [24] , and evaluation  [6] . Understanding how dancers express emotions through movement provides valuable insights into the expressive behavior of the performer. To extract expressive behavior from movement, LMA has become a popular framework as it provides a structured language to describe both the quantitative and qualitative aspects of human motion. In study  [1] , LMA is used to recognize and analyze expressive gestures, including dancing, moving, waving, pointing, and stopping, with four emotions happy, angry, sad and neutral. Feature evaluation was performed using ML methods and subjective evaluation. The results show that the features are 87. 03% accurate in gesture classification.  [25]  used Kinect to track dancers and developed models for action and emotion recognition with 88.34% and 98.95% accuracy on skeleton data. Features like eigenvalue speed and skeleton pair distance help distinguish emotions. LMA was used in human action recognition in  [22] , with a two-stage approach in which the first feature descriptors are defined using three components of LMA, including body, space, and shape. The results were obtained on various datasets using Dynamic Time Warping (DTW) to measure similarity in actions. Several studies have focused on the classification of dance emotions using LMA-based feature descriptors. A method is proposed to extract the motion qualities from dance performances for indexing and analysis in  [4] . LMA-based features were used to investigate the correlation of features with dancers expressed emotional state. The results show low inter-feature correlation between dancers and their emotional state.\n\n[3] investigated similarities of various emotional states using extracted LMA extracted features. The results show that the features can partially extract LMA components that can be used for the dance classification from emotion.\n\nFor automatic feature extraction and better results, Deep learning (DL) has been used.  [27]  applied a hybrid deep learning method based on Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) to effectively identify emotions. For body structure, spatial orientation, and force effect LMAbased feature descriptors were used to add emotional changes during movement. Their approach successfully recognizes emotions in dance movements with high accuracy.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Methodology",
      "text": "To improve emotion recognition in contemporary dance, our study is divided into six main parts: 1) Data pre-processing, 2) 3D human body pose estimation, 3) LMA feature extraction, 4) Multiclass classification, 5) Evaluation, and 6) Explainability of feature descriptors as shown in Fig.  1 .",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Data Pre-Processing",
      "text": "We use contemporary dance performance videos from the Dance Motion capture dataset provided by the University of Cyprus  [5] . This dataset contains performances of 5 dancers expressing 12 emotions including afraid, angry, annoyed, bored, excited, happy, miserable, pleased, relaxed, sad, satisfied and tired. The dataset has a few limitations, such as: 1) inconsistent video duration, 2) limited number of dancers and performances, 3) low frame rate, and 4) a fixed camera angle for a single perspective.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "3D Human Body Pose Estimation",
      "text": "To obtain the joints keypoint data from dance videos, we use Neural Localizer Fields (NLF)  [23]  for 3D body pose estimation. We compare NLF with other state-of-the-art (SOTA) methods including Mediapipe  [19]  and OpenPose  [12]  and choose NLF for several reasons including: 1) It is an advanced model trained on massive data to estimate 2D/3D points from single image, 2) the dance performances have many frames where some body parts are occluded or missing in some cases when dancer is very close to the camera and NLF performs really well",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Lma Feature Extraction",
      "text": "Laban Movement Analysis is a language and a structured framework to describe, and interpret human body movements. It categorizes human motion into four main components: BODY, EFFORT, SHAPE and SPACE. Body component describes the structural and physical characteristics of human body and is responsible for joints connectivity, movement and their influence on each other.\n\nFor joint connectivity, we calculate the Euclidean distance and angles between the hands, shoulders, pelvis, knees, and ankles. For movement, we propose a new feature descriptor to describe the joint that initiates movement in a sequence, as shown in Equation  1 .\n\nHere P j (t) denotes the position of joint j at time t, ∆t is the time interval, w is the short time-window to add temporal dynamics, and τ is a data-driven threshold calculated using standard-deviation of the entire sequence. Effort component describes the intention, dynamic qualities of movement, and energy used during movement. It is associated with the change in emotion or mood, hence it is useful for motion expressivity and emotion description. We mainly focus on upper and lower body parts, such as hands, feet, head, and pelvis, as these joints are involved most in emotion expression. The Effort component has four factors: Space, Weight, Time, and Flow. Effort Space describes the attention of movement in space, and it can be direct where the movement is focused on single direction, and indirect where the movement is focused in multi-directions. For this we calculate the distance of each joint for a short time-window to the total distance covered by that joint using Equation  2 .\n\nTotal space is calculated by multiplying the weights α j of selected joints J to their space factor using Equation  3 . Joint weights are used to give more importance to extremities, as defined in  [13] .\n\nEffort Weight describes how powerful or strong a movement is, it can be strong or light. For this we calculate the kinetic energy of selected joints J using Equation  4 . Here v j (t i ) denotes the velocity of a joint j at time t i .\n\nEffort Time captures a sense of urgency. It tells how quick or sustained a movement is executed. For this we calculate the acceleration of selected joints over a sliding time-window as shown in Equation  5 .\n\nwhere Time j (T ) = 1 T T i=1 a j (t i ), and a j denotes the acceleration of a joint j. All these features are inspired from  [18] . Space component describes the relationship of movement with space. For this we calculate trajectory of whole sequence, curvature, and propose a new feature spatial dispersion that describes how dancer is using kinesphere or it's personal space. It is calculated as distance of upper body parts to torso, pelvis for lower body parts. total path covered, and total distance covered. Shape component describes how the body is changing shape during the movement. For this we calculate the volume of the body using ConvexHull algorithm implemented in Python SciPy package  [26] .\n\nOnce we quantify all LMA components, we obtain a descriptor vector composed of 54 features which is used as input to the classification models.",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "Multi-Class Emotion Classification",
      "text": "For emotion classification we use ML methods including Support Vector Machines (SVM)  [14] , and Random Forest (RF)  [10] , since they are already used for emotion classification in  [1] [27]  [3] . Firstly, we use 3 fold cross-validation to divide the dataset into 3 sets including training, testing, and validation to overcome overfitting and data dependency. For both SVM and RF the best hyperparameter values were found using GridSearch  [8] , and the best parameter values were selected based on the validation accuracy.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Model Explainability Using Shap",
      "text": "Machine learning models are often considered black-box systems, which means that the process by which they arrive at specific predictions remains unclear. It is challenging to determine the factors that influence their results. In order to improve our understanding for emotion classification in contemporary dance performances, we use SHapley additive explanations (SHAP)  [21] , which is a game theory-based method to explain the predictions of ML models by assigning importance values to each feature for a given prediction. It tells the contribution of each feature to a specific prediction. For SVM we applied KernelExplainer, and for Random Forest we applied TreeExplainer  [20] .",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Results",
      "text": "In this section, we present the experimental results obtained using proposed LMA feature descriptors. For evaluation accuracy, precision, and recall metrics are used to assess the performance of our method. Next, we summarize the key quantitative results, highlighting how our approach compares with other methods. Table  1  shows the results of individual emotional states, It can be observed that RF demonstrates consistent performance across all classes and metrics. Similarly, the SVM shows balanced performance but is lower than that of RF. Our method maintains consistent performance across all emotional states, unlike  [3] , where some classes show high accuracy while others perform lower, clearly indicating that the features do not capture overlapping emotions.\n\nTable  2  presents the comparison of different methods on the Dance Motion Capture dataset when compared to the proposed method. It is evident that the proposed method outperforms all other methods in terms of accuracy. RF achieves a higher accuracy of 96.85% compared to SVM's 93.90%.\n\nIn Fig.  2 , we show the predictions of our method for unseen movement sequences, where it successfully recognizes emotions in dance performances.\n\nOur sliding window approach improves the overall accuracy of emotion classification, as shown in Fig.  3 . It can be observed that a smaller window size results in lower accuracy, while increasing the window size improves the accuracy for both RF and SVM. In our case, the optimal window size is 25-30 for a balanced performance, and after 30 the improvement is negligible. Although it is evident that a larger window improves accuracy, it is also important to note that it may suppress nuanced emotional details. Therefore, selecting an optimal window size is crucial.  Currently, our method achieves promising results for emotion classification in contemporary dance. However, there remains a challenge regarding interpretability and explainability of the models, which has not been explored in existing research on emotion classification. We aim to investigate questions such as which features significantly affect the ability of models to classify angry movements from those that are happy or excited, as they look very similar visually. To answer such questions, we apply various method that explain the contributions of features individually or as a whole. The SHAP summary plot in Fig.  4  shows most influential features in predicting emotions from movement data. Body volume has the highest impact, indicating that overall body expansion or contraction plays a key role in emotional expression. LMA Effort time has high impact as well which is essential to distinguish angry movements from sad. Overall, both global body features and localized joint behavior impact model's predictions. Impact of key movement features on emotion predictions are illustrated in Fig.  5  and Fig.  6 . The horizontal axis represents the SHAP value, where positive values push the prediction towards a target class and negative values push it away. In both plots, features such as Body volume, Effort Time, and Pelvis Jerkiness show strong positive influence, indicating that emotions associated with expansive or intense movements (e.g., anger or excitement) are driven by higher body expansion, energetic motion, and movement irregularities. Conversely, lower values in these features tend to align with sustained movements (e.g., sadness or tiredness), reflecting more contracted posture, reduced movement dispersion, and lower kinetic energy.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Conclusion",
      "text": "In this study, we improve existing Laban Movement Analysis (LMA) feature descriptors by adding the temporal dynamics with sliding window approach, introduce novel robust descriptors that capture both quantitative and qualitative aspects of emotions in dance. With a comparative analysis, we show that the proposed approach achieves higher accuracy compared to existing methods. Furthermore, we provide interpretations and explanations of the feature descriptors to better understand black-box models and their predictions. Overall, our study improves the understanding and recognition of dance emotions using improved LMA based feature descriptors, and contribute to more effective and transparent emotion and motion analysis in dance performances. Future work includes extending the framework to dance style classification.",
      "page_start": 10,
      "page_end": 10
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Overview of the proposed method for Emotion Recognition in Contem-",
      "page": 4
    },
    {
      "caption": "Figure 2: , we show the predictions of our method for unseen movement se-",
      "page": 6
    },
    {
      "caption": "Figure 3: It can be observed that a smaller window size results",
      "page": 6
    },
    {
      "caption": "Figure 2: Ground truth and model predictions for three unseen dance performances.",
      "page": 7
    },
    {
      "caption": "Figure 3: Impact of sliding window size on accuracy.",
      "page": 8
    },
    {
      "caption": "Figure 4: shows most",
      "page": 8
    },
    {
      "caption": "Figure 4: Impact of top 10 features on models predictions.",
      "page": 8
    },
    {
      "caption": "Figure 5: and Fig. 6. The horizontal axis represents the SHAP value, where posi-",
      "page": 9
    },
    {
      "caption": "Figure 5: Impact of features on the model’s predictions for dance movements ex-",
      "page": 9
    },
    {
      "caption": "Figure 6: Impact of features on the model’s predictions for dance movements ex-",
      "page": 9
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "muhammad.turab.muslim.bajeer@etu.univ-st-etienne.fr": "{philippe.colantoni,\ndamien.muselet,\nalain.tremeau}@univ-st-etienne.fr"
        },
        {
          "muhammad.turab.muslim.bajeer@etu.univ-st-etienne.fr": "framework for emotion recog-\nAbstract. This paper presents a novel"
        },
        {
          "muhammad.turab.muslim.bajeer@etu.univ-st-etienne.fr": "nition in contemporary dance by improving existing Laban Movement"
        },
        {
          "muhammad.turab.muslim.bajeer@etu.univ-st-etienne.fr": "Analysis\n(LMA)\nfeature descriptors and introducing robust, novel de-"
        },
        {
          "muhammad.turab.muslim.bajeer@etu.univ-st-etienne.fr": "scriptors\nthat capture both quantitative and qualitative aspects of\nthe"
        },
        {
          "muhammad.turab.muslim.bajeer@etu.univ-st-etienne.fr": "movement. Our\napproach extracts\nexpressive\ncharacteristics\nfrom 3D"
        },
        {
          "muhammad.turab.muslim.bajeer@etu.univ-st-etienne.fr": "keypoints data of professional dancers performing contemporary dance"
        },
        {
          "muhammad.turab.muslim.bajeer@etu.univ-st-etienne.fr": "under various emotional states, and train multiple classifiers,\nincluding"
        },
        {
          "muhammad.turab.muslim.bajeer@etu.univ-st-etienne.fr": "Random Forests and Support Vector Machines. Additionally, provide"
        },
        {
          "muhammad.turab.muslim.bajeer@etu.univ-st-etienne.fr": "in-depth explanation of\nfeatures and their impact on model predictions"
        },
        {
          "muhammad.turab.muslim.bajeer@etu.univ-st-etienne.fr": "using explainable machine learning methods. Overall, our study improves"
        },
        {
          "muhammad.turab.muslim.bajeer@etu.univ-st-etienne.fr": "emotion recognition in contemporary dance and offers promising appli-"
        },
        {
          "muhammad.turab.muslim.bajeer@etu.univ-st-etienne.fr": "cations\nin performance analysis, dance training, and human–computer"
        },
        {
          "muhammad.turab.muslim.bajeer@etu.univ-st-etienne.fr": "interaction with highest accuracy of 96.85%."
        },
        {
          "muhammad.turab.muslim.bajeer@etu.univ-st-etienne.fr": "· Emotion Recognition · Ex-\nKeywords: Laban Movement Analysis"
        },
        {
          "muhammad.turab.muslim.bajeer@etu.univ-st-etienne.fr": "plainable AI · 3D Body Pose Estimation"
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "plainable AI · 3D Body Pose Estimation": "1\nIntroduction"
        },
        {
          "plainable AI · 3D Body Pose Estimation": "In recent years, human emotion recognition has become an important research"
        },
        {
          "plainable AI · 3D Body Pose Estimation": "direction in the field of motion analysis and human-computer interaction. Emo-"
        },
        {
          "plainable AI · 3D Body Pose Estimation": "tion recognition involves"
        },
        {
          "plainable AI · 3D Body Pose Estimation": "features\nthat describe the emotion and their"
        },
        {
          "plainable AI · 3D Body Pose Estimation": "tional state. It has been widely used in many fields including emotions in facial"
        },
        {
          "plainable AI · 3D Body Pose Estimation": "expressions [11], speech recognition [16], text [2] and psychological signals [15]."
        },
        {
          "plainable AI · 3D Body Pose Estimation": "Emotion analysis\nis not"
        },
        {
          "plainable AI · 3D Body Pose Estimation": "that involves movements. For instance, dance is a form of body movements that"
        },
        {
          "plainable AI · 3D Body Pose Estimation": "is used to express various emotions. Dance has been an integral part of human"
        },
        {
          "plainable AI · 3D Body Pose Estimation": "history,\ntraditions, and cultures"
        },
        {
          "plainable AI · 3D Body Pose Estimation": "Over the years, dance styles have evolved greatly reflecting cultural, social, and"
        },
        {
          "plainable AI · 3D Body Pose Estimation": "artistic changes. One of the new styles that has emerged is contemporary dance"
        },
        {
          "plainable AI · 3D Body Pose Estimation": "that combines elements of"
        },
        {
          "plainable AI · 3D Body Pose Estimation": "desire to break away from the rigid structures of traditional ballet and modern"
        },
        {
          "plainable AI · 3D Body Pose Estimation": "dance. Unlike traditional dance, it allows dancers to explore novel forms of move-"
        },
        {
          "plainable AI · 3D Body Pose Estimation": "ment and emotional expression without setting strict rules. Due to the free-form"
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "2\nMuhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": "structure of the contemporary dance style,\nit becomes challenging to recognize"
        },
        {
          "2\nMuhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": "emotions."
        },
        {
          "2\nMuhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": "For such challenges, Laban Movement analysis (LMA) [17] provides a com-"
        },
        {
          "2\nMuhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": "prehensive framework for the evaluation and interpretation of human body move-"
        },
        {
          "2\nMuhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": "ments.\nIt is divided into four main components including Body, Effort, Shape,"
        },
        {
          "2\nMuhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": "and Space. These components describe the structural, geometrical, and dynamic"
        },
        {
          "2\nMuhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": "properties of motion. Body and Space components describe how the human body"
        },
        {
          "2\nMuhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": "moves, either within the body or in relation with the 3D space surrounding the"
        },
        {
          "2\nMuhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": "body. The Shape component describes the shape morphology of the body during"
        },
        {
          "2\nMuhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": "the motion, whereas the Effort component focuses on the qualitative aspects of"
        },
        {
          "2\nMuhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": "the movement in terms of dynamics, energy, and intent. LMA is more qualitative"
        },
        {
          "2\nMuhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": "than quantitative, and a few studies have tried to propose feature descriptors"
        },
        {
          "2\nMuhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": "that quantify the qualities of LMA to some extent. However, there are still a few"
        },
        {
          "2\nMuhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": "challenges\nincluding capturing temporal dynamics of movement, and clear ex-"
        },
        {
          "2\nMuhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": "planation of feature descriptors. Many current feature descriptors for movement"
        },
        {
          "2\nMuhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": "analysis may not\nfully capture\nthe dynamic\ncharacteristics without\ntemporal"
        },
        {
          "2\nMuhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": "dynamics. To address\nthese\nchallenges, we propose\nrobust\nfeature descriptors"
        },
        {
          "2\nMuhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": "with temporal dynamics to capture the dynamic nuances of LMA qualities with"
        },
        {
          "2\nMuhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": "their explanation on model predictions and individual performance. The main"
        },
        {
          "2\nMuhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": "contributions of this study are as follows:"
        },
        {
          "2\nMuhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": "– We improve existing feature descriptors by adding temporal dynamics to ac-"
        },
        {
          "2\nMuhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": "curately capture movement trends and behaviors within short time windows."
        },
        {
          "2\nMuhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": "– We propose new feature descriptors for the four LMA components that cap-"
        },
        {
          "2\nMuhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": "ture rich representations of movements."
        },
        {
          "2\nMuhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": "– We perform a comprehensive evaluation on a contemporary dance dataset"
        },
        {
          "2\nMuhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": "using Machine Learning (ML) methods, and analyze the interpretability of"
        },
        {
          "2\nMuhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": "our descriptors with eXplainable AI methods."
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n3": "descriptors are defined using three components of LMA,\nincluding body, space,"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n3": "and shape. The results were obtained on various datasets using Dynamic Time"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n3": "Warping (DTW) to measure similarity in actions. Several studies have focused"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n3": "on the classification of dance emotions using LMA-based feature descriptors. A"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n3": "method is proposed to extract\nthe motion qualities\nfrom dance performances"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n3": "for\nindexing and analysis\nin [4]. LMA-based features were used to investigate"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n3": "the correlation of\nfeatures with dancers expressed emotional state. The results"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n3": "show low inter-feature correlation between dancers and their emotional\nstate."
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n3": "[3]\ninvestigated similarities of various emotional states using extracted LMA ex-"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n3": "tracted features. The results show that the features can partially extract LMA"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n3": "components that can be used for the dance classification from emotion."
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n3": "For automatic feature extraction and better results, Deep learning (DL) has"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n3": "been used.\n[27] applied a hybrid deep learning method based on Convolutional"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n3": "Neural Networks (CNN) and Long Short-Term Memory (LSTM) to effectively"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n3": "identify emotions. For body structure, spatial orientation, and force effect LMA-"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n3": "based feature descriptors were used to add emotional changes during movement."
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n3": "Their approach successfully recognizes emotions in dance movements with high"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n3": "accuracy."
        }
      ],
      "page": 3
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Angry emotions tend to have \nSVM\nRandom Forest": "Recall\nAccuracy\nPrecision"
        },
        {
          "Angry emotions tend to have \nSVM\nRandom Forest": "strong movements."
        },
        {
          "Angry emotions tend to have \nSVM\nRandom Forest": "Fig. 1: Overview of the proposed method for Emotion Recognition in Contem-"
        },
        {
          "Angry emotions tend to have \nSVM\nRandom Forest": "porary Dance Performances."
        },
        {
          "Angry emotions tend to have \nSVM\nRandom Forest": "in such cases outperforming existing SOTA methods. 3) Dancers back-and-forth"
        },
        {
          "Angry emotions tend to have \nSVM\nRandom Forest": "movement\nintroduces\nchallenges\nin feature\nextraction due\nto shifting camera"
        },
        {
          "Angry emotions tend to have \nSVM\nRandom Forest": "perspectives. NLF effectively addresses shifting camera perspective by providing"
        },
        {
          "Angry emotions tend to have \nSVM\nRandom Forest": "the 3D keypoints in absolute camera-space."
        },
        {
          "Angry emotions tend to have \nSVM\nRandom Forest": "3.3\nLMA Feature Extraction"
        },
        {
          "Angry emotions tend to have \nSVM\nRandom Forest": "Laban Movement Analysis is a language and a structured framework to describe,"
        },
        {
          "Angry emotions tend to have \nSVM\nRandom Forest": "and interpret human body movements.\nIt categorizes human motion into four"
        },
        {
          "Angry emotions tend to have \nSVM\nRandom Forest": "main components: BODY, EFFORT, SHAPE and SPACE. Body component"
        },
        {
          "Angry emotions tend to have \nSVM\nRandom Forest": "describes\nthe structural and physical characteristics of human body and is\nre-"
        },
        {
          "Angry emotions tend to have \nSVM\nRandom Forest": "sponsible for\njoints connectivity, movement and their\ninfluence on each other."
        },
        {
          "Angry emotions tend to have \nSVM\nRandom Forest": "For joint connectivity, we calculate the Euclidean distance and angles between"
        },
        {
          "Angry emotions tend to have \nSVM\nRandom Forest": "the hands, shoulders, pelvis, knees, and ankles. For movement, we propose a new"
        },
        {
          "Angry emotions tend to have \nSVM\nRandom Forest": "feature descriptor\nto describe the joint\nthat\ninitiates movement\nin a sequence,"
        },
        {
          "Angry emotions tend to have \nSVM\nRandom Forest": "as shown in Equation 1."
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "it\nis useful\nfor motion expressivity and emotion description. We mainly focus"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "on upper and lower body parts, such as hands,\nfeet, head, and pelvis, as these"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "joints are involved most in emotion expression. The Effort component has four"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "factors: Space, Weight, Time, and Flow. Effort Space describes the attention of"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "movement in space, and it can be direct where the movement is focused on single"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "direction, and indirect where the movement\nis focused in multi-directions. For"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "this we calculate the distance of each joint for a short time-window to the total"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "distance covered by that joint using Equation 2."
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "(cid:80)T"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "i=1 ∥Pj(ti) − Pj(ti − w)∥"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "(2)\nSpacej(T ) ="
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "∥Pj(T ) − Pj(t1)∥"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "Total\nspace\nis\nof\nselected joints J\ncalculated by multiplying the weights αj"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "to their\nspace\nfactor using Equation 3. Joint weights are used to give more"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "importance to extremities, as defined in [13]."
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "(cid:88) j\nSpace(T ) =\n(3)\nαj Spacej(T )"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "∈J"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "Effort Weight describes how powerful or\nstrong a movement\nis,\nit\ncan be"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "strong or light. For this we calculate the kinetic energy of selected joints J using"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "Equation 4. Here vj(ti) denotes the velocity of a joint j at time ti."
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "(cid:88) j\n(cid:88) j\n1 2\n(4)\nW eight(t) =\nαjvj(ti)2\nEj(ti) ="
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "∈J\n∈J"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "Effort Time captures a sense of urgency.\nIt\ntells how quick or\nsustained a"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "movement\nis executed. For\nthis we calculate the acceleration of selected joints"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "over a sliding time-window as shown in Equation 5."
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "(cid:88) j\nTime(T ) =\n(5)\nαj Timej(T )"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "∈J"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "(cid:80)T"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "denotes\nthe acceleration of a joint\nwhere Timej(T ) = 1"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "i=1 aj(ti), and aj\nT"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "j. All\nthese\nfeatures are\ninspired from [18]. Space component describes\nthe"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "relationship of movement with space. For this we calculate trajectory of whole"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "sequence, curvature, and propose a new feature spatial dispersion that describes"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "how dancer is using kinesphere or it’s personal space. It is calculated as distance"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "of upper body parts to torso, pelvis for lower body parts. total path covered, and"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "total distance covered. Shape component describes how the body is changing"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "shape during the movement. For this we calculate the volume of the body using"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "ConvexHull algorithm implemented in Python SciPy package [26]."
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "Once we quantify all LMA components, we obtain a descriptor vector com-"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n5": "posed of 54 features which is used as input to the classification models."
        }
      ],
      "page": 5
    },
    {
      "caption": "Table 1: shows the results of individual emotional states, It can be",
      "data": [
        {
          "6": "for emotion classification in [1][27][3]. Firstly, we use 3 fold cross-validation to di-",
          "Muhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": ""
        },
        {
          "6": "vide the dataset into 3 sets including training, testing, and validation to overcome",
          "Muhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": ""
        },
        {
          "6": "overfitting and data dependency. For both SVM and RF the best hyperparame-",
          "Muhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": ""
        },
        {
          "6": "ter values were found using GridSearch [8], and the best parameter values were",
          "Muhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": ""
        },
        {
          "6": "selected based on the validation accuracy.",
          "Muhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": ""
        },
        {
          "6": "3.5",
          "Muhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": "Model Explainability Using SHAP"
        },
        {
          "6": "Machine learning models are often considered black-box systems, which means",
          "Muhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": ""
        },
        {
          "6": "that",
          "Muhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": "the process by which they arrive at\nspecific predictions\nremains unclear."
        },
        {
          "6": "It",
          "Muhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": "is challenging to determine the factors\nthat\ninfluence their\nresults.\nIn order"
        },
        {
          "6": "to improve our understanding for emotion classification in contemporary dance",
          "Muhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": ""
        },
        {
          "6": "performances, we use SHapley additive",
          "Muhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": "explanations\n(SHAP)\n[21], which is a"
        },
        {
          "6": "game theory-based method to explain the predictions of ML models by assigning",
          "Muhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": ""
        },
        {
          "6": "importance values to each feature for a given prediction. It tells the contribution",
          "Muhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": ""
        },
        {
          "6": "of each feature to a specific prediction. For SVM we applied KernelExplainer,",
          "Muhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": ""
        },
        {
          "6": "and for Random Forest we applied TreeExplainer [20].",
          "Muhammad Turab, Philippe Colantoni, Damien Muselet, and Alain Trémeau": ""
        }
      ],
      "page": 6
    },
    {
      "caption": "Table 1: Classification results of RF and SVM for each emotion using sliding",
      "data": [
        {
          "Table 1: Classification results of RF and SVM for each emotion using sliding": "window of 25 consecutive frames."
        },
        {
          "Table 1: Classification results of RF and SVM for each emotion using sliding": ""
        },
        {
          "Table 1: Classification results of RF and SVM for each emotion using sliding": "Emotion"
        },
        {
          "Table 1: Classification results of RF and SVM for each emotion using sliding": ""
        },
        {
          "Table 1: Classification results of RF and SVM for each emotion using sliding": "Afraid"
        },
        {
          "Table 1: Classification results of RF and SVM for each emotion using sliding": "Angry"
        },
        {
          "Table 1: Classification results of RF and SVM for each emotion using sliding": "Annoyed"
        },
        {
          "Table 1: Classification results of RF and SVM for each emotion using sliding": "Bored"
        },
        {
          "Table 1: Classification results of RF and SVM for each emotion using sliding": "Excited"
        },
        {
          "Table 1: Classification results of RF and SVM for each emotion using sliding": "Happy"
        },
        {
          "Table 1: Classification results of RF and SVM for each emotion using sliding": "Miserable"
        },
        {
          "Table 1: Classification results of RF and SVM for each emotion using sliding": "Pleased"
        },
        {
          "Table 1: Classification results of RF and SVM for each emotion using sliding": "Relaxed"
        },
        {
          "Table 1: Classification results of RF and SVM for each emotion using sliding": "Sad"
        },
        {
          "Table 1: Classification results of RF and SVM for each emotion using sliding": "Satisfied"
        },
        {
          "Table 1: Classification results of RF and SVM for each emotion using sliding": "Tired"
        },
        {
          "Table 1: Classification results of RF and SVM for each emotion using sliding": "Average"
        }
      ],
      "page": 7
    },
    {
      "caption": "Table 1: Classification results of RF and SVM for each emotion using sliding",
      "data": [
        {
          "Table 2: Comparison of emotion classification with state-of-the-art ML methods": "on Dance Motion Dataset [5] using sliding window of 25."
        },
        {
          "Table 2: Comparison of emotion classification with state-of-the-art ML methods": "Study"
        },
        {
          "Table 2: Comparison of emotion classification with state-of-the-art ML methods": "[27]"
        },
        {
          "Table 2: Comparison of emotion classification with state-of-the-art ML methods": "[27]"
        },
        {
          "Table 2: Comparison of emotion classification with state-of-the-art ML methods": "[3]"
        },
        {
          "Table 2: Comparison of emotion classification with state-of-the-art ML methods": "[3]"
        },
        {
          "Table 2: Comparison of emotion classification with state-of-the-art ML methods": "[7]"
        },
        {
          "Table 2: Comparison of emotion classification with state-of-the-art ML methods": "Ours"
        },
        {
          "Table 2: Comparison of emotion classification with state-of-the-art ML methods": "Ours"
        }
      ],
      "page": 7
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Fig. 3: Impact of sliding window size on accuracy.": "Currently, our method achieves promising results for emotion classification in"
        },
        {
          "Fig. 3: Impact of sliding window size on accuracy.": "contemporary dance. However, there remains a challenge regarding interpretabil-"
        },
        {
          "Fig. 3: Impact of sliding window size on accuracy.": "ity and explainability of the models, which has not been explored in existing re-"
        },
        {
          "Fig. 3: Impact of sliding window size on accuracy.": "search on emotion classification. We aim to investigate questions such as which"
        },
        {
          "Fig. 3: Impact of sliding window size on accuracy.": "features\nsignificantly affect\nthe ability of models\nto classify angry movements"
        },
        {
          "Fig. 3: Impact of sliding window size on accuracy.": "from those that are happy or excited, as they look very similar visually. To an-"
        },
        {
          "Fig. 3: Impact of sliding window size on accuracy.": "swer such questions, we apply various method that explain the contributions of"
        },
        {
          "Fig. 3: Impact of sliding window size on accuracy.": "features individually or as a whole. The SHAP summary plot in Fig. 4 shows most"
        },
        {
          "Fig. 3: Impact of sliding window size on accuracy.": "influential\nfeatures\nin predicting emotions\nfrom movement data. Body volume"
        },
        {
          "Fig. 3: Impact of sliding window size on accuracy.": "has\nthe highest\nimpact,\nindicating that overall body expansion or contraction"
        },
        {
          "Fig. 3: Impact of sliding window size on accuracy.": "plays a key role in emotional expression. LMA Effort time has high impact as"
        },
        {
          "Fig. 3: Impact of sliding window size on accuracy.": "well which is essential to distinguish angry movements from sad. Overall, both"
        },
        {
          "Fig. 3: Impact of sliding window size on accuracy.": "global body features and localized joint behavior impact model’s predictions."
        }
      ],
      "page": 8
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n9": "Impact of key movement\nfeatures on emotion predictions are illustrated in"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n9": "Fig. 5 and Fig. 6. The horizontal axis represents the SHAP value, where posi-"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n9": "tive values push the prediction towards a target class and negative values push"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n9": "it away.\nIn both plots,\nfeatures\nsuch as Body volume, Effort Time, and Pelvis"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n9": "Jerkiness\nshow strong positive\ninfluence,\nindicating that\nemotions associated"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n9": "with expansive\nor\nintense movements\n(e.g.,\nanger\nor\nexcitement)\nare driven"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n9": "by higher body expansion, energetic motion, and movement irregularities. Con-"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n9": "versely,\nlower values in these features\ntend to align with sustained movements"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n9": "(e.g.,\nsadness or\ntiredness),\nreflecting more contracted posture,\nreduced move-"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n9": "ment dispersion, and lower kinetic energy."
        }
      ],
      "page": 9
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "References": "1. Ajili,"
        },
        {
          "References": ""
        },
        {
          "References": "Applications 78, 16575–16600 (2019)"
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": "Cultural Heritage (JOCCH) 8(4), 1–19 (2015)"
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": "e1996 (2021)"
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": "9. Brave, S., Nass, C.: Emotion in human-computer"
        },
        {
          "References": ""
        },
        {
          "References": "10. Breiman, L.: Random forests. Machine learning 45, 5–32 (2001)"
        }
      ],
      "page": 10
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": ""
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": "bon, E., Sobieranski, A.C.: A survey on facial emotion recognition techniques: A"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": "state-of-the-art literature review. Information Sciences 582, 593–617 (2022)"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": ""
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": "person 2d pose estimation using part affinity fields. IEEE transactions on pattern"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": "analysis and machine intelligence 43(1), 172–186 (2019)"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": ""
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": "//github.com/open-mmlab/mmpose (2020)"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": ""
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": "(1995)"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": ""
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": "sis: A review. Electronic Notes in Theoretical Computer Science 343, 35–55 (2019)"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": ""
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": "emotion recognition using deep learning\ntechniques: A review.\nIEEE access 7,"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": "117327–117345 (2019)"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": "von Laban, R.: The mastery of movement on the stage. MacDonald & Evans (1950)"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": ""
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": "motion.\nIn: Proceedings of\nthe 2nd International Workshop on Movement and"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": "Computing. pp. 21–28 (2015)"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": ""
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": "F., Chang, C.L., Yong, M.G., Lee, J., et al.: Mediapipe: A framework for building"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": "perception pipelines. arXiv preprint arXiv:1906.08172 (2019)"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": ""
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": "R., Himmelfarb, J., Bansal, N., Lee, S.I.: From local explanations to global under-"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": "standing with explainable ai for trees. Nature Machine Intelligence 2(1), 2522–5839"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": "(2020)"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": ""
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": "In: Guyon, I., Luxburg, U.V., Bengio, S., Wallach, H., Fergus, R., Vishwanathan,"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": "S., Garnett, R.\n(eds.) Advances\nin Neural\nInformation Processing Systems 30,"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": "pp. 4765–4774. Curran Associates,\nInc.\n(2017), http://papers.nips.cc/paper/"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": "7062-a-unified-approach-to-interpreting-model-predictions.pdf"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": ""
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": "ban movement analysis and dynamic time warping. Procedia Computer Science"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": "176, 390–399 (2020)"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": "I., Pons-Moll, G.: Neural\nlocalizer fields\nfor continuous 3d human pose"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": "and shape estimation. arXiv preprint arXiv:2407.07532 (2024)"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": ""
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": "dance. PeerJ Computer Science 9, e1441 (2023)"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": ""
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": "based on machine\nlearning models. J. COMBIN. MATH. COMBIN. COMPUT"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": "718 (2025)\n124(699),"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": ""
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": "peau, D., Burovski, E., Peterson, P., Weckesser, W., Bright, J., et al.: Scipy 1.0:"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": "fundamental algorithms for scientific computing in python. Nature methods 17(3),"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": "261–272 (2020)"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": ""
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": "on laban motion analysis using convolutional neural network and long short-term"
        },
        {
          "Emotion Recognition in Contemporary Dance Performances using LMA\n11": "memory. IEEE Access 8, 124928–124938 (2020)"
        }
      ],
      "page": 11
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Expressive motions recognition and analysis with learning and statistical methods",
      "authors": [
        "I Ajili",
        "Z Ramezanpanah",
        "M Mallem",
        "J Didier"
      ],
      "year": "2019",
      "venue": "Multimedia Tools and Applications"
    },
    {
      "citation_id": "2",
      "title": "A survey of state-of-the-art approaches for emotion recognition in text",
      "authors": [
        "N Alswaidan",
        "M Menai"
      ],
      "year": "2020",
      "venue": "Knowledge and Information Systems"
    },
    {
      "citation_id": "3",
      "title": "Emotion analysis and classification: understanding the performers' emotions using the lma entities",
      "authors": [
        "A Aristidou",
        "P Charalambous",
        "Y Chrysanthou"
      ],
      "year": "2015",
      "venue": "Computer Graphics Forum"
    },
    {
      "citation_id": "4",
      "title": "Feature extraction for human motion indexing of acted dance performances",
      "authors": [
        "A Aristidou",
        "Y Chrysanthou"
      ],
      "year": "2014",
      "venue": "2014 International Conference on Computer Graphics Theory and Applications (GRAPP)"
    },
    {
      "citation_id": "5",
      "title": "Digital dance ethnography: Organizing large dance collections",
      "authors": [
        "A Aristidou",
        "A Shamir",
        "Y Chrysanthou"
      ],
      "year": "2019",
      "venue": "J. Comput. Cult. Herit",
      "doi": "10.1145/3344383"
    },
    {
      "citation_id": "6",
      "title": "Folk dance evaluation using laban movement analysis",
      "authors": [
        "A Aristidou",
        "E Stavrakis",
        "P Charalambous",
        "Y Chrysanthou",
        "S Himona"
      ],
      "year": "2015",
      "venue": "Journal on Computing and Cultural Heritage (JOCCH)"
    },
    {
      "citation_id": "7",
      "title": "Emodescriptor: A hybrid feature for emotional classification in dance movements",
      "authors": [
        "J Bai",
        "R Dai",
        "J Dai",
        "J Pan"
      ],
      "year": "1996",
      "venue": "Computer Animation and Virtual Worlds"
    },
    {
      "citation_id": "8",
      "title": "Random search for hyper-parameter optimization",
      "authors": [
        "J Bergstra",
        "Y Bengio"
      ],
      "year": "2012",
      "venue": "The journal of machine learning research"
    },
    {
      "citation_id": "9",
      "title": "Emotion in human-computer interaction",
      "authors": [
        "S Brave",
        "C Nass"
      ],
      "year": "2007",
      "venue": "The humancomputer interaction handbook"
    },
    {
      "citation_id": "10",
      "title": "Random forests",
      "authors": [
        "L Breiman"
      ],
      "year": "2001",
      "venue": "Machine learning"
    },
    {
      "citation_id": "11",
      "title": "A survey on facial emotion recognition techniques: A state-of-the-art literature review",
      "authors": [
        "F Canal",
        "T Müller",
        "J Matias",
        "G Scotton",
        "A De Sa Junior",
        "E Pozzebon",
        "A Sobieranski"
      ],
      "year": "2022",
      "venue": "Information Sciences"
    },
    {
      "citation_id": "12",
      "title": "Openpose: Realtime multiperson 2d pose estimation using part affinity fields",
      "authors": [
        "Z Cao",
        "G Hidalgo",
        "T Simon",
        "S Wei",
        "Y Sheikh"
      ],
      "year": "2019",
      "venue": "IEEE transactions on pattern analysis and machine intelligence"
    },
    {
      "citation_id": "13",
      "title": "Openmmlab pose estimation toolbox and benchmark",
      "authors": [
        "M Contributors"
      ],
      "year": "2020",
      "venue": "Openmmlab pose estimation toolbox and benchmark"
    },
    {
      "citation_id": "14",
      "title": "Support-vector networks",
      "authors": [
        "C Cortes",
        "V Vapnik"
      ],
      "year": "1995",
      "venue": "Machine learning"
    },
    {
      "citation_id": "15",
      "title": "Emotion recognition from physiological signal analysis: A review",
      "authors": [
        "M Egger",
        "M Ley",
        "S Hanke"
      ],
      "year": "2019",
      "venue": "Electronic Notes in Theoretical Computer Science"
    },
    {
      "citation_id": "16",
      "title": "Speech emotion recognition using deep learning techniques: A review",
      "authors": [
        "R Khalil",
        "E Jones",
        "M Babar",
        "T Jan",
        "M Zafar",
        "T Alhussain"
      ],
      "year": "2019",
      "venue": "IEEE access"
    },
    {
      "citation_id": "17",
      "title": "The mastery of movement on the stage",
      "authors": [
        "R Von Laban"
      ],
      "year": "1950",
      "venue": "The mastery of movement on the stage"
    },
    {
      "citation_id": "18",
      "title": "A review of computable expressive descriptors of human motion",
      "authors": [
        "C Larboulette",
        "S Gibet"
      ],
      "year": "2015",
      "venue": "Proceedings of the 2nd International Workshop on Movement and Computing"
    },
    {
      "citation_id": "19",
      "title": "Mediapipe: A framework for building perception pipelines",
      "authors": [
        "C Lugaresi",
        "J Tang",
        "H Nash",
        "C Mcclanahan",
        "E Uboweja",
        "M Hays",
        "F Zhang",
        "C Chang",
        "M Yong",
        "J Lee"
      ],
      "year": "2019",
      "venue": "Mediapipe: A framework for building perception pipelines",
      "arxiv": "arXiv:1906.08172"
    },
    {
      "citation_id": "20",
      "title": "From local explanations to global understanding with explainable ai for trees",
      "authors": [
        "S Lundberg",
        "G Erion",
        "H Chen",
        "A Degrave",
        "J Prutkin",
        "B Nair",
        "R Katz",
        "J Himmelfarb",
        "N Bansal",
        "S Lee"
      ],
      "year": "2020",
      "venue": "Nature Machine Intelligence"
    },
    {
      "citation_id": "21",
      "title": "A unified approach to interpreting model predictions",
      "authors": [
        "S Lundberg",
        "S Lee",
        "I Guyon",
        "U Luxburg",
        "S Bengio",
        "H Wallach",
        "R Fergus",
        "S Vishwanathan"
      ],
      "year": "2017",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "22",
      "title": "Human action recognition using laban movement analysis and dynamic time warping",
      "authors": [
        "Z Ramezanpanah",
        "M Mallem",
        "F Davesne"
      ],
      "year": "2020",
      "venue": "Procedia Computer Science"
    },
    {
      "citation_id": "23",
      "title": "Neural localizer fields for continuous 3d human pose and shape estimation",
      "authors": [
        "I Sárándi",
        "G Pons-Moll"
      ],
      "year": "2024",
      "venue": "Neural localizer fields for continuous 3d human pose and shape estimation",
      "arxiv": "arXiv:2407.07532"
    },
    {
      "citation_id": "24",
      "title": "A deep learning-based approach for emotional analysis of sports dance",
      "authors": [
        "Q Sun",
        "X Wu"
      ],
      "year": "2023",
      "venue": "PeerJ Computer Science"
    },
    {
      "citation_id": "25",
      "title": "Research on the mechanism of emotion expression in dance based on machine learning models",
      "authors": [
        "G Tan",
        "J Wang"
      ],
      "year": "2025",
      "venue": "J. COMBIN. MATH. COMBIN. COMPUT"
    },
    {
      "citation_id": "26",
      "title": "Scipy 1.0: fundamental algorithms for scientific computing in python",
      "authors": [
        "P Virtanen",
        "R Gommers",
        "T Oliphant",
        "M Haberland",
        "T Reddy",
        "D Cournapeau",
        "E Burovski",
        "P Peterson",
        "W Weckesser",
        "J Bright"
      ],
      "year": "2020",
      "venue": "Nature methods"
    },
    {
      "citation_id": "27",
      "title": "Dance emotion recognition based on laban motion analysis using convolutional neural network and long short-term memory",
      "authors": [
        "S Wang",
        "J Li",
        "T Cao",
        "H Wang",
        "P Tu",
        "Y Li"
      ],
      "year": "2020",
      "venue": "IEEE Access"
    }
  ]
}