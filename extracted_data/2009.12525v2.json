{
  "paper_id": "2009.12525v2",
  "title": "This Work Has Been Submitted To The Ieee For Possible Publication. Copyright May Be Transferred Without Notice, After Which This Version May No Longer Be Accessible",
  "published": "2020-09-26T07:22:07Z",
  "authors": [
    "Xiaolong Zhong",
    "Zhong Yin"
  ],
  "keywords": [
    "Cross-subject",
    "deep learning",
    "emotional recognition",
    "human-machine interaction",
    "physiological signals"
  ],
  "sections": [
    {
      "section_name": "I. Introduction",
      "text": "motion recognition (ER) plays a significant role in affective human-machine interactions. The purpose of ER is to retrieve the affective status of human beings at a particular point in time given a relevant data recording from an individual. There is a high possibility for applications in medical-care systems, such as active and assisted living module  [1] , driver-assistance systems  [2] , early detection of depression  [3] , and autistic spectral disorders  [4] . Feasible clues for an ER task include body gestures  [5] , facial expressions  [6] , speech  [7] , eye blinking  [8] , and neurophysiological signals  [9] -  [10] . Among them, neurophysiological signals have a capability to reflect the inner cognitive states of individuals and make impartial ER systems possible  [11] .\n\nIn our study, we concentrated on leveraging the ongoing electroencephalography (EEG) to build a functional ER system. Previous studies on cognitive psychology demonstrated the association between affective information of the human emotional state and the electrical activity of the cerebral cortex. The EEG can be a direct consequence of specific affective stimuli  [12] . Nevertheless, extracting emotional indicators from the EEG is difficult because of the individual differences, non-stationarity, and the artifacts induced by eye movement and respiration. A promising solution for the identification of salient information in the EEG associated with human affective responses is to build reliable feature representations and pattern classification models with ML tools.\n\nIn particular, there is a statistical significance in the way individuals sense and express their feelings  [13] . People may express distinct feelings and cortical responses when exposed to an identical effective stimulus  [14] . Therefore, the pattern classifier of interpreting EEG may not yield the right choice with regard to the context of various users of an ER system  [15] . Accordingly, many studies tend to focus on the design of specific ER systems. However, this classification model requires a large part of the gathered EEG samples from a specific person, and the recorded EEG could not be utilized for unseen individuals.\n\nAccordingly, studies into cross-individual ER systems based on machine learning models have been investigated. This signifies that a classifier can transfer knowledge pertaining to EEG data distribution among multiple ER users  [16] .\n\nIn such circumstances, the ER model is trained and tested by different individuals. It significantly reduces the time cost for recording EEG signals from the same person given that the size of the available training data is enlarged when multiple users are involved. However, the current cross-individual approach to EEG classification tends to perform poorly compared with the individual-specific approach because of the severe individual differences of EEG data E distributions  [17]  To model the mapping between EEG data and emotional states more accurately based on a cross-individual paradigm, we adopted deep-learning (DL) methods  [18] . There have been numerous successful utilizations of DL to the broad-scale image, voice, and video data. In contrast to many static images, EEG signals are multichannel, nonlinear time series, and the quantity of instances in numerous public databases is limited, thus making this modality less sufficient for training broad-scale networks that contain millions of parameters. Therefore, current convolutional neural network (CNN) models based on the DL principle have to leverage data augmentation and model regularization techniques. In this study, the CNN is applied as a basis to develop the cross-individual ER system. The CNN-based emotion classifier is trained based on end-to-end learning of the abstract features from the deep-scale original data.\n\nTo improve the characterization of the dynamical properties in the EEG features across multiple users of the ER system, we introduce a dynamic entropy-based pattern learning (DEPL) framework to smooth out short-term fluctuations and highlight long-term trends or cycles of feature representations. The DEPL first introduces differential entropy (DE) to characterize EEG signals  [19] . The spatial information that is coded in the electrode placement in the cerebral cortex is extracted by transferring DE features to interpretable two-dimensional (2-D) maps. In particular, the squeeze-excitation (SE) block  [20]  is employed to enhance the capability of deep representations of DE features by modeling the interdependencies between the channels of its informative features. Finally, the CNN classifiers are trained separately based on the classical EEG frequency bands of theta, alpha, beta, and gamma, to predict the final affective states. The public datasets DEAP  [21]  and MAHNOB-HCI  [22]  are adopted to validate the effectiveness of the proposed method.\n\nIn summary, our main contributions are three folds:\n\n(1) The DEPL deep learning system is first introduced to the EEG based affective computing for cross individual emotion recognition.\n\n(2) A method of salient region extraction based on attention mechanism is designed in the DEPL. The inter-channel dependencies have been evaluated along with the high-level feature representation.\n\n(3) The validation of the DEPL and various deep learning models shows connections between different structures of CNNs and the corresponding generalization capability.\n\nThis study is organized as follows. In section II, we introduce related work in the field of EEG-based affective computing. Section III describes the data preprocessing steps of the DEAP and MAHNOB-HCI databases. The details of the proposed DEPL framework are presented in Section IV. The experiments for performance evaluation and comparison of the ER system are given in section V. The discussions of the results and the conclusion of the study are presented in sections VI and VII, respectively.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Ii. Related Works",
      "text": "Most EEG-based-affect classification models label and represent various facets of emotions, and subsequently apply the two-dimensional bipolar affective model based on valence and arousal  [23] . Atkinson and Campos  [24]  used the minimum-redundancy maximum-relevance (mRMR) method for feature selection, and the support vector machine (SVM) for the binary classification of low/high valence and arousal for individual-dependent emotion recognition based on data from the DEAP database. Yoon and Chung  [25]  presented a classification method based on the Pearson correlation coefficient and Bayesian models that achieved accuracies of 70.9% for valence and 70.1% for arousal. In  [26] , the level feature fusion (LFF) algorithm was employed to extract emotional EEG features, and the SVM with a Gaussian kernel was used as the classifier. The model obtained an accuracy of 68.8% for valence and 63.6% for arousal for binary classification, and 59.57% for valence and 57.44% for arousal for three-class classification of the MAHNOB database.\n\nIn  [27] , a DL model was used based on the long-short term memory framework to classify low/high valence and arousal based on the EEG raw data from the DEAP database, with accuracies of 85.45% and 85.65%. In  [28] , a three-dimensional (3-D) CNN-based scheme was applied to classify emotional states, and achieved a mean accuracy of 87.44% for valence and 88.49% for arousal on the DEAP dataset. The training samples were summed by an augmentation process following the superposition of noise on the original EEG sequences.\n\nMost of the existing work on individual, independent ER tasks tends to perform poorly compared with the individual-specific approaches. Li et al.  [29]  adopted the SVM classifier based on the automatic feature selection methods and the \"leave-one-subject-out\" verification strategy to evaluate the ER performance on the DEAP database based on which the highest mean recognition accuracy of 59.06% was achieved for binary classification. In  [30]",
      "page_start": 5,
      "page_end": 6
    },
    {
      "section_name": "Iii. Datasets And Eeg Features",
      "text": "",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "A. Dataset Description And Data Acquisition",
      "text": "The DEAP is an open-source database recording of multimodal physiological signals with emotional evaluations generated by 32 volunteers with selected video clips. Specifically, this database includes 32-channel EEG and peripheral physiological signals. Each participant was asked to watch 40 trials of music videos (one-minute per video) with different emotional stimuli. The EEG signals of these volunteers were recorded simultaneously. The volunteers then rated the videos on a scale of 1 to 9 in terms of arousal, valence, liking, dominance, and familiarity.\n\nIn this study, we only focused on 2-D emotional models where the arousal (ranging from weak to strong) and valence dimensions (ranging from negative to positive) were adopted to generate target-affective states. The 40 stimulus videos included 20 low-arousal/valence clips and 20 high-arousal/valence clips. Only the EEG data in the DEAP were used for deep-network modelling that had been downsampled to 128 Hz. The frequency component (in the range of 4-45 Hz) was preserved by band-pass filtering and ocular artifacts were removed by blind source separation algorithms. The duration of the denoised EEG in each trial was 63 s. Of these, 60 s were experimental data (recorded while watching the video), and 3 s were pre-trial baseline data (before watching), which contained a total number of samples of (60 + 3) √ó 128 = 8064 for each channel. Similarly, the MAHNOB-HCI database contains EEG, video, audio, gaze, and peripheral physiological recordings from 30 participants. Each participant watched 20 clips extracted from Hollywood movies and video websites. The stimulus videos ranged in duration from 35 s to 117 s. Their perceived arousal and valence levels were also labelled on a discrete scale from 1 to 9. Given that the EEG data were incomplete in the cases of six participants, only the data from 24 participants were available. The sampling frequency of the EEG was also 128 Hz, and the average potential was used as a reference value to measure the EEG potential difference. High-pass filters were employed to perform artifact removal. Specifically, for each trial of the EEG, a 60 s segment from the first 5 s to the 65 s time-point were used in the following analysis. We then divided these EEG recordings to high-class (ratings 6-9) and a low-class (ratings 1-5)\n\nrecordings. Table  I  shows a summary of the DEAP and MAHNOB-HCI datasets.\n\n...",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "B. Computation Of Differential Entropy",
      "text": "Applying complexity measures with entropy-based pattern learning has been certified as one of the leading technical means for EEG-based emotion recognition  [31] . Entropy measures can be exploited to quantify the nonlinearity, uncertainty, and non-stationarity of neurophysiological signals  [32] -  [33] . Additionally, there is plenty of persuasive evidence that illustrates that the entropy measures have a strong ability to extract regularity information from EEG signals indicating clinical significances  [34] . In this study, the DE is presented to characterize the affective clues in an EEG recording, and is defined as follows,\n\nIn (  1 ), S is the support set of the random variable, X is a continuous random variable of the observed value x , and () fX is the probability density function of X . The value x is drawn from a normal distribution with a zero mean, i.e.\n\nÔÄ® ÔÄ©\n\nBefore applying (2), each EEG segment is decomposed with Butterworth filters in four classical bands, i.e., theta, alpha, beta, and gamma, as shown in Fig.  1 . The theta (4-7 Hz) component is active in light-sleep patterns  [35] , while the alpha (8-13 Hz) is activated in a relaxed state by closing the eyes  [36] . The beta (14-30 Hz) band constitutes the \"active thinking and reasoning wave\" band  [37] , and the Gamma band (31-45 Hz) is related to bursts of perceptive and advanced information processing  [38] . Consequently, in a fixed frequency band i , the differential entropy",
      "page_start": 7,
      "page_end": 8
    },
    {
      "section_name": "C. Data Processing And Feature Extraction",
      "text": "The data pre-processing and feature extraction processes can be summarized according to the procedure EEG_PRE in Table  II . According to Yang et al.  [39] , the DE indicators of the EEG in baseline conditions can improve the inter-emotion discriminant capability of the feature space. Hence, the differences between the EEG at various experimental conditions and the baseline recording are computed. For each participant, all the 32 channels were [40], a window with a size of 1 s can be suitable so that the 7680 point data of each channel was divided into 60 epochs.\n\nThe total number of EEG epochs of each participant was equal to 40 √ó 60 = 2400 with the dimensionality of 128 (samples) √ó 32 (channels) √ó 4 (bands). Subsequently, the corresponding DE feature vector of each epoch",
      "page_start": 8,
      "page_end": 9
    },
    {
      "section_name": "Iv. Dynamical Entropy-Based Pattern Learning",
      "text": "The ER framework designed based on the DEPL method is shown in Fig.  2 . The leave-one-subject-out paradigm has been used to validate the binary classification performance. The DEPL consists of four modules, i.e. dynamical feature smoothing, 2-D feature mapping, the deep network for feature abstraction, and channel feature re-calibration. Owing to the lack of a baseline signal in the MAHNOB dataset, (  6 ) is only applied on the DEAP dataset. Table  II  summarizes the procedure of the dynamical feature smoothing.",
      "page_start": 9,
      "page_end": 11
    },
    {
      "section_name": "C. Deep Network For Feature Abstraction",
      "text": "To preserve the local spatial structure of the EEG features, the deep CNN can be applied on the 2-D-like frame in a functionality of image recognition. In this study, our CNN model is developed based on the LeNet-5  [41] , which was the primary models for all types of CNN applications in the domain of computer vision, as shown in Fig.  4(a) .\n\nGiven an input EEG feature map indicated by x , an abstracted feature at the th i row and th j column in a convolutional layer indicated by ij y can be calculated by applying the spatial convolution operation, ( ) ( ( ) ( ) ).\n\nIn (  7  In all the types of activation functions, the rectified linear unit (ReLU)  [42]  was used, and was the most successful.\n\nConversely, according to the conclusion inferred by Ramachandran et al.  [43] , the Swish activation can help improve the convergence speed of the training. Thence, we used the Swish activation function instead of the ReLU. The Swish function is a smooth, non-monotonic function defined as ( ) (1/ (1 ))\n\nÔÄ´ .",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "D. Channel Feature Recalibration",
      "text": "To strengthen the abstraction capability of a CNN, prior research had indicated the profits of heightening the spatial encoding  [44] . Recent studies have revealed that the deep feature representations can be boosted by introducing learning mechanisms into the network that support catch-spatial correlations between features. Therefore, we employ the squeeze-excitation (SE) block to allow the network to perform channel feature recalibration (see Fig.  4(b) ).\n\nAt any given transformation :\n\n, e.g. a convolution, we would be able to produce a relevant SE block to perform the feature re-calibration. First, the features U are performed as a squeeze action that generate a channel descriptor based on the fusion of the feature maps spanning in HW ÔÇ¥ . This descriptor intends to generate an embedding of the global spatial information of channel-wise feature responses so that the functional signal from the global receptive field can be used by its lower layer. The information aggregated in the squeeze operation is followed by an excitation action. It is in the form of a simple self-gating mechanism that embeds as an input, and generates a set of modulation weights for each channel. Applying these weights to the feature map U produces the output of the SE block that can be fed immediately to the subsequent network layers.\n\nIn a SE block, the convolutional operator ( , ) conv ÔÉóÔÉó can be defined as, ' 1  ( , )  .\n\nIn the equation, * represents the operation of convolution, and\n\n.\n\nThe excitation operation is then performed with a sigmoid activation and the final output of the block is obtained by rescaling U with the activations s , ÔÄ® ÔÄ© ÔÄ® ÔÄ©",
      "page_start": 12,
      "page_end": 13
    },
    {
      "section_name": "( , )",
      "text": ".\n\n( , ) .\n\nIn the above equations, g and f denote the ReLU and sigmoid functions with weights of",
      "page_start": 14,
      "page_end": 14
    },
    {
      "section_name": "E. Training And Implementation",
      "text": "Given that the final goal of the ER task is to identify a decision function ( ) :\n\nwhere refers to a cross-entropy cost calculated by, 1 log .\n\nq n ii jj ij yy n ÔÄΩÔÄΩ ÔÄΩÔÄ≠ ÔÉ•ÔÉ•  (13)  In this way, our training target can be set to make the predicted probability distribution ( ) ( )",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "ÀÜ= ( )",
      "text": "ii sm y g o as close to the ground truth label i y as possible. The operator ()  In the DEPL framework, the first convolutional layer filters the 9 √ó 9, 2-D input array that corresponded to each frequency band based on the use of 100 kernels with three rows and three columns. The next layer is a max-pooling layer with a pooling size of 2 √ó 2 and a stride of 2 pixels. Another convolutional layer was then added with 100 filters, and a 3√ó3 kernel was used as the input. Followed by this layer was another max-pooling layer with the same hyper-parameters. At the end of the network, three fully connected layers with 120, 120, and 2 neurons are added for supervised emotion recognition on the binary arousal and valence levels.\n\nOwing to the fact that the limited number of samples may lead to overfitting, we introduce an L2 regularization term into the error signal of every convolution layer and employed the dropout mechanism at all the fully connected layers.\n\nIn addition, the batch normalization (BN) was implemented with the SE block between the convolutional layer and the max-pooling layer. The model training process is detailed in Table  III .",
      "page_start": 14,
      "page_end": 14
    },
    {
      "section_name": "V. Experiments And Results",
      "text": "",
      "page_start": 14,
      "page_end": 14
    },
    {
      "section_name": "A. Experimental Setup",
      "text": "The leave-one-subject-out paradigm with z-scored features has been used in the following sections to facilitate cross-individual EEG classification in which a single participant obtained from the entire EEG database was used as the test participant, while the remaining data were used in the training process. This cross-validation process was repeated until each participant was used as a test participant.\n\nWe implemented the DEPL with the Keras framework libraries in Python and trained it on a Tesla T4 graphics processing unit (GPU) based on Google's cloud platform. The truncated normal distribution function was used to initialize the weight of the kernels, and the Adam optimizer was adopted to minimize the cross-entropy loss function.\n\nThe initial learning rate was 1.0e-05. The key probability of the dropout operation was 0.6. The penalty strength of the L2 regularization was 0.6. We used 100 epochs and trained our model with batches, which contained 32 experiments each. Finally, we fine-tuned the network to obtain the final classification model. The classic method used to compare with our method was implemented with scikit-learn, and was trained with a laptop computer that had a Windows 10¬Æ operation system, an Intel¬Æi5 central processing unit (CPU) at 1.60 GHz, and 4 G configurations.",
      "page_start": 15,
      "page_end": 15
    },
    {
      "section_name": "B. Comparison Of Different Cnn Structures",
      "text": "Before implementing the DEPL, the optimal frequency band had been examined in Fig.  5(a) . For the DEAP database, the highest and the lowest accuracies were achieved by the gamma and theta band features, respectively. For the MAHNOB database, the highest and the lowest accuracies were achieved by the gamma and alpha band features, respectively. The arousal and valence dimensions of the same database possessed similar performance patterns.\n\nIn Fig.  6 (b), we utilized paired ùë°-tests to explore whether the improvements between various bands were significant or not. It is shown that the average accuracies of participants between each two bands were significantly different for the DEAP database. The observation indicates that using gamma features significantly improved the DEPL performance compared with theta, alpha, or beta features (p < 0.001). Similar observations were found in the case of the MAHNOB database with p < 0.05. Therefore, we implemented the DEPL model with the use of gamma features.\n\nWe also compared the current network structure of the DEPL with three popular deep CNN architectures, i.e., the CNN models with ReLU function without feature smoothing (denoted as CNN-1), the CNN model with ReLU function, feature smoothing (denoted as CNN-2), and the CNN model with the ReLU function, SE blocks, and feature smoothing (denoted as CNN-3). The comparison of the accuracy and the p values showed that the current network structure possessed the highest participant average performance.",
      "page_start": 16,
      "page_end": 16
    },
    {
      "section_name": "C. Comparison With Shallow Learning Machines",
      "text": "Several state-of-the-art machine-learning classifiers were considered as baseline classifiers. These included SVM, logistic regression (LR), extreme gradient boosting (XGBoost), gradient boosting decision tree (GBDT), K-nearest neighbors (KNN), decision tree (DT), random forest (RF) and naive Bayes (NB) models. All hyper-parameters of the shallow learning machines have been optimized in detail, and the optimal value is shown in Table  IV . Note that the DEPL model applied the optimal structure as shown in the previous section. Table V lists the ùêπ1-scores and classification accuracies of all shallow learning machines, and the DEPL with the gamma frequency band features. We observed that our method yielded the highest accuracy: 66.23% for valence, 68.50% for arousal (DEAP), and 70.25% for valence and 73.27% for arousal (MAHNOB). At the same time, our method yielded the highest F1-score. We also notice that the ensemble algorithm and the SVM could improve the classification performance against other classical methods. In Fig.  7 , the paired ùë°-test was adopted to compare whether the performance improvement was significant or not. It can be observed that the DEPL significantly outperformed all the classical shallow learning machines with p < 0.001.",
      "page_start": 17,
      "page_end": 17
    },
    {
      "section_name": "D. Comparison With Modern Deep-Learning Models",
      "text": "To validate the performance of the DEPL on ER tasks, we introduced several modern deep-learning approaches for comparison, e.g. AlexNet  [45]  and InceptNet  [46] . Moreover, to explore whether the feature fusion from all four frequency bands can improve the ER performance or not, a multi-input model has been designed and denoted as  The average participant accuracies of all five models are listed in Fig.  8 . Specifically, the deep ANN penalty strength of the L2 regularization was set to 0.001. The AlexNet, InceptNet, and FreqNet also introduced the SE blocks and the Swish activation function. From the figure, we can observe that the DEPL obtained the highest accuracy. In particular, the classification performance was degraded when more than two convolution-pooling blocks were involved. This indicates that deeper CNN models may not be suitable for EEG feature decoding because of the over-fitting problem.\n\nConversely, the back-propagation-based deep artificial neural network (ANN) achieved the lowest performance.\n\nOwing to the fact that the FreqNet model may be too complicated, and the interferences between different frequency bands, the accuracy was also unsatisfactory.",
      "page_start": 18,
      "page_end": 18
    },
    {
      "section_name": "E. Comparison Of Computational Complexity",
      "text": "The computational complexity of the DEPL is compared with several classical learning machines in Table VII with asymptotic notations. It is observed that the running time of the DEPL is drastically higher than those of classical shallow classifiers. The reason behind this is that ensemble learning machines, e.g. RF, adopt divide and conquer principles to design classifier trees. The height of the tree is log( ) n and significantly reduces the increased order of the running time. Conversely, the main time cost of the DEPL is attributed to the procedure of training weights of hierarchical convolution and full connection feature representations. However, compared with several modern DL models, the DEPL has the least number of trainable parameters and achieves the best recognition performance. This part indicates the suitability of the DEPL to tackle the ER tasks with cross-individual training and testing paradigms.",
      "page_start": 20,
      "page_end": 20
    },
    {
      "section_name": "Vi. Discussion",
      "text": "The competitive performance of the proposed DEPL framework for tackling ER tasks in cross-individual paradigms is mainly attributed to three aspects.\n\n(1) The DEPL is able to eliminate short-term fluctuations and highlight long-term trends in EEG data with the use of dynamical feature smoothing. This allows DEPL to track the temporal dynamics of the affective status over time.  (2)  The benefits of the DL allow it to be capable to abstract structural data built by locating all EEG channels in a matrix.\n\nDeep networks are superior to shallow learning machines because they introduce the layer-wise convolution operations for feature-synthesis, and because they minimize possible inter-individual inconsistencies associated with high-dimensional feature maps. (3) Moreover, the SE-block in conjunction with the Swish activation function efficiently models the interdependencies between the channels, and helps the DEPL converge faster. The observation that the gamma frequency band is superior to the performance gained by the theta, alpha, and beta bands, indicates the significance of high-frequency cortical activities in affective computing. The potential reason is attributed to the fact that the gamma waves are heavily involved in the human reasoning and thinking procedures. For the parameter settings of the DEPL, the initial weights learned from different participants are unable to help the DEPL to converge faster owing to the low-migration ability of the current CNN structure. In fact, this implies that the types of the EEG responses are considerable among different individuals involved in the same ER task.\n\nIn Table  VIII , the performance of the DEPL is compared with recently reported publication findings. In general, the values of the accuracy obtained from the individual-dependent ER systems (exceeded 90%) are far better than those from the cross-individual models (approximately 60%). We found that the DEPL could facilitate much more emotionally relevant feature patterns to achieve better performance, particularly for both the DEAP and MAHNOB databases, compared with the existing methods. However, it should be carefully noted that the size of the training set, data pre-processing steps, and definitions of the emotional classes could be different, even when subjected to the same training and testing paradigms. These factors could significantly affect the final ER accuracy listed in the table.\n\nThrough the comparative analysis presented above, the DEPL may contribute to the improved tracking of the temporal dynamics of the affective status from the EEG signals with respect to time to enable cross-individual emotional recognition. The limitations of the current study mainly refer to two points.  (1)  We only extracted the DE features from raw EEG signals, and did not explore the other entropy measures, such as ApEn  [54] , fuzzy entropy  [55] , and multiscale entropy  [56] . Different entropy measures may capture informative features from EEG signals in specific emotional states.  (2)  The DEPL was trained on four frequency bands independently to investigate the performance differences and locate the best bands. However, the proper fusion of the four models may result in a higher generalization capacity. It can also be noted that the cross-individual ER task is still difficult because the accuracy is far from the perfect even for binary affective states.",
      "page_start": 20,
      "page_end": 22
    },
    {
      "section_name": "Vii. Conclusions",
      "text": "In this study, the cross-individual ER system, DEPL, was proposed. The system achieved an outstanding performance with EEG mappings. In the DEPL framework, we exploited dynamic entropy in quantitative EEG",
      "page_start": 22,
      "page_end": 22
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: An illustration of mapping electroencephalographic (EEG) signals over time to differential entropy (DE) feature vectors.",
      "page": 7
    },
    {
      "caption": "Figure 1: The theta (4‚Äì7 Hz) component is active in light-sleep patterns [35], while",
      "page": 8
    },
    {
      "caption": "Figure 2: The leave-one-subject-out paradigm has",
      "page": 9
    },
    {
      "caption": "Figure 2: Dynamic entropy-based pattern learning to enable cross-individual emotion recognition based on EEG signals.",
      "page": 10
    },
    {
      "caption": "Figure 3: Construction of the two-dimensional (2-D) plane.",
      "page": 11
    },
    {
      "caption": "Figure 3: C. Deep Network for Feature Abstraction",
      "page": 11
    },
    {
      "caption": "Figure 4: Basic architecture of (a) the LeNet-5 and (b) the squeeze-excitation building block.",
      "page": 12
    },
    {
      "caption": "Figure 5: Box plots of the average participant classification accuracies of two databases. Subfigure (a) represents the classification accuracies of theta, alpha, beta,",
      "page": 15
    },
    {
      "caption": "Figure 6: Heat-map plots of the p-values of paired ùë°-test between (a) the four EEG bands of the different DEPL rhythms and (b) the four different deep models.",
      "page": 16
    },
    {
      "caption": "Figure 5: (a). For the DEAP database,",
      "page": 16
    },
    {
      "caption": "Figure 6: (b), we utilized paired ùë°-tests to explore whether the improvements between various bands were significant",
      "page": 16
    },
    {
      "caption": "Figure 7: , the paired ùë°-test was adopted to compare whether",
      "page": 17
    },
    {
      "caption": "Figure 7: Heat-map plots of the p-values of utilized paired ùë°-test between shallow learning machines and the DEPL model.",
      "page": 18
    },
    {
      "caption": "Figure 8: Specifically, the deep ANN penalty strength",
      "page": 18
    },
    {
      "caption": "Figure 8: Error-bar plots of the classification accuracy comparison between deep learning approaches for binary classification into low/high valence and arousal on the",
      "page": 19
    }
  ],
  "tables": [],
  "citations": [
    {
      "citation_id": "1",
      "title": "Intelligent sensing systems for measuring wellness indices of the daily activities for the elderly",
      "authors": [
        "N Suryadevara",
        "M Quazi",
        "S Mukhopadhyay"
      ],
      "year": "2012",
      "venue": "2012 Eighth Int. Conf. Intell. Environ"
    },
    {
      "citation_id": "2",
      "title": "A novel real-time emotion detection system from audio streams based on bayesian quadratic discriminate classifier for adas",
      "authors": [
        "F Al Machot",
        "A Mosa",
        "K Dabbour",
        "A Fasih",
        "C Schwarzlm√ºller",
        "M Ali",
        "K Kyamakya"
      ],
      "year": "2011",
      "venue": "Proc. Joint INDS'11 & ISTET'11"
    },
    {
      "citation_id": "3",
      "title": "Psychologist in a pocket: towards depression screening on mobile phones",
      "authors": [
        "J Bitsch",
        "R Ramos",
        "T Ix",
        "P Ferrer-Cheng",
        "K Wehrle"
      ],
      "year": "2015",
      "venue": "pHealth"
    },
    {
      "citation_id": "4",
      "title": "Processing of emotion words by patients with autism spectrum disorders: Evidence from reaction times and EEG",
      "authors": [
        "A Lartseva",
        "T Dijkstra",
        "C Kan",
        "J Buitelaar"
      ],
      "year": "2014",
      "venue": "J. Autism Dev. Disord"
    },
    {
      "citation_id": "5",
      "title": "Automatic measurement of affect in dimensional and continuous spaces: Why, what, and how?",
      "authors": [
        "H Gunes",
        "M Pantic"
      ],
      "year": "2010",
      "venue": "Proc. 7th Int. Conf. Methods Techn"
    },
    {
      "citation_id": "6",
      "title": "A review on automatic facial expression recognition systems assisted by multimodal sensor data",
      "authors": [
        "N Samadiani",
        "G Huang",
        "B Cai",
        "W Luo",
        "C Chi",
        "Y Xiang",
        "J He"
      ],
      "year": "2019",
      "venue": "Sensors"
    },
    {
      "citation_id": "7",
      "title": "3D CNN-based speech emotion recognition using K-means clustering and spectrograms",
      "authors": [
        "N Hajarolasvadi",
        "H Demirel"
      ],
      "year": "2019",
      "venue": "Entropy"
    },
    {
      "citation_id": "8",
      "title": "Multimodal emotion recognition in response to videos",
      "authors": [
        "M Soleymani",
        "M Pantic",
        "T Pun"
      ],
      "year": "2011",
      "venue": "IEEE Trans. Affective Comput"
    },
    {
      "citation_id": "9",
      "title": "Recognition of emotions using multimodal physiological signals and an ensemble deep learning model",
      "authors": [
        "Z Yin",
        "M Zhao",
        "Y Wang",
        "J Yang",
        "J Zhang"
      ],
      "year": "2017",
      "venue": "Comput. Methods Progr. Biomed"
    },
    {
      "citation_id": "10",
      "title": "MoSa: A modeling and sentiment analysis system for mobile application big data",
      "authors": [
        "Y Zhang",
        "W Ren",
        "T Zhu",
        "E Faith"
      ],
      "year": "2019",
      "venue": "Symmetry"
    },
    {
      "citation_id": "11",
      "title": "EEG-based automatic emotion recognition: Feature extraction, selection and classification methods",
      "authors": [
        "P Ackermann",
        "C Kohlschein",
        "J Bitsch",
        "K Wehrle",
        "S Jeschke"
      ],
      "year": "2016",
      "venue": "IEEE 18th Int. Conf. E-health Netw., Appl. Serv. (Healthcom)"
    },
    {
      "citation_id": "12",
      "title": "A review on the computational methods for emotional state estimation from the human EEG",
      "authors": [
        "M Kim",
        "M Kim",
        "E Oh",
        "S Kim"
      ],
      "year": "2013",
      "venue": "Comput. Math. Methods Med"
    },
    {
      "citation_id": "13",
      "title": "Revealing feelings: facets of emotional expressivity in self-reports, peer ratings, and behavior",
      "authors": [
        "J Gross",
        "O John"
      ],
      "year": "1997",
      "venue": "J. Personal. Soc. Psychol"
    },
    {
      "citation_id": "14",
      "title": "Toward machine emotional intelligence: Analysis of affective physiological state",
      "authors": [
        "R Picard",
        "E Vyzas",
        "J Healey"
      ],
      "year": "2001",
      "venue": "IEEE Trans. Pattern Anal. Mach. Intell"
    },
    {
      "citation_id": "15",
      "title": "Subject-independent emotion recognition based on physiological signals: a three-stage decision method",
      "authors": [
        "J Chen",
        "B Hu",
        "Y Wang",
        "P Moore",
        "Y Dai",
        "L Feng",
        "Z Ding"
      ],
      "year": "2017",
      "venue": "BMC Med. Inform. Decis. Mak"
    },
    {
      "citation_id": "16",
      "title": "Emotional state classification from EEG data using machine learning approach",
      "authors": [
        "X Wang",
        "D Nie",
        "B Lu"
      ],
      "year": "2014",
      "venue": "Neurocomputing"
    },
    {
      "citation_id": "17",
      "title": "Filtering of spontaneous and low intensity emotions in educational contexts",
      "authors": [
        "S Salmeron-Majadas",
        "M Arevalillo-Herr√° Ez",
        "O Santos",
        "M Saneiro",
        "R Cabestrero",
        "P Quir√≥s",
        "J Boticario"
      ],
      "year": "2015",
      "venue": "Int. Conf. Artif. Intell. Education"
    },
    {
      "citation_id": "18",
      "title": "Deep learning with convolutional neural networks for EEG decoding and visualization",
      "authors": [
        "R Schirrmeister",
        "J Springenberg",
        "L Fiederer",
        "M Glasstetter",
        "K Eggensperger",
        "M Tangermann",
        "T Ball"
      ],
      "year": "2017",
      "venue": "Hum. Brain Mapp"
    },
    {
      "citation_id": "19",
      "title": "Differential entropy feature for EEG-based vigilance estimation",
      "authors": [
        "L Shi",
        "Y Jiao",
        "B Lu"
      ],
      "year": "2013",
      "venue": "35th Ann. Int. Conf. IEEE Eng. Med. Biol. Soc. (EMBC)"
    },
    {
      "citation_id": "20",
      "title": "Squeeze-and-excitation networks",
      "authors": [
        "J Hu",
        "L Shen",
        "G Sun"
      ],
      "year": "2018",
      "venue": "Proceedings of the IEEE Conf. Comput. Vis. Pattern Recognition"
    },
    {
      "citation_id": "21",
      "title": "Deap: A database for emotion analysis; using physiological signals",
      "authors": [
        "S Koelstra",
        "C Muhl",
        "M Soleymani",
        "J Lee",
        "A Yazdani",
        "T Ebrahimi",
        "I Patras"
      ],
      "year": "2011",
      "venue": "IEEE Trans. Affective Comput"
    },
    {
      "citation_id": "22",
      "title": "A multimodal database for affect recognition and implicit tagging",
      "authors": [
        "M Soleymani",
        "J Lichtenauer",
        "T Pun"
      ],
      "year": "2011",
      "venue": "IEEE Trans. Affective Comput"
    },
    {
      "citation_id": "23",
      "title": "Affective space is bipolar",
      "authors": [
        "J Russell"
      ],
      "year": "1979",
      "venue": "J. Personal. Soc. Psychol"
    },
    {
      "citation_id": "24",
      "title": "Improving BCI-based emotion recognition by combining EEG feature selection and kernel classifiers",
      "authors": [
        "J Atkinson",
        "D Campos"
      ],
      "year": "2016",
      "venue": "Expert Syst. Appl"
    },
    {
      "citation_id": "25",
      "title": "EEG-based emotion estimation using Bayesian weighted-log-posterior function and perceptron convergence algorithm",
      "authors": [
        "H Yoon",
        "S Chung"
      ],
      "year": "2013",
      "venue": "Comput. Biol. Med"
    },
    {
      "citation_id": "26",
      "title": "Emotion classification in arousal valence model using MAHNOB-HCI database",
      "authors": [
        "M Wiem",
        "Z Lachiri"
      ],
      "year": "2017",
      "venue": "Int. J. Adv. Comput. Sci. Appl"
    },
    {
      "citation_id": "27",
      "title": "Emotion recognition based on EEG using LSTM recurrent neural network",
      "authors": [
        "S Alhagry",
        "A Fahmy",
        "R El-Khoribi"
      ],
      "year": "2017",
      "venue": "Emotion"
    },
    {
      "citation_id": "28",
      "title": "EEG-based emotion recognition using 3D convolutional neural networks",
      "authors": [
        "E Salama",
        "R El-Khoribi",
        "M Shoman",
        "M Shalaby"
      ],
      "year": "2018",
      "venue": "Int. J. Adv. Comput. Sci. Appl"
    },
    {
      "citation_id": "29",
      "title": "Exploring EEG features in cross-subject emotion recognition",
      "authors": [
        "X Li",
        "D Song",
        "P Zhang",
        "Y Zhang",
        "Y Hou",
        "B Hu"
      ],
      "year": "2018",
      "venue": "Front. Neurosci"
    },
    {
      "citation_id": "30",
      "title": "Subject independent emotion recognition from EEG using VMD and deep learning",
      "authors": [
        "P Pandey",
        "K Seeja"
      ],
      "year": "2019",
      "venue": "J. King Saud Univ. Comput. Inform. Sci"
    },
    {
      "citation_id": "31",
      "title": "EEG-based emotion recognition using frequency domain features and support vector machines",
      "authors": [
        "X Wang",
        "D Nie",
        "B Lu"
      ],
      "year": "2011",
      "venue": "Int. Conf. Neural Inform. Proc"
    },
    {
      "citation_id": "32",
      "title": "Nonlinear characterization and complexity analysis of cardiotocographic examinations using entropy measures",
      "authors": [
        "J Marques",
        "P Cortez",
        "J Madeiro",
        "V De Albuquerque",
        "S Fong",
        "F Schlindwein"
      ],
      "year": "2020",
      "venue": "J. Supercomput"
    },
    {
      "citation_id": "33",
      "title": "Analysis of absence seizure generation using EEG spatial-temporal regularity measures",
      "authors": [
        "N Mammone",
        "D Labate",
        "A Lay-Ekuakille",
        "F Morabito"
      ],
      "year": "2012",
      "venue": "Int. J. Neural Syst"
    },
    {
      "citation_id": "34",
      "title": "Entropy index in quantitative EEG measurement for diagnosis accuracy",
      "authors": [
        "A Lay-Ekuakille",
        "P Vergallo",
        "G Griffo",
        "F Conversano",
        "S Casciaro",
        "S Urooj",
        "A Trabacca"
      ],
      "year": "2013",
      "venue": "IEEE Trans. Instrum. Meas"
    },
    {
      "citation_id": "35",
      "title": "Theta oscillations in the hippocampus",
      "authors": [
        "G Buzs√° Ki"
      ],
      "year": "2002",
      "venue": "Neuron"
    },
    {
      "citation_id": "36",
      "title": "Extraversion-introversion and 8-13 Hz waves in frontal cortical regions",
      "authors": [
        "Y Tran",
        "A Craig",
        "P Mcisaac"
      ],
      "year": "2001",
      "venue": "Personal. Individ. Differences"
    },
    {
      "citation_id": "37",
      "title": "Devices and methods for maintaining an alert state of consciousness through brain wave monitoring",
      "year": "2000",
      "venue": "U.S. Patent"
    },
    {
      "citation_id": "38",
      "title": "Gamma-band responses in the brain: a short review of psychophysiological correlates and functional significance",
      "authors": [
        "C Ba≈üar-Eroglu",
        "D Str√ºber",
        "M Sch√ºrmann",
        "M Stadler",
        "E Ba≈üar"
      ],
      "year": "1996",
      "venue": "Int. J. Psychophysiol"
    },
    {
      "citation_id": "39",
      "title": "Continuous convolutional neural network with 3D input for EEG-based emotion recognition",
      "authors": [
        "Y Yang",
        "Q Wu",
        "F Fu",
        "X Chen"
      ],
      "year": "2018",
      "venue": "Int. Conf. Neural Inform. Proc"
    },
    {
      "citation_id": "40",
      "title": "Emotional state classification from EEG data using machine learning approach",
      "authors": [
        "X Wang",
        "D Nie",
        "B Lu"
      ],
      "year": "2014",
      "venue": "Neurocomputing"
    },
    {
      "citation_id": "41",
      "title": "Gradient-based learning applied to document recognition",
      "authors": [
        "Y Lecun",
        "L Bottou",
        "Y Bengio",
        "P Haffner"
      ],
      "year": "1998",
      "venue": "Proc. IEEE"
    },
    {
      "citation_id": "42",
      "title": "Rectified linear units improve restricted boltzmann machines",
      "authors": [
        "V Nair",
        "G Hinton"
      ],
      "year": "2010",
      "venue": "Proc. 27th Int. Conf. Mach. Learn. (ICML-10)"
    },
    {
      "citation_id": "43",
      "title": "Swish: a self-gated activation function",
      "authors": [
        "P Ramachandran",
        "B Zoph",
        "Q Le"
      ],
      "year": "2017",
      "venue": "Swish: a self-gated activation function",
      "arxiv": "arXiv:1710.05941"
    },
    {
      "citation_id": "44",
      "title": "Deep Learning for EEG motor imagery classification based on multi-layer CNNs feature fusion",
      "authors": [
        "S Amin",
        "M Alsulaiman",
        "G Muhammad",
        "M Mekhtiche",
        "M Hossain"
      ],
      "year": "2019",
      "venue": "Fut. Gener. Computer Syst"
    },
    {
      "citation_id": "45",
      "title": "Imagenet classification with deep convolutional neural networks",
      "authors": [
        "A Krizhevsky",
        "I Sutskever",
        "G Hinton"
      ],
      "year": "2012",
      "venue": "Adv. Neural Inform. Proc. Syst"
    },
    {
      "citation_id": "46",
      "title": "Going deeper with convolutions",
      "authors": [
        "C Szegedy",
        "W Liu",
        "Y Jia",
        "S Reed",
        "D Anguelov",
        "A Rabinovich"
      ],
      "year": "2015",
      "venue": "Proc. IEEE Conf. Comput. Vis. Pattern Recognit"
    },
    {
      "citation_id": "47",
      "title": "Continuous convolutional neural network with 3D input for EEG-based emotion recognition",
      "authors": [
        "Y Yang",
        "Q Wu",
        "X Fu",
        "Chen"
      ],
      "year": "2018",
      "venue": "Int. Conf. Neural Inform. Proc"
    },
    {
      "citation_id": "48",
      "title": "Emotion recognition from multi-channel EEG through parallel convolutional recurrent neural network",
      "authors": [
        "Y Yang",
        "Q Wu",
        "M Qiu",
        "Y Wang",
        "X Chen"
      ],
      "year": "2018",
      "venue": "Int. Jt. Conf. Neural Netw. (IJCNN)"
    },
    {
      "citation_id": "49",
      "title": "Multi-method fusion of cross-subject emotion recognition based on high-dimensional EEG features",
      "authors": [
        "F Yang",
        "X Zhao",
        "W Jiang",
        "P Gao",
        "G Liu"
      ],
      "year": "2019",
      "venue": "Front. Comput. Neurosci"
    },
    {
      "citation_id": "50",
      "title": "Cross-corpus EEG-based emotion recognition",
      "authors": [
        "S Rayatdoost",
        "M Soleymani"
      ],
      "year": "2018",
      "venue": "IEEE 28th Int. Workshop Mach. Learn. Signal Process. (MLSP)"
    },
    {
      "citation_id": "51",
      "title": "Emotion recognition from EEG signals using hierarchical Bayesian network with privileged information",
      "authors": [
        "Z Gao",
        "S Wang"
      ],
      "year": "2015",
      "venue": "Proceedings of the 5th ACM Int. Conf. Multimedia Retr"
    },
    {
      "citation_id": "52",
      "title": "SVM-based feature selection methods for emotion recognition from multimodal data",
      "authors": [
        "C Torres-Valencia",
        "M √Ålvarez-L√≥pez",
        "A Orozco-Guti√© Rrez"
      ],
      "year": "2017",
      "venue": "J. Multimodal User Interf"
    },
    {
      "citation_id": "53",
      "title": "EEG-based emotion recognition utilizing wavelet coefficients",
      "authors": [
        "A Momennezhad"
      ],
      "year": "2018",
      "venue": "Multimedia Tools Appl"
    },
    {
      "citation_id": "54",
      "title": "Approximate entropy as a measure of system complexity",
      "authors": [
        "S Pincus"
      ],
      "year": "1991",
      "venue": "Proc. Natl. Academy Sci"
    },
    {
      "citation_id": "55",
      "title": "Deep convolutional neural network for the automated detection and diagnosis of seizure using EEG signals",
      "authors": [
        "U Acharya",
        "S Oh",
        "Y Hagiwara",
        "J Tan",
        "H Adeli"
      ],
      "year": "2018",
      "venue": "Comput. Biol. Med"
    },
    {
      "citation_id": "56",
      "title": "Multiscale entropy analysis of biological signals",
      "authors": [
        "M Costa",
        "A Goldberger",
        "C Peng"
      ],
      "year": "2005",
      "venue": "Phys. Rev. E"
    }
  ]
}