{
  "paper_id": "2310.04450v1",
  "title": "Investigating Large Language Models' Perception Of Emotion Using Appraisal Theory",
  "published": "2023-10-03T16:34:47Z",
  "authors": [
    "Nutchanon Yongsatianchot",
    "Parisa Ghanad Torshizi",
    "Stacy Marsella"
  ],
  "keywords": [
    "Large language model",
    "Appraisal theory",
    "coping"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Large Language Models (LLM) like ChatGPT have significantly advanced in recent years and are now being used by the general public. As more people interact with these systems, improving our understanding of these black box models is crucial, especially regarding their understanding of human psychological aspects. In this work, we investigate their emotion perception through the lens of appraisal and coping theory using the Stress and Coping Process Questionaire (SCPQ). SCPQ is a validated clinical instrument consisting of multiple stories that evolve over time and differ in key appraisal variables such as controllability and changeability. We applied SCPQ to three recent LLMs from OpenAI, davinci-003, ChatGPT, and GPT-4 and compared the results with predictions from the appraisal theory and human data. The results show that LLMs' responses are similar to humans in terms of dynamics of appraisal and coping, but their responses did not differ along key appraisal dimensions as predicted by the theory and data. The magnitude of their responses is also quite different from humans in several variables. We also found that GPTs can be quite sensitive to instruction and how questions are asked. This work adds to the growing literature evaluating the psychological aspects of LLMs and helps enrich our understanding of the current models.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "I. Introduction",
      "text": "Large language models (LLM) have made significant progress in recent years. With the introduction of ChatGPT by OpenAI, the general public, not just researchers, has widely used and interacted with these LLMs. These models can write stories, songs, poems, and code. People have also used them to answer various questions, including basic facts about the world, medical questions, and social and emotional events. As these AI systems interact with people more and more, it is essential to investigate and improve our understanding of how they perceive and understand humans' social and psychological aspects. Existing research has begun to study various cognitive and psychological abilities of LLMs, including decision-making, information search, causal reasoning, and theory of mind  [1] -  [3] .\n\nContinuing this line of research, in this work, we aim to further investigate LLMs' ability to perceive and evaluate emotions and related factors. Emotion has multiple dimensions, including the expression of emotion, the relation to cognition, physiological experience, subjective experience, and the impact on coping responses. There are also multiple theories of emotion  [4] -  [9] . We choose to investigate emotion perception through the lens of appraisal and coping theory. Specifically, we compare LLMs perception of emotional and stressful scenarios to the characterizations of these scenarios by appraisal theory and related human data. From another angle, we investigate whether or not LLMs are sensitive to appraisal dimensions of scenarios and whether this would lead to responses with different coping tendencies. We choose appraisal theory because it provides a representation of emotional scenarios in terms of appraisal variables, allowing us to investigate emotion perception at a deeper level beyond simple emotion categories. In addition, some appraisal theories, such as Lazarus's theory  [4] , provide a link from appraisal variables to coping behaviors, allowing us to further examine LLMs' responses at the behavior level.\n\nTo accomplish this, we use a validated clinical instrument, the Stress and Coping Process Questionaire (SCPQ), by Perrez and Reicherts  [10] . SCPQ is built upon Lazarus's appraisal and coping theory. It includes measurements of emotional experience, appraisal variables, and coping intentions and behaviors. It has also been used to evaluate a computational model of emotion before  [11] . In SCPQ, subjects are presented with hypothetical stereotypical stressful scenarios which evolve over time, and their responses are measured across multiple time steps. This allows us to investigate the dynamics of appraisal and coping. Furthermore, SCPQ consists of two specific types of scenarios: aversive and loss or failure. These two types differ significantly along several key appraisal dimensions: controllability, changeability, and ambiguity. This permits us to check the model's sensitivity to appraisal dimensions. In sum, SCPQ provides a useful testbed to investigate the important aspects of appraisal and coping theory within LLMs.\n\nWe subjected SCPQ to three recent LLMs from OpenAI: text-davinci-003, ChatGPT, and GPT-4  [12] ,  [13] . We focus on models from OpenAI because they are the most well-known models and GPT-4 seems to be the current best available model at the time of this writing  [14] . We compared their results with human data and hypotheses from the theory  [10] . In addition, we tested how LLMs would change if we instructed them to act as a person with depression compared to what the theory predicted. Lastly, we also investigated the 979-8-3503-2745-8/23/$31.00 ©2023 IEEE sensitivity of these models on instruction and prompts along several aspects. The results show that LLMs' responses are similar to human trends regarding the dynamics of appraisal and coping. However, they still could not differentiate between the two scenario types well. Their responses are also quite different from humans in terms of magnitude in several key variables, including controllability and coping. ChatGPT and GPT-4, when instructed to act as a depressed person, respond in a way that is consistent with the theory's prediction. Lastly, we found that LLMs can be quite sensitive to instruction and how questions are asked.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Ii. Related Work",
      "text": "As SCPQ is heavily influenced by Lazarus' appraisal and coping theory, we first briefly review Lazarus's theory here. Appraisal theories of emotion define appraisal as an evaluation of what the situation implies for personal well-being based on one's goals and beliefs  [15] ,  [16] ,  [4] ,  [5] . Lazarus's theory emphasizes the importance of the process or dynamics involved in coping  [4] . In particular, the person-environment relationship is always changing, leading to different, evolving emotional experiences, appraisal evaluations, and coping.\n\nLazarus proposes two main dimensions of appraisals: primary and secondary appraisal dimensions. Primary appraisals include goal relevance, goal congruence, and type of egoinvolvement. Secondary appraisals include blameworthiness, coping potential (whether and how a person can manage the demands and consequences of the situation), and future expectancy (the degree to which things are likely to change for the better or worse ). Effectively, secondary appraisals involve how people can cope with the situation. Note that, in SCPQ, with influence from earlier work on helplessness  [17] , Perrez and Reicherts use the term controllability (the subjective appraisal of personal ability to control the situation) instead of coping potential and changeability (the subjective appraisal that the stressful event will change by itself) instead of future expectancy.\n\nLazarus also proposes two broad types of coping: problemfocused coping (directly changing the situation or the environment) and emotion-focused coping (changing one's goals and/or beliefs to adjust to the situation). These copings are also the main focus of SCPQ.\n\nWith the influence of Lazarus's theory, SCPQ focuses on not only appraisal but also the dynamics of appraisal and coping. This makes it stand out among other similar scenario-based instruments  [18] ,  [19] . In addition, SCPQ extends Lazarus's taxonomy further. We go into more detail in the next section. Additionally, SCQP has been used to evaluate a computational model before  [11] . A critical difference is that in the previous work, the scenarios were manually constructed to be in the right format that the model could process, but here we are using LLMs to interpret the scenario directly from the text.\n\nOn the other side, there has been more and more work evaluating the psychological aspects of LLMs. For example, Binz and Schulz (2023) studied GPT-3's decision-making, information search, and causal reasoning using cognitive psychological tests such as heuristic and biases tests and the cognitive reflection tests  [1] . They found that it can solve these tasks similarly or better than human subjects.  Kosinski (2023)  investigated Theory of Mind (ToM) in LLMs using standard false-belief tasks and found that ChatGPT and text-davinci-003 can solve most ToM tasks  [3] .  Miotto et al. (2022)  explored personality, values, and demographic of GPT-3 using validated questionnaires  [20] . They found GPT-3 to be similar to the human baseline sample and is close to a young adult demographic.  Bubeck et al. (2023)  subject GPT-4 to various tests such as mathematics, coding, medicine, law, and psychology  [2] . They show that GPT-4 outperforms ChatGPT on ToM and emotion perception. Nevertheless, they simply tested the models on a few examples and did not systematically evaluate their psychological aspects and related factors.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Iii. Stress And Coping Process Questionaire",
      "text": "The Stress and Coping Process Questionaire (SCPQ) was developed by Perrez and Reicherts to measure a human subject's appraisal and coping variables in stressful and emotional scenarios that occur in their daily life  [10] . SCPQ has been validated by a panel of clinician experts and applied to normal human subjects as well as in clinical settings.\n\nA subject is presented with a series of hypothetical scenarios that are divided into three episodes or phases, corresponding to different stages of the stressful scenario: phase 1 beginning, phase 2 continuation, and phase 3 outcome. Their responses are measured at the end of each phase, reflecting the key assumption of SCPQ that the dynamics of a stressful scenario are crucial to understanding how stress and coping develop.\n\nSCPQ consists of two types of scenarios: aversive and loss or failure (loss). Examples of loss scenarios are the loss of a friendly relationship, the loss of an important object, and the failure of an interesting side job. Examples of aversive scenarios are criticism from the partner, arguments about problems in a relationship, and reproaches from colleagues. The key differences between the two types are the level of controllability, changeability, and ambiguity. By design, the loss scenarios are less controllable, less changeable, and less ambiguous than the aversive scenarios.\n\nBoth types of scenarios follow a similar course of three episodes. The loss or aversive scenario is looming at the beginning (phase 1) and becomes unavoidable, imminent, or reinforced in phase 2. The outcome phase (phase 3) can either be positive or negative. For loss scenarios, the positive outcome involves finding a substitution, while the negative outcome depicts the final loss without any successful substitution. For aversive scenarios, the positive outcome involves successfully removing the source of stress, while the negative outcome depicts the continuation of the stress.\n\nBelow are examples of an aversive scenario and a loss scenario, respectively.\n\nAn aversive scenario with a positive outcome: \" There are nine scenarios for each type, a total of eighteen scenarios. The responses can be aggregated to reflect the general tendency toward these types of scenarios and compared between the two types, which differ along crucial appraisal dimensions.\n\nSCPQ includes the following measurement.\n\n• Emotional Responses: 1) anxious -calm, 2) depressedcheerful, and 3) angry -gentle, • Appraisals: 1) changeability, 2) controllability, and 3) negative valence, • Coping intentions: 1) Problem-focused coping, 2)\n\nEmotion-focused coping 1  , and 3) Self-esteem, • Self-directed coping behaviors: 1) search for information, 2) suppress information, 3) re-evaluation, and 4) palliation (calming self-instruction or smoking, drinking, and eating), • Environment-directed coping behavior: 1) Active (to prevent or confront the stressor) and 2) Passive (waiting, hesitating, resigning). • Blameworthines: 1) Self-blaming and 2) Other-blaming, Below, we summarize the hypotheses that are supported by the human data from the SCPQ study 2  .\n\n• H1.1: Valence should be lower in the positive outcome than in the negative outcome in phase 3. • H1.2: Subjects should perceive higher controllability and changeability in the aversive scenarios than in the loss scenarios.\n\n• H1.3: Controllability and changeability should decrease from phase 1 to phase 2. • H2.1: Subjects should use more active coping in aversive scenarios than in loss scenarios. • H2.2: Subjects should use less passive coping in aversive scenarios than in loss scenarios. • H3.1: Subjects' intention to use problem-focused coping is less in aversive scenarios than in loss scenarios. • H3.2: Subjects' intention to use emotion-focused coping is more in aversive scenarios than loss scenarios. • H4.1: Subjects will blame themselves and others more in aversive scenarios than in loss scenarios. • H4.2: Self-blame will decrease over time, while Otherblame will increase over time. These are the trends that we will investigate in LLMs' results. The main rationale of H2-H4 is that aversive scenarios should be perceived as more controllable and changeable, so subjects are expected to cope differently between the two types of scenarios. The SCPQ study involved 100 non-student adults with an average age of 38 years (sd 11.8).\n\nAdditionally, Perrez and Reicherts provide the following hypotheses regarding depression:\n\n• H5.1: Depressed persons perceive stressful scenarios to be more stressful and higher negative valence.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Iv. Openai'S Gpts",
      "text": "In this work, we choose to investigate three recent LLMs from OpenAI's family of Generative Pre-trained Transformer models, or GPT  [12] ,  [13] . These include text-davinci-003 (D003), gpt-3.5-turbo (Chat-GPT), gpt-4 (GPT-4). The first two are from the GPT3.5 family. These three models have been fine-tuned using Reinforcement Learning with Human Feedback (RLHF)  [21] , and ChatGPT and GPT-4 have been optimized for chat. ChatGPT and GPT-4 also allow the user to set a system message (i.e., describing what kind of an assistant you want it to be). We do not use this feature to allow a comparison with the old model. To maximize the replicability of our results, we set the temperature parameter to 0 in all of our experiments. This makes the outputs mostly deterministic, selecting the outputs with the highest log probability. All other parameters are set to default.\n\nAs these models can be sensitive to instruction  [1] ,  [22] ,  [23] , we investigate four different variations of prompting and asking the models. Here is the default instruction taken from SCPQ with a slight modification: \"Try to clearly imagine the scenario below and then answer the question with the choice only in one line.\" First, we either ask it to output choices (default) or just the number only (\"the choice's number only\"). The number only makes sense here because all measurements use a Likert scale ranging from 0 up to 5. We test this variation because our early testing showed that sometimes the models may output more than just a choice, such as repeating the question, even when the instruction specifies \"choice only.\"\n\nThe second variation is the location of the instruction. There are two versions: either putting the instruction before (default) or after (\"the above scenario\") the scenario. The reason for testing this is that, as these models use attention mechanisms, the distance of the context could impact how the LLM follows the instruction.\n\nThird, we investigate either asking them one question at a time (individual) or multiple questions at a time (batch). The batch follows the set of questions as stated above. The rationale for this is that asking in batches can save time and costs, as you don't need to repeat the scenario every time.\n\nThese first three variations result in eight different combinations of instructions. Lastly, we also test the effect of appending the previous (appraisal) answers to the prompt. The reason is that, as we are interested in the dynamics, knowing their previous answers could be crucial. For this variation, we only use the default instruction as asking for the number only or after the scenario does not make sense in this case.\n\nCode, including all SCPQ scenarios and instructions, data, and all results, including additional results not shown in the paper, can be found at github.com/yongsa-nut/PerrezSAIWS.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "V. Results",
      "text": "Figure  1  shows the estimated mean with the 95% standard error for all the key measurements of the three models and human data. The setup here is the default setup, where the question is asked one by one, and the instruction is placed before the scenario and asks for choices. We choose to report this here as it is the most similar to the human setup. We discuss the results for other setups in the next section.\n\nCrucially, we focus mainly here on the qualitative results comparing the trend of results from the model and humans. The main reason is that there is a discrepancy between human data and model data. The human results are obtained from averaging over 100 subjects and nine scenarios, while the model results are from averaging nine scenarios making their uncertainty incomparable.\n\nFigure  1 .A shows the results for depressed/cheerful emotional reactions. For this result and valence, we only focus on the outcome (positive or negative) in phase 3. We see that all three models show the expected trend where the positive outcome results in more cheerful and less depressed than the negative outcome. Compared to humans, all three models rate the cheerful to be lower in the positive outcome, where D003 is closest to the human rating. The results for the other two emotional reactions are similar.\n\nThe results for valence in Figure  1 .B also shows a similar trend. Like humans, all three models rate the valence to be lower in the positive outcome than in the negative outcome. However, all three models rate valence higher than humans in both negative and positive outcomes.\n\nNext, for changeability in Figure  1 .C, we see that none of the models follow the human trend exactly where there is a difference between the two types of scenarios across two times, and the changeability in both types goes down. D003 always rates changeability to be zero. On the other hand, ChatGPT only rates changeability to go down in phase 2 for loss scenarios, while GPT-4 only rates changeability to go down for aversive scenarios. For controllability (Figure  1 .D), we see that only D003 and GPT-4 show the expected trend of controllability going down over time for both scenario types. However, GPT-4 does not perceive the two types to be different, unlike D003. In all cases, all three models perceive controllability to be lower than what humans perceive.\n\nWe turn now to coping intentions. For problem-focused coping in Figure  1 .E, only ChatGPT shows the trend of lowering it over time for loss scenarios. None of the models show that problem-focused coping at phase 2 in loss scenarios is lower than in aversive scenarios. In addition, all models rate problem-focused coping higher than the human data across time and type. For emotion-focused coping in Figure  1 .F, we see that only D003 shows a similar trend to the human data, where the intention is going down over time in the aversive case. On the other hand, both ChatGPT and GPT-4 rate it maximum across time and type.\n\nNext, we look at coping behaviors. First, for passivity (Figure  1 .G, both ChatGPT and GPT-4 show a trend similar to humans where the passivity increases over time. Second, for active influence (Figure  1 .H), only GPT-4 shows the trend that the active influence would decrease over time but only for the aversive case. On the other hand, only ChatGPT shows a clear difference between the two types.\n\nLastly, we turn to blameworthiness. First, for blaming others (Figure  1 .I), all models show that, in the loss scenarios, blaming others increases from phase 1 to 2. However, only D003 shows an increase in blaming others in the aversive scenarios. None of the models shows that blaming others is higher in the aversive than in the loss scenarios at phase 2, like the human data.\n\nSecond, for self-blaming (Figure ??J), both ChatGPT and GPT-4 show trends similar to the human data, where blaming oneself decreases over time in the aversive type and is higher in the aversive type than in the loss type in phase 1.\n\nOverall, we observe in many cases that LLMs's responses are similar to human's data in the case of the dynamics, but not in the case of scenario types.\n\nNext, we look at the results comparing the model instructed to act as a person with depression (Depression) and the model without the instruction (Normal), focusing only on aversive scenarios (the loss scenarios show similar trends). Figure  2  shows the key six measurements. The pattern is clear that, for ChatGPT and GPT-4 but not D003, there is a difference between the depression and normal case in the expected directions. In particular, controllability, changeability, problem-  focused coping, and palliation are lower in the depression case than in the normal case, while blaming oneself and valence are higher in the depression case than in the normal case. Figure  3  shows the results on controllability for the three models across eight combination instructions across three choices. Overall, we see that there are variations across these instructions. This means that the instruction, where it is, and how many questions are asked could affect the output from the models. The biggest difference comes from asking in a batch instead of asking each question individually. The variation also depends on the model. Similar results can be found in other questions not shown here.\n\nNext, we zoom into selected questions. Figure  4  shows the GPT-4's results for changeability (A) and controllability (B) across all combinations of setup. Due to space limitations, we focus only on these two as the theory argues they strongly influence the coping response, and GPT-4 is the latest model. Again, we see that there are variations in both controllability and changeability across combinations. For changeability (Figure  4 .A), a few combinations show the expected trends aligning with human data, where changeability decreases over time and differs between aversive and loss types. In the case of controllability (Figure  4 .B), it increases rather than decreases over time for the aversive type when asking in a batch. In addition, the value is also higher in the batch setup. On the other hand, when asking the questions individually, controllability decreases over time, aligning with the expected trend. However, only in one of the setups (asking to output only a number and after the scenario), controllability across all phases is higher in the aversive scenarios than in the loss scenarios, as expected by the theory and human data. Nevertheless, the value in this setup is still lower than humans, and its changeability does not align with humans. Overall, there is no single setup here where both changeability and controllability align with the expected trends.\n\nIn addition to these eight setups, we look at the effect of appending their appraisal answers to the prompt. However, we do not observe any significant changes in any variables aside from a few cases for ChatGPT. These include changeability and controllability in phase 2, in the right direction.\n\nBeyond the variation shown in the figure, we found that GPT-4 follows instructions better than the other two models. In particular, when asking in a batch, ChatGPT and D003 may not answer all the questions. Further, when asked to answer with choice, ChatGPT occasionally did not answer just a choice but provided a full sentence reiterating the question instead. These did not happen with GPT-4.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Vi. Discussion",
      "text": "Overall, no model follows all the human trends and hypotheses as predicted by appraisal and coping theory. Nonetheless, the responses from the three models depict the right trends for the dynamics in several variables, including emotional responses, appraisal variables, and coping. In many cases, however, the models could not differentiate the two scenario types well, and the magnitudes are quite different from humans. A few cases stand out. For example, all models rate the negative valence to be more negative than humans. One potential explanation could be from the human side, namely it could be due to experimenter demand effects. Another interesting case concerns the particular aspects of emotionfocused coping that SCPQ considers, specifically to remain calm and composed. Both ChatGPT and GPT-4 always answer the highest value. We speculate that this could be due to finetuning with RLHF.\n\nImportantly, we also observe some differences between humans and LLMs on several key appraisal variables. In particular, GPT-4 rated the controllability and changeability decrease over time but didn't rate the two scenario types differently. We speculate that this could be due to the limited information provided in the scenarios. Human subjects bring with them their own knowledge and experiences of these daily stressful scenarios, which could make them aware of various ways that they could deal with them. However, these are not explicitly in the sceanrios, and LLM may not be able to infer them from just a short snippet. Another explanation and limitation of SCPQ is that these scenarios are hypothetical, and people may behave and appraise them differently if they were real. To fully test the perception of appraisal and emotion, future work is needed to compare LLMs' results with human data from real events.\n\nAnother interesting result is that ChatGPT and GPT-4 can be instructed to act as a depressed person, where their responses show trends similar to the theory's prediction, such as perceiving less controllability and more negative valence. Nevertheless, we need to interpret this result with caution. At a minimum, it could mean that these models have learned the stereotypical behaviors of depressed people. Future research is needed to further explore LLMs in this direction. Still, this opens up the possibility of instructing the models to act as a person with various personalities or psychological conditions to investigate how it would affect the appraisal evaluation and emotional experiences.\n\nThis highlights another limitation of this work: human data is an average over multiple people and not a single individual. We did not compare LLMs, which have been fine-tuned in a specific way, against a specific person. Future work may look into instructing the model to match with a specific subject or group of subjects for comparison, a matched pair design.\n\nOur results also indicate that all models can be quite sensitive to the instruction and prompts. Asking in a batch, which could reduce the cost and speed up the query, could yield different results from asking each question one by one. Moreover, the older models may struggle to answer all the questions in the right format, especially when the number of questions increases.\n\nIn conclusion, this work seeks to understand LLMs through the lens of appraisal and coping theory, and we found some evidence suggesting that there is still some discrepancy between how human and LLMs perceive emotional scenarios. Nevertheless, as mentioned, this only touches a few aspects of emotional experiences and provides only one view of emotion theory. It is also possible that these LLMs trained on a large amount of human data would learn a different representation of scenarios from appraisal theory. It is an open question whether or not this different representation could be used in some way to inform theory or our understanding of emotion.\n\nRegardless, as these black box LLMs interact with more and more people, it is crucial for researchers to investigate how they understand human emotional experiences thoroughly. This work provides some initial steps toward this endeavor.",
      "page_start": 7,
      "page_end": 7
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: shows the estimated mean with the 95% standard",
      "page": 4
    },
    {
      "caption": "Figure 1: A shows the results for depressed/cheerful emo-",
      "page": 4
    },
    {
      "caption": "Figure 1: B also shows a similar",
      "page": 4
    },
    {
      "caption": "Figure 1: C, we see that none of",
      "page": 4
    },
    {
      "caption": "Figure 1: D), we see that only D003 and GPT-4 show the expected",
      "page": 4
    },
    {
      "caption": "Figure 1: E, only ChatGPT shows the trend of",
      "page": 4
    },
    {
      "caption": "Figure 1: G, both ChatGPT and GPT-4 show a trend similar",
      "page": 4
    },
    {
      "caption": "Figure 1: H), only GPT-4 shows the trend",
      "page": 4
    },
    {
      "caption": "Figure 1: I), all models show that, in the loss scenarios,",
      "page": 4
    },
    {
      "caption": "Figure 2: shows the key six measurements. The pattern is clear that,",
      "page": 4
    },
    {
      "caption": "Figure 1: Human vs The three models results for selected variables. The points show The estimated means and the error bars is 95% standard errors. The pink",
      "page": 5
    },
    {
      "caption": "Figure 2: Depression vs Normal Results for the three models for the selected variables. The pink with circle points is the depression instruction and the blue",
      "page": 6
    },
    {
      "caption": "Figure 3: The sensitivity analysis results on controllability for the three models",
      "page": 6
    },
    {
      "caption": "Figure 3: shows the results on controllability for the three",
      "page": 6
    },
    {
      "caption": "Figure 4: The sensitive analysis results across eight combinations across three",
      "page": 6
    },
    {
      "caption": "Figure 4: shows the",
      "page": 7
    },
    {
      "caption": "Figure 4: A), a few combinations show the expected trends",
      "page": 7
    },
    {
      "caption": "Figure 4: B), it increases rather than",
      "page": 7
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "Abstract—Large Language Models (LLM) like ChatGPT have\nthe\nimpact\non\ncoping\nresponses.\nThere\nare\nalso multiple"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "significantly advanced in recent years and are now being used by"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "theories of emotion [4]–[9]. We choose to investigate emotion"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "the general public. As more people interact with these systems,"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "perception through the\nlens of\nappraisal\nand coping theory."
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "improving our understanding of these black box models is crucial,"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "Specifically, we compare LLMs perception of emotional and"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "especially regarding their understanding of human psychological"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "stressful\nscenarios\nto the characterizations of\nthese scenarios\naspects.\nIn this work, we\ninvestigate\ntheir\nemotion perception"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "through the lens of appraisal and coping theory using the Stress\nby\nappraisal\ntheory\nand\nrelated\nhuman\ndata. From another"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "and Coping Process Questionaire (SCPQ). SCPQ is a validated"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "angle, we\ninvestigate whether or not LLMs\nare\nsensitive\nto"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "clinical\ninstrument consisting of multiple stories that evolve over"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "appraisal\ndimensions\nof\nscenarios\nand whether\nthis would"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "time and differ in key appraisal variables such as controllability"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "lead to responses with different coping tendencies. We choose"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "and changeability. We applied SCPQ to three recent LLMs from"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "appraisal\ntheory because it provides a representation of emo-\nOpenAI, davinci-003, ChatGPT, and GPT-4 and compared the"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "results with predictions\nfrom the appraisal\ntheory and human\ntional scenarios in terms of appraisal variables, allowing us to"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "data. The\nresults\nshow that LLMs’\nresponses\nare\nsimilar\nto"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "investigate emotion perception at a deeper level beyond simple"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "humans\nin\nterms\nof\ndynamics\nof\nappraisal\nand\ncoping,\nbut"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "emotion categories. In addition, some appraisal\ntheories, such"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "their\nresponses did not differ\nalong key\nappraisal dimensions"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "as Lazarus’s theory [4], provide a link from appraisal variables"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "as predicted by\nthe\ntheory\nand data. The magnitude\nof\ntheir"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "to coping behaviors, allowing us\nto further examine LLMs’\nresponses is also quite different from humans in several variables."
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "We also found that GPTs can be quite sensitive to instruction and\nresponses at\nthe behavior\nlevel."
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "how questions are asked. This work adds to the growing literature"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "To accomplish this, we use a validated clinical\ninstrument,"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "evaluating the psychological aspects of LLMs and helps enrich"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "the Stress and Coping Process Questionaire (SCPQ), by Perrez"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "our understanding of\nthe current models."
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "and Reicherts [10]. SCPQ is built upon Lazarus’s appraisal and"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "Index Terms—Large language model, Appraisal theory, coping"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "coping theory.\nIt\nincludes measurements of emotional experi-"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "ence, appraisal variables, and coping intentions and behaviors."
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "It has also been used to evaluate a computational model of"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "I.\nINTRODUCTION"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "emotion before [11]. In SCPQ, subjects are presented with hy-"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "Large\nlanguage models\n(LLM)\nhave made\nsignificant\npothetical stereotypical stressful scenarios which evolve over"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "progress in recent years. With the introduction of ChatGPT by\ntime, and their\nresponses are measured across multiple time"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "OpenAI,\nthe general public, not\njust\nresearchers, has widely\nsteps. This allows us to investigate the dynamics of appraisal"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "used and interacted with these LLMs. These models can write\nand coping. Furthermore, SCPQ consists of two specific types"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "stories, songs, poems, and code. People have also used them\nof\nscenarios:\naversive\nand loss or\nfailure. These\ntwo types"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "to answer various questions,\nincluding basic facts about\nthe\ndiffer\nsignificantly\nalong\nseveral\nkey\nappraisal\ndimensions:"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "world, medical questions,\nand social\nand emotional\nevents.\ncontrollability, changeability, and ambiguity. This permits us to"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "As\nthese AI\nsystems\ninteract with\npeople more\nand more,\ncheck the model’s sensitivity to appraisal dimensions. In sum,"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "it\nis\nessential\nto investigate\nand improve our understanding\nSCPQ provides a useful\ntestbed to investigate the important"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "of\nhow they\nperceive\nand\nunderstand\nhumans’\nsocial\nand\naspects of appraisal and coping theory within LLMs."
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "psychological\naspects. Existing research has begun to study\nWe subjected SCPQ to three recent LLMs\nfrom OpenAI:"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "various cognitive and psychological abilities of LLMs,\ninclud-\ntext-davinci-003, ChatGPT, and GPT-4 [12],\n[13]. We"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "ing decision-making, information search, causal reasoning, and\nfocus\non models\nfrom OpenAI\nbecause\nthey\nare\nthe most"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "theory of mind [1]–[3].\nwell-known models and GPT-4 seems\nto be the current best"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "available model at\nthe time of this writing [14]. We compared\nContinuing this\nline of\nresearch,\nin this work, we aim to"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "their results with human data and hypotheses from the theory\nfurther\ninvestigate LLMs’\nability\nto\nperceive\nand\nevaluate"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "emotions\nand related factors. Emotion has multiple dimen-\n[10].\nIn addition, we tested how LLMs would change if we"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "instructed them to act as a person with depression compared\nsions,\nincluding\nthe\nexpression\nof\nemotion,\nthe\nrelation\nto"
        },
        {
          "s.marsella@northeastern.edu\nghanadparisa@gmail.com\nnutjung.nutlc@gmail.com": "to what\nthe theory predicted. Lastly, we also investigated the\ncognition, physiological experience, subjective experience, and"
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "sensitivity of\nthese models on instruction and prompts along": "several\naspects. The\nresults\nshow that LLMs’\nresponses\nare",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "the\ncognitive\nreflection\ntests\n[1].\nThey\nfound\nthat\nit\ncan"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "similar\nto human trends\nregarding the dynamics of appraisal",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "solve\nthese\ntasks\nsimilarly\nor\nbetter\nthan\nhuman\nsubjects."
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "and coping. However, they still could not differentiate between",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "Kosinski (2023) investigated Theory of Mind (ToM) in LLMs"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "the\ntwo scenario types well. Their\nresponses\nare\nalso quite",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "using standard false-belief\ntasks and found that ChatGPT and"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "different\nfrom humans\nin terms of magnitude in several key",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "text-davinci-003 can solve most ToM tasks [3]. Miotto"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "variables,\nincluding controllability and coping. ChatGPT and",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "et al. (2022) explored personality, values, and demographic of"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "GPT-4, when instructed to act as a depressed person, respond",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "GPT-3 using validated questionnaires [20]. They found GPT-"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "in a way that\nis consistent with the theory’s prediction. Lastly,",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "3 to be\nsimilar\nto the human baseline\nsample\nand is\nclose"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "we found that LLMs can be quite sensitive to instruction and",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "to a young adult demographic. Bubeck et al.\n(2023)\nsubject"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "how questions are asked.",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "GPT-4 to various tests such as mathematics, coding, medicine,"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "law, and psychology [2]. They show that GPT-4 outperforms"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "II. RELATED WORK",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": ""
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "ChatGPT on ToM and emotion perception. Nevertheless,\nthey"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "As SCPQ is heavily influenced by Lazarus’ appraisal and",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "simply\ntested\nthe models\non\na\nfew examples\nand\ndid\nnot"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "coping theory, we first briefly review Lazarus’s\ntheory here.",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "systematically evaluate their psychological aspects and related"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "Appraisal theories of emotion define appraisal as an evaluation",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "factors."
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "of what\nthe\nsituation implies\nfor personal well-being based",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": ""
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "III. STRESS AND COPING PROCESS QUESTIONAIRE"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "on\none’s\ngoals\nand\nbeliefs\n[15],\n[16],\n[4],\n[5]. Lazarus’s",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": ""
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "theory emphasizes the importance of the process or dynamics",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "The Stress and Coping Process Questionaire (SCPQ) was"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "involved in coping [4].\nIn particular,\nthe person-environment",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "developed by Perrez and Reicherts to measure a human sub-"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "relationship is always changing,\nleading to different, evolving",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "ject’s appraisal and coping variables in stressful and emotional"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "emotional experiences, appraisal evaluations, and coping.",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "scenarios\nthat occur\nin their daily life [10]. SCPQ has been"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "Lazarus proposes\ntwo main dimensions of appraisals: pri-",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "validated by a panel of clinician experts and applied to normal"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "mary and secondary appraisal dimensions. Primary appraisals",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "human subjects as well as in clinical settings."
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "include\ngoal\nrelevance,\ngoal\ncongruence,\nand\ntype\nof\nego-",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "A subject is presented with a series of hypothetical scenarios"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "involvement. Secondary appraisals\ninclude blameworthiness,",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "that are divided into three episodes or phases, corresponding"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "coping\npotential\n(whether\nand\nhow a\nperson\ncan manage",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "to different stages of the stressful scenario: phase 1 beginning,"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "the demands\nand consequences of\nthe\nsituation),\nand future",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "phase 2 continuation, and phase 3 outcome. Their\nresponses"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "expectancy (the degree to which things are likely to change",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "are measured\nat\nthe\nend\nof\neach\nphase,\nreflecting\nthe\nkey"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "for\nthe\nbetter\nor worse\n). Effectively,\nsecondary\nappraisals",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "assumption of SCPQ that\nthe dynamics of a stressful scenario"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "involve how people\ncan cope with the\nsituation. Note\nthat,",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "are crucial\nto understanding how stress and coping develop."
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "in SCPQ, with influence\nfrom earlier work on helplessness",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "SCPQ consists of\ntwo types of scenarios: aversive and loss"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "[17], Perrez\nand Reicherts use\nthe\nterm controllability (the",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "or\nfailure (loss). Examples of\nloss\nscenarios are the loss of"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "subjective appraisal of personal ability to control the situation)",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "a\nfriendly relationship,\nthe\nloss of\nan important object,\nand"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "instead of coping potential and changeability (the subjective",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "the\nfailure of\nan interesting side\njob. Examples of\naversive"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "appraisal\nthat\nthe stressful event will change by itself) instead",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "scenarios\nare\ncriticism from the\npartner,\narguments\nabout"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "of\nfuture expectancy.",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "problems\nin a relationship, and reproaches\nfrom colleagues."
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "Lazarus also proposes two broad types of coping: problem-",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "The key differences between the\ntwo types\nare\nthe\nlevel of"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "focused coping (directly changing the\nsituation or\nthe\nenvi-",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "the\ncontrollability,\nchangeability,\nand ambiguity. By design,"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "ronment) and emotion-focused coping (changing one’s goals",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "loss\nscenarios are\nless\ncontrollable,\nless\nchangeable, and"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "and/or beliefs\nto adjust\nto the\nsituation). These\ncopings\nare",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "less ambiguous than the aversive scenarios."
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "also the main focus of SCPQ.",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "Both types of\nscenarios\nfollow a\nsimilar\ncourse of\nthree"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "With the influence of Lazarus’s theory, SCPQ focuses on not",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "episodes. The\nloss\nor\naversive\nscenario\nis\nlooming\nat\nthe"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "only appraisal but also the dynamics of appraisal and coping.",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "imminent,\nbeginning (phase 1)\nand becomes unavoidable,"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "This makes\nit\nstand out among other\nsimilar\nscenario-based",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "or reinforced in phase 2. The outcome phase (phase 3) can"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "instruments\n[18],\n[19].\nIn addition, SCPQ extends Lazarus’s",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "either be positive or negative. For\nloss scenarios,\nthe positive"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "taxonomy further. We go into more detail\nin the next section.",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "outcome\ninvolves finding a\nsubstitution, while\nthe negative"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "Additionally, SCQP has been used to evaluate a computational",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "outcome depicts the final\nloss without any successful substi-"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "model before [11]. A critical difference is that\nin the previous",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "tution. For aversive scenarios,\nthe positive outcome involves"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "work,\nthe scenarios were manually constructed to be in the",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "successfully removing the source of stress, while the negative"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "right\nformat\nthat\nthe model\ncould process, but here we\nare",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "outcome depicts the continuation of\nthe stress."
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "using LLMs to interpret\nthe scenario directly from the text.",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "Below are\nexamples\nof\nan\naversive\nscenario\nand\na\nloss"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "scenario,\nrespectively."
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "On\nthe\nother\nside,\nthere\nhas\nbeen more\nand more work",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": ""
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "An aversive scenario with a positive outcome:"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "evaluating the psychological aspects of LLMs. For example,",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": ""
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "Binz\nand\nSchulz\n(2023)\nstudied GPT-3’s\ndecision-making,",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "•\nPhase 1: ”You are together with some colleagues. One"
        },
        {
          "sensitivity of\nthese models on instruction and prompts along": "information\nsearch,\nand\ncausal\nreasoning\nusing\ncognitive",
          "psychological\ntests\nsuch\nas\nheuristic\nand\nbiases\ntests\nand": "says\nthat\nyou\ndon’t\npull\nyour weight when\nthere\nis"
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "colleagues.”",
          "• H1.3: Controllability and changeability should decrease": "from phase 1 to phase 2."
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "•\nPhase 2: ”Sometime later, another colleague hints that the",
          "• H1.3: Controllability and changeability should decrease": "• H2.1: Subjects should use more active coping in aversive"
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "problem is not\nthat you don’t\nthink of others but\nthat you",
          "• H1.3: Controllability and changeability should decrease": "scenarios than in loss scenarios."
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "lack any real\ninterest\nin the work.”",
          "• H1.3: Controllability and changeability should decrease": "• H2.2: Subjects should use less passive coping in aversive"
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "•\nPhase 3: ”Finally, you realize what your colleagues were",
          "• H1.3: Controllability and changeability should decrease": "scenarios than in loss scenarios."
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "really getting at,\nand you,\nfor your part, were\nable\nto",
          "• H1.3: Controllability and changeability should decrease": "• H3.1: Subjects’\nintention to use problem-focused coping"
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "convince them that you sometimes are more cautious at",
          "• H1.3: Controllability and changeability should decrease": "is less in aversive scenarios than in loss scenarios."
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "your work than others.”",
          "• H1.3: Controllability and changeability should decrease": "• H3.2: Subjects’\nintention to use emotion-focused coping"
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "A loss scenario with a negative outcome.",
          "• H1.3: Controllability and changeability should decrease": "is more in aversive scenarios than loss scenarios."
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "",
          "• H1.3: Controllability and changeability should decrease": "• H4.1: Subjects will blame themselves and others more in"
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "•\nPhase 1: ”A person who was very close to you, especially",
          "• H1.3: Controllability and changeability should decrease": ""
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "",
          "• H1.3: Controllability and changeability should decrease": "aversive scenarios than in loss scenarios."
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "in recent\ntimes, has\nto move away unexpectedly. When",
          "• H1.3: Controllability and changeability should decrease": ""
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "",
          "• H1.3: Controllability and changeability should decrease": "• H4.2: Self-blame will decrease over\ntime, while Other-"
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "you parted, you reassured each other you would both keep",
          "• H1.3: Controllability and changeability should decrease": ""
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "",
          "• H1.3: Controllability and changeability should decrease": "blame will\nincrease over\ntime."
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "in close contact. But his/her new home is quite far away.",
          "• H1.3: Controllability and changeability should decrease": ""
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "You could see each other only rarely,\nif at all.”",
          "• H1.3: Controllability and changeability should decrease": "These\nare\nthe\ntrends\nthat we will\ninvestigate\nin LLMs’"
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "•\nPhase 2: ”In the meantime, some weeks have passed. The",
          "• H1.3: Controllability and changeability should decrease": "results. The main rationale of H2-H4 is that aversive scenarios"
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "person hasn’t gotten in touch with you again. Neverthe-",
          "• H1.3: Controllability and changeability should decrease": "should be perceived as more controllable and changeable, so"
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "less, you feel\nfrom time to time that you miss him/her.”",
          "• H1.3: Controllability and changeability should decrease": "subjects are expected to cope differently between the two types"
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "•\nPhase 3: ”Finally, it has become clear that your friendship",
          "• H1.3: Controllability and changeability should decrease": "of scenarios. The SCPQ study involved 100 non-student adults"
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "is not\nthe\nsame\nanymore. Your\nrelationship with other",
          "• H1.3: Controllability and changeability should decrease": "with an average age of 38 years (sd 11.8)."
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "people can’t\nreplace what you have lost. Now and then,",
          "• H1.3: Controllability and changeability should decrease": "Additionally, Perrez\nand Reicherts\nprovide\nthe\nfollowing"
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "you\nfeel\ndisappointed\nabout\nthe\nrelationship\nyou\nhave",
          "• H1.3: Controllability and changeability should decrease": "hypotheses regarding depression:"
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "lost.”",
          "• H1.3: Controllability and changeability should decrease": ""
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "",
          "• H1.3: Controllability and changeability should decrease": "• H5.1: Depressed persons perceive stressful\nscenarios\nto"
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "There are nine scenarios for each type, a total of eighteen",
          "• H1.3: Controllability and changeability should decrease": "be more stressful and higher negative valence."
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "scenarios. The responses can be aggregated to reflect\nthe gen-",
          "• H1.3: Controllability and changeability should decrease": "• H5.2: Depressed persons perceive\nlower\ncontrollability"
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "eral\ntendency toward these types of\nscenarios and compared",
          "• H1.3: Controllability and changeability should decrease": "and changeability."
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "between the\ntwo types, which differ\nalong crucial\nappraisal",
          "• H1.3: Controllability and changeability should decrease": "• H6.1: Depressed persons use less active/problem-focused"
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "dimensions.",
          "• H1.3: Controllability and changeability should decrease": "coping."
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "SCPQ includes the following measurement.",
          "• H1.3: Controllability and changeability should decrease": "• H6.2: Depressed persons use more palliation."
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "• Emotional Responses: 1) anxious - calm, 2) depressed -",
          "• H1.3: Controllability and changeability should decrease": "• H6.3: Depressed persons blame themselves more."
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "cheerful, and 3) angry - gentle,",
          "• H1.3: Controllability and changeability should decrease": ""
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "",
          "• H1.3: Controllability and changeability should decrease": "In short, depressed persons are expected to perceive scenar-"
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "• Appraisals:\n1)\nchangeability,\n2)\ncontrollability,\nand\n3)",
          "• H1.3: Controllability and changeability should decrease": ""
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "",
          "• H1.3: Controllability and changeability should decrease": "ios worse both in controllability and changeability,\nresulting"
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "negative valence,",
          "• H1.3: Controllability and changeability should decrease": ""
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "",
          "• H1.3: Controllability and changeability should decrease": "in different coping patterns."
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "• Coping\nintentions:\n1)\nProblem-focused\ncoping,\n2)",
          "• H1.3: Controllability and changeability should decrease": ""
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "Emotion-focused coping1, and 3) Self-esteem,",
          "• H1.3: Controllability and changeability should decrease": "IV. OPENAI’S GPTS"
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "•\nSelf-directed coping behaviors: 1) search for information,",
          "• H1.3: Controllability and changeability should decrease": ""
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "",
          "• H1.3: Controllability and changeability should decrease": "In\nthis\nwork,\nwe\nchoose\nto\ninvestigate\nthree\nrecent"
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "2)\nsuppress\ninformation, 3)\nre-evaluation, and 4) pallia-",
          "• H1.3: Controllability and changeability should decrease": ""
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "",
          "• H1.3: Controllability and changeability should decrease": "LLMs\nfrom OpenAI’s\nfamily\nof\nGenerative\nPre-trained"
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "tion (calming self-instruction or\nsmoking, drinking, and",
          "• H1.3: Controllability and changeability should decrease": ""
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "",
          "• H1.3: Controllability and changeability should decrease": "Transformer models,\nor\nGPT\n[12],\n[13].\nThese\ninclude"
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "eating),",
          "• H1.3: Controllability and changeability should decrease": ""
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "",
          "• H1.3: Controllability and changeability should decrease": "text-davinci-003\ngpt-3.5-turbo\n(D003),\n(Chat-"
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "• Environment-directed coping behavior: 1) Active (to pre-",
          "• H1.3: Controllability and changeability should decrease": ""
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "",
          "• H1.3: Controllability and changeability should decrease": "GPT), gpt-4 (GPT-4). The first\ntwo are\nfrom the GPT3.5"
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "vent or\nconfront\nthe\nstressor)\nand 2) Passive\n(waiting,",
          "• H1.3: Controllability and changeability should decrease": ""
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "",
          "• H1.3: Controllability and changeability should decrease": "family. These three models have been fine-tuned using Rein-"
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "hesitating,\nresigning).",
          "• H1.3: Controllability and changeability should decrease": ""
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "",
          "• H1.3: Controllability and changeability should decrease": "forcement Learning with Human Feedback (RLHF)\n[21], and"
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "• Blameworthines: 1) Self-blaming and 2) Other-blaming,",
          "• H1.3: Controllability and changeability should decrease": ""
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "",
          "• H1.3: Controllability and changeability should decrease": "ChatGPT and GPT-4 have been optimized for chat. ChatGPT"
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "Below, we summarize the hypotheses that are supported by",
          "• H1.3: Controllability and changeability should decrease": ""
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "",
          "• H1.3: Controllability and changeability should decrease": "and GPT-4 also allow the user\nto set a system message (i.e.,"
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "the human data from the SCPQ study2.",
          "• H1.3: Controllability and changeability should decrease": ""
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "",
          "• H1.3: Controllability and changeability should decrease": "describing what kind of an assistant you want\nit\nto be). We"
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "• H1.1: Valence should be lower\nin the positive outcome",
          "• H1.3: Controllability and changeability should decrease": ""
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "",
          "• H1.3: Controllability and changeability should decrease": "do not use\nthis\nfeature\nto allow a\ncomparison with the old"
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "than in the negative outcome in phase 3.",
          "• H1.3: Controllability and changeability should decrease": ""
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "",
          "• H1.3: Controllability and changeability should decrease": "model. To maximize\nthe\nreplicability of our\nresults, we\nset"
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "• H1.2: Subjects should perceive higher controllability and",
          "• H1.3: Controllability and changeability should decrease": ""
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "",
          "• H1.3: Controllability and changeability should decrease": "the temperature parameter to 0 in all of our experiments. This"
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "changeability in the aversive scenarios\nthan in the loss",
          "• H1.3: Controllability and changeability should decrease": ""
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "",
          "• H1.3: Controllability and changeability should decrease": "makes the outputs mostly deterministic, selecting the outputs"
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "scenarios.",
          "• H1.3: Controllability and changeability should decrease": ""
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "",
          "• H1.3: Controllability and changeability should decrease": "with the highest\nlog probability. All other parameters are set"
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "",
          "• H1.3: Controllability and changeability should decrease": "to default."
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "1The question is “To remain calm and composed . . . ” Strictly speaking,",
          "• H1.3: Controllability and changeability should decrease": ""
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "this is not\nthe same as emotion-focused coping as defined in Lazarus theory",
          "• H1.3: Controllability and changeability should decrease": "As\nthese models can be sensitive to instruction [1],\n[22],"
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "which is about changing one internal beliefs, goals, or\nintention.",
          "• H1.3: Controllability and changeability should decrease": ""
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "",
          "• H1.3: Controllability and changeability should decrease": "[23], we investigate four different variations of prompting and"
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "2Note that we do not present\nthe results involving self-directed coping here",
          "• H1.3: Controllability and changeability should decrease": ""
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "",
          "• H1.3: Controllability and changeability should decrease": "asking the models. Here is the default\ninstruction taken from"
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "as they were not supported by human data, but\nthe LLM results can be found",
          "• H1.3: Controllability and changeability should decrease": ""
        },
        {
          "difficult work. He claims\nthat you don’t\nthink of other": "on Github.",
          "• H1.3: Controllability and changeability should decrease": "SCPQ with a slight modification: “Try to clearly imagine the"
        }
      ],
      "page": 3
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "scenario below and then answer\nthe question with the choice": "only in one\nline.” First, we\neither\nask it\nto output\nchoices",
          "lower\nin the positive outcome than in the negative outcome.": "However, all\nthree models rate valence higher than humans in"
        },
        {
          "scenario below and then answer\nthe question with the choice": "(default) or just the number only (“the choice’s number only”).",
          "lower\nin the positive outcome than in the negative outcome.": "both negative and positive outcomes."
        },
        {
          "scenario below and then answer\nthe question with the choice": "The number only makes sense here because all measurements",
          "lower\nin the positive outcome than in the negative outcome.": "Next,\nfor changeability in Figure 1.C, we see that none of"
        },
        {
          "scenario below and then answer\nthe question with the choice": "use a Likert scale ranging from 0 up to 5. We test this variation",
          "lower\nin the positive outcome than in the negative outcome.": "the models\nfollow the\nhuman\ntrend\nexactly where\nthere\nis"
        },
        {
          "scenario below and then answer\nthe question with the choice": "because our early testing showed that\nsometimes\nthe models",
          "lower\nin the positive outcome than in the negative outcome.": "a difference between the\ntwo types of\nscenarios\nacross\ntwo"
        },
        {
          "scenario below and then answer\nthe question with the choice": "may output more\nthan just\na\nchoice,\nsuch as\nrepeating the",
          "lower\nin the positive outcome than in the negative outcome.": "times, and the changeability in both types goes down. D003"
        },
        {
          "scenario below and then answer\nthe question with the choice": "question, even when the instruction specifies “choice only.”",
          "lower\nin the positive outcome than in the negative outcome.": "always\nrates\nchangeability\nto\nbe\nzero. On\nthe\nother\nhand,"
        },
        {
          "scenario below and then answer\nthe question with the choice": "The second variation is the location of the instruction. There",
          "lower\nin the positive outcome than in the negative outcome.": "ChatGPT only\nrates\nchangeability\nto\ngo\ndown\nin\nphase\n2"
        },
        {
          "scenario below and then answer\nthe question with the choice": "are two versions: either putting the instruction before (default)",
          "lower\nin the positive outcome than in the negative outcome.": "for\nloss\nscenarios, while GPT-4 only rates\nchangeability to"
        },
        {
          "scenario below and then answer\nthe question with the choice": "or after\n(“the above scenario”)\nthe scenario. The reason for",
          "lower\nin the positive outcome than in the negative outcome.": "go\ndown\nfor\naversive\nscenarios. For\ncontrollability\n(Figure"
        },
        {
          "scenario below and then answer\nthe question with the choice": "testing this is that, as these models use attention mechanisms,",
          "lower\nin the positive outcome than in the negative outcome.": "1.D), we see that only D003 and GPT-4 show the expected"
        },
        {
          "scenario below and then answer\nthe question with the choice": "the distance of the context could impact how the LLM follows",
          "lower\nin the positive outcome than in the negative outcome.": "trend of controllability going down over time for both scenario"
        },
        {
          "scenario below and then answer\nthe question with the choice": "the instruction.",
          "lower\nin the positive outcome than in the negative outcome.": "types. However, GPT-4 does not perceive the two types to be"
        },
        {
          "scenario below and then answer\nthe question with the choice": "Third, we\ninvestigate\neither\nasking them one question at",
          "lower\nin the positive outcome than in the negative outcome.": "different, unlike D003.\nIn all cases, all\nthree models perceive"
        },
        {
          "scenario below and then answer\nthe question with the choice": "a\ntime\n(individual) or multiple questions\nat\na\ntime\n(batch).",
          "lower\nin the positive outcome than in the negative outcome.": "controllability to be lower\nthan what humans perceive."
        },
        {
          "scenario below and then answer\nthe question with the choice": "The batch follows\nthe set of questions as\nstated above. The",
          "lower\nin the positive outcome than in the negative outcome.": "We\nturn\nnow to\ncoping\nintentions. For\nproblem-focused"
        },
        {
          "scenario below and then answer\nthe question with the choice": "rationale for\nthis is that asking in batches can save time and",
          "lower\nin the positive outcome than in the negative outcome.": "coping\nin\nFigure\n1.E,\nonly ChatGPT shows\nthe\ntrend\nof"
        },
        {
          "scenario below and then answer\nthe question with the choice": "costs, as you don’t need to repeat\nthe scenario every time.",
          "lower\nin the positive outcome than in the negative outcome.": "lowering it over\ntime for\nloss scenarios. None of\nthe models"
        },
        {
          "scenario below and then answer\nthe question with the choice": "These first\nthree variations\nresult\nin eight different\ncom-",
          "lower\nin the positive outcome than in the negative outcome.": "show that problem-focused coping at phase 2 in loss scenarios"
        },
        {
          "scenario below and then answer\nthe question with the choice": "binations\nof\ninstructions. Lastly, we\nalso\ntest\nthe\neffect\nof",
          "lower\nin the positive outcome than in the negative outcome.": "is lower than in aversive scenarios. In addition, all models rate"
        },
        {
          "scenario below and then answer\nthe question with the choice": "appending the previous (appraisal) answers to the prompt. The",
          "lower\nin the positive outcome than in the negative outcome.": "problem-focused coping higher\nthan the human data\nacross"
        },
        {
          "scenario below and then answer\nthe question with the choice": "reason is that, as we are interested in the dynamics, knowing",
          "lower\nin the positive outcome than in the negative outcome.": "time and type. For emotion-focused coping in Figure 1.F, we"
        },
        {
          "scenario below and then answer\nthe question with the choice": "their previous answers could be crucial. For this variation, we",
          "lower\nin the positive outcome than in the negative outcome.": "see that only D003 shows a similar\ntrend to the human data,"
        },
        {
          "scenario below and then answer\nthe question with the choice": "only use the default\ninstruction as asking for the number only",
          "lower\nin the positive outcome than in the negative outcome.": "where the intention is going down over\ntime in the aversive"
        },
        {
          "scenario below and then answer\nthe question with the choice": "or after\nthe scenario does not make sense in this case.",
          "lower\nin the positive outcome than in the negative outcome.": "case. On the other hand, both ChatGPT and GPT-4 rate\nit"
        },
        {
          "scenario below and then answer\nthe question with the choice": "Code,\nincluding all SCPQ scenarios and instructions, data,",
          "lower\nin the positive outcome than in the negative outcome.": "maximum across time and type."
        },
        {
          "scenario below and then answer\nthe question with the choice": "and all\nresults,\nincluding additional\nresults not\nshown in the",
          "lower\nin the positive outcome than in the negative outcome.": "Next, we\nlook\nat\ncoping\nbehaviors.\nFirst,\nfor\npassivity"
        },
        {
          "scenario below and then answer\nthe question with the choice": "paper, can be found at github.com/yongsa-nut/PerrezSAIWS.",
          "lower\nin the positive outcome than in the negative outcome.": "(Figure 1.G, both ChatGPT and GPT-4 show a trend similar"
        },
        {
          "scenario below and then answer\nthe question with the choice": "",
          "lower\nin the positive outcome than in the negative outcome.": "to humans where the passivity increases over\ntime. Second,"
        },
        {
          "scenario below and then answer\nthe question with the choice": "V. RESULTS",
          "lower\nin the positive outcome than in the negative outcome.": ""
        },
        {
          "scenario below and then answer\nthe question with the choice": "",
          "lower\nin the positive outcome than in the negative outcome.": "for active influence (Figure 1.H), only GPT-4 shows the trend"
        },
        {
          "scenario below and then answer\nthe question with the choice": "Figure 1 shows the estimated mean with the 95% standard",
          "lower\nin the positive outcome than in the negative outcome.": "that\nthe active influence would decrease over time but only for"
        },
        {
          "scenario below and then answer\nthe question with the choice": "error\nfor all\nthe key measurements of\nthe three models and",
          "lower\nin the positive outcome than in the negative outcome.": "the aversive case. On the other hand, only ChatGPT shows a"
        },
        {
          "scenario below and then answer\nthe question with the choice": "human data. The\nsetup here\nis\nthe default\nsetup, where\nthe",
          "lower\nin the positive outcome than in the negative outcome.": "clear difference between the two types."
        },
        {
          "scenario below and then answer\nthe question with the choice": "question is\nasked one by one,\nand the\ninstruction is placed",
          "lower\nin the positive outcome than in the negative outcome.": "Lastly, we turn to blameworthiness. First, for blaming others"
        },
        {
          "scenario below and then answer\nthe question with the choice": "before the scenario and asks for choices. We choose to report",
          "lower\nin the positive outcome than in the negative outcome.": "(Figure\n1.I),\nall models\nshow that,\nin\nthe\nloss\nscenarios,"
        },
        {
          "scenario below and then answer\nthe question with the choice": "this here\nas\nit\nis\nthe most\nsimilar\nto the human setup. We",
          "lower\nin the positive outcome than in the negative outcome.": "blaming others\nincreases\nfrom phase 1 to 2. However, only"
        },
        {
          "scenario below and then answer\nthe question with the choice": "discuss the results for other setups in the next section.",
          "lower\nin the positive outcome than in the negative outcome.": "D003\nshows\nan\nincrease\nin\nblaming\nothers\nin\nthe\naversive"
        },
        {
          "scenario below and then answer\nthe question with the choice": "Crucially, we focus mainly here on the qualitative results",
          "lower\nin the positive outcome than in the negative outcome.": "scenarios. None of\nthe models\nshows\nthat blaming others\nis"
        },
        {
          "scenario below and then answer\nthe question with the choice": "comparing the trend of\nresults\nfrom the model and humans.",
          "lower\nin the positive outcome than in the negative outcome.": "higher\nin the aversive than in the loss\nscenarios at phase 2,"
        },
        {
          "scenario below and then answer\nthe question with the choice": "The main reason is that\nthere is a discrepancy between human",
          "lower\nin the positive outcome than in the negative outcome.": "like the human data."
        },
        {
          "scenario below and then answer\nthe question with the choice": "data\nand model data. The human results\nare obtained from",
          "lower\nin the positive outcome than in the negative outcome.": "Second,\nfor\nself-blaming (Figure ??J), both ChatGPT and"
        },
        {
          "scenario below and then answer\nthe question with the choice": "averaging\nover\n100\nsubjects\nand\nnine\nscenarios, while\nthe",
          "lower\nin the positive outcome than in the negative outcome.": "GPT-4 show trends similar to the human data, where blaming"
        },
        {
          "scenario below and then answer\nthe question with the choice": "model\nresults are from averaging nine scenarios making their",
          "lower\nin the positive outcome than in the negative outcome.": "oneself decreases over time in the aversive type and is higher"
        },
        {
          "scenario below and then answer\nthe question with the choice": "uncertainty incomparable.",
          "lower\nin the positive outcome than in the negative outcome.": "in the aversive type than in the loss type in phase 1."
        },
        {
          "scenario below and then answer\nthe question with the choice": "Figure 1.A shows\nthe results\nfor depressed/cheerful emo-",
          "lower\nin the positive outcome than in the negative outcome.": "Overall, we observe in many cases that LLMs’s responses"
        },
        {
          "scenario below and then answer\nthe question with the choice": "tional\nreactions. For\nthis\nresult\nand valence, we only focus",
          "lower\nin the positive outcome than in the negative outcome.": "are similar\nto human’s data in the case of\nthe dynamics, but"
        },
        {
          "scenario below and then answer\nthe question with the choice": "on the outcome (positive or negative)\nin phase 3. We see that",
          "lower\nin the positive outcome than in the negative outcome.": "not\nin the case of scenario types."
        },
        {
          "scenario below and then answer\nthe question with the choice": "all\nthree models\nshow the expected trend where the positive",
          "lower\nin the positive outcome than in the negative outcome.": "Next, we look at\nthe results comparing the model\ninstructed"
        },
        {
          "scenario below and then answer\nthe question with the choice": "outcome results in more cheerful and less depressed than the",
          "lower\nin the positive outcome than in the negative outcome.": "to act as a person with depression (Depression) and the model"
        },
        {
          "scenario below and then answer\nthe question with the choice": "negative outcome. Compared to humans, all\nthree models rate",
          "lower\nin the positive outcome than in the negative outcome.": "without\nthe\ninstruction (Normal),\nfocusing only on aversive"
        },
        {
          "scenario below and then answer\nthe question with the choice": "the cheerful\nto be lower in the positive outcome, where D003",
          "lower\nin the positive outcome than in the negative outcome.": "scenarios\n(the\nloss\nscenarios\nshow similar\ntrends). Figure 2"
        },
        {
          "scenario below and then answer\nthe question with the choice": "is closest\nto the human rating. The results\nfor\nthe other\ntwo",
          "lower\nin the positive outcome than in the negative outcome.": "shows\nthe key six measurements. The pattern is\nclear\nthat,"
        },
        {
          "scenario below and then answer\nthe question with the choice": "emotional\nreactions are similar.",
          "lower\nin the positive outcome than in the negative outcome.": "for ChatGPT and GPT-4 but not D003,\nthere is a difference"
        },
        {
          "scenario below and then answer\nthe question with the choice": "The results for valence in Figure 1.B also shows a similar",
          "lower\nin the positive outcome than in the negative outcome.": "between the depression and normal case in the expected di-"
        },
        {
          "scenario below and then answer\nthe question with the choice": "trend. Like humans, all\nthree models\nrate the valence to be",
          "lower\nin the positive outcome than in the negative outcome.": "rections.\nIn particular, controllability, changeability, problem-"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Fig. 1. Human vs The three models results for selected variables. The points show The estimated means and the error bars is 95% standard errors. The pink": "line with circle dots is the aversive type and the blue line with triangles is the loss type. The likert scales are as follows. Emotion: Very depressed (0)"
        },
        {
          "Fig. 1. Human vs The three models results for selected variables. The points show The estimated means and the error bars is 95% standard errors. The pink": "cheerful"
        },
        {
          "Fig. 1. Human vs The three models results for selected variables. The points show The estimated means and the error bars is 95% standard errors. The pink": "Certainty 100% (4)."
        }
      ],
      "page": 5
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Fig. 2.\nDepression vs Normal Results for\nthe three models for\nthe selected variables. The pink with circle points is the depression instruction and the blue": "with triangle points is without\nthe instruction."
        },
        {
          "Fig. 2.\nDepression vs Normal Results for\nthe three models for\nthe selected variables. The pink with circle points is the depression instruction and the blue": "focused coping, and palliation are lower in the depression case"
        },
        {
          "Fig. 2.\nDepression vs Normal Results for\nthe three models for\nthe selected variables. The pink with circle points is the depression instruction and the blue": "than in the normal case, while blaming oneself and valence"
        },
        {
          "Fig. 2.\nDepression vs Normal Results for\nthe three models for\nthe selected variables. The pink with circle points is the depression instruction and the blue": "are higher\nin the depression case than in the normal case."
        }
      ],
      "page": 6
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "depends on the model. Similar\nresults can be found in other": "questions not shown here.",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "humans\nand LLMs\non\nseveral\nkey\nappraisal\nvariables.\nIn"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "Next, we zoom into selected questions. Figure 4 shows the",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "particular, GPT-4 rated the\ncontrollability and changeability"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "GPT-4’s\nresults\nfor changeability (A) and controllability (B)",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "decrease\nover\ntime\nbut\ndidn’t\nrate\nthe\ntwo\nscenario\ntypes"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "across all combinations of setup. Due to space limitations, we",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "differently. We speculate that\nthis could be due to the limited"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "focus only on these\ntwo as\nthe\ntheory argues\nthey strongly",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "information provided in the scenarios. Human subjects bring"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "influence the coping response, and GPT-4 is the latest model.",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "with them their own knowledge and experiences of these daily"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "Again, we see that\nthere are variations\nin both controllabil-",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "stressful scenarios, which could make them aware of various"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "ity and changeability across combinations. For changeability",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "ways\nthat\nthey\ncould\ndeal with\nthem. However,\nthese\nare"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "(Figure 4.A),\na\nfew combinations\nshow the\nexpected trends",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "not explicitly in the sceanrios, and LLM may not be able to"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "aligning with human data, where changeability decreases over",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "infer them from just a short snippet. Another explanation and"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "time\nand\ndiffers\nbetween\naversive\nand\nloss\ntypes.\nIn\nthe",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "limitation of SCPQ is\nthat\nthese\nscenarios\nare hypothetical,"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "case of\ncontrollability (Figure 4.B),\nit\nincreases\nrather\nthan",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "and people may behave and appraise them differently if\nthey"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "decreases over\ntime\nfor\nthe\naversive\ntype when asking in a",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "were real. To fully test the perception of appraisal and emotion,"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "batch.\nIn addition,\nthe value is also higher\nin the batch setup.",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "future work is needed to compare LLMs’\nresults with human"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "On the other hand, when asking the questions\nindividually,",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "data from real events."
        },
        {
          "depends on the model. Similar\nresults can be found in other": "controllability decreases over time, aligning with the expected",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "Another\ninteresting\nresult\nis\nthat ChatGPT\nand GPT-4"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "trend. However, only in one of\nthe setups\n(asking to output",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "can be\ninstructed to act\nas\na depressed person, where\ntheir"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "only a number and after\nthe scenario), controllability across",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "responses show trends similar to the theory’s prediction, such"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "all\nphases\nis\nhigher\nin\nthe\naversive\nscenarios\nthan\nin\nthe",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "as perceiving less controllability and more negative valence."
        },
        {
          "depends on the model. Similar\nresults can be found in other": "loss\nscenarios,\nas\nexpected by the\ntheory and human data.",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "Nevertheless, we need to interpret\nthis result with caution. At"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "Nevertheless, the value in this setup is still lower than humans,",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "a minimum,\nit could mean that\nthese models have learned the"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "and its\nchangeability does not\nalign with humans. Overall,",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "stereotypical behaviors of depressed people. Future research"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "there\nis no single\nsetup here where both changeability and",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "is needed to further explore LLMs in this direction. Still,\nthis"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "controllability align with the expected trends.",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "opens up the possibility of\ninstructing the models to act as a"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "In addition to these eight\nsetups, we look at\nthe effect of",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "person with various personalities or psychological conditions"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "appending their appraisal answers to the prompt. However, we",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "to investigate how it would affect\nthe appraisal evaluation and"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "do not observe any significant changes in any variables aside",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "emotional experiences."
        },
        {
          "depends on the model. Similar\nresults can be found in other": "from a few cases\nfor ChatGPT. These include changeability",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "This highlights another limitation of this work: human data"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "and controllability in phase 2,\nin the right direction.",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "is an average over multiple people and not a single individual."
        },
        {
          "depends on the model. Similar\nresults can be found in other": "",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "We did not compare LLMs, which have been fine-tuned in a"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "Beyond the variation shown in the figure, we\nfound that",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": ""
        },
        {
          "depends on the model. Similar\nresults can be found in other": "",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "specific way, against a specific person. Future work may look"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "GPT-4 follows instructions better\nthan the other\ntwo models.",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": ""
        },
        {
          "depends on the model. Similar\nresults can be found in other": "",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "into instructing the model\nto match with a specific subject or"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "In particular, when asking in a batch, ChatGPT and D003",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": ""
        },
        {
          "depends on the model. Similar\nresults can be found in other": "",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "group of subjects for comparison, a matched pair design."
        },
        {
          "depends on the model. Similar\nresults can be found in other": "may\nnot\nanswer\nall\nthe\nquestions. Further, when\nasked\nto",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": ""
        },
        {
          "depends on the model. Similar\nresults can be found in other": "",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "Our\nresults\nalso\nindicate\nthat\nall models\ncan\nbe\nquite"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "answer with choice, ChatGPT occasionally did not answer just",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": ""
        },
        {
          "depends on the model. Similar\nresults can be found in other": "",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "sensitive to the instruction and prompts. Asking in a batch,"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "a choice but provided a full sentence reiterating the question",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": ""
        },
        {
          "depends on the model. Similar\nresults can be found in other": "",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "which could reduce the cost and speed up the query, could"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "instead. These did not happen with GPT-4.",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": ""
        },
        {
          "depends on the model. Similar\nresults can be found in other": "",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "yield different\nresults from asking each question one by one."
        },
        {
          "depends on the model. Similar\nresults can be found in other": "",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "Moreover,\nthe older models may struggle\nto answer\nall\nthe"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "VI. DISCUSSION",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": ""
        },
        {
          "depends on the model. Similar\nresults can be found in other": "",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "questions in the right\nformat, especially when the number of"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "Overall, no model follows all the human trends and hypothe-",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "questions increases."
        },
        {
          "depends on the model. Similar\nresults can be found in other": "ses as predicted by appraisal and coping theory. Nonetheless,",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "In conclusion,\nthis work seeks to understand LLMs through"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "the\nresponses\nfrom the\nthree models depict\nthe\nright\ntrends",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "the lens of appraisal and coping theory, and we found some"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "for\nthe\ndynamics\nin\nseveral\nvariables,\nincluding\nemotional",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "evidence\nsuggesting that\nthere\nis\nstill\nsome discrepancy be-"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "responses,\nappraisal\nvariables,\nand\ncoping.\nIn many\ncases,",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "tween how human and LLMs perceive\nemotional\nscenarios."
        },
        {
          "depends on the model. Similar\nresults can be found in other": "however,\nthe models could not differentiate the two scenario",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "Nevertheless, as mentioned,\nthis only touches a few aspects of"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "types well, and the magnitudes are quite different\nfrom hu-",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "emotional experiences and provides only one view of emotion"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "mans. A few cases\nstand out. For\nexample,\nall models\nrate",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "theory.\nIt\nis also possible that\nthese LLMs trained on a large"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "the negative valence to be more negative than humans. One",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "amount of human data would learn a different representation of"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "potential explanation could be from the human side, namely",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "scenarios from appraisal theory. It is an open question whether"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "it\ncould\nbe\ndue\nto\nexperimenter\ndemand\neffects. Another",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "or not\nthis different representation could be used in some way"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "interesting case\nconcerns\nthe particular\naspects of\nemotion-",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "to inform theory or our understanding of emotion."
        },
        {
          "depends on the model. Similar\nresults can be found in other": "focused coping that SCPQ considers,\nspecifically to remain",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "Regardless,\nas\nthese black box LLMs\ninteract with more"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "calm and composed. Both ChatGPT and GPT-4 always answer",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "and more people,\nit\nis\ncrucial\nfor\nresearchers\nto investigate"
        },
        {
          "depends on the model. Similar\nresults can be found in other": "the highest value. We speculate that\nthis could be due to fine-",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "how they understand human emotional experiences thoroughly."
        },
        {
          "depends on the model. Similar\nresults can be found in other": "tuning with RLHF.",
          "Importantly, we\nalso\nobserve\nsome\ndifferences\nbetween": "This work provides some initial steps toward this endeavor."
        }
      ],
      "page": 7
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "ETHICAL IMPACT STATEMENT": ""
        },
        {
          "ETHICAL IMPACT STATEMENT": "several"
        },
        {
          "ETHICAL IMPACT STATEMENT": ""
        },
        {
          "ETHICAL IMPACT STATEMENT": ""
        },
        {
          "ETHICAL IMPACT STATEMENT": "is critical for research to explore and evaluate"
        },
        {
          "ETHICAL IMPACT STATEMENT": ""
        },
        {
          "ETHICAL IMPACT STATEMENT": "results"
        },
        {
          "ETHICAL IMPACT STATEMENT": ""
        }
      ],
      "page": 8
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "approved study.": "REFERENCES"
        },
        {
          "approved study.": "[1] M. Binz and E. Schulz, “Using cognitive psychology to understand gpt-"
        },
        {
          "approved study.": "3,” Proceedings of\nthe National Academy of Sciences, vol. 120, no. 6,"
        },
        {
          "approved study.": "p. e2218523120, 2023."
        },
        {
          "approved study.": "[2]\nS. Bubeck, V. Chandrasekaran, R. Eldan, J. Gehrke, E. Horvitz, E. Ka-"
        },
        {
          "approved study.": "mar, P. Lee, Y. T. Lee, Y. Li, S. Lundberg, et al., “Sparks of artificial"
        },
        {
          "approved study.": "arXiv\npreprint\ngeneral\nintelligence:\nEarly\nexperiments with\ngpt-4,”"
        },
        {
          "approved study.": "arXiv:2303.12712, 2023."
        },
        {
          "approved study.": "[3] M. Kosinski, “Theory of mind may have spontaneously emerged in large"
        },
        {
          "approved study.": "language models,” arXiv preprint arXiv:2302.02083, 2023."
        },
        {
          "approved study.": "[4] R. S. Lazarus, Emotion and adaptation.\nOxford University Press on"
        },
        {
          "approved study.": "Demand, 1991."
        },
        {
          "approved study.": "[5] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal"
        },
        {
          "approved study.": "theories of emotion: State of\nthe art and future development,” Emotion"
        },
        {
          "approved study.": "Review, vol. 5, no. 2, pp. 119–124, 2013."
        },
        {
          "approved study.": "[6]\nP. Ekman et al., “Basic emotions,” Handbook of cognition and emotion,"
        },
        {
          "approved study.": "vol. 98, no. 45-60, p. 16, 1999."
        },
        {
          "approved study.": "[7] A. R. Damasio,\n“The\nsomatic marker\nhypothesis\nand\nthe\npossible"
        },
        {
          "approved study.": "the\nfunctions of\nthe prefrontal\ncortex,” Philosophical Transactions of"
        },
        {
          "approved study.": "Royal\nSociety\nof\nLondon.\nSeries B: Biological\nSciences,\nvol.\n351,"
        },
        {
          "approved study.": "no. 1346, pp. 1413–1420, 1996."
        },
        {
          "approved study.": "[8]\nJ. A. Russell, “A circumplex model of affect.,” Journal of personality"
        },
        {
          "approved study.": "and social psychology, vol. 39, no. 6, p. 1161, 1980."
        },
        {
          "approved study.": "[9]\nL. F. Barrett, “The theory of constructed emotion: an active inference ac-"
        },
        {
          "approved study.": "count of interoception and categorization,” Social cognitive and affective"
        },
        {
          "approved study.": "neuroscience, vol. 12, no. 1, pp. 1–23, 2017."
        },
        {
          "approved study.": "[10] M. Perrez and M. Reicherts, “Stress, coping, and health: A situation-"
        },
        {
          "approved study.": "behavior approach: Theory, methods, applications,” (No Title), 1992."
        },
        {
          "approved study.": "[11]\nJ. Gratch\nand\nS. Marsella,\n“Evaluating\na\ncomputational model\nof"
        },
        {
          "approved study.": "emotion,” Autonomous Agents and Multi-Agent Systems, vol. 11, pp. 23–"
        },
        {
          "approved study.": "43, 2005."
        },
        {
          "approved study.": "[12]\nT. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal,"
        },
        {
          "approved study.": "A. Neelakantan, P. Shyam, G. Sastry, A. Askell, et al., “Language mod-"
        },
        {
          "approved study.": "in neural\ninformation processing\nels are few-shot\nlearners,” Advances"
        },
        {
          "approved study.": "systems, vol. 33, pp. 1877–1901, 2020."
        },
        {
          "approved study.": "[13] O. AI, “Gpt-4 technical report,” arXiv preprint arXiv:2303.08774, 2023."
        },
        {
          "approved study.": "[14] B. Peng, C. Li, P. He, M. Galley, and J. Gao, “Instruction tuning with"
        },
        {
          "approved study.": "gpt-4,” arXiv preprint arXiv:2304.03277, 2023."
        },
        {
          "approved study.": "[15] M. B. Arnold, Emotion and personality.\nColumbia University Press,"
        },
        {
          "approved study.": "1960."
        },
        {
          "approved study.": "[16] C. A. Smith, R. S. Lazarus, et al., “Emotion and adaptation,” Handbook"
        },
        {
          "approved study.": "of personality: Theory and research, vol. 21, pp. 609–637, 1990."
        },
        {
          "approved study.": "[17] M. Seligman, “P.(1975). helplessness: On depression, development, and"
        },
        {
          "approved study.": "death,” Friedman, San Francisco, 1972."
        },
        {
          "approved study.": "[18] C. Harmon-Jones, B. Bastian,\nand E. Harmon-Jones,\n“The\ndiscrete"
        },
        {
          "approved study.": "emotions questionnaire: A new tool\nfor measuring state\nself-reported"
        },
        {
          "approved study.": "emotions,” PloS one, vol. 11, no. 8, p. e0159915, 2016."
        },
        {
          "approved study.": "[19] K. R. Scherer, “Evidence for\nthe existence of emotion dispositions and"
        },
        {
          "approved study.": "the effects of appraisal bias.,” Emotion, vol. 21, no. 6, p. 1224, 2021."
        },
        {
          "approved study.": "[20] M. Miotto, N. Rossberg,\nand B. Kleinberg,\n“Who\nis\ngpt-3?\nan\nex-"
        },
        {
          "approved study.": "arXiv\npreprint\nploration\nof\npersonality,\nvalues\nand\ndemographics,”"
        },
        {
          "approved study.": "arXiv:2209.14338, 2022."
        },
        {
          "approved study.": "[21]\nL. Ouyang,\nJ. Wu, X.\nJiang, D. Almeida, C. Wainwright, P. Mishkin,"
        },
        {
          "approved study.": "C. Zhang, S. Agarwal, K. Slama, A. Ray,\net al.,\n“Training language"
        },
        {
          "approved study.": "models to follow instructions with human feedback,” Advances in Neural"
        },
        {
          "approved study.": "Information Processing Systems, vol. 35, pp. 27730–27744, 2022."
        },
        {
          "approved study.": "[22] M. Bommarito II\nand D. M. Katz,\n“Gpt\ntakes\nthe bar\nexam,” arXiv"
        },
        {
          "approved study.": "preprint arXiv:2212.14402, 2022."
        }
      ],
      "page": 8
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Using cognitive psychology to understand gpt-3",
      "authors": [
        "M Binz",
        "E Schulz"
      ],
      "year": "2023",
      "venue": "Proceedings of the National Academy of Sciences"
    },
    {
      "citation_id": "2",
      "title": "Sparks of artificial general intelligence: Early experiments with gpt-4",
      "authors": [
        "S Bubeck",
        "V Chandrasekaran",
        "R Eldan",
        "J Gehrke",
        "E Horvitz",
        "E Kamar",
        "P Lee",
        "Y Lee",
        "Y Li",
        "S Lundberg"
      ],
      "year": "2023",
      "venue": "Sparks of artificial general intelligence: Early experiments with gpt-4",
      "arxiv": "arXiv:2303.12712"
    },
    {
      "citation_id": "3",
      "title": "Theory of mind may have spontaneously emerged in large language models",
      "authors": [
        "M Kosinski"
      ],
      "year": "2023",
      "venue": "Theory of mind may have spontaneously emerged in large language models",
      "arxiv": "arXiv:2302.02083"
    },
    {
      "citation_id": "4",
      "title": "Emotion and adaptation",
      "authors": [
        "R Lazarus"
      ],
      "year": "1991",
      "venue": "Emotion and adaptation"
    },
    {
      "citation_id": "5",
      "title": "Appraisal theories of emotion: State of the art and future development",
      "authors": [
        "A Moors",
        "P Ellsworth",
        "K Scherer",
        "N Frijda"
      ],
      "year": "2013",
      "venue": "Emotion Review"
    },
    {
      "citation_id": "6",
      "title": "Basic emotions",
      "authors": [
        "P Ekman"
      ],
      "year": "1999",
      "venue": "Handbook of cognition and emotion"
    },
    {
      "citation_id": "7",
      "title": "The somatic marker hypothesis and the possible functions of the prefrontal cortex",
      "authors": [
        "A Damasio"
      ],
      "year": "1996",
      "venue": "Philosophical Transactions"
    },
    {
      "citation_id": "8",
      "title": "A circumplex model of affect",
      "authors": [
        "J Russell"
      ],
      "year": "1980",
      "venue": "Journal of personality and social psychology"
    },
    {
      "citation_id": "9",
      "title": "The theory of constructed emotion: an active inference account of interoception and categorization",
      "authors": [
        "L Barrett"
      ],
      "year": "2017",
      "venue": "Social cognitive and affective neuroscience"
    },
    {
      "citation_id": "10",
      "title": "Stress, coping, and health: A situationbehavior approach: Theory, methods, applications",
      "authors": [
        "M Perrez",
        "M Reicherts"
      ],
      "year": "1992",
      "venue": "Stress, coping, and health: A situationbehavior approach: Theory, methods, applications"
    },
    {
      "citation_id": "11",
      "title": "Evaluating a computational model of emotion",
      "authors": [
        "J Gratch",
        "S Marsella"
      ],
      "year": "2005",
      "venue": "Autonomous Agents and Multi-Agent Systems"
    },
    {
      "citation_id": "12",
      "title": "Language models are few-shot learners",
      "authors": [
        "T Brown",
        "B Mann",
        "N Ryder",
        "M Subbiah",
        "J Kaplan",
        "P Dhariwal",
        "A Neelakantan",
        "P Shyam",
        "G Sastry",
        "A Askell"
      ],
      "year": "2020",
      "venue": "Advances in neural information processing systems"
    },
    {
      "citation_id": "13",
      "title": "Gpt-4 technical report",
      "authors": [
        "O Ai"
      ],
      "year": "2023",
      "venue": "Gpt-4 technical report",
      "arxiv": "arXiv:2303.08774"
    },
    {
      "citation_id": "14",
      "title": "Instruction tuning with gpt-4",
      "authors": [
        "B Peng",
        "C Li",
        "P He",
        "M Galley",
        "J Gao"
      ],
      "year": "2023",
      "venue": "Instruction tuning with gpt-4",
      "arxiv": "arXiv:2304.03277"
    },
    {
      "citation_id": "15",
      "title": "Emotion and personality",
      "authors": [
        "M Arnold"
      ],
      "year": "1960",
      "venue": "Emotion and personality"
    },
    {
      "citation_id": "16",
      "title": "Emotion and adaptation",
      "authors": [
        "C Smith",
        "R Lazarus"
      ],
      "year": "1990",
      "venue": "Handbook of personality: Theory and research"
    },
    {
      "citation_id": "17",
      "title": "helplessness: On depression, development, and death",
      "authors": [
        "M Seligman"
      ],
      "year": "1972",
      "venue": "helplessness: On depression, development, and death"
    },
    {
      "citation_id": "18",
      "title": "The discrete emotions questionnaire: A new tool for measuring state self-reported emotions",
      "authors": [
        "C Harmon-Jones",
        "B Bastian",
        "E Harmon-Jones"
      ],
      "year": "2016",
      "venue": "PloS one"
    },
    {
      "citation_id": "19",
      "title": "Evidence for the existence of emotion dispositions and the effects of appraisal bias",
      "authors": [
        "K Scherer"
      ],
      "year": "2021",
      "venue": "Emotion"
    },
    {
      "citation_id": "20",
      "title": "Who is gpt-3? an exploration of personality, values and demographics",
      "authors": [
        "M Miotto",
        "N Rossberg",
        "B Kleinberg"
      ],
      "year": "2022",
      "venue": "Who is gpt-3? an exploration of personality, values and demographics",
      "arxiv": "arXiv:2209.14338"
    },
    {
      "citation_id": "21",
      "title": "Training language models to follow instructions with human feedback",
      "authors": [
        "L Ouyang",
        "J Wu",
        "X Jiang",
        "D Almeida",
        "C Wainwright",
        "P Mishkin",
        "C Zhang",
        "S Agarwal",
        "K Slama",
        "A Ray"
      ],
      "year": "2022",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "22",
      "title": "Gpt takes the bar exam",
      "authors": [
        "M Bommarito",
        "D Katz"
      ],
      "year": "2022",
      "venue": "Gpt takes the bar exam",
      "arxiv": "arXiv:2212.14402"
    },
    {
      "citation_id": "23",
      "title": "Is gpt-3 a psychopath? evaluating large language models from a psychological perspective",
      "authors": [
        "X Li",
        "Y Li",
        "L Liu",
        "L Bing",
        "S Joty"
      ],
      "year": "2022",
      "venue": "Is gpt-3 a psychopath? evaluating large language models from a psychological perspective",
      "arxiv": "arXiv:2212.10529"
    }
  ]
}