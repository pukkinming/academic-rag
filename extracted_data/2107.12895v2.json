{
  "paper_id": "2107.12895v2",
  "title": "Emotion Recognition Under Consideration Of The Emotion Component Process Model",
  "published": "2021-07-27T15:53:25Z",
  "authors": [
    "Felix Casel",
    "Amelie Heindl",
    "Roman Klinger"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Emotion classification in text is typically performed with neural network models which learn to associate linguistic units with emotions. While this often leads to good predictive performance, it does only help to a limited degree to understand how emotions are communicated in various domains. The emotion component process model (CPM) by Scherer (  2005 ) is an interesting approach to explain emotion communication. It states that emotions are a coordinated process of various subcomponents, in reaction to an event, namely the subjective feeling, the cognitive appraisal, the expression, a physiological bodily reaction, and a motivational action tendency. We hypothesize that these components are associated with linguistic realizations: an emotion can be expressed by describing a physiological bodily reaction (\"he was trembling\"), or the expression (\"she smiled\"), etc. We annotate existing literature and Twitter emotion corpora with emotion component classes and find that emotions on Twitter are predominantly expressed by event descriptions or subjective reports of the feeling, while in literature, authors prefer to describe what characters do, and leave the interpretation to the reader. We further include the CPM in a multitask learning model and find that this supports the emotion categorization. The annotated corpora are available at https://www. ims.uni-stuttgart.de/data/emotion.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "The task of emotion classification from written text is to map textual units, like documents, paragraphs, or sentences, to a predefined set of emotions. Common class inventories rely on psychological theories such as those proposed by  Ekman (1992)  (anger, disgust, fear, joy, sadness, surprise) or  Plutchik (2001) . Often, emotion classification is tackled as an end-to-end learning task, potentially informed by lexical resources (see the SemEval Shared Task 1 on Affect in Tweets for an overview of recent approaches  (Mohammad et al., 2018) ).\n\nWhile end-to-end learning and fine-tuning of pretrained models for classification have shown great performance improvements in contrast to purely feature-based methods, such approaches typically neglect the existing knowledge about emotions in psychology (which might help in classification and to better understand how emotions are communicated). There are only very few approaches that aim at combining psychological theories (beyond basic emotion categories) with emotion classification models: We are only aware of the work by  Hofmann et al. (2020) , who incorporate the cognitive appraisal of events, and  Buechel et al. (2020) , who jointly learn affect (valence, arousal) and emotion classes; next to knowledge-base-oriented modelling of events by  Balahur et al. (2012)  and  Cambria et al. (2014) .\n\nAn interesting and attractive theory for computational modelling of emotions that has not been used in natural language processing yet is the emotion component process model  (Scherer, 2005, CPM) . This model states that emotions are a coordinated process in five subsystems, following an event that is relevant for the experiencer of the emotion, namely a motivational action tendency, the motor expression component, a neurophysiological, bodily symptom, the subjective feeling, and the cognitive appraisal. The cognitive appraisal has been explored in a fine-grained manner by  Hofmann et al. (2020) , mentioned above. The subjective feeling component is related to the dimensions of affect.  1 We hypothesize (and subsequently analyze) that emotions in text are communicated in a variety of ways, and that these different stylistic means follow the emotion component process model. The communication of emotions can either be an explicit mention of the emotion name (\"I am angry\"), focus on the motivational aspect (\"He wanted to run away.\"), describe the expression (\"She smiled.\", \"He shouted.\") or a physiological bodily reaction (\"she was trembling\", \"a tear was running down his face\"), the subjective feeling (\"I felt so bad.\"), or, finally, describe a cognitive appraisal (\"I wasn't sure what was happening.\", \"I am not responsible.\").\n\nWith this paper, we study how emotions are communicated (following the component model) in Tweets (based on the Twitter Emotion Corpus TEC, by  Mohammad (2012) ) and literature (based on the REMAN corpus by  Kim and Klinger (2018) ). We post-annotate a subset of 3041 instances with the use of emotion component-based emotion communication categories, analyze this corpus, and perform joint modelling/multi-task learning experiments. Our research goals are (1) to understand if emotion components are distributed similarly across emotion categories and domains, and (2) to evaluate if informing an emotion classifier about emotion components improves their performance (and to evaluate various classification approaches). We find that emotion component and emotion classification prediction interact and benefit from each other and that emotions are communicated by means of various components in literature and social media. The corpus is available at https: //www.ims.uni-stuttgart.de/data/emotion.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Background And Related Work",
      "text": "",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Emotion Models",
      "text": "Emotion models can be separated into those that consider a discrete set of categories or those that focus on underlying principles like affect. The model of basic emotions by  Ekman (1992)  considers anger, disgust, fear, joy, sadness, and surprise. According to his work, there are nine characteristics that a basic emotion fulfills: These are (1) distinctive universal signals, (2) presence in other primates, (3) distinctive physiology, (4) distinctive universals in antecedent events, (5) coherence among emotional response, (6) quick onset, (7) brief duration, (8) automatic appraisal, and (9) unbidden occurrence. His model of the six universal  Rashkin et al., 2018) .\n\nemotions constitutes one of the most popular emotion sets in natural language processing. Yet it might be doubted if this set is sufficient.  Plutchik (2001)  proposed a model with eight main emotions, visualized on a colored wheel. In this visualization, opposites and distance of emotion names are supposed to correspond to their respective relation.\n\nA complementary approach to categorizing emotions in discrete sets is advocated by  Russell and Mehrabian (1977) . Their dimensional affect model corresponds to a 3-dimensional vector space with dimensions for pleasure-displeasure, the degree of arousal, and dominance-submissiveness (VAD). Emotion categories correspond to points in this vector space. A more expressive alternative to the VAD model of affect is motivated by the cognitive appraisal process that is part of emotions. The model of  Smith and Ellsworth (1985)  introduces a set of variables that they map to the principle components of pleasantness, responsibility/control, certainty, attention, effort, and situational control. They show that these dimensions are more powerful to distinguish emotion categories than VAD.\n\nAppraisals are also part of the emotion component process model by  Scherer (2005) , which is central to this paper. The five components are cognitive appraisal, neurophysiological bodily symptoms, motor expressions, motivational action tendencies, and subjective feelings. Cognitive appraisal is concerned with the evaluation of an event. The event is assessed regarding its relevance to the individual, the implications and consequences it might lead to, the possible ways to cope with it and control it, and its significance according to personal values and social norms. The component of neurophysiological symptoms regards automatically activated reactions and symptoms of the body, like changes in the heartbeat or breathing pattern. The motor expression component contains all movements, facial expressions, changes concerning the speech, and similar patterns. Actions like attention shifts and movement with respect to the position of the event are part of the motivational action tendencies component. Finally, the component of subjective feelings takes into account how strong, important, and persisting the felt sensations are.  Scherer (2005)  argues that it is possible to infer the emotion a person is experiencing by analyzing the set of changes in the five components.  Scherer (2009)  also points out that computational models must not ignore emotion components.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Emotion Analysis In Text",
      "text": "The majority of modelling approaches focuses on the analysis of fundamental emotions (see  Alswaidan and Menai, 2020; Mohammad et al., 2018; Bostan and Klinger, 2018)  or on the recognition of valence, arousal, and dominance  (Buechel and Hahn, 2017) . Work with a focus on other aspects of emotions is scarce.\n\nNoteworthy, though this has not been a computational study, is the motivation of the ISEAR project  (Scherer and Wallbott, 1994) , from which a textual corpus originated, which is frequently used in NLP. It consists of event descriptions and is therefore relevant for appraisal theories. Further, participants in that study have not only been asked to report on events they experienced, but they also report additional aspects, including the existence of bodily reactions. However, their work does not focus on the linguistic realization of emotion components, but on the existence in the described event.\n\nSimilarly,  Troiano et al. (2019)  asked crowdworkers to report on events that caused an emotion. This resource has then been postannotated with appraisal dimensions  (Hofmann et al., 2020) . This is the only recent work we are aware of that models appraisal as a component of the CPM to predict emotion categories, next to the rule-based classification approach by  Shaikh et al. (2009) , who built on top of the work by  Clore and Ortony (2013) . Another noteworthy related work is SenticNet, which models event properties including people's goals, for sentiment analysis  (Cambria et al., 2014) .\n\nThe only work we are aware of that studies emotion components (though not following the CPM, and without computational modelling), is the corpus study by  Kim and Klinger (2019) . They analyze if emotions in fan fiction are communicated via facial descriptions, body posture descriptions, the appearance, look, voice, gestures, subjective sensations, or spatial relations of characters. This set of variables is not the same as emotion components, however, it is related. They find that some emotions are preferred to be described with particular aspects by authors. Their work was motivated by the linguistic study of  van Meel (1995) .\n\nIn contrast to their work, our study compares two different domains (Tweets and Literature), and follows the emotion component process model more strictly. Further, we show the use of that model for computational emotion classification through multi-task learning.\n\n3 Corpus Annotation",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Corpus Selection",
      "text": "To study the relation between emotion components and emotions, we annotate subsets from two different existing emotion corpora from two different domains, namely literature and social media.\n\nFor literature, we use the REMAN corpus  (Kim and Klinger, 2018) , which consists of fiction written after the year 1800. It is manually annotated with text spans related to emotions, as well as their experiencers, causes, and targets. Emotion cue spans are annotated with the emotions of anger, fear, trust, disgust, joy, sadness, surprise, and anticipation, as well as 'other emotion'. From the 1720 instances, we randomly sample a subset of 1000. Each instance comprises a sentence triple and may contain any number of annotated spans. We map the emotions associated to spans to the text instances as the union of all labels, which leads to a multi-label classification task. Instances without emotion annotations are considered 'neutral'.\n\nFor the social media domain, we choose the Twitter Emotion Corpus (TEC)  (Mohammad, 2012) . The emotion categories are anger, disgust, fear, joy, sadness, and surprise. TEC consists of approximately 21,000 posts from Twitter that have a hashtag at the end which states one of the six mentioned emotions. According to the authors, the validity of hashtags as classification labels is commensurable to the inter-annotator agreements of human annotators. We randomly sample 2041 instances with the emotion hashtags as labels for the creation of our corpus. Each instance equals one post and has exactly one emotion label.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Annotation Procedure And Inter-Annotator Agreement",
      "text": "We annotate the emotion component dimensions independently: The existence of a CPM label means that this component is mentioned somewhere in the text, independent of its function to communicate one of the emotions. This is a simplification due to the fact that it turned out to be difficult to infer from the limited context of an instance if an emotion category and an emotion component mention are actually in relation. Further, this procedure also ensures that there is no information leak introduced in the annotation process (e.g., that components are only annotated if they indeed inform the emotion, and that a model could learn from its sheer presence).",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Component Explanation Of Example Example",
      "text": "Cognitive appraisal evaluation of the pleasantness of an event. Thinks that @melbahughes had a great 50th birthday party Neurophysiol. symptoms change in someone's heartbeat.\n\nLoves when a song makes your heart race [...] Motiv. Action tendencies urge to attack a person or object.\n\nsometimes when i think bout you i want to beat the shit out of your face so everyone can see how ugly you are inside and out Motor expressions facial expression. @TheBodyShopUK when I walk in the room and my 9month old nephew recognises me and his face lights up with the biggest smile thats 100% Subjective feelings internal feeling state. Feelin a bit sad tonight We refined the annotation guidelines in an iterative process with two annotators. Annotator 1 is a 23 year-old female undergraduate computer science student, Annotator 2 is a 28 year-old male graduate student of computational linguistics. We first defined a list of guidelines for each emotion component, then let each annotator label 40 randomly sampled instances (20 each in two iterations) out of each corpus and measured the interannotator agreement. Based on instances with disagreement, we refined the guidelines. The achieved inter-annotator agreement scores are displayed in Table  2 . We observe that particularly the concepts of cognitive appraisal and motivational action tendencies have been clarified. During this process, for example, the discussion of the instance \"He did so, and to his surprise, found that all the bank stock had been sold, and transferred\" lead to the addition of a rule stating that the explicit mention of a feeling has to be annotated with subjective feeling. A rule for the annotation of tiredness as neurophysiological symptoms was created due to the instance \"Here he remained the whole night, feeling very tired and sorrowful.\". Concerning the annotation of verbal communication as motor expression, we decided to only annotate instances with verbal communications that address an emotional reaction or instances with interjections as for example 'oh' or 'wow'. With this clarification, the instance \"'Jolly rum thing about that boat,' said the spokesman of the party, as the boys continued their walk. 'I expect it got adrift somehow,' said another. 'I don't know,' said the first.\" should not be annotated, whereas \"'Sounds delightful.' 'Oh, it was actually pretty cool.'\" should (this aspect has particularly appeared in the second annotator training round, which lead to a slight decrease in agreement). We make the annotation guidelines available together with our corpus. Table  1  shows a short excerpt.\n\nAfter the refinement process concluded, Annotator 1 annotated the subsample of TEC and Annotator 2 annotated the subsample of REMAN.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Corpus Statistics",
      "text": "We show corpus statistics in Table  3  to develop an understanding how emotions are communicated in the two domains. For both corpora, we observe that cognitive appraisal is most frequent. In TEC, the second most dominant component is subjective feeling, while in REMAN it is the motor expression. The amount of subjective feeling descriptions is substantially lower for literature than for social media -which is in line with the show-don't-tell paradigm which is obviously not followed in social media as it is in literature.\n\nComponents are not distributed equally across emotions. Particularly noteworthy is the cooccurrence of disgust with neurophysiological symptoms in social media, but not in literature where this component dominates the emotion of fear. We also observe a particularly high cooccurrence of the subjective feeling component with fear for social media, which is not the case for literature. In literature, the motivational action tendency component co-occurs with anger (and anticipation) more frequently than with all other emotions. This is not the case for the social media do- main. On the REMAN corpus, components occur least frequently when there is no emotion across all components. For both corpora, neurophysiological symptoms make up the smallest share of components, even more so in the case of TEC than REMAN.\n\nIn a comparison of social media and literature, we observe that emotions are distributed more uniformly in literature. The relative number of cooccurrences of CPM components with emotions varies more for REMAN than for the TEC corpus.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Methods",
      "text": "We will now turn to the computational modelling of emotion components and evaluate their usefulness for emotion classification. We evaluate a set of different feature-based and deep-learning based classification approaches to join the tasks of emotion classification and component classification.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Emotion Classifier",
      "text": "As baseline emotion classification models which are not particularly informed about components, we use two models: Emo-ME-Base is a maximum entropy (ME) classifier with TF-IDF-weighted bagof-words unigram and bigram features. As preprocessing, we convert all words to lowercase, and stem them with the PorterStemmer. On TEC, with its single-label annotation, Emo-ME-Base consists of one model, while on REMAN with multi-label annotation, we use 10 binary classifiers.\n\nOur neural baseline Emo-NN-Base uses pretrained BERT sentence embeddings 2  (Devlin et al., 2019)  as input features. Inspired by  Chen and Wang (2018) ;  Sosa (2017) , the network architecture consists of a bidirectional LSTM layer  (Hochreiter and Schmidhuber, 1997) , followed by a convolutional layer with kernel sizes 2, 3, 5, 7, 13, and 2 https://tfhub.dev/google/experts/bert/wiki books/sst2/1 25. The outputs of the convolutional layer are maxpooled over the dimension of the input sequence, inspired by  Collobert et al. (2011) . Stacked on top of the pooling layer is a fully connected layer. Its outputs are finally fed into an output layer with a sigmoid activation function (see Figure  1a ).  3 We use dropout regularization after each layer. The network uses a weighted cross-entropy loss function, whereby the loss of false negatives is multiplied by 4 to increase recall. The model is trained using an Adam optimizer  (Kingma and Ba, 2015) . All network parameters of this model and subsequent neural models are determined using a subset of the training data as development set for the RE-MAN corpus and using 10-fold cross-validation for the TEC corpus. Details of the resulting hyperparameters are listed in the Appendix.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Component Classifier",
      "text": "The emotion component classifiers predict which of the five CPM components occur in a text instance. Our Cpm-ME-Base baseline models (one for each component) only use bag-of-words features in the same configuration as Emo-ME-Base.\n\nIn the model Cpm-ME-Adv, we add taskspecific features, namely features derived from manually crafted small dictionaries with words associated with the different components. Those dictionaries were developed without considering the corpora and with inspiration from  Scherer (2005)  and contain on average 26 items. Further, we add part-of-speech tags (calculated with spaCy 4  , Honnibal et al. (  2020 )) and glove-twitter-100 embeddings 5    (Pennington et al., 2014) . Additionally, only for the cognitive appraisal component, we run the appraisal classifier developed by  Hofmann et al. (2020)  and use the predictions as features.  6  For each component individually, the best-performing combination of these features is chosen.\n\nThe Cpm-NN-Base is configured analogously to Emo-NN-Base. The primary reason for using an equivalent setup is to facilitate a multi-head architecture as joint model for both tasks in the next step.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Joint Modelling And Multi-Task Learning Of Emotions And Components",
      "text": "To analyze if emotion classification benefits from the component prediction (and partially also vice versa), we set up several model configurations.\n\nIn Emo-Cpm-ME-Pred, we predict the emotion with Cpm-ME-Adv and use these predictions as features. Other than that, Emo-Cpm-ME-Pred corresponds to Emo-ME-Base. In Emo-Cpm-ME-Gold, we replace the predictions by gold component annotations to analyze error propagation.\n\nEmo-Cpm-NN-Pred and Emo-Cpm-NN-Gold are configured analogously and follow the same architecture as Emo-NN-Base with the following differences: A binary vector with the CPM annotations is introduced as additional input feature, feeding into a fully connected layer. Its outputs are concatenated with the outputs of the penultimate layer and passed to another fully connected layer, followed by the output layer.\n\nEmo-Cpm-NN-Pred uses Cpm-NN-Base to obtain component predictions, but the weights of Cpm-NN-Base are frozen. The basic network architecture resembles that of the Emo-Cpm-NN-Gold model, replacing the additional CPM input vector with the Cpm-NN-Base model (see Figure  1b ). Its outputs are, again, fed into a fully connected layer which is connected to the output layer.\n\nNext to the models that make use of the output of the CPM classifiers for prediction, we use two multi-task learning models which predict emotions and components based on shared latent variables. For a multi-head variant (MTL-MH), the basic architectures of the individual models for both tasks remain the same. Outputs of the CNN layer are fed to two separate, task-specific, fully connected layers. This model has two output layers, one for emotion classification and one for CPM component classification. Both tasks use the weighted cross entropy loss function to increase recall.\n\nBased on the model proposed by  Misra et al. (2016) , we use cross-stitch units in our model MTL-XS. This model employs two separate parallel instances of the Cpm-NN-Base architecture introduced above, one for the CPM classification task and one for emotion classification. The model additionally employs one cross-stitch unit after the respective CNN layers. This sharing unit learns a linear combination of the pooled task-specific CNN activation maps which is then passed to the taskspecific fully connected layers. The cross-stitch unit learns during training which information to share across tasks (see Figure  1c ).",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Results",
      "text": "For our experiments, we use our reannotated subsample of TEC and REMAN (not all instances available in TEC and REMAN). We split the corpora into 90% for training and 10% to test.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Component Prediction",
      "text": "We start the discussion of the results with the component classification, a classification task that has not been addressed before and for which our data set is the first that becomes available to the research community. Table  4  shows the results. The model performances are acceptable. Macroaverage F 1 scores on REMAN range from .42 of MTL-MH to .59 for Cpm-ME-Adv, and from .53 (Cpm-ME-Base) to .57 (Cpm-NN-Base) on TEC. There are, however, differences for the components: On TEC, there are difficulties in predicting neurophysiological symptoms. The addition of taskspecific features in Cpm-ME-Adv shows a clear improvement across all components.\n\nThe neural baseline Cpm-NN-Base outperforms Cpm-ME-Adv on TEC, and does so without feature engineering. On REMAN, the feature-based model is superior which might be due to the engineered features being more commonly represented in the literature domain than in social media. This is partially leveraged in the MTL-XS model on REMAN.\n\nThe components are not equally difficult to predict; the relations between the components are comparable across models. The lowest performance scores are observed for neurophysiological symptoms. This holds across models and corpora. For the neurophysiological component on the literature domain, however, the engineered features in Cpm-ME-Adv show substantial improvement, yielding an F 1 score of 0.44. Cognitive appraisal shows best prediction performances, with F 1 between .73 and .86. For TEC, we observe a correlation between performance and class size for all components.\n\nFor REMAN, Cpm-ME-Adv is the bestperforming model. Cpm-ME-Adv's macro average F 1 of 0.59 is 9pp higher than the second best F 1score. For TEC, the best results are achieved by Cpm-NN-Base with a macro F 1 of 0.57.",
      "page_start": 7,
      "page_end": 8
    },
    {
      "section_name": "Emotion Classification",
      "text": "In this section, we discuss the performance of our emotion classification models across different configurations. One question is how providing component information to them helps most. Table  5  shows the results for all experiments.\n\nThe comparison of Emo-ME-Base and Emo-NN-Base reveals that a pure word-based model is not able to categorize emotions in REMAN, due to the imbalancedness in this multilabel classification setup. This observation is in line with previous results  (Kim and Klinger, 2018) . The use of BERT's contextualized sentence embeddings leads to a strong improvement of 43pp (against a 0 F 1 for Emo-ME-Base). The performance of the ME models is comparably limited also on TEC, though this is less obvious on the micro-averaged F 1 due to the imbalancedness of the resource (.35 macro, .54 micro F 1 ).\n\nOur main research question is if emotion components help emotion classification. In our first attempt to include this information as features, we see some improvement. On REMAN, Emo-Cpm-ME-Pred \"boosts\" from 0 to 6 F 1 , on TEC we  observe an improvement by 1pp, to .55 F 1 . The inclusion of predicted component information as features in the neural network model shows no improvement on REMAN or on TEC.\n\nTo answer the question if this limited improvement is only due to a limited performance of the component classification model, we compare these results to a setting, in which the predicted values are replaced by gold labels from the annotation. This setup does show an improvement with Emo-Cpm-ME-Gold to .14 F 1 on REMAN, which is obviously still very low; and no improvement on TEC. However, with our neural model Emo-Cpm-NN-Gold, we see the potential of gold information increasing the score for emotion classification to .45 F 1 on REMAN and .62 F 1 on TEC.\n\nThis is an unrealistic setting -the classifier does not have access to annotated labels in real world applications. However, in the (realistic) crossstitch multi-task learning setting of MTL-XS, we observe further improvements: On REMAN, we achieve .47 F 1 (which is even slightly higher than with gold component labels), which constitutes an achieved improvement by 4pp to the emotion classifier which is not informed about components. On TEC, we achieve .61 F 1 , which is close to the model that has access to gold components (.62). This is an improvement of 4pp as well in comparison to the model that has no access to components but follows the same architecture.\n\nParticularly, we observe that models with component information perform better across all emotions, with the exception of surprise on the REMAN corpus and anger on the TEC corpus. We can therefore conclude that emotion component information does contribute to emotion classification; the bestperforming combination is via a cross-stitch model.\n\nA detailed discussion based on example predictions of the various models is available in the Appendix.",
      "page_start": 7,
      "page_end": 8
    },
    {
      "section_name": "Conclusion And Future Work",
      "text": "We presented the first data sets (based on existing emotion corpora) with emotion component annotation.  While Hofmann et al. (2020)  has proposed to use the cognitive appraisal for emotion classification, they did not succeed to present models that actually benefit in emotion classification performance. That might be due to the fact that cognitive appraisal classification itself is challenging, and that they did not compare multiple multi-task learning approaches.\n\nWith this paper we moved to another psychological theory, namely the emotion component process model, and make the first annotations available that closely follow this theory. Based on this resource, we have shown that, even with a comparably limited data set size, emotion components contribute to emotion classification. We expect that with a larger corpus the improvement would be more substantial than it is already now. A manual introspection of the data instances also shows that the components indeed help. Further, we have seen that emotions are communicated quite differently in the two domains, which is an explanation why emotion classification systems (up-to-today) need to be developed particularly for domains of interest. We propose that future work analyzes further which information is relevant and should be shared across these tasks in multi-task learning models.\n\nFurther, we propose that larger corpora should be created across more domains, and also that multitask learning is not only performed individually, but also across corpora. Presumably, the component information in different domains is not the same, but might be helpful across them.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Ethical Considerations",
      "text": "We did not collect a new data set from individuals, but did reannotate existing and publicly available resources. Therefore, this paper does not pose ethical questions regarding data collection.\n\nHowever, emotion analysis has the principled potential to be misused, and researchers need to be aware that their findings (though they are not in themselves harmful) might lead to software that can do harm. We assume that sentiment and emotion analysis are sufficiently well-known that users of social media might be aware that their data could be automatically analyzed. However, we propose that no automatic system ever does report back analyses of individuals and instead does aggregate data of anonymized posts. We do not assume that analyzing literature data poses any risk.\n\nOne aspect of our work we would like to point out is that, in contrast to other and previous emotion analysis research, we focus and enable particularly the analysis of implicit (and perhaps even unconcious) communication of emotions. That might further mean that authors of posts in social media are not aware that their emotional state could be computationally analyzed, potentially, they are not even fully aware of their own affective state. We would like to point out that automatically analyzing social media data without the explicit consent of the users is unethical at least when the user can be identified or identify themselves, particularly if they might not be aware of the details of an analysis system.\n\n(1) As for the hero of this story, 'His One Fault' was absent-mindedness. He forgot to lock his uncle's stable door, and the horse was stolen. In seeking to recover the stolen horse, he unintentionally stole another.",
      "page_start": 9,
      "page_end": 13
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Neural Model Architectures (subset)",
      "page": 5
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "ims.uni-stuttgart.de/data/emotion.": ""
        },
        {
          "ims.uni-stuttgart.de/data/emotion.": "1\nIntroduction"
        },
        {
          "ims.uni-stuttgart.de/data/emotion.": "The task of emotion classiﬁcation from written text"
        },
        {
          "ims.uni-stuttgart.de/data/emotion.": "is to map textual units, like documents, paragraphs,"
        },
        {
          "ims.uni-stuttgart.de/data/emotion.": "or sentences, to a predeﬁned set of emotions. Com-"
        },
        {
          "ims.uni-stuttgart.de/data/emotion.": "mon class inventories rely on psychological"
        },
        {
          "ims.uni-stuttgart.de/data/emotion.": "ories\nsuch as"
        },
        {
          "ims.uni-stuttgart.de/data/emotion.": ""
        },
        {
          "ims.uni-stuttgart.de/data/emotion.": "(anger, disgust,\nfear,\njoy,\nsadness,"
        },
        {
          "ims.uni-stuttgart.de/data/emotion.": "∗The ﬁrst two authors contributed equally to this work."
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "Plutchik (2001). Often, emotion classiﬁcation is"
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "tackled as an end-to-end learning task, potentially"
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": ""
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "informed by lexical\nresources (see the SemEval"
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": ""
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "Shared Task 1 on Affect in Tweets for an overview"
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": ""
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "of recent approaches (Mohammad et al., 2018))."
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": ""
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "While end-to-end learning and ﬁne-tuning of pre-"
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": ""
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "trained models for classiﬁcation have shown great"
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": ""
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "performance improvements in contrast\nto purely"
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": ""
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "feature-based methods, such approaches typically"
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": ""
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "neglect the existing knowledge about emotions in"
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": ""
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "psychology (which might help in classiﬁcation and"
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": ""
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "to better understand how emotions are communi-"
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "cated). There are only very few approaches that"
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "aim at combining psychological theories (beyond"
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": ""
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "basic emotion categories) with emotion classiﬁca-"
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": ""
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "tion models: We are only aware of\nthe work by"
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": ""
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "Hofmann et al. (2020), who incorporate the cogni-"
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": ""
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "tive appraisal of events, and Buechel et al. (2020),"
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": ""
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "who jointly learn affect (valence, arousal) and emo-"
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": ""
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "tion classes; next to knowledge-base-oriented mod-"
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "elling of events by Balahur et al. (2012) and Cam-"
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": ""
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "bria et al. (2014)."
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": ""
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "An interesting and attractive theory for computa-"
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": ""
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "tional modelling of emotions that has not been used"
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": ""
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "in natural language processing yet is the emotion"
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": ""
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "component process model (Scherer, 2005, CPM)."
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": ""
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "This model states that emotions are a coordinated"
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "process\nin ﬁve subsystems,\nfollowing an event"
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": ""
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "that is relevant for the experiencer of the emotion,"
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": ""
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "namely a motivational action tendency,\nthe mo-"
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "tor expression component, a neurophysiological,"
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "bodily symptom, the subjective feeling, and the cog-"
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "nitive appraisal. The cognitive appraisal has been"
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": ""
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "explored in a ﬁne-grained manner by Hofmann et al."
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": ""
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "(2020), mentioned above. The subjective feeling"
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": ""
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "component is related to the dimensions of affect.1"
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": ""
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "1There exists other work that has been motivated by ap-"
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "praisal\ntheories, but\nthat\nis either rule-based (Shaikh et al.,"
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": ""
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "2009; Udochukwu and He, 2015) or does not explicitly model"
        },
        {
          "{ﬁrstname.lastname}@ims.uni-stuttgart.de": "appraisal or component dimensions\n(Balahur et al., 2012;"
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "We hypothesize (and subsequently analyze) that": "emotions in text are communicated in a variety of",
          "emotions constitutes one of the most popular emo-": "tion sets in natural\nlanguage processing. Yet\nit"
        },
        {
          "We hypothesize (and subsequently analyze) that": "ways, and that\nthese different stylistic means fol-",
          "emotions constitutes one of the most popular emo-": "might be doubted if this set is sufﬁcient. Plutchik"
        },
        {
          "We hypothesize (and subsequently analyze) that": "low the emotion component process model. The",
          "emotions constitutes one of the most popular emo-": "(2001) proposed a model with eight main emotions,"
        },
        {
          "We hypothesize (and subsequently analyze) that": "communication of emotions can either be an ex-",
          "emotions constitutes one of the most popular emo-": "visualized on a colored wheel.\nIn this visualiza-"
        },
        {
          "We hypothesize (and subsequently analyze) that": "plicit mention of the emotion name (“I am angry”),",
          "emotions constitutes one of the most popular emo-": "tion, opposites and distance of emotion names are"
        },
        {
          "We hypothesize (and subsequently analyze) that": "focus on the motivational aspect (“He wanted to",
          "emotions constitutes one of the most popular emo-": "supposed to correspond to their respective relation."
        },
        {
          "We hypothesize (and subsequently analyze) that": "run away.”), describe the expression (“She smiled.”,",
          "emotions constitutes one of the most popular emo-": ""
        },
        {
          "We hypothesize (and subsequently analyze) that": "",
          "emotions constitutes one of the most popular emo-": "A complementary approach to categorizing emo-"
        },
        {
          "We hypothesize (and subsequently analyze) that": "“He shouted.”) or a physiological bodily reaction",
          "emotions constitutes one of the most popular emo-": ""
        },
        {
          "We hypothesize (and subsequently analyze) that": "",
          "emotions constitutes one of the most popular emo-": "tions in discrete sets is advocated by Russell and"
        },
        {
          "We hypothesize (and subsequently analyze) that": "(“she was trembling”, “a tear was running down his",
          "emotions constitutes one of the most popular emo-": ""
        },
        {
          "We hypothesize (and subsequently analyze) that": "",
          "emotions constitutes one of the most popular emo-": "Mehrabian (1977). Their dimensional affect model"
        },
        {
          "We hypothesize (and subsequently analyze) that": "face”), the subjective feeling (“I felt so bad.”), or, ﬁ-",
          "emotions constitutes one of the most popular emo-": ""
        },
        {
          "We hypothesize (and subsequently analyze) that": "",
          "emotions constitutes one of the most popular emo-": "corresponds to a 3-dimensional vector space with"
        },
        {
          "We hypothesize (and subsequently analyze) that": "nally, describe a cognitive appraisal (“I wasn’t sure",
          "emotions constitutes one of the most popular emo-": ""
        },
        {
          "We hypothesize (and subsequently analyze) that": "",
          "emotions constitutes one of the most popular emo-": "dimensions\nfor pleasure-displeasure,\nthe degree"
        },
        {
          "We hypothesize (and subsequently analyze) that": "what was happening.”, “I am not responsible.”).",
          "emotions constitutes one of the most popular emo-": ""
        },
        {
          "We hypothesize (and subsequently analyze) that": "",
          "emotions constitutes one of the most popular emo-": "of arousal, and dominance-submissiveness (VAD)."
        },
        {
          "We hypothesize (and subsequently analyze) that": "With this paper, we study how emotions are com-",
          "emotions constitutes one of the most popular emo-": ""
        },
        {
          "We hypothesize (and subsequently analyze) that": "",
          "emotions constitutes one of the most popular emo-": "Emotion categories correspond to points in this"
        },
        {
          "We hypothesize (and subsequently analyze) that": "municated (following the component model)\nin",
          "emotions constitutes one of the most popular emo-": ""
        },
        {
          "We hypothesize (and subsequently analyze) that": "",
          "emotions constitutes one of the most popular emo-": "vector space. A more expressive alternative to the"
        },
        {
          "We hypothesize (and subsequently analyze) that": "Tweets (based on the Twitter Emotion Corpus TEC,",
          "emotions constitutes one of the most popular emo-": ""
        },
        {
          "We hypothesize (and subsequently analyze) that": "",
          "emotions constitutes one of the most popular emo-": "VAD model of affect\nis motivated by the cogni-"
        },
        {
          "We hypothesize (and subsequently analyze) that": "by Mohammad (2012)) and literature (based on",
          "emotions constitutes one of the most popular emo-": ""
        },
        {
          "We hypothesize (and subsequently analyze) that": "",
          "emotions constitutes one of the most popular emo-": "tive appraisal process that is part of emotions. The"
        },
        {
          "We hypothesize (and subsequently analyze) that": "the REMAN corpus by Kim and Klinger (2018)).",
          "emotions constitutes one of the most popular emo-": ""
        },
        {
          "We hypothesize (and subsequently analyze) that": "",
          "emotions constitutes one of the most popular emo-": "model of Smith and Ellsworth (1985) introduces"
        },
        {
          "We hypothesize (and subsequently analyze) that": "We post-annotate a subset of 3041 instances with",
          "emotions constitutes one of the most popular emo-": ""
        },
        {
          "We hypothesize (and subsequently analyze) that": "",
          "emotions constitutes one of the most popular emo-": "a set of variables that\nthey map to the principle"
        },
        {
          "We hypothesize (and subsequently analyze) that": "the use of emotion component-based emotion com-",
          "emotions constitutes one of the most popular emo-": ""
        },
        {
          "We hypothesize (and subsequently analyze) that": "",
          "emotions constitutes one of the most popular emo-": "components of pleasantness, responsibility/control,"
        },
        {
          "We hypothesize (and subsequently analyze) that": "munication categories, analyze this corpus, and",
          "emotions constitutes one of the most popular emo-": ""
        },
        {
          "We hypothesize (and subsequently analyze) that": "",
          "emotions constitutes one of the most popular emo-": "certainty, attention, effort, and situational control."
        },
        {
          "We hypothesize (and subsequently analyze) that": "perform joint modelling/multi-task learning ex-",
          "emotions constitutes one of the most popular emo-": ""
        },
        {
          "We hypothesize (and subsequently analyze) that": "",
          "emotions constitutes one of the most popular emo-": "They show that these dimensions are more power-"
        },
        {
          "We hypothesize (and subsequently analyze) that": "periments. Our\nresearch goals are (1)\nto under-",
          "emotions constitutes one of the most popular emo-": ""
        },
        {
          "We hypothesize (and subsequently analyze) that": "",
          "emotions constitutes one of the most popular emo-": "ful to distinguish emotion categories than VAD."
        },
        {
          "We hypothesize (and subsequently analyze) that": "stand if emotion components are distributed simi-",
          "emotions constitutes one of the most popular emo-": ""
        },
        {
          "We hypothesize (and subsequently analyze) that": "larly across emotion categories and domains, and",
          "emotions constitutes one of the most popular emo-": "Appraisals are also part of the emotion compo-"
        },
        {
          "We hypothesize (and subsequently analyze) that": "(2) to evaluate if informing an emotion classiﬁer",
          "emotions constitutes one of the most popular emo-": "nent process model by Scherer (2005), which is"
        },
        {
          "We hypothesize (and subsequently analyze) that": "about emotion components improves their perfor-",
          "emotions constitutes one of the most popular emo-": "central to this paper. The ﬁve components are cog-"
        },
        {
          "We hypothesize (and subsequently analyze) that": "mance (and to evaluate various classiﬁcation ap-",
          "emotions constitutes one of the most popular emo-": "nitive appraisal, neurophysiological bodily symp-"
        },
        {
          "We hypothesize (and subsequently analyze) that": "proaches). We ﬁnd that emotion component and",
          "emotions constitutes one of the most popular emo-": "toms, motor expressions, motivational action ten-"
        },
        {
          "We hypothesize (and subsequently analyze) that": "",
          "emotions constitutes one of the most popular emo-": "Cognitive ap-\ndencies,\nand subjective feelings."
        },
        {
          "We hypothesize (and subsequently analyze) that": "emotion classiﬁcation prediction interact and bene-",
          "emotions constitutes one of the most popular emo-": ""
        },
        {
          "We hypothesize (and subsequently analyze) that": "ﬁt from each other and that emotions are communi-",
          "emotions constitutes one of the most popular emo-": "praisal is concerned with the evaluation of an event."
        },
        {
          "We hypothesize (and subsequently analyze) that": "cated by means of various components in literature",
          "emotions constitutes one of the most popular emo-": "The event is assessed regarding its relevance to the"
        },
        {
          "We hypothesize (and subsequently analyze) that": "and social media. The corpus is available at https:",
          "emotions constitutes one of the most popular emo-": "individual,\nthe implications and consequences it"
        },
        {
          "We hypothesize (and subsequently analyze) that": "//www.ims.uni-stuttgart.de/data/emotion.",
          "emotions constitutes one of the most popular emo-": "might lead to, the possible ways to cope with it and"
        },
        {
          "We hypothesize (and subsequently analyze) that": "",
          "emotions constitutes one of the most popular emo-": "control it, and its signiﬁcance according to personal"
        },
        {
          "We hypothesize (and subsequently analyze) that": "2\nBackground and Related Work",
          "emotions constitutes one of the most popular emo-": "values and social norms. The component of neu-"
        },
        {
          "We hypothesize (and subsequently analyze) that": "",
          "emotions constitutes one of the most popular emo-": "rophysiological symptoms regards automatically"
        },
        {
          "We hypothesize (and subsequently analyze) that": "2.1\nEmotion Models",
          "emotions constitutes one of the most popular emo-": ""
        },
        {
          "We hypothesize (and subsequently analyze) that": "",
          "emotions constitutes one of the most popular emo-": "activated reactions and symptoms of the body, like"
        },
        {
          "We hypothesize (and subsequently analyze) that": "Emotion models can be separated into those that",
          "emotions constitutes one of the most popular emo-": ""
        },
        {
          "We hypothesize (and subsequently analyze) that": "",
          "emotions constitutes one of the most popular emo-": "changes in the heartbeat or breathing pattern. The"
        },
        {
          "We hypothesize (and subsequently analyze) that": "consider a discrete set of categories or those that",
          "emotions constitutes one of the most popular emo-": ""
        },
        {
          "We hypothesize (and subsequently analyze) that": "",
          "emotions constitutes one of the most popular emo-": "motor expression component contains all move-"
        },
        {
          "We hypothesize (and subsequently analyze) that": "focus on underlying principles like affect.\nThe",
          "emotions constitutes one of the most popular emo-": ""
        },
        {
          "We hypothesize (and subsequently analyze) that": "",
          "emotions constitutes one of the most popular emo-": "ments, facial expressions, changes concerning the"
        },
        {
          "We hypothesize (and subsequently analyze) that": "model of basic emotions by Ekman (1992) consid-",
          "emotions constitutes one of the most popular emo-": ""
        },
        {
          "We hypothesize (and subsequently analyze) that": "",
          "emotions constitutes one of the most popular emo-": "speech, and similar patterns. Actions like attention"
        },
        {
          "We hypothesize (and subsequently analyze) that": "ers anger, disgust, fear, joy, sadness, and surprise.",
          "emotions constitutes one of the most popular emo-": ""
        },
        {
          "We hypothesize (and subsequently analyze) that": "",
          "emotions constitutes one of the most popular emo-": "shifts and movement with respect\nto the position"
        },
        {
          "We hypothesize (and subsequently analyze) that": "According to his work,\nthere are nine character-",
          "emotions constitutes one of the most popular emo-": ""
        },
        {
          "We hypothesize (and subsequently analyze) that": "",
          "emotions constitutes one of the most popular emo-": "of\nthe event are part of\nthe motivational action"
        },
        {
          "We hypothesize (and subsequently analyze) that": "istics that a basic emotion fulﬁlls: These are (1)",
          "emotions constitutes one of the most popular emo-": ""
        },
        {
          "We hypothesize (and subsequently analyze) that": "",
          "emotions constitutes one of the most popular emo-": "tendencies component. Finally, the component of"
        },
        {
          "We hypothesize (and subsequently analyze) that": "distinctive universal signals, (2) presence in other",
          "emotions constitutes one of the most popular emo-": ""
        },
        {
          "We hypothesize (and subsequently analyze) that": "",
          "emotions constitutes one of the most popular emo-": "subjective feelings takes into account how strong,"
        },
        {
          "We hypothesize (and subsequently analyze) that": "primates,\n(3) distinctive physiology,\n(4) distinc-",
          "emotions constitutes one of the most popular emo-": ""
        },
        {
          "We hypothesize (and subsequently analyze) that": "",
          "emotions constitutes one of the most popular emo-": "important, and persisting the felt sensations are."
        },
        {
          "We hypothesize (and subsequently analyze) that": "tive universals in antecedent events, (5) coherence",
          "emotions constitutes one of the most popular emo-": ""
        },
        {
          "We hypothesize (and subsequently analyze) that": "",
          "emotions constitutes one of the most popular emo-": "Scherer (2005) argues that\nit\nis possible to infer"
        },
        {
          "We hypothesize (and subsequently analyze) that": "among emotional\nresponse,\n(6) quick onset,\n(7)",
          "emotions constitutes one of the most popular emo-": ""
        },
        {
          "We hypothesize (and subsequently analyze) that": "",
          "emotions constitutes one of the most popular emo-": "the emotion a person is experiencing by analyzing"
        },
        {
          "We hypothesize (and subsequently analyze) that": "brief duration, (8) automatic appraisal, and (9) un-",
          "emotions constitutes one of the most popular emo-": ""
        },
        {
          "We hypothesize (and subsequently analyze) that": "",
          "emotions constitutes one of the most popular emo-": "the set of changes in the ﬁve components. Scherer"
        },
        {
          "We hypothesize (and subsequently analyze) that": "bidden occurrence. His model of the six universal",
          "emotions constitutes one of the most popular emo-": ""
        },
        {
          "We hypothesize (and subsequently analyze) that": "",
          "emotions constitutes one of the most popular emo-": "(2009) also points out that computational models"
        },
        {
          "We hypothesize (and subsequently analyze) that": "Rashkin et al., 2018).",
          "emotions constitutes one of the most popular emo-": "must not ignore emotion components."
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "2.2\nEmotion Analysis in Text": "The majority of modelling approaches\nfocuses",
          "3\nCorpus Annotation": "3.1\nCorpus Selection"
        },
        {
          "2.2\nEmotion Analysis in Text": "on the analysis of fundamental emotions (see Al-",
          "3\nCorpus Annotation": ""
        },
        {
          "2.2\nEmotion Analysis in Text": "",
          "3\nCorpus Annotation": "To study the relation between emotion components"
        },
        {
          "2.2\nEmotion Analysis in Text": "swaidan and Menai, 2020; Mohammad et al., 2018;",
          "3\nCorpus Annotation": ""
        },
        {
          "2.2\nEmotion Analysis in Text": "",
          "3\nCorpus Annotation": "and emotions, we annotate subsets from two dif-"
        },
        {
          "2.2\nEmotion Analysis in Text": "Bostan and Klinger, 2018) or on the recognition",
          "3\nCorpus Annotation": ""
        },
        {
          "2.2\nEmotion Analysis in Text": "",
          "3\nCorpus Annotation": "ferent existing emotion corpora from two different"
        },
        {
          "2.2\nEmotion Analysis in Text": "of valence, arousal, and dominance (Buechel and",
          "3\nCorpus Annotation": ""
        },
        {
          "2.2\nEmotion Analysis in Text": "",
          "3\nCorpus Annotation": "domains, namely literature and social media."
        },
        {
          "2.2\nEmotion Analysis in Text": "Hahn, 2017). Work with a focus on other aspects",
          "3\nCorpus Annotation": ""
        },
        {
          "2.2\nEmotion Analysis in Text": "",
          "3\nCorpus Annotation": "For literature, we use the REMAN corpus (Kim"
        },
        {
          "2.2\nEmotion Analysis in Text": "of emotions is scarce.",
          "3\nCorpus Annotation": ""
        },
        {
          "2.2\nEmotion Analysis in Text": "",
          "3\nCorpus Annotation": "and Klinger, 2018), which consists of ﬁction writ-"
        },
        {
          "2.2\nEmotion Analysis in Text": "Noteworthy, though this has not been a computa-",
          "3\nCorpus Annotation": ""
        },
        {
          "2.2\nEmotion Analysis in Text": "",
          "3\nCorpus Annotation": "ten after the year 1800.\nIt\nis manually annotated"
        },
        {
          "2.2\nEmotion Analysis in Text": "tional study, is the motivation of the ISEAR project",
          "3\nCorpus Annotation": ""
        },
        {
          "2.2\nEmotion Analysis in Text": "",
          "3\nCorpus Annotation": "with text spans related to emotions, as well as their"
        },
        {
          "2.2\nEmotion Analysis in Text": "(Scherer and Wallbott, 1994), from which a textual",
          "3\nCorpus Annotation": ""
        },
        {
          "2.2\nEmotion Analysis in Text": "",
          "3\nCorpus Annotation": "experiencers, causes, and targets.\nEmotion cue"
        },
        {
          "2.2\nEmotion Analysis in Text": "corpus originated, which is frequently used in NLP.",
          "3\nCorpus Annotation": ""
        },
        {
          "2.2\nEmotion Analysis in Text": "",
          "3\nCorpus Annotation": "spans are annotated with the emotions of anger,"
        },
        {
          "2.2\nEmotion Analysis in Text": "It consists of event descriptions and is therefore",
          "3\nCorpus Annotation": ""
        },
        {
          "2.2\nEmotion Analysis in Text": "",
          "3\nCorpus Annotation": "fear,\ntrust, disgust,\njoy, sadness, surprise, and an-"
        },
        {
          "2.2\nEmotion Analysis in Text": "relevant for appraisal theories. Further, participants",
          "3\nCorpus Annotation": ""
        },
        {
          "2.2\nEmotion Analysis in Text": "",
          "3\nCorpus Annotation": "ticipation, as well as ‘other emotion’.\nFrom the"
        },
        {
          "2.2\nEmotion Analysis in Text": "in that study have not only been asked to report on",
          "3\nCorpus Annotation": ""
        },
        {
          "2.2\nEmotion Analysis in Text": "",
          "3\nCorpus Annotation": "1720 instances, we randomly sample a subset of"
        },
        {
          "2.2\nEmotion Analysis in Text": "events they experienced, but\nthey also report ad-",
          "3\nCorpus Annotation": ""
        },
        {
          "2.2\nEmotion Analysis in Text": "",
          "3\nCorpus Annotation": "1000. Each instance comprises a sentence triple"
        },
        {
          "2.2\nEmotion Analysis in Text": "ditional aspects, including the existence of bodily",
          "3\nCorpus Annotation": ""
        },
        {
          "2.2\nEmotion Analysis in Text": "",
          "3\nCorpus Annotation": "and may contain any number of annotated spans."
        },
        {
          "2.2\nEmotion Analysis in Text": "reactions. However, their work does not focus on",
          "3\nCorpus Annotation": ""
        },
        {
          "2.2\nEmotion Analysis in Text": "",
          "3\nCorpus Annotation": "We map the emotions associated to spans to the text"
        },
        {
          "2.2\nEmotion Analysis in Text": "the linguistic realization of emotion components,",
          "3\nCorpus Annotation": ""
        },
        {
          "2.2\nEmotion Analysis in Text": "",
          "3\nCorpus Annotation": "instances as the union of all labels, which leads to"
        },
        {
          "2.2\nEmotion Analysis in Text": "but on the existence in the described event.",
          "3\nCorpus Annotation": ""
        },
        {
          "2.2\nEmotion Analysis in Text": "",
          "3\nCorpus Annotation": "a multi-label classiﬁcation task. Instances without"
        },
        {
          "2.2\nEmotion Analysis in Text": "Similarly, Troiano et al.\n(2019) asked crowd-",
          "3\nCorpus Annotation": ""
        },
        {
          "2.2\nEmotion Analysis in Text": "",
          "3\nCorpus Annotation": "emotion annotations are considered ‘neutral’."
        },
        {
          "2.2\nEmotion Analysis in Text": "workers to report on events that caused an emotion.",
          "3\nCorpus Annotation": ""
        },
        {
          "2.2\nEmotion Analysis in Text": "",
          "3\nCorpus Annotation": "For the social media domain, we choose the Twit-"
        },
        {
          "2.2\nEmotion Analysis in Text": "This resource has then been postannotated with ap-",
          "3\nCorpus Annotation": ""
        },
        {
          "2.2\nEmotion Analysis in Text": "",
          "3\nCorpus Annotation": "ter Emotion Corpus (TEC)\n(Mohammad, 2012)."
        },
        {
          "2.2\nEmotion Analysis in Text": "praisal dimensions (Hofmann et al., 2020). This is",
          "3\nCorpus Annotation": ""
        },
        {
          "2.2\nEmotion Analysis in Text": "",
          "3\nCorpus Annotation": "The emotion categories are anger, disgust, fear, joy,"
        },
        {
          "2.2\nEmotion Analysis in Text": "the only recent work we are aware of that models",
          "3\nCorpus Annotation": ""
        },
        {
          "2.2\nEmotion Analysis in Text": "",
          "3\nCorpus Annotation": "sadness, and surprise. TEC consists of approxi-"
        },
        {
          "2.2\nEmotion Analysis in Text": "appraisal as a component of the CPM to predict",
          "3\nCorpus Annotation": ""
        },
        {
          "2.2\nEmotion Analysis in Text": "",
          "3\nCorpus Annotation": "mately 21,000 posts from Twitter that have a hash-"
        },
        {
          "2.2\nEmotion Analysis in Text": "emotion categories, next to the rule-based classiﬁ-",
          "3\nCorpus Annotation": ""
        },
        {
          "2.2\nEmotion Analysis in Text": "",
          "3\nCorpus Annotation": "tag at the end which states one of the six mentioned"
        },
        {
          "2.2\nEmotion Analysis in Text": "cation approach by Shaikh et al. (2009), who built",
          "3\nCorpus Annotation": ""
        },
        {
          "2.2\nEmotion Analysis in Text": "",
          "3\nCorpus Annotation": "emotions. According to the authors, the validity of"
        },
        {
          "2.2\nEmotion Analysis in Text": "on top of the work by Clore and Ortony (2013). An-",
          "3\nCorpus Annotation": ""
        },
        {
          "2.2\nEmotion Analysis in Text": "",
          "3\nCorpus Annotation": "hashtags as classiﬁcation labels is commensurable"
        },
        {
          "2.2\nEmotion Analysis in Text": "other noteworthy related work is SenticNet, which",
          "3\nCorpus Annotation": ""
        },
        {
          "2.2\nEmotion Analysis in Text": "",
          "3\nCorpus Annotation": "to the inter-annotator agreements of human anno-"
        },
        {
          "2.2\nEmotion Analysis in Text": "models event properties including people’s goals,",
          "3\nCorpus Annotation": ""
        },
        {
          "2.2\nEmotion Analysis in Text": "",
          "3\nCorpus Annotation": "tators. We randomly sample 2041 instances with"
        },
        {
          "2.2\nEmotion Analysis in Text": "for sentiment analysis (Cambria et al., 2014).",
          "3\nCorpus Annotation": ""
        },
        {
          "2.2\nEmotion Analysis in Text": "",
          "3\nCorpus Annotation": "the emotion hashtags as labels for the creation of"
        },
        {
          "2.2\nEmotion Analysis in Text": "The only work we are aware of that studies emo-",
          "3\nCorpus Annotation": "our corpus. Each instance equals one post and has"
        },
        {
          "2.2\nEmotion Analysis in Text": "tion components (though not following the CPM,",
          "3\nCorpus Annotation": "exactly one emotion label."
        },
        {
          "2.2\nEmotion Analysis in Text": "and without computational modelling), is the cor-",
          "3\nCorpus Annotation": ""
        },
        {
          "2.2\nEmotion Analysis in Text": "",
          "3\nCorpus Annotation": "3.2\nAnnotation Procedure and"
        },
        {
          "2.2\nEmotion Analysis in Text": "pus study by Kim and Klinger (2019). They ana-",
          "3\nCorpus Annotation": ""
        },
        {
          "2.2\nEmotion Analysis in Text": "",
          "3\nCorpus Annotation": "Inter-Annotator Agreement"
        },
        {
          "2.2\nEmotion Analysis in Text": "lyze if emotions in fan ﬁction are communicated",
          "3\nCorpus Annotation": ""
        },
        {
          "2.2\nEmotion Analysis in Text": "via facial descriptions, body posture descriptions,",
          "3\nCorpus Annotation": "We annotate the emotion component dimensions in-"
        },
        {
          "2.2\nEmotion Analysis in Text": "the appearance,\nlook, voice, gestures, subjective",
          "3\nCorpus Annotation": "dependently: The existence of a CPM label means"
        },
        {
          "2.2\nEmotion Analysis in Text": "sensations, or spatial relations of characters. This",
          "3\nCorpus Annotation": "that this component is mentioned somewhere in the"
        },
        {
          "2.2\nEmotion Analysis in Text": "set of variables is not the same as emotion compo-",
          "3\nCorpus Annotation": "text,\nindependent of its function to communicate"
        },
        {
          "2.2\nEmotion Analysis in Text": "nents, however, it is related. They ﬁnd that some",
          "3\nCorpus Annotation": "one of the emotions. This is a simpliﬁcation due"
        },
        {
          "2.2\nEmotion Analysis in Text": "emotions are preferred to be described with partic-",
          "3\nCorpus Annotation": "to the fact that it turned out to be difﬁcult to infer"
        },
        {
          "2.2\nEmotion Analysis in Text": "ular aspects by authors. Their work was motivated",
          "3\nCorpus Annotation": "from the limited context of an instance if an emo-"
        },
        {
          "2.2\nEmotion Analysis in Text": "by the linguistic study of van Meel (1995).",
          "3\nCorpus Annotation": "tion category and an emotion component mention"
        },
        {
          "2.2\nEmotion Analysis in Text": "In contrast to their work, our study compares two",
          "3\nCorpus Annotation": "are actually in relation. Further, this procedure also"
        },
        {
          "2.2\nEmotion Analysis in Text": "different domains (Tweets and Literature), and fol-",
          "3\nCorpus Annotation": "ensures that there is no information leak introduced"
        },
        {
          "2.2\nEmotion Analysis in Text": "lows the emotion component process model more",
          "3\nCorpus Annotation": "in the annotation process (e.g.,\nthat components"
        },
        {
          "2.2\nEmotion Analysis in Text": "strictly. Further, we show the use of that model",
          "3\nCorpus Annotation": "are only annotated if they indeed inform the emo-"
        },
        {
          "2.2\nEmotion Analysis in Text": "for computational emotion classiﬁcation through",
          "3\nCorpus Annotation": "tion, and that a model could learn from its sheer"
        },
        {
          "2.2\nEmotion Analysis in Text": "multi-task learning.",
          "3\nCorpus Annotation": "presence)."
        }
      ],
      "page": 3
    },
    {
      "caption": "Table 2: Inter-annotator agreement after the different it was actually pretty cool.’” should (this aspect",
      "data": [
        {
          "Component": "Cognitive appraisal",
          "Explanation of Example": "evaluation of the pleasantness of an event.",
          "Example": "Thinks that @melbahughes had a great 50th birth-"
        },
        {
          "Component": "",
          "Explanation of Example": "",
          "Example": "day party"
        },
        {
          "Component": "Neurophysiol. symptoms",
          "Explanation of Example": "change in someone’s heartbeat.",
          "Example": "Loves when a song makes your heart race [...]"
        },
        {
          "Component": "Motiv. Action tendencies",
          "Explanation of Example": "urge to attack a person or object.",
          "Example": "sometimes when i think bout you i want to beat the"
        },
        {
          "Component": "",
          "Explanation of Example": "",
          "Example": "shit out of your face so everyone can see how ugly"
        },
        {
          "Component": "",
          "Explanation of Example": "",
          "Example": "you are inside and out"
        },
        {
          "Component": "Motor expressions",
          "Explanation of Example": "facial expression.",
          "Example": "@TheBodyShopUK when I walk in the room and"
        },
        {
          "Component": "",
          "Explanation of Example": "",
          "Example": "my 9month old nephew recognises me and his face"
        },
        {
          "Component": "",
          "Explanation of Example": "",
          "Example": "lights up with the biggest smile thats 100%"
        },
        {
          "Component": "Subjective feelings",
          "Explanation of Example": "internal feeling state.",
          "Example": "Feelin a bit sad tonight"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table 2: Inter-annotator agreement after the different it was actually pretty cool.’” should (this aspect",
      "data": [
        {
          "Neurophysiological symptoms\n0.459": "",
          "–": ""
        },
        {
          "Neurophysiological symptoms\n0.459": "Motiv. Action tendencies\n0.444",
          "–": "0.732"
        },
        {
          "Neurophysiological symptoms\n0.459": "",
          "–": ""
        },
        {
          "Neurophysiological symptoms\n0.459": "Motor expressions\n0.643",
          "–": "0.617"
        },
        {
          "Neurophysiological symptoms\n0.459": "Subjective feelings\n0.733",
          "–": "0.793"
        },
        {
          "Neurophysiological symptoms\n0.459": "",
          "–": ""
        },
        {
          "Neurophysiological symptoms\n0.459": "Table 2:\nInter-annotator agreement after",
          "–": "the different"
        },
        {
          "Neurophysiological symptoms\n0.459": "",
          "–": ""
        },
        {
          "Neurophysiological symptoms\n0.459": "annotation rounds during the guideline creation process",
          "–": ""
        },
        {
          "Neurophysiological symptoms\n0.459": "",
          "–": ""
        },
        {
          "Neurophysiological symptoms\n0.459": "measured with Cohen’s κ.",
          "–": "In the second round, no an-"
        },
        {
          "Neurophysiological symptoms\n0.459": "",
          "–": ""
        },
        {
          "Neurophysiological symptoms\n0.459": "notator detected the neurophysiological component",
          "–": "in"
        },
        {
          "Neurophysiological symptoms\n0.459": "",
          "–": ""
        },
        {
          "Neurophysiological symptoms\n0.459": "the sample instances.",
          "–": ""
        },
        {
          "Neurophysiological symptoms\n0.459": "",
          "–": ""
        }
      ],
      "page": 4
    },
    {
      "caption": "Table 2: Inter-annotator agreement after the different it was actually pretty cool.’” should (this aspect",
      "data": [
        {
          "Subjective feelings\ninternal feeling state.": "Table 1: Excerpt of the ﬁnal annotation guidelines including examples from TEC.",
          "Feelin a bit sad tonight": ""
        },
        {
          "Subjective feelings\ninternal feeling state.": "Component\nround 1\nround 2",
          "Feelin a bit sad tonight": "example ‘oh’ or ‘wow’. With this clariﬁcation, the"
        },
        {
          "Subjective feelings\ninternal feeling state.": "Cognitive appraisal\n0.288\n0.777",
          "Feelin a bit sad tonight": "that boat,’ said\ninstance “‘Jolly rum thing about"
        },
        {
          "Subjective feelings\ninternal feeling state.": "Neurophysiological symptoms\n0.459\n–",
          "Feelin a bit sad tonight": ""
        },
        {
          "Subjective feelings\ninternal feeling state.": "",
          "Feelin a bit sad tonight": "the spokesman of the party, as the boys continued"
        },
        {
          "Subjective feelings\ninternal feeling state.": "Motiv. Action tendencies\n0.444\n0.732",
          "Feelin a bit sad tonight": ""
        },
        {
          "Subjective feelings\ninternal feeling state.": "",
          "Feelin a bit sad tonight": "their walk.\n‘I expect\nit got adrift somehow,’ said"
        },
        {
          "Subjective feelings\ninternal feeling state.": "Motor expressions\n0.643\n0.617",
          "Feelin a bit sad tonight": ""
        },
        {
          "Subjective feelings\ninternal feeling state.": "Subjective feelings\n0.733\n0.793",
          "Feelin a bit sad tonight": "another. ‘I don’t know,’ said the ﬁrst.” should not"
        },
        {
          "Subjective feelings\ninternal feeling state.": "",
          "Feelin a bit sad tonight": "‘Oh,\nbe annotated, whereas “‘Sounds delightful.’"
        },
        {
          "Subjective feelings\ninternal feeling state.": "Table 2:\nInter-annotator agreement after\nthe different",
          "Feelin a bit sad tonight": ""
        },
        {
          "Subjective feelings\ninternal feeling state.": "",
          "Feelin a bit sad tonight": "it was actually pretty cool.’” should (this aspect"
        },
        {
          "Subjective feelings\ninternal feeling state.": "annotation rounds during the guideline creation process",
          "Feelin a bit sad tonight": ""
        },
        {
          "Subjective feelings\ninternal feeling state.": "",
          "Feelin a bit sad tonight": "has particularly appeared in the second annotator"
        },
        {
          "Subjective feelings\ninternal feeling state.": "measured with Cohen’s κ.\nIn the second round, no an-",
          "Feelin a bit sad tonight": ""
        },
        {
          "Subjective feelings\ninternal feeling state.": "",
          "Feelin a bit sad tonight": "training round, which lead to a slight decrease in"
        },
        {
          "Subjective feelings\ninternal feeling state.": "notator detected the neurophysiological component\nin",
          "Feelin a bit sad tonight": ""
        },
        {
          "Subjective feelings\ninternal feeling state.": "",
          "Feelin a bit sad tonight": "agreement). We make the annotation guidelines"
        },
        {
          "Subjective feelings\ninternal feeling state.": "the sample instances.",
          "Feelin a bit sad tonight": ""
        },
        {
          "Subjective feelings\ninternal feeling state.": "",
          "Feelin a bit sad tonight": "available together with our corpus. Table 1 shows"
        },
        {
          "Subjective feelings\ninternal feeling state.": "",
          "Feelin a bit sad tonight": "a short excerpt."
        },
        {
          "Subjective feelings\ninternal feeling state.": "",
          "Feelin a bit sad tonight": "After the reﬁnement process concluded, Annota-"
        },
        {
          "Subjective feelings\ninternal feeling state.": "We reﬁned the annotation guidelines in an iter-",
          "Feelin a bit sad tonight": ""
        },
        {
          "Subjective feelings\ninternal feeling state.": "",
          "Feelin a bit sad tonight": "tor 1 annotated the subsample of TEC and Annota-"
        },
        {
          "Subjective feelings\ninternal feeling state.": "ative process with two annotators. Annotator 1 is",
          "Feelin a bit sad tonight": ""
        },
        {
          "Subjective feelings\ninternal feeling state.": "",
          "Feelin a bit sad tonight": "tor 2 annotated the subsample of REMAN."
        },
        {
          "Subjective feelings\ninternal feeling state.": "a 23 year-old female undergraduate computer sci-",
          "Feelin a bit sad tonight": ""
        },
        {
          "Subjective feelings\ninternal feeling state.": "ence student, Annotator 2 is a 28 year-old male",
          "Feelin a bit sad tonight": ""
        },
        {
          "Subjective feelings\ninternal feeling state.": "",
          "Feelin a bit sad tonight": "3.3\nCorpus Statistics"
        },
        {
          "Subjective feelings\ninternal feeling state.": "graduate student of computational linguistics. We",
          "Feelin a bit sad tonight": ""
        },
        {
          "Subjective feelings\ninternal feeling state.": "ﬁrst deﬁned a list of guidelines for each emotion",
          "Feelin a bit sad tonight": "We show corpus statistics in Table 3 to develop an"
        },
        {
          "Subjective feelings\ninternal feeling state.": "component,\nthen let each annotator label 40 ran-",
          "Feelin a bit sad tonight": "understanding how emotions are communicated in"
        },
        {
          "Subjective feelings\ninternal feeling state.": "domly sampled instances (20 each in two itera-",
          "Feelin a bit sad tonight": "the two domains. For both corpora, we observe"
        },
        {
          "Subjective feelings\ninternal feeling state.": "tions) out of each corpus and measured the inter-",
          "Feelin a bit sad tonight": "that cognitive appraisal is most frequent. In TEC,"
        },
        {
          "Subjective feelings\ninternal feeling state.": "annotator agreement. Based on instances with dis-",
          "Feelin a bit sad tonight": "the second most dominant component is subjective"
        },
        {
          "Subjective feelings\ninternal feeling state.": "agreement, we reﬁned the guidelines. The achieved",
          "Feelin a bit sad tonight": "feeling, while in REMAN it is the motor expression."
        },
        {
          "Subjective feelings\ninternal feeling state.": "inter-annotator agreement scores are displayed in",
          "Feelin a bit sad tonight": "The amount of subjective feeling descriptions is"
        },
        {
          "Subjective feelings\ninternal feeling state.": "Table 2. We observe that particularly the concepts",
          "Feelin a bit sad tonight": "substantially lower\nfor\nliterature than for social"
        },
        {
          "Subjective feelings\ninternal feeling state.": "of cognitive appraisal and motivational action ten-",
          "Feelin a bit sad tonight": "media – which is in line with the show-don’t-tell"
        },
        {
          "Subjective feelings\ninternal feeling state.": "dencies have been clariﬁed. During this process,",
          "Feelin a bit sad tonight": "paradigm which is obviously not followed in social"
        },
        {
          "Subjective feelings\ninternal feeling state.": "for example,\nthe discussion of\nthe instance “He",
          "Feelin a bit sad tonight": "media as it is in literature."
        },
        {
          "Subjective feelings\ninternal feeling state.": "did so, and to his surprise, found that all the bank",
          "Feelin a bit sad tonight": "Components are not distributed equally across"
        },
        {
          "Subjective feelings\ninternal feeling state.": "stock had been sold, and transferred” lead to the",
          "Feelin a bit sad tonight": "emotions.\nParticularly\nnoteworthy\nis\nthe\nco-"
        },
        {
          "Subjective feelings\ninternal feeling state.": "addition of a rule stating that the explicit mention",
          "Feelin a bit sad tonight": "occurrence\nof\ndisgust with\nneurophysiological"
        },
        {
          "Subjective feelings\ninternal feeling state.": "of a feeling has to be annotated with subjective",
          "Feelin a bit sad tonight": "symptoms\nin social media, but not\nin literature"
        },
        {
          "Subjective feelings\ninternal feeling state.": "feeling. A rule for the annotation of tiredness as",
          "Feelin a bit sad tonight": "where this component dominates the emotion of"
        },
        {
          "Subjective feelings\ninternal feeling state.": "neurophysiological symptoms was created due to",
          "Feelin a bit sad tonight": "fear.\nWe\nalso observe\na particularly high co-"
        },
        {
          "Subjective feelings\ninternal feeling state.": "the instance “Here he remained the whole night,",
          "Feelin a bit sad tonight": "occurrence of\nthe subjective feeling component"
        },
        {
          "Subjective feelings\ninternal feeling state.": "feeling very tired and sorrowful.”. Concerning the",
          "Feelin a bit sad tonight": "with fear for social media, which is not\nthe case"
        },
        {
          "Subjective feelings\ninternal feeling state.": "annotation of verbal communication as motor ex-",
          "Feelin a bit sad tonight": "for literature. In literature, the motivational action"
        },
        {
          "Subjective feelings\ninternal feeling state.": "pression, we decided to only annotate instances",
          "Feelin a bit sad tonight": "tendency component co-occurs with anger (and an-"
        },
        {
          "Subjective feelings\ninternal feeling state.": "with verbal communications that address an emo-",
          "Feelin a bit sad tonight": "ticipation) more frequently than with all other emo-"
        },
        {
          "Subjective feelings\ninternal feeling state.": "tional reaction or instances with interjections as for",
          "Feelin a bit sad tonight": "tions. This is not the case for the social media do-"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "25. The outputs of the convolutional layer are max-": ""
        },
        {
          "25. The outputs of the convolutional layer are max-": "pooled over the dimension of the input sequence,"
        },
        {
          "25. The outputs of the convolutional layer are max-": "inspired by Collobert et al. (2011). Stacked on top"
        },
        {
          "25. The outputs of the convolutional layer are max-": ""
        },
        {
          "25. The outputs of the convolutional layer are max-": "of the pooling layer is a fully connected layer. Its"
        },
        {
          "25. The outputs of the convolutional layer are max-": ""
        },
        {
          "25. The outputs of the convolutional layer are max-": ""
        },
        {
          "25. The outputs of the convolutional layer are max-": "outputs are ﬁnally fed into an output layer with a"
        },
        {
          "25. The outputs of the convolutional layer are max-": ""
        },
        {
          "25. The outputs of the convolutional layer are max-": "sigmoid activation function (see Figure 1a).3"
        },
        {
          "25. The outputs of the convolutional layer are max-": ""
        },
        {
          "25. The outputs of the convolutional layer are max-": "We use dropout regularization after each layer."
        },
        {
          "25. The outputs of the convolutional layer are max-": ""
        },
        {
          "25. The outputs of the convolutional layer are max-": "The network uses a weighted cross-entropy loss"
        },
        {
          "25. The outputs of the convolutional layer are max-": ""
        },
        {
          "25. The outputs of the convolutional layer are max-": "function, whereby the loss of false negatives is mul-"
        },
        {
          "25. The outputs of the convolutional layer are max-": "tiplied by 4 to increase recall. The model is trained"
        },
        {
          "25. The outputs of the convolutional layer are max-": ""
        },
        {
          "25. The outputs of the convolutional layer are max-": "using an Adam optimizer (Kingma and Ba, 2015)."
        },
        {
          "25. The outputs of the convolutional layer are max-": "All network parameters of this model and subse-"
        },
        {
          "25. The outputs of the convolutional layer are max-": ""
        },
        {
          "25. The outputs of the convolutional layer are max-": "quent neural models are determined using a subset"
        },
        {
          "25. The outputs of the convolutional layer are max-": ""
        },
        {
          "25. The outputs of the convolutional layer are max-": "of the training data as development set for the RE-"
        },
        {
          "25. The outputs of the convolutional layer are max-": ""
        },
        {
          "25. The outputs of the convolutional layer are max-": "MAN corpus and using 10-fold cross-validation for"
        },
        {
          "25. The outputs of the convolutional layer are max-": ""
        },
        {
          "25. The outputs of the convolutional layer are max-": "the TEC corpus. Details of the resulting hyperpa-"
        },
        {
          "25. The outputs of the convolutional layer are max-": ""
        },
        {
          "25. The outputs of the convolutional layer are max-": "rameters are listed in the Appendix."
        },
        {
          "25. The outputs of the convolutional layer are max-": ""
        },
        {
          "25. The outputs of the convolutional layer are max-": ""
        },
        {
          "25. The outputs of the convolutional layer are max-": "4.2\nComponent Classiﬁer"
        },
        {
          "25. The outputs of the convolutional layer are max-": ""
        },
        {
          "25. The outputs of the convolutional layer are max-": ""
        },
        {
          "25. The outputs of the convolutional layer are max-": "The emotion component classiﬁers predict which of"
        },
        {
          "25. The outputs of the convolutional layer are max-": ""
        },
        {
          "25. The outputs of the convolutional layer are max-": "the ﬁve CPM components occur in a text instance."
        },
        {
          "25. The outputs of the convolutional layer are max-": ""
        },
        {
          "25. The outputs of the convolutional layer are max-": "Our Cpm-ME-Base baseline models (one for each"
        },
        {
          "25. The outputs of the convolutional layer are max-": "component) only use bag-of-words features in the"
        },
        {
          "25. The outputs of the convolutional layer are max-": ""
        },
        {
          "25. The outputs of the convolutional layer are max-": "same conﬁguration as Emo-ME-Base."
        },
        {
          "25. The outputs of the convolutional layer are max-": "In\nthe model Cpm-ME-Adv, we\nadd\ntask-"
        },
        {
          "25. The outputs of the convolutional layer are max-": "speciﬁc features, namely features derived from"
        },
        {
          "25. The outputs of the convolutional layer are max-": "manually crafted small dictionaries with words as-"
        },
        {
          "25. The outputs of the convolutional layer are max-": "sociated with the different components. Those dic-"
        },
        {
          "25. The outputs of the convolutional layer are max-": "tionaries were developed without considering the"
        },
        {
          "25. The outputs of the convolutional layer are max-": "corpora and with inspiration from Scherer (2005)"
        },
        {
          "25. The outputs of the convolutional layer are max-": "and contain on average 26 items. Further, we add"
        },
        {
          "25. The outputs of the convolutional layer are max-": ""
        },
        {
          "25. The outputs of the convolutional layer are max-": "part-of-speech tags (calculated with spaCy4, Hon-"
        },
        {
          "25. The outputs of the convolutional layer are max-": "nibal et al. (2020)) and glove-twitter-100 embed-"
        },
        {
          "25. The outputs of the convolutional layer are max-": "dings5 (Pennington et al., 2014). Additionally, only"
        },
        {
          "25. The outputs of the convolutional layer are max-": "for the cognitive appraisal component, we run the"
        },
        {
          "25. The outputs of the convolutional layer are max-": "appraisal classiﬁer developed by Hofmann et al."
        },
        {
          "25. The outputs of the convolutional layer are max-": "(2020) and use the predictions as features.6\nFor"
        },
        {
          "25. The outputs of the convolutional layer are max-": "each component individually, the best-performing"
        },
        {
          "25. The outputs of the convolutional layer are max-": "combination of these features is chosen."
        },
        {
          "25. The outputs of the convolutional layer are max-": ""
        },
        {
          "25. The outputs of the convolutional layer are max-": "The Cpm-NN-Base is conﬁgured analogously"
        },
        {
          "25. The outputs of the convolutional layer are max-": ""
        },
        {
          "25. The outputs of the convolutional layer are max-": "to Emo-NN-Base. The primary reason for using"
        },
        {
          "25. The outputs of the convolutional layer are max-": ""
        },
        {
          "25. The outputs of the convolutional layer are max-": "an equivalent\nsetup is\nto facilitate a multi-head"
        },
        {
          "25. The outputs of the convolutional layer are max-": ""
        },
        {
          "25. The outputs of the convolutional layer are max-": "architecture as joint model\nfor both tasks in the"
        },
        {
          "25. The outputs of the convolutional layer are max-": ""
        },
        {
          "25. The outputs of the convolutional layer are max-": "next step."
        },
        {
          "25. The outputs of the convolutional layer are max-": ""
        },
        {
          "25. The outputs of the convolutional layer are max-": ""
        },
        {
          "25. The outputs of the convolutional layer are max-": "3We selected this architecture based on preliminary ex-"
        },
        {
          "25. The outputs of the convolutional layer are max-": ""
        },
        {
          "25. The outputs of the convolutional layer are max-": "periments on the validation data. We evaluated it against"
        },
        {
          "25. The outputs of the convolutional layer are max-": "LSTM-Dense Layer and CNN-LSTM architectures."
        },
        {
          "25. The outputs of the convolutional layer are max-": "4https://spacy.io/usage/linguistic-features#pos-tagging"
        },
        {
          "25. The outputs of the convolutional layer are max-": ""
        }
      ],
      "page": 5
    },
    {
      "caption": "Table 3: Total/relative counts of CPM components and emotions in our reannoted TEC and REMAN subsam-",
      "data": [
        {
          "Emotion": "Anger",
          "Cognitive": "(75%)",
          "Phys.": "(5%)",
          "Motiv. Action": "(18%)",
          "Motor Exp.": "(12%)",
          "Subject.": "(29%)",
          "Total": "169"
        },
        {
          "Emotion": "Disgust",
          "Cognitive": "(83%)",
          "Phys.": "(14%)",
          "Motiv. Action": "(8%)",
          "Motor Exp.": "(22%)",
          "Subject.": "(24%)",
          "Total": "78"
        },
        {
          "Emotion": "Joy",
          "Cognitive": "(71%)",
          "Phys.": "(7%)",
          "Motiv. Action": "(21%)",
          "Motor Exp.": "(11%)",
          "Subject.": "(27%)",
          "Total": "848"
        },
        {
          "Emotion": "Sadness",
          "Cognitive": "(87%)",
          "Phys.": "(3%)",
          "Motiv. Action": "(16%)",
          "Motor Exp.": "(14%)",
          "Subject.": "(38%)",
          "Total": "373"
        },
        {
          "Emotion": "Fear",
          "Cognitive": "(74%)",
          "Phys.": "(3%)",
          "Motiv. Action": "(14%)",
          "Motor Exp.": "(10%)",
          "Subject.": "(49%)",
          "Total": "266"
        },
        {
          "Emotion": "Surprise",
          "Cognitive": "(71%)",
          "Phys.": "(1%)",
          "Motiv. Action": "(18%)",
          "Motor Exp.": "(18%)",
          "Subject.": "(27%)",
          "Total": "307"
        },
        {
          "Emotion": "Total.",
          "Cognitive": "(75%)",
          "Phys.": "(5%)",
          "Motiv. Action": "(18%)",
          "Motor Exp.": "(13%)",
          "Subject.": "(32%)",
          "Total": ""
        },
        {
          "Emotion": "Anger",
          "Cognitive": "(67%)",
          "Phys.": "(7%)",
          "Motiv. Action": "(41%)",
          "Motor Exp.": "(62%)",
          "Subject.": "(26%)",
          "Total": "98"
        },
        {
          "Emotion": "Anticip.",
          "Cognitive": "(59%)",
          "Phys.": "(5%)",
          "Motiv. Action": "(43%)",
          "Motor Exp.": "(54%)",
          "Subject.": "(16%)",
          "Total": "117"
        },
        {
          "Emotion": "Disgust",
          "Cognitive": "(86%)",
          "Phys.": "(5%)",
          "Motiv. Action": "(22%)",
          "Motor Exp.": "(35%)",
          "Subject.": "(17%)",
          "Total": "94"
        },
        {
          "Emotion": "Fear",
          "Cognitive": "(67%)",
          "Phys.": "(23%)",
          "Motiv. Action": "(24%)",
          "Motor Exp.": "(49%)",
          "Subject.": "(24%)",
          "Total": "143"
        },
        {
          "Emotion": "Joy",
          "Cognitive": "(57%)",
          "Phys.": "(5%)",
          "Motiv. Action": "(13%)",
          "Motor Exp.": "(55%)",
          "Subject.": "(31%)",
          "Total": "213"
        },
        {
          "Emotion": "Neutral",
          "Cognitive": "(34%)",
          "Phys.": "(0%)",
          "Motiv. Action": "(11%)",
          "Motor Exp.": "(19%)",
          "Subject.": "(3%)",
          "Total": "116"
        },
        {
          "Emotion": "Other",
          "Cognitive": "(57%)",
          "Phys.": "(10%)",
          "Motiv. Action": "(19%)",
          "Motor Exp.": "(47%)",
          "Subject.": "(19%)",
          "Total": "113"
        },
        {
          "Emotion": "Sadness",
          "Cognitive": "(69%)",
          "Phys.": "(14%)",
          "Motiv. Action": "(16%)",
          "Motor Exp.": "(49%)",
          "Subject.": "(31%)",
          "Total": "136"
        },
        {
          "Emotion": "Surprise",
          "Cognitive": "(74%)",
          "Phys.": "(8%)",
          "Motiv. Action": "(15%)",
          "Motor Exp.": "(60%)",
          "Subject.": "(16%)",
          "Total": "139"
        },
        {
          "Emotion": "Trust",
          "Cognitive": "(82%)",
          "Phys.": "(2%)",
          "Motiv. Action": "(15%)",
          "Motor Exp.": "(30%)",
          "Subject.": "(23%)",
          "Total": "115"
        },
        {
          "Emotion": "Total",
          "Cognitive": "(61%)",
          "Phys.": "(8%)",
          "Motiv. Action": "(19%)",
          "Motor Exp.": "(44%)",
          "Subject.": "(17%)",
          "Total": ""
        }
      ],
      "page": 6
    },
    {
      "caption": "Table 3: Total/relative counts of CPM components and emotions in our reannoted TEC and REMAN subsam-",
      "data": [
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "Trust\n94\n(82%)\n2\n(2%)\n17\n(15%)\n34\n(30%)\n27\n(23%)\n115"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "Total\n610\n(61%)\n76\n(8%)\n190\n(19%)\n440\n(44%)\n174\n(17%)"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "Table 3: Total/relative counts of CPM components and emotions in our\nreannoted TEC and REMAN subsam-"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "ples. Note that\nthe CPM categorization is a multi-label\ntask, with 1000 instances in REMAN and 2041 instances"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "reannotated in TEC."
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "4.3\nJoint Modelling and Multi-Task Learning\nmulti-task learning models which predict emotions"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "of Emotions and Components\nand components based on shared latent variables."
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "For a multi-head variant (MTL-MH), the basic ar-"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "To analyze if emotion classiﬁcation beneﬁts from"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "chitectures of the individual models for both tasks"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "the component prediction (and partially also vice"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "remain the same. Outputs of the CNN layer are"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "versa), we set up several model conﬁgurations."
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "fed to two separate, task-speciﬁc, fully connected"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "In Emo-Cpm-ME-Pred, we predict the emotion"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "layers. This model has two output layers, one for"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "with Cpm-ME-Adv and use these predictions as fea-"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "emotion classiﬁcation and one for CPM component"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "tures. Other than that, Emo-Cpm-ME-Pred corre-"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "classiﬁcation. Both tasks use the weighted cross"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "sponds to Emo-ME-Base. In Emo-Cpm-ME-Gold,"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "entropy loss function to increase recall."
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "we replace the predictions by gold component an-"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "Based on the model proposed by Misra et al."
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "notations to analyze error propagation."
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "(2016), we use cross-stitch units\nin our model"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "Emo-Cpm-NN-Pred and Emo-Cpm-NN-Gold"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "MTL-XS. This model employs two separate par-"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "are conﬁgured analogously and follow the same"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "allel\ninstances of the Cpm-NN-Base architecture"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "architecture as Emo-NN-Base with the following"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "introduced above, one for the CPM classiﬁcation"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "differences: A binary vector with the CPM anno-"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "task and one for emotion classiﬁcation. The model"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "tations is introduced as additional\ninput\nfeature,"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "additionally employs one cross-stitch unit after the"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "feeding into a fully connected layer. Its outputs are"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "respective CNN layers. This sharing unit learns a"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "concatenated with the outputs of the penultimate"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "linear combination of the pooled task-speciﬁc CNN"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "layer and passed to another fully connected layer,"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "activation maps which is then passed to the task-"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "followed by the output layer."
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "speciﬁc fully connected layers. The cross-stitch"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "Emo-Cpm-NN-Pred uses Cpm-NN-Base to ob-"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "unit\nlearns during training which information to"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "tain component predictions, but\nthe weights of"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "share across tasks (see Figure 1c)."
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "Cpm-NN-Base are frozen. The basic network archi-"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "tecture resembles that of the Emo-Cpm-NN-Gold"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "model, replacing the additional CPM input vector\n5\nResults"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "with the Cpm-NN-Base model (see Figure 1b). Its"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "outputs are, again, fed into a fully connected layer\nFor our experiments, we use our reannotated sub-"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "which is connected to the output layer.\nsample of TEC and REMAN (not all\ninstances"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "Next to the models that make use of the output\navailable in TEC and REMAN). We split the cor-"
        },
        {
          "Surprise\n103\n(74%)\n11\n(8%)\n21\n(15%)\n83\n(60%)\n22\n(16%)\n139": "of the CPM classiﬁers for prediction, we use two\npora into 90% for training and 10% to test."
        }
      ],
      "page": 6
    },
    {
      "caption": "Table 5: specific features in Cpm-ME-Adv shows a clear showstheresultsforallexperiments.",
      "data": [
        {
          "Cpm-ME-Base": "R",
          "Cpm-ME-Adv": "R",
          "Cpm-NN-Base": "R",
          "MTL-XS": "R",
          "MTL-MH": "R"
        },
        {
          "Cpm-ME-Base": "98",
          "Cpm-ME-Adv": "98",
          "Cpm-NN-Base": "98",
          "MTL-XS": "98",
          "MTL-MH": "96"
        },
        {
          "Cpm-ME-Base": "20",
          "Cpm-ME-Adv": "40",
          "Cpm-NN-Base": "20",
          "MTL-XS": "20",
          "MTL-MH": "0"
        },
        {
          "Cpm-ME-Base": "47",
          "Cpm-ME-Adv": "68",
          "Cpm-NN-Base": "26",
          "MTL-XS": "42",
          "MTL-MH": "68"
        },
        {
          "Cpm-ME-Base": "56",
          "Cpm-ME-Adv": "65",
          "Cpm-NN-Base": "53",
          "MTL-XS": "60",
          "MTL-MH": "60"
        },
        {
          "Cpm-ME-Base": "32",
          "Cpm-ME-Adv": "53",
          "Cpm-NN-Base": "37",
          "MTL-XS": "53",
          "MTL-MH": "32"
        },
        {
          "Cpm-ME-Base": "51",
          "Cpm-ME-Adv": "65",
          "Cpm-NN-Base": "47",
          "MTL-XS": "55",
          "MTL-MH": "51"
        },
        {
          "Cpm-ME-Base": "",
          "Cpm-ME-Adv": "",
          "Cpm-NN-Base": "",
          "MTL-XS": "",
          "MTL-MH": ""
        },
        {
          "Cpm-ME-Base": "99",
          "Cpm-ME-Adv": "98",
          "Cpm-NN-Base": "88",
          "MTL-XS": "90",
          "MTL-MH": "91"
        },
        {
          "Cpm-ME-Base": "17",
          "Cpm-ME-Adv": "33",
          "Cpm-NN-Base": "17",
          "MTL-XS": "17",
          "MTL-MH": "17"
        },
        {
          "Cpm-ME-Base": "57",
          "Cpm-ME-Adv": "74",
          "Cpm-NN-Base": "51",
          "MTL-XS": "57",
          "MTL-MH": "54"
        },
        {
          "Cpm-ME-Base": "52",
          "Cpm-ME-Adv": "61",
          "Cpm-NN-Base": "58",
          "MTL-XS": "48",
          "MTL-MH": "32"
        },
        {
          "Cpm-ME-Base": "70",
          "Cpm-ME-Adv": "70",
          "Cpm-NN-Base": "81",
          "MTL-XS": "81",
          "MTL-MH": "80"
        },
        {
          "Cpm-ME-Base": "59",
          "Cpm-ME-Adv": "67",
          "Cpm-NN-Base": "59",
          "MTL-XS": "59",
          "MTL-MH": "55"
        },
        {
          "Cpm-ME-Base": "",
          "Cpm-ME-Adv": "",
          "Cpm-NN-Base": "",
          "MTL-XS": "",
          "MTL-MH": ""
        }
      ],
      "page": 7
    },
    {
      "caption": "Table 5: specific features in Cpm-ME-Adv shows a clear showstheresultsforallexperiments.",
      "data": [
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": "5.1\nComponent Prediction"
        },
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": ""
        },
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": "We start the discussion of the results with the com-"
        },
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": ""
        },
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": "ponent classiﬁcation, a classiﬁcation task that has"
        },
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": ""
        },
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": "not been addressed before and for which our data"
        },
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": ""
        },
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": "set is the ﬁrst that becomes available to the research"
        },
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": ""
        },
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": "community. Table 4 shows the results."
        },
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": ""
        },
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": "The model performances are acceptable. Macro-"
        },
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": "average F1 scores on REMAN range from .42 of"
        },
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": ""
        },
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": "MTL-MH to .59 for Cpm-ME-Adv, and from .53"
        },
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": "(Cpm-ME-Base) to .57 (Cpm-NN-Base) on TEC."
        },
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": "There are, however, differences for the components:"
        },
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": "On TEC,\nthere are difﬁculties in predicting neu-"
        },
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": "rophysiological symptoms. The addition of task-"
        },
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": "speciﬁc features in Cpm-ME-Adv shows a clear"
        },
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": "improvement across all components."
        },
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": "The neural baseline Cpm-NN-Base outperforms"
        },
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": "Cpm-ME-Adv on TEC, and does so without feature"
        },
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": "engineering. On REMAN, the feature-based model"
        },
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": "is superior which might be due to the engineered"
        },
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": "features being more commonly represented in the"
        },
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": "literature domain than in social media. This is par-"
        },
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": "tially leveraged in the MTL-XS model on REMAN."
        },
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": "The components are not equally difﬁcult to pre-"
        },
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": "dict; the relations between the components are com-"
        },
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": "parable across models. The lowest performance"
        },
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": "scores are observed for neurophysiological symp-"
        },
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": "toms. This holds across models and corpora. For"
        },
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": "the neurophysiological component on the literature"
        },
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": "domain, however, the engineered features in Cpm-"
        },
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": "ME-Adv show substantial\nimprovement, yielding"
        },
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": "an F1 score of 0.44. Cognitive appraisal shows best"
        },
        {
          "Table 4: Performance of the emotion component detection models (multiplied by 100).": "prediction performances, with F1 between .73 and"
        }
      ],
      "page": 7
    },
    {
      "caption": "Table 5: F (/100) results across models and emotion categories. (empty cells denote that this category is not",
      "data": [
        {
          "Anger\nAnticip\nDisgust\nModel": "Emo-ME-Base\n0\n0\n0",
          "Fear": "0",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "0\n0\n0\n0\n0\n0\n0\n0"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "Emo-Cpm-ME-Gold\n18\n0\n0",
          "Fear": "25",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "16\n62\n0\n0\n0\n0\n12\n14"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "Emo-Cpm-ME-Pred\n0\n0\n0",
          "Fear": "12",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "15\n0\n0\n0\n0\n14\n4\n6"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "REMAN\nEmo-NN-Base\n36\n18\n29",
          "Fear": "41",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "71\n59\n46\n14\n36\n50\n40\n43"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "Emo-Cpm-NN-Gold\n56\n22\n28",
          "Fear": "37",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "68\n71\n15\n39\n50\n60\n45\n45"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "Emo-Cpm-NN-Pred\n33\n32\n0",
          "Fear": "34",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "71\n52\n40\n17\n58\n42\n38\n43"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "MTL-MH\n35\n16\n24",
          "Fear": "39",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "56\n62\n49\n22\n48\n67\n42\n42"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "MTL-XS\n38\n24\n26",
          "Fear": "47",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "54\n37\n46\n47\n64\n48\n64\n55"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "Emo-ME-Base\n11\n0",
          "Fear": "53",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "64\n43\n38\n35\n54"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "Emo-Cpm-ME-Gold\n11\n0",
          "Fear": "59",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "66\n40\n43\n36\n55"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "Emo-Cpm-ME-Pred\n11\n0",
          "Fear": "59",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "67\n43\n43\n37\n55"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "Emo-NN-Base\n41\n44",
          "Fear": "56",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "69\n51\n39\n50\n57"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "TEC\nEmo-Cpm-NN-Gold\n52\n33",
          "Fear": "67",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "72\n60\n47\n55\n62"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "Emo-Cpm-NN-Pred\n32\n0",
          "Fear": "59",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "70\n53\n44\n43\n56"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "MTL-MH\n57\n17",
          "Fear": "53",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "76\n45\n53\n50\n58"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "MTL-XS\n34\n50",
          "Fear": "60",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "57\n53\n61\n73\n44"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "(/100)\nTable 5: F1",
          "Fear": "results across models and emotion categories.",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "(empty cells denote that\nthis category is not"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "",
          "Fear": "available in the respective corpus. The best scores (except the gold setting) are printed bold face.",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": ""
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "observe an improvement by 1pp,\nto .55 F1. The",
          "Fear": "",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "with the exception of surprise on the REMAN cor-"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "inclusion of predicted component\ninformation as",
          "Fear": "",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "pus and anger on the TEC corpus. We can there-"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "features in the neural network model shows no im-",
          "Fear": "",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "fore conclude that emotion component information"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "provement on REMAN or on TEC.",
          "Fear": "",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "does contribute to emotion classiﬁcation; the best-"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "To answer the question if this limited improve-",
          "Fear": "",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "performing combination is via a cross-stitch model."
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "ment\nis only due to a limited performance of the",
          "Fear": "",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "A detailed discussion based on example predic-"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "component classiﬁcation model, we compare these",
          "Fear": "",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "tions of the various models is available in the Ap-"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "results to a setting, in which the predicted values",
          "Fear": "",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "pendix."
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "are replaced by gold labels from the annotation.",
          "Fear": "",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": ""
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "",
          "Fear": "",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "6\nConclusion and Future Work"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "This setup does show an improvement with Emo-",
          "Fear": "",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": ""
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "Cpm-ME-Gold to .14 F1 on REMAN, which is",
          "Fear": "",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "We presented the ﬁrst data sets (based on existing"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "obviously still very low; and no improvement on",
          "Fear": "",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": ""
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "",
          "Fear": "",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "emotion corpora) with emotion component anno-"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "TEC. However, with our neural model Emo-Cpm-",
          "Fear": "",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": ""
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "",
          "Fear": "",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "tation. While Hofmann et al. (2020) has proposed"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "NN-Gold, we see the potential of gold information",
          "Fear": "",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": ""
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "",
          "Fear": "",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "to use the cognitive appraisal for emotion classi-"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "increasing the score for emotion classiﬁcation to",
          "Fear": "",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": ""
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "",
          "Fear": "",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "ﬁcation,\nthey did not succeed to present models"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": ".45 F1 on REMAN and .62 F1 on TEC.",
          "Fear": "",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "that actually beneﬁt in emotion classiﬁcation per-"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "This is an unrealistic setting – the classiﬁer does",
          "Fear": "",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "formance. That might be due to the fact that cog-"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "not have access to annotated labels in real world",
          "Fear": "",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "nitive appraisal classiﬁcation itself is challenging,"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "applications.\nHowever,\nin the (realistic) cross-",
          "Fear": "",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "and that they did not compare multiple multi-task"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "stitch multi-task learning setting of MTL-XS, we",
          "Fear": "",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "learning approaches."
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "observe further improvements: On REMAN, we",
          "Fear": "",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "With this paper we moved to another psychologi-"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "achieve .47 F1 (which is even slightly higher than",
          "Fear": "",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "cal theory, namely the emotion component process"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "with gold component labels), which constitutes an",
          "Fear": "",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "model, and make the ﬁrst annotations available that"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "achieved improvement by 4pp to the emotion clas-",
          "Fear": "",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "closely follow this theory. Based on this resource,"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "siﬁer which is not informed about components. On",
          "Fear": "",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "we have shown that, even with a comparably lim-"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "TEC, we achieve .61 F1, which is close to the model",
          "Fear": "",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "ited data set size, emotion components contribute"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "that has access to gold components (.62). This is",
          "Fear": "",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "to emotion classiﬁcation. We expect\nthat with a"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "an improvement of 4pp as well\nin comparison to",
          "Fear": "",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "larger corpus the improvement would be more sub-"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "the model\nthat has no access to components but",
          "Fear": "",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "stantial\nthan it\nis already now. A manual\nintro-"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "follows the same architecture.",
          "Fear": "",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "spection of the data instances also shows that the"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "Particularly, we observe that models with compo-",
          "Fear": "",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "components indeed help. Further, we have seen"
        },
        {
          "Anger\nAnticip\nDisgust\nModel": "nent information perform better across all emotions,",
          "Fear": "",
          "Joy\nNeutral\nOther\nSadness\nSurpr.\nTrust\nMacavg.\nMicavg.": "that emotions are communicated quite differently"
        }
      ],
      "page": 8
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "in the two domains, which is an explanation why": "emotion classiﬁcation systems (up-to-today) need",
          "References": ""
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "Nourah Alswaidan and Mohamed Menai. 2020. A sur-"
        },
        {
          "in the two domains, which is an explanation why": "to be developed particularly for domains of inter-",
          "References": ""
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "vey of state-of-the-art approaches for emotion recog-"
        },
        {
          "in the two domains, which is an explanation why": "est. We propose that future work analyzes further",
          "References": "nition in text. Knowledge and Information Systems,"
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "62:2937–2987."
        },
        {
          "in the two domains, which is an explanation why": "which information is relevant and should be shared",
          "References": ""
        },
        {
          "in the two domains, which is an explanation why": "across these tasks in multi-task learning models.",
          "References": ""
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "Alexandra Balahur,\nJesus M. Hermida,\nand Andrew"
        },
        {
          "in the two domains, which is an explanation why": "Further, we propose that larger corpora should be",
          "References": "Montoyo. 2012. Building and exploiting emotinet,"
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "a knowledge base for emotion detection based on"
        },
        {
          "in the two domains, which is an explanation why": "created across more domains, and also that multi-",
          "References": ""
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "IEEE Transactions on\nthe appraisal\ntheory model."
        },
        {
          "in the two domains, which is an explanation why": "task learning is not only performed individually, but",
          "References": ""
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "Affective Computing, 3(1):88–101."
        },
        {
          "in the two domains, which is an explanation why": "also across corpora. Presumably,\nthe component",
          "References": ""
        },
        {
          "in the two domains, which is an explanation why": "information in different domains is not\nthe same,",
          "References": "Laura-Ana-Maria Bostan and Roman Klinger. 2018."
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "An analysis of annotated corpora for emotion clas-"
        },
        {
          "in the two domains, which is an explanation why": "but might be helpful across them.",
          "References": ""
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "the 27th Inter-\nsiﬁcation in text.\nIn Proceedings of"
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "national Conference on Computational Linguistics,"
        },
        {
          "in the two domains, which is an explanation why": "Acknowledgments",
          "References": ""
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "pages 2104–2119, Santa Fe, New Mexico, USA. As-"
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "sociation for Computational Linguistics."
        },
        {
          "in the two domains, which is an explanation why": "This work was supported by Deutsche Forschungs-",
          "References": ""
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "Sven Buechel and Udo Hahn. 2017. EmoBank: Study-"
        },
        {
          "in the two domains, which is an explanation why": "gemeinschaft (project CEAT, KL 2869/1-2).",
          "References": ""
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "ing the impact of annotation perspective and repre-"
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "sentation format on dimensional emotion analysis."
        },
        {
          "in the two domains, which is an explanation why": "Ethical Considerations",
          "References": ""
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "the 15th Conference of\nthe Euro-\nIn Proceedings of"
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "pean Chapter of\nthe Association for Computational"
        },
        {
          "in the two domains, which is an explanation why": "We did not collect a new data set from individuals,",
          "References": "Linguistics: Volume 2, Short Papers, pages 578–585,"
        },
        {
          "in the two domains, which is an explanation why": "but did reannotate existing and publicly available",
          "References": "Valencia, Spain. Association for Computational Lin-"
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "guistics."
        },
        {
          "in the two domains, which is an explanation why": "resources. Therefore, this paper does not pose ethi-",
          "References": ""
        },
        {
          "in the two domains, which is an explanation why": "cal questions regarding data collection.",
          "References": ""
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "Sven Buechel, Luise Modersohn, and Udo Hahn. 2020."
        },
        {
          "in the two domains, which is an explanation why": "However, emotion analysis has the principled",
          "References": "Towards a uniﬁed framework for emotion analysis."
        },
        {
          "in the two domains, which is an explanation why": "potential\nto be misused, and researchers need to",
          "References": ""
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "Erik Cambria, Daniel Olsher, and Dheeraj Rajagopal."
        },
        {
          "in the two domains, which is an explanation why": "be aware that their ﬁndings (though they are not in",
          "References": ""
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "2014.\nSenticnet 3: A common and common-sense"
        },
        {
          "in the two domains, which is an explanation why": "themselves harmful) might lead to software that can",
          "References": "knowledge base for cognition-driven sentiment anal-"
        },
        {
          "in the two domains, which is an explanation why": "do harm. We assume that sentiment and emotion",
          "References": "ysis.\nIn Proceedings of the AAAI."
        },
        {
          "in the two domains, which is an explanation why": "analysis are sufﬁciently well-known that users of",
          "References": ""
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "Nan Chen and Peikang Wang. 2018. Advanced com-"
        },
        {
          "in the two domains, which is an explanation why": "social media might be aware that their data could",
          "References": ""
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "bined LSTM-CNN model for Twitter sentiment anal-"
        },
        {
          "in the two domains, which is an explanation why": "be automatically analyzed. However, we propose",
          "References": "ysis.\nIn 2018 5th IEEE International Conference on"
        },
        {
          "in the two domains, which is an explanation why": "that no automatic system ever does report back",
          "References": "Cloud Computing and Intelligence Systems (CCIS),"
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "pages 684–687."
        },
        {
          "in the two domains, which is an explanation why": "analyses of individuals and instead does aggregate",
          "References": ""
        },
        {
          "in the two domains, which is an explanation why": "data of anonymized posts. We do not assume that",
          "References": ""
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "Gerald L. Clore and Andrew Ortony. 2013.\nPsycho-"
        },
        {
          "in the two domains, which is an explanation why": "analyzing literature data poses any risk.",
          "References": "logical construction in the OCC model of emotion."
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "Emotion Review, 5(4):335–343."
        },
        {
          "in the two domains, which is an explanation why": "One aspect of our work we would like to point",
          "References": ""
        },
        {
          "in the two domains, which is an explanation why": "out is that, in contrast to other and previous emotion",
          "References": ""
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "Ronan Collobert, Jason Weston, L´eon Bottou, Michael"
        },
        {
          "in the two domains, which is an explanation why": "analysis research, we focus and enable particularly",
          "References": ""
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "Karlen, Koray Kavukcuoglu, and Pavel Kuksa. 2011."
        },
        {
          "in the two domains, which is an explanation why": "the analysis of implicit (and perhaps even uncon-",
          "References": "Natural\nlanguage processing (almost)\nfrom scratch."
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "Journal\nof machine\nlearning\nresearch,\n12:2493–"
        },
        {
          "in the two domains, which is an explanation why": "cious) communication of emotions.\nThat might",
          "References": ""
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "2537."
        },
        {
          "in the two domains, which is an explanation why": "further mean that authors of posts in social media",
          "References": ""
        },
        {
          "in the two domains, which is an explanation why": "are not aware that\ntheir emotional state could be",
          "References": ""
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "Jacob Devlin, Ming-Wei Chang, Kenton Lee,\nand"
        },
        {
          "in the two domains, which is an explanation why": "computationally analyzed, potentially, they are not",
          "References": "Kristina Toutanova. 2019.\nBERT: Pre-training of"
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "deep bidirectional\ntransformers for language under-"
        },
        {
          "in the two domains, which is an explanation why": "even fully aware of their own affective state. We",
          "References": ""
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "the 2019 Conference\nstanding.\nIn Proceedings of"
        },
        {
          "in the two domains, which is an explanation why": "would like to point out that automatically analyzing",
          "References": ""
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "of\nthe North American Chapter of\nthe Association"
        },
        {
          "in the two domains, which is an explanation why": "social media data without\nthe explicit consent of",
          "References": ""
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "for Computational Linguistics: Human Language"
        },
        {
          "in the two domains, which is an explanation why": "the users is unethical at\nleast when the user can",
          "References": "Technologies, Volume 1 (Long and Short Papers),"
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "pages 4171–4186, Minneapolis, Minnesota. Associ-"
        },
        {
          "in the two domains, which is an explanation why": "be identiﬁed or identify themselves, particularly if",
          "References": ""
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "ation for Computational Linguistics."
        },
        {
          "in the two domains, which is an explanation why": "they might not be aware of the details of an analysis",
          "References": ""
        },
        {
          "in the two domains, which is an explanation why": "system.",
          "References": ""
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "Paul Ekman. 1992. An argument\nfor basic emotions."
        },
        {
          "in the two domains, which is an explanation why": "",
          "References": "Cognition & emotion, 6(3-4):169–200."
        }
      ],
      "page": 9
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "Long\nshort-term memory.\nNeural Computation,",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "ence on Empirical Methods\nin Natural Language"
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "9(8):1735–1780.",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "Processing\n(EMNLP),\npages\n1532–1543,\nDoha,"
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "Qatar. Association for Computational Linguistics."
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "Jan Hofmann, Enrica Troiano, Kai Sassenberg, and Ro-",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": ""
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "man Klinger. 2020. Appraisal\ntheories for emotion",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "Robert Plutchik. 2001.\nThe nature of emotions: Hu-"
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "the 28th In-\nclassiﬁcation in text.\nIn Proceedings of",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "man emotions have deep evolutionary roots, a fact"
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "ternational Conference on Computational Linguis-",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "that may explain their complexity and provide tools"
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "tics, pages 125–138, Barcelona, Spain (Online). In-",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "for clinical practice. American scientist, 89(4):344–"
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "ternational Committee on Computational Linguis-",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "350."
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "tics.",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": ""
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "Hannah\nRashkin,\nMaarten\nSap,\nEmily\nAllaway,"
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "Matthew Honnibal,\nInes Montani,\nSoﬁe Van Lan-",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "Noah A. Smith, and Yejin Choi. 2018. Event2Mind:"
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "deghem,\nand\nAdriane\nBoyd.\n2020.\nspaCy:",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "Commonsense inference on events, intents, and reac-"
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "Industrial-strength Natural Language Processing in",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "tions.\nIn Proceedings of the 56th Annual Meeting of"
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "Python.",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "the Association for Computational Linguistics (Vol-"
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "ume 1: Long Papers), pages 463–473, Melbourne,"
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "Evgeny Kim and Roman Klinger. 2018. Who feels",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "Australia. Association for Computational Linguis-"
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "what and why?\nannotation of a literature corpus",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "tics."
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "with semantic roles of emotions.\nIn Proceedings of",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": ""
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "James Russell and Albert Mehrabian. 1977. Evidence"
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "the 27th International Conference on Computational",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": ""
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "for a three-factor theory of emotions. Journal of Re-"
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "Linguistics, pages 1345–1359. Association for Com-",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": ""
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "search in Personality, 11(3):273–294."
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "putational Linguistics.",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": ""
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "Klaus R. Scherer. 2005. What are emotions? and how"
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "Evgeny Kim and Roman Klinger. 2019. An analysis",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": ""
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "can they be measured?\nSocial Science Information,"
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "of emotion communication channels in fan-ﬁction:",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": ""
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "44(4):695–729."
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "Towards emotional storytelling.\nIn Proceedings of",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": ""
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "the Second Workshop on Storytelling, pages 56–64,",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": ""
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "Klaus R. Scherer. 2009.\nEmotions are emergent pro-"
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "Florence,\nItaly. Association for Computational Lin-",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": ""
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "cesses:\nthey require a dynamic computational archi-"
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "guistics.",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": ""
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "tecture. Philosophical Transactions of the Royal So-"
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "ciety B, 364(1535):3459–3474."
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "Diederik P. Kingma\nand Jimmy Ba. 2015.\nAdam:",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": ""
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "Inter-\nA method\nfor\nstochastic\noptimization.\nIn",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": ""
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "Klaus R. Scherer and Harald G. Wallbott. 1994.\nEvi-"
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "national Conference on Learning Representations",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": ""
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "dence for universality and cultural variation of differ-"
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "(ICLR Poster).",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": ""
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "Journal of per-\nential emotion response patterning."
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "sonality and social psychology, 66(2):310."
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "Jacques M. van Meel. 1995. Representing emotions in",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": ""
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "literature and paintings: A comparative analysis. Po-",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": ""
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "Mostafa Al Masum Shaikh, Helmut Prendinger,\nand"
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "etics, 23(1):159 – 176. Emotions and Cultural Prod-",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": ""
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "Mitsuru Ishizuka. 2009. A linguistic interpretation"
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "ucts.",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": ""
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "of the OCC emotion model for affect sensing from"
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "text. Affective Information Processing, pages 45–73."
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "Ishan Misra, Abhinav Shrivastava, Abhinav Gupta, and",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": ""
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "Martial Hebert. 2016.\nCross-stitch networks\nfor",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": ""
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "Craig A. Smith and Phoebe C. Ellsworth. 1985.\nPat-"
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "the\nIEEE\nmulti-task learning.\nIn Proceedings of",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": ""
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "Journal of\nterns of cognitive appraisal\nin emotion."
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "Conference on Computer Vision and Pattern Recog-",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": ""
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "personality and social psychology, 48(4):813."
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "nition, pages 3994–4003.",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": ""
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "Pedro M. Sosa. 2017. Twitter sentiment analysis using"
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "Saif Mohammad. 2012.\n#emotional\ntweets.\nIn *SEM",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": ""
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "combined LSTM-CNN models. Eprint Arxiv, pages"
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "2012:\nThe First Joint Conference on Lexical and",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": ""
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "1–9."
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "Computational Semantics – Volume 1: Proceedings",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": ""
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "of the main conference and the shared task, and Vol-",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "Enrica Troiano, Sebastian Pad´o, and Roman Klinger."
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "ume 2: Proceedings of the Sixth International Work-",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "2019. Crowdsourcing and validating event-focused"
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "shop on Semantic Evaluation (SemEval 2012), pages",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "emotion corpora for German and English.\nIn Pro-"
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "246–255, Montr´eal, Canada. Association for Com-",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "ceedings of\nthe 57th Annual Meeting of\nthe Asso-"
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "putational Linguistics.",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "ciation for Computational Linguistics, pages 4005–"
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "4011, Florence, Italy. Association for Computational"
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "Saif Mohammad, Felipe Bravo-Marquez, Mohammad",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "Linguistics."
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "Salameh, and Svetlana Kiritchenko. 2018. SemEval-",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": ""
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "2018 task 1: Affect\nin tweets.\nIn Proceedings of",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "Orizu Udochukwu and Yulan He. 2015. A rule-based"
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "The 12th International Workshop on Semantic Eval-",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "approach to implicit emotion detection in text.\nIn"
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "uation, pages 1–17, New Orleans, Louisiana. Asso-",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "Natural Language Processing and Information Sys-"
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "ciation for Computational Linguistics.",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "tems, pages 197–203, Cham. Springer International"
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": "Publishing."
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "Jeffrey Pennington, Richard Socher, and Christopher",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": ""
        },
        {
          "Sepp\nHochreiter\nand\nJ¨urgen\nSchmidhuber.\n1997.": "Manning. 2014.\nGloVe: Global vectors\nfor word",
          "the 2014 Confer-\nrepresentation.\nIn Proceedings of": ""
        }
      ],
      "page": 10
    },
    {
      "caption": "Table 6: shows the performance scores if just one additional feature is enabled (while bag-of-words",
      "data": [
        {
          "A": "",
          "Ablation Study for Feature Based Maximum Entropy Classiﬁcation Model of": "Emotion Components"
        },
        {
          "A": "Table 6 shows the performance scores if",
          "Ablation Study for Feature Based Maximum Entropy Classiﬁcation Model of": "just one additional\nfeature is enabled (while bag-of-words"
        },
        {
          "A": "",
          "Ablation Study for Feature Based Maximum Entropy Classiﬁcation Model of": "always remains available). It can be seen, that the most advantageous feature are word embeddings. On"
        },
        {
          "A": "",
          "Ablation Study for Feature Based Maximum Entropy Classiﬁcation Model of": "REMAN, Cpm-ME-Adv achieves a macro F1-score of 0.59 and a micro F1-score of 0.67. On TEC, we"
        },
        {
          "A": "",
          "Ablation Study for Feature Based Maximum Entropy Classiﬁcation Model of": "have respective values of 0.56 and 0.71, with the high micro score resulting from cognitive appraisal being"
        },
        {
          "A": "the best performing class while also being more than twice as frequent as any other component.",
          "Ablation Study for Feature Based Maximum Entropy Classiﬁcation Model of": ""
        }
      ],
      "page": 11
    },
    {
      "caption": "Table 6: shows the performance scores if just one additional feature is enabled (while bag-of-words",
      "data": [
        {
          "have respective values of 0.56 and 0.71, with the high micro score resulting from cognitive appraisal being": "the best performing class while also being more than twice as frequent as any other component."
        },
        {
          "have respective values of 0.56 and 0.71, with the high micro score resulting from cognitive appraisal being": ""
        },
        {
          "have respective values of 0.56 and 0.71, with the high micro score resulting from cognitive appraisal being": "Component"
        },
        {
          "have respective values of 0.56 and 0.71, with the high micro score resulting from cognitive appraisal being": "Cognitive appraisal"
        },
        {
          "have respective values of 0.56 and 0.71, with the high micro score resulting from cognitive appraisal being": "Neurophysiological symptoms"
        },
        {
          "have respective values of 0.56 and 0.71, with the high micro score resulting from cognitive appraisal being": "Action tendencies"
        },
        {
          "have respective values of 0.56 and 0.71, with the high micro score resulting from cognitive appraisal being": "Motor expressions"
        },
        {
          "have respective values of 0.56 and 0.71, with the high micro score resulting from cognitive appraisal being": "Subjective feelings"
        },
        {
          "have respective values of 0.56 and 0.71, with the high micro score resulting from cognitive appraisal being": "Macro avg."
        },
        {
          "have respective values of 0.56 and 0.71, with the high micro score resulting from cognitive appraisal being": "Micro avg."
        },
        {
          "have respective values of 0.56 and 0.71, with the high micro score resulting from cognitive appraisal being": "Cognitive appraisal"
        },
        {
          "have respective values of 0.56 and 0.71, with the high micro score resulting from cognitive appraisal being": "Neurophysiological symptoms"
        },
        {
          "have respective values of 0.56 and 0.71, with the high micro score resulting from cognitive appraisal being": "Action tendencies"
        },
        {
          "have respective values of 0.56 and 0.71, with the high micro score resulting from cognitive appraisal being": "Motor expressions"
        },
        {
          "have respective values of 0.56 and 0.71, with the high micro score resulting from cognitive appraisal being": "Subjective feelings"
        },
        {
          "have respective values of 0.56 and 0.71, with the high micro score resulting from cognitive appraisal being": "Macro avg."
        },
        {
          "have respective values of 0.56 and 0.71, with the high micro score resulting from cognitive appraisal being": "Micro avg."
        }
      ],
      "page": 11
    },
    {
      "caption": "Table 6: shows the performance scores if just one additional feature is enabled (while bag-of-words",
      "data": [
        {
          "complete results for the neural network, including precision and recall values.": ""
        },
        {
          "complete results for the neural network, including precision and recall values.": "Emotion"
        },
        {
          "complete results for the neural network, including precision and recall values.": "Anger"
        },
        {
          "complete results for the neural network, including precision and recall values.": "Anticipation"
        },
        {
          "complete results for the neural network, including precision and recall values.": "Disgust"
        },
        {
          "complete results for the neural network, including precision and recall values.": "Fear"
        },
        {
          "complete results for the neural network, including precision and recall values.": "Joy"
        },
        {
          "complete results for the neural network, including precision and recall values.": "Neutral"
        },
        {
          "complete results for the neural network, including precision and recall values.": "Other"
        },
        {
          "complete results for the neural network, including precision and recall values.": "Sadness"
        },
        {
          "complete results for the neural network, including precision and recall values.": "Surprise"
        },
        {
          "complete results for the neural network, including precision and recall values.": "Trust"
        },
        {
          "complete results for the neural network, including precision and recall values.": "Macro avg."
        },
        {
          "complete results for the neural network, including precision and recall values.": "Micro avg."
        },
        {
          "complete results for the neural network, including precision and recall values.": "Anger"
        },
        {
          "complete results for the neural network, including precision and recall values.": "Disgust"
        },
        {
          "complete results for the neural network, including precision and recall values.": "Fear"
        },
        {
          "complete results for the neural network, including precision and recall values.": "Joy"
        },
        {
          "complete results for the neural network, including precision and recall values.": "Sadness"
        },
        {
          "complete results for the neural network, including precision and recall values.": "Surprise"
        },
        {
          "complete results for the neural network, including precision and recall values.": "Macro avg."
        },
        {
          "complete results for the neural network, including precision and recall values.": "Micro avg."
        }
      ],
      "page": 11
    },
    {
      "caption": "Table 8: Neural network parameters. In cases where multiple values are displayed, the first value refers to the",
      "data": [
        {
          "Parameter": "Bi-LSTM units",
          "Cpm-NN-Base": "24",
          "Emo-NN-Base": "24",
          "Emo-Cpm-NN-Gold": "24",
          "Emo-Cpm-NN-Pred": "24",
          "MTL-XS": "32 / 24",
          "MTL-MH": "24"
        },
        {
          "Parameter": "CNN ﬁlters",
          "Cpm-NN-Base": "10",
          "Emo-NN-Base": "10",
          "Emo-Cpm-NN-Gold": "16",
          "Emo-Cpm-NN-Pred": "16",
          "MTL-XS": "12 / 10",
          "MTL-MH": "16"
        },
        {
          "Parameter": "FC neurons (cpm)",
          "Cpm-NN-Base": "128",
          "Emo-NN-Base": "—",
          "Emo-Cpm-NN-Gold": "96",
          "Emo-Cpm-NN-Pred": "64",
          "MTL-XS": "128",
          "MTL-MH": "128"
        },
        {
          "Parameter": "FC neurons (emo)",
          "Cpm-NN-Base": "—",
          "Emo-NN-Base": "128",
          "Emo-Cpm-NN-Gold": "128",
          "Emo-Cpm-NN-Pred": "128",
          "MTL-XS": "128",
          "MTL-MH": "128"
        },
        {
          "Parameter": "FC neurons (comb.)",
          "Cpm-NN-Base": "—",
          "Emo-NN-Base": "—",
          "Emo-Cpm-NN-Gold": "128",
          "Emo-Cpm-NN-Pred": "96",
          "MTL-XS": "—",
          "MTL-MH": "—"
        },
        {
          "Parameter": "Loss weight (emo)",
          "Cpm-NN-Base": "—",
          "Emo-NN-Base": "4.0",
          "Emo-Cpm-NN-Gold": "6.0",
          "Emo-Cpm-NN-Pred": "4.0",
          "MTL-XS": "7.8",
          "MTL-MH": "7.8"
        },
        {
          "Parameter": "Loss weight (cpm)",
          "Cpm-NN-Base": "1.5",
          "Emo-NN-Base": "—",
          "Emo-Cpm-NN-Gold": "—",
          "Emo-Cpm-NN-Pred": "—",
          "MTL-XS": "1.5",
          "MTL-MH": "1.5"
        },
        {
          "Parameter": "Task weight (emo)",
          "Cpm-NN-Base": "—",
          "Emo-NN-Base": "1.0",
          "Emo-Cpm-NN-Gold": "1.0",
          "Emo-Cpm-NN-Pred": "1.0",
          "MTL-XS": "0.75",
          "MTL-MH": "0.75"
        },
        {
          "Parameter": "Task weight (cpm)",
          "Cpm-NN-Base": "1.0",
          "Emo-NN-Base": "—",
          "Emo-Cpm-NN-Gold": "—",
          "Emo-Cpm-NN-Pred": "—",
          "MTL-XS": "0.5",
          "MTL-MH": "0.35"
        },
        {
          "Parameter": "Minibatch size",
          "Cpm-NN-Base": "60",
          "Emo-NN-Base": "50",
          "Emo-Cpm-NN-Gold": "50",
          "Emo-Cpm-NN-Pred": "50",
          "MTL-XS": "25",
          "MTL-MH": "25"
        },
        {
          "Parameter": "Bi-LSTM units",
          "Cpm-NN-Base": "24",
          "Emo-NN-Base": "24",
          "Emo-Cpm-NN-Gold": "24",
          "Emo-Cpm-NN-Pred": "24",
          "MTL-XS": "32/24",
          "MTL-MH": "24"
        },
        {
          "Parameter": "CNN ﬁlters",
          "Cpm-NN-Base": "32",
          "Emo-NN-Base": "32",
          "Emo-Cpm-NN-Gold": "32",
          "Emo-Cpm-NN-Pred": "32",
          "MTL-XS": "24/24",
          "MTL-MH": "32"
        },
        {
          "Parameter": "FC neurons (cpm)",
          "Cpm-NN-Base": "32",
          "Emo-NN-Base": "—",
          "Emo-Cpm-NN-Gold": "—",
          "Emo-Cpm-NN-Pred": "64",
          "MTL-XS": "128",
          "MTL-MH": "32"
        },
        {
          "Parameter": "FC neurons (emo)",
          "Cpm-NN-Base": "—",
          "Emo-NN-Base": "128",
          "Emo-Cpm-NN-Gold": "128",
          "Emo-Cpm-NN-Pred": "128",
          "MTL-XS": "128",
          "MTL-MH": "128"
        },
        {
          "Parameter": "FC neurons (comb.)",
          "Cpm-NN-Base": "—",
          "Emo-NN-Base": "—",
          "Emo-Cpm-NN-Gold": "256",
          "Emo-Cpm-NN-Pred": "256",
          "MTL-XS": "—",
          "MTL-MH": "—"
        },
        {
          "Parameter": "Loss weight (emo)",
          "Cpm-NN-Base": "—",
          "Emo-NN-Base": "1.0",
          "Emo-Cpm-NN-Gold": "1.0",
          "Emo-Cpm-NN-Pred": "1.0",
          "MTL-XS": "1.0",
          "MTL-MH": "1.0"
        },
        {
          "Parameter": "Loss weight (cpm)",
          "Cpm-NN-Base": "1.0",
          "Emo-NN-Base": "—",
          "Emo-Cpm-NN-Gold": "—",
          "Emo-Cpm-NN-Pred": "—",
          "MTL-XS": "1.0",
          "MTL-MH": "1.0"
        },
        {
          "Parameter": "Task weight (emo)",
          "Cpm-NN-Base": "—",
          "Emo-NN-Base": "1.0",
          "Emo-Cpm-NN-Gold": "1.0",
          "Emo-Cpm-NN-Pred": "1.0",
          "MTL-XS": "0.75",
          "MTL-MH": "0.5"
        },
        {
          "Parameter": "Task weight (cpm)",
          "Cpm-NN-Base": "1.0",
          "Emo-NN-Base": "—",
          "Emo-Cpm-NN-Gold": "—",
          "Emo-Cpm-NN-Pred": "—",
          "MTL-XS": "0.5",
          "MTL-MH": "0.5"
        },
        {
          "Parameter": "Minibatch size",
          "Cpm-NN-Base": "40",
          "Emo-NN-Base": "80",
          "Emo-Cpm-NN-Gold": "80",
          "Emo-Cpm-NN-Pred": "80",
          "MTL-XS": "80",
          "MTL-MH": "80"
        }
      ],
      "page": 12
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "stolen. In seeking to recover the stolen horse, he unintentionally stole another. (REMAN)"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "Emotion Emo-NN-Base\ndisgust, other, sadness"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "cognitive appraisal\nCPM, MTL-XS"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "neutral\nEmotion, MTL-XS"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "CPM Gold\ncognitive appraisal, action tendency"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "neutral\nEmotion Gold"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "(2) In that fatal valley, at the foot of that declivity which the cuirassiers had ascended, now inundated by the masses of the English, under"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "the converging ﬁres of the victorious hostile cavalry, under a frightful density of projectiles, this square fought on. It was commanded by"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "an obscure ofﬁcer named Cambronne. At each discharge, the square diminished and replied. (REMAN)"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "Emotion Emo-NN-Base\nanger, disgust, fear"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "CPM, MTL-XS\ncognitive appraisal, subjective feeling"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "fear\nEmotion, MTL-XS"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "cognitive appraisal\nCPM Gold"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "fear\nEmotion Gold"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "(3) If sleep came at all,\nit might be a sleep without waking. But after all\nthat was but one chance in a hundred:\nthe action of the drug"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "was incalculable, and the addition of a few drops to the regular dose would probably do no more than procure for her the rest she so"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "desperately needed....\nShe did not,\nin truth, consider\nthe question very closely–the physical craving for sleep was her only sustained"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "sensation. Her mind shrank from the glare of thought as instinctively as eyes contract in a blaze of light–darkness, darkness was what she"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "must have at any cost. (REMAN)"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "Emotion Emo-NN-Base\nsadness, fear"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "CPM, MTL-XS\ncognitive appraisal, action tendency"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "Emotion, MTL-XS\nfear, anticipation"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "CPM Gold\ncognitive appraisal, neurophysiological symptoms, action tendencies"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "Emotion Gold\nfear, anticipation"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "(4) @justinbieber nocticed a girl the ﬁrst day she got a twitter! :( (TEC)"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "Emotion Emo-NN-Base\njoy"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "CPM, MTL-XS\ncognitive appraisal, subjective feeling"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "sadness\nEmotion, MTL-XS"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "CPM Gold\ncognitive appraisal, subjective feeling"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "sadness\nEmotion Gold"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "(5) when the love of your life is half way acrosss the world (TEC)"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "Emotion Emo-NN-Base\njoy"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "subjective feeling\nCPM, MTL-XS"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "sadness\nEmotion, MTL-XS"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "cognitive appraisal\nCPM Gold"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "sadness\nEmotion Gold"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "(6) My sister is home! YAY. VISIT (TEC)"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "cognitive appraisal, motor expression\nCPM Cpm-ME-Adv"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "Emotion Emo-ME-Base\njoy"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "surprise\nEmotion Emo-Cpm-ME-Pred"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "surprise\nEmotion Emo-Cpm-ME-Gold"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "cognitive appraisal, motor expression\nCPM Gold"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "surprise\nEmotion Gold"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "(7) @lauren frost It was?!?! What the heck, man! I always miss it! Haha. - You guys need another reunion!! :) (TEC)"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "cognitive appraisal, motor expression, subjective feeling\nCPM Cpm-ME-Adv"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "Emotion Emo-ME-Base\nsurprise"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "sadness\nEmotion Emo-Cpm-ME-Pred"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "sadness\nEmotion Emo-Cpm-ME-Gold"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "cognitive appraisal, motor expression, subjective feeling\nCPM Gold"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "sadness\nEmotion Gold"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "(8) And if this was a necessary preparation for what, should follow, I would be the very last\nto complain of it. We went\nto bed again,"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "and the forsaken child of some half-animal mother, now perhaps asleep in some ﬁlthy lodging for tramps,\nlay in my Ethelwyn’s bosom."
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "I loved her the more for it;\nthough, I confess,\nit would have been very painful\nto me had she shown it possible for her to treat\nthe baby"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "otherwise, especially after what we had been talking about that same evening. (REMAN)"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "CPM Cpm-ME-Adv\ncognitive appraisal, action tendency, subjective feeling"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "Emotion Emo-ME-Base\n/"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "joy\nEmotion Emo-Cpm-ME-Pred"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "joy\nEmotion Emo-Cpm-ME-Gold"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "cognitive appraisal, subjective feeling\nCPM Gold"
        },
        {
          "(1) As for the hero of this story, ’His One Fault’ was absent-mindedness. He forgot\nto lock his uncle’s stable door, and the horse was": "Emotion Gold\ndisgust, joy, sadness, trust"
        }
      ],
      "page": 13
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "A survey of state-of-the-art approaches for emotion recognition in text",
      "authors": [
        "Nourah Alswaidan",
        "Mohamed Menai"
      ],
      "year": "2020",
      "venue": "Knowledge and Information Systems",
      "doi": "10.1007/s10115-020-01449-0"
    },
    {
      "citation_id": "2",
      "title": "Building and exploiting emotinet, a knowledge base for emotion detection based on the appraisal theory model",
      "authors": [
        "Alexandra Balahur",
        "Jesus Hermida",
        "Andrew Montoyo"
      ],
      "year": "2012",
      "venue": "IEEE Transactions on Affective Computing",
      "doi": "10.1109/T-AFFC.2011.33"
    },
    {
      "citation_id": "3",
      "title": "An analysis of annotated corpora for emotion classification in text",
      "authors": [
        "Laura-Ana-Maria Bostan",
        "Roman Klinger"
      ],
      "year": "2018",
      "venue": "Proceedings of the 27th International Conference on Computational Linguistics"
    },
    {
      "citation_id": "4",
      "title": "EmoBank: Studying the impact of annotation perspective and representation format on dimensional emotion analysis",
      "authors": [
        "Sven Buechel",
        "Udo Hahn"
      ],
      "year": "2017",
      "venue": "Proceedings of the 15th Conference of the European Chapter"
    },
    {
      "citation_id": "5",
      "title": "",
      "authors": [
        "Sven Buechel",
        "Luise Modersohn",
        "Udo Hahn"
      ],
      "year": "2020",
      "venue": ""
    },
    {
      "citation_id": "6",
      "title": "Senticnet 3: A common and common-sense knowledge base for cognition-driven sentiment analysis",
      "authors": [
        "Erik Cambria",
        "Daniel Olsher",
        "Dheeraj Rajagopal"
      ],
      "year": "2014",
      "venue": "Proceedings of the AAAI"
    },
    {
      "citation_id": "7",
      "title": "Advanced combined LSTM-CNN model for Twitter sentiment analysis",
      "authors": [
        "Nan Chen",
        "Peikang Wang"
      ],
      "year": "2018",
      "venue": "2018 5th IEEE International Conference on Cloud Computing and Intelligence Systems (CCIS)",
      "doi": "10.1109/CCIS.2018.8691381"
    },
    {
      "citation_id": "8",
      "title": "Psychological construction in the OCC model of emotion",
      "authors": [
        "Gerald Clore",
        "Andrew Ortony"
      ],
      "year": "2013",
      "venue": "Emotion Review",
      "doi": "10.1177/1754073913489751"
    },
    {
      "citation_id": "9",
      "title": "Natural language processing (almost) from scratch",
      "authors": [
        "Ronan Collobert",
        "Jason Weston",
        "Léon Bottou",
        "Michael Karlen",
        "Koray Kavukcuoglu",
        "Pavel Kuksa"
      ],
      "year": "2011",
      "venue": "Journal of machine learning research"
    },
    {
      "citation_id": "10",
      "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "authors": [
        "Jacob Devlin",
        "Ming-Wei Chang",
        "Kenton Lee",
        "Kristina Toutanova"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
      "doi": "10.18653/v1/N19-1423"
    },
    {
      "citation_id": "11",
      "title": "An argument for basic emotions",
      "authors": [
        "Paul Ekman"
      ],
      "year": "1992",
      "venue": "Cognition & emotion",
      "doi": "10.1080/02699939208411068"
    },
    {
      "citation_id": "12",
      "title": "Long short-term memory",
      "authors": [
        "Sepp Hochreiter",
        "Jürgen Schmidhuber"
      ],
      "year": "1997",
      "venue": "Neural Computation",
      "doi": "10.1162/neco.1997.9.8.1735"
    },
    {
      "citation_id": "13",
      "title": "Appraisal theories for emotion classification in text",
      "authors": [
        "Jan Hofmann",
        "Enrica Troiano",
        "Kai Sassenberg",
        "Roman Klinger"
      ],
      "year": "2020",
      "venue": "Proceedings of the 28th International Conference on Computational Linguistics",
      "doi": "10.18653/v1/2020.coling-main.11"
    },
    {
      "citation_id": "14",
      "title": "Who feels what and why? annotation of a literature corpus with semantic roles of emotions",
      "authors": [
        "Matthew Honnibal",
        "Ines Montani",
        "Sofie Van Landeghem",
        "Adriane Boyd"
      ],
      "year": "2018",
      "venue": "Proceedings of the 27th International Conference on Computational Linguistics",
      "doi": "10.5281/zenodo.1212303"
    },
    {
      "citation_id": "15",
      "title": "An analysis of emotion communication channels in fan-fiction: Towards emotional storytelling",
      "authors": [
        "Evgeny Kim",
        "Roman Klinger"
      ],
      "year": "2019",
      "venue": "Proceedings of the Second Workshop on Storytelling",
      "doi": "10.18653/v1/W19-3406"
    },
    {
      "citation_id": "16",
      "title": "Adam: A method for stochastic optimization",
      "authors": [
        "P Diederik",
        "Jimmy Kingma",
        "Ba"
      ],
      "year": "2015",
      "venue": "International Conference on Learning Representations (ICLR Poster)"
    },
    {
      "citation_id": "17",
      "title": "Representing emotions in literature and paintings: A comparative analysis",
      "authors": [
        "M Jacques",
        "Van Meel"
      ],
      "year": "1995",
      "venue": "Poetics",
      "doi": "10.1016/0304-422X(94)00013-V"
    },
    {
      "citation_id": "18",
      "title": "Cross-stitch networks for multi-task learning",
      "authors": [
        "Ishan Misra",
        "Abhinav Shrivastava",
        "Abhinav Gupta",
        "Martial Hebert"
      ],
      "year": "2016",
      "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition"
    },
    {
      "citation_id": "19",
      "title": "#emotional tweets",
      "authors": [
        "Saif Mohammad"
      ],
      "year": "2012",
      "venue": "SEM 2012: The First Joint Conference on Lexical and Computational Semantics"
    },
    {
      "citation_id": "20",
      "title": "SemEval-2018 task 1: Affect in tweets",
      "authors": [
        "Saif Mohammad",
        "Felipe Bravo-Marquez",
        "Mohammad Salameh",
        "Svetlana Kiritchenko"
      ],
      "year": "2018",
      "venue": "Proceedings of The 12th International Workshop on Semantic Evaluation",
      "doi": "10.18653/v1/S18-1001"
    },
    {
      "citation_id": "21",
      "title": "GloVe: Global vectors for word representation",
      "authors": [
        "Jeffrey Pennington",
        "Richard Socher",
        "Christopher Manning"
      ],
      "year": "2014",
      "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
      "doi": "10.3115/v1/D14-1162"
    },
    {
      "citation_id": "22",
      "title": "The nature of emotions: Human emotions have deep evolutionary roots, a fact that may explain their complexity and provide tools for clinical practice",
      "authors": [
        "Robert Plutchik"
      ],
      "year": "2001",
      "venue": "American scientist"
    },
    {
      "citation_id": "23",
      "title": "Event2Mind: Commonsense inference on events, intents, and reactions",
      "authors": [
        "Maarten Hannah Rashkin",
        "Emily Sap",
        "Noah Allaway",
        "Yejin Smith",
        "Choi"
      ],
      "year": "2018",
      "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/P18-1043"
    },
    {
      "citation_id": "24",
      "title": "Evidence for a three-factor theory of emotions",
      "authors": [
        "James Russell",
        "Albert Mehrabian"
      ],
      "year": "1977",
      "venue": "Journal of Research in Personality",
      "doi": "10.1016/0092-6566(77)90037-X"
    },
    {
      "citation_id": "25",
      "title": "What are emotions? and how can they be measured?",
      "authors": [
        "Klaus Scherer"
      ],
      "year": "2005",
      "venue": "Social Science Information",
      "doi": "10.1177/0539018405058216"
    },
    {
      "citation_id": "26",
      "title": "Emotions are emergent processes: they require a dynamic computational architecture",
      "authors": [
        "Klaus Scherer"
      ],
      "year": "1535",
      "venue": "Philosophical Transactions of the Royal Society B",
      "doi": "10.1098/rstb.2009.0141"
    },
    {
      "citation_id": "27",
      "title": "Evidence for universality and cultural variation of differential emotion response patterning",
      "authors": [
        "Klaus Scherer",
        "Harald Wallbott"
      ],
      "year": "1994",
      "venue": "Journal of personality and social psychology",
      "doi": "10.1037//0022-3514.66.2.310"
    },
    {
      "citation_id": "28",
      "title": "A linguistic interpretation of the OCC emotion model for affect sensing from text. Affective Information Processing",
      "authors": [
        "Mostafa Al",
        "Masum Shaikh",
        "Helmut Prendinger",
        "Mitsuru Ishizuka"
      ],
      "year": "2009",
      "venue": "A linguistic interpretation of the OCC emotion model for affect sensing from text. Affective Information Processing",
      "doi": "10.1007/978-1-84800-306-4_4"
    },
    {
      "citation_id": "29",
      "title": "Patterns of cognitive appraisal in emotion",
      "authors": [
        "Craig Smith",
        "Phoebe Ellsworth"
      ],
      "year": "1985",
      "venue": "Journal of personality and social psychology"
    },
    {
      "citation_id": "30",
      "title": "Twitter sentiment analysis using combined LSTM-CNN models",
      "authors": [
        "Pedro Sosa"
      ],
      "year": "2017",
      "venue": "Eprint Arxiv"
    },
    {
      "citation_id": "31",
      "title": "Crowdsourcing and validating event-focused emotion corpora for German and English",
      "authors": [
        "Enrica Troiano",
        "Sebastian Padó",
        "Roman Klinger"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/P19-1391"
    },
    {
      "citation_id": "32",
      "title": "A rule-based approach to implicit emotion detection in text",
      "authors": [
        "Orizu Udochukwu",
        "Yulan He"
      ],
      "year": "2015",
      "venue": "Natural Language Processing and Information Systems",
      "doi": "10.1007/978-3-319-19581-0_17"
    }
  ]
}