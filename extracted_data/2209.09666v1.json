{
  "paper_id": "2209.09666v1",
  "title": "Documenting Use Cases In The Affective Computing Domain Using Unified Modeling Language",
  "published": "2022-09-19T10:04:18Z",
  "authors": [
    "Isabelle Hupont",
    "Emilia Gomez"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "The study of the ethical impact of AI and the design of trustworthy systems needs the analysis of the scenarios where AI systems are used, which is related to the software engineering concept of \"use case\" and the \"intended purpose\" legal term. However, there is no standard methodology for use case documentation covering the context of use, scope, functional requirements and risks of an AI system. In this work, we propose a novel documentation methodology for AI use cases, with a special focus on the affective computing domain. Our approach builds upon an assessment of use case information needs documented in the research literature and the recently proposed European regulatory framework for AI. From this assessment, we adopt and adapt the Unified Modeling Language (UML), which has been used in the last two decades mostly by software engineers. Each use case is then represented by an UML diagram and a structured table, and we provide a set of examples illustrating its application to several affective computing scenarios.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "I. Introduction",
      "text": "Given the social and ethical impact that some affective computing systems may have  [1] , it becomes of the utmost importance to clearly identify and document their context of use, envisaged operational scenario or intended purpose. Undertaking such use case documentation practices would benefit, among others, system vendors and developers to make key design decisions from early development stages (e.g. target user profile/population, data gathering strategies, human oversight mechanisms to be put in place), authorities and auditors to assess the potential risks and misuses of a system, end users to understand the permitted uses of a commercial system, the people on whom the system is used to know how their data is processed and, in general, the wide public to have a better informed knowledge of the technology.\n\nThe need for transparency and documentation practices in the field of Artificial Intelligence (AI) has been widely acknowledged in the recent literature  [2] . Several methodologies have been proposed for AI documentation, but their focus is rather on data  [3]  and models  [4]  than AI systems as a whole, limiting at most the documentation of use cases to a brief textual description. Nowadays, voluntary AI documentation practices are in the process of becoming legal requirements in some countries. The European Commission presented in April 2021 its pioneering proposal for the Regulation of Artificial Intelligence, the AI Act  [5] , which regulates software systems that are developed with AI techniques such as machine or deep learning. Interestingly, the legal text does not mandate any specific technical solutions or approaches to be adopted; instead, it focuses on the intended purpose of an AI system which determines its risk profile and, consequently, a set of legal requirements that must be met. The AI Act's approach further reinforces the need to properly document AI use cases.\n\nThe concept of use case has been used in classic software development for more than 20 years. Use cases are powerful documentation tools to capture the context of use, scope and functional requirements of a software system. They allow structuring requirements according to user goals  [6]  and provide a means to specify the interaction between a certain software system and its environment  [7] . This work revisits classic software use case documentation methodologies, more particularly those based on the Unified Markup Language (UML) specification  [8] , and proposes a template-based approach for AI use case documentation considering current information needs identified in the research literature and the European AI Act. Although the documentation methodology we propose is horizontal, i.e. it can be applied to different domains (e.g AI for medicine, social media, law enforcement), we address the specific information needs of affective computing use cases. The objective is to provide a standardised basis for an AI and affective computing technology-agnostic use case repository, where different aspects such as intended users, opportunities or risk levels can be easily assessed. To the best of our knowledge, this is the first methodology specific to the documentation of AI use cases.\n\nThe remainder of the paper is as follows. Section II provides an overview of the current AI regulatory framework, existing approaches for the documentation of AI and affective computing systems, and a background on UML. Section III identifies use case information needs and proposes an UML-based methodology for their unified documentation. In Section IV, we put the methodology into practice with some concrete exemplar affective computing use cases. Finally, Section V concludes the paper.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Ii. Background",
      "text": "",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "A. \"Intended Purpose\" And \"Emotion Recognition Systems\" In The Ai Act",
      "text": "The intended purpose of an AI system is central to the European AI Act. It is defined as \"the use for which an AI system is intended by the provider, including the specific context and conditions of use, as specified in the information supplied by the provider in the instructions for use, promotional or sales materials and statements, as well as in the technical documentation\" 1  . An AI system's intended purpose determines its risk profile which can be, from highest to lowest: (1) unacceptable risk, covering harmful uses of AI or uses that contradict ethical values; (2) high-risk, covering uses identified through a list of high-risk application areas that may create an adverse impact on people's safety, health or fundamental rights; (3) transparency risk, covering uses that are subject to a set of transparency rules (e.g. conversational agents, deepfakes); and (4) minimal risk, covering all other AI systems.\n\nThe AI Act explicitly and implicitly refers to affective computing systems in several parts of the legal text 2 . A transparency risk generally applies to affective computing systems, but there are some clearly identified prohibited practices and high-risk areas. Prohibited practices include systems used to distort a person's behaviour to cause psychological harm, and systems used by public authorities to perform social scoring based on predicted personality or social behaviour. AI systems intended to be used as \"polygraphs and similar tools or to detect the emotional state of a person\" are listed as high-risk in the areas of \"law enforcement\" and \"migration, asylum and border control management\". There might be situations where emotion recognition is exploited in recruitment contexts or to determine access to educational institutions, which would also be high-risk, as would emotion recognition systems being a safety component of a product (e.g. a system integrated in a car that detects a driver's drowsiness and undertakes a safety action) or that are part of a machine or medical device (e.g. a companion robot for autistic children).\n\nTherefore, the AI Act establishes a clear set of harmonised rules that link use cases -including affective computing onesto risk levels, which in turn imply different legal requirements. This opens the door to the creation of a use case documentation methodology allowing for an unambiguous assessment of risk levels, such as the one proposed in this work, which could be a valuable tool for different stakeholders, ranging from system providers to authorities.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "B. Current Approaches For The Documentation Of Ai Systems",
      "text": "In the recent years, both key academic and industry players have proposed methodologies aiming at defining documentation approaches that increase transparency and trust in AI.\n\nAmong the most successful initiatives, we find some that focus on documenting the datasets used for AI, such as Datasheets for Datasets  [3] , The Dataset Nutrition Label  [9] ,  [10]  and Data Cards  [11] , as well as some that address the documentation of AI models and algorithms from a technical perspective, such as Model Cards  [4]  and AI Factsheets  [12] . Very recently, the Organisation for Economic Co-operation and Development (OECD) has proposed a policy-oriented Framework for the classification of AI systems  [13]  to which high-calibre institutions and a large number of AI practitioners have contributed. Being in the form of questionnaires or more visual factsheets, these methodologies are not based on formal documentation standards or specifications. Moreover, even though some of them do explicitly ask about the intended use of AI the system (e.g. \"What is the intended use of the service output?\"  [12]  and \"Intended Use\" section in  [4] ), it is just in very broad terms and provided examples lack sufficient details to address complex legal concerns. To date, there is no unified and comprehensive AI documentation approach focusing exclusively on use cases.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "C. Documentation Of Affective Computing Use Cases",
      "text": "The aforementioned documentation approaches have scarcely been used in the field of affective computing. Only the Model Cards original paper comes with a \"smiling detection in images\" and a detection of \"toxicity in text\" example. Use cases in the field have rather been presented to the community in plain text form (i.e. without following any documentation template), either in survey papers  [14] -  [16] , in papers presenting a very concrete application  [17] -  [19]  or in articles discussing ethical issues  [1] ,  [20] ,  [21] . Interestingly, the Association for the Advancement of Affective Computing (AAAC) has recently launched the affective computing commercial products database  [22] , which presents a table with a list of commercial products, a brief description of each one and associated tags such as modality (e.g. speech, text, face), format (e.g. software, hardware) and application domain (e.g. general purpose, education, health). It is however limited to a high level description of real products in the market.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "D. Unified Modeling Language (Uml) For Use Case Reporting",
      "text": "The Unified Modeling Language (UML) specification has been widely used in software engineering in the last two decades  [8] ,  [23] . It provides a standard way to visualize the design and behaviour of a system by introducing a set of graphical notation elements. In particular, it allows for use case modelling, without entering into implementation details, in the form of intuitive use case diagrams whose main elements are depicted in Figure  1 .\n\nUse cases capture a system's requirements, i.e., what the system is supposed to do. A use case is triggered by an actor (it might be a person or group of persons), who is called primary actor. The use case describes the various sets of interactions that can occur between the various actors, while the primary actor is in pursuit of a goal. A use case is completed successfully when the goal that is associated with it is reached. Use case descriptions also include possible extensions to this sequence, e.g., alternative sequences that may also satisfy the goal, as well as sequences that may lead to failure in completing the service.\n\nOnce use cases have been modelled in a diagrammatic form, the next step is to describe them in an easy-to-understand and structured written manner. Traditional use case modelling always includes this step, and several standards have been suggested for the layout of use case descriptions. The most widely used is the table format proposed by Cockburn in  [6]  and shown in Figure  2 -left.\n\nUML is an powerful tool for use case documentation and communication, even to non-technical audiences. Nevertheless, it has not yet been exploited to document AI use cases.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Iii. An Uml-Based Documentation Methodology",
      "text": "FOR AI AND AFFECTIVE COMPUTING USE CASES We propose a novel methodology for the documentation of AI use cases which is grounded on (1) the UML standard specification for use case modeling and (2) the requirements for use case documentation under the European AI Act. Our methodology pays particular attention to information needs related to affective computing use cases. It is intended to be a tool to increase transparency and facilitate the understanding of the intended purpose of an AI system, in order to ease the assessment of its risk level and other relevant contextual considerations.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "A. Information Needs Related To The \"Intended Purpose\" Under The Ai Act",
      "text": "As discussed in Section II-A, the European AI Act centres around the concept of intended use. Several key information elements are essential to document the intended use of an AI system according to the legal text. We have compiled them in the list presented in Table  I . As can be seen, the intended purpose of the system shall be put into context by providing additional information on: who will be the users and the target persons on which the system is intended to be used; the operational, geographical, behavioural and functional contexts of use that are foreseen, including a description of the hardware on which the system is intended to run (e.g. to highlight whether it is part of a device/machine); which are the system's inputs and outputs; and, if applicable, whether the system is a safety component of a product. Additionally, it is as important to clearly specify the intended use of the system as its foreseeable potential misuses and unintended purposes.\n\nFinally, the application areas information element is one of the most important to assess when it comes to identify a system's risk level. The legal text links some practices, areas and concrete applications within these areas to prohibited practices and high-risk profiles. Table  II  compiles the prohibited practices (top) and high-risk application areas (bottom) mentioned in the legal text that are directly related to emotion recognition, or where some kind of affective computing technique could potentially be used (e.g. personality prediction for social scoring, facial expression recognition for student proctoring, pain detection for establishing priority in emergency services). In order to facilitate the identification of the level of risk of an affective computing system, it is therefore essential to indicate whether its intended application area(s) or any foreseeable misuse are among those on the list.\n\nIt should be noted that Table  I  is not meant to be a final and exhaustive list of information elements needed for compliance with any future legal requirement. First and foremost, because the AI regulation is still under negotiation, and is therefore subject to be modified in its road towards adoption. Second, because the objective of this work is the documentation of use cases, which is just a small part of the technical documentation required to demonstrate conformity with the legal text.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Element Description",
      "text": "",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Intended Purpose",
      "text": "Use for which an AI system is intended by the provider.\n\nIf the system is a safety component of a product, it must be clearly stated.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "User",
      "text": "Natural or legal person using an AI system under its authority.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Target Persons",
      "text": "Persons or group of persons on which the system is intended to be used.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Context Of Use",
      "text": "Description of all forms on which the system is deployed (e.g. characteristics of the specific geographical, behavioural or functional setting) and of the hardware on which it is intended to run.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Application Areas",
      "text": "List of areas in which the AI system is intended to be applied, including those in Table  II .",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Reasonably Foreseeable Misuses",
      "text": "Uses of an AI system in a way that is not in accordance with its intended purpose, which may lead to errors, faults, inconsistencies, or risks to health, safety or fundamental rights.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Inputs",
      "text": "Data provided to or directly acquired by the system, on the basis of which the system produces an output.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Outputs",
      "text": "Outputs of the AI system as provided to the user.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "B. Revisiting Uml For Ai And Affective Computing Use Case Documentation",
      "text": "The idea of intended use defined in the AI Act is closely related to the traditional software concept of use case, as defined in the UML specification. UML use case diagrams do not enter into technical details (e.g. implementation details, algorithm architectures) but rather focus on the context of use, the main actors using the system, and actor-actor and actor-system interactions, which is a focus aligned with that proposed by the AI Act to assess a system's risk level. The UML language is thus a powerful, standardized and highly visual tool to operationalise the need for a unified documentation of AI use cases.\n\nIn Figure  2 -right, we propose an adaptation of the classic table template accompanying UML use case diagrams  [6]  to the AI Act's taxonomy. As can be seen, the adapted fields are minimal and there is an almost perfect correspondence with the original template. We have only renamed some key words (in blue in the table), namely scope to intended purpose, primary actor to user, stakeholders and interests to target persons, and open issues to misuses. We have also included a new field called application areas (in green), allowing to clearly identify the area(s) in which the system is intended to be used and, if applicable, specify whether they correspond to those listed in Table  II .",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Iv. Methodology In Practice: Example Of Affective Computing Use Cases",
      "text": "In this section, we apply the proposed methodology to the documentation of three representative affective computing systems. Figures  3 4 5 show their corresponding UML use case diagrams and accompanying tables, which are further described below.\n\nSmart camera. In this first use case, the system is a smart camera that shoots a picture only when all the people posing in front of it are smiling. There are several products in the market with this feature  [24] ,  [25] , which have inspired this example. The UML diagram of the smart shooting use case and its corresponding table are shown in Figure  3  left and right, correspondingly. This application may seem simple and naive a priori, but it has recently caused controversy. Workers at a Beijing office were forced to smile to an AI camera to get through the front doors, change the temperature or print documents, in an attempt to improve the working environment by keeping workers happy  [26] . However, some workers felt their emotions were manipulated. Our proposed UML table makes it clear that the target application domain is entertainment and leisure exclusively, and the misuses field explicitly emphasises that the system is not conceived to be used to monitor or manipulate emotions in contexts such as working environments. This important claim excludes the use case from the high-risk area of workers management > monitoring and evaluation of performance and behaviour (c.f. Table  II ).\n\nAffective music recommender. Figure  4  shows the UML diagram and table for the second use case, corresponding to an affective music recommender system proposing songs to the user based on her personality, current mood and playlist history. This use case has been inspired by the work presented in  [27] . Several studies have shown that users' music playlists can be used to infer emotions, personality traits and vulnerabilities  [28] ; the other way round, certain music pieces can induce behaviours and manipulate listeners' emotions  [29] . The proposed methodology allows to frame the ethical use of the system by documenting step by step its conceived functioning, and how and for what purpose personality and mood prediction are extracted and used (based on profile data voluntarily provided by the platform's users, with the sole purpose of making the most appropriate and enjoyable music recommendations). The misuses field further strengthens the system's ethical principles by explicitly signaling the prohibition of proposing music pre-conceived to exploit vulnerabilities, manipulate, distort or induce certain emotions or behaviour in users, which would be a prohibited practice according to the AI Act (c.f. Table  II ).\n\nDriver attention monitoring. The third example is a use case where a driver's face is recorded with a car in-cabin camera, and monitored in order to recognise drowsiness and Fig.  2 : Left: classic table template for the documentation of UML use case diagrams, as in  [6] . Right: proposed adaptation for the documentation of AI use cases, inspired by the European AI Act's definitions. Green text corresponds to added fields, while blue text is used for fields that have been adapted. distraction. When such situations are detected, the vehicle's attention monitoring system sends alerts in the form of beep tones and light symbols in the car dash (Figure  5 ). Driver monitoring systems have been a popular affective computing application in the last decade and the modelling of this use case is inspired by different papers  [30] ,  [31]  as well as real commercial products  [32] ,  [33] . The intended purpose field in the proposed UML-based table clearly states that the system is part of a safety component of the vehicle, which immediately positions it as a high-risk profile according to the AI Act. Further, the documentation methodology allows to indicate that the system is conceived to alert the driver, but in any case to allow the vehicle to take full control of the car in an autonomous manner.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "V. Conclusions And Future Work",
      "text": "In this paper, we propose a methodology for the documentation of AI use cases which covers the particular information elements needed to address affective computing ones. The methodology has a solid grounding, being based on two strong pillars: (1) the UML use case modelling standard, and (2) the recently proposed European AI regulatory framework. Each use case is represented in a highly visual way by means of an UML diagram, accompanied by a structured and concise table that compiles the relevant information to understand the intended use of a system, and to assess its risk level and foreseeable misuses. Our approach is not intended to be an exhaustive methodology for the technical documentation of AI or affective computing systems (e.g. to demonstrate compliance with legal acts). Rather, it aims to provide a template for compiling related use cases with a simple but effective and unified language, understandable even by nontechnical audiences. We have demonstrated the power of this language through practical affective computing exemplar use cases.\n\nIn the near future, we plan to develop a collaborative repository compiling a catalogue of AI -including affective computing-use cases following the proposed template. The first step will be to transcribe the 60 facial processing applications presented in  [1] , which contain 18 emotion recognition use cases, in order to add them to this catalogue.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Ethical Impact Statement",
      "text": "The methodology presented in this paper proposes the first unified documentation approach for AI use cases, with a strong focus on affective computing ones, which allows to differentiate intended uses and potential misuses. In the last years, the need for trustworthy AI has been raised by both private and public key institutions and researchers in the field  [1] ,  [3] ,  [12] ,  [13] ,  [34] . In particular, documentation has been identified as a key factor towards the fulfilment of transparency  [2] , one of the seven pillar requirements for trustworthy AI established by the High-Level Expert Group on Artificial Intelligence (AI HLEG)  [35] . Therefore, this work represents a major step towards ethical AI and affective computing, and could even constitute a basis for the future standardisation activities in this area.",
      "page_start": 5,
      "page_end": 5
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Use cases capture a system’s requirements, i.e., what the",
      "page": 2
    },
    {
      "caption": "Figure 1: Main UML graphical notation elements for use case",
      "page": 3
    },
    {
      "caption": "Figure 2: -right, we propose an adaptation of the classic",
      "page": 4
    },
    {
      "caption": "Figure 4: shows the UML",
      "page": 4
    },
    {
      "caption": "Figure 2: Left: classic table template for the documentation of UML use case diagrams, as in [6]. Right: proposed adaptation",
      "page": 5
    },
    {
      "caption": "Figure 3: First use case: methodology applied to a smart camera system with embedded smile detection capabilities.",
      "page": 6
    },
    {
      "caption": "Figure 4: Second use case: proposed methodology applied to an affective music recommender system.",
      "page": 6
    },
    {
      "caption": "Figure 5: Third use case: proposed methodology applied to a driver attention monitoring system.",
      "page": 7
    }
  ],
  "tables": [],
  "citations": [
    {
      "citation_id": "1",
      "title": "The landscape of facial processing applications in the context of the european AI Act and the development of trustworthy systems",
      "authors": [
        "I Hupont",
        "S Tolan",
        "H Gunes",
        "E Gómez"
      ],
      "year": "2022",
      "venue": "Nature Scientific Reports"
    },
    {
      "citation_id": "2",
      "title": "Documenting high-risk ai: an european regulatory perspective",
      "authors": [
        "I Hupont",
        "M Micheli",
        "B Delipetrev",
        "E Gómez",
        "J Soler",
        "Garrido"
      ],
      "year": "2022",
      "venue": "Documenting high-risk ai: an european regulatory perspective"
    },
    {
      "citation_id": "3",
      "title": "Datasheets for datasets",
      "authors": [
        "T Gebru",
        "J Morgenstern",
        "B Vecchione",
        "J Vaughan",
        "H Wallach",
        "H Iii",
        "K Crawford"
      ],
      "year": "2021",
      "venue": "Communications of the ACM"
    },
    {
      "citation_id": "4",
      "title": "Model cards for model reporting",
      "authors": [
        "M Mitchell",
        "S Wu",
        "A Zaldivar",
        "P Barnes",
        "L Vasserman",
        "B Hutchinson",
        "E Spitzer",
        "I Raji",
        "T Gebru"
      ],
      "year": "2019",
      "venue": "Conference on Fairness, Accountability, and Transparency"
    },
    {
      "citation_id": "5",
      "title": "European Commission's proposal for a Regulation on Artificial Intelligence",
      "year": "2021",
      "venue": "European Commission's proposal for a Regulation on Artificial Intelligence"
    },
    {
      "citation_id": "6",
      "title": "Writing effective use cases",
      "authors": [
        "A Cockburn"
      ],
      "year": "2001",
      "venue": "Writing effective use cases"
    },
    {
      "citation_id": "7",
      "title": "Applications of linguistic techniques for use case analysis",
      "authors": [
        "A Fantechi",
        "S Gnesi",
        "G Lami",
        "A Maccari"
      ],
      "year": "2003",
      "venue": "Requirements Engineering"
    },
    {
      "citation_id": "8",
      "title": "Unified modeling language specification v2.5.1",
      "venue": "Unified modeling language specification v2.5.1"
    },
    {
      "citation_id": "9",
      "title": "The dataset nutrition label: A framework to drive higher data quality standards",
      "authors": [
        "S Holland",
        "A Hosny",
        "S Newman",
        "J Joseph",
        "K Chmielinski"
      ],
      "year": "2018",
      "venue": "The dataset nutrition label: A framework to drive higher data quality standards",
      "arxiv": "arXiv:1805.03677"
    },
    {
      "citation_id": "10",
      "title": "nd gen): Leveraging context to mitigate harms in artificial intelligence",
      "authors": [
        "K Chmielinski",
        "S Newman",
        "M Taylor",
        "J Joseph",
        "K Thomas",
        "J Yurkofsky",
        "Y Qiu"
      ],
      "year": "2022",
      "venue": "The dataset nutrition label",
      "arxiv": "arXiv:2201.03954"
    },
    {
      "citation_id": "11",
      "title": "Data cards: Purposeful and transparent dataset documentation for responsible ai",
      "authors": [
        "M Pushkarna",
        "A Zaldivar",
        "O Kjartansson"
      ],
      "year": "2022",
      "venue": "Data cards: Purposeful and transparent dataset documentation for responsible ai",
      "arxiv": "arXiv:2204.01075"
    },
    {
      "citation_id": "12",
      "title": "AI Fact-Sheets: Increasing trust in AI services through supplier's declarations of conformity",
      "authors": [
        "M Arnold",
        "R Bellamy",
        "M Hind",
        "S Houde",
        "S Mehta",
        "A Mojsilović",
        "R Nair",
        "K Ramamurthy",
        "A Olteanu",
        "D Piorkowski"
      ],
      "year": "2019",
      "venue": "IBM Journal of Research and Development"
    },
    {
      "citation_id": "13",
      "title": "OECD Framework for Classification of AI Systems: a tool for effective AI policies",
      "authors": [
        "Oecd"
      ],
      "year": "2022",
      "venue": "OECD Framework for Classification of AI Systems: a tool for effective AI policies"
    },
    {
      "citation_id": "14",
      "title": "Adapting software with affective computing: a systematic review",
      "authors": [
        "R Aranha",
        "C Corrêa",
        "F Nunes"
      ],
      "year": "2019",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "15",
      "title": "Emotion recognition in naturalistic speech and language-a survey",
      "authors": [
        "F Weninger",
        "M Wöllmer",
        "B Schuller"
      ],
      "year": "2015",
      "venue": "Emotion Recognition: A Pattern Analysis Approach"
    },
    {
      "citation_id": "16",
      "title": "Affective computing for large-scale heterogeneous multimedia data: A survey",
      "authors": [
        "S Zhao",
        "S Wang",
        "M Soleymani",
        "D Joshi",
        "Q Ji"
      ],
      "year": "2019",
      "venue": "ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM)"
    },
    {
      "citation_id": "17",
      "title": "Automated pain detection in facial videos of children using human-assisted transfer learning",
      "authors": [
        "X Xu",
        "K Craig",
        "D Diaz",
        "M Goodwin",
        "M Akcakaya",
        "B Susam",
        "J Huang",
        "V Sa"
      ],
      "year": "2018",
      "venue": "International Workshop on Artificial Intelligence in Health"
    },
    {
      "citation_id": "18",
      "title": "Affectivespotlight: Facilitating the communication of affective responses from audience members during online presentations",
      "authors": [
        "P Murali",
        "J Hernandez",
        "D Mcduff",
        "K Rowan",
        "J Suh",
        "M Czerwinski"
      ],
      "year": "2021",
      "venue": "CHI Conference on Human Factors in Computing Systems"
    },
    {
      "citation_id": "19",
      "title": "Enhancing player experience in game with affective computing",
      "authors": [
        "D Setiono",
        "D Saputra",
        "K Putra",
        "J Moniaga",
        "A Chowanda"
      ],
      "year": "2021",
      "venue": "Procedia Computer Science"
    },
    {
      "citation_id": "20",
      "title": "Guidelines for assessing and minimizing risks of emotion recognition applications",
      "authors": [
        "J Hernandez",
        "J Lovejoy",
        "D Mcduff",
        "J Suh",
        "T O'brien",
        "A Sethumadhavan",
        "G Greene",
        "R Picard",
        "M Czerwinski"
      ],
      "year": "2021",
      "venue": "9th International Conference on Affective Computing and Intelligent Interaction (ACII)"
    },
    {
      "citation_id": "21",
      "title": "An ethical framework for guiding the development of affectively-aware artificial intelligence",
      "authors": [
        "D Ong"
      ],
      "year": "2021",
      "venue": "9th International Conference on Affective Computing and Intelligent Interaction (ACII)"
    },
    {
      "citation_id": "22",
      "title": "Association for the Advancement of Affective Computing (AAAC), \"Product database",
      "venue": "Association for the Advancement of Affective Computing (AAAC), \"Product database"
    },
    {
      "citation_id": "23",
      "title": "UML diagrams in software engineering research: a systematic literature review",
      "authors": [
        "H Koc",
        "A Erdogan",
        "Y Barjakly",
        "S Peker"
      ],
      "year": "2021",
      "venue": "UML diagrams in software engineering research: a systematic literature review"
    },
    {
      "citation_id": "24",
      "title": "Detecting a face and shooting (Smart Shutter)",
      "authors": [
        "Canon"
      ],
      "year": "2022",
      "venue": "Detecting a face and shooting (Smart Shutter)"
    },
    {
      "citation_id": "25",
      "title": "Smile timer",
      "authors": [
        "Nikon"
      ],
      "year": "2022",
      "venue": "Smile timer"
    },
    {
      "citation_id": "26",
      "title": "Employees at a Beijing office have to smile for an AI camera to get through the front doors, change the temperature, or print documents",
      "year": "2021",
      "venue": "Business Insider"
    },
    {
      "citation_id": "27",
      "title": "Affective music recommender system (MRS): Investigating the effectiveness and user satisfaction of different mood inducement strategies",
      "authors": [
        "R Amini",
        "M Willemsen",
        "M Graus"
      ],
      "year": "2019",
      "venue": "Affective music recommender system (MRS): Investigating the effectiveness and user satisfaction of different mood inducement strategies"
    },
    {
      "citation_id": "28",
      "title": "A survey of music recommendation system",
      "authors": [
        "P Deshmukh",
        "G Kale"
      ],
      "year": "2018",
      "venue": "International Journal of Scientific Research in Computer Science, Engineering and Information Technology (IJSRCSEIT)"
    },
    {
      "citation_id": "29",
      "title": "Music emotion recognition: Toward new, robust standards in personalized and context-sensitive applications",
      "authors": [
        "J Gómez-Cañón",
        "E Cano",
        "T Eerola",
        "P Herrera",
        "X Hu",
        "Y.-H Yang",
        "E Gómez"
      ],
      "year": "2021",
      "venue": "IEEE Signal Processing Magazine"
    },
    {
      "citation_id": "30",
      "title": "Driver drowsiness monitoring system using visual behaviour and machine learning",
      "authors": [
        "A Kumar",
        "R Patra"
      ],
      "year": "2018",
      "venue": "IEEE Symposium on Computer Applications & Industrial Electronics (ISCAIE)"
    },
    {
      "citation_id": "31",
      "title": "Affective driver state monitoring for personalized, adaptive ADAS",
      "authors": [
        "V Govindarajan",
        "K Driggs-Campbell",
        "R Bajcsy"
      ],
      "year": "2018",
      "venue": "21st International Conference on Intelligent Transportation Systems (ITSC)"
    },
    {
      "citation_id": "32",
      "title": "Driver monitoring system",
      "authors": [
        "Subaru"
      ],
      "year": "2022",
      "venue": "Driver monitoring system"
    },
    {
      "citation_id": "33",
      "title": "Tesla starts using cabin cameras for driver monitoring",
      "authors": [
        "Cnbc"
      ],
      "year": "2021",
      "venue": "Tesla starts using cabin cameras for driver monitoring"
    },
    {
      "citation_id": "34",
      "title": "Codesigning checklists to understand organizational challenges and opportunities around fairness in AI",
      "authors": [
        "M Madaio",
        "L Stark",
        "J Vaughan",
        "H Wallach"
      ],
      "year": "2020",
      "venue": "CHI Conference on Human Factors in Computing Systems"
    },
    {
      "citation_id": "35",
      "title": "European Commission's Ethics Guidelines for Trustworthy AI",
      "year": "2019",
      "venue": "European Commission's Ethics Guidelines for Trustworthy AI"
    }
  ]
}