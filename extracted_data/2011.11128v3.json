{
  "paper_id": "2011.11128v3",
  "title": "Deep Learning In Eeg: Advance Of The Last Ten-Year Critical Period",
  "published": "2020-11-22T22:34:26Z",
  "authors": [
    "Shu Gong",
    "Kaibo Xing",
    "Andrzej Cichocki",
    "Junhua Li"
  ],
  "keywords": [
    "Deep Learning",
    "Electroencephalogram (EEG)",
    "Classification",
    "Brain Computer Interface",
    "Disease",
    "Emotion",
    "Sleep",
    "Mental State"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Deep learning has achieved excellent performance in a wide range of domains, especially in speech recognition and computer vision. Relatively less work has been done for EEG, but there is still significant progress attained in the last decade. Due to the lack of a comprehensive and topic widely covered survey for deep learning in EEG, we attempt to summarize recent progress to provide an overview, as well as perspectives for future developments. We first briefly mention the artifacts removal for EEG signal and then introduce deep learning models that have been utilized in EEG processing and classification. Subsequently, the applications of deep learning in EEG are reviewed by categorizing them into groups such as brain-computer interface, disease detection, and emotion recognition. They are followed by the discussion, in which the pros and cons of deep learning are presented and future directions * S. Gong and K. Xing are with the",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Machine learning technology has benefited to diverse domains in our modern society  [1] ,  [2] . Deep learning, a subcategory of machine learning technology, has been showing excellent performance in pattern recognition  [3] , dramatically improving classification accuracy. It is worth noting that new world records were created by using deep learning in many competitions such as ImageNet Competition  [4] . The research outcomes of deep learning in speech recognition  [5]  and computer vision  [6]  have been successfully utilized to develop practical application systems, which are remarkably influencing our life and even changing our lifestyle.\n\nDeep learning is an enhanced variant of traditional neural network, which is thought to be established based on the inspiration of hierarchical structure existing in visual cortex of the human brain. The adjective 'deep' in the term of deep learning describes the attribute of multiple processing layers forming a long-cascaded architecture. The extracted information becomes more and more abstract from the lowest layer to the highest layer. This is one of the advantages for the deep learning as information expression could be more meaningful when passing onto a higher layer. Meanwhile, deep learning suffers from the issues of slow convergence and high computation demand. These disadvantages have been released by introducing training strategies such as dropout  [7]  and batch normalization  [8] , and the availability of high-performance computers. The high performance is not only due to the capacity improvement of central processing units, but also new computing units such as graphic processing unit and tensor processing unit. These new computing units are designed to suit matrix manipulation, which greatly reduce computational time in deep learning. Moreover, the availability of large scale of data and increased capacity of data storage also promote the use of deep learning. Electroencephalogram (EEG) signal was first recorded by Hans Berger in the year of 1924  [9] , which manifests underlying brain activity. Multiple electrodes can be set to record EEG signal by placing them on different locations of the scalp and temporal fluctuations in voltage can be captured in a high resolution (e.g., in milliseconds) by using a high sampling rate. With the advantages of multi-channel recording and high temporal resolution, EEG has been applied to numerous domains from brain-computer interface  [10, 11, 12, 13] , to emotion  [14, 15] , to cognition  [16] , to brain diseases  [17] . EEG processing methodology is evolved from simple methods such as mean and amplitude comparison to complicated methods such as connectivity topology and deep learning. In particular, deep learning exhibits better performance in EEG classification (a.k.a., recognition or identification) compared to conventional methods (e.g., support vector machine). By using deep learning, discriminative features could be extracted without handcraft, which requires specific knowledge and expertise. It could avoid the low performance derived from unsuitable handcrafted features. However, deep learning is not a destination because model architecture and parameters have to be set manually. A good classification performance is usually not obtained by just feeding data into a deep learning model. This is because the target signal is much weaker than the background signal and noise, resulting in a low signal-to-noise ratio. Therefore, artifacts removal is commonly adopted to remove artifacts so that the signal-to-noise ratio can be improved before feeding into a deep learning model. This is quite different compared to image or video processing, where image or video is directly fed into a deep learning model. To date, different kinds of deep learning models have been employed to process and classify EEG signal. Cecotti et al. used convolutional neural network (CNN) to extract features from steady-state visual evoked potential in 2008  [18] . Li et al. employed denoising autoencoder to classify two classes of motor imagery using EEG recorded from 14 electrodes on the sensorimotor cortex  [19] . Tsiouris et al. applied recurrent neural network (RNN) to capture sequential relationships for seizure detection  [20] . A survey covering six EEG-based applications was done in 2019, where studies were reviewed separately for task type, model type and so on  [21] . A more specialized survey on motor imagery classification can be found in  [22] . A distribution summary showing which disease is dominantly targeted in the studies of deep learning-based disease diagnosis can be found in  [23] . If you want to read a survey on brain-computer interface (more beyond motor imagery), it can be found in Section 5 of  [24] . If a wide range of topics of deep learning in EEG is sought, this survey can be an option.\n\nAlthough EEG domain is far behind compared to the domains such as computer vision  [25]  and speech recognition  [26]  in terms of adopting deep learning, significant progress has been achieved in the last decade. It is time to summarize the achievements of deep learning in EEG for the past 10 years and discuss current existing issues and future directions. The searching criterion [\"Deep Learning\" AND \"EEG\" AND \"Classification\" OR \"Recognition\" OR \"Identification\"] was used for literature retrieval in the Web of Science in March 2020. After manual selection, 193 papers were included in this survey. During the revision in February 2021, we applied the same searching criterion to find newly-published literature after the previous searching and selected  20  papers to be included in this survey. After the acceptance, seven more papers were further included, but they were not used to update the figures and tables due to the constrained time.\n\nAs shown in Fig.  1 , the majority of these papers were published after 2017 while there was a rapid increase from the year of 2019. In 2019, the number of papers in the topic of brain-computer interface and disease detection are significantly more than the other topics. In 2020, the numbers of the published papers in more topics are rapidly increased, although disease detection is still a leading topic. The rapid increase of the published papers about deep learning in EEG is continued in 2021. The remainder of the survey is organized as follows. In Section II, artifacts removal is briefly introduced. This is followed by the detailed descriptions of all deep learning models which have been applied to EEG in Section III. In this section, we also mention the advantages and limitations of each deep learning model. Subsequently, the applications of deep learning in EEG are detailed along with publicly available EEG datasets used in these applications in Section IV. Finally, discussions are given and future directions are drawn at the end of the survey. All abbreviations used in this survey are listed in Table  1 .",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Artifacts Removal",
      "text": "In general, artifacts are larger than that we intend to extract from EEG signal in terms of scale, leading to a low signal-to-noise ratio (SNR). In order to improve SNR, EEG signal is preprocessed to remove or mitigate the effect of artifacts on the signal before the signal is further processed. For example, a notch filter  [16]  is effective for eliminating the interference of power line. Independent component analysis  [27]  is usually utilized to remove eye movements-related and muscular activity-related artifacts. Classical methods of artifacts removal and their targeted artifacts are summarized in Table  2 .\n\nWhen deep learning emerges, the step of artifacts removal is kept. EEG signal is preprocessed as usual to remove artifacts before inputting into a deep learning model. This is an effective way as all artifacts removal methods can be applied with deep learning models to be of both benefits inherited from the artifacts removal methods and deep learning models. This is also a natural and straightforward way that researchers are able to easily implement. However, an independent step of artifacts removal is not always necessary. The first several layers in a deep learning model could be functioned as artifacts removal, where noise is removed through the layers. To this end, a few attempts were done. For example, Supratak et al. inputted raw EEG data into a CNN for the classification of sleep stages. Their study showed that an acceptable performance can be achieved without an independent step of artifacts removal  [28] . In addition, Bahador et al. mapped the correlation of EEG channels into a 2D space and used a CNN model to learn representations related to particular artifacts. With respect to artifact detection, this method outperformed spectrogram-based CNNs  [29] . Moreover, no auxiliary reference signal was required in their method.",
      "page_start": 5,
      "page_end": 6
    },
    {
      "section_name": "Deep Learning Models",
      "text": "In this section, we describe each fundamental deep learning model. Their variants and combinations are not included as they share the similar rationale with fundamental models. A deep learning model is a hierarchical structure, comprising layers through which data are mapped into more and more abstract. Whatever a deep learning model is, there are an input layer, an output layer, and one or more hidden units (see Fig.  2(A) ). The hidden unit might be one of the layer structures illustrated in Fig.  2 (B) or their combinations. In the following subsections, we introduce classical deep learning models where typical units illustrated in Fig.  2 (B) are embedded.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Restricted Boltzmann Machine And Deep Belief Networks",
      "text": "A restricted Boltzmann machine (RBM)  [30]  is an undirected graph model (see Fig.  2 (B): RBM Unit), which has a visible layer v = (v 1 , v 2 , . . . , v n ) and a hidden layer h = (h 1 , h 2 , . . . , h n ). Connections exist only between visible layer v and hidden layer h and there are no connections between nodes within the visible layer or hidden layer. The energy function for an RBM is defined as:\n\nwhere W is the weight matrix, a and b are bias vectors. The joint probability of v and h is constructed in terms of E:\n\nwhere Z is a normalizing constant defined as:\n\nThe marginal distribution over the visible variables is obtained as:\n\nThe conditional probabilities can be described as:\n\nwhere σ is logistic function defined as:\n\nA deep belief network (DBN) is constructed by stacking multiple RBMs  [31] . Each RBM in the DBN is trained using an unsupervised manner at first. Then, the output of previous RBM is inputted into the next RBM. All RBMs are fine-tuned together by supervised optimization.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Convolutional Neural Network",
      "text": "Convolutional neural network (CNN)  [32]  is good at capturing spatial information of data (see Fig.  2 (B): Convolutional Unit). Most CNNs consist of two types of layers: convolutional layer, pooling layer.\n\nIn specific, a convolutional layer has filters k l ij , the size of which is usually much smaller than the dimension of input data and forms a locally connected structure. Filter at layer l can produce feature maps X l j by convolving with the input X l-1 i plus biases b l j . These features are subjected to a non-linear transformation f (•) and can be mathematically expressed as:\n\nWhere M l-1 represents the number of feature maps in layer l -1, and * denotes convolution operation. A pooling layer is responsible for feature selection and information filtering. Two kinds of pooling operations are widely used: max pooling and average pooling. In max pooling, maximum value is mapped from a sub-region by pooling operator. In average pooling, the average value of a sub-region is selected as the result. A fully-connected layer is usually added at the last part of a CNN in the case of classification. It transforms a long 1D vector and outputs to the next layer (usually softmax).\n\nWeight sharing and sparse connections are two basic strategies in CNN models, which lead to dramatic reduction in the number of parameters. These strategies are helpful to reduce training time and enhance training effectiveness. Moreover, they also mitigate the overfitting problem while retaining a good capability of complex feature extraction.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Recurrent Neural Networks",
      "text": "Recurrent neural network (RNN)  [33]  was developed to deal with sequential data because of its unique recurrent structure (see Fig.  2(B ): Recurrent Unit), which allows previous outputs to be used as inputs while having hidden states. It is widely used in applications that need to extract sequential information, such as natural language processing, speech recognition, and EEG classification.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Gru",
      "text": "Gated Recurrent Unit (GRU)  [34]  has two gates, reset r t and update z t . Let x t be the input at time step t to a GRU layer and h t be the output vector. The output activation is a linear interpolation between the activation from the previous time step and a candidate activation ĥt .\n\nwhere z t decides the interpolation weight, which is computed by:\n\nwhere W and U are weight matrices for the update gate, b is a bias vector, and f (•) is a non-linear function (usually sigmoid function). The candidate activation is also controlled by an additional reset gate and computed as follows:\n\nwhere represents an element-wise multiplication and g(•) is often a nonlinear tanh function. The reset gate is computed in a similar manner as the update gate:",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Lstm",
      "text": "Different from GRU, Long Short-Term Memory (LSTM)  [35]  has three gates, input i t , output o t , and forget gates f t . Each LSTM cell has an additional memory component c t . The gates are calculated in a similar manner as the GRU but LSTM has additional memory components.\n\nA memory component is updated by forgetting the existing content and adding a new memory component as:\n\nwhere ĉt can be computed by:\n\nThe updated equation for the memory component is controlled by the forget and input gates. Then, the output of the LSTM unit is computed from the memory modulated by the output gate according to the following equation:",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Autoencoder And Stacked Autoencoder",
      "text": "Autoencoder (AE) is a symmetrical structure with two layers  [36]  (see Fig.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "2(B): Autoencoder Unit).",
      "text": "An encoder learns latent representation from the input data while a decoder restores the latent representation as close to the input data as possible. The goal of an autoencoder is to minimize the reconstruction error between the input and the output.\n\nGiven the inputs x ∈ R, the encoding process first maps it into a latent representation h ∈ R through a weight matrix W v , bias b v , and an activation function f (•):\n\nThen the decoding process transforms the latent representation h into the reconstruction y through a weight matrix W h , bias b h , and an activation function g(•):\n\nTo simplify the network architecture, the tied weights strategy W v = W h = W are usually employed. The parameters to be determined are\n\nThe training of an autoencoder is to minimize the loss:\n\nGiven the training samples D n , the loss function is defined as:\n\nwhere L is the error of the reconstruction and N Dn is the number of the training samples. Stacked autoencoder (SAE) is a neural network, where autoencoders are connected one another to form a cascade.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Others",
      "text": "In addition to the aforementioned models, there are other models aiming to solve particular shortcomings existing in the above models. For example, capsule network (CapsNet) was proposed to overcome the shortcoming that CNN does not well capture the relationships between the parts of an image  [37] . When it applied to fMRI  [38]  and EEG  [15] , it is expected to capture comprehensive relationships among brain regions, channels, or frequencies, and so on. To shorten training time, extreme learning machine (ELM) was proposed, where the weights of hidden layers are randomly assigned and fixed during the training  [39] . Weight randomization is also implemented in echo state network (ESN)  [40] . ESN is a recurrent neural network where the weights of hidden layers are randomly and sparsely assigned and fixed while the weights of output layer can be tuned. Spiking neural network (SNN) is a biologically inspired model and has been used to explore brain activity patterns in  [41] . Deep polynomial network (DPN) uses a quadratic function to process its inputs and is able to learn features between different samples or dimensions. It was implemented in  [42]  to utilize features from multiple views for motor imagery classification, including common spatial pattern, power spectral density, and wavelet packet transform. In addition, some variants of deep learning models were proposed by using different training strategies, such as generative adversarial network.",
      "page_start": 11,
      "page_end": 12
    },
    {
      "section_name": "Applications",
      "text": "We summarized applications, in which deep learning was utilized for EEG processing and classification, in this section. For your convenience, we group diverse applications into six topics, which are brain-computer interface (see Table  3  for the details of studies), disease detection (see Table  4 ), emotion recognition (see Table  5 ), operator functional states (see Table  6 ), sleep stage classification (see Table  7 ), as well as the applications other than above topics (see Table  8 ). According to statistics, the majority of selected papers belong to the topics of brain-computer interface (account for 26%) and disease detection (account for 25%). The percentages of each topic and the percentages of each model used in each topic are illustrated in Fig.  3 . In addition, we collected the information of the publicly available datasets which had been used in the studies and listed them in Table  9 .",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Brain-Computer Interface",
      "text": "A brain-computer interface (BCI) can be defined as a system that decodes brain activity and translate user's intentions into messages or commands for the purposes of communication or the control of external devices, and more. In this topic, deep learning was mainly applied to establish motor imagery (MI)-and P300-based BCIs (see Fig.  4 ).\n\nTransfer learning is utilized to mitigate the cost of re-training or solve the problem of data lack in the target domain. A deep learning model trained on the data collected from a session or a subject can be transferred to classify/recognise the data of another session or another subject with a finetuning. In some cases, the fine-tuning is omitted. In general, the fine-tuning positively contributes to the performance. The extent of fine-tuning was investigated in a recent study  [43] . It shows that the best performance of motor imagery classification was achieved when all layers were tuned except the   [47] . This model was then adapted based on a small amount of data from a subject before applying to this subject. Their results showed that an average improvement of 6∼9% was achieved for motor imagery classification in terms of classification accuracy.\n\nTransferring can also be conducted between domains. A CNN-based model (VGG-16) trained on image data (the data from ImageNet) was transferred to recognize EEG data by freezing the parameters in the first several layers and fine-tuning the parameters in the last several layers using an EEG dataset  [48] . The performance was better than that of support vector machine. Similar to the domain of image recognition, the amount of EEG data can also be increased by augmentation procedure. Li et al. produced new samples by adding noise into EEG data  [49] . They claimed that adding noise into amplitudes of power spectra was superior to that adding noise into EEG time series in terms of classification accuracy. Zhang et al. used intrinsic mode functions derived from empirical mode decomposition to generate new EEG samples so that the total number of samples was increased  [50] .\n\nClassical models such as CNN and RNN were originally developed for image or speech recognition, so they did not well match the characteristics of EEG signal. They should be adapted before applying to EEG recognition. Li et al. designed a CNN-based network consisted of three blocks to capture spatial and temporal dependencies  [49] . Multi-channel raw EEG signals were fed into temporal convolutional layer and spatial convolutional layer successively in the first block. In the second block, a standard convolutional layer and a dilated convolutional layer were utilized to extract temporal information at different scales while reducing the number of parameters. The extracted features were finally used for motor imagery classification in the third block. In another CNN-based network  [51] , a layer was fed by all outputs from previous layers and its output was inputted to all following layers. By using such dense inter-layer connections, information loss could be reduced. In  [50] , EEG signals were transformed into tensors and fed into a CNN-like network where convolution were replaced with complex Morlet wavelets, resulting in parameter reduction. Wavelet kernel was also used to learn time-frequency features  [46] . Their results demonstrated that wavelet kernels can provide faster convergence rate and higher classification accuracy compared to plain CNN. Alazrai et al. used CNN to extract features from time-frequency images, which were transformed using a quadratic timefrequency distribution  [52] . The methods were compared to a support vector machine, and it suggested that CNN can achieve good performance in MI tasks of the same hand.\n\nIn order to accelerate the training course and alleviate the overfitting problem, Liu et al. adjusted the number and position of batch normaliza-tion layers in a CNN-based network for P300 detection  [8] . Kshirsagar et al. employed leaky rectified linear unit activation function at each convolutional layer  [53] . To evaluate whether the number of convolutional layers needs to be adjusted for different BCI tasks and find out an optimal structure, Lawhern et al. compared networks with different numbers of convolutional layers  [54] . Their results showed that deep CNN (i.e., five convolutional layers) tended to perform better on the oscillatory BCI dataset than on the event-related potential BCI dataset, while shallow CNN (i.e., two convolutional layers) achieved better performance on the event-related potential BCI dataset. Apart from CNN, Lu et al. used a DBN (i.e., three RBMs and an output layer) to extract features of motor imagery  [44] . Some studies aimed to compare performances of different deep learning models. For example, Pei et al. compared SAE and CNN in the classification of reaching movements  [55] . They found that SAE was better than CNN and suggested that poorer performance in CNN might be due to the lack of training data. One year later, another study comparing between these two models showed that SAE had satisfactory performance in some trials, but inefficient to those trials of the subjects who were less attentive in P300 detection, while CNN performed well in terms of accuracy and information transfer rate  [53] .\n\nThe combination of deep learning model and traditional model or the mixture of two or more types of deep learning models is applied to EEG classification. For example, SAE was combined with support vector machine to classify EEG signal  [56] . SAE was also combined with CNN to develop a new model  [57] , where CNN layers were used to extract features from 2D time-frequency images (obtained by Fourier transform over EEG signals) and SAE was further used to extract features. In  [58] , the features extracted by CNN were fed into an autoencoder for cross-subject MI classification. This combination achieved a better accuracy for the cross-subject classification, but worse for the subject-specific classification, compared to the combination of CNN and multilayer perceptron (MLP). Zhang et al. presented a hybrid network comprised of CNN and LSTM, in which EEG signals were sequentially processed through common spatial pattern, CNN, and LSTM  [59] . The idea of using CNN and LSTM to extract spatial and temporal features was also conceived by Yang et al.  [60] . However, they inserted a discrete wavelet transformation (DWT) between CNN and LSTM, which led to better performance in the MI classification compared to that of pure combination of CNN and LSTM.\n\nIn addition to P300-and MI-based BCIs, deep learning models also ap-",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "Disease Detection",
      "text": "Machine learning could benefit disease diagnosis by providing assistant information and preliminary diagnostic results. In this topic, deep learning models were also widely employed to detect a variety of diseases (see the distribution of the selected papers over diseases in Fig.  5 ). In this subsection, commonly used models and model designing strategies were introduced at first, including the examples of single or hybrid models, as well as the detailed architecture (e.g., layer settings). Afterwards, we described other techniques that have an influence on the performance of deep learning. CNN is a deep learning model, which has been widely adopted for the detection of brain diseases (e.g., seizure detection  [64]  and schizophrenia identification  [65] ). When CNN is combined with other models, classification performance can be improved. In  [68] , CNN and autoencoder (AE) were combined to learn robust features in an unsupervised way. The integrated network had an encoder consisting of convolution and down-sampling and a decoder consisting of deconvolution and up-sampling. Their results demonstrated that CNN+AE is superior to principal component analysis (PCA) and sparse random projection (SRP) in epilepsy related feature extraction. In  [69] , a hybrid model combining CNN, AE, and LSTM achieved remarkable prediction of seizure. Combined deep learning model was used for pre-training and latent representation learning. By this, the accuracy of focal and non-focal classification was improved  [70] . However, model combination is not always positive to the performance improvement. Some studies showed that performance may decline in some cases. For instance, Mumtaz et al. combined CNN and LSTM to detect unipolar depression. Their results showed that the hybrid model did not outperform single model of CNN  [71] .\n\nBeyond the selection of deep learning models, model settings also vary across studies. Tsiouris et al. found that overfitting problem can be mitigated by shuffling input EEG segments, which could replace the dropout role partially  [20] . Qiu et al. applied data corruption in the stacked autoencoder for seizure detection  [72] . Specifically, they designed a denoising sparse autoencoder, in which some of the input data were set to zero. This improved model robustness and reduced overfitting problem. In addition, performance is also influenced by the condition of data recording. Mumtaz et al. found that unipolar depression can be more accurately detected using the EEG recorded under the condition of eyes open compared to that of eyes closed  [71] . In the study of attention deficit hyperactivity disorder (ADHD) detection using a CNN model, EEG signals at different channels were rearranged to make adjacent channels together in the connectivity matrix to improve accuracy  [73] . Moreover, Tsiouris et al. shuffled interictal and preictal segments of EEG to avoid the overfitting in seizure detection  [20] . Yuan et al. used a channel-aware module to enhance the capability of feature learning and concentrate on important and relevant EEG channels  [74] . Daoud et al. computed the statistical variance and entropy of the channels, and selected those with the highest variance entropy product for seizure prediction  [69] .\n\nThe performance of deep learning for disease detection is affected by EEG data arrangement. For example, EEG data are reshaped into 2D format before inputting into a deep learning model. In  [75] , EEG data were transformed into 2D images of spectral powers. Then, these images were fed into a CNN network for distinguishing Alzheimer's disease and mild cognitive impairment from healthy controls. To differentiate patients with schizophrenia  [76] , Pearson correlation coefficients were calculated between channels and assembled as a correlation matrix. Correlation matrices of each subject were fed into a CNN network. Moreover, fast Fourier transform  [77]  and continuous wavelet transform  [78]  were used to transform EEG data into 2D images for motor impairment neural disorders and epilepsy classification, respectively. Wei et al. further converted 2D images into 3D stacked images according to the mutual correlation intensity between channels  [79] . To utilize comprehensive information from different data forms, Tian et al. used three CNNs to respectively obtain features existing in the time, frequency, and time-frequency domain, and then ultilized these features for seizure detection  [80] . By comparing with the methods that ultilizing features from only one domain, the proposed method exhibited better performance. According to the study comparing among raw EEG signal, Fourier transform, wavelet transform, and empirical mode decomposition, raw signals and empirical mode decomposition were better than the others in distinguishing focal EEG from non-focal EEG, while Fourier transform was best in ictal and non-ictal classification  [81] . To handle the problem of inadequate data, sliding time window was used to split continuous EEG signal into segments with partial overlapping to increase the data amount in  [82] . Cao et al. de-veloped an interactive system to help experts label the new data, and the data can be added to fine-tune the deep learning model to gradually improve the interictal-ictal continuum classification accuracy  [17] .",
      "page_start": 14,
      "page_end": 14
    },
    {
      "section_name": "Emotion Recognition",
      "text": "Emotion conveys lots of underlying information during conversations and is part of communication between people. People can understand emotion by reading facial expression, voice tone, and gestures. From the perspective of artificial intelligence, emotion can be recognized based on the data of facial expression  [83] , eye movement measures  [84] , EEG  [85] , or galvanic skin response signal  [86] . According to the arousal and valence, emotion can be categorized into different classes (see Fig.  6 ). Based on the statistics of the included papers in this survey, the studies mainly aimed to classify three classes (i.e., positive, neutral, and negative) or more classes (partitioned based on the scores of arousal and valence). Within these papers, the datasets named 'SEED'  [87]  and 'DEAP'  [88]  were frequently used to evaluate deep learning models for emotion recognition.\n\nSEED dataset was published by the BCMI laboratory at the Shanghai Jiao Tong University  [87] . For this dataset, 62 channels were used to collect EEG data from 15 subjects when they were watching positive, negative, and neutral video clips. The data were collected from the subjects three times with an interval of one week or longer. Thus, it enables cross-session investigations. Zheng et al. demonstrated the stable patterns of EEG signals over time for emotion recognition  [89] . Besides, they found that differential entropy could provide better performance than other features such as differential asymmetry and rational asymmetry. Using this dataset, Yang et al. proposed a hierarchical network which consists of subnetwork node, and this method boosted 5%-10% accuracy  [90] . Li et al. trained a CNN and accomplished around 88% of recognition accuracy based on features of the gamma band  [91] . Zhang et al. proposed a two-layer RNN model to extract spatial and temporal features, respectively. The first layer of their model is an RNN layer that takes EEG signals from electrodes as inputs. The outputs of the first layer were concatenated along the time dimension and fed into the second RNN layer. The performance evaluated on the SEED dataset was 89.5%  [83] . In  [92] , Zeng et al. used an architecture that adapted from Sinc-Net (a CNN-based network proposed for speaker recognition  [93] ) to classify emotion. Their results demonstrated that the adapted SincNet (i.e., three convolutional layers and three fully connected layers) was promising for emotion classification, reaching an accuracy of around 95% as evaluated on the SEED dataset.\n\nAnother dataset named 'DEAP'  [88] , was collected from 32 subjects when they watched 40 one-minute-long music videos. Perceptual emotion was assessed in terms of arousal, valence, liking, and dominance. Studies using this dataset have showed that deep learning was successful and effective to classify emotion categories based on EEG.  [85] ,  [94] . Even using raw EEG as the input, LSTM achieved an acceptable accuracy of around 85% in the emotion classification  [95] . In  [96] , various handcrafted EEG features (e.g. sample entropy, mean, and power spectral density) were fed into three stacked autoencoders in a parallel way for voting. Chao et al. also designed a parallel architecture to process EEG signal. However, they used DBN as the basic unit  [97] . To improve the classification performance and utilize strengths of different models. Li et al. combined CNN and LSTM to extract representations from multi-channel EEG, in which CNN was used to learn inter-channel and inter-frequency correlation while LSTM was used to extract contextual information  [98] . The model combination was also used in  [99] , where feature extraction was done by graph convolutional networks, temporal information was memorized by LSTM, and classification was done by a SVM. The same idea of model combination was also used in  [100] , where CNN was used for feature extraction.\n\nBesides the two commonly used datasets (i.e., SEED and DEAP), Serap Aydın used affective video clips to induce nine emotional states (fear, anger, happiness, sadness, amusement, surprise, excitement, calmness, and disgust) and investigated gender effect on emotion recognition  [101] . This paper revealed that emotion is more affected by individual experience than gender. Zhu et al. designed an experiment to explored the emotion in the scenario of two-person interaction. In their experiment, two person need to rate their emotions induced by the same piciture one by one. They extracted the intrabrain and inter-brain phase synchronization features from emotional EEG signals and applied a CNN model to evaluate  [102] . As we know, deep learning needs parameter tuning and it is time-consuming. To mitigate this problem, various strategies were proposed. Hemantha et al. modified the backpropagation neural network by arranging layers in a circular manner that the output can access the parameters of the input and hidden layers  [103] . This modification reduced convergence time by around 20%. Jirayucharoensak et al. used principal component analysis for dimension reduction to lower computation cost  [104] . Gao et al. utilized gradient priority particle swarm optimization to optimize parameters of a CNN model  [105] .",
      "page_start": 20,
      "page_end": 20
    },
    {
      "section_name": "Operator Functional States",
      "text": "The operator functional states (OFS) describe the mental states of operators in specific working conditions  [106] . Two of them are mental workload and mental fatigue. In specific, mental workload is a measure of cognitive resources consumed in the human working memory while mental fatigue is identified by an accumulated process of a disinclination of effort and drowsiness. To date, deep learning was used to identify mental states based on EEG signal. For example, drivers'  [107]  [108] [109]  [110]  and pilots'  [111]  fatigue was monitored for the purposes of preventing fatigued operation.\n\nGeneralization is one of the important metrics to evaluate a model. In the classification of operator functional states, large variance across subjects is challenging. Many studies employed subject-specific classifiers. For example, Tao et al. fused multiple ELMs and Naive Bayesian model to build a subjectspecific classifier. This ensemble model with fine-tuned hyper-parameters was of the higher subject-specific accuracy in mental workload assessment  [112] . In the study of  [113] , Zhang et al. selected the most relevant EEG channels for each subject and used these subject-specific channels for calculating weights between the input layer and the first hidden layer in the DBN. In contrast to the subject-specific models, the cross-subject model aims to have a general model for tolerating variance of subjects. For example, Heron et al. used multi-path convolutional layers and bi-directional LSTM layers to learn frequency and temporal features over subjects. This model achieved low variance in performance across subjects and showed better generalization compared to subject-specific models  [114] . Another cross-subject model was proposed using an adaptive DBN with the weights of the first hidden layer iteratively updated to track the EEG changes in a new subject  [115] . When different tasks were used to induce mental workload, the induced workload might be variable across tasks. The cross-task workload classification was made by using a CNN+RNN model  [116] . Another study used transfer learning strategy to improve model generalization for the classification of mental workload  [117] .\n\nMultiple kinds of features can be fused to improve assessment performance of mental workload. Gao et al. presented a temporal convolutional block to extract sequential information of EEG. The block orderly consists of a 1D convolution, a rectified linear activation, and a batch normalization. Temporal convolutional blocks and dense layers for spatial feature fusion were combined to form a novel network. Their results showed that this architecture can achieve higher accuracy for fatigue classification, when compared to these networks that replace convolutional block by 1D convolution  [109] . Zhang et al. proposed a two-stream CNN network to learn spectral and temporal features  [118] . One stream of CNN was fed by power spectral density topographic maps and the other was fed by topographic maps of amplitude distributions. At the same year (2019), they designed another network for the same propose of learning spectral and temporal features for mental workload classification. In this network, CNN with 3D kernels were first applied to EEG cubes, then extracted features from CNN were flatten to 1D vectors and fed to a bidirectional LSTM for further processing and classification  [116] .\n\nBoth models (i.e. two-stream CNN and CNN+LSTM) showed a significant improvement in mental workload classification.",
      "page_start": 22,
      "page_end": 22
    },
    {
      "section_name": "Sleep Stage Classification",
      "text": "Sleep stage classification helps us understand the course of sleep to assess sleep quality and diagnose sleep-related disorders. Table  10  briefly summarized the characteristics of each sleep stage. With the aid of EEG recording, sleep quality can be assessed objectively. In the processing of sleep quality, sleep staging is a precedent step. To date, deep learning has been applied to sleep staging. For instance, LSTM model was used for sleep stage classification based on a single channel EEG  [119] . CNN+LSTM model was proposed to classify sleep stages  [120]  [28] and detect sleep spindles  [121] .\n\nSleep consists of a sequence of stages. Therefore, temporal information should be useful for sleep stage classification. Morlet wavelets  [122]  and time-frequency representations  [119] [123]  were applied to retain temporal information in the extraction of spectral features. These extracted features were then learned by deep learning models for sleep stage classification, showing promising performance. Using the time-frequency representation of EEG, CNN model achieved good performance  [124] . In another study, the CNN was combined with LSTM to capture both temporal and spatial information for sleep stage classification  [125] . The CNN was also combined with attention mechanism for sleep stage classification  [126] . In contrast to the supervised learning, unsupervised learning can perform with unlabeled data, which is preferable when the data labelling is expensive or very time-consuming. Zhang et al. presented a CNN model with a greedy layer-wise training strategy, in which complex-valued k-means was utilized to train filters used in the convolution with unlabeled EEG data  [127] . In  [128] , unsupervised sparse DBN was used to extract features. Subsequent classifiers (e.g., kNN or SVM) performed well on sleep stage classification by using these unsupervisedextracted features. Jaoude et al. demonstrated that a large training data can help validate classification performance. They trained a deep learning model (CNN+RNN) on sleep data from more than six thousand participants and tested on several publicly available datasets. The model achieved as good as humam experts in sleep staging accuracy  [129] . Usually, the numbers of samples for each sleep stage are unbalanced. To date, several methods have been proposed to release this issue, including the class-balanced random sampling  [122] , data augmentation  [130] , class-balance training set design  [28] , and synthetic minority oversampling technique  [131] .",
      "page_start": 23,
      "page_end": 23
    },
    {
      "section_name": "Others",
      "text": "Those studies that cannot be grouped into the above topics are presented in this subsection. A summary table with key information of those studies is prepared (see Table  8 ). On the one hand, EEG with deep learning can be used for person identification  [132] ,  [133] , age and gender prediction  [134] . On the other hand, it can also be used to decode brain activity related to vision, audio  [135] , and pain  [136] . In a study of image classification  [137] , LSTM was used to extract EEG features while CNN was used to extract image features. This study claimed that features extracted from EEG could help image classification so that classification performance was improved. In  [138] , a CNN+LSTM hybrid network was used to extracted visual representations from EEG, and a generative adversarial network was applied to reconstruct images from the learnt EEG representations. Deep learning and EEG were also applied to understand brain functions and structure. These studies aimed to understand functional brain connectivity  [139] , speech laterality  [140] , as well as memory under specific conditions. For example, Baltatzis et al. investigated the brain's activity of different people (ever experienced school bullying or not) to different stimuli (2D videos or Virtual Reality)  [141] . Doborjeh et al. used EEG and spiking neural network to decode how the brain react to various commercial brands (locally familiar or not)  [142] . Arora et al. studied the memory loss after seizure surgery  [143] .",
      "page_start": 25,
      "page_end": 26
    },
    {
      "section_name": "Discussion",
      "text": "In this survey, we reviewed the researches of deep learning in EEG for the last ten years, which is a critical period for the development of deep learning used in EEG. An introduction about deep learning in EEG was first presented in the first section. Subsequently, we presented classical methods of artifacts removal which is an important step in EEG processing. We detailed prevalent deep learning models, followed by the comprehensive reviews on different applications that used deep learning to process and classify EEG signals. These applications were categorised into several topics for presentation. The increase in the number of published papers suggested that the research of deep learning in EEG are expanding over time. Although remark-able achievements were obtained, challenges and limitations still exist, which need to be addressed. We discuss them below and provide our perspectives.\n\nThe performance of deep learning-based classification should be further improved. Although the published papers showed the advantages of deep learning in EEG classification and demonstrated that deep learning is superior to conventional methods, the performance is much lower compared to the performance achieved by deep learning in image or speech classification  [25] ,  [26] . The reasons for the lower performance are mainly due to two aspects: EEG signal itself and deep learning models. On the one hand, EEG signal is non-stationary and much variable over time, which makes the extraction of robust features difficult. An effective solution for this problem is to partition continuous EEG signal into short segments, which can be seen as a stationary signal. However, this is only an approximation but not a final solution. When performing cross-subject classification or cross-session classification, EEG over subjects or sessions is largely variable, making the above problem more dominant. On the other hand, most deep models are originally proposed to process other signals (e.g., images) rather than EEG. Although certain adaptions of the models have been done, the performance is still not ideal because of mismatch between the models and EEG characteristics. Taking CNN as an example, it is more suitable for image processing. Raw images can be directly fed into the CNN. However, this is not the case when applying to EEG signals. Although we have seen some studies, in which raw EEG was fed into CNN directly without pre-processing, it is not mainstream. The mainstream is still to pre-process EEG before feeding into a deep learning model because the pre-processing is very effective for removing noises to improve signal-to-noise ratio. Another advantage of the pre-processing step is that EEG data can be transformed into other representations and/or reorganised to facilitate the following processing in the deep learning model. For instance, spectral power density is one of the most widely used feature for EEG signal. Without a separate pre-processing step, this kind of feature cannot be obtained because temporal EEG signal cannot be transformed into spectral domain within the deep learning model. Available data size in EEG studies is significantly smaller than that available in image or speech studies  [25] ,  [26] . As we know, the deep learning model requires extensive training and a large data size can benefit model training to a great extent. Compared to the millions of training data in image or speech recognition, the scale of training data is much less in EEG classification, only from tens, hundreds, or at most thousands of participants.\n\nOne potential solution for the lack of EEG data in the model training is the use of transfer learning. Deep learning model can be trained by the data which are not collected at the moment and the trained model can be used for recognition or classification on the new collected EEG data after finetuning or even without fine-tuning  [44] ,  [45] ,  [46] . Unlike image classification, for which there are mature existing pre-trained models (e.g., ImageNet pre-trained VGG model), there is no publicly available pre-trained model for EEG classification. If VGG model is directly applied to EEG, reorganization of EEG has to be done in order to meet the input data format of VGG model. This reorganization might lead to information loss and give detrimental effect on the EEG classification. In addition, there is no idea how well a model trained on images can be tuned to classify EEG signal.\n\nBased on the effectiveness comparison of transfer learning, greater performance improvement was observed in image classification compared to EEG classification. This might be due to the lack of effective training framework and strategies that are suitable for transferring EEG patterns. There was an attempt to transfer the model trained on images to EEG classification  [48] . This transferring is across distinct modalities. It is likely to have a better performance when transferring across relevant modalities. As we know, there are different modalities (e.g., functional near-infrared spectroscopy (fNIRS) and EEG) that can be used to measure underlying brain activity. A deep learning model can be trained on one modality and then fine-tuned by the other modality to classify signals of that modality. Or, different modalities can be used together to train a deep learning model so that the training can be benefited from the complementary information existing in the different modalities. It is a fusion of modalities. It has been seen that classification performance was elevated by feature fusion in the case of using conventional classifiers  [144] . The fusion could be done at the different stages of the classification process (e.g., at the beginning of initial feature fusion or at the later stage of decision fusion  [145] ,  [146] ). Wu et al. utilized both EEG and Electrooculogram (EOG) to classify the level of vigilance by fusing the features extracted from EEG and EOG  [147] . In the future, more extensive research should be carried out to elevate the development of fusion in deep learning models. Especially, to address how to effectively fuse multiple modalities in deep learning models for neurophysiological signal classification and analysis. Of course, collecting adequate data is a straightforward solution for the lack of EEG data. However, this results in new issues, such as cost increase and time delay. If data collection involves different institutes, extra communi-cation effort should be paid to coordinate the data collection. Meanwhile, computation demand will be increased with the increase of data size, which requires to upgrade computational hardware or replace with the new generation hardware (e.g., central processing unit (CPU) and graphics processing unit (GPU)). As mentioned in  [148] , cloud computing service is an effective way to share hardware resources so that the hardware cost in individual institutes will be reduced. Using the cloud computing service, data protection and privacy have to be considered, especially for clinical data.\n\nWhen applying a deep learning model to EEG, we need to adapt the deep learning model in compliance with the characteristics of EEG. For example, how to arrange the input data or how to set kernel size should be considered. EEG signal is usually not directly used and commonly transformed before feeding into a deep learning model. There are strong relationships among temporal domain, spectral domain, and spacial domain. It is important these relationships should be kept as much as possible when arranging the input data. When EEG channels are stacked along a dimension, their spacial layout is distorted. In this case, kernels, such as square kernel, that usually-used in image recognition are no longer effective for EEG classification. A column kernel (covering all channels) is a better choice, which has been supported by the study in  [149] . Further, Wang et al. extended the column kernel by considering brain anatomic structure to develop multiple kernels with the sizes matching brain region sizes, achieving a better performance in schizophrenia identification compared to the usually-used kernels, such as square kernel  [38] .\n\nWe believe deep learning models should be changed to be more flexible. The trained model can be adapted dynamically in real-time as needed. This is not limited to dynamic parameter tuning. Ideally, model architecture can also be adjusted when needed. Also, we hope the newly-developed deep learning model could perform multiple tasks at the same time in the future. Please see the detailed description in  [150] .\n\nApart from the purposes of deep learning-based EEG classification, deep learning may also be a useful tool to reveal neural mechanisms of the brain. When a deep learning model achieves a satisfactory classification performance, it captures essential differences existing between the classes. Therefore, we can look at what information the deep learning model focuses on to roughly infer the underlying associated brain activity. For example, Goh et al. presented spatial distribution of brain activations associated with lower limb movements by probing into the model of spatio-spectral representation learning  [149] . We expect that advanced deep learning models developed in the future could reversely decompose EEG signal back into the representation in the brain to reveal underlying brain mechanisms. It is unrealistic at the current stage, but paying efforts to make progress towards to this target.\n\nA prominent advance we need to mention is the EEGNet  [54] , which is proven effective for different BCI paradigms. Another promising model is SincNet, which was initially proposed for speaker recognition and also well for the classification of EEG signal  [92] . New deep learning architectures, such as capsule network  [38] , are also required to enhance the chance of success of EEG applications.\n\nLastly, a mix of different deep learning units has been increasingly seen, which integrates the characteristics of these units to benefit data learning. Because there is not definite guidance to set optimal deep learning architecture (e.g., model depth and model width) currently, model complexity might be considered to determine the model architecture. The model should have enough capacity for learning information in accordance with classification tasks while its complexity should be kept as low as possible to minimize computational cost.",
      "page_start": 25,
      "page_end": 25
    },
    {
      "section_name": "Conclusion",
      "text": "Our survey is a glimpse of what have been done for the deep learning in EEG over the past ten years. There are still many researches currently on-going at laboratories and hospitals, dealing with challenges we mentioned above and beyond. We hope that our survey can provide the researchers who are working in this field with a summary and facilitate their researches.",
      "page_start": 29,
      "page_end": 29
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Numbers of the published papers in each year. Note that numbers",
      "page": 3
    },
    {
      "caption": "Figure 1: , the majority of these papers were published after",
      "page": 5
    },
    {
      "caption": "Figure 2: (A) Generic framework of a deep learning model. (B) Classical",
      "page": 6
    },
    {
      "caption": "Figure 2: (A)). The hidden",
      "page": 7
    },
    {
      "caption": "Figure 2: (B) or their com-",
      "page": 7
    },
    {
      "caption": "Figure 2: (B) are embedded.",
      "page": 7
    },
    {
      "caption": "Figure 2: (B): RBM Unit), which has a visible layer v = (v1, v2, . . . , vn) and",
      "page": 7
    },
    {
      "caption": "Figure 2: (B): Convolutional Unit). Most CNNs consist of",
      "page": 8
    },
    {
      "caption": "Figure 2: (B): Recurrent",
      "page": 9
    },
    {
      "caption": "Figure 2: (B): Autoencoder Unit).",
      "page": 10
    },
    {
      "caption": "Figure 3: In addition, we",
      "page": 12
    },
    {
      "caption": "Figure 3: Percentages of application topics and deep learning models. The",
      "page": 13
    },
    {
      "caption": "Figure 4: (A) Paradigms of brain-computer interface. (B) Percentages of the",
      "page": 14
    },
    {
      "caption": "Figure 5: Percentages of the selected papers across diseases.",
      "page": 17
    },
    {
      "caption": "Figure 5: ). In this subsec-",
      "page": 17
    },
    {
      "caption": "Figure 6: Four illustrative emotions classiﬁed based on the scores of arousal",
      "page": 20
    },
    {
      "caption": "Figure 6: ). Based on the statistics",
      "page": 20
    }
  ],
  "tables": [
    {
      "caption": "Table 2: When deep learning emerges, the step of artifacts removal is kept. EEG",
      "page": 6
    },
    {
      "caption": "Table 3: for the details of studies), disease detection (see Table 4), emotion",
      "page": 12
    },
    {
      "caption": "Table 5: ), operator functional states (see Table 6), sleep stage",
      "page": 12
    },
    {
      "caption": "Table 7: ), as well as the applications other than above topics",
      "page": 12
    },
    {
      "caption": "Table 8: ). According to statistics, the majority of selected papers belong",
      "page": 12
    },
    {
      "caption": "Table 10: brieﬂy summa-",
      "page": 24
    },
    {
      "caption": "Table 8: ). On the one hand, EEG with deep learning can be",
      "page": 25
    },
    {
      "caption": "Table 1: The Abbreviations in This Survey",
      "page": 63
    },
    {
      "caption": "Table 2: Typical Methods for Artifacts Removal",
      "page": 64
    },
    {
      "caption": "Table 3: Key Information of Papers about Brain-Computer Interface",
      "page": 65
    },
    {
      "caption": "Table 4: Key Information of Papers about Disease Detection",
      "page": 71
    },
    {
      "caption": "Table 5: Key Information of Papers about Emotion Recognition",
      "page": 77
    },
    {
      "caption": "Table 6: Key Information of Papers about Operator Functional States",
      "page": 80
    },
    {
      "caption": "Table 7: Key Information of Papers about Sleep Stage Classiﬁcation",
      "page": 82
    },
    {
      "caption": "Table 8: Key Information about Other Applications",
      "page": 85
    },
    {
      "caption": "Table 9: A Summary of Datasets Mentioned in This Survey",
      "page": 89
    },
    {
      "caption": "Table 10: A Brief Summary of Sleep Stages",
      "page": 92
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Machine learning: Trends, perspectives, and prospects",
      "authors": [
        "M Jordan",
        "T Mitchell"
      ],
      "year": "2015",
      "venue": "Science"
    },
    {
      "citation_id": "2",
      "title": "Machine learning",
      "authors": [
        "D Michie",
        "D Spiegelhalter",
        "C Taylor"
      ],
      "year": "1994",
      "venue": "Neural and Statistical Classification"
    },
    {
      "citation_id": "3",
      "title": "Deep learning",
      "authors": [
        "Y Lecun",
        "Y Bengio",
        "G Hinton"
      ],
      "year": "2015",
      "venue": "nature"
    },
    {
      "citation_id": "4",
      "title": "Imagenet large scale visual recognition challenge",
      "authors": [
        "O Russakovsky",
        "J Deng",
        "H Su",
        "J Krause",
        "S Satheesh",
        "S Ma",
        "Z Huang",
        "A Karpathy",
        "A Khosla",
        "M Bernstein"
      ],
      "year": "2015",
      "venue": "International journal of computer vision"
    },
    {
      "citation_id": "5",
      "title": "Deep speech 2: End-to-end speech recognition in english and mandarin",
      "authors": [
        "D Amodei",
        "S Ananthanarayanan",
        "R Anubhai",
        "J Bai",
        "E Battenberg",
        "C Case",
        "J Casper",
        "B Catanzaro",
        "Q Cheng",
        "G Chen"
      ],
      "year": "2016",
      "venue": "International conference on machine learning"
    },
    {
      "citation_id": "6",
      "title": "Object detection with deep learning: A review",
      "authors": [
        "Z.-Q Zhao",
        "P Zheng",
        "S.-T Xu",
        "X Wu"
      ],
      "year": "2019",
      "venue": "IEEE transactions on neural networks and learning systems"
    },
    {
      "citation_id": "7",
      "title": "Simultaneous Human Health Monitoring and Time-Frequency Sparse Representation Using EEG and ECG Signals",
      "authors": [
        "W He",
        "G Wang",
        "J Hu",
        "C Li",
        "B Guo",
        "F Li"
      ],
      "year": "2019",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "8",
      "title": "Deep learning based on Batch Normalization for P300 signal detection",
      "authors": [
        "M Liu",
        "W Wu",
        "Z Gu",
        "Z Yu",
        "F Qi",
        "Y Li"
      ],
      "year": "2018",
      "venue": "Neurocomputing"
    },
    {
      "citation_id": "9",
      "title": "Hans berger (1873-1941), richard caton (1842-1926), and electroencephalography",
      "authors": [
        "L Haas"
      ],
      "year": "2003",
      "venue": "Neurosurgery & Psychiatry"
    },
    {
      "citation_id": "10",
      "title": "A practical vepbased brain-computer interface",
      "authors": [
        "Y Wang",
        "R Wang",
        "X Gao",
        "B Hong",
        "S Gao"
      ],
      "year": "2006",
      "venue": "IEEE Transactions on neural systems and rehabilitation engineering"
    },
    {
      "citation_id": "11",
      "title": "Combining erps and eeg spectral features for decoding intended movement direction",
      "authors": [
        "J Li",
        "Y Wang",
        "L Zhang",
        "T.-P Jung"
      ],
      "year": "2012",
      "venue": "IEEE Engineering in Medicine and Biology Society"
    },
    {
      "citation_id": "12",
      "title": "Sparse bayesian classification of eeg for brain-computer interface",
      "authors": [
        "Y Zhang",
        "G Zhou",
        "J Jin",
        "Q Zhao",
        "X Wang",
        "A Cichocki"
      ],
      "year": "2015",
      "venue": "IEEE transactions on neural networks and learning systems"
    },
    {
      "citation_id": "13",
      "title": "Canonical polyadic decomposition with auxiliary information for brain-computer interface",
      "authors": [
        "J Li",
        "C Li",
        "A Cichocki"
      ],
      "year": "2015",
      "venue": "IEEE journal of biomedical and health informatics"
    },
    {
      "citation_id": "14",
      "title": "Eeg-based emotion classification using deep belief networks",
      "authors": [
        "W.-L Zheng",
        "J.-Y Zhu",
        "Y Peng",
        "B.-L Lu"
      ],
      "year": "2014",
      "venue": "2014 IEEE International Conference on Multimedia and Expo (ICME)"
    },
    {
      "citation_id": "15",
      "title": "Emotion Recognition from Multiband EEG Signals Using CapsNet",
      "authors": [
        "H Chao",
        "L Dong",
        "Y Liu",
        "B Lu"
      ],
      "year": "2019",
      "venue": "Sensors"
    },
    {
      "citation_id": "16",
      "title": "Deep models for engagement assessment with scarce label information",
      "authors": [
        "F Li",
        "G Zhang",
        "W Wang",
        "R Xu",
        "T Schnell",
        "J Wen",
        "F Mckenzie",
        "J Li"
      ],
      "year": "2017",
      "venue": "IEEE Transactions on Human-Machine Systems"
    },
    {
      "citation_id": "17",
      "title": "Smile: A System to Support Machine Learning on EEG Data at Scale",
      "authors": [
        "L Cao",
        "W Tao",
        "S An",
        "J Jin",
        "Y Yan",
        "X Liu",
        "W Ge",
        "A Sah",
        "L Battle",
        "J Sun",
        "R Chang",
        "B Westover",
        "S Madden",
        "M Stonebrakerl"
      ],
      "year": "2019",
      "venue": "Proceedings of the VLDB Endowment"
    },
    {
      "citation_id": "18",
      "title": "Convolutional neural network with embedded fourier transform for eeg classification",
      "authors": [
        "H Cecotti",
        "A Graeser"
      ],
      "year": "2008",
      "venue": "th International Conference on Pattern Recognition"
    },
    {
      "citation_id": "19",
      "title": "Deep learning of multifractal attributes from motor imagery induced eeg",
      "authors": [
        "J Li",
        "A Cichocki"
      ],
      "year": "2014",
      "venue": "International Conference on Neural Information Processing"
    },
    {
      "citation_id": "20",
      "title": "A Long Short-Term Memory deep learning network for the prediction of epileptic seizures using EEG signals",
      "authors": [
        "K Tsiouris",
        "V Pezoulas",
        "M Zervakis",
        "S Konitsiotis",
        "D Koutsouris",
        "D Fotiadis"
      ],
      "year": "2018",
      "venue": "Computers in Biology and Medicine"
    },
    {
      "citation_id": "21",
      "title": "Deep learning for electroencephalogram (eeg) classification tasks: a review",
      "authors": [
        "A Craik",
        "Y He",
        "J Contreras-Vidal"
      ],
      "year": "2019",
      "venue": "Journal of neural engineering"
    },
    {
      "citation_id": "22",
      "title": "Deep learning for motor imagery eeg-based classification: A review",
      "authors": [
        "A Al-Saegh",
        "S Dawwd",
        "J Abdul-Jabbar"
      ],
      "year": "2021",
      "venue": "Biomedical Signal Processing and Control"
    },
    {
      "citation_id": "23",
      "title": "Diagnosis and prognosis of mental disorders by means of eeg and deep learning: a systematic mapping study",
      "authors": [
        "M Rivera",
        "M Teruel",
        "A Maté",
        "J Trujillo"
      ],
      "year": "2021",
      "venue": "Artificial Intelligence Review"
    },
    {
      "citation_id": "24",
      "title": "Eeg-based brain-computer interfaces (bcis): A survey of recent studies on signal sensing technologies and computational intelligence approaches and their applications",
      "authors": [
        "X Gu",
        "Z Cao",
        "A Jolfaei",
        "P Xu",
        "D Wu",
        "T.-P Jung",
        "C.-T Lin"
      ],
      "year": "2021",
      "venue": "IEEE/ACM transactions on computational biology and bioinformatics"
    },
    {
      "citation_id": "25",
      "title": "Deep convolutional neural networks for image classification: A comprehensive review",
      "authors": [
        "W Rawat",
        "Z Wang"
      ],
      "year": "2017",
      "venue": "Neural computation"
    },
    {
      "citation_id": "26",
      "title": "Speech recognition using deep neural networks: A systematic review",
      "authors": [
        "A Nassif",
        "I Shahin",
        "I Attili",
        "M Azzeh",
        "K Shaalan"
      ],
      "year": "2019",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "27",
      "title": "Optimized Deep Learning for EEG Big Data and Seizure Prediction BCI via Internet of Things",
      "authors": [
        "M Hosseini",
        "D Pompili",
        "K Elisevich",
        "H Soltanian-Zadeh"
      ],
      "year": "2017",
      "venue": "IEEE Transactions on Big Data"
    },
    {
      "citation_id": "28",
      "title": "DeepSleepNet: A Model for Automatic Sleep Stage Scoring Based on Raw Single-Channel EEG",
      "authors": [
        "A Supratak",
        "H Dong",
        "C Wu",
        "Y Guo"
      ],
      "year": "2017",
      "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering"
    },
    {
      "citation_id": "29",
      "title": "A Correlation-Driven Mapping For Deep Learning application in detecting artifacts within the EEG",
      "authors": [
        "N Bahador",
        "K Erikson",
        "J Laurila",
        "J Koskenkari",
        "T Ala-Kokko",
        "J Kortelainen"
      ],
      "year": "2020",
      "venue": "Journal of Neural Engineering",
      "doi": "10.1088/1741-2552/abb5bd"
    },
    {
      "citation_id": "30",
      "title": "Restricted boltzmann machines for collaborative filtering",
      "authors": [
        "R Salakhutdinov",
        "A Mnih",
        "G Hinton"
      ],
      "year": "2007",
      "venue": "Proceedings of the 24th international conference on Machine learning"
    },
    {
      "citation_id": "31",
      "title": "A fast learning algorithm for deep belief nets",
      "authors": [
        "G Hinton",
        "S Osindero",
        "Y.-W Teh"
      ],
      "year": "2006",
      "venue": "Neural computation"
    },
    {
      "citation_id": "32",
      "title": "Imagenet classification with deep convolutional neural networks",
      "authors": [
        "A Krizhevsky",
        "I Sutskever",
        "G Hinton"
      ],
      "year": "2012",
      "venue": "Imagenet classification with deep convolutional neural networks"
    },
    {
      "citation_id": "33",
      "title": "A critical review of recurrent neural networks for sequence learning",
      "authors": [
        "Z Lipton",
        "J Berkowitz",
        "C Elkan"
      ],
      "year": "2015",
      "venue": "A critical review of recurrent neural networks for sequence learning",
      "arxiv": "arXiv:1506.00019"
    },
    {
      "citation_id": "34",
      "title": "Empirical evaluation of gated recurrent neural networks on sequence modeling",
      "authors": [
        "J Chung",
        "C Gulcehre",
        "K Cho",
        "Y Bengio"
      ],
      "year": "2014",
      "venue": "Empirical evaluation of gated recurrent neural networks on sequence modeling",
      "arxiv": "arXiv:1412.3555"
    },
    {
      "citation_id": "35",
      "title": "Long short-term memory",
      "authors": [
        "S Hochreiter",
        "J Schmidhuber"
      ],
      "year": "1997",
      "venue": "Neural computation"
    },
    {
      "citation_id": "36",
      "title": "Learning internal representations by error propagation",
      "authors": [
        "D Rumelhart",
        "G Hinton",
        "R Williams"
      ],
      "year": "1985",
      "venue": "Learning internal representations by error propagation"
    },
    {
      "citation_id": "37",
      "title": "Dynamic routing between capsules",
      "authors": [
        "S Sabour",
        "N Frosst",
        "G Hinton"
      ],
      "year": "2017",
      "venue": "Advances in neural information processing systems"
    },
    {
      "citation_id": "38",
      "title": "Multikernel capsule network for schizophrenia identification",
      "authors": [
        "T Wang",
        "A Bezerianos",
        "A Cichocki",
        "J Li"
      ],
      "year": "2020",
      "venue": "IEEE Transactions on Cybernetics"
    },
    {
      "citation_id": "39",
      "title": "Deep Extreme Learning Machine and Its Application in EEG Classification",
      "authors": [
        "S Ding",
        "N Zhang",
        "X Xu",
        "L Guo",
        "J Zhang"
      ],
      "year": "2015",
      "venue": "Mathematical Problems in Engineering"
    },
    {
      "citation_id": "40",
      "title": "Reservoir computing for emotion valence discrimination from EEG signals",
      "authors": [
        "L Bozhkov",
        "P Koprinkova-Hristova",
        "P Georgieva"
      ],
      "year": "2017",
      "venue": "Neurocomputing"
    },
    {
      "citation_id": "41",
      "title": "A Spiking Neural Network Methodology and System for Learning and Comparative Analysis of EEG Data From Healthy Versus Addiction Treated Versus Addiction Not Treated Subjects",
      "authors": [
        "M Doborjeh",
        "G Wang",
        "N Kasabov",
        "R Kydd",
        "B Russell"
      ],
      "year": "2016",
      "venue": "IEEE Transactions on Biomedical Engineering"
    },
    {
      "citation_id": "42",
      "title": "Walking Imagery Evaluation in Brain Computer Interfaces via a Multi-view Multi-level Deep Polynomial Network",
      "authors": [
        "B Lei",
        "X Liu",
        "S Liang",
        "W Hang",
        "Q Wang",
        "K Choi",
        "J Qin"
      ],
      "year": "2019",
      "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering"
    },
    {
      "citation_id": "43",
      "title": "Adaptive transfer learning for eeg motor imagery classification with deep convolutional neural network",
      "authors": [
        "K Zhang",
        "N Robinson",
        "S.-W Lee",
        "C Guan"
      ],
      "year": "2021",
      "venue": "Neural Networks"
    },
    {
      "citation_id": "44",
      "title": "A Deep Learning Scheme for Motor Imagery Classification based on Restricted Boltzmann Machines",
      "authors": [
        "N Lu",
        "T Li",
        "X Ren",
        "H Miao"
      ],
      "year": "2017",
      "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering"
    },
    {
      "citation_id": "45",
      "title": "Cross-Subject EEG Signal Recognition Using Deep Domain Adaptation Network",
      "authors": [
        "W Hang",
        "W Feng",
        "R Du",
        "S Liang",
        "Y Chen",
        "Q Wang",
        "X Liu"
      ],
      "year": "2019",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "46",
      "title": "Learning joint spacetime-frequency features for EEG decoding on small labeled data",
      "authors": [
        "D Zhao",
        "F Tang",
        "B Si",
        "X Feng"
      ],
      "year": "2019",
      "venue": "Neural Networks"
    },
    {
      "citation_id": "47",
      "title": "An end-to-end deep learning approach to MI-EEG signal classification for BCIs",
      "authors": [
        "H Dose",
        "J Moller",
        "H Iversen",
        "S Puthusserypady"
      ],
      "year": "2018",
      "venue": "Expert Systems with Applications"
    },
    {
      "citation_id": "48",
      "title": "A Deep Transfer Convolutional Neural Network Framework for EEG Signal Classification",
      "authors": [
        "G Xu",
        "X Shen",
        "S Chen",
        "Y Zong",
        "C Zhang",
        "H Yue",
        "M Liu",
        "F Chen",
        "W Che"
      ],
      "year": "2019",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "49",
      "title": "A Channel-Projection Mixed-Scale Convolutional Neural Network for Motor Imagery EEG Decoding",
      "authors": [
        "Y Li",
        "X Zhang",
        "B Zhang",
        "M Lei",
        "W Cui",
        "Y Guo"
      ],
      "year": "2019",
      "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering"
    },
    {
      "citation_id": "50",
      "title": "A Novel Deep Learning Approach With Data Augmentation to Classify Motor Imagery Signals",
      "authors": [
        "Z Zhang",
        "F Duan",
        "J Sole-Casals",
        "J Dinares-Ferran",
        "A Cichocki",
        "Z Yang",
        "Z Sun"
      ],
      "year": "2019",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "51",
      "title": "Densely Feature Fusion Based on Convolutional Neural Networks for Motor Imagery EEG Classification",
      "authors": [
        "D Li",
        "J Wang",
        "J Xu",
        "X Fang"
      ],
      "year": "2019",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "52",
      "title": "A Deep Learning Framework for Decoding Motor Imagery Tasks of the Same Hand Using EEG Signals",
      "authors": [
        "R Alazrai",
        "M Abuhijleh",
        "H Alwanni",
        "M Daoud"
      ],
      "year": "2019",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "53",
      "title": "Improving Performance of Devanagari Script Input-Based P300 Speller Using Deep Learning",
      "authors": [
        "G Kshirsagar",
        "N Londhe"
      ],
      "year": "2019",
      "venue": "IEEE Transactions on Biomedical Engineering"
    },
    {
      "citation_id": "54",
      "title": "EEGNet: a compact convolutional neural network for EEG-based brain-computer interfaces",
      "authors": [
        "V Lawhern",
        "A Solon",
        "N Waytowich",
        "S Gordon",
        "C Hung",
        "B Lance"
      ],
      "year": "2018",
      "venue": "Journal of Neural Engineering"
    },
    {
      "citation_id": "55",
      "title": "Decoding Asynchronous Reaching in Electroencephalography Using Stacked Autoencoders",
      "authors": [
        "D Pei",
        "M Burns",
        "R Chandramouli",
        "R Vinjamuri"
      ],
      "year": "2018",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "56",
      "title": "P300 based character recognition using sparse autoencoder with ensemble of SVMs",
      "authors": [
        "S Kundu",
        "S Ari"
      ],
      "year": "2019",
      "venue": "Biocybernetics and Biomedical Engineering"
    },
    {
      "citation_id": "57",
      "title": "A novel deep learning approach for classification of EEG motor imagery signals",
      "authors": [
        "Y Tabar",
        "U Halici"
      ],
      "year": "2017",
      "venue": "Journal of Neural Engineering"
    },
    {
      "citation_id": "58",
      "title": "Deep Learning for EEG motor imagery classification based on multi-layer CNNs feature fusion",
      "authors": [
        "S Amin",
        "M Alsulaiman",
        "G Muhammad",
        "M Mekhtiche",
        "M Hossain"
      ],
      "year": "2019",
      "venue": "Future Generation Computer Systems-the International Journal of Escience"
    },
    {
      "citation_id": "59",
      "title": "A novel hybrid deep learning scheme for four-class motor imagery classification",
      "authors": [
        "R Zhang",
        "Q Zong",
        "L Dou",
        "X Zhao"
      ],
      "year": "2019",
      "venue": "Journal of Neural Engineering"
    },
    {
      "citation_id": "60",
      "title": "Deep Fusion Feature Learning Network for MI-EEG Classification",
      "authors": [
        "J Yang",
        "S Yao",
        "J Wang"
      ],
      "year": "2018",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "61",
      "title": "The extraction of motion-onset VEP BCI features based on deep learning and compressed sensing",
      "authors": [
        "T Ma",
        "H Li",
        "H Yang",
        "X Lv",
        "P Li",
        "T Liu",
        "D Yao",
        "P Xu"
      ],
      "year": "2017",
      "venue": "Journal of Neuroscience Methods"
    },
    {
      "citation_id": "62",
      "title": "A Single-Chanel SSVEP-Based BCI Speller Using Deep Learning",
      "authors": [
        "T Nguyen",
        "W Chung"
      ],
      "year": "2019",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "63",
      "title": "Compact convolutional neural networks for classification of asynchronous steady-state visual evoked potentials",
      "authors": [
        "N Waytowich",
        "V Lawhern",
        "J Garcia",
        "J Cummings",
        "J Faller",
        "P Sajda",
        "J Vettel"
      ],
      "year": "2018",
      "venue": "Journal of Neural Engineering"
    },
    {
      "citation_id": "64",
      "title": "Deep convolutional neural network for the automated detection and diagnosis of seizure using EEG signals",
      "authors": [
        "U Acharya",
        "S Oh",
        "Y Hagiwara",
        "J Tan",
        "H Adeli"
      ],
      "year": "2018",
      "venue": "Computers in Biology and Medicine"
    },
    {
      "citation_id": "65",
      "title": "Deep Convolutional Neural Network Model for Automated Diagnosis of Schizophrenia Using EEG Signals",
      "authors": [
        "S Oh",
        "J Vicnesh",
        "E Ciaccio",
        "R Yuvaraj",
        "U Acharya"
      ],
      "year": "2019",
      "venue": "Applied Sciences-Basel"
    },
    {
      "citation_id": "66",
      "title": "Epileptic Signal Classification With Deep EEG Features by Stacked CNNs",
      "authors": [
        "J Cao",
        "J Zhu",
        "W Hu",
        "A Kummert"
      ],
      "year": "2020",
      "venue": "IEEE Transactions on Cognitive and Developmental Systems"
    },
    {
      "citation_id": "67",
      "title": "Detection of Interictal Discharges With Convolutional Neural Networks Using Discrete Ordered Multichannel Intracranial EEG",
      "authors": [
        "A Antoniades",
        "L Spyrou",
        "D Martin-Lopez",
        "A Valentin",
        "G Alarcon",
        "S Sanei",
        "C Took"
      ],
      "year": "2017",
      "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering"
    },
    {
      "citation_id": "68",
      "title": "Deep Convolution Neural Network and Autoencoders-Based Unsupervised Feature Learning of EEG Signals",
      "authors": [
        "T Wen",
        "Z Zhang"
      ],
      "year": "2018",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "69",
      "title": "Efficient Epileptic Seizure Prediction Based on Deep Learning",
      "authors": [
        "H Daoud",
        "M Bayoumi"
      ],
      "year": "2019",
      "venue": "IEEE Transactions on Biomedical Circuits and Systems"
    },
    {
      "citation_id": "70",
      "title": "Deep Learning Approach for Epileptic Focus Localization",
      "authors": [
        "H Daoud",
        "M Bayoumi"
      ],
      "year": "2020",
      "venue": "IEEE Transactions on Biomedical Circuits and Systems"
    },
    {
      "citation_id": "71",
      "title": "A deep learning framework for automatic diagnosis of unipolar depression",
      "authors": [
        "W Mumtaz",
        "A Qayyum"
      ],
      "year": "2019",
      "venue": "International Journal of Medical Informatics"
    },
    {
      "citation_id": "72",
      "title": "Denoising Sparse Autoencoder-Based Ictal PEG Classification",
      "authors": [
        "Y Qiu",
        "W Zhou",
        "N Yu",
        "P Du"
      ],
      "year": "2018",
      "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering"
    },
    {
      "citation_id": "73",
      "title": "A deep learning framework for identifying children with ADHD using an EEG-based brain network",
      "authors": [
        "H Chen",
        "Y Song",
        "X Li"
      ],
      "year": "2019",
      "venue": "Neurocomputing"
    },
    {
      "citation_id": "74",
      "title": "A Multi-View Deep Learning Framework for EEG Seizure Detection",
      "authors": [
        "Y Yuan",
        "G Xun",
        "K Jia",
        "A Zhang"
      ],
      "year": "2019",
      "venue": "IEEE Journal of Biomedical and Health Informatics"
    },
    {
      "citation_id": "75",
      "title": "A Convolutional Neural Network approach for classification of dementia stages based on 2D-spectral representation of EEG recordings",
      "authors": [
        "C Ieracitano",
        "N Mammone",
        "A Bramanti",
        "A Hussain",
        "F Morabito"
      ],
      "year": "2019",
      "venue": "Neurocomputing"
    },
    {
      "citation_id": "76",
      "title": "Classification of People who Suffer Schizophrenia and Healthy People by EEG Signals using Deep Learning",
      "authors": [
        "C Naira",
        "C Del Alamo"
      ],
      "year": "2019",
      "venue": "International Journal of Advanced Computer Science and Applications"
    },
    {
      "citation_id": "77",
      "title": "Automatic Classification of Motor Impairment Neural Disorders from EEG Signals Using Deep Convolutional Neural Networks",
      "authors": [
        "G Vrbancic",
        "V Podgorelec"
      ],
      "year": "2018",
      "venue": "Elektronika Ir Elektrotechnika"
    },
    {
      "citation_id": "78",
      "title": "Epilepsy Detection by Using Scalogram Based Convolutional Neural Network from EEG Signals",
      "authors": [
        "O Turk",
        "M Ozerdem"
      ],
      "year": "2019",
      "venue": "Brain Sciences"
    },
    {
      "citation_id": "79",
      "title": "Automatic seizure detection using three-dimensional CNN based on multi-channel EEG",
      "authors": [
        "X Wei",
        "L Zhou",
        "Z Chen",
        "L Zhang",
        "Y Zhou"
      ],
      "year": "2018",
      "venue": "Bmc Medical Informatics and Decision Making"
    },
    {
      "citation_id": "80",
      "title": "Deep Multi-View Feature Learning for EEG-Based Epileptic Seizure Detection",
      "authors": [
        "X Tian",
        "Z Deng",
        "W Ying",
        "K Choi",
        "D Wu",
        "B Qin",
        "J Wang",
        "H Shen",
        "S Wang"
      ],
      "year": "2019",
      "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering"
    },
    {
      "citation_id": "81",
      "title": "Classification of epileptic EEG recordings using signal transforms and convolutional neural networks",
      "authors": [
        "R San-Segundo",
        "M Gil-Martin",
        "L D'haro-Enriquez",
        "J Pardo"
      ],
      "year": "2019",
      "venue": "Computers in Biology and Medicine"
    },
    {
      "citation_id": "82",
      "title": "An automated system for epilepsy detection using EEG brain signals based on deep learning approach",
      "authors": [
        "I Ullah",
        "M Hussain",
        "E Qazi",
        "H Aboalsamh"
      ],
      "year": "2018",
      "venue": "Expert Systems with Applications"
    },
    {
      "citation_id": "83",
      "title": "Spatial-Temporal Recurrent Neural Network for Emotion Recognition",
      "authors": [
        "T Zhang",
        "W Zheng",
        "Z Cui",
        "Y Zong",
        "Y Li"
      ],
      "year": "2019",
      "venue": "IEEE Transactions on Cybernetics"
    },
    {
      "citation_id": "84",
      "title": "Emotion-Meter: A Multimodal Framework for Recognizing Human Emotions",
      "authors": [
        "W Zheng",
        "W Liu",
        "Y Lu",
        "B Lu",
        "A Cichocki"
      ],
      "year": "2019",
      "venue": "IEEE Transactions on Cybernetics"
    },
    {
      "citation_id": "85",
      "title": "Classification of Human Emotions from Electroencephalogram (EEG) Signal using Deep Neural Network",
      "authors": [
        "A Al-Nafjan",
        "A Al-Wabil",
        "M Hosny",
        "Y Al-Ohali"
      ],
      "year": "2017",
      "venue": "International Journal of Advanced Computer Science and Applications"
    },
    {
      "citation_id": "86",
      "title": "Electroencephalography Based Fusion Two-Dimensional (2D)-Convolution Neural Networks (CNN) Model for Emotion Recognition System",
      "authors": [
        "Y Kwon",
        "S Shin",
        "S Kim"
      ],
      "year": "2018",
      "venue": "Sensors"
    },
    {
      "citation_id": "87",
      "title": "Investigating critical frequency bands and channels for eeg-based emotion recognition with deep neural networks",
      "authors": [
        "W.-L Zheng",
        "B.-L Lu"
      ],
      "year": "2015",
      "venue": "IEEE Transactions on Autonomous Mental Development"
    },
    {
      "citation_id": "88",
      "title": "Deap: A database for emotion analysis; using physiological signals",
      "authors": [
        "S Koelstra",
        "C Muhl",
        "M Soleymani",
        "J.-S Lee",
        "A Yazdani",
        "T Ebrahimi",
        "T Pun",
        "A Nijholt",
        "I Patras"
      ],
      "year": "2011",
      "venue": "IEEE transactions on affective computing"
    },
    {
      "citation_id": "89",
      "title": "Identifying Stable Patterns over Time for Emotion Recognition from EEG",
      "authors": [
        "W.-L Zheng",
        "J.-Y Zhu",
        "B.-L Lu"
      ],
      "year": "2017",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "90",
      "title": "EEG-Based Emotion Recognition Using Hierarchical Network With Subnetwork Nodes",
      "authors": [
        "Y Yang",
        "Q Wu",
        "W.-L Zheng",
        "B.-L Lu"
      ],
      "year": "2018",
      "venue": "IEEE Transactions on Cognitive and Developmental Systems"
    },
    {
      "citation_id": "91",
      "title": "Hierarchical Convolutional Neural Networks for EEG-Based Emotion Recognition",
      "authors": [
        "J Li",
        "Z Zhang",
        "H He"
      ],
      "year": "2018",
      "venue": "Cognitive Computation"
    },
    {
      "citation_id": "92",
      "title": "EEG Emotion Classification Using an Improved SincNet-Based Deep Learning Model",
      "authors": [
        "H Zeng",
        "Z Wu",
        "J Zhang",
        "C Yang",
        "H Zhang",
        "G Dai",
        "W Kong"
      ],
      "year": "2019",
      "venue": "Brain Sciences"
    },
    {
      "citation_id": "93",
      "title": "Speaker recognition from raw waveform with sincnet",
      "authors": [
        "M Ravanelli",
        "Y Bengio"
      ],
      "year": "2018",
      "venue": "2018 IEEE Spoken Language Technology Workshop (SLT)"
    },
    {
      "citation_id": "94",
      "title": "Arousal and Valence Classification Model Based on Long Short-Term Memory and DEAP Data for Mental Healthcare Management",
      "authors": [
        "E Choi",
        "D Kim"
      ],
      "year": "2018",
      "venue": "Healthcare Informatics Research"
    },
    {
      "citation_id": "95",
      "title": "Emotion Recognition based on EEG using LSTM Recurrent Neural Network",
      "authors": [
        "S Alhagry",
        "A Fahmy",
        "R El-Khoribi"
      ],
      "year": "2017",
      "venue": "International Journal of Advanced Computer Science and Applications"
    },
    {
      "citation_id": "96",
      "title": "Emotion Recognition from Physiological Signals Using Parallel Stacked Autoencoders",
      "authors": [
        "S Bagherzadeh",
        "K Maghooli",
        "J Farhadi",
        "M Soroush"
      ],
      "year": "2018",
      "venue": "Neurophysiology"
    },
    {
      "citation_id": "97",
      "title": "Recognition of Emotions Using Multichannel EEG Data and DBN-GC-Based Ensemble Deep Learning Framework",
      "authors": [
        "H Chao",
        "H Zhi",
        "L Dong",
        "Y Liu"
      ],
      "year": "2018",
      "venue": "Computational Intelligence and Neuroscience"
    },
    {
      "citation_id": "98",
      "title": "Deep fusion of multi-channel neurophysiological signal for emotion recognition and monitoring",
      "authors": [
        "X Li",
        "D Song",
        "P Zhang",
        "Y Hou",
        "B Hu"
      ],
      "year": "2017",
      "venue": "International Journal of Data Mining and Bioinformatics"
    },
    {
      "citation_id": "99",
      "title": "Eeg emotion recognition using fusion model of graph convolutional neural networks and lstm",
      "authors": [
        "Y Yin",
        "X Zheng",
        "B Hu",
        "Y Zhang",
        "X Cui"
      ],
      "year": "2021",
      "venue": "Applied Soft Computing"
    },
    {
      "citation_id": "100",
      "title": "Emotion recognition based on eeg feature maps through deep learning network",
      "authors": [
        "A Topic",
        "M Russo"
      ],
      "year": "2021",
      "venue": "Engineering Science and Technology, an International Journal"
    },
    {
      "citation_id": "101",
      "title": "Deep Learning Classification of Neuro-Emotional Phase Domain Complexity Levels Induced by Affective Video Film Clips",
      "authors": [
        "S Aydin"
      ],
      "year": "2020",
      "venue": "IEEE Journal of Biomedical and Health Informatics"
    },
    {
      "citation_id": "102",
      "title": "EEG-based approach for recognizing human social emotion perception",
      "authors": [
        "L Zhu",
        "C Su",
        "J Zhang",
        "G Cui",
        "A Cichocki",
        "C Zhou",
        "J Li"
      ],
      "year": "2020",
      "venue": "Advanced Engineering Informatics"
    },
    {
      "citation_id": "103",
      "title": "Brain signal based human emotion analysis by circular back propagation and Deep Kohonen Neural Networks",
      "authors": [
        "D Hemanth",
        "J Anitha",
        "L Son"
      ],
      "year": "2018",
      "venue": "Computers & Electrical Engineering"
    },
    {
      "citation_id": "104",
      "title": "EEG-Based Emotion Recognition Using Deep Learning Network with Principal Component Based Covariate Shift Adaptation",
      "authors": [
        "S Jirayucharoensak",
        "S Pan-Ngum",
        "P Israsena"
      ],
      "year": "2014",
      "venue": "Scientific World Journal"
    },
    {
      "citation_id": "105",
      "title": "A GPSO-optimized convolutional neural networks for EEGbased emotion recognition",
      "authors": [
        "Z Gao",
        "Y Li",
        "Y Yang",
        "X Wang",
        "N Dong",
        "H Chiang"
      ],
      "year": "2020",
      "venue": "Neurocomputing"
    },
    {
      "citation_id": "106",
      "title": "Task-generic mental fatigue recognition based on neurophysiological signals and dynamical deep extreme learning machine",
      "authors": [
        "Z Yin",
        "J Zhang"
      ],
      "year": "2018",
      "venue": "Neurocomputing"
    },
    {
      "citation_id": "107",
      "title": "Driving Fatigue Detection from EEG Using a Modified PCANet Method",
      "authors": [
        "Y Ma",
        "B Chen",
        "R Li",
        "C Wang",
        "J Wang",
        "Q She",
        "Z Luo",
        "Y Zhang"
      ],
      "year": "2019",
      "venue": "Computational Intelligence and Neuroscience"
    },
    {
      "citation_id": "108",
      "title": "EEG classification of driver mental states by deep learning",
      "authors": [
        "H Zeng",
        "C Yang",
        "G Dai",
        "F Qin",
        "J Zhang",
        "W Kong"
      ],
      "year": "2018",
      "venue": "Cognitive Neurodynamics"
    },
    {
      "citation_id": "109",
      "title": "EEG-Based Spatio-Temporal Convolutional Neural Network for Driver Fatigue Evaluation",
      "authors": [
        "Z Gao",
        "X Wang",
        "Y Yang",
        "C Mu",
        "Q Cai",
        "W Dang",
        "S Zuo"
      ],
      "year": "2019",
      "venue": "IEEE Transactions on Neural Networks and Learning Systems"
    },
    {
      "citation_id": "110",
      "title": "Improving EEG-Based Driver Fatigue Classification Using Sparse-Deep Belief Networks",
      "authors": [
        "R Chai",
        "S Ling",
        "P San",
        "G Naik",
        "T Nguyen",
        "Y Tran",
        "A Craig",
        "H Nguyen"
      ],
      "year": "2017",
      "venue": "Frontiers in Neuroscience"
    },
    {
      "citation_id": "111",
      "title": "Pilots' Fatigue Status Recognition Using Deep Contractive Autoencoder Network",
      "authors": [
        "E Wu",
        "X Peng",
        "C Zhang",
        "J Lin",
        "R Sheng"
      ],
      "year": "2019",
      "venue": "IEEE Transactions on Instrumentation and Measurement"
    },
    {
      "citation_id": "112",
      "title": "Individual-Specific Classification of Mental Workload Levels Via an Ensemble Heterogeneous Extreme Learning Machine for EEG Modeling",
      "authors": [
        "J Tao",
        "Z Yin",
        "L Liu",
        "Y Tian",
        "Z Sun",
        "J Zhang"
      ],
      "year": "2019",
      "venue": "Symmetry-Basel"
    },
    {
      "citation_id": "113",
      "title": "A deep learning scheme for mental workload classification based on restricted Boltzmann machines",
      "authors": [
        "J Zhang",
        "S Li"
      ],
      "year": "2017",
      "venue": "Cognition Technology & Work"
    },
    {
      "citation_id": "114",
      "title": "Cross-Participant EEG-Based Assessment of Cognitive Workload Using Multi-Path Convolutional Recurrent Neural Networks",
      "authors": [
        "R Hefron",
        "B Borghetti",
        "C Kabban",
        "J Christensen",
        "J Estepp"
      ],
      "year": "2018",
      "venue": "Sensors"
    },
    {
      "citation_id": "115",
      "title": "Cross-subject recognition of operator functional states via EEG and switching deep belief networks with adaptive weights",
      "authors": [
        "Z Yin",
        "J Zhang"
      ],
      "year": "2017",
      "venue": "Neurocomputing"
    },
    {
      "citation_id": "116",
      "title": "Learning Spatial-Spectral-Temporal EEG Features With Recurrent 3D Convolutional Neural Networks for Cross-Task Mental Workload Assessment",
      "authors": [
        "P Zhang",
        "X Wang",
        "W Zhang",
        "J Chen"
      ],
      "year": "2019",
      "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering"
    },
    {
      "citation_id": "117",
      "title": "Physiological-signal-based mental workload estimation via transfer dynamical autoencoders in a deep learning framework",
      "authors": [
        "Z Yin",
        "M Zhao",
        "W Zhang",
        "Y Wang",
        "Y Wang",
        "J Zhang"
      ],
      "year": "2019",
      "venue": "Neurocomputing"
    },
    {
      "citation_id": "118",
      "title": "Spectral and Temporal Feature Learning With Two-Stream Neural Networks for Mental Workload Assessment",
      "authors": [
        "P Zhang",
        "X Wang",
        "J Chen",
        "W You",
        "W Zhang"
      ],
      "year": "2019",
      "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering"
    },
    {
      "citation_id": "119",
      "title": "Mixed Neural Network Approach for Temporal Sleep Stage Classification",
      "authors": [
        "H Dong",
        "A Supratak",
        "W Pan",
        "C Wu",
        "P Matthews",
        "Y Guo"
      ],
      "year": "2018",
      "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering"
    },
    {
      "citation_id": "120",
      "title": "Recurrent Deep Neural Networks for Real-Time Sleep Stage Classification From Single Channel EEG",
      "authors": [
        "E Bresch",
        "U Grossekathofer",
        "G Garcia-Molina"
      ],
      "year": "2018",
      "venue": "Recurrent Deep Neural Networks for Real-Time Sleep Stage Classification From Single Channel EEG"
    },
    {
      "citation_id": "121",
      "title": "A deep learning approach for real-time detection of sleep spindles",
      "authors": [
        "P Kulkarni",
        "Z Xiao",
        "E Robinson",
        "A Jami",
        "J Zhang",
        "H Zhou",
        "S Henin",
        "A Liu",
        "R Osorio",
        "J Wang",
        "Z Chen"
      ],
      "year": "2019",
      "venue": "Journal of Neural Engineering"
    },
    {
      "citation_id": "122",
      "title": "Automatic Sleep Stage Scoring Using Time-Frequency Analysis and Stacked Sparse Autoencoders",
      "authors": [
        "O Tsinalis",
        "P Matthews",
        "Y Guo"
      ],
      "year": "2016",
      "venue": "Annals of Biomedical Engineering"
    },
    {
      "citation_id": "123",
      "title": "Automatic A-Phase Detection of Cyclic Alternating Patterns in Sleep Using Dynamic Temporal Information",
      "authors": [
        "S Hartmann",
        "M Baumert"
      ],
      "year": "2019",
      "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering"
    },
    {
      "citation_id": "124",
      "title": "Orthogonal convolutional neural networks for automatic sleep stage classification based on single-channel EEG",
      "authors": [
        "J Zhang",
        "R Yao",
        "W Ge",
        "J Gao"
      ],
      "year": "2020",
      "venue": "Computer Methods and Programs in Biomedicine"
    },
    {
      "citation_id": "125",
      "title": "Pediatric Sleep Stage Classification Using Multi-Domain Hybrid Neural Networks",
      "authors": [
        "Y Jeon",
        "S Kim",
        "H Choi",
        "Y Chung",
        "S Choi",
        "H Kim",
        "S Yoon",
        "H Hwang",
        "K Kim"
      ],
      "year": "2019",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "126",
      "title": "An attention-based deep learning approach for sleep stage classification with single-channel eeg",
      "authors": [
        "E Eldele",
        "Z Chen",
        "C Liu",
        "M Wu",
        "C.-K Kwoh",
        "X Li",
        "C Guan"
      ],
      "year": "2021",
      "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering"
    },
    {
      "citation_id": "127",
      "title": "Complex-valued unsupervised convolutional neural networks for sleep stage classification",
      "authors": [
        "J Zhang",
        "Y Wu"
      ],
      "year": "2018",
      "venue": "Computer Methods and Programs in Biomedicine"
    },
    {
      "citation_id": "128",
      "title": "Automatic sleep stage classification based on sparse deep belief net and combination of multiple classifiers",
      "authors": [
        "J Zhang",
        "Y Wu",
        "J Bai",
        "F Chen"
      ],
      "year": "2016",
      "venue": "Transactions of the Institute of Measurement and Control"
    },
    {
      "citation_id": "129",
      "title": "Expert-level automated sleep staging of long-term scalp electroencephalography recordings using deep learning",
      "authors": [
        "M Jaoude",
        "H Sun",
        "K Pellerin",
        "M Pavlova",
        "R Sarkis"
      ],
      "venue": "Expert-level automated sleep staging of long-term scalp electroencephalography recordings using deep learning"
    },
    {
      "citation_id": "130",
      "title": "Deep convolutional neural network for classification of sleep stages from single-channel EEG signals",
      "authors": [
        "Z Mousavi",
        "T Rezaii",
        "S Sheykhivand",
        "A Farzamnia",
        "S Razavi"
      ],
      "year": "2019",
      "venue": "Journal of Neuroscience Methods"
    },
    {
      "citation_id": "131",
      "title": "Automatic Sleep Staging Employing Convolutional Neural Networks and Cortical Connectivity Images",
      "authors": [
        "P Chriskos",
        "C Frantzidis",
        "P Gkivogkli",
        "P Bamidis",
        "C Kourtidou-Papadeli"
      ],
      "year": "2020",
      "venue": "IEEE Transactions on Neural Networks and Learning Systems"
    },
    {
      "citation_id": "132",
      "title": "Adversarial Deep Learning in EEG Biometrics",
      "authors": [
        "O Ozdenizci",
        "Y Wang",
        "T Koike-Akino",
        "D Erdogmus"
      ],
      "year": "2019",
      "venue": "IEEE Signal Processing Letters"
    },
    {
      "citation_id": "133",
      "title": "Convolutional Neural Networks Using Dynamic Functional Connectivity for EEG-Based Person Identification in Diverse Human States",
      "authors": [
        "M Wang",
        "H El-Fiqi",
        "J Hu",
        "H Abbass"
      ],
      "year": "2019",
      "venue": "IEEE Transactions on Information Forensics and Security"
    },
    {
      "citation_id": "134",
      "title": "EEG-Based Age and Gender Prediction Using Deep BLSTM-LSTM Network Model",
      "authors": [
        "P Kaushik",
        "A Gupta",
        "P Roy",
        "D Dogra"
      ],
      "year": "2019",
      "venue": "IEEE Sensors Journal"
    },
    {
      "citation_id": "135",
      "title": "Connecting Deep Neural Networks to Physical, Perceptual, and Electrophysiological Auditory Signals",
      "authors": [
        "N Huang",
        "M Slaney",
        "M Elhilali"
      ],
      "year": "2018",
      "venue": "Frontiers in Neuroscience"
    },
    {
      "citation_id": "136",
      "title": "Diverse frequency band-based convolutional neural networks for tonic cold pain assessment using EEG",
      "authors": [
        "M Yu",
        "Y Sun",
        "B Zhu",
        "L Zhu",
        "Y Lin",
        "X Tang",
        "Y Guo",
        "G Sun",
        "M Dong"
      ],
      "year": "2020",
      "venue": "Neurocomputing"
    },
    {
      "citation_id": "137",
      "title": "A Context-Supported Deep Learning Framework for Multimodal Brain Imaging Classification",
      "authors": [
        "J Jiang",
        "A Fares",
        "S Zhong"
      ],
      "year": "2019",
      "venue": "IEEE Transactions on Human-Machine Systems"
    },
    {
      "citation_id": "138",
      "title": "Decoding human brain activity with deep learning",
      "authors": [
        "X Zheng",
        "W Chen",
        "M Li",
        "T Zhang",
        "Y You",
        "Y Jiang"
      ],
      "year": "2020",
      "venue": "Biomedical Signal Processing and Control"
    },
    {
      "citation_id": "139",
      "title": "A Novel Method of Building Functional Brain Network Using Deep Learning Algorithm with Application in Proficiency Detection",
      "authors": [
        "C Hua",
        "H Wang",
        "H Wang",
        "S Lu",
        "C Liu",
        "S Khalid"
      ],
      "year": "2019",
      "venue": "International Journal of Neural Systems"
    },
    {
      "citation_id": "140",
      "title": "Is it possible to detect cerebral dominance via EEG signals by using deep learning?",
      "authors": [
        "S Toraman",
        "S Tuncer",
        "F Balgetir"
      ],
      "year": "2019",
      "venue": "Medical Hypotheses"
    },
    {
      "citation_id": "141",
      "title": "Bullying incidences identification within an immersive environment using HD EEG-based analysis: A Swarm Decomposition and Deep Learning approach",
      "authors": [
        "V Baltatzis",
        "K Bintsi",
        "G Apostolidis",
        "L Hadjileontiadis"
      ],
      "year": "2017",
      "venue": "Scientific Reports"
    },
    {
      "citation_id": "142",
      "title": "Modelling Peri-Perceptual Brain Processes in a Deep Learning Spiking Neural Network Architecture",
      "authors": [
        "Z Doborjeh",
        "N Kasabov",
        "M Doborjeh",
        "A Sumich"
      ],
      "year": "2018",
      "venue": "Scientific Reports"
    },
    {
      "citation_id": "143",
      "title": "Comparison of logistic regression, support vector machines, and deep learning classifiers for predicting memory encoding success using human intracranial EEG recordings",
      "authors": [
        "A Arora",
        "J Lin",
        "A Gasperian",
        "J Maldjian",
        "J Stein",
        "M Kahana",
        "B Lega"
      ],
      "year": "2018",
      "venue": "Journal of Neural Engineering"
    },
    {
      "citation_id": "144",
      "title": "Discrimination of Mental Workload Levels From Multi-Channel fNIRS Using Deep Leaning-Based Approaches",
      "authors": [
        "T Ho",
        "J Gwak",
        "C Park",
        "J Song"
      ],
      "year": "2019",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "145",
      "title": "Performance improvement of driving fatigue identification based on power spectra and connectivity using feature level and decision level fusions",
      "authors": [
        "J Harvy",
        "E Sigalas",
        "N Thakor",
        "A Bezerianos",
        "J Li"
      ],
      "year": "2018",
      "venue": "2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)"
    },
    {
      "citation_id": "146",
      "title": "Eeg-based multiclass workload identification using feature fusion and selection",
      "authors": [
        "Z Pei",
        "H Wang",
        "A Bezerianos",
        "J Li"
      ],
      "year": "2020",
      "venue": "IEEE Transactions on Instrumentation and Measurement"
    },
    {
      "citation_id": "147",
      "title": "Multimodal vigilance estimation using deep learning",
      "authors": [
        "W Wu",
        "W Sun",
        "Q Wu",
        "Y Yang",
        "H Zhang",
        "W.-L Zheng",
        "B.-L Lu"
      ],
      "year": "2020",
      "venue": "IEEE Transactions on Cybernetics"
    },
    {
      "citation_id": "148",
      "title": "Cognitive state analysis, understanding, and decoding from the perspective of brain connectivity",
      "authors": [
        "J Li",
        "A Bezerianos",
        "N Thakor"
      ],
      "year": "2020",
      "venue": "Cognitive state analysis, understanding, and decoding from the perspective of brain connectivity",
      "arxiv": "arXiv:2005.12191"
    },
    {
      "citation_id": "149",
      "title": "Spatio-Spectral Representation Learning for Electroencephalographic Gait-Pattern Classification",
      "authors": [
        "S Goh",
        "H Abbass",
        "K Tan",
        "A Al-Mamun",
        "N Thakor",
        "A Bezerianos",
        "J Li"
      ],
      "year": "2018",
      "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering"
    },
    {
      "citation_id": "150",
      "title": "Thoughts on neurophysiological signal analysis and classification",
      "authors": [
        "J Li"
      ],
      "year": "2020",
      "venue": "Brain Science Advances"
    },
    {
      "citation_id": "151",
      "title": "Deep Channel-Correlation Network for Motor Imagery Decoding From the Same Limb",
      "authors": [
        "X Ma",
        "S Qiu",
        "W Wei",
        "S Wang",
        "H He"
      ],
      "year": "2020",
      "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering"
    },
    {
      "citation_id": "152",
      "title": "Separated channel convolutional neural network to realize the training free motor imagery BCI systems",
      "authors": [
        "X Zhu",
        "P Li",
        "C Li",
        "D Yao",
        "R Zhang",
        "P Xu"
      ],
      "year": "2019",
      "venue": "Biomedical Signal Processing and Control"
    },
    {
      "citation_id": "153",
      "title": "Deep learning for hybrid EEG-fNIRS brain-computer interface: application to motor imagery classification",
      "authors": [
        "A Chiarelli",
        "P Croce",
        "A Merla",
        "F Zappasodi"
      ],
      "year": "2018",
      "venue": "Journal of Neural Engineering"
    },
    {
      "citation_id": "154",
      "title": "Validating Deep Neural Networks for Online Decoding of Motor Imagery Movements from EEG Signals",
      "authors": [
        "Z Tayeb",
        "J Fedjaev",
        "N Ghaboosi",
        "C Richter",
        "L Everding",
        "X Qu",
        "Y Wu",
        "G Cheng",
        "J Conradt"
      ],
      "year": "2019",
      "venue": "Sensors"
    },
    {
      "citation_id": "155",
      "title": "EEG Classification of Motor Imagery Using a Novel Deep Learning Framework",
      "authors": [
        "M Dai",
        "D Zheng",
        "R Na",
        "S Wang",
        "S Zhang"
      ],
      "year": "2019",
      "venue": "Sensors"
    },
    {
      "citation_id": "156",
      "title": "Motor Imagery EEG Classification Using Capsule Networks",
      "authors": [
        "K Ha",
        "J Jeong"
      ],
      "year": "2019",
      "venue": "Sensors"
    },
    {
      "citation_id": "157",
      "title": "Feature recognition of motor imaging EEG signals based on deep learning",
      "authors": [
        "T Shi",
        "L Ren",
        "W Cui"
      ],
      "year": "2019",
      "venue": "Personal and Ubiquitous Computing"
    },
    {
      "citation_id": "158",
      "title": "Short time Fourier transformation and deep neural networks for motor imagery brain computer interface recognition",
      "authors": [
        "Z Wang",
        "L Cao",
        "Z Zhang",
        "X Gong",
        "Y Sun",
        "H Wang"
      ],
      "year": "2018",
      "venue": "Concurrency and Computation-Practice & Experience"
    },
    {
      "citation_id": "159",
      "title": "Multilevel Weighted Feature Fusion Using Convolutional Neural Networks for EEG Motor Imagery Classification",
      "authors": [
        "S Amin",
        "M Alsulaiman",
        "G Muhammad",
        "M Bencherif",
        "M Hossain"
      ],
      "year": "2019",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "160",
      "title": "Deep learning with convolutional neural networks for eeg decoding and visualization",
      "authors": [
        "R Schirrmeister",
        "J Springenberg",
        "L Fiederer",
        "M Glasstetter",
        "K Eggensperger",
        "M Tangermann",
        "F Hutter",
        "W Burgard",
        "T Ball"
      ],
      "year": "2017",
      "venue": "Human brain mapping"
    },
    {
      "citation_id": "161",
      "title": "A novel end-to-end deep learning scheme for classifying multi-class motor imagery electroencephalography signals",
      "authors": [
        "A Hassanpour",
        "M Moradikia",
        "H Adeli",
        "S Khayami",
        "P Shamsinejadbabaki"
      ],
      "venue": "A novel end-to-end deep learning scheme for classifying multi-class motor imagery electroencephalography signals"
    },
    {
      "citation_id": "162",
      "title": "A hierarchical semi-supervised extreme learning machine method for EEG recognition",
      "authors": [
        "Q She",
        "B Hu",
        "Z Luo",
        "T Nguyen",
        "Y Zhang"
      ],
      "year": "2019",
      "venue": "Medical & Biological Engineering & Computing"
    },
    {
      "citation_id": "163",
      "title": "A correntropy-based classifier for motor imagery brain-computer interfaces",
      "authors": [
        "L Uribe",
        "C Stefano",
        "V De Oliveira",
        "T Costa",
        "P Rodrigues",
        "D Soriano",
        "L Boccato",
        "G Castellano",
        "R Attux"
      ],
      "year": "2019",
      "venue": "Biomedical Physics & Engineering Express"
    },
    {
      "citation_id": "164",
      "title": "Motor Imagery EEG Classification Based on Kernel Hierarchical Extreme Learning Machine",
      "authors": [
        "L Duan",
        "M Bao",
        "S Cui",
        "Y Qiao",
        "J Miao"
      ],
      "year": "2017",
      "venue": "Cognitive Computation"
    },
    {
      "citation_id": "165",
      "title": "A Parallel Multiscale Filter Bank Convolutional Neural Networks for Motor Imagery EEG Classification",
      "authors": [
        "H Wu",
        "Y Niu",
        "F Li",
        "Y Li",
        "B Fu",
        "G Shi",
        "M Dong"
      ],
      "year": "2019",
      "venue": "Frontiers in Neuroscience"
    },
    {
      "citation_id": "166",
      "title": "Efficient Classification of Motor Imagery Electroencephalography Signals Using Deep Learning Methods",
      "authors": [
        "I Majidov",
        "T Whangbo"
      ],
      "year": "2019",
      "venue": "Sensors"
    },
    {
      "citation_id": "167",
      "title": "Semisupervised Deep Stacking Network with Adaptive Learning Rate Strategy for Motor Imagery EEG Recognition",
      "authors": [
        "X Tang",
        "W Ma",
        "D Kong",
        "W Li"
      ],
      "year": "2019",
      "venue": "Neural Computation"
    },
    {
      "citation_id": "168",
      "title": "Wavelet Transform Time-Frequency Image and Convolutional Network-Based Motor Imagery EEG Classification",
      "authors": [
        "B Xu",
        "L Zhang",
        "A Song",
        "C Wu",
        "W Li",
        "D Zhang",
        "G Xu",
        "H Li",
        "H Zeng"
      ],
      "year": "2019",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "169",
      "title": "Subject-Independent Brain-Computer Interfaces Based on Deep Convolutional Neural Networks",
      "authors": [
        "O.-Y Kwon",
        "M.-H Lee",
        "C Guan",
        "S.-W Lee"
      ],
      "year": "2020",
      "venue": "IEEE Transactions on Neural Networks and Learning Systems"
    },
    {
      "citation_id": "170",
      "title": "A deep CNN approach to decode motor preparation of upper limbs from time-frequency maps of EEG signals at source level",
      "authors": [
        "N Mammone",
        "C Ieracitano",
        "F Morabito"
      ],
      "year": "2020",
      "venue": "Neural Networks"
    },
    {
      "citation_id": "171",
      "title": "Motor Imagery Classification via Temporal Attention Cues of Graph Embedded EEG Signals",
      "authors": [
        "D Zhang",
        "K Chen",
        "D Jian",
        "L Yao"
      ],
      "year": "2020",
      "venue": "IEEE Journal of Biomedical and Health Informatics"
    },
    {
      "citation_id": "172",
      "title": "Deep Temporal-Spatial Feature Learning for Motor Imagery-Based Brain-Computer Interfaces",
      "authors": [
        "J Chen",
        "Z Yu",
        "Z Gu",
        "Y Li"
      ],
      "year": "2020",
      "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering"
    },
    {
      "citation_id": "173",
      "title": "Brain-Controlled Robotic Arm System Based on Multi-Directional CNN-BiLSTM Network Using EEG Signals",
      "authors": [
        "J.-H Jeong",
        "K.-H Shim",
        "D.-J Kim",
        "S.-W Lee"
      ],
      "year": "2020",
      "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering"
    },
    {
      "citation_id": "174",
      "title": "Multi-ganglion ANN based feature learning with application to P300-BCI signal classification",
      "authors": [
        "W Gao",
        "J Guan",
        "J Gao",
        "D Zhou"
      ],
      "year": "2015",
      "venue": "Biomedical Signal Processing and Control"
    },
    {
      "citation_id": "175",
      "title": "Convolutional neural networks for decoding of covert attention focus and saliency maps for EEG feature visualization",
      "authors": [
        "A Farahat",
        "C Reichert",
        "C Sweeney-Reed",
        "H Hinrichs"
      ],
      "year": "2019",
      "venue": "Journal of Neural Engineering"
    },
    {
      "citation_id": "176",
      "title": "Decoding P300 Variability Using Convolutional Neural Networks",
      "authors": [
        "A Solon",
        "V Lawhern",
        "J Touryan",
        "J Mcdaniel",
        "A Ries",
        "S Gordon"
      ],
      "year": "2019",
      "venue": "Frontiers in Human Neuroscience"
    },
    {
      "citation_id": "177",
      "title": "Stacked Autoencoders for the P300 Component Detection",
      "authors": [
        "L Vareka",
        "P Mautner"
      ],
      "year": "2017",
      "venue": "Frontiers in Neuroscience"
    },
    {
      "citation_id": "178",
      "title": "A new method for P300 detection in deep belief networks: Nesterov momentum and drop based learning rate",
      "authors": [
        "S Morabbi",
        "M Keyvanpour",
        "S Shojaedini"
      ],
      "year": "2019",
      "venue": "Health and Technology"
    },
    {
      "citation_id": "179",
      "title": "Universal Joint Feature Extraction for P300 EEG Classification Using Multi-Task Autoencoder",
      "authors": [
        "A Ditthapron",
        "N Banluesombatkul",
        "S Ketrat",
        "E Chuangsuwanich",
        "T Wilaiprasitporn"
      ],
      "year": "2019",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "180",
      "title": "Documenting, modelling and exploiting p300 amplitude changes due to variable target delays in donchin's speller",
      "authors": [
        "L Citi",
        "R Poli",
        "C Cinel"
      ],
      "year": "2010",
      "venue": "Journal of Neural Engineering"
    },
    {
      "citation_id": "181",
      "title": "A new auditory multi-class brain-computer interface paradigm: spatial hearing as an informative cue",
      "authors": [
        "M Schreuder",
        "B Blankertz",
        "M Tangermann"
      ],
      "year": "2010",
      "venue": "PloS one"
    },
    {
      "citation_id": "182",
      "title": "Gaze-independent bci-spelling using rapid serial visual presentation (rsvp)",
      "authors": [
        "L Acqualagna",
        "B Blankertz"
      ],
      "year": "2013",
      "venue": "Clinical Neurophysiology"
    },
    {
      "citation_id": "183",
      "title": "Decoding auditory attention to instruments in polyphonic music using single-trial eeg classification",
      "authors": [
        "M Treder",
        "H Purwins",
        "D Miklody",
        "I Sturm",
        "B Blankertz"
      ],
      "year": "2014",
      "venue": "Journal of neural engineering"
    },
    {
      "citation_id": "184",
      "title": "Recognition of words from braingenerated signals of speech-impaired people: Application of autoencoders as a neural Turing machine controller in deep neural networks",
      "authors": [
        "B Boloukian",
        "F Safi-Esfahani"
      ],
      "year": "2020",
      "venue": "Neural Networks"
    },
    {
      "citation_id": "185",
      "title": "An efficient p300-based brain-computer interface for disabled subjects",
      "authors": [
        "U Hoffmann",
        "J.-M Vesin",
        "T Ebrahimi",
        "K Diserens"
      ],
      "year": "2008",
      "venue": "Journal of Neuroscience methods"
    },
    {
      "citation_id": "186",
      "title": "Feature Selection of Deep Learning Models for EEG-Based RSVP Target Detection",
      "authors": [
        "J Chen",
        "Z Mao",
        "R Zheng",
        "Y Huang",
        "L He"
      ],
      "year": "2019",
      "venue": "Ieice Transactions on Information and Systems"
    },
    {
      "citation_id": "187",
      "title": "Translation of eeg-based performance prediction models to rapid serial visual presentation tasks",
      "authors": [
        "J Touryan",
        "G Apker",
        "S Kerick",
        "B Lance",
        "A Ries",
        "K Mc-Dowell"
      ],
      "year": "2013",
      "venue": "International Conference on Augmented Cognition"
    },
    {
      "citation_id": "188",
      "title": "Convolutional Neural Network for Multi-Category Rapid Serial Visual Presentation BCI",
      "authors": [
        "R Manor",
        "A Geva"
      ],
      "year": "2015",
      "venue": "Frontiers in Computational Neuroscience"
    },
    {
      "citation_id": "189",
      "title": "Multimodal Neural Network for Rapid Serial Visual Presentation Brain Computer Interface",
      "authors": [
        "R Manor",
        "L Mishali",
        "A Geva"
      ],
      "year": "2016",
      "venue": "Frontiers in Computational Neuroscience"
    },
    {
      "citation_id": "190",
      "title": "Efficient representations of EEG signals for SSVEP frequency recognition based on deep multiset CCA",
      "authors": [
        "Q Liu",
        "Y Jiao",
        "Y Miao",
        "C Zuo",
        "X Wang",
        "A Cichocki",
        "J Jin"
      ],
      "year": "2020",
      "venue": "Neurocomputing"
    },
    {
      "citation_id": "191",
      "title": "A comparison study of canonical correlation analysis based methods for detecting steady-state visual evoked potentials",
      "authors": [
        "M Nakanishi",
        "Y Wang",
        "Y.-T Wang",
        "T.-P Jung"
      ],
      "year": "2015",
      "venue": "PloS one"
    },
    {
      "citation_id": "192",
      "title": "Early Alzheimer's disease diagnosis based on EEG spectral images using deep learning",
      "authors": [
        "X Bi",
        "H Wang"
      ],
      "year": "2019",
      "venue": "Neural Networks"
    },
    {
      "citation_id": "193",
      "title": "Deep Learning Representation from Electroencephalography of Early-Stage Creutzfeldt-Jakob Disease and Features for Differentiation from Rapidly Progressive Dementia",
      "authors": [
        "F Morabito",
        "M Campolo",
        "N Mammone",
        "M Versaci",
        "S Franceschetti",
        "F Tagliavini",
        "V Sofia",
        "D Fatuzzo",
        "A Gambardella",
        "A Labate",
        "L Mumoli",
        "G Tripodi",
        "S Gasparini",
        "V Cianci",
        "C Sueri",
        "E Ferlazzo",
        "U Aguglia"
      ],
      "year": "2017",
      "venue": "Deep Learning Representation from Electroencephalography of Early-Stage Creutzfeldt-Jakob Disease and Features for Differentiation from Rapidly Progressive Dementia"
    },
    {
      "citation_id": "194",
      "title": "Hierarchical Poincare analysis for anaesthesia monitoring",
      "authors": [
        "K Hayase",
        "K Hayashi",
        "T Sawa"
      ],
      "venue": "Journal of Clinical Monitoring and Computing"
    },
    {
      "citation_id": "195",
      "title": "Spectrum Analysis of EEG Signals Using CNN to Model Patient's Consciousness Level Based on Anesthesiologists' Experience",
      "authors": [
        "Q Liu",
        "J Cai",
        "S Fan",
        "M Abbod",
        "J Shieh",
        "Y Kung",
        "L Lin"
      ],
      "year": "2019",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "196",
      "title": "A Real-Time Depth of Anesthesia Monitoring System Based on Deep Neural Network With Large EDO Tolerant EEG Analog Front-End",
      "authors": [
        "Y Park",
        "S.-H Han",
        "W Byun",
        "J.-H Kim",
        "H.-C Lee",
        "S.-J Kim"
      ],
      "year": "2020",
      "venue": "IEEE Transactions on Biomedical Circuits and Systems"
    },
    {
      "citation_id": "197",
      "title": "Wave2Vec: Vectorizing Electroencephalography Bio-Signal for Prediction of Brain Disease",
      "authors": [
        "S Kim",
        "J Kim",
        "H Chun"
      ],
      "year": "2018",
      "venue": "International Journal of Environmental Research and Public Health"
    },
    {
      "citation_id": "198",
      "title": "Use of deep learning to detect personalized spatial-frequency abnormalities in EEGs of children with ADHD",
      "authors": [
        "H Chen",
        "Y Song",
        "X Li"
      ],
      "year": "2019",
      "venue": "Journal of Neural Engineering"
    },
    {
      "citation_id": "199",
      "title": "Neurophysiological Correlates of Concussion: Deep Learning for Clinical Assessment",
      "authors": [
        "R Boshra",
        "K Ruiter",
        "C Dematteo",
        "J Reilly",
        "J Connolly"
      ],
      "year": "2019",
      "venue": "Neurophysiological Correlates of Concussion: Deep Learning for Clinical Assessment"
    },
    {
      "citation_id": "200",
      "title": "Automated tracking of level of consciousness and delirium in critical illness using deep learning",
      "authors": [
        "H Sun",
        "E Kimchi",
        "O Akeju",
        "S Nagaraj",
        "L Mcclain",
        "D Zhou",
        "E Boyle",
        "W Zheng",
        "W Ge",
        "M Westover"
      ],
      "year": "2019",
      "venue": "Npj Digital Medicine"
    },
    {
      "citation_id": "201",
      "title": "Automated Depression Detection Using Deep Representation and Sequence Learning with EEG Signals",
      "authors": [
        "B Ay",
        "O Yildirim",
        "M Talo",
        "U Baloglu",
        "G Aydin",
        "S Puthankattil",
        "U Acharya"
      ],
      "year": "2019",
      "venue": "Journal of Medical Systems"
    },
    {
      "citation_id": "202",
      "title": "Automated eeg-based screening of depression using deep convolutional neural network",
      "authors": [
        "U Acharya",
        "S Oh",
        "Y Hagiwara",
        "J Tan",
        "H Adeli",
        "D Subha"
      ],
      "year": "2018",
      "venue": "Computer methods and programs in biomedicine"
    },
    {
      "citation_id": "203",
      "title": "Automated EEG-based screening of depression using deep convolutional neural network",
      "authors": [
        "U Acharya",
        "S Oh",
        "Y Hagiwara",
        "J Tan",
        "H Adeli",
        "D Subha"
      ],
      "year": "2018",
      "venue": "Computer Methods and Programs in Biomedicine"
    },
    {
      "citation_id": "204",
      "title": "Depression recognition using machine learning methods with different feature generation strategies",
      "authors": [
        "X Li",
        "X Zhang",
        "J Zhu",
        "W Mao",
        "S Sun",
        "Z Wang",
        "C Xia",
        "B Hu"
      ],
      "year": "2019",
      "venue": "Artificial Intelligence in Medicine"
    },
    {
      "citation_id": "205",
      "title": "Multimodal Mild Depression Recognition Based on EEG-EM Synchronization Acauisition Network",
      "authors": [
        "J Zhu",
        "Y Wang",
        "R La",
        "J Zhan",
        "J Niu",
        "S Zeng",
        "X Hu"
      ],
      "year": "2019",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "206",
      "title": "A Dynamic Filtering DF-RNN Deep-Learning-Based Approach for EEG-Based Neurological Disorders Diagnosis",
      "authors": [
        "G Bouallegue",
        "R Djemal",
        "S Alshebeili",
        "H Aldhalaan"
      ],
      "year": "2020",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "207",
      "title": "Indications of nonlinear deterministic and finitedimensional structures in time series of brain electrical activity: Dependence on recording region and brain state",
      "authors": [
        "R Andrzejak",
        "K Lehnertz",
        "F Mormann",
        "C Rieke",
        "P David",
        "C Elger"
      ],
      "year": "2001",
      "venue": "Physical Review E"
    },
    {
      "citation_id": "208",
      "title": "Nonrandomness, nonlinear dependence, and nonstationarity of electroencephalographic recordings from epilepsy patients",
      "authors": [
        "R Andrzejak",
        "K Schindler",
        "C Rummel"
      ],
      "year": "2012",
      "venue": "Physical Review E"
    },
    {
      "citation_id": "209",
      "title": "A new framework using deep auto-encoder and energy spectral density for medical waveform data classification and processing",
      "authors": [
        "A Karim",
        "M Guzel",
        "M Tolun",
        "H Kaya",
        "F Celebi"
      ],
      "year": "2019",
      "venue": "Biocybernetics and Biomedical Engineering"
    },
    {
      "citation_id": "210",
      "title": "Epileptic seizure detection and prediction using stacked bidirectional long short term memory",
      "authors": [
        "D Thara",
        "B Premasudha",
        "F Xiong"
      ],
      "year": "2019",
      "venue": "Pattern Recognition Letters"
    },
    {
      "citation_id": "211",
      "title": "Neuro-Detect: A Machine Learning-Based Fast and Accurate Seizure Detection System in the IoMT",
      "authors": [
        "M Sayeed",
        "S Mohanty",
        "E Kougianos",
        "H Zaveri"
      ],
      "year": "2019",
      "venue": "IEEE Transactions on Consumer Electronics"
    },
    {
      "citation_id": "212",
      "title": "Microseizures and the spatiotemporal scales of human partial epilepsy",
      "authors": [
        "M Stead",
        "M Bower",
        "B Brinkmann",
        "K Lee",
        "W Marsh",
        "F Meyer",
        "B Litt",
        "J Van Gompel",
        "G Worrell"
      ],
      "year": "2010",
      "venue": "Brain"
    },
    {
      "citation_id": "213",
      "title": "Large-scale electrophysiology: acquisition, compression, encryption, and storage of big data",
      "authors": [
        "B Brinkmann",
        "M Bower",
        "K Stengel",
        "G Worrell",
        "M Stead"
      ],
      "year": "2009",
      "venue": "Journal of neuroscience methods"
    },
    {
      "citation_id": "214",
      "title": "Optimized deep neural network architecture for robust detection of epileptic seizures using EEG signals",
      "authors": [
        "R Hussein",
        "H Palangi",
        "R Ward",
        "Z Wang"
      ],
      "year": "2019",
      "venue": "Clinical Neurophysiology"
    },
    {
      "citation_id": "215",
      "title": "Semi-Supervised EEG Signals Classification System for Epileptic Seizure Detection",
      "authors": [
        "A Abdelhameed",
        "M Bayoumi"
      ],
      "year": "2019",
      "venue": "IEEE Signal Processing Letters"
    },
    {
      "citation_id": "216",
      "title": "Wavelet based deep learning approach for epilepsy detection",
      "authors": [
        "R Akut"
      ],
      "year": "2019",
      "venue": "Health Information Science and Systems"
    },
    {
      "citation_id": "217",
      "title": "Seizure detection by convolutional neural network-based analysis of scalp electroencephalography plot images",
      "authors": [
        "A Emami",
        "N Kunii",
        "T Matsuo",
        "T Shinozaki",
        "K Kawai",
        "H Takahashi"
      ],
      "year": "2019",
      "venue": "Neuroimage-Clinical"
    },
    {
      "citation_id": "218",
      "title": "Convolutional Long-Short Term Memory Networks Model For Long Duration EEG Signal Classification",
      "authors": [
        "U Baloglu",
        "O Yildirim"
      ],
      "year": "2019",
      "venue": "Journal of Mechanics in Medicine and Biology"
    },
    {
      "citation_id": "219",
      "title": "Neonatal seizure detection from raw multi-channel EEG using a fully convolutional architecture",
      "authors": [
        "A O'shea",
        "G Lightbody",
        "G Boylan",
        "A Temko"
      ],
      "year": "2020",
      "venue": "Neural Networks"
    },
    {
      "citation_id": "220",
      "title": "Feature relevance in physiological networks for classification o obstructive sleep apnea",
      "authors": [
        "C Jansen",
        "S Hodel",
        "T Penzel",
        "M Spott",
        "D Krefting"
      ],
      "year": "2018",
      "venue": "Physiological Measurement"
    },
    {
      "citation_id": "221",
      "title": "The siesta project polygraphic and clinical database",
      "authors": [
        "G Klosh",
        "B Kemp",
        "T Penzel",
        "A Schlogl",
        "P Rappelsberger",
        "E Trenker",
        "G Gruber",
        "J Zeithofer",
        "B Saletu",
        "W Herrmann"
      ],
      "year": "2001",
      "venue": "IEEE Engineering in Medicine and Biology Magazine"
    },
    {
      "citation_id": "222",
      "title": "EEG-based outcome prediction after cardiac arrest with convolutional neural networks: Performance and visualization of discriminative features",
      "authors": [
        "S Jonas",
        "A Rossetti",
        "M Oddo",
        "S Jenni",
        "P Favaro",
        "F Zubler"
      ],
      "year": "2019",
      "venue": "Human Brain Mapping"
    },
    {
      "citation_id": "223",
      "title": "Outcome Prediction in Postanoxic Coma With Deep Learning*",
      "authors": [
        "M Tjepkema-Cloostermans",
        "C Lourenco",
        "B Ruijter",
        "S Tromp",
        "G Drost",
        "F Kornips",
        "A Beishuizen",
        "F Bosch",
        "J Hofmeijer",
        "M Van Putten"
      ],
      "year": "2019",
      "venue": "Critical Care Medicine"
    },
    {
      "citation_id": "224",
      "title": "Cognitive Smart Healthcare for Pathology Detection and Monitoring",
      "authors": [
        "S Amin",
        "M Hossain",
        "G Muhammad",
        "M Alhussein",
        "M Rahman"
      ],
      "year": "2019",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "225",
      "title": "Deep Learning With EEG Spectrograms in Rapid Eye Movement Behavior Disorder",
      "authors": [
        "G Ruffini",
        "D Ibanez",
        "M Castellano",
        "L Dubreuil-Vall",
        "A Soria-Frisch",
        "R Postuma",
        "J Gagnon",
        "J Montplaisir"
      ],
      "year": "2019",
      "venue": "Frontiers in Neurology"
    },
    {
      "citation_id": "226",
      "title": "Binary classification of multichannel-eeg records based on the e-complexity of continuous vector functions",
      "authors": [
        "A Piryatinska",
        "B Darkhovsky",
        "A Kaplan"
      ],
      "year": "2017",
      "venue": "Computer methods and programs in biomedicine"
    },
    {
      "citation_id": "227",
      "title": "A Multi-Domain Connectome Convolutional Neural Network for Identifying Schizophrenia From EEG Connectivity Patterns",
      "authors": [
        "C.-R Phang",
        "F Noman",
        "H Hussain",
        "C.-M Ting",
        "H Ombao"
      ],
      "year": "2020",
      "venue": "IEEE Journal of Biomedical and Health Informatics"
    },
    {
      "citation_id": "228",
      "title": "Recognition of emotions using multimodal physiological signals and an ensemble deep learning model",
      "authors": [
        "Z Yin",
        "M Zhao",
        "Y Wang",
        "J Yang",
        "J Zhang"
      ],
      "year": "2017",
      "venue": "Computer Methods and Programs in Biomedicine"
    },
    {
      "citation_id": "229",
      "title": "Emotion recognition using empirical mode decomposition and approximation entropy",
      "authors": [
        "T Chen",
        "S Ju",
        "X Yuan",
        "M Elhoseny",
        "F Ren",
        "M Fan",
        "Z Chen"
      ],
      "year": "2018",
      "venue": "Computers & Electrical Engineering"
    },
    {
      "citation_id": "230",
      "title": "An analysis of smartphone overuse recognition in terms of emotions using brainwaves and deep learning",
      "authors": [
        "S Kim",
        "H Kang"
      ],
      "year": "2018",
      "venue": "Neurocomputing"
    },
    {
      "citation_id": "231",
      "title": "Classification of Affective States via EEG and Deep Learning",
      "authors": [
        "J Teo",
        "L Chew",
        "J Chia",
        "J Mountstephens"
      ],
      "year": "2018",
      "venue": "International Journal of Advanced Computer Science and Applications"
    },
    {
      "citation_id": "232",
      "title": "A Hierarchical Bidirectional GRU Model With Attention for EEG-Based Emotion Classification",
      "authors": [
        "J Chen",
        "D Jiang",
        "N Zhang"
      ],
      "year": "2019",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "233",
      "title": "Fear Level Classification Based on Emotional Dimensions and Machine Learning Techniques",
      "authors": [
        "O Balan",
        "G Moise",
        "A Moldoveanu",
        "M Leordeanu",
        "F Moldoveanu"
      ],
      "year": "2019",
      "venue": "Sensors"
    },
    {
      "citation_id": "234",
      "title": "Investigating the Use of Pretrained Convolutional Neural Network on Cross-Subject and Cross-Dataset EEG Emotion Recognition",
      "authors": [
        "Y Cimtay",
        "E Ekmekcioglu"
      ],
      "year": "2020",
      "venue": "Sensors"
    },
    {
      "citation_id": "235",
      "title": "EEG-Based Emotion Classification Using Long Short-Term Memory Network with Attention Mechanism",
      "authors": [
        "Y Kim",
        "A Choi"
      ],
      "year": "2020",
      "venue": "Sensors"
    },
    {
      "citation_id": "236",
      "title": "Deep Physiological Affect Network for the Recognition of Human Emotions",
      "authors": [
        "B Kim",
        "S Jo"
      ],
      "year": "2018",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "237",
      "title": "Classification of Drowsiness Levels Based on a Deep Spatio-Temporal Convolutional Bidirectional LSTM Network Using Electroencephalography Signals",
      "authors": [
        "J Jeong",
        "B Yu",
        "D Lee",
        "S Lee"
      ],
      "year": "2019",
      "venue": "Brain Sciences"
    },
    {
      "citation_id": "238",
      "title": "Cross-session classification of mental workload levels using EEG and an adaptive deep learning model",
      "authors": [
        "Z Yin",
        "J Zhang"
      ],
      "year": "2017",
      "venue": "Biomedical Signal Processing and Control"
    },
    {
      "citation_id": "239",
      "title": "Deep Convolutional Neural Networks for mental load classification based on EEG data",
      "authors": [
        "Z Jiao",
        "X Gao",
        "Y Wang",
        "J Li",
        "H Xu"
      ],
      "year": "2018",
      "venue": "Pattern Recognition"
    },
    {
      "citation_id": "240",
      "title": "Assessing cognitive mental workload via EEG signals and an ensemble deep learning classifier based on denoising autoencoders",
      "authors": [
        "S Yang",
        "Z Yin",
        "Y Wang",
        "W Zhang",
        "Y Wang",
        "J Zhang"
      ],
      "year": "2019",
      "venue": "Computers in Biology and Medicine"
    },
    {
      "citation_id": "241",
      "title": "A Deep Learning Model for Automated Sleep Stages Classification Using PSG Signals",
      "authors": [
        "O Yildirim",
        "U Baloglu",
        "U Acharya"
      ],
      "year": "2019",
      "venue": "International Journal of Environmental Research and Public Health"
    },
    {
      "citation_id": "242",
      "title": "An end-to-end framework for real-time automatic sleep stage classification",
      "authors": [
        "A Patanaik",
        "J Ong",
        "J Gooley",
        "S Ancoli-Israel",
        "M Chee"
      ],
      "year": "2018",
      "venue": "Sleep"
    },
    {
      "citation_id": "243",
      "title": "A hybrid self-attention deep learning framework for multivariate sleep stage classification",
      "authors": [
        "Y Yuan",
        "K Jia",
        "F Ma",
        "G Xun",
        "Y Wang",
        "L Su",
        "A Zhang"
      ],
      "year": "2019",
      "venue": "Bmc Bioinformatics"
    },
    {
      "citation_id": "244",
      "title": "Automated sleep stage scoring of the Sleep Heart Health Study using deep neural networks",
      "authors": [
        "L Zhang",
        "D Fabbri",
        "R Upender",
        "D Kent"
      ],
      "year": "2019",
      "venue": "Sleep"
    },
    {
      "citation_id": "245",
      "title": "Automated sleep-wake staging combining robust feature extraction, artificial neural network classification, and flexible decision rules",
      "authors": [
        "F Chapotot",
        "G Becq"
      ],
      "year": "2010",
      "venue": "International Journal of Adaptive Control and Signal Processing"
    },
    {
      "citation_id": "246",
      "title": "Automatic Human Sleep Stage Scoring Using Deep Neural Networks",
      "authors": [
        "A Malafeev",
        "D Laptev",
        "S Bauer",
        "X Omlin",
        "A Wierzbicka",
        "A Wichniak",
        "W Jernajczyk",
        "R Riener",
        "J Buhmann",
        "P Achermann"
      ],
      "year": "2018",
      "venue": "Frontiers in Neuroscience"
    },
    {
      "citation_id": "247",
      "title": "Joint Classification and Prediction CNN Framework for Automatic Sleep Stage Classification",
      "authors": [
        "H Phan",
        "F Andreotti",
        "N Cooray",
        "O Chen",
        "M Vos"
      ],
      "year": "2019",
      "venue": "IEEE Transactions on Biomedical Engineering"
    },
    {
      "citation_id": "248",
      "title": "A Deep Learning Architecture for Temporal Sleep Stage Classification Using Multivariate and Multimodal Time Series",
      "authors": [
        "S Chambon",
        "M Galtier",
        "P Arnal",
        "G Wainrib",
        "A Gramfort"
      ],
      "year": "2018",
      "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering"
    },
    {
      "citation_id": "249",
      "title": "A Multisite Randomized Trial of Portable Sleep Studies and Positive Airway Pressure Autotitration Versus Laboratory-Based Polysomnography for the Diagnosis and Treatment of Obstructive Sleep Apnea: The HomePAP Study",
      "authors": [
        "C Rosen",
        "D Auckley",
        "R Benca",
        "N Foldvary-Schaefer",
        "C Iber",
        "V Kapur",
        "M Rueschman",
        "P Zee",
        "S Redline"
      ],
      "year": "2012",
      "venue": "Sleep",
      "doi": "10.5665/sleep.1870"
    },
    {
      "citation_id": "250",
      "title": "Gastric Banding Surgery versus Continuous Positive Airway Pressure for Obstructive Sleep Apnea: A Randomized Controlled Trial",
      "authors": [
        "J Bakker",
        "A Tavakkoli",
        "M Rueschman",
        "W Wang",
        "R Andrews",
        "A Malhotra",
        "R Owens",
        "A Anand",
        "K Dudley",
        "S Patel"
      ],
      "year": "2018",
      "venue": "American Journal of Respiratory and Critical Care Medicine",
      "doi": "10.1164/rccm.201708-1637LE"
    },
    {
      "citation_id": "251",
      "title": "Expert-level sleep scoring with deep neural networks",
      "authors": [
        "S Biswal",
        "H Sun",
        "B Goparaju",
        "M Westover",
        "J Sun",
        "M Bianchi"
      ],
      "year": "2018",
      "venue": "Journal of the American Medical Informatics Association"
    },
    {
      "citation_id": "252",
      "title": "A convolutional neural network for sleep stage scoring from raw single-channel EEG",
      "authors": [
        "A Sors",
        "S Bonnet",
        "S Mirek",
        "L Vercueil",
        "J Payen"
      ],
      "year": "2018",
      "venue": "Biomedical Signal Processing and Control"
    },
    {
      "citation_id": "253",
      "title": "Overview of recruitment for the osteoporotic fractures in men study (mros)",
      "authors": [
        "J Blank",
        "P Cawthon",
        "M Carrion-Petersen",
        "L Harper",
        "J Johnson",
        "E Mitson",
        "R Delay"
      ],
      "year": "2005",
      "venue": "Contemporary clinical trials"
    },
    {
      "citation_id": "254",
      "title": "The childhood adenotonsillectomy trial (chat): rationale, design, and challenges of a randomized controlled trial evaluating a standard surgical procedure in a pediatric population",
      "authors": [
        "S Redline",
        "R Amin",
        "D Beebe",
        "R Chervin",
        "S Garetz",
        "B Giordani",
        "C Marcus",
        "R Moore",
        "C Rosen",
        "R Arens"
      ],
      "year": "2011",
      "venue": "Sleep"
    },
    {
      "citation_id": "255",
      "title": "ROM-based Inference Method Built on Deep Learning for Sleep Stage Classification",
      "authors": [
        "M Almeer",
        "H Hassen",
        "N Nawaz"
      ],
      "year": "2019",
      "venue": "Tem Journal-Technology Education Management Informatics"
    },
    {
      "citation_id": "256",
      "title": "A Residual Based Attention Model for EEG Based Sleep Staging",
      "authors": [
        "W Qu",
        "Z Wang",
        "H Hong",
        "Z Chi",
        "D Feng",
        "R Grunstein",
        "C Gordon"
      ],
      "year": "2020",
      "venue": "IEEE Journal of Biomedical and Health Informatics"
    },
    {
      "citation_id": "257",
      "title": "DOSED: A deep learning approach to detect multiple sleep microevents in EEG signal",
      "authors": [
        "S Charnbon",
        "V Thorey",
        "P Arnal",
        "E Mignot",
        "A Gramfort"
      ],
      "year": "2019",
      "venue": "Journal of Neuroscience Methods"
    },
    {
      "citation_id": "258",
      "title": "Nocturnal rapid eye movement sleep latency for identifying patients with narcolepsy/hypocretin deficiency",
      "authors": [
        "O Andlauer",
        "H Moore",
        "L Jouhier",
        "C Drake",
        "P Peppard",
        "F Han",
        "S.-C Hong",
        "F Poli",
        "G Plazzi",
        "R O'hara"
      ],
      "year": "2013",
      "venue": "JAMA neurology"
    },
    {
      "citation_id": "259",
      "title": "Sleep disordered breathing and mortality: eighteen-year follow-up of the wisconsin sleep cohort",
      "authors": [
        "T Young",
        "L Finn",
        "P Peppard",
        "M Szklo-Coxe",
        "D Austin",
        "F Nieto",
        "R Stubbs",
        "K Hla"
      ],
      "year": "2008",
      "venue": "Sleep"
    },
    {
      "citation_id": "260",
      "title": "Age and gender classification using brain-computer interface",
      "authors": [
        "B Kaur",
        "D Singh",
        "P Roy"
      ],
      "year": "2019",
      "venue": "Neural Computing and Applications"
    },
    {
      "citation_id": "261",
      "title": "Modeling electroencephalography waveforms with semi-supervised deep belief nets: fast classification and anomaly measurement",
      "authors": [
        "D Wulsin",
        "J Gupta",
        "R Mani",
        "J Blanco",
        "B Litt"
      ],
      "year": "2011",
      "venue": "Journal of Neural Engineering"
    },
    {
      "citation_id": "262",
      "title": "Cat Swarm Fractional Calculus optimization-based deep learning for artifact removal from EEG signal",
      "authors": [
        "J Anem",
        "G Kumar",
        "R Madhu"
      ],
      "venue": "Journal of Experimental & Theoretical Artificial Intelligence"
    },
    {
      "citation_id": "263",
      "title": "Artificial Muscle Intelligence System With Deep Learning for Post-Stroke Assistance and Rehabilitation",
      "authors": [
        "S Jacob",
        "V Menon",
        "F Al-Turjman",
        "P Vinoj",
        "L Mostarda"
      ],
      "year": "2019",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "264",
      "title": "Automatic ocular artifacts removal in EEG using deep learning",
      "authors": [
        "B Yang",
        "K Duan",
        "C Fan",
        "C Hu",
        "J Wang"
      ],
      "year": "2018",
      "venue": "Biomedical Signal Processing and Control"
    },
    {
      "citation_id": "265",
      "title": "Deep learning human mind for automated visual classification",
      "authors": [
        "C Spampinato",
        "S Palazzo",
        "I Kavasidis",
        "D Giordano",
        "N Souly",
        "M Shah"
      ],
      "year": "2017",
      "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition"
    },
    {
      "citation_id": "266",
      "title": "Deep Convolutional Neural Networks for Feature-Less Automatic Classification of Independent Components in Multi-Channel Electrophysiological Brain Recordings",
      "authors": [
        "P Croce",
        "F Zappasodi",
        "L Marzetti",
        "A Merla",
        "V Pizzella",
        "A Chiarelli"
      ],
      "year": "2019",
      "venue": "IEEE Transactions on Biomedical Engineering"
    },
    {
      "citation_id": "267",
      "title": "Subject adaptation network for EEG data analysis",
      "authors": [
        "Y Ming",
        "W Ding",
        "D Pelusi",
        "D Wu",
        "Y Wang",
        "M Prasad",
        "C Lin"
      ],
      "year": "2019",
      "venue": "Applied Soft Computing"
    },
    {
      "citation_id": "268",
      "title": "EEG signal classification using LSTM and improved neural network algorithms",
      "authors": [
        "P Nagabushanam",
        "S George",
        "S Radha"
      ],
      "venue": "EEG signal classification using LSTM and improved neural network algorithms"
    },
    {
      "citation_id": "269",
      "title": "EEG-based image classification via a region-level stacked bi-directional deep learning framework",
      "authors": [
        "A Fares",
        "S Zhong",
        "J Jiang"
      ],
      "year": "2019",
      "venue": "Bmc Medical Informatics and Decision Making"
    },
    {
      "citation_id": "270",
      "title": "Towards reconstructing intelligible speech from the human auditory cortex",
      "authors": [
        "H Akbari",
        "B Khalighinejad",
        "J Herrero",
        "A Mehta",
        "N Mesgarani"
      ],
      "year": "2019",
      "venue": "Towards reconstructing intelligible speech from the human auditory cortex"
    },
    {
      "citation_id": "271",
      "title": "Deep Neural Architectures for Mapping Scalp to Intracranial EEG",
      "authors": [
        "A Antoniades",
        "L Spyrou",
        "D Martin-Lopez",
        "A Valentin",
        "G Alarcon",
        "S Sanei",
        "C Took"
      ],
      "year": "2018",
      "venue": "International Journal of Neural Systems"
    },
    {
      "citation_id": "272",
      "title": "A Deep Evolutionary Approach to Bioinspired Classifier Optimisation for Brain-Machine Interaction",
      "authors": [
        "J Bird",
        "D Faria",
        "L Manso",
        "A Ekart",
        "C Buckingham"
      ],
      "year": "2019",
      "venue": "Complexity"
    },
    {
      "citation_id": "273",
      "title": "Semi-Supervised Deep Blind Compressed Sensing for Analysis and Reconstruction of Biomedical Signals From Compressive Measurements",
      "authors": [
        "V Singhal",
        "A Majumdar",
        "R Ward"
      ],
      "year": "2018",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "274",
      "title": "Semi-supervised Stacked Label Consistent Autoencoder for Reconstruction and Analysis of Biomedical Signals",
      "authors": [
        "A Gogna",
        "A Majumdar",
        "R Ward"
      ],
      "year": "2017",
      "venue": "IEEE Transactions on Biomedical Engineering"
    },
    {
      "citation_id": "275",
      "title": "Dual deep neural network-based classifiers to detect experimental seizures",
      "authors": [
        "H Jang",
        "K Cho"
      ],
      "year": "2019",
      "venue": "Korean Journal of Physiology & Pharmacology"
    },
    {
      "citation_id": "276",
      "title": "Favorite Video Classification Based on Multimodal Bidirectional LSTM",
      "authors": [
        "T Ogawa",
        "Y Sasaka",
        "K Maeda",
        "M Haseyama"
      ],
      "year": "2018",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "277",
      "title": "A Deep Learning Approach for Vital Signs Compression and Energy Efficient Delivery in mhealth Systems",
      "authors": [
        "A Ben Said",
        "M Al-Sa'd",
        "M Tlili",
        "A Abdellatif",
        "A Mohamed",
        "T Elfouly",
        "K Harras",
        "M O'connor"
      ],
      "year": "2018",
      "venue": "Summary of Datasets Mentioned in This Survey Dataset Name Modality Data Information Category URL BCI Challenge EEG 26 Participants, 56 Channels"
    },
    {
      "citation_id": "278",
      "title": "CAP Sleep Database EEG, EOG, EMG, ECG 16 Participants, 3 EEG Channels W, S1",
      "venue": "CAP Sleep Database EEG, EOG, EMG, ECG 16 Participants, 3 EEG Channels W, S1"
    },
    {
      "citation_id": "279",
      "title": "Scalp EEG Database EEG 22 Participants, 23 Channels",
      "authors": [
        "Chb-Mit"
      ],
      "venue": "Scalp EEG Database EEG 22 Participants, 23 Channels"
    },
    {
      "citation_id": "280",
      "title": "Hz Ictal Activity, Siezure Onset, and Ofsset",
      "venue": "Hz Ictal Activity, Siezure Onset, and Ofsset"
    },
    {
      "citation_id": "281",
      "title": "CSU BCI Collection EEG Vary with data sets in the database Normal and Motor Impairments",
      "venue": "CSU BCI Collection EEG Vary with data sets in the database Normal and Motor Impairments"
    },
    {
      "citation_id": "282",
      "title": "SEED Dataset EEG and Eye Movement 15 Participants, 62 Channels",
      "authors": [
        "Arousal",
        "Iiking Valence"
      ],
      "year": "1000",
      "venue": "emotions EEG Brainwave Dataset: Mental State EEG 4 Participants, 4 Channels, -Hz Relaxed, Concentrating, and Neutral"
    },
    {
      "citation_id": "283",
      "title": "441 Participants, C4-A1 and C3-A2",
      "authors": [
        "Eog Shhs Eeg"
      ],
      "venue": "Sleep-EDF Database Expanded EEG, EOG, EMG 61 Participants, Fpz-Cz and Pz"
    },
    {
      "citation_id": "284",
      "title": "",
      "authors": [
        "W Hz",
        "S1"
      ],
      "venue": ""
    },
    {
      "citation_id": "285",
      "title": "Sleep-EDF Database EEG, EOG, EMG 20 Participants, Fpz-Cz and Pz",
      "venue": "Sleep-EDF Database EEG, EOG, EMG 20 Participants, Fpz-Cz and Pz"
    },
    {
      "citation_id": "286",
      "title": "",
      "authors": [
        "W Hz",
        "N1"
      ],
      "venue": ""
    },
    {
      "citation_id": "287",
      "title": "Barcelona EEG Database EEG 5 Participants, 7500 Pairs of Signals, 512 or 1024 Hz Focal and Non-Focal",
      "venue": "Barcelona EEG Database EEG 5 Participants, 7500 Pairs of Signals, 512 or 1024 Hz Focal and Non-Focal"
    },
    {
      "citation_id": "288",
      "title": "The SIESTA Normative Database (cross-institute)",
      "venue": "The SIESTA Normative Database (cross-institute)"
    },
    {
      "citation_id": "289",
      "title": "ECG 292 Participants, 6 EEG Channels, Variable",
      "authors": [
        "Eog Eeg",
        "Emg"
      ],
      "venue": "ECG 292 Participants, 6 EEG Channels, Variable"
    },
    {
      "citation_id": "290",
      "title": "UCD Database EEG and Physiological Signals 25 Participants",
      "venue": "UCD Database EEG and Physiological Signals 25 Participants"
    },
    {
      "citation_id": "291",
      "title": "",
      "authors": [
        "Rem Sws"
      ],
      "venue": ""
    },
    {
      "citation_id": "292",
      "title": "LUMED Dataset EEG and Physiological Signals 11 Participants, 8 Channels, 500 Hz Negative and Positive Valence",
      "venue": "LUMED Dataset EEG and Physiological Signals 11 Participants, 8 Channels, 500 Hz Negative and Positive Valence"
    }
  ]
}