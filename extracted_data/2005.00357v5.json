{
  "paper_id": "2005.00357v5",
  "title": "Beneath The Tip Of The Iceberg: Current Challenges And New Directions In Sentiment Analysis Research",
  "published": "2020-05-01T13:05:23Z",
  "authors": [
    "Soujanya Poria",
    "Devamanyu Hazarika",
    "Navonil Majumder",
    "Rada Mihalcea"
  ],
  "keywords": [
    "Natural Language Processing",
    "Sentiment Analysis",
    "Emotion Recognition",
    "Aspect Based Sentiment Analysis",
    "Sarcasm Analysis",
    "Sentiment-aware Dialogue Generation",
    "Bias in Sentiment Analysis Systems"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Sentiment analysis as a field has come a long way since it was first introduced as a task nearly 20 years ago. It has widespread commercial applications in various domains like marketing, risk management, market research, and politics, to name a few. Given its saturation in specific subtasks -such as sentiment polarity classification -and datasets, there is an underlying perception that this field has reached its maturity. In this article, we discuss this perception by pointing out the shortcomings and under-explored, yet key aspects of this field necessary to attain true sentiment understanding. We analyze the significant leaps responsible for its current relevance. Further, we attempt to chart a possible course for this field that covers many overlooked and unanswered questions.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "S ENTIMENT analysis, also known as opinion mining, is a research field that aims at understanding the underlying sentiment of unstructured content. E.g., in this sentence, \"John dislikes the camera of iPhone 7\", according to the technical definition  (Liu, 2012)  of sentiment analysis, John plays the role of the opinion holder exposing his negative sentiment towards the aspect -camera of the entity -iPhone 7. Since its early beginnings  (Pang et al., 2002; Turney, 2002) , sentiment analysis has established itself as an influential field of research with widespread applications in industry. Its everincreasing popularity and demand stem from the individuals, businesses, and governments interested in understanding people's views about products, political agendas, or marketing campaigns. Public opinion also stimulates market trends, which makes it relevant for financial predictions. Furthermore, education and healthcare sectors make use of sentiment analysis for behavioral analysis of students and patients.\n\nOver the years, the scope for innovation and commercial demand has jointly driven research in sentiment analysis. However, there has been an emerging perception that the problem of sentiment analysis is merely a text/content categorization task -one that requires content to be classified into two or three categories of sentiments: positive, negative, or neutral. This has led to a belief among researchers that\n\n• Soujanya Poria can be contacted at sporia@sutd.edu.sg • Devamanyu Hazarika can be contacted at hazarika@comp.nus.edu.sg • Navonil Majumder can be contacted at navonil majumder@sutd.edu.sg • Rada Mihalcea can be contacted at mihalcea@umich.edu sentiment analysis has reached its saturation. Through this work, we set forth to address this misconception.\n\nFigure  1  shows that many benchmark datasets on the polarity detection subtask of sentiment analysis, like IMDB or SST-2, have reached saturation points, as reflected by the nearperfect scores achieved by many modern data-driven methods. However, this does not imply that sentiment analysis is solved. Rather, we believe that this perception of saturation has manifested from excessive research publications that focus only on shallow sentiment understanding, such as kway text classification, whilst ignoring other key un-and under-explored problems relevant to this research field.  Liu (2015)  presents sentiment analysis as mini-NLP, given its reliance on topics covering almost the entirety of NLP. Similarly,  Cambria et al. (2017)  characterize sentiment analysis as a big suitcase of subtasks and subproblems, involving open syntactic, semantic, and pragmatic problems. As such, there remain several open research directions to be extensively studied, such as understanding motive and cause of sentiment, sentiment dialogue generation, sentiment reasoning, and so on. At its core, effective inference of sentiment requires an understanding of multiple fundamental problems in NLP. These include assigning polarities to aspects, negation handling, resolving co-references, and identifying syntactic dependencies to exploit sentiment flow. The figurative nature of language also influences sentiment analysis, often exploited using linguistic devices, such as sarcasm and irony. This complex composition of multiple tasks makes sentiment analysis a challenging yet interesting research space.\n\nFigure  1  also demonstrates that the methods with a Fig.  1 : Performance trends of recent models on IMDB  (Maas et al., 2011) , SST-2, SST-5  (Socher et al., 2013)  and Semeval  (Pontiki et al., 2014)  datasets. The tasks involve sentiment classification in either aspect or sentence level. Note: Data obtained from https://paperswithcode.com/task/sentiment-analysis. The labels on the graphs are either citations or system names that are also retrieved from https://paperswithcode.com/task/sentiment-analysis.\n\ncontextual language model as their backbone, much like in other areas of NLP, have dominated these benchmark datasets. Equipped with millions or billions of parameters, transformer-based networks such as BERT  (Devlin et al., 2019) , RoBERTa  (Liu et al., 2019) , and their variants have pushed the state-of-the-art to new heights. Despite this performance boost, these models are opaque, and their innerworkings are not fully understood. Thus, the question that remains is how far have we progressed since the beginning of sentiment analysis?  (Pang et al., 2002)  The importance of lexical, syntactical, and contextual features has been acknowledged numerous times in the past. Recently, due to the advent of the powerful contextualized word embeddings and networks like BERT, we can compute much better representations of such features. Does this entail true sentiment understanding? Not likely, as we are far from any significant achievement in multi-faceted sentiment research, such as the underlying motivations behind an expressed sentiment, sentiment reasoning, and so on. As members of this research community, we believe that we should strive to move past simple classification as the benchmark of progress and instead direct our efforts towards learning tangible sentiment understanding. Taking a step in this direction would include analyzing, customizing, and training modern architectures in the context of sentiment, emphasizing finegrained analysis and exploration of parallel new directions, such as multimodal learning, sentiment reasoning, sentimentaware natural language generation, and figurative language.\n\nThe primary goal of this paper is to motivate new researchers approaching this area. We begin by summarizing the key milestones reached (Figure  3 ) in the last two decades of sentiment analysis research, followed by opening the discussion on new and understudied research areas of sentiment analysis. We also identify some of the critical shortcomings in several sub-fields of sentiment analysis and describe potential research directions. This paper is not intended as a survey of the field -we mainly cover a small number of key contributions that have either had a seminal impact on this field or have the potential to open new avenues. Our intention, thus, is to draw attention to key research topics within the broad field of sentiment analysis and identify critical directions left to be explored. We also uncover promising new frameworks and applications that may drive sentiment analysis research in the near future.\n\nThe rest of the paper is organized as follows: Section 2 briefly describes the key developments and achievements in the sentiment analysis research; we discuss the future directions of sentiment analysis research in Section 3; and finally, Section 4 concludes the paper. We illustrate the overall organization of the paper in Figure  2 . We curate all the articles, that cover the past and future of sentiment analysis (see Figure  2 ), on this repository: https://github. com/declare-lab/awesome-sentiment-analysis.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Nostalgic Past:",
      "text": "Early SA",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Analysis Of:",
      "text": "-Affect -Subjectivity Granularities -Document-level SA -Sentence-level SA -Aspect-level SA Major Trends -Rule-based -Lexicon-based -Machine learning - Deep learning  product  (Pang & Lee, 2004; Glorot et al., 2011; Moraes et al., 2013b) .  Pang et al. (2002)  conducted one of the initial works on document-level sentiment analysis, where they assigned positive/negative polarity to review documents. They used various features, including unigrams (bag of words) and trained simple classifiers, such as Naive Bayes classifiers and SVMs. Although primarily framed as a classification/regression task, alternate forms of documentlevel sentiment analysis research include other tasks such as generating opinion summaries  (Ku et al., 2006; Lloret et al., 2009) .\n\nSentence-level sentiment analysis restricts the analysis to individual sentences  (Yu & Hatzivassiloglou, 2003; Kim & Hovy, 2004) . These sentences could belong to documents, conversations, or standalone micro-texts found in resources such as microblogs  (Kouloumpis et al., 2011) .\n\nWhile both document-and sentence-level sentiment analysis provide an overall sentiment orientation, they do not indicate the target of the sentiment in many cases. They implicitly assume that the text span (document or sentence) conveys a single sentiment towards an entity, which typically is a very strong assumption.\n\nTo overcome this challenge, the analysis is directed towards a finer level of scrutiny, i.e., aspect-level sentiment analysis, where sentiment is identified for each entity  (Hu & Liu, 2004b ) (along with its aspects). Aspect-level analysis allows a better understanding of the sentiment distribution. We discuss its challenges in Section 3.1.\n\nIn addition to these three granularity levels, a significant amount of studies have been done for phrase-level sentiment analysis, which focus on phrases within a sentence  (Wilson et al., 2005b) . In this granularity, the goal is to analyze how the sentiment of words, present in lexicons, can change in and out of context, e.g., good vs. doesn't look good. Many compositional factors, such as negators, modals, or intensifiers, may flip or change the degree of sentiment  (Kiritchenko et al., 2016) , which makes it a difficult yet important task.\n\nIn the initial developments of sentiment analysis, phraselevel study contributed numerous advances in defining rules that accounted for these compositions. We discuss these in the next section. Phrase-level sentiment analysis has also been important in small text pieces found in micro-blogs, such as Twitter. Many recent shared-tasks discuss this area of research  (Nakov et al., 2013; Rosenthal et al., 2014 Rosenthal et al., , 2015) )  (see Section 2.4).",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Trends In Sentiment Analysis Applications",
      "text": "Rule-Based Sentiment Analysis: A major section of the history of sentiment analysis research has focused on utilizing sentiment-bearing words and utilizing their compositions to analyze phrasal units for polarity. Early work identified that the simple counting of valence words, i.e., a bagof-words approach, can provide incorrect results  (Polanyi & Zaenen, 2006) . This led to the emergence of research on valence shifters that incorporated changes in valence and polarity of terms based on contextual usage  (Polanyi & Zaenen, 2006; Moilanen & Pulman, 2007) . However, only valence shifters were not enough to detect sentiment -it also required understanding sentiment flows across syntactic units. Thus, researchers introduced the concept of modeling sentiment composition, learned via heuristics and rules  (Choi & Cardie, 2008) , hybrid systems  (Rentoumi et al., 2010) , syntactic dependencies  (Nakagawa et al., 2010; Hutto & Gilbert, 2014) , amongst others.\n\nSentiment Lexicons are at the heart of rule-based sentiment analysis methods. Simply defined, these lexicons are dictionaries that contain sentiment annotations for their constituent words, phrases, or synsets  (Joshi et al., 2017a; Cambria et al., 2020) .\n\nSentiWordNet  (Esuli & Sebastiani, 2006 ) is one such popular sentiment lexicon that builds on top of Wordnet  (Miller, 1995) . In this lexicon, each synset is assigned with positive, negative, and objective scores, which indicate their subjectivity orientation. As the labeling is associated with synsets, the subjectivity score is tied to word senses. This trait is desirable as subjectivity and word-senses have strong semantic dependence, as highlighted in  Wiebe & Mihalcea (2006) .\n\nSO-CAL  (Taboada et al., 2011) , as the name suggests, presents a lexicon-based sentiment calculator. It contains a dictionary of words associated with their semantic orientation (polarity and strength). The strength of this resource is in its ability to account for contextual valence shifts, which include factors that affect the polarity of words through intensification, lessening, and negations.\n\nOther popular lexicons include SCL-OPP  (Kiritchenko & Mohammad, 2016a) , SCL-NMA  (Kiritchenko & Mohammad, 2016b) , amongst others. These lexicons not just store wordpolarity associations but also include phrases or rules that reflect complex sentiment compositions, e.g., negations, intensifiers. NRC Lexicon  Mohammad & Turney (2010 , 2013)  is another popular lexicon that hosts both word-sentiment and word-emotion pairs with high-quality annotations.\n\nLexicons have been mainly created using three broad approaches, manual, automatic, and semi-supervised. In manual creation, expert-annotation  (Taboada et al., 2011)  or crowd-sourcing  (Socher et al., 2013)  is used to create annotations. In automatic methods, annotations are generated or expanded using knowledge bases, such as Wordnet. The advantage of automatic methods is a broader coverage of instances and also sense-specific annotations, especially for Wordnet-based expansions  (Esuli & Sebastiani, 2006) . However, automatic methods tend to have higher noise in the annotations. The final approach is to use semi-supervised learning, such as label propagation  (Zhu & Ghahramani, 2002)  or graph propagation  (Velikovich et al., 2010) , to create new sentiment lexicons that could be domain-specific  (Tai & Kao, 2013)  or in new languages  (Chen & Skiena, 2014)  -two topics that hold high relevance in present research directions.\n\nThough lexicons provide valuable resources for archiving sentiment polarity of words or phrases, utilizing them to infer sentence-level polarities has been quite challenging. Moreover, no one lexicon can handle all the nuances observed from semantic compositionality  (Toledo-Ronen et al., 2018; Kiritchenko & Mohammad, 2016d)  or account for contextual polarity. Lexicons also have many challenges in their creation, such as combating subjectivity in annotations  (Mohammad, 2017) .\n\nWhile sentiment lexicons remain an integral component of sentiment analysis systems, especially for low-resource instances, there has been an increase in focus towards",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Deep Learning Foundations",
      "text": "",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Sa On Reviews",
      "text": "Sentiment-specific Word Embeddings",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Contextual Language Models",
      "text": "Lexicons for SA Opinion Summarization  (Hu & Liu, 2004)  Private States  (Wiebe, 1994)  Subjectivity Analysis  (Wiebe, 1999)  Bag of words & Syntactic Rules  (Turney 2002 )",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Sentiment Composition",
      "text": "Valence Shifters  (Polanyi & Zaenen, 2006)  SentiWordNet  (Esuli, 2006)  SO-CAL  (Taboada, 2011)  Semantics an Sentiment  (Maas, 2011)  Sentiment Loss  (Tang et al., 2014)  RNTN  (Socher et al., 2013)  CNN, Dynamic CNN  (Kim et al., 2014 , Kalchbrenner et al. 2014)  ULMFiT  (Howard & Ruder, 2018)  BERT  (Devlin, 2019)  Fig.  3 : A non-exhaustive illustration of some of the milestones of sentiment analysis research.\n\nstatistical solutions. These solutions do not suffer from the issue of rules-coverage and provide better opportunities to handle generalization. Machine Learning-Based Sentiment Analysis: Statistical approaches that employ machine learning have been appealing to this area, particularly due to their independence over hand-engineered rules. Despite best efforts, the rules could never be enumerated exhaustively, which always kept the generalization capability limited. With machine learning, the opportunity to learn generic representations emerged. Throughout the development of sentiment analysis, MLbased approaches-both supervised and unsupervised-have employed myriad of algorithms that include SVMs  (Moraes et al., 2013a) , Naive Bayes Classifiers  (Tan et al., 2009) , nearest neighbour  (Moghaddam & Ester, 2010) , combined with features that range from bag-of-words (including weighted variants)  (Martineau & Finin, 2009) , lexicons  (Gavilanes et al., 2016)  to syntactic features such as parts of speech  (Mejova & Srinivasan, 2011) . A detailed review for most of these works has been provided in  (Liu, 2010 (Liu, , 2012)) .\n\nDeep Learning Era: The advent of deep learning saw the use of distributional embeddings and techniques for representation learning for various tasks of sentiment analysis. One of the initial models was the Recursive Neural Tensor Network (RNTN)  Socher et al. (2013) , which determined the sentiment of a sentence by modeling the compositional effects of sentiment in its phrases. This work also introduced the Stanford Sentiment Treebank corpus comprising of parse trees fully labeled with sentiment labels. The unique usage of recursive neural networks adapted to model the compositional structure in syntactic trees was highly innovative and influencing  (Tai et al., 2015) .\n\nCNNs and RNNs were also used for feature extraction. The popularity of these networks, especially that of CNNs, can be traced back to  Kim (2014) . Although CNNs had been used in NLP systems earlier  (Collobert et al., 2011) , the investigatory work by  Kim (2014)  presented a CNN architecture which was simple (single-layered) and also delved into the notion of non-static embeddings. It was a popular network, that became the de-facto sentential feature extractor for many of the sentiment analysis tasks. Similar to CNNs, RNNs also enjoyed high popularity. Aside from polarity prediction, these architectures outperformed tradi-tional graphical models in structured prediction tasks such as aspect, aspect-term and opinion-term extraction  (Poria et al., 2016; Irsoy & Cardie, 2014) . Aspect-level sentiment analysis, in particular, saw an increase in complex neural architectures that involve attention mechanisms  (Wang et al., 2016) , memory networks  (Tang et al., 2016b)  and adversarial learning  (Karimi et al., 2020; Chen et al., 2018) . For a comprehensive review of modern deep learning architectures, please refer to  (Zhang et al., 2018a) .\n\nAlthough the majority of the works employing deep networks rely on automated feature learning, their heavy reliance on annotated data is often limiting. As a result, providing inductive biases via syntactic information, or external knowledge in the form of lexicons as additional input has seen a resurgence  (Tay et al., 2018b) .\n\nAs seen in Figure  1 , the recent works based on neural architectures  (Le & Mikolov, 2014; Dai & Le, 2015; Johnson & Zhang, 2016; Miyato et al., 2017; McCann et al., 2017; Howard & Ruder, 2018; Xie et al., 2019; Thongtan & Phienthrakul, 2019)  have dominated over traditional machine learning models  (Maas et al., 2011; Wang & Manning, 2012) . Similar trends can be observed in other benchmark datasets such as Yelp, SST  (Socher et al., 2013) , and Amazon Reviews  (Zhang et al., 2015) . Within neural methods, much like other fields of NLP, present trends are dominated by the contextual encoders, which are pre-trained as language models using the Transformer architecture  (Vaswani et al., 2017) . Models like BERT, XLNet, RoBERTa, and their adaptations have achieved the state-of-the-art performances on multiple sentiment analysis datasets and benchmarks  (Hoang et al., 2019; Munikar et al., 2019; Raffel et al., 2019) . Despite this progress, it is still not clear as to whether these new models learn the composition semantics associated to sentiment or simply learn surface patterns  (Rogers et al., 2020) .\n\nSentiment-Aware Word Embeddings: One of the critical building blocks of a text-processing deep-learning architecture is its word embeddings. It is known that the word representations rely on the task it is being used for  (Labutov & Lipson, 2013) . However, most sentiment analysis-based models use static general-purpose word representations.  Tang et al. (2014)  proposed an important work in this direction that provided word representations tailored for sentiment analysis. While general embeddings mapped words with similar syntactic context into nearby representations, this work incorporated sentiment information into the learning loss to account for sentiment regularities.\n\nAlthough the community has proposed some approaches in this topic  (Maas et al., 2011; Bespalov et al., 2011) , promising traction has been limited  (Tang et al., 2015) . Further, with the popularity of contextual models such as BERT, it remains to be seen how sentiment information can be incorporated into its embeddings.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Sentiment Analysis In Diverse Domains",
      "text": "Sentiment analysis in micro-blogs, such as Twitter, require different processing techniques compared to traditional text pieces. Enforced maximum text length often coerces users to express their opinion straightforwardly. However, sarcasm and irony pose a challenge to these systems. Tweets are rife with internal slangs, abbreviations, and emoticons -which adds to the complexity of mining their opinions. Moreover, the limited length restricts the presence of contextual cues normally present in dialogues or documents  (Kharde & Sonawane, 2016) .\n\nFrom a data point of view, opinionated data is found in abundance in such micro-blogs. Reflections of this have been observed in the recent benchmark shared tasks based on Twitter data. These include Semeval shared tasks for sentiment analysis, aspect-based sentiment analysis and figurative language in Twitter 1, 2, 3, 4 .\n\nA new trend amongst users in Twitter is the concept of daisy-chaining multiple tweets to compose a longer piece of text. Existing research, however, has not addressed this phenomenon to acquire additional context. Future work on Twitter sentiment analysis could benefit from analyzing users' personalities based on their historical tweets.\n\nThe application of sentiment analysis is not limited to social media and review articles. It spans from emails  (Hag Ali & El Gayar, 2019)  to financial documents  (Krishnamoorthy, 2017)  showing the efficacy in understanding the mood of users across different domains.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Optimistic Future: Upcoming Trends In Sentiment Analysis",
      "text": "The previous section highlighted some of the milestones in sentiment analysis research, which helped develop the field into its present state. Despite the progress, we believe the problems are far from solved. In this section, we take an optimistic view on the road ahead in sentiment analysis research and highlight several applications rife with open problems and challenges.\n\nApplications of sentiment analysis take form in many ways. Fig.  4  presents one such example where a user is chatting with a chit-chat style chatbot. In the conversation, to generate an appropriate response, the bot needs to understand the user's opinion. This involves multiple subtasks that include 1) extracting aspects like service, seats for the entity airline, 2) aspect-level sentiment analysis along 1. http://alt.qcri.org/semeval2015/task10/ 2. http://alt.qcri.org/semeval2015/task12/ 3. http://alt.qcri.org/semeval2015/task11/ 4. https://sites.google.com/view/figlang2020/ with knowing 3) who holds the opinion and why (sentiment reasoning). Added challenges include analyzing code-mixed data (e.g. \"les meilleurs du monde\"), understanding domainspecific terms (e.g., rude crew), and handling sarcasmwhich could be highly contextual and detectable only when preceding utterances are taken into consideration. Once the utterances are understood, the bot can now determine appropriate response-styles and perform controlled-natural language generation (NLG) based on the decided sentiment. The overall example demonstrates the dependence of sentiment analysis on these applications and sub-tasks, some of which are new and still at early development stages. We discuss these applications next.",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "Aspect-Based Sentiment Analysis",
      "text": "Although sentiment analysis provides an overall indication of the author or speaker's sentiments, it is often the case when a piece of text comprises multiple aspects with varied sentiments. For example, in the following sentence, \"This actor is the only failure in an otherwise brilliant cast.\", the opinion is attached to two particular entities, actor (negative opinion) and cast (positive opinion). There is also an absence of an overall opinion that could be assigned to the full sentence.\n\nAspect-based Sentiment Analysis (ABSA) takes such finegrained view and aims to identify the sentiments towards each entity (or their aspects)  (Liu, 2015; Liu & Zhang, 2012) . The problem involves two major sub-tasks, 1) Aspectextraction, which identifies the aspects 5 mentioned within a given sentence or paragraph (actor and cast in the above example) 2) Aspect-level Sentiment Analysis (ALSA), which determines the sentiment orientation associated with the corresponding aspects/ opinion targets (actor ↦ negative and cast ↦ positive)  (Hu & Liu, 2004a) . Proposed approaches for aspect extraction include rule-based strategies  (Qiu et al., 2011; Liu et al., 2015) , topic models  (Mei et al., 2007; He et al., 2011) , and more recently, sequential structured-prediction models such as CRFs  (Shu et al., 2017) . For aspect-level sentiment analysis, the algorithms primarily aim to model the relationship between the opinion targets and their context. To achieve this, models based on CNNs  (Li & Lu, 2017) , memory networks  (Tay et al., 2017) , etc. have been explored. Primarily, the associations have been learnt through attention mechanism  (Wang et al., 2016) .\n\nDespite the advances in this field, there remain many factors which are open for research and hold the potential to improve performances further. We discuss them below.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Aspect-Term Auto-Categorization",
      "text": "Aspect-terms extraction is the first step towards aspect-level sentiment analysis. This task has been studied rigorously in the literature  (Poria et al., 2016) . Thanks to the advent of deep sequential learning, the performance of this task on the benchmark datasets  (Hu & Liu, 2004b; Pontiki et al., 2016)  has reached a new level. Aspect terms are needed to be categorized into aspect groups to present a coherent view of the expressed opinions. We illustrate this categorization in Fig.  5 . Approaches to aspect-term auto-categorization are mostly 5. In the context of aspect-based sentiment analysis, aspect is the generic term utilized for topics, entities, or their attributes/features. They are also known as opinion targets.\n\nNever flying with that airline again. Their service sucks. Such rude crew.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Bot User",
      "text": "And their seats were \"les meilleurs du monde\" !!! Aww that sucks! That airline should be grounded. based on supervised and unsupervised topic classification and lexicon driven. These three types of approaches succumb to scalability issues when subjected to new domains with novel aspect categories. We believe that entity linking-based approaches, coupled with semantic graphs like Probase  (Wu et al., 2012) , should be able to perform reasonably while overcoming scalability issues. For example, the sentence \"With this phone, I always have a hard time getting signal indoors.\" contains one aspect term signal, that can be passed to an entity linker -on a graph containing a tree shown in Fig.  5  -with the surrounding words as context to obtain aspect category phone:signal-quality.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Conversation Sentiment Analysis",
      "text": "",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "What",
      "text": "",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Implicit Aspect-Level Sentiment Analysis",
      "text": "Sentiment on different aspects can be expressed implicitly. Although under-studied, the importance of detecting implicit aspect-level sentiment can not be ignored as they represent a unique nature of natural language. For example, in the sentence, \"Oh no! Crazy Republicans voted against this bill\", the speaker explicitly expresses her/his negative sentiment on the Republicans. At the same time, we can infer that the speaker's sentiment towards the bill is positive. In the work by  Deng et al. (2014) , it is called as opinion-oriented implicatures. As most datasets are not labeled with such details, models trained on present datasets might miss extracting bill as an aspect term and its associated polarity. Thus, this remains an open problem in the overall ABSA task. The case of implicit sentiment is also observed in contextual sentiment analysis, which we further discuss in Section 3.3.2.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Aspect Term-Polarity Co-Extraction",
      "text": "Most existing algorithms in this area consider aspect extraction and aspect-level sentiment analysis as sequential (pipelined) or independent tasks. In both these cases, the relationship between the tasks is ignored. Efforts towards joint learning of these tasks have gained traction in recent trends. These include hierarchical neural networks  (Lakkaraju et al., 2014) , multi-task CNNs  (Wu et al., 2016) , and CRF-based approaches by framing both the sub-tasks as sequence labeling problems  (Li et al., 2019; Luo et al., 2019) . The notion of joint learning opens up several avenues for exploring the relationships between the sub-tasks and possible dependencies from other tasks.\n\nAnother strategy is to leverage transfer learning since aspect extraction can be utilized as a scaffolding for aspectbased sentiment analysis  (Majumder et al., 2020) . Knowledge transfer can also be observed from textual to multimodal ABSA system.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Exploiting Inter-Aspect Relations For Aspect-Level Sentiment Analysis",
      "text": "The primary focus of algorithms proposed for aspect-level sentiment analysis has been to model the dependencies between opinion targets and their corresponding opinionated words in the context  (Tang et al., 2016a) . Besides, modeling the relationships between aspects also holds potential in this task  (Hazarika et al., 2018c) . For example, in the sentence \"my favs here are the tacos pastor and the tostada de tinga\", the aspects \"tacos pastor\" and \"tostada de tinga\" are connected using conjunction \"and\" and both rely on the sentiment bearing word \"favs\". Understanding such interaspect dependency can significantly aid the aspect-level sentiment analysis performance and remains to be researched extensively.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Quest For Richer And Larger Datasets",
      "text": "The two widely used publicly available datasets for aspectbased sentiment analysis are Amazon product review  (Hu & Liu, 2004b)  and Semeval-2016  (Pontiki et al., 2016)  datasets. Both these datasets are quite small in size that hinders any statistically significant performance improvement between methods utilizing them.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Multimodal Sentiment Analysis",
      "text": "The majority of research works on sentiment analysis have been conducted using only textual modality. However, with the increasing number of user-generated videos available on online platforms such as YouTube, Facebook, Vimeo, and others, multimodal sentiment analysis has emerged at the forefront of sentiment analysis research. The commercial interests fuel this rise as the enterprises tend to make business decisions on their products by analyzing user sentiments in these videos. Figure  6  presents examples where the presence of multimodal signals in addition to the text itself is necessary in order to make correct predictions of their emotions and sentiments. Multimodal fusion is at the heart of multimodal sentiment analysis, with an increasing number of works proposing new fusion techniques. These include Multiple Kernel Learning, tensor-based non-linear fusion  (Zadeh et al., 2017) , memory networks  (Zadeh et al., 2018a) , amongst others. The granularity at which such fusion methods are applied also varies -from word-level to utterance-level.\n\nBelow, we identify three key directions that can aid future research:",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Complex Fusion Methods Vs. Simple Concatenation",
      "text": "Multimodal information fusion is a core component of multimodal sentiment analysis. Although several fusion techniques  (Zadeh et al., 2018c (Zadeh et al., ,a, 2017) )  have been recently proposed, in our experience, a simple concatenation-based fusion method performs at par with most of these methods. We believe these methods are unable to provide significant improvements in the fusion due to their inability to model correlations among different modalities and handle noise. Reliable fusion remains a major future work.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Lack Of Large Datasets",
      "text": "The field of multimodal sentiment analysis also suffers from the lack of larger datasets. The available datasets, such as MOSI  (Zadeh et al., 2016) , MOSEI  (Zadeh et al., 2018b) , MELD  (Poria et al., 2019)  are not large enough and carry suboptimal inter-annotator agreement that impedes the performance of complex deep learning frameworks.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Fine-Grained Annotation",
      "text": "The primary goal of multimodal fusion is to accumulate the contribution from each modality. However, measuring that contribution is not trivial as there is no available dataset that annotates the individual role of each modality. We show one such example in Figure  6 , where each modality is labeled with the sentiment it carries. Having such rich fine-grained annotations should better guide multimodal fusion methods and make them more interpretable. This fine-grained annotation can also open the door to novel multimodal fusion approaches.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Contextual Sentiment Analysis",
      "text": "",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Influence Of Topics",
      "text": "The usage of sentiment words varies from one topic to another. Words that sound neutral on the surface can bear sentiment when conjugated with other words or phrases. For example, the word big in big house can carry positive sentiment when someone intends to purchase a big house for leisure. However, the same word could evoke negative sentiments when used in the context -A big house is hard to clean. Unfortunately, research in sentiment analysis has not focused much on this aspect. The sentiment of some words can be vague and specified only when seen in context, e.g., the word massive in the context of massive earthquake and massive villa. A dataset composed of such contextual sentiment bearing phrases would be a great contribution to the research community in the future.\n\nThis research problem is also related to word sense disambiguation. Below we present an example, borrowed from the work by  Choi et al. (2017) :\n\na. The Federal Government carried the province for many years. b. The troops carried the town after a brief fight.\n\nIn the first sentence, the sense of carry has a positive polarity. However, in the second sentence, the same word has negative connotations. Hence, depending on the context, the sense of words and their polarities can change. In  Choi et al. (2017) , the authors adopted topic models to associate word senses with sentiments. As this particular I don't think I can do this anymore.\n\n[ frustrated ]\n\nWell I guess you aren't trying hard enough.   (Busso et al., 2008) .\n\nresearch problem widens its scope to the task of word sense disambiguation, it would be useful to employ contextual language models to decipher word senses in contexts and assign the corresponding polarity.",
      "page_start": 8,
      "page_end": 9
    },
    {
      "section_name": "Sentiment Analysis In Monologues And Conversational Context",
      "text": "Context is at the core of NLP research. According to several recent studies  (Peters et al., 2018; Devlin et al., 2019) , contextual sentence and word-embeddings can improve the performance of the state-of-the-art NLP systems by a significant margin.\n\nThe notion of context can vary from problem to problem. For example, while calculating word representations, the surrounding words carry contextual information. Likewise, to classify a sentence in a document, other neighboring sentences are considered as its context.  Poria et al. (2017)  utilize surrounding utterances in a video as context and experimentally show that contextual evidence indeed aids in classification.\n\nThere have been very few works on inferring implicit sentiment  (Deng & Wiebe, 2014)  from context. This is crucial for achieving true sentiment understanding. Let us consider this sentence \"Oh no. The bill has been passed\". As there are no explicit sentiment markers present in the isolated sentence -\"The bill has been passed\", it would sound like a neutral sentence. Consequently, the sentiment behind 'bill' is not expressed by any particular word. However, considering the sentence in the context -\"Oh no\", which exhibits negative sentiment, it can be inferred that the opinion expressed on the 'bill' is negative. The inferential logic that one requires to arrive at such conclusions is the understanding of sentiment flow in the context. In this particular example, the contextual sentiment of the sentence -\"Oh no\" flows to the next sentence and thus making it a negative opinionated sentence. Tackling such tricky and fine-grained cases require bespoke modeling and datasets containing an ample quantity of such non-trivial samples. Further, commonsense knowledge can also aid in making such inferences. In the literature  (Poria et al., 2017) , the use of LSTMs to model such sequential sentiment flow has been ineffectual. We think it would be fruitful to utilize logic rules, finite-state transducers, belief, and information propagation mechanisms to address this problems  (Deng et al., 2014; Deng & Wiebe, 2014) . We also note that contextual sentences may not always help. Hence, one can ponder using a gate or switch to learn and further infer when to count on contextual information.\n\nIn conversational sentiment-analysis, to determine the emotions and sentiments of an utterance at time t, the preceding utterances at time < t can be considered as its context. However, computing this context representation can often be difficult due to complex sentiment dynamics.\n\nSentiments in conversations are deeply tied with emotional dynamics consisting of two important aspects: selfand inter-personal dependencies  (Morris & Keltner, 2000) . Selfdependency, also known as emotional inertia, deals with the aspect of influence that speakers have on themselves during conversations  (Kuppens et al., 2010) . On the other hand, inter-personal dependencies relate to the sentimentaware influences that the counterparts induce into a speaker. Conversely, during the course of a dialogue, speakers also tend to mirror their counterparts to build rapport  (Navarretta et al., 2016) . This phenomenon is illustrated in Figure  7 . Here, P a is frustrated over her long term unemployment and seeks encouragement (u 1 , u 3 ). P b , however, is pre-occupied and replies sarcastically (u 4 ). This enrages P a to appropriate an angry response (u 6 ). In this dialogue, self-dependencies are evident in P b , who does not deviate from his nonchalant behavior. P a , however, gets sentimentally influenced by P b . Modeling self-and inter-personal relationships and dependencies may also depend on the topic of the conversation as well as various other factors like argument structure, interlocutors' personality, intents, viewpoints on the conversation, attitude towards each other, and so on. Hence, analyzing all these factors is key for a true self and inter-personal dependency modeling that can lead to enriched context understanding  (Hazarika et al., 2018d) .\n\nThe contextual information can come from both local and distant conversational history. As opposed to the local context, distant context often plays a smaller role in sentiment analysis of conversations. Distant contextual information is useful mostly in the scenarios when a speaker refers to earlier utterances spoken by any of the speakers in the conversational history.\n\nThe usefulness of context is more prevalent in classifying short utterances, like yeah, okay, no, that can express different sentiments depending on the context and discourse of the dialogue. The examples in Fig.  8   information from the context. However, these models fail to explain the situations where contextual information is needed. Hence, finding contextualized conversational utterance representations is an active area of research.",
      "page_start": 9,
      "page_end": 10
    },
    {
      "section_name": "User, Cultural, And Situational Context",
      "text": "Sentiment also depends on the user, cultural, and situational context.\n\nIndividuals have subtle ways of expressing emotions and sentiments. For instance, some individuals are more sarcastic than others. For such cases, the usage of certain words would vary depending on if they are being sarcastic. Let's consider this example, P a ∶ The order has been cancelled., P b ∶ This is great!. If P b is a sarcastic person, then his response would express negative emotion to the order being canceled through the word great. On the other hand, P b 's response, great, could be taken literally if the canceled order is beneficial to P b (perhaps P b cannot afford the product he ordered). As necessary background information is often missing from the conversations, speaker profiling based on preceding utterances often yields improved results.\n\nThe underlying emotion of the same word can vary from one person to another. E.g., the word okay can bear different sentiment intensity and polarity depending on the speaker's character. This incites the need to do user profiling for finegrained sentiment analysis, which is a necessary task for e-commerce product review understanding.\n\nUnderstanding sentiment also requires cultural and situational awareness. A hot and sunny weather can be treated as a good weather in USA but certainly not in Singapore. Eating ham could be accepted in one religion and prohibited by another.\n\nA basic sentiment analysis system that only relies on distributed word representations and deep learning frameworks are susceptible to these examples if they do not encompass rudimentary contextual information.",
      "page_start": 10,
      "page_end": 11
    },
    {
      "section_name": "Role Of Commonsense Knowledge In Sentiment Analysis",
      "text": "In layman's term, commonsense knowledge consists of facts that all human beings are expected to know. Due to this characteristic, humans tend to ignore expressing commonsense knowledge explicitly. As a result, word embeddings trained on the human-written text do not encode such trivial yet important knowledge that can potentially improve language understanding. The distillation of commonsense knowledge, thus, has become a new trend in modern NLP research. We show one such example in the Fig.  9  which illustrates the latent commonsense concepts that humans easily infer or discover given a situation. In particular, the present scenario informs that David is a good cook and will be making pasta for some people. Based on this information, commonsense can be employed to infer related events such as, dough for the pasta would be available, people would eat food (pasta), the pasta is expected to be good (David is good cook), etc. These inferences would enhance the text representation with many more concepts that can be utilized by neural systems in diverse downstream tasks.\n\nDavid is a good cook.\n\nHe will be making pasta for us today.\n\ndough_available people_eat good_pasta Fig.  9 : An illustration of commonsense reasoning and inference.\n\nIn the context of sentiment analysis, utilizing commonsense for associating aspects with their sentiments can be highly beneficial for this task. Commonsense knowledge graphs connect the aspects to various sentiment-bearing concepts via semantic links  (Ma et al., 2018) . Additionally, semantic links between words can be utilized to mine associations between the opinion target and the opinionbearing word. What is the best way to grasp commonsense knowledge is still an open research question.\n\nCommonsense knowledge is also required to understand 1) You liked it? You really liked it?\n\n2) Oh, yeah!\n\n3) Which part exactly?\n\n4) The whole thing! Can we go?\n\n5) What about the scene with the kangaroo?\n\n6) I was surprised to see a kangaroo in a world war epic. implicit sentiment of the sentences that do not accommodate any explicit sentiment marker. E.g., the sentiment of the speaker in this sentence, \"We have not seen the sun since last week\" is negative as not catching the sight of the sun for a long time is generally treated as a negative event in our society. A system not adhering to this commonsense knowledge would fail to detect the underlying sentiment of such sentences correctly.\n\nWith the advent of commonsense modeling algorithms such as Comet  (Bosselut et al., 2019) , we think, there will be a new wave of research focusing on the role of commonsense knowledge in sentiment analysis in the near future.",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Sentiment Reasoning",
      "text": "Apart from exploring the what, we should also explore the who and why. Here, the who detects the entity whose sentiment is being determined, whereas why reveals the stimulus/reason for the sentiment.",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Who? The Opinion Holder",
      "text": "While analyzing opinionated text, it is often important to know the opinion holder. In most cases, the opinion holder is the person who spoke/wrote the sentence. Yet, there can be situations where the opinion holder is an entity (or entities) mentioned in the text  (Mohammad, 2017) . Consider the following two lines of opinionated text: a. The movie was too slow and boring. b. Stella found the movie to be slow and boring. In both the sentences above, the sentiment attached to the movie is negative. However, the opinion holder for the first sentence is the speaker while in the second sentence it is Stella. The task could be further complex with the need to map varied usage of the same entity term (e.g. Jonathan, John) or the use of pronouns (he, she, they)  (Liu, 2012) .\n\nMany works have studied the task of opinion-holder identification -a subtask of opinion extraction (opinion holder, opinion phrase, and opinion target identification). These works include approaches that use named-entity recognition  (Kim & Hovy, 2004) , parsing and ranking candidates  (Kim & Hovy, 2006) , semantic role labeling  (Wiegand & Ruppenhofer, 2015) , structured prediction using CRFs  (Choi et al., 2006) , multi-tasking  (Yang & Cardie, 2013) , amongst others. The MPQA corpus  (Deng & Wiebe, 2015)  provided supervised annotations for this task. However, for deep learning approaches, this topic has been understudied  (Zhang et al., 2019a; Quan et al., 2019) .",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Why? The Sentiment Stimulus",
      "text": "The majority of the sentiment analysis research works to date are about classifying contents into positive, negative, and neutral and till date, only a little attention has been paid to sentiment cause identification. Future research in sentiment analysis should focus on what drives a person to express positive or negative sentiment on a topic or aspect.\n\nTo reason about a particular sentiment of an opinionholder, it is important to understand the target of the sentiment  (Deng & Wiebe, 2014) , and whether there are implications of holding such sentiment. For instance, when stating \"I am sorry that John Doe went to prison.\", understanding the target of the sentiment in the phrase \"John Doe goes to prison\", and knowing that \"go to prison\" has negative implications on the target, implies positive sentiment toward John Doe. 6  Moreover, it is important to understand what caused the sentiment. Although in this example, it is straightforward to conclude that \"go to prison\" is the reason of the expressed negative expression. One can also infer new knowledge from this simplified reasoning -\"go to prison\" is a negative event. This sentiment knowledge discovery can further help to enrich phrase-level sentiment lexicons.\n\nThe ability to reason is necessary for any explainable AI system. In the context of sentiment analysis, it is often desired to understand the cause of an expressed sentiment 6. Example provided by Jan Wiebe (2016), personal communication. by the speaker. E.g., consider a review on a smartphone, \"I hate the touchscreen as it freezes after 2-3 touches\". While it is critical to detect the negative sentiment expressed on touchscreen, digging into the detail that causes this sentiment is also of prime importance  (Liu, 2012) , which in this case is implied by the phrase \"freezes after 2-3 touches\". To date, there is not much work exploring this aspect of the sentiment analysis research.  Li & Hovy (2017)  discuss two possible reasons that give rise to opinions. Firstly, an opinion-holder might have an emotional bias towards the entity/topic in question. Secondly, the sentiment could be borne out of mental (dis)satisfaction towards a goal achievement.\n\nGrasping the cause of sentiment is also very important in dialogue systems. As an example, we can refer to Figure  10 , where Joey expresses anger once he ascertains Chandler's deception in the previous utterance.\n\nIt is hard to define a taxonomy or tagset for the reasoning of both emotions and sentiments. At present, there is no available dataset that contains such rich annotations. Building such a dataset would enable future dialogue systems to frame meaningful argumentation logic and discourse structure, taking one step closer to human-like conversation.",
      "page_start": 11,
      "page_end": 12
    },
    {
      "section_name": "Domain Adaptation",
      "text": "Most of the state-of-the-art sentiment analysis models enjoy the privilege of having in-domain training datasets. However, this is not a viable scenario, as curating large amounts of training data for every domain is impractical. Domain adaptation in sentiment analysis solves this problem by learning the characteristics of the unseen domain. Sentiment classification, in fact, is known to be sensitive towards domains as mode of expressing opinions across domains vary. Also, valence of affective words may vary based on different domains  (Liu, 2012) .\n\nDiverse approaches have been proposed for cross-domain sentiment analysis. One line of work models domaindependent word embeddings  (Sarma et al., 2018; Shi et al., 2018; K Sarma et al., 2019)  or domain-specific sentiment lexicons  (Hamilton et al., 2016) , while others attempt to learn representations based on either co-occurrences of domainspecific with domain-independent terms (pivots)  (Blitzer et al., 2007; Pan et al., 2010; Ziser & Reichart, 2018; Sharma et al., 2018)  or shared representations using deep networks  (Glorot et al., 2011) .\n\nOne of the major breakthroughs in domain adaptation research employs adversarial learning that trains to fool a domain discriminator by learning domain-invariant representations  (Ganin et al., 2016) . In this work, the authors utilize bag of words as the input features to the network. Incorporating bag of words limits the network to access any external knowledge about the unseen words of the target domain. Hence, the performance improvement can be completely attributed to the efficacy of the adversarial network. However, in recent works, researchers tend to utilize distributed word representations such as Glove, BERT. These representations, aka word embeddings, are usually trained on huge open-domain corpora and consequently contain domain invariant information. Future research should explain whether the gain in domain adaptation performance comes from these word embeddings or the core network architecture. In summary, the works in domain adaptation lean towards outshining the state of the art on benchmark datasets. What remains to be seen is the interpretability of these methods. Although some works claim to learn the domaindependent sentiment orientation of the words during domain invariant training, there is barely any well-defined analysis to validate such claims.",
      "page_start": 12,
      "page_end": 13
    },
    {
      "section_name": "Use Of External Knowledge",
      "text": "The key idea that most of the existing works encapsulate is to learn domain-invariant shared representations as a means to domain adaptation. While global or contextual word embeddings have shown their efficacy in modeling domain-invariant and specific representations, it might be a good idea to couple these embeddings with multi-relational external knowledge graphs for domain adaptation. Multirelation knowledge graphs represent semantic relations between concepts. Hence, they can contain complementary information over the word embeddings, such as Glove, since these embeddings are not trained on explicit semantic relations. Semantic knowledge graphs can establish relationships between domain-specific concepts of several domains using domain-general concepts -providing vital information that can be exploited for domain adaptation. One such example is presented in Fig.  11 . Researchers are encouraged to read these early works  (Alam et al., 2018; Xiang et al., 2010)  on exploiting external knowledge for domain adaptation.",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Scaling Up To Many Domains",
      "text": "Most of the present works in this area use the setup of a source and target domain pair for training. Although appealing, this setup requires retraining as and when the target domain changes. The recent literature in domain adaptation goes beyond single-source-target  (Zhao et al., 2018a)  to multisource and multi-target  (Gholami et al., 2020b,a)  training. However, in sentiment analysis, these setups have not been fully explored and deserve more attention  (Wu & Huang, 2016) .",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Multilingual Sentiment Analysis",
      "text": "The majority of sentiment analysis research has been conducted on English datasets. However, the advent of social media platforms has made multilingual content available via platforms such as Facebook and Twitter. Consequently, there is a recent surge in works with diverse languages  (Dashtipour et al., 2016) . The NLP community, in general, is now also vocal to promote research on languages other than English. 7  In the context of sentiment analysis, despite the recent surge in multilingual sentiment analysis, several directions need more traction: 3.6.1 Language-Specific Lexicons Today's rule-based sentiment analysis system, such as Vader, works great for the English language, thanks to the availability of resources like sentiment lexicons. For other languages such as Hindi, French, Arabic, not many wellcurated lexicons are available.",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Sentiment Analysis Of Code-Mixed Data",
      "text": "In many cultures, people on social media post content that are a mix of multiple languages  (Lal et al., 2019; Guptha et al., 2020; Gambäck & Das, 2016) . For example, \"Itna izzat diye aapne mujhe !!! Tears of joy. :'( :'(\", in this sentence, the bold text is in Hindi with roman orthography, and the rest is in English. Code-mixing poses a significant challenge to the rule-and deep learning-based methods. A possible future work to combat this challenge would be to develop language models on code-mixed data. How and where to mix languages is a person's own choice, one of the main hardships. Another critical challenge associated with this task is identifying the deep compositional semantic that lies in the code mixed data. Unfortunately, only a little research has been carried out on this topic  (Lal et al., 2019; Joshi et al., 2016) .",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "Machine Translation As A Solution To Multilingual Sentiment Analysis",
      "text": "Can machine translation be used as a solution to multilingual or cross-lingual sentiment analysis? Recently, several papers  Saadany & Orasan (2020) ;  Balamurali et al. (2013)  have attempted this problem.  Saadany & Orasan (2020)  claim that the associated sentiment is not preserved for contronyms, negations, diacritic, and idiomatic expressions when translated from Arabic to English. One solution to tackle this problem, as proposed by  Saadany & Orasan (2020) , is integrating sentiment information in the encoding stage in a machine translation system. However, this research has yet to witness much research attention.",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "Sarcasm Analysis",
      "text": "The study of sarcasm analysis is highly integral to the development of sentiment analysis due to its prevalence in opinionated text  (Maynard & Greenwood, 2014; Majumder et al., 2019b) . Detecting sarcasm is highly challenging due to the figurative nature of text, which is accompanied by nuances and implicit meanings  (Jorgensen et al., 1984) . Over recent years, this research field has established itself as an important problem in NLP with many works proposing different 7. Because of a now widely known statement made by Professor Emily M.Bender on Twitter, we now use the term #BenderRule to require that the language addressed by research projects by explicitly stated, even when that language is English https://bit.ly/3aIqS0C • Text : suggests a compliment.\n\n• Audio : neutral tone.\n\n• Video : straight face.",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "2)",
      "text": "Fig.  12 : Incongruent modalities in sarcasm present in the MUStARD dataset  (Castro et al., 2019) . solutions to address this task  (Joshi et al., 2017b) . Broadly, the main contributions have emerged from the speech and text communities. In speech, existing works leverage different signals such as prosodic cues  (Bryant, 2010; Woodland & Voyer, 2011) , acoustic features including low-level descriptors, and spectral features  (Cheang & Pell, 2008) . Whereas in textual systems, traditional approaches consider rule-based  (Khattri et al., 2015)  or statistical patterns (González-Ibá ñez et al., 2011b), stylistic patterns  (Tsur et al., 2010) , incongruity  (Joshi et al., 2015; Tay et al., 2018a) , situational disparity  (Riloff et al., 2013) , and hashtags  (Maynard & Greenwood, 2014) . While stylistic patterns, incongruity, and valence shifters are some of the ways humans use to express sarcasm, it is also highly contextual. In addition, sarcasm also depends on a person's personality, intellect, and the ability to reason over commonsense. In the literature, these aspects of sarcasm remain under-explored.",
      "page_start": 14,
      "page_end": 14
    },
    {
      "section_name": "Leveraging Context In Sarcasm Detection",
      "text": "Although the research for sarcasm analysis has primarily dealt with analyzing the sentence at hand, recent trends have started to acquire contextual understanding by looking beyond the text. Similar to sentiment analysis ( Sections 3.2 and 3.3), sarcasm detection can benefit with contextual cues provided by conversation histories, author tendencies, and multimodality.\n\nUser Profiling and Conversational Context: Two types of contextual information have been explored for providing additional cues to detect sarcasm: authorial context and conversational context. Leveraging authorial context delves with analyzing the author's sarcastic tendencies (user profiling) by looking at their historical and meta data  (Bamman & Smith, 2015; Hazarika et al., 2018a) . Similarly, the conversational context uses the additional information acquired from surrounding utterances to determine whether a sentence is sarcastic  (Ghosh et al., 2018) . It is often found that sarcasm is apparent only when put into context over what was mentioned earlier. For example, when tasked to identify whether the sentence \"He sure played very well\" is sarcastic, it is imperative to look at prior statements in the conversation to reveal facts (\"The team lost yesterday\").\n\nMultimodal Context: We also identify multimodal signals to be important for sarcasm detection. Sarcasm is often expressed without linguistic markers, and instead, by using verbal and non-verbal cues. Change of tone, overemphasis on words, straight face, etc. are some such cues that indicate sarcasm. There have been very few works that adopt multimodal strategies to determine sarcasm  (Schifanella et al., 2016) .  Castro et al. (2019)  recently released a multimodal sarcasm detection dataset, MUStARD, that takes conversational context into account. Fig.  12  presents two cases from this dataset, where sarcasm is expressed through the incongruity between modalities. In the first case, the language modality indicates fear or anger. In contrast, the facial modality lacks any visible sign of anxiety that would agree with the textual modality. In the second case, the text is indicative of a compliment, but the vocal tonality and facial expressions show indifference. In both cases, the incongruity between modalities acts as a strong indicator of sarcasm. While useful, MUStARD contains only 500 odd instances, posing a significant challenge to training deep networks on this dataset.",
      "page_start": 13,
      "page_end": 14
    },
    {
      "section_name": "Annotation Challenges: Intended Vs. Perceived Sarcasm",
      "text": "Sarcasm is a highly subjective tool and poses significant challenges in curating annotations for supervised datasets. This difficulty is particularly evident in perceived sarcasm, where human annotators are employed to label text as sarcastic or not. Sarcasm recognition is known to be a difficult task for humans due to its reliance on pragmatic factors such as common ground  (Clark, 1996) . This difficulty is also observed through the low annotator agreements across the datasets curated for perceived sarcasm  (González-Ibá ñez et al., 2011a; Castro et al., 2019) . To combat such perceptual subjectivity, recent emotion analysis approaches utilize perceptual uncertainty in their modeling  (Zhang et al., 2018b; Gui et al., 2017; Han et al., 2017) .\n\nIn our experience of curating a multimodal sarcasm detection dataset  (Castro et al., 2019) , we observed poor annotation quality, which occurred mainly due to the hardships associated with this task.  Hovy et al. (2013)  noticed that people undertaking such tasks remotely online are often guilty of spamming, or providing careless or random responses.\n\nOne solution to this problem is to rely on self annotated data collection. While convenient, obtaining labeled data from hashtags has been found to introduce both noise (incorrectly-labeled examples) and bias (only certain forms of sarcasm are likely to be tagged  (Davidov et al., 2010) , and predominantly by certain types of Twitter users  (Bamman & Smith, 2015) ).\n\nRecently, Oprea & Magdy (2019) presented the iSarcasm dataset, which provides labels by the original writers for the sarcastic posts. This kind of annotation is promising as it circumvents the issues mentioned above while capturing the intended sarcasm. To address the issues stemmed from annotating perceived sarcasm, Best-Worst Scaling (MaxDiff/BWS)  (Kiritchenko & Mohammad, 2016c ) could be employed to alleviate the effect of subjectivity in annotations.\n\nBWS attempts to alleviate the ambiguity in annotations by asking annotators to compare rather than indicate. Thus, rather than identifying the presence of sarcasm or its intensity, BWS would ask annotators to choose the most sarcastic (best) and least sarcastic (worst) sentences from candidate 4-tuples -leading to easier and better decision making.  Kiritchenko & Mohammad (2016c)  shows that such comparisons can be converted into a ranked list of the items based on the property of interest, which in this case is perceived sarcasm.",
      "page_start": 14,
      "page_end": 14
    },
    {
      "section_name": "Target Identification In Sarcastic Text",
      "text": "Identifying the target of ridicule within a sarcastic texta new concept recently introduced by Joshi et al. (  2018 )has important applications. It can help chat-based systems better understand user frustration and help ABSA tasks assign the sarcastic intent with the correct target in general. Though similar, there are differences from the vanilla aspect extraction task (Section 3.1) as the text might contain multiple aspects/entities with only a subset being a sarcastic target  (Patro et al., 2019) . When expressing sarcasm, people tend not to use the target of ridicule explicitly, which makes this task immensely challenging to combat.",
      "page_start": 14,
      "page_end": 14
    },
    {
      "section_name": "Style Transfer Between Sarcastic And Literal Meaning",
      "text": "Figurative to Literal Meaning Conversion: Converting a sentence from its figurative meaning to its honest and literal form is an exciting application. It involves taking a sarcastic sentence such as \"I loved sweating under the sun the whole day\" to \"I hated sweating under the sun the whole day\". It has the potential to aid opinion mining, sentiment analysis, and summarization systems. These systems are often trained to analyze the literal semantics, and such a conversion would allow for accurate processing. Present approaches include converting a full sentence using monolingual machine translation techniques  (Peled & Reichart, 2017) , and also word-level analysis, where target words are disambiguated into their sarcastic or literal meaning  (Ghosh et al., 2015) . This application could also help in 1) performing data augmentation and 2) generating adversarial examples as both the forms (sarcastic and literal) convey the same meaning but with different lexical forms.\n\nGenerating Sarcasm from Non-Figurative Sentences: The ability to generate sarcastic sentences is an important yardstick in the development of NLG. The goal of building socially-relevant and engaging, interactive systems demand such creativity. Sarcastic content generation can also benefit content/media generation that finds applications in fields like advertisements.  Mishra et al. (2019b)  recently proposed a modular approach to generate sarcastic text from negative sentiment-aware scenarios. End-to-end counterparts to this approach have not been well studied yet. Also, most of the works here rely on a particular type of sarcasmone which involves incongruities within the sentence. The generation of other flavors of sarcasm (as mentioned before) has not been yet studied. Recently,  Chakrabarty et al. (2020)  proposed a retrieval-based method that focuses on some of the points raised above, indicating the promise of research in this direction.",
      "page_start": 15,
      "page_end": 15
    },
    {
      "section_name": "Sentiment And Creative Language",
      "text": "While the above discussion is focused on sarcasm analysis, other forms of creative language tools, such as irony, humor, etc. also have co-dependence with sentiment analysis. Irony is more generic than sarcasm as it used to mean the opposite of what is being said, whereas sarcasm has an intent to criticize. Previous works have utilized sentiment information for detecting irony  Farías et al. (2015) . However, compared to sarcasm, research utilizing sentiment-irony relationships has been scanty. Humor is another tool that is often used in human language. Identifying humor also has deep ties with sentiment analysis. Multiple works mention that detecting humor often relies on mining the sentimental relations between the setup and the corresponding punchline  Liu et al. (2018) ;  Hasan et al. (2019) ;  Zhang et al. (2019b) . Recent works also reveal that architectures developed for sentiment analysis perform similarly for tasks related to humor prediction  Hazarika et al. (2020) . Looking at the reverse, some works demonstrate that knowing humor, sarcasm, etc. aids in making sentiment analysis systems more robust  Badlani et al. (2019) . The above points indicate the relationships between sentiment analysis with creative language, thus opening whole new doors for research  Majumder et al. (2019b) .",
      "page_start": 15,
      "page_end": 15
    },
    {
      "section_name": "Sentiment-Aware Natural Language Generation (Nlg)",
      "text": "Language generation is considered one of the major components of the field of NLP. Historically, the focus of statistical language models has been to create syntactically coherent text using architectures such as n-grams models  (Stolcke, 2002)  or auto-regressive recurrent architectures  (Bengio et al., 2003; Mikolov et al., 2010; Sundermeyer et al., 2012) . These generative models have important applications in areas including representation learning, dialogue systems, amongst others. However, present-day models are not trained to produce affective content that can emulate human communication. Such abilities are desirable in many applications such as comment/review generation  (Dong et al., 2017) , and emotional chatbots  (Zhou et al., 2018; Ma et al., 2020) .\n\nEarly efforts in this direction included works that either focused on related topics such as personality-conditioned text generation  (Mairesse & Walker, 2007)  or pattern-based approaches for the generation of emotional sentences  (Keshtkar & Inkpen, 2011) . These works were significantly pipe-lined with specific modules for sentence structure and content planning, followed by surface realization. Such sequential modules allowed constraints to be defined based on personality/emotional traits, which were mapped to sentential parameters that include sentence length, vocabulary usage, or part-of-speech (POS) dependencies. Needless to say, such efforts, though well-defined, are not scalable to general scenarios and cross-domain settings.",
      "page_start": 15,
      "page_end": 16
    },
    {
      "section_name": "Conditional Generative Models",
      "text": "We, human beings, count on several variables such as emotion, sentiment, prior assumptions, intent, or personality to participate in dialogues and monologues. In other words, these variables control the language that we generate. Hence, it is outrageous to claim that a vanilla seq2seq framework can generate near perfect natural language. Recently, conditional generative models have been developed to address this task. Conditioning on attributes, such as, sentiment can be approached in several ways. One way is by learning disentangled representations, where the key idea is to separate the textual content from high-level attributes, such as, sentiment and tense in the hidden latent code. Present approaches utilize generative models such as VAEs  (Hu et al., 2017) , GANs  (Wang & Wan, 2018)  or Seq2Seq models  (Radford et al., 2017) . Learning disentangled representations is presently an open area of research. Enforcing independence of factors in the latent representation and presenting quantitative metrics to evaluate the factored hidden code are some of the challenges associated with these models.\n\nAn alternate method is to pose the problem as an attributeto-text translation task  (Dong et al., 2017; Zang & Wan, 2017) . In this setup, desired attributes are encoded into hidden states which condition upon a decoder tasked to generate the desired text. The attributes could include user's preferences (including historical text), descriptive phrases (e.g. product description for reviews), and sentiment. Similar to general translation tasks, this approach demands parallel data and raises generalization challenges, such as, cross-domain generalization. Moreover, the attributes might not be available in the desired formats. As mentioned, attributes might be embedded in conversational histories, which would require sophisticated NLU capabilities similar to the ones used in task-oriented dialogue bots. They might also be in the form of structured data, such as Wikipedia tables or knowledge graphs, tasked to be translated into textual descriptions, i.e., data-to-text -an open area of research  (Mishra et al., 2019a) .\n\n3.8.1.1 Our conceptual conditional generative model: In Fig.  13 , we illustrate a dialogue-generation mechanism that leverages these key variables. In this illustration, P represents the personality of the speaker; S represents the speaker-state; I denotes the intent of the speaker; E refers to the speaker's emotional-aware state, and U refers to the observed utterances. The definitions of these variables are as given below:\n\nTopic: Topic is a key element that governs and drives a conversation. Without knowing the topical information, dialogue understanding can be incomplete and vague.",
      "page_start": 15,
      "page_end": 15
    },
    {
      "section_name": "Personality (P ):",
      "text": "As per the standard definition of personality, this variable controls the basic behavior of a person under varied circumstances. Personality can also signify different dimensions, such as, values, needs, goals, agency, and more, according to the theory of appraisals  (Ellsworth & Scherer, 2003)  in affective computing.\n\nObserved conversational history (U ): The observed utterances in the conversational history are represented as U . U provides contextual information and play a critical role in constructing other states such as S and I.\n\nBackground knowledge (B): Background knowledge represents the prior assumptions, pre-existing inter-speaker relations, speaker's knowledge and opinion about the topic and any other background or external information that are not explicitly present in the conversational history. Such knowledge usually evolves over time depending on how the speaker experiences the environment and interacts with it.\n\nSpeaker-state (S): Speaker-state can be defined as the latent memory of a speaker that evolves over the turns in the conversation. This memory contains the information\n\nVariables external to the interlocutors (a) obtained through the process of cognition and thinking. For example, let us consider this conversation: A (excited and happy): You know I am getting married! B (excited and happy): Wow! that's great news. Who is that lucky person? When is the ceremony?\n\nIn this conversation, person B listens to person A (refer to variable U in Fig.  13 ) and applies cognition and thinking to construct a latent memory which we call as S. S can also rely on the background knowledge B.\n\nIntent (I): Intent defines the goal that the speaker wants to achieve in the conversation. Intent can be triggered after cognition and thinking i.e., S.\n\nIn the above example, it is obvious that the intent of person B (i.e., intention to know who is person A marrying and the date of the ceremony) is governed by his/her cognition after hearing the statement by person A. Intent can heavily rely on the personality of the speaker.\n\nExternal and sensory inputs (Q): In the process of a conversation, certain sensory or other external events can directly initiate cognition and affect. We call these inputs as Q. These inputs can often be non-verbal cues. Affective reactions to these sensory inputs can occur with or without any complex cognitive modeling. When the stimulus is sudden and unexpected, the affective reaction can occur before evaluating and appraising the situation through cognitive modeling. This is called Affective Primacy  (Zajonc, 1980) . For example, our immediate reaction when we encounter an unknown creature in the jungle without evaluating whether it is safe or dangerous. Sensory inputs Q can also trigger cognitive modeling for subsequent evaluation of the situation and thus can update the latent speaker-state S.\n\nEmotional-aware state (E): Emotional-aware state encodes the emotion of the speaker at time t. As proposed by the psychology theorist Lazarus in his article  (Lazarus, 1982) , the emotional-state can be triggered by cognition and thinking, we think in a conversation, this state should be controlled by S and I. If we refer to the same example above, the expressed emotion by person B depends on the speaker-state S and intent I. According to the theory of affective primacy by  (Zajonc, 1980) , the affective or emotional state does not always depend on cognition, and in various situations, an affective response can be spontaneous without relying on any prior cognitive evaluation of the situation e.g., we fear when we encounter a snake, our eyes blink when we are exposed to sudden bright light source. Based on this theory, the state E may not always depend on S and I. In the case of affective primacy, affect directly depends on the sensory or external inputs, i.e., Q which are very important in multimodal conversations.\n\nThe workflow: At turn t, the speaker conceives several pragmatic concepts, such as argumentation logic, viewpoint, personality, conversational history, emotion coding sequence of the interlocutors in the conversation and inter-personal relationships-which can collectively construct the latent speaker-state S  (Hovy, 1987)  by the means of cognition. Next, the intent I of the speaker is formulated based on the current speaker-state, personality and previous intent of the same speaker (at t -2). Personality P , speaker-state S, intent I and external or sensory inputs Q can jointly influence the emotion E of the speaker. Finally, the intent, the speaker state, and the speaker's emotion jointly manifest as the spoken utterance.\n\n3.8.1.2 Aspect-level text summarization: One application of conditional generative models is aspect-level text summarization( Fig.  14 ). Aspect-level text summarization task consists of two stages: aspect extraction and aspect summarization. The first stage distills all the aspects discussed in the input text. The latter generates an abstractive or extractive gist of the extracted aspects from the source text. In the case of abstractive gist, the model generates content conditioned on the given aspect. Existing works  (Frermann & Klementiev, 2019)  address this task by leveraging aspect-level document segmentation and use that to generate both abstractive and extractive aspect-level summaries.",
      "page_start": 16,
      "page_end": 16
    },
    {
      "section_name": "Aspect Extraction Input",
      "text": "Dear Manager, I would like to convey to you the state of the water supply and pest problem around the trash chute.\n\nThe water pressure is significantly low during the morning (7 -9 AM), which is inconvenient for us commuters. Also, we noticed rats around trash chute outlet, which can lead to degradation of health and sanctity of our community.\n\nWe appreciate your service to our community.",
      "page_start": 17,
      "page_end": 17
    },
    {
      "section_name": "Thank You, Resident",
      "text": "Dear Manager, I would like to convey to you the state of the water supply and pest problem around the trash chute.\n\nThe water pressure is significantly low during the morning (7 -9 AM), which is inconvenient for us commuters. Also, we noticed rats around trash chute outlet, which can lead to degradation of health and sanctity of our community.\n\nWe appreciate your service to our community.",
      "page_start": 18,
      "page_end": 18
    },
    {
      "section_name": "Thank You, Resident",
      "text": "",
      "page_start": 18,
      "page_end": 18
    },
    {
      "section_name": "Aspect-Level Summarization",
      "text": "๏Water Pressure: From 7 to 9 AM, the water pressure is low ๏Trash Chute Outlet: It is infested with rats ๏Service: People are happy about the service Fig.  14 : Aspect-level text summarization: an application of conditional generative modeling.",
      "page_start": 19,
      "page_end": 19
    },
    {
      "section_name": "Sentiment-Aware Dialogue Generation",
      "text": "The area of affect-controlled text has also percolated into dialogue systems. The aim here is to equip emotional intelligence into these systems to improve user interest and engagement  (Partala & Surakka, 2004; Prendinger & Ishizuka, 2005) . Two key functionalities are important to achieve this goal  (Hasegawa et al., 2013) :\n\n1) Given a user query, determine the best emotional/sentiment response adhering to social rules of conversations. 2) Generate the response eliciting that emotion/sentiment.\n\nPresent works in this field either approach these two sub-problems independently  (Ghosh et al., 2017)  or in a joint manner  (Gu et al., 2019) . The proposed models range over various approaches, which include affective language models  (Ghosh et al., 2017)  or seq2seq models customized to generate emotionally-conditioned text  (Zhou et al., 2018; Asghar et al., 2018) .  Kong et al. (2019)  take an adversarial approach to generate sentiment-aware responses in the dialogue setup conditioned on sentiment labels. For a brief review of some of the recent works in this area, available corpora and evaluation metrics, please refer to  Pamungkas (2019) .\n\nDespite the recent surge of interest in this application, there remains significant work to be done to achieve robust emotional dialogue models. Upon trying various emotional response generation models such as ECM  (Zhou et al., 2018) , we surmise, these models lack the ability of conversational emotion recognition and tend to generate generic, emotionally incoherent responses. Better emotion modeling is required to improve contextual emotional understanding  (Hazarika et al., 2018b) , followed by emotional anticipation strategies for the response generation. These strategies could be optimized to steer the conversation towards a particular emotion  (Lubis et al., 2018)  or be flexible by proposing appropriate emotional categories. The quest for better text with diversity and coherence and fine-grained control over emotional intensity are still open problems for the generation stage. Also, automatic evaluation is a notorious problem that has plagued all applications of dialogue models.\n\nTo this end, following the work by  Hovy (1987) , we illustrate a sentiment and emotion-aware dialogue generation framework in Figure  13  that can be considered as the basis of future research. The model incorporates several cognitive variables, i.e., intent, sentiment, and interlocutor's latent state for coherent dialogue generation.",
      "page_start": 17,
      "page_end": 18
    },
    {
      "section_name": "Sentiment-Aware Style Transfer",
      "text": "Style transfer of sentiment is a new area of research. It focuses on flipping the sentiment of sentences by deleting or inserting new sentiment-bearing words. E.g., to change the sentiment of \"The chicken was delicious\", we need to find a replacement of the word delicious that carries negative sentiment.\n\nRecent methods on sentiment-aware style transfer attempt to disentangle sentiment bearing contents from other non-sentiment bearing parts in the text by relying on rulebased  (Li et al., 2018)  and adversarial learning-based  (John et al., 2019)  techniques.\n\nAdversarial learning-based methods to sentiment style transfer suffer from the lack of available parallel corpora, which opens the door to a potential future work. Some initial works, such as  (Shen et al., 2017) , address non-parallel style transfer, albeit with strict model assumptions. We also think this research area should be studied together with the ABSA (aspect-based sentiment analysis) research to learn the association between topics/aspects and sentiment words. Considering the example above, learning better association between topics/aspects and opinionated words should aid a system to substitute delicious with unpalatable instead of another negative word rude.",
      "page_start": 17,
      "page_end": 17
    },
    {
      "section_name": "Bias In Sentiment Analysis Systems",
      "text": "Fairness in machine learning has gained much traction recently. Amongst multiple proposed definitions of fairness, we particularly look into ones that attempt to avoid disparate treatment and thus reduce the disparate impact across demographics. This requires removing bias that favors a subset of the population with an unfair advantage.\n\nStudying fairness in sentiment analysis is crucial, as diverse demographics often share the derived commercial systems. Sentiment analysis systems are often used in sensitive areas, such as healthcare, which deals with sensitive topics like counseling. Customer calls and marketing leads, from various backgrounds, are often screened for sentiment cues, and the acquired analytics drives major decisionmaking. Thus, understanding the presence of harmful bias is critical. Unfortunately, the field is at its nascent stage and has received minimal attention. However, some developments have been observed in this area, which opens up numerous research directions.\n\nWhile there can be different demographics, such as gender, race, age, etc., our subsequent discussions, without any loss of generality, primarily exemplify gender biases.\n\n3.9.1 Identifying Causes of Bias in Sentiment Analysis Systems Bias can be introduced into the sentiment analysis models through three main sources:\n\n1) Bias in word embeddings: Word embeddings are often trained on publicly available sources of text, such as Wikipedia. However, a survey by  Collier & Bear (2012)  found that less than 15% of contributions to Wikipedia come from women. Therefore, the resultant word embeddings would naturally under-represent women's point of view. 2) Bias in the model architecture: Sentiment-analysis systems often use meta information, such as gender identifiers and indicators of demographics that include age, race, nationality, and geographical cues. Twitter sentiment analysis is one such application where conditioning on these variables is prevalent  (Mitchell et al., 2013; Vosoughi et al., 2015; Volkova et al., 2013) . Though helpful, such design choices can often lead to various forms of bias such as gender bias, geographic (location) bias, etc. from theses conditioned variables. These model architectures can further amplify the bias observed in the training data. Sentiment intensity of a word or phrase can be interpreted differently across geographical demographics. For example, the general perception about good weather, good traffic, cheap phone can vary among the Indian and American populations. Hence, training a sentiment model on data originating from one geographic location can expose the model to demographic bias when applied to data from other locations. Thus, depending on the end application and region of interest, a cogent solution to this issue could be to develop demographicspecific sentiment analysis models rather than creating a generic one. However, as data is often a combination of multiple demographic classes -e.g. a combination of various ages, genders, and locations, etc. -building mutually exclusive demographic-based models would be computationally prohibitive. Nevertheless, research in domain adaptation is one possible avenue towards solving this problem as it would help adapting a trained sentiment model on a source demographic data to learn the features of the target demography. 3) Bias in the training data: There are different scenarios where a sentiment-analysis system can inherit bias from its training data. These include highly frequent co-occurrence of a sentiment phrase with a particular gender -for example, woman co-occurring with nasty -, over-or under-representation of a particular gender within the training samples, strong correlation between a particular demographic and sentiment label -for instance, samples from female subjects frequently belonging to positive sentiment category. An author's stylistic sense of writing can also be one of the many sources of bias in sentiment systems. E.g., one person uses strong sentiment words to express a positive opinion but prefers to use milder sentiment words in exhibiting negative opinions. Similarly, sentiment expression might vary across races and genders, e.g., as shown in a recent study by  Bhardwaj et al. (2020) . As a result, a sentiment analysis model might show a drastic difference in the sentiment intensities when the gender word in the same sentence is changed from masculine to feminine or vice versa, making the task of identifying bias and de-biasing difficult.",
      "page_start": 17,
      "page_end": 17
    },
    {
      "section_name": "Evaluating Bias",
      "text": "Recent works present corpora that curate examples, specifically to evaluate the existence of bias. The Equity Evaluation Corpus (EEC)  (Kiritchenko & Mohammad, 2018)  is one such example that focuses on finding gender and racial bias. The sentences in this corpus are generated using simple templates, such as \"<Person> made me feel <emotional state word>\", \"<Person> feels angry\". The variable <Person> can be a female name such as \"Jasmine\", or a male name such as \"Alan\". A pretrained sentiment or emotion intensity predictor is then tasked to predict the emotion and sentiment intensity of the sentences. According to the task setting, a model can be called gender-biased when it consistently or significantly predicts higher or lower sentiment intensity scores for sentences carrying female-names than male-names, or vice versa. The EEC corpus contains 7 templates of type: <Person> and <emotional state word>. The placeholder <Person> can be filled by any of 60 gender-specific names or phrases. Out of those 60 gender-specific names, 40 are genderspecific names (20-female, 20-male). Rest 20 are noun phrases grouped as female-male pairs such as \"my mother\" and \"my father\". Variable <emotional state word> can take four emotions -Anger, Fear, Sadness, and Joy -each having 5 representative words 8 . Thus, there are 1200 (60 × 5 × 4) samples for each template. Finally, there are 8400 (7 × 1200) samples equally divided in female and male-specific sentences (60 × (5 × 4) × 7 = 4200 each) and 4 emotion categories (5 × 7 × 60 = 2100 each). We refer readers to  Kiritchenko & Mohammad (2018)  for an elaborative explanation on the EEC corpus. While this is a good step, the work is limited to exploring bias that is related only to gender and race. Moreover, the templates utilized to create the examples might be too simplistic, and identifying such biases and de-biasing them might be relatively easy. Future work should design more complex cases that cover a wider range of scenarios. Challenge appears when we have scenarios like \"John told Monica that she lost her mental stability\" vs. \"John told Peter that he lost his mental stability\". If the sentiment polarity in either of these two sentences is predicted significantly different from the other, that would indicate a likely gender bias issue.",
      "page_start": 18,
      "page_end": 18
    },
    {
      "section_name": "De-Biasing",
      "text": "If a model shows the sign of bias because of the training data, one approach to curb this bias is to distill a subset that 8. e.g.,:-{angry, enraged} represents a common emotion, anger does not display any explicit indication of bias. However, often it is unfeasible to collate data meeting such constraints. Hence, it is the responsibility of researchers to come up with solutions that can de-bias any bias introduced by the training data and model architecture.\n\nThe primary approach to de-biasing is to perturb a text with word substitution to generate counterfactual cases in the training data. These generated instances can then be used to regularize the learning of the model, either by constraining the embedding spaces to be invariant to the perturbations or minimizing the difference in predictions between both the correct and perturbed instances. While recent approaches, such as  (Huang et al., 2019b) , have proposed these methods in language models, another direction could be to mask out bias contributing terms during training. However, such a method presents its own challenges since masking might cause semantic gaps.\n\nIn general, we observe that while many works demonstrate or discuss the existence of bias, and also propose bias detection techniques, there is a shortage of works that propose de-biasing approaches.\n\nExisting studies mostly focus on identifying genderbias in context-independent word representations such as GloVe  (Bolukbasi et al., 2016; Kaneko & Bollegala, 2019; Kumar et al., 2020) . Contrarily, BERT word-to-vector(s) mapping is highly context-dependent which makes it difficult to analyse biases intrinsic to BERT. While a lot has been studied, identified, and mitigated when it comes to genderbias in static word embeddings  (Bolukbasi et al., 2016; Zhao et al., 2018c; Caliskan et al., 2017; Zhao et al., 2018b) , very few recent works study gender-bias in contextualized settings. In  Zhao et al. (2019) ;  Basta et al. (2019) ;  Gonen & Goldberg (2019) , the authors apply debiasing on ELMo.  Kurita et al. (2019)  propose a template-based approach to quantify bias in BERT.  Sahlgren & Olsson (2019)  study bias in both contextualized and non-contextualized Swedish embeddings.\n\nApart from the traditional bias in models, bias can also exist at a higher level when making research choices. A simple example is the tendency of the community to resort to English-based corpora, primarily due to the notion of increased popularity and wider acceptance. Such trends diminish the research growth of marginalized topics and study of arguably more interesting languages -a gap which widens through time  (Hovy & Spruit, 2016) . As highlighted in Section 3.6, as a community, we should make conscious choices to help in the equality of under-represented communities within NLP and Sentiment Analysis.",
      "page_start": 18,
      "page_end": 19
    },
    {
      "section_name": "Conclusion",
      "text": "Sentiment analysis is often regarded as a simple classification task to categorize contents into positive, negative, and neutral sentiments. In contrast, the task of sentiment analysis is highly complex and governed by multiple variables like human motives, intents, contextual nuances. Disappointingly, these aspects of sentiment analysis remain either un-or under-explored.\n\nThrough this paper, we strove to diverge from the idea that sentiment analysis, as a field of research, has saturated. We argued against this fallacy by highlighting several open problems spanning across subtasks under the umbrella of sentiment analysis, such as aspect-level sentiment analysis, sarcasm analysis, multimodal sentiment analysis, sentimentaware dialogue generation, and others. Our goal was to debunk, through examples, the common misconceptions associated with sentiment analysis and shed light on several future research directions. We hope this work would help reinvigorate researchers and students to fall in love with this immensely interesting and exciting field, again.",
      "page_start": 19,
      "page_end": 19
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: shows that many benchmark datasets on the",
      "page": 1
    },
    {
      "caption": "Figure 1: also demonstrates that the methods with a",
      "page": 1
    },
    {
      "caption": "Figure 1: Performance trends of recent models on IMDB (Maas et al., 2011), SST-2, SST-5 (Socher et al., 2013) and Semeval (Pontiki",
      "page": 2
    },
    {
      "caption": "Figure 3: ) in the last two decades",
      "page": 2
    },
    {
      "caption": "Figure 2: We curate",
      "page": 2
    },
    {
      "caption": "Figure 2: ), on this repository: https://github.",
      "page": 2
    },
    {
      "caption": "Figure 2: The paper is logically divided into two sections. First, we analyze the past trends and where we stand today in",
      "page": 3
    },
    {
      "caption": "Figure 3: A non-exhaustive illustration of some of the milestones of sentiment analysis research.",
      "page": 5
    },
    {
      "caption": "Figure 1: , the recent works based on neural",
      "page": 5
    },
    {
      "caption": "Figure 4: presents one such example where a user is",
      "page": 6
    },
    {
      "caption": "Figure 5: Approaches to aspect-term auto-categorization are mostly",
      "page": 6
    },
    {
      "caption": "Figure 4: The example illustrates the various challenges and applications that holistic sentiment analysis depends on.",
      "page": 7
    },
    {
      "caption": "Figure 5: An example of the aspect term auto-categorization.",
      "page": 7
    },
    {
      "caption": "Figure 5: — with the surrounding words as context to obtain aspect",
      "page": 7
    },
    {
      "caption": "Figure 6: Importance of multimodal cues. Green shows primary",
      "page": 8
    },
    {
      "caption": "Figure 6: presents examples where the presence",
      "page": 8
    },
    {
      "caption": "Figure 6: , where each modality",
      "page": 8
    },
    {
      "caption": "Figure 8: explain this phenomenon.",
      "page": 9
    },
    {
      "caption": "Figure 8: Role of context in sentiment analysis in conversation.",
      "page": 10
    },
    {
      "caption": "Figure 9: which illustrates the",
      "page": 10
    },
    {
      "caption": "Figure 9: An illustration of commonsense reasoning and infer-",
      "page": 10
    },
    {
      "caption": "Figure 10: Sentiment cause analysis.",
      "page": 11
    },
    {
      "caption": "Figure 11: Domain-general term graphic bridges the semantic",
      "page": 12
    },
    {
      "caption": "Figure 11: Researchers are encouraged to read",
      "page": 12
    },
    {
      "caption": "Figure 12: Incongruent modalities in sarcasm present in the",
      "page": 13
    },
    {
      "caption": "Figure 12: presents two",
      "page": 14
    },
    {
      "caption": "Figure 13: , we illustrate a dialogue-generation mech-",
      "page": 15
    },
    {
      "caption": "Figure 13: Our proposed conceptual framework for conditional generative conversation modeling. A dyadic conversation",
      "page": 16
    },
    {
      "caption": "Figure 13: ) and applies cognition and thinking",
      "page": 16
    },
    {
      "caption": "Figure 14: ). Aspect-level text summarization",
      "page": 16
    },
    {
      "caption": "Figure 14: Aspect-level text summarization: an application of conditional generative modeling.",
      "page": 17
    },
    {
      "caption": "Figure 13: that can be considered as the basis",
      "page": 17
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "selur\ncigoL MTSL-SAC-iB egraL-TREB NND-TM TREBnaps aTREBoR TENLX B3-5T\nNNC-D1 +\nNTNR NNC\n93.794.694.895.6 96 96.796.897.197.4\n88.187.889.389.589.790.391.290.991.3\n85.4\nycaruccA\n2013 2014 2015 2016 2017 2018 2019\nSST-2": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": ".4"
        },
        {
          "selur\ncigoL MTSL-SAC-iB egraL-TREB NND-TM TREBnaps aTREBoR TENLX B3-5T\nNNC-D1 +\nNTNR NNC\n93.794.694.895.6 96 96.796.897.197.4\n88.187.889.389.589.790.391.290.991.3\n85.4\nycaruccA\n2013 2014 2015 2016 2017 2018 2019\nSST-2": "UCD\n75.\nycaruccA\n201",
          "Column_2": "",
          "Column_3": "ADA-TREB\nnon-neural neural\nTP-TREB\nnaC-CRN MTSL-EATA teNmeM NAGM\nMTSL-DT NNC-FP NABP NMI\nNAI EACG\n8\n81.5\n7175.31 76.5 75.3 74.6 77.6 78.8 79.6\n71.8 72.9 73.2",
          "Column_4": ""
        },
        {
          "selur\ncigoL MTSL-SAC-iB egraL-TREB NND-TM TREBnaps aTREBoR TENLX B3-5T\nNNC-D1 +\nNTNR NNC\n93.794.694.895.6 96 96.796.897.197.4\n88.187.889.389.589.790.391.290.991.3\n85.4\nycaruccA\n2013 2014 2015 2016 2017 2018 2019\nSST-2": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "4"
        },
        {
          "selur\ncigoL MTSL-SAC-iB egraL-TREB NND-TM TREBnaps aTREBoR TENLX B3-5T\nNNC-D1 +\nNTNR NNC\n93.794.694.895.6 96 96.796.897.197.4\n88.187.889.389.589.790.391.290.991.3\n85.4\nycaruccA\n2013 2014 2015 2016 2017 2018 2019\nSST-2": "",
          "Column_2": "",
          "Column_3": "4 2016 2018 2018 2019\nSemeval 2014 T4 SB2",
          "Column_4": ""
        },
        {
          "selur\ncigoL MTSL-SAC-iB egraL-TREB NND-TM TREBnaps aTREBoR TENLX B3-5T\nNNC-D1 +\nNTNR NNC\n93.794.694.895.6 96 96.796.897.197.4\n88.187.889.389.589.790.391.290.991.3\n85.4\nycaruccA\n2013 2014 2015 2016 2017 2018 2019\nSST-2": "",
          "Column_2": "",
          "Column_3": "11),SST-2,SST-5(Socheretal.,2013)andSemeval(Ponti\neitheraspectorsentencelevel.Note:Dataobtainedfro\nsonthegraphsareeithercitationsorsystemnamesth\nent-analysis.",
          "Column_4": ""
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "oMLE\nrahC+NCB\neVoC+\nNNC-D1 cipE -eerT MTSL + NCB -TREB\n53.7 53.6 54.7 55\n49.6 51\n.7 47.4"
        },
        {
          "Column_1": "13 2014 2014 2015 2016 2017 2018\n20"
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Optimistic Future:\nFuture Directions in\nSentiment Analysis\nAspect- Multimodal Contextual Sentiment Domain Multilingual Sarcasm Sentiment- Bias in\nbased SA SA SA Reasoning Adaptation SA Analysis aware NLG SA Systems\nAspect-term\ncategorization\nSA in Topical Sarcastic NLG\nImplicit ABSA Multimodal context text conditioned Cause of\nfusion Handle code generation on sentiment Bias\nJoint SA in Exploit switching\nasp p e o c la t r - i t t e y r m Qu d e a st t a o s f e l t a s rge Co a n l v c e o r n s t a e t x io t n- opin E o x n tr a h c o t l d er kn e o x w te l r e n d a g l e Create sa c D r o c e n a t t s e e m c x t t in aw S a e r n e t d im ia e lo n g t- ue Ev b a i l a u s ate\nextraction multilingual system\nle T a r A r a n B n i S s n f A g e r in F a i n n n e o -g ta ra ti i o n n e s d SA c c o u in n lt t u u e r s x a e t l r, mot o iv p F e i i n n b i d o e n h ind Scale to multi- S l e e n xi t c im on e s nt ann A ot d a d ti r o e n s s b ias a S w en a t r i e m s e t n y t le - S D M en e o t - i d b m e ia e ls s n t\ndomains preserving transfer\nModel Commonsense machine Find target of\ninter-aspect knowledge for translation sarcasm\nrelations SA\nNeed of large\ndatasets": "Fig. 2: The paper is logically divided into two sections. First, we analyze the past trends and where we stand today in\nhe sentiment analysis Literature. Next, we present an Optimistic peek into the future of sentiment analysis, where we"
        }
      ],
      "page": 3
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "Fig.4:Theexampleillustratesthevariouschallengesandapplicationsthatholisticsentimen\nPhone speaker’ssentimenttowardsthe\nbyDengetal.(2014),itiscalledas\nAsmostdatasetsarenotlabeled\ntrainedonpresentdatasetsmigh\naspecttermanditsassociatedpol\nScreen Processor Network\nopenproblemintheoverallABS\nsentimentisalsoobservedincon\nwhichwefurtherdiscussinSecti\nPanel Resolution Clock speed Cache 5G Signal quality\n3.1.3 AspectTerm-PolarityCo-\nFig.5:Anexampleoftheaspecttermauto-categorization.\nMost existing algorithms in thi\ntraction and aspect-level sentim\nbasedonsupervisedandunsupervisedtopicclassification (pipelined) or independent task\nandlexicondriven.Thesethreetypesofapproachessuccumb relationship between the tasks i\nto scalability issues when subjected to new domains with joint learning of these tasks h\nnovelaspectcategories.Webelievethatentitylinking-based cent trends. These include hie\napproaches,coupledwithsemanticgraphslikeProbase(Wu (Lakkaraju et al., 2014), multi-ta\net al., 2012), should be able to perform reasonably while and CRF-based approaches by f\novercoming scalability issues. For example, the sentence as sequence labeling problems\n“Withthisphone,Ialwayshaveahardtimegettingsignalindoors.” 2019).Thenotionofjointlearnin\ncontains one aspect term signal, that can be passed to an for exploring the relationships b",
          "Poriaetal.,BENEATHTHETIPOFTHEICEBERG:CURRENTCHALLENGESANDNEWDIRECTIONSINSENTIMENTANALYSISRESEARCH 7\nConversation Sentiment Analysis\nUser Bot\n[ABSA and sentiment reasoning]\nWhat airline service\nNever flying with that airline again.\nWho the user\nTheir service sucks. Such rude crew.\nWhy rude crew\nc\no\nn\n[domain adaptation] te\nx\nt\nAnd their seats were “les meilleurs du\n[sarcasm] What seats\nmonde” !!!\ntranslation: the best in the world\n[code-mixed sentiments]\nnegative\n(agreement with user)\nAww that sucks! That airline should\n[sentiment-aware NLG]\nbe grounded.\nFig.4:Theexampleillustratesthevariouschallengesandapplicationsthatholisticsentimentanalysisdependson.\nPhone speaker’ssentimenttowardsthebillispositive.Inthework\nbyDengetal.(2014),itiscalledasopinion-orientedimplicatures.": "Fig.4:Theexampleillustratesthevariouschallengesandapplicationsthatholisticsentimen\nPhone speaker’ssentimenttowardsthe\nbyDengetal.(2014),itiscalledas"
        }
      ],
      "page": 7
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "[sentiment-aware NLG]"
        }
      ],
      "page": 7
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "t - 1"
        }
      ],
      "page": 16
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "time t"
        }
      ],
      "page": 16
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "t + 1"
        }
      ],
      "page": 16
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "t - 1"
        }
      ],
      "page": 16
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "time t"
        }
      ],
      "page": 16
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "t + 1"
        }
      ],
      "page": 16
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Domain adaptation with adversarial training and graph embeddings",
      "authors": [
        "F Alam",
        "S Joty",
        "M Imran"
      ],
      "year": "2018",
      "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018"
    },
    {
      "citation_id": "2",
      "title": "Affective neural response generation",
      "authors": [
        "N Asghar",
        "P Poupart",
        "J Hoey",
        "X Jiang",
        "L Mou"
      ],
      "year": "2018",
      "venue": "European Conference on Information Retrieval"
    },
    {
      "citation_id": "3",
      "title": "An ensemble of humour, sarcasm, and hate speechfor sentiment classification in online reviews",
      "authors": [
        "R Badlani",
        "N Asnani",
        "M Rai"
      ],
      "year": "2019",
      "venue": "Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019)"
    },
    {
      "citation_id": "4",
      "title": "Lost in translation: viability of machine translation for cross language sentiment analysis",
      "authors": [
        "A Balamurali",
        "M Khapra",
        "P Bhattacharyya"
      ],
      "year": "2013",
      "venue": "International Conference on Intelligent Text Processing and Computational Linguistics"
    },
    {
      "citation_id": "5",
      "title": "Contextualized sarcasm detection on twitter",
      "authors": [
        "D Bamman",
        "N Smith"
      ],
      "year": "2015",
      "venue": "Proceedings of the Ninth International Conference on Web and Social Media, ICWSM 2015, University of Oxford"
    },
    {
      "citation_id": "6",
      "title": "Evaluating the underlying gender bias in contextualized word embeddings",
      "authors": [
        "C Basta",
        "M Costa-Jussà",
        "N Casas"
      ],
      "year": "2019",
      "venue": "Proceedings of the First Workshop on Gender Bias in Natural Language Processing"
    },
    {
      "citation_id": "7",
      "title": "A neural probabilistic language model",
      "authors": [
        "Y Bengio",
        "R Ducharme",
        "P Vincent",
        "C Jauvin"
      ],
      "year": "2003",
      "venue": "Journal of machine learning research"
    },
    {
      "citation_id": "8",
      "title": "Sentiment classification based on supervised latent n-gram analysis",
      "authors": [
        "D Bespalov",
        "B Bai",
        "Y Qi",
        "A Shokoufandeh"
      ],
      "year": "2011",
      "venue": "Proceedings of the 20th ACM Conference on Information and Knowledge Management, CIKM 2011"
    },
    {
      "citation_id": "9",
      "title": "Investigating gender bias in bert",
      "authors": [
        "R Bhardwaj",
        "N Majumder",
        "S Poria"
      ],
      "year": "2020",
      "venue": "Investigating gender bias in bert"
    },
    {
      "citation_id": "10",
      "title": "Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification",
      "authors": [
        "J Blitzer",
        "M Dredze",
        "F Pereira"
      ],
      "year": "2007",
      "venue": "ACL 2007, Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "11",
      "title": "Man is to computer programmer as woman is to homemaker? debiasing word embeddings",
      "authors": [
        "T Bolukbasi",
        "K.-W Chang",
        "J Zou",
        "V Saligrama",
        "A Kalai"
      ],
      "year": "2016",
      "venue": "Advances in neural information processing systems"
    },
    {
      "citation_id": "12",
      "title": "Comet: Commonsense transformers for automatic knowledge graph construction",
      "authors": [
        "A Bosselut",
        "H Rashkin",
        "M Sap",
        "C Malaviya",
        "A Celikyilmaz",
        "Y Choi"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "13",
      "title": "Prosodic contrasts in ironic speech",
      "authors": [
        "G Bryant"
      ],
      "year": "2010",
      "venue": "Discourse Processes"
    },
    {
      "citation_id": "14",
      "title": "IEMOCAP: interactive emotional dyadic motion capture database",
      "authors": [
        "C Busso",
        "M Bulut",
        "C Lee",
        "A Kazemzadeh",
        "E Mower",
        "S Kim",
        "J Chang",
        "S Lee",
        "S Narayanan"
      ],
      "year": "2008",
      "venue": "Lang. Resour. Evaluation"
    },
    {
      "citation_id": "15",
      "title": "Semantics derived automatically from language corpora contain human-like biases",
      "authors": [
        "A Caliskan",
        "J Bryson",
        "A Narayanan"
      ],
      "year": "2017",
      "venue": "Science"
    },
    {
      "citation_id": "16",
      "title": "Sentiment analysis is a big suitcase",
      "authors": [
        "E Cambria",
        "S Poria",
        "A Gelbukh",
        "M Thelwall"
      ],
      "year": "2017",
      "venue": "IEEE Intell. Syst"
    },
    {
      "citation_id": "17",
      "title": "Senticnet 6: Ensemble application of symbolic and subsymbolic AI for sentiment analysis",
      "authors": [
        "E Cambria",
        "Y Li",
        "F Xing",
        "S Poria",
        "K Kwok"
      ],
      "year": "2020",
      "venue": "CIKM '20: The 29th ACM International Conference on Information and Knowledge Management, Virtual Event"
    },
    {
      "citation_id": "18",
      "title": "Towards multimodal sarcasm detection (an obviously perfect paper)",
      "authors": [
        "S Castro",
        "D Hazarika",
        "V Pérez-Rosas",
        "R Zimmermann",
        "R Mihalcea",
        "S Poria"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019"
    },
    {
      "citation_id": "19",
      "title": "Rˆ3: Reverse, retrieve, and rank for sarcasm generation with commonsense knowledge",
      "authors": [
        "T Chakrabarty",
        "D Ghosh",
        "S Muresan",
        "N Peng"
      ],
      "year": "2020",
      "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "20",
      "title": "The sound of sarcasm",
      "authors": [
        "H Cheang",
        "M Pell"
      ],
      "year": "2008",
      "venue": "Speech Commun"
    },
    {
      "citation_id": "21",
      "title": "Adversarial deep averaging networks for cross-lingual sentiment classification",
      "authors": [
        "X Chen",
        "Y Sun",
        "B Athiwaratkun",
        "C Cardie",
        "K Weinberger"
      ],
      "year": "2018",
      "venue": "Trans. Assoc. Comput. Linguistics"
    },
    {
      "citation_id": "22",
      "title": "Building sentiment lexicons for all major languages",
      "authors": [
        "Y Chen",
        "S Skiena"
      ],
      "year": "2014",
      "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, ACL 2014"
    },
    {
      "citation_id": "23",
      "title": "Learning with compositional semantics as structural inference for subsentential sentiment analysis",
      "authors": [
        "Y Choi",
        "C Cardie"
      ],
      "year": "2008",
      "venue": "2008 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "24",
      "title": "Joint extraction of entities and relations for opinion recognition",
      "authors": [
        "Y Choi",
        "E Breck",
        "C Cardie"
      ],
      "year": "2006",
      "venue": "EMNLP 2006, Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "25",
      "title": "Coarse-grained+/-effect word sense disambiguation for implicit sentiment analysis",
      "authors": [
        "Y Choi",
        "J Wiebe",
        "R Mihalcea"
      ],
      "year": "2017",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "26",
      "title": "Using Language",
      "authors": [
        "H Clark"
      ],
      "year": "1996",
      "venue": "Using Language"
    },
    {
      "citation_id": "27",
      "title": "Conflict, criticism, or confidence: An empirical examination of the gender gap in wikipedia contributions",
      "authors": [
        "B Collier",
        "J Bear"
      ],
      "year": "2012",
      "venue": "Proceedings of the ACM 2012 Conference on Computer Supported Cooperative Work, CSCW '12"
    },
    {
      "citation_id": "28",
      "title": "Natural language processing (almost) from scratch",
      "authors": [
        "R Collobert",
        "J Weston",
        "L Bottou",
        "M Karlen",
        "K Kavukcuoglu",
        "P Kuksa"
      ],
      "year": "2011",
      "venue": "Journal of Machine Learning Research"
    },
    {
      "citation_id": "29",
      "title": "Semi-supervised sequence learning",
      "authors": [
        "A Dai",
        "Q Le"
      ],
      "year": "2015",
      "venue": "Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems"
    },
    {
      "citation_id": "30",
      "title": "Erratum to: Multilingual sentiment analysis: State of the art and independent comparison of techniques",
      "authors": [
        "K Dashtipour",
        "S Poria",
        "A Hussain",
        "E Cambria",
        "A Hawalah",
        "A Gelbukh",
        "Q Zhou"
      ],
      "year": "2016",
      "venue": "Cognitive Computation"
    },
    {
      "citation_id": "31",
      "title": "Semi-supervised recognition of sarcastic sentences in twitter and amazon",
      "authors": [
        "D Davidov",
        "O Tsur",
        "A Rappoport"
      ],
      "year": "2010",
      "venue": "Proceedings of the fourteenth conference on computational natural language learning"
    },
    {
      "citation_id": "32",
      "title": "Sentiment propagation via implicature constraints",
      "authors": [
        "L Deng",
        "J Wiebe"
      ],
      "year": "2014",
      "venue": "Proceedings of the 14th Conference of the European Chapter"
    },
    {
      "citation_id": "33",
      "title": "MPQA 3.0: An entity/event-level sentiment corpus",
      "authors": [
        "L Deng",
        "J Wiebe"
      ],
      "year": "2015",
      "venue": "NAACL HLT 2015, The 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies"
    },
    {
      "citation_id": "34",
      "title": "Joint inference and disambiguation of implicit sentiments via implicature constraints",
      "authors": [
        "L Deng",
        "J Wiebe",
        "Y Choi"
      ],
      "year": "2014",
      "venue": "Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers"
    },
    {
      "citation_id": "35",
      "title": "BERT: pre-training of deep bidirectional transformers for language understanding",
      "authors": [
        "J Devlin",
        "M Chang",
        "K Lee",
        "K Toutanova"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019"
    },
    {
      "citation_id": "36",
      "title": "Learning to generate product reviews from attributes",
      "authors": [
        "L Dong",
        "S Huang",
        "F Wei",
        "M Lapata",
        "M Zhou",
        "K Xu"
      ],
      "year": "2017",
      "venue": "Proceedings of the 15th Conference of the European Chapter"
    },
    {
      "citation_id": "37",
      "title": "Appraisal processes in emotion",
      "authors": [
        "P Ellsworth",
        "K Scherer"
      ],
      "year": "2003",
      "venue": "Appraisal processes in emotion"
    },
    {
      "citation_id": "38",
      "title": "SENTIWORDNET: A publicly available lexical resource for opinion mining",
      "authors": [
        "A Esuli",
        "F Sebastiani"
      ],
      "year": "2006",
      "venue": "Proceedings of the Fifth International Conference on Language Resources and Evaluation, LREC 2006"
    },
    {
      "citation_id": "39",
      "title": "Applying basic features from sentiment analysis for automatic irony detection",
      "authors": [
        "D Farías",
        "J Benedí",
        "P Rosso"
      ],
      "year": "2015",
      "venue": "Pattern Recognition and Image Analysis -7th Iberian Conference"
    },
    {
      "citation_id": "40",
      "title": "Inducing document structure for aspect-based summarization",
      "authors": [
        "L Frermann",
        "A Klementiev"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "41",
      "title": "Comparing the level of codeswitching in corpora",
      "authors": [
        "B Gambäck",
        "A Das"
      ],
      "year": "2016",
      "venue": "Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC'16)"
    },
    {
      "citation_id": "42",
      "title": "Domainadversarial training of neural networks",
      "authors": [
        "Y Ganin",
        "E Ustinova",
        "H Ajakan",
        "P Germain",
        "H Larochelle",
        "F Laviolette",
        "M March",
        "V Lempitsky"
      ],
      "year": "2016",
      "venue": "Journal of Machine Learning Research"
    },
    {
      "citation_id": "43",
      "title": "Unsupervised method for sentiment analysis in online texts",
      "authors": [
        "M Gavilanes",
        "T Álvarez-L Ópez",
        "J Juncal-Martínez",
        "E Costa-Montenegro",
        "González-Casta Ño"
      ],
      "year": "2016",
      "venue": "Expert Syst. Appl"
    },
    {
      "citation_id": "44",
      "title": "Unsupervised multi-target domain adaptation: An information theoretic approach",
      "authors": [
        "B Gholami",
        "P Sahu",
        "O Rudovic",
        "K Bousmalis",
        "V Pavlovic"
      ],
      "year": "2020",
      "venue": "IEEE Trans. Image Processing"
    },
    {
      "citation_id": "45",
      "title": "Unsupervised multi-target domain adaptation: An information theoretic approach",
      "authors": [
        "B Gholami",
        "P Sahu",
        "O Rudovic",
        "K Bousmalis",
        "V Pavlovic"
      ],
      "year": "2020",
      "venue": "IEEE Trans. Image Processing"
    },
    {
      "citation_id": "46",
      "title": "Sarcastic or not: Word embeddings to predict the literal or sarcastic meaning of words",
      "authors": [
        "D Ghosh",
        "W Guo",
        "S Muresan"
      ],
      "year": "2015",
      "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "47",
      "title": "Sarcasm analysis using conversation context",
      "authors": [
        "D Ghosh",
        "A Fabbri",
        "S Muresan"
      ],
      "year": "2018",
      "venue": "Computational Linguistics"
    },
    {
      "citation_id": "48",
      "title": "Affect-lm: A neural language model for customizable affective text generation",
      "authors": [
        "S Ghosh",
        "M Chollet",
        "E Laksana",
        "L.-P Morency",
        "S Scherer"
      ],
      "year": "2017",
      "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "49",
      "title": "Domain adaptation for large-scale sentiment classification: A deep learning approach",
      "authors": [
        "X Glorot",
        "A Bordes",
        "Y Bengio"
      ],
      "year": "2011",
      "venue": "Proceedings of the 28th international conference on machine learning (ICML-11)"
    },
    {
      "citation_id": "50",
      "title": "Lipstick on a pig: Debiasing methods cover up systematic gender biases in word embeddings but do not remove them",
      "authors": [
        "H Gonen",
        "Y Goldberg"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies"
    },
    {
      "citation_id": "51",
      "title": "Identifying sarcasm in twitter: A closer look",
      "authors": [
        "R González-Ibá Ñez",
        "S Muresan",
        "N Wacholder"
      ],
      "year": "2011",
      "venue": "The 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Conference"
    },
    {
      "citation_id": "52",
      "title": "Identifying sarcasm in twitter: A closer look",
      "authors": [
        "R González-Ibá Ñez",
        "S Muresan",
        "N Wacholder"
      ],
      "year": "2011",
      "venue": "The 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Conference"
    },
    {
      "citation_id": "53",
      "title": "Towards automated emotional conversation generation with implicit and explicit affective strategy",
      "authors": [
        "X Gu",
        "W Xu",
        "S Li"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 International Symposium on Signal Processing Systems"
    },
    {
      "citation_id": "54",
      "title": "Curriculum learning for facial expression recognition",
      "authors": [
        "L Gui",
        "T Baltrušaitis",
        "L.-P Morency"
      ],
      "year": "2017",
      "venue": "2017 12th IEEE International Conference on Automatic Face & Gesture Recognition"
    },
    {
      "citation_id": "55",
      "title": "Minority positive sampling for switching points -an anecdote for the code-mixing language modelling",
      "authors": [
        "V Guptha",
        "A Chatterjee",
        "P Chopra",
        "A Das"
      ],
      "venue": "Minority positive sampling for switching points -an anecdote for the code-mixing language modelling"
    },
    {
      "citation_id": "56",
      "title": "Language Resources and Evaluation Conference (LREC 2020)",
      "year": "2020",
      "venue": "Language Resources and Evaluation Conference (LREC 2020)"
    },
    {
      "citation_id": "57",
      "title": "Sentiment analysis using unlabeled email data",
      "authors": [
        "R Hag Ali",
        "N El Gayar"
      ],
      "year": "2019",
      "venue": "2019 International Conference on Computational Intelligence and Knowledge Economy (ICCIKE)"
    },
    {
      "citation_id": "58",
      "title": "Inducing domain-specific sentiment lexicons from unlabeled corpora",
      "authors": [
        "W Hamilton",
        "K Clark",
        "J Leskovec",
        "D Jurafsky"
      ],
      "year": "2016",
      "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "59",
      "title": "From hard to soft: Towards more human-like emotion recognition by modelling the perception uncertainty",
      "authors": [
        "J Han",
        "Z Zhang",
        "M Schmitt",
        "M Pantic",
        "B Schuller"
      ],
      "year": "2017",
      "venue": "Proceedings of the 25th ACM international conference on Multimedia"
    },
    {
      "citation_id": "60",
      "title": "UR-FUNNY: A multimodal language dataset for understanding humor",
      "authors": [
        "M Hasan",
        "W Rahman",
        "A Zadeh",
        "J Zhong",
        "M Tanveer",
        "L Morency",
        "M Hoque"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing"
    },
    {
      "citation_id": "61",
      "title": "Predicting and eliciting addressee's emotion in online dialogue",
      "authors": [
        "T Hasegawa",
        "N Kaji",
        "N Yoshinaga",
        "M Toyoda"
      ],
      "year": "2013",
      "venue": "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "62",
      "title": "Predicting the semantic orientation of adjectives",
      "authors": [
        "V Hatzivassiloglou",
        "K Mckeown"
      ],
      "year": "1997",
      "venue": "Proceedings of the 35th annual meeting of the association for computational linguistics and eighth conference of the european chapter of the association for computational linguistics"
    },
    {
      "citation_id": "63",
      "title": "Effects of adjective orientation and gradability on sentence subjectivity",
      "authors": [
        "V Hatzivassiloglou",
        "J Wiebe"
      ],
      "year": "2000",
      "venue": "Proceedings of the 18th conference on Computational"
    },
    {
      "citation_id": "64",
      "title": "CASCADE: contextual sarcasm detection in online discussion forums",
      "authors": [
        "D Hazarika",
        "S Poria",
        "S Gorantla",
        "E Cambria",
        "R Zimmermann",
        "R Mihalcea"
      ],
      "year": "2018",
      "venue": "Proceedings of the 27th International Conference on Computational Linguistics, COLING 2018"
    },
    {
      "citation_id": "65",
      "title": "ICON: interactive conversational memory network for multimodal emotion detection",
      "authors": [
        "D Hazarika",
        "S Poria",
        "R Mihalcea",
        "E Cambria",
        "R Zimmermann"
      ],
      "year": "2018",
      "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "66",
      "title": "Modeling inter-aspect dependencies for aspect-based sentiment analysis",
      "authors": [
        "D Hazarika",
        "S Poria",
        "P Vij",
        "G Krishnamurthy",
        "E Cambria",
        "R Zimmermann"
      ],
      "year": "2018",
      "venue": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT"
    },
    {
      "citation_id": "67",
      "title": "Conversational memory network for emotion recognition in dyadic dialogue videos",
      "authors": [
        "D Hazarika",
        "S Poria",
        "A Zadeh",
        "E Cambria",
        "L Morency",
        "R Zimmermann"
      ],
      "year": "2018",
      "venue": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2018"
    },
    {
      "citation_id": "68",
      "title": "MISA: modalityinvariant and -specific representations for multimodal sentiment analysis",
      "authors": [
        "D Hazarika",
        "R Zimmermann",
        "S Poria",
        "C Chen",
        "R Cucchiara",
        "X Hua",
        "G Qi",
        "E Ricci",
        "Z Zhang"
      ],
      "year": "2020",
      "venue": "MM '20: The 28th ACM International Conference on Multimedia"
    },
    {
      "citation_id": "69",
      "title": "Automatically extracting polarity-bearing topics for cross-domain sentiment classification",
      "authors": [
        "Y He",
        "C Lin",
        "H Alani"
      ],
      "year": "2011",
      "venue": "The 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Conference"
    },
    {
      "citation_id": "70",
      "title": "Aspect-based sentiment analysis using BERT",
      "authors": [
        "M Hoang",
        "O Bihorac",
        "J Rouces"
      ],
      "year": "2019",
      "venue": "Proceedings of the 22nd Nordic Conference on Computational Linguistics"
    },
    {
      "citation_id": "71",
      "title": "The social impact of natural language processing",
      "authors": [
        "D Hovy",
        "S Spruit"
      ],
      "year": "2016",
      "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "72",
      "title": "Learning whom to trust with MACE",
      "authors": [
        "D Hovy",
        "T Berg-Kirkpatrick",
        "A Vaswani",
        "E Hovy"
      ],
      "year": "2013",
      "venue": "Human Language Technologies: Conference of the North American Chapter of the Association of Computational Linguistics, Proceedings"
    },
    {
      "citation_id": "73",
      "title": "Generating natural language under pragmatic constraints",
      "authors": [
        "E Hovy"
      ],
      "year": "1987",
      "venue": "Journal of Pragmatics"
    },
    {
      "citation_id": "74",
      "title": "Universal language model finetuning for text classification",
      "authors": [
        "J Howard",
        "S Ruder"
      ],
      "year": "2018",
      "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018"
    },
    {
      "citation_id": "75",
      "title": "Mining and summarizing customer reviews",
      "authors": [
        "M Hu",
        "B Liu"
      ],
      "year": "2004",
      "venue": "Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining"
    },
    {
      "citation_id": "76",
      "title": "Mining and summarizing customer reviews",
      "authors": [
        "M Hu",
        "B Liu"
      ],
      "year": "2004",
      "venue": "Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining"
    },
    {
      "citation_id": "77",
      "title": "Toward controlled generation of text",
      "authors": [
        "Z Hu",
        "Z Yang",
        "X Liang",
        "R Salakhutdinov",
        "E Xing"
      ],
      "year": "2017",
      "venue": "Proceedings of the 34th International Conference on Machine Learning, ICML 2017"
    },
    {
      "citation_id": "78",
      "title": "ANA at semeval-2019 task 3: Contextual emotion detection in conversations through hierarchical lstms and BERT",
      "authors": [
        "C Huang",
        "A Trabelsi",
        "O Zaïane"
      ],
      "year": "2019",
      "venue": "Proceedings of the 13th International Workshop on Semantic Evaluation, SemEval@NAACL-HLT 2019"
    },
    {
      "citation_id": "79",
      "title": "Reducing sentiment bias in language models via counterfactual evaluation",
      "authors": [
        "P Huang",
        "H Zhang",
        "R Jiang",
        "R Stanforth",
        "J Welbl",
        "J Rae",
        "V Maini",
        "D Yogatama",
        "P Kohli"
      ],
      "year": "2019",
      "venue": "Reducing sentiment bias in language models via counterfactual evaluation"
    },
    {
      "citation_id": "80",
      "title": "A parsimonious rule-based model for sentiment analysis of social media text",
      "authors": [
        "C Hutto",
        "E Gilbert",
        "Vader"
      ],
      "year": "2014",
      "venue": "international AAAI conference on weblogs and social media"
    },
    {
      "citation_id": "81",
      "title": "Opinion mining with deep recurrent neural networks",
      "authors": [
        "O Irsoy",
        "C Cardie"
      ],
      "year": "2014",
      "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "82",
      "title": "Disentangled representation learning for non-parallel text style transfer",
      "authors": [
        "V John",
        "L Mou",
        "H Bahuleyan",
        "O Vechtomova"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019"
    },
    {
      "citation_id": "83",
      "title": "Supervised and semi-supervised text categorization using LSTM for region embeddings",
      "authors": [
        "R Johnson",
        "T Zhang"
      ],
      "year": "2016",
      "venue": "Proceedings of the 33nd International Conference on Machine Learning"
    },
    {
      "citation_id": "84",
      "title": "Test of the mention theory of irony",
      "authors": [
        "J Jorgensen",
        "G Miller",
        "D Sperber"
      ],
      "year": "1984",
      "venue": "Journal of Experimental Psychology: General"
    },
    {
      "citation_id": "85",
      "title": "Harnessing context incongruity for sarcasm detection",
      "authors": [
        "A Joshi",
        "V Sharma",
        "P Bhattacharyya"
      ],
      "year": "2015",
      "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing"
    },
    {
      "citation_id": "86",
      "title": "Towards sub-word level compositions for sentiment analysis of hindi-english code mixed text",
      "authors": [
        "A Joshi",
        "A Prabhu",
        "M Shrivastava",
        "V Varma"
      ],
      "year": "2016",
      "venue": "COLING 2016, 26th International Conference on Computational Linguistics, Proceedings of the Conference: Technical Papers"
    },
    {
      "citation_id": "87",
      "title": "Sentiment resources: Lexicons and datasets",
      "authors": [
        "A Joshi",
        "P Bhattacharyya",
        "S Ahire"
      ],
      "year": "2017",
      "venue": "A Practical Guide to Sentiment Analysis"
    },
    {
      "citation_id": "88",
      "title": "Automatic sarcasm detection: A survey",
      "authors": [
        "A Joshi",
        "P Bhattacharyya",
        "M Carman"
      ],
      "year": "2017",
      "venue": "ACM Computing Surveys (CSUR)"
    },
    {
      "citation_id": "89",
      "title": "Sarcasm target identification: Dataset and an introductory approach",
      "authors": [
        "A Joshi",
        "P Goel",
        "P Bhattacharyya",
        "M Carman"
      ],
      "year": "2018",
      "venue": "Proceedings of the Eleventh International Conference on Language Resources and Evaluation, LREC 2018"
    },
    {
      "citation_id": "90",
      "title": "Shallow domain adaptive embeddings for sentiment analysis",
      "authors": [
        "P Sarma",
        "Y Liang",
        "W Sethares"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)"
    },
    {
      "citation_id": "91",
      "title": "Gender-preserving debiasing for pre-trained word embeddings",
      "authors": [
        "M Kaneko",
        "D Bollegala"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019"
    },
    {
      "citation_id": "92",
      "title": "Adversarial training for aspect-based sentiment analysis with BERT",
      "authors": [
        "A Karimi",
        "L Rossi",
        "A Prati",
        "K Full"
      ],
      "year": "2020",
      "venue": "Adversarial training for aspect-based sentiment analysis with BERT"
    },
    {
      "citation_id": "93",
      "title": "A pattern-based model for generating text to express emotion",
      "authors": [
        "F Keshtkar",
        "D Inkpen"
      ],
      "year": "2011",
      "venue": "International Conference on Affective Computing and Intelligent Interaction"
    },
    {
      "citation_id": "94",
      "title": "Sentiment analysis of twitter data : A survey of techniques",
      "authors": [
        "V Kharde",
        "S Sonawane"
      ],
      "year": "2016",
      "venue": "Sentiment analysis of twitter data : A survey of techniques"
    },
    {
      "citation_id": "95",
      "title": "Your sentiment precedes you: Using an author's historical tweets to predict sarcasm",
      "authors": [
        "A Khattri",
        "A Joshi",
        "P Bhattacharyya",
        "M Carman"
      ],
      "year": "2015",
      "venue": "Proceedings of the 6th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, WASSA@EMNLP 2015"
    },
    {
      "citation_id": "96",
      "title": "Determining the sentiment of opinions",
      "authors": [
        "S Kim",
        "E Hovy"
      ],
      "year": "2004",
      "venue": "COLING 2004, 20th International Conference on Computational Linguistics, Proceedings of the Conference"
    },
    {
      "citation_id": "97",
      "title": "Extracting opinions, opinion holders, and topics expressed in online news media text",
      "authors": [
        "S.-M Kim",
        "E Hovy"
      ],
      "year": "2006",
      "venue": "Proceedings of the Workshop on Sentiment and Subjectivity in Text"
    },
    {
      "citation_id": "98",
      "title": "Convolutional neural networks for sentence classification",
      "authors": [
        "Y Kim"
      ],
      "year": "2014",
      "venue": "EMNLP 2014"
    },
    {
      "citation_id": "99",
      "title": "Happy accident: A sentiment composition lexicon for opposing polarity phrases",
      "authors": [
        "S Kiritchenko",
        "S Mohammad"
      ],
      "year": "2016",
      "venue": "Proceedings of the Tenth International Conference on Language Resources and Evaluation LREC 2016"
    },
    {
      "citation_id": "100",
      "title": "The effect of negators, modals, and degree adverbs on sentiment composition",
      "authors": [
        "S Kiritchenko",
        "S Mohammad"
      ],
      "year": "2016",
      "venue": "Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, WASSA@NAACL-HLT 2016"
    },
    {
      "citation_id": "101",
      "title": "Examining gender and race bias in two hundred sentiment analysis systems",
      "authors": [
        "S Kiritchenko",
        "S Mohammad"
      ],
      "year": "2018",
      "venue": "Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics, *SEM@NAACL-HLT 2018"
    },
    {
      "citation_id": "102",
      "title": "Capturing reliable fine-grained sentiment associations by crowdsourcing and best-worst scaling",
      "authors": [
        "S Kiritchenko",
        "S Mohammad"
      ],
      "year": "2016",
      "venue": "NAACL HLT 2016, The 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies"
    },
    {
      "citation_id": "103",
      "title": "Sentiment composition of words with opposing polarities",
      "authors": [
        "S Kiritchenko",
        "S Mohammad"
      ],
      "year": "2016",
      "venue": "The 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies"
    },
    {
      "citation_id": "104",
      "title": "Semeval-2016 task 7: Determining sentiment intensity of english and arabic phrases",
      "authors": [
        "S Kiritchenko",
        "S Mohammad",
        "M Salameh",
        "S Bethard",
        "D Cer",
        "M Carpuat",
        "D Jurgens"
      ],
      "year": "2016",
      "venue": "Proceedings of the 10th International Workshop on Semantic Evaluation, SemEval@NAACL-HLT 2016"
    },
    {
      "citation_id": "105",
      "title": "An adversarial approach to high-quality, sentiment-controlled neural dialogue generation",
      "authors": [
        "X Kong",
        "B Li",
        "G Neubig",
        "E Hovy",
        "Y Yang"
      ],
      "year": "2019",
      "venue": "An adversarial approach to high-quality, sentiment-controlled neural dialogue generation",
      "arxiv": "arXiv:1901.07129"
    },
    {
      "citation_id": "106",
      "title": "Twitter sentiment analysis: The good the bad and the omg! Icwsm",
      "authors": [
        "E Kouloumpis",
        "T Wilson",
        "J Moore"
      ],
      "year": "2011",
      "venue": "Twitter sentiment analysis: The good the bad and the omg! Icwsm"
    },
    {
      "citation_id": "107",
      "title": "Sentiment analysis of financial news articles using performance indicators",
      "authors": [
        "S Krishnamoorthy"
      ],
      "year": "2017",
      "venue": "Knowledge and Information Systems"
    },
    {
      "citation_id": "108",
      "title": "Opinion extraction, summarization and tracking in news and blog corpora",
      "authors": [
        "L Ku",
        "Y Liang",
        "H Chen"
      ],
      "year": "2006",
      "venue": "Computational Approaches to Analyzing Weblogs, Papers from the 2006 AAAI Spring Symposium"
    },
    {
      "citation_id": "109",
      "title": "Nurse is closer to woman than surgeon? mitigating gender-biased proximities in word embeddings",
      "authors": [
        "V Kumar",
        "T Bhotia",
        "T Chakraborty"
      ],
      "year": "2020",
      "venue": "Trans. Assoc. Comput. Linguistics"
    },
    {
      "citation_id": "110",
      "title": "Emotional inertia and psychological maladjustment",
      "authors": [
        "P Kuppens",
        "N Allen",
        "L Sheeber"
      ],
      "year": "2010",
      "venue": "Psychological Science"
    },
    {
      "citation_id": "111",
      "title": "Measuring bias in contextualized word representations",
      "authors": [
        "K Kurita",
        "N Vyas",
        "A Pareek",
        "A Black",
        "Y Tsvetkov"
      ],
      "year": "2019",
      "venue": "Proceedings of the First Workshop on Gender Bias in Natural Language Processing"
    },
    {
      "citation_id": "112",
      "title": "Re-embedding words",
      "authors": [
        "I Labutov",
        "H Lipson"
      ],
      "year": "2013",
      "venue": "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "113",
      "title": "Aspect specific sentiment analysis using hierarchical deep learning",
      "authors": [
        "H Lakkaraju",
        "R Socher",
        "C Manning"
      ],
      "year": "2014",
      "venue": "NIPS Workshop on deep learning and representation learning"
    },
    {
      "citation_id": "114",
      "title": "De-mixing sentiment from code-mixed text",
      "authors": [
        "Y Lal",
        "V Kumar",
        "M Dhar",
        "M Shrivastava",
        "P Koehn"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop"
    },
    {
      "citation_id": "115",
      "title": "Thoughts on the relations between emotion and cognition",
      "authors": [
        "R Lazarus"
      ],
      "year": "1982",
      "venue": "American psychologist"
    },
    {
      "citation_id": "116",
      "title": "Distributed representations of sentences and documents",
      "authors": [
        "Q Le",
        "T Mikolov"
      ],
      "year": "2014",
      "venue": "International conference on machine learning"
    },
    {
      "citation_id": "117",
      "title": "Learning latent sentiment scopes for entitylevel sentiment analysis",
      "authors": [
        "H Li",
        "W Lu"
      ],
      "year": "2017",
      "venue": "Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence"
    },
    {
      "citation_id": "118",
      "title": "Reflections on sentiment/opinion analysis",
      "authors": [
        "J Li",
        "E Hovy"
      ],
      "year": "2017",
      "venue": "A Practical Guide to Sentiment Analysis"
    },
    {
      "citation_id": "119",
      "title": "Delete, retrieve, generate: a simple approach to sentiment and style transfer",
      "authors": [
        "J Li",
        "R Jia",
        "H He",
        "P Liang"
      ],
      "year": "2018",
      "venue": "Proceedings of the 2018 Conference of the North American Chapter"
    },
    {
      "citation_id": "120",
      "title": "A unified model for opinion target extraction and target sentiment prediction",
      "authors": [
        "X Li",
        "L Bing",
        "P Li",
        "W Lam"
      ],
      "year": "2019",
      "venue": "The Thirty-Third AAAI Conference on Artificial Intelligence, AAAI 2019, The Thirty-First Innovative Applications of Artificial Intelligence Conference, IAAI 2019, The Ninth AAAI Symposium on Educational Advances in Artificial Intelligence"
    },
    {
      "citation_id": "121",
      "title": "Sentiment analysis and subjectivity",
      "authors": [
        "B Liu"
      ],
      "year": "2010",
      "venue": "Handbook of Natural Language Processing"
    },
    {
      "citation_id": "122",
      "title": "Sentiment Analysis and Opinion Mining. Synthesis Lectures on Human Language Technologies",
      "authors": [
        "B Liu"
      ],
      "year": "2012",
      "venue": "Sentiment Analysis and Opinion Mining. Synthesis Lectures on Human Language Technologies"
    },
    {
      "citation_id": "123",
      "title": "Sentiment Analysis -Mining Opinions, Sentiments, and Emotions",
      "authors": [
        "B Liu"
      ],
      "year": "2015",
      "venue": "Sentiment Analysis -Mining Opinions, Sentiments, and Emotions"
    },
    {
      "citation_id": "124",
      "title": "A survey of opinion mining and sentiment analysis",
      "authors": [
        "B Liu",
        "L Zhang"
      ],
      "venue": "Mining Text Data"
    },
    {
      "citation_id": "125",
      "title": "Modeling sentiment association in discourse for humor recognition",
      "authors": [
        "L Liu",
        "D Zhang",
        "W Song"
      ],
      "year": "2018",
      "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018"
    },
    {
      "citation_id": "126",
      "title": "Automated rule selection for aspect extraction in opinion mining",
      "authors": [
        "Q Liu",
        "Z Gao",
        "B Liu",
        "Y Zhang"
      ],
      "year": "2015",
      "venue": "Proceedings of the Twenty-Fourth International Joint Conference on Artificial Intelligence"
    },
    {
      "citation_id": "127",
      "title": "A robustly optimized BERT pretraining approach",
      "authors": [
        "Y Liu",
        "M Ott",
        "N Goyal",
        "J Du",
        "M Joshi",
        "D Chen",
        "O Levy",
        "M Lewis",
        "L Zettlemoyer",
        "V Stoyanov",
        "Roberta"
      ],
      "year": "2019",
      "venue": "A robustly optimized BERT pretraining approach"
    },
    {
      "citation_id": "128",
      "title": "Towards building a competitive opinion summarization system: Challenges and keys",
      "authors": [
        "E Lloret",
        "A Balahur",
        "M Palomar",
        "A Montoyo"
      ],
      "year": "2009",
      "venue": "Human Language Technologies: Conference of the North American Chapter of the Association of Computational Linguistics, Proceedings"
    },
    {
      "citation_id": "129",
      "title": "Eliciting positive emotion through affect-sensitive dialogue response generation: A neural network approach",
      "authors": [
        "N Lubis",
        "S Sakti",
        "K Yoshino",
        "S Nakamura"
      ],
      "year": "2018",
      "venue": "Thirty-Second AAAI Conference on Artificial Intelligence"
    },
    {
      "citation_id": "130",
      "title": "DOER: dual cross-shared RNN for aspect term-polarity co-extraction",
      "authors": [
        "H Luo",
        "T Li",
        "B Liu",
        "J Zhang"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019"
    },
    {
      "citation_id": "131",
      "title": "Targeted aspect-based sentiment analysis via embedding commonsense knowledge into an attentive LSTM",
      "authors": [
        "Y Ma",
        "H Peng",
        "E Cambria"
      ],
      "year": "2018",
      "venue": "Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18)"
    },
    {
      "citation_id": "132",
      "title": "A survey on empathetic dialogue systems",
      "authors": [
        "Y Ma",
        "K Nguyen",
        "F Xing",
        "E Cambria"
      ],
      "year": "2020",
      "venue": "Inf. Fusion"
    },
    {
      "citation_id": "133",
      "title": "Learning word vectors for sentiment analysis",
      "authors": [
        "A Maas",
        "R Daly",
        "P Pham",
        "D Huang",
        "A Ng",
        "C Potts"
      ],
      "year": "2011",
      "venue": "Proceedings of the 49th annual meeting of the association for computational linguistics: Human language technologies"
    },
    {
      "citation_id": "134",
      "title": "Personage: Personality generation for dialogue",
      "authors": [
        "F Mairesse",
        "M Walker"
      ],
      "year": "2007",
      "venue": "Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics"
    },
    {
      "citation_id": "135",
      "title": "Dialoguernn: An attentive RNN for emotion detection in conversations",
      "authors": [
        "N Majumder",
        "S Poria",
        "D Hazarika",
        "R Mihalcea",
        "A Gelbukh",
        "E Cambria"
      ],
      "year": "2019",
      "venue": "The Thirty-Third AAAI Conference on Artificial Intelligence, AAAI 2019, The Thirty-First Innovative Applications of Artificial Intelligence Conference, IAAI 2019, The Ninth AAAI Symposium on Educational Advances in Artificial Intelligence"
    },
    {
      "citation_id": "136",
      "title": "Sentiment and sarcasm classification with multitask learning",
      "authors": [
        "N Majumder",
        "S Poria",
        "H Peng",
        "N Chhaya",
        "E Cambria",
        "A Gelbukh"
      ],
      "year": "2019",
      "venue": "IEEE Intell. Syst"
    },
    {
      "citation_id": "137",
      "title": "Improving aspectlevel sentiment analysis with aspect extraction",
      "authors": [
        "N Majumder",
        "R Bhardwaj",
        "S Poria",
        "A Zadeh",
        "A Gelbukh",
        "A Hussain",
        "L Morency"
      ],
      "year": "2020",
      "venue": "Improving aspectlevel sentiment analysis with aspect extraction"
    },
    {
      "citation_id": "138",
      "title": "Delta TFIDF: an improved feature space for sentiment analysis",
      "authors": [
        "J Martineau",
        "T Finin"
      ],
      "year": "2009",
      "venue": "Proceedings of the Third International Conference on Weblogs and Social Media"
    },
    {
      "citation_id": "139",
      "title": "Who cares about sarcastic tweets? investigating the impact of sarcasm on sentiment analysis",
      "authors": [
        "D Maynard",
        "M Greenwood"
      ],
      "year": "2014",
      "venue": "LREC 2014 Proceedings"
    },
    {
      "citation_id": "140",
      "title": "Learned in translation: Contextualized word vectors",
      "authors": [
        "B Mccann",
        "J Bradbury",
        "C Xiong",
        "R Socher"
      ],
      "year": "2017",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "141",
      "title": "Topic sentiment mixture: modeling facets and opinions in weblogs",
      "authors": [
        "Q Mei",
        "X Ling",
        "M Wondra",
        "H Su",
        "C Zhai"
      ],
      "year": "2007",
      "venue": "Proceedings of the 16th International Conference on World Wide Web, WWW 2007"
    },
    {
      "citation_id": "142",
      "title": "Exploring feature definition and selection for sentiment classifiers",
      "authors": [
        "Y Mejova",
        "P Srinivasan"
      ],
      "year": "2011",
      "venue": "Proceedings of the Fifth International Conference on Weblogs and Social Media"
    },
    {
      "citation_id": "143",
      "title": "Recurrent neural network based language model",
      "authors": [
        "T Mikolov",
        "M Karafiát",
        "L Burget",
        "J Černock Ỳ",
        "S Khudanpur"
      ],
      "year": "2010",
      "venue": "Eleventh annual conference of the international speech communication association"
    },
    {
      "citation_id": "144",
      "title": "Wordnet: A lexical database for english",
      "authors": [
        "G Miller"
      ],
      "year": "1995",
      "venue": "Commun. ACM"
    },
    {
      "citation_id": "145",
      "title": "Storytelling from structured data and knowledge graphs : An NLG perspective",
      "authors": [
        "A Mishra",
        "A Laha",
        "K Sankaranarayanan",
        "P Jain",
        "S Krishnan"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Conference of the Association for Computational Linguistics: Tutorial Abstracts, ACL 2019"
    },
    {
      "citation_id": "146",
      "title": "A modular architecture for unsupervised sarcasm generation",
      "authors": [
        "A Mishra",
        "T Tater",
        "K Sankaranarayanan"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing"
    },
    {
      "citation_id": "147",
      "title": "The geography of happiness: Connecting twitter sentiment and expression, demographics, and objective characteristics of place",
      "authors": [
        "L Mitchell",
        "K Harris",
        "M Frank",
        "P Dodds",
        "C Danforth"
      ],
      "year": "2013",
      "venue": "The geography of happiness: Connecting twitter sentiment and expression, demographics, and objective characteristics of place"
    },
    {
      "citation_id": "148",
      "title": "Adversarial training methods for semi-supervised text classification",
      "authors": [
        "T Miyato",
        "A Dai",
        "I Goodfellow"
      ],
      "year": "2017",
      "venue": "5th International Conference on Learning Representations"
    },
    {
      "citation_id": "149",
      "title": "Opinion digger: an unsupervised opinion miner from unstructured product reviews",
      "authors": [
        "S Moghaddam",
        "M Ester"
      ],
      "year": "2010",
      "venue": "Proceedings of the 19th ACM Conference on Information and Knowledge Management, CIKM 2010"
    },
    {
      "citation_id": "150",
      "title": "Emotions evoked by common words and phrases: Using Mechanical Turk to create an emotion lexicon",
      "authors": [
        "S Mohammad",
        "P Turney"
      ],
      "year": "2010",
      "venue": "Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text"
    },
    {
      "citation_id": "151",
      "title": "Crowdsourcing a wordemotion association lexicon",
      "authors": [
        "S Mohammad",
        "P Turney"
      ],
      "year": "2013",
      "venue": "Comput. Intell"
    },
    {
      "citation_id": "152",
      "title": "Challenges in sentiment analysis",
      "authors": [
        "S Mohammad"
      ],
      "year": "2017",
      "venue": "A practical guide to sentiment analysis"
    },
    {
      "citation_id": "153",
      "title": "Sentiment composition",
      "authors": [
        "K Moilanen",
        "S Pulman"
      ],
      "year": "2007",
      "venue": "Proceedings of RANLP"
    },
    {
      "citation_id": "154",
      "title": "Document-level sentiment classification: An empirical comparison between SVM and ANN",
      "authors": [
        "R Moraes",
        "J Valiati",
        "W Neto"
      ],
      "year": "2013",
      "venue": "Expert Syst. Appl"
    },
    {
      "citation_id": "155",
      "title": "Document-level sentiment classification: An empirical comparison between svm and ann",
      "authors": [
        "R Moraes",
        "J Valiati",
        "W Neto"
      ],
      "year": "2013",
      "venue": "Expert Systems with Applications"
    },
    {
      "citation_id": "156",
      "title": "Mining product reputations on the web",
      "authors": [
        "S Morinaga",
        "K Yamanishi",
        "K Tateishi",
        "T Fukushima"
      ],
      "year": "2002",
      "venue": "Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining"
    },
    {
      "citation_id": "157",
      "title": "How emotions work: The social functions of emotional expression in negotiations",
      "authors": [
        "M Morris",
        "D Keltner"
      ],
      "year": "2000",
      "venue": "Research in organizational behavior"
    },
    {
      "citation_id": "158",
      "title": "Fine-grained sentiment classification using BERT",
      "authors": [
        "M Munikar",
        "S Shakya",
        "A Shrestha"
      ],
      "year": "2019",
      "venue": "Fine-grained sentiment classification using BERT"
    },
    {
      "citation_id": "159",
      "title": "Dependency tree-based sentiment classification using crfs with hidden variables",
      "authors": [
        "T Nakagawa",
        "K Inui",
        "S Kurohashi"
      ],
      "year": "2010",
      "venue": "Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics"
    },
    {
      "citation_id": "160",
      "title": "Semeval-2013 task 2: Sentiment analysis in twitter",
      "authors": [
        "P Nakov",
        "S Rosenthal",
        "Z Kozareva",
        "V Stoyanov",
        "A Ritter",
        "T Wilson"
      ],
      "year": "2013",
      "venue": "Proceedings of the 7th International Workshop on Semantic Evaluation, SemEval@NAACL-HLT 2013"
    },
    {
      "citation_id": "161",
      "title": "Sentiment analysis: Capturing favorability using natural language processing",
      "authors": [
        "T Nasukawa",
        "J Yi"
      ],
      "year": "2003",
      "venue": "Proceedings of the 2nd international conference on Knowledge capture"
    },
    {
      "citation_id": "162",
      "title": "Mirroring facial expressions and emotions in dyadic conversations",
      "authors": [
        "C Navarretta",
        "K Choukri",
        "T Declerck",
        "S Goggi",
        "M Grobelnik",
        "B Maegaard"
      ],
      "year": "2016",
      "venue": "LREC"
    },
    {
      "citation_id": "163",
      "title": "A dataset of intended sarcasm",
      "authors": [
        "S Oprea",
        "W Magdy",
        "Isarcasm"
      ],
      "year": "2019",
      "venue": "A dataset of intended sarcasm"
    },
    {
      "citation_id": "164",
      "title": "Emotionally-aware chatbots: A survey",
      "authors": [
        "E Pamungkas"
      ],
      "year": "1906",
      "venue": "Emotionally-aware chatbots: A survey"
    },
    {
      "citation_id": "165",
      "title": "Cross-domain sentiment classification via spectral feature alignment",
      "authors": [
        "S Pan",
        "X Ni",
        "J Sun",
        "Q Yang",
        "Z Chen"
      ],
      "year": "2010",
      "venue": "Proceedings of the 19th International Conference on World Wide Web, WWW 2010"
    },
    {
      "citation_id": "166",
      "title": "A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts",
      "authors": [
        "B Pang",
        "L Lee"
      ],
      "year": "2004",
      "venue": "Proceedings of the 42nd annual meeting on Association for Computational Linguistics"
    },
    {
      "citation_id": "167",
      "title": "Thumbs up?: sentiment classification using machine learning techniques",
      "authors": [
        "B Pang",
        "L Lee",
        "S Vaithyanathan"
      ],
      "year": "2002",
      "venue": "Proceedings of the ACL-02 conference on Empirical methods in natural language processing"
    },
    {
      "citation_id": "168",
      "title": "The effects of affective interventions in human-computer interaction",
      "authors": [
        "T Partala",
        "V Surakka"
      ],
      "year": "2004",
      "venue": "Interacting with computers"
    },
    {
      "citation_id": "169",
      "title": "A deep-learning framework to detect sarcasm targets",
      "authors": [
        "J Patro",
        "S Bansal",
        "A Mukherjee"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019"
    },
    {
      "citation_id": "170",
      "title": "Sarcasm SIGN: interpreting sarcasm with sentiment based monolingual machine translation",
      "authors": [
        "L Peled",
        "R Reichart"
      ],
      "year": "2017",
      "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "171",
      "title": "Deep contextualized word representations",
      "authors": [
        "M Peters",
        "M Neumann",
        "M Iyyer",
        "M Gardner",
        "C Clark",
        "K Lee",
        "L Zettlemoyer"
      ],
      "year": "2018",
      "venue": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2018"
    },
    {
      "citation_id": "172",
      "title": "Contextual valence shifters",
      "authors": [
        "L Polanyi",
        "A Zaenen"
      ],
      "year": "2006",
      "venue": "Computing attitude and affect in text: Theory and applications"
    },
    {
      "citation_id": "173",
      "title": "Semeval-2014 task 4: Aspect based sentiment analysis",
      "authors": [
        "M Pontiki",
        "D Galanis",
        "J Pavlopoulos",
        "H Papageorgiou",
        "I Androutsopoulos",
        "S Manandhar"
      ],
      "year": "2014",
      "venue": "Proceedings of the 8th International Workshop on Semantic Evaluation, SemEval@COLING 2014"
    },
    {
      "citation_id": "174",
      "title": "Semeval-2016 task 5: Aspect based sentiment analysis",
      "authors": [
        "M Pontiki",
        "D Galanis",
        "H Papageorgiou",
        "I Androutsopoulos",
        "S Manandhar",
        "A.-S Mohammad",
        "M Al-Ayyoub",
        "Y Zhao",
        "B Qin",
        "O De Clercq"
      ],
      "year": "2016",
      "venue": "Proceedings of the 10th international workshop on semantic evaluation"
    },
    {
      "citation_id": "175",
      "title": "Aspect extraction for opinion mining with a deep convolutional neural network",
      "authors": [
        "S Poria",
        "E Cambria",
        "A Gelbukh"
      ],
      "year": "2016",
      "venue": "Knowl. Based Syst"
    },
    {
      "citation_id": "176",
      "title": "Context-dependent sentiment analysis in user-generated videos",
      "authors": [
        "S Poria",
        "E Cambria",
        "D Hazarika",
        "N Majumder",
        "A Zadeh",
        "L.-P Morency"
      ],
      "year": "2017",
      "venue": "ACL 2017"
    },
    {
      "citation_id": "177",
      "title": "MELD: A multimodal multi-party dataset for emotion recognition in conversations",
      "authors": [
        "S Poria",
        "D Hazarika",
        "N Majumder",
        "G Naik",
        "E Cambria",
        "R Mihalcea"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019"
    },
    {
      "citation_id": "178",
      "title": "The empathic companion: A character-based interface that addresses users'affective states",
      "authors": [
        "H Prendinger",
        "M Ishizuka"
      ],
      "year": "2005",
      "venue": "Applied Artificial Intelligence"
    },
    {
      "citation_id": "179",
      "title": "Opinion word expansion and target extraction through double propagation",
      "authors": [
        "G Qiu",
        "B Liu",
        "J Bu",
        "C Chen"
      ],
      "year": "2011",
      "venue": "Computational Linguistics"
    },
    {
      "citation_id": "180",
      "title": "End-to-end joint opinion role labeling with BERT",
      "authors": [
        "W Quan",
        "J Zhang",
        "X Hu"
      ],
      "year": "2019",
      "venue": "2019 IEEE International Conference on Big Data (Big Data)"
    },
    {
      "citation_id": "181",
      "title": "Learning to generate reviews and discovering sentiment",
      "authors": [
        "A Radford",
        "R Jozefowicz",
        "I Sutskever"
      ],
      "year": "2017",
      "venue": "Learning to generate reviews and discovering sentiment",
      "arxiv": "arXiv:1704.01444"
    },
    {
      "citation_id": "182",
      "title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
      "authors": [
        "C Raffel",
        "N Shazeer",
        "A Roberts",
        "K Lee",
        "S Narang",
        "M Matena",
        "Y Zhou",
        "W Li",
        "P Liu"
      ],
      "year": "2019",
      "venue": "Exploring the limits of transfer learning with a unified text-to-text transformer"
    },
    {
      "citation_id": "183",
      "title": "United we stand: Improving sentiment analysis by joining machine learning and rule based methods",
      "authors": [
        "V Rentoumi",
        "S Petrakis",
        "M Klenner",
        "G Vouros",
        "V Karkaletsis"
      ],
      "year": "2010",
      "venue": "LREC"
    },
    {
      "citation_id": "184",
      "title": "Sarcasm as contrast between a positive sentiment and negative situation",
      "authors": [
        "E Riloff",
        "A Qadir",
        "P Surve",
        "L Silva",
        "N Gilbert",
        "R Huang"
      ],
      "year": "2013",
      "venue": "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, EMNLP 2013"
    },
    {
      "citation_id": "185",
      "title": "A primer in bertology: What we know about how BERT works",
      "authors": [
        "A Rogers",
        "O Kovaleva",
        "A Rumshisky"
      ],
      "year": "2020",
      "venue": "A primer in bertology: What we know about how BERT works"
    },
    {
      "citation_id": "186",
      "title": "Semeval-2014 task 9: Sentiment analysis in twitter",
      "authors": [
        "S Rosenthal",
        "A Ritter",
        "P Nakov",
        "V Stoyanov"
      ],
      "year": "2014",
      "venue": "Proceedings of the 8th International Workshop on Semantic Evaluation, SemEval@COLING 2014"
    },
    {
      "citation_id": "187",
      "title": "Semeval-2015 task 10: Sentiment analysis in twitter",
      "authors": [
        "S Rosenthal",
        "P Nakov",
        "S Kiritchenko",
        "S Mohammad",
        "A Ritter",
        "V Stoyanov"
      ],
      "year": "2015",
      "venue": "Proceedings of the 9th International Workshop on Semantic Evaluation, SemEval@NAACL-HLT 2015"
    },
    {
      "citation_id": "188",
      "title": "Is it great or terrible? preserving sentiment in neural machine translation of arabic reviews",
      "authors": [
        "H Saadany",
        "C Orasan"
      ],
      "year": "2020",
      "venue": "Is it great or terrible? preserving sentiment in neural machine translation of arabic reviews",
      "arxiv": "arXiv:2010.13814"
    },
    {
      "citation_id": "189",
      "title": "Gender bias in pretrained Swedish embeddings",
      "authors": [
        "M Sahlgren",
        "F Olsson"
      ],
      "year": "2019",
      "venue": "Proceedings of the 22nd Nordic Conference on Computational Linguistics"
    },
    {
      "citation_id": "190",
      "title": "Domain adapted word embeddings for improved sentiment classification",
      "authors": [
        "P Sarma",
        "Y Liang",
        "B Sethares"
      ],
      "year": "2018",
      "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018"
    },
    {
      "citation_id": "191",
      "title": "Detecting sarcasm in multimodal social platforms",
      "authors": [
        "R Schifanella",
        "P De Juan",
        "J Tetreault",
        "L Cao"
      ],
      "year": "2016",
      "venue": "Proceedings of the 2016 ACM Conference on Multimedia Conference, MM 2016"
    },
    {
      "citation_id": "192",
      "title": "Identifying transferable information across domains for cross-domain sentiment classification",
      "authors": [
        "R Sharma",
        "P Bhattacharyya",
        "S Dandapat",
        "H Bhatt"
      ],
      "year": "2018",
      "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018"
    },
    {
      "citation_id": "193",
      "title": "Style transfer from non-parallel text by cross-alignment",
      "authors": [
        "T Shen",
        "T Lei",
        "R Barzilay",
        "T Jaakkola"
      ],
      "year": "2017",
      "venue": "Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems"
    },
    {
      "citation_id": "194",
      "title": "Learning domainsensitive and sentiment-aware word embeddings",
      "authors": [
        "B Shi",
        "Z Fu",
        "L Bing",
        "W Lam"
      ],
      "year": "2018",
      "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018"
    },
    {
      "citation_id": "195",
      "title": "Lifelong learning CRF for supervised aspect extraction",
      "authors": [
        "L Shu",
        "H Xu",
        "B Liu"
      ],
      "year": "2017",
      "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, ACL 2017"
    },
    {
      "citation_id": "196",
      "title": "Recursive deep models for semantic compositionality over a sentiment treebank",
      "authors": [
        "R Socher",
        "A Perelygin",
        "J Wu",
        "J Chuang",
        "C Manning",
        "A Ng",
        "C Potts"
      ],
      "year": "2013",
      "venue": "Proceedings of the 2013 conference on empirical methods in natural language processing"
    },
    {
      "citation_id": "197",
      "title": "Srilm-an extensible language modeling toolkit",
      "authors": [
        "A Stolcke"
      ],
      "year": "2002",
      "venue": "Seventh international conference on spoken language processing"
    },
    {
      "citation_id": "198",
      "title": "Lstm neural networks for language modeling",
      "authors": [
        "M Sundermeyer",
        "R Schl Üter",
        "H Ney"
      ],
      "year": "2012",
      "venue": "Thirteenth annual conference of the international speech communication association"
    },
    {
      "citation_id": "199",
      "title": "Lexicon-based methods for sentiment analysis",
      "authors": [
        "M Taboada",
        "J Brooke",
        "M Tofiloski",
        "K Voll",
        "M Stede"
      ],
      "year": "2011",
      "venue": "Computational Linguistics"
    },
    {
      "citation_id": "200",
      "title": "Improved semantic representations from tree-structured long short-term memory networks",
      "authors": [
        "K Tai",
        "R Socher",
        "C Manning"
      ],
      "year": "2015",
      "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing"
    },
    {
      "citation_id": "201",
      "title": "Automatic domain-specific sentiment lexicon generation with label propagation",
      "authors": [
        "Y Tai",
        "H Kao"
      ],
      "year": "2013",
      "venue": "The 15th International Conference on Information Integration and Web-based Applications & Services, IIWAS '13"
    },
    {
      "citation_id": "202",
      "title": "Adapting naive bayes to domain adaptation for sentiment analysis",
      "authors": [
        "S Tan",
        "X Cheng",
        "Y Wang",
        "H Xu"
      ],
      "year": "2009",
      "venue": "Advances in Information Retrieval, 31th European Conference on IR Research"
    },
    {
      "citation_id": "203",
      "title": "Learning sentiment-specific word embedding for twitter sentiment classification",
      "authors": [
        "D Tang",
        "F Wei",
        "N Yang",
        "M Zhou",
        "T Liu",
        "B Qin"
      ],
      "year": "2014",
      "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "204",
      "title": "Document modeling with gated recurrent neural network for sentiment classification",
      "authors": [
        "D Tang",
        "B Qin",
        "T Liu"
      ],
      "year": "2015",
      "venue": "Proceedings of the 2015 conference on empirical methods in natural language processing"
    },
    {
      "citation_id": "205",
      "title": "Effective lstms for target-dependent sentiment classification",
      "authors": [
        "D Tang",
        "B Qin",
        "X Feng",
        "T Liu"
      ],
      "year": "2016",
      "venue": "COLING 2016, 26th International Conference on Computational Linguistics, Proceedings of the Conference: Technical Papers"
    },
    {
      "citation_id": "206",
      "title": "Aspect level sentiment classification with deep memory network",
      "authors": [
        "D Tang",
        "B Qin",
        "T Liu"
      ],
      "year": "2016",
      "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "207",
      "title": "Dyadic memory networks for aspect-based sentiment analysis",
      "authors": [
        "Y Tay",
        "L Tuan",
        "S Hui"
      ],
      "year": "2017",
      "venue": "Proceedings of the 2017 ACM on Conference on Information and Knowledge Management, CIKM 2017"
    },
    {
      "citation_id": "208",
      "title": "Reasoning with sarcasm by reading in-between",
      "authors": [
        "Y Tay",
        "A Luu",
        "S Hui",
        "J Su"
      ],
      "year": "2018",
      "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018"
    },
    {
      "citation_id": "209",
      "title": "Attentive gated lexicon reader with contrastive contextual co-attention for sentiment classification",
      "authors": [
        "Y Tay",
        "A Luu",
        "S Hui",
        "J Su"
      ],
      "year": "2018",
      "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Brussels"
    },
    {
      "citation_id": "210",
      "title": "Sentiment classification using document embeddings trained with cosine similarity",
      "authors": [
        "T Thongtan",
        "T Phienthrakul"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019"
    },
    {
      "citation_id": "211",
      "title": "Learning sentiment composition from sentiment lexicons",
      "authors": [
        "O Toledo-Ronen",
        "R Bar-Haim",
        "A Halfon",
        "C Jochim",
        "A Menczel",
        "R Aharonov",
        "N Slonim"
      ],
      "year": "2018",
      "venue": "Proceedings of the 27th International Conference on Computational Linguistics, COLING 2018"
    },
    {
      "citation_id": "212",
      "title": "An operational system for detecting and tracking opinions in on-line discussion",
      "authors": [
        "R Tong"
      ],
      "year": "2001",
      "venue": "Working Notes of the ACM SIGIR 2001 Workshop on Operational Text Classification"
    },
    {
      "citation_id": "213",
      "title": "ICWSM -A great catchy name: Semi-supervised recognition of sarcastic sentences in online product reviews",
      "authors": [
        "O Tsur",
        "D Davidov",
        "A Rappoport"
      ],
      "year": "2010",
      "venue": "Proceedings of the Fourth International Conference on Weblogs and Social Media, ICWSM 2010"
    },
    {
      "citation_id": "214",
      "title": "Thumbs up or thumbs down? semantic orientation applied to unsupervised classification of reviews",
      "authors": [
        "P Turney"
      ],
      "year": "2002",
      "venue": "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "215",
      "title": "Attention is all you need",
      "authors": [
        "A Vaswani",
        "N Shazeer",
        "N Parmar",
        "J Uszkoreit",
        "L Jones",
        "A Gomez",
        "L Kaiser",
        "I Polosukhin"
      ],
      "year": "2017",
      "venue": "Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems"
    },
    {
      "citation_id": "216",
      "title": "The viability of web-derived polarity lexicons",
      "authors": [
        "L Velikovich",
        "S Blair-Goldensohn",
        "K Hannan",
        "R Mc-Donald"
      ],
      "year": "2010",
      "venue": "Human Language Technologies: Conference of the North American Chapter of the Association of Computational Linguistics, Proceedings"
    },
    {
      "citation_id": "217",
      "title": "Exploring demographic language variations to improve multilingual sentiment analysis in social media",
      "authors": [
        "S Volkova",
        "T Wilson",
        "D Yarowsky"
      ],
      "year": "2013",
      "venue": "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "218",
      "title": "Enhanced twitter sentiment classification using contextual information",
      "authors": [
        "S Vosoughi",
        "H Zhou",
        "D Roy"
      ],
      "year": "2015",
      "venue": "Proceedings of the 6th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, WASSA@EMNLP 2015"
    },
    {
      "citation_id": "219",
      "title": "Generating sentimental texts via mixture adversarial networks",
      "authors": [
        "K Wang",
        "X Wan",
        "Sentigan"
      ],
      "year": "2018",
      "venue": "Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence"
    },
    {
      "citation_id": "220",
      "title": "Baselines and bigrams: Simple, good sentiment and topic classification",
      "authors": [
        "S Wang",
        "C Manning"
      ],
      "year": "2012",
      "venue": "The 50th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "221",
      "title": "Attentionbased LSTM for aspect-level sentiment classification",
      "authors": [
        "Y Wang",
        "M Huang",
        "X Zhu",
        "L Zhao"
      ],
      "year": "2016",
      "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "222",
      "title": "Learning subjective adjectives from corpora",
      "authors": [
        "J Wiebe"
      ],
      "year": "2000",
      "venue": "Proceedings of the Seventeenth National Conference on Artificial Intelligence and Twelfth Conference on on Innovative Applications of Artificial Intelligence"
    },
    {
      "citation_id": "223",
      "title": "Word sense and subjectivity",
      "authors": [
        "J Wiebe",
        "R Mihalcea"
      ],
      "year": "2006",
      "venue": "ACL 2006, 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "224",
      "title": "Tracking point of view in narrative",
      "authors": [
        "J Wiebe"
      ],
      "year": "1994",
      "venue": "Computational Linguistics"
    },
    {
      "citation_id": "225",
      "title": "Development and use of a gold-standard data set for subjectivity classifications",
      "authors": [
        "J Wiebe",
        "R Bruce",
        "T Hara"
      ],
      "year": "1999",
      "venue": "Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics"
    },
    {
      "citation_id": "226",
      "title": "Opinion holder and target extraction based on the induction of verbal categories",
      "authors": [
        "M Wiegand",
        "J Ruppenhofer"
      ],
      "year": "2015",
      "venue": "Proceedings of the 19th Conference on Computational Natural Language Learning"
    },
    {
      "citation_id": "227",
      "title": "A system for subjectivity analysis",
      "authors": [
        "T Wilson",
        "P Hoffmann",
        "S Somasundaran",
        "J Kessler",
        "J Wiebe",
        "Y Choi",
        "C Cardie",
        "E Riloff",
        "S Patwardhan",
        "Opinionfinder"
      ],
      "year": "2005",
      "venue": "Proceedings of hlt/emnlp on interactive demonstrations"
    },
    {
      "citation_id": "228",
      "title": "Recognizing contextual polarity in phrase-level sentiment analysis",
      "authors": [
        "T Wilson",
        "J Wiebe",
        "P Hoffmann"
      ],
      "year": "2005",
      "venue": "HLT/EMNLP 2005, Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "229",
      "title": "Context and intonation in the perception of sarcasm",
      "authors": [
        "J Woodland",
        "D Voyer"
      ],
      "year": "2011",
      "venue": "Metaphor and Symbol"
    },
    {
      "citation_id": "230",
      "title": "Sentiment domain adaptation with multiple sources",
      "authors": [
        "F Wu",
        "Y Huang"
      ],
      "year": "2016",
      "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "231",
      "title": "Aspect-based opinion summarization with convolutional neural networks",
      "authors": [
        "H Wu",
        "Y Gu",
        "S Sun",
        "X Gu"
      ],
      "year": "2016",
      "venue": "2016 International Joint Conference on Neural Networks, IJCNN 2016"
    },
    {
      "citation_id": "232",
      "title": "Probase: A probabilistic taxonomy for text understanding",
      "authors": [
        "W Wu",
        "H Li",
        "H Wang",
        "K Zhu"
      ],
      "year": "2012",
      "venue": "Proceedings of the ACM SIGMOD International Conference on Management of Data"
    },
    {
      "citation_id": "233",
      "title": "Bridging domains using world wide knowledge for transfer learning",
      "authors": [
        "E Xiang",
        "B Cao",
        "D Hu",
        "Q Yang"
      ],
      "year": "2010",
      "venue": "IEEE Trans. Knowl. Data Eng"
    },
    {
      "citation_id": "234",
      "title": "Unsupervised data augmentation",
      "authors": [
        "Q Xie",
        "Z Dai",
        "E Hovy",
        "M.-T Luong",
        "Q Le"
      ],
      "year": "2019",
      "venue": "Unsupervised data augmentation",
      "arxiv": "arXiv:1904.12848"
    },
    {
      "citation_id": "235",
      "title": "Joint inference for fine-grained opinion extraction",
      "authors": [
        "B Yang",
        "C Cardie"
      ],
      "year": "2013",
      "venue": "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, ACL 2013"
    },
    {
      "citation_id": "236",
      "title": "Towards answering opinion questions: Separating facts from opinions and identifying the polarity of opinion sentences",
      "authors": [
        "H Yu",
        "V Hatzivassiloglou"
      ],
      "year": "2003",
      "venue": "Proceedings of the 2003 conference on Empirical methods in natural language processing"
    },
    {
      "citation_id": "237",
      "title": "Multimodal sentiment intensity analysis in videos: Facial gestures and verbal messages",
      "authors": [
        "A Zadeh",
        "R Zellers",
        "E Pincus",
        "L Morency"
      ],
      "year": "2016",
      "venue": "IEEE Intelligent Systems"
    },
    {
      "citation_id": "238",
      "title": "Tensor fusion network for multimodal sentiment analysis",
      "authors": [
        "A Zadeh",
        "M Chen",
        "S Poria",
        "E Cambria",
        "L.-P Morency"
      ],
      "year": "2017",
      "venue": "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "239",
      "title": "Memory fusion network for multi-view sequential learning",
      "authors": [
        "A Zadeh",
        "P Liang",
        "N Mazumder",
        "S Poria",
        "E Cambria",
        "L.-P Morency"
      ],
      "year": "2018",
      "venue": "AAAI"
    },
    {
      "citation_id": "240",
      "title": "Multimodal language analysis in the wild: CMU-MOSEI dataset and interpretable dynamic fusion graph",
      "authors": [
        "A Zadeh",
        "P Liang",
        "S Poria",
        "E Cambria",
        "L Morency"
      ],
      "year": "2018",
      "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018"
    },
    {
      "citation_id": "241",
      "title": "Multi-attention recurrent network for human communication comprehension",
      "authors": [
        "A Zadeh",
        "P Liang",
        "S Poria",
        "P Vij",
        "E Cambria",
        "L.-P Morency"
      ],
      "year": "2018",
      "venue": "AAAI"
    },
    {
      "citation_id": "242",
      "title": "Feeling and thinking: Preferences need no inferences",
      "authors": [
        "R Zajonc"
      ],
      "year": "1980",
      "venue": "AMERICAN PSYCHOLOGIST"
    },
    {
      "citation_id": "243",
      "title": "Towards automatic generation of product reviews from aspect-sentiment scores",
      "authors": [
        "H Zang",
        "X Wan"
      ],
      "year": "2017",
      "venue": "Proceedings of the 10th International Conference on Natural Language Generation"
    },
    {
      "citation_id": "244",
      "title": "Deep learning for sentiment analysis: A survey",
      "authors": [
        "L Zhang",
        "S Wang",
        "B Liu"
      ],
      "year": "2018",
      "venue": "Wiley Interdiscip. Rev. Data Min. Knowl. Discov"
    },
    {
      "citation_id": "245",
      "title": "Enhancing opinion role labeling with semantic-aware word representations from semantic role labeling",
      "authors": [
        "M Zhang",
        "P Liang",
        "G Fu"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019"
    },
    {
      "citation_id": "246",
      "title": "Irony detection via sentiment-based transfer learning",
      "authors": [
        "S Zhang",
        "X Zhang",
        "J Chan",
        "P Rosso"
      ],
      "year": "2019",
      "venue": "Inf. Process. Manag"
    },
    {
      "citation_id": "247",
      "title": "Character-level convolutional networks for text classification",
      "authors": [
        "X Zhang",
        "J Zhao",
        "Y Lecun"
      ],
      "year": "2015",
      "venue": "Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems"
    },
    {
      "citation_id": "248",
      "title": "Dynamic difficulty awareness training for continuous emotion prediction",
      "authors": [
        "Z Zhang",
        "J Han",
        "E Coutinho",
        "B Schuller"
      ],
      "year": "2018",
      "venue": "IEEE Transactions on Multimedia"
    },
    {
      "citation_id": "249",
      "title": "Adversarial multiple source domain adaptation",
      "authors": [
        "H Zhao",
        "S Zhang",
        "G Wu",
        "J Moura",
        "J Costeira",
        "G Gordon"
      ],
      "year": "2018",
      "venue": "Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems"
    },
    {
      "citation_id": "250",
      "title": "Gender bias in coreference resolution: Evaluation and debiasing methods",
      "authors": [
        "J Zhao",
        "T Wang",
        "M Yatskar",
        "V Ordonez",
        "K.-W Chang"
      ],
      "year": "2018",
      "venue": "Proceedings of the 2018 Conference of the North American Chapter"
    },
    {
      "citation_id": "251",
      "title": "Learning gender-neutral word embeddings",
      "authors": [
        "J Zhao",
        "Y Zhou",
        "Z Li",
        "W Wang",
        "K.-W Chang"
      ],
      "year": "2018",
      "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "252",
      "title": "Gender bias in contextualized word embeddings",
      "authors": [
        "J Zhao",
        "T Wang",
        "M Yatskar",
        "R Cotterell",
        "V Ordonez",
        "K.-W Chang"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies"
    },
    {
      "citation_id": "253",
      "title": "Emotional chatting machine: Emotional conversation generation with internal and external memory",
      "authors": [
        "H Zhou",
        "M Huang",
        "T Zhang",
        "X Zhu",
        "B Liu"
      ],
      "year": "2018",
      "venue": "Thirty-Second AAAI Conference on Artificial Intelligence"
    },
    {
      "citation_id": "254",
      "title": "Learning from labeled and unlabeled data with label propagation",
      "authors": [
        "X Zhu",
        "Z Ghahramani"
      ],
      "year": "2002",
      "venue": "Learning from labeled and unlabeled data with label propagation"
    },
    {
      "citation_id": "255",
      "title": "Pivot based language modeling for improved neural domain adaptation",
      "authors": [
        "Y Ziser",
        "R Reichart"
      ],
      "year": "2018",
      "venue": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2018"
    }
  ]
}