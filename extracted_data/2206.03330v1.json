{
  "paper_id": "2206.03330v1",
  "title": "Multimedia, Oct 2022, Lisbon, Portugal",
  "published": "2022-06-07T14:15:08Z",
  "authors": [
    "Zhiyao Cen",
    "Xiangwen Deng",
    "Hengjie Zheng",
    "Jianing Zhao",
    "Anjie Jin",
    "Chentao Fu",
    "Tianqi Wang",
    "Shangming Yang",
    "Jingdian Yang"
  ],
  "keywords": [
    "Emotion recognition",
    "EEG",
    "multi-modal",
    "brain mapping algorithm",
    "baseline filtering"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Emotion plays a significant role in our daily life. Recognition of emotion is wide-spread in the field of health care and human-computer interaction. Emotion is the result of the coordinated activities of cortical and subcortical neural processes, which correlate to specific physiological responses. However, the existing emotion recognition techniques failed to combine various physiological signals as one integrated feature representation. Meanwhile, many researchers ignored the problem of over-fitting model with high accuracy, which was actually false high accuracy caused by improper pre-processing. In this paper, sigmoid baseline filtering is conducted to solve the over-fitting problem from source. To construct a physiologicalbased algorithm, a 3D spatial and functional brain mapping is proposed based on human physiological mechanism and international electrode system, which combines the signals of the central and peripheral nervous system together. By combining the baseline filtering, 3D brain mapping, and simple 4D-CNN, a novel emotion recognition model is finally proposed. Experiment results demonstrate that the performance of the proposed model is comparable to the state of art algorithms.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Introduction",
      "text": "Positive emotion can improve our sense of happiness  [8] , while negative emotion may lead to health problems  [33] . Recently, emotion recognition has attracted more and more attention, especially in academic research.\n\nGenerally, two main approaches are adopted for human emotion recognition: One utilizes non-physiological signals, such as facial expression  [11] , intonation  [21] , and emotional vocabulary  [7] . The another one utilizes physiological signals generated by the CNS and PNS (short for central and peripheral nervous system), including EEG  [19] , EOG  [3] , and PSR  [22] . As far as we are concerned, physiological signals are considered more reliable information, which reflect objective physiological variations of human emotion.\n\nHowever, many developed emotion recognition models focused on the accuracy but ignored the hidden problems in the preprocessing. Recently, a pre-processing method named base-mean, first proposed in a paper  [43] , was employed in many EEG-based emotional recognition research  [1, 3, 9, 23, 30, 40, 45] . Despite the fact that these models achieved high accuracy, it is further validated that this popular base-mean method results in a severe over-fitting problem which will finally lead to the unreliability of a model and false high accuracy. As validation, mathematical demonstration and experiment results are shown. To solve this over-fitting problem while following the idea of removing baseline effect, sigmoid baseline filtering in frequency domain is proposed.\n\nOn the other hand, there has never been a reliable and physiological-based algorithm to combine different physiological signals as an integrated representation. Some researchers only adopted EEG for emotion recognition  [14, 22] , some roughly combined EEG with other physiological signals after separate feature extraction  [3, 36] . To construct a highly reliable integrated feature representation, a 3D spatial and functional brain mapping algorithm is proposed in this paper, following the idea of cortical cartography  [13] . In this mapping algorithm, EEG signal is mapped as CNS signal by following the electrode system  [18] , and the selected peripheral physiological signals are mapped as PNS signals by coordinating the research results of functional brain divisions  [4, 10, 17, 20, 44] . Finally, a simple 4D-CNN is applied to extract features of CNS and PNS signals simultaneously on spatial, temporal, and functional dimensions.\n\nIn summary, the main contributions of this paper are as follows:\n\n(1) The over-fitting problem of the popular base-mean is revealed, and sigmoid baseline filtering is proposed to solve the problem.\n\n(2) The CNS and PNS signals are integrated into one 3D representation for the first time, by applying the proposed spatial and functional brain mapping based on physiological research results and international electrode system.\n\n(3) Extensive comparative experiments on DEAP and SEED datasets are conducted to demonstrate that the proposed model has comparable or better performance in emotion recognition.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Related Works",
      "text": "The literature related to our model can be roughly divided into two categories.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Pre-Processing Of Cns And Pns Signals",
      "text": "Pre-processing is absolutely necessary for neuron network models. Both CNS and PNS signals are discrete timing signals, which record electrical intensity varying with time.\n\nIn  [45] , Z-sore normalization was implemented to normalize values per frame. In  [3] , different temporal window sizes were compared for EEG and EOG signals. Different band pass filtering in frequency domain were applied in  [25, 37, 43] . Besides that, one pre-processing with baseline called base-mean, proposed by Yang in  [43] , stood out for its high accuracy. This base-mean method tends to remove baseline effect in raw EEG signals. But it also unintentionally results in a high similarity problem, an over-fitting model, and the false high accuracy result. To overcome the above overfitting problem while following the idea of baseline effect removal, the sigmoid baseline filtering in frequency domain is proposed.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Feature Representation And Extraction Of Cns And Pns Signals",
      "text": "The emotional features in CNS and PNS signals can be extracted on three dimensions: spatial, temporal, and functional. Many researchers focused on spatial or temporal dimension and proposed various methods of feature representation and extraction, but very few of them made the best of PNS signals on the functional dimension.\n\nOn temporal dimension, CNS and PNS signals are time-series data in essence. So, many models were aimed at constructing and extracting temporal features. ACRNN in  [35]  was based on RNN and self-attention mechanism. Scaling-Net in  [16]  deployed convolution layers to extract temporal features. FAWT-RF in  [14]  transformed data to frequency domain for noise reduction and emotion classification.\n\nOn spatial dimension, emotional features also exist in the complex correlations between different EEG channels. To reconstruct the relative positional relationships of EEG signals, the form of 2D image series was put forward. Then, different interpolation algorithms were applied to further reconstruct the missing information  [32, 38] . Meanwhile, high-level spatial features were also revealed: Symmetric features were extracted by combining different ways of folding  [30] , and deeper relationships between adjacent channels were revealed by using dynamic and graphic EEG representation  [5] .\n\nOn functional dimension, the multi-modal data can be adopted as auxiliary signals with EEG in emotion recognition task. Multimodal data or peripheral physiological signals include EOG, EMG, GSR and so on  [19] , which reflect objective variations of human physiological function. However, existing models with multi-modal data failed to take CNS and PNS signals as an integrated feature representation  [31, 36] . In our proposed model, CNS signals and PNS signals are merged in 3D cuboid series using spatial and functional mapping, which maximizes the potential of all physiological signals.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Proposed Method",
      "text": "The proposed model is composed of three parts: the sigmoid baseline filtering, the spatial brain mapping of CNS signals, the functional brain mapping of PNS signals, and a simple 4D-CNN. The overview framework of our proposed model is shown in Fig  1 .",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Pre-Processing With Baseline Signals",
      "text": "Pre-processing is essential for neuron networks, and baselinerelated pre-processing of EEG signals was already conducted in research field  [3] . Recently, one popular pre-processing called basemean, which was first proposed by Yang  [43] , was employed in many EEG-based emotion recognition research  [1, 23, 30] . However, it is later proved that this base-mean method leads to severe over-fitting problem.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Strengths And Weaknesses Of Base-Mean Pre-Processing.",
      "text": "Base-mean pre-processing is a simple and effective method to remove the baseline effect or the resting state in EEG signals. But it also results in extra similarity between training set and test set, which leads to an over-fitting model with false high accuracy result.\n\nThe strengths of base-mean are its simplicity and effectiveness of removing baseline effect in raw EEG data. As to simplicity, the base-mean only contains simple shape transformation and common mathematical operation. As to effectiveness, many models achieved very high accuracy by using base-mean method: The accuracy of LSTM-CNN in  [43]  improved greatly to 97.8%, 91.03% for arousal and valence classification. Additionally, other models using basemean method also achieved very high accuracy: 96.61%, 96.43% in 3D-CNN  [45] , and 94.22%, 94.58% in 4D-Attention  [40] ).\n\nThe major weaknesses of base-mean method are the similarity and over-fitting problems. Crucial steps of base-mean are explained below. In the beginning, the Base-Mean and Raw-EEG matrices of the same shape are the results of splitting and taking elementwise mean values of the EEG data. Then Base-Removed matrices are equal to subtraction of Raw-EEG with Base-Mean. On the surface, the subtraction is considered as removal of baseline effect. But actually, it is also a way of baseline marking, as the homologous Raw-EEG matrices, which correspond to the same emotion label, are marked by the same Base-Mean matrix. Thus, similarity between homologous Base-Removed matrices increases for their same baseline feature. Then, the random shuffling separates homologous Base-Removed matrices into a training set and test set randomly. Finally, the extra baseline marking can be learned easily by the neuron network, which leads to over-fitting and false high accuracy.\n\nIn Table  2 , the results validate the existence of the high similarity problem and the baseline marking. On the one hand, base-mean indeed removes the baseline effect, for the similarity within homologous Base-Removed matrices actually increased compared to Raw-EEG. On the other hand, the notable increase of similarity between Base-Removed and Base-Mean validates the existence of baseline marking.\n\nwhere A and B represents two matrices of the same shape, m and n represents number of channels and frames per data, cov represents the covariance, and ùúé represents standard deviation.\n\nIn Table  1 , the results of DT, KNN, and SVM are listed, showing the severe over-fitting problem and false high accuracy by using base-mean method. The 1st and 2nd rows show that the accuracy is very high even with minimal training ratio by using base-mean, which is usually a sign of over-fitting. The 2nd, 3rd, and 4th rows show that the model using base-mean actually learned a lot from the baseline features in the homologous Base-Removed matrices. The 5th and 6th rows show that the severe over-fitting results by using base-mean in the way of replacing EEG data with randomvalued but normalized data. All these results prove that base-mean pre-processing leads to over-fitting and false high accuracy.\n\nIn the table, Raw represents EEG data without base-mean preprocessing, Random represents usage of random-valued but normalized matrices, and Split (ratio) represents ways of train-test-split and the training set ratio. Splitting by data means dividing the homologous matrices generated from one original data all to the training set or all to the test set, whereas the splitting by index means randomly dividing the homologous matrices from one original data between the training and test set based on the exact ratio. The over-fitting problem of base-mean stems from dealing with different homologous Raw-EEG matrices by subtracting them from the same Base-Mean matrix. To solve the high similarity and overfitting problem from source, the sigmoid baseline filtering is conducted in frequency domain, following the idea of baseline effect removal, multiple band-pass filter, and echo reduction in multiple microphone audio system.  [12, 39] . The filtering mainly contains two steps: First, convert data to frequency domain and quantify the baseline effect; Second, remove the baseline effect and convert data back to time domain.\n\nThe raw data are divided into Base-Mean and Raw-EEG matrices, which are transformed into frequency domain by using Fast Fourier Transform (FFT) as follows,\n\nwhere R and B represents the Raw-EEG and Base-Mean matrices, while RT and BT represents Raw-EEG and Base-Mean matrices after FFT.\n\nThen, the baseline influence can be measured by the difference between the values of RT and BT, forming the Deactivate-Filter matrices which are calculated as follows,\n\nwhere D represents Deactivate-Filter matrix containing quantified value of baseline effect in every Raw-EEG matrix. Sig means the sigmoid function which softens the result. Notice that Deactivate-Filter is computed differently even for homologous RT. So the high similarity problem is avoided, and the over-fitting problem is solved from source. Finally, the Filtered-EEG matrices are calculated using above RT, BT, and D matrices and transformed back to time domain, which is shown as follows,\n\nwhere F represents Filtered-EEG, symbol ‚Ä¢ indicates element-wise multiplication (Hadamard product). IFFT means Inverse Fast Fourier Transform (IFFT).\n\nTo summarize, the core idea of sigmoid baseline filtering is to remove baseline effect from every segment of raw EEG. Specifically, to lower the value of some frequencies in Raw-EEG, which have high intensity in Base-Mean. Unlike base-mean, the over-fitting problem is avoided from source for every homologous EEG segments are dealt with differently. The similarity comparison between matrices using sigmoid baseline filtering is shown in Table  2 .",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Spatial And Functional Brain Mapping Of Cns And Pns Signals",
      "text": "To construct a reliable and integrated feature representation for both CNS and PNS signals, the 3D spatial and functional brain mapping algorithm is proposed, following the concept of the cortical cartography  [13] . This brain mapping algorithm has three steps: In the figure, names like ùêπùê∂ 1 represent EEG electrode channels, and characters like F, Fp, T, C, O, and P represent frontal, prefrontal, temporal, central, occipital, and parietal lobes. The odd and even number subscript of characters respectively represent left and right hemispheres of brain.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Selection Of Pns Signals.",
      "text": "In our proposed model, the essence of PNS functional brain mapping is to select appropriate physiological signals as PNS signals, and map them into the 3D cuboid series. As for PNS signals selection, electrode placement system and functional brain division literature are referenced.\n\nOn DEAP dataset, there are 8 types of PNS signals: GSR, Respiration amplitude, Skin temperature, Blood volume by plethysmograph, Electromyogram (EMG) of Zygomaticus and Trapezius muscles, and Electrooculogram (EOG) of vertical and horizontal. Peripheral signals with apparent brain division and close to emotion are preferentially chosen to be the final PNS signals.\n\nEMG is an auxiliary examination of some neurological and muscular diseases  [27, 29] . It reflects the health and excitability of nervous system related to muscle movement, which relates to motor cortex located in anterior central gyrus at the boundary of frontal and central lobes  [10] .  Respiration amplitude was adopted in many emotion-related studies, like feedback of Laughter  [15]  and sleep  [2] . The respiration center  [44] , which gives orders to respiratory muscles, is located in the medulla oblongata and pons, which is close to the bottom of brain.\n\nSkin temperature was also adopted in many emotional recognition tasks  [20] . The preoptic anterior hypothalamus (POAH) is the principal center for body temperature regulation  [17] , which is close to the center of brain.\n\nEOG records electrical signals of vertical and horizontal eye movements, which was essential in some emotion recognition models  [31] . Since many brain regions are involved with eye movement and human vision, two visual cortex in the frontal lobe and pariental lobe are both considered  [4] .\n\nGSR is short for Galvanic Skin Response. It is usually regarded as a measurement of perspiration, which reflects stress and surprise  [26] . Studies showed that GSR is related to arousal  [28] , but no corresponding brain region is found for GSR.\n\nElectrocardiogram was also adopted in the field of emotion recognition. But the existence of cardiac autonomic nervous means that heart functions quite independently, and there is no brain region specifically associated with it.\n\nBlood volume is an essential index in medicine. However, it is influenced by many factors in complex ways, so no specific brain region is related. Besides that, the correlation between blood volume and emotion is also not yet verified.\n\nAs mentioned above, EOG, EMG, Respiration amplitude, and Skin temperature are selected as PNS signals for further functional mapping.",
      "page_start": 5,
      "page_end": 6
    },
    {
      "section_name": "Functional Brain Mapping Of Pns Signals.",
      "text": "After the selection of peripheral physiological signals, the functional brain divisions of different PNS signals are also evident. Then, the mapping locations for PNS signals can be calculated, referencing the 10-20 international electrode placement system and functional brain division literature, while using mapped CNS channels as anchor points. The proposed 3D functional mapping is shown on the right side of Fig 2 . \nFirst, the brain regions are evident for PNS signals according to the physiological research results related to peripheral signals. This process is elaborated in 3.2.2 and recorded as follows,\n\nwhere GetRegion function returns the brain region (BR) of a given type (T) of PNS signals.\n\nSecond, find the standard electrodes in the corresponding brain region. The center of brain region is calculated as follows,\n\nwhere GetElectrodes function returns the electrode locations according to the given brain region, DPC represents the center of the brain region, and Avg function returns integer-rounded center location of given electrode locations while avoiding overlapping with the mapped CNS signals. Table  3  shows the corresponding brain divisions and standard electrodes of PNS signals, where names like ùêπùê∂ 1 represent name of EEG electrode channels, according to the 10-20 international electrode placement system. Third, the final mapping locations of PNS signals are calculated as follows, ùëÄùëÉ = ùê¥ùë£ùëî(ùê∑ùëÉùê∂, ùê∂ùëÉ),  (9)  where CP represents the brain center which is close to the hypothalamus, and MP represents the final mapping locations of PNS signals. The reason for using brain center is that the CNS signals are recorded on the brain surface, so the mapping of PNS signals should be closer to the brain center.",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "Experiments 4.1 Materials",
      "text": "The DEAP dataset is selected to evaluate the performance of proposed model, which is extensively used in many EEG-related studies. Comparative experiments on SEED dataset are also conducted, which is shown in Chapter 5.3.3.\n\nThe DEAP  [19]  is an open dataset developed by Koelstra and colleagues. This dataset contains 32 EEG channels and 8 peripheral physiological channels, which were collected when 32 participants watched 40 videos, each with 60 seconds duration. Each data contains 63s signals, and the first 3s are the baseline signals. The participants rated a self-assessment of arousal, valence, liking, and dominance after watching 60s video. The signals are down-sampled to 128hz, and the data size of DEAP is (32 √ó 40 √ó (32+8) √ó (128 √ó 63)), which represents (participants √ó videos √ó channels √ó frames). The structure of the DEAP dataset is shown in Table  4 .",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Implementation Details",
      "text": "For pre-processing, data is processed with some basic algorithms before the sigmoid baseline filtering. Z-score algorithm is used to normalize every temporal frame, making it easier for network to train. Dualization of emotion labels is utilized for two-class classification task on DEAP dataset (score in range  [5, 9)  is positive and [1, 5) is negative). For the 4D-CNN network, details of parameters and layers are listed below. To extract spatial and temporal features in 3D series data (frames √ó (length √ó width √ó height)), the first two layers are 3D convolution layer, which is followed by one 1D convolution layer, and three fully connected layers are adopted for the final emotion classification. Traditionally, RELU is considered as an excitation function. Dropout layer with 0.5 dropping rate and batch-normalization layer are implemented after each 3D convolution layer. Zero padding has been already implemented in the stage of 3D brain mapping. The kernel size is (1",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Results And Discussion 5.1 Results For Subject-Dependent Classification",
      "text": "To further verify the effectiveness of the proposed model, the subject-independent comparative experiments are conducted between our model and the latest models, including hybrid neuron network, multi-modal network, attention network and so on. Both CNN-SAE-DNN  [24]  and CNN-LSTM  [43]  are hybrid network models, which can be used to extract features on multiple dimensions. EEG-EOG  [3]  combines EEG and EOG signals for emotion recognition. 2D-CNN  [22]  is implemented to extract features of EEG and GSR on spatial and temporal dimensions. 4D-CNN  [40]  is based on 4D feature representations, and the attention mechanism is applied. SFE-Net  [30]      ; Second, our model performs the best among other models using multi-modal data (2D-CNN and EEG-EOG); Third, the proposed model is still competitive with models applying base-mean pre-processing with false high accuracy (CNN-LSTM, SFE-Net). The specific five-fold results of proposed model for emotion classification on DEAP dataset are 92.22%, 92.31%, 92.17%, 92.13%, and 93.18% for arousal and 92.46%, 92.68%, 92.33%, 92.68%, and 93.06% for valence.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Results For Subject-Independent Classification",
      "text": "To show the comparable performance of the proposed model, testing results of proposed model and state-of-the-art models are compared. Models include dynamic graph convolutional neuron network (DGCNN)  [34] , multi-grain cascade forest (MC-Forrest)  [6] ,    [42]  and CNN-RNN  [44] . Generally, the proposed model shows obvious advantages in subjectdependent emotion classification: The mean value of 32 participants' classification accuracy is 96.62% for arousal and 95.89% for valence.\n\nIn DGCNN, the dynamic graphic convolution helps to iterate and find the correlation between EEG channels. In MC-Forest, an enhanced deep random forest is employed to extract complex features. In Cont-CNN, baseline signals are utilized, and continuous convolution layers are implemented. In CNN-RNN, both spatial and temporal characteristics are extracted. Our proposed model benefits from the baseline and constructs abundant spatial functional features. The subject-dependent experiment results are shown in Table  5 .\n\nFrom the table, the accuracy of the proposed model is about 10% higher than Cont-CNN and CNN-RNN, more stable than DGCNN, and roughly the same as MC-Forest. The results show that our model with baseline filter and brain mapping is very efficient and effective for individual emotion recognition.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Discussion",
      "text": "In this section, three groups of comparative experiments are conducted to further evaluate the performance of the proposed method. The experiments include: Compare different levels of spatial and functional brain mapping to prove the effectiveness; Compare different combinations of 3D and 1D convolution layers to find the best fit; Compare different levels of 3D spatial mapping on SEED dataset to fully explore the possibility of 3D brain mapping. For all comparative experiments, the training epoch is set to 50, while other settings, processes, and structure remain unchanged as much as possible.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Different Levels Of Spatial And Functional Brain Mapping.",
      "text": "To show the advantages of spatial and functional brain mapping of CNS and PNS signals, four levels of brain mapping are compared: 2D image EEG series, 3D series after spatial brain mapping, 3D series after spatial and functional brain mapping (the proposed model), 3D series lacking of specific PNS signal. The comparison results in Table  6  show that the 3D spatial and functional mapping is indeed effective, achieving about 7% higher accuracy than 2D image EEG series. However, the results also indicate that the spatial mapping alone is less efficient than 2D series. This phenomenon is actually results from the inadequate number of EEG channels on DEAP dataset (32 in total), which is further validated in chapter 3.2 on SEED dataset. The results also show that EOG and EMG are the most effective PNS signals, while the respiration amplitude seems to be the least useful.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Different Combinations Of Convolution Layers.",
      "text": "To show the effectiveness of the developed 3D plus 1D convolution layers and find its best fit, three different combinations of 3D and 1D convolution layers are compared: one 3D convolution layer, two 3D convolution layers, one 3D with one 1D convolution layers, and two 3D with one 1D convolution layers. The experiment results are shown in table 7, indicating that the best arrangement is two 3D with one 1D convolution layers, which achieved about 5% higher accuracy compared to the model with one 3D convolution layer. The results show that two 3D with one 1D convolution layers can extract spatial, temporal, and functional features very well for emotion classification tasks.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Spatial Mapping On Seed Dataset.",
      "text": "In order to show the effectiveness of brain mapping algorithm on other dataset, different levels of spatial mapping are conducted on SEED dataset  [46] .\n\nThe SEED dataset is similar to DEAP dataset but with more EEG channels (62) and no multi-modal data. The data in SEED dataset is transformed to be similar to data on DEAP, which includes the data shape of (45 √ó 45 √ó 62 √ó (128 √ó 63)) representing (participants √ó videos √ó channels √ó frames), electrodes relative positions, and keeping only negative and positive data labels.\n\nThe results are shown in Table  8 . In the table, 2D standard represents 2D EEG series with 62 channels, shrink-32 represents 3D mapping of 32 channels,and expand-146 represents 3D mapping of 146 EEG channels. Extra channels in expand-146 are the copies of original channels, which is filled randomly near the brain center. From the Table, the 3D spatial mapping achieves higher results than 2D EEG image series with sufficient EEG channels. This also explains the seeming ineffectiveness of spatial mapping on DEAP dataset: the lack of EEG channels (32 EEG channels on DEAP dataset).",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Conclusion",
      "text": "The proposed model is proposed to improve accuracy of emotion recognition while avoiding over-fitting, which is composed of three parts: the sigmoid baseline filtering for pre-processing, the spatial and functional brain mapping of CNS and PNS signals for integrated feature representation, and compact 4D-CNN for feature extraction and emotion recognition. By combining baseline with the spatial, temporal, and functional information of various physiological signals, our proposed model can automatically extract features to accomplish the goal of emotion recognition. In addition, it is also discussed that the effectiveness of spatial and functional brain mapping, different combination of convolution layers, and potential of brain mapping on other dataset. Specifically, the accuracy of emotion classification on DEAP dataset is 92.31% for valence and 92.76% for arousal. Abundant experiments show that the proposed model can obtain top performance for emotion recognition.",
      "page_start": 9,
      "page_end": 9
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: The overview framework of the proposed method. Firstly, the sigmoid baseline filtering is proposed as substitute for",
      "page": 4
    },
    {
      "caption": "Figure 2: In the figure, names like ùêπùê∂1 represent EEG electrode channels,",
      "page": 5
    },
    {
      "caption": "Figure 2: The spatial and functional brain mapping. The left side is the spatial mapping of CNS signals (EEG), where names",
      "page": 6
    },
    {
      "caption": "Figure 2: First, the brain regions are evident for PNS signals according to",
      "page": 6
    },
    {
      "caption": "Figure 3: The structure of 4D-CNN",
      "page": 7
    },
    {
      "caption": "Figure 4: and Fig 5, from which we can",
      "page": 7
    },
    {
      "caption": "Figure 4: The arousal classification accuracies (%) of all sub-",
      "page": 8
    },
    {
      "caption": "Figure 5: The valence classification accuracies (%) of all sub-",
      "page": 8
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "DGCN N\nM C-Fo",
          "Column_7": "rest"
        },
        {
          "Column_1": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "Cont-C\nCN N -R",
          "Column_7": "N N\nN N"
        },
        {
          "Column_1": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "O urs",
          "Column_7": ""
        }
      ],
      "page": 8
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "DGCN N\nM C-Fo",
          "Column_7": "rest"
        },
        {
          "Column_1": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "Cont-C\nCN N -R",
          "Column_7": "N N\nN N"
        },
        {
          "Column_1": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "O urs",
          "Column_7": ""
        }
      ],
      "page": 8
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Automated Feature Extraction on AsMap for Emotion Classification Using EEG",
      "authors": [
        "Zaved Ahmed",
        "Nidul Sinha",
        "Souvik Phadikar",
        "Ebrahim Ghaderpour"
      ],
      "year": "2022",
      "venue": "Sensors"
    },
    {
      "citation_id": "2",
      "title": "General Anesthesia, Sleep, and Coma",
      "authors": [
        "Emery Brown",
        "Ralph Lydic",
        "Nicholas Schiff"
      ],
      "year": "2010",
      "venue": "General Anesthesia, Sleep, and Coma"
    },
    {
      "citation_id": "3",
      "title": "Combination of EOG and EEG for emotion recognition over different window sizes",
      "authors": [
        "Huili Cai",
        "Xiaofeng Liu",
        "Aimin Jiang",
        "Rongrong Ni",
        "Xu Zhou",
        "Angelo Cangelosi"
      ],
      "year": "2021",
      "venue": "2021 IEEE 2nd International Conference on Human-Machine Systems (ICHMS)"
    },
    {
      "citation_id": "4",
      "title": "Head Movements Evoked by Electrical Stimulation in the Frontal Eye Field of the Monkey: Evidence for Independent Eye and Head Control",
      "authors": [
        "Lewis Chen"
      ],
      "year": "2006",
      "venue": "Journal of neurophysiology"
    },
    {
      "citation_id": "5",
      "title": "Epilepsy Classification for Mining Deeper Relationships between EEG Channels based on GCN",
      "authors": [
        "Xin Chen",
        "Yuanjie Zheng",
        "Yi Niu",
        "Chengiiang Li"
      ],
      "year": "2020",
      "venue": "Epilepsy Classification for Mining Deeper Relationships between EEG Channels based on GCN"
    },
    {
      "citation_id": "6",
      "title": "Emotion Recognition from Multi-Channel EEG via Deep Forest",
      "authors": [
        "Juan Cheng",
        "Meiyao Chen",
        "Chang Li",
        "Yu Liu",
        "Rencheng Song",
        "Aiping Liu",
        "Xun Chen"
      ],
      "year": "2020",
      "venue": "IEEE Journal of Biomedical and Health Informatics PP"
    },
    {
      "citation_id": "7",
      "title": "Multi-Modal Emotion Recognition from Speech and Text. Computational Linguistics and Chinese Language Processing 9",
      "authors": [
        "Ze-Jing Chuang",
        "Chung-Hsien Wu"
      ],
      "year": "2004",
      "venue": "Multi-Modal Emotion Recognition from Speech and Text. Computational Linguistics and Chinese Language Processing 9"
    },
    {
      "citation_id": "8",
      "title": "Happiness Unpacked: Positive Emotions Increase Life Satisfaction by Building Resilience",
      "authors": [
        "Michael Cohn",
        "Barbara Fredrickson",
        "Stephanie Brown",
        "Joseph Mikels",
        "Anne Conway"
      ],
      "year": "2009",
      "venue": "Happiness Unpacked: Positive Emotions Increase Life Satisfaction by Building Resilience"
    },
    {
      "citation_id": "9",
      "title": "SFE-Net: EEG-based Emotion Recognition with Symmetrical Spatial Feature Extraction",
      "authors": [
        "Xiangwen Deng",
        "Shangming Yang",
        "Junlin Zhu"
      ],
      "year": "2021",
      "venue": "SFE-Net: EEG-based Emotion Recognition with Symmetrical Spatial Feature Extraction"
    },
    {
      "citation_id": "10",
      "title": "Evoked Potentials of the Somatic Cortex and EMG Reactions of the Shoulder Muscles Elicited by Passive Extension of the Elbow Joint in Unanesthetized Cats",
      "authors": [
        "G Dovgalets"
      ],
      "year": "2004",
      "venue": "Neurophysiology"
    },
    {
      "citation_id": "11",
      "title": "Emotion recognition via facial expression and affective prosody in schizophrenia: A methodological review",
      "authors": [
        "Jane Edwards",
        "Henry Jackson",
        "Philippa Pattison"
      ],
      "year": "2002",
      "venue": "Clinical psychology review"
    },
    {
      "citation_id": "12",
      "title": "Reducing noise in audio systems",
      "authors": [
        "Gary Elko"
      ],
      "year": "2007",
      "venue": "Journal of The Acoustical Society of America -J ACOUST SOC AMER"
    },
    {
      "citation_id": "13",
      "title": "Effects of Aminophylline on Respiratory Center and Reflex Activity in Premature Infants with Apnea",
      "authors": [
        "Tilo Gerhardt",
        "Jean Mccarthy",
        "Eduardo Bancalari"
      ],
      "year": "1983",
      "venue": "Pediatric Research"
    },
    {
      "citation_id": "14",
      "title": "Cross-Subject Emotion Recognition Using Flexible Analytic Wavelet Transform From EEG Signals",
      "year": "2018",
      "venue": "IEEE Sensors Journal"
    },
    {
      "citation_id": "15",
      "title": "Coherent with laughter: Subjective experience, behavior, and physiological responses during amusement and joy",
      "authors": [
        "David Herring",
        "Mary Burleson",
        "Nicole Roberts",
        "Michael Devine"
      ],
      "year": "2011",
      "venue": "International Journal of Psychophysiology"
    },
    {
      "citation_id": "16",
      "title": "ScalingNet: extracting features from raw EEG data for emotion recognition",
      "authors": [
        "Jingzhao Hu",
        "Chen Wang",
        "Qiaomei Jia",
        "Qirong Bu"
      ],
      "year": "2021",
      "venue": "ScalingNet: extracting features from raw EEG data for emotion recognition"
    },
    {
      "citation_id": "17",
      "title": "Types of neuronal responses in the rat thalamus to peripheral temperature changes",
      "authors": [
        "R Jahns"
      ],
      "year": "1975",
      "venue": "Experimental Brain Research"
    },
    {
      "citation_id": "18",
      "title": "The ten-twenty electrode system of the International Federation. The International Federation of Clinical Neurophysiology",
      "authors": [
        "George Klem",
        "Hans L√ºders",
        "Herbert Jasper",
        "Christian Elger"
      ],
      "year": "1999",
      "venue": "The ten-twenty electrode system of the International Federation. The International Federation of Clinical Neurophysiology"
    },
    {
      "citation_id": "19",
      "title": "DEAP: A Database for Emotion Analysis Using Physiological Signals",
      "authors": [
        "Sander Koelstra",
        "Christian M√ºhl",
        "Mohammad Soleymani",
        "Jong-Seok Lee",
        "Ashkan Yazdani",
        "Touradj Ebrahimi",
        "Anton Thierry Pun",
        "Ioannis Nijholt",
        "Patras"
      ],
      "year": "2011",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "20",
      "title": "The use of nasal skin temperature measurements in studying emotion in macaque monkeys",
      "authors": [
        "K Kuraoka",
        "Nakamura"
      ],
      "year": "2011",
      "venue": "PHYSIOLOGY AND BEHAVIOR"
    },
    {
      "citation_id": "21",
      "title": "Emotion recognition by speech signals",
      "authors": [
        "Oh-Wook Kwon",
        "Kwokleung Chan",
        "Jiucang Hao",
        "Te-Won Lee"
      ],
      "year": "2003",
      "venue": "Emotion recognition by speech signals"
    },
    {
      "citation_id": "22",
      "title": "Electroencephalography Based Fusion Two-Dimensional (2D)-Convolution Neural Networks (CNN) Model for Emotion Recognition System",
      "authors": [
        "Sae-Byuk Yea-Hoon Kwon",
        "Shin-Dug Shin",
        "Kim"
      ],
      "year": "2018",
      "venue": "Sensors"
    },
    {
      "citation_id": "23",
      "title": "A feature-based on potential and differential entropy information for electroencephalogram emotion recognition",
      "authors": [
        "Dongdong Li",
        "Li Xie",
        "Bing Chai",
        "Zhe Wang"
      ],
      "year": "2021",
      "venue": "Electronics Letters"
    },
    {
      "citation_id": "24",
      "title": "EEG-Based Emotion Classification Using a Deep Neural Network and Sparse Autoencoder",
      "authors": [
        "Junxiu Liu",
        "Guopei Wu",
        "Yuling Luo",
        "Senhui Qiu",
        "Su Yang",
        "Wei Li",
        "Yifei Bi"
      ],
      "year": "2020",
      "venue": "Frontiers in Systems Neuroscience"
    },
    {
      "citation_id": "25",
      "title": "EEG-Based Emotion Classification Using Spiking Neural Networks",
      "authors": [
        "Yuling Luo",
        "Qiang Fu",
        "Juntao Xie",
        "Yunbai Qin",
        "Guopei Wu",
        "Junxiu Liu",
        "Frank Jiang",
        "Yi Cao",
        "Xuemei Ding"
      ],
      "year": "2020",
      "venue": "EEG-Based Emotion Classification Using Spiking Neural Networks"
    },
    {
      "citation_id": "26",
      "title": "The GSR in the detection of guilt",
      "authors": [
        "T Lykken",
        "David"
      ],
      "year": "1959",
      "venue": "Journal of Applied Psychology"
    },
    {
      "citation_id": "27",
      "title": "Electrocardiogram-based emotion recognition system using empirical mode decomposition and discrete Fourier transform",
      "authors": [
        "M Murugappan",
        "Wan Khairunizam",
        "Sazali Yaacob",
        "Jerritta Selvaraj"
      ],
      "year": "2013",
      "venue": "Expert Systems"
    },
    {
      "citation_id": "28",
      "title": "A continuous and objective evaluation of emotional experience with interactive play environments",
      "authors": [
        "Regan Mandryk",
        "Margaret Atkins",
        "Kori Inkpen"
      ],
      "year": "2006",
      "venue": "Conference on Human Factors in Computing Systems -Proceedings"
    },
    {
      "citation_id": "29",
      "title": "Waking genioglossal electromyogram in sleep apnea patients versus normal controls (a neuromuscular compensatory mechanism)",
      "authors": [
        "D J W S Mezzanotte",
        "D P Tangel",
        "White"
      ],
      "year": "1992",
      "venue": "Journal of Clinical Investigation"
    },
    {
      "citation_id": "30",
      "title": "Emotion Classification Using Fast Fourier Transform and Recurrent Neural Networks",
      "authors": [
        "Hendra Prawira",
        "Sinta Sundari",
        "Esmeralda Djamal",
        "Arlisa Wulandari"
      ],
      "year": "2021",
      "venue": "Emotion Classification Using Fast Fourier Transform and Recurrent Neural Networks"
    },
    {
      "citation_id": "31",
      "title": "Correlated Attention Networks for Multimodal Emotion Recognition",
      "authors": [
        "Jie-Lin Qiu",
        "Xiao-Yu Li",
        "Kai Hu"
      ],
      "year": "2018",
      "venue": "Correlated Attention Networks for Multimodal Emotion Recognition"
    },
    {
      "citation_id": "32",
      "title": "EEG Channel Interpolation Using Deep Encoder-decoder Networks",
      "authors": [
        "Sari Saba-Sadiya",
        "Tuka Alhanai",
        "Taosheng Liu",
        "Mohammad Ghassemi"
      ],
      "year": "2020",
      "venue": "2020 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)"
    },
    {
      "citation_id": "33",
      "title": "Hostility, Anger, Aggressiveness, and Coronary Heart Disease: An Interpersonal Perspective on Personality, Emotion, and Health",
      "authors": [
        "Timothy Smith",
        "Kelly Baron",
        "John Ruiz",
        "Linda Gallo"
      ],
      "year": "2005",
      "venue": "Journal of personality"
    },
    {
      "citation_id": "34",
      "title": "EEG Emotion Recognition Using Dynamical Graph Convolutional Neural Networks",
      "authors": [
        "Tengfei Song",
        "Wenming Zheng",
        "Peng Song",
        "Zhen Cui"
      ],
      "year": "2018",
      "venue": "IEEE Transactions on Affective Computing PP"
    },
    {
      "citation_id": "35",
      "title": "EEG-based Emotion Recognition via Channel-wise Attention and Self Attention",
      "authors": [
        "Wei Tao",
        "Chang Li",
        "Rencheng Song",
        "Juan Cheng",
        "Yu Liu",
        "Feng Wan",
        "Xun Chen"
      ],
      "year": "2020",
      "venue": "IEEE Transactions on Affective Computing PP"
    },
    {
      "citation_id": "36",
      "title": "Multimodal Emotion Recognition using Deep Neural Network-A Survey",
      "authors": [
        "V Haritha",
        "Pillai Praveen Thulasidharan"
      ],
      "year": "2018",
      "venue": "International Journal of Computer Sciences and Engineering"
    },
    {
      "citation_id": "37",
      "title": "Emotion recognition with convolutional neural network and EEG-based EFDMs",
      "authors": [
        "Fei Wang",
        "Shichao Wu",
        "Weiwei Zhang",
        "Zongfeng Xu",
        "Yahui Zhang",
        "Chengdong Wu",
        "Sonya Coleman"
      ],
      "year": "2020",
      "venue": "Neuropsychologia"
    },
    {
      "citation_id": "38",
      "title": "Automatic Epileptic Seizure Detection in EEG Signals Using Multi-Domain Feature Extraction and Nonlinear Analysis",
      "authors": [
        "Lina Wang",
        "Weining Xue",
        "Yang Li",
        "Meilin Luo",
        "Jie Huang",
        "Weigang Cui",
        "Chao Huang"
      ],
      "year": "2017",
      "venue": "Entropy"
    },
    {
      "citation_id": "39",
      "title": "Apparatus and method of noise and echo reduction in multiple microphone audio systems",
      "authors": [
        "S Wang",
        "S Gupta",
        "Elt Choy"
      ],
      "year": "2012",
      "venue": "Apparatus and method of noise and echo reduction in multiple microphone audio systems"
    },
    {
      "citation_id": "40",
      "title": "Zhendi Chen, and Quansheng Ren. 2021. 4D Attention-based Neural Network for EEG Emotion Recognition",
      "authors": [
        "Guowen Xiao",
        "Mengwen Ye",
        "Bowen Xu"
      ],
      "year": "2021",
      "venue": "Zhendi Chen, and Quansheng Ren. 2021. 4D Attention-based Neural Network for EEG Emotion Recognition"
    },
    {
      "citation_id": "41",
      "title": "A Multi-Column CNN Model for Emotion Recognition from EEG Signals",
      "authors": [
        "Heekyung Yang",
        "Jongdae Han",
        "Kyungha Min"
      ],
      "year": "2019",
      "venue": "Sensors"
    },
    {
      "citation_id": "42",
      "title": "Continuous Convolutional Neural Network with 3D Input for EEG-Based Emotion Recognition",
      "authors": [
        "Yilong Yang",
        "Qingfeng Wu",
        "Yazhen Fu",
        "Xiaowei Chen"
      ],
      "year": "2018",
      "venue": "Continuous Convolutional Neural Network with 3D Input for EEG-Based Emotion Recognition"
    },
    {
      "citation_id": "43",
      "title": "Emotion Recognition from Multi-Channel EEG through Parallel Convolutional Recurrent Neural Network",
      "authors": [
        "Y Yang",
        "Q Wu",
        "Q Ming",
        "Y Wang",
        "X Chen"
      ],
      "year": "2018",
      "venue": "2018 International Joint Conference on Neural Networks (IJCNN)"
    },
    {
      "citation_id": "44",
      "title": "Emotion Recognition from Multi-Channel EEG through Parallel Convolutional Recurrent Neural Network",
      "authors": [
        "Yilong Yang",
        "Qingfeng Wu",
        "Ming Qiu",
        "Wang Yingdong",
        "Xiaowei Chen"
      ],
      "year": "2018",
      "venue": "Emotion Recognition from Multi-Channel EEG through Parallel Convolutional Recurrent Neural Network"
    },
    {
      "citation_id": "45",
      "title": "A 3D Convolutional Neural Network for Emotion Recognition based on EEG Signals",
      "authors": [
        "Y Zhao",
        "J Yang",
        "J Lin",
        "D Yu",
        "X Cao"
      ],
      "year": "2020",
      "venue": "2020 International Joint Conference on Neural Networks (IJCNN)"
    },
    {
      "citation_id": "46",
      "title": "Identifying Stable Patterns over Time for Emotion Recognition from EEG",
      "authors": [
        "Wei-Long Zheng",
        "Jia-Yi Zhu",
        "Bao-Liang Lu"
      ],
      "year": "2016",
      "venue": "IEEE Transactions on Affective Computing"
    }
  ]
}