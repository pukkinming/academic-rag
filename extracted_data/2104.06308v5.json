{
  "paper_id": "2104.06308v5",
  "title": "Sfe-Net: Eeg-Based Emotion Recognition With Symmetrical Spatial Feature Extraction",
  "published": "2021-04-09T12:59:38Z",
  "authors": [
    "Xiangwen Deng",
    "Junlin Zhu",
    "Shangming Yang"
  ],
  "keywords": [
    "CCS CONCEPTS",
    "Computing methodologies ‚Üí Neural networks",
    "Shape representations",
    "Object identification Emotion Recognition",
    "EEG",
    "Folding",
    "Interpolation"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Emotion recognition based on EEG (electroencephalography) has been widely used in human-computer interaction, distance education and health care. However, the conventional methods ignore the adjacent and symmetrical characteristics of EEG signals, which also contain salient information related to emotion. In this paper, a spatial folding ensemble network (SFE-Net) is presented for EEG feature extraction and emotion recognition. Firstly, for the undetected area between EEG electrodes, an improved Bicubic-EEG interpolation algorithm is developed for EEG channels information completion, which allows us to extract a wider range of adjacent space features. Then, motivated by the spatial symmetric mechanism of human brain, we fold the input EEG channels data with five different symmetrical strategies, which enable the proposed network to extract the information of space features of EEG signals more effectively. Finally, a 3DCNN-based spatial, temporal extraction, and a multi-voting strategy of ensemble learning are integrated to model a new neural network. With this network, the spatial features of different symmetric folding signals can be extracted simultaneously, which greatly improves the robustness and accuracy of emotion recognition. The experimental results on DEAP and SEED datasets show that the proposed algorithm has comparable performance in terms of recognition accuracy.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Emotion is a complicated physiological response of human beings, which plays an important role in our daily life and work  [25] . Positive emotions help us to improve human health and work efficiency, while negative emotions may cause health problems  [20] . Nowadays emotion recognition has been widely used in many scientific and technological fields, such as human-computer interaction, distance education, and health care, etc., and has gained wide attention of academic research.\n\nIn general, there are two different ways to recognize emotion. One is to directly consider non-physiological signals such as facial expressions  [9] , speech  [46] , body gesture  [31] , text  [26]  to construct models, which collect data in a non-invasive way. However, for this approach, it is difficult to obtain correct emotions if people deliberately mask their true feelings  [28] . Another approach is to consider physiological signals such as heart rate  [32] , skin conductivity  [2] , respiration  [16] , and EEG to classify emotions. EEG, signaled by the central nervous system, is a direct response to brain activity and is more objective and reliable in capturing real human emotions.\n\nEEG-based emotion recognition methods can be roughly partitioned into two parts: EEG feature extraction and emotion classification. Firstly, EEG features are extracted from the time domain, frequency domain, and time-frequency domain  [19] . Then, they are used to train a classifier. Researchers mainly construct models using machine learning methods to deal with EEG emotion recognition tasks. However, the existing machine learning methods ignore the symmetric spatial characteristics of EEG signals, which may also contain salient information related to emotion. Deep learning has been widely applied in recent years, which has demonstrated its capabilities of temporal and spatial feature extraction in multi-channel EEG emotion recognition.\n\nFor example, in  [45] , researchers applied GCN to extract graph domain feature and LSTM to capture temporal features, and in  [17] , researchers also used convolutional neural network (CNN) to capture spatial features.\n\nAlthough the existing emotion recognition models have achieved high accuracy, most models only consider spatial features of adjacent channels but ignore the symmetry of human brain in information processing. Neurological studies  [5]  have shown that asymmetrical activities of the brain are effective in emotional processing, which indicates that there exist strong correlations for symmetrical channels in brain activities. Thus, how to capture adjacent and symmetrical features more effectively is still an interesting topic in the research of emotion recognition.\n\nTo apply the symmetric mechanism of human brain for EEG data processing, a spatial folding ensemble network named SFE-Net for the EEG feature extraction and emotion recognition is proposed in this paper. First, the input EEG channels data is folded with five different symmetrical folding strategies: the left-right folding, the right-left folding, the top-bottom folding, the bottom-top folding, and the entire double-sided brain folding. Additionally, to enable the SFE-Net to extract feature information of temporal and spatial features, an improved Bicubic-interpolation is proposed for EEG channel information completion, from which the proposed network can extract a wider range of adjacent and symmetrical spatial features of a human brain. Then 3D-CNN based spatial and temporal extraction and a multi-voting strategy of ensemble learning are employed to model a new neural network, from which the spatial features of different folds can be extracted simultaneously, which greatly improves the robustness and accuracy of emotion recognition.\n\nIn summary, the main contributions of this paper are as follows:\n\n(1) An improved interpolation algorithm with five different symmetric folding strategies is proposed to reinforce the sample data, which is helpful for the model to extract more effective features of adjacent and symmetrical spatial features more effectively in the next step.\n\n(2) A multi-voting strategy of 3D-CNN with ensemble learning is proposed for the folded signals, which greatly improves the robustness and accuracy of emotion recognition.\n\n(3) Extensive experiments are conducted on two benchmark datasets. The experimental results show that the proposed algorithm has comparable performance in terms of recognition accuracy.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Related Works",
      "text": "The related literature to the proposed work can be organized into two categories.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Eeg Interpolation Algorithms",
      "text": "Interpolation algorithms have been widely used in image processing for pixel filling. For example, Zheng et al.  [47]  proposed an adaptive k-nearest neighbors search and random non-linear regression for image interpolation to improve picture resolution. Zhou et al.  [49]  implemented a bilinear interpolation algorithm on novel enhanced quantum image representation (NEQR). Khaledyan et al.  [14]  implemented a bilinear and bicubic image interpolation with low cost to efficiently improve the real-time image super-resolution.\n\nSince EEG signals can also be viewed as images, many researchers have recently applied interpolation algorithms to enhance the spatial structure of EEG. For example, Huang et al.  [11]  proposed a separable convolutional neural network(CNN) with bilinear interpolation in a brain-computer interface for EEG classification. Svantesson et al.  [37]  utilized CNN as an interpolation method to upsample and restore channels, which finally recreate EEG signals with higher accuracy. In the field of EEG-based emotion recognition, interpolation algorithms are still relatively scarce. Cho et al.  [50]  used RBF (Radial Basis Function) interpolation algorithm to construct a new 2D EEG signal frame, which combines with DE (Differential Entropy) characteristics to achieve higher accuracy. However, RBF is a global interpolation algorithm, which may result in large errors when the EEG value is in a local drastic variation. To overcome the limitation, a new interpolation approach called the improved Bicubic-EEG interpolation is proposed, which can avoid the issue that local drastic changes lead to precision decline.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Eeg Feature Extraction",
      "text": "Neurological studies  [23] ,  [7]  have shown that emotional response is closely related to the cerebral cortex of the human brain, which is a 3D spatial structure and is not completely symmetrical between the left and right hemispheres. Consequently, emotion-related features of EEG signals, which in essence belong to time series, may not only exist on a temporal dimension but also exist on a spatial dimension for adjacent and symmetrical channels. For temporal feature extraction, some researchers utilize deep learning models to obtain dynamic information based on raw EEG signals automatically. Soleymani et al.  [33]  proposed an LSTM-RNN and continuous conditional random field algorithm to detect the emotional state of the subjects from their EEG signals and facial expressions. Anubhav et al.  [1]  proposed an LSTM neural network that could efficiently learn the features from the band power of EEG signals. Fourati et al.  [8]  presented an Echo State Network (ESN), which applied a recursive layer to perform the feature extraction step directly from the raw EEG.\n\nFor spatial feature extraction, Yang et al.  [44]  proposed a parallel convolutional recurrent neural network to extract spatial characteristics of EEG streams, which convert the chain-like EEG sequence into a 2D-like frame sequence. Li et al.  [17]  presented a hierarchical convolutional neural network to capture spatial information among different channels based on 2D EEG maps. Song et al.  [35]  proposed a dynamical graph convolutional neural network to explore the deeper-level spatial information for adjacent channels, which utilized a graph to model the multichannel EEG signals.\n\nAlthough these methods all reconstruct the EEG matrix based on the actual channel position of the brain to obtain spatial structure, they fill the undetected electrodes with zero in the matrix, which may destroy the original structure and lead to errors in classification. More importantly, they ignore the correlations for symmetrical channels, which also contain salient information in brain activities. To address the above-mentioned limitations, we propose the SFE-Net model, which takes into account adjacent and symmetrical spatial features simultaneously.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Proposed Method",
      "text": "By reconstructing the spatial characteristics of EEG channels with channel interpolation and spatial folding data preprocessing, 3D-CNN and ensemble learning are applied for feature extraction and data classification respectively.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Reconstruction Of The Spatial Characteristics Of Eeg Channels",
      "text": "Using a one-dimensional vector to represent each frame of EEG channels may ignore the spatial structure. The two-dimensional EEG image for emotion recognition has been widely studied in recent years  [43] . For example, the one-dimensional vector of each original EEG frame is 32*1 and the two-dimensional EEG image is 9*9. To improve the inconsistency and uncertainty of the spatial information between multiple adjacent channels, each frame of EEG channels is mapped to a matrix according to the structure of the human brain to obtain two-dimensional EEG images. As shown in Fig.  1 , the left part 2 is a plan view of the international 10-20 system. And the blue-filled EEG electrodes are the test points implemented in the DEAP dataset. We relocate each time sampling to a two-dimensional electrode topology according to the spatial position of the electrode. The unused electrodes are filled with zero. Then, channel filling and space folding based on a two-dimensional EEG will be performed for data completion.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "The Improved Bicubic-Eeg Interpolation Algorithm.",
      "text": "Since there are certain unsampled parts between the brain electrical electrodes, we believe that this may ignore some critical information. So an improved interpolation algorithm is developed to reconstruct them. After comprehensively calculating the area around the blank space of the proposed algorithm, the new values can be obtained.\n\nFor the improved Bicubic-EEG interpolation algorithm, the inspiration came from the bicubic interpolation. In numerical analysis, bicubic interpolation is one of the most frequently used interpolation methods in a two-dimensional space. The classic algorithms of linear interpolation include: nearest neighbor method, bilinear interpolation, bicubic B-spline interpolation  [40]  etc. Although the nearest neighbor method is simple and easy to implement, it will produce obvious jagged edges and mosaics in the new image. For bilinear interpolation, it has a smoothing function and can effectively overcome the drawbacks of the nearest neighbor method, but bilinear interpolation will degrade the high-frequency part of the image and make the image details blurred. As for the bicubic B-spline interpolation, compared to the bilinear interpolation, the transition and smoothness of the image will be focused more. However, the disadvantage is that the cost of computation is relatively high. The original Bicubic-EEG interpolation method can increase the receptive field of adjacent areas to obtain higher efficiency of data completion. We re-optimized the algorithm according to the distribution of the EEG channels to solve the problem of the large cost of calculation in bicubic interpolation. Fig.  2  shows the improved Bicubic-EEG interpolation method. The right part in Fig.  2  is a simple profile of the algorithm.\n\nSpecifically, the detailed description of the improved Bicubic-EEG interpolation algorithm is shown as follows:\n\nThe original BiCubic function  [13]  is\n\nwhere ùëé is in [-1, 0].  [13]  demonstrated that the best value of ùëé is -0.5. For the interpolated EEG channels (ùë•, ùë¶), the points (ùë• ùëñ , ùë¶ ùëó ) is taken in a 3 √ó 3 neighborhood, ùëñ, ùëó = 0, 1, 2, . . . Then the interpolate points will be computed as follows,\n\nwhere ùëì (ùë•, ùë¶) is the value to be filled at (ùë•, ùë¶), and ùëì (ùë• ùëñ , ùë¶ ùëñ ) is the value of the EEG channels at (ùë• ùëñ , ùë¶ ùëñ ). Since ùëì (ùë• ùëñ , ùë¶ ùëñ ) in Eq. (  2 ) may have ùëì (ùë• ùëñ , ùë¶ ùëñ ) = 0. In this case, the ùëì (ùë• ùëñ , ùë¶ ùëñ ) is taken as the center, and again set a 3 √ó 3 neighborhood. After the neighborhood points are averaged, the value of ùëì (ùë• ùëñ , ùë¶ ùëñ ) is obtained. In this case, ùëì (ùë•, ùë¶) as defined as follows:\n\nwhere ùê¥ùë£ùëî() is the average of the non-zero part of data. Thus, the interpolation can be obtained.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Spatial Fold Of Eeg.",
      "text": "To better extract the feature of EEG channels, a data input model is constructed by fully considering the symmetrical information of various brain regions. All EEG channels are folded in half according to the distribution of the electrodes with different approaches. The folds include folding symmetrically from left to right or right to left, folding symmetrically from top to bottom or bottom to top, and folding the entire double-sided brain completely. In all, we have five types of folding. All the folding approaches are shown in Fig.  3 . These five folding results are employed as the input data of the SFE-Net. With this input model, the ensemble learning in the next step can extract various symmetrical information at the same time.   3  shows the process of the proposed fold model. Specifically, the folding method includes five categories: folding the left brain on the right brain, folding the right brain on the left brain, folding the forebrain on the hindbrain, folding the hindbrain on the forebrain, and folding the entire double-sided brain completely.\n\nFor different folding strategies, the channel space organization is as follows: For left-right folds and right-left folds, the feature matrix size is 9 √ó 5 √ó 2. For top-bottom folds and bottom-top folds, the feature matrix size is 5 √ó 9 √ó 2. For the entire double-sided brain folding, the size of the feature matrix is 9 √ó 9 √ó 2.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "The Proposed Of Sfe-Net",
      "text": "The goal of the network is to fully extract the symmetrical features in the EEG to achieve accurate emotion recognition. The proposed network has three steps. First, the network folds the EEG data with five different approaches for input. Then the feature extraction capabilities of 3D-CNN is utilized to learn the temporal and spatial features of the adjacent and symmetric EEG channels of each folding mode. Finally, the voting mechanism of ensemble learning is used to integrate these features into the classifier.\n\nThe framework of the SFE-Net model is presented in Fig.  4 , from which we can see that SFE-Net is composed of three parts, including data folding, the 3D-CNN feature extracting, and ensemble learning.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "The 3D-Cnn For Feature Extraction.",
      "text": "3D-CNN is a deep learning method, which is an extension of traditional CNN  [12] . It improves convolution and pooling operations, which makes it superior in constructing long sequence spatiotemporal feature models. 3D convolution generates a series of 3D feature volumes by processing 3D input, where the third dimension is modeled by continuous input time frames.\n\nFormally, the value at position (ùë•, ùë¶, ùëß) on the ùëóth feature map in the ùëñth layer is given by\n\nwhere ùëÉ ùëñ , ùëÑ ùëñ and ùëÖ ùëñ are the sizes of the 3D kernel along the temporal dimension, ùëä ùëùùëûùëü ùëñ ùëóùëö is the (ùëù, ùëû, ùëü )th value of the kernel connected to the ùëöth feature map in the previous layer, and ùëì is the activation function of the network, which has a rectifying linear unit (Relu) to enhance network performance.\n\nDue to the dependence between long-time sequence fragments such as voice, video, and EEG signals, studies show that the utilization of 3D-CNN can improve the accuracy and robustness of the model. In addition, three-dimensional convolution operations can visualize and model the spatial correlation between video frames or pixels. For example, 3D-CNN is utilized for action recognition in  [39] . Since the EEG channels signal also has both time and space features, 3D-CNN is applied to fully extract time and space features from the 3D EEG input cube we constructed.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Ensemble Learning And Voting Mechanism.",
      "text": "The ensemble learning implements independent training based on several learning algorithms. Then, it flexibly combines the basic learners of the learning results.\n\nSince the learning results for different algorithms generally have certain differences, the combined learning result is usually better than that of an individual algorithms. The design of each basic classifier in ensemble learning should be different from each other. Generally, a basic classifier can be constructed by using different input features, training sets, and learning algorithms  [27] . To have some difference for different algorithms  [6] , we consider that not only the left and right sides of the brain may have symmetrical regional features, but the front and rear sides of the brain may also have symmetrical regional features. Thus ensemble learning can be applied to synthesize the characteristics of front and rear symmetry and the left and right symmetry at the same time. In Therefore, this approach that integrates all the symmetric features helps to improve the robustness of the network.\n\nThe proposed SFE-Net framework is shown in Fig.  4 . Five CNN classifiers are employed, including CNN1 . . . CNN5. Every CNN classifier is a basic learning algorithms. From all the five CNN, a powerful algorithms is formed through a diversified voting strategy. Each learning algorithm ùë¶ ùëñ will predict the result ùëå (ùë•) according to the category set ùê∂ 1 , ùê∂ 2 . . . , ùê∂ ùëÅ . The integration strategy is formulated as follows:\n\nwhere the N-dimensional -----‚Üí ùë£ùëíùëêùë°ùëúùëü ùë¶",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "Experiments 4.1 Materials",
      "text": "In the experiment, the DEAP dataset  [15]  and the SEED dataset  [48]  are selected to evaluate the performance of the network. These two datasets are widely used in the field of emotion recognition.\n\nDEAP: The DEAP dataset is a multi-modal dataset developed by  Koelstra   The structure of the DEAP dataset is shown in Table  1 . A total of 15 segments are selected to stimulate (neutral, negative and positive) emotions. Each stimulus includes a 5-second movie prompt, 4-minute editing, 45-second self-assessment, and a 15-second rest time. A total of 15 Chinese subjects participated in this study. Each subject needs to perform the same experiment three times on different dates to ensure the authenticity and universality of the extracted EEG data. A total of 45 EEG data were recorded. Tags were assigned based on the content of the clip (-1 for negative, 0 for neutral, and 1 for positive). The data was collected through 62 channels. These channels were placed according to a 10-20 system and downsampled to 200 Hz. Since the duration of each video is different, to be unified, the middle 60s of each video was intercepted as the duration. The structure of the SEED dataset is shown in Table  2 .",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Implementation Details",
      "text": "The structure of SFE-Net is shown in Fig.  4 . The proposed SFE-Net model is mainly composed of 2 parts. Firstly, the model with the space-time extraction capabilities of 3D-CNN was trained parallelly.\n\nSecondly, we integrated all the different folding results and obtained the final result of the voting decision.\n\nThe SFE-Net model includes four convolutional layers. Since the time dimension is doubled after folding, the purpose of the first layer of convolution is to extract features in the time dimension and reduce the number of parameters. To reduce the loss of information of the input data, zero padding is used in each convolutional layer. After each convolution, batch-normalization is adopted. Then RELU activation function is utilized to increase nonlinearity. The pooling size of the largest pooling layer is 2 √ó 1 √ó 1, which can reduce the size of the data in the time dimension. The feature maps of each layer are 8, 8, 16, and 32 respectively. Finally, a fully connected layer is designed to map the 32 feature maps into a feature vector of 512 dimensions. After regularization, set dropout = 0.5 to avoid over-fitting in a fully connected layer. In each convolutional layer, L2 regularization may prevent over-fitting, and L2=0.001. The Adam optimizer can minimize the cross-entropy loss function. The learning rate is set to 0.001. The learning epoch is 100. For the subject-dependent classification of 32 subjects, the dataset is split in patient-wise and for each subject, 80% of EEG data are randomly used for training and 20% for testing. For the subject-independent classification of 32 subjects, the data of the 32 subjects are integrated and randomly selected 80% for training and 20% for testing. 5 fold cross-validation methods is adopted in the experiments, in which the dataset is split into 5 parts and we circularly select 4 parts for training and the rest for testing.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Results And Discussion 5.1 Results For Subject-Independent Classification",
      "text": "To show the performance of the proposed method, the proposed algorithm will be compared with the latest methods on the DEAP and SEED datasets, including CNN-LSTM, CNN+EFDMs, CAN, and some other methods. The special channel setting is used to extract the hidden features of symmetrical channels.\n\nComparing with multimodal methods such as ECNN, Bimodal-LSTM, the recognition accuracy of the proposed model increased by more than 4%, which indicates that the proposed method is not just an efficient single-mode, but has better performance.\n\nComparing with manual feature extraction methods such as SNN, ST-SBSSVM, and 3D-CNN+DE, our method can construct feature data automatically on raw data.\n\nThese methods either have a spatial setting to extract spatiotemporal information, or manually construct special feature data for identification. However, the symmetrical channel information of EEG signals is ignored. SFE-Net also benefits from the ensemble learning of different folding approaches and comprehensive voting decision-making strategies. Extracting more symmetrical information at the same time is equivalent to an efficient data enhancement. Voting decision-making improves the robustness of the model. Table  3  shows the comparison results of different methods on the DEAP dataset and SEED dataset. From this table, we can see that SFE-Net can achieve very competitive experimental results. The accuracy on DEAP has reached 91.94% in Arousal and 92.49% in Valence. It also reached 99.19% on the SEED dataset. Compared with existing EEG recognition methods, the accuracy has significantly improved by SFE-Net.",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "Results For Subject-Dependent Classification",
      "text": "In order to further verify the effectiveness of SFE-Net approach, we compare the proposed method with the state-of-the-art methods, including decision tree (DT)  [43] ,dynamic graph convolutional neural network (DGCNN)  [34] , multi-grain cascade forest (gcForest)  [3] , continuous CNN (Cont-CNN)  [43] , Support Vector Machine (SVM)  [36] , Multilayer Perceptron (MLP)  [43] , and CNN-RNN  [44] . DGCNN was proposed by Song et al  [34] , which can dynamically learn the internal relationship between different EEG channels represented by the adjacency matrix, thereby classifying EEG emotions. Cont-CNN is a convolutional neural network with no pooling operation, which takes a constructed 3D EEG cube as input. The 3D EEG cube is a three-dimensional representation that combines the DE features with the spatial information between the electrodes  [43] . gcForest is a model based on deep forest, Cheng et al.  [3]  applied it to emotion recognition based on EEG. Yang et al. also constructed features based on 2D EEG frames  [44] . CNN-RNN is a hybrid neural network. It extracts spatial and temporal features from the constructed 2DEEG frame and 1D EEG sequence, respectively. To be fair, we will directly take the results in their literature as a comparison  [22] .\n\nFrom the results, first of all, the proposed method is far superior to the recognition effect of basic neural networks such as MLP and SVM. Then, compared with the two latest CNN-based methods (Cont-CNN and CNN-RNN), the proposed method also shows obvious advantages. The results on the DEAP dataset are shown in Fig.  5 , Fig.  6 . and the results on the SEED dataset are shown in Fig.  7 .",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "Discussion",
      "text": "The proposed model can achieve high accuracy, mainly because it developed ensemble learning with the improved Bicubic-EEG interpolation algorithm and EEG folding. This network can effectively learn higher-level adjacent and symmetrical spatial features related to emotions. In this section, three types of comparative experiments are conducted to evaluate the performance of the proposed emotion recognition method. At first, a comparison of five different folding strategies is conducted to explore the best folding approach and evaluate the effectiveness of the method. Then, interpolation algorithms are employed to compare the influence of different algorithms on the experimental results to verify the effectiveness of the improved Bicubic-EEG interpolation algorithm. Finally, ensemble learning is used as a comparison to further explore the best ensemble strategy by integrating different folding methods.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Various Folding Methods.",
      "text": "To show the advantages of spatial folding in this study, we have five types of folded original EEG data and unfolded original EEG data for comparison. Thus, the sample data for emotion recognition after spatial folding can be obtained. The other experimental settings and network parameters remain unchanged. The results are shown in Table  4 . We can see that the difference is not very high on DEAP Valence. The average increase on DEAP Arousal is 1.21%, and the maximum increase is 2.07%. However, the folding methods have achieved amazing results on the SEED dataset, with an average increase of 18.89%, and a maximum increase of 19.6%. The results show that the method using half-folding to reconstruct the spatial features of the original data can greatly improve the ability of 3D-CNN to extract symmetric features.",
      "page_start": 7,
      "page_end": 8
    },
    {
      "section_name": "Channel Interpolation Algorithm.",
      "text": "To show the effectiveness of the developed Bicubic-EEG interpolation algorithm, the improved Bicubic-EEG interpolation algorithm is compared with the Bilinear interpolation algorithm and unfilled raw EEG data. The experimental results are shown in Fig.  8  and Fig.  9 .  From the comparative experiments, we can see that the improved Bicubic-EEG interpolation algorithm has achieved a 2.12% improvement on DEAP four-category classification (low/high arousal and low/high valence). However, amazing progress on the SEED dataset is achieved, which increases the accuracy by 16.94%. At the same time, all experiments have demonstrated that the improved Bicubic-EEG interpolation algorithm is better than the general linear interpolation algorithm. The results show that the proposed method improves 3D-CNN's ability to extract adjacent spatial features in unsampled regions of the EEG data.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Different Ensemble Strategies.",
      "text": "To show the efficiency of integrated learning strategy in ensemble learning, two types of comparative experiments are conducted. In the first one, voting is not applied but the average strategy is employed to integrate different classifiers. The second one is to repeat the same folding method five times for voting integration, instead of the previous voting integration with five different foldings. The experimental results are shown in Table  5 , from which we can see that for the three evaluation indicators DEAP Arousal, DEAP Valence, and DEAP four-category classification, the the proposed model has 5.7%, 4.42%, and 8.45% more than that of the average strategy obtained respectively. All of them are higher than the average strategy. For these three evaluation indicators, on average, the voting results of the proposed five different folding methods are 2.43%, 2.14%, and 3.22% higher than that of the same folding method five times. From the results, we can see that the voting strategy obviously performs better than the average strategy. And the integration of using five different folding methods performs better than the integration of using the same folding method five times repeatedly. These results show the effectiveness of the proposed ensemble method.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Conclusion",
      "text": "A spatial folding ensemble network (SFE-Net) is presented for electroencephalography feature extraction and emotion recognition. By combining time, regional symmetry, and regional adjacent information, this model can automatically extract features to achieve emotion recognition.\n\nThe average accuracies of the proposed model for the Valence classification and Arousal classification on the DEAP dataset are 91.94%, 92.49%, respectively. Specifically, the accuracy is 99.19% on the SEED dataset. Thus, the results show that the algorithm we poposed can obtain state of art performance, which significantly demonstrate the effectiveness of the algorithm in learning spatial symmetry and spatial region information. However, in the proposed work, only single-mode experiments were performed. In the future, we will explore how to construct a multi-modal model to better extract various features.",
      "page_start": 8,
      "page_end": 8
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: , the left part 2 is a plan view of the international",
      "page": 3
    },
    {
      "caption": "Figure 1: The two-dimensional plane of the EEG electrode",
      "page": 3
    },
    {
      "caption": "Figure 1: , ‚Ñéand ùë§are the maximum number of electrodes which",
      "page": 3
    },
    {
      "caption": "Figure 2: The improved Bicubic-EEG interpolation scheme",
      "page": 3
    },
    {
      "caption": "Figure 2: shows the",
      "page": 3
    },
    {
      "caption": "Figure 2: is a simple profile of the algorithm.",
      "page": 3
    },
    {
      "caption": "Figure 3: These five folding results are employed as the input data of the",
      "page": 3
    },
    {
      "caption": "Figure 3: The proposed 5 folding approaches",
      "page": 4
    },
    {
      "caption": "Figure 3: shows the process of the proposed fold model. Specifically,",
      "page": 4
    },
    {
      "caption": "Figure 4: The structure of SFE-Net",
      "page": 5
    },
    {
      "caption": "Figure 4: . Five CNN",
      "page": 5
    },
    {
      "caption": "Figure 4: The proposed SFE-Net",
      "page": 6
    },
    {
      "caption": "Figure 5: , Fig. 6. and the results on the SEED dataset are shown in Fig. 7.",
      "page": 7
    },
    {
      "caption": "Figure 5: Arousal classification accuracies (%) of each subject",
      "page": 7
    },
    {
      "caption": "Figure 6: Valence classification accuracies (%) of each subject",
      "page": 7
    },
    {
      "caption": "Figure 7: Three-category classification accuracies (%) of each",
      "page": 7
    },
    {
      "caption": "Figure 9: Figure 8: Performance comparison between different inter-",
      "page": 8
    },
    {
      "caption": "Figure 9: Performance comparison between different inter-",
      "page": 8
    }
  ],
  "tables": [
    {
      "caption": "Table 1: Table 1: The structure of the DEAP dataset",
      "page": 5
    },
    {
      "caption": "Table 2: The structure of the SEED dataset",
      "page": 5
    },
    {
      "caption": "Table 3: The comparative experiment results",
      "page": 6
    },
    {
      "caption": "Table 4: The different ways to fold signals on the DEAP",
      "page": 7
    },
    {
      "caption": "Table 4: We can see that the difference",
      "page": 7
    },
    {
      "caption": "Table 5: Test results of different folding strategies under en-",
      "page": 8
    },
    {
      "caption": "Table 5: , from which we",
      "page": 8
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "An Efficient Approach to EEG-Based Emotion Recognition using LSTM Network",
      "authors": [
        "Anubhav Anubhav",
        "Debarshi Nath",
        "Divyashikha Sethia",
        "Diksha Kalra",
        "Indu Sreedevi"
      ],
      "year": "2020",
      "venue": "2020 16th IEEE International Colloquium on Signal Processing and Its Applications (CSPA)",
      "doi": "10.1109/CSPA48992.2020.9068691"
    },
    {
      "citation_id": "2",
      "title": "Emotion Recognition Based on Skin Potential Signals with a Portable Wireless Device",
      "authors": [
        "Shuhao Chen",
        "Ke Jiang",
        "Haoji Hu",
        "Haoze Kuang",
        "Jianyi Yang",
        "Jikui Luo",
        "Xinhua Chen",
        "Yubo Li"
      ],
      "year": "2021",
      "venue": "Sensors",
      "doi": "10.3390/s21031018"
    },
    {
      "citation_id": "3",
      "title": "Emotion Recognition From Multi-Channel EEG via Deep Forest",
      "authors": [
        "J Cheng",
        "M Chen",
        "C Li",
        "Y Liu",
        "R Song",
        "A Liu",
        "X Chen"
      ],
      "year": "2021",
      "venue": "IEEE Journal of Biomedical and Health Informatics",
      "doi": "10.1109/JBHI.2020.2995767"
    },
    {
      "citation_id": "4",
      "title": "Investigating the Use of Pretrained Convolutional Neural Network on Cross-Subject and Cross-Dataset EEG Emotion Recognition",
      "authors": [
        "Yucel Cimtay",
        "Erhan Ekmekcioglu"
      ],
      "year": "2020",
      "venue": "Sensors"
    },
    {
      "citation_id": "5",
      "title": "EEG-based emotion recognition using an end-to-end regional-asymmetric convolutional neural network",
      "authors": [
        "Heng Cui",
        "Aiping Liu",
        "Xu Zhang",
        "Xiang Chen",
        "Kongqiao Wang",
        "Xun Chen"
      ],
      "year": "2020",
      "venue": "Knowledge-Based Systems",
      "doi": "10.1016/j.knosys.2020.106243"
    },
    {
      "citation_id": "6",
      "title": "Ensemble Methods in Machine Learning",
      "authors": [
        "G Thomas",
        "Dietterich"
      ],
      "year": "2000",
      "venue": "Multiple Classifier Systems"
    },
    {
      "citation_id": "7",
      "title": "Differing emotional response from right and left hemisphere",
      "authors": [
        "Stuart Dimond",
        "Linda Farrington",
        "Peter Johnson"
      ],
      "year": "1976",
      "venue": "Nature",
      "doi": "10.1038/261690a0"
    },
    {
      "citation_id": "8",
      "title": "Optimized Echo State Network with Intrinsic Plasticity for EEG-Based Emotion Recognition",
      "authors": [
        "Rahma Fourati",
        "Boudour Ammar",
        "Chaouki Aouiti",
        "Javier Sanchez-Medina",
        "Adel Alimi"
      ],
      "year": "2017",
      "venue": "International Conference on Neural Information Processing",
      "doi": "10.1007/978-3-319-70096-0_73"
    },
    {
      "citation_id": "9",
      "title": "Dominant and Complementary Emotion Recognition from Still Images of Faces",
      "authors": [
        "Jianzhu Guo",
        "Zhen Lei",
        "Jun Wan",
        "Egils Avots",
        "Noushin Hajarolasvadi",
        "Boris Knyazev",
        "Artem Kuharenko",
        "Julio Jacques",
        "Xavier Baro",
        "Demirel Hasan"
      ],
      "year": "2018",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "10",
      "title": "Multimodal Emotion Recognition Based on Ensemble Convolutional Neural Network",
      "authors": [
        "Haiping",
        "Huang",
        "Zhenchao",
        "Hu",
        "Wenming",
        "Min Wang",
        "Wu"
      ],
      "year": "2019",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "11",
      "title": "S-EEGNet: Electroencephalogram Signal Classification Based on a Separable Convolution Neural Network With Bilinear Interpolation",
      "authors": [
        "Wenkai Huang",
        "Yihao Xue",
        "Lingkai Hu",
        "Hantang Liuli"
      ],
      "year": "2020",
      "venue": "S-EEGNet: Electroencephalogram Signal Classification Based on a Separable Convolution Neural Network With Bilinear Interpolation",
      "doi": "10.1109/ACCESS.2020.3009665"
    },
    {
      "citation_id": "12",
      "title": "3D Convolutional Neural Networks for Human Action Recognition",
      "authors": [
        "S Ji",
        "W Xu",
        "M Yang",
        "K Yu"
      ],
      "year": "2013",
      "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
      "doi": "10.1109/TPAMI.2012.59"
    },
    {
      "citation_id": "13",
      "title": "Cubic convolution interpolation for digital image processing",
      "authors": [
        "Robert Keys"
      ],
      "year": "1982",
      "venue": "IEEE Trans Acoust Speech Signal Process. Acoustics, Speech and Signal Processing",
      "doi": "10.1109/TASSP.1981.1163711"
    },
    {
      "citation_id": "14",
      "title": "Low-Cost Implementation of Bilinear and Bicubic Image Interpolation for Real-Time Image Super-Resolution",
      "authors": [
        "Donya Khaledyan",
        "Abdolah Amirany",
        "Kian Jafari",
        "Mohammad Moaiyeri",
        "Abolfazl Zargari",
        "Najmeh Mashhadi"
      ],
      "year": "2020",
      "venue": "IEEE Global Humanitarian Technology Conference (GHTC)",
      "doi": "10.1109/GHTC46280.2020.9342625"
    },
    {
      "citation_id": "15",
      "title": "DEAP: A Database for Emotion Analysis ;Using Physiological Signals",
      "authors": [
        "Koelstra"
      ],
      "year": "2012",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "16",
      "title": "A Real Time Human Emotion Recognition System Using Respiration Parameters and ECG: 10th International Conference",
      "authors": [
        "C Kumar",
        "Satwik Pai"
      ],
      "year": "2018",
      "venue": "A Real Time Human Emotion Recognition System Using Respiration Parameters and ECG: 10th International Conference",
      "doi": "10.1007/978-3-030-04021-5_4"
    },
    {
      "citation_id": "17",
      "title": "Hierarchical Convolutional Neural Networks for EEG-Based Emotion Recognition",
      "authors": [
        "Jinpeng Li",
        "Zhaoxiang Zhang",
        "Huiguang He"
      ],
      "year": "2018",
      "venue": "Cognitive Computation",
      "doi": "10.1007/s12559-017-9533-x"
    },
    {
      "citation_id": "18",
      "title": "Latent Factor Decoding of Multi-Channel EEG for Emotion Recognition Through Autoencoder-Like Neural Networks",
      "authors": [
        "Xiang Li",
        "Zhigang Zhao",
        "Dawei Song",
        "Yazhou Zhang",
        "Di Wang"
      ],
      "year": "2020",
      "venue": "Frontiers in Neuroscience"
    },
    {
      "citation_id": "19",
      "title": "A Novel Neural Network Model based on Cerebral Hemispheric Asymmetry for EEG Emotion Recognition",
      "authors": [
        "Yang Li",
        "Wenming Zheng",
        "Zhen Cui",
        "Tong Zhang",
        "Yuan Zong"
      ],
      "year": "2018",
      "venue": "A Novel Neural Network Model based on Cerebral Hemispheric Asymmetry for EEG Emotion Recognition",
      "doi": "10.24963/ijcai.2018/216"
    },
    {
      "citation_id": "20",
      "title": "A Review of Emotion Recognition Using Physiological Signals",
      "authors": [
        "S Lin",
        "J Xie",
        "M Yang",
        "Z Li",
        "X Yang"
      ],
      "year": "2018",
      "venue": "Sensors"
    },
    {
      "citation_id": "21",
      "title": "EEG-Based Emotion Classification Using a Deep Neural Network and Sparse Autoencoder",
      "authors": [
        "Junxiu Liu",
        "Guopei Wu",
        "Yuling Luo",
        "Senhui Qiu",
        "Yifei Bi"
      ],
      "year": "2020",
      "venue": "Frontiers in Systems Neuroscience"
    },
    {
      "citation_id": "22",
      "title": "Multi-channel EEG-based Emotion Recognition via a Multi-level Features Guided Capsule Network",
      "authors": [
        "Yu Liu",
        "Yufeng Ding",
        "Chang Li",
        "Juan Cheng",
        "Xun Chen"
      ],
      "year": "2020",
      "venue": "Computers in Biology and Medicine"
    },
    {
      "citation_id": "23",
      "title": "Practical emotional neural networks",
      "authors": [
        "Ehsan Lotfi"
      ],
      "year": "2014",
      "venue": "Neural Networks",
      "doi": "10.1016/j.neunet.2014.06.012"
    },
    {
      "citation_id": "24",
      "title": "EEG-based Emotion Classification Using Spiking Neural Networks",
      "authors": [
        "Yuling Luo",
        "Qiang Fu",
        "Juntao Xie",
        "Yunbai Qin",
        "Xuemei Ding"
      ],
      "year": "2020",
      "venue": "IEEE Access PP"
    },
    {
      "citation_id": "25",
      "title": "Psychosomatic disease and the\" visceral brain\": Recent developments bearing on the Papez theory of emotion",
      "authors": [
        "Paul Maclean"
      ],
      "year": "1948",
      "venue": "Psychosomatic medicine",
      "doi": "10.1097/00006842-194911000-00003"
    },
    {
      "citation_id": "26",
      "title": "M3ER: Multiplicative Multimodal Emotion Recognition using Facial, Textual, and Speech Cues",
      "authors": [
        "Trisha Mittal",
        "Uttaran Bhattacharya",
        "Rohan Chandra"
      ],
      "year": "2020",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence",
      "doi": "10.1609/aaai.v34i02.5492"
    },
    {
      "citation_id": "27",
      "title": "A multi-level approach using genetic algorithms in an ensemble of Least Squares Support Vector Machines",
      "authors": [
        "Carlos Alberto De Ara√∫jo Padilha",
        "Augusto Barone",
        "Duarte Adri?o D√≥ria",
        "Neto"
      ],
      "year": "2016",
      "venue": "A multi-level approach using genetic algorithms in an ensemble of Least Squares Support Vector Machines"
    },
    {
      "citation_id": "28",
      "title": "A Novel Emotion Elicitation Index Using Frontal Brain Asymmetry for Enhanced EEG-Based Emotion Recognition",
      "authors": [
        "Panagiotis Petrantonakis",
        "Leontios Hadjileontiadis"
      ],
      "year": "2011",
      "venue": "IEEE Engineering in Medicine and Biology Society",
      "doi": "10.1109/TITB.2011.2157933"
    },
    {
      "citation_id": "29",
      "title": "Correlated Attention Networks for Multimodal Emotion Recognition",
      "authors": [
        "J Qiu",
        "X Li",
        "K Hu"
      ],
      "year": "2018",
      "venue": "2018 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)",
      "doi": "10.1109/BIBM.2018.8621129"
    },
    {
      "citation_id": "30",
      "title": "Multi-Scale Frequency Bands Ensemble Learning for EEG-Based Emotion Recognition",
      "authors": [
        "Fangyao Shen",
        "Yong Peng",
        "Wanzeng Kong",
        "Guojun Dai"
      ],
      "year": "2021",
      "venue": "Sensors"
    },
    {
      "citation_id": "31",
      "title": "Emotion Recognition Based on Multi-View Body Gestures",
      "authors": [
        "Zhijuan Shen",
        "Jun Cheng",
        "Xiping Hu",
        "Qian Dong"
      ],
      "year": "2019",
      "venue": "Emotion Recognition Based on Multi-View Body Gestures",
      "doi": "10.1109/ICIP.2019.8803460"
    },
    {
      "citation_id": "32",
      "title": "Wearable Emotion Recognition Using Heart Rate Data from a Smart Bracelet",
      "authors": [
        "Lin Shu",
        "Yang Yu",
        "Wenzhuo Chen",
        "Haoqiang Hua",
        "Qin Li",
        "Jianxiu Jin",
        "Xiangmin Xu"
      ],
      "year": "2020",
      "venue": "Sensors",
      "doi": "10.3390/s20030718"
    },
    {
      "citation_id": "33",
      "title": "Analysis of EEG Signals and Facial Expressions for Continuous Emotion Detection",
      "authors": [
        "M Soleymani",
        "S Asghari-Esfeden",
        "Y Fu",
        "M Pantic"
      ],
      "year": "2016",
      "venue": "IEEE Transactions on Affective Computing",
      "doi": "10.1109/TAFFC.2015.2436926"
    },
    {
      "citation_id": "34",
      "title": "EEG Emotion Recognition Using Dynamical Graph Convolutional Neural Networks",
      "authors": [
        "Tengfei Song",
        "Wenming Zheng",
        "Peng Song",
        "Zhen Cui"
      ],
      "year": "2018",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "35",
      "title": "EEG Emotion Recognition Using Dynamical Graph Convolutional Neural Networks",
      "authors": [
        "T Song",
        "W Zheng",
        "P Song",
        "Z Cui"
      ],
      "year": "2020",
      "venue": "IEEE Transactions on Affective Computing",
      "doi": "10.1109/TAFFC.2018.2817622"
    },
    {
      "citation_id": "36",
      "title": "Least squares support vector machine classifiers",
      "authors": [
        "J Suykens",
        "J Vandewalle"
      ],
      "year": "1999",
      "venue": "Neural Processing Letters"
    },
    {
      "citation_id": "37",
      "title": "Virtual EEG-electrodes: Convolutional neural networks as a method for upsampling or restoring channels",
      "authors": [
        "Mats Svantesson",
        "H√•kan Olausson",
        "Anders Eklund",
        "Magnus Thordstein"
      ],
      "year": "2021",
      "venue": "Journal of Neuroscience Methods",
      "doi": "10.1016/j.jneumeth.2021.109126"
    },
    {
      "citation_id": "38",
      "title": "Multimodal Emotion Recognition Using Deep Neural Networks",
      "authors": [
        "Hao Tang",
        "Wei Liu",
        "Wei-Long Zheng",
        "Bao-Liang Lu"
      ],
      "year": "2017",
      "venue": "Neural Information Processing"
    },
    {
      "citation_id": "39",
      "title": "Learning Spatiotemporal Features with 3D Convolutional Networks",
      "authors": [
        "Du Tran",
        "Lubomir Bourdev",
        "Rob Fergus",
        "Lorenzo Torresani",
        "Manohar Paluri"
      ],
      "year": "2015",
      "venue": "Learning Spatiotemporal Features with 3D Convolutional Networks",
      "arxiv": "arXiv:1412.0767[cs.CV]"
    },
    {
      "citation_id": "40",
      "title": "B-Spline Signal Processing : Part II-Efficient Design and Applications",
      "authors": [
        "M Unser"
      ],
      "year": "1993",
      "venue": "Trans. IEEE"
    },
    {
      "citation_id": "41",
      "title": "Emotion recognition with convolutional neural network and EEG-based EFDMs",
      "authors": [
        "Fei Wang",
        "Shichao Wu",
        "Weiwei Zhang",
        "Zongfeng Xu",
        "Sonya Coleman"
      ],
      "year": "2020",
      "venue": "Neuropsychologia"
    },
    {
      "citation_id": "42",
      "title": "Multi-method Fusion of Cross-Subject Emotion Recognition Based on High-Dimensional EEG Features",
      "authors": [
        "Fu Yang",
        "Xingcong Zhao",
        "Wenge Jiang",
        "Pengfei Gao",
        "Guangyuan Liu"
      ],
      "year": "2019",
      "venue": "Frontiers in Computational Neuroscience"
    },
    {
      "citation_id": "43",
      "title": "Continuous Convolutional Neural Network with 3D Input for EEG-Based Emotion Recognition",
      "authors": [
        "Yilong Yang",
        "Qingfeng Wu",
        "Yazhen Fu",
        "Xiaowei Chen"
      ],
      "year": "2018",
      "venue": "Neural Information Processing"
    },
    {
      "citation_id": "44",
      "title": "Emotion Recognition from Multi-Channel EEG through Parallel Convolutional Recurrent Neural Network",
      "authors": [
        "Yilong Yang",
        "Qingfeng Wu",
        "Ming Qiu",
        "Wang Yingdong",
        "Xiaowei Chen"
      ],
      "year": "2018",
      "venue": "Emotion Recognition from Multi-Channel EEG through Parallel Convolutional Recurrent Neural Network",
      "doi": "10.1109/IJCNN.2018.8489331"
    },
    {
      "citation_id": "45",
      "title": "EEG emotion recognition using fusion model of graph convolutional neural networks and LSTM",
      "authors": [
        "Yongqiang Yin",
        "Xiangwei Zheng",
        "Bin Hu",
        "Yuang Zhang",
        "Xinchun Cui"
      ],
      "year": "2021",
      "venue": "Applied Soft Computing",
      "doi": "10.1016/j.asoc.2020.106954"
    },
    {
      "citation_id": "46",
      "title": "Speech Emotion Recognition Using Deep Convolutional Neural Network and Discriminant Temporal Pyramid Matching",
      "authors": [
        "S Zhang",
        "S Zhang",
        "T Huang",
        "W Gao"
      ],
      "year": "2018",
      "venue": "IEEE Transactions on Multimedia",
      "doi": "10.1109/TMM.2017.2766843"
    },
    {
      "citation_id": "47",
      "title": "Image interpolation with adaptive k-nearest neighbors search and random nonlinear regression",
      "authors": [
        "Jieying Zheng",
        "Wanru Song",
        "Yahong Wu",
        "Feng Liu"
      ],
      "year": "2020",
      "venue": "IET Image Processing",
      "doi": "10.1049/iet-ipr.2019.1591"
    },
    {
      "citation_id": "48",
      "title": "Identifying Stable Patterns over Time for Emotion Recognition from EEG",
      "authors": [
        "Wei Long Zheng",
        "Jia Yi Zhu",
        "Bao Lu"
      ],
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "49",
      "title": "Quantum realization of the bilinear interpolation method for NEQR",
      "authors": [
        "Ri-Gui Zhou",
        "Wenwen Hu",
        "Ping Fan",
        "Hou Ian"
      ],
      "year": "2017",
      "venue": "Scientific Reports",
      "doi": "10.1038/s41598-017-02575-6"
    },
    {
      "citation_id": "50",
      "title": "Differential Entropy Feature Signal Extraction Based on Activation Mode and Its Recognition in Convolutional Gated Recurrent Unit Network",
      "authors": [
        "Yongsheng Zhu",
        "Qinghua Zhong"
      ],
      "year": "2021",
      "venue": "Frontiers in Physics",
      "doi": "10.3389/fphy.2020.629620"
    }
  ]
}