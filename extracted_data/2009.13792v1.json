{
  "paper_id": "2009.13792v1",
  "title": "Micro-Facial Expression Recognition In Video Based On Optimal Convolutional Neural Network (Mfeocnn) Algorithm",
  "published": "2020-09-29T05:56:26Z",
  "authors": [
    "S. D. Lalitha",
    "K. K. Thyagharajan"
  ],
  "keywords": [
    "Adaptive median Filter",
    "Micro-Facial Expression",
    "Histogram of Oriented Gradients",
    "Local binary pattern",
    "Geometric features",
    "Lion optimization",
    "Convolution neural network"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Facial expression is a standout amongst the most imperative features of human emotion recognition. For demonstrating the emotional states facial expressions are utilized by the people. In any case, recognition of facial expressions has persisted a testing and intriguing issue with regards to PC vision. Recognizing the Micro-Facial expression in video sequence is the main objective of the proposed approach. For efficient recognition, the proposed method utilizes the optimal convolution neural network. Here the proposed method considering the input dataset is the CK+ dataset. At first, by means of Adaptive median filtering preprocessing is performed in the input image. From the preprocessed output, the extracted features are Geometric features, Histogram of Oriented Gradients features and Local binary pattern features. The novelty of the proposed method is, with the help of Modified Lion Optimization (MLO) algorithm, the optimal features are selected from the extracted features. In a shorter computational time, it has the benefits of rapidly focalizing and effectively acknowledging with the aim of getting an overall arrangement or idea. Finally, the recognition is done by Convolution Neural network (CNN). Then the performance of the proposed MFEOCNN method is analysed in terms of false measures and recognition accuracy. This kind of emotion recognition is mainly used in medicine, marketing, E-learning, entertainment, law and monitoring. From the simulation, we know that the proposed approach achieves maximum recognition accuracy of 99.2% with minimum Mean Absolute Error (MAE) value. These results are compared with the existing for MicroFacial Expression Based Deep-Rooted Learning (MFEDRL), Convolutional Neural Network with Lion Optimization (CNN+LO) and Convolutional Neural Network (CNN) without optimization. The simulation of the proposed method is done in the working platform of MATLAB.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Recognizing facial emotions using machine learning is considered as one of the challenging tasks in the recent years. For conveying the emotions and intentions some nonverbal methods like facial expressions, gestures etc., are used by human beings. Still it is a challenging task to identify the facial expressions by machine whereas, the expressions are quickly recognized by every individual without any delay or effort. For the real time applications, recognition of human emotions is encouraging in computer vision and image processing  [1] . It is challenging but essential in the human-computer environment for the development of automatic recognition of facial emotions.\n\nFrom the recent researches, it is clear that more maturely the recognition of facial expressions has grown. The recent research techniques on facial expression recognition are classified on the basis of data sources or the targets to be recognized. From the recognition target's point of view the facial expressions like neutral, disgust, fear, sad, anger, surprise and joy are recognized by many facial expression recognition methods  [2] . Alternatively, to describe the facial expressions by AUs (action units), a system FACS (facial action coding) has been introduced. There are 46 AUs in the FACS system which is used for describing the fundamental facial expressions on the basis of activities of muscles  [3] .\n\nGenerally, from the data sources' point of view the methods of recognition of facial emotions are classified into image sequence (video) based techniques and static image based techniques. For extracting the facial features, a typical method is estimating the optical flow in image sequence based methods  [4] . Conversely, it is more difficult to recognize the facial emotions from static images because there is no availability of temporal information in the static images. Initially, a neutral face is considered as reference face and it should be recognized in the image sequence based techniques  [5] . Then depending on the difference between the input and the reference image the recognition is performed. However, it is challenging for recognizing the facial emotions of the input images if the reference image is not recognized correctly. Hence, for the emotion recognition static images are often used by psychologists  [6] .\n\nAmong the facial expression recognition techniques, appearance based methods are the most popular. For avoiding the problems in landmark or feature point detection, the appearance images are processed and the features are extracted as two-dimensional holistic patterns  [7] . In order to classify the holistic patterns, these methods are generally based on LDA (Linear discriminant analysis). Anyhow, in high dimensional data the methods based on LDA are suffered from small-sample size problem  [8] .\n\nDue to the variation in the faces of one person to another automatic recognition of facial expressions is difficult  [9] . Though, the recognition is performed with some constraints particular to culture, various issues such as presence of glasses, facial hair make the recognition task more complex. Orientation of face and variation in the input image space are the other challenges included in the recognition process. Because of this, in the images a search for a fixed pattern is disabled. Owing to the camera angle, there may be a difference in the poses of faces. The faces may be towards frontal or non-frontal. Some facial features are obscured because the faces are at different angles  [10] .\n\nTo apply on the input images, various preprocessing methods are needed which have good insensitivity for rotation, scaling and translation of the head. Recently, geometrical information or local spatial analysis are used as facial features by feature based recognition methods. For the robust classification of facial expressions, an important step discriminant analysis) and LDA (linear discriminant analysis) were combined in the RDA. Ill-posed and small sample size issues suffered from LDA and QDA were solved by RDA by using various regularization techniques. Also, in the RDA, for the estimation of optimal parameters PSO (particle swarm optimization) method was used. The results from this approach have demonstrated that the Anyhow, the environmental conditions like lightning to be depended by the performance of extraction of facial point in the real time applications like robotics. Therefore, the facial point can be identified inaccurately if there is nonuniform illumination. Hence, the facial expression's recognition rate cannot be expected highly. This issue makes the feature extraction process more challenging  [12] . Before the process of feature extraction, image processing techniques like Rank Normalization, Histogram Equalization and DCT normalization are applied for the compensation of illumination variation in the input image. Considering these issues, a new method has been proposed so as to tackle these issues.\n\nThe outline of the paper is given as follows, a brief review of researches in facial expression recognition is provided in section 2. In section 3, the contribution of the proposed method is presented. The proposed is automatic localization of facial points  [11] .\n\nMicro-Facial expression recognition is presented in section 4. In section 5, the proposed performance evaluation and comparative analysis is presented. Finally the conclusions are summed up.",
      "page_start": 1,
      "page_end": 3
    },
    {
      "section_name": "Related Work",
      "text": "As facial emotion recognition (FER) is one of a challenging tasks, to cope with the problems in recognizing the facial emotions  (Arora et.al, 2018)  have presented an effective framework. For encoding the facial components into features the gradients have been applied. For the facial emotion recognition, by using the random forest classifier the presented model was trained. Further, by the testing process it has been combined to classify the emotions. The presented method has robust feature extraction techniques. Results have exposed that the presented approach has outperformed the existing approaches in terms of recognition accuracy, false rejection rate and false acceptance rate.\n\nIn autism spectrum disorder (ASD) a key deficit field is recognition of facial emotions. In youth with ASD, for examining the trajectories of facial emotion recognition  (Rosen et.al, 2016 ) have presented a study in which the repeated measurements over 18 weeks are recorded and the effects of externalizing and internalizing symptoms are evaluated. Even for the difficult stimuli, the errors in the facial emotion recognition are reduced over time which was revealed by the analysis of Hierarchical Linear Modeling. The externalizing symptoms have attenuated the improvement of FER whereas, the internalizing symptoms have enhanced the improvement of FER.\n\nA boosting approach based on RDA (regularized discriminant analysis) was developed and its application in FER was discussed by  (Lee et.al, 2012) . QDA (quadratic discriminant analysis) and LDA (linear discriminant analysis) were combined in the RDA. Ill-posed and small sample size issues suffered from LDA and QDA were solved by RDA by using various regularization techniques. Also, in the RDA, for the estimation of optimal parameters PSO (particle swarm optimization) method was used. The results from this approach have demonstrated that the facial emotions were recognized robustly and accurately. When compared with the existing techniques the proposed approach outperformed them.\n\nIn real-world natural situations, for robustly recognizing the facial emotions  (Shojaeilangari et.al, 2015)  have proposed a system with ESL (Extreme Sparse Learning). The proposed method has the capability for learning both the non-linear classification and dictionary model. To provide accurate classification by the proposed method, the reconstruction property of the sparse representation has been combined together with the ELM's (extreme learning machine) discriminative power. On both the spontaneous facial emotion and acted databases, the recognition accuracy of state-of-the-art methods has been achieved by the proposed method.\n\nIn the recognition of facial emotions, still, there are some open challenging issues for simple and efficient feature selection and classification. During the classification process, for reducing the interclass pixel mismatch problem, a simple and effective FER approach has been developed by  (Krestinskaya et.al, 2017) . For removing the intensity offsets with Min-Max metric which is able to suppress the feature outliers, pixel normalization application has been included in the proposed approach. Though this method has been able to overcome many of the existing methods, the memory requirement for implementing the proposed method is very large.  (Sebe et.al, 2002)  have proposed a method for recognizing the emotions from the facial expressions in the video sequences. They have used a classifier called Cauchy Naive Bayes in which the model distribution is Cauchy distribution. To select the best assumption of model distribution, a framework has been provided. Results have shown that the Cauchy distribution assumption has provided a much better outcome than Gaussian distribution assumption.\n\nFor the automatic recognition of emotions, an approach has been proposed by  (Dhall et.al, 2011) . To encode the appearance and shape information, the LPQ (local phase quantization) and PHOG (pyramid of histogram of gradients) have been extracted in this approach. From the face tracking based on CLM (constraint local model), the normalized shape vectors have been derived. Then, k-means clustering has been applied to select the key frames. The proposed method has performed better than the baseline result.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Contribution",
      "text": "Our contribution in this paper is, we proposed an effective Micro-Facial expression recognition in video on the basis of optimal convolution neural network.\n\nThe proposed system performs the following procedure, a) For Micro-Facial expression recognition, a novel algorithm called MFEOCNN is proposed. To identify the facial expression, efficient features are selected optimally by means of Modified lion optimization (MLO) method. b) The proposed Micro-Facial expression recognition is done by convolutional neural network, which is recognized the facial expression in to relevant expression and irrelevant expression.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Proposed Method",
      "text": "In this paper, human facial expression recognition process is developed using three steps such as, i) Preprocessing ii) Extraction of features iii) Optimal feature selection and Micro-Facial expression recognition (MFEOCNN). Here the proposed method considering the input dataset is CohnKanada (CK+) dataset. Initially the input video is converted into number of frames, and then each frame is given to the input for preprocessing stage. The main intension of preprocessing stage is getting image as clear with normalized intensity, uniform size and shape. For preprocessing, an adaptive median filter is considered by the proposed system. Then the features are extracted from the resultant output. To extract the appearance variations of a testing image-spatial analysis micro facial features are utilized. In a sequence of facial images, to recognize the expressions motion information features are utilized. The proposed method considers the Histogram of Oriented Gradients (HOG) features, the local binary pattern (LBP) features and the Geometric features. Once the features are extracted from the input image they are given to further process. Optimal feature selection and Micro-Facial expression recognition is the final step of the developed method. Here the extracted features are selected optimally by means of MLO. Next the optimal features are utilized to recognize the Micro-Facial expressions. For recognizing the facial expression the suggested method utilizes CNN (convolutional neural network). The facial expression is effectively recognized by the proposed method based on CNN  [23] . The overall flow diagram of the proposed recognition method is shown in fig.  1 .\n\nThree Important steps in the proposed technique are,\n\n• Preprocessing\n\n• Feature extraction • Optimal feature selection and Micro-Facial expression recognition",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "Preprocessing",
      "text": "Initial stage of proposed Micro-Facial expression recognition is preprocessing. Preprocessing strategies predominantly went for the improvement of the face image without adjusting the data contained in an image. For the preprocessing, an adaptive median filter is utilized. This compares each pixel with its neighbor pixels to classify the noise pixels. The pixels which are not aligned structurally and are different from their neighbor pixels are denoted as impulse noise. Then the median pixel value is assigned to these noise pixels.\n\nLet Xij be the pixel value of input image, Xmin and Xmax indicate the minimum and maximum pixel value of the image. Xmed represents the median value. Wcrnt be the current window size, Wmnin and Wmax represents the minimum and maximum widow size. Wcrnt starts with the Wmin. The procedure of adaptive median filter is given beneath.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Procedure Of Adaptive Median Filter:",
      "text": "Input: Input image. Output: Preprocessed image. Start Capture Image. Preprocess the image. Identify minimum, maximum and median value of the image. Initialize the current window size, minimum and maximum window size.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Level A:",
      "text": "If Xmin<Xmed<Xmax then med Im pulsenoise , so the algorithm pass to level B.\n\nElse, the window size is increased, in which replace the pixel value with median value and repeat level A.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Level B:",
      "text": "If Xmin<Xij<Xmax then med Im pulsenoise , so the pixel value is unchanged.\n\nElse pixel is either equal to Xmax or Xmin then replace the pixel value with median value from level A. Restore the image pixel. End Stop Based on that, the noises from the input image or frames are removed and it will prepare the input frame for the next process.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Feature Extraction",
      "text": "Recognizing the facial expressions is a very challenging. In order to overcome this difficulty, the implemented method has to identify the uniqueness of each image under various expressions. In the proposed system, the feature values are calculated from the Neutral image as well as from the expression image. In our examination, the feature extracted from the preprocessed output is,\n\n• Geometric Features • HOG features • LBP features",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Geometric Features",
      "text": "In geometric based feature extraction  [27]  strategy, points which portray the geometric data related with facial features for example, eye, eyebrow, and mouth are set apart on the face. The proposed strategy needs to label each image with a lot of landmark points to discover the varieties in the face by ascertaining the deviation esteems. To discover the landmark points, pixels between the neutral image and the distinctive face responses of a specific individual is looked at. By utilizing the Euclidean distance, the contrast between the pixels is determined. The estimation of Euclidean distance is as per the following equation",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "….. (1)",
      "text": "After calculating the Euclidean distance, we need to apply the landmark points. The landmark points are connected as pursues: in the event that the Euclidean distance for a specific pixel is zero, at that point we need to prohibit that pixel. On the off chance that the Euclidean distance for a specific pixel gets any esteem, at that point we need to stamp that pixel as landmark point. From the input image the feature values are extracted based on the above process, then the extracted features are fed to the input for the next process.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Local Binary Pattern",
      "text": "The LBP  [25]  feature extraction strategy is a basic and non-parametric technique that depicts spatial data of the pixels in regards to their neighbor pixels. This is finished by appointing a label to every pixel utilizing the below equation,",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "….. (2)",
      "text": "Where, H G and V G represents the horizontal and vertical gradients.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Histogram Of Oriented Gradients",
      "text": "The HOG  [26]  feature extraction strategy utilizes local gradients to depict the shape of an object. To this end, the horizontal and vertical gradients of a given picture are determined first. At that point, the magnitude (M) and the direction (D) of every pixel's gradient are shown in below equation. the acknowledgment issue. Here the traditional lion algorithm  [22]  is modified by the updation function of PSO  [24]  algorithm. The proposed modified lion optimization algorithm based feature selection is clarified.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Optimal Feature Selection And Micro-Facial Expression Recognition",
      "text": "Feature selection in itself is one of the vital research territories in the space of machine learning. The principle of selecting features is getting the most optimal features which provide assistance in enhancing the recognition accuracy and lessening computational overhead, resource request and storage space necessity. In the process the most persuasive features get chose so that the user can be able to interpret the connection between the features and classes. In this paper, MLO method is proposed to choose the optimal features for the acknowledgment issue. Here the traditional lion algorithm  [22]  is modified by the updation function of PSO  [24]  algorithm. The proposed modified lion optimization algorithm based feature selection is clarified.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Modified Lion Optimization (Mlo) Algorithm",
      "text": "MLO is a Meta heuristic algorithm which is based on the population. Meta heuristic algorithms can produce distinctive answers for the issue in each run. Lion has one of a kind social conduct so it is the most grounded warm blooded animal on the planet. Lions have two sorts of social conduct: residents and nomads. Lion can switch the kind of social association, residents may progress toward becoming nomads and the other way around. Residents live in groups called as pride, in which the resident males and females are taken care of conceive an offspring. The second authoritative conduct is nomads, who move periodically either in sets or independently. Sets are more observed among the related males who have been avoided from the maternal pride. The MLO comprises of following steps, ➢ Evaluate fitness value for each lion ➢ Perform hunting operation and moving towards safe place for each lion ➢ Perform roaming operation for each lion ➢ Perform mating operation for each lion ➢ Perform updation operation using velocity updation These steps are repeated until some stopping condition is met.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Pf Indicates The Female Line Position",
      "text": "The distance between the chosen point by tournament selection and the female lion is indicated as D, {SP1} Indicates a vector for which, the starting point is the female lion's previous location and its moving direction is towards the selected point, {SP2} And {SP1} are perpendicular A low number of achievement demonstrates that the lions are swinging around the optimum point without critical enhancement. Additionally, a high number of achievements shows that they have met at a point which is far away from the optimum point. With the goal that the measure of the competition is assessed utilizing the achievement values.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Bsti, T",
      "text": "G Indicates the best position until iteration t, TSj (SU)Indicates the number of lions in the pride j which has an enhancement in the fitness for the last iteration, For each iteration, the tournament size is unstable, it implies that when SU esteem diminishes, TSj (SU)is expanded and it prompts assorted variety. With the goal that the competition estimate is determined utilizing beneath equation, STEP 4: Roaming operation: Roaming is a local search which helps the lion optimization algorithm (LOA) to look for a solution to enhance it. By n units, the lion moves towards the chosen region, where n is a random number with uniform distribution.\n\nThe distance between the selected area of territory and the position of male lion is indicated as D. Also, in the search space the nomad lions are moving chaotically. The new positions of nomad lions are given as pursues,\n\nThe probability value is denoted as probi , the random vector is indicated as RANDj , the uniform random number between 0 and 1 is denoted as randj and the current position of nomad is represented as Lij .\n\nFor every nomad lion, the probability value is independently calculated by using the below equation, Where, BstNO -represents the optimum delay of nomad lion NOi -represents the delay of i th lion\n\nThe number of nomad lions is represented as M. STEP 5: Mating operation: Mating is the vital one that guarantees the lions survival. A direct combination of parents is the mating operator to produce two new offspring. After choosing the male lions and female lion for mating, the new cubs are generated.\n\nHere, j is the dimension. If the male lion i is selected for mating, then SUi = 1, otherwise SUi = 0 .\n\nA random number with uniform distribution with standard deviation 0.1 and mean 0.5 is denoted as and the resident male lions count in a pride is denoted as NR .\n\nIn this lion algorithm, the information between the genders are shared by mating, while the new cubs get character from the two genders. Vi -indicates the current velocity.",
      "page_start": 8,
      "page_end": 9
    },
    {
      "section_name": "Lpi -Indicates The Current Lion Position",
      "text": "The overall flow of the proposed MLO algorithm is given in fig.  2 . From the above process the optimal features are selected for the proposed MFEOCNN. By utilizing this two updation process, it will conquer the weaknesses of the individual execution. Also, in a shorter computational time it has the benefits of rapidly focalizing and effectively acknowledging with the aim of getting an overall arrangement or idea. Then the output of this process is given to the recognition process. The clear explanation of the proposed recognition approach is described in further section.",
      "page_start": 9,
      "page_end": 10
    },
    {
      "section_name": "Recognizing Micro-Facial Expression Using Convolution Neural Network:",
      "text": "The proposed framework is developed by using a CNN with three layers which can distinguish and recognize the images into predefined classes. Here the strategy is thinking about the contribution as the optimal features. In CNN, the optimal features are directly given to the input feature map. There is no need to find the feature map in CNN. So, when compared to the traditional CNN the developed approach reaches the minimum processing time. CNN is typically made by a set out of layers that can be assembled by their functionalities. It is variations of MultiLayer Perceptron (MLPs) which are enlivened from biology. Convolution neural network can be connected to a wide assortment of computational tasks. The network comprises of three sorts of layers specifically convolution layer, output layer and sub sampling layer. The proposed CNN is appeared in fig.  3 .  This layer plays out the recognition of the facial expression dependent on the features separated by the past convolutional layers. In completely connected layer, each neuron is associated with each neuron of past layer. A soft max function is utilized to change over the yield of neural network into likelihood for each class. In view of the above procedure the facial expression is recognized as relevant emotion or irrelevant emotion.",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "V. Result And Discussion",
      "text": "The proposed Micro-Facial expression recognition in video based on optimal CNN is done on the working platform of MATLAB (version 2017a). The proposed system is implemented in a windows machine with the configurations Intel (R) Core i5 processor, 3.20 GHz, 4 GB RAM, and the platform of operating system is Microsoft Window7 Professional. In the proposed technique, adaptive median filter is utilized for preprocessing. From the preprocessed image the LBP, HOG geometric features are extracted. Then the optimal feature selection and MicroFacial expression recognition is done by Modified Lion Optimization (MLO) algorithm and Convolution neural network (CNN). Here the proposed method considering the input dataset is CK+ dataset  [28] . The experimental results are shown in the below sections. The sample images of the input dataset is shown in fig.  6 .",
      "page_start": 11,
      "page_end": 11
    }
  ],
  "figures": [],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Training \nTesting": ""
        }
      ],
      "page": 4
    },
    {
      "caption": "Table 1: Table 1: Details of evaluation parameters",
      "data": [
        {
          "Parameters": "Data Set",
          "Value": "Cohn-Kanada (CK+) dataset"
        },
        {
          "Parameters": "No of  Persons",
          "Value": "123 persons"
        },
        {
          "Parameters": "No  \nof video sequence",
          "Value": "593 video sequence"
        },
        {
          "Parameters": "Image Resolution",
          "Value": "640×480 and  640×490"
        },
        {
          "Parameters": "Tool Used",
          "Value": "Matlab 2017 a"
        }
      ],
      "page": 12
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Metho ds": "MFEOCNN  \n(CNN+MLO)",
          "Acc \nurac y": "0.99 2",
          "Rec all": "0.97 2",
          "F- \nMea \nsure": "0.97 2",
          "Prec \nision": "0.97 2",
          "Sens \nitivit y": "0.97 2",
          "Spec \nificit y": "0.99 5"
        }
      ],
      "page": 13
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "MEASURE \nS (%)": "Accuracy",
          "Proposed \nMFEOCNN  \n(CNN +MLO)": "0.992",
          "Existing \nMFEDRL": "0.98",
          "Existing  \nCNN \n+LO": "0.986",
          "Existing CNN": "0.984"
        },
        {
          "MEASURE \nS (%)": "F-Measure",
          "Proposed \nMFEOCNN  \n(CNN +MLO)": "0.972",
          "Existing \nMFEDRL": "0.93",
          "Existing  \nCNN \n+LO": "0.952",
          "Existing CNN": "0.944"
        },
        {
          "MEASURE \nS (%)": "Recall",
          "Proposed \nMFEOCNN  \n(CNN +MLO)": "0.972",
          "Existing \nMFEDRL": "0.93",
          "Existing  \nCNN \n+LO": "0.952",
          "Existing CNN": "0.944"
        },
        {
          "MEASURE \nS (%)": "Precision",
          "Proposed \nMFEOCNN  \n(CNN +MLO)": "0.972",
          "Existing \nMFEDRL": "0.93",
          "Existing  \nCNN \n+LO": "0.952",
          "Existing CNN": "0.944"
        },
        {
          "MEASURE \nS (%)": "Sensitivity",
          "Proposed \nMFEOCNN  \n(CNN +MLO)": "0.972",
          "Existing \nMFEDRL": "0.93",
          "Existing  \nCNN \n+LO": "0.952",
          "Existing CNN": "0.944"
        },
        {
          "MEASURE \nS (%)": "Specificity",
          "Proposed \nMFEOCNN  \n(CNN +MLO)": "0.995",
          "Existing \nMFEDRL": "0.99",
          "Existing  \nCNN \n+LO": "0.992",
          "Existing CNN": "0.944"
        }
      ],
      "page": 14
    },
    {
      "caption": "Table 4: Table.4 Comparison of recognition performance of various papers",
      "data": [
        {
          "Methods": "Proposed  \nMFEOCNN",
          "Recognition Accuracy": "99.2%"
        },
        {
          "Methods": "CDMML [20]",
          "Recognition Accuracy": "96.6%"
        },
        {
          "Methods": "LEMHI-CNN [21]",
          "Recognition Accuracy": "83.2%"
        }
      ],
      "page": 16
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Automatic facial feature extraction and expression recognition based on neural network",
      "authors": [
        "S Khandait",
        "R Thool",
        "P Khandait"
      ],
      "year": "2012",
      "venue": "Int J Adv Comput Sci Appl"
    },
    {
      "citation_id": "2",
      "title": "Facial expression recognition using principal component analysis",
      "authors": [
        "A Garg",
        "V Choudhary"
      ],
      "year": "2012",
      "venue": "Int J Sci Res Eng Technol"
    },
    {
      "citation_id": "3",
      "title": "Facial expression recognition using principal component analysis",
      "authors": [
        "A Gosavi",
        "S Khot"
      ],
      "year": "2013",
      "venue": "Int J Soft Comput Eng (IJSCE)"
    },
    {
      "citation_id": "4",
      "title": "Facial expression recognition based on geometric features and geodesic distance",
      "authors": [
        "W Cheng",
        "L Jingtian"
      ],
      "year": "2014",
      "venue": "Int J Signal Process"
    },
    {
      "citation_id": "5",
      "title": "The first facial expression recognition and analysis challenge",
      "authors": [
        "M Valstar",
        "B Jiang",
        "M Mehu",
        "M Pantic",
        "S Klaus"
      ],
      "year": "2011",
      "venue": "Automatic Face and Gesture Recognition"
    },
    {
      "citation_id": "6",
      "title": "Facial and vocal expressions of emotion",
      "authors": [
        "J Russell",
        "J Bachorowski",
        "J Fernandez-Dols"
      ],
      "year": "2003",
      "venue": "Annu Rev Psychol"
    },
    {
      "citation_id": "7",
      "title": "Emotion Analysis in Man-Machine Interaction Systems",
      "authors": [
        "T Balomenos",
        "A Raouzaiou",
        "S Ioannou",
        "A Drosopoulos",
        "K Karpouzis",
        "S Kollias"
      ],
      "year": "2005",
      "venue": "Procceedings of the First International Workshop on Machine Learning for Multimodal Interaction"
    },
    {
      "citation_id": "8",
      "title": "Deciphering the enigmatic face: The importance of facial dynamics to interpreting subtle facial expressions",
      "authors": [
        "Z Ambadar",
        "J Schooler",
        "J Cohn"
      ],
      "year": "2005",
      "venue": "Psychological Science"
    },
    {
      "citation_id": "9",
      "title": "Personalized facial expression recognition in indoor environments",
      "authors": [
        "C Chang",
        "Y Huang"
      ],
      "year": "2010",
      "venue": "Proc IEEE World Congress of Computational Intelligence"
    },
    {
      "citation_id": "10",
      "title": "Automatic facial expression analysis: a survey",
      "authors": [
        "B Fasel",
        "J Luettin"
      ],
      "year": "2003",
      "venue": "Pattern Recogn"
    },
    {
      "citation_id": "11",
      "title": "A direct LDA algorithm for high-dimensional data-Interests: Image Processing And Machine with application to face recognition",
      "authors": [
        "H Yu",
        "J Yang"
      ],
      "year": "2001",
      "venue": "Pattern Recogn"
    },
    {
      "citation_id": "12",
      "title": "Facial expression recognition based on twodimensional discriminant locality preserving projections",
      "authors": [
        "R Zhi",
        "Q Ruan"
      ],
      "year": "2008",
      "venue": "Neurocomputing"
    },
    {
      "citation_id": "13",
      "title": "Facial Emotion Recognition Systems based on PCA and Gradient Features",
      "authors": [
        "M Arora",
        "M Kumar",
        "N Garg"
      ],
      "year": "2018",
      "venue": "National Academy Science Letters"
    },
    {
      "citation_id": "14",
      "title": "Externalizing and internalizing symptoms moderate longitudinal patterns of facial emotion recognition in autism spectrum disorder",
      "authors": [
        "T Rosen",
        "M Lerner"
      ],
      "year": "2016",
      "venue": "Journal of autism and developmental and disorders"
    },
    {
      "citation_id": "15",
      "title": "An improved boosting algorithm and its application to facial emotion recognition",
      "authors": [
        "C Lee",
        "C Shih",
        "W Lai",
        "P Lin"
      ],
      "year": "2012",
      "venue": "Journal of Ambient Intelligence and Humanized Computing"
    },
    {
      "citation_id": "16",
      "title": "Robust representation and recognition of facial emotions using extreme sparse learning",
      "authors": [
        "S Shojaeilangari",
        "W Yau",
        "K Nandakumar",
        "J Li",
        "E Teoh"
      ],
      "year": "2015",
      "venue": "IEEE Transactions on Image Processing"
    },
    {
      "citation_id": "17",
      "title": "Facial emotion recognition using min-max similarity classifier",
      "authors": [
        "O Krestinskaya",
        "A James"
      ],
      "year": "2017",
      "venue": "Advances in Computing, Communications and Informatics (ICACCI)"
    },
    {
      "citation_id": "18",
      "title": "Emotion recognition using a cauchy naive bayes classifier",
      "authors": [
        "N Sebe",
        "M Lew",
        "I Cohen",
        "A Garg",
        "S Huang"
      ],
      "year": "2002",
      "venue": "Emotion recognition using a cauchy naive bayes classifier"
    },
    {
      "citation_id": "19",
      "title": "Emotion recognition using PHOG and LPQ features",
      "authors": [
        "A Dhall",
        "A Asthana",
        "R Goecke",
        "T Gedeon"
      ],
      "year": "2011",
      "venue": "Automatic Face & Gesture Recognition and Workshops"
    },
    {
      "citation_id": "20",
      "title": "Collaborative discriminative multi-metric learning for facial expression recognition in video",
      "authors": [
        "H Yan"
      ],
      "year": "2018",
      "venue": "Pattern Recognition"
    },
    {
      "citation_id": "21",
      "title": "Video facial emotion recognition based on local enhanced motion history image and CNN-CTSLSTM networks",
      "authors": [
        "M Hu",
        "H Wang",
        "X Wang",
        "J Yang1",
        "R Wang"
      ],
      "year": "2019",
      "venue": "Journal of Visual Communication and Image Representation"
    },
    {
      "citation_id": "22",
      "title": "Lion optimization algorithm (LOA): a nature-inspired metaheuristic algorithm",
      "authors": [
        "M Yazdani",
        "F Jolai"
      ],
      "year": "2016",
      "venue": "Journal of computational design and engineering"
    },
    {
      "citation_id": "23",
      "title": "Subject independent facial expression recognition with robust face detection using a convolutional neural network",
      "authors": [
        "M Matsugu",
        "K Mori",
        "Y Mitari",
        "Y Kaneda"
      ],
      "year": "2003",
      "venue": "Neural Networks"
    },
    {
      "citation_id": "24",
      "title": "Particle swarm optimization. Encyclopedia of machine learning",
      "authors": [
        "J Kennedy"
      ],
      "year": "2010",
      "venue": "Particle swarm optimization. Encyclopedia of machine learning"
    },
    {
      "citation_id": "25",
      "title": "Local binary patterns for multi-view facial expression recognition. Computer vision and image understanding",
      "authors": [
        "S Moore",
        "R Bowden"
      ],
      "year": "2011",
      "venue": "Local binary patterns for multi-view facial expression recognition. Computer vision and image understanding"
    },
    {
      "citation_id": "26",
      "title": "Facial expression recognition and histograms of oriented gradients: a comprehensive study",
      "authors": [
        "P Carcagnì",
        "Del Coco",
        "M Leo",
        "M Distante"
      ],
      "year": "2015",
      "venue": "SpringerPlus"
    },
    {
      "citation_id": "27",
      "title": "A novel geometric facial representation based on multiscale extended local binary patterns",
      "authors": [
        "D Huang",
        "M Ardabilian",
        "Y Wang",
        "L Chen"
      ],
      "year": "2011",
      "venue": "InFace and Gesture"
    },
    {
      "citation_id": "28",
      "title": "The extended cohn-kanade dataset (ck+): A complete dataset for action unit and emotion-specified expression",
      "authors": [
        "P Lucey",
        "J Cohn",
        "T Kanade",
        "J Saragih",
        "Z Ambadar",
        "I Matthews"
      ],
      "year": "2010",
      "venue": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition-Workshops"
    },
    {
      "citation_id": "29",
      "title": "Micro-Facial Expression Recognition Based on Deep-Rooted Learning Algorithm",
      "authors": [
        "S Lalitha",
        "K Thyagharajan"
      ],
      "year": "2019",
      "venue": "International Journal of Computational Intelligence Systems"
    }
  ]
}