{
  "paper_id": "2202.12703v2",
  "title": "Novel Techniques For Improving Nneten Entropy Calculation For Short And Noisy Time Series",
  "published": "2022-02-25T14:01:13Z",
  "authors": [
    "Hanif Heidari",
    "Andrei Velichko",
    "Murugappan Murugappan",
    "Muhammad E. H. Chowdhury"
  ],
  "keywords": [
    "Entropy",
    "NNetEn",
    "Neural Network Entropy",
    "time series",
    "neural network",
    "short length signal",
    "signal to noise ratio",
    "offset",
    "EEG"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Entropy is a fundamental concept in the field of information theory. During measurement, conventional entropy measures are susceptible to length and amplitude changes in time series. A new entropy metric, neural network entropy (NNetEn), has been developed to overcome these limitations. NNetEn entropy is computed using a modified LogNNet neural network classification model. The algorithm contains a reservoir matrix of N = 19625 elements that must be filled with the given data. A substantial number of practical time series have fewer elements than 19625. The contribution of this paper is threefold. Firstly, this work investigates different methods of filling the reservoir with time series (signal) elements. The reservoir filling method determines the accuracy of the entropy estimation by convolution of the study time series and LogNNet test data. The present study proposes 6 methods for filling the reservoir for time series of any length 5 ‚â§ N ‚â§ 19625. Two of them (Method 3 and Method 6) employ the novel approach of stretching the time series to create intermediate elements that complement it, but do not change its dynamics. The most reliable methods for short time series are Method 3 and Method 5. The second part of the study examines the influence of noise and constant bias on entropy values. In addition to external noise, the hyperparameter (bias) used in entropy calculation also plays a critical role. Our study examines three different time series data types (chaotic, periodic, and binary) with different dynamic properties, Signal to Noise Ratio (SNR), and offsets. The NNetEn entropy calculation errors are less than 10% when SNR is greater than 30 dB, and entropy decreases with an increase in the bias component. The third part of the article analyzes real-time biosignal EEG data collected from emotion recognition experiments. The NNetEn measures show robustness under low-amplitude noise using various filters. Thus, NNetEn measures entropy effectively when applied to real-world environments with ambient noise, white noise, and 1/f noise.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Introduction",
      "text": "Entropy-based methods are efficient tools for analyzing any nonlinear, non-stationary, or dynamic signals  [1, 2] . Compared to other nonlinear methods  [3] , entropy-based feature analysis is computationally efficient and highly suitable for analyzing the input data with fewer to a larger number of samples. The entropy-based analysis has been widely used in medical diagnosis, fault detection, image processing applications, information encryption and speech recognition  [4] [5] [6] [7] [8] [9] . Researchers are actively utilizing entropy measures in many real-world applications due to their efficient information retrieval from the input data. Yaƒü at al. used entropy-based features to classify plant leaf diseases  [10] . Multiscale symbolic fuzzy entropy is used for fault detection in rotating machinery  [11] ; Minhas et al. examined the weighted entropy method for bearing fault detection  [2] ; Ai et al. studied the fusion information entropy for roller bearing fault detection in aircraft engines  [4] ; Ra et al. evaluated the permutation entropy of Electroencephalogram (EEG) signals for early diagnosis of epileptic seizures  [5] ; Zavala-Yoe et al. investigated the multiscale entropy to study Doose and Lennox-Gastaut syndromes in children  [6] ;  Benedetto et al. utilized  the Shannon entropy to model the flows between different financial time series  [12] ; Silva et al. investigated the predictability of monthly precipitation time series using permutation entropy; Nie et al. introduced a generalized entropy measure for image segmentation  [13] ; and  Oludehinwa et al. investigated  the relationship between the degree of complexity of magnetospheric dynamics and various categories of geomagnetic storms using the maximum Lyapunov exponent and the approximate entropy measure  [14] . The major challenges in conventional entropy measurements are: (a) hyperparameter tuning; (b) input data length limitations; (c) the effect of input noise on the results.\n\nRecently, Velichko and Heidari proposed a new measure of entropy (NNetEn) based on the LogNNet artificial neural network (ANN)  [15] . In the analysis of time series, the number of epochs is the only control parameter that achieves substantially more stable results than other conventional entropy measures (approximate entropy, Shannon entropy, etc). Further, it has the advantage of being independent of signal amplitude, suitable for analyzing short and lengthy-time series data, and does not consider the probability distribution within the data, which makes it distinct from other traditional entropy measures  [15] . The main objective of this work is to propose a novel ANN-based entropy calculation for variable data lengths with limited number of hyperparameters to overcome constraints of conventional entropy computations. Hence, this paper investigates different reservoir matrix filling methods and the effects of noise on the value of NNetEn in light of its advantages over other entropy measures.\n\nIn the first part of the scientific results, a method is presented for filling the reservoir with time series data (signals). Ultimately, the adequacy of the entropy estimate is determined by the reservoir filling method incorporated into the convolution of the time series under study with LogNNet test data derived from the MNIST database. In this study, six methods (Methods 1-6) are proposed for filling a reservoir of time series with a length of 5 ‚â§ N ‚â§ 19625. A range of N in this range is most commonly used for financial markets  [16] , physical experiments  [17, 18] , and biological and medical data  [19, 20] . Both Method 3 and Method 6 use a novel approach to stretching time series in which intermediate elements are generated to complement the time series without changing its dynamics. In particular, this approach can be applied to short series (N < 1000) of physical data. We believe that Method 3 and Method 5 are the most effective methods for short time series. A number of studies have already proven the effectiveness of these methods, as indicated in the preprint of this work. An analysis of ship-radiated noise signals was conducted by Li et al. using NNetEn  [21]  (Method 5). A method of detecting motor imaginary in patients with stroke or spinal cord injury was developed by Heilari using NNetEn  [22] . According to his findings, eight channels are enough for classification, unlike previous studies that considered 30 channels. In remote sensing imagery and geophysical mapping, Velichko et al. used Method 1 for twodimensional NNetEn. An S-Switch-based chaotic spike oscillator circuit was analyzed with Method 3 for bifurcation and entropy analysis  [25] . During major geomagnetic storms, Oludehinwa et al. used Method 3 for NNetEn to examine the response of dynamical complexity in traveling ionospheric disturbances across Eastern Africa sector. Thus, in the first part of the work, we examined different matrix-filling techniques for entropy computation of short time series. The experimental results demonstrate that the proposed matrix filling method can be applied to time series with a length of N ‚â• 5.\n\nThe second part of the study is devoted to the problem of the influence on the entropy value of the presence of noise or a constant bias in the signal. Results demonstrate that the error in calculating the NNetEn entropy is less than 10% when the signal-to-noise ratio is greater than 30dB. Also shown, with an increase in the bias component, the role of the chaotic components is weakened, and entropy decreases. In relation to comparing the performance of different entropy measures, noise can be regarded as one of the most significant factors affecting the entropy value  [27] . It has been demonstrated that Kolmogorov-Sinai entropy and the correlation integral algorithm are inefficient methods for calculating entropy in the presence of noise  [28] . It has been observed that the permutation entropy measure is highly volatile in the presence of noise  [29]  . Similarly, the entropy features are generally calculated from the given time series following the removal of noise (filtering). Consequently, reducing the effects of noise in time series data has become a popular research topic over the last few decades. In  [30] , Xie and Guo applied fuzzy spectrum entropy analysis to denoise biomedical signals; Chatterjee et.al. reduced the effect of noise from chemical and electronic sources using patterns of ion current chromatograms  [31] ; Na et.al. compared cross-correlation with Shannon entropy in order to minimize the effects due to unwanted noise  [32] ; Wang et.al. studied multi-fault features of transmission in the presence of noise  [33] . Time series length is also an impacting factor that affects entropy  [27, 34, 35] . Conventional entropy measures are not suitable for time series analysis with a limited number of data. This is because they are very sensitive to the length of the data series  [36, 37] . Wu et al. presented a modification to multiscale entropy to deal with imprecise entropy values  [38] , and Niu and Wang used a simplified version of multiscale entropy to analyze the short financial time series to overcome this challenge  [36] .\n\nWe present a real-time example of time-series data collected from an emotion recognition experiment for testing the efficacy of the proposed NNetEn on time-series data analysis in the third part of the article. Affective computing has become a hot topic from both a theoretical and practical perspective in recent years due to rapid technological advancements. Over the past few years, affective computing research has grown rapidly and has been applied to healthcare, robotics, management, marketing, and smart technology  [39, 40] . The manifestation of emotion can be determined by a variety of means, including facial expressions, gestures, speech signals, and biosignals such as electroencephalograms (EEGs), electromyograms (EMGs), electrocardiograms (ECGs), etc. Due to their ability to capture minute changes in emotions, EEG signals are more robust than other signals because they are not subjected to fake or masking behaviors. The acquisition of EEG signals is inexpensive, has a high temporal resolution, and offers an adequate spatial resolution. A study by Soroush et al.  [39]  examined different methods for classifying emotions based on EEG signals. In their study  [43] , Murugappan et al. used extreme machine learning combined with recurrent quantification analysis (RQA) to detect emotion in EEG data collected from Parkinson's patients (PD). A mean differential entropy method is presented by Li et al for classifying emotional states in EEG data  [44] . A tunable Q-wavelet transform was implemented by Murugappan et al.  [42]  to improve the accuracy of EEG emotion recognition in PD patients. A tunable Q-wavelet transform, and support vector machine method were used by Tuncer et al. to recognize emotions based on EEG signals  [40] . A study by Li et al attempted to identify emotions through EEG in the presence of noise  [45] . Researchers collected EEG data from 14 healthy subjects for the detection of six basic emotions, namely happiness, sadness, fear, anger, disgust, and surprise  [46] . We examined real-time data from a normal control subject using a 14-channel Emotiv EPOC wireless EEG data acquisition device in order to evaluate NNetEn's performance. A variety of filters are applied to the signal to demonstrate that NNetEn measures are robust under low-amplitude noise. Therefore, NNetEn is an effective measure of entropy in real-world environments that involves ambient noise, white noise, and 1/f noise.\n\nThe major contributions in the present work are: ÔÇ∑ Proposed six different types of matrix filling (reservoir) methods to compute the NNetEn on the input data with variable data length.\n\nÔÇ∑ Investigated the performance of NNetEn under different types of noises and constant bias.\n\nÔÇ∑ Analyzed the performance of NNetEn on real-time physiological signals (EEG).\n\nThe rest of the paper is structured as follows. In Section 2, the LogNNet model and matrix padding techniques are presented. In Section 3, numerical examples are presented to investigate the efficiency of the matrix filling techniques and the effect of noise on the NNetEn measure. The performance of NNetEn with real-time EEG data is also presented in Section 3. Finally, Section 4 is devoted to conclusions.",
      "page_start": 2,
      "page_end": 5
    },
    {
      "section_name": "Methods",
      "text": "",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Lognnet Model For Entropy Calculation",
      "text": "NNetEn is a recently introduced entropy measure based on the LogNNet model (Figure  1 )  [15] . Unlike conventional entropy measures, NNetEn does not consider a probability distribution. In addition, it depends on only one parameter i.e. Number of epochs in the LogNNet model. These advantageous features make NNetEn a powerful entropy measure for any time series data analysis. In the NNetEn algorithm, the Modified National Institute of Standards and Technology (MNIST-10  [47] ) dataset is considered the input of LogNNet. MNIST-10 is a popular benchmark and large size dataset which is widely used for comparing the efficiency of different machine learning algorithms  [48] .This dataset is divided into training and testing parts which contain 60000 and 100000 images, respectively with a resolution of 28 √ó 28 pixels. The NNetEn algorithm requires a reservoir matrix which is constructed by using the given time series. The reservoir matrix is denoted by W1 in Figure  1 , where P is the number of considered neurons. In the classification phase, a feedforward artificial neural network with single layer and 25 neurons is used. Therefore, the reservoir matrix has a capacity to accommodate N0 = 19625 elements.\n\n. The number of epochs Ep is the only control parameter in the LogNNet algorithm. The classification accuracy of LogNNet shows the degree of chaos in the reservoir matrix and is defined as the NNetEn entropy measure\n\nThe flowchart of the NNetEn algorithm is shown in Table  1 .\n\nNNetEn algorithm  [15] . In this article, based on the heuristic approach, we considered the maximum value of the epoch, Ep = 100 and NNetEn is referred as NNetEn (100).\n\nThe concept of learning inertia (LI) is introduced in  [15]  for investigating the effect of Ep on the NNetEn value.\n\nFor a given time series, the learning inertia concerning epochs numbers Ep1 and Ep2 is defined as follows,\n\nAn analysis of the behavior of LI provides valuable information about the convergence of the learning process in neural networks models, which helps the researchers to discover additional features of chaotic signals. For example in  [26] , LI was used for filtering the NNetEn signal (Ep1 = 20, Ep2 = 1), and in  [15] , LI was the feature of the occurrence of weak chaos in the periodic component (Ep1 = 100, Ep2 = 400). Hence, based on the heuristic approach, we have used the value of Ep1 and Ep2 as 100 and 400, respectively on this work. The calculation of one time series with 100 epochs takes about 37 s using one Intel‚Ñ¢ Co‚Ñ¢ m3-8100Y CPU @ 1.10 GHz processor thread. The NNetEn calculation program is available for free download (see Section Data Availability).",
      "page_start": 5,
      "page_end": 6
    },
    {
      "section_name": "Reservoir Filling Techniques",
      "text": "In practice, it is difficult to obtain time series with N = 19625 data points. Presume that we have a time series data with N data points. If N > 19625, we must ignore N-19625 data points of the time series and fill the reservoir matrix with the remaining data points. This case rarely occurs in real-world applications. If the total number of data points in the time series data is less than 19625 (N) data points, we propose six different types of reservoir filling methods to utilize the LogNNet to compute the NNetEn values. Here, the process of filling is performed through either row-wise or column wise filling of the reservoir matrix. For the purpose of describing the filling processes, we considered a smaller size matrix W1 filled with series xn = n, where n varies from 1 to 9.\n\n(a) Method 1: Row-wise filling with duplication\n\nIn this method, the matrix W1 is filled row by row, doubling the row for subsequent data points, as described in Figure  2 .  This method is similar to filling the matrix row by row. We considered the zero values for the remaining data points in the matrix row if the row cannot be filled with all the given time series data points. A schematic description and an example of this method is given in Figure  3 .\n\n1 2 3 4 5 6 7 8 9 0 0 0 0 0 1 2 3 4 5 6 7 8 9 0 0 0 0 0 In this method, the matrix W1is filled column by column, duplicating the columns for the subsequent data points, as shown in Figure  5 .  This method is similar to Method 2 where the column is considered instead of rows (Figure  6 ). In this method, the matrix is filled column by column, stretching the time series to N = 19625, as described in method 3.",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "Experimental Results And Discussion",
      "text": "",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "The Effect Of The Length Of The Time Series On The Value Of Nneten",
      "text": "We investigated the efficiency and stability of the six matrix-filling methods using the above-mentioned matrixfilling methods on three types of time series, namely periodic discrete maps, binary discrete maps, and logistic maps, taking into consideration the total number of data points N. A robust analysis of different matric-filling methods can be obtained by considering periodic  [51] , binary  [52] , and chaotic time series  [51]  as follows:\n\n(i) Periodic discrete map:\n\n(ii) Binary discrete map:\n\n(iii) Logistic map:\n\nThe epochs number (ùëõ) is set to 100 in this sub-section. for N < 11000 because there is less variation and deviation from the reference level. Figure  8  and Figure  9  illustrate the NNetEn measures for a periodic discrete map (Eq.(  3 )) and a binary discrete map (Eq.(  4 )) with different numbers of data points in the range N = 10,..., 19625. Method 3 is most suitable for periodic time series with N > 5 since it does not fluctuate in entropy values and converges in a small number of cases (N). Both Method 3 and Method 6 use the novel stretching approach when intermediate elements have been generated that complement the time series without altering its dynamics. This approach is especially relevant for short series of physical nature. In Figure  9 , method 5 gives the most stable results for binary time series when N > 11000, and method 1 is suitable when N > 5. Based on Method 2 (row-wise filling with an additional zero element), NNetEn exhibits divergence and periodic behavior for all-time series considered. In a similar comparison, Method 5 (column-wise filling with an additional zero element) shows that NNetEn's periodic behavior decreases with increasing N, and eventually converges.",
      "page_start": 8,
      "page_end": 9
    },
    {
      "section_name": "The Effects Of Noise On The Nneten Measure",
      "text": "We considered the noisy signal in the form\n\nwhere xn is the original signal given by Eqn. (3) -Eqn. (  5 ) and zn is the random noise. The random noise  [51]  signal is formulated as,\n\nwhere R is a random number between 0 and 1, A is the amplitude of noise and B is the bias of the noise signal. To investigate the effect of noise on NNetEn measure, we considered the following signal-to-noise ratio  [53] ,\n\nwhere, Asignal and Anoise denote the amplitude of the main signal and the amplitude of noise, respectively.\n\nNNetEn considers matrix filling method 5 to be the main reservoir filling technique among the six different types of filling methods. This is because this method performs well in calculating the entropy measure on two different types of time series data among three different types of time series. The values of NNetEn and learning inertia for the original signal without noise and with different offsets B are presented in Figure  10 . The dependencies generally take the form of a bell-shaped curve with a maximum of entropy at a certain bias value and a minimum of LI that corresponds to a maximum of NNetEn. In the case of a binary signal, entropy remains unchanged.\n\nIncreasing the modulus of constant bias results in a decrease in entropy for sinusoidal and logistic signals.  The properties of the random signals are listed in Table  2 .   at B = 0, while the value of inertia has a minimum value at this point. Due to its small value for all three random signals, the mean value (Table  2 ) does not play a significant role in the analysis. The complexity of the signals at B = 0 determines the entropy of the signals. As a result of its high entropy and complexity, the signal random_1 is the most complex. Across all three signals, learning inertia is close to zero and increases as |B| increases. It is a universal phenomenon for NNetEn to be dependent on B in a bell-shaped manner. As the bias component B is increased, the role of chaotic components is weakened, and entropy is decreased. In addition, the LI value increases with a decrease in the importance of chaotic components. The LI can be used to assess the degree of chaos in a system in terms of its degree of regularity. Based on our earlier work  [49] , this may explain the increased LI in the transition region.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Influence Of Noise Amplitude A On The Main Signal",
      "text": "As discussed in Eqn 7, we examined the effect of noise scale A in NNetEn with B = 0 in this subsection. Figure  13  illustrates how the shape of the sinusoidal signal changes as the noise amplitude increases from A = 0 to 1. In the case of A = 0.05, 0.  NNetEn shows the greatest change with increasing A when the sine periodic map is considered. In the case of sine, NNetEn increases by 100% when A is raised to 0.05, by 20% for the binary map, and by 5% for the logistic chaotic map when A is elevated to 0.05. The logistic chaotic map (Figure  16 ) exhibits a small variation due to the initial chaotic nature of the signal, and the addition of random noise slightly increases its irregularity. As a result, the error in calculating NNetEn entropy for all types of signals is less than 10% when the SNR exceeds 30 decibels. As a result, NNetEn can now be measured for experimental signals with the noise of different characteristics, white noise, or 1/f noise, without requiring noise filtering.",
      "page_start": 14,
      "page_end": 16
    },
    {
      "section_name": "The Effect Of Offset B",
      "text": "In this subsection, we consider noise in the form of Eqn 7, where A is fixed, and B varies between 0 and 1 in increments of 0.05. In order to examine the effect of offset B, A is assumed to be 0.05 or 0.3. The results are shown in Figure  17  to Figure  19 . In all figures, NNetEn decreases with increasing bias (B). As a result, the stochastic property of the noisy signal decreases with increasing offset B. There is a considerably higher degree of complexity in the behavior of LI dependent on B than in NNetEn dependent on B. For a sinusoidal signal, there are maxima and minima, and for a logistic chaotic map, an increase in B increases LI. If B is increased by 5%, NNetEn will be affected by 10%. Therefore, B has a smaller effect on NNetEn than A.",
      "page_start": 16,
      "page_end": 16
    },
    {
      "section_name": "Analysis Of Nneten With Real-Time Data",
      "text": "To investigate the performance of NNetEn with real-time data, we examined an EEG signal acquired from a normal control subject using the 14-channel Emotiv EPOC wireless EEG data acquisition device with a sampling rate of 128 samples per second for a duration of 56 seconds (Figure  20a ). A detailed description of the data acquisition environment and experimental settings can be found in  [46] . To assess the effectiveness of the proposed NNetEn on time-series data analysis, we also considered a real-time example of time-series data collected from an emotion recognition experiment. Rapid technological advancements have made affective computing a hot topic from both a theoretical and practical perspective in recent years. As affective computing research has grown rapidly over the past few years, it has been applied to a variety of fields, including healthcare, robotics, management, marketing, and smart technologies  [39, 40] . Different modalities can be used to assess emotion, including facial expressions, gestures, speech signals, and biosignals (EEG, Electromyogram (EMG), Electrocardiogram (ECG), etc.). EEG signals are more robust since they are not affected by fake or mask behaviors and directly correlate with the electrical activity of the brain to detect minute changes in emotion  [41, 42] . An EEG signal can be acquired by a low-cost data acquisition device, is more temporally accurate, and offers a high spatial resolution. According to Soroush et al. , different methods have been developed to classify emotions based on EEG signals  [39] . Murugappan et al. used extreme machine learning along with recurrent quantification analysis (RQA) for the detection of EEG emotions in Parkinson's disease patients  [43] . Li et al introduced the mean differential entropy method for the classification of EEG emotions  [44] . In a study conducted by Murugappan et al., a tunable Q-wavelet transform was used in order to improve the accuracy of EEG emotion recognition for patients with Parkinson's disease  [42] . A tunable Q-wavelet transform, and the support vector machine method were used by Tuncer et al. to recognize emotion from EEG signals  [40] . A study conducted by Li et al investigated the recognition of emotions using EEG in the presence of noise  [45] . According to  [46] , researchers collected the EEG data from 14 normal and healthy subjects for the purpose of detecting six basic emotions: happiness, sadness, fear, anger, disgust, and surprise. Figure  20b  illustrates the spectrum of the signal being analyzed. A large portion of the spectrum covers the range from 0.02 to 30 Hz, with zero DC component, while a high-frequency region reaches frequencies of 65 Hz.\n\nAn IIR Butterworth band-pass filter of 4th order is usually used to filter the raw signal in the range of 0.5 to 49 (Figure  20c ). Therefore, it allows for the removal of high-frequency and low-frequency noises due to interference with power lines, movement artifacts, baseline interferences, etc. Typically, high-frequency and low-frequency noises are filtered by low-pass filters (Figure  21a ) and high-pass filters (Figure  21b ), respectively. Figures  21c  and 21d  illustrate a typical characteristic of an ideal band-stop and band-pass filter with a lower (Fc1) and upper (Fc2) cut-off frequency. A raw EEG signal has an entropy of NNetEn (100) = 0.637, and after passing through a band-pass filter with a cut-off frequency of 0.5 -49 Hz, it has an entropy of NNetEn(100) = 0.657. The removal of high-frequency and low-frequency noises has not significantly affected the NNetEn (100) entropy value, since the signal under consideration initially exhibits a high entropy in the range of 0.5 -49 Hz.\n\nThis section examines the impact of low-pass and high-pass FFT filters on the value of NNetEn (100). Figure  22a  and Figure  22b  illustrate the effects of low-pass filtering with Fc = 40, 20, 5 Hz and high-pass filtering with Fc = 0.1, 0.5, 1 Hz. According to the spectral response of the original signal, the cut-off frequencies above have been arbitrarily selected.\n\nThe next step is to analyze the effect of low-pass and high-pass FFT filters on the value of NNetEn (100). Figures  22a  and 22b  illustrate the effects of low-pass filtering with Fc = 40, 20, 5 Hz and high-pass filtering with Fc = 0.1, 0.5, 1 Hz. Based on the spectral response of the original signal, the above cut-off frequencies were arbitrarily selected. Therefore, the presence of high-frequency noise with a frequency of over 40 Hz does not affect the value of NNetEn, and the EEG signal entropy can be measured quite accurately without a preliminary filtering process. Using a low-pass filter with Fc = 40 Hz reduces entropy, so the signal becomes smooth, and irregularity is tamed. Figure  22a  presents signals that have passed low-pass filters with a cut-off frequency of Fc = 20 Hz and Fc = 5 Hz, with entropies of NNetEn (100) ~ 0.52 and NNetEn (100) ~ 0.33, respectively. The signal has the least randomness at Fc = 5 Hz, due to its smoothed shape compared to raw EEG data. A high-pass filter does not significantly affect NNetEn (100), as shown in figure  23b . Comparing Figures 22b, it is evident that the shape of the signal changes significantly if the low-frequency component is removed. Variations in signal shape are caused by an increase in Fc, which results in an increase in the entropy value (see Figure  23b ). It can be explained by the fact that the entropy value increases in highfrequency regions. In Figure  20 (a), the sample EEG signal after band-pass filter 0.5 Hz and 49 Hz had an entropy value NNetEn(100) = 0.657. We examined the robustness of NNetEn of sample EEG signal under a band-block filter. As shown in Figure  23 (a), we filtered the EEG signal using an IIR Butterworth low-pass filter with a cutoff frequency of Fc = 5 Hz and determined that NNeEn (100) is approximately 0.33. The value of NNetEn (100) decreases to 0.5 when a high-pass filter with a cut-off frequency of Fc = 45 Hz is applied (Figure  24a ). As shown in Figure  24b , a high-pass and low-pass filter (band-block filter) are combined to produce the resultant signal. A band-block filtered signal (Figure  24b ) has an entropy value of NNeEn (100) ~0.345, similar to the entropy of a low pass filtered signal with Fc = 5 Hz. Thus, the removal of the main carrier frequencies in the range of 5-45 Hz leads to a decrease in entropy.\n\nAs a result, NNetEn measures are robust in the presence of noise. NNetEn allows the analysis of various types of real-time biosignals or time series data using the same method.",
      "page_start": 17,
      "page_end": 20
    },
    {
      "section_name": "Conclusion",
      "text": "This and 6 stretch time series by complementing them without affecting their dynamics. Short-time series data are handled more efficiently by Method 3 and Method 5. We have investigated three different time series data types (chaotic, periodic, and binary) with different dynamic properties, assorted signal-to-noise ratios (SNRs), and offset values. Found that NNetEn entropy calculation errors are less than 10% when SNR is greater than 30dB. It is also shown that with an increase in the bias component, the role of the chaotic components is weakened, and entropy decreases. NNetEn calculation methodology has been evaluated using real-time EEG data collected from emotion recognition tasks to assess its robustness under various noise conditions. The experimental results indicate that the NNetEn measures are robust under low-amplitude noise. Thus, NNetEn is an effective measure of entropy when applied to real-world environments with various types of noise. Even though the proposed method retrieves information from the given time series data efficiently, it's computationally expensive (requires more computational memory and time). Our goal in future research is to expand the supported platforms, including Python, and to speed up calculations to reduce their computational complexity. Furthermore, NNetEn computation can also be applied to applications that involve multidimensional time-series data.",
      "page_start": 21,
      "page_end": 21
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: ) [15]. Unlike",
      "page": 5
    },
    {
      "caption": "Figure 1: , where P",
      "page": 5
    },
    {
      "caption": "Figure 1: The LogNNet model structure for NNetEn calculation [49]",
      "page": 5
    },
    {
      "caption": "Figure 2: (a) The structure of matrix filling method 1; (b) An example of a time series with nine data points.",
      "page": 7
    },
    {
      "caption": "Figure 3: (a) The structure of matrix filling method 2; (b) An example of a time series with nine data points.",
      "page": 7
    },
    {
      "caption": "Figure 4: (a) shows a time series {xn} with N = 100 values. The",
      "page": 7
    },
    {
      "caption": "Figure 4: (b)). The detailed arrangement of the data points {zn} near x28 is shown in Figure",
      "page": 7
    },
    {
      "caption": "Figure 4: (a) The time series {xn} with N = 100 data points; (b) Stretching {xn}into the time series {zn} with N",
      "page": 8
    },
    {
      "caption": "Figure 5: (a) The structure of matrix filling method 4; (b) An example of a time series with nine data points.",
      "page": 8
    },
    {
      "caption": "Figure 6: (a) The structure of matrix filling method 5; (b) An example of a time series with nine data points.",
      "page": 8
    },
    {
      "caption": "Figure 7: shows different matrix filling methods applied to measure the NNetEn values for a chaotic logistic map",
      "page": 9
    },
    {
      "caption": "Figure 7: The effect of time series length on NNetEn values for the logistic map (Eqn 5) using different matrix",
      "page": 10
    },
    {
      "caption": "Figure 8: The effect of time series length on NNetEn values for periodic time series (Eqn 3) using different",
      "page": 10
    },
    {
      "caption": "Figure 8: and Figure 9 illustrate",
      "page": 11
    },
    {
      "caption": "Figure 9: The effect of time series length on NNetEn values for binary time series (Eqn.4) using different",
      "page": 11
    },
    {
      "caption": "Figure 9: , method 5 gives the most stable results for binary time series when N > 11000, and method 1 is suitable",
      "page": 12
    },
    {
      "caption": "Figure 10: The dependencies",
      "page": 12
    },
    {
      "caption": "Figure 10: (a)The values of NNetEn for the main signals (A = 0), (b) The learning inertia values for the main",
      "page": 12
    },
    {
      "caption": "Figure 11: shows the first 100",
      "page": 12
    },
    {
      "caption": "Figure 11: The first 100 data points of the random signals of the form (Eqn 7) with A = 1 and B = 0.",
      "page": 13
    },
    {
      "caption": "Figure 12: (a) The values of NNetEn of random signals. (b)The learning inertia of random signals.",
      "page": 13
    },
    {
      "caption": "Figure 12: shows the NNetEn and learning inertia values for random signals. We found that the NNetEn value for",
      "page": 13
    },
    {
      "caption": "Figure 13: illustrates how the shape of the sinusoidal signal changes as the noise amplitude increases from A = 0 to 1. In",
      "page": 14
    },
    {
      "caption": "Figure 13: The effect of amplitude noise on sine periodic signal.",
      "page": 15
    },
    {
      "caption": "Figure 14: The NNetEn (a) and learning inertia (b) values of noisy sine periodic map where the offset is",
      "page": 15
    },
    {
      "caption": "Figure 15: The NNetEn (a) and learning inertia (b) values of the noisy binary map where the offset is neglected.",
      "page": 15
    },
    {
      "caption": "Figure 16: The NNetEn (a) and learning inertia (b) values of the noisy logistic map where the offset is",
      "page": 16
    },
    {
      "caption": "Figure 16: ) exhibits a small variation due to the",
      "page": 16
    },
    {
      "caption": "Figure 17: to Figure 19. In all figures, NNetEn decreases with increasing bias (B). As a result, the",
      "page": 16
    },
    {
      "caption": "Figure 17: The NNetEn (a) and learning inertia (b) values of noisy sine periodic map for amplitude noise A  =",
      "page": 16
    },
    {
      "caption": "Figure 18: The NNetEn (a) and learning inertia (b) values of the noisy binary map for amplitude noise A  = 0.05",
      "page": 16
    },
    {
      "caption": "Figure 19: The NNetEn (a) and learning inertia (b) values of noisy logistic map for amplitude noise A  = 0.05",
      "page": 17
    },
    {
      "caption": "Figure 20: a). A detailed description of the data",
      "page": 17
    },
    {
      "caption": "Figure 20: b illustrates the spectrum of the signal being analyzed. A large portion of the spectrum covers the range",
      "page": 18
    },
    {
      "caption": "Figure 20: c). Therefore, it allows for the removal of high-frequency and low-frequency noises due to interference",
      "page": 18
    },
    {
      "caption": "Figure 21: a) and high-pass filters (Figure 21b), respectively. Figures 21c",
      "page": 18
    },
    {
      "caption": "Figure 22: b illustrate the effects of low-pass filtering with Fc = 40, 20, 5 Hz and high-pass filtering with Fc =",
      "page": 18
    },
    {
      "caption": "Figure 20: An example of a raw EEG signal (a), frequency‚Äôs spectrum of EEG raw signal (b), signal after band-",
      "page": 18
    },
    {
      "caption": "Figure 21: Frequency characteristics of low-pass (a), high pass (b), band-stop (c), and band-pass (d) filters",
      "page": 19
    },
    {
      "caption": "Figure 22: Examples of EEG signal filtering when applying (a) Low-pass filter (b) High - pass filter",
      "page": 19
    },
    {
      "caption": "Figure 23: NNetEn (100) for EEG signal after applying (a) low-pass filter (b) high-pass filter",
      "page": 19
    },
    {
      "caption": "Figure 23: a. If Fc > 40 Hz, NNetEn (100) ~ 0.63 is the same, and practically does not change.",
      "page": 19
    },
    {
      "caption": "Figure 22: a presents signals that have passed low-pass filters with a cut-off frequency of Fc = 20 Hz and Fc = 5",
      "page": 20
    },
    {
      "caption": "Figure 24: Signals: (a) High frequency noise and (b) signal after band-stop filter",
      "page": 20
    },
    {
      "caption": "Figure 23: b). It can be explained by the fact that the entropy value increases in high-",
      "page": 20
    },
    {
      "caption": "Figure 20: (a), the sample EEG signal after band-pass filter 0.5 Hz and 49 Hz had an entropy",
      "page": 20
    },
    {
      "caption": "Figure 23: (a), we filtered the EEG signal using an IIR Butterworth low-pass filter with a cut-",
      "page": 20
    },
    {
      "caption": "Figure 24: a). As shown",
      "page": 20
    },
    {
      "caption": "Figure 24: b, a high-pass and low-pass filter (band-block filter) are combined to produce the resultant signal. A",
      "page": 20
    },
    {
      "caption": "Figure 24: b) has an entropy value of NNeEn (100) ~0.345, similar to the entropy of a",
      "page": 20
    }
  ],
  "tables": [
    {
      "caption": "Table 1: W = [(w ) ]",
      "page": 5
    },
    {
      "caption": "Table 1: NNetEn algorithm [15].",
      "page": 6
    },
    {
      "caption": "Table 2: Table 2. The statistical properties of random signals.",
      "page": 13
    },
    {
      "caption": "Table 2: ) does not play a significant role in the analysis. The complexity of the signals at",
      "page": 14
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Financial time series analysis based on fractional and multiscale permutation entropy",
      "authors": [
        "J Li",
        "P Shang",
        "X Zhang"
      ],
      "year": "2019",
      "venue": "Commun. Nonlinear Sci. Numer. Simul",
      "doi": "10.1016/j.cnsns.2019.104880"
    },
    {
      "citation_id": "2",
      "title": "Bearing fault detection and recognition methodology based on weighted multiscale entropy approach",
      "authors": [
        "A Minhas",
        "P Kankar",
        "N Kumar",
        "S Singh"
      ],
      "year": "2021",
      "venue": "Mech. Syst. Signal Process",
      "doi": "10.1016/j.ymssp.2020.107073"
    },
    {
      "citation_id": "3",
      "title": "A new hybrid model for wind speed forecasting combining long short-term memory neural network, decomposition methods and grey wolf optimizer",
      "authors": [
        "A Altan",
        "S Karasu",
        "E Zio"
      ],
      "year": "2021",
      "venue": "Appl. Soft Comput",
      "doi": "10.1016/j.asoc.2020.106996"
    },
    {
      "citation_id": "4",
      "title": "Fusion information entropy method of rolling bearing fault diagnosis based on n-dimensional characteristic parameter distance",
      "authors": [
        "Y Ai",
        "J Guan",
        "C Fei",
        "J Tian",
        "F Zhang"
      ],
      "year": "2017",
      "venue": "Mech. Syst. Signal Process",
      "doi": "10.1016/j.ymssp.2016.11.019"
    },
    {
      "citation_id": "5",
      "title": "Improving Epileptic Seizure Prediction",
      "authors": [
        "J Ra",
        "T Li",
        "L Yan"
      ],
      "year": "2021",
      "venue": "Sensors (Switzerland)"
    },
    {
      "citation_id": "6",
      "title": "Entropy measures to study and model long term simultaneous evolution of children in Doose and Lennox -Gastaut syndromes",
      "authors": [
        "R Zavala-Yoe",
        "R Ramirez-Mendoza",
        "L Cordero"
      ],
      "year": "2016",
      "venue": "Entropy measures to study and model long term simultaneous evolution of children in Doose and Lennox -Gastaut syndromes",
      "doi": "10.1142/S0219635216500138"
    },
    {
      "citation_id": "7",
      "title": "A novel True Random Bit Generator design for image encryption",
      "authors": [
        "T Etem",
        "T Kaya"
      ],
      "year": "2020",
      "venue": "Phys. A Stat. Mech. its Appl",
      "doi": "10.1016/j.physa.2019.122750"
    },
    {
      "citation_id": "8",
      "title": "Fast Image Encryption Algorithm for Logistics-Sine-Cosine Mapping",
      "authors": [
        "P Wang",
        "Y Wang",
        "J Xiang",
        "X Xiao"
      ],
      "year": "2022",
      "venue": "Fast Image Encryption Algorithm for Logistics-Sine-Cosine Mapping"
    },
    {
      "citation_id": "9",
      "title": "Self-generated encryption model of acoustics",
      "authors": [
        "T Etem",
        "T Kaya"
      ],
      "year": "2020",
      "venue": "Appl. Acoust",
      "doi": "10.1016/j.apacoust.2020.107481"
    },
    {
      "citation_id": "10",
      "title": "Artificial Intelligence-Based Robust Hybrid Algorithm Design and Implementation for Real-Time Detection of Plant Diseases in Agricultural Environments",
      "authors": [
        "ƒ∞ Yaƒü",
        "A Altan"
      ],
      "year": "1732",
      "venue": "Biology",
      "doi": "10.3390/biology11121732"
    },
    {
      "citation_id": "11",
      "title": "The entropy algorithm and its variants in the fault diagnosis of rotating machinery: A review",
      "authors": [
        "Y Li",
        "X Wang",
        "Z Liu",
        "X Liang",
        "S Si"
      ],
      "year": "2018",
      "venue": "IEEE Access",
      "doi": "10.1109/ACCESS.2018.2873782"
    },
    {
      "citation_id": "12",
      "title": "Modeling the flow of information between financial time-series by an entropy-based approach",
      "authors": [
        "F Benedetto",
        "L Mastroeni",
        "P Vellucci"
      ],
      "year": "2021",
      "venue": "Ann. Oper. Res",
      "doi": "10.1007/s10479-019-03319-7"
    },
    {
      "citation_id": "13",
      "title": "A novel generalized entropy and its application in image thresholding",
      "authors": [
        "F Nie",
        "P Zhang",
        "J Li",
        "D Ding"
      ],
      "year": "2017",
      "venue": "Signal Processing",
      "doi": "10.1016/j.sigpro.2016.11.004"
    },
    {
      "citation_id": "14",
      "title": "Magnetospheric chaos and dynamical complexity response during storm time disturbance",
      "authors": [
        "Aaron Oludehinwa",
        "I Isaac Olusola",
        "O Segun Bolaji",
        "O Olayinka Odeyemi",
        "O Ndzi Njah"
      ],
      "year": "2021",
      "venue": "Nonlinear Process. Geophys",
      "doi": "10.5194/NPG-28-257-2021"
    },
    {
      "citation_id": "15",
      "title": "A method for estimating the entropy of time series using artificial neural networks",
      "authors": [
        "A Velichko",
        "H Heidari"
      ],
      "year": "2021",
      "venue": "Entropy",
      "doi": "10.3390/e23111432"
    },
    {
      "citation_id": "16",
      "title": "Permutation transition entropy: Measuring the dynamical complexity of financial time series",
      "authors": [
        "X Zhao",
        "M Ji",
        "N Zhang",
        "P Shang"
      ],
      "year": "2020",
      "venue": "Chaos, Solitons and Fractals",
      "doi": "10.1016/j.chaos.2020.109962"
    },
    {
      "citation_id": "17",
      "title": "Sensitivity of Entropy Method to Time Series Length in Hydrometric Network Design",
      "authors": [
        "J Keum",
        "P Coulibaly"
      ],
      "year": "2017",
      "venue": "J. Hydrol. Eng",
      "doi": "10.1061/(asce)he.1943-5584.0001508"
    },
    {
      "citation_id": "18",
      "title": "Estimation of a noise level using coarse-grained entropy of experimental time series of internal pressure in a combustion engine",
      "authors": [
        "G Litak",
        "R Taccani",
        "R Radu",
        "K Urbanowicz",
        "J Ho≈Çyst",
        "M Wendeker",
        "A Giadrossi"
      ],
      "year": "2005",
      "venue": "Chaos, Solitons & Fractals",
      "doi": "10.1016/j.chaos.2004.06.057"
    },
    {
      "citation_id": "19",
      "title": "Physiological time-series analysis using approximate entropy and sample entropy maturity in premature infants Physiological time-series analysis using approximate entropy and sample entropy",
      "authors": [
        "J Richman",
        "J Moorman"
      ],
      "year": "2000",
      "venue": "Am. J. Physiol. Hear. Circ. Physiol"
    },
    {
      "citation_id": "20",
      "title": "Fast computation of sample entropy and approximate entropy in biomedicine",
      "authors": [
        "Y Pan",
        "Y Wang",
        "S Liang",
        "K Lee"
      ],
      "year": "2011",
      "venue": "Comput. Methods Programs Biomed",
      "doi": "10.1016/j.cmpb.2010.12.003"
    },
    {
      "citation_id": "21",
      "title": "Research on Feature Extraction Method of Ship Radiated Noise with K-nearest Neighbor Mutual Information Variational Mode Decomposition",
      "authors": [
        "G Li",
        "F Liu",
        "H Yang"
      ],
      "year": "2022",
      "venue": "Neural Network Estimation Time Entropy and Self-organizi. Measurement"
    },
    {
      "citation_id": "22",
      "title": "Biomedical Signal Analysis Using Entropy Measures : A Case Study of Motor Imaginary BCI in End Users with Disability",
      "authors": [
        "H Heidari"
      ],
      "year": "2022",
      "venue": "Biomedical Signals Based Computer-Aided Diagnosis for Neurological Disorders"
    },
    {
      "citation_id": "23",
      "title": "Entropy Approximation by Machine Learning Regression: Application for Irregularity Evaluation of Images in Remote Sensing, Remote Sens",
      "authors": [
        "A Velichko",
        "M Belyaev",
        "M Wagner",
        "A Taravat"
      ],
      "year": "2022",
      "venue": "Entropy Approximation by Machine Learning Regression: Application for Irregularity Evaluation of Images in Remote Sensing, Remote Sens",
      "doi": "10.3390/rs14235983"
    },
    {
      "citation_id": "24",
      "title": "NNetEn2D: Two-Dimensional Neural Network Entropy in Remote Sensing Imagery and Geophysical Mapping",
      "authors": [
        "A Velichko",
        "M Wagner",
        "A Taravat",
        "B Hobbs",
        "A Ord"
      ],
      "year": "2022",
      "venue": "NNetEn2D: Two-Dimensional Neural Network Entropy in Remote Sensing Imagery and Geophysical Mapping"
    },
    {
      "citation_id": "25",
      "title": "Bifurcation and Entropy Analysis of a Chaotic Spike Oscillator Circuit Based on the S-Switch",
      "authors": [
        "P Boriskov",
        "A Velichko",
        "N Shilovsky",
        "M Belyaev"
      ],
      "year": "2022",
      "venue": "Bifurcation and Entropy Analysis of a Chaotic Spike Oscillator Circuit Based on the S-Switch",
      "doi": "10.3390/rs14092166"
    },
    {
      "citation_id": "26",
      "title": "Dynamical complexity response in Traveling Ionospheric Disturbances across Eastern Africa sector during geomagnetic storms using Neural Network Entropy",
      "authors": [
        "I Oludehinwa",
        "A Velichko",
        "B Ogunsua",
        "O Olusola",
        "O Odeyemi",
        "A Njah",
        "Ologun"
      ],
      "year": "2022",
      "venue": "Earth Sp. Sci. Open Arch",
      "doi": "10.1002/essoar.10510393.1"
    },
    {
      "citation_id": "27",
      "title": "Ordinal patterns-based methodologies for distinguishing chaos from noise in discrete time series",
      "authors": [
        "M Zanin",
        "F Olivares"
      ],
      "year": "2021",
      "venue": "Ordinal patterns-based methodologies for distinguishing chaos from noise in discrete time series"
    },
    {
      "citation_id": "28",
      "title": "Approximate entropy and sample entropy: A comprehensive tutorial",
      "authors": [
        "A Delgado-Bonal",
        "A Marshak"
      ],
      "year": "2019",
      "venue": "Entropy",
      "doi": "10.3390/e21060541"
    },
    {
      "citation_id": "29",
      "title": "Improved Permutation Entropy for Measuring Complexity of Time Series under Noisy Condition",
      "authors": [
        "Z Chen",
        "Y Li",
        "H Liang",
        "J Yu"
      ],
      "year": "2019",
      "venue": "Improved Permutation Entropy for Measuring Complexity of Time Series under Noisy Condition"
    },
    {
      "citation_id": "30",
      "title": "Fuzzy entropy spectrum analysis for biomedical signals de-noising",
      "authors": [
        "H Xie",
        "T Guo"
      ],
      "year": "2018",
      "venue": "IEEE EMBS Int. Conf. Biomed. Heal. Informatics, BHI 2018. 2018-Janua",
      "doi": "10.1109/BHI.2018.8333367"
    },
    {
      "citation_id": "31",
      "title": "Using cross-correlation with pattern recognition entropy to obtain reduced total ion current chromatograms from raw liquid chromatography-mass spectrometry data",
      "authors": [
        "S Chatterjee",
        "S Chapman",
        "B Lunt",
        "M Linford"
      ],
      "year": "2018",
      "venue": "Bull. Chem. Soc. Jpn",
      "doi": "10.1246/BCSJ.20180230"
    },
    {
      "citation_id": "32",
      "title": "Noise reduction algorithm with the soft thresholding based on the Shannon entropy and bone-conduction speech cross-correlation bands",
      "authors": [
        "S Na",
        "Q Wei",
        "K Seong",
        "J Cho",
        "M Kim"
      ],
      "year": "2018",
      "venue": "Technol. Heal. Care",
      "doi": "10.3233/THC-174615"
    },
    {
      "citation_id": "33",
      "title": "A novel method for multi-fault feature extraction of a gearbox under strong background noise",
      "authors": [
        "Z Wang",
        "J Wang",
        "Z Zhao",
        "R Wang"
      ],
      "year": "2018",
      "venue": "Entropy",
      "doi": "10.3390/e20010010"
    },
    {
      "citation_id": "34",
      "title": "Multivariate Multiscale Entropy Analysis",
      "authors": [
        "M Ahmed",
        "D Mandic"
      ],
      "year": "2012",
      "venue": "Multivariate Multiscale Entropy Analysis"
    },
    {
      "citation_id": "35",
      "title": "Fuzzy Entropy analysis of the electroencephalogram in patients with Alzheimer's disease: Is the method superior to Sample Entropy?",
      "authors": [
        "S Simons",
        "P Espino",
        "D Ab√°solo"
      ],
      "year": "2018",
      "venue": "Entropy",
      "doi": "10.3390/e20010021"
    },
    {
      "citation_id": "36",
      "title": "Quantifying complexity of financial short-term time series by composite multiscale entropy measure",
      "authors": [
        "H Niu",
        "J Wang"
      ],
      "year": "2015",
      "venue": "Commun. Nonlinear Sci. Numer. Simul",
      "doi": "10.1016/j.cnsns.2014.08.038"
    },
    {
      "citation_id": "37",
      "title": "Neural estimator of information for time-series data with dependency",
      "authors": [
        "S Molavipour",
        "H Ghourchian",
        "G Bassi",
        "M Skoglund"
      ],
      "year": "2021",
      "venue": "Entropy",
      "doi": "10.3390/e23060641"
    },
    {
      "citation_id": "38",
      "title": "Modified multiscale entropy for short-term time series analysis",
      "authors": [
        "S Wu",
        "De",
        "C Wu",
        "K Lee",
        "S Lin"
      ],
      "year": "2013",
      "venue": "Phys. A Stat. Mech. its Appl",
      "doi": "10.1016/j.physa.2013.07.075"
    },
    {
      "citation_id": "39",
      "title": "A Review on EEG Signals Based Emotion Recognition",
      "authors": [
        "M Soroush",
        "K Maghooli",
        "S Setarehdan",
        "A Nasrabadi"
      ],
      "year": "2017",
      "venue": "A Review on EEG Signals Based Emotion Recognition",
      "doi": "10.15171/icnj.2017.01"
    },
    {
      "citation_id": "40",
      "title": "Chaos , Solitons and Fractals A new fractal pattern feature generation function based emotion recognition method using EEG",
      "authors": [
        "T Tuncer",
        "S Dogan",
        "A Subasi"
      ],
      "year": "2021",
      "venue": "Chaos, Solitons and Fractals",
      "doi": "10.1016/j.chaos.2021.110671"
    },
    {
      "citation_id": "41",
      "title": "Automated Parkinson's Disease Detection and Affective Analysis from Emotional EEG Signals",
      "authors": [
        "R Parameshwara",
        "S Member",
        "S Narayana",
        "S Member",
        "M Murugappan",
        "S Member",
        "R Subramanian",
        "S Member"
      ],
      "venue": "Automated Parkinson's Disease Detection and Affective Analysis from Emotional EEG Signals",
      "doi": "10.48550/arXiv.2202.12936"
    },
    {
      "citation_id": "42",
      "title": "Tunable Q wavelet transform based emotion classification in Parkinson's disease using Electroencephalography",
      "authors": [
        "M Murugappan",
        "W Alshuaib",
        "A Bourisly",
        "S Khare",
        "S Sruthi",
        "V Bajaj"
      ],
      "year": "2020",
      "venue": "PLoS One",
      "doi": "10.1371/journal.pone.0242014"
    },
    {
      "citation_id": "43",
      "title": "Emotion Classification in Parkinson's D isease EEG using RQA and ELM. 2020 16th IEEE Int",
      "authors": [
        "M Murugappan",
        "W Alshuaib",
        "A Bourisly",
        "S Sruthi",
        "W Khairunizam",
        "B Shalini",
        "W Yean"
      ],
      "year": "2020",
      "venue": "Colloq. Signal Process. Its Appl",
      "doi": "10.1109/CSPA48992.2020.9068709"
    },
    {
      "citation_id": "44",
      "title": "Electronics Letters -2021 -Li -A feature-based on potential and differential entropy information for",
      "venue": "Electronics Letters -2021 -Li -A feature-based on potential and differential entropy information for"
    },
    {
      "citation_id": "45",
      "title": "Multi-channel EEG-based emotion recognition in the presence of noisy labels",
      "authors": [
        "C Li",
        "Y Hou",
        "R Song",
        "J Cheng",
        "Y Liu",
        "X Chen"
      ],
      "year": "2022",
      "venue": "Multi-channel EEG-based emotion recognition in the presence of noisy labels"
    },
    {
      "citation_id": "46",
      "title": "Emotion processing in disease: An EEG spectral power study",
      "authors": [
        "R Yuvaraj",
        "M Murugappan",
        "M Omar",
        "N Ibrahim",
        "K Sundaraj",
        "K Mohamad",
        "M Satiyan"
      ],
      "year": "2014",
      "venue": "Int. J. Neurosci",
      "doi": "10.3109/00207454.2013.860527"
    },
    {
      "citation_id": "47",
      "title": "The MNIST database of handwritten digit images for machine learning research",
      "authors": [
        "L Deng"
      ],
      "year": "2012",
      "venue": "IEEE Signal Process. Mag",
      "doi": "10.1109/MSP.2012.2211477"
    },
    {
      "citation_id": "48",
      "title": "MNIST-NET10: A heterogeneous deep networks fusion based on the degree of certainty to reach 0.1% error rate. ensembles overview and proposal",
      "authors": [
        "S Tabik",
        "R Alvear-Sandoval",
        "M Ruiz",
        "J Sancho-G√≥mez",
        "A Figueiras-Vidal",
        "F Herrera"
      ],
      "year": "2020",
      "venue": "Inf. Fusion",
      "doi": "10.1016/j.inffus.2020.04.002"
    },
    {
      "citation_id": "49",
      "title": "A Method for Estimating the Entropy of Time Series Using Artificial Neural Networks",
      "authors": [
        "A Velichko",
        "H Heidari"
      ],
      "year": "2021",
      "venue": "Entropy",
      "doi": "10.3390/e23111432"
    },
    {
      "citation_id": "50",
      "title": "Neural Network for Low-Memory IoT Devices and MNIST Image Recognition Using Kernels Based on Logistic Map",
      "authors": [
        "A Velichko"
      ],
      "year": "2020",
      "venue": "Electronics",
      "doi": "10.3390/electronics9091432"
    },
    {
      "citation_id": "51",
      "title": "Effects of randomness on chaos and order of coupled logistic maps",
      "authors": [
        "M Savi"
      ],
      "year": "2007",
      "venue": "Phys. Lett. Sect. A Gen. At. Solid State Phys",
      "doi": "10.1016/j.physleta.2006.11.095"
    },
    {
      "citation_id": "52",
      "title": "A New Measure to Characterize the Self-Similarity of Binary Time Series and its Application",
      "authors": [
        "S Lee",
        "C Park"
      ],
      "year": "2021",
      "venue": "IEEE Access",
      "doi": "10.1109/ACCESS.2021.3081400"
    },
    {
      "citation_id": "53",
      "title": "Predictability of Complex Dynamical Systems",
      "authors": [
        "J Kadtke",
        "M Kremliovsky"
      ],
      "year": "1996",
      "venue": "Predictability of Complex Dynamical Systems"
    },
    {
      "citation_id": "54",
      "title": "An improved LogNNet classifier for IoT applications",
      "authors": [
        "H Heidari",
        "A Velichko"
      ],
      "year": "2021",
      "venue": "J. Phys.: Conf. Ser",
      "doi": "10.1088/1742-6596/2094/3/032015"
    }
  ]
}