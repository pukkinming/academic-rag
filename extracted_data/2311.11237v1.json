{
  "paper_id": "2311.11237v1",
  "title": "Implementation Of Ai Deep Learning Algorithm For Multi-Modal Sentiment Analysis",
  "published": "2023-11-19T05:49:39Z",
  "authors": [
    "Jiazhen Wang"
  ],
  "keywords": [
    "Emotion analysis",
    "feature fusion emotion analysis model",
    "a short text",
    "dual objective perception unit",
    "attention mechanism"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "A multi-modal emotion recognition method was established by combining two-channel convolutional neural network with ring network. This method can extract emotional information effectively and improve learning efficiency. The words were vectorized with GloVe, and the word vector was input into the convolutional neural network. Combining attention mechanism and maximum pool converter BiSRU channel, the local deep emotion and pre-post sequential emotion semantics are obtained. Finally, multiple features are fused and input as the polarity of emotion, so as to achieve the emotion analysis of the target. Experiments show that the emotion analysis method based on feature fusion can effectively improve the recognition accuracy of emotion data set and reduce the learning time. The model has a certain generalization.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "I. Introduction",
      "text": "Text emotion analysis refers to the analysis and processing of words such as \"people's evaluation of goods, services, events and other entities\" to obtain the subjective emotion information to be displayed. The research contents include: classification of emotion information, extraction of emotion information, emotion analysis and so on. At present, the commonly used emotion recognition techniques mainly include SVM, conditional random field, information entropy, etc., and they are all based on word bags. For example, some scholars  [1]  applied support vector machines to the emotion recognition and classification of sentences. However, this method tends to be sparse and high-dimensional for largescale data. In recent years, domestic and foreign scholars  [2]  have successively launched new algorithms based on deep neural networks, opening up a new way for the research of the above problems. At present, many neural network methods are commonly used based on convolutional neural network (CNN), sequence basis (RNN) and tree structure (RAE). CNN, as used in reference  [3] , classifies the polarity of emotions. In literature  [4] , bidirectional sequence model (BLSTM) was used to study Chinese text classification. Because of its outstanding advantages in text feature extraction and sentiment analysis, it has attracted much attention from researchers in recent years. Literature  [5]  is a typical application example of recursive self-coding algorithm. This project intends to construct a multimodal emotion recognition method based on two pathways CNN and one bidirectional simple circuit cell (BiSRU). The method quantifies words using GloVe and captures keywords using CNN. Obtain the deep and meaningful emotional features contained in the text from a local perspective. Text context-dependent semantics are mined based on BiSRU's ability to analyze time series data. The overall temporal emotional features are extracted from the text to overcome the ability of CNN to process temporal data. This paper studies the automatic acquisition of word importance based on attention mechanism and combines it with the maximum pooling feature of BiSRU. Finally, the double-channel emotional features are integrated to fully mine the emotional information of the text and make the feature information more comprehensive.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Ii. Feature Fusion Emotion Analysis Model",
      "text": "Vectorization of small samples is intended. Convolutional neural network is used for deep learning of small samples as the input layer of LSTM. The error back propagation algorithm is used to train the model  [6] . Therefore, the feature fusion emotion analysis model can not only learn the local features of short microblog texts, but also learn the longdistance context history information.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "A. Text Vectorization",
      "text": "The neural network takes the text vector as input and converts the text data into a one-dimensional real number vector. At present, there are two kinds of vectorized representation of text: primary representation and divergent representation. one-hot representation means that each word is represented by a large vector whose dimension is the same as the size of the vocabulary, which is usually extremely rare, and that no two words are associated with each other  [7] . The distributed representation is represented in low-dimensional vectors, allowing related words to be semantically closer together, which is called \"embedding\". This article is subdivided into two representations: one hot and word embedding. 1 hot is to use a splitter to segment the word, and then perform one-hot encoding on the word to generate a \"one hot\" dictionary. Lexical embeddings use segmentation tools to segment words. word2vec is used to learn the vocabulary vector, and the dictionary of word embedding is eventually generated. Figure  1  shows the text Vectorization process algorithm (the picture is quoted in Vectorization Techniques in NLP [Guide]).",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "B. Emotion Recognition Method Of Convolutional Neural Network",
      "text": "Although CNN can extract some local features from text, it can't handle the long-term context correlation problem well. However, because short-term memory models can be learned over a long period of time, they can efficiently use a wide range of background knowledge  [8] . In this paper, a novel method based on convolutional memory network is proposed for emotion recognition of text. As shown in Figure  2 , the network layer of the feature fusion emotion analysis model includes convolution layer, pooling layer, timing layer and output layer (the picture is quoted in Accurate deep neural network inference using computational phase-change) memory).",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Fig. 2. Convolutional Memory Neural Network Model",
      "text": "The local character of text is extracted by convolutional network. In this algorithm, the original image is filtered first, and then the image is segmented by convolutional algorithm. In this paper, a convolution operation is proposed, which uses multiple convolution kernels of different sizes to construct new vectors. The row embedding algorithm is relearned to make it better use of the original data characteristics. Text is inserted before convolution, and then images are inserted  [9] . Convolutional neural algorithm can extract small samples with specific meaning from small samples. Therefore, a multi-layer convolutional network is proposed to realize emotion extraction. After sampling the sample layer, the corresponding local features can be obtained.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Iii. Semi-Supervised Text Emotion Analysis Of Fast Link Syntax",
      "text": "",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "A. Lexical Vector Represents Vocabulary",
      "text": "Compared with existing vocabulary package theory, Semi-Supervised RAE uses word vector to represent vocabulary, for example, \"college student\" is represented by (0, 1, 0, 0). \"Teacher\" is represented by  (",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Sr  ",
      "text": ", where Y is the size of the vocabulary. Then the vector for\n\nt  is a binary vector with a dimension of thesaurus size and a value of 0 or 1, all positions being 0 except the t index.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "B. Guided Loop Automatic Coding",
      "text": "Tree-based information is usually used to obtain the lowdimensional vector representation of the sentence, that is, supervised loop self-coding. Suppose   The calculation method of reconstructed nodes is\n\nWhere:",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "C. Automatic Coding Of Undirected Loops",
      "text": "The tree of a general sentence is generally unknown. This paper presents a self-coding algorithm based on tree automatic learning. The optimization objective function of the tree structure prediction process is\n\n() Ru  is the optimal tree structure model of sentence u .θ is the parameter set. Set () u  is the set of all possible tree structures of sentence u . v is one of these structures.\n\nd is a ternary structure with no terminal node in the calculation process. 12 [ , ]; ( )\n\nis the search function of this ternary structure. Since the degree of contribution of words to sentence meaning varies, each word should be weighted accordingly when calculating reconstruction errors.\n\n12 , nnis the number of words under the current child node 12 , zz. In order to avoid obtaining too few parent nodes in the process of iterating repeatedly to reduce reconstruction errors, which brings inconvenience to the following operations, formula (2) is standardized here:\n\nD. Semi-supervised loop automatic coding After obtaining the vector expression of the sentence, in order to estimate the emotional trend of the whole expression. Add a softmax (•) classifier to the network: max( )\n\nl is the current type of emotion. l  is the parameter matrix. If there is an T emotion, then T hR  , and ( | )\n\nThe optimization objective function of semi-supervised recursion self-coding on the data set is  , ,   )\n\n is the L-BFGS algorithm the optimal solution of the optimization objective function (11), where the gradient used is",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Iv. Experimental Results And Analysis",
      "text": "",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "A. Experimental Data Set",
      "text": "The paper used four groups of English public emotion samples. 1) MR Is a double-category table of emotions in English film reviews, including two dimensions of positive and negative emotions. 2) CR refers to a user's evaluation of different products, which is a data set of two categories of emotion, respectively negative and positive. 3) SST-2 divides the film into two categories, namely: training, confirmation and test, among which the emotional category has negative category and positive category. 4) Subj is a set of subjective evaluations with subjective evaluations and objective markers. Unsegmented training samples, test samples, magnetic resonance and CR samples of test samples are given in this paper. The test was carried out by cross-validation method. Table  1  shows information about the size of the data set.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "B. Comparison Experiment Settings",
      "text": "The different dimension of word vector has certain influence on the recognition result. This thesis firstly makes a comparative study on the vector scale of vocabulary. Word vectorization was performed using a 50-dimensional glove.6B.50D, a 100-dimensional glove.6B.100d, a 200dimensional glove.6B.200D and a 300-dimensional glove.6B.300d, respectively. The convolutional neural network model is tested using MR Data. In order to study the classification, the most suitable word vector dimension is obtained. The resulting effect is shown in Figure  4 . The results show that the prediction accuracy of the convolutional neural network algorithm is the highest when the word vector dimension is 300. The experiment was conducted on four different sets of emotion words. In order to verify the validity of the convolutional neural network model proposed in this paper, the proposed model is compared with some traditional neural network models.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "C. Experimental Study And Conclusion",
      "text": "Convolutional neural networks were compared with 5 different training modes. Experimental comparison results are shown in Table  2 . show that the convolutional neural network model proposed in this paper has better classification accuracy than the other five models on the four data sets, and the effectiveness of this method in text emotion recognition is verified by experiments.  By comparing the training time consumed by five different types of neural networks on different samples, and comparing their performance on SST-2. It can be seen from Table  3  that the computational speed of the qubit realized by the proposed method is only 340 milliseconds, which is much lower than that of the bilinear short-term memory algorithm. The experimental results show that this method can realize parallel processing of text and reduce the time required for learning. V. CONCLUSION A multimodal emotion detection method based on convolutional network and bidirectional single loop unit is proposed. Convolutional neural network is used to extract context-dependent semantics, and the attention is fused with the maximum pooled bidirectional simple loop to achieve the effective fusion of context-dependent semantic information. In order to obtain more rich emotional characteristics. This improves the performance of emotion recognition and speeds up the learning process. The effectiveness of the proposed method is proved by comparison with several classical neural networks.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Model Comparison Results",
      "text": "",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Model",
      "text": "",
      "page_start": 5,
      "page_end": 5
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: shows the text Vectorization process",
      "page": 1
    },
    {
      "caption": "Figure 1: Text vectorization process algorithm",
      "page": 2
    },
    {
      "caption": "Figure 2: Convolutional memory neural network model",
      "page": 2
    },
    {
      "caption": "Figure 3: is quoted in Deep Learning for High-Impedance",
      "page": 3
    },
    {
      "caption": "Figure 3: Supervised recursive self-coding structure",
      "page": 3
    },
    {
      "caption": "Figure 4: The results",
      "page": 4
    },
    {
      "caption": "Figure 4: Comparison of word vector dimensions",
      "page": 5
    }
  ],
  "tables": [
    {
      "caption": "Table 2: Experiments show that the convolutional",
      "data": [
        {
          "Model": "Kim CNN",
          "MR": "82.00",
          "CR": "84.94",
          "SST-2": "86.77",
          "Subj": "96.78"
        },
        {
          "Model": "BiLSTM",
          "MR": "81.66",
          "CR": "84.44",
          "SST-2": "86.09",
          "Subj": "97.25"
        },
        {
          "Model": "CNN-BiLSTM",
          "MR": "82.27",
          "CR": "85.18",
          "SST-2": "87.06",
          "Subj": "97.78"
        },
        {
          "Model": "CNN-BiSRU",
          "MR": "83.22",
          "CR": "85.59",
          "SST-2": "88.03",
          "Subj": "97.55"
        },
        {
          "Model": "CNN-BiLSTM-MA",
          "MR": "82.85",
          "CR": "86.43",
          "SST-2": "86.21",
          "Subj": "97.47"
        },
        {
          "Model": "Convolutional neural network",
          "MR": "85.08",
          "CR": "88.57",
          "SST-2": "89.81",
          "Subj": "98.09"
        }
      ],
      "page": 5
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Multi-modal pedestrian detection algorithm based on deep learning",
      "authors": [
        "Li Xiaoyan",
        "Fu Huitong",
        "Wang Niu Wentao",
        "Peng",
        "Wang Zhigang",
        "Weiming"
      ],
      "year": "2021",
      "venue": "Journal of Xi 'an Jiaotong University"
    },
    {
      "citation_id": "2",
      "title": "Weibo emotion analysis based on deep learning and attention mechanism",
      "authors": [
        "L Zhou Xiangzhen",
        "Shuai",
        "Dong Sui"
      ],
      "year": "2022",
      "venue": "Journal of Nanjing Normal University: Natural Science Edition"
    },
    {
      "citation_id": "3",
      "title": "Research on intelligent analysis and verification algorithm of medical data based on deep learning",
      "authors": [
        "Li Yang",
        "Guo Yuzhe",
        "Le"
      ],
      "year": "2022",
      "venue": "Electronic Design Engineering"
    },
    {
      "citation_id": "4",
      "title": "Speech enhancement deep learning algorithm based on joint loss function",
      "authors": [
        "Yang Lingling"
      ],
      "year": "2022",
      "venue": "Electronic Products World"
    },
    {
      "citation_id": "5",
      "title": "Research on image quality volume model of deep learning reconstruction algorithm",
      "authors": [
        "Liu Fangtao",
        "Chang Rui",
        "Cui Liu",
        "Shi"
      ],
      "year": "2022",
      "venue": "Theoretical and Applied Research of CT"
    },
    {
      "citation_id": "6",
      "title": "Vascular ultrasound image segmentation algorithm based on phase symmetry",
      "authors": [
        "Guan Shaoya",
        "Zhang Cheng",
        "Cai Meng"
      ],
      "year": "2022",
      "venue": "Journal of Beijing University of Aeronautics and Astronautics"
    },
    {
      "citation_id": "7",
      "title": "Real-time deep learning tracking algorithm based on NPU",
      "year": "2022",
      "venue": "Journal of Applied Optics"
    },
    {
      "citation_id": "8",
      "title": "Identity recognition algorithm based on deep learning and gait analysis",
      "authors": [
        "Wang Jinzhu"
      ],
      "year": "2021",
      "venue": "Electronic Design Engineering"
    },
    {
      "citation_id": "9",
      "title": "Multimodal emotion recognition based on speech and video images",
      "authors": [
        "Wang Chuan-Yu",
        "L Wei-Xiang",
        "Chen Zhen-Huan"
      ],
      "year": "2021",
      "venue": "Computer Engineering and Applications"
    }
  ]
}