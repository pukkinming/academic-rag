{
  "paper_id": "2212.02908v6",
  "title": "This Is The Accepted Manuscript Of The Journal Article, Published In Ieee Transactions On Affective Computing. The Citation Is 'Z. Li Et Al., \"Towards Human-Compatible Autonomous Car: A Study Of Non-Verbal Turing Test In Automated Driving With Affective Transition Modelling,\" In Ieee Transactions On Affective Computing",
  "published": "2022-12-06T12:06:34Z",
  "authors": [
    "Zhaoning Li",
    "Qiaoli Jiang",
    "Zhengming Wu",
    "Anqi Liu",
    "Haiyan Wu",
    "Miner Huang",
    "Kai Huang",
    "Yixuan Ku"
  ],
  "keywords": [
    "Affective transition",
    "Artificial social intelligence",
    "Autonomous cars (ACs)",
    "Differential Emotions Scale (DES-IV)",
    "Field theory",
    "Mentalising",
    "Non-verbal variation of the Turing test",
    "Pre-trained language models (PLMs)",
    "Signal detection theory (SDT)"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Autonomous cars are indispensable when humans go further down the hands-free route. Although existing literature highlights that the acceptance of the autonomous car will increase if it drives in a human-like manner, sparse research offers the naturalistic experience from a passenger's seat perspective to examine the humanness of current autonomous cars. The present study tested whether the AI driver could create a human-like ride experience for passengers based on 69 participants' feedback in a real-road scenario. We designed a ride experience-based version of the non-verbal Turing test for automated driving. Participants rode in autonomous cars (driven by either human or AI drivers) as a passenger and judged whether the driver was human or AI. The AI driver failed to pass our test because passengers detected the AI driver above chance. In contrast, when the human driver drove the car, the passengers' judgement was around chance. We further investigated how human passengers ascribe humanness in our test. Based on Lewin's field theory, we advanced a computational model combining signal detection theory with pre-trained language models to predict passengers' humanness rating behaviour. We employed affective transition between pre-study baseline emotions and corresponding post-stage emotions as the signal strength of our model. Results showed that the passengers' ascription of humanness would increase with the greater affective transition. Our study suggested an important role of affective transition in passengers' ascription of humanness, which might become a future direction for autonomous driving.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "B.",
      "text": "From top to bottom: manual driving mode (the human driver was actively steering); autonomous mode, in which the human driver would be free to release the steering wheel, meaning that the AI driver (i.e., WeRide ONE algorithm  [55] ) would take control of the car; the participants would ride in the rear seat taking the role of a passenger, and a thick black drape hid the driver cabin from the passenger's viewpoint. C. Sub-figure  (1)  is the satellite image of the test stages (yellow colour). The dark blue of the sub-figure  (2) (3) (4)  represents the first, second and third stages, respectively. Each participant would experience three stages in turn (randomly assigned to the manual driving mode or autonomous mode). The red arrow indicates the direction of travel. The 4-point star and 5-point star represent the start and end location of the AC, respectively. Furthermore, the traffic lights in all three stages have been marked. language models (PLMs)  [65] ,  [66] ,  [67]  (Section 2.2), as depicted in Fig.  2 . In this SDT-based model (Section 2.2.2), we used affective transition (AT, Section 2.2.3) between prestudy baseline emotions and corresponding post-stage emotions (collected using the modified Differential Emotions Scale and written description, Section 2.2.1), transformed by PLM (Section 2.2.4), as the signal strength.\n\nThe results showed that our proposed computational model could adequately predict passengers' humanness rating behaviour in the non-verbal variation of the Turing test (Section 3.2). Further analysis (Section 4) suggested that affective transition, serving as a hypothetical essential part (i.e., P ) of passengers' subjective ride experience in our model, may play a crucial role in their ascription of humanness. Specifically, we found that the passengers' ascription of humanness would increase with the greater AT (Section 4.1). Moreover, based on the analysis of AT, we also gave concrete suggestions for the AI driver to offer a human-like ride experience for the passenger (Section 4.2-3). Taking the results of behavioural experiments and computational modelling together, we conjecture that the lack of a certain level of mentalising ability in the current selfdriving algorithm may underlie its failure to pass our nonverbal variation of the Turing test. In this regard, our study calls for a spotlight on the importance of ensuring ACs (or artificial social intelligence, more broadly speaking) have at least some mentalising ability (Section 5).",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "Methods",
      "text": "",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "The Non-Verbal Variation Of The Turing Test",
      "text": "In this subsection, we will first brief on the information of participants and how we recruit them. Next, we give the details of the conducted non-verbal variation of the Turing test, as illustrated in Fig.  1 .",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Participants",
      "text": "We recruited 23 employees of WeRide (a Chinese hightech company aiming to develop the most advanced autonomous driving technology) and 46 tourists and passersby via on-site registration in the Guangzhou International Biological Island. The entire sample included 45 males and 24 females, aged 34.48 (SD = 10.44, range =  [21, 60] ) years on average. After welcoming, all participants received information about the aims of the experiment and provided informed consent. Participants each received a plush toy for participating in our study. The local ethics committee approved our research protocol (2020-0515-0140).",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Procedure",
      "text": "In the double-blind non-verbal variation of the Turing test, participants went by the SAE Level 4 AC (see Fig.  1A ), driven by either the human driver (manual driving mode) or the AI driver (autonomous mode). Due to legal restrictions, one engineer would place in the passenger's seat (the front one) to monitor the AC. Therefore, the participants  The car stopped more quickly at traffic lights.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Pre-Trained Language Models",
      "text": "",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Whitening And Dimensionality Reduction",
      "text": "",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Feature Extraction",
      "text": "",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Pre-Study Baseline Vector",
      "text": "",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Distance Measures",
      "text": "Global pooling\n\nFig.  2 : Schematic illustration of the computational modelling. The modelling process was underpinned by Lewin's field theory  [56] , which is expressed by a cartoon version of the formula: B = f (P, E) at the centre of the figure . A. From left to right: A participant was filling out pre-study self-reported scores of the modified DES-IV on his smartphone; the stage began; after the stage, the participant was completing the online questionnaire, including his humanness rating (i.e., the answer to a variation of a Turing test question, 'Do you think the driver was a real human or an AI algorithm?', 1 for 'AI driver'; 2 for 'Not sure'; 3 for 'Human driver'), post-stage modified DES-IV scores, the scores of safety and comfort, and written mixed feelings (optional). B. The high-level illustration of our model, with the framework of SDT as the backbone.\n\nThe signal strength (computed as affective transition, AT) and stimulus (human driver or AI driver) are the model's input, while the output is the participant's humanness rating behaviour. Notice that the two competing hypotheses (H 1 and H 2 ) about the possible relatedness between the participant's humanness rating and the magnitude of signal strength are all depicted. C. The further computation of AT, i.e., the computation of the distance between the pre-study baseline and post-stage vectors, in which vectors would be transformed by Optimus Prime (a fictional character created by the Transformers franchise), i.e., the transformation module. D. The internal transformation procedure when giving Optimus Prime a participant's post-stage rating scores and mixed feelings.\n\nwould ride in the rear seat, taking the role of a passenger, with a thick black drape hiding the driver cabin from the passenger's viewpoint (see Fig.  1B ). If the passenger cannot distinguish between the manual driving mode and autonomous mode, the non-verbal variation of the Turing test is passed. In turn, each participant would experience three stages assigned randomly to the manual driving mode or autonomous mode. There were three stages in a 3.4-km-long real road circuit 2 over the Guangzhou International Biological Island in Panyu District, Guangzhou, Guangdong Province, China. Starting from the Xingdao Ring Road North, the first stage (around 1.6 km) included six traffic lights and a left-hand turn towards the second stage on Luoxuan Avenue. After a straight ride of around 1.2 km with two traffic lights, a left-2. Although the road circuit is a real road, it is important to note that the environment may only partially capture the complexity and variability of real-life road situations. The car used in the experiment had a safety prompt, which is not typically present in daily real-world scenarios.\n\nhand turn to the third stage on the Xingdao Ring Road South was performed. Finally, the third stage is around 0.6 km, including a big left-hand curve and two traffic lights. The predetermined course ended at the beginning of the first stage (see Fig.  1C ). Self-reported emotions were assessed before the whole study as pre-study baseline emotions.\n\nIn contrast, humanness ratings, safety, comfort, post-stage emotions and mixed feelings were measured during the lag time (participants have 1-2 minutes to rest before the next stage) after each stage, and we will further introduce these data in Section 2.2.1.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "How Do Human Passengers Ascribe Humanness?",
      "text": "To understand passengers' ascription of humanness in the non-verbal variation of the Turing test, we advanced a computational model which specifies the detailed steps for generating passengers' humanness rating behaviour, as shown in Fig.  2 . At the centre of Fig.  2 , we portrayed Lewin's equation  [56] , B = f (P, E), for the highest-level illustration of our computational modelling method. In the following four parts, we will first introduce the details of the participant data collected in the non-verbal variation of the Turing test (see Fig.  2A ) and subsequently describe our model in detail from a top-down perspective (see Fig.  2B-D ).",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Participant Data: Self-Reported Scores, Humanness Ratings, And Mixed Feelings",
      "text": "We collected self-reported scores (including pre-study baseline emotions, post-stage emotions, safety and comfort), humanness ratings and mixed feelings from participants in the non-verbal variation of the Turing test (Fig.  2A ). Specifically, pre-study baseline emotions and post-stage emotions were collected using the modified DES-IV  [68] ,  [69]  (on Likert scales from 1-4) since it has been suggested that passengers' emotion plays a fundamental role in the social acceptance of ACs  [16] ,  [70] ,  [71] . The left side of Fig.  2D  shows an example in which a participant rated six emotions as follows: '较 强烈快乐' (Enjoyment 3/4), '较强烈兴趣' (Interest 3/4), '较 轻微惊奇' (Surprise 2/4), '一点也没有恐惧' (Fear 1/4), '一点 也没有紧张' (Tension 1/4), '较强烈满意' (Satisfaction 3/4).\n\nBesides, user acceptance also resides in the increase of their trust towards the AC  [72] . Therefore, in the light of passengers' safety and comfort could establish trust towards the AC  [73] ,  [74] ,  [75] , self-reported scores of safety and comfort were rated on an integer scale from 1 to 4, 1 meaning 'Not safe (comfortable) at all' and 4 meaning 'Very safe (comfortable)'. Besides, the humanness rating behaviour (B in Lewin's equation), i.e., the answer to a variation of a Turing test question, 'Do you think the driver was a real human or an AI algorithm?', was rated from 1-3, 1 for 'AI driver'; 2 for 'Not sure'; 3 for 'Human driver'. Notice that a three-option scale rather than a forced choice scale (with no middle option 'Not sure') was used because 1) humanness is more like a continuous rather than simple dichotomous variable; 2) using a three-option rating scale is a decent trade-off between an attempt to create an approximately continuous variable for the humanness (i.e., a rating scale with more options is better) and the convenience for passengers to ascribe humanness (i.e., a rating scale with fewer options is better).\n\nExcepting all the quantitative ratings, the qualitative assessments, i.e., participants' mixed feelings, were also collected, given that the information contained in natural language texts may be able to predict human behaviour  [76] . The lower-left corner of Fig.  2D  shows an example of one participant's mixed feelings about the past stage: '过红绿灯 时停车较急促。' (The car stopped more quickly at traffic lights). In total, we got 68, 68, and 65 participants' data for the first, second, and third stages, respectively.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Backbone: Signal Detection Theory",
      "text": "Signal detection theory (SDT)  [62] ,  [63] ,  [64]  is a general framework widely used by psychologists to describe decisions made under conditions of uncertainty. Here, we adopted the most common SDT framework, the equal variance SDT (EVSDT) model (which assumes that signal strength distributions are two Gaussian distributions with equal variances), as the backbone of our computational model, with the motivation to regard the perception system of the passenger as an information processing  [77] ,  [78]  system (Fig.  2B ). Thus, we could formulate passengers' ascription of humanness into detecting the signal from the noise, in which the stimulus (E in Lewin's equation) from the human driver represents the signal, and that from the AI driver represents the noise.\n\nTo better introduce this information processing process, we take the input signal strength SS k , stimulus E k and output humanness rating behaviour B k of the observation k as an example. We begin by calculating the point estimates of the EVSDT parameters. More specifically, using observations (excluding k) from passengers, we can compute hit rates H 1/2 , H 2/3 and false alarm rates F 1/2 and F 2/3 under two criteria by (here, we hypothesised that the signal strength from the human driver was greater than that from the AI driver, i.e., hypothesis 1 (H 1 ), as depicted on the left of Fig.  2B ):\n\nThen response criteria c 1 and c 2 can be given by:\n\nwhere Φ -1 is the inverse cumulative normal distribution function, which converts the hit rate or false alarm rate into a z score. Therefore, B k given SS k and E k is:\n\nNotice that in this example, B k equals the magnitude of SS k , i.e., M k , which means B and M are positively correlated. An alternative hypothesis, hypothesis 2 (H 2 ), is that the signal strength from the AI driver was greater than that from the human driver, i.e., B and M are negatively correlated, as shown on the right of Fig.  2B , and the above calculations can easily be adapted to H 2 .",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Signal Strength: Affective Transition",
      "text": "Further, to figure out how to represent the signal strength in SDT, we examined whether pre-study baseline emotions (including enjoyment, interest, surprise, fear, tension and satisfaction), post-stage emotions (same as baseline emotions) and safety and comfort scores are associated with passengers' humanness rating behaviour (i.e., B). None of these measures was consistently correlated with B across three road stages (Appendix Table  1 ). Moreover, we also found that the raw scores of the measures mentioned above were not significantly different between the human and AI driver conditions (Appendix Fig.  1 ), which ineluctably can not hold the role of signal strength to detect humanness across three stages.\n\nIf not the above pre-study nor post-stage measures affect the passenger's humanness rating behaviour, then perhaps a dynamic change in emotions, i.e., affective transition (AT) between pre-study baseline emotions and corresponding post-stage emotions, holds the key. We tested this possibility by using representational similarity analysis (RSA)  [79] . RSA is a widely used framework for analysing common representational mapping between computational models, brain activity and behavioural data  [79] ,  [80] ,  [81] , in which second-order isomorphism  [82]  (i.e., the match of dissimilarity matrices) is of the essence. By relating the representational geometry of affective transition to humanness rating behaviour, we found that intertrial variability in AT was significantly and consistently correlated with that in B across three road stages and two conditions (Fig.  3 ), indicating the potential of AT to play a role in passengers' ascription of humanness. Ergo, we employed AT, computed as the proximity between self-reported scores of pre-study and post-stage emotions, as the signal strength in SDT. That is to say, we leveraged passengers' AT to represent variable P for investigating the specific and concrete form of Lewin's equation  [  ) as follows:\n\nwhere z denotes z-score normalisation, and dist represents the distance measure, which could be absolute distance, one of the Anna Karenina distances  [83]  (including mean distance, minimum distance and the product of the absolute and minimum distance), reversed Anna Karenina distance  [83]  (i.e., maximum distance), Pearson distance, Euclidean distance, Mahalanobis distance, cosine distance, Manhattan distance, word mover's distance  [84]  or word rotator's distance  [85] . Notice that the selection of specific distance measures was performed under the crossvalidation procedure (Section 3.2).",
      "page_start": 7,
      "page_end": 8
    },
    {
      "section_name": "Transformation: Leveraging Pre-Trained Language Models",
      "text": "Another key point to remember is that we transformed passengers' rating scores of emotions into corresponding language descriptions (together with their written mixed feelings) and leveraged PLMs to obtain the high-dimensional text representation to compute affective transition (Fig.  2D ).\n\nThe intuition of transformation is two-fold: Firstly, recent evidence from cognitive neuroscience has shown that, in addition to sensory-derived, embodied knowledge representation, there is another language-derived, non-sensory knowledge representation for concepts with sensory referents in the human brain  [86] ,  [87] ,  [88] , and PLMs hold great promise for simulating this type of knowledge coding system  [89] ,  [90] ,  [91] ,  [92] . Therefore, we may better represent passengers' emotional experiences by utilising PLMs to simulate the language-derived coding system in their brains. Secondly, PLMs have achieved unprecedented success in many natural language processing (NLP) tasks  [93] ,  [94] ,  [95] ,  [96] . Incorporating the prior semantic knowledge in PLMs into our computational model might further boost the model performance. Thus, we could gain a better understanding of passengers' humanness rating behaviour from a data-driven perspective.\n\nIn this study, we tested 282 different PLMs, including 120 pre-trained word embeddings  [65] ,  [97]  and 162 transformer-based  [98]  PLMs (such as ELECTRA  [66]  and T5  [67] ), for encoding passenger's emotion scores and their written mixed feelings. Specifically, given the corresponding language descriptions L k of the observation k, we can use the following equations to describe the general feature extraction process of a multilayer transformer-based PLM:\n\nwhere H 0 k is the input representations constructed by summing the corresponding token embeddings (E token k ), segment embeddings (E seg k ), and position embeddings (E pos k ). Then, the hidden representations of L k at the α-th layer of the N -layer PLM can be calculated as:\n\nEmpirically, we compute the average of hidden representations H avg k ∈ R n×d from the first layer and last layer as the final extracted feature of L k  [99] ,  [100] , where n is the length of the L k and d is the size of the transformer layer 3 . Notice that we get the sentence-level representations via the above procedure. To get the document-level representations, we first need to get the sentence-level representations for six emotions and mixed feelings separately, and then conduct global average pooling over each matrix and stack these vectors vertically. Next, we conduct global pooling  [101]  over H avg k to get the vector representation v k ∈ R d :\n\nwhere pooling operations could be max-, mean-, minover-time operations or a combination of two or three of these operations. Finally, we further conduct whitening transformation and dimensionality reduction  [100]  to improve the representations obtained via the above procedure. Given a set of vector representations of N observations {v i } N i=1 , we can compute its mean vector µ and covariance matrix Σ as follows:\n\nThen we conduct SVD decomposition  [102]  over Σ to get the related orthogonal matrix U and diagonal matrix Λ.\n\n] and κ denotes the number 3. For pre-trained word embeddings, we can directly get the corresponding hidden representations H k for L k without the above procedure; nevertheless, we use the same symbol H avg k below for concise writing (d denotes the number of dimensions for word embeddings in this case) of columns that need to be kept in W ), the transformed vector v k can be given as:\n\nThe selection of different level representations, the specific pooling operations and the κ value were performed under the cross-validation procedure (Section 3.2).",
      "page_start": 7,
      "page_end": 8
    },
    {
      "section_name": "Results",
      "text": "",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Results Of The Non-Verbal Variation Of The Turing Test",
      "text": "To examine whether the AI driver passed our non-verbal variation of the Turing test, we ran one-sample Wilcoxon tests on the average humanness rating scores (normalised to the range [0, 1] for better illustration) across trials for each condition against the chance level of 0.5 (i.e., the expected value of random rating). As shown in Fig.  4 , when The above results indicated that, on average, passengers could detect and discriminate between human and AI drivers. Thus, the AI driver did not pass our nonverbal variation of the Turing test.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Results Of The Computational Models",
      "text": "We trained and evaluated the computational models under the nested leave-one-out cross-validation (nested-LOOCV) procedure  [103] . We compared our models with machine learning baselines 4 : MLR, the multi-class logistic regression classifier; KNN, the nearest neighbour classifier; SVC, the support vector machine; RF, the random forest classifier; XGBoost, the decision tree-based ensemble classifier that uses a gradient boosting framework; MLP, the multilayer perceptron classifier; and naive baselines: Random, which posits that the passenger's humanness rating behaviour is generated at random with equal probability; Probability, which posits that the passenger's humanness rating behaviour is drawn at random from the population of history ratings; Detective, which posits that the passenger could discern the difference between the human and AI drivers and thus make the correct guess all the time. Within our proposed SDT-AT framework, we tested the following models: Original, in which AT was derived directly from a distance between multidimensional scores of pre-study and post-stage emotions without transformation with PLM; PLM-wv, in which pre-trained word embeddings would transform passenger's emotion scores or mixed feelings; PLM-tf, in which transformer-based PLM would transform passenger's emotion scores or mixed feelings. For the above SDT-AT models, we computed AT based on different data components: positive affect (PA, including enjoyment, interest, surprise and satisfaction), negative affect (NA, including fear and tension), all affect (AA, including PA and NA), mixed feelings (MF) 5 or a combination between MF and other data components. For machine learning baselines, we tested different model inputs: AA, PA or NA of prestudy baselines, post-stage or a combination of the above two. We used Spearman's rank correlation score (rho) as the evaluation metric and selected hyperparameters with the highest rho score in the inner loop cross-validation of the nested-LOOCV.\n\nThe performance of different computational models is shown in Table  1   6 . Based on Lewin's equation, our proposed SDT-AT models provided superior within-(Table  1a c) and cross-stage performance (Table  1d ) than all other baselines, demonstrating the overall effectiveness of these models. Moreover, the declining performance of the Original model indicated the significance of transformation with PLM in computing AT. Specifically, PLM-tf (PA+MF) and PLM-tf (PA) outperformed all other models with rho scores of 0.4768 (p = 3.94 × 10 -5 ) and 0.4739 (p = 4.46 × 10 -5 ) on the first and second stages (Table  1a -b, see further analysis in Section 4.2), respectively. Furthermore, PLM-wv (MF) surpassed all the other competing models with rho scores of 0.5615 (p = 1.14 × 10 -6 ) and 0.5093 (p < 1.0 × 10 -13 ) on the third and all stages (Table 1c-d, see further analysis in Section 4.3), respectively.\n\nWe also conducted the model simulations to verify whether our proposed winning computational models could replicate the passenger's humanness rating be-4. Due to the high computational load, we trained and evaluated machine learning baselines under the nested cross-validation with ten folds in the outer loop and five folds in the inner loop.\n\n5. For the Original model, MF would be 1 if the passenger had written mixed feelings or 0 if the passenger did not have written mixed feelings at a given trial.\n\n6. For the convenience of the display, we only show the results of PLMs with the highest rho score from the outer loop cross-validation of nested-LOOCV. The blue and red colours denote stimuli, i.e., human and AI drivers, respectively. '1st' for the first stage; '2nd' for the second stage; '3rd' for the third stage. Both correlation scores are in Spearman rho rankorder units, and corresponding p-values were derived from one-tailed permutation tests (10,000 iterations).\n\nhaviour. Fig.  5  shows that our computational model accurately captured the passenger's humanness rating behaviour patterns in the non-verbal variation of the Turing test. Further, by using representational similarity analysis (RSA)  [79] , we directly compared the representational geometry of empirically observed humanness rating behaviour with those of model simulations. As shown in Fig.  6 , we found that representational dissimilarity matrices (RDMs) of model simulations were highly correlated with the RDM of empirically observed humanness rating behaviour (withinstage: rho = 0.6607, p = 0.0039; cross-stage: rho = 0.6577, p = 0.0049), suggesting that our computational model exhibited the same humanness rating behaviour pattern as passengers did. Altogether, these results permit us to use our computational models in further elucidating the implications that radiate from passengers' ascription of humanness in the non-verbal variation of the Turing test (see Section 4).",
      "page_start": 8,
      "page_end": 11
    },
    {
      "section_name": "Analysis",
      "text": "",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Analysis Of Relatedness Between The Humanness Rating And The Magnitude Of Affective Transition",
      "text": "In computational modelling, we incorporated two competing hypotheses (H 1 and H 2 , see Section 2.2.2 and Fig.  2B ) about the relatedness between humanness rating behaviour and the magnitude of affective transition into our proposed SDT-AT models, respectively. Then, we selected the winning model with the highest rho score in the outer loop crossvalidation of the nested-LOOCV, as reported in Table  1 . To reveal which hypothesis holds, we compared the passenger's humanness rating to the magnitude of AT derived from our winning models. Fig.  7 : Bar chart for the Spearman's rank correlation scores between the humanness rating (AI driver 1, Not sure 2, Human driver 3) and the magnitude of affective transition (low magnitude 1, medium magnitude 2, and high magnitude 3). Each trial's magnitude of affective transition was obtained using the nested-LOOCV procedure with the predictive model trained by the remaining N -1 samples, excluding one to-be-predicted sample. All the p-values were based on twotailed tests of significance. For the first and the second stage, N = 68; for the third stage, N = 65; for all stages, N = 201.\n\nIn favour of H 1 , we observed strong positive withinand cross-stage associations between the humanness rating and the magnitude of AT (first stage: rho = 0.4768, p = 3.94×10 -5 ; second stage: rho = 0.4739, p = 4.46×10 -5 ; third stage: rho = 0.5615, p = 1.14 × 10 -6 ; all stages: rho = 0.5093, p < 1.0 × 10 -13 , see Fig.  7 ), such that the ascription of humanness would increase with the greater affective transition. The above analysis suggested that AT, posited as a crucial part of passengers' ride experience in our model, may play an important role in their ascription of humanness.",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Analysis Of The Direction For At On The Starting Two Stages",
      "text": "Our proposed SDT-AT models in which AT was derived (or partly derived) from the positive affect (PA) dominated comparisons on the first and second stages (see Table  1a b). However, we did not know how the passenger's PA changed under two conditions during the starting two stages since AT is just a scalar quantity with no direction.\n\nIt might be the case that the passenger's PA would greatly or moderately increase or decrease under the human driver condition while moderately or slightly increase or decrease under the AI driver condition, given that the previous analysis (Section 4.1) showed that the signal strength (i.e., AT) from the human driver was greater than that from the AI driver. To investigate this further, we examined mean changes in PA (calculated as post-stage minus pre-study PA summary scores of enjoyment, interest, surprise and satisfaction) during the first and second stages, respectively. As presented in Table  2 , passengers showed significant or marginal significant increases in PA under the human driver condition (first stage: ∆M = 0.742, p = 0.046; second stage: ∆M = 0.500, p = 0.065), while passengers showed decreases in PA under the AI driver condition, though insignificantly (first stage: ∆M = -0.622, p = 0.218; second stage: ∆M = -0.375, p = 0.223). Our analysis indicates that enhancing positive affect may be the essence of the humanlike ride experience during the starting two stages. Because the greater the affective transition along with this enhancement, the higher the passenger's humanness rating will be.",
      "page_start": 11,
      "page_end": 12
    },
    {
      "section_name": "Word Cloud Analysis Of Mixed Feelings",
      "text": "Given our proposed SDT-AT models in which AT was obtained from the mixed feelings (MF) yielded the best performance on the third and all stages (see  follows: 'The car braked sharply or non-linearly.'; 'The car had a rough or bumpy start.' The above comparison vividly showed the difference in the passenger's subjective ride experience between the two conditions and illustrates details of what needs to be improved for current automated driving to offer a human-like ride experience for the passenger and thus increase the social acceptance of ACs.",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "Discussion",
      "text": "",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "Contributions And Implications",
      "text": "As autonomous cars are increasing on our roads, the human role gradually shifts from active drivers to passive passengers. Meanwhile, a growing body of literature  [22] ,  [23] ,  [24] ,  [25] ,  [26]  highlights that the acceptance of the AC will increase if it drives in a stereotypical human manner. Nevertheless, very little research has been devoted to investigating the humanness of the AC from the perspective of passive passengers. Herein, in the present study, for the first time, we examined whether the current SAE Level 4 AC, i.e., AC with the WeRide ONE  [55]  as its self-driving algorithm, could create a human-like ride experience for passengers in a real-road scenario and hence pass the nonverbal variation of the Turing test from the perspective of passive passengers.\n\nOur results showed that human passengers might be sensitive to the human-like ride experience, as indicated by the higher humanness rating in our non-verbal variation of the Turing test for the human driver condition relative to the AI driver condition. When the AI driver controlled the AC, results showed that passengers' humanness ratings were below the chance level, indicating that the WeRide ONE did not pass our variation of a non-verbal Turing test because human passengers could successfully detect the AI driver based on their subjective ride experience (Fig.  4 ). Nonetheless, we also noticed that the WeRide ONE could successfully trick human passengers in some trials, revealing the promising fact that some self-driving algorithms, like the WeRide ONE, are beginning to learn and imitate human behaviour in a convincing manner.\n\nAs the literature suggests  [104] , even the best technology, such as a vehicle that drives itself, is of little use if the user does not accept it. Consequently, given the key role that human likeness played in improving the passengers' acceptance towards ACs, we investigated further why passengers could discern the AI driver in most trials and not in others in our non-verbal variation of the Turing test. Specifically, on the basis of Lewin's field theory  [56] , we advanced a computational model combining signal detection theory (SDT) with pre-trained language models (PLMs) to predict passengers' humanness rating behaviour. We employed affective transition (AT), computed as the proximity between rating vectors of pre-study and post-stage emotions transformed by PLM, as the signal strength in our SDT models. The results showed that our SDT-AT models could adequately predict passengers' humanness rating behaviour in the nonverbal variation of the Turing test (Table  1 , Fig.  5  and Fig.  6 ), the implications of which are as follows.\n\nFirst, our proposed computational model is a concrete application of Lewin's field theory, in which we replaced the variables in Lewin's equation with the specific situational and personal characteristics of the passenger (e.g., B with the humanness rating behaviour, P with AT and E with the stimulus). The practical success of basing the computational modelling on Lewin's seemingly abstract and theoretical field theory speaks directly to his famous maxim that 'there is nothing as practical as a good theory'  [105] . Second, our proposed models not only achieved superior within-stage performance than all other baselines (Table  1a -c) but also showed superiority in cross-stage performance (Table  1d ). Together with the agreement between model simulations and empirical observations (Fig.  5  and Fig.  6 ), our results indicate that we may succeed in discovering the general law B = f (P, E) which is valid for the dynamic structure of the passenger's psychological field (i.e., (P, E)). Finally, these results also demonstrate the possibility and feasibility of using NLP techniques, such as PLMs, as adjuncts to the interaction between social cognition and artificial intelligence to guide theorising and the generation of conceptual insights  [106] ,  [107] .\n\nOverall, conducting affective computing in this novel way enable us to discover the latent relatedness between AT and the passenger's humanness rating behaviour. Importantly, we offer the first insights into what renders passengers' subjective ride experience truly human-like for future automated driving: the passengers' ascription of humanness would increase with the greater affective transition (Fig.  7 ). Our further analysis of AT provided more concrete suggestions for the self-driving algorithm to offer a human-like ride experience for the passenger, e.g., improving passengers' positive affect during the starting stage (Table  2 ) and ensuring smoother starting and braking (Fig.  8 ).\n\nMentalising is a holistic process of inferring about a target agent's beliefs, motivations (i.e., cognitive mentalising), emotions and feelings (i.e., affective mentalising  [108] ), which not only plays a pivotal role in human social interaction  [109] ,  [110]  but also is central to human-machine communication  [111] ,  [112] . We conjecture that the reason behind the phenomena we just described above (e.g., the relatively lower humanness rating and AT in the AI driver condition) is that the current self-driving algorithm may lack a certain level of mentalising ability (especially affective mentalising ability). For instance, without understanding the emotions and feelings of the passenger and how specific driving behaviour affect the passenger's emotions and feelings particularly (for a similar example of pedestrian-AC interaction, see  [113] ), the self-driving algorithm may not be able to provide passengers with a comfortable and pleasant ride experience as the human driver. More generally, as suggested by the literature  [114] , current AI is yet to fully embrace 'hot' cognition (refers to emotional and social cognition; in contrast to 'cold' cognition processes, i.e., nonemotional information processing  [115] ), and it is crucial that AI applications should include a mentalising system to help improve human-machine interaction. Ergo, we think it is very likely that imbuing future ACs with artificial mentalising ability will increase their human likeness and thus encourage automated driving to be integrated into human society. And the interdisciplinary collaboration incorporating psychology, neuroscience and computer science is the path we must take to develop such kind of artificial social intelligence with mentalising ability  [116] ,  [117] ,  [118] .",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Limitations And Future Work",
      "text": "One could argue that passengers' humanness rating behaviour might not emerge completely after but during the stage. In other words, passengers might make the humanness rating first (which later results in their affective transition) during the road stage before they report post-stage emotions. In response to this questioning of logical rationality, let us go back to the buttress of our computational modelling, i.e., Lewin's field theory. One principle of Lewin's field theory is contemporaneity, which means that the behaviour in a psychological field depends only upon the psychological field 'at that time'  [119] , i.e., B t = f (P t , E t ) 7 . Empirically, a 'field at a given time' does not refer to a moment without time extension, but to a certain time period  [119]  (quite similar to describing the velocity of a point with treating a moment as a certain time period in physics  [120] ). In our case, it is worth noting that the psychological past and psychological future within a road stage are simultaneous parts of the passenger's psychological field existing at a given time t. That is to say, to the size of the passenger's humanness rating behaviour, the whole road stage the passenger rode would be considered as the size of the passenger's psychological field (cf.  [119] ). It cannot be excluded the possibility that passengers' humanness rating 7. For the sake of brevity, we ignored the time subscript t in the previous description of Lewin's equation.\n\nbehaviour emerged during the road stage before passengers reported post-stage emotions if one is outside of Lewin's field theory, though the contemporaneity principle of field theory has already sufficed to address this concern. Future work should try to investigate this possibility with a more rigorous and sophisticated experimental design.\n\nThere are also several limitations that we should address in the present study. First, we conducted the non-verbal variation of the Turing test in a non-social context where no pedestrians were in the test stages. Thus, neither the AI nor the human driver in our experiment will face the so-called social or moral dilemma (e.g. trolley problem)  [121] ,  [122] ,  [123] ,  [124] . Given the far-reaching importance of AI ethical decision-making to its social acceptance  [125] , further research on this topic is necessary. Second, due to the capacity of people the event could hold, the number of participants in the current study was limited (68, 68 and 65 effective observations in the first stage, second stage and third stage, respectively). Third, we ignored the inherent differences of passengers, e.g., individual differences in their driving experiences and social cognition (large individual differences have been found in human mentalising ability and social behaviour  [126] ,  [127] ,  [128] ,  [129] ), all of which might affect the generalisation of our results. Hence, validation tests (with a larger sample size, conducted in real-life road situations without safety prompts and under different driving and environmental conditions) would be crucial in future work to test whether our findings will remain. Finally, we only used self-reported scores to measure the emotional experiences of passengers, which limits our adventure towards the neural underpinnings supporting passengers' ascription of humanness in our non-verbal variation of the Turing test. Future studies might uncover this by using physiological measurement (e.g., heart rate, eyemovement entropy, galvanic skin response  [130] ), mobile electroencephalography (EEG)  [131]  (or even combined with mouse-tracking  [132] ) or portable functional near-infrared spectroscopy  [133] ,  [134] .",
      "page_start": 13,
      "page_end": 13
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: They had to",
      "page": 3
    },
    {
      "caption": "Figure 1: The non-verbal variation of the Turing test for automated driving in detail. A. SAE Level 4 AC used in the test.",
      "page": 4
    },
    {
      "caption": "Figure 2: In this SDT-based model (Section 2.2.2),",
      "page": 4
    },
    {
      "caption": "Figure 2: Schematic illustration of the computational modelling. The modelling process was underpinned by Lewin’s field",
      "page": 5
    },
    {
      "caption": "Figure 1: B). If the passenger",
      "page": 5
    },
    {
      "caption": "Figure 1: C). Self-reported emotions were assessed",
      "page": 5
    },
    {
      "caption": "Figure 2: At the centre of Fig. 2, we portrayed",
      "page": 5
    },
    {
      "caption": "Figure 2: A) and subsequently describe our",
      "page": 6
    },
    {
      "caption": "Figure 2: A). Specifically,",
      "page": 6
    },
    {
      "caption": "Figure 2: D shows an exam-",
      "page": 6
    },
    {
      "caption": "Figure 2: D shows an example of one",
      "page": 6
    },
    {
      "caption": "Figure 2: B). Thus, we could formulate passengers’",
      "page": 6
    },
    {
      "caption": "Figure 2: B, and the above",
      "page": 6
    },
    {
      "caption": "Figure 3: Intertrial variability in affective transition (AT) was significantly and consistently correlated with intertrial variability",
      "page": 7
    },
    {
      "caption": "Figure 1: ), which ineluctably can",
      "page": 7
    },
    {
      "caption": "Figure 4: The normalised humanness rating scores, their mean",
      "page": 8
    },
    {
      "caption": "Figure 5: Comparisons of the proportion of humanness rating",
      "page": 10
    },
    {
      "caption": "Figure 6: Representational similarity between empirically ob-",
      "page": 10
    },
    {
      "caption": "Figure 5: shows that our computational model ac-",
      "page": 10
    },
    {
      "caption": "Figure 7: Bar chart for the Spearman’s rank correlation scores",
      "page": 11
    },
    {
      "caption": "Figure 7: ), such that the ascription of",
      "page": 11
    },
    {
      "caption": "Figure 8: , the word cloud highlights the salient MF",
      "page": 11
    },
    {
      "caption": "Figure 8: Word cloud displaying mixed feelings (MF) from all",
      "page": 12
    },
    {
      "caption": "Figure 5: and Fig. 6),",
      "page": 12
    },
    {
      "caption": "Figure 5: and Fig. 6), our results",
      "page": 12
    },
    {
      "caption": "Figure 1: The raw self-reported scores (including pre-study baseline emotions, post-stage emotions, safety and comfort) and",
      "page": 14
    }
  ],
  "tables": [
    {
      "caption": "Table 1: ). Moreover, we also tance, one of the Anna Karenina distances [83] (including",
      "data": [
        {
          "Column_1": ".4028",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": ""
        },
        {
          "Column_1": "****",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": ""
        },
        {
          "Column_1": "",
          "Column_2": "0.2",
          "Column_3": "592",
          "Column_4": "",
          "Column_5": "",
          "Column_6": ""
        },
        {
          "Column_1": "",
          "Column_2": "**",
          "Column_3": "**",
          "Column_4": "",
          "Column_5": "",
          "Column_6": ""
        },
        {
          "Column_1": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "0.108",
          "Column_5": "6",
          "Column_6": ""
        },
        {
          "Column_1": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "**",
          "Column_5": "",
          "Column_6": ""
        }
      ],
      "page": 7
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "pectedvalue\n1\n0.8\n0.6\n*\n0.5\n0.44\n0.4\n0.34\n0.2\n0\nFirst stage": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "ofr": "",
          "andomrati": "",
          "Column_7": "",
          "ng": "",
          ").Asshow": "",
          "Column_10": "",
          "Column_11": "",
          "nin": "",
          "Fig.4,when\nHuman driver\nAI driver\n****\n0.46\n0.33\nAll stages": "Human driver"
        },
        {
          "pectedvalue\n1\n0.8\n0.6\n*\n0.5\n0.44\n0.4\n0.34\n0.2\n0\nFirst stage": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "ofr": "",
          "andomrati": "",
          "Column_7": "",
          "ng": "",
          ").Asshow": "",
          "Column_10": "",
          "Column_11": "",
          "nin": "",
          "Fig.4,when\nHuman driver\nAI driver\n****\n0.46\n0.33\nAll stages": "AI driver"
        },
        {
          "pectedvalue\n1\n0.8\n0.6\n*\n0.5\n0.44\n0.4\n0.34\n0.2\n0\nFirst stage": "",
          "Column_2": "*",
          "Column_3": "",
          "Column_4": "",
          "ofr": "",
          "andomrati": "",
          "Column_7": "**",
          "ng": "",
          ").Asshow": "",
          "Column_10": "0.53 **",
          "Column_11": "",
          "nin": "",
          "Fig.4,when\nHuman driver\nAI driver\n****\n0.46\n0.33\nAll stages": "****"
        },
        {
          "pectedvalue\n1\n0.8\n0.6\n*\n0.5\n0.44\n0.4\n0.34\n0.2\n0\nFirst stage": "",
          "Column_2": "",
          "Column_3": "0.44",
          "Column_4": "",
          "ofr": "",
          "andomrati": "",
          "Column_7": "0.40",
          "ng": "",
          ").Asshow": "",
          "Column_10": "",
          "Column_11": "",
          "nin": "",
          "Fig.4,when\nHuman driver\nAI driver\n****\n0.46\n0.33\nAll stages": "0.46"
        },
        {
          "pectedvalue\n1\n0.8\n0.6\n*\n0.5\n0.44\n0.4\n0.34\n0.2\n0\nFirst stage": "",
          "Column_2": "0.34",
          "Column_3": "",
          "Column_4": "",
          "ofr": "",
          "andomrati": "0.35",
          "Column_7": "",
          "ng": "",
          ").Asshow": "0.28",
          "Column_10": "",
          "Column_11": "",
          "nin": "",
          "Fig.4,when\nHuman driver\nAI driver\n****\n0.46\n0.33\nAll stages": "0.33"
        },
        {
          "pectedvalue\n1\n0.8\n0.6\n*\n0.5\n0.44\n0.4\n0.34\n0.2\n0\nFirst stage": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "ofr": "",
          "andomrati": "Second stag",
          "Column_7": "",
          "ng": "e",
          ").Asshow": "Third stage",
          "Column_10": "",
          "Column_11": "",
          "nin": "",
          "Fig.4,when\nHuman driver\nAI driver\n****\n0.46\n0.33\nAll stages": ""
        }
      ],
      "page": 8
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "None": "0.0029\n-0.0060\n0.1491",
          "SDT-AT": "Original\nPLM-wv\nPLM-tf"
        }
      ],
      "page": 9
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "None": "0.0010\n-0.0017\n0.0394",
          "SDT-AT": "Original\nPLM-wv\nPLM-tf"
        }
      ],
      "page": 9
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "None": "0.0001\n-0.0021\n0.3168**",
          "SDT-AT": "Original\nPLM-wv\nPLM-tf"
        }
      ],
      "page": 9
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "None": "0.0013\n-0.0006\n0.1764**",
          "SDT-AT": "Original\nPLM-wv\nPLM-tf"
        }
      ],
      "page": 9
    },
    {
      "caption": "Table 1: 6. Based on Lewin’s equation, our pro- 3rd 3rd",
      "data": [
        {
          "Column_1": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "",
          "Column_10": "",
          "Column_11": "O",
          "Column_12": "bse\nSim\nge\ns r\net\ns (",
          "Column_13": ""
        },
        {
          "Column_1": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "",
          "Column_10": "ll s",
          "Column_11": "ta",
          "Column_12": "",
          "Column_13": ""
        },
        {
          "Column_1": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "A",
          "Column_10": "",
          "Column_11": "",
          "Column_12": "",
          "Column_13": ""
        },
        {
          "Column_1": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "man",
          "Column_10": "n",
          "Column_11": "es",
          "Column_12": "",
          "Column_13": ""
        },
        {
          "Column_1": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "stio\nula\ndri",
          "Column_10": "n\nti\nver",
          "Column_11": "b\non\n’.",
          "Column_12": "",
          "Column_13": ""
        },
        {
          "Column_1": "ordembeddings 1st 2nd 3rd 1st 2nd 3rd",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "",
          "Column_10": "",
          "Column_11": "",
          "Column_12": "",
          "Column_13": ""
        },
        {
          "Column_1": "sormixedfeel- 1st\nMwouldtrans- Human 2nd\nfeelings.Forthe driver Dissimilarity\n3rd\nsedondifferent\nding enjoyment, AI driver 1st 0 1\ne affect (NA, in- 2nd\ncluding PA and\n3rd\non between MF rho= 0.6607 rho= 0.6577\nrningbaselines, p=0.0039 Observed RDM p= 0.0049\nor NA of pre-\non of the above 1st 1st\ncore(rho)asthe 2nd 2nd\nmeters with the\n3rd 3rd\nalidation of the\n1st 1st\nional models is 2nd 2nd\nuation, our pro- 3rd 3rd\nithin-(Table1a- 1st 2nd 3rd 1st 2nd 3rd 1st 2nd 3rd 1st 2nd 3rd\nSimulated RDM Simulated RDM\n) than all other",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "",
          "Column_10": "",
          "Column_11": "",
          "Column_12": "",
          "Column_13": ""
        }
      ],
      "page": 10
    },
    {
      "caption": "Table 1: a-c) but also",
      "data": [
        {
          "Column_1": "式",
          "g mode\ndard.": ""
        },
        {
          "Column_1": "a\ned\nd\ned\ny.",
          "g mode\ndard.": ""
        }
      ],
      "page": 12
    },
    {
      "caption": "Table 1: a represent Spearman’s rank correlation",
      "data": [
        {
          "1st\n4\n3\n2": "",
          "Column_2": "st",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "",
          "Column_10": "",
          "Column_11": "",
          "Column_12": "",
          "Column_13": "",
          "Column_14": "",
          "Column_15": "",
          "Column_16": "",
          "Column_17": "",
          "Column_18": "",
          "Column_19": "",
          "Column_20": "",
          "Column_21": "",
          "Column_22": "",
          "Column_23": "",
          "Column_24": "",
          "Column_25": "",
          "Column_26": "",
          "Column_27": "",
          "Column_28": "",
          "Column_29": ""
        },
        {
          "1st\n4\n3\n2": "1\n2\n4",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "",
          "Column_10": "",
          "Column_11": "",
          "Column_12": "",
          "Column_13": "",
          "Column_14": "",
          "Column_15": "",
          "Column_16": "",
          "Column_17": "",
          "Column_18": "",
          "Column_19": "",
          "Column_20": "",
          "Column_21": "",
          "Column_22": "",
          "Column_23": "",
          "Column_24": "",
          "Column_25": "",
          "Column_26": "",
          "Column_27": "",
          "Column_28": "",
          "Column_29": ""
        },
        {
          "1st\n4\n3\n2": "",
          "Column_2": "nd",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "",
          "Column_10": "",
          "Column_11": "",
          "Column_12": "",
          "Column_13": "",
          "Column_14": "",
          "Column_15": "",
          "Column_16": "",
          "Column_17": "",
          "Column_18": "",
          "Column_19": "",
          "Column_20": "",
          "Column_21": "",
          "Column_22": "",
          "Column_23": "",
          "Column_24": "",
          "Column_25": "",
          "Column_26": "",
          "Column_27": "",
          "Column_28": "",
          "Column_29": ""
        },
        {
          "1st\n4\n3\n2": "3\n2\n1",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "",
          "Column_10": "",
          "Column_11": "",
          "Column_12": "",
          "Column_13": "",
          "Column_14": "",
          "Column_15": "",
          "Column_16": "",
          "Column_17": "",
          "Column_18": "",
          "Column_19": "",
          "Column_20": "",
          "Column_21": "",
          "Column_22": "",
          "Column_23": "",
          "Column_24": "",
          "Column_25": "",
          "Column_26": "",
          "Column_27": "",
          "Column_28": "",
          "Column_29": ""
        },
        {
          "1st\n4\n3\n2": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "",
          "Column_10": "",
          "Column_11": "",
          "Column_12": "",
          "Column_13": "",
          "Column_14": "",
          "Column_15": "",
          "Column_16": "",
          "Column_17": "",
          "Column_18": "",
          "Column_19": "",
          "Column_20": "",
          "Column_21": "",
          "Column_22": "",
          "Column_23": "",
          "Column_24": "",
          "Column_25": "p= 0.0",
          "Column_26": "4",
          "Column_27": "",
          "Column_28": "",
          "Column_29": ""
        },
        {
          "1st\n4\n3\n2": "3\n4",
          "Column_2": "rd",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "",
          "Column_10": "",
          "Column_11": "",
          "Column_12": "",
          "Column_13": "",
          "Column_14": "",
          "Column_15": "",
          "Column_16": "",
          "Column_17": "",
          "Column_18": "",
          "Column_19": "",
          "Column_20": "",
          "Column_21": "",
          "Column_22": "",
          "Column_23": "",
          "Column_24": "",
          "Column_25": "",
          "Column_26": "",
          "Column_27": "",
          "Column_28": "",
          "Column_29": ""
        },
        {
          "1st\n4\n3\n2": "3\n2\n1\nE",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "",
          "Column_10": "",
          "Column_11": "",
          "Column_12": "",
          "Column_13": "",
          "Column_14": "",
          "Column_15": "",
          "Column_16": "",
          "Column_17": "",
          "Column_18": "",
          "Column_19": "",
          "Column_20": "",
          "Column_21": "",
          "Column_22": "",
          "Column_23": "",
          "Column_24": "",
          "Column_25": "",
          "Column_26": "",
          "Column_27": "",
          "Column_28": "",
          "Column_29": ""
        },
        {
          "1st\n4\n3\n2": "",
          "Column_2": "njoyme",
          "Column_3": "nt",
          "Column_4": "Interest",
          "Column_5": "",
          "Column_6": "Surprise",
          "Column_7": "",
          "Column_8": "Fear",
          "Column_9": "",
          "Column_10": "Tension",
          "Column_11": "S",
          "Column_12": "atisfacti",
          "Column_13": "",
          "Column_14": "on",
          "Column_15": "Safety",
          "Column_16": "",
          "Column_17": "Comfort",
          "Column_18": "",
          "Column_19": "Enjoyme",
          "Column_20": "nt I",
          "Column_21": "nterest",
          "Column_22": "",
          "Column_23": "Surprise",
          "Column_24": "",
          "Column_25": "Fear",
          "Column_26": "",
          "Column_27": "Tension",
          "Column_28": "S",
          "Column_29": "atisfaction"
        },
        {
          "1st\n4\n3\n2": "",
          "Column_2": "Pre-study baseline",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "",
          "Column_10": "",
          "Column_11": "",
          "Column_12": "",
          "Column_13": "",
          "Column_14": "Human driver",
          "Column_15": "",
          "Column_16": "",
          "Column_17": "",
          "Column_18": "AI driver Post-stage",
          "Column_19": "",
          "Column_20": "",
          "Column_21": "",
          "Column_22": "",
          "Column_23": "",
          "Column_24": "",
          "Column_25": "",
          "Column_26": "",
          "Column_27": "",
          "Column_28": "",
          "Column_29": ""
        }
      ],
      "page": 14
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "The Positronic Man",
      "authors": [
        "I Asimov",
        "R Silverberg"
      ],
      "year": "1992",
      "venue": "The Positronic Man"
    },
    {
      "citation_id": "2",
      "title": "World Health Organization",
      "year": "2018",
      "venue": "Global status report on road safety 2018: Summary"
    },
    {
      "citation_id": "3",
      "title": "Automated Driving Systems 2.0: A Vision for Safety",
      "year": "2022",
      "venue": "13069a-ads2.0 090617 v9a tag.pdf"
    },
    {
      "citation_id": "4",
      "title": "Although autonomous cars are not yet manufactured, their acceptance already is",
      "authors": [
        "W Payre",
        "S Birrell",
        "A Parkes"
      ],
      "year": "2021",
      "venue": "Theor. Issues Ergonom. Sci"
    },
    {
      "citation_id": "5",
      "title": "Governing autonomous vehicles: emerging responses for safety, liability, privacy, cybersecurity, and industry risks",
      "authors": [
        "A Taeihagh",
        "H Lim"
      ],
      "year": "2019",
      "venue": "Transp. Rev"
    },
    {
      "citation_id": "6",
      "title": "Autonomous vehicles and public health",
      "authors": [
        "D Rojas-Rueda",
        "M Nieuwenhuijsen",
        "H Khreis",
        "H Frumkin"
      ],
      "year": "2020",
      "venue": "Annu. Rev. Public Health"
    },
    {
      "citation_id": "7",
      "title": "Algorithmic decision-making in AVs: Understanding ethical and technical concerns for smart cities",
      "authors": [
        "H Lim",
        "A Taeihagh"
      ],
      "year": "2019",
      "venue": "Sustainability"
    },
    {
      "citation_id": "8",
      "title": "Reinforcement learning and deep neural network for autonomous driving",
      "authors": [
        "S Mohammed",
        "A Bytyn",
        "G Ascheid",
        "G Dartmann"
      ],
      "year": "2019",
      "venue": "Big Data Analytics for Cyber-Physical Systems. Elsevier"
    },
    {
      "citation_id": "9",
      "title": "Public health, ethics, and autonomous vehicles",
      "authors": [
        "J Fleetwood"
      ],
      "year": "2017",
      "venue": "Amer. J. Public Health"
    },
    {
      "citation_id": "10",
      "title": "Autoware on board: Enabling autonomous vehicles with embedded systems",
      "authors": [
        "S Kato",
        "S Tokunaga",
        "Y Maruyama",
        "S Maeda",
        "M Hirabayashi",
        "Y Kitsukawa",
        "A Monrroy",
        "T Ando",
        "Y Fujii",
        "T Azumi"
      ],
      "year": "2018",
      "venue": "ACM/IEEE 9th Int. Conf. Cyber-Phys. Syst"
    },
    {
      "citation_id": "11",
      "title": "Towards heterogeneous computing platforms for autonomous driving",
      "authors": [
        "H Chishiro",
        "K Suito",
        "T Ito",
        "S Maeda",
        "T Azumi",
        "K Funaoka",
        "S Kato"
      ],
      "year": "2019",
      "venue": "IEEE Int. Conf. Embedded Softw. Syst"
    },
    {
      "citation_id": "12",
      "title": "Apollo: Open Source Autonomous Driving",
      "authors": [
        "Apollo Baidu",
        "Team"
      ],
      "year": "2022",
      "venue": "Apollo: Open Source Autonomous Driving"
    },
    {
      "citation_id": "13",
      "title": "First results in robot road-following",
      "authors": [
        "R Wallace",
        "A Stentz",
        "C Thorpe",
        "H Moravec",
        "W Whittaker",
        "T Kanade"
      ],
      "year": "1985",
      "venue": "Proc. 9th Int. Joint Conf"
    },
    {
      "citation_id": "14",
      "title": "Autonomous land vehicle project at CMU",
      "authors": [
        "T Kanade",
        "C Thorpe",
        "W Whittaker"
      ],
      "year": "1986",
      "venue": "Proc. 1986 ACM 14th Annu. Conf. Comput. Sci"
    },
    {
      "citation_id": "15",
      "title": "VITS-A vision system for autonomous land vehicle navigation",
      "authors": [
        "M Turk",
        "D Morgenthaler",
        "K Gremban",
        "M Marra"
      ],
      "year": "1988",
      "venue": "IEEE Trans. Pattern Anal. Mach. Intell"
    },
    {
      "citation_id": "16",
      "title": "Kill switch: The evolution of road rage in an increasingly AI car culture",
      "authors": [
        "J Carpenter"
      ],
      "year": "2020",
      "venue": "Living with Robots"
    },
    {
      "citation_id": "17",
      "title": "Deep reinforcement learning for human-like driving policies in collision avoidance tasks of self-driving cars",
      "authors": [
        "R Emuna",
        "A Borowsky",
        "A Biess"
      ],
      "year": "2020",
      "venue": "Deep reinforcement learning for human-like driving policies in collision avoidance tasks of self-driving cars",
      "arxiv": "arXiv:2006.04218"
    },
    {
      "citation_id": "18",
      "title": "Tesla deaths: Every Tesla accident resulting in death",
      "year": "2022",
      "venue": "Tesla deaths: Every Tesla accident resulting in death"
    },
    {
      "citation_id": "19",
      "title": "Challenges for automated vehicle driver training: A thematic analysis from manual and automated driving",
      "authors": [
        "S Merriman",
        "K Plant",
        "K Revell",
        "N Stanton"
      ],
      "year": "2021",
      "venue": "Transp. Res. Part F: Traffic Psychol. Behav"
    },
    {
      "citation_id": "20",
      "title": "What can we learn from Automated Vehicle collisions? A deductive thematic analysis of five Automated Vehicle collisions",
      "year": "2021",
      "venue": "Saf. Sci"
    },
    {
      "citation_id": "21",
      "title": "Calibration of trust in automated driving: A matter of initial level of trust and automated driving style?",
      "authors": [
        "J Manchon",
        "M Bueno",
        "J Navarro"
      ],
      "year": "2021",
      "venue": "Human Factors"
    },
    {
      "citation_id": "22",
      "title": "A framework for modeling human-like driving behaviors for autonomous vehicles in driving simulators",
      "authors": [
        "T Al-Shihabi",
        "R Mourant"
      ],
      "year": "2001",
      "venue": "Proc. 5th Int. Conf. Auton. Agents"
    },
    {
      "citation_id": "23",
      "title": "Toward more realistic driving behavior models for autonomous vehicles in driving simulators",
      "year": "2003",
      "venue": "Transp. Res. Rec"
    },
    {
      "citation_id": "24",
      "title": "Human-like motion planning model for driving in signalized intersections",
      "authors": [
        "Y Gu",
        "Y Hashimoto",
        "L.-T Hsu",
        "M Iryo-Asano",
        "S Kamijo"
      ],
      "year": "2017",
      "venue": "IATSS Res"
    },
    {
      "citation_id": "25",
      "title": "Exploring personalised autonomous vehicles to influence user trust",
      "authors": [
        "X Sun",
        "J Li",
        "P Tang",
        "S Zhou",
        "X Peng",
        "H Li",
        "Q Wang"
      ],
      "year": "2020",
      "venue": "Cogn. Comput"
    },
    {
      "citation_id": "26",
      "title": "Learning accurate, comfortable and human-like driving",
      "authors": [
        "S Hecker",
        "D Dai",
        "L Van Gool"
      ],
      "year": "2019",
      "venue": "Learning accurate, comfortable and human-like driving",
      "arxiv": "arXiv:1903.10995"
    },
    {
      "citation_id": "27",
      "title": "Optimisation-based identification of situation determined cost functions for the implementation of a human-like driving style in an autonomous car",
      "authors": [
        "S Kraus",
        "S Albrecht",
        "M Sobotka",
        "B Heißing",
        "M Ulbrich"
      ],
      "year": "2010",
      "venue": "Int. Symp. Adv. Vehicle Control"
    },
    {
      "citation_id": "28",
      "title": "Toward human-like behavior generation in urban environment based on markov decision process with hybrid potential maps",
      "authors": [
        "C Guo",
        "K Kidono",
        "R Terashima",
        "Y Kojima"
      ],
      "year": "2018",
      "venue": "2018 IEEE Intell. Vehicles Symp. (IV)"
    },
    {
      "citation_id": "29",
      "title": "Humancentered risk assessment of an automated vehicle using vehicular wireless communication",
      "authors": [
        "D Shin",
        "B Kim",
        "K Yi",
        "A Carvalho",
        "F Borrelli"
      ],
      "year": "2018",
      "venue": "IEEE Trans. Intell. Transp. Syst"
    },
    {
      "citation_id": "30",
      "title": "Learning from naturalistic driving data for human-like autonomous highway driving",
      "authors": [
        "D Xu",
        "Z Ding",
        "X He",
        "H Zhao",
        "M Moze",
        "F Aioun",
        "F Guillemard"
      ],
      "year": "2020",
      "venue": "IEEE Trans. Intell. Transp. Syst"
    },
    {
      "citation_id": "31",
      "title": "Human-like lane change decision model for autonomous vehicles that considers the risk perception of drivers in mixed traffic",
      "authors": [
        "C Wang",
        "Q Sun",
        "Z Li",
        "H Zhang"
      ],
      "year": "2020",
      "venue": "Sensors"
    },
    {
      "citation_id": "32",
      "title": "Human-like driving behaviour emerges from a risk-based driver model",
      "authors": [
        "S Kolekar",
        "J Winter",
        "D Abbink"
      ],
      "year": "2020",
      "venue": "Nature Commun"
    },
    {
      "citation_id": "33",
      "title": "Decision-making for automated vehicles at intersections adapting human-like behavior",
      "authors": [
        "P Beaucorps",
        "T Streubel",
        "A Verroust-Blondet",
        "F Nashashibi",
        "B Bradai",
        "P Resende"
      ],
      "year": "2017",
      "venue": "2017 IEEE Intell. Vehicles Symp. (IV)"
    },
    {
      "citation_id": "34",
      "title": "Human-like car-following model for autonomous vehicles considering the cut-in behavior of other vehicles in mixed traffic",
      "authors": [
        "R Fu",
        "Z Li",
        "Q Sun",
        "C Wang"
      ],
      "year": "2019",
      "venue": "Accident Anal. & Prevention"
    },
    {
      "citation_id": "35",
      "title": "Don't drive me my way: Subjective perception of autonomous braking trajectories for pedestrian crossings",
      "authors": [
        "C Lehsing",
        "K Bengler"
      ],
      "year": "2019",
      "venue": "Proc. 10th Int. Symp. Inf"
    },
    {
      "citation_id": "36",
      "title": "Hailing a driverless ride in a Waymo",
      "authors": [
        "E Niedermeyer"
      ],
      "year": "2022",
      "venue": "Hailing a driverless ride in a Waymo"
    },
    {
      "citation_id": "37",
      "title": "Driving style: How should an automated vehicle behave?",
      "authors": [
        "L Oliveira",
        "K Proctor",
        "C Burns",
        "S Birrell"
      ],
      "year": "2019",
      "venue": "Information"
    },
    {
      "citation_id": "38",
      "title": "Modeling and interpreting realworld human risk decision making with inverse reinforcement learning",
      "authors": [
        "Q Liu",
        "H Wu",
        "A Liu"
      ],
      "year": "2019",
      "venue": "Modeling and interpreting realworld human risk decision making with inverse reinforcement learning",
      "arxiv": "arXiv:1906.05803"
    },
    {
      "citation_id": "39",
      "title": "Three principles to determine the right-of-way for AVs: Safe interaction with humans",
      "authors": [
        "L Li",
        "C Zhao",
        "X Wang",
        "Z Li",
        "L Chen",
        "Y Lv",
        "N.-N Zheng",
        "F.-Y Wang"
      ],
      "year": "2021",
      "venue": "IEEE Trans. Intell. Transp. Syst"
    },
    {
      "citation_id": "40",
      "title": "Social behavior for autonomous vehicles",
      "authors": [
        "W Schwarting",
        "A Pierson",
        "J Alonso-Mora",
        "S Karaman",
        "D Rus"
      ],
      "year": "2019",
      "venue": "Proc. Nat. Acad. Sci"
    },
    {
      "citation_id": "41",
      "title": "Should my car drive as I do? What kind of driving style do drivers prefer for the design of automated driving functions",
      "authors": [
        "S Griesche",
        "E Nicolay",
        "D Assmann",
        "M Dotzauer",
        "D Käthner"
      ],
      "year": "2016",
      "venue": "Braunschweiger Symp"
    },
    {
      "citation_id": "42",
      "title": "Driving comfort, enjoyment and acceptance of automated driving-effects of drivers' age and driving style familiarity",
      "authors": [
        "F Hartwich",
        "M Beggiato",
        "J Krems"
      ],
      "year": "2018",
      "venue": "Ergonomics"
    },
    {
      "citation_id": "43",
      "title": "Turing in the driver's seat: Can people distinguish between automated and manually driven vehicles?",
      "authors": [
        "N Stanton",
        "A Eriksson",
        "V Banks",
        "P Hancock"
      ],
      "year": "2020",
      "venue": "Human Factors Ergonom. Manuf"
    },
    {
      "citation_id": "44",
      "title": "Using the driving behavior of an automated vehicle to communicate intentions-a wizard of oz study",
      "authors": [
        "T Fuest",
        "L Michalowski",
        "L Träris",
        "H Bellem",
        "K Bengler"
      ],
      "year": "2018",
      "venue": "2018 21st Int. Conf. Intell. Transp. Syst"
    },
    {
      "citation_id": "45",
      "title": "What driving style makes pedestrians think a passing vehicle is driving automatically?",
      "authors": [
        "P Bazilinskyy",
        "T Sakuma",
        "J De Winter"
      ],
      "year": "2021",
      "venue": "Appl. Ergonom"
    },
    {
      "citation_id": "46",
      "title": "Do you shift or not? Influence of trajectory behaviour on perceived safety during automated driving on rural roads",
      "authors": [
        "P Rossner",
        "A Bullinger"
      ],
      "year": "2019",
      "venue": "Int. Conf. Human-Comput. Interact"
    },
    {
      "citation_id": "47",
      "title": "Comfort or not? Automated driving style and user characteristics causing human discomfort in automated driving",
      "authors": [
        "A Dettmann",
        "F Hartwich",
        "P Roßner",
        "M Beggiato",
        "K Felbel",
        "J Krems",
        "A Bullinger"
      ],
      "year": "2021",
      "venue": "Int. J. Human-Comput. Interact"
    },
    {
      "citation_id": "48",
      "title": "Computing machinery and intelligence",
      "authors": [
        "A Turing"
      ],
      "year": "1950",
      "venue": "Mind"
    },
    {
      "citation_id": "49",
      "title": "Taxonomy and Definitions for Terms Related to Driving Automation Systems for On-Road Motor Vehicles",
      "year": "2022",
      "venue": "Taxonomy and Definitions for Terms Related to Driving Automation Systems for On-Road Motor Vehicles"
    },
    {
      "citation_id": "50",
      "title": "The status and future of the Turing test",
      "authors": [
        "J Moor"
      ],
      "year": "2001",
      "venue": "Minds and Mach"
    },
    {
      "citation_id": "51",
      "title": "A non-verbal Turing test: Differentiating mind from machine in gaze-based social interaction",
      "authors": [
        "U Pfeiffer",
        "B Timmermans",
        "G Bente",
        "K Vogeley",
        "L Schilbach"
      ],
      "year": "2011",
      "venue": "PloS One"
    },
    {
      "citation_id": "52",
      "title": "Human-like behavioral variability blurs the distinction between a human and a machine in a nonverbal Turing test",
      "authors": [
        "F Ciardo",
        "D Tommaso",
        "A Wykowska"
      ],
      "year": "2022",
      "venue": "Sci. Robot"
    },
    {
      "citation_id": "53",
      "title": "Do autonomous vehicles drive like humans? A Turing approach and an application to SAE automation Level 2 cars",
      "authors": [
        "E Cascetta",
        "A Cartenì",
        "L Di Francesco"
      ],
      "year": "2022",
      "venue": "Transp. Res. Part C: Emerg. Technol"
    },
    {
      "citation_id": "54",
      "title": "Human-like interactive behavior generation for autonomous vehicles: A Bayesian gametheoretic approach with Turing test",
      "authors": [
        "Y Zhang",
        "P Hang",
        "C Huang",
        "C Lv"
      ],
      "year": "2022",
      "venue": "Adv. Intell. Syst"
    },
    {
      "citation_id": "55",
      "title": "WeRide unveils WeRide Master Platform (WMP) as the key technology to mass production of Level 4 autonomous vehicles",
      "authors": [
        "Weride"
      ],
      "year": "2022",
      "venue": "WeRide unveils WeRide Master Platform (WMP) as the key technology to mass production of Level 4 autonomous vehicles"
    },
    {
      "citation_id": "56",
      "title": "Principles of Topological Psychology",
      "authors": [
        "K Lewin"
      ],
      "year": "1936",
      "venue": "Principles of Topological Psychology"
    },
    {
      "citation_id": "57",
      "title": "Kurt Lewin's Field Theory: A Review and Re-evaluation",
      "authors": [
        "B Burnes",
        "B Cooke"
      ],
      "year": "2013",
      "venue": "Int. J. Manage. Rev"
    },
    {
      "citation_id": "58",
      "title": "Field Theory in Social Science: Selected Theoretical Papers",
      "authors": [
        "K Lewin"
      ],
      "year": "1951",
      "venue": "Field Theory in Social Science: Selected Theoretical Papers"
    },
    {
      "citation_id": "59",
      "title": "The Sage Handbook of Methods in Social Psychology",
      "authors": [
        "C Sansone",
        "C Morf",
        "A Panter"
      ],
      "year": "2003",
      "venue": "The Sage Handbook of Methods in Social Psychology"
    },
    {
      "citation_id": "60",
      "title": "Cognitive Psychology. Cengage Learning",
      "authors": [
        "R Sternberg",
        "K Sternberg"
      ],
      "year": "2013",
      "venue": "Cognitive Psychology. Cengage Learning"
    },
    {
      "citation_id": "61",
      "title": "The Practical Theorist: The Life and Work of Kurt Lewin",
      "authors": [
        "A Marrow"
      ],
      "year": "1977",
      "venue": "The Practical Theorist: The Life and Work of Kurt Lewin"
    },
    {
      "citation_id": "62",
      "title": "A statistical theory of target detection by pulsed radar",
      "authors": [
        "J Marcum",
        "Rand Corp Santa Monica Ca"
      ],
      "year": "1947",
      "venue": "Tech. Rep"
    },
    {
      "citation_id": "63",
      "title": "A decision-making theory of visual detection",
      "authors": [
        "W Tanner",
        "J Swets"
      ],
      "year": "1954",
      "venue": "Psychol. Rev"
    },
    {
      "citation_id": "64",
      "title": "Signal Detection Theory and Psychophysics",
      "authors": [
        "D Green",
        "J Swets"
      ],
      "year": "1966",
      "venue": "Signal Detection Theory and Psychophysics"
    },
    {
      "citation_id": "65",
      "title": "Analogical reasoning on Chinese morphological and semantic relations",
      "authors": [
        "S Li",
        "Z Zhao",
        "R Hu",
        "W Li",
        "T Liu",
        "X Du"
      ],
      "year": "2018",
      "venue": "Proc. 56th Annu. Meeting Assoc. Comput. Linguistics"
    },
    {
      "citation_id": "66",
      "title": "ELECTRA: Pre-training text encoders as discriminators rather than generators",
      "authors": [
        "K Clark",
        "M.-T Luong",
        "Q Le",
        "C Manning"
      ],
      "year": "2020",
      "venue": "8th Int. Conf. Learn. Representations"
    },
    {
      "citation_id": "67",
      "title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
      "authors": [
        "C Raffel",
        "N Shazeer",
        "A Roberts",
        "K Lee",
        "S Narang",
        "M Matena",
        "Y Zhou",
        "W Li",
        "P Liu"
      ],
      "year": "2020",
      "venue": "J. Mach. Learn. Res"
    },
    {
      "citation_id": "68",
      "title": "Stability of emotion experiences and their relations to traits of personality",
      "authors": [
        "C Izard",
        "D Libero",
        "P Putnam",
        "O Haynes"
      ],
      "year": "1993",
      "venue": "J. Pers. Soc. Psychol"
    },
    {
      "citation_id": "69",
      "title": "Emotion regulation and depression of college students",
      "authors": [
        "M Huang",
        "D Guo"
      ],
      "year": "2001",
      "venue": "Chinese Mental Health J"
    },
    {
      "citation_id": "70",
      "title": "Automatic emotion recognition for the calibration of autonomous driving functions",
      "authors": [
        "J Sini",
        "A Marceddu",
        "M Violante"
      ],
      "year": "2020",
      "venue": "Electronics"
    },
    {
      "citation_id": "71",
      "title": "A novel approach to improve the social acceptance of autonomous driving vehicles by recognizing the emotions of passengers",
      "authors": [
        "A Marceddu",
        "J Sini",
        "M Violante",
        "B Montrucchio"
      ],
      "year": "2021",
      "venue": "13th Int. Conf. Mach. Vis."
    },
    {
      "citation_id": "72",
      "title": "Impact of ITS advances on the industry",
      "authors": [
        "G Dimitrakopoulos",
        "L Uden",
        "I Varlamis"
      ],
      "year": "2020",
      "venue": "The Future of Intelligent Transport Systems"
    },
    {
      "citation_id": "73",
      "title": "Societal and Individual Acceptance of Autonomous Driving",
      "authors": [
        "E Fraedrich",
        "B Lenz"
      ],
      "year": "2016",
      "venue": "Autonomous Driving"
    },
    {
      "citation_id": "74",
      "title": "What drives the acceptance of autonomous driving? An investigation of acceptance factors from an end-user's perspective",
      "authors": [
        "I Nastjuk",
        "B Herrenkind",
        "M Marrone",
        "A Brendel",
        "L Kolbe"
      ],
      "year": "2020",
      "venue": "Technol. Forecasting Soc. Change"
    },
    {
      "citation_id": "75",
      "title": "Public acceptance and perception of autonomous vehicles: a comprehensive review",
      "authors": [
        "K Othman"
      ],
      "year": "2021",
      "venue": "AI Ethics"
    },
    {
      "citation_id": "76",
      "title": "Massscale emotionality reveals human behaviour and marketplace success",
      "authors": [
        "M Rocklage",
        "D Rucker",
        "L Nordgren"
      ],
      "year": "2021",
      "venue": "Nature Human behav"
    },
    {
      "citation_id": "77",
      "title": "Perception and Communication",
      "authors": [
        "D Broadbent"
      ],
      "year": "1958",
      "venue": "Perception and Communication"
    },
    {
      "citation_id": "78",
      "title": "Information Processing",
      "authors": [
        "C Wickens",
        "C Carswell"
      ],
      "year": "2012",
      "venue": "Handbook of Human Factors and Ergonomics"
    },
    {
      "citation_id": "79",
      "title": "Representational similarity analysisconnecting the branches of systems neuroscience",
      "authors": [
        "N Kriegeskorte"
      ],
      "year": "2008",
      "venue": "Frontiers Syst. Neurosci"
    },
    {
      "citation_id": "80",
      "title": "A guide to representational similarity analysis for social neuroscience",
      "authors": [
        "H Popal",
        "Y Wang",
        "I Olson"
      ],
      "year": "2019",
      "venue": "Soc. Cogn. Affect. Neurosci"
    },
    {
      "citation_id": "81",
      "title": "NeuroRA: A python toolbox of representational analysis from multi-modal neural data",
      "authors": [
        "Z Lu",
        "Y Ku"
      ],
      "year": "2020",
      "venue": "Frontiers Neuroinf"
    },
    {
      "citation_id": "82",
      "title": "Second-order isomorphism of internal representations: Shapes of states",
      "authors": [
        "R Shepard",
        "S Chipman"
      ],
      "year": "1970",
      "venue": "Cogn. Psychol"
    },
    {
      "citation_id": "83",
      "title": "Idiosynchrony: From shared responses to individual differences during naturalistic neuroimaging",
      "authors": [
        "E Finn",
        "E Glerean",
        "A Khojandi",
        "D Nielson",
        "P Molfese",
        "D Handwerker",
        "P Bandettini"
      ],
      "year": "2020",
      "venue": "NeuroImage"
    },
    {
      "citation_id": "84",
      "title": "From word embeddings to document distances",
      "authors": [
        "M Kusner",
        "Y Sun",
        "N Kolkin",
        "K Weinberger"
      ],
      "year": "2015",
      "venue": "Proc. 32nd Int. Conf"
    },
    {
      "citation_id": "85",
      "title": "Word rotator's distance",
      "authors": [
        "S Yokoi",
        "R Takahashi",
        "R Akama",
        "J Suzuki",
        "K Inui"
      ],
      "year": "2020",
      "venue": "Proc. 2020 Conf. Empirical Methods Natural Lang. Process"
    },
    {
      "citation_id": "86",
      "title": "Neural representation of visual concepts in people born blind",
      "authors": [
        "E Striem-Amit",
        "X Wang",
        "Y Bi",
        "A Caramazza"
      ],
      "year": "2018",
      "venue": "Nature Commun"
    },
    {
      "citation_id": "87",
      "title": "Two forms of knowledge representations in the human brain",
      "authors": [
        "X Wang",
        "W Men",
        "J Gao",
        "A Caramazza",
        "Y Bi"
      ],
      "year": "2020",
      "venue": "Neuron"
    },
    {
      "citation_id": "88",
      "title": "Dual coding of knowledge in the human brain",
      "authors": [
        "Y Bi"
      ],
      "year": "2021",
      "venue": "Trends Cogn. Sci"
    },
    {
      "citation_id": "89",
      "title": "Combining computational controls with natural text reveals aspects of meaning composition",
      "authors": [
        "M Toneva",
        "T Mitchell",
        "L Wehbe"
      ],
      "year": "2022",
      "venue": "Nature Comput. Sci"
    },
    {
      "citation_id": "90",
      "title": "The neural architecture of language: Integrative modeling converges on predictive processing",
      "authors": [
        "M Schrimpf",
        "I Blank",
        "G Tuckute",
        "C Kauf",
        "E Hosseini",
        "N Kanwisher",
        "J Tenenbaum",
        "E Fedorenko"
      ],
      "year": "2021",
      "venue": "Proc. Nat. Acad. Sci"
    },
    {
      "citation_id": "91",
      "title": "Cortical processing of reference in language revealed by computational models",
      "authors": [
        "J Li",
        "S Wang",
        "W.-M Luh",
        "L Pylkkänen",
        "Y Yang",
        "J Hale"
      ],
      "year": "2021",
      "venue": "Cortical processing of reference in language revealed by computational models"
    },
    {
      "citation_id": "92",
      "title": "Shared computational principles for language processing in humans and deep language models",
      "authors": [
        "A Goldstein",
        "Z Zada",
        "E Buchnik",
        "M Schain",
        "A Price",
        "B Aubrey",
        "S Nastase",
        "A Feder",
        "D Emanuel",
        "A Cohen"
      ],
      "year": "2022",
      "venue": "Nature Neurosci"
    },
    {
      "citation_id": "93",
      "title": "Deep contextualized word representations",
      "authors": [
        "M Peters",
        "M Neumann",
        "M Iyyer",
        "M Gardner",
        "C Clark",
        "K Lee",
        "L Zettlemoyer"
      ],
      "year": "2018",
      "venue": "Proc. 2018 Conf. North Amer"
    },
    {
      "citation_id": "94",
      "title": "BERT: Pretraining of deep bidirectional transformers for language understanding",
      "authors": [
        "J Devlin",
        "M.-W Chang",
        "K Lee",
        "K Toutanova"
      ],
      "year": "2019",
      "venue": "Proc. 2019 Conf. North Amer. Chapter Assoc"
    },
    {
      "citation_id": "95",
      "title": "Language models are few-shot learners",
      "authors": [
        "T Brown",
        "B Mann",
        "N Ryder",
        "M Subbiah",
        "J Kaplan",
        "P Dhariwal",
        "A Neelakantan",
        "P Shyam",
        "G Sastry",
        "A Askell"
      ],
      "year": "2020",
      "venue": "Adv. Neural Inf. Process. Syst"
    },
    {
      "citation_id": "96",
      "title": "Pretrained models: Past, present and future",
      "authors": [
        "X Han",
        "Z Zhang",
        "N Ding",
        "Y Gu",
        "X Liu",
        "Y Huo",
        "J Qiu",
        "L Zhang",
        "W Han",
        "M Huang",
        "Q Jin",
        "Y Lan",
        "Y Liu",
        "Z Liu",
        "Z Lu",
        "X Qiu",
        "R Song",
        "J Tang",
        "J.-R Wen",
        "J Yuan",
        "W Zhao",
        "J Zhu"
      ],
      "year": "2021",
      "venue": "AI Open"
    },
    {
      "citation_id": "97",
      "title": "Directional skip-gram: Explicitly distinguishing left and right context for word embeddings",
      "authors": [
        "Y Song",
        "S Shi",
        "J Li",
        "H Zhang"
      ],
      "year": "2018",
      "venue": "Proc. 2018 Conf. North Amer"
    },
    {
      "citation_id": "98",
      "title": "Attention is all you need",
      "authors": [
        "A Vaswani",
        "N Shazeer",
        "N Parmar",
        "J Uszkoreit",
        "L Jones",
        "A Gomez",
        "Ł Kaiser",
        "I Polosukhin"
      ],
      "year": "2017",
      "venue": "Adv. Neural Inf. Process. Syst"
    },
    {
      "citation_id": "99",
      "title": "On the sentence embeddings from pre-trained language models",
      "authors": [
        "B Li",
        "H Zhou",
        "J He",
        "M Wang",
        "Y Yang",
        "L Li"
      ],
      "year": "2020",
      "venue": "Proc. 2020 Conf. Empirical Methods Natural Lang. Process"
    },
    {
      "citation_id": "100",
      "title": "Whitening sentence representations for better semantics and faster retrieval",
      "authors": [
        "J Su",
        "J Cao",
        "W Liu",
        "Y Ou"
      ],
      "year": "2021",
      "venue": "Whitening sentence representations for better semantics and faster retrieval",
      "arxiv": "arXiv:2103.15316"
    },
    {
      "citation_id": "101",
      "title": "Natural language processing (almost) from scratch",
      "authors": [
        "R Collobert",
        "J Weston",
        "L Bottou",
        "M Karlen",
        "K Kavukcuoglu",
        "P Kuksa"
      ],
      "year": "2011",
      "venue": "J. Mach. Learn. Res"
    },
    {
      "citation_id": "102",
      "title": "Singular Value Decomposition and Least Squares Solutions",
      "authors": [
        "G Golub",
        "C Reinsch"
      ],
      "year": "1971",
      "venue": "Linear Algebra"
    },
    {
      "citation_id": "103",
      "title": "Model Assessment and Selection",
      "authors": [
        "T Hastie",
        "J Friedman",
        "R Tibshirani"
      ],
      "year": "2001",
      "venue": "The Elements of Statistical Learning: Data Mining, Inference, and Prediction"
    },
    {
      "citation_id": "104",
      "title": "The mind in the machine: Anthropomorphism increases trust in an autonomous vehicle",
      "authors": [
        "A Waytz",
        "J Heafner",
        "N Epley"
      ],
      "year": "2014",
      "venue": "J. Exp. Soc. Psychol"
    },
    {
      "citation_id": "105",
      "title": "Psychology and the process of group living",
      "authors": [
        "K Lewin"
      ],
      "year": "1943",
      "venue": "J. Soc. Psychol"
    },
    {
      "citation_id": "106",
      "title": "From text to thought: How analyzing language can advance psychological science",
      "authors": [
        "J Jackson",
        "J Watts",
        "J.-M List",
        "C Puryear",
        "R Drabble",
        "K Lindquist"
      ],
      "year": "2022",
      "venue": "Perspectives Psychol. Sci"
    },
    {
      "citation_id": "107",
      "title": "The topological space of subjective experience",
      "authors": [
        "C Tallon-Baudry"
      ],
      "year": "2022",
      "venue": "Trends Cogn. Sci"
    },
    {
      "citation_id": "108",
      "title": "The role of the orbitofrontal cortex in affective theory of mind deficits in criminal offenders with psychopathic tendencies",
      "authors": [
        "S Shamay-Tsoory",
        "H Harari",
        "J Aharon-Peretz",
        "Y Levkovitz"
      ],
      "year": "2010",
      "venue": "Cortex"
    },
    {
      "citation_id": "109",
      "title": "Mentalizing during social InterAction: A four component model",
      "authors": [
        "H Wu",
        "X Liu",
        "C Hagan",
        "D Mobbs"
      ],
      "year": "2020",
      "venue": "Cortex"
    },
    {
      "citation_id": "110",
      "title": "Seven computations of the social brain",
      "authors": [
        "T Molapour",
        "C Hagan",
        "B Silston",
        "H Wu",
        "M Ramstead",
        "K Friston",
        "D Mobbs"
      ],
      "year": "2021",
      "venue": "Soc. Cogn. Affect. Neurosci"
    },
    {
      "citation_id": "111",
      "title": "Of like mind: The (mostly) similar mentalizing of robots and humans",
      "authors": [
        "J Banks"
      ],
      "year": "2021",
      "venue": "Technol., Mind, and Behav"
    },
    {
      "citation_id": "112",
      "title": "Dynamical driving interactions between human and mentalizingdesigned autonomous vehicle",
      "authors": [
        "Y Zhang",
        "S Zhang",
        "Z Liang",
        "H Li",
        "H Wu",
        "Q Liu"
      ],
      "year": "2022",
      "venue": "2022 IEEE Int. Conf. Develop. Learn"
    },
    {
      "citation_id": "113",
      "title": "Importance of instruction for pedestrian-automated driving vehicle interaction with an external human machine interface: Effects on pedestrians' situation awareness, trust, perceived risks and decision making",
      "authors": [
        "H Liu",
        "T Hirayama",
        "M Watanabe"
      ],
      "year": "2021",
      "venue": "2021 IEEE Intell. Vehicles Symp. (IV)"
    },
    {
      "citation_id": "114",
      "title": "Knowing me, knowing you: theory of mind in AI",
      "authors": [
        "F Cuzzolin",
        "A Morelli",
        "B Cirstea",
        "B Sahakian"
      ],
      "year": "2020",
      "venue": "Psychol. Med"
    },
    {
      "citation_id": "115",
      "title": "Theory of mind and preference learning at the interface of cognitive science, neuroscience, and AI: A review",
      "authors": [
        "C Langley",
        "B Cirstea",
        "F Cuzzolin",
        "B Sahakian"
      ],
      "year": "2022",
      "venue": "Frontiers Artif. Intell"
    },
    {
      "citation_id": "116",
      "title": "What can computational models learn from human selective attention? A review from an audiovisual unimodal and crossmodal perspective",
      "authors": [
        "D Fu",
        "C Weber",
        "G Yang",
        "M Kerzel",
        "W Nan",
        "P Barros",
        "H Wu",
        "X Liu",
        "S Wermter"
      ],
      "year": "2020",
      "venue": "Frontiers Integr. Neurosci"
    },
    {
      "citation_id": "117",
      "title": "Can AI detect pain and express pain empathy? A review from emotion recognition and a human-centered AI perspective",
      "authors": [
        "S Cao",
        "D Fu",
        "X Yang",
        "S Wermter",
        "X Liu",
        "H Wu"
      ],
      "year": "2021",
      "venue": "Can AI detect pain and express pain empathy? A review from emotion recognition and a human-centered AI perspective",
      "arxiv": "arXiv:2110.04249"
    },
    {
      "citation_id": "118",
      "title": "Supporting artificial social intelligence with theory of mind",
      "authors": [
        "J Williams",
        "S Fiore",
        "F Jentsch"
      ],
      "year": "2022",
      "venue": "Frontiers Artif. Intell"
    },
    {
      "citation_id": "119",
      "title": "Defining the 'field at a given time",
      "authors": [
        "K Lewin"
      ],
      "year": "1943",
      "venue": "Psychol. Rev"
    },
    {
      "citation_id": "120",
      "title": "Frustration and regression: An experiment with young children",
      "authors": [
        "R Barker",
        "T Dembo",
        "K Lewin"
      ],
      "year": "1941",
      "venue": "Univ. Iowa Stud.: Child Welfare"
    },
    {
      "citation_id": "121",
      "title": "The social dilemma of autonomous vehicles",
      "authors": [
        "J.-F Bonnefon",
        "A Shariff",
        "I Rahwan"
      ],
      "year": "2016",
      "venue": "Science"
    },
    {
      "citation_id": "122",
      "title": "Psychological roadblocks to the adoption of self-driving vehicles",
      "authors": [
        "A Shariff",
        "J.-F Bonnefon",
        "I Rahwan"
      ],
      "year": "2017",
      "venue": "Nature Human Behav"
    },
    {
      "citation_id": "123",
      "title": "The moral machine experiment",
      "authors": [
        "E Awad",
        "S Dsouza",
        "R Kim",
        "J Schulz",
        "J Henrich",
        "A Shariff",
        "J.-F Bonnefon",
        "I Rahwan"
      ],
      "year": "2018",
      "venue": "Nature"
    },
    {
      "citation_id": "124",
      "title": "Trust in autonomous cars: Exploring the role of shared moral values, reasoning, and emotion in safetycritical decisions",
      "authors": [
        "R Yokoi",
        "K Nakayachi"
      ],
      "year": "2021",
      "venue": "Human factors"
    },
    {
      "citation_id": "125",
      "title": "Is society ready for AI ethical decision making? Lessons from a study on autonomous cars",
      "authors": [
        "J Caro-Burnett",
        "S Kaneko"
      ],
      "year": "2022",
      "venue": "J. Behav. Exp. Econ"
    },
    {
      "citation_id": "126",
      "title": "Mentalizing during social interaction: The development and validation of the Interactive Mentalizing Questionnaire",
      "authors": [
        "H Wu",
        "B Fung",
        "D Mobbs"
      ],
      "year": "2021",
      "venue": "Frontiers Psychol"
    },
    {
      "citation_id": "127",
      "title": "Social conformity is associated with inter-trial electroencephalogram variability",
      "authors": [
        "H Zhang",
        "K Zhang",
        "Z Zhang",
        "M Zhao",
        "Q Liu",
        "W Luo",
        "H Wu"
      ],
      "year": "2023",
      "venue": "Ann. New York Acad. Sci"
    },
    {
      "citation_id": "128",
      "title": "Individual variation in the neurophysiological representation of negative emotions in virtual reality is shaped by sociability",
      "authors": [
        "R Wang",
        "R Yu",
        "Y Tian",
        "H Wu"
      ],
      "year": "2022",
      "venue": "NeuroImage"
    },
    {
      "citation_id": "129",
      "title": "Every individual makes a difference: A trinity derived from linking individual brain morphometry, connectivity and mentalising ability",
      "authors": [
        "Z Li",
        "Q Dong",
        "B Hu",
        "H Wu"
      ],
      "year": "2023",
      "venue": "Human Brain Mapping"
    },
    {
      "citation_id": "130",
      "title": "Keep calm and ride along: Passenger comfort and anxiety as physiological responses to autonomous driving styles",
      "authors": [
        "N Dillen",
        "M Ilievski",
        "E Law",
        "L Nacke",
        "K Czarnecki",
        "O Schneider"
      ],
      "year": "2020",
      "venue": "Proc. 2020 CHI Conf"
    },
    {
      "citation_id": "131",
      "title": "The urban brain: analysing outdoor physical activity with mobile EEG",
      "authors": [
        "P Aspinall",
        "P Mavros",
        "R Coyne",
        "J Roe"
      ],
      "year": "2015",
      "venue": "Brit. J. Sports Med"
    },
    {
      "citation_id": "132",
      "title": "A resource for assessing dynamic binary choices in the adult brain using EEG and mouse-tracking",
      "authors": [
        "K Chen",
        "R Wang",
        "J Huang",
        "F Gao",
        "Z Yuan",
        "Y Qi",
        "H Wu"
      ],
      "year": "2022",
      "venue": "Sci. Data"
    },
    {
      "citation_id": "133",
      "title": "A wearable multichannel fNIRS system for brain imaging in freely moving subjects",
      "authors": [
        "S Piper",
        "A Krueger",
        "S Koch",
        "J Mehnert",
        "C Habermehl",
        "J Steinbrink",
        "H Obrig",
        "C Schmitz"
      ],
      "year": "2014",
      "venue": "NeuroImage"
    },
    {
      "citation_id": "134",
      "title": "A portable fNIRS system with eight channels",
      "authors": [
        "J Si",
        "R Zhao",
        "Y Zhang",
        "N Zuo",
        "X Zhang",
        "T Jiang"
      ],
      "year": "2015",
      "venue": "Opt"
    }
  ]
}