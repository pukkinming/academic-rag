{
  "paper_id": "2109.11732v2",
  "title": "Holistic Semi-Supervised Approaches For Eeg Representation Learning",
  "published": "2021-09-24T03:58:13Z",
  "authors": [
    "Guangyi Zhang",
    "Ali Etemad"
  ],
  "keywords": [
    "Semi-supervised learning",
    "deep learning",
    "electroencephalography",
    "emotion recognition"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Recently, supervised methods, which often require substantial amounts of class labels, have achieved promising results for EEG representation learning. However, labeling EEG data is a challenging task. More recently, holistic semi-supervised learning approaches, which only require few output labels, have shown promising results in the field of computer vision. These methods, however, have not yet been adapted for EEG learning. In this paper, we adapt three state-of-the-art holistic semi-supervised approaches, namely MixMatch [1], Fix-Match [2], and AdaMatch [3], as well as five classical semisupervised methods for EEG learning. We perform rigorous experiments with all 8 methods on two public EEG-based emotion recognition datasets, namely SEED and SEED-IV. The experiments with different amounts of limited labeled samples show that the holistic approaches achieve strong results even when only 1 labeled sample is used per class. Further experiments show that in most cases, AdaMatch is the most effective method, followed by MixMatch and FixMatch.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Human emotions are highly informative non-verbal cues that can be widely used to enhance human-machine interaction. Many solutions have been proposed for affective computing  [4]  using Electroencephalography (EEG), as EEG is widely used for directly measuring brain activity with high spatiotemporal resolution. Recently, various deep learning models have achieved state-of-the-art performances in emotion recognition tasks due to the capability of learning highly discriminative information from multichannel EEG recordings  [5, 6] . However, as the significant majority of existing EEGbased deep emotion recognition solutions are 'supervised' methods  [6, 7, 8, 9, 10] , they rely on the annotated labels. Labeling EEG, on the other hand, is difficult, time-consuming, and costly. To obtain reliable labels, many EEG-based studies require various emotion annotation approaches, including pre-stimulation and post-experiment self-assessments, as well as multiple expert evaluations  [5, 6, 11] . Moreover, most existing fully supervised learning algorithms suffer from per-formance drop when only a few training samples are labeled. As a result, it is important to investigate how to develop effective solutions that can deal with limited labeled training samples.\n\nSemi-Supervised Learning (SSL) has been recognized as a powerful paradigm to address the problems of a scarcity of labeled training samples, achieving great success in the field of computer vision  [12] . For example, pseudo-labeling was proposed to encourage low-entropy predictions of unlabeled data  [13] . To do so, a model was first trained using limited labeled data. The model was then used to predict pseudolabels for the unlabeled data. Finally, the model was retrained using the entire data with true labels and pseudo labels combined  [13] . Consistency regularization, in conjunction with data augmentation, has lately become popular in SSL studies  [14, 15, 16] . Common regularization techniques including stochastic augmentation applied to input data and dropout applied throughout the network have been employed in recent SSL frameworks  [14] . For instance, the Π-model  [14]  trained the network (with dropout) on both the original and augmented inputs, and minimized the distance between their corresponding outputs, as an unsupervised loss. Meanwhile, a supervised cross-entropy loss was only computed for the labeled set. To improve the Π-model, 'temporal ensembling' and 'mean teacher' methods further relied on consistency regularization techniques for SSL  [14, 15] .\n\nIn addition to the classical SSL approaches mentioned above, several new holistic SSL methods  [1, 2, 3]  have been recently proposed and achieved state-of-the-art results (we discuss these in detail in the next Section). However, their use has been mostly limited to computer vision tasks, and have therefore not been explored in other domains such as brain-computer interfaces (BCI) or biological signal processing. Only in a recent paper  [17] , few of the classical SSL frameworks were used for BCI with EEG representation learning. In this paper, we adapt, implement, and where necessary, modify three state-of-the-art holistic SSL methods, MixMatch  [1] , FixMatch  [2] , and AdaMatch  [3] , in addition to the five classical SSL methods, Π-model  [14] ,temporal assembling  [14] , mean teacher  [15] , convolutional autoencoders  [18] , and pseudo labeling  [13] , for EEG representation learning. We then perform a comprehensive study, comparing these methods against one another when different amounts of labels are used per class. Our study shows that these methods can indeed be effectively used in the field of BCI for EEG learning, with the holistic methods, particularly AdaMatch and MixMatch, showing reasonable performances even when 1 label per class is used for training. An overview of the holistic SSL methods for EEG learning is shown in Figure  1 . Strong and weak augmentations are represented by A s and A w , respectively (discussed in Section 3.4). We also use the terms p m and θ to refer to the deep learning model and model parameters, respectively.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Holistic Self-Supervised Eeg Learning",
      "text": "",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Problem Setup",
      "text": "",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Holistic Ssl Approaches",
      "text": "MixMatch. To adapt MixMatch  [1]  for EEG learning, we first perform a data augmentation on labeled data to obtain A w (x l b ). We then apply two different data augmentations on the unlabeled data and calculate the model predictions:\n\nwhere q x b is the model prediction on augmented labeled inputs. q u1 b and q u2 b are the two model predictions on the same unlabeled input (x u b ) with different augmentations. In the second phase, we average the predictions over the augmented unlabeled data. We then minimize the entropy of the label distribution (a process known as sharpening), using:\n\nwhere p b is the average prediction as p b = (softmax(q u1 b ) + softmax(q u2 b ))/2. T is the 'temperature' to adjust the entropy of the label distribution. We choose T = 1 as suggested in  [1] .\n\nIn the third phase, we use MixUp  [19]  to combine the augmented labeled data along with the corresponding labels, with the augmented unlabeled data along with the sharpened predictions. This creates new mixed labeled and unlabeled sets, (x l b , ỹl b ) and (x u b , ỹu b )  [1] . The process is as follows:\n\nwhere , represents the concatenation operation of two or more sets. B represents Beta distribution with α = 0.75. p u b is the sharpened prediction based on sharpen(p b , T ). M is the concatenation of augmented labeled and unlabeled sets, M is the set of M after a random shuffle operation, and |.| is the size of the set.\n\nIn the last step, we train the model on mixed data. Our semi-supervised loss comprises of a supervised term\n\nwith cross-entropy loss (H), and an unsupervised term\n\nThe overall semi-supervised loss is then calculated as L = L s + wL u , where w is a warm-up function that is used to gradually increase the weight of the unsupervised term as the number of training epochs increases  [1] . FixMatch. FixMatch, proposed in  [2] , provides a simpler method for combining pseudo-labeling with consistency regularization. FixMatch employs cross-entropy between model predictions and pseudo-labels rather than calculating the squared difference as the unsupervised loss. The model prediction is computed using strongly augmented unlabeled data as p m (y | A s (x u b )). The pseudo-label is generated using weakly augmented unlabeled data as y u b = arg max(q u b ), where\n\nFollowing that, we utilize a pre-defined confidence threshold τ to guarantee that pseudo-labels are only used to update the loss when the model prediction is confident:\n\nHere, I is the binary mask and max(q u b ) represents the highest class probability in the prediction (q u b ). Next, we use the supervised term\n\nThe total loss is the sum of the supervised and unsupervised terms as L = L u + L s . No warm-up function is used since the weight of the unsupervised term will automatically rise as the model's confidence grows with each training epoch  [2] . AdaMatch. To adapt AdaMatch  [3] , which is an improved SSL method based on FixMatch, we first obtain the predictions for weakly augmented labeled and unlabeled data as q l b = p m (y | A w (x l b ); θ) and q u b , respectively, where q l b , q u b ∈ R B×k . Let's represent the class distribution of labeled data using the expected values of predictions for the weakly augmented labeled data, as E(q l b ) ∈ R k , and the estimated class distribution of unlabeled data using the expected values of predictions for the weakly augmented unlabeled data, as E(q u b ) ∈ R k , where E(.) is expectation operator. Accordingly, the estimated labels for unlabeled data are rectified by multiplying them with the ratio of class distributions of labeled data to the estimated class distribution of unlabeled data. This operation can be denoted as\n\nwhere qu b ∈ R B×k , and the L1 normalization operator ||.|| ensures that the class distribution sums up to 1.\n\nFollowing, the predefined threshold is multiplied by the mean value of the most confident prediction for the weakly augmented labeled data as τ • µ max(q l b ) ∈ R, which is referred to as the relative confidence threshold  [3] , where max(q l b ) ∈ R B . Consequently, the unsupervised loss is calculated as\n\nwhere ỹu b = arg max(q u b ), I ∈ {0, 1} B , max(q u b ) ∈ R B , and\n\nThe total loss is the weighted sum of the supervised term (L s in Eq. 10) and the unsupervised term (wL u ), where w is a warm-up function used in  [3] , as L = L s + wL u .",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Experimental Setup And Results",
      "text": "",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Datasets",
      "text": "SEED. The SEED dataset  [5]  contains EEG recorded using 62 electrodes at the sampling rate of 1000 Hz. In the experiments, 15 film clips with three emotions (neutral, positive, and negative) were selected as stimuli. The studies were completed by a total of 15 individuals, 8 females and 7 males. Each subject takes part in the experiment twice, with each experiment consisting of 15 recording sessions. SEED-IV. The SEED-IV dataset  [6]  contains 62-channel EEG recordings obtained with a sample frequency of 1000 Hz. 72 video snippets with four emotions (neutral, fear, sad, and happy) were used as stimuli. The experiments were carried out by 15 participants (8 females and 7 males). Each subject repeated the experiment three times, with different stimuli used each time. Each experiment has 24 recording sessions (6 sessions for each emotion).",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Pre-Processing And Feature Extraction",
      "text": "We follow the exact pre-processing steps described in  [5, 6]  as follows. We first down-sample the EEG to 200 Hz. Then, to reduce artefacts, band-pass filters with frequencies ranging from 0.3 -50 Hz and 1 -75 Hz were applied to recordings from the SEED and SEED-IV. Following pre-processing, EEG were split into continuous segments of the same length (1 second for SEED and 4 seconds for SEED-IV) with no overlap. Differential Entropy (DE) features were extracted from five bands (delta, theta, alpha, beta, and gamma) of each EEG segment. We assume EEG signals obey a Gaussian distribution N (µ, σ 2 ), and thus DE can be calculated as DE = 1  2 log 2πeσ 2 .",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Evaluation Protocols",
      "text": "We apply the same evaluation protocols that were used in the original dataset publications  [5, 6] . For SEED, we use the first 9 sessions for training and the remaining 6 sessions for testing. For SEED-IV, we use the first 16 sessions for training, and the rest 8 sessions for testing. We use the classification accuracy to measure the performance of the semi-supervised techniques for recognition of three emotions (neutral, positive, and negative) in SEED and four emotions (neutral, fear, sad, and happy) in SEED-IV.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Implementation Details",
      "text": "Data Augmentation. We use additive Gaussian noise to augment the EEG signals. We denote the augmented data as A(x) = x + N (µ, σ), where x ∼ [0, 1], N is a Gaussian distribution with µ = 0.5. The intensity level of data augmentation can be tuned by changing σ. We choose σ of 0.8 and 0.2 in additive Gaussian Noise to represent strong (A s ) and weak (A w ) augmentations, respectively. Backbone Network. As our backbone network, we use an efficient lightweight CNN architecture, consisting of two convolutional blocks and one classifier. Each block consists of a 1-D convolutional layer followed by a 1-D batch normalization layer and a LeakyReLU activation. The classifier contains two fully connected layers with a dropout rate of 0.5. Hyper-parameters. In all the experiments, we run 30 training epochs with a batch size of 8. We employ Adam optimizer  [20]  with the default learning rate of 0.001. Tuning Table  1 . The performance of holistic approaches in comparison to other semi-supervised methods on SEED and SEED-IV.  of the hyper-parameters has been done on the validation set D v (with no leakage with the test set). To set the pre-defined threshold (τ ) in FixMatch and AdaMatch, we perform a grid search in [0.0 -1.0] with a step size of 0.1. In FixMatch, we set τ = 0.9 for both datasets, while in AdaMatch, we set τ = 0.6 and τ = 0.5 for SEED and SEED-IV, respectively.\n\nOur experiments were carried out on two NVIDIA GeForce RTX 2080 Ti and six Tesla P100 GPUs using PyTorch  [21] .",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Classical Ssl Settings",
      "text": "For all the classical SSL baselines, we use the same convolutional module used as the backbone for the holistic methods (see Section 3.4). For the decoder component of the convolutional autoencoder, we use two transposed convolutional 1-D blocks. In each block, a 1-D transposed convolutional layer is followed by a 1-D batch normalization layer and a ReLU activation. We implement the Π-model, temporal ensembling, mean teacher, pseudo-labeling, and convolutional autoencoder with the same algorithm settings (e.g., loss function, unsupervised weight, etc.) as used in  [17] .",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Performance",
      "text": "We conduct experiments using all the SSL methods where a few training samples per class are labeled (m ∈ {1, 3, 5, 7, 10, 25}) , as done in  [1, 2, 3] . We repeat each experiment five times, each time using a different random seed for the selection of the subsets (D l , D u , and D v ). Table  1  displays the average and standard deviations of accuracies for SEED and SEED-IV datasets. Our results show that in the majority scenarios where very few labeled samples are used, the holistic SSL approaches not only achieve the best results (shown in bold), but also obtain the second-best performances (shown with underline). In SEED, AdaMatch achieves the best performance, while MixMatch achieves the second-best results. AdaMatch performs the best in SEED-IV when very few labeled samples are available (m ∈ {1, 3}), while MixMatch performs the best when more samples are labeled (m ∈ {5, 7, 10, 25}). AdaMatch and MixMatch consistently rank first and second in most scenarios for both datasets. Among the classical SSL methods, the Convolutional Autoencoder consistently achieves the best results for both datasets. We compare the performance of the holistic approaches to the supervised-only method, where the results are averaged across all six scenarios where few labeled samples are present. The supervised-only method employs the same backbone network (Section 3.4) but are only trained on the labeled samples. As shown in Figure  2 , AdaMatch achieves the best performance with 83.47 ± 10.07% for SEED, while MixMatch achieves the best result with 67.83 ± 15.92% for SEED-IV. AdaMatch and MixMatch outperform FixMatch in both datasets. In comparison, the supervised-only model achieves accuracies of 74.68 ± 11.32% and 60.15 ± 16.28% for SEED and SEED-IV, respectively.",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "Conclusion",
      "text": "In this research, we adapt and implement three state-of-the-art holistic semi-supervised learning approaches originally proposed for computer vision  [1, 2, 3] , for EEG representation learning. We conduct extensive experiments with the holistic SSL approaches and five additional well-known classical SSL methods, where only 1, 3, 5, 7, 10, and 25 samples per class are labeled. We evaluate all the SSL methods on two large publicly available datasets, namely SEED and SEED-IV. The holistic approaches achieve the best results and the secondbest results in the majority of scenarios for both datasets. The results also show that the holistic approaches remarkably outperform the supervised-only method, addressing the challenge of scarcity of labeled EEG data.",
      "page_start": 4,
      "page_end": 4
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: An overview of holistic SSL approaches for EEG rep-",
      "page": 2
    },
    {
      "caption": "Figure 1: 2. HOLISTIC SELF-SUPERVISED EEG LEARNING",
      "page": 2
    },
    {
      "caption": "Figure 2: Average performance of holistic SSL methods in com-",
      "page": 4
    },
    {
      "caption": "Figure 2: , AdaMatch achieves",
      "page": 4
    }
  ],
  "tables": [
    {
      "caption": "Table 1: displays lengeofscarcityoflabeledEEGdata.",
      "data": [
        {
          "1label 3labels 5labels 7labels 10labels 25labels": "60.25(9.57) 67.87(10.14) 72.43(11.32) 74.94(10.84) 76.35(10.93) 77.87(10.88)\n59.22(9.02) 69.95(9.07) 73.80(9.78) 77.15(9.57) 79.80(9.53) 83.83(8.73)\n53.97(8.24) 62.75(9.98) 66.42(9.46) 69.90(11.32) 71.48(8.98) 77.09(9.66)\n71.39(12.20) 80.03(11.69) 82.86(10.89) 84.74(9.70) 85.46(9.77) 87.34(8.96)\n68.02(13.20) 78.11(12.02) 79.57(10.78) 82.21(11.03) 84.11(9.79) 85.32(9.38)"
        },
        {
          "1label 3labels 5labels 7labels 10labels 25labels": "68.97(13.93) 80.89(12.80) 83.94(10.30) 85.46(9.64) 85.84(9.24) 86.88(8.78)\n66.36(13.84) 76.26(11.56) 79.04(10.68) 81.79(10.56) 83.14(9.98) 84.44(9.09)\n74.03(11.78) 82.59(10.26) 83.62(10.84) 85.84(9.69) 86.71(9.09) 88.02(8.80)"
        }
      ],
      "page": 4
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "",
      "authors": [
        "References"
      ],
      "venue": ""
    },
    {
      "citation_id": "2",
      "title": "Mixmatch: A holistic approach to semi-supervised learning",
      "authors": [
        "David Berthelot",
        "Nicholas Carlini",
        "Ian Goodfellow",
        "Nicolas Papernot",
        "Avital Oliver",
        "Colin Raffel"
      ],
      "year": "2019",
      "venue": "Advances in Neural Information Processing Systems (NeurIPS)"
    },
    {
      "citation_id": "3",
      "title": "Fixmatch: Simplifying semi-supervised learning with consistency and confidence",
      "authors": [
        "Kihyuk Sohn",
        "David Berthelot",
        "Nicholas Carlini",
        "Zizhao Zhang",
        "Han Zhang",
        "Colin Raffel",
        "Ekin Dogus Cubuk",
        "Alexey Kurakin",
        "Chun-Liang Li"
      ],
      "year": "2020",
      "venue": "Advances in Neural Information Processing Systems (NeurIPS)"
    },
    {
      "citation_id": "4",
      "title": "Adamatch: A unified approach to semi-supervised learning and domain adaptation",
      "authors": [
        "David Berthelot",
        "Rebecca Roelofs",
        "Kihyuk Sohn",
        "Nicholas Carlini",
        "Alex Kurakin"
      ],
      "year": "2021",
      "venue": "Adamatch: A unified approach to semi-supervised learning and domain adaptation",
      "arxiv": "arXiv:2106.04732"
    },
    {
      "citation_id": "5",
      "title": "Affective Computing",
      "authors": [
        "Rosalind Picard"
      ],
      "year": "2000",
      "venue": "Affective Computing"
    },
    {
      "citation_id": "6",
      "title": "Investigating critical frequency bands and channels for eeg-based emotion recognition with deep neural networks",
      "authors": [
        "Wei-Long Zheng",
        "Bao-Liang Lu"
      ],
      "year": "2015",
      "venue": "IEEE Transactions on Autonomous Mental Development"
    },
    {
      "citation_id": "7",
      "title": "Emotionmeter: A multimodal framework for recognizing human emotions",
      "authors": [
        "Wei-Long Zheng",
        "Wei Liu",
        "Yifei Lu",
        "Bao-Liang Lu",
        "Andrzej Cichocki"
      ],
      "year": "2018",
      "venue": "IEEE Transactions on Cybernetics"
    },
    {
      "citation_id": "8",
      "title": "Capsule attention for multimodal eeg-eog representation learning with application to driver vigilance estimation",
      "authors": [
        "Guangyi Zhang",
        "Ali Etemad"
      ],
      "year": "2021",
      "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering"
    },
    {
      "citation_id": "9",
      "title": "Rfnet: Riemannian fusion network for eeg-based brain-computer interfaces",
      "authors": [
        "Guangyi Zhang",
        "Ali Etemad"
      ],
      "year": "2020",
      "venue": "Rfnet: Riemannian fusion network for eeg-based brain-computer interfaces",
      "arxiv": "arXiv:2008.08633"
    },
    {
      "citation_id": "10",
      "title": "Identifying stable patterns over time for emotion recognition from eeg",
      "authors": [
        "Wei-Long Zheng",
        "Jia-Yi Zhu",
        "Bao-Liang Lu"
      ],
      "year": "2017",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "11",
      "title": "Spatial-temporal recurrent neural network for emotion recognition",
      "authors": [
        "Tong Zhang",
        "Wenming Zheng",
        "Zhen Cui",
        "Yuan Zong",
        "Yang Li"
      ],
      "year": "2018",
      "venue": "IEEE Transactions on Cybernetics"
    },
    {
      "citation_id": "12",
      "title": "Amigos: A dataset for affect, personality and mood research on individuals and groups",
      "authors": [
        "Juan Abdon",
        "Miranda Correa",
        "Mojtaba Khomami Abadi",
        "Niculae Sebe",
        "Ioannis Patras"
      ],
      "year": "2018",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "13",
      "title": "A survey on semi-supervised learning",
      "authors": [
        "E Jesper",
        "Van Engelen",
        "H Holger",
        "Hoos"
      ],
      "year": "2020",
      "venue": "Machine Learning"
    },
    {
      "citation_id": "14",
      "title": "Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks",
      "authors": [
        "Dong-Hyun Lee"
      ],
      "year": "2013",
      "venue": "Workshop on challenges in representation learning, ICML"
    },
    {
      "citation_id": "15",
      "title": "Temporal ensembling for semi-supervised learning",
      "authors": [
        "Laine Samuli",
        "Aila Timo"
      ],
      "year": "2017",
      "venue": "International Conference on Learning Representations (ICLR)"
    },
    {
      "citation_id": "16",
      "title": "Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results",
      "authors": [
        "Antti Tarvainen",
        "Harri Valpola"
      ],
      "year": "2017",
      "venue": "Advances in Neural Information Processing Systems (NeurIPS)"
    },
    {
      "citation_id": "17",
      "title": "Realistic evaluation of deep semi-supervised learning algorithms",
      "authors": [
        "Avital Oliver",
        "Augustus Odena",
        "Colin Raffel",
        "Ekin Dogus Cubuk",
        "Ian Goodfellow"
      ],
      "year": "2018",
      "venue": "Advances in Neural Information Processing Systems (NeurIPS)"
    },
    {
      "citation_id": "18",
      "title": "Deep recurrent semi-supervised eeg representation learning for emotion recognition",
      "authors": [
        "Guangyi Zhang",
        "Ali Etemad"
      ],
      "year": "2021",
      "venue": "2021 9th International Conference on Affective Computing and Intelligent Interaction (ACII)"
    },
    {
      "citation_id": "19",
      "title": "Caesnet: Convolutional autoencoder based semi-supervised network for improving multiclass classification of endomicroscopic images",
      "authors": [
        "Li Tong",
        "Hang Wu",
        "May Wang"
      ],
      "year": "2019",
      "venue": "Journal of the American Medical Informatics Association"
    },
    {
      "citation_id": "20",
      "title": "mixup: Beyond empirical risk minimization",
      "authors": [
        "Hongyi Zhang",
        "Moustapha Cisse",
        "David Yann N Dauphin",
        "Lopez-Paz"
      ],
      "year": "2018",
      "venue": "International Conference on Learning Representations (ICML)"
    },
    {
      "citation_id": "21",
      "title": "Adam: A method for stochastic optimization",
      "authors": [
        "P Diederik",
        "Jimmy Kingma",
        "Ba"
      ],
      "year": "2014",
      "venue": "Adam: A method for stochastic optimization",
      "arxiv": "arXiv:1412.6980"
    },
    {
      "citation_id": "22",
      "title": "Pytorch: An imperative style, high-performance deep learning library",
      "authors": [
        "Adam Paszke",
        "Sam Gross",
        "Francisco Massa",
        "Adam Lerer",
        "James Bradbury",
        "Gregory Chanan",
        "Trevor Killeen",
        "Zeming Lin",
        "Natalia Gimelshein",
        "Luca Antiga"
      ],
      "year": "2019",
      "venue": "Advances in Neural Information Processing Systems (NeurIPS)"
    }
  ]
}