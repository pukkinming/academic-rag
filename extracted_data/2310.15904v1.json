{
  "paper_id": "2310.15904v1",
  "title": "Do Stochastic Parrots Have Feelings Too? Improving Neural Detection Of Synthetic Text Via Emotion Recognition",
  "published": "2023-10-24T15:07:35Z",
  "authors": [
    "Alan Cowap",
    "Yvette Graham",
    "Jennifer Foster"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Recent developments in generative AI have shone a spotlight on high-performance synthetic text generation technologies. The now wide availability and ease of use of such models highlights the urgent need to provide equally powerful technologies capable of identifying synthetic text. With this in mind, we draw inspiration from psychological studies which suggest that people can be driven by emotion and encode emotion in the text they compose. We hypothesize that pretrained language models (PLMs) have an affective deficit because they lack such an emotional driver when generating text and consequently may generate synthetic text which has affective incoherence i.e. lacking the kind of emotional coherence present in human-authored text. We subsequently develop an emotionally aware detector by fine-tuning a PLM on emotion. Experiment results indicate that our emotionallyaware detector achieves improvements across a range of synthetic text generators, various sized models, datasets, and domains. Finally, we compare our emotionally-aware synthetic text detector to ChatGPT in the task of identification of its own output and show substantial gains, reinforcing the potential of emotion as a signal to identify synthetic text. Code, models, and datasets are available at https: //github.com/alanagiasi/emoPLMsynth",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Modern PLMs can surpass human-level baselines across several tasks in general language understanding  (Wang et al., 2018 (Wang et al., , 2019) )  and can produce synthetic text that can exceed human level quality, such as synthetic propaganda thought to be more plausible than human written propaganda  (Zellers et al., 2019) . PLMs have been used to generate disinformation  (Zellers et al., 2019; Brown et al., 2020) , left-or right-biased news  (Gupta et al., 2020) , fake comments  (Weiss, 2019) , fake reviews  (Adelani et al., 2019) , and plagiarism  (Gao et al., 2022)  and can generate synthetic text at scale, across domains, and across languages.\n\nThe increasing high quality of synthetic text from larger and larger PLMs brings with it an increasing risk of negative impact due to potential misuses. In this work, we focus on the task of synthetic text detection. Due to the potentially profound consequences of global synthetic disinformation we focus mainly, but not exclusively, on the detection of synthetic text in the news domain. 1  Synthetic news has already been published on one highly reputable media website, only later to be withdrawn and apologies issued for the \"breach of trust\"  (Crowley, 2023a,b) .\n\nCurrent approaches to synthetic text detection tend to focus on learning artefacts from the output distribution of PLMs  (Gehrmann et al., 2019; Pillutla et al., 2021; Mitchell et al., 2023) , e.g. increased perplexity caused by nucleus sampling  (Zellers et al., 2019) . However, PLM distributions are dependent on training data and numerous hyperparameter choices including model architecture and sampling strategy. This gives rise to a combinatorial explosion of possible distributions and makes the task of synthetic text detection very difficult. Furthermore, it is not unexpected that performance decreases when classifying out-of-distribution instances, and there is a growing field of work investigating this shortcoming  (Yang et al., 2023) .\n\nIn this work, we consider not only the PLM output distribution, but also the other side of the synthetic text detection coin -human factors. We present a novel approach to the task of synthetic text detection which aims to exploit any difference between expression of emotion in human-authored and synthetic text. Neural word representations can have difficulty with emotion words, and PLM sampling strategies are stochastic rather than driven by emotion -we use the term affective deficit to refer to these shortcomings. Thus, the resulting synthetic text can express emotion in an incoherent way, and we introduce the term affective incoherence to refer to this type of limitation. To be clear, we do not contend that synthetic text is devoid of emotion, rather that the emotional content of synthetic text may be affectively incoherent, and that this affective incoherence stems from the underlying affective deficit of the PLM.\n\nFor the purpose of demonstration of the affective deficit that we believe to be characteristic of text produced by PLMs, we provide the following simple example of human-versus machineauthored text with positive emotion words highlighted in orange and negative emotion words in pink. One shows coherent emotion expected of human-authored text, while the other demonstrates affective incoherence (see footnote 2  to reveal which was synthetic/human-authored text).\n\n1. Roberts chuckled when asked if he was happy to be on the other team now when Puig's name comes up. \"Yeah, I am happy,\" he said, smiling. 2. I'm really happy for him. Over the course of those three seasons, the 25-year-old has gone from rolling to poor to worse and old.\n\nIn this simple example, we have demonstrated one kind of affective incoherence present in synthetic text but we suspect that fine-tuning an emotionallyaware PLM could detect additional and more complex emotional patterns that might go undetected by humans. We hypothesise that the affective deficit of PLMs could result in synthetic text which is affectively incoherent, which could be useful in distinguishing it from human text. We use a transfer learning (Pan and Yang, 2010) method to train an \"emotionally-aware\" detector model. By fine-tuning a PLM first on emotion classification and then on our target task of synthetic text detection, we demonstrate improvements across a range of synthetic text generators, various sized models, datasets and domains. Furthermore, our emotionally-aware detector proves to be more accurate at distinguishing between human and ChatGPT text than (zero-shot) ChatGPT itself.\n\nFinally, we create two new datasets: NEWSsynth, a dataset of 20k human and synthetic news articles, and ChatGPT100, a testset of 100 human and Chat-GPT texts on a range of topics. We make all code, models and datasets publicly available to aid future research. 3",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Related Work",
      "text": "People are relatively poor at detecting synthetic text, and have been shown to score just above random chance  (Gehrmann et al., 2019; Uchendu et al., 2021) . Hybrid systems, such as GLTR  (Gehrmann et al., 2019)  for example, use automation to provide information to aid human classification, highlighting a text sequence using colours to represent likeness to the PLM output distribution such as GPT-2  (Radford et al., 2019) .  Gehrmann et al. (2019)  reported an increase in detection accuracy of approximately 18% (from 54% to 72%) using GLTR, while  Uchendu et al. (2021)  report an F1 score of 46% using GLTR with a heuristic based on an analysis of human text.\n\nBoth human and hybrid approaches involve human decisions, which can be slow, expensive, susceptible to bias, and inconsistent. Automatic detection produces the best results for synthetic text detection. This usually involves training PLMs to detect other PLMs, but zero-shot detection methods also exist, e.g. DetectGPT  (Mitchell et al., 2023) . Potentially the best supervised detector, BERT, can detect synthetic text from 19 different generators with a mean F1 of 87.99%, compared to 56.81% for hybrid, and worst of all humans at 53.58%  (Uchendu et al., 2021) .\n\nPerformance of SOTA detectors can however be inconsistent and unpredictable due to several factors specific to both the detector and generator, including: model size and architecture, training data and domain thereof, sampling strategy, hyperparameter selection, and sentence length. As mentioned above,  Uchendu et al. (2021)  showed the best of these models (BERT) achieves a mean F1 of 87.99% on 19 different synthetic text generators. However, the mean score hides the wide range (≈53%) of F1's, ranging from as low as 47.01% to 99.97%, for distinct synthetic text generators. This volatility may be due in part to the detector simply learning artefacts of the generator distribution. Consequently, the task of synthetic text detection is somewhat of an arms race with detectors playing catch-up, forced to learn ever-changing distributions due to the numerous factors that can potentially change those distributions.\n\nExisting approaches to synthetic text detection exploit properties of synthetic text. Synthetic text can be incoherent and degrade as the length of generated text increases  (Holtzman et al., 2020) , perplexity increases with increasing length unlike human text  (Zellers et al., 2019) , and PLMs are susceptible to sampling bias, induction bias, and exposure bias  (Ranzato et al., 2016) . For example, exposure bias can contribute to brittle text which is repetitive, incoherent, even containing hallucinations  (Arora et al., 2022) . Synthetic text can have an inconsistent factual structure, such as mentioning irrelevant entities  (Zhong et al., 2020) . Perhaps unsurprisingly, synthetic text detection is less difficult with longer excerpts of generated text, for both humans and machines  (Ippolito et al., 2020) .\n\nOne aspect of writing that has not, up to now, been a focus of synthetic text detection efforts is the expression of emotion. The problem of encoding emotion was first identified in neural NLP with static embeddings such as word2vec  (Mikolov et al., 2013; Wang et al., 2020a) . Static word embeddings have difficulty distinguishing antonymns from synonyms  (Santus et al., 2014) . This deficit is present in embeddings for words which represent opposing emotions (e.g. joy-sadness) (Seyeditabari and Zadrozny, 2017). Furthermore, words representing opposing emotions can have closer embeddings relative to words representing similar emotions  (Agrawal et al., 2018) . There have been various approaches to address this affective deficit in embeddings, such as transfer learning from sentiment analysis  (Kratzwald et al., 2018) , an additional training phase using an emotional lexicon and psychological model of emotions  (Seyeditabari et al., 2019) , and combining separately-learned semantic and sentiment embedding spaces  (Wang et al., 2020a) .\n\nAddressing potential affective deficits of PLMs is also the goal of work aiming to make dialogue systems more empathetic. For example  Huang et al. (2018)  force dialogue generation to express emotion based on the emotion detected in an utterance, while  Rashkin et al. (2019)  follow a similar approach with a transformer architecture to make the system more empathetic. In contrast,  Wang et al. (2020b)  report that human text can display consistency in emotional content whereby similar emotions tend to occur adjacent to each other while dissimilar emotions seldom do.  4 Past work in synthetic text detection has focused on the properties of synthetic text generators and is yet to take advantage of the factors that potentially influence human-authored text, such as the emotions humans express in the text they write. Our work exploits this PLM affective deficit to improve synthetic text detection.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Equipping Plms With Emotional Intelligence",
      "text": "Our method is illustrated in Figure  1 . The process works as follows:\n\n1. PLMSYNTH: In the leftmost column of Figure  1 , human articles and synthetic articles are used to fine-tune a PLM to discriminate between the two kinds of text. This is indicated by the blue nodes in the PLM illustration. 2. EMOPLM: In the middle column of Figure  1 , a second dataset annotated for emotions with Ekman's 6 emotions  (Ekman, 1992 (Ekman, , 1999 (Ekman, , 2016 ) is used to fine-tune a PLM on the task of emotion classification. This makes our model emotionally-aware, as indicated by the red nodes in the PLM illustration. 3. EMOPLMSYNTH: The multi-class (6 head) classification layer from emoPLM is removed and replaced with a binary classification layer. The emotionally-aware PLM is then finetuned on the task of discriminating between human and synthetic articles. The PLM is still emotionally-aware while also being able to detect synthetic text -as indicated by the red and blue nodes respectively in the PLM.\n\nWe conduct experiments using various PLM sizes, architectures, datasets, and domains for synthetic text generation and detection.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "News Domain Experiments",
      "text": "",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Generator And Detector Models",
      "text": "To generate synthetic text, we use the Grover causal PLM (GPT-2 architecture) pretrained on 32M news articles from the RealNews dataset  (Zellers et al., 2019) . We choose BERT  (Devlin et al., 2019)  as our main detector model since it is freely available and performs well in several tasks including sequence classification. A baseline BERT model (we call this BERTsynth) is fine-tuned on the task of",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Datasets",
      "text": "We create and release NEWSsynth, a dataset containing 10k human and 10k synthetic news articles. 10k human-authored news articles were taken from the RealNews-Test dataset  (Zellers et al., 2019)  and used as a prompt to Grover base to generate a corresponding 10k synthetic articles. The prompt includes the news article, headline, date, author, web domain etc. as described by  Zellers et al. (2019) . The dataset was split 10k-2k-8k for train, validation, and test respectively, the same ratio used by  Zellers et al. (2019)  with 50:50 human:synthetic text in each split, see Appendix B.3 for details. An investigation of length of human vs synthetic text is provided in Appendix E.\n\nIn a second experiment, we also use the full RealNews-Test dataset itself, which comprises the same 10k human news articles used in NEWSsynth and 10k synthetic articles generated by Grover mega . The use of synthetic text generated by Grover mega instead of Grover base allows comparison of BERTsynth and emoBERTsynth on text generated by a larger generator model, and against results reported for other models on this dataset.\n\nWe use the GoodNewsEveryone dataset  (Bostan et al., 2020)  to train emoBERT. This dataset contains 5k news headlines, and was chosen since it is within the target domain (news) and language (English) and is annotated with categorical emotions. The 15 emotion labels from GoodNewsEveryone were reduced to 11 emotions using the mapping schema of  (Bostan and Klinger, 2018) , and further reduced to 6 emotions based on the Plutchik Wheel of Emotion  (Plutchik, 1980 (Plutchik, , 2001) )  -see Table  1  and Figure  3  in Appendix A -resulting in 5k news headlines labelled with Ekman's 6 basic emotions, the most frequently used categorical emotion model in psychology literature  (Ekman, 1992 (Ekman, , 1999 (Ekman, , 2016)) .",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Training Bertsynth",
      "text": "We train BERTsynth, a BERT base -cased model fine-tuned for synthetic text detection (using the NEWSsynth or RealNews-Test dataset). Input sequence length was maintained at the BERT maximum of 512 tokens (≈ 384 words). Five training runs were conducted. Each training run was 4 epochs -the most possible within GPU time constraints and similar to those of  Zellers et al. (2019)",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Training Emobert",
      "text": "We train emoBERT, a BERT base -cased model finetuned on the single label multiclass task of emotion classification using the GoodNewsEveryone dataset. Fine-tuning emoBERT followed a similar process to fine-tuning BERTsynth described in §4.3. This time, there were 5k examples and fine-tuning was for 10 epochs. Classification accuracy is not the end goal for emoBERT. Its purpose is to reduce the affective deficit of the PLM by modifying the representations of words conveying emotions and to improve performance in the task of synthetic text detection by transfer learning. The mean F1 µ for emoBERT is 39.4% on the Validation set -more than double mean chance (16.7%) and within the range 31% to 98% reported for within-corpus emotion classification in UnifiedEmotion  (Bostan and Klinger, 2018) . See Appendix D for more details.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Training Emobertsynth",
      "text": "We train emoBERTsynth, an emoBERT model finetuned for synthetic text detection (using the NEWSsynth or RealNews-Test dataset). The best emoBERT model (checkpoint) from each of the 5 training runs had its emotion classification head (6 outputs) replaced with a binary classification head (2 outputs) for human vs synthetic text classification, see Figure  1 . Each model was then finetuned on the synthetic text detection task using the exact same process and set of random seeds (for dataset shuffling) as the 5 best models described in §4.3. This allowed a direct comparison between the 5 BERTsynth models (trained on synthetic text detection only) and the 5 emoBERTsynth models (fine-tuned on emotion classification followed by synthetic text detection).",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Results",
      "text": "The results in Figure  2  and Table  2  show the performance of BERTsynth and emoBERTsynth when fine-tuned on the NEWSsynth dataset. The results support the hypothesis that emotion can help detect synthetic text. emoBERTsynth outperforms BERTsynth in head-to-head for accuracy and F1 in all 5 runs.\n\nLooking at precision and recall, emoBERTsynth outperforms BERTsynth in precision in all 5 runs, while the opposite is the case for recall. It is worth Test results for BERTsynth and emoBERTsynth on the NEWSsynth dataset. emoBERTsynth is higher for Accuracy, Precision and F1, while BERTsynth is higher for Recall.\n\ncomparing the relative difference in recall and precision between emoBERTsynth and BERTsynth models in Table  2 . emoBERTsynth has a difference between the mean recall and mean precision of 4.76 (89.04 -84.28) while the difference for BERTsynth is more than double that at 10.  81 (91.63 -80.82  Thus, we suggest our emotionally-aware PLM, emoBERTsynth, is a better performing model than the standard PLM, BERTsynth, because it has a better balance between precision and recall.\n\nIn Table  3  we compare BERTsynth and emoBERTsynth on the RealNews-Test dataset. Recall that this dataset contains synthetic articles generated by Grover mega instead of the smaller Grover base . We also compare against the FastText, GPT-2 and BERT detector models reported by  Zellers et al. (2019)  on this dataset. emoBERTsynth has the highest accuracy, outperforming BERTsynth by 1.4%, BERT base by 9.03%, GPT-2 base by 10.03%, and FastText by 12.43%. These results support the hypothesis that emotion can improve synthetic text detection.\n\nThere is a 7.63 point difference between our BERTsynth model and the BERT model reported by  Zellers et al. (2019) , despite both models being BERT base and fine-tuned on the same dataset and splits. However, there are differences in how the models were treated before this fine-tuning, and there may be some hyperparameter differences for fine-tuning. We described in §4.3 how we fine-tune a randomly initialised BERT model to create BERTsynth.  Zellers et al. (2019)  reported their BERT models were domain adapted to News (by training on RealNews) at a length of 1024 WordPiece tokens. It is possible that this additional domain-adaptation and extended input sequence length actually harmed the performance of the BERT base model on the synthetic detection task. The performance of synthetic text detectors can improve with length  (Ippolito et al., 2020)  and the longer input sequence length could help in this regard. However, the vast majority of human and syn-thetic news articles in RealNews-Test are shorter than 1024 tokens. Thus, they may not benefit from that extended input length and the model may in fact be somewhat reliant on those later input tokens for prediction.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Size",
      "text": "",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Analysis",
      "text": "In this section, we perform a further set of experiments to aid in interpreting our main results.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Length Of Human Vs Synthetic Articles",
      "text": "We investigate whether PLMs simply learn something about the length of articles as a proxy for discrimination between human and synthetic text. The BERTsynth fine-tuning regime ( §4.3) was repeated using all (20k) and half (10k) of NEWSsynth. In all 5 runs, the BERTsynth model trained on the larger 20k dataset performed better than the equivalent model trained on the smaller 10k datasetsee Table  4 . There was a modest improvement in precision (+2.43%) with a much larger increase in recall (+11.78%). The results suggest that recall is most sensitive to the size of the training set. This is perhaps because the PLM is already trained on human text during pretraining but not synthetic text (exposure bias), so more exposure to synthetic text increases the model's ability to detect synthetic text correctly with fewer false negatives.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Alternative Forms Of Emobert",
      "text": "What is the effect of using different emotion datasets to fine-tune our emotionally aware PLMs on the downstream task of synthetic text detection?\n\nWe conduct experiments on emoBERTsynth by finetuning eight alternative emoBERT models:\n\n• GNE involves fine-tuning using the Good-NewsEveryone dataset ( §4.2) as in the main experiments; • GNE r involves fine-tuning with a version of GNE with randomised labels. We do this to examine the extent to which the difference between BERTsynth and emoBERTsynth can be attributed to emotion or to the process of fine-tuning on an arbitrary classification task with the GNE data; • AT involves fine-tuning with the Affec-tiveText dataset comprising 1.5k news headlines in English annotated with respect to Ekman's 6 emotions  (Strapparava and Mihalcea, 2008 ); • GA is GNE and AT combined; • SST-2 involves fine-tuning on the task of sentiment polarity classification using the SST-2 dataset of 68,221 movie reviews in English  (Socher et al., 2013 ); • GAS is GNE, AT, and SST-2 combined; with SST-2 positive sentiment mapped to joy and negative sentiment mapped to sadness; • S-GA involves first fine-tuning on sentiment using SST-2 and then fine-tuning on emotion using GA. This experiment is inspired by  Kratzwald et al. (2018)  who report that emotion classification can be improved by transfer learning from sentiment analysis; • GAS+is GAS but mapped to positive and negative sentiment.  6 The results (Table  5 ) reveal that the bestperforming emoBERTsynth models are those finetuned using GNE or using GNE and AffectiveText combined (GA). The latter achieves the highest accuracy and the former the highest F1. We attribute the relatively poor performance of AffectiveText on its own to its small size, comprising only 1.5k headlines (split 625 + 125 for training and dev splits respectively) compared to 5k for GNE and 68k for SST-2.\n\nTable  5  also shows that fine-tuning on GNE outperforms fine-tuning with randomised labels (GNE r ). The 1.1 point drop in accuracy of GNE r compared to GNE suggests that the emotion classification task does play a role in the improved performance of emoBERTsynth versus BERTsynth.\n\nThe results in Table  5  suggest that fine-tuning on sentiment is not particularly helpful. The poor performance of GAS could be due to the crude mapping of negative sentiment to sadness (because Prec. is the SST-2 sentiment dataset. GAS is the combined GNE, AT, and SST-2 datasets. S-GA is first fine-tuned on sentiment using the SST-2 dataset, and then finetuned on emotion using the GNE and AT datasets, and finally fine-tuned on synthetic text detection. GAS+-is GAS but mapped to positive and negative sentiment.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Rec",
      "text": "it could be any 1 of 5 Ekman emotions), which results in a large dataset imbalance across emotion labels. When we go in the opposite direction and mapped the emotion labels to sentiment labels (GAS+-), the results improved. Overall, however, the results suggest that mixing emotion and sentiment datasets is not a good idea (particularly if they are disproportionate in size and imbalanced), and that sentiment alone is not sufficient.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "A Larger Detector Model",
      "text": "We next investigate what happens when we use a PLM larger than BERT to detect synthetic text.\n\nUsing the same experimental setup described in §4, we substituted BLOOM  (Scao et al., 2023)  in place of BERT for the synthetic text detector.\n\nBLOOM is an open-science causal PLM alternative to  GPT-3 (Brown et al., 2020) . We use the BLOOM 560M size model. The results in Table  6  show that the emotionally-aware BLOOM PLM (emoBLOOMsynth) outperforms the standard BLOOM (BLOOMsynth) in all metrics.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Chatgpt Experiments",
      "text": "All experiments so far have involved PLMs pretrained with the self-supervised objective of predicting the next token or a masked token. We conduct a final experiment with ChatGPT, a more human- aligned Large Language Model (LLM) which has undergone a second training or \"alignment\" phase using Reinforcement Learning from Human Feedback on top of an underlying LLM (GPT 3.5 in our case)  (OpenAI, 2022; Ouyang et al., 2022) . We create a custom dataset comprising human articles and ChatGPT synthetic text from multiple non-news domains, and use it to compare our BERTsynth and emoBERTsynth models against ChatGPT (in a zeroshot setting) on the task of detecting ChatGPT's own synthetic text. 7\n\nChatGPT100 We create and release Chat-GPT100 -a dataset comprising human articles and synthetic articles generated by ChatGPT. Following  Clark et al. (2021)  who collected 50 human articles and generated 50 articles using GPT2 and GPT3, we also collect 50 human articles, and we then use ChatGPT to generate 50 synthetic ones. The human written articles are from 5 different domains: Science, Entertainment, Sport, Business, and Philosophy. We used reputable websites for the human text which was gathered manually, see Table  8  in Appendix B.3. The synthetic text was generated by providing ChatGPT with a prompt such as \"In less than 400 words, tell me about moral philosophy.\" where human text on the same topic, moral philosophy in this case, had already been found online. The data generated by ChatGPT is semantically correct and was checked manually. Subject areas in which the authors are knowledgeable were chosen so that the correctness of the synthetic text could be checked. To be comparable with the detectors presented in our earlier experiments, the articles were limited to a maximum of 384 words (≈ 512 tokens) and truncated at a natural sentence boundary. The two articles were then made to be approximately the same length. Detection task Each article was appended to the following prompt to ChatGPT: \"Was the following written by a human or a computer, choose human or computer only?\" Having tested ChatGPT, we then tested our BERTsynth and emoBERTsynth models (the models fine-tuned on RealNews-Test from Table  3 ).",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Results",
      "text": "The results are shown in Table  7 . The first thing to note is that no model performs particularly well. ChatGPT tends to misclassify its own synthetic text as human (hence the low recall score of 30%). 8 BERTsynth and emoBERTsynth, on the other hand, tend to classify text as machinewritten and they both obtain 100% recall. We previously saw ( §4.7.2) that recall is most sensitive to fine-tuning set size. The emoBERTsynth and emoBERTsynth models have been exposed to synthetic text during fine-tuning, whereas ChatGPT is performing the task zero-shot. This could explain some of the difference in recall between the ChatGPT and the two fine-tuned models.\n\nFinally, as with our experiments with Grovergenerated text, emoBERTsynth outperforms BERTsynth on all metrics. The dataset is small so we must be careful not to conclude too much from this result, but it does suggest that fine-tuning on emotion could be beneficial when detecting synthetic text from LLMs and more sophisticated generators, in non-news domains. This is in line with the results of our earlier experiments using variously size PLMs (such as Grover, BERT, BLOOM), used as generators and detectors in the news domain, and shows the potential for our approach with different generator models and in different domains.",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Conclusion",
      "text": "We conducted experiments investigating the role that emotion recognition can play in the detection 8 ChatGPTs responses suggest it may use fact-checking as a proxy during synthetic text detection.\n\nof synthetic text. An emotionally-aware PLM finetuned on emotion classification and subsequently trained on synthetic text detection (emoPLMsynth) outperformed a model with identical fine-tuning on synthetic text detection, but without emotion training, (PLMsynth). The results hold across different synthetic text generators, model sizes, datasets and domains. This work specifically demonstrates the benefits of considering emotion in the task of detecting synthetic text, it contributes two new datasets (NEWSsynth and ChatGPT100) and, more generally, it hints at the potential benefits of considering human factors in NLP and Machine Learning.\n\nIs it possible that some other proxy for synthetic text is at play? We ruled out some potential proxies related to article length in §4.7.1. In ablation studies in §4.7.3, we showed that the emotion labels result in an improvement in performance compared to randomized labels for the same emotion dataset. Other potential proxies are nonsensical sentences, repetitive text, etc. However, we account for these by comparing our emotionally-aware PLMs (emoPLMsynth) against standard PLMs fine-tuned on synthetic text detection only (PLMsynth). Thus, any advantage or disadvantage of sentences without meaning (or any other factor) is also available to the non-emotionally-aware model against which we compare our emotionally-aware model.\n\nFuture work will investigate further the affective profile (i.e. emotional content and characteristics) of human and synthetic text; and attempt to determine if there are measurable differences which may prove useful in the task of synthetic text detection.",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "Limitations",
      "text": "The datasets used in this work (synthetic text datasets, emotion datasets, and sentiment dataset) are English language and model performance in other languages may vary. We primarily focus on the news domain and, while performance in other domains may vary  (Merchant et al., 2020) , we include experiments in several non-news domains ( §5).\n\nThe emotion datasets are imbalanced across emotion labels which can impact overall performance, and we conducted ablation experiments to find the best combination of emotion and sentiment datasets ( §4.7.3). GoodNewsEveryone's 15 emotions were mapped to Ekman's 6 emotions  (Ekman, 1992 (Ekman, , 1999 (Ekman, , 2016)) , factoring in Plutchik's wheel of emotion  (Plutchik, 1980 (Plutchik, , 2001)) , but there is no firm agreement in the literature as to which is the 'correct' or 'best' emotion model  (Ekman, 2016) . The emotion models used in this work are the two most popular in the literature.\n\nThe maximum input sequence length of BERT is 512 tokens and articles longer than this are truncated, which may negatively affect performance on the synthetic text detection task  (Ippolito et al., 2020) . However, we also saw that increasing the input sequence length may actually contribute to poorer performance ( §4.6).",
      "page_start": 14,
      "page_end": 14
    },
    {
      "section_name": "Ethical Considerations",
      "text": "We release multiple PLMs (emoBERTsynth, BERTsynth, emoBLOOMsynth and BLOOMsynth) which we refer to generically as emoPLMsynth and PLMsynth. emoPLMsynth and PLMsynth are BERT or BLOOM models with versions fine-tuned on NEWSsynth or the RealNews-Test  (Zellers et al., 2019)  datasets; emoPLMsynth is also fine-tuned on combinations of the GoodNewsEveryone  (Bostan et al., 2020) , AffectiveText  (Strapparava and Mihalcea, 2008) , and SST-2  (Socher et al., 2013)  datasets.\n\nWe release ChatGPT100, a dataset comprising 100 English language articles in various non-news domains. 50 articles are human written, and 50 articles are generated by ChatGPT. The 100 articles have all been manually curated and do not contain toxic content. Furthermore, ChatGPT has a content filter which flags potentially harmful content.\n\nWe release, NEWSsynth, a dataset comprising 40k English language articles in the news domain. 9  20k news articles are human (from RealNews-Test) and 20k generated by Grover. Publishing synthetic text is a risk, but NEWSsynth is clearly labelled as containing synthetic text. This is a similar precaution to synthetic text from Grover which has already been published and is publicly available  (Zellers et al., 2019) .\n\nThe potential harms, such as toxic synthetic text  (Gehman et al., 2020) , of PLMs pretrained on webcrawled data has been the subject of much discussion  (Bender et al., 2021) . Since emoPLMsynth and PLMsynth (and Grover) were pretrained and/or finetuned on web-crawled data there is a possibility they could produce inappropriate synthetic text and this includes the NEWSsynth dataset. We recognise these potential harms and to mitigate them include the caveat below with the released datasets (NEWSsynth and ChatGPT100) and the released language models (emoPLMsynth, PLMsynth):\n\nCare must be taken when using these language models (emoPLMsynth and PLMsynth), and datasets (NEWSsynth and ChatGPT100) as they may produce or contain ethically problematic content. Data scraped from the web may contain content which is ethically problematic such as adult content, bias, toxicity etc. and web-scraped data is used in the pre-trained language models such as BERT, BLOOM and Grover. PLMsynth and emoPLMsynth are based on BERT or BLOOM PLMs, while NEWSsynth was generated by Grover. Consequently, emoPLMsynth and PLMsynth could produce text which is ethically problematic, while NEWSsynth may contain ethically problematic content. As a result, any use of the language models (emoPLMsynth, PLMsynth) or the datasets (NEWSsynth or ChatGPT100) should employ appropriate checks and test regimes to handle potential harmful content.\n\nThe intended use of the emoPLMsynth and PLMsynth models, and the NEWSsynth and Chat-GPT100 datasets, is for research purposes and beneficial downstream tasks such as identifying synthetic text perhaps in online news, reviews, comments, plagiarism etc. Online platforms could use this identification to decide whether or not to publish such content, or where to surface it via recommender algorithms etc. This could help protect public confidence in online discourse.\n\nEnergy usage was reduced by training on smaller models and for a relatively small number of epochs where possible, by using random search rather than an exhaustive grid search, and by using freely available managed compute resources where possible.\n\non Empirical Methods in Natural Language Processing (EMNLP), pages 2461-2470, Online. Association for Computational Linguistics.",
      "page_start": 15,
      "page_end": 15
    },
    {
      "section_name": "A Plutchik Wheel Of Emotion",
      "text": "The Plutchik Wheel of Emotion  (Plutchik, 1980 (Plutchik, , 2001 ) is shown in Figure  3  and is the most commonly used dimensional model in psychology literature.",
      "page_start": 16,
      "page_end": 16
    },
    {
      "section_name": "B Reproducibility",
      "text": "All code, models, and datasets (including NEWSsynth and ChatGPT100) are available at https://github.com/alanagiasi/ emoPLMsynth.",
      "page_start": 17,
      "page_end": 17
    },
    {
      "section_name": "B.1 Parameters Used For Generating Synthetic Text With Grover",
      "text": "Grover BASE was used for generating synthetic text news articles in NEWSsynth. Full contextual metadata was used, in addition to a value of 0.95 because both can make discrimination more difficult. According to  Zellers et al. (2019)  contextual data decreased perplexity by 0.9 points for Grover BASE , and a top-p value in the range 0.92 to 0.98 is a Goldilocks zone where discrimination is hardest (so we chose top-p=0.95 as it is in the middle of this difficult detection zone). Source code, installation, and generation instructions for Grover can be found on the Grover github.   Regarding the emotional content and journalistic content of news articles in NEWSsynth: Previous authors have specifically chosen the news domain because of its high emotional content  (Strapparava and Mihalcea, 2007; Bostan et al., 2020) . It is long established that different emotions lead to different actions  (Spielberger, 1972)  including what we write  (Brand, 1985) . Emotion can be exploited, for example \"engagement based ranking\" tends to favour content that evokes anger (Haugen, 2021). While some journalistic reporting is objective, opinion editorials (op-ed) are opinions pushing an agenda and, for example, tabloids tend to specifically exploit emotion. The 10k news articles in the NEWSsynth training split, for example, come from 150 online sources which also include: movie reviews and entertainment such as rollingstone.com, hollywoodlife.com, bollywoodhungama.com and mashable.com; and tabloids such as thedailymail.co.uk, dailystar.co.uk, thedailystar.net etc. which cover many types of news including journalism, op-eds, reviews, opinions etc. In short, NEWSsynth is not limited to nonemotional objective fact reporting, it contains a broad spectrum of journalistic styles and content.",
      "page_start": 18,
      "page_end": 18
    },
    {
      "section_name": "Chatgpt100",
      "text": "We release ChatGPT100, a dataset comprising 100 English language articles in various non-news domains (Science, (Music, Movies), Sport, Business, and Philosophy). 50 articles are human written, and 50 articles are generated by ChatGPT. The 100 articles have all been manually curated and do not contain toxic content. Furthermore, ChatGPT has a content filter which flags potentially harmful content.\n\nThe 50 human articles contained in ChatGPT100 were gathered between 16-24 March 2023 from the domains shown in Table  8 . The 50 synthetic articles contained in ChatGPT100 were generated using ChatGPT 3.5 (March 14 2023 version) on dates between 16-24 March 2023.\n\nRealNews and RealNews-Test These datasets were released with Grover and are described there in detail  (Zellers et al., 2019) .\n\nEmotion and Sentiment Datasets GoodNew-sEveryone is described in detail  (Bostan et al., 2020)  with modifications made to the dataset for this work described in §4.2. The distribution of emotion intensity is shown in Table  9  showing almost all are 'medium' while 2 examples have no emotion. AffectiveText was released as part of Se-mEval 2008 and is described in detail  (Strapparava and Mihalcea, 2008) , while the SST-2 sentiment dataset is described in detail  (Socher et al., 2013) .",
      "page_start": 19,
      "page_end": 19
    },
    {
      "section_name": "C Hyperparameters Used For Fine-Tuning",
      "text": "The hyperparameters used for PLM fine-tuning are listed below. If not specifically listed, the hyperparameter value used was the default using Hug-gingFace Transformer libraries. 12 The BERT BASEcased and BERT LARGE -cased models were down- emoBERT, BERTsynth, and emoBERTsynth were all trained using freely available Google Colab with a single GPU (Tesla K80 or Tesla T4) with no guarantee on available RAM 14  or an NVIDIA GeForce RTX3090 GPU with 24GB RAM.\n\nAll models were trained and evaluated for 5 runs using different seeds for each of the 5 runs. The seeds used are listed below.\n\n• Data seeds =  [17, 38, 5, 91, 59 ] #n, n-6, n+6\n\nfor train-val-test seeds respectively",
      "page_start": 19,
      "page_end": 19
    },
    {
      "section_name": "D Emobert Emotion Classification Results",
      "text": "The mean F1 µ for emoBERT is 39.4% on the Validation set -more than double mean chance (16.7%) and within the range 31% to 98% (mean = 62.6%) reported for within-corpus emotion classification in UnifiedEmotion  (Bostan and Klinger, 2018) . Good-NewsEveryone does not report news headline emotion classification  (Bostan et al., 2020) .",
      "page_start": 19,
      "page_end": 19
    },
    {
      "section_name": "E Length Of Human Vs Synthetic Articles In Newssynth",
      "text": "Figures 5 -8 illustrate the relative lengths of human and synthetic articles and sentences in NEWSsynth (train and validation splits) as described in §4.7.1 and shown in Table  10 .",
      "page_start": 19,
      "page_end": 19
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: The process",
      "page": 3
    },
    {
      "caption": "Figure 1: , human articles and synthetic articles",
      "page": 3
    },
    {
      "caption": "Figure 1: , a second dataset annotated for emotions",
      "page": 3
    },
    {
      "caption": "Figure 1: The emotionally-aware PLM (emoPLMsynth) takes advantage of its prior fine-tuning on emotion to",
      "page": 4
    },
    {
      "caption": "Figure 3: in Appendix A – resulting",
      "page": 4
    },
    {
      "caption": "Figure 1: Each model was then fine-",
      "page": 5
    },
    {
      "caption": "Figure 2: and Table 2 show the per-",
      "page": 5
    },
    {
      "caption": "Figure 3: and is the most com-",
      "page": 15
    },
    {
      "caption": "Figure 3: Plutchik Wheel of Emotion. The middle",
      "page": 15
    },
    {
      "caption": "Figure 4: Combined Confusion Matrix for Emotion",
      "page": 17
    },
    {
      "caption": "Figure 4: depicts the combined results of the",
      "page": 17
    },
    {
      "caption": "Figure 4: Anger and Surprise are the two emotions",
      "page": 17
    },
    {
      "caption": "Figure 5: Scatter plot of number of words per article",
      "page": 18
    },
    {
      "caption": "Figure 6: Number of words per article for human (green)",
      "page": 18
    },
    {
      "caption": "Figure 7: Number of sentences per article for human",
      "page": 18
    },
    {
      "caption": "Figure 8: Number of words per sentence for human",
      "page": 18
    },
    {
      "caption": "Figure 8: Table 10: Comparison of Human and synthetic text in the NEWSsynth dataset showing the mean (x) and standard deviation (σ)",
      "page": 19
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "alan.cowap2@mail.dcu.ie,": "2School of Computer Science and Statistics, Trinity College Dublin",
          "jennifer.foster@dcu.ie": ""
        },
        {
          "alan.cowap2@mail.dcu.ie,": "ygraham@tcd.ie",
          "jennifer.foster@dcu.ie": ""
        },
        {
          "alan.cowap2@mail.dcu.ie,": "Abstract",
          "jennifer.foster@dcu.ie": "can generate synthetic text at scale, across domains,"
        },
        {
          "alan.cowap2@mail.dcu.ie,": "",
          "jennifer.foster@dcu.ie": "and across languages."
        },
        {
          "alan.cowap2@mail.dcu.ie,": "Recent developments\nin generative AI have",
          "jennifer.foster@dcu.ie": ""
        },
        {
          "alan.cowap2@mail.dcu.ie,": "",
          "jennifer.foster@dcu.ie": "The increasing high quality of\nsynthetic text"
        },
        {
          "alan.cowap2@mail.dcu.ie,": "shone a spotlight on high-performance syn-",
          "jennifer.foster@dcu.ie": ""
        },
        {
          "alan.cowap2@mail.dcu.ie,": "",
          "jennifer.foster@dcu.ie": "from larger and larger PLMs brings with it an in-"
        },
        {
          "alan.cowap2@mail.dcu.ie,": "thetic text generation technologies. The now",
          "jennifer.foster@dcu.ie": ""
        },
        {
          "alan.cowap2@mail.dcu.ie,": "",
          "jennifer.foster@dcu.ie": "creasing risk of negative impact due to potential"
        },
        {
          "alan.cowap2@mail.dcu.ie,": "wide availability and ease of use of such models",
          "jennifer.foster@dcu.ie": ""
        },
        {
          "alan.cowap2@mail.dcu.ie,": "highlights the urgent need to provide equally",
          "jennifer.foster@dcu.ie": "misuses.\nIn this work, we focus on the task of"
        },
        {
          "alan.cowap2@mail.dcu.ie,": "powerful\ntechnologies capable of identifying",
          "jennifer.foster@dcu.ie": "synthetic text detection.\nDue to the potentially"
        },
        {
          "alan.cowap2@mail.dcu.ie,": "synthetic text. With this\nin mind, we draw",
          "jennifer.foster@dcu.ie": ""
        },
        {
          "alan.cowap2@mail.dcu.ie,": "",
          "jennifer.foster@dcu.ie": "profound consequences of global synthetic disin-"
        },
        {
          "alan.cowap2@mail.dcu.ie,": "inspiration from psychological studies which",
          "jennifer.foster@dcu.ie": ""
        },
        {
          "alan.cowap2@mail.dcu.ie,": "",
          "jennifer.foster@dcu.ie": "formation we focus mainly, but not exclusively, on"
        },
        {
          "alan.cowap2@mail.dcu.ie,": "suggest that people can be driven by emotion",
          "jennifer.foster@dcu.ie": ""
        },
        {
          "alan.cowap2@mail.dcu.ie,": "",
          "jennifer.foster@dcu.ie": "the detection of synthetic text in the news domain.1"
        },
        {
          "alan.cowap2@mail.dcu.ie,": "and encode emotion in the text they compose.",
          "jennifer.foster@dcu.ie": ""
        },
        {
          "alan.cowap2@mail.dcu.ie,": "",
          "jennifer.foster@dcu.ie": "Synthetic news has already been published on one"
        },
        {
          "alan.cowap2@mail.dcu.ie,": "We hypothesize that pretrained language mod-",
          "jennifer.foster@dcu.ie": ""
        },
        {
          "alan.cowap2@mail.dcu.ie,": "",
          "jennifer.foster@dcu.ie": "highly reputable media website, only later to be"
        },
        {
          "alan.cowap2@mail.dcu.ie,": "els (PLMs) have an affective deficit because",
          "jennifer.foster@dcu.ie": ""
        },
        {
          "alan.cowap2@mail.dcu.ie,": "they lack such an emotional driver when gen-",
          "jennifer.foster@dcu.ie": "withdrawn and apologies issued for the “breach of"
        },
        {
          "alan.cowap2@mail.dcu.ie,": "erating text and consequently may generate",
          "jennifer.foster@dcu.ie": "trust” (Crowley, 2023a,b)."
        },
        {
          "alan.cowap2@mail.dcu.ie,": "synthetic text which has affective incoherence",
          "jennifer.foster@dcu.ie": ""
        },
        {
          "alan.cowap2@mail.dcu.ie,": "",
          "jennifer.foster@dcu.ie": "Current approaches to synthetic text detection"
        },
        {
          "alan.cowap2@mail.dcu.ie,": "i.e.\nlacking the kind of emotional coherence",
          "jennifer.foster@dcu.ie": ""
        },
        {
          "alan.cowap2@mail.dcu.ie,": "",
          "jennifer.foster@dcu.ie": "tend to focus on learning artefacts from the out-"
        },
        {
          "alan.cowap2@mail.dcu.ie,": "present\nin human-authored text. We subse-",
          "jennifer.foster@dcu.ie": ""
        },
        {
          "alan.cowap2@mail.dcu.ie,": "",
          "jennifer.foster@dcu.ie": "put distribution of PLMs (Gehrmann et al., 2019;"
        },
        {
          "alan.cowap2@mail.dcu.ie,": "quently develop an emotionally aware detec-",
          "jennifer.foster@dcu.ie": ""
        },
        {
          "alan.cowap2@mail.dcu.ie,": "",
          "jennifer.foster@dcu.ie": "Pillutla et al., 2021; Mitchell et al., 2023),\ne.g."
        },
        {
          "alan.cowap2@mail.dcu.ie,": "tor by fine-tuning a PLM on emotion.\nEx-",
          "jennifer.foster@dcu.ie": ""
        },
        {
          "alan.cowap2@mail.dcu.ie,": "",
          "jennifer.foster@dcu.ie": "increased perplexity caused by nucleus sampling"
        },
        {
          "alan.cowap2@mail.dcu.ie,": "periment results indicate that our emotionally-",
          "jennifer.foster@dcu.ie": ""
        },
        {
          "alan.cowap2@mail.dcu.ie,": "aware detector achieves improvements across",
          "jennifer.foster@dcu.ie": "(Zellers et al., 2019). However, PLM distributions"
        },
        {
          "alan.cowap2@mail.dcu.ie,": "a range of synthetic text generators, various",
          "jennifer.foster@dcu.ie": "are dependent on training data and numerous hy-"
        },
        {
          "alan.cowap2@mail.dcu.ie,": "sized models, datasets, and domains. Finally,",
          "jennifer.foster@dcu.ie": "perparameter choices including model architecture"
        },
        {
          "alan.cowap2@mail.dcu.ie,": "we compare our emotionally-aware synthetic",
          "jennifer.foster@dcu.ie": ""
        },
        {
          "alan.cowap2@mail.dcu.ie,": "",
          "jennifer.foster@dcu.ie": "and sampling strategy. This gives rise to a combina-"
        },
        {
          "alan.cowap2@mail.dcu.ie,": "text detector to ChatGPT in the task of iden-",
          "jennifer.foster@dcu.ie": ""
        },
        {
          "alan.cowap2@mail.dcu.ie,": "",
          "jennifer.foster@dcu.ie": "torial explosion of possible distributions and makes"
        },
        {
          "alan.cowap2@mail.dcu.ie,": "tification of its own output and show substan-",
          "jennifer.foster@dcu.ie": ""
        },
        {
          "alan.cowap2@mail.dcu.ie,": "",
          "jennifer.foster@dcu.ie": "the task of synthetic text detection very difficult."
        },
        {
          "alan.cowap2@mail.dcu.ie,": "tial gains, reinforcing the potential of emotion",
          "jennifer.foster@dcu.ie": ""
        },
        {
          "alan.cowap2@mail.dcu.ie,": "",
          "jennifer.foster@dcu.ie": "Furthermore, it is not unexpected that performance"
        },
        {
          "alan.cowap2@mail.dcu.ie,": "as a signal\nto identify synthetic text.\nCode,",
          "jennifer.foster@dcu.ie": ""
        },
        {
          "alan.cowap2@mail.dcu.ie,": "",
          "jennifer.foster@dcu.ie": "decreases when classifying out-of-distribution in-"
        },
        {
          "alan.cowap2@mail.dcu.ie,": "models, and datasets are available at https:",
          "jennifer.foster@dcu.ie": ""
        },
        {
          "alan.cowap2@mail.dcu.ie,": "//github.com/alanagiasi/emoPLMsynth",
          "jennifer.foster@dcu.ie": "stances, and there is a growing field of work inves-"
        },
        {
          "alan.cowap2@mail.dcu.ie,": "",
          "jennifer.foster@dcu.ie": "tigating this shortcoming (Yang et al., 2023)."
        },
        {
          "alan.cowap2@mail.dcu.ie,": "1\nIntroduction",
          "jennifer.foster@dcu.ie": ""
        },
        {
          "alan.cowap2@mail.dcu.ie,": "",
          "jennifer.foster@dcu.ie": "In this work, we consider not only the PLM out-"
        },
        {
          "alan.cowap2@mail.dcu.ie,": "",
          "jennifer.foster@dcu.ie": "put distribution, but also the other side of the syn-"
        },
        {
          "alan.cowap2@mail.dcu.ie,": "Modern PLMs can surpass human-level baselines",
          "jennifer.foster@dcu.ie": ""
        },
        {
          "alan.cowap2@mail.dcu.ie,": "",
          "jennifer.foster@dcu.ie": "thetic text detection coin – human factors. We"
        },
        {
          "alan.cowap2@mail.dcu.ie,": "across several tasks in general language understand-",
          "jennifer.foster@dcu.ie": ""
        },
        {
          "alan.cowap2@mail.dcu.ie,": "",
          "jennifer.foster@dcu.ie": "present a novel approach to the task of synthetic"
        },
        {
          "alan.cowap2@mail.dcu.ie,": "ing (Wang et al., 2018, 2019) and can produce syn-",
          "jennifer.foster@dcu.ie": ""
        },
        {
          "alan.cowap2@mail.dcu.ie,": "",
          "jennifer.foster@dcu.ie": "text detection which aims to exploit any difference"
        },
        {
          "alan.cowap2@mail.dcu.ie,": "thetic text that can exceed human level quality, such",
          "jennifer.foster@dcu.ie": ""
        },
        {
          "alan.cowap2@mail.dcu.ie,": "",
          "jennifer.foster@dcu.ie": "between expression of emotion in human-authored"
        },
        {
          "alan.cowap2@mail.dcu.ie,": "as synthetic propaganda thought to be more plausi-",
          "jennifer.foster@dcu.ie": ""
        },
        {
          "alan.cowap2@mail.dcu.ie,": "",
          "jennifer.foster@dcu.ie": "and synthetic text. Neural word representations can"
        },
        {
          "alan.cowap2@mail.dcu.ie,": "ble than human written propaganda (Zellers et al.,",
          "jennifer.foster@dcu.ie": ""
        },
        {
          "alan.cowap2@mail.dcu.ie,": "",
          "jennifer.foster@dcu.ie": "have difficulty with emotion words, and PLM sam-"
        },
        {
          "alan.cowap2@mail.dcu.ie,": "2019). PLMs have been used to generate disinfor-",
          "jennifer.foster@dcu.ie": ""
        },
        {
          "alan.cowap2@mail.dcu.ie,": "",
          "jennifer.foster@dcu.ie": "pling strategies are stochastic rather than driven by"
        },
        {
          "alan.cowap2@mail.dcu.ie,": "mation (Zellers et al., 2019; Brown et al., 2020),",
          "jennifer.foster@dcu.ie": ""
        },
        {
          "alan.cowap2@mail.dcu.ie,": "",
          "jennifer.foster@dcu.ie": "emotion – we use the term affective deficit to refer"
        },
        {
          "alan.cowap2@mail.dcu.ie,": "left- or right-biased news (Gupta et al., 2020), fake",
          "jennifer.foster@dcu.ie": ""
        },
        {
          "alan.cowap2@mail.dcu.ie,": "comments (Weiss, 2019),\nfake reviews (Adelani",
          "jennifer.foster@dcu.ie": ""
        },
        {
          "alan.cowap2@mail.dcu.ie,": "",
          "jennifer.foster@dcu.ie": "1The news domain is recognised as having high emotional"
        },
        {
          "alan.cowap2@mail.dcu.ie,": "et al., 2019), and plagiarism (Gao et al., 2022) and",
          "jennifer.foster@dcu.ie": "content (Strapparava and Mihalcea, 2007; Bostan et al., 2020)."
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "human-authored text, while the other demonstrates": "affective incoherence (see footnote2 to reveal which"
        },
        {
          "human-authored text, while the other demonstrates": ""
        },
        {
          "human-authored text, while the other demonstrates": "1. Roberts chuckled when asked if he was happy"
        },
        {
          "human-authored text, while the other demonstrates": "to be on the other team now when Puig’s name"
        },
        {
          "human-authored text, while the other demonstrates": "comes up. “Yeah, I am happy,” he said, smil-"
        },
        {
          "human-authored text, while the other demonstrates": "ing."
        },
        {
          "human-authored text, while the other demonstrates": "I’m really happy for him. Over the course of"
        },
        {
          "human-authored text, while the other demonstrates": "those three seasons, the 25-year-old has gone"
        },
        {
          "human-authored text, while the other demonstrates": "from rolling to poor to worse and old."
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "to these shortcomings. Thus, the resulting synthetic": "text can express emotion in an incoherent way, and",
          "models and datasets publicly available to aid future": "research.3"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "we introduce the term affective incoherence to re-",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "2\nRelated Work"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "fer to this type of limitation. To be clear, we do",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "not contend that synthetic text\nis devoid of emo-",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "People are relatively poor at detecting synthetic"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "tion, rather that the emotional content of synthetic",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "text, and have been shown to score just above ran-"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "text may be affectively incoherent, and that\nthis",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "dom chance (Gehrmann et al., 2019; Uchendu et al.,"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "affective incoherence stems from the underlying",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "2021). Hybrid systems, such as GLTR (Gehrmann"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "affective deficit of the PLM.",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "et al., 2019) for example, use automation to provide"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "For the purpose of demonstration of the affec-",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "information to aid human classification, highlight-"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "tive deficit\nthat we believe to be characteristic of",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "ing a text sequence using colours to represent like-"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "text produced by PLMs, we provide the follow-",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "ness to the PLM output distribution such as GPT-2"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "ing simple example of human- versus machine-",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "(Radford et al., 2019). Gehrmann et al.\n(2019)"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "authored text with positive emotion words high-",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "reported an increase in detection accuracy of ap-"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "lighted in orange and negative emotion words in",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "proximately 18% (from 54% to 72%) using GLTR,"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "pink. One shows coherent emotion expected of",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "while Uchendu et al.\n(2021)\nreport an F1 score"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "human-authored text, while the other demonstrates",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "of 46% using GLTR with a heuristic based on an"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "affective incoherence (see footnote2 to reveal which",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "analysis of human text."
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "was synthetic/human-authored text).",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "Both human and hybrid approaches involve hu-"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "1. Roberts chuckled when asked if he was happy",
          "models and datasets publicly available to aid future": "man decisions, which can be slow, expensive, sus-"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "to be on the other team now when Puig’s name",
          "models and datasets publicly available to aid future": "ceptible to bias, and inconsistent. Automatic de-"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "comes up. “Yeah, I am happy,” he said, smil-",
          "models and datasets publicly available to aid future": "tection produces the best results for synthetic text"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "ing.",
          "models and datasets publicly available to aid future": "detection. This usually involves training PLMs to"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "I’m really happy for him. Over the course of\n2.",
          "models and datasets publicly available to aid future": "detect other PLMs, but zero-shot detection meth-"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "those three seasons, the 25-year-old has gone",
          "models and datasets publicly available to aid future": "ods also exist, e.g. DetectGPT (Mitchell et al.,"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "from rolling to poor to worse and old.",
          "models and datasets publicly available to aid future": "2023).\nPotentially the best supervised detector,"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "BERT, can detect synthetic text from 19 different"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "In this simple example, we have demonstrated one",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "generators with a mean F1 of 87.99%, compared"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "kind of affective incoherence present in synthetic",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "to 56.81% for hybrid, and worst of all humans at"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "text but we suspect that fine-tuning an emotionally-",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "53.58% (Uchendu et al., 2021)."
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "aware PLM could detect additional and more com-",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "Performance of SOTA detectors can however"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "plex emotional patterns that might go undetected by",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "be inconsistent and unpredictable due to several"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "humans. We hypothesise that the affective deficit",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "factors specific to both the detector and generator,"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "of PLMs could result\nin synthetic text which is",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "including: model size and architecture,\ntraining"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "affectively incoherent, which could be useful\nin",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "data and domain thereof,\nsampling strategy, hy-"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "distinguishing it from human text.",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "perparameter selection, and sentence length. As"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "We use a transfer learning (Pan and Yang, 2010)",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "mentioned above, Uchendu et al. (2021) showed"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "method to train an “emotionally-aware” detector",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "the best of these models (BERT) achieves a mean"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "model.\nBy fine-tuning a PLM first on emotion",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "F1 of 87.99% on 19 different synthetic text genera-"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "classification and then on our target\ntask of syn-",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "tors. However, the mean score hides the wide range"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "thetic text detection, we demonstrate improvements",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "(≈53%) of F1’s, ranging from as low as 47.01%"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "across a range of synthetic text generators, vari-",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "to 99.97%,\nfor distinct synthetic text generators."
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "ous sized models, datasets and domains. Further-",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "This volatility may be due in part\nto the detector"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "more, our emotionally-aware detector proves to be",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "simply learning artefacts of\nthe generator distri-"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "more accurate at distinguishing between human",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "bution. Consequently,\nthe task of synthetic text"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "and ChatGPT text than (zero-shot) ChatGPT itself.",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "detection is somewhat of an arms race with detec-"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "Finally, we create two new datasets: NEWSsynth,",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "tors playing catch-up, forced to learn ever-changing"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "a dataset of 20k human and synthetic news articles,",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "distributions due to the numerous factors that can"
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "and ChatGPT100, a testset of 100 human and Chat-",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "potentially change those distributions."
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "GPT texts on a range of topics. We make all code,",
          "models and datasets publicly available to aid future": ""
        },
        {
          "to these shortcomings. Thus, the resulting synthetic": "",
          "models and datasets publicly available to aid future": "Existing approaches to synthetic text detection"
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "an inconsistent factual structure, such as mention-": ""
        },
        {
          "an inconsistent factual structure, such as mention-": "ing irrelevant entities (Zhong et al., 2020). Perhaps"
        },
        {
          "an inconsistent factual structure, such as mention-": ""
        },
        {
          "an inconsistent factual structure, such as mention-": "unsurprisingly, synthetic text detection is less diffi-"
        },
        {
          "an inconsistent factual structure, such as mention-": "cult with longer excerpts of generated text, for both"
        },
        {
          "an inconsistent factual structure, such as mention-": "humans and machines (Ippolito et al., 2020)."
        },
        {
          "an inconsistent factual structure, such as mention-": "One aspect of writing that has not, up to now,"
        },
        {
          "an inconsistent factual structure, such as mention-": "been a focus of synthetic text detection efforts is"
        },
        {
          "an inconsistent factual structure, such as mention-": "the expression of emotion.\nThe problem of en-"
        },
        {
          "an inconsistent factual structure, such as mention-": "coding emotion was first identified in neural NLP"
        },
        {
          "an inconsistent factual structure, such as mention-": "with static embeddings such as word2vec (Mikolov"
        },
        {
          "an inconsistent factual structure, such as mention-": "et al., 2013; Wang et al., 2020a). Static word em-"
        },
        {
          "an inconsistent factual structure, such as mention-": "beddings have difficulty distinguishing antonymns"
        },
        {
          "an inconsistent factual structure, such as mention-": "from synonyms (Santus et al., 2014). This deficit"
        },
        {
          "an inconsistent factual structure, such as mention-": "is present\nin embeddings for words which repre-"
        },
        {
          "an inconsistent factual structure, such as mention-": "sent opposing emotions (e.g.\njoy-sadness) (Seyed-"
        },
        {
          "an inconsistent factual structure, such as mention-": "itabari and Zadrozny, 2017). Furthermore, words"
        },
        {
          "an inconsistent factual structure, such as mention-": "representing opposing emotions can have closer"
        },
        {
          "an inconsistent factual structure, such as mention-": ""
        },
        {
          "an inconsistent factual structure, such as mention-": "embeddings relative to words representing similar"
        },
        {
          "an inconsistent factual structure, such as mention-": ""
        },
        {
          "an inconsistent factual structure, such as mention-": "emotions (Agrawal et al., 2018). There have been"
        },
        {
          "an inconsistent factual structure, such as mention-": ""
        },
        {
          "an inconsistent factual structure, such as mention-": "various approaches to address this affective deficit"
        },
        {
          "an inconsistent factual structure, such as mention-": ""
        },
        {
          "an inconsistent factual structure, such as mention-": "in embeddings, such as transfer learning from sen-"
        },
        {
          "an inconsistent factual structure, such as mention-": ""
        },
        {
          "an inconsistent factual structure, such as mention-": "timent analysis (Kratzwald et al., 2018), an addi-"
        },
        {
          "an inconsistent factual structure, such as mention-": ""
        },
        {
          "an inconsistent factual structure, such as mention-": "tional\ntraining phase using an emotional\nlexicon"
        },
        {
          "an inconsistent factual structure, such as mention-": ""
        },
        {
          "an inconsistent factual structure, such as mention-": "and psychological model of emotions (Seyeditabari"
        },
        {
          "an inconsistent factual structure, such as mention-": ""
        },
        {
          "an inconsistent factual structure, such as mention-": "et al., 2019), and combining separately-learned se-"
        },
        {
          "an inconsistent factual structure, such as mention-": ""
        },
        {
          "an inconsistent factual structure, such as mention-": "mantic and sentiment embedding spaces (Wang"
        }
      ],
      "page": 3
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "exploit properties of synthetic text. Synthetic text": "can be incoherent and degrade as the length of",
          "Past work in synthetic text detection has focused": "on the properties of synthetic text generators and is"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "generated text\nincreases (Holtzman et al., 2020),",
          "Past work in synthetic text detection has focused": "yet to take advantage of the factors that potentially"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "perplexity increases with increasing length unlike",
          "Past work in synthetic text detection has focused": "influence human-authored text, such as the emo-"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "human text (Zellers et al., 2019), and PLMs are",
          "Past work in synthetic text detection has focused": "tions humans express in the text\nthey write. Our"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "susceptible to sampling bias,\ninduction bias, and",
          "Past work in synthetic text detection has focused": "work exploits this PLM affective deficit to improve"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "exposure bias\n(Ranzato et al., 2016). For example,",
          "Past work in synthetic text detection has focused": "synthetic text detection."
        },
        {
          "exploit properties of synthetic text. Synthetic text": "exposure bias can contribute to brittle text which",
          "Past work in synthetic text detection has focused": ""
        },
        {
          "exploit properties of synthetic text. Synthetic text": "",
          "Past work in synthetic text detection has focused": "3\nEquipping PLMs with Emotional"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "is repetitive, incoherent, even containing hallucina-",
          "Past work in synthetic text detection has focused": ""
        },
        {
          "exploit properties of synthetic text. Synthetic text": "",
          "Past work in synthetic text detection has focused": "Intelligence"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "tions (Arora et al., 2022). Synthetic text can have",
          "Past work in synthetic text detection has focused": ""
        },
        {
          "exploit properties of synthetic text. Synthetic text": "an inconsistent factual structure, such as mention-",
          "Past work in synthetic text detection has focused": ""
        },
        {
          "exploit properties of synthetic text. Synthetic text": "",
          "Past work in synthetic text detection has focused": "Our method is illustrated in Figure 1. The process"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "ing irrelevant entities (Zhong et al., 2020). Perhaps",
          "Past work in synthetic text detection has focused": ""
        },
        {
          "exploit properties of synthetic text. Synthetic text": "",
          "Past work in synthetic text detection has focused": "works as follows:"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "unsurprisingly, synthetic text detection is less diffi-",
          "Past work in synthetic text detection has focused": ""
        },
        {
          "exploit properties of synthetic text. Synthetic text": "cult with longer excerpts of generated text, for both",
          "Past work in synthetic text detection has focused": "1. PLMSYNTH:\nIn\nthe\nleftmost\ncolumn\nof"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "humans and machines (Ippolito et al., 2020).",
          "Past work in synthetic text detection has focused": "Figure 1, human articles and synthetic articles"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "One aspect of writing that has not, up to now,",
          "Past work in synthetic text detection has focused": "are used to fine-tune a PLM to discriminate"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "been a focus of synthetic text detection efforts is",
          "Past work in synthetic text detection has focused": "between\nthe\ntwo\nkinds\nof\ntext.\nThis\nis"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "the expression of emotion.\nThe problem of en-",
          "Past work in synthetic text detection has focused": "indicated\nby\nthe\nblue\nnodes\nin\nthe PLM"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "coding emotion was first identified in neural NLP",
          "Past work in synthetic text detection has focused": "illustration."
        },
        {
          "exploit properties of synthetic text. Synthetic text": "with static embeddings such as word2vec (Mikolov",
          "Past work in synthetic text detection has focused": "2. EMOPLM: In the middle column of Figure"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "et al., 2013; Wang et al., 2020a). Static word em-",
          "Past work in synthetic text detection has focused": "1, a second dataset annotated for emotions"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "beddings have difficulty distinguishing antonymns",
          "Past work in synthetic text detection has focused": "with Ekman’s\n6\nemotions\n(Ekman,\n1992,"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "from synonyms (Santus et al., 2014). This deficit",
          "Past work in synthetic text detection has focused": "1999,\n2016)\nis\nused\nto fine-tune\na PLM"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "is present\nin embeddings for words which repre-",
          "Past work in synthetic text detection has focused": "on the task of emotion classification.\nThis"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "sent opposing emotions (e.g.\njoy-sadness) (Seyed-",
          "Past work in synthetic text detection has focused": "makes our model emotionally-aware, as indi-"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "itabari and Zadrozny, 2017). Furthermore, words",
          "Past work in synthetic text detection has focused": "cated by the red nodes in the PLM illustration."
        },
        {
          "exploit properties of synthetic text. Synthetic text": "representing opposing emotions can have closer",
          "Past work in synthetic text detection has focused": ""
        },
        {
          "exploit properties of synthetic text. Synthetic text": "",
          "Past work in synthetic text detection has focused": "3. EMOPLMSYNTH: The multi-class (6 head)"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "embeddings relative to words representing similar",
          "Past work in synthetic text detection has focused": ""
        },
        {
          "exploit properties of synthetic text. Synthetic text": "",
          "Past work in synthetic text detection has focused": "classification layer from emoPLM is removed"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "emotions (Agrawal et al., 2018). There have been",
          "Past work in synthetic text detection has focused": ""
        },
        {
          "exploit properties of synthetic text. Synthetic text": "",
          "Past work in synthetic text detection has focused": "and replaced with a binary classification layer."
        },
        {
          "exploit properties of synthetic text. Synthetic text": "various approaches to address this affective deficit",
          "Past work in synthetic text detection has focused": ""
        },
        {
          "exploit properties of synthetic text. Synthetic text": "",
          "Past work in synthetic text detection has focused": "The\nemotionally-aware PLM is\nthen fine-"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "in embeddings, such as transfer learning from sen-",
          "Past work in synthetic text detection has focused": ""
        },
        {
          "exploit properties of synthetic text. Synthetic text": "",
          "Past work in synthetic text detection has focused": "tuned on the task of discriminating between"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "timent analysis (Kratzwald et al., 2018), an addi-",
          "Past work in synthetic text detection has focused": ""
        },
        {
          "exploit properties of synthetic text. Synthetic text": "",
          "Past work in synthetic text detection has focused": "human and synthetic articles. The PLM is still"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "tional\ntraining phase using an emotional\nlexicon",
          "Past work in synthetic text detection has focused": ""
        },
        {
          "exploit properties of synthetic text. Synthetic text": "",
          "Past work in synthetic text detection has focused": "emotionally-aware while also being able to"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "and psychological model of emotions (Seyeditabari",
          "Past work in synthetic text detection has focused": ""
        },
        {
          "exploit properties of synthetic text. Synthetic text": "",
          "Past work in synthetic text detection has focused": "detect synthetic text - as indicated by the red"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "et al., 2019), and combining separately-learned se-",
          "Past work in synthetic text detection has focused": ""
        },
        {
          "exploit properties of synthetic text. Synthetic text": "",
          "Past work in synthetic text detection has focused": "and blue nodes respectively in the PLM."
        },
        {
          "exploit properties of synthetic text. Synthetic text": "mantic and sentiment embedding spaces (Wang",
          "Past work in synthetic text detection has focused": ""
        },
        {
          "exploit properties of synthetic text. Synthetic text": "et al., 2020a).",
          "Past work in synthetic text detection has focused": "We conduct experiments using various PLM"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "Addressing potential affective deficits of PLMs",
          "Past work in synthetic text detection has focused": "sizes, architectures, datasets, and domains for syn-"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "is also the goal of work aiming to make dialogue",
          "Past work in synthetic text detection has focused": "thetic text generation and detection."
        },
        {
          "exploit properties of synthetic text. Synthetic text": "systems more empathetic. For example Huang et al.",
          "Past work in synthetic text detection has focused": ""
        },
        {
          "exploit properties of synthetic text. Synthetic text": "",
          "Past work in synthetic text detection has focused": "4\nNews Domain Experiments"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "(2018) force dialogue generation to express emo-",
          "Past work in synthetic text detection has focused": ""
        },
        {
          "exploit properties of synthetic text. Synthetic text": "tion based on the emotion detected in an utterance,",
          "Past work in synthetic text detection has focused": ""
        },
        {
          "exploit properties of synthetic text. Synthetic text": "",
          "Past work in synthetic text detection has focused": "4.1\nGenerator and Detector Models"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "while Rashkin et al.\n(2019)\nfollow a similar ap-",
          "Past work in synthetic text detection has focused": ""
        },
        {
          "exploit properties of synthetic text. Synthetic text": "",
          "Past work in synthetic text detection has focused": "To generate synthetic text, we use the Grover causal"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "proach with a transformer architecture to make",
          "Past work in synthetic text detection has focused": ""
        },
        {
          "exploit properties of synthetic text. Synthetic text": "",
          "Past work in synthetic text detection has focused": "PLM (GPT-2 architecture) pretrained on 32M news"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "the system more empathetic.\nIn contrast, Wang",
          "Past work in synthetic text detection has focused": ""
        },
        {
          "exploit properties of synthetic text. Synthetic text": "",
          "Past work in synthetic text detection has focused": "articles from the RealNews dataset (Zellers et al.,"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "et al. (2020b) report\nthat human text can display",
          "Past work in synthetic text detection has focused": ""
        },
        {
          "exploit properties of synthetic text. Synthetic text": "",
          "Past work in synthetic text detection has focused": "2019). We choose BERT (Devlin et al., 2019) as"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "consistency in emotional content whereby similar",
          "Past work in synthetic text detection has focused": ""
        },
        {
          "exploit properties of synthetic text. Synthetic text": "",
          "Past work in synthetic text detection has focused": "our main detector model since it is freely available"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "emotions tend to occur adjacent to each other while",
          "Past work in synthetic text detection has focused": ""
        },
        {
          "exploit properties of synthetic text. Synthetic text": "",
          "Past work in synthetic text detection has focused": "and performs well\nin several\ntasks including se-"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "dissimilar emotions seldom do.4",
          "Past work in synthetic text detection has focused": ""
        },
        {
          "exploit properties of synthetic text. Synthetic text": "",
          "Past work in synthetic text detection has focused": "quence classification. A baseline BERT model (we"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "4For a comprehensive survey of sentiment control in syn-",
          "Past work in synthetic text detection has focused": ""
        },
        {
          "exploit properties of synthetic text. Synthetic text": "",
          "Past work in synthetic text detection has focused": "call\nthis BERTsynth) is fine-tuned on the task of"
        },
        {
          "exploit properties of synthetic text. Synthetic text": "thetic text see (Lorandi and Belz, 2023) and for studies of",
          "Past work in synthetic text detection has focused": ""
        },
        {
          "exploit properties of synthetic text. Synthetic text": "emotion in human writing,\nsee (Brand, 1985, 1987, 1991;",
          "Past work in synthetic text detection has focused": "Bohn-Gettler and Rapp, 2014; Knaller, 2017)."
        }
      ],
      "page": 3
    },
    {
      "caption": "Table 1: and Figure 3 in Appendix A – resulting",
      "data": [
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "improve performance on the task of synthetic text detection.",
          "takes advantage of\nits prior fine-tuning on emotion to": "In contrast,\nthe standard PLM fine-tuned only on"
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "synthetic text detection (PLMsynth) has no training on emotion. Our experiments show the emotionally-aware PLM",
          "takes advantage of\nits prior fine-tuning on emotion to": ""
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "(emoPLMLsynth) outperforms the standard PLM (PLMsynth) in multiple scenarios.",
          "takes advantage of\nits prior fine-tuning on emotion to": ""
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "synthetic text detection, while our proposed model",
          "takes advantage of\nits prior fine-tuning on emotion to": "generated by a larger generator model, and against"
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "is the same BERT model, firstly fine-tuned on emo-",
          "takes advantage of\nits prior fine-tuning on emotion to": "results reported for other models on this dataset."
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "tion classification (we call this intermediate model",
          "takes advantage of\nits prior fine-tuning on emotion to": ""
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "",
          "takes advantage of\nits prior fine-tuning on emotion to": "We use the GoodNewsEveryone dataset (Bostan"
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "emoBERT) before further fine-tuning for synthetic",
          "takes advantage of\nits prior fine-tuning on emotion to": ""
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "",
          "takes advantage of\nits prior fine-tuning on emotion to": "et al., 2020)\nto train emoBERT. This dataset con-"
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "text detection. This final proposed model is referred",
          "takes advantage of\nits prior fine-tuning on emotion to": ""
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "",
          "takes advantage of\nits prior fine-tuning on emotion to": "tains 5k news headlines, and was chosen since it is"
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "to as emoBERTsynth.",
          "takes advantage of\nits prior fine-tuning on emotion to": ""
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "",
          "takes advantage of\nits prior fine-tuning on emotion to": "within the target domain (news) and language (En-"
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "",
          "takes advantage of\nits prior fine-tuning on emotion to": "glish) and is annotated with categorical emotions."
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "4.2\nDatasets",
          "takes advantage of\nits prior fine-tuning on emotion to": ""
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "",
          "takes advantage of\nits prior fine-tuning on emotion to": "The 15 emotion labels from GoodNewsEveryone"
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "",
          "takes advantage of\nits prior fine-tuning on emotion to": "were reduced to 11 emotions using the mapping"
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "We create and release NEWSsynth, a dataset con-",
          "takes advantage of\nits prior fine-tuning on emotion to": ""
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "",
          "takes advantage of\nits prior fine-tuning on emotion to": "schema of\n(Bostan and Klinger, 2018), and fur-"
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "taining 10k human and 10k synthetic news articles.",
          "takes advantage of\nits prior fine-tuning on emotion to": ""
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "",
          "takes advantage of\nits prior fine-tuning on emotion to": "ther reduced to 6 emotions based on the Plutchik"
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "10k human-authored news articles were taken from",
          "takes advantage of\nits prior fine-tuning on emotion to": ""
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "",
          "takes advantage of\nits prior fine-tuning on emotion to": "Wheel of Emotion (Plutchik, 1980, 2001) – see"
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "the RealNews-Test dataset (Zellers et al., 2019) and",
          "takes advantage of\nits prior fine-tuning on emotion to": ""
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "",
          "takes advantage of\nits prior fine-tuning on emotion to": "Table 1 and Figure 3 in Appendix A – resulting"
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "used as a prompt to Groverbase to generate a cor-",
          "takes advantage of\nits prior fine-tuning on emotion to": ""
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "",
          "takes advantage of\nits prior fine-tuning on emotion to": "in 5k news headlines labelled with Ekman’s 6 ba-"
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "responding 10k synthetic articles. The prompt in-",
          "takes advantage of\nits prior fine-tuning on emotion to": ""
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "",
          "takes advantage of\nits prior fine-tuning on emotion to": "sic emotions, the most frequently used categorical"
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "cludes the news article, headline, date, author, web",
          "takes advantage of\nits prior fine-tuning on emotion to": ""
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "",
          "takes advantage of\nits prior fine-tuning on emotion to": "emotion model\nin psychology literature (Ekman,"
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "domain etc. as described by Zellers et al. (2019).",
          "takes advantage of\nits prior fine-tuning on emotion to": ""
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "",
          "takes advantage of\nits prior fine-tuning on emotion to": "1992, 1999, 2016)."
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "The dataset was split 10k-2k-8k for train, valida-",
          "takes advantage of\nits prior fine-tuning on emotion to": ""
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "tion, and test respectively, the same ratio used by",
          "takes advantage of\nits prior fine-tuning on emotion to": ""
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "Zellers et al. (2019) with 50:50 human:synthetic",
          "takes advantage of\nits prior fine-tuning on emotion to": ""
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "text in each split, see Appendix B.3 for details. An",
          "takes advantage of\nits prior fine-tuning on emotion to": "4.3\nTraining BERTsynth"
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "investigation of length of human vs synthetic text",
          "takes advantage of\nits prior fine-tuning on emotion to": ""
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "is provided in Appendix E.",
          "takes advantage of\nits prior fine-tuning on emotion to": ""
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "",
          "takes advantage of\nits prior fine-tuning on emotion to": "We\na\nBERTbase-cased model"
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "In\na\nsecond\nexperiment,\nwe\nalso\nuse\nthe",
          "takes advantage of\nits prior fine-tuning on emotion to": "fine-tuned for synthetic text detection (using the"
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "full RealNews-Test\ndataset\nitself, which\ncom-",
          "takes advantage of\nits prior fine-tuning on emotion to": "NEWSsynth or RealNews-Test dataset).\nInput se-"
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "prises the same 10k human news articles used in",
          "takes advantage of\nits prior fine-tuning on emotion to": "quence length was maintained at\nthe BERT max-"
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "NEWSsynth and 10k synthetic articles generated",
          "takes advantage of\nits prior fine-tuning on emotion to": "imum of 512 tokens (≈ 384 words).\nFive train-"
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "by Grovermega. The use of synthetic text generated",
          "takes advantage of\nits prior fine-tuning on emotion to": "ing runs were conducted. Each training run was 4"
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "by Grovermega instead of Groverbase allows com-",
          "takes advantage of\nits prior fine-tuning on emotion to": "epochs – the most possible within GPU time con-"
        },
        {
          "Figure 1: The emotionally-aware PLM (emoPLMsynth)": "parison of BERTsynth and emoBERTsynth on text",
          "takes advantage of\nits prior fine-tuning on emotion to": "straints and similar to those of Zellers et al. (2019)"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table 2: show the per-",
      "data": [
        {
          "GoodNewsEveryone\nEkman": "→",
          "4.5\nTraining emoBERTsynth": ""
        },
        {
          "GoodNewsEveryone\nEkman": "disgust\ndisgust (8%)",
          "4.5\nTraining emoBERTsynth": "We train emoBERTsynth, an emoBERT model fine-"
        },
        {
          "GoodNewsEveryone\nEkman": "→\nfear\nfear (8%)",
          "4.5\nTraining emoBERTsynth": "tuned\nfor\nsynthetic\ntext\ndetection\n(using\nthe"
        },
        {
          "GoodNewsEveryone\nEkman": "→\nsadness, guilt, shame\nsadness (14%)",
          "4.5\nTraining emoBERTsynth": "NEWSsynth or RealNews-Test dataset). The best"
        },
        {
          "GoodNewsEveryone\nEkman": "→\njoy, trust, pride, love/like, posi-\nhappiness",
          "4.5\nTraining emoBERTsynth": "emoBERT model (checkpoint) from each of the 5"
        },
        {
          "GoodNewsEveryone\nEkman": "tive anticipation/optimism\n(17%)",
          "4.5\nTraining emoBERTsynth": ""
        },
        {
          "GoodNewsEveryone\nEkman": "",
          "4.5\nTraining emoBERTsynth": "training runs had its emotion classification head"
        },
        {
          "GoodNewsEveryone\nEkman": "",
          "4.5\nTraining emoBERTsynth": "(6 outputs)\nreplaced with a binary classification"
        },
        {
          "GoodNewsEveryone\nEkman": "→\nanger, annoyance, negative an-\nanger (24%)",
          "4.5\nTraining emoBERTsynth": ""
        },
        {
          "GoodNewsEveryone\nEkman": "",
          "4.5\nTraining emoBERTsynth": "head (2 outputs) for human vs synthetic text clas-"
        },
        {
          "GoodNewsEveryone\nEkman": "ticipation/pessimism",
          "4.5\nTraining emoBERTsynth": ""
        },
        {
          "GoodNewsEveryone\nEkman": "",
          "4.5\nTraining emoBERTsynth": "sification, see Figure 1. Each model was then fine-"
        },
        {
          "GoodNewsEveryone\nEkman": "→\nnegative surprise, positive sur-\nsurprise (30%)",
          "4.5\nTraining emoBERTsynth": ""
        },
        {
          "GoodNewsEveryone\nEkman": "",
          "4.5\nTraining emoBERTsynth": "tuned on the synthetic text detection task using the"
        },
        {
          "GoodNewsEveryone\nEkman": "prise",
          "4.5\nTraining emoBERTsynth": ""
        },
        {
          "GoodNewsEveryone\nEkman": "",
          "4.5\nTraining emoBERTsynth": "exact same process and set of random seeds (for"
        },
        {
          "GoodNewsEveryone\nEkman": "Table 1: Emotion Mapping Schema: GoodNewsEvery-",
          "4.5\nTraining emoBERTsynth": "dataset shuffling) as the 5 best models described"
        },
        {
          "GoodNewsEveryone\nEkman": "one (15 emotions) to Ekman 6 basic emotions. % shows",
          "4.5\nTraining emoBERTsynth": "in §4.3. This allowed a direct comparison between"
        },
        {
          "GoodNewsEveryone\nEkman": "the emotion label distribution in the dataset.",
          "4.5\nTraining emoBERTsynth": ""
        },
        {
          "GoodNewsEveryone\nEkman": "",
          "4.5\nTraining emoBERTsynth": "the 5 BERTsynth models (trained on synthetic text"
        },
        {
          "GoodNewsEveryone\nEkman": "",
          "4.5\nTraining emoBERTsynth": "detection only) and the 5 emoBERTsynth models"
        },
        {
          "GoodNewsEveryone\nEkman": "",
          "4.5\nTraining emoBERTsynth": "(fine-tuned on emotion classification followed by"
        },
        {
          "GoodNewsEveryone\nEkman": "who used 5 epochs.5 For each training run, a unique",
          "4.5\nTraining emoBERTsynth": ""
        },
        {
          "GoodNewsEveryone\nEkman": "",
          "4.5\nTraining emoBERTsynth": "synthetic text detection)."
        },
        {
          "GoodNewsEveryone\nEkman": "seed was used for model initialization, and a unique",
          "4.5\nTraining emoBERTsynth": ""
        },
        {
          "GoodNewsEveryone\nEkman": "set of three seeds were used for the dataset shuffle -",
          "4.5\nTraining emoBERTsynth": "4.6\nResults"
        },
        {
          "GoodNewsEveryone\nEkman": "one seed each for train, validation, and test splits.",
          "4.5\nTraining emoBERTsynth": ""
        },
        {
          "GoodNewsEveryone\nEkman": "",
          "4.5\nTraining emoBERTsynth": "The results in Figure 2 and Table 2 show the per-"
        },
        {
          "GoodNewsEveryone\nEkman": "Furthermore, the HuggingFace library shuffles the",
          "4.5\nTraining emoBERTsynth": ""
        },
        {
          "GoodNewsEveryone\nEkman": "",
          "4.5\nTraining emoBERTsynth": "formance of BERTsynth and emoBERTsynth when"
        },
        {
          "GoodNewsEveryone\nEkman": "training data between epochs. The reproducibility",
          "4.5\nTraining emoBERTsynth": ""
        },
        {
          "GoodNewsEveryone\nEkman": "",
          "4.5\nTraining emoBERTsynth": "fine-tuned on the NEWSsynth dataset. The results"
        },
        {
          "GoodNewsEveryone\nEkman": "of the training and validation results using seeds",
          "4.5\nTraining emoBERTsynth": ""
        },
        {
          "GoodNewsEveryone\nEkman": "",
          "4.5\nTraining emoBERTsynth": "support\nthe hypothesis that emotion can help de-"
        },
        {
          "GoodNewsEveryone\nEkman": "was verified by conducting multiple runs of training",
          "4.5\nTraining emoBERTsynth": ""
        },
        {
          "GoodNewsEveryone\nEkman": "",
          "4.5\nTraining emoBERTsynth": "tect\nsynthetic text.\nemoBERTsynth outperforms"
        },
        {
          "GoodNewsEveryone\nEkman": "and validation. Hyperparameter values are listed in",
          "4.5\nTraining emoBERTsynth": ""
        },
        {
          "GoodNewsEveryone\nEkman": "",
          "4.5\nTraining emoBERTsynth": "BERTsynth in head-to-head for accuracy and F1"
        },
        {
          "GoodNewsEveryone\nEkman": "Appendix C.",
          "4.5\nTraining emoBERTsynth": ""
        },
        {
          "GoodNewsEveryone\nEkman": "",
          "4.5\nTraining emoBERTsynth": "in all 5 runs."
        },
        {
          "GoodNewsEveryone\nEkman": "",
          "4.5\nTraining emoBERTsynth": "Looking at precision and recall, emoBERTsynth"
        },
        {
          "GoodNewsEveryone\nEkman": "4.4\nTraining emoBERT",
          "4.5\nTraining emoBERTsynth": "outperforms BERTsynth in precision in all 5 runs,"
        },
        {
          "GoodNewsEveryone\nEkman": "",
          "4.5\nTraining emoBERTsynth": "while the opposite is the case for recall. It is worth"
        },
        {
          "GoodNewsEveryone\nEkman": "We train emoBERT, a BERTbase-cased model fine-",
          "4.5\nTraining emoBERTsynth": ""
        },
        {
          "GoodNewsEveryone\nEkman": "tuned on the single label multiclass task of emo-",
          "4.5\nTraining emoBERTsynth": ""
        },
        {
          "GoodNewsEveryone\nEkman": "tion classification using the GoodNewsEveryone",
          "4.5\nTraining emoBERTsynth": ""
        },
        {
          "GoodNewsEveryone\nEkman": "dataset. Fine-tuning emoBERT followed a similar",
          "4.5\nTraining emoBERTsynth": ""
        },
        {
          "GoodNewsEveryone\nEkman": "process to fine-tuning BERTsynth described in §4.3.",
          "4.5\nTraining emoBERTsynth": ""
        },
        {
          "GoodNewsEveryone\nEkman": "This time, there were 5k examples and fine-tuning",
          "4.5\nTraining emoBERTsynth": ""
        },
        {
          "GoodNewsEveryone\nEkman": "was for 10 epochs.",
          "4.5\nTraining emoBERTsynth": ""
        },
        {
          "GoodNewsEveryone\nEkman": "Classification accuracy is not\nthe end goal for",
          "4.5\nTraining emoBERTsynth": ""
        },
        {
          "GoodNewsEveryone\nEkman": "emoBERT.\nIts purpose is\nto reduce the affective",
          "4.5\nTraining emoBERTsynth": ""
        },
        {
          "GoodNewsEveryone\nEkman": "deficit of\nthe PLM by modifying the representa-",
          "4.5\nTraining emoBERTsynth": ""
        },
        {
          "GoodNewsEveryone\nEkman": "tions of words conveying emotions and to improve",
          "4.5\nTraining emoBERTsynth": ""
        },
        {
          "GoodNewsEveryone\nEkman": "performance in the task of synthetic text detection",
          "4.5\nTraining emoBERTsynth": ""
        },
        {
          "GoodNewsEveryone\nEkman": "by transfer learning. The mean F1µ for emoBERT",
          "4.5\nTraining emoBERTsynth": ""
        },
        {
          "GoodNewsEveryone\nEkman": "",
          "4.5\nTraining emoBERTsynth": "BERTsynth\nFigure\n2:\nTest\nresults\nfor\nand"
        },
        {
          "GoodNewsEveryone\nEkman": "is 39.4% on the Validation set - more than double",
          "4.5\nTraining emoBERTsynth": ""
        },
        {
          "GoodNewsEveryone\nEkman": "",
          "4.5\nTraining emoBERTsynth": "emoBERTsynth\nNEWSsynth\non\nthe\ndataset."
        },
        {
          "GoodNewsEveryone\nEkman": "mean chance (16.7%) and within the range 31% to",
          "4.5\nTraining emoBERTsynth": "emoBERTsynth"
        },
        {
          "GoodNewsEveryone\nEkman": "",
          "4.5\nTraining emoBERTsynth": "is\nhigher\nfor Accuracy,\nPrecision"
        },
        {
          "GoodNewsEveryone\nEkman": "98% reported for within-corpus emotion classifica-",
          "4.5\nTraining emoBERTsynth": "and F1, while BERTsynth is higher for Recall."
        },
        {
          "GoodNewsEveryone\nEkman": "tion in UnifiedEmotion (Bostan and Klinger, 2018).",
          "4.5\nTraining emoBERTsynth": ""
        },
        {
          "GoodNewsEveryone\nEkman": "See Appendix D for more details.",
          "4.5\nTraining emoBERTsynth": "comparing the\nrelative difference\nin recall\nand"
        },
        {
          "GoodNewsEveryone\nEkman": "",
          "4.5\nTraining emoBERTsynth": "precision between emoBERTsynth and BERTsynth"
        },
        {
          "GoodNewsEveryone\nEkman": "5After each epoch the model (checkpoint) was run against",
          "4.5\nTraining emoBERTsynth": "models in Table 2. emoBERTsynth has a difference"
        },
        {
          "GoodNewsEveryone\nEkman": "the validation set for Accuracy, and the checkpoint and Ac-",
          "4.5\nTraining emoBERTsynth": ""
        },
        {
          "GoodNewsEveryone\nEkman": "",
          "4.5\nTraining emoBERTsynth": "between the mean recall and mean precision of 4.76"
        },
        {
          "GoodNewsEveryone\nEkman": "curacy results were saved (in addition to F1, Precision and",
          "4.5\nTraining emoBERTsynth": ""
        },
        {
          "GoodNewsEveryone\nEkman": "",
          "4.5\nTraining emoBERTsynth": "(89.04 - 84.28) while the difference for BERTsynth"
        },
        {
          "GoodNewsEveryone\nEkman": "Recall). The checkpoint with the highest Accuracy score was",
          "4.5\nTraining emoBERTsynth": ""
        },
        {
          "GoodNewsEveryone\nEkman": "then run on the Test set.",
          "4.5\nTraining emoBERTsynth": "is more than double that at 10.81 (91.63 - 80.82)."
        }
      ],
      "page": 5
    },
    {
      "caption": "Table 3: we compare BERTsynth and forprediction.",
      "data": [
        {
          "Precision": "Bs",
          "Recall": "Bs",
          "F1": "Bs",
          "Accuracy": "emoBs"
        },
        {
          "Precision": "80.30",
          "Recall": "92.40",
          "F1": "85.92",
          "Accuracy": "85.46"
        },
        {
          "Precision": "82.26",
          "Recall": "90.90",
          "F1": "86.37",
          "Accuracy": "86.55"
        },
        {
          "Precision": "78.01",
          "Recall": "92.40",
          "F1": "84.60",
          "Accuracy": "84.99"
        },
        {
          "Precision": "77.44",
          "Recall": "94.85",
          "F1": "85.27",
          "Accuracy": "86.83"
        },
        {
          "Precision": "86.09",
          "Recall": "87.58",
          "F1": "86.83",
          "Accuracy": "86.98"
        },
        {
          "Precision": "80.82",
          "Recall": "91.63",
          "F1": "85.80",
          "Accuracy": "86.16"
        },
        {
          "Precision": "(9.89)",
          "Recall": "(5.70)",
          "F1": "(0.62)",
          "Accuracy": "(0.63)"
        }
      ],
      "page": 6
    },
    {
      "caption": "Table 3: we compare BERTsynth and forprediction.",
      "data": [
        {
          "the standard PLM, BERTsynth, because it has a": "better balance between precision and recall.",
          "that extended input\nlength and the model may in": "fact be somewhat reliant on those later input tokens"
        },
        {
          "the standard PLM, BERTsynth, because it has a": "BERTsynth\nIn\nTable\n3\nwe\ncompare\nand",
          "that extended input\nlength and the model may in": "for prediction."
        },
        {
          "the standard PLM, BERTsynth, because it has a": "emoBERTsynth\non\nthe RealNews-Test\ndataset.",
          "that extended input\nlength and the model may in": ""
        },
        {
          "the standard PLM, BERTsynth, because it has a": "Recall\nthat\nthis\ndataset\ncontains\nsynthetic\nar-",
          "that extended input\nlength and the model may in": "Size\nModel\nAcc."
        },
        {
          "the standard PLM, BERTsynth, because it has a": "ticles\ngenerated\nby\ninstead\nof\nthe\nGrovermega",
          "that extended input\nlength and the model may in": ""
        },
        {
          "the standard PLM, BERTsynth, because it has a": "",
          "that extended input\nlength and the model may in": "11M\nFastText\n63.80"
        },
        {
          "the standard PLM, BERTsynth, because it has a": "We\nalso compare\nagainst\nsmaller Groverbase.",
          "that extended input\nlength and the model may in": ""
        },
        {
          "the standard PLM, BERTsynth, because it has a": "",
          "that extended input\nlength and the model may in": "124M\n66.20\nGPT-2base"
        },
        {
          "the standard PLM, BERTsynth, because it has a": "the FastText, GPT-2 and BERT detector models",
          "that extended input\nlength and the model may in": ""
        },
        {
          "the standard PLM, BERTsynth, because it has a": "",
          "that extended input\nlength and the model may in": "67.20\nBERTbase"
        },
        {
          "the standard PLM, BERTsynth, because it has a": "reported by Zellers et al.\n(2019) on this dataset.",
          "that extended input\nlength and the model may in": ""
        },
        {
          "the standard PLM, BERTsynth, because it has a": "",
          "that extended input\nlength and the model may in": "BERTsynth\n74.83"
        },
        {
          "the standard PLM, BERTsynth, because it has a": "emoBERTsynth has the highest accuracy, outper-",
          "that extended input\nlength and the model may in": ""
        },
        {
          "the standard PLM, BERTsynth, because it has a": "",
          "that extended input\nlength and the model may in": "76.23\nemoBERTsynth"
        },
        {
          "the standard PLM, BERTsynth, because it has a": "forming BERTsynth by 1.4%, BERTbase by 9.03%,",
          "that extended input\nlength and the model may in": ""
        },
        {
          "the standard PLM, BERTsynth, because it has a": "GPT-2base by 10.03%, and FastText by 12.43%.",
          "that extended input\nlength and the model may in": ""
        }
      ],
      "page": 6
    },
    {
      "caption": "Table 3: we compare BERTsynth and forprediction.",
      "data": [
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "Var.\n(9.89)\n(4.35)\n(5.70)\n(3.45)",
          "87.11\n86.16\n85.80\n84.80": "(0.62)\n(2.08)\n(1.68)\n(0.63)"
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "∆\n+3.46\n-2.59",
          "87.11\n86.16\n85.80\n84.80": "+1.31\n+1.36"
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "Table 2: Comparison of BERTsynth (Bs) and emoBERTsynth (emoBs) against the NEWSsynth test set. (Variance",
          "87.11\n86.16\n85.80\n84.80": ""
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "is shown in brackets under the mean). emoBs outperforms Bs in head-to-head for all 5 runs in Accuracy, F1, and",
          "87.11\n86.16\n85.80\n84.80": ""
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "Precision; while Bs outperforms emoBs in head-to-head for all 5 runs in Recall.",
          "87.11\n86.16\n85.80\n84.80": ""
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "Thus, we suggest our emotionally-aware PLM,",
          "87.11\n86.16\n85.80\n84.80": "thetic news articles in RealNews-Test are shorter"
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "emoBERTsynth, is a better performing model than",
          "87.11\n86.16\n85.80\n84.80": "than 1024 tokens. Thus, they may not benefit from"
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "the standard PLM, BERTsynth, because it has a",
          "87.11\n86.16\n85.80\n84.80": "that extended input\nlength and the model may in"
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "better balance between precision and recall.",
          "87.11\n86.16\n85.80\n84.80": "fact be somewhat reliant on those later input tokens"
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "BERTsynth\nIn\nTable\n3\nwe\ncompare\nand",
          "87.11\n86.16\n85.80\n84.80": "for prediction."
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "emoBERTsynth\non\nthe RealNews-Test\ndataset.",
          "87.11\n86.16\n85.80\n84.80": ""
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "Recall\nthat\nthis\ndataset\ncontains\nsynthetic\nar-",
          "87.11\n86.16\n85.80\n84.80": "Size\nModel\nAcc."
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "ticles\ngenerated\nby\ninstead\nof\nthe\nGrovermega",
          "87.11\n86.16\n85.80\n84.80": ""
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "",
          "87.11\n86.16\n85.80\n84.80": "11M\nFastText\n63.80"
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "We\nalso compare\nagainst\nsmaller Groverbase.",
          "87.11\n86.16\n85.80\n84.80": ""
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "",
          "87.11\n86.16\n85.80\n84.80": "124M\n66.20\nGPT-2base"
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "the FastText, GPT-2 and BERT detector models",
          "87.11\n86.16\n85.80\n84.80": ""
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "",
          "87.11\n86.16\n85.80\n84.80": "67.20\nBERTbase"
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "reported by Zellers et al.\n(2019) on this dataset.",
          "87.11\n86.16\n85.80\n84.80": ""
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "",
          "87.11\n86.16\n85.80\n84.80": "BERTsynth\n74.83"
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "emoBERTsynth has the highest accuracy, outper-",
          "87.11\n86.16\n85.80\n84.80": ""
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "",
          "87.11\n86.16\n85.80\n84.80": "76.23\nemoBERTsynth"
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "forming BERTsynth by 1.4%, BERTbase by 9.03%,",
          "87.11\n86.16\n85.80\n84.80": ""
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "GPT-2base by 10.03%, and FastText by 12.43%.",
          "87.11\n86.16\n85.80\n84.80": ""
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "",
          "87.11\n86.16\n85.80\n84.80": "Table 3:\nemoBERTsynth outperforms other model ar-"
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "These results support the hypothesis that emotion",
          "87.11\n86.16\n85.80\n84.80": ""
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "",
          "87.11\n86.16\n85.80\n84.80": "chitectures and sizes detecting human and Grovermega"
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "can improve synthetic text detection.",
          "87.11\n86.16\n85.80\n84.80": ""
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "",
          "87.11\n86.16\n85.80\n84.80": "(1.5B) synthetic text from the RealNews-Test dataset."
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "There is a 7.63 point difference between our",
          "87.11\n86.16\n85.80\n84.80": ""
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "",
          "87.11\n86.16\n85.80\n84.80": "Detector model sizes include 11M and 124M parame-"
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "BERTsynth model and the BERT model reported",
          "87.11\n86.16\n85.80\n84.80": "ters and architectures include FastText, GPT-2base, and"
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "by Zellers et al. (2019), despite both models be-",
          "87.11\n86.16\n85.80\n84.80": "and\nBERTbase. The FastText,\nGPT-2base\nBERTbase re-"
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "",
          "87.11\n86.16\n85.80\n84.80": "sults are reported by Zellers et al. (2019)."
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "ing BERTbase and fine-tuned on the same dataset",
          "87.11\n86.16\n85.80\n84.80": ""
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "and splits. However, there are differences in how",
          "87.11\n86.16\n85.80\n84.80": ""
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "the models were treated before this fine-tuning,",
          "87.11\n86.16\n85.80\n84.80": ""
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "",
          "87.11\n86.16\n85.80\n84.80": "4.7\nAnalysis"
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "and there may be some hyperparameter differences",
          "87.11\n86.16\n85.80\n84.80": ""
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "for fine-tuning. We described in §4.3 how we",
          "87.11\n86.16\n85.80\n84.80": "In this section, we perform a further set of experi-"
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "fine-tune a randomly initialised BERT model\nto",
          "87.11\n86.16\n85.80\n84.80": "ments to aid in interpreting our main results."
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "create BERTsynth. Zellers et al. (2019) reported",
          "87.11\n86.16\n85.80\n84.80": ""
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "",
          "87.11\n86.16\n85.80\n84.80": "4.7.1\nLength of Human vs Synthetic articles"
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "their BERT models were domain adapted to News",
          "87.11\n86.16\n85.80\n84.80": ""
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "(by training on RealNews) at a length of 1024",
          "87.11\n86.16\n85.80\n84.80": "We investigate whether PLMs simply learn some-"
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "WordPiece tokens.\nIt\nis possible that\nthis addi-",
          "87.11\n86.16\n85.80\n84.80": "thing about\nthe length of articles as a proxy for"
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "tional domain-adaptation and extended input se-",
          "87.11\n86.16\n85.80\n84.80": "discrimination between human and synthetic text."
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "quence length actually harmed the performance of",
          "87.11\n86.16\n85.80\n84.80": "An analysis of NEWSsynth articles (train and valida-"
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "the BERTbase model on the synthetic detection task.",
          "87.11\n86.16\n85.80\n84.80": "tion splits) reveals no obvious correlation (Pearson"
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "The performance of synthetic text detectors can",
          "87.11\n86.16\n85.80\n84.80": "r = 0.20) between the number of words in a human"
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "improve with length (Ippolito et al., 2020) and the",
          "87.11\n86.16\n85.80\n84.80": "article and the resulting synthetic article. 64% of"
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "longer input sequence length could help in this re-",
          "87.11\n86.16\n85.80\n84.80": "human articles are longer than their corresponding"
        },
        {
          "84.28\n91.63\nMean\n80.82\n89.04": "gard. However, the vast majority of human and syn-",
          "87.11\n86.16\n85.80\n84.80": "synthetic article, while 34% of synthetic articles"
        }
      ],
      "page": 6
    },
    {
      "caption": "Table 4: BERTsynth metrics for different split sizes, tionclassificationcanbeimprovedbytransfer",
      "data": [
        {
          "• SST-2 involves fine-tuning on the task of sen-": ""
        },
        {
          "• SST-2 involves fine-tuning on the task of sen-": "timent polarity classification using the SST-2"
        },
        {
          "• SST-2 involves fine-tuning on the task of sen-": ""
        },
        {
          "• SST-2 involves fine-tuning on the task of sen-": "dataset of 68,221 movie reviews in English"
        },
        {
          "• SST-2 involves fine-tuning on the task of sen-": "(Socher et al., 2013);"
        },
        {
          "• SST-2 involves fine-tuning on the task of sen-": "• GAS is GNE, AT, and SST-2 combined; with"
        },
        {
          "• SST-2 involves fine-tuning on the task of sen-": "SST-2 positive sentiment mapped to joy and"
        },
        {
          "• SST-2 involves fine-tuning on the task of sen-": ""
        },
        {
          "• SST-2 involves fine-tuning on the task of sen-": "negative sentiment mapped to sadness;"
        },
        {
          "• SST-2 involves fine-tuning on the task of sen-": ""
        },
        {
          "• SST-2 involves fine-tuning on the task of sen-": "• S-GA involves first fine-tuning on sentiment"
        },
        {
          "• SST-2 involves fine-tuning on the task of sen-": ""
        },
        {
          "• SST-2 involves fine-tuning on the task of sen-": "using SST-2 and then fine-tuning on emo-"
        },
        {
          "• SST-2 involves fine-tuning on the task of sen-": "tion using GA. This experiment is inspired by"
        },
        {
          "• SST-2 involves fine-tuning on the task of sen-": ""
        },
        {
          "• SST-2 involves fine-tuning on the task of sen-": "Kratzwald et al. (2018) who report that emo-"
        }
      ],
      "page": 7
    },
    {
      "caption": "Table 4: BERTsynth metrics for different split sizes, tionclassificationcanbeimprovedbytransfer",
      "data": [
        {
          "are longer. Human articles are longer overall, but": "have slightly shorter sentences than synthetic text;",
          "between BERTsynth and emoBERTsynth can": "be attributed to emotion or to the process of"
        },
        {
          "are longer. Human articles are longer overall, but": "and human articles have more sentences per article",
          "between BERTsynth and emoBERTsynth can": "fine-tuning on an arbitrary classification task"
        },
        {
          "are longer. Human articles are longer overall, but": "- which accounts for their longer mean length. Sim-",
          "between BERTsynth and emoBERTsynth can": "with the GNE data;"
        },
        {
          "are longer. Human articles are longer overall, but": "ilar observations were made for RealNews-Test by",
          "between BERTsynth and emoBERTsynth can": "• AT involves\nfine-tuning with\nthe Affec-"
        },
        {
          "are longer. Human articles are longer overall, but": "Bhat and Parthasarathy (2020). See Table 10 and",
          "between BERTsynth and emoBERTsynth can": "tiveText dataset comprising 1.5k news head-"
        },
        {
          "are longer. Human articles are longer overall, but": "Figs. 5 to 8 in Appendix E. Overall, these results",
          "between BERTsynth and emoBERTsynth can": "lines in English annotated with respect to Ek-"
        },
        {
          "are longer. Human articles are longer overall, but": "point neither to article length nor sentence length as",
          "between BERTsynth and emoBERTsynth can": "man’s 6 emotions (Strapparava and Mihalcea,"
        },
        {
          "are longer. Human articles are longer overall, but": "a reliable discriminator for synthetic text suggest-",
          "between BERTsynth and emoBERTsynth can": "2008);"
        },
        {
          "are longer. Human articles are longer overall, but": "ing that detector models are not simply learning",
          "between BERTsynth and emoBERTsynth can": "• GA is GNE and AT combined;"
        },
        {
          "are longer. Human articles are longer overall, but": "",
          "between BERTsynth and emoBERTsynth can": "• SST-2 involves fine-tuning on the task of sen-"
        },
        {
          "are longer. Human articles are longer overall, but": "length as a proxy for human vs synthetic text.",
          "between BERTsynth and emoBERTsynth can": ""
        },
        {
          "are longer. Human articles are longer overall, but": "",
          "between BERTsynth and emoBERTsynth can": "timent polarity classification using the SST-2"
        },
        {
          "are longer. Human articles are longer overall, but": "4.7.2\nSize of fine-tuning splits",
          "between BERTsynth and emoBERTsynth can": ""
        },
        {
          "are longer. Human articles are longer overall, but": "",
          "between BERTsynth and emoBERTsynth can": "dataset of 68,221 movie reviews in English"
        },
        {
          "are longer. Human articles are longer overall, but": "",
          "between BERTsynth and emoBERTsynth can": "(Socher et al., 2013);"
        },
        {
          "are longer. Human articles are longer overall, but": "Split\nPrec.\nRecall\nF1\nAcc.",
          "between BERTsynth and emoBERTsynth can": "• GAS is GNE, AT, and SST-2 combined; with"
        },
        {
          "are longer. Human articles are longer overall, but": "",
          "between BERTsynth and emoBERTsynth can": "SST-2 positive sentiment mapped to joy and"
        },
        {
          "are longer. Human articles are longer overall, but": "5-1-4k\n78.39\n79.85\n78.89\n78.58",
          "between BERTsynth and emoBERTsynth can": ""
        },
        {
          "are longer. Human articles are longer overall, but": "",
          "between BERTsynth and emoBERTsynth can": "negative sentiment mapped to sadness;"
        },
        {
          "are longer. Human articles are longer overall, but": "Var.\n(24.10)\n(17.33)\n(3.17)\n(6.51)",
          "between BERTsynth and emoBERTsynth can": ""
        },
        {
          "are longer. Human articles are longer overall, but": "",
          "between BERTsynth and emoBERTsynth can": "• S-GA involves first fine-tuning on sentiment"
        },
        {
          "are longer. Human articles are longer overall, but": "10-2-8k\n80.82\n91.63\n85.80\n84.80",
          "between BERTsynth and emoBERTsynth can": ""
        },
        {
          "are longer. Human articles are longer overall, but": "Var.\n(9.89)\n(5.70)\n(0.62)\n(1.68)",
          "between BERTsynth and emoBERTsynth can": "using SST-2 and then fine-tuning on emo-"
        },
        {
          "are longer. Human articles are longer overall, but": "",
          "between BERTsynth and emoBERTsynth can": "tion using GA. This experiment is inspired by"
        },
        {
          "are longer. Human articles are longer overall, but": "∆\n+2.43\n+11.78\n+6.91\n+6.22",
          "between BERTsynth and emoBERTsynth can": ""
        },
        {
          "are longer. Human articles are longer overall, but": "",
          "between BERTsynth and emoBERTsynth can": "Kratzwald et al. (2018) who report that emo-"
        },
        {
          "are longer. Human articles are longer overall, but": "Table 4:\nBERTsynth metrics for different split sizes,",
          "between BERTsynth and emoBERTsynth can": "tion classification can be improved by transfer"
        },
        {
          "are longer. Human articles are longer overall, but": "using the NEWSsynth dataset averaged over 5 runs (with",
          "between BERTsynth and emoBERTsynth can": "learning from sentiment analysis;"
        },
        {
          "are longer. Human articles are longer overall, but": "variance shown in brackets).",
          "between BERTsynth and emoBERTsynth can": "• GAS+- is GAS but mapped to positive and"
        },
        {
          "are longer. Human articles are longer overall, but": "",
          "between BERTsynth and emoBERTsynth can": "negative sentiment.6"
        },
        {
          "are longer. Human articles are longer overall, but": "The BERTsynth fine-tuning regime (§4.3) was re-",
          "between BERTsynth and emoBERTsynth can": ""
        }
      ],
      "page": 7
    },
    {
      "caption": "Table 4: BERTsynth metrics for different split sizes, tionclassificationcanbeimprovedbytransfer",
      "data": [
        {
          "variance shown in brackets).": "",
          "• GAS+- is GAS but mapped to positive and": "negative sentiment.6"
        },
        {
          "variance shown in brackets).": "The BERTsynth fine-tuning regime (§4.3) was re-",
          "• GAS+- is GAS but mapped to positive and": ""
        },
        {
          "variance shown in brackets).": "",
          "• GAS+- is GAS but mapped to positive and": "The\nresults\n(Table\n5)\nreveal\nthat\nthe\nbest-"
        },
        {
          "variance shown in brackets).": "peated using all (20k) and half (10k) of NEWSsynth.",
          "• GAS+- is GAS but mapped to positive and": ""
        },
        {
          "variance shown in brackets).": "",
          "• GAS+- is GAS but mapped to positive and": "performing emoBERTsynth models are those fine-"
        },
        {
          "variance shown in brackets).": "In all 5 runs, the BERTsynth model trained on the",
          "• GAS+- is GAS but mapped to positive and": ""
        },
        {
          "variance shown in brackets).": "",
          "• GAS+- is GAS but mapped to positive and": "tuned using GNE or using GNE and AffectiveText"
        },
        {
          "variance shown in brackets).": "larger 20k dataset performed better than the equiv-",
          "• GAS+- is GAS but mapped to positive and": ""
        },
        {
          "variance shown in brackets).": "",
          "• GAS+- is GAS but mapped to positive and": "combined (GA). The latter achieves the highest ac-"
        },
        {
          "variance shown in brackets).": "alent model\ntrained on the smaller 10k dataset –",
          "• GAS+- is GAS but mapped to positive and": ""
        },
        {
          "variance shown in brackets).": "",
          "• GAS+- is GAS but mapped to positive and": "curacy and the former the highest F1. We attribute"
        },
        {
          "variance shown in brackets).": "see Table 4. There was a modest improvement in",
          "• GAS+- is GAS but mapped to positive and": ""
        },
        {
          "variance shown in brackets).": "",
          "• GAS+- is GAS but mapped to positive and": "the relatively poor performance of AffectiveText on"
        },
        {
          "variance shown in brackets).": "precision (+2.43%) with a much larger increase in",
          "• GAS+- is GAS but mapped to positive and": ""
        },
        {
          "variance shown in brackets).": "",
          "• GAS+- is GAS but mapped to positive and": "its own to its small size, comprising only 1.5k head-"
        },
        {
          "variance shown in brackets).": "recall (+11.78%). The results suggest that recall is",
          "• GAS+- is GAS but mapped to positive and": ""
        },
        {
          "variance shown in brackets).": "",
          "• GAS+- is GAS but mapped to positive and": "lines (split 625 + 125 for training and dev splits"
        },
        {
          "variance shown in brackets).": "most sensitive to the size of the training set. This",
          "• GAS+- is GAS but mapped to positive and": ""
        },
        {
          "variance shown in brackets).": "",
          "• GAS+- is GAS but mapped to positive and": "respectively) compared to 5k for GNE and 68k for"
        },
        {
          "variance shown in brackets).": "is perhaps because the PLM is already trained on",
          "• GAS+- is GAS but mapped to positive and": ""
        },
        {
          "variance shown in brackets).": "",
          "• GAS+- is GAS but mapped to positive and": "SST-2."
        },
        {
          "variance shown in brackets).": "human text during pretraining but not synthetic text",
          "• GAS+- is GAS but mapped to positive and": ""
        },
        {
          "variance shown in brackets).": "",
          "• GAS+- is GAS but mapped to positive and": "Table 5 also shows\nthat fine-tuning on GNE"
        },
        {
          "variance shown in brackets).": "(exposure bias), so more exposure to synthetic text",
          "• GAS+- is GAS but mapped to positive and": ""
        },
        {
          "variance shown in brackets).": "",
          "• GAS+- is GAS but mapped to positive and": "outperforms fine-tuning with randomised labels"
        },
        {
          "variance shown in brackets).": "increases the model’s ability to detect synthetic text",
          "• GAS+- is GAS but mapped to positive and": ""
        },
        {
          "variance shown in brackets).": "correctly with fewer false negatives.",
          "• GAS+- is GAS but mapped to positive and": "(GNEr). The 1.1 point drop in accuracy of GNEr"
        },
        {
          "variance shown in brackets).": "",
          "• GAS+- is GAS but mapped to positive and": "compared to GNE suggests that the emotion clas-"
        },
        {
          "variance shown in brackets).": "4.7.3\nAlternative forms of emoBERT",
          "• GAS+- is GAS but mapped to positive and": ""
        },
        {
          "variance shown in brackets).": "",
          "• GAS+- is GAS but mapped to positive and": "sification task does play a role in the improved"
        },
        {
          "variance shown in brackets).": "What\nis\nthe\neffect\nof\nusing\ndifferent\nemotion",
          "• GAS+- is GAS but mapped to positive and": "performance of emoBERTsynth versus BERTsynth."
        },
        {
          "variance shown in brackets).": "datasets to fine-tune our emotionally aware PLMs",
          "• GAS+- is GAS but mapped to positive and": "The results in Table 5 suggest\nthat fine-tuning"
        },
        {
          "variance shown in brackets).": "on the downstream task of synthetic text detection?",
          "• GAS+- is GAS but mapped to positive and": "on sentiment is not particularly helpful. The poor"
        },
        {
          "variance shown in brackets).": "We conduct experiments on emoBERTsynth by fine-",
          "• GAS+- is GAS but mapped to positive and": "performance of GAS could be due to the crude"
        },
        {
          "variance shown in brackets).": "tuning eight alternative emoBERT models:",
          "• GAS+- is GAS but mapped to positive and": "mapping of negative sentiment to sadness (because"
        },
        {
          "variance shown in brackets).": "",
          "• GAS+- is GAS but mapped to positive and": "6Happiness was mapped to positive sentiment; sadness,"
        },
        {
          "variance shown in brackets).": "• GNE involves fine-tuning using the Good-",
          "• GAS+- is GAS but mapped to positive and": ""
        },
        {
          "variance shown in brackets).": "",
          "• GAS+- is GAS but mapped to positive and": "fear, anger and disgust were mapped to negative sentiment;"
        },
        {
          "variance shown in brackets).": "NewsEveryone dataset (§4.2) as in the main",
          "• GAS+- is GAS but mapped to positive and": ""
        },
        {
          "variance shown in brackets).": "",
          "• GAS+- is GAS but mapped to positive and": "surprise was mapped to sentiment using a DistilBERT (base-"
        },
        {
          "variance shown in brackets).": "experiments;",
          "• GAS+- is GAS but mapped to positive and": "uncased) (Sanh et al., 2020) sentiment classifier fine-tuned"
        },
        {
          "variance shown in brackets).": "",
          "• GAS+- is GAS but mapped to positive and": "on the SST-2 dataset and available on HuggingFace. https:"
        },
        {
          "variance shown in brackets).": "• GNEr involves fine-tuning with a version of",
          "• GAS+- is GAS but mapped to positive and": ""
        },
        {
          "variance shown in brackets).": "",
          "• GAS+- is GAS but mapped to positive and": "//huggingface.co/distilbert-base-uncased 14.05% of"
        },
        {
          "variance shown in brackets).": "GNE with randomised labels. We do this to",
          "• GAS+- is GAS but mapped to positive and": ""
        },
        {
          "variance shown in brackets).": "",
          "• GAS+- is GAS but mapped to positive and": "’surprise’ mapped to positive, while the remaining 85.95%"
        },
        {
          "variance shown in brackets).": "examine the extent\nto which the difference",
          "• GAS+- is GAS but mapped to positive and": "mapped to negative sentiment."
        }
      ],
      "page": 7
    },
    {
      "caption": "Table 6: Comparison of BLOOMsynth and",
      "data": [
        {
          "Prec.\nRec.\nF1\nAcc.": ""
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "BLOOMsynth\n81.90\n85.95\n83.79\n83.40"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "Var.\n(4.76)\n(12.22)\n(1.23)\n(0.93)"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": ""
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "85.98\n88.02\n86.90\n86.75\nemoBLOOMsynth"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "Var.\n(5.72)\n(9.96)\n(0.27)\n(0.15)"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "∆\n+4.08\n+2.07\n+3.11\n+3.35"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": ""
        },
        {
          "Prec.\nRec.\nF1\nAcc.": ""
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "BLOOMsynth\nTable\n6:\nComparison\nof\nand"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": ""
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "emoBLOOMsynth\nNEWSsynth\nagainst\nthe\ntest\nset"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "averaged\nover\n5\nruns\n(with\nvariance\nin\nbrackets)."
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "emoBLOOMsynth outperforms BLOOMsynth in Accuracy,"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "F1, Recall, and Precision."
        },
        {
          "Prec.\nRec.\nF1\nAcc.": ""
        },
        {
          "Prec.\nRec.\nF1\nAcc.": ""
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "aligned Large Language Model (LLM) which has"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": ""
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "undergone a second training or “alignment” phase"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": ""
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "using Reinforcement Learning from Human Feed-"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "back on top of an underlying LLM (GPT 3.5 in our"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": ""
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "case) (OpenAI, 2022; Ouyang et al., 2022). We cre-"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": ""
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "ate a custom dataset comprising human articles and"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": ""
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "ChatGPT synthetic text from multiple non-news"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": ""
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "domains, and use it to compare our BERTsynth and"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": ""
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "emoBERTsynth models against ChatGPT (in a zero-"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": ""
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "shot setting) on the task of detecting ChatGPT’s"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "own synthetic text.7"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "Chat-\nChatGPT100\nWe\ncreate\nand\nrelease"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "GPT100 - a dataset comprising human articles and"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "synthetic articles generated by ChatGPT. Following"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "Clark et al. (2021) who collected 50 human articles"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "and generated 50 articles using GPT2 and GPT3,"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "we also collect 50 human articles, and we then use"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "ChatGPT to generate 50 synthetic ones. The hu-"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "man written articles are from 5 different domains:"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "Science, Entertainment, Sport, Business, and Phi-"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "losophy. We used reputable websites for the human"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": ""
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "text which was gathered manually, see Table 8 in"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": ""
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "Appendix B.3. The synthetic text was generated"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": ""
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "by providing ChatGPT with a prompt such as “In"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "less than 400 words, tell me about moral philoso-"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": ""
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "phy.” where human text on the same topic, moral"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": ""
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "philosophy in this case, had already been found"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": ""
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "online. The data generated by ChatGPT is seman-"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": ""
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "tically correct and was checked manually. Subject"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": ""
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "areas in which the authors are knowledgeable were"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": ""
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "chosen so that the correctness of the synthetic text"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": ""
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "could be checked. To be comparable with the de-"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": ""
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "tectors presented in our earlier experiments,\nthe"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "articles were limited to a maximum of 384 words"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": ""
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "(≈ 512 tokens) and truncated at a natural sentence"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "boundary. The two articles were then made to be"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "approximately the same length."
        },
        {
          "Prec.\nRec.\nF1\nAcc.": ""
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "7We use ChatGPT-3.5 (Mar-14-2023 version) between"
        },
        {
          "Prec.\nRec.\nF1\nAcc.": "dates 16-Mar-2023 and 24-Mar-2023."
        }
      ],
      "page": 8
    },
    {
      "caption": "Table 7: The belsresultinanimprovementinperformancecom-",
      "data": [
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "75.00\nChatGPT\n30.00\n42.86\n60.00",
          "of synthetic text. An emotionally-aware PLM fine-": "tuned on emotion classification and subsequently"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "100.00\nBERTsynth\n60.24\n75.19\n67.00",
          "of synthetic text. An emotionally-aware PLM fine-": "trained on synthetic text detection (emoPLMsynth)"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "100.00\n80.65\n76.00\nemoBERTsynth\n67.57",
          "of synthetic text. An emotionally-aware PLM fine-": ""
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "outperformed a model with identical fine-tuning on"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "synthetic text detection, but without emotion train-"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "Table 7: Our emotionally aware PLM (emoBERTsynth)",
          "of synthetic text. An emotionally-aware PLM fine-": ""
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "ing,\n(PLMsynth).\nThe results hold across differ-"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "outperforms ChatGPT and BERTsynth at detecting syn-",
          "of synthetic text. An emotionally-aware PLM fine-": ""
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "ent synthetic text generators, model sizes, datasets"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "thetic text in the ChatGPT100 dataset. Note that Chat-",
          "of synthetic text. An emotionally-aware PLM fine-": ""
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "GPT is performing the task zero-shot.",
          "of synthetic text. An emotionally-aware PLM fine-": "and domains. This work specifically demonstrates"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "the benefits of considering emotion in the task of"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "detecting synthetic text,\nit contributes\ntwo new"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "Detection task\nEach article was appended to the",
          "of synthetic text. An emotionally-aware PLM fine-": ""
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "datasets (NEWSsynth and ChatGPT100) and, more"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "following prompt\nto ChatGPT: “Was the follow-",
          "of synthetic text. An emotionally-aware PLM fine-": ""
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "generally, it hints at the potential benefits of consid-"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "ing written by a human or a computer, choose hu-",
          "of synthetic text. An emotionally-aware PLM fine-": ""
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "ering human factors in NLP and Machine Learning."
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "man or computer only?” Having tested ChatGPT,",
          "of synthetic text. An emotionally-aware PLM fine-": ""
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "Is it possible that some other proxy for synthetic"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "we then tested our BERTsynth and emoBERTsynth",
          "of synthetic text. An emotionally-aware PLM fine-": ""
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "text is at play? We ruled out some potential prox-"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "models (the models fine-tuned on RealNews-Test",
          "of synthetic text. An emotionally-aware PLM fine-": ""
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "ies related to article length in §4.7.1.\nIn ablation"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "from Table 3).",
          "of synthetic text. An emotionally-aware PLM fine-": ""
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "studies in §4.7.3, we showed that the emotion la-"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "bels result in an improvement in performance com-"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "Results\nThe results are shown in Table 7. The",
          "of synthetic text. An emotionally-aware PLM fine-": ""
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "pared to randomized labels for the same emotion"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "first\nthing to note is that no model performs par-",
          "of synthetic text. An emotionally-aware PLM fine-": ""
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "dataset. Other potential proxies are nonsensical sen-"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "ticularly well. ChatGPT tends to misclassify its",
          "of synthetic text. An emotionally-aware PLM fine-": ""
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "tences, repetitive text, etc. However, we account for"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "own synthetic text as human (hence the low recall",
          "of synthetic text. An emotionally-aware PLM fine-": ""
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "these by comparing our emotionally-aware PLMs"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "score of 30%).8\nBERTsynth and emoBERTsynth,",
          "of synthetic text. An emotionally-aware PLM fine-": ""
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "(emoPLMsynth) against standard PLMs fine-tuned"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "on the other hand, tend to classify text as machine-",
          "of synthetic text. An emotionally-aware PLM fine-": ""
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "on synthetic text detection only (PLMsynth). Thus,"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "written and they both obtain 100% recall. We pre-",
          "of synthetic text. An emotionally-aware PLM fine-": ""
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "any advantage or disadvantage of sentences with-"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "viously saw (§4.7.2) that recall\nis most sensitive",
          "of synthetic text. An emotionally-aware PLM fine-": ""
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "out meaning (or any other factor) is also available"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "to fine-tuning set size.\nThe emoBERTsynth and",
          "of synthetic text. An emotionally-aware PLM fine-": ""
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "to the non-emotionally-aware model against which"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "emoBERTsynth models have been exposed to syn-",
          "of synthetic text. An emotionally-aware PLM fine-": ""
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "we compare our emotionally-aware model."
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "thetic text during fine-tuning, whereas ChatGPT",
          "of synthetic text. An emotionally-aware PLM fine-": ""
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "is performing the task zero-shot. This could ex-",
          "of synthetic text. An emotionally-aware PLM fine-": "Future work will investigate further the affective"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "plain some of the difference in recall between the",
          "of synthetic text. An emotionally-aware PLM fine-": "profile (i.e. emotional content and characteristics)"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "ChatGPT and the two fine-tuned models.",
          "of synthetic text. An emotionally-aware PLM fine-": "of human and synthetic text; and attempt to deter-"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "Finally, as with our experiments with Grover-",
          "of synthetic text. An emotionally-aware PLM fine-": "mine if there are measurable differences which may"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "emoBERTsynth\ngenerated\ntext,\noutperforms",
          "of synthetic text. An emotionally-aware PLM fine-": "prove useful in the task of synthetic text detection."
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "BERTsynth on all metrics.\nThe dataset\nis small",
          "of synthetic text. An emotionally-aware PLM fine-": ""
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "so we must be careful not\nto conclude too much",
          "of synthetic text. An emotionally-aware PLM fine-": "Limitations"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "from this result, but it does suggest that fine-tuning",
          "of synthetic text. An emotionally-aware PLM fine-": ""
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "The datasets used in this work (synthetic\ntext"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "on emotion could be beneficial when detecting",
          "of synthetic text. An emotionally-aware PLM fine-": ""
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "datasets, emotion datasets, and sentiment dataset)"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "synthetic text from LLMs and more sophisticated",
          "of synthetic text. An emotionally-aware PLM fine-": ""
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "are English language and model performance in"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "generators,\nin non-news domains. This is in line",
          "of synthetic text. An emotionally-aware PLM fine-": ""
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "other languages may vary. We primarily focus on"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "with the results of our earlier experiments using",
          "of synthetic text. An emotionally-aware PLM fine-": ""
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "the news domain and, while performance in other"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "variously\nsize PLMs\n(such\nas Grover, BERT,",
          "of synthetic text. An emotionally-aware PLM fine-": ""
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "domains may vary (Merchant et al., 2020), we in-"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "BLOOM), used as generators\nand detectors\nin",
          "of synthetic text. An emotionally-aware PLM fine-": ""
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "clude experiments in several non-news domains"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "the news domain, and shows the potential for our",
          "of synthetic text. An emotionally-aware PLM fine-": ""
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "(§5)."
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "approach with different generator models and in",
          "of synthetic text. An emotionally-aware PLM fine-": ""
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "The emotion datasets are imbalanced across emo-"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "different domains.",
          "of synthetic text. An emotionally-aware PLM fine-": ""
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "tion labels which can impact overall performance,"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "and we conducted ablation experiments\nto find"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "6\nConclusion",
          "of synthetic text. An emotionally-aware PLM fine-": ""
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "the best combination of emotion and sentiment"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "We conducted experiments investigating the role",
          "of synthetic text. An emotionally-aware PLM fine-": ""
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "datasets (§4.7.3). GoodNewsEveryone’s 15 emo-"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "that emotion recognition can play in the detection",
          "of synthetic text. An emotionally-aware PLM fine-": ""
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "tions were mapped to Ekman’s 6 emotions (Ekman,"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "",
          "of synthetic text. An emotionally-aware PLM fine-": "1992, 1999, 2016), factoring in Plutchik’s wheel"
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "8ChatGPTs responses suggest it may use fact-checking as",
          "of synthetic text. An emotionally-aware PLM fine-": ""
        },
        {
          "Model\nPrec.\nRec.\nF1\nAcc.": "a proxy during synthetic text detection.",
          "of synthetic text. An emotionally-aware PLM fine-": "of emotion (Plutchik, 1980, 2001), but there is no"
        }
      ],
      "page": 9
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "firm agreement in the literature as to which is the": "’correct’ or ’best’ emotion model (Ekman, 2016).",
          "include the caveat below with the released datasets": "(NEWSsynth and ChatGPT100) and the released"
        },
        {
          "firm agreement in the literature as to which is the": "The emotion models used in this work are the two",
          "include the caveat below with the released datasets": "language models (emoPLMsynth, PLMsynth):"
        },
        {
          "firm agreement in the literature as to which is the": "most popular in the literature.",
          "include the caveat below with the released datasets": ""
        },
        {
          "firm agreement in the literature as to which is the": "",
          "include the caveat below with the released datasets": "Care must be taken when using these"
        },
        {
          "firm agreement in the literature as to which is the": "The maximum input sequence length of BERT",
          "include the caveat below with the released datasets": ""
        },
        {
          "firm agreement in the literature as to which is the": "",
          "include the caveat below with the released datasets": "language models\n(emoPLMsynth\nand"
        },
        {
          "firm agreement in the literature as to which is the": "is 512 tokens and articles longer than this are trun-",
          "include the caveat below with the released datasets": ""
        },
        {
          "firm agreement in the literature as to which is the": "",
          "include the caveat below with the released datasets": "PLMsynth),\nand datasets\n(NEWSsynth"
        },
        {
          "firm agreement in the literature as to which is the": "cated, which may negatively affect performance",
          "include the caveat below with the released datasets": ""
        },
        {
          "firm agreement in the literature as to which is the": "",
          "include the caveat below with the released datasets": "and ChatGPT100) as they may produce"
        },
        {
          "firm agreement in the literature as to which is the": "on the synthetic text detection task (Ippolito et al.,",
          "include the caveat below with the released datasets": ""
        },
        {
          "firm agreement in the literature as to which is the": "",
          "include the caveat below with the released datasets": "or contain ethically problematic content."
        },
        {
          "firm agreement in the literature as to which is the": "2020). However, we also saw that increasing the",
          "include the caveat below with the released datasets": ""
        },
        {
          "firm agreement in the literature as to which is the": "",
          "include the caveat below with the released datasets": "Data scraped from the web may con-"
        },
        {
          "firm agreement in the literature as to which is the": "input sequence length may actually contribute to",
          "include the caveat below with the released datasets": ""
        },
        {
          "firm agreement in the literature as to which is the": "",
          "include the caveat below with the released datasets": "tain content which is ethically problem-"
        },
        {
          "firm agreement in the literature as to which is the": "poorer performance (§4.6).",
          "include the caveat below with the released datasets": ""
        },
        {
          "firm agreement in the literature as to which is the": "",
          "include the caveat below with the released datasets": "atic such as adult content, bias,\ntoxic-"
        },
        {
          "firm agreement in the literature as to which is the": "",
          "include the caveat below with the released datasets": "ity etc. and web-scraped data is used in"
        },
        {
          "firm agreement in the literature as to which is the": "Ethical Considerations",
          "include the caveat below with the released datasets": ""
        },
        {
          "firm agreement in the literature as to which is the": "",
          "include the caveat below with the released datasets": "the pre-trained language models such as"
        },
        {
          "firm agreement in the literature as to which is the": "We\nrelease\nmultiple\nPLMs\n(emoBERTsynth,",
          "include the caveat below with the released datasets": ""
        },
        {
          "firm agreement in the literature as to which is the": "",
          "include the caveat below with the released datasets": "BERT, BLOOM and Grover. PLMsynth"
        },
        {
          "firm agreement in the literature as to which is the": "BERTsynth,\nemoBLOOMsynth\nand\nBLOOMsynth)",
          "include the caveat below with the released datasets": ""
        },
        {
          "firm agreement in the literature as to which is the": "",
          "include the caveat below with the released datasets": "and emoPLMsynth are based on BERT"
        },
        {
          "firm agreement in the literature as to which is the": "which we refer to generically as emoPLMsynth and",
          "include the caveat below with the released datasets": ""
        },
        {
          "firm agreement in the literature as to which is the": "",
          "include the caveat below with the released datasets": "or BLOOM PLMs, while NEWSsynth"
        },
        {
          "firm agreement in the literature as to which is the": "PLMsynth. emoPLMsynth and PLMsynth are BERT",
          "include the caveat below with the released datasets": ""
        },
        {
          "firm agreement in the literature as to which is the": "",
          "include the caveat below with the released datasets": "was generated by Grover. Consequently,"
        },
        {
          "firm agreement in the literature as to which is the": "or BLOOM models with versions fine-tuned on",
          "include the caveat below with the released datasets": ""
        },
        {
          "firm agreement in the literature as to which is the": "",
          "include the caveat below with the released datasets": "emoPLMsynth and PLMsynth could pro-"
        },
        {
          "firm agreement in the literature as to which is the": "NEWSsynth or the RealNews-Test (Zellers et al.,",
          "include the caveat below with the released datasets": ""
        },
        {
          "firm agreement in the literature as to which is the": "",
          "include the caveat below with the released datasets": "duce text which is ethically problematic,"
        },
        {
          "firm agreement in the literature as to which is the": "2019) datasets; emoPLMsynth is also fine-tuned on",
          "include the caveat below with the released datasets": ""
        },
        {
          "firm agreement in the literature as to which is the": "",
          "include the caveat below with the released datasets": "while NEWSsynth may contain ethically"
        },
        {
          "firm agreement in the literature as to which is the": "combinations of the GoodNewsEveryone (Bostan",
          "include the caveat below with the released datasets": ""
        },
        {
          "firm agreement in the literature as to which is the": "",
          "include the caveat below with the released datasets": "problematic content. As a result, any use"
        },
        {
          "firm agreement in the literature as to which is the": "et al., 2020), AffectiveText (Strapparava and Mi-",
          "include the caveat below with the released datasets": ""
        },
        {
          "firm agreement in the literature as to which is the": "",
          "include the caveat below with the released datasets": "of the language models (emoPLMsynth,"
        },
        {
          "firm agreement in the literature as to which is the": "halcea, 2008),\nand SST-2 (Socher et al., 2013)",
          "include the caveat below with the released datasets": ""
        },
        {
          "firm agreement in the literature as to which is the": "",
          "include the caveat below with the released datasets": "PLMsynth) or the datasets (NEWSsynth"
        },
        {
          "firm agreement in the literature as to which is the": "datasets.",
          "include the caveat below with the released datasets": ""
        },
        {
          "firm agreement in the literature as to which is the": "",
          "include the caveat below with the released datasets": "or ChatGPT100) should employ appro-"
        },
        {
          "firm agreement in the literature as to which is the": "We release ChatGPT100, a dataset comprising",
          "include the caveat below with the released datasets": ""
        },
        {
          "firm agreement in the literature as to which is the": "",
          "include the caveat below with the released datasets": "priate checks and test regimes to handle"
        },
        {
          "firm agreement in the literature as to which is the": "100 English language articles in various non-news",
          "include the caveat below with the released datasets": ""
        },
        {
          "firm agreement in the literature as to which is the": "",
          "include the caveat below with the released datasets": "potential harmful content."
        },
        {
          "firm agreement in the literature as to which is the": "domains.\n50 articles are human written, and 50",
          "include the caveat below with the released datasets": ""
        },
        {
          "firm agreement in the literature as to which is the": "articles are generated by ChatGPT. The 100 articles",
          "include the caveat below with the released datasets": "emoPLMsynth\nThe\nintended\nuse\nof\nthe\nand"
        },
        {
          "firm agreement in the literature as to which is the": "have all been manually curated and do not contain",
          "include the caveat below with the released datasets": "PLMsynth models, and the NEWSsynth and Chat-"
        },
        {
          "firm agreement in the literature as to which is the": "toxic content. Furthermore, ChatGPT has a content",
          "include the caveat below with the released datasets": "GPT100 datasets, is for research purposes and ben-"
        },
        {
          "firm agreement in the literature as to which is the": "filter which flags potentially harmful content.",
          "include the caveat below with the released datasets": "eficial downstream tasks such as identifying syn-"
        },
        {
          "firm agreement in the literature as to which is the": "We release, NEWSsynth, a dataset comprising",
          "include the caveat below with the released datasets": "thetic text perhaps in online news, reviews, com-"
        },
        {
          "firm agreement in the literature as to which is the": "40k English language articles in the news domain. 9",
          "include the caveat below with the released datasets": "ments, plagiarism etc. Online platforms could use"
        },
        {
          "firm agreement in the literature as to which is the": "20k news articles are human (from RealNews-Test)",
          "include the caveat below with the released datasets": "this identification to decide whether or not to pub-"
        },
        {
          "firm agreement in the literature as to which is the": "and 20k generated by Grover. Publishing synthetic",
          "include the caveat below with the released datasets": "lish such content, or where to surface it via rec-"
        },
        {
          "firm agreement in the literature as to which is the": "text\nis a risk, but NEWSsynth is clearly labelled",
          "include the caveat below with the released datasets": "ommender algorithms etc. This could help protect"
        },
        {
          "firm agreement in the literature as to which is the": "as containing synthetic text. This is a similar pre-",
          "include the caveat below with the released datasets": "public confidence in online discourse."
        },
        {
          "firm agreement in the literature as to which is the": "caution to synthetic text from Grover which has",
          "include the caveat below with the released datasets": "Energy usage was reduced by training on smaller"
        },
        {
          "firm agreement in the literature as to which is the": "already been published and is publicly available",
          "include the caveat below with the released datasets": "models and for a relatively small number of epochs"
        },
        {
          "firm agreement in the literature as to which is the": "(Zellers et al., 2019).",
          "include the caveat below with the released datasets": "where possible, by using random search rather than"
        },
        {
          "firm agreement in the literature as to which is the": "The potential harms, such as toxic synthetic text",
          "include the caveat below with the released datasets": "an exhaustive grid search, and by using freely avail-"
        },
        {
          "firm agreement in the literature as to which is the": "(Gehman et al., 2020), of PLMs pretrained on web-",
          "include the caveat below with the released datasets": "able managed compute resources where possible."
        },
        {
          "firm agreement in the literature as to which is the": "crawled data has been the subject of much discus-",
          "include the caveat below with the released datasets": ""
        },
        {
          "firm agreement in the literature as to which is the": "",
          "include the caveat below with the released datasets": "Acknowledgements"
        },
        {
          "firm agreement in the literature as to which is the": "sion (Bender et al., 2021). Since emoPLMsynth and",
          "include the caveat below with the released datasets": ""
        },
        {
          "firm agreement in the literature as to which is the": "PLMsynth (and Grover) were pretrained and/or fine-",
          "include the caveat below with the released datasets": ""
        },
        {
          "firm agreement in the literature as to which is the": "",
          "include the caveat below with the released datasets": "This publication has emanated from research con-"
        },
        {
          "firm agreement in the literature as to which is the": "tuned on web-crawled data there is a possibility",
          "include the caveat below with the released datasets": ""
        },
        {
          "firm agreement in the literature as to which is the": "",
          "include the caveat below with the released datasets": "ducted with the financial support of Science Foun-"
        },
        {
          "firm agreement in the literature as to which is the": "they could produce inappropriate synthetic text and",
          "include the caveat below with the released datasets": ""
        },
        {
          "firm agreement in the literature as to which is the": "",
          "include the caveat below with the released datasets": "dation Ireland under Grant number 18/CRT/6183."
        },
        {
          "firm agreement in the literature as to which is the": "this includes the NEWSsynth dataset. We recog-",
          "include the caveat below with the released datasets": ""
        },
        {
          "firm agreement in the literature as to which is the": "",
          "include the caveat below with the released datasets": "For the purpose of Open Access,\nthe author has"
        },
        {
          "firm agreement in the literature as to which is the": "nise these potential harms and to mitigate them",
          "include the caveat below with the released datasets": ""
        },
        {
          "firm agreement in the literature as to which is the": "",
          "include the caveat below with the released datasets": "applied a CC BY public copyright licence to any"
        },
        {
          "firm agreement in the literature as to which is the": "",
          "include the caveat below with the released datasets": "Author Accepted Manuscript version arising from"
        },
        {
          "firm agreement in the literature as to which is the": "9We include 20k articles in addition to the 20k used in this",
          "include the caveat below with the released datasets": ""
        },
        {
          "firm agreement in the literature as to which is the": "work",
          "include the caveat below with the released datasets": "this submission."
        }
      ],
      "page": 10
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "We\nthank Rowan Zellers\nfor his permission": "",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "sociation for Computational Linguistics."
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "to use 20k human articles\nfrom RealNews-Test",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": ""
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "(Zellers et al., 2019)\nin the NEWSsynth dataset",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": ""
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "Alice Brand. 1991. Social Cognition, Emotions, and"
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "which we release with this paper.",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "Journal of Advanced\nthe Psychology of Writing."
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "We thank the reviewers for their valuable feed-",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "Composition, 11(2):395–407. Publisher: JAC."
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "back which helped improve the paper.",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": ""
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "Alice G. Brand. 1985.\nHOT COGNITION: EMO-"
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "Journal of\nTIONS AND WRITING BEHAVIOR."
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "Advanced Composition, 6:5–15. Publisher: JAC."
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "References",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": ""
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "Alice G. Brand. 1987. The Why of Cognition: Emotion"
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "David Ifeoluwa Adelani, Haotian Mai, Fuming Fang,",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": ""
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "and the Writing Process. College Composition and"
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "Huy H. Nguyen,\nJunichi Yamagishi,\nand\nIsao",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": ""
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "Communication, 38(4):436–443. Publisher: National"
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "Echizen. 2019.\nGenerating Sentiment-Preserving",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": ""
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "Council of Teachers of English."
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "Fake Online Reviews Using Neural Language Mod-",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": ""
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "els and Their Human- and Machine-based Detection.",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": ""
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie"
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "arXiv:1907.09177 [cs]. ArXiv: 1907.09177.",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": ""
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind"
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "Neelakantan, Pranav Shyam, Girish Sastry, Amanda"
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "Ameeta Agrawal, Aijun An, and Manos Papagelis. 2018.",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": ""
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "Askell,\nSandhini Agarwal,\nAriel Herbert-Voss,"
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "Learning Emotion-enriched Word Representations.",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": ""
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "Gretchen Krueger, Tom Henighan, Rewon Child,"
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "In Proceedings of the 27th International Conference",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": ""
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "Aditya Ramesh, Daniel M. Ziegler,\nJeffrey Wu,"
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "on Computational Linguistics, pages 950–961, Santa",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": ""
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "Clemens Winter, Christopher Hesse, Mark Chen, Eric"
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "Fe, New Mexico, USA. Association for Computa-",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": ""
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess,"
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "tional Linguistics.",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": ""
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "Jack Clark, Christopher Berner, Sam McCandlish,"
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "Kushal Arora, Layla El Asri, Hareesh Bahuleyan,",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "Alec Radford,\nIlya Sutskever, and Dario Amodei."
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "and Jackie Chi Kit Cheung. 2022.\nWhy Expo-",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "2020.\nLanguage Models are Few-Shot Learners."
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "sure Bias Matters: An Imitation Learning Perspec-",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "arXiv:2005.14165 [cs]. ArXiv: 2005.14165."
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "tive of Error Accumulation in Language Generation.",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": ""
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "Elizabeth Clark, Tal August, Sofia Serrano, Nikita"
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "ArXiv:2204.01171 [cs].",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": ""
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "Haduong, Suchin Gururangan, and Noah A. Smith."
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "Emily M. Bender, Timnit Gebru, Angelina McMillan-",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "2021.\nAll That’s\n’Human’\nIs Not Gold:\nEval-"
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "Major, and Shmargaret Shmitchell. 2021. On the",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "uating\nHuman\nEvaluation\nof\nGenerated\nText."
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "Dangers of Stochastic Parrots: Can Language Models",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "arXiv:2107.00061 [cs]. ArXiv: 2107.00061."
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "Be Too Big? &#x1f99c;.\nIn Proceedings of the 2021",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": ""
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "ACM Conference on Fairness, Accountability, and",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "Sinéad Crowley. 2023a.\nIrish Times editor apologises"
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "Transparency, FAccT ’21, pages 610–623, New York,",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "for ’breach of trust’. Section: News."
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "NY, USA. Association for Computing Machinery.",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": ""
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "Sinéad Crowley. 2023b.\nIrish Times takes down article"
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "Meghana Moorthy Bhat and Srinivasan Parthasarathy.",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "amid AI suggestions. Section: News."
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "2020.\nHow Effectively Can Machines Defend",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": ""
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "Against Machine-Generated Fake News? An Empiri-",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "Jacob Devlin, Ming-Wei Chang, Kenton Lee,\nand"
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "cal Study.\nIn Proceedings of the First Workshop on",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "Kristina Toutanova.\n2019.\nBERT: Pre-training"
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "Insights from Negative Results in NLP, pages 48–53,",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "of Deep Bidirectional Transformers for Language"
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "Online. Association for Computational Linguistics.",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "Understanding.\narXiv:1810.04805 [cs].\nArXiv:"
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "1810.04805."
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "Catherine M. Bohn-Gettler and David N. Rapp. 2014.",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": ""
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "Emotion during reading and writing.\nIn Interna-",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "Paul Ekman. 1992. An argument for basic emotions."
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "tional handbook of emotions in education, Educa-",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "Cognition and Emotion, 6(3/4):169–200."
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "tional psychology handbook series, pages 437–457.",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": ""
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "Routledge/Taylor & Francis Group, New York, NY,",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "Paul Ekman. 1999. Basic Emotions.\nIn Handbook of"
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "US.",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "Cognition and Emotion, pages 45–60. John Wiley &"
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "Sons, Ltd."
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "Laura Ana Maria Bostan, Evgeny Kim, and Roman",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": ""
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "Klinger. 2020. GoodNewsEveryone: A Corpus of",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "Paul Ekman. 2016. What Scientists Who Study Emo-"
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "News Headlines Annotated with Emotions, Seman-",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "Perspectives on Psychological\ntion Agree About."
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "tic Roles, and Reader Perception.\nIn Proceedings of",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "Science, 11(1):31–34."
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "the 12th Language Resources and Evaluation Confer-",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": ""
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "ence, pages 1554–1566, Marseille, France. European",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "Catherine A. Gao, Frederick M. Howard, Nikolay S."
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "Language Resources Association.",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "Markov, Emma C. Dyer, Siddhi Ramesh, Yuan Luo,"
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "and Alexander T. Pearson. 2022. Comparing scien-"
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "Laura-Ana-Maria Bostan and Roman Klinger. 2018. An",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "tific abstracts generated by ChatGPT to original ab-"
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "Analysis of Annotated Corpora for Emotion Classi-",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "stracts using an artificial intelligence output detector,"
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "the 27th Inter-\nfication in Text.\nIn Proceedings of",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "plagiarism detector, and blinded human reviewers."
        },
        {
          "We\nthank Rowan Zellers\nfor his permission": "national Conference on Computational Linguistics,",
          "pages 2104–2119, Santa Fe, New Mexico, USA. As-": "Pages: 2022.12.23.521610 Section: New Results."
        }
      ],
      "page": 11
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "Yejin Choi, and Noah A. Smith. 2020.\nRealToxi-",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "trol Sentiment in Text Generation: A Survey of the"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "cityPrompts: Evaluating Neural Toxic Degeneration",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "State-of-the-Art in Sentiment-Control Techniques.\nIn"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "in Language Models.\nIn Findings of the Association",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "Proceedings of the 13th Workshop on Computational"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "for Computational Linguistics: EMNLP 2020, pages",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "Approaches to Subjectivity, Sentiment & Social Me-"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "3356–3369, Online. Association for Computational",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "dia Analysis, Toronto, Canada."
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "Linguistics.",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": ""
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "Amil Merchant, Elahe Rahimtoroghi, Ellie Pavlick, and"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "Sebastian Gehrmann, Hendrik Strobelt, and Alexander",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "Ian Tenney. 2020. What Happens To BERT Embed-"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "Rush. 2019. GLTR: Statistical Detection and Visual-",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "the\ndings During Fine-tuning?\nIn Proceedings of"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "ization of Generated Text.\nIn Proceedings of the 57th",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "Third BlackboxNLP Workshop on Analyzing and In-"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "Annual Meeting of the Association for Computational",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "terpreting Neural Networks for NLP, pages 33–44,"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "Linguistics: System Demonstrations, pages 111–116,",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "Online. Association for Computational Linguistics."
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "Florence, Italy. Association for Computational Lin-",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": ""
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "guistics.",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "Tomás Mikolov, Kai Chen, Greg Corrado, and Jeffrey"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "Dean. 2013. Efficient Estimation of Word Represen-"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "Saurabh Gupta, Hong Huy Nguyen,\nJunichi Yamag-",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": ""
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "tations in Vector Space.\nIn 1st International Con-"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "ishi, and Isao Echizen. 2020. Viable Threat on News",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": ""
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "ference on Learning Representations,\nICLR 2013,"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "Reading: Generating Biased News Using Natural",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": ""
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "Scottsdale, Arizona, USA, May 2-4, 2013, Workshop"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "the Fourth\nLanguage Models.\nIn Proceedings of",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": ""
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "Track Proceedings."
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "Workshop on Natural Language Processing and Com-",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": ""
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "putational Social Science, pages 55–65, Online. As-",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "Eric Mitchell, Yoonho Lee, Alexander Khazatsky,"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "sociation for Computational Linguistics.",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "Christopher\nD. Manning,\nand\nChelsea\nFinn."
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "2023. DetectGPT: Zero-Shot Machine-Generated"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "Frances Haugen. 2021.\nPublic Hearing on Whistle-",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": ""
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "Text\nDetection\nusing\nProbability\nCurvature."
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "blower’s\ntestimony\non\nthe\nnegative\nimpact\nof",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": ""
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "ArXiv:2301.11305 [cs] version: 1."
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "big\ntech\ncompanies’\nproducts\non\nuser:\nopen-",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": ""
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "ing\nstatement\nby\nFrances HAUGEN.\nURL:",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": ""
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "OpenAI.\n2022.\nIntroducing\nChatGPT."
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "https://multimedia.europarl.europa.eu/it/public-",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": ""
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "URL:https://openai.com/blog/chatgpt."
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "hearing-on-whistle-blowers-testimony-on-",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": ""
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "the-negative-impact-of-big-tech-companies-",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Car-"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "products-on-user-frances-haugen-opening-",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "roll L. Wainwright, Pamela Mishkin, Chong Zhang,"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "statements_I213108-V_v.",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "Sandhini Agarwal, Katarina Slama, Alex Ray, John"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "Schulman, Jacob Hilton, Fraser Kelton, Luke Miller,"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": ""
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "Maddie Simens, Amanda Askell, Peter Welinder,"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "Yejin Choi. 2020. The Curious Case of Neural Text",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": ""
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "Paul Christiano, Jan Leike, and Ryan Lowe. 2022."
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "Degeneration.\nIn ICLR2020.",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": ""
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "Training language models to follow instructions with"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "human feedback.\nIn NeurIPS. arXiv. Version Num-"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "Chenyang Huang, Osmar Zaïane, Amine Trabelsi, and",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": ""
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "ber: 1."
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "Nouha Dziri. 2018.\nAutomatic Dialogue Genera-",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": ""
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "tion with Expressed Emotions.\nIn Proceedings of",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": ""
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "Sinno Jialin Pan and Qiang Yang. 2010. A Survey on"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "the 2018 Conference of\nthe North American Chap-",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": ""
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "IEEE Transactions on Knowledge\nTransfer Learning."
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "ter of the Association for Computational Linguistics:",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": ""
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "and Data Engineering, 22(10):1345–1359. Confer-"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "Human Language Technologies, Volume 2 (Short Pa-",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": ""
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "ence Name:\nIEEE Transactions on Knowledge and"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "pers), pages 49–54, New Orleans, Louisiana. Associ-",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": ""
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "Data Engineering."
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "ation for Computational Linguistics.",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": ""
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "Krishna Pillutla, Swabha Swayamdipta, Rowan Zellers,"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "Daphne Ippolito, Daniel Duckworth, Chris Callison-",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": ""
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "John Thickstun, Sean Welleck, Yejin Choi, and Zaid"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "Burch, and Douglas Eck. 2020. Automatic Detec-",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": ""
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "Harchaoui. 2021. MAUVE: Measuring the Gap Be-"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "tion of Generated Text is Easiest when Humans are",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": ""
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "tween Neural Text and Human Text using Divergence"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "the 58th Annual Meet-\nFooled.\nIn Proceedings of",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": ""
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "Frontiers.\nIn Advances in Neural Information Pro-"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "ing of the Association for Computational Linguistics,",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": ""
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "cessing Systems."
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "pages 1808–1822, Online. Association for Computa-",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": ""
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "tional Linguistics.",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": ""
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "ROBERT Plutchik. 1980. Chapter 1 - A GENERAL"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "Susanne Knaller. 2017. Emotions and the Process of",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "PSYCHOEVOLUTIONARY THEORY OF EMO-"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "Writing.\nIn Ingeborg Jandl, Susanne Knaller, Sabine",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "TION.\nIn Robert Plutchik and Henry Kellerman,"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "Schönfellner, and Gudrun Tockner, editors, Lettre,",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "editors, Theories of Emotion, pages 3–33. Academic"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "1 edition, pages 17–28. transcript Verlag, Bielefeld,",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "Press."
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "Germany.",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": ""
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "Robert Plutchik. 2001. The Nature of Emotions: Hu-"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "Bernhard Kratzwald, Suzana Ilic, Mathias Kraus, Stefan",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "man emotions have deep evolutionary roots, a fact"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "Feuerriegel, and Helmut Prendinger. 2018.\nDeep",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "that may explain their complexity and provide tools"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "learning for affective computing:\ntext-based emotion",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "for clinical practice. American Scientist, 89(4):344–"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "recognition in decision support. Decision Support",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "350. Publisher: Sigma Xi, The Scientific Research"
        },
        {
          "Samuel Gehman, Suchin Gururangan, Maarten Sap,": "Systems, 115:24–35. ArXiv: 1803.06397.",
          "Michela Lorandi and Anya Belz. 2023. How to Con-": "Society."
        }
      ],
      "page": 12
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "Dario Amodei, and Ilya Sutskever. 2019. Language",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "bastian Nagel, Shamik Bose, Shamsuddeen Hassan"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "Models are Unsupervised Multitask Learners.",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Muhammad, Shanya Sharma, Shayne Longpre, So-"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "maieh Nikpoor, Stanislav Silberberg, Suhas Pai, Syd-"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "Marc’Aurelio Ranzato, Sumit Chopra, Michael Auli,",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "ney Zink, Tiago Timponi Torrent, Timo Schick, Tris-"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "and Wojciech Zaremba. 2016. Sequence Level Train-",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "tan Thrush, Valentin Danchev, Vassilina Nikoulina,"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "ing with Recurrent Neural Networks.\nIn ICLR 2016.",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Veronika Laippala, Violette Lepercq, Vrinda Prabhu,"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Zaid Alyafeai, Zeerak Talat, Arun Raja, Benjamin"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "Hannah Rashkin, Eric Michael Smith, Margaret Li,",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Heinzerling, Chenglei Si, Davut Emre Ta¸sar, Eliz-"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "and Y.-Lan Boureau. 2019.\nTowards Empathetic",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "abeth Salesky, Sabrina J. Mielke, Wilson Y. Lee,"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "Open-domain Conversation Models: a New Bench-",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Abheesht Sharma, Andrea Santilli, Antoine Chaffin,"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "mark and Dataset. arXiv:1811.00207 [cs]. ArXiv:",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Arnaud Stiegler, Debajyoti Datta, Eliza Szczechla,"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "1811.00207.",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Gunjan Chhablani, Han Wang, Harshit Pandey, Hen-"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "drik Strobelt,\nJason Alan Fries,\nJos Rozen, Leo"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "Victor Sanh, Lysandre Debut, Julien Chaumond, and",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Gao, Lintang Sutawika, M. Saiful Bari, Maged S."
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "Thomas Wolf. 2020. DistilBERT, a distilled version",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Al-shaibani, Matteo Manica, Nihal Nayak, Ryan"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "of BERT: smaller,\nfaster, cheaper and lighter.\nIn",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Teehan, Samuel Albanie, Sheng Shen, Srulik Ben-"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "5th Workshop on Energy Efficient Machine Learning",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "David, Stephen H. Bach, Taewoon Kim, Tali Bers,"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "and Cognitive Computing - NeurIPS 2019. arXiv.",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Thibault Fevry, Trishala Neeraj, Urmish Thakker,"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "ArXiv:1910.01108 [cs].",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Vikas Raunak, Xiangru Tang, Zheng-Xin Yong,"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Zhiqing Sun, Shaked Brody, Yallow Uri, Hadar"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "Enrico Santus, Qin Lu, Alessandro Lenci, and Chu-Ren",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Tojarieh, Adam Roberts, Hyung Won Chung, Jae-"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "Huang. 2014. Taking Antonymy Mask off in Vec-",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "sung Tae,\nJason Phang, Ofir Press, Conglong Li,"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "the 28th Pacific Asia\ntor Space.\nIn Proceedings of",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": ""
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Deepak Narayanan, Hatim Bourfoune, Jared Casper,"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "Conference on Language, Information and Comput-",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": ""
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Jeff Rasley, Max Ryabinin, Mayank Mishra, Minjia"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "ing, pages 135–144, Phuket,Thailand. Department of",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Zhang, Mohammad Shoeybi, Myriam Peyrounette,"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "Linguistics, Chulalongkorn University.",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Nicolas Patry, Nouamane Tazi, Omar Sanseviero,"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Patrick von Platen, Pierre Cornette, Pierre François"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "Teven Le Scao, Angela Fan, Christopher Akiki, El-",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": ""
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Lavallée, Rémi Lacroix, Samyam Rajbhandari, San-"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "lie Pavlick, Suzana Ili´c, Daniel Hesslow, Roman",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": ""
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "chit Gandhi, Shaden Smith, Stéphane Requena, Suraj"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "Castagné, Alexandra Sasha Luccioni, François Yvon,",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": ""
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Patil, Tim Dettmers, Ahmed Baruwa, Amanpreet"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "Matthias Gallé, Jonathan Tow, Alexander M. Rush,",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": ""
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Singh, Anastasia Cheveleva, Anne-Laure Ligozat,"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "Stella Biderman, Albert Webson, Pawan Sasanka Am-",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": ""
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Arjun Subramonian, Aurélie Névéol, Charles Lover-"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "manamanchi, Thomas Wang, Benoît Sagot, Niklas",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": ""
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "ing, Dan Garrette, Deepak Tunuguntla, Ehud Reiter,"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "Muennighoff, Albert Villanova del Moral, Olatunji",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": ""
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Ekaterina Taktasheva, Ekaterina Voloshina, Eli Bog-"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "Ruwase, Rachel Bawden, Stas Bekman, Angelina",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": ""
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "danov, Genta Indra Winata, Hailey Schoelkopf, Jan-"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "McMillan-Major,\nIz Beltagy, Huu Nguyen, Lucile",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": ""
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Christoph Kalo, Jekaterina Novikova, Jessica Zosa"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "Saulnier, Samson Tan, Pedro Ortiz Suarez, Vic-",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": ""
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Forde, Jordan Clive, Jungo Kasai, Ken Kawamura,"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "tor Sanh, Hugo Laurençon, Yacine Jernite,\nJulien",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": ""
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Liam Hazan, Marine Carpuat, Miruna Clinciu, Na-"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "Launay, Margaret Mitchell, Colin Raffel, Aaron",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": ""
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "joung Kim, Newton Cheng, Oleg Serikov, Omer"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "Gokaslan, Adi Simhi, Aitor Soroa, Alham Fikri",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": ""
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Antverg, Oskar van der Wal, Rui Zhang, Ruochen"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "Aji, Amit Alfassy, Anna Rogers, Ariel Kreisberg",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": ""
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Zhang, Sebastian Gehrmann, Shachar Mirkin, Shani"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "Nitzav, Canwen Xu, Chenghao Mou, Chris Emezue,",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": ""
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Pais, Tatiana Shavrina, Thomas Scialom, Tian Yun,"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "Christopher Klamm, Colin Leong, Daniel van Strien,",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": ""
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Tomasz Limisiewicz, Verena Rieser, Vitaly Protasov,"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "David\nIfeoluwa Adelani, Dragomir Radev,\nEd-",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": ""
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Vladislav Mikhailov, Yada Pruksachatkun, Yonatan"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "uardo González Ponferrada, Efrat Levkovizh, Ethan",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": ""
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Belinkov, Zachary Bamberger, Zdenˇek Kasner, Al-"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "Kim, Eyal Bar Natan, Francesco De Toni, Gérard",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": ""
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "ice Rueda, Amanda Pestana, Amir Feizpour, Am-"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "Dupont, Germán Kruszewski, Giada Pistilli, Hady",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": ""
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "mar Khan, Amy Faranak, Ana Santos, Anthony"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "Elsahar, Hamza Benyamina, Hieu Tran, Ian Yu, Idris",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": ""
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Hevia, Antigona Unldreaj, Arash Aghagol, Are-"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "Abdulmumin, Isaac Johnson, Itziar Gonzalez-Dios,",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": ""
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "zoo Abdollahi, Aycha Tammour, Azadeh HajiHos-"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "Javier de la Rosa, Jenny Chim, Jesse Dodge, Jian Zhu,",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": ""
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "seini, Bahareh Behroozi, Benjamin Ajibade, Bharat"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "Jonathan Chang, Jörg Frohberg, Joseph Tobing, Joy-",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": ""
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Saxena, Carlos Muñoz Ferrandis, Danish Contrac-"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "deep Bhattacharjee, Khalid Almubarak, Kimbo Chen,",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": ""
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "tor, David Lansky, Davis David, Douwe Kiela,"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "Kyle Lo, Leandro Von Werra, Leon Weber, Long",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": ""
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Duong A. Nguyen, Edward Tan, Emi Baylor, Ez-"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "Phan, Loubna Ben allal, Ludovic Tanguy, Manan",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": ""
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "inwanne Ozoani, Fatima Mirza, Frankline Onon-"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "Dey, Manuel Romero Muñoz, Maraim Masoud,",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": ""
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "iwu, Habib Rezanejad, Hessie Jones, Indrani Bhat-"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "María Grandury, Mario Šaško, Max Huang, Max-",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "tacharya,\nIrene Solaiman,\nIrina Sedenko,\nIsar Ne-"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "imin Coavoux, Mayank Singh, Mike Tian-Jian Jiang,",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "jadgholi, Jesse Passmore, Josh Seltzer, Julio Bonis"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "Minh Chien Vu, Mohammad A.\nJauhar, Mustafa",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Sanz, Livia Dutra, Mairon Samagaio, Maraim El-"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "Ghaleb, Nishant Subramani, Nora Kassner, Nuru-",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "badri, Margot Mieskes, Marissa Gerchick, Martha"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "laqilla Khamis, Olivier Nguyen, Omar Espejel, Ona",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Akinlolu, Michael McKenna, Mike Qiu, Muhammed"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "de Gibert, Paulo Villegas, Peter Henderson, Pierre",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "Ghauri, Mykola Burynok, Nafis Abrar, Nazneen Ra-"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "Colombo, Priscilla Amuok, Quentin Lhoest, Rheza",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": "jani, Nour Elkott, Nour Fahmy, Olanrewaju Samuel,"
        },
        {
          "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,": "Harliman, Rishi Bommasani, Roberto Luis López,",
          "Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-": ""
        }
      ],
      "page": 13
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "izadeh, Sarmad Shubber, Silas Wang, Sourav Roy,",
          "Fourth International Workshop on Semantic Evalua-": "tions (SemEval-2007), pages 70–74, Prague, Czech"
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "Sylvain Viguier, Thanh Le, Tobi Oyebade, Trieu Le,",
          "Fourth International Workshop on Semantic Evalua-": "Republic. Association for Computational Linguistics."
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "Yoyo Yang, Zach Nguyen, Abhinav Ramesh Kashyap,",
          "Fourth International Workshop on Semantic Evalua-": ""
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "",
          "Fourth International Workshop on Semantic Evalua-": "Adaku Uchendu, Zeyu Ma, Thai Le, Rui Zhang, and"
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "Alfredo Palasciano, Alison Callahan, Anima Shukla,",
          "Fourth International Workshop on Semantic Evalua-": ""
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "",
          "Fourth International Workshop on Semantic Evalua-": "Dongwon Lee. 2021. TURINGBENCH: A Bench-"
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "Antonio Miranda-Escalada, Ayush Singh, Benjamin",
          "Fourth International Workshop on Semantic Evalua-": ""
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "",
          "Fourth International Workshop on Semantic Evalua-": "mark Environment for Turing Test in the Age of Neu-"
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "Beilharz, Bo Wang, Caio Brito, Chenxi Zhou, Chirag",
          "Fourth International Workshop on Semantic Evalua-": ""
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "",
          "Fourth International Workshop on Semantic Evalua-": "ral Text Generation.\nIn Findings of the Association"
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "Jain, Chuxin Xu, Clémentine Fourrier, Daniel León",
          "Fourth International Workshop on Semantic Evalua-": ""
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "",
          "Fourth International Workshop on Semantic Evalua-": "for Computational Linguistics: EMNLP 2021, pages"
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "Periñán, Daniel Molano, Dian Yu, Enrique Manjava-",
          "Fourth International Workshop on Semantic Evalua-": ""
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "",
          "Fourth International Workshop on Semantic Evalua-": "2001–2016, Punta Cana, Dominican Republic. Asso-"
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "cas, Fabio Barth, Florian Fuhrimann, Gabriel Altay,",
          "Fourth International Workshop on Semantic Evalua-": ""
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "",
          "Fourth International Workshop on Semantic Evalua-": "ciation for Computational Linguistics."
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "Giyaseddin Bayrak, Gully Burns, Helena U. Vrabec,",
          "Fourth International Workshop on Semantic Evalua-": ""
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "Imane Bello, Ishani Dash, Jihyun Kang, John Giorgi,",
          "Fourth International Workshop on Semantic Evalua-": ""
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "",
          "Fourth International Workshop on Semantic Evalua-": "Alex Wang, Yada Pruksachatkun, Nikita Nangia, Aman-"
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "Jonas Golde,\nJose David Posada, Karthik Ranga-",
          "Fourth International Workshop on Semantic Evalua-": ""
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "",
          "Fourth International Workshop on Semantic Evalua-": "preet Singh, Julian Michael, Felix Hill, Omer Levy,"
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "sai Sivaraman, Lokesh Bulchandani, Lu Liu, Luisa",
          "Fourth International Workshop on Semantic Evalua-": ""
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "",
          "Fourth International Workshop on Semantic Evalua-": "and Samuel Bowman. 2019. SuperGLUE: A Stickier"
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "Shinzato, Madeleine Hahn de Bykhovetz, Maiko",
          "Fourth International Workshop on Semantic Evalua-": ""
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "",
          "Fourth International Workshop on Semantic Evalua-": "Benchmark for General-Purpose Language Under-"
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "Takeuchi, Marc Pàmies, Maria A. Castillo, Mari-",
          "Fourth International Workshop on Semantic Evalua-": ""
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "",
          "Fourth International Workshop on Semantic Evalua-": "standing Systems.\nIn Advances in Neural Informa-"
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "anna Nezhurina, Mario Sänger, Matthias Samwald,",
          "Fourth International Workshop on Semantic Evalua-": ""
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "",
          "Fourth International Workshop on Semantic Evalua-": "tion Processing Systems, volume 32. Curran Asso-"
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "Michael Cullan, Michael Weinberg, Michiel De Wolf,",
          "Fourth International Workshop on Semantic Evalua-": ""
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "",
          "Fourth International Workshop on Semantic Evalua-": "ciates, Inc."
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "Mina Mihaljcic, Minna Liu, Moritz Freidank, Myung-",
          "Fourth International Workshop on Semantic Evalua-": ""
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "sun Kang,\nNatasha\nSeelam,\nNathan Dahlberg,",
          "Fourth International Workshop on Semantic Evalua-": ""
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "",
          "Fourth International Workshop on Semantic Evalua-": "Alex Wang, Amanpreet Singh, Julian Michael, Felix"
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "Nicholas Michio Broad, Nikolaus Muellner, Pascale",
          "Fourth International Workshop on Semantic Evalua-": ""
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "",
          "Fourth International Workshop on Semantic Evalua-": "Hill, Omer Levy, and Samuel Bowman. 2018. GLUE:"
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "Fung, Patrick Haller, Ramya Chandrasekhar, Re-",
          "Fourth International Workshop on Semantic Evalua-": ""
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "",
          "Fourth International Workshop on Semantic Evalua-": "A Multi-Task Benchmark and Analysis Platform for"
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "nata Eisenberg, Robert Martin, Rodrigo Canalli, Ros-",
          "Fourth International Workshop on Semantic Evalua-": ""
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "",
          "Fourth International Workshop on Semantic Evalua-": "Natural Language Understanding.\nIn Proceedings"
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "aline Su, Ruisi Su, Samuel Cahyawijaya, Samuele",
          "Fourth International Workshop on Semantic Evalua-": ""
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "",
          "Fourth International Workshop on Semantic Evalua-": "of\nthe 2018 EMNLP Workshop BlackboxNLP: An-"
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "Garda, Shlok S. Deshmukh, Shubhanshu Mishra,",
          "Fourth International Workshop on Semantic Evalua-": ""
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "",
          "Fourth International Workshop on Semantic Evalua-": "alyzing and Interpreting Neural Networks for NLP,"
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "Sid Kiblawi, Simon Ott, Sinee Sang-aroonsiri, Sr-",
          "Fourth International Workshop on Semantic Evalua-": ""
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "",
          "Fourth International Workshop on Semantic Evalua-": "pages 353–355, Brussels, Belgium. Association for"
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "ishti Kumar, Stefan Schweter, Sushil Bharati, Tan-",
          "Fourth International Workshop on Semantic Evalua-": ""
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "",
          "Fourth International Workshop on Semantic Evalua-": "Computational Linguistics."
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "may Laud, Théo Gigant, Tomoya Kainuma, Wo-",
          "Fourth International Workshop on Semantic Evalua-": ""
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "jciech Kusa, Yanis Labrak, Yash Shailesh Bajaj,",
          "Fourth International Workshop on Semantic Evalua-": "Shuo Wang, Aishan Maoliniyazi, Xinle Wu, and Xi-"
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "Yash Venkatraman, Yifan Xu, Yingxin Xu, Yu Xu,",
          "Fourth International Workshop on Semantic Evalua-": "aofeng Meng. 2020a. Emo2Vec: Learning Emotional"
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "Zhe Tan, Zhongli Xie, Zifan Ye, Mathilde Bras,",
          "Fourth International Workshop on Semantic Evalua-": "ACM\nEmbeddings via Multi-Emotion Category."
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "Younes Belkada, and Thomas Wolf. 2023. BLOOM:",
          "Fourth International Workshop on Semantic Evalua-": "Transactions on Internet Technology, 20(2):13:1–"
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "A 176B-Parameter Open-Access Multilingual Lan-",
          "Fourth International Workshop on Semantic Evalua-": "13:17."
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "guage Model. ArXiv:2211.05100 [cs].",
          "Fourth International Workshop on Semantic Evalua-": ""
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "",
          "Fourth International Workshop on Semantic Evalua-": "Yan Wang, Jiayu Zhang, Jun Ma, Shaojun Wang, and"
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "Armin Seyeditabari, Narges Tabari, Shafie Gholizade,",
          "Fourth International Workshop on Semantic Evalua-": "Jing Xiao. 2020b. Contextualized Emotion Recogni-"
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "and Wlodek Zadrozny. 2019.\nEmotional Embed-",
          "Fourth International Workshop on Semantic Evalua-": "tion in Conversation as Sequence Tagging.\nIn Pro-"
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "dings: Refining Word Embeddings to Capture Emo-",
          "Fourth International Workshop on Semantic Evalua-": "ceedings of the 21th Annual Meeting of the Special"
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "tional Content of Words.\narXiv:1906.00112 [cs].",
          "Fourth International Workshop on Semantic Evalua-": "Interest Group on Discourse and Dialogue, pages"
        },
        {
          "Ran An, Rasmus Kromann, Ryan Hao, Samira Al-": "ArXiv: 1906.00112.",
          "Fourth International Workshop on Semantic Evalua-": "186–195, 1st virtual meeting. Association for Com-"
        }
      ],
      "page": 14
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "ing (EMNLP), pages 2461–2470, Online. Association": ""
        },
        {
          "ing (EMNLP), pages 2461–2470, Online. Association": "for Computational Linguistics."
        },
        {
          "ing (EMNLP), pages 2461–2470, Online. Association": ""
        },
        {
          "ing (EMNLP), pages 2461–2470, Online. Association": ""
        },
        {
          "ing (EMNLP), pages 2461–2470, Online. Association": "A\nPlutchik Wheel of Emotion"
        },
        {
          "ing (EMNLP), pages 2461–2470, Online. Association": ""
        },
        {
          "ing (EMNLP), pages 2461–2470, Online. Association": "The Plutchik Wheel of Emotion (Plutchik, 1980,"
        },
        {
          "ing (EMNLP), pages 2461–2470, Online. Association": ""
        },
        {
          "ing (EMNLP), pages 2461–2470, Online. Association": "2001) is shown in Figure 3 and is the most com-"
        },
        {
          "ing (EMNLP), pages 2461–2470, Online. Association": "monly used dimensional model in psychology liter-"
        },
        {
          "ing (EMNLP), pages 2461–2470, Online. Association": "ature."
        },
        {
          "ing (EMNLP), pages 2461–2470, Online. Association": ""
        },
        {
          "ing (EMNLP), pages 2461–2470, Online. Association": ""
        },
        {
          "ing (EMNLP), pages 2461–2470, Online. Association": ""
        }
      ],
      "page": 15
    },
    {
      "caption": "Table 8: The 50 synthetic",
      "data": [
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "ticles in the NEWSsynth training split, for exam-"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "ple, come from 150 online sources which also in-"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "clude: movie reviews and entertainment such as"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "rollingstone.com, hollywoodlife.com, bollywood-"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "hungama.com and mashable.com;\nand tabloids"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "such as thedailymail.co.uk, dailystar.co.uk, thedai-"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "lystar.net etc. which cover many types of news"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "including journalism, op-eds,\nreviews, opinions"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "etc.\nIn short, NEWSsynth is not\nlimited to non-"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "emotional objective fact\nreporting,\nit contains a"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "broad spectrum of journalistic styles and content."
        },
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "ChatGPT100\nWe release ChatGPT100, a dataset"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "comprising 100 English language articles in var-"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "ious non-news domains (Science, Entertainment"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "(Music, Movies), Sport, Business, and Philosophy)."
        },
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "50 articles are human written, and 50 articles are"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "generated by ChatGPT. The 100 articles have all"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "been manually curated and do not contain toxic"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "content. Furthermore, ChatGPT has a content filter"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "which flags potentially harmful content."
        },
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "The 50 human articles contained in ChatGPT100"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "were gathered between 16-24 March 2023 from"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "the domains shown in Table 8. The 50 synthetic"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "articles contained in ChatGPT100 were generated"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "using ChatGPT 3.5 (March 14 2023 version) on"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "dates between 16-24 March 2023."
        },
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "RealNews and RealNews-Test\nThese datasets"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "were released with Grover and are described there"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "in detail (Zellers et al., 2019)."
        },
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "Emotion and Sentiment Datasets\nGoodNew-"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "sEveryone is described in detail\n(Bostan et al.,"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "2020) with modifications made to the dataset for"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "this work described in §4.2. The distribution of"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "emotion intensity is shown in Table 9 showing al-"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "most all are ’medium’ while 2 examples have no"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "emotion. AffectiveText was released as part of Se-"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "mEval 2008 and is described in detail (Strapparava"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "and Mihalcea, 2008), while the SST-2 sentiment"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "dataset is described in detail (Socher et al., 2013)."
        },
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "C\nHyperparameters used for Fine-tuning"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "The hyperparameters used for PLM fine-tuning are"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "listed below.\nIf not specifically listed,\nthe hyper-"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "parameter value used was the default using Hug-"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "gingFace Transformer libraries. 12 The BERTBASE-"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "cased and BERTLARGE-cased models were down-"
        },
        {
          "to specifically exploit emotion. The 10k news ar-": ""
        },
        {
          "to specifically exploit emotion. The 10k news ar-": "12https://huggingface.co/transformers/"
        }
      ],
      "page": 16
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "• Data seeds = [17, 38, 5, 91, 59] #n, n-6, n+6": ""
        },
        {
          "• Data seeds = [17, 38, 5, 91, 59] #n, n-6, n+6": "for train-val-test seeds respectively"
        },
        {
          "• Data seeds = [17, 38, 5, 91, 59] #n, n-6, n+6": ""
        },
        {
          "• Data seeds = [17, 38, 5, 91, 59] #n, n-6, n+6": "• Metric for best model: F1µ"
        },
        {
          "• Data seeds = [17, 38, 5, 91, 59] #n, n-6, n+6": ""
        },
        {
          "• Data seeds = [17, 38, 5, 91, 59] #n, n-6, n+6": "• Training + Validation time: 11mins (for 10"
        },
        {
          "• Data seeds = [17, 38, 5, 91, 59] #n, n-6, n+6": ""
        },
        {
          "• Data seeds = [17, 38, 5, 91, 59] #n, n-6, n+6": "epochs)"
        },
        {
          "• Data seeds = [17, 38, 5, 91, 59] #n, n-6, n+6": ""
        },
        {
          "• Data seeds = [17, 38, 5, 91, 59] #n, n-6, n+6": "Inference time: 22s (for 2k examples)"
        },
        {
          "• Data seeds = [17, 38, 5, 91, 59] #n, n-6, n+6": ""
        }
      ],
      "page": 17
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "•\nInference time: 22s (for 2k examples)": ""
        },
        {
          "•\nInference time: 22s (for 2k examples)": "D\nemoBERT Emotion Classification"
        },
        {
          "•\nInference time: 22s (for 2k examples)": "Results"
        },
        {
          "•\nInference time: 22s (for 2k examples)": "The mean F1µ for emoBERT is 39.4% on the Valida-"
        },
        {
          "•\nInference time: 22s (for 2k examples)": "tion set - more than double mean chance (16.7%)"
        },
        {
          "•\nInference time: 22s (for 2k examples)": "and within the range 31% to 98% (mean = 62.6%)"
        },
        {
          "•\nInference time: 22s (for 2k examples)": ""
        },
        {
          "•\nInference time: 22s (for 2k examples)": "reported for within-corpus emotion classification in"
        },
        {
          "•\nInference time: 22s (for 2k examples)": ""
        },
        {
          "•\nInference time: 22s (for 2k examples)": "UnifiedEmotion (Bostan and Klinger, 2018). Good-"
        },
        {
          "•\nInference time: 22s (for 2k examples)": ""
        },
        {
          "•\nInference time: 22s (for 2k examples)": "NewsEveryone does not report news headline emo-"
        },
        {
          "•\nInference time: 22s (for 2k examples)": "tion classification (Bostan et al., 2020)."
        },
        {
          "•\nInference time: 22s (for 2k examples)": ""
        },
        {
          "•\nInference time: 22s (for 2k examples)": ""
        },
        {
          "•\nInference time: 22s (for 2k examples)": ""
        },
        {
          "•\nInference time: 22s (for 2k examples)": ""
        },
        {
          "•\nInference time: 22s (for 2k examples)": ""
        },
        {
          "•\nInference time: 22s (for 2k examples)": ""
        },
        {
          "•\nInference time: 22s (for 2k examples)": ""
        },
        {
          "•\nInference time: 22s (for 2k examples)": ""
        },
        {
          "•\nInference time: 22s (for 2k examples)": ""
        },
        {
          "•\nInference time: 22s (for 2k examples)": ""
        },
        {
          "•\nInference time: 22s (for 2k examples)": ""
        },
        {
          "•\nInference time: 22s (for 2k examples)": ""
        }
      ],
      "page": 17
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "goal for emoBERT. The purpose of emoBERT is to": "reduce the affective deficit of the PLM by modify-"
        },
        {
          "goal for emoBERT. The purpose of emoBERT is to": "ing the word representations of words representing"
        },
        {
          "goal for emoBERT. The purpose of emoBERT is to": "emotions and to improve performance in the task"
        },
        {
          "goal for emoBERT. The purpose of emoBERT is to": "of synthetic text detection by transfer learning."
        }
      ],
      "page": 18
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Source": "",
          "Words Per Article": "x",
          "Sentences Per Article": "σ",
          "Words Per Sentence": "σ"
        },
        {
          "Source": "Human",
          "Words Per Article": "594.56",
          "Sentences Per Article": "25.23",
          "Words Per Sentence": "15.98"
        },
        {
          "Source": "Synthetic",
          "Words Per Article": "417.98",
          "Sentences Per Article": "8.64",
          "Words Per Sentence": "16.60"
        },
        {
          "Source": "",
          "Words Per Article": "",
          "Sentences Per Article": "Figure 7",
          "Words Per Sentence": "Figure 8"
        },
        {
          "Source": "Table 10: Comparison of Human and synthetic text in the NEWSsynth dataset showing the mean (x) and standard deviation (σ)",
          "Words Per Article": "",
          "Sentences Per Article": "",
          "Words Per Sentence": ""
        },
        {
          "Source": "",
          "Words Per Article": "for Word Per Article, Sentences Per Article, and Words Per Sentence. Human articles are longer overall, but have slightly shorter",
          "Sentences Per Article": "",
          "Words Per Sentence": ""
        },
        {
          "Source": "",
          "Words Per Article": "sentences than synthetic text; and Human articles have more Sentences Per Article - which accounts for their longer mean length.",
          "Sentences Per Article": "",
          "Words Per Sentence": ""
        }
      ],
      "page": 19
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Generating Sentiment-Preserving Fake Online Reviews Using Neural Language Models and Their Human-and Machine-based Detection",
      "authors": [
        "David Ifeoluwa Adelani",
        "Haotian Mai",
        "Fuming Fang",
        "H Huy",
        "Junichi Nguyen",
        "Isao Yamagishi",
        "Echizen"
      ],
      "year": "2019",
      "venue": "Generating Sentiment-Preserving Fake Online Reviews Using Neural Language Models and Their Human-and Machine-based Detection",
      "arxiv": "arXiv:1907.09177[cs].ArXiv:1907.09177"
    },
    {
      "citation_id": "2",
      "title": "Learning Emotion-enriched Word Representations",
      "authors": [
        "Ameeta Agrawal",
        "Aijun An",
        "Manos Papagelis"
      ],
      "year": "2018",
      "venue": "Proceedings of the 27th International Conference on Computational Linguistics"
    },
    {
      "citation_id": "3",
      "title": "Why Exposure Bias Matters: An Imitation Learning Perspective of Error Accumulation in Language Generation",
      "authors": [
        "Kushal Arora",
        "Layla Asri",
        "Hareesh Bahuleyan",
        "Jackie Chi",
        "Kit Cheung"
      ],
      "year": "2022",
      "venue": "Why Exposure Bias Matters: An Imitation Learning Perspective of Error Accumulation in Language Generation",
      "doi": "10.48550/arXiv.2204.01171"
    },
    {
      "citation_id": "4",
      "title": "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? &#x1f99c",
      "authors": [
        "Emily Bender",
        "Timnit Gebru",
        "Angelina Mcmillan-Major",
        "Shmargaret Shmitchell"
      ],
      "year": "2021",
      "venue": "Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, FAccT '21",
      "doi": "10.1145/3442188.3445922"
    },
    {
      "citation_id": "5",
      "title": "How Effectively Can Machines Defend Against Machine-Generated Fake News? An Empirical Study",
      "authors": [
        "Meghana Moorthy",
        "Srinivasan Parthasarathy"
      ],
      "year": "2020",
      "venue": "Proceedings of the First Workshop on Insights from Negative Results in NLP"
    },
    {
      "citation_id": "6",
      "title": "Emotion during reading and writing",
      "authors": [
        "Catherine Bohn-Gettler",
        "David Rapp"
      ],
      "year": "2014",
      "venue": "International handbook of emotions in education, Educational psychology handbook series"
    },
    {
      "citation_id": "7",
      "title": "GoodNewsEveryone: A Corpus of News Headlines Annotated with Emotions, Semantic Roles, and Reader Perception",
      "authors": [
        "/ Routledge",
        "Francis Taylor",
        "New Group",
        "N York",
        "Laura Ana",
        "Maria Bostan",
        "Evgeny Kim",
        "Roman Klinger"
      ],
      "year": "2020",
      "venue": "Proceedings of the 12th Language Resources and Evaluation Conference"
    },
    {
      "citation_id": "8",
      "title": "An Analysis of Annotated Corpora for Emotion Classification in Text",
      "authors": [
        "Laura-Ana-Maria Bostan",
        "Roman Klinger"
      ],
      "year": "2018",
      "venue": "Proceedings of the 27th International Conference on Computational Linguistics"
    },
    {
      "citation_id": "9",
      "title": "Social Cognition, Emotions, and the Psychology of Writing",
      "authors": [
        "Alice Brand"
      ],
      "year": "1991",
      "venue": "Journal of Advanced Composition"
    },
    {
      "citation_id": "10",
      "title": "HOT COGNITION: EMO-TIONS AND WRITING BEHAVIOR",
      "authors": [
        "Alice Brand"
      ],
      "year": "1985",
      "venue": "Journal of Advanced Composition"
    },
    {
      "citation_id": "11",
      "title": "The Why of Cognition: Emotion and the Writing Process. College Composition and Communication",
      "authors": [
        "Alice Brand"
      ],
      "year": "1987",
      "venue": "The Why of Cognition: Emotion and the Writing Process. College Composition and Communication",
      "doi": "10.2307/357637"
    },
    {
      "citation_id": "12",
      "title": "Language Models are Few-Shot Learners",
      "authors": [
        "B Tom",
        "Benjamin Brown",
        "Nick Mann",
        "Melanie Ryder",
        "Jared Subbiah",
        "Prafulla Kaplan",
        "Arvind Dhariwal",
        "Pranav Neelakantan",
        "Girish Shyam",
        "Amanda Sastry",
        "Sandhini Askell",
        "Ariel Agarwal",
        "Gretchen Herbert-Voss",
        "Tom Krueger",
        "Rewon Henighan",
        "Aditya Child",
        "Daniel Ramesh",
        "Jeffrey Ziegler",
        "Clemens Wu",
        "Christopher Winter",
        "Mark Hesse",
        "Eric Chen",
        "Mateusz Sigler",
        "Scott Litwin",
        "Benjamin Gray",
        "Jack Chess",
        "Christopher Clark",
        "Sam Berner",
        "Alec Mccandlish",
        "Ilya Radford",
        "Dario Sutskever",
        "Amodei"
      ],
      "year": "2020",
      "venue": "Language Models are Few-Shot Learners",
      "arxiv": "arXiv:2005.14165[cs].ArXiv:2005.14165"
    },
    {
      "citation_id": "13",
      "title": "All That's 'Human' Is Not Gold: Evaluating Human Evaluation of Generated Text",
      "authors": [
        "Elizabeth Clark",
        "Tal August",
        "Sofia Serrano",
        "Nikita Haduong",
        "Suchin Gururangan",
        "Noah Smith"
      ],
      "year": "2021",
      "venue": "All That's 'Human' Is Not Gold: Evaluating Human Evaluation of Generated Text",
      "arxiv": "arXiv:2107.00061[cs].ArXiv:2107.00061"
    },
    {
      "citation_id": "14",
      "title": "Times editor apologises for 'breach of trust",
      "venue": "Times editor apologises for 'breach of trust"
    },
    {
      "citation_id": "15",
      "title": "2023b. Irish Times takes down article amid AI suggestions",
      "authors": [
        "Sinéad Crowley"
      ],
      "venue": "2023b. Irish Times takes down article amid AI suggestions"
    },
    {
      "citation_id": "16",
      "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "authors": [
        "Jacob Devlin",
        "Ming-Wei Chang",
        "Kenton Lee",
        "Kristina Toutanova"
      ],
      "year": "2019",
      "venue": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "arxiv": "arXiv:1810.04805[cs].ArXiv:1810.04805"
    },
    {
      "citation_id": "17",
      "title": "An argument for basic emotions",
      "authors": [
        "Paul Ekman"
      ],
      "year": "1992",
      "venue": "Cognition and Emotion",
      "doi": "10.1080/02699939208411068"
    },
    {
      "citation_id": "18",
      "title": "Basic Emotions",
      "authors": [
        "Paul Ekman"
      ],
      "year": "1999",
      "venue": "Handbook of Cognition and Emotion",
      "doi": "10.1002/0470013494.ch3"
    },
    {
      "citation_id": "19",
      "title": "What Scientists Who Study Emotion Agree About",
      "authors": [
        "Paul Ekman"
      ],
      "year": "2016",
      "venue": "Perspectives on Psychological Science",
      "doi": "10.1177/1745691615596992"
    },
    {
      "citation_id": "20",
      "title": "Comparing scientific abstracts generated by ChatGPT to original abstracts using an artificial intelligence output detector, plagiarism detector, and blinded human reviewers",
      "authors": [
        "Catherine Gao",
        "Frederick Howard",
        "Nikolay Markov",
        "Emma Dyer",
        "Siddhi Ramesh",
        "Yuan Luo",
        "Alexander Pearson"
      ],
      "year": "2022",
      "venue": "Comparing scientific abstracts generated by ChatGPT to original abstracts using an artificial intelligence output detector, plagiarism detector, and blinded human reviewers",
      "doi": "10.1101/2022.12.23.521610"
    },
    {
      "citation_id": "21",
      "title": "RealToxi-cityPrompts: Evaluating Neural Toxic Degeneration in Language Models",
      "authors": [
        "Suchin Samuel Gehman",
        "Maarten Gururangan",
        "Yejin Sap",
        "Noah Choi",
        "Smith"
      ],
      "year": "2020",
      "venue": "Findings of the Association for Computational Linguistics: EMNLP 2020",
      "doi": "10.18653/v1/2020.findings-emnlp.301"
    },
    {
      "citation_id": "22",
      "title": "GLTR: Statistical Detection and Visualization of Generated Text",
      "authors": [
        "Sebastian Gehrmann",
        "Hendrik Strobelt",
        "Alexander Rush"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations",
      "doi": "10.18653/v1/P19-3019"
    },
    {
      "citation_id": "23",
      "title": "Viable Threat on News Reading: Generating Biased News Using Natural Language Models",
      "authors": [
        "Saurabh Gupta",
        "Hong Huy Nguyen",
        "Junichi Yamagishi",
        "Isao Echizen"
      ],
      "year": "2020",
      "venue": "Proceedings of the Fourth Workshop on Natural Language Processing and Computational Social Science",
      "doi": "10.18653/v1/2020.nlpcss-1.7"
    },
    {
      "citation_id": "24",
      "title": "Public Hearing on Whistleblower's testimony on the negative impact of big tech companies' products on user: opening statement by Frances HAUGEN",
      "authors": [
        "Frances Haugen"
      ],
      "year": "2021",
      "venue": "Public Hearing on Whistleblower's testimony on the negative impact of big tech companies' products on user: opening statement by Frances HAUGEN"
    },
    {
      "citation_id": "25",
      "title": "The Curious Case of Neural Text Degeneration",
      "authors": [
        "Ari Holtzman",
        "Jan Buys",
        "Li Du",
        "Maxwell Forbes",
        "Yejin Choi"
      ],
      "year": "2020",
      "venue": "The Curious Case of Neural Text Degeneration"
    },
    {
      "citation_id": "26",
      "title": "Automatic Dialogue Generation with Expressed Emotions",
      "authors": [
        "Chenyang Huang",
        "Osmar Zaïane",
        "Amine Trabelsi",
        "Nouha Dziri"
      ],
      "year": "2018",
      "venue": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
      "doi": "10.18653/v1/N18-2008"
    },
    {
      "citation_id": "27",
      "title": "Automatic Detection of Generated Text is Easiest when Humans are Fooled",
      "authors": [
        "Daphne Ippolito",
        "Daniel Duckworth",
        "Chris Callison-Burch",
        "Douglas Eck"
      ],
      "year": "2020",
      "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/2020.acl-main.164"
    },
    {
      "citation_id": "28",
      "title": "Emotions and the Process of Writing",
      "authors": [
        "Susanne Knaller"
      ],
      "year": "2017",
      "venue": "Lettre, 1 edition",
      "doi": "10.14361/9783839437933-002"
    },
    {
      "citation_id": "29",
      "title": "Michela Lorandi and Anya Belz. 2023. How to Control Sentiment in Text Generation: A Survey of the State-of-the-Art in Sentiment-Control Techniques",
      "authors": [
        "Bernhard Kratzwald",
        "Suzana Ilic",
        "Mathias Kraus",
        "Stefan Feuerriegel",
        "Helmut Prendinger"
      ],
      "year": "2018",
      "venue": "Proceedings of the 13th Workshop on Computational Approaches to Subjectivity",
      "doi": "10.1016/j.dss.2018.09.002"
    },
    {
      "citation_id": "30",
      "title": "What Happens To BERT Embeddings During Fine-tuning?",
      "authors": [
        "Amil Merchant",
        "Elahe Rahimtoroghi",
        "Ellie Pavlick",
        "Ian Tenney"
      ],
      "year": "2020",
      "venue": "Proceedings of the Third BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP",
      "doi": "10.18653/v1/2020.blackboxnlp-1.4"
    },
    {
      "citation_id": "31",
      "title": "Efficient Estimation of Word Representations in Vector Space",
      "authors": [
        "Tomás Mikolov",
        "Kai Chen",
        "Greg Corrado",
        "Jeffrey Dean"
      ],
      "year": "2013",
      "venue": "1st International Conference on Learning Representations, ICLR 2013"
    },
    {
      "citation_id": "32",
      "title": "DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature",
      "authors": [
        "Eric Mitchell",
        "Yoonho Lee",
        "Alexander Khazatsky",
        "Christopher Manning",
        "Chelsea Finn"
      ],
      "year": "2023",
      "venue": "DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature",
      "doi": "10.48550/arXiv.2301.11305"
    },
    {
      "citation_id": "33",
      "title": "OpenAI. 2022. Introducing ChatGPT",
      "venue": "OpenAI. 2022. Introducing ChatGPT"
    },
    {
      "citation_id": "34",
      "title": "Training language models to follow instructions with human feedback",
      "authors": [
        "Long Ouyang",
        "Jeff Wu",
        "Xu Jiang",
        "Diogo Almeida",
        "Carroll Wainwright",
        "Pamela Mishkin",
        "Chong Zhang",
        "Sandhini Agarwal",
        "Katarina Slama",
        "Alex Ray",
        "John Schulman",
        "Jacob Hilton",
        "Fraser Kelton",
        "Luke Miller",
        "Maddie Simens",
        "Amanda Askell",
        "Peter Welinder",
        "Paul Christiano",
        "Jan Leike",
        "Ryan Lowe"
      ],
      "year": "2022",
      "venue": "Training language models to follow instructions with human feedback",
      "doi": "10.48550/ARXIV.2203.02155"
    },
    {
      "citation_id": "35",
      "title": "A Survey on Transfer Learning",
      "authors": [
        "Jialin Sinno",
        "Qiang Pan",
        "Yang"
      ],
      "year": "2010",
      "venue": "Conference Name: IEEE Transactions on Knowledge and Data Engineering",
      "doi": "10.1109/TKDE.2009.191"
    },
    {
      "citation_id": "36",
      "title": "MAUVE: Measuring the Gap Between Neural Text and Human Text using Divergence Frontiers",
      "authors": [
        "Krishna Pillutla",
        "Swabha Swayamdipta",
        "Rowan Zellers",
        "John Thickstun",
        "Sean Welleck",
        "Yejin Choi",
        "Zaid Harchaoui"
      ],
      "year": "2021",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "37",
      "title": "Chapter 1 -A GENERAL PSYCHOEVOLUTIONARY THEORY OF EMO-TION",
      "authors": [
        "Robert Plutchik"
      ],
      "year": "1980",
      "venue": "Theories of Emotion",
      "doi": "10.1016/B978-0-12-558701-3.50007-7"
    },
    {
      "citation_id": "38",
      "title": "The Nature of Emotions: Human emotions have deep evolutionary roots, a fact that may explain their complexity and provide tools for clinical practice",
      "authors": [
        "Robert Plutchik"
      ],
      "year": "2001",
      "venue": "American Scientist"
    },
    {
      "citation_id": "39",
      "title": "Language Models are Unsupervised Multitask Learners",
      "authors": [
        "Alec Radford",
        "Jeffrey Wu",
        "Rewon Child",
        "David Luan",
        "Dario Amodei",
        "Ilya Sutskever"
      ],
      "year": "2019",
      "venue": "Language Models are Unsupervised Multitask Learners"
    },
    {
      "citation_id": "40",
      "title": "Sequence Level Training with Recurrent Neural Networks",
      "authors": [
        "Aurelio Marc",
        "Sumit Ranzato",
        "Michael Chopra",
        "Wojciech Auli",
        "Zaremba"
      ],
      "year": "2016",
      "venue": "Sequence Level Training with Recurrent Neural Networks"
    },
    {
      "citation_id": "41",
      "title": "Towards Empathetic Open-domain Conversation Models: a New Benchmark and Dataset",
      "authors": [
        "Eric Hannah Rashkin",
        "Margaret Smith",
        "Y.-Lan Li",
        "Boureau"
      ],
      "year": "2019",
      "venue": "Towards Empathetic Open-domain Conversation Models: a New Benchmark and Dataset",
      "arxiv": "arXiv:1811.00207[cs].ArXiv:1811.00207"
    },
    {
      "citation_id": "42",
      "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter",
      "authors": [
        "Victor Sanh",
        "Lysandre Debut",
        "Julien Chaumond",
        "Thomas Wolf"
      ],
      "year": "2019",
      "venue": "5th Workshop on Energy Efficient Machine Learning and Cognitive Computing -NeurIPS",
      "doi": "10.48550/arXiv.1910.01108"
    },
    {
      "citation_id": "43",
      "title": "Taking Antonymy Mask off in Vector Space",
      "authors": [
        "Enrico Santus",
        "Qin Lu",
        "Alessandro Lenci",
        "Chu-Ren Huang"
      ],
      "year": "2014",
      "venue": "Proceedings of the 28th Pacific Asia Conference on Language, Information and Computing"
    },
    {
      "citation_id": "44",
      "title": "Hyung Won Chung, Jaesung Tae",
      "authors": [
        "Le Teven",
        "Angela Scao",
        "Christopher Fan",
        "Ellie Akiki",
        "Suzana Pavlick",
        "Daniel Ilić",
        "Roman Hesslow",
        "Alexandra Castagné",
        "François Sasha Luccioni",
        "Matthias Yvon",
        "Jonathan Gallé",
        "Alexander Tow",
        "Stella Rush",
        "Albert Biderman",
        "Pawan Webson",
        "Thomas Sasanka Ammanamanchi",
        "Benoît Wang",
        "Niklas Sagot",
        "Albert Muennighoff",
        "Olatunji Villanova Del Moral",
        "Rachel Ruwase",
        "Stas Bawden",
        "Angelina Bekman",
        "Iz Mcmillan-Major",
        "Huu Beltagy",
        "Lucile Nguyen",
        "Samson Saulnier",
        "Pedro Tan",
        "Victor Suarez",
        "Hugo Sanh",
        "Yacine Laurençon",
        "Julien Jernite",
        "Margaret Launay",
        "Colin Mitchell",
        "Aaron Raffel",
        "Adi Gokaslan",
        "Aitor Simhi",
        "Alham Soroa",
        "Amit Fikri Aji",
        "Anna Alfassy",
        "Ariel Rogers",
        "Canwen Nitzav",
        "Chenghao Xu",
        "Chris Mou",
        "Christopher Emezue",
        "Colin Klamm",
        "Leong",
        "David Daniel Van Strien",
        "Dragomir Ifeoluwa Adelani",
        "Eduardo Radev",
        "Efrat Ponferrada",
        "Ethan Levkovizh",
        "Eyal Kim",
        "Francesco Bar Natan",
        "Gérard Toni",
        "Germán Dupont",
        "Giada Kruszewski",
        "Hady Pistilli",
        "Hamza Elsahar",
        "Hieu Benyamina",
        "Ian Tran",
        "Idris Yu",
        "Isaac Abdulmumin",
        "Itziar Johnson",
        "Javier Gonzalez-Dios",
        "Jenny De La Rosa",
        "Jesse Chim",
        "Jian Dodge",
        "Jonathan Zhu",
        "Jörg Chang",
        "Joseph Frohberg",
        "Joydeep Tobing",
        "Khalid Bhattacharjee",
        "Kimbo Almubarak",
        "Kyle Chen",
        "Leandro Lo",
        "Leon Von Werra",
        "Long Weber",
        "Paulo Phan",
        "Peter Villegas",
        "Pierre Henderson",
        "Priscilla Colombo",
        "Quentin Amuok",
        "Rheza Lhoest",
        "Rishi Harliman",
        "Roberto Bommasani",
        "Rui Luis López",
        "Salomey Ribeiro",
        "Sampo Osei",
        "Sebastian Pyysalo",
        "Shamik Nagel",
        "Shamsuddeen Bose",
        "Shanya Hassan Muhammad",
        "Shayne Sharma",
        "Somaieh Longpre",
        "Stanislav Nikpoor",
        "Suhas Silberberg",
        "Sydney Pai",
        "Tiago Zink",
        "Timo Timponi Torrent",
        "Tristan Schick",
        "Valentin Thrush",
        "Vassilina Danchev",
        "Veronika Nikoulina",
        "Violette Laippala",
        "Vrinda Lepercq",
        "Zaid Prabhu",
        "Zeerak Alyafeai",
        "Arun Talat",
        "Benjamin Raja",
        "Chenglei Heinzerling",
        "Davut Si",
        "Elizabeth Taşar",
        "Sabrina Salesky",
        "Wilson Mielke",
        "Abheesht Lee",
        "Andrea Sharma",
        "Antoine Santilli",
        "Arnaud Chaffin",
        "Debajyoti Stiegler",
        "Eliza Datta",
        "Gunjan Szczechla",
        "Han Chhablani",
        "Harshit Wang",
        "Hendrik Pandey",
        "Jason Strobelt",
        "Alan Fries",
        "Jos Rozen",
        "Leo Gao",
        "Lintang Sutawika",
        "M Saiful",
        "Maged Bari",
        "Matteo Al-Shaibani",
        "Nihal Manica",
        "Ryan Nayak",
        "Samuel Teehan",
        "Sheng Albanie",
        "Srulik Shen",
        "Stephen Ben-David",
        "Taewoon Bach",
        "Tali Kim",
        "Thibault Bers",
        "Trishala Fevry",
        "Urmish Neeraj",
        "Vikas Thakker",
        "Xiangru Raunak",
        "Zheng-Xin Tang",
        "Zhiqing Yong",
        "Shaked Sun",
        "Yallow Brody",
        "Hadar Uri",
        "Adam Tojarieh",
        "Ofir Roberts ; Phang",
        "Conglong Press",
        "Deepak Li",
        "Hatim Narayanan",
        "Jared Bourfoune",
        "Jeff Casper",
        "Max Rasley",
        "Mayank Ryabinin",
        "Minjia Mishra",
        "Mohammad Zhang",
        "Myriam Shoeybi",
        "Nicolas Peyrounette",
        "Nouamane Patry",
        "Omar Tazi",
        "Sanseviero",
        "Pierre Patrick Von Platen",
        "Pierre Cornette",
        "Rémi François Lavallée",
        "Samyam Lacroix",
        "Sanchit Rajbhandari",
        "Shaden Gandhi",
        "Stéphane Smith",
        "Suraj Requena",
        "Tim Patil",
        "Ahmed Dettmers",
        "Amanpreet Baruwa",
        "Anastasia Singh",
        "Anne-Laure Cheveleva",
        "Arjun Ligozat",
        "Aurélie Subramonian",
        "Charles Névéol",
        "Dan Lovering",
        "Deepak Garrette",
        "Ehud Tunuguntla",
        "Ekaterina Reiter",
        "Ekaterina Taktasheva",
        "Eli Voloshina",
        "Genta Bogdanov",
        "Hailey Indra Winata",
        "Jan-Christoph Schoelkopf",
        "Jekaterina Kalo",
        "Jessica Novikova",
        "Jordan Zosa Forde",
        "Jungo Clive",
        "Ken Kasai",
        "Liam Kawamura",
        "Marine Hazan",
        "Miruna Carpuat",
        "Najoung Clinciu",
        "Newton Kim",
        "Oleg Cheng",
        "Omer Serikov",
        "Oskar Antverg",
        "Rui Van Der Wal",
        "Ruochen Zhang",
        "Sebastian Zhang",
        "Shachar Gehrmann",
        "Shani Mirkin",
        "Tatiana Pais",
        "Thomas Shavrina",
        "Tian Scialom",
        "Tomasz Yun",
        "Verena Limisiewicz",
        "Vitaly Rieser",
        "Vladislav Protasov",
        "Yada Mikhailov",
        "Yonatan Pruksachatkun",
        "Zachary Belinkov",
        "Zdeněk Bamberger",
        "Alice Kasner",
        "Amanda Rueda",
        "Amir Pestana",
        "Ammar Feizpour",
        "Amy Khan",
        "Ana Faranak",
        "Anthony Santos",
        "Silas Hevia",
        "Sourav Wang",
        "Sylvain Roy",
        "Thanh Viguier",
        "Tobi Le",
        "Trieu Oyebade",
        "Yoyo Le",
        "Zach Yang",
        "Nguyen ; Chenxi",
        "Chirag Zhou",
        "Chuxin Jain",
        "Clémentine Xu",
        "Fourrier",
        "Daniel Daniel León Periñán",
        "Dian Molano",
        "Enrique Yu",
        "Fabio Manjavacas",
        "Florian Barth",
        "Gabriel Fuhrimann",
        "Giyaseddin Altay",
        "Gully Bayrak",
        "Helena Burns",
        "Imane Vrabec",
        "Ishani Bello",
        "Jihyun Dash",
        "John Kang",
        "Jonas Giorgi",
        "Jose Golde",
        "Karthik David Posada",
        "Lokesh Rangasai Sivaraman",
        "Lu Bulchandani",
        "Luisa Liu",
        "Shinzato"
      ],
      "venue": "Antigona Unldreaj, Arash Aghagol, Arezoo Abdollahi",
      "doi": "10.48550/arXiv.2211.05100"
    },
    {
      "citation_id": "45",
      "title": "Emotional Embeddings: Refining Word Embeddings to Capture Emotional Content of Words",
      "authors": [
        "Armin Seyeditabari",
        "Narges Tabari",
        "Shafie Gholizade",
        "Wlodek Zadrozny"
      ],
      "year": "2019",
      "venue": "Emotional Embeddings: Refining Word Embeddings to Capture Emotional Content of Words",
      "arxiv": "arXiv:1906.00112[cs].ArXiv:1906.00112"
    },
    {
      "citation_id": "46",
      "title": "Can Word Embeddings Help Find Latent Emotions in Text? Preliminary Results",
      "authors": [
        "Armin Seyeditabari",
        "Wlodek Zadrozny"
      ],
      "year": "2017",
      "venue": "The Thirtieth International Flairs Conference"
    },
    {
      "citation_id": "47",
      "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank",
      "authors": [
        "Richard Socher",
        "Alex Perelygin",
        "Jean Wu",
        "Jason Chuang",
        "Christopher Manning",
        "Andrew Ng",
        "Christopher Potts"
      ],
      "year": "2013",
      "venue": "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "48",
      "title": "Anxiety as an Emotional State",
      "authors": [
        "Charles Spielberger"
      ],
      "year": "1972",
      "venue": "Current trends and research",
      "doi": "10.1016/B978-0-12-657401-2.50009-5"
    },
    {
      "citation_id": "49",
      "title": "Learning to identify emotions in text",
      "authors": [
        "C Strapparava",
        "Rada Mihalcea"
      ],
      "year": "2008",
      "venue": "SAC '08",
      "doi": "10.1145/1363686.1364052"
    },
    {
      "citation_id": "50",
      "title": "SemEval-2007 Task 14: Affective Text",
      "authors": [
        "Carlo Strapparava",
        "Rada Mihalcea"
      ],
      "year": "2007",
      "venue": "Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007)"
    },
    {
      "citation_id": "51",
      "title": "TURINGBENCH: A Benchmark Environment for Turing Test in the Age of Neural Text Generation",
      "authors": [
        "Adaku Uchendu",
        "Zeyu Ma",
        "Thai Le",
        "Rui Zhang",
        "Dongwon Lee"
      ],
      "year": "2021",
      "venue": "Findings of the Association for Computational Linguistics: EMNLP 2021"
    },
    {
      "citation_id": "52",
      "title": "SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems",
      "authors": [
        "Alex Wang",
        "Yada Pruksachatkun",
        "Nikita Nangia",
        "Amanpreet Singh",
        "Julian Michael",
        "Felix Hill",
        "Omer Levy",
        "Samuel Bowman"
      ],
      "year": "2019",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "53",
      "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding",
      "authors": [
        "Alex Wang",
        "Amanpreet Singh",
        "Julian Michael",
        "Felix Hill",
        "Omer Levy",
        "Samuel Bowman"
      ],
      "year": "2018",
      "venue": "Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP",
      "doi": "10.18653/v1/W18-5446"
    },
    {
      "citation_id": "54",
      "title": "Vec: Learning Emotional Embeddings via Multi-Emotion Category",
      "authors": [
        "Shuo Wang",
        "Aishan Maoliniyazi",
        "Xinle Wu",
        "Xiaofeng Meng"
      ],
      "year": "2020",
      "venue": "ACM Transactions on Internet Technology",
      "doi": "10.1145/3372152"
    },
    {
      "citation_id": "55",
      "title": "Contextualized Emotion Recognition in Conversation as Sequence Tagging",
      "authors": [
        "Yan Wang",
        "Jiayu Zhang",
        "Jun Ma",
        "Shaojun Wang",
        "Jing Xiao"
      ],
      "year": "2020",
      "venue": "Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue"
    },
    {
      "citation_id": "56",
      "title": "Deepfake Bot Submissions to Federal Public Comment Websites Cannot Be Distinguished from Human Submissions",
      "authors": [
        "Max Weiss"
      ],
      "year": "2019",
      "venue": "Technology Science"
    },
    {
      "citation_id": "57",
      "title": "Out-of-Distribution Generalization in Text Classification: Past, Present, and Future",
      "authors": [
        "Linyi Yang",
        "Yaoxiao Song",
        "Xuan Ren",
        "Chenyang Lyu",
        "Yidong Wang",
        "Lingqiao Liu",
        "Jindong Wang",
        "Jennifer Foster",
        "Yue Zhang"
      ],
      "year": "2023",
      "venue": "Out-of-Distribution Generalization in Text Classification: Past, Present, and Future",
      "doi": "10.48550/arXiv.2305.14104"
    },
    {
      "citation_id": "58",
      "title": "Defending Against Neural Fake News",
      "authors": [
        "Rowan Zellers",
        "Ari Holtzman",
        "Hannah Rashkin",
        "Yonatan Bisk",
        "Ali Farhadi",
        "Franziska Roesner",
        "Yejin Choi"
      ],
      "year": "2019",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "59",
      "title": "Neural Deepfake Detection with Factual Structure of Text",
      "authors": [
        "Wanjun Zhong",
        "Duyu Tang",
        "Zenan Xu",
        "Ruize Wang",
        "Nan Duan",
        "Ming Zhou",
        "Jiahai Wang",
        "Jian Yin"
      ],
      "year": "2020",
      "venue": "Proceedings of the 2020 Conference",
      "doi": "10.18653/v1/2020.emnlp-main.193"
    }
  ]
}