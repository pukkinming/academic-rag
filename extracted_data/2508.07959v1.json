{
  "paper_id": "2508.07959v1",
  "title": "Large Language Models For Subjective Language Understanding: A Survey",
  "published": "2025-08-11T13:10:44Z",
  "authors": [
    "Changhao Song",
    "Yazhou Zhang",
    "Hui Gao",
    "Ben Yao",
    "Peng Zhang"
  ],
  "keywords": [
    "including sentiment analysis",
    "emotion recognition",
    "sarcasm detection",
    "humor understanding",
    "stance detection",
    "metaphor"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Subjective language understanding refers to a broad set of natural language processing tasks where the goal is to interpret or generate content that conveys personal feelings, opinions, or figurative meanings rather than objective facts. With the advent of large language models (LLMs) such as ChatGPT, LLaMA, and others, there has been a paradigm shift in how we approach these inherently nuanced tasks. In this survey, we provide a comprehensive review of recent advances in applying LLMs to subjective language tasks,",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction 1.Background And Motivation",
      "text": "Human communication is rich with subjective language -expressions of sentiment, emotion, opinion, humor, sarcasm, metaphor, and other non-literal or evaluative meanings. Understanding such language is crucial for AI systems that interact with humans or analyze human-generated text. Traditional NLP approaches to these tasks often relied on task-specific models and carefully crafted features or annotated data. For example, sentiment analysis has long been tackled with machine learning classifiers or pre-trained language models fine-tuned on labeled sentiment corpora, and sarcasm detection research evolved from manual pattern-based methods to neural models over the past decade. However, these narrow models typically handled each subjective phenomenon in isolation and lacked generalization: a model trained for sentiment would not handle humor, and vice versa.\n\nThe rise of large language models (LLMs) has brought new opportunities to address subjective language understanding in a more unified and general way. Modern LLMs such as OpenAI's GPT-4, Google's PaLM, Meta's LLaMA, etc., have demonstrated remarkable capabilities in natural language understanding and generation across a wide range of tasks, via techniques like zero-shot/few-shot prompting and instruction tuning. Intuitively, many subjective language tasks might benefit from these capabilities: for instance, an LLM might recognize subtle sarcastic cues by virtue of having seen many examples in its training data, or it might generate more empathetic responses by leveraging learned patterns of emotional expression. Early successes with LLMs (e.g., GPT-3) on tasks like zero-shot sentiment analysis suggested that they internalize a great deal of subjective semantic knowledge. As a result, the community has shifted toward exploring how prompting or fine-tuning LLMs can solve affective and subjective NLP tasks that were previously considered very challenging. Despite this optimism, subjective language understanding remains unsolved. These tasks often require nuanced contextual and commonsense reasoning, understanding of tone and pragmatics, and even a theory of mind. There are growing research efforts to evaluate how well LLMs truly \"understand\" emotions, humor, or figurative meanings, and results have been mixed. For example, while LLMs have made progress in sentiment analysis and emotion recognition, they still struggle with sarcasm and humor. In one study, GPT-4 was found to perform roughly at a human level on sentiment, emotion intensity, and political stance classification, but sarcasm detection remained a stumbling block. Such findings motivate a closer look at each type of subjective task to identify what unique challenges it poses and the progress current LLMs have made toward meeting those challenges.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "What Is Subjective Language",
      "text": "Subjective language can be defined as any utterance or text whose meaning or interpretation depends on personal perspectives, feelings, or opinions, rather than objective facts. From a linguistic perspective, subjectivity in language is often indicated by the presence of opinionated words, emotion-laden expressions, first-person viewpoints, or figurative devices. For example, the sentence \"The movie was an absolute masterpiece!\" is subjective because it expresses the speaker's positive evaluation (it's not a verifiable fact, but an opinion). Similarly, \"I feel upset about what happened\" is subjective, revealing an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions can be marked in text (e.g., through certain adjectives, intensifiers, or discourse structures), and how they differ from objective statements of fact. A classic NLP problem formulation is subjectivity classification: determining if a given sentence is subjective or objective. This can be seen as a coarse form of subjective language understanding. From a cognitive perspective, subjective language relates to the speaker's or writer's internal state -their emotions, attitudes, beliefs, or intentions. Cognitive and psychological studies of language indicate that understanding subjectivity often requires theory of mind (inferring the speaker's intent or feelings) and empathy. For instance, sarcasm and irony are quintessential subjective uses of language: the literal content diverges from the intended meaning, and the listener must infer the speaker's true attitude (often the opposite of the literal words). Similarly, humor involves cognitive processes like surprise, incongruity, and shared knowledge between the interlocutors. Affective science provides insights into how humans express and perceive emotions through language (e.g. certain metaphors like \"heartbroken\" to indicate sadness). Thus, subjective language understanding is inherently interdisciplinary, bridging NLP with cognitive psychology.\n\nIn this survey, subjective language is an umbrella term encompassing affective language (sentiments, emotions, and attitudes) and figurative or non-literal language (sarcasm, humor, metaphor, etc.), as well as other subjectivity phenomena like personal intent or aesthetic preference. All these facets share the quality that purely literal or surface-level analysis often fails -one must grasp the underlying subjective meaning. We will clarify the scope of tasks covered in the next subsection.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "The Scope Of The Paper",
      "text": "The Scope of this Paper includes eight interrelated tasks that we categorize as core to Subjective Language Understanding: (1) Sentiment Analysis, (2) Emotion Recognition, (3) Sarcasm Detection, (4) Humor Detection, (5) Stance Detection,  (6)  Metaphor Recognition,  (7)  Intent Detection, and (8) Aesthetics Identification. These tasks span a range of applications and research communities, from traditional sentiment analysis in product reviews, to detecting humorous or sarcastic content on social media, to identifying a user's intent in dialogue systems, to evaluating the aesthetic quality of creative content. By no means is this list exhaustive of all subjective phenomena in language (for example, bias detection, hate speech/offensive tone detection, and moral sentiment analysis are also subjective tasks, but we focus on the eight listed areas as they are most prominently addressed with LLM-era techniques in our surveyed literature). We aim to provide a unified treatment, highlighting common challenges and techniques, while also diving into task-specific details.\n\nFigure  1  provides a conceptual taxonomy of these tasks, which we describe here. Affective tasks include sentiment analysis and emotion recognition: these deal with identifying feelings or attitudes expressed in text. Sentiment analysis typically focuses on polarity (positive/negative/neutral sentiment towards a target), whereas emotion recognition assigns more fine-grained emotion categories (happy, sad, angry, etc.) or even emotion intensity levels. Figurative language tasks cover sarcasm, humor, and metaphors. They require understanding non-literal meanings and often involve cultural or contextual knowledge -sarcasm and humor can overlap (sarcasm is often a bitter form of humor), and metaphors are imaginative expressions mapping one concept onto another. Stance detection is about inferring the position (pro/con/neutral) of the author with respect to a specific topic or claim -it's subjective in that it reveals opinion, though often about external issues (politics, etc.). Intent detection (in user conversations or commands) is somewhat different but still subjective: it involves understanding the underlying goal or intention behind an utterance (for example, whether a question is actually a request, or what the user wants to achieve). Finally, aesthetics identification is an emerging area where the task is to evaluate the aesthetic or subjective quality of content -often images (image aesthetics rating) but also text style. It intersects with sentiment and with multi-modal understanding.\n\nDespite differences, all these tasks are unified by requiring the model to go beyond literal meaning and often to incorporate world knowledge and cultural context. Our survey specifically investigates how LLMs have been applied to each task, and what advantages or limitations they bring.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Distinction From Existing Llm Surveys",
      "text": "It is important to clarify how our survey differs from prior surveys, especially those focusing on LLMs or affective computing. One closely related work is  [229] . Their survey centers on how LLMs can be used for affective computing tasks, mainly sentiment and emotion analysis and affective text generation. In contrast, our survey covers a broader notion of subjective language, not limited to emotions but also including stance, figurative language (sarcasm, humor, metaphor), user intent, and aesthetic judgement. Thus, we address a wider range of tasks under the umbrella of subjectivity. Another difference is in emphasis: we delve into how LLMs perform understanding (analysis) of subjective language. We also include tasks like metaphor and humor which might not be treated in-depth in an affective computing survey.\n\nMoreover, existing general LLM surveys mention these tasks only briefly, if at all. To our knowledge, this is the first comprehensive survey specifically targeting subjective language understanding in the LLM era. We synthesize results from over 200 recent papers and highlight trends such as prompt engineering for subjectivity, multi-task learning of subjective phenomena, and integrating domain knowledge into LLMs. We also draw on benchmarks and studies evaluating LLMs on these tasks.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Contribution And Structure Of The Paper",
      "text": "The contributions of this survey are as follows:\n\n• We define and motivate subjective language understanding as a field, clarifying its scope and importance in NLP. We connect linguistic definitions of subjectivity with the challenges faced by AI, providing a conceptual foundation for readers (Section 2).\n\n• We provide an overview of LLMs (Section 3) with a focus on their relevance to subjective tasks. This includes a brief history of language model evolution leading to current state-ofthe-art models, and a discussion of why the properties of LLMs (such as in-context learning and knowledge integration) make them promising for subjective language understanding.\n\n• For each of the eight tasks (Sections 4 -11), we present a task definition, key datasets, LLM-based methods, and challenges. We thoroughly review literature in each area: for instance, how LLMs have been fine-tuned or prompted for sentiment analysis, how they've been evaluated on humor and sarcasm, what novel techniques have been proposed, etc. We highlight representative papers and methods, and we analyze their strengths and weaknesses in context. Wherever applicable, we cite quantitative results from papers or benchmarks to give a sense of the state-of-the-art performance.\n\n• We perform a comparative analysis in Section 12, discussing commonalities and differences among the tasks. We examine, for example, how sarcasm detection and humor detection overlap in needing cultural knowledge, or how sentiment and emotion recognition differ in granularity but share methodical approaches. We also discuss the potential of unified models or multi-task training to handle multiple subjective tasks together, referencing any multi-task studies we found. We compare single-task fine-tuning versus multi-task (or instruction-based) approaches in the context of subjectivity: which yields better performance or efficiency, based on recent experiments.\n\n• We outline challenges and open issues (Section 13) that emerged from the literature review. These include technical challenges (e.g., handling context and pragmatics, avoiding LLM hallucinations in subjective inference, data scarcity for less common tasks), as well as ethical considerations (e.g., the risk of bias when an AI system judges what is \"beautiful\" or interprets user emotion, and privacy issues in emotion/intent detection). We also discuss how subjective language understanding by AI can impact society (for instance, the use of stance detection in monitoring social media could raise fairness concerns).\n\n• We conclude (Section 14) by summarizing key findings -for example, which tasks LLMs have significantly advanced and which remain very challenging -and by calling for a unified research framework and evaluation for subjective language understanding. We emphasize that as LLMs become central to NLP, it's crucial to develop standardized benchmarks that cover the spectrum of subjective tasks, and to encourage research that bridges these areas rather than treating each in isolation. Ultimately, truly human-like language understanding by AI will require competence in all these subjective dimensions. We hope our survey accelerates progress toward that goal.\n\nThe structure of the paper follows the outline above. Readers interested in specific tasks can refer directly to Sections 4-11 for detailed surveys of each area. We now proceed to formally define subjective language understanding and present a taxonomy of tasks (Section 2), before discussing LLM foundations (Section 3) and then diving into each task.\n\n2 Defining Subjective Language Understanding 2.1 Definitions of Subjectivity: Linguistic and Cognitive Perspectives Subjectivity has been a topic of interest in both linguistics and cognitive science, each providing a complementary perspective. From the linguistic perspective, subjectivity in language is about the expression of personal stance. Linguist Janet Besnier noted that subjectivity is \"the linguistic encoding of the speaker's perspective\" -this can manifest as opinions, evaluations, or other attitude markers in text. Classic work by Wiebe et al. (  2004 ) in computational linguistics distinguished subjective sentences (those containing opinions, sentiments, or feelings) from objective sentences (factual descriptions). Linguistically, clues to subjectivity include: opinion adjectives (e.g. \"beautiful,\" \"terrible\"), modal verbs and hedges (which indicate uncertainty or perspective, e.g. \"I think,\" \"probably\"), first-person references (\"I believe...\"), and intensifiers (\"very happy,\" \"extremely costly\"). Even punctuation or tone words (exclamation marks, emotive interjections like \"ugh\") signal subjectivity. These linguistic markers have been used historically to build subjectivity lexicons and classifiers. For example, a sentence like \"In my opinion, this is a huge mistake!\" is clearly subjective due to the phrase \"in my opinion\" and the evaluative term \"huge mistake.\" On the other hand, \"The water boils at 100°C.\" is objective. However, there are many gray areas and subtle cases; a sentence can convey a subjective attitude without explicit markers, especially if context is required.\n\nFrom the cognitive perspective, subjectivity ties into how humans process language and infer others' mental states. Cognitive scientists consider Theory of Mind (ToM) -the ability to attribute thoughts, intentions, or emotions to others -as crucial for understanding subjective aspects of communication.\n\nWhen someone says \"Sure, I just love getting stuck in traffic for hours,\" an listener with theory of mind will recognize the likely sarcastic intent (the speaker's true attitude is the opposite of the literal words). Thus, cognitively, subjective language often demands inference beyond the literal text, involving knowledge of speaker intentions, cultural context, and sometimes shared experiences. Emotion understanding is another cognitive aspect: humans have an innate ability to read emotional cues in language (certain words or even the rhythm of text can imply an emotional state). Cognitive and social psychology also discuss how people use language to perform actions. For instance, being polite or rude, being humorous or serious. These aspects highlight that subjective language understanding is not just a textual analysis problem, but an exercise in modeling human-like interpretations.\n\nIn summary, linguistically we can describe subjectivity through observable markers in language, while cognitively we explain subjectivity by the mental processes a listener/reader uses to interpret those utterances. An effective AI system must bridge both: detect the markers and patterns, and apply reasoning to interpret them correctly.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Key Characteristics Of Subjective Language",
      "text": "What makes subjective language particularly challenging for computational models? We outline a few key characteristics:\n\nAmbiguity and Subtlety Subjective expressions are often ambiguous. The same phrase can have different meanings depending on context or tone. For example, \"Yeah, right.\" could be sincere agreement or a sarcastic dismissal, depending on context and perhaps the speaker's intonation. Subjective language relies heavily on context (both linguistic context and real-world context). Small cues can flip the interpretation. This subtlety is why tasks like sarcasm detection are hard -there is no single keyword that always signals sarcasm.\n\nFigurative and Non-literal meaning Much of subjective language is non-literal. Metaphors, idioms, and jokes involve meaning that cannot be obtained by straightforward dictionary lookup. For instance, \"kick the bucket\" meaning \"to die\" or \"spill the tea\" meaning \"to gossip\" are idiomatic and subjective. Similarly, metaphors like \"a rollercoaster of emotions\" convey subjective experience via analogy. LLMs have shown some ability to interpret idioms and metaphors, which is a positive sign. But generating or identifying non-literal language remains challenging. The non-literal nature often overlaps with humor and sarcasm. Influence of Personal and Societal Biases Subjective language ties to personal perspective, which can reflect biases. Models learning from subjective data risk absorbing biases (e.g., associating certain sentiments with demographic groups, or having skewed humor that might be offensive). We highlight this because it's both a characteristic and an ethical challenge: understanding subjective language requires recognizing whose perspective is reflected (for instance, the stance in a tweet may depend on the tweeter's political alignment). LLMs need mechanisms to handle this -either by being neutral or not amplifying harmful biases. This is discussed more in Section 13 on ethical implications.\n\nThese characteristics show why subjective language understanding is a tough problem for AI and why success here is a good proxy for genuine natural language \"understanding,\" as it goes beyond surface text. Next, we classify the tasks under subjective language understanding in a unified taxonomy.",
      "page_start": 5,
      "page_end": 6
    },
    {
      "section_name": "A Unified Taxonomy Of Subjective Tasks",
      "text": "We identified 8 key tasks as the focus. Here, we briefly define each and position it in our taxonomy:\n\nSentiment Analysis Determine the sentiment polarity expressed in a given text, often categorized as positive, negative, or neutral. Sometimes \"sentiment analysis\" also includes aspect-based sentiment analysis (polarity toward specific aspects of an entity) and intensity (strength of sentiment). It traditionally answers questions like, \"Is this product review positive or negative?\" or \"How does this tweet's author feel about topic X?\". In our taxonomy, sentiment analysis is a fundamental subjective task concerning evaluative attitude. It is usually considered \"simpler\" than full emotion recognition because it deals with broad valence (good/bad) rather than specific emotions. However, it is ubiquitous in industry (e.g., opinion mining) and is a cornerstone of affective NLP.\n\nEmotion Recognition Identify the emotion(s) expressed in a text. This could be a classification into categories (joy, sadness, anger, fear, etc.) or a regression in an emotional dimension (such as valence, arousal). Emotion recognition can be seen as richer labeling than sentiment: \"I am furious about the delay\" has negative sentiment, but more specifically the emotion is anger. Emotion recognition might involve multiple labels if more than one emotion is present. We also include related tasks like emotion cause detection under this umbrella, although the main focus is classification of emotion from text. This lies in the affective branch of our taxonomy, alongside sentiment.\n\nSarcasm Detection Determine if a given text is sarcastic or not. Sarcasm is usually a form of verbal irony where the intended meaning is opposite to the literal wording, often to mock or convey contempt. For instance, \"Oh, great, another Monday morning meeting. I'm so excited.\" is likely sarcastic. This task is binary (sarcastic vs not), though some research considers degrees of sarcasm or types of sarcastic expression. Sarcasm detection is a prototypical figurative language task in our taxonomy, requiring high-level pragmatic inference. It's notoriously hard because it depends on subtle cues and sometimes knowledge of the speaker's personality or context. We include irony detection here as well, as computationally the two overlap a lot.\n\nHumor Detection Identify if a text is intended to be humorous or not (and possibly, how funny it is). Humor detection overlaps with sarcasm in that both involve non-literal cues and surprise, but humor is broader -not all humor is sarcastic; it could be puns, absurdity, etc. This task might be binary (humorous vs not) or involve scoring jokes by funniness. It's subjective because humor reception varies across audiences. It sits with sarcasm under figurative language understanding. An example: \"I told my computer I needed a break, and now it won't stop sending me KitKat ads.\" A model should detect this is a joke (wordplay on \"break\"). Humor understanding might also involve explaining the joke, but our focus is mainly on detection/classification and understanding.\n\nStance Detection Given a text and a specific target or claim, determine whether the author's stance is in favor, against, or neutral toward the target. For example, in a debate forum post about climate change, does the author support or oppose the existence of human-induced climate change? Stance is similar to sentiment, but specifically anchored to a target proposition and not necessarily about personal feelings -one can have a stance on an issue without an emotional tone. Still, it's subjective as it reflects opinion. Stance detection can be closed-target or open-target. This task is important in analyzing social media, fake news, and online conversations. In our taxonomy it is somewhat between affective and opinion tasks -we categorize it under subjective opinion analysis.\n\nMetaphor Recognition Determine which words or phrases in a text are used metaphorically (as opposed to literally), or more generally identify and interpret metaphors. For example, in \"After the argument, a wave of anger washed over him,\" the phrase \"wave of anger\" is metaphorical. Metaphor recognition can be a token-level sequence labeling task (label each word as literal or metaphoric) or a classification of a phrase/sentence as containing metaphor. It's a figurative language task. Interpretation of metaphor is a related challenge -e.g., GPT-4 has shown an ability to interpret novel metaphors by providing explanations. In our scope, we primarily consider recognition. Metaphors are subjectively used to convey concepts in a more vivid way, often tied to creativity and cognition.\n\nIntent Detection Intent detection involves classifying a user's utterance according to its underlying intent. It's a key component in task-oriented dialogue systems. Although this seems more \"semantic\" than \"subjective,\" we include it because recognizing user intent is related to interpreting implicit meaning in their request -essentially a pragmatic understanding task. For instance, the user query \"I'm hungry\" has the intent FindRestaurant implicitly. Or in open-ended conversation, \"It's cold here\" could be an indirect intent for the thermostat to be turned up. Intent detection also includes detecting intent strength or ambiguity. It's subjective as the model must infer the human's goal from context, and different users might phrase intentions in diverse, personal ways.\n\nAesthetics Identification This is a relatively novel task in NLP -assessing the aesthetic quality or style of content. Traditionally, this has been more common in computer vision (image aesthetics rating), but with multi-modal models and stylistic text generation, it's coming to NLP. Here we consider tasks like: given an image and possibly a description, rate its aesthetic appeal; or given a piece of text, judge its writing style aesthetics (is it eloquent, is it engaging). The Textual Aesthetics work  (Jiang et al., 2024)  introduced a dataset and method to fine-tune LLMs to produce more aesthetically pleasing text outputs. And on the image side, AesBench (Huang et al., 2024) is a benchmark that asks LLM-based vision-language models to perform various aesthetic understanding tasks on images. This task is subjective by nature -\"beauty is in the eye of the beholder.\" It intersects with sentiment (pleasing vs not pleasing) but goes beyond, into artistic elements and human preference. We place it in its own category, touching both affective and cognitive.\n\nThis taxonomy shows the diverse landscape we cover. Relationships exist between tasks: sarcasm and humor are linked, sentiment and stance both deal with evaluation but target differently, emotion and intent sometimes intersect. One ambition of the field is to handle overlapping phenomena jointly.",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "Why Llms Matter For Subjectivity",
      "text": "We expect LLMs to be particularly suitable for subjective language understanding for several reasons, supported by recent research: Unified Handling of Language and Multi-modality Some of the latest \"LLM\" systems are multimodal. For tasks like aesthetics, which involve images, or emotion recognition from multimodal cues, these architectures extend the LLM paradigm. The extension of these to subjective queries (e.g., \"Is this person in the image happy or sad?\" or \"Rate the aesthetics of this photograph\") is a current research frontier. LLMs provide a coherent way to integrate modalities -by converting everything to a \"language\" (descriptions, dialogues) and then processing with a powerful language reasoning core. This could be more effective than earlier multi-modal systems that treated vision and text separately. Our survey will touch on some multimodal aspects (especially in aesthetics and in a few humor/sarcasm datasets that have context or images).\n\nIn summary, LLMs matter for subjectivity because they bring general intelligence-like capabilities to NLP: flexibility, knowledge, and adaptability. However, as we will see, they are not a panacea. There are also reasons LLMs might struggle or require augmentation: e.g., they might lack true understanding of emotion (they predict patterns but don't \"feel\"), they might have biases, and they might produce convincing but incorrect interpretations. Throughout the survey, we will evaluate how well the promise of LLMs translates into actual task performance, citing concrete results.\n\nHaving set the stage, we will first provide a brief overview of LLMs -their evolution and current state of the art (Section 3) -before exploring each subjective language task in Sections 4-11.\n\n3 Large Language Models (LLMs) for Subjective Language Understanding",
      "page_start": 7,
      "page_end": 8
    },
    {
      "section_name": "Evolution Of Language Models And Emergence Of Llms",
      "text": "In recent years, natural language processing has evolved dramatically in language modeling. Early models like word2vec  [121]  and RNNs  [49]  (2012-2017) captured local patterns but were contextually limited. The Transformer architecture  [180]  enabled deeper, larger models. OpenAI's GPT series exemplifies this shift. GPT-1  [144]  (2018) with 117M parameters highlighted pre-training on unlabeled text and task fine-tuning. GPT-2  [145]  (2019) expanded to 1.5B parameters, showcasing coherent text generation. The breakthrough came with GPT-3  [19]  (2020), at 175B parameters, demonstrating strong zero-shot and few-shot learning across tasks like sentiment analysis and translation without explicit training-emerging as a general-purpose NLP tool. This paradigm was quickly adopted, leading to other LLMs like Google's T5  [146] , BERT-like encoders, and larger models such as PaLM  [34]  (540B) and Megatron-Turing NLG  [160]  (530B).\n\nIn 2022-2023, instruction tuning and interactive LLMs, known as chatbot models, emerged. OpenAI's InstructGPT  [134]  and ChatGPT (based on GPT-3.5) were fine-tuned with human feedback to better follow instructions and conversational cues, aligning with human preferences for greater practical effectiveness. GPT-4  [    [168]  and Vicuna  [32]  fine-tuning LLaMA for ChatGPT-like functionality.\n\nIn the context of subjective language, models specifically to handle such tasks have emerged: e.g., a model named SentimentGPT  [85]  was proposed by  Kheiri & Karimi (2023)  which analyzes how GPT-based models depart from classical ML in sentiment analysis. Specialized variants or prompting techniques (like emotion-aware LLMs) have been developed. Some research has tried to incorporate psychological theories into LLMs by fine-tuning or prompting  [214] . Furthermore, the line between \"language model\" and \"multimodal model\" is blurring -GPT-4 and others can accept images as input in addition to text, allowing them to describe an image's emotional content or aesthetics. This versatility positions LLMs as central hubs for processing subjective information across modalities.\n\nTo summarize this evolution: we went from task-specific small models, to moderate pre-trained models fine-tuned per task, to gargantuan models that can perform all tasks with minimal task-specific tuning. This is a paradigm shift: instead of building a separate classifier for sarcasm, we can now prompt one general model to do sarcasm detection, perhaps even alongside other tasks. It opens the door for multi-task subjective language models, which we discuss later in the survey (Section 12).",
      "page_start": 8,
      "page_end": 9
    },
    {
      "section_name": "Current State-Of-The-Art Models",
      "text": "The current landscape of Large Language Models (LLMs) for subjective language understanding is characterized by a diverse array of models and techniques, broadly categorizable into prompt-based, Supervised Fine-Tuning (SFT)-based, and reasoning-based approaches. Prominent models frequently cited in recent literature include OpenAI's GPT series (GPT-3.5, GPT-4, GPT-4o  [74] ), Google's Gemini  [170]  (Gemini 1.5 Flash  [171] , Gemini 1.5 Pro, Gemini 2.0 Flash), Meta's Llama series (Llama-2, Llama-3  [48] , Llama-3.1), Mistral AI's models (Mistral 7B  [81] , Mixtral 8x7B  [82] ), and others like Qwen-2  [203] , and DeepSeek-R1  [60]  models.\n\nPrompt-based LLMs leverage the inherent capabilities of pre-trained models by providing carefully crafted input prompts to guide their responses for specific tasks. This includes zero-shot prompting, where the model performs a task without any prior examples, and few-shot prompting, where a small number of examples are included in the prompt to demonstrate the desired output. For subjective tasks, the design of the prompt is critical, as it can influence the model's perspective and reasoning. For example, techniques like Chain-of-Thought (CoT)  [189]  prompting, which encourage the model to generate intermediate reasoning steps, have been applied to improve performance on tasks requiring deeper understanding. However, research indicates that CoT prompting, especially for larger LLMs, might suffer from \"posterior collapse,\" where the model relies more on pre-existing reasoning priors than on the evidence presented in the prompt, particularly in complex subjective domains like emotion and morality.\n\nSFT-based LLMs involve taking a pre-trained LLM and further training it (fine-tuning) on a specific dataset relevant to a particular subjective task. This process adapts the general knowledge of the LLM to the nuances of the target domain. For instance, models like RoBERTa  [108]  and BERT  [40]  have been fine-tuned for tasks such as subjectivity detection in news articles or sentiment analysis.\n\nWhile fine-tuning can lead to high performance on the specific dataset, it may not always generalize well to out-of-distribution data or other subjective tasks without further adaptation. Parameter-efficient fine-tuning (PEFT) methods like LoRA  [71]  (Low-Rank Adaptation) and QLoRA  [39]  are also gaining traction, allowing for adaptation with reduced computational cost.\n\nReasoning-based LLMs focus on enhancing the model's ability to perform logical inference and understand complex relationships, which is crucial for many subjective tasks. This includes methods that explicitly guide the model's reasoning process. For example, the \"Reasoning through Perspective Transition\" (RPT) method enables LLMs to dynamically select among direct, role, and third-person perspectives to solve subjective problems more effectively by ranking perspectives and choosing the most suitable one for a given scenario. Another approach, \"Reasoning in Conversation\" (RiC), simulates dialogues to mine useful contextual information for subjective tasks like metaphor recognition and dark humor detection, rather than relying solely on chain-of-thought rationales. These methods aim to overcome the limitations of standard prompting by encouraging more structured and adaptable reasoning. The development of models like GPT-4, which are reported to have improved reasoning capabilities, also falls under this umbrella.\n\nThe choice of model and approach often depends on the specific task, the availability of labeled data, computational resources, and the desired level of interpretability and generalization. For instance, while proprietary models like GPT-4 often lead in performance, open-source models like Llama and Mistral provide flexibility for customization and fine-tuning . The ongoing research explores hybrid approaches, knowledge distillation from larger to smaller models, and methods to improve the robustness and reliability of LLMs in subjective understanding.",
      "page_start": 9,
      "page_end": 10
    },
    {
      "section_name": "Multi-Model Llms For Subjective Language Understanding",
      "text": "The concept of Multi-Model LLMs is increasingly significant in addressing the complexities of subjective language understanding. This approach recognizes that a single LLM may be insufficient to capture all aspects of subjectivity, particularly with multimodal inputs or tasks requiring diverse expertise. For example, in sarcasm detection, visual cues accompanying text can be vital for clarifying meaning. The Commander-GPT  [228]  framework is proposed for multimodal sarcasm detection, where a central LLM (e.g., GPT-4) coordinates specialized models (\"generals\") skilled in areas like image content analysis or textual analysis. This ensemble approach aims to leverage the strengths of different models for more robust sarcasm recognition than a single model can achieve. Similarly, in Speech Emotion Recognition (SER), systems are developed that combine audio encoders (e.g., Whisper-large-v3  [143] ) with LLMs (e.g., Gemma-2-2B-it  [172] ) to process both speech signals and transcriptions, forming a unified multimodal architecture. These systems align features from different modalities and manage token overload from high-dimensional audio embeddings.\n\nAnother dimension of Multi-Model encompasses ensemble methods or collaborative agent frameworks, wherein multiple LLM instances or diverse models collaborate. For subjectivity detection in news, an ensemble of multiple LLMs is employed, combining predictions via majority voting to enhance robustness and mitigate biases. In stance detection, the COLA  [92]  framework utilizes LLMs in a three-stage collaborative process, assigning distinct roles to address challenges like multi-aspect knowledge and advanced reasoning, enabling nuanced analysis beyond a single LLM's capacity. Additionally, hybrid approaches integrating smaller, fine-tuned models (e.g., BERT) with larger LLMs (e.g., GPT-4, Llama-3) are emerging. For intent detection, uncertain predictions from a fine-tuned BERT may be routed to an LLM, with BERT information dynamically generating prompts for the LLM to reduce label space, balancing computational efficiency with advanced LLM capabilities. These multi-model strategies signify a shift towards developing sophisticated systems for subjective language understanding, surpassing reliance on a singular LLM.\n\nTo conclude this section, LLMs have rapidly become the toolkit of choice for subjective language understanding. We now have a variety of ways to use them (direct prompting, fine-tuning, etc.) and a variety of models to choose from. The remaining sections will detail each task. We will see that for tasks with limited data (like humor, sarcasm), creative prompting and large models (GPT-4) often lead the pack, whereas for tasks with lots of data (like sentiment), fine-tuned smaller models can still compete or outperform in some cases -though the gap is closing as LLMs get instruction-tuned on sentiment during their general training. Next, we dive into Sentiment Analysis as the first task, which historically is one of the most studied and will illustrate many general points.\n\n4 Sentiment Analysis",
      "page_start": 10,
      "page_end": 11
    },
    {
      "section_name": "Task Definition Of Sentiment Analysis",
      "text": "Sentiment analysis, also known as opinion mining, is a core task in NLP that focuses on identifying, extracting, quantifying, and studying affective states and subjective information from text. The primary goal is to determine the attitude or emotional tone of a writer or speaker with respect to a particular topic, product, person, or entity. This attitude can be categorized in various ways, most commonly as positive, negative, or neutral. More fine-grained approaches may also identify the intensity of the sentiment (e.g., very positive, slightly negative) or detect specific emotions. Sentiment analysis can be performed at different levels of granularity: document-level (classifying the overall sentiment of an entire document), sentence-level (determining sentiment for individual sentences), or aspect-level (identifying sentiment towards specific aspects or features of an entity mentioned in the text, e.g., \"The camera is good, but the battery life is poor\"). The task is crucial for a wide range of applications, including brand monitoring, market research, customer feedback analysis, product recommendation, and social media analytics. The challenge lies in accurately interpreting nuanced language, sarcasm, irony, and context-dependent expressions that can alter the perceived sentiment.",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Dataset Of Sentiment Analysis",
      "text": "Sentiment analysis has been built on a set of well-established supervised benchmarks spanning reviews and social media. Core movie and product review resources include MR (movie reviews, also known as the Polarity dataset), the Stanford Sentiment Treebank (SST; phrase-level labels with SST-2 binary and SST-5 five-class variants), IMDb (50k balanced reviews), Amazon product reviews (millions of star ratings), and Yelp Reviews (hundreds of thousands, widely used in LLM studies   [12]  released 5,929 tweets about nuclear power with explicit sarcasm annotations to study how irony and emoji shift sentiment labels. Financial sentiment has long been supported by the Financial PhraseBank and by stock-related Twitter corpora; more recently,  [38]  introduced a Reddit-based market sentiment dataset labeled bullish, bearish, or neutral to address data scarcity in finance. Multilingual product-review datasets (e.g., Arabic, Chinese) broaden coverage across languages, and niche multimodal or \"aesthetic\" sentiment resources illustrate crossovers with vision-language and aspect-centric judgments.\n\nIn the LLM era (2022-2025), classic benchmarks continue to anchor evaluation while new practices and specialized datasets expand the landscape. Studies routinely test zero-/few-shot LLMs on SST-2/SST-5, MR/Polarity, IMDb, Amazon/Yelp, and Twitter/SemEval sets; for example,  [226]  report LLM results on SST-2 and MR. Prompt-based evaluation suites  [12]  have also appeared, complementing large-scale benchmarks with targeted probes. Meanwhile, domain-specific datasets-especially in finance (e.g., Reddit market sentiment) and in sarcasm-aware settings-highlight persistent challenges that remain even when models perform strongly on standard corpora. Taken together, today's sentiment datasets span binary, ternary, and five-class labeling; phrase-and aspect-level annotation; multiple domains and languages; and scales from thousands to over a million instances, providing comprehensive coverage for training and assessing LLM-based sentiment analysis.",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Llm Methods Of Sentiment Analysis",
      "text": "Large language models (LLMs) have reset expectations for sentiment analysis, yet recent evaluations urge caution. Broad benchmarking shows LLMs do well on simpler settings but lag on complex tasks requiring structured outputs or deeper inference, motivating a more realistic evaluation agenda  [223] . Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity extremes, sarcasm, and irony  [107] . Mechanistically, sentiment appears to lie along a largely linear direction in activation space; causal ablations at key tokens (e.g., commas) degrade zero-shot accuracy, offering both interpretability and a warning about brittleness  [175] . Fairness audits reveal persistent social biases despite fine-tuning, especially around age, underscoring the need for bias testing in deployment  [142] . Surveys synthesize these trade-offs across domains, noting computational cost, domain sensitivity, and ethics as recurring themes, and framing finance as a distinctive setting where \"what is financial sentiment\" itself demands care  [54] [116]  [88] .\n\nFew-shot Prompting Few-shot prompting is label-efficient but variably reliable. Techniques such as SuperICL and bootstrapping strengthen generative LLMs for financial news, producing stable, explainable signals that improve portfolio construction  [127] . Complementarily, AI-generated exemplars can aid context extraction, though their benefits depend on prompt design and task complexity  [4] . Evidence across domains shows the data regime is pivotal: in data-scarce software engineering corpora, larger LLMs achieve zero-shot SOTA, whereas with sufficient labels, fine-tuned small LMs retake the lead  [222] . Zero-shot multilingual ABSA remains challenging; leaner prompts often outperform elaborate self-consistency or self-debate strategies, especially in English  [191] . In Chinese healthcare ABSA, compact sLLMs are competitive and efficient, follow instructions well, and support privacy-preserving deployment  [208] . Detailed prompts help zero/few-shot ABSA but become less critical after fine-tuning  [158] . Overall, few-shot methods offer speed and low labeling cost but can be unstable across domains and remain vulnerable to irony and subtle cues  [223][107] .\n\nChain-of-Thought Reasoning Reasoning-oriented prompting can improve reliability and transparency but introduces latency and new hallucination pathways. In finance, Domain Knowledge Chain-of-Thought (DK-CoT) integrates domain expertise with CoT, boosting robustness and weighted F1 for news sentiment  [27] . For weak supervision, Reddit pipelines pair CoT with multiple reasoning paths to stabilize weak labels and train efficient downstream models  [38] . For policy analytics, multi-task reasoning frameworks jointly infer travel modes, sentiments, and rationales from tweets, enabling insights without manual labels  [150] . Nevertheless, in multilingual ABSA, complex selfimprovement or self-debate prompts do not consistently outperform simple zero-shot baselines, indicating diminishing returns from heavier reasoning prompts across languages  [191] .\n\nFine-Tuning and Ensemble Approaches Fine-tuning, ensembling, and continual learning deliver durable gains when compute and data allow. On the high end, fine-tuned GPT-3.5 sets SOTA on SemEval-2014 ABSA, albeit at higher cost  [158] . On the efficiency frontier, compact models excel on the speed-accuracy trade-off: EmoBERTTiny surpasses 7B-chat LLM baselines with millisecond inference, making it well suited for real-time use  [164] . For ensembling, RGPT adaptively reweights hard instances and aggregates historical predictions to boost specialized LLM classifiers, outperforming SOTA LLMs and even average human performance on multiple benchmarks  [226] .\n\nFor non-stationary settings, continual learning with domain-decoupled adapters preserves prior knowledge while acquiring new domains and performs domain positioning at inference without explicit IDs, achieving SOTA across 19 ABSA datasets  [45] . In finance, a domain-specific LLaMA-2 paired with summarization of long filings improves return prediction and robustness, and even lifts traditional models  [33] . Cross-model comparisons suggest GPT-4 generalizes best, FinBERT excels on structured financial text, and T5 lags in recall/generalization  [154] , echoing reviews that highlight FinBERT's reliability and the cost-benefit calculus of task-specific fine-tuning  [116][222] .\n\nLLMs for Data Augmentation/Annotation LLMs are effective labelers and data generators. In low-resource ABSA, few-shot prompting to synthesize annotations raises F1, especially for aspectlevel sentiment with modest seed data  [68] . At scale, weak-labeling pipelines provide tractable supervision: CoT-stabilized Reddit market sentiment  [38] , GPT-4-labeled Baijiu stock forums followed by LLaMA fine-tuning  [241] , and multi-LLM majority voting for large social studies  [185] .\n\nIn health-related social media, domain-aware prompting and targeted fine-tuning outperform lexicon baselines yet still fall short of high accuracy, motivating hybrid workflows and practical prompting guidance  [64] . Overall, the advantages are rapid coverage and flexible domain adaptation; the risks are label noise, ethical and copyright constraints, and amplification of existing biases  [38][142] .\n\nHandling Nuances and Context Handling nuance and context often calls for architectural or retrieval enhancements. Retrieval-augmented LLMs ground instructions in external evidence, mitigat-ing pretraining-task mismatch and short-text context gaps, and thereby improving financial sentiment accuracy  [219] . Summarization layers condense long filings into analysis-ready text, boosting sentiment fidelity and return predictiveness  [33] . Multi-source fusion of Twitter/news sentiment with dynamic asset models improves both short-and long-horizon stock forecasts  [157] . For trading, LLMbased, sentiment-driven strategies with improved prompting deliver profitable, stable performance with explainable rationales  [127] , and financial DK-CoT further stresses cost-effective reliability and class-weighted metrics given asymmetric downside risks  [27] . Nonetheless, sarcasm, brevity, and domain shifts remain difficult  [107] , multilingual ABSA is brittle  [191] , and the linear sentiment mechanism is both a lever for control and a single-point vulnerability-motivating more realistic benchmarks and protocols  [175][223] .\n\nA practical recipe emerges. When labels are scarce, start with few-shot prompting or weak-label pipelines; add CoT/DK-CoT for interpretability and stability in finance or policy analyses. Under tight latency or privacy budgets, prefer compact or small LLMs fine-tuned for the domain. For shifting domains, adopt continual learning with decoupled adapters and retrieval augmentation.\n\nIn finance, combine summarization with domain knowledge to translate sentiment into actionable returns. At every stage, integrate fairness auditing and robust evaluation practices to counter bias and over-optimism, guided by domain surveys and reviews that articulate the cost, robustness, and ethical trade-offs intrinsic to LLM-based sentiment analysis.",
      "page_start": 11,
      "page_end": 13
    },
    {
      "section_name": "Key Challenges Of Sentiment Analysis",
      "text": "Despite the significant progress enabled by LLMs in sentiment analysis, several key challenges persist. One prominent challenge is the accurate identification and classification of neutral sentiment. Neutral statements often lack explicit emotional cues or may contain a mix of positive and negative aspects that cancel each other out, making them difficult for models to categorize correctly. For example, a statement like \"The product arrived on time\" is factual and neutral, but models might incorrectly assign a positive sentiment if they overemphasize words like \"on time\" without considering the overall neutrality of the expression. The ResearchGate article on BERT applications specifically points out that the detection of neutral reviews is a problem impacting model accuracy. This difficulty is compounded when neutral expressions are subtle or when the model is trained on imbalanced datasets where neutral examples are underrepresented. Improving the model's ability to distinguish between genuinely neutral content and weakly positive/negative content remains an active area of research. This often involves curating more balanced datasets, developing more sophisticated feature representations, or employing techniques that specifically target the nuances of neutral language.\n\nAnother significant challenge is the subjectivity and inherent ambiguity in human language, which directly impacts sentiment analysis. Sentiment is not always explicitly stated and can be conveyed through sarcasm, irony, figurative language, or cultural context, all of which are difficult for models to interpret accurately. For instance, a statement like \"Great, another Monday!\" might be interpreted as positive by a naive model focusing on the word \"great,\" while a human would easily recognize the negative sentiment conveyed through sarcasm. The inherent ambiguity means that even human annotators may disagree on the sentiment label for a particular piece of text, leading to noisy training data and affecting model performance. The subjective nature of sentiment also means that what one person perceives as positive, another might see as negative or neutral, depending on their personal experiences, beliefs, and cultural background. This variability makes it challenging to create universally applicable sentiment analysis models. Addressing this requires not only more sophisticated models but also a deeper understanding of pragmatics and context, potentially through the integration of commonsense knowledge and world knowledge into LLMs.\n\nFinally, the presence of false or deceptive reviews in datasets poses a considerable challenge to the accuracy and reliability of sentiment analysis models. On many online platforms, particularly e-commerce and review sites, businesses or individuals may post fake positive reviews to boost their own reputation or fake negative reviews to damage a competitor's. These deceptive reviews are often crafted to mimic genuine expressions of sentiment, making them difficult for automated systems to detect. When models are trained on datasets contaminated with such false reviews, they can learn incorrect associations and produce unreliable sentiment predictions. The ResearchGate article suggests that future research could focus on constructing false review categorization models to mitigate this issue. This involves developing techniques to identify and filter deceptive content before it is used for training sentiment analysis models, or to build models inherently more robust to such noise. This is critical for applications where sentiment analysis supports decision-making, as predictions based on manipulated data can lead to erroneous conclusions and unfair outcomes.\n\nIn summary, LLMs bring excellent generalization and an ability to incorporate context and world knowledge into sentiment analysis. With the right prompting, they can even outperform some task-specific models, especially in zero or few-shot settings. Fine-tuning and advanced prompting further close the gap for hard cases, making LLMs the new state of the art for sentiment analysis in many evaluations. Yet, ensuring they correctly handle tricky linguistic phenomena remains an active research challenge. The lessons learned in sentiment analysis -about prompting, augmentation, and hybrid deployment -carry over to other subjective tasks, as we explore next.\n\n5 Emotion Recognition",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "Task Definition Of Emotion Recognition",
      "text": "Emotion recognition in NLP is the task of identifying and classifying the emotional state expressed in textual data. This involves going beyond positive or negative sentiment to discern specific emotions such as joy, sadness, anger, fear, surprise, or disgust, and often nuanced or complex emotional states. The task is crucial for enabling machines to understand and respond to human emotions more effectively, enhancing human-computer interaction. The core challenge lies in the subjectivity and ambiguity of human emotions, which are influenced by context, cultural background, and individual differences. Emotion recognition systems aim to analyze textual cues, such as word choice, sentence structure, and punctuation, to infer the emotional tone. This process often involves feature engineering techniques, such as extracting n-grams or using lexicons, or more advanced deep learning models that can capture contextual information and semantic nuances. The ultimate goal is to develop models that can accurately interpret the emotional content of text, enabling applications in areas like customer feedback analysis, mental health monitoring, and empathetic conversational AI.\n\nThe definition of emotion recognition tasks can vary depending on the specific application and the granularity of emotions being considered. Some approaches focus on a small set of basic emotions, while others aim for a more fine-grained classification, including complex or ambiguous emotions. For instance, in conversational AI, emotion recognition is often applied at the utterance level within a dialogue, requiring an understanding of how emotions evolve and interact between speakers. This involves not only recognizing the emotion in a single utterance but also considering the conversational history and speaker dependencies. Furthermore, the task can be formulated as singlelabel classification (assigning one primary emotion to a text segment) or multi-label classification (assigning multiple relevant emotions if the text expresses a blend of feelings). The complexity of human emotions means that a single piece of text might evoke different emotional interpretations from different annotators, highlighting the challenge of achieving high inter-annotator agreement and the need for models that can handle this ambiguity. Therefore, a comprehensive task definition for emotion recognition must consider the scope of emotions, the unit of analysis (e.g., word, sentence, document, utterance), and the potential for multiple or blended emotional states.",
      "page_start": 14,
      "page_end": 14
    },
    {
      "section_name": "Dataset Of Emotion Recognition",
      "text": "Progress in text-based emotion recognition has been driven by diverse, well-annotated datasets that vary in source, label scheme, and the degree of context they provide. Foundational resources established basic taxonomies and tasks: ISEAR collects self-reported experiences across seven emotions; Emotion-Stimulus links narrative sentences to emotions and their causes; and early social media corpora such as TEC, CrowdFlower/Appen, and domain-specific sets like Electoral Tweets support broad coverage of tweet-level emotion. Dialog-oriented corpora such as DailyDialog, EmotionX, and spoken or multimodal benchmarks like IEMOCAP and MELD helped crystallize Emotion Recognition in Conversations, where context and speaker identity shape interpretation. Dimensional perspectives are captured by EmoBank with VAD scores, complementing categorical labels. Within this landscape, the SemEval 2018 \"Affect in Tweets\" shared task standardized multilingual benchmarks for both emotion classification and intensity (regression and ordinal), helping to consolidate practical evaluation protocols. Beyond news and social media, literary corpora with sentence-or character-level annotations have supported studies of narrative affect. These datasets also exposed core challenges-multi-label co-occurrence and low inter-annotator agreement-leading to calls for multi-perspective labeling and quality controls.\n\nThe modern large-scale era is anchored by GoEmotions  [36] , a 58k-comment Reddit corpus with 27 categories plus Neutral that enabled fine-grained classification and robust transfer. It has become a default benchmark for LLMs and smaller fine-tuned models alike. In dialogue and empathyfocused settings, EmpatheticDialogues  [147]  (32 emotions) supports empathetic response modeling, while MELD and IEMOCAP remain central for contextual and multimodal ERC. Specialized tasks expanded the scope: RECCON  [138]  targets emotion cause extraction within conversations, and Affect in Tweets from SemEval-2018 remains a standard for intensity modeling. Together, these corpora benchmark discriminative classification, intensity estimation, and causal reasoning across single-utterance and contextual settings.\n\nRecent work (2022-2025) emphasizes context-rich, task-oriented, and ambiguity-aware evaluation aligned with LLM capabilities. EmoWOZ  [52]  introduces emotional variation in task-oriented dialogues, probing whether systems detect shifts such as anger versus neutrality in service conversations. New evaluations target uncertainty and mixed affect;  [70]  propose an Ambiguous Emotion Dataset with high annotator disagreement to test whether models can recognize uncertain or blended emotions, and report results across multiple standard datasets. Surveys such as  [29]  document a broadening agenda from classification to emotionally aware response generation and Theory-of-Mind assessments, while reinforcing that discriminative emotion recognition remains a foundational testbed. Across this landscape, datasets differ in granularity (categorical vs. dimensional), domain (tweets, Reddit, dialogues, narratives), and annotation scheme (single-vs. multi-label, intensity, cause), and many are used to probe LLMs' strengths and weaknesses under context, subjectivity, and ambiguity. At the same time, multimodal image/video resources, together with ERC counterparts such as MELD, underscore an ongoing trend toward richer, context-sensitive, and comprehensive evaluation.",
      "page_start": 14,
      "page_end": 15
    },
    {
      "section_name": "Llm Methods Of Emotion Recognition",
      "text": "Prompting and Adaptive Emotional Reasoning Prompt-and reasoning-centric approaches use lightweight controls to elicit latent affective abilities in general-purpose LLMs. EmotionPrompt injects affective cues into instructions, improving induction-style tasks, broad capability benchmarks, and human-rated generative quality  [97] . Emotional Chain-of-Thought aligns intermediate reasoning with human emotional guidelines, increasing harmlessness and positivity  [101] . Task-adaptive long reasoning (Emotion-o1) adjusts chain length to difficulty and jointly rewards accuracy, depth, diversity, and logical consistency, improving advanced affective tasks such as sarcasm detection  [161] .\n\nFor noisy speech-text pipelines, Revise-Reason-Recognize combines emotion-specific prompts (acoustic, linguistic, psychological) with ASR correction to maintain robustness  [100] . Trainingfree in-context learning that pairs image-similarity retrieval with chain-of-thought enables contextaware visual emotion understanding without retraining  [96] . Reinforcement learning with verifiable rewards improves explainability, accuracy, and out-of-distribution robustness for omnimodal emotion recognition, while attributing modality contributions  [235] .\n\nInstruction Tuning and Parameter-Efficient Specialization Parameter-efficient customization enables cost-effective specialization of LLMs for affective computing. DialogueLLM performs instruction tuning on multimodal dialogues and injects visual context as knowledge, reaching stateof-the-art results on emotion recognition in conversation (ERC) with modest compute  [224] . Adapterbased approaches such as P-Tuning v2 and LoRA allow LLMs to surpass dedicated baselines across multiple emotion datasets, demonstrating transferability and efficiency  [135] . In low-resource settings, knowledge-augmented few-shot learning that couples contrastive embedding training with prompt-based self-prediction enhances sentiment and affect analysis  [204] . For multi-label scenarios, ambiguity-aware prompting enables reliable modeling of overlapping emotions, particularly when dialogue and speech cues are available  [70] . Extending beyond recognition, fine-tuned LLMs can infer emotion-regulation strategies from observed behavior-outperforming Bayesian baselines even without post-interview data-highlighting potential for coaching and therapeutic applications  [126] .\n\nComplementarily, cross-context fusion with LoRA and targeted domain adaptation further advances continuous affect prediction in challenging multimodal benchmarks  [213] .\n\nMultimodal and Omni-Modal Emotion Integration Multimodal instruction tuning is accelerating perception-rich emotional intelligence in LLMs. Emotion-LLaMA integrates audio-visual-text encoders with instruction tuning on MERR to couple recognition with reasoning, achieving state-ofthe-art results across multiple corpora and zero-shot video settings  [31] . Omni-Emotion advances video MLLMs with fine-grained facial and acoustic modeling, including micro-expressions, and curates high-quality, human-reviewed datasets for both recognition and explanation  [205] . AffectGPT combines pre-fusion multimodal alignment with training on MER-Caption to support open-vocabulary emotion captioning, evaluated via MER-UniBench  [103] . On the visual front, EmoVIT pioneers affect-oriented visual instruction tuning by generating emotion-specific instructions, excelling at classification and affective reasoning  [196] . Face-centric EMO-LLaMA further leverages instruction data and facial priors (global/local features, demographics) to deliver SOTA-comparable FER, covering micro-expressions and audio-vision fusion  [198] . For speech-centric applications, EMOVA provides end-to-end omni-modality with disentangled speech tokenization and controllable style for expressive spoken dialogue  [25] , while SECap moves beyond discrete labels to natural-language emotion captions through HuBERT and Q-Former interfaces to LLaMA  [199] . From a privacy standpoint, DEEMO demonstrates strong recognition and reasoning using de-identified video/audio and non-facial body cues, reducing identity exposure  [98] . For compositional affect, LVLMs adapted via two-stage tuning-basic emotions followed by compound optimization-achieve SOTA with zero-shot generalization  [215] , and remain effective for context-aware detection using training-free retrieval or light fine-tuning  [96] . Complementary visual-affective modeling with multi-perspective projection and EmoPrompt further strengthens nuanced emotion reasoning in MLLMs  [206] .\n\nBenchmarking Emotional Intelligence: Strengths, Gaps, and Risks A rapidly maturing evaluation ecosystem is revealing strengths, limitations, and risks. Grounded in psychological theory and spanning English and Chinese, EmoBench assesses emotion understanding and application, showing LLMs-despite progress-still fall short of average human performance  [152] . EmoBench-M extends evaluation to multimodal settings and indicates MLLMs continue to lag humans on core emotional intelligence scenarios  [72] . From a reliability perspective, EmotionHallucer audits \"emotion hallucinations\" across perceptual and knowledge dimensions, finds widespread errors, and proposes a mitigation framework with measurable gains  [197] . With respect to empathy, EmotionQueen probes key, mixed, and implicit events as well as intention recognition, revealing strong performance on explicit tasks but persistent limits for implicit affect  [28] . For multimodal emotion understanding, MER-UniBench offers a dedicated benchmark  [103] , while AEB and the EmoLLMs suite standardize multi-task affective evaluation and annotation  [109] . Large-scale comparisons further show that LLMs can surpass humans in empathy ratings, though performance varies by emotion  [190] ; psychometric tests often place top LLMs at or above average human EQ, yet with mechanisms distinct from human reasoning and uneven skill profiles across EI branches  [188][182] . In image-only emotion recognition, specialized CNNs still hold a slight edge over general LLMs, although LLMs remain practical under data scarcity  [128] . Collectively, these benchmarks chart clear progress while highlighting open challenges in multimodality, implicit emotion inference, and hallucination control.\n\nInteractive Systems and Emotional Support End-user systems highlight promise and caveats.\n\nEmbodied \"Virtual Humans\" couple LLMs with realistic avatars and explicit psychological constructs (e.g., personality, mood) to steer affective valence in semi-guided dialogue, achieving high naturalness and realism, although arousal control remains difficult  [113] . In child-facing settings, a state machine-guided chatbot elicits sharing of personal events and emotions and is perceived as a \"close friend\" in laboratory studies  [153] . For psychotherapy support, fusing emotion-aware embeddings with LLMs and retrieving context from sessions improves empathy, coherence, and fluency  [148] . Beyond clinical use, LLM-generated arguments are as persuasive as human ones and show cognitive effort and moral language-implications for civic education and risks of misinformation  [20] . Nonetheless, in emotional-support conversations current LLMs exhibit strategy biases and miscalibrated preferences that hinder effectiveness, underscoring the need for external oversight and bias mitigation before reliable deployment  [83] . Methodologically, ambiguity-aware prompting and behavior-level strategy recognition broaden coverage of real-world affective ambiguity and regulation  [70][126] .\n\nMechanistic Affective Modeling and Causal Extraction Mechanistic and theory-driven accounts are increasingly aligning model behavior with affective science. At the representation level, converging evidence for emotion-selective neuron groups in LLMs-together with ablation studies showing cross-layer compensation-implies distributed, model-dependent circuitry for affect  [94] . From a cognitive-science perspective, a comprehensive survey maps advances in LLM-based emotion cognition onto the sensation-perception-attention pipeline and situates techniques ranging from contrastive learning to theory-of-mind-style reasoning  [29] . For causal explanation, emotion-cause triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal context and utterance-pair communication  [104] . On the data side, hybrid human-AI labeling pipelines show GPT-4 can flag low-quality annotations, improving reliability and efficiency in affect datasets while remaining perceptually distinct from human raters  [133] . Taken together with audits of hallucination and generalization, these strands chart paths toward theory-grounded, trustworthy emotional intelligence, including improved handling of ambiguity and regulation  [231] [70]  [126] .\n\nOverall, emotion recognition with large models now follows a coherent trajectory: lightweight prompting delivers immediate gains; instruction tuning with parameter-efficient adapters consolidates capability; multimodal and omni-modal architectures capture real-world signals; and theory-grounded benchmarks surface blind spots in implicit understanding and hallucination. Coupling explainable reinforcement learning, privacy-preserving design, and hybrid human-AI annotation improves reliability, while retrieval grounding and bias mitigation safeguard sensitive deployments. Selecting methods by data budget, latency, and modality turns a diverse toolkit into a robust, accurate, and responsible strategy for affective AI.",
      "page_start": 16,
      "page_end": 16
    },
    {
      "section_name": "Key Challenges Of Emotion Recognition",
      "text": "Despite significant progress, emotion recognition using LLMs faces several key challenges, primarily stemming from the inherent nature of human emotions and the limitations of current models. One of the most prominent challenges is the ambiguity and subjectivity of emotional expression. Human emotions are complex and often nuanced, making it difficult to assign a single, definitive label. Textual expressions can be interpreted differently by different individuals or even by the same individual under varying contexts. This is reflected in low inter-annotator agreement in many emotion datasets. LLMs, while powerful, can struggle to capture this inherent ambiguity, often providing a single emotion label that might not fully represent the subtlety of the expressed feeling. Forcing complex, mixed emotions into discrete, predefined categories is an oversimplification that can lead to models trained on an incomplete or skewed representation of reality. The AER-LLM study specifically addresses this by focusing on recognizing ambiguous emotions, but it remains a core challenge for the field. The subjective experience of emotion is also shaped by cultural and individual factors, which are often not adequately accounted for in datasets or models.\n\nAnother significant challenge is the context-dependency of emotions. The meaning of a word or phrase, and the emotion it conveys, can drastically change depending on the surrounding text, the speaker's intent, and the broader situational context. While LLMs are adept at capturing some level of context, fully understanding long-range dependencies and subtle contextual cues that disambiguate emotional meaning remains difficult. For example, sarcasm, irony, or humor can completely invert the apparent emotional valence of a statement, and detecting these figurative language uses is a challenge in itself. Furthermore, the reliability and bias in datasets pose a major hurdle. Many emotion recognition datasets are created using majority voting from multiple annotators, which can obscure the inherent ambiguity and lead to a \"flattened\" representation of emotions. Datasets may also suffer from biases related to the demographics of the annotators or the sources of the text (e.g., specific social media platforms), leading to models that perform well on similar data but generalize poorly to new domains or populations. The \"observer effect,\" where the act of being monitored alters a user's emotional expression, can also compromise data fidelity, especially in real-world settings.\n\nThe interpretability and explainability of LLM-based emotion recognition systems also present challenges. While LLMs can achieve high accuracy, understanding why a model made a particular emotional prediction is often difficult. This \"black box\" nature can be problematic, especially in sensitive applications like mental health monitoring or human-robot interaction, where trust and transparency are crucial. Research into \"emotion neurons\" attempts to shed light on the internal representations of emotions within LLMs, but this is still an emerging area. Moreover, ethical considerations are paramount. The deployment of emotion recognition systems raises concerns about privacy, surveillance, and the potential for misuse, particularly if the systems are not robust or fair across different demographic groups . Ensuring that these technologies are developed and deployed responsibly is a critical ongoing challenge. Finally, resource limitations for low-resource languages and the computational cost of training and deploying large LLMs can also hinder the widespread adoption and further development of sophisticated emotion recognition systems . Addressing these multifaceted challenges requires interdisciplinary collaboration and continued innovation in model architecture, dataset creation, and evaluation methodologies.\n\nThe successes in emotion recognition lay a foundation for tackling other subjective phenomena. One such phenomenon that heavily intersects with sentiment and emotion is sarcasm, which we discuss next, as it often flips sentiment and adds complexity to emotion recognition tasks.\n\n6 Sarcasm Detection",
      "page_start": 17,
      "page_end": 17
    },
    {
      "section_name": "Task Definition Of Sarcasm Detection",
      "text": "Sarcasm detection is a specialized task within natural language understanding that focuses on identifying whether a piece of text is intended to be sarcastic. Sarcasm is a form of figurative language where the speaker or writer says the opposite of what they truly mean, often for humorous, ironic, or critical effect. The core challenge in sarcasm detection lies in the discrepancy between the literal meaning of the words and the intended, often opposite, meaning. This discrepancy is signaled through contextual cues, tone of voice (in spoken language), linguistic patterns, or shared knowledge between the communicator and the audience. For example, the statement \"Oh, great, another meeting!\" is likely sarcastic if the speaker is known to dislike meetings or if the context suggests a negative sentiment towards meetings. Accurately detecting sarcasm is crucial for a deeper understanding of sentiment and opinion, as misinterpreting a sarcastic statement as literal can lead to a misunderstanding of the speaker's intent. The task is particularly relevant in analyzing social media text, product reviews, and online discussions, where sarcasm is frequently employed. The output of a sarcasm detection system is typically a binary label (sarcastic or not sarcastic), although some approaches may attempt to identify the target of the sarcasm or its underlying sentiment.",
      "page_start": 18,
      "page_end": 18
    },
    {
      "section_name": "Dataset Of Sarcasm Detection",
      "text": "Research on sarcasm and irony detection has been driven by datasets drawn largely from social media and curated benchmarks. Early Twitter corpora collected via distant supervision with hashtags such as #sarcasm (e.g., the widely used Ptáček Twitter corpus) established a scalable but noisy paradigm.\n\nSemEval-2018 Task 3 on Irony Detection in English Tweets standardized evaluation with both binary and fine-grained labels (e.g., Non-irony, Verbal Irony, Situational Irony), and many studies use its binary setting for comparability. Outside social media, the News Headlines dataset contrasts satirical headlines from The Onion with genuine headlines from HuffPost, offering a style-specific but domain-limited benchmark frequently used to test transfer.\n\nContext-rich and multimodal resources broadened coverage. The Reddit Self-Annotated Corpus (SARC)  [86]  leverages user markers (e.g., \"/s\"), provides both balanced and large unbalanced splits with hundreds of thousands of comments, and supplies conversational structure (parent/child and thread hierarchy) critical for pragmatic cues. CASCADE  [239]  focuses explicitly on dialogue context by labeling the final utterance in multi-turn discussions as sarcastic or not. MUStARD  [21]  and its extension MUStARD++  [14]  compile sarcastic and non-sarcastic dialogue snippets from TV shows with aligned video/audio and transcripts; despite being multimodal, their text transcripts are widely used for text-only experiments targeting conversational sarcasm.\n\nRecent datasets emphasize annotation quality, multilinguality, and speech. SemEval-2022 Task 6 (iSarcasmEval) addresses the noise of hashtag supervision by asking original authors to annotate intended sarcasm in English and Arabic and to provide literal rephrasings for sarcastic tweets, yielding smaller but high-fidelity pairs that support supervised learning and analysis of meaning contrast. In 2025, PodSarc introduced a large spoken sarcasm benchmark from a podcast, pairing audio with transcripts and using LLM-assisted labels that were human-validated. Concurrently, LLM-based studies have evaluated across \"widely used benchmark datasets\" spanning tweets, forums, and dialogues (e.g., those above). For instance,  [95]  report state-of-the-art results on SemEval-2018 and MUStARD using text-only prompting, while broader assessments such as multi-agent approaches like  [102]  underscore the continuing role of these benchmarks.\n\nTogether, these datasets cover short quips, threaded conversations, news headlines, and audiovisual dialogue, with diverse annotation methodologies (self-annotation, author intent, expert/crowd labels). They reveal design trade-offs: distant supervision scales but is noisy; author-intent labels and paired rephrasings increase reliability but reduce size; conversational and multimodal context improves ecological validity. This variety enables comprehensive evaluation of sarcasm detectors and LLMs, while highlighting persistent challenges of domain shift, context dependence, and pragmatic nuance.",
      "page_start": 18,
      "page_end": 18
    },
    {
      "section_name": "Llm Methods Of Sarcasm Detection",
      "text": "Prompted Reasoning for Sarcasm Pragmatic and metacognitive prompting enrich LLMs' capacity to infer implied meanings and reconcile contextual mismatches, delivering state-of-the-art performance  [95] . In a complementary direction, SarcasmCue formalizes cue-centric reasoning-contradictions, graphs, bags, and tensors-showing that non-sequential cue aggregation can boost smaller models, whereas stronger models benefit more from structured chains and graphs  [209] . Moreover, chain-of-thought rationales aid entity-level sentiment in news and can transfer to sarcasm; however, their effectiveness is inconsistent and improves with self-consistency  [90] . Fine-tuning still outperforms zero-shot prompting for sarcasm on large GPT variants  [56] , and LLaMA-3 often succeeds on shorter inputs yet struggles as length increases  [117] . More broadly, benchmarking indicates that supervised PLMs surpass LLMs on sarcasm  [225] , and scaling alone does not guarantee pragmatic competence-sarcasm continues to lag metaphor under psychiatric-style probing  [200] .\n\nAdditionally, specialized fine-tuning on iSarcasmEval with efficient PEFT/QLoRA yields strong gains, underscoring the importance of target-domain supervision and explicit intention cues  [69] .\n\nMultimodal Understanding and OOD Robustness Generative, instruction-following multimodal systems that retrieve demonstrations sidestep overfitting-prone fusion stacks and improve out-ofdistribution generalization on RedEval while achieving in-domain SOTA  [166] . On the reasoning front, MiDRE blends internal incongruity reasoning with external LVLM rationales and adaptively weights them to outperform prior methods  [80] ; DMDP injects deep, modality-disentangled prompts for few-shot settings and cross-dataset generalization  [79] ; and CofiPara first uses LMM-generated rationales to train coarse sarcasm and then targets fine-grained sarcasm entities  [105] . Complementarily, EilMoB extracts emotion-aware textual incongruity from image-text pairs and bridges modalities to exploit cross-source tensions  [234] . In parallel, agentic VLLM pipelines that triangulate superficial form, semantics, and sentiment consistently lift zero-shot performance on MMSD2.0  [186] . However, evaluations expose a seeing-understanding gap: high perceptual accuracy coexists with sizable sarcasm-comprehension errors rooted in pragmatic and affective reasoning deficits  [227] , and explanation quality does not reliably track model scale  [7] . Taken together, a unified benchmark (MHSDB) underscores that robust multimodal fusion and carefully chosen integration strategies are pivotal for nuanced humor and sarcasm  [47] .\n\nMulti-Agent Orchestration Pipelines Decomposing the challenge of complex sarcasm into coordinated expert roles enhances both robustness and interpretability. In this paradigm, Commander-GPT dispatches focused sub-tasks-keyword extraction, sentiment estimation, and cross-modal verification-to specialized LLMs and fuses their outputs through a coordinating controller  [228] . From a complementary angle, CAF-I formalizes irony via multi-agent collaboration that separates context, semantics, and rhetoric, then aggregates them with a decision agent and iterative feedback  [110] .\n\nThrough the lens of deliberation, LDGNet stages debates among LLM \"debaters\" and employs a learned judge to surface latent world knowledge, producing reliable sentiment decisions across both in-domain and OOD settings  [237] . Extending these ideas to audio-only conditions, LLM-guided annotation pipelines with human-in-the-loop gating introduce new speech sarcasm resources (PodSarc) and enable competitive bimodal systems, bringing agentic supervision to low-visibility modalities  [102] . Taken together, systematic decomposition, structured interaction, and principled adjudication emerge as a coherent design pattern for pragmatic inference under uncertainty.\n\nCommonsense, Incongruity, and Knowledge Alignment Commonsense-centered approaches treat emotional incongruity as a primary signal for sarcasm. In this framing, EICR combines retrievalaugmented LLMs, dependency-graph refinement, adaptive reasoning skeletons, and adversarial contrastive learning to isolate sentiment-inconsistent subgraphs while suppressing spurious correlations  [140] . From a temporal perspective, KA-LLM models evolving events by building dynamic knowledge graphs over topic-target pairs and aligning them with hybrid objectives, thereby explaining how sarcasm triggers shift over time  [195] . On the multimodal front, recent methods extract or synthesize textual \"incongruity carriers\" to narrow modality gaps-EilMoB's emotion-aware incongruity modeling and CofiPara's rationale-guided pretraining exemplify this trend  [234][105] .\n\nComplementarily, external rationales generated by LVLMs, though often noisy, supply useful cues that move beyond shallow captions and steer incongruity resolution  [80] . Looking back, earlier contextual paradigms-such as CASCADE's incorporation of user and discussion features-anticipated today's knowledge-infused strategies and, at the same time, highlight enduring difficulties with implicit sarcasm that lacks overt cues  [238][151] .\n\nNuances, Augmentation, and Linguistic Variety Language nuance remains pivotal. At the domain level, a nuclear-industry study shows topic-specific LLMs struggle with sarcasm while general-domain models perform better; robustness improves with adversarial text augmentation and targeted sarcasm removal, whereas emojis tend to amplify rather than flip sentiment  [12] . Across language varieties, the BESSTIE benchmark finds degraded transfer from inner-circle to outer-circle English-especially for sarcasm-underscoring the need for variety-specific resources and adaptation  [162] . In cross-lingual settings, Indonesian sarcasm experiments indicate that fine-tuned PLMs outperform zero-shot LLMs, and naive augmentation does not remedy class imbalance  [165] . On the evaluation side, out-ofdistribution suites like RedEval and explanation audits expose metric pitfalls-embedding-based scores can assign high similarity to contradictory explanations-calling for more reliable assessment protocols  [166][7] . From an optimization standpoint, dynamic adjustment during multi-task finetuning (DAO) stabilizes learning across heterogeneous sentiment subtasks, a strategy well-suited to sarcasm's imbalanced, multi-objective regimes  [44] .\n\nBenchmarks and Evaluation Practices Recent resources are making evaluation more comprehensive and equitable. In head-to-head comparisons, SarcasmBench assesses LLMs and PLMs across datasets and prompts, finding GPT-4 the strongest among LLMs yet still behind supervised PLMs; moreover, few-shot instruction-only prompting often outperforms chain-of-thought  [225] . At the multimodal scale, MHSDB standardizes humor and sarcasm evaluation across languages and modalities, with fusion approaches consistently beating unimodal baselines  [47] . From a sociolinguistic angle, BESSTIE systematically probes English varieties to reveal persistent equity gaps  [162] . Methodologically, MORE-based audits show that automatic metrics can misjudge explanation faithfulness  [7] , while Visual Room tasks disentangle perception from pragmatic comprehension to quantify the \"understanding gap\"  [227] . Even so, core datasets like SARC 2.0 pol-bal remain valuable for contrasting tuned and zero-shot paradigms across successive GPT generations  [57] . Historically, Reddit-based studies continue to highlight the centrality of conversational context and user history  [238] . Meanwhile, new speech corpora such as PodSarc expand modality coverage  [102] , and regional resources like IdSarcasm sustain non-English evaluation  [165] .\n\nLessons From Sentiment and ABSA Progress in sentiment analysis offers transferable tools for sarcasm detection. At the modeling level, instruction-tuned financial LLMs show that small supervised instruction sets can imbue numeracy and domain fluency beyond generic chat models  [218] [77], while at the optimization level, dynamic adaptive strategies improve the stability of multi-task finetuning across diverse sentiment objectives  [44] . At the reasoning level, chain-of-thought rationales strengthen entity-specific sentiment decisions and, when paired with self-consistency, suggest promptengineering routes for sarcasm  [90] . At the task granularity level, ABSA comparisons highlight domain sensitivity and the value of strong PLMs/LLMs (DeBERTa, PaLM, GPT) for fine-grained aspect judgments-capabilities adjacent to pinpointing sarcasm targets  [125] . In applied contexts, ChatGPT aligns closely with human ABSA in hospitality  [3] , design-aware position encoding enriches generative ABSA with implicit knowledge  [63] , and prompt-engineered sentiment analysis can discriminate subtle clinical language in fibromyalgia screening  [181] . From an evaluation perspective, broader audits indicate that LLMs still lag humans on sentiment, humor, and metaphor, yet remain sensitive to prompt improvements  [212] . From a domain perspective, case studies on nuclear discourse show that sarcasm and sentiment intertwine with policy frames, topicality, and stylistic signals, motivating joint modeling and specialized augmentation  [91][12] .\n\nOverall, recent advances in sarcasm detection leveraging Large Language Models (LLMs) reveal a clear trajectory from single-task fine-tuning toward prompt-engineered, reasoning-aware, and multi-agent/multimodal systems. Benchmarks and empirical studies consistently show that purely scaling models does not guarantee pragmatic comprehension, particularly when sarcasm hinges on cultural, contextual, or emotional incongruity. Techniques such as pragmatic metacognitive prompting, structured cue reasoning, commonsense integration, and dynamic knowledge alignment improve robustness, while agentic frameworks and modality-bridging architectures enable richer interpretation across text, image, and audio. Evaluation work underscores persistent gaps across varieties, languages, and OOD scenarios, urging more equitable, context-aware resources. Crosspollination from sentiment and ABSA research, along with nuanced handling of topic-specific language cues, suggests that future sarcasm detection will benefit from domain adaptation, explicit reasoning steps, and hybrid integration of statistical, commonsense, and multimodal signals to approach human-like interpretive capability.",
      "page_start": 19,
      "page_end": 19
    },
    {
      "section_name": "Key Challenges Of Sarcasm Detection",
      "text": "Sarcasm detection remains a challenging task for LLMs due to several inherent difficulties. One primary challenge is the heavy reliance on context. The interpretation of an utterance as sarcastic often depends on a wide array of contextual factors, including world knowledge, shared understanding between interlocutors, the speaker's typical style, and the specific situation. LLMs, despite their extensive pre-training, may still struggle to access and integrate all relevant contextual information, especially if it's not explicitly stated in the immediate text. For example, understanding a sarcastic comment about a recent event requires knowledge of that event. Another significant challenge is the subtlety and variability of sarcastic cues. Sarcasm can be expressed in many different ways, and the cues can be very subtle, such as a slight change in word choice, a particular sentence structure, or even the absence of expected emotional markers. These cues can be difficult for models to learn, especially when they are sparse or overlap with non-sarcastic language patterns. The ambiguity between sarcasm and other forms of figurative language like irony, humor, or hyperbole also poses a challenge. Distinguishing these closely related concepts can be difficult even for humans, and models may misclassify one for the other.\n\nFurthermore, dataset bias and quality are ongoing concerns. Many sarcasm detection datasets are created from specific sources like social media, which may not be representative of sarcasm in other domains or genres. The annotation process itself can be subjective, and inter-annotator agreement is not always high, leading to noisy labels. Sarcasm is also highly culture-dependent; what is considered sarcastic in one culture may not be in another, or the cues might differ. LLMs trained on data primarily from one cultural context may not generalize well to others. The lack of vocal or visual cues in text-based sarcasm is another hurdle. In spoken communication, tone of voice, facial expressions, and body language provide crucial signals for sarcasm. Text-based models must rely solely on linguistic cues, making the task inherently harder. Finally, adversarial attacks, where subtle changes are made to a text to fool a model into misclassifying sarcasm, highlight the brittleness of some current approaches. Addressing these challenges requires continued research into more context-aware, robust, and nuanced LLM architectures and training methodologies.\n\nWe now turn to humor detection, a related challenge that overlaps with sarcasm-sarcasm is a form of humor, though not all humor is sarcastic, and both involve non-literal intent-yet it introduces distinct demands on background knowledge and linguistic creativity. These added complexities are precisely what current LLMs are being tested on.\n\n7 Humor Detection",
      "page_start": 21,
      "page_end": 22
    },
    {
      "section_name": "Task Definition Of Humor Detection",
      "text": "Humor detection is the task of automatically determining whether a piece of text is intended to be humorous, with some variants also rating its degree or categorizing the humor type; broader humor understanding includes explaining why something is funny and generating jokes. The task is challenging because humor is subjective and culturally contingent, often relies on non-literal intent and linguistic creativity-puns, wordplay, sarcasm, incongruity (overlapping with sarcasm and metaphor), exaggeration, and cultural references-and may require external knowledge and context to \"get\" the joke. Unlike sentiment analysis, cues are subtler and more context-dependent. Applications include improving human-computer interaction through appropriate responses, filtering or recommending humorous content, and analyzing social dynamics in online communities. While post-ChatGPT LLMs can produce jokes, explain simple ones, and often flag humorous intent, truly human-like humor comprehension still demands advanced reasoning and commonsense.",
      "page_start": 21,
      "page_end": 21
    },
    {
      "section_name": "Dataset Of Humor Detection",
      "text": "Work on humor detection has relied on short-form, web-scraped resources that seeded early modeling. Widely used collections include the Short Jokes dataset and the 160,000 Jokes dataset from Kaggle, Pun of the Day, a 16k one-liners collection, and large Reddit jokes dumps (e.g., from r/Jokes). These corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from other sources to form binary detection sets; variants target specific subtypes such as roast/insult humor. Beyond English, multilingual resources emerged, notably the Spanish HAHA (Humor Analysis) datasets at IberLEF (with humor presence and funniness ratings), Hinglish puns collections, and Chinese releases such as CHumor 1.0. Early multimodal and conversational angles came from UR-FUNNY (humor in TED-talk conversations) and MUStARD (multimodal sarcasm, overlapping with humorous cues). Researchers also began to exploit aligned or minimally contrastive pairs to better capture what \"makes\" text funny, including The Onion satire with human-edited \"serious\" counterparts (the Unfunny Corpus) and aligned topic-matched joke/non-joke pairs.\n\nFrom 2020 to 2021, shared tasks consolidated high-quality, carefully annotated benchmarks.\n\nSemEval-2020 Task 7 introduced Humicroedit, in which single-word edits turn news headlines humorous, supporting pairwise ranking and analysis of humor-inducing transformations. SemEval-2021 Task 7 (HaHackathon) released a large English dataset-primarily tweets and short texts-with multiple annotators per item, covering humor detection (yes/no), funniness rating, and offense in humor; the \"Humor and Offense\" (HAHO) references typically refer to this split. These tasks highlighted subjectivity via dense annotation and established standard evaluation settings. In parallel, Twitter hashtag (#humor) collections and several Kaggle humor-detection datasets (e.g., HahahaClf) offered additional short-text benchmarks.\n\nSince 2022, datasets have broadened in modality, context, and language while being used to probe large language models (LLMs). Studies have evaluated LLMs (e.g., GPT-3) on SemEval-2021, Humicroedit, Pun-of-the-Day and Hinglish pun sets, and Reddit joke vs non-joke discrimination, often finding humor-especially wordplay-remains challenging. Conversational and workplacecontext corpora (e.g., WRIME and other dialogue resources, including dinner-party dialogues with humorous turns) test whether models recognize humor in context and alongside social variables such as appropriateness and offense. Aligned-pair designs gained traction: beyond Humicroedit, satire-serious headline pairs and other minimally contrastive text pairs have been shown to help models learn portable humor cues, with reports that classifiers trained on such pairs generalize well across datasets. These efforts underscore how dataset choices-humor type (puns, satire, insults), text length, conversational context, and offensiveness-strongly shape detection performance.\n\nRecent directions extend humor detection into new settings and modalities. Targeted datasets for emotionally supportive dialogues have been proposed  [141] , separating humor generation in a specified style from humor recognition in context (e.g., recognizing a counselor's gentle joke and its appropriateness). In vision-and-language, HumorDB  [78]  has been introduced for graphical humor, providing images (cartoons, photos) labeled for funniness, funniness ratings, and minimally contrastive pairs that differ only in a humor-bearing element; initial results show vision-language models perform above chance yet below human levels. Parallel \"co-creativity\" evaluations-such as AI-assisted meme captioning-link detection to generation and collaborative use. Together with established resources like Kaggle short-joke corpora, Reddit jokes, Pun of the Day, Humicroedit, UR-FUNNY, MUStARD, SemEval-2021, HAHA (Spanish), Hinglish puns, CHumor 1.0, WRIME, and aligned satire-serious pairs, this expanding ecosystem supports robust, comparative evaluation of humor detection across text, dialogue, and images.",
      "page_start": 21,
      "page_end": 22
    },
    {
      "section_name": "Llm Methods Of Humor Detection",
      "text": "Benchmarking and Dataset-Driven Approaches Large-scale, high-quality datasets remain the foundation for advancing humor recognition. Chumor 1.0 and 2.0  [65] [65]  [66] , sourced from Ruo Zhi Ba, target culturally nuanced Chinese humor, revealing state-of-the-art (SOTA) LLMs perform only slightly above chance, with human explanations far superior. TalkFunny  [30]  extends this by capturing explainable humor responses with chain-of-humor annotations, enabling evaluation of conversational humor comprehension. HumorBench  [129]  and HumorDB  [78]  introduce English cartoon-caption and visual humor datasets, respectively, exposing persistent performance gaps between human and model understanding. MHSDB  [47]  and YesBut  [73]  widen scope to multimodal/multilingual humor, showing fusion of modalities consistently outperforms unimodal baselines, but contradiction-based narrative humor remains elusive. These benchmarks underscore that data realism, cultural specificity, and multi-modality are crucial for robust humor understanding evaluation.\n\nPrompting and Few-Shot Baselines Even without task-specific fine-tuning, prompt-based strategies provide informative baselines for humor detection. From a low-resource perspective, few-shot prompting of GPT-4 and Gemini on Croatian tweets  [9]  yields LLM-human agreement on par with human-human agreement, indicating feasibility for rapid dataset bootstrapping. At the modality level, multimodal prompting that incorporates speech audio  [10]  improves explanations of phonetic humor by recovering prosodic cues that purely text-based models miss. In workplace settings,  [155]  shows that current LLMs misjudge contextual appropriateness, underscoring the gap between surface-level humor detection and situational awareness. These studies position prompting as a lightweight entry point to humor recognition while revealing the brittleness of context-sensitive judgments.\n\nFine-Tuning and Representation Learning When domain alignment is critical, supervised adaptation surpasses prompting. From a task-alignment perspective, CYUT's CLEF JOKER submission  [193]  fine-tuned LLaMA 3 and RoBERTa for humor-genre classification, outperforming zero-shot GPT-4, though test-set generalization lagged. From a representation-learning angle,  [50]  leveraged hidden LLM representations with cross-validation to achieve competitive accuracy without finetuning, while noting ambiguous class boundaries. In language-specific settings, specialized Chinese humor models such as CFunModel  [216]  integrate multi-task learning on aggregated humor corpora, surpassing general-purpose LLMs on recognition benchmarks. Taken together, these studies suggest that controlled adaptation improves humor sensitivity, provided overfitting is managed.\n\nCultural, Linguistic, and Translation-Aware Methods Humor recognition becomes more challenging when linguistic or cultural gaps arise. From a cross-lingual perspective, Jokes or Gibberish?  [137]  examines humor preservation in English-Thai translation and finds that explanation-augmented prompting (GPT-Ex) yields the highest joke retention, particularly for idioms and cultural references. From a cross-cultural angle,  [61]  quantifies humor intensity in Chinese and English family jokes via ambiguity, sentiment, and incongruity indicators, revealing divergences in humor structure. In slang-heavy Chinese contexts, DuanzAI  [149]  boosts LLM comprehension of slang-based humor through phonetic matching and pinyin-hanzi disambiguation. These approaches highlight the value of embedding cultural and linguistic priors into recognition systems for culturally situated humor.\n\nMultimodal Humor Understanding Humor often spans text, images, and audio, necessitating multimodal processing. From a representation perspective, ClassicMemes-50-Templates  [37]  and MemeMind  [17]  address meme classification and explanation using vision-language embeddings. From the knowledge integration angle, BottleHumor  [75]  leverages the information bottleneck to iteratively distill relevant world knowledge for multimodal humor explanation. In terms of fusion strategies, MHSDB  [47]  and YesBut  [73]  show that multimodal feature fusion outperforms unimodal approaches; however, models still struggle to comprehend implicit contradictions conveyed in visuals.\n\nSafety, Ethics, and Robustness Beyond accuracy, humor recognition intersects with safety and ethical concerns. HumorReject  [194]  fine-tunes LLMs to respond to harmful prompts with indirect refusals, decoupling safety from denial templates.  [122]  found that safety filters often erase minority perspectives in comedic contexts, reinforcing hegemonic norms; they advocate artist-centric alignment. Red-teaming LVLMs revealed that dark-humor prompts can bypass safety tuning, generating toxic or insulting content. These works highlight the need to blend cultural sensitivity, adversarial testing, and humor-aware refusal strategies when deploying humor recognition or interaction systems.\n\nHumor detection is converging on a data-model-alignment playbook: realistic, culturally grounded multimodal benchmarks; lightweight prompting for quick gains; targeted adaptation and representation reuse for domain fit; and culture-and translation-aware priors. Multimodal fusion and knowledge-centric approaches advance explanation and situational awareness, while humor-aware refusals and adversarial evaluation integrate safety into deployment. Ultimately, humor serves as a sharp probe of commonsense, pragmatics, and cross-modal reasoning, paving a practical path from benchmarking to robust, culturally sensitive interaction.",
      "page_start": 23,
      "page_end": 23
    },
    {
      "section_name": "Key Challenges Of Humor Detection",
      "text": "Humor detection presents challenges for LLMs, primarily due to the subjective and culturally dependent nature of humor. What one individual or culture finds hilarious, another might find offensive, confusing, or not funny. This subjectivity makes it difficult to create applicable humor detection models and to establish a clear \"ground truth\" for training data. Annotators may disagree on whether a particular text is humorous, leading to noisy labels and potentially biased models. Another challenge is the diversity and complexity of humor. Humor can manifest in countless forms, including puns, satire, irony, slapstick, absurdity, and observational humor, each with its own linguistic and cognitive mechanisms. LLMs may struggle to learn a unified representation that captures all these varied types effectively. For example, understanding a pun requires phonological and semantic knowledge, while understanding satire requires awareness of social norms and critique.\n\nThe reliance on implicit meaning, common sense, and world knowledge is another hurdle. Many jokes rely on unstated premises, cultural references, or an understanding of typical scenarios that are then subverted. LLMs, despite their vast training data, may not always possess the depth of world knowledge or the ability to make the subtle inferences required to \"get\" a joke. The incongruityresolution theory of humor suggests that humor arises from the perception of an incongruity that is then resolved in a playful or unexpected way. Modeling this cognitive process of identifying and resolving incongruity is a complex task for LLMs. Furthermore, humor is often context-dependent. A statement might be funny in one context but not in another. Capturing and representing the relevant context, especially in short texts or isolated utterances, can be difficult. Finally, evaluating humor detection systems is challenging. Standard metrics like accuracy may not fully capture a model's ability to understand humor, especially if the test data is biased or if the humor is particularly subtle. Developing more nuanced evaluation methods that can assess a model's deeper understanding of humor is an ongoing research area.\n\nIn summary, LLMs have made noticeable progress in recognizing humor and even explaining certain kinds of jokes, but they are far from truly understanding all humor as humans do. They tend to be formulaic and miss subtle context. Humor detection research with LLMs is pushing boundaries by introducing style-aware evaluation, co-creativity studies, and multimodal humor tasks. These efforts highlight both the capability and the limits of current models. The insights gained (e.g., need for multi-step reasoning and context modeling) echo those in sarcasm and metaphor tasks. We next look at stance detection, another task requiring subjective understanding, where LLMs are proving useful, especially in zero-shot and multi-agent settings.\n\n8 Stance Detection",
      "page_start": 23,
      "page_end": 24
    },
    {
      "section_name": "Task Definition Of Stance Detection",
      "text": "Stance detection is a core NLP task that determines an author's position toward an explicitly specified target (e.g., a person, policy, product, or proposition), typically assigning labels such as Favor/Support, Against/Oppose, Neutral/Neither, and in some frameworks Query when the text asks about the target without a clear position. Unlike sentiment analysis, which captures overall positive/negative tone, stance is inherently target-dependent: the same text can take different stances depending on the target and may diverge from its sentiment (e.g., \"The policy is harsh but necessary\" is negative in tone yet supportive in stance). This target-conditioned nature-and the need to capture both explicit signals and implicit, context-driven cues-makes stance detection challenging but vital for political discourse analysis, rumor and misinformation tracking, public health and opinion monitoring, argument mining, and social media moderation. With the rise of online communication, its importance has grown, and modern large language models, combining broad world knowledge with pragmatic inference, are increasingly effective for few-and zero-shot stance detection on emerging topics.",
      "page_start": 24,
      "page_end": 24
    },
    {
      "section_name": "Dataset Of Stance Detection",
      "text": "Recent surveys of stance detection for the LLM era emphasize that progress is driven by diverse, wellannotated datasets spanning social media, news, forums, and debate platforms, and covering targets such as political actors, ideologies, policies, products, and public-health topics. Annotation typically presents a text with a target and asks human annotators to label stance; inter-annotator agreement is a key quality signal. Dataset characteristics-size, class balance, target specificity, explicit vs. implicit stance, and modality-strongly shape model design and performance. Cross-lingual and multimodal resources are increasingly common, reflecting the realities of online discourse.\n\nEarly work established core benchmarks and task variants. SemEval-2016 Task 6 on Twitter included five targets (Atheism, Climate Change, Feminism, Hillary Clinton, Legalization of Abortion) with Favor/Against/None labels, showing that tweets can convey stance without explicitly naming the target. Related lines include rumor-related stance tasks with conversational labels such as support, deny, query, and discuss (as in SemEval), and the Fake News Challenge (FNC-1), which frames stance between headlines and articles as agree, disagree, discuss, or unrelated. Broader-document settings appear in debate/forum corpora such as PERSPECTRum  [26]  and in argumentation resources like ArgMin, as well as stance in news commentaries. Multilingual threads include datasets around specific political contexts (e.g., stance on Catalan independence). Mohammad's releases surrounding the SemEval stance task consolidated early public resources and practices for evaluation.\n\nAs the field matured, a subsequent phase emphasized cross-target and event-driven generalization. P-STANCE  [99]  collects tweets expressing stance toward U.S. political figures and is designed for cross-target evaluation (training on one figure, testing on another), probing target transfer. COVID-19  [55]  datasets capture stance toward fast-evolving public-health topics (e.g., masking), adding noise, sarcasm, and shifting narratives typical of crisis-time social media. These corpora broadened domains and targets while keeping tweet-scale inputs well matched to general-purpose language models.\n\nMore recently, datasets increasingly meet LLM-oriented needs: broader topical coverage, more languages, and richer signals. VAST  [5]  (Varied Stance Topics) extends target breadth and domains to test open-domain stance recognition. VaxxStance  [2]  focuses on vaccine-related stance, supporting research on public-health discourse and implicit attitudes. MAWQIF  [6]  expands Arabic stance resources, advancing cross-lingual and low-resource evaluation. Recent corpora also explore multimodality (text plus images or user/profile cues) and finer-grained or implicit labels, making annotation harder and class balance more uneven. These datasets are central to benchmarking zero-shot and crosstarget capabilities of LLMs and to studying robustness in realistic, multilingual settings, including misinformation and rapidly evolving events. Together, the earlier benchmarks (e.g., SemEval-2016, FNC-1, debate/news datasets) and the latest resources (e.g., VAST, VaxxStance, MAWQIF) provide complementary testbeds for stance detection, enabling systematic comparison of methods while highlighting persistent challenges such as implicit stance, domain shift, and cross-lingual transfer.",
      "page_start": 24,
      "page_end": 25
    },
    {
      "section_name": "Llm Methods Of Stance Detection",
      "text": "Symbolic and Logic-Augmented Reasoning Within Symbolic and Logic-Augmented Reasoning, fusing symbolic constraints with LLMs yields more interpretable and consistent stance decisions. From a rule-encoding perspective, FOLAR encodes First-Order Logic (FOL) rules elicited by Chainof-Thought into a Logic Tensor Network and applies multi-decision fusion to curb bias  [35] . From the lens of rationale unification, LogiMDF consolidates divergent LLM rationales via a Logical Fusion Schema and models them with a multi-view hypergraph network to reconcile inconsistencies  [217] . From the angle of prompt-based knowledge integration, prompt-tuned fusion frameworks leverage multi-prompt learning and explanation-guided supervision to incorporate LLM-acquired knowledge, strengthening reasoning while filtering noise  [43][42] . For cross-target transfer, performance improves when LLMs surface target-oriented analytical perspectives and natural language explanations that are then fused into the predictor  [41] . At the memory-augmentation level, semiparametric \"experienced experts\" dynamically retrieve domain-specialized memories to stabilize reasoning and reduce hallucinations  [187] . In sum, symbolic and logic-augmented fusion enhances the interpretability and consistency of stance reasoning.\n\nChain-of-Thought and Explicit Rationales Across tasks, explicit reasoning consistently improves zero-and few-shot stance detection. From a methodological perspective, Chain-of-Stance decomposes the decision process into stance-aware steps and delivers substantial gains without task-specific fine-tuning  [115] , while Stance Reasoner performs zero-shot inference by generating background-grounded reasoning chains that steer the final stance, enhancing both interpretability and generalization  [169] . In practical terms, CoT-derived explanations can supervise downstream models or calibrate prompt tuning, achieving strong performance at modest cost  [43][42] . From an annotation perspective, GPT-4's zero-shot CoT emerges as a competitive and economical alternative to few-shot prompting  [112] . From a knowledge discovery standpoint, CoT also serves as a knowledge elicitation tool for logic extraction and cross-target analysis pipelines  [41][35] . Chain-of-Thought and explicit rationales constitute a unifying paradigm that enhances accuracy, data efficiency, and interpretability while enabling scalable knowledge discovery in stance detection.",
      "page_start": 26,
      "page_end": 26
    },
    {
      "section_name": "Multi-Agent Collaboration And Consistency",
      "text": "Collaborative agent architectures integrate multifaceted knowledge and enforce cross-agent consistency to improve decision quality. In this vein, COLA orchestrates role-infused expert agents-linguistic, domain, and social-media specialists-that debate and consolidate a stance, providing explainability without requiring additional training data  [92] . Extending structured deliberation, ZSMD sets up support-versus-oppose debaters augmented with background knowledge and introduces a referee to resolve disagreements, thereby improving zero-shot performance and capturing nuance  [114] . On the efficiency front, CoVer amortizes LLM reasoning over batches and employs a small model to verify logical consistency and aggregate predictions, substantially reducing LLM calls while maintaining state-of-the-art results  [202] . Multi-Agent Collaboration and Consistency-through role specialization, structured debate with arbitration, and systematic consistency checking-yield a unified, cost-conscious pipeline that enhances accuracy, robustness, and explainability in stance assessment.\n\nKnowledge Injection and Retrieval Augmentation Injecting structured knowledge helps bridge target-text gaps and stabilizes zero-shot and cross-target settings. At the representation level, prompted LLMs extract target-text relations that are fed into a generation model and coupled with prototypical contrastive alignment to strengthen decoding  [230] . From a retrieval perspective, retrieval-augmented pipelines ground tweet-claim relations with evidence and LLM reasoning to enhance stance truthfulness  [240] . On the training side, multi-task fine-tuning with debate data and knowledge retrieval complements LLM semantics and boosts zero-shot performance  [51] . For low-resource transfer, knowledge can be infused and aligned from diverse sources  [201] . In terms of data coverage, synthetic open-domain stance corpora generated by ChatGPT expand coverage while remaining cost-effective  [233] . Knowledge Injection and Retrieval Augmentation operate as synergistic levers that ground representations and decoding with explicit evidence, improve truthfulness, and extend generalization across domains, targets, and resource levels at cost.\n\nFine-Tuning, Reinforcement, and Data Curation Modern LLMs-including midsize models fine-tuned on public datasets-now surpass prior benchmarks and offer strong efficiency-accuracy tradeoffs  [59] . Methodologically, reinforcement tuning with hybrid rewards can surface high-quality LLM-annotated examples and enable joint stance detection and rumor verification under label scarcity  [207] . From a data-annotation standpoint, LLMs themselves are viable labelers: few-shot and zero-shot chain-of-thought GPT-4 labeling approaches approximate supervised baselines at lower cost  [112] . From a domain-adaptation angle, domain-specific corpora such as δ-Stance show that while proprietary LLMs capture polarity, supervised fine-tuning is essential for modeling intensity and supports cross-domain transfer  [62] . In terms of data augmentation, synthetic open-domain datasets complement human labels and improve generalization to unseen targets  [233] . Fine-Tuning, Reinforcement, and Data Curation function as mutually reinforcing pillars, yielding systems that are accurate, sample-efficient, and robust across domains and targets.\n\nMultimodal and Multilingual Stance Understanding From a cross-lingual perspective, VLMs underuse visual cues and over-rely on textual content, with performance strongly shaped by language support and model size  [179] . With respect to multimodal conversational use, complexity increases; new datasets and MLLM architectures that learn joint text-image representations achieve state-of-theart results yet still reveal substantial headroom  [131] . In terms of multi-turn dialogue, progress remains limited: even specialized attention mechanisms yield only modest gains on recent benchmarks, highlighting unresolved issues in long-range dependencies and dialogue-role modeling  [132] . From an application and safety standpoint, stance-driven generation systems demonstrate downstream utility and safety-aware content creation in advocacy contexts  [184] . Overall, the field is advancing but unevenly, with improved representation learning tempered by persistent challenges in cross-lingual grounding, long-context reasoning, and controllable safe generation.\n\nUser-Level Stance and Political Bias From a theory-driven standpoint, agendas call for shifting from message-level to user-level modeling, integrating psychological features and LLM-inferred attributes to better capture stance formation  [13] . Methodologically, unsupervised pipelines that map user timelines to socio-political statements via LLM-based NLI generalize across elections and cultures, approaching supervised scores  [53] . Political bias remains consequential: LLMs skew liberal and are sensitive to demographic cues, underscoring careful prompt design  [136] . At the dataset level, effects dominate performance variance in political stance tasks, and target ambiguity exacerbates errors, calling for clearer target specification and robust prompting  [130] . Overall, advances will hinge on user-centered modeling, bias-aware prompting, and clearer targets.\n\nA comprehensive survey inventories LLM-driven stance detection across learning regimes, modalities, and target relations, mapping applications (misinformation, politics, health, moderation) and open challenges (implicit stance, bias, explainability, low-resource, real-time, compute). The emerging toolbox-logic-infused reasoning, multi-agent collaboration, knowledge retrieval/injection, and datacentric supervision-charts a coherent path toward interpretable, scalable, and generalizable stance detection systems that transfer across targets, modalities, and users.",
      "page_start": 27,
      "page_end": 27
    },
    {
      "section_name": "Key Challenges Of Stance Detection",
      "text": "Despite the significant progress enabled by Large Language Models (LLMs) in stance detection, several key challenges persist, limiting the robustness and general applicability of current systems.\n\nFor instance, implicit stance expression, cultural biases in training data, and the computational costs associated with LLMs. Implicit stance expression is a major hurdle because individuals often convey their opinions indirectly, using sarcasm, irony, or subtle linguistic cues that are difficult for models to interpret accurately without a deep understanding of context and world knowledge. LLMs, despite their advanced capabilities, can still struggle with such nuanced language, leading to misclassification. Cultural biases present in the vast corpora used to pretrain LLMs can also propagate into stance detection models, causing them to perform differently across various demographic groups or cultural contexts. This can lead to unfair or inaccurate predictions, particularly when dealing with sensitive topics or diverse user bases. Addressing these biases requires careful dataset curation, debiasing techniques, and culturally-aware model development.\n\nAnother challenge is the computational expense of training and deploying LLMs, especially for real-time applications or resource-constrained environments. While parameter-efficient fine-tuning methods offer relief, the inference latency and hardware requirements for state-of-the-art LLMs can be prohibitive. Furthermore, the dynamic nature of language and the emergence of slang, neologisms, and discourse patterns mean that models can quickly become outdated if not continuously updated or retrained. The evaluation of stance detection models presents challenges, as human annotators may disagree on the stance label for ambiguous texts, making it difficult to establish a ground truth. Developing evaluation metrics that can capture the nuances of stance and account for inter-annotator disagreement is an ongoing area of research. These challenges highlight the need for further research in areas like explainable stance reasoning, low-resource adaptation, and the development of real-time deployment frameworks for LLM-based stance detection systems.\n\nStance detection benefits from LLMs' language mastery and reasoning. The post-ChatGPT era has yielded methodologies -sequential reasoning, multi-agent frameworks -that have pushed stance detection performance to new highs, even in zero-shot settings. Yet, challenges like implicit stance and model bias ensure it remains an active field. The innovations, such as structured reasoning about opinions, could be relevant to other subjective tasks, since stance co-occurs with sentiment, emotion, and figurative language. One such overlapping task is metaphor recognition, which we examine next, where LLMs are used to detect when language is used non-literally.\n\n9 Metaphor Recognition",
      "page_start": 27,
      "page_end": 28
    },
    {
      "section_name": "Task Definition Of Metaphor Recognition",
      "text": "Metaphor recognition is a task in natural language processing that involves identifying and interpreting metaphorical language within text. Metaphors are figurative expressions where a concept (the \"target\" or \"tenor\") is understood in terms of another, often unrelated, concept (the \"source\" or \"vehicle\"). For example, in the phrase \"time is money,\" the abstract concept of \"time\" (target) is conceptualized through the more concrete concept of \"money\" (source), implying that time is a valuable resource that can be spent, saved, or wasted. The task of metaphor recognition typically involves two subtasks: metaphor identification (detecting whether a word or phrase is used metaphorically) and metaphor interpretation (understanding the meaning conveyed by the metaphor, often by identifying the mapping between source and target domains). This is essential for deeper natural language understanding, as metaphors are pervasive in everyday communication, literature, and specialized domains like law and medicine. Understanding metaphors enables LLMs to grasp nuanced meanings, infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because LLMs possess broad semantic knowledge: they \"know\" word meanings and can detect expectationviolating usages, much like humans rely on Selectional Preference Violation as a cue for metaphor. Post-ChatGPT models have been applied to metaphor tasks to see if they grasp abstract figurative language and even to generate metaphors.",
      "page_start": 27,
      "page_end": 28
    },
    {
      "section_name": "Dataset Of Metaphor Recognition",
      "text": "Research on metaphor Recognition has been anchored by several foundational datasets created before 2022. The VU Amsterdam Metaphor Corpus  [163]  (VUA/VUAMC) remains the primary benchmark: it provides token-level metaphor annotations across genres (news, fiction, academic, conversation) following MIP/MIPVU, covers all parts of speech, and contains tens of thousands of labels; it also underpinned the 2018 and 2020 shared tasks. Verb-focused resources include TroFi  [15]  ( 3k sentences for 50 target verbs labeled as literal vs metaphorical) and MOH-X  [123]  (647 verb instances), which are frequently paired for evaluation. Other established sets target specific constructions or populations: LCC datasets  [124]  emphasize adjective-noun metaphors; the TOEFL metaphor dataset  [89]  annotates second-language learner sentences; and the Stab news corpus marks sentence-level metaphor presence. While mainstream benchmarks frame the problem as word-level tagging, some studies also consider multi-word or idiomatic metaphors.\n\nRecently, the landscape expanded toward evaluation of deeper interpretation and LLM robustness. The Metaphor Understanding Challenge Dataset (MUNCH)  [176]  is a notable LLM-oriented benchmark that couples naturally occurring metaphorical sentences from four genres with over 10,000 humanwritten apt paraphrases and 1,500 inapt paraphrases, enabling tests that distinguish genuine metaphor understanding from lexical overlap; it also spans varying levels of novelty and is openly available. In Chinese, a recent shared-task-style resource (\"Task 9\")  [24]  provides 34,463 metaphorical sentences annotated with tenor, vehicle, and ground, plus two 500-sentence validation sets aligned with the test format, supporting component-level analysis beyond binary identification. Complementing this, CMDAG  [156]  is a 28K-sentence Chinese literary corpus annotated for tenor, vehicle, and ground that uniquely leverages grounds as chain-of-thought to steer metaphor generation; code is available. Newer datasets also explore metaphor novelty and multilingual coverage (e.g., Russian). Consistent with these trends, recent methods  [106]  continue to report results on VUA/VUAMC and the smaller verb datasets (MOH-X, TroFi), underscoring their role as standard testbeds.\n\nComplementing core resources, domain-specific corpora have been curated to probe generalization, including classical, metaphor-rich texts such as the Bhagavad Gita and the Sermon on the Mount  [23] .\n\nMultimodal efforts link language to gesture or vision to study how metaphors align with nonverbal cues, and some datasets combine figurative categories (e.g., hyperbole with metaphor  [236] ) to encourage unified modeling. Finally, a subset of tasks explicitly targets concurrent or multi-word metaphors, though word-level tagging remains the dominant formulation. Together, these datasets enable both traditional identification and deeper interpretation, and they offer varied genres, languages, and novelty levels for comprehensive evaluation.",
      "page_start": 28,
      "page_end": 29
    },
    {
      "section_name": "Llm Methods Of Metaphor Recognition",
      "text": "Theory-Guided Prompting Pipelines Recent advances have shifted metaphor recognition from superficial multimodal fusion to cognitively grounded prompting and scaffolding. On the cognitive side, Chain-of-Cognition prompting encourages models to reason about source-target mappings and cross-modal associations rather than merely combining modalities  [220] . On the instructional side, Theory-guided Scaffolding Instruction operationalizes metaphor theory through staged questions and a knowledge graph, yielding interpretable decisions and enabling recovery when models falter  [174] . From a decision-making perspective, Dual-Perspective Metaphor Detection integrates implicit datastore cues with explicit theory-driven prompts and self-judgment to improve reliability and explainability  [106] . In Chinese multimodal scenarios, a Chain-of-Thought bi-level optimizer approximates human cognition by modeling hierarchical mappings  [221] . As for context, lightweight injection proves effective: introducing hypothetical scenarios before proverbs markedly improves word-level detection  [58] . Meanwhile, few-shot GPT-3, although exhibiting partial knowledge of mappings, suffers from source hallucination and overreliance on lexical triggers-underscoring the need for guided reasoning  [183] . Taken together, these advances point toward more human-like, reliable, and interpretable metaphor recognition.\n\nMultimodal Recognition With Imaginative Bridges Multimodal metaphor understanding hinges on aligning heterogeneous cues through cognitively plausible bridges. Beyond simple caption fusion, Chain-of-Cognition prompting elicits textual entity relations and ties them to visual evidence for cross-domain mapping  [220] . Under low-resource conditions, imaginative frames grounded in Conceptual Metaphor Theory stimulate cross-modal association and enable data-efficient, retrievalaugmented reasoning  [173] . On the efficiency front, CDGLT introduces controlled \"concept drift\" via SLERP-perturbed CLIP embeddings and tunes only LayerNorms to bridge literal-figurative gaps at low cost  [139] . In Chinese settings, CM3D and a Chain-of-Thought mapping model provide annotated domains and interpretable alignment signals  [221] . On the generation and supervision side, a co-creation pipeline that expands linguistic metaphors into textual entailments for diffusion models yields high-quality visual metaphors and intrinsic/extrinsic evaluation signals useful for recognition supervision  [22] . Empirically, however, II-Bench shows MLLMs lag humans on implied meanings-especially for abstract or sentiment-laden images-spotlighting sentiment reasoning as a key bottleneck  [111] . Targeted sentiment-aware reasoning may help close this gap.\n\nPretraining, Corpora, and Benchmarks Dedicated resources and pretraining schemes are catalyzing measurable progress. On the pretraining front, MetaPro 2.0 couples a large paraphrase-rich VMC-P corpus with Anomalous Language Modeling, markedly improving identification and literal paraphrasing of figurative expressions  [119] . On the diagnostic side, MUNCH differentiates genuine interpretation from mere lexical similarity using apt/inapt paraphrases across genres, revealing persistent LLM mapping gaps  [176] . On the resource side, the Figurative Archive aggregates Italian metaphors with psycholinguistic ratings and corpus metrics, enabling controlled studies of familiarity and concreteness effects  [18] . In Chinese contexts, CMDAG contributes a large corpus with tenors, vehicles, and grounds; supervising with grounds as Chain-of-Thought improves generative quality and yields explicit features reusable for recognition  [156] . For multimodal Chinese, CM3D brings crossmodal mappings into the ecosystem  [221] . On the evaluation front, domain-specific studies-from religious texts showing cross-translation consistency  [23]  to large-scale analyses of the Book of Songs revealing cognitive variation  [11] -stress cross-cultural robustness. Taken together, these corpora and training paradigms target anomalous language head-on and help standardize evaluation. Continued multilingual expansion will further strengthen generalization.\n\nContext, Domain, and Emotion as Signals Contextualization, domain adaptation, and affective cues are decisive for recognition. On contextualization, prompted contexts close the abstraction gap in proverb-level detection  [58] . In translation, domain adaptation reduces metaphor errors; literary-adapted NMT and LLMs compare favorably with commercial MT despite a 64-80% accuracy ceiling  [84] . Methodologically, multi-agent reasoning maps culturally laden Traditional Chinese Medicine metaphors to Western medical concepts, illustrating cross-paradigm grounding as a route to reliable mapping  [167] . On the affect side, emotion knowledge helps disambiguate figurative devices: modeling bidirectional dynamics between hyperbole and metaphor with emotion-aware features delivers large F1 gains and reduces type confusion  [236] . For interdisciplinary reading and political discourse, dialogic/on-demand metaphor generation and prompt-engineered analyses make opaque jargon accessible while preserving critical reflection  [211][120] . Across traditions, religious and classical corpora expose invariances and differences that can calibrate domain-sensitive recognizers  [23][11] . Together, these directions chart a practical path toward robust metaphor recognition.\n\nCreativity-Aware Signals For Recognition Recognition improves when systems internalize analogy structure and creativity constraints. At scale, larger LMs better separate metaphors from faulty analogies via perplexity, yet metaphorical fluency remains hard-evidence of structural awareness without full creative competence  [16] . On data generation and supervision, human-AI co-creation of visual metaphors surfaces entailments and image-text correspondences that supervise detectors and stress-test cross-domain alignment  [22] . From an assessment perspective, automatic scoring of metaphor creativity supplies scalar signals aligned with human judgments, a promising auxiliary objective for recognition models  [46] . In tooling, authoring systems that scaffold extended metaphor creation make explicit coherence, extension, and revision steps-signals robust recognizers should verify  [87] . For evaluation, comparative studies of novel literary metaphors map divergences between human and model interpretations, yielding granular error taxonomies for training and analysis  [76] . Together, these strands point toward recognition that is structurally grounded and creatively aware.\n\nLimits, Biases, and Reliability Controls Empirical audits caution against overconfidence: GPT-3 often hallucinates source domains, mislabels literal as figurative (and the reverse), and overrelies on lexical cues at the expense of context  [183] . In vision-language settings, MLLMs trail humans on implied meanings, and sentiment hints can artificially inflate scores-evidence of shallow affective reasoning  [111] . Conceptually, critics urge reframing \"hallucination\" as \"confabulation,\" which better captures context-shaped fabrication in figurative inference  [159] ; related links to absolute metaphors and psychosis theories point to structural blind spots in token-based reasoning  [67] . From a comparative cognition standpoint, analyses reveal domain preferences and biases that depart from human metaphor usage, highlighting fairness and generalization risks  [118] . On the reliability front, self-judgment with theory-guided prompts  [106] , emotion-informed multitask training  [236] , and scaffolded stepwise support  [174]  offer pragmatic controls that raise the floor for trustworthy recognition. Continued stress-testing across domains will be essential.\n\nMetaphor recognition is shifting from shallow fusion to grounded, theory-guided pipelines: chainof-cognition prompts, scaffolded instruction, and self-judgment align source-target mappings with visual evidence for interpretable decisions. Imaginative multimodal bridges and low-cost adapters improve cross-domain alignment, while corpora and anomalous-language pretraining standardize evaluation and boost generalization. Domain and emotion signals reduce errors; creativity-aware supervision adds structural discipline. Yet LLMs still hallucinate and miss implied sentiment. Next, unifying cognitive scaffolds with retrieval, sentiment-aware modules, and uncertainty-backed by multilingual, domain-rich benchmarks-promises more robust, human-like understanding.",
      "page_start": 30,
      "page_end": 30
    },
    {
      "section_name": "Key Challenges Of Metaphor Recognition",
      "text": "Metaphor recognition presents key challenges for Large Language Models (LLMs), primarily stemming from the nuanced, context-dependent, and culturally specific nature of metaphorical language. One challenge, as highlighted by experiments with the MUNCH dataset, is that LLMs may struggle to perform full metaphor interpretation, sometimes relying on lexical similarity rather than genuine cross-domain mapping. This means that even if an LLM correctly identifies a word as metaphorical, it might not accurately understand the intended meaning or the specific way the source domain illuminates the target domain. The interpretation of novel metaphors, which are creative and not part of common parlance, is particularly difficult because LLMs primarily learn from existing text corpora and may not have encountered these specific figurative uses before.\n\nAnother significant challenge is the ambiguity in distinguishing metaphorical usage from literal usage, especially for polysemous words (words with multiple meanings). LLMs need to disambiguate word senses based on context, which can be complex when both literal and metaphorical interpretations are plausible. Furthermore, the \"grounds\" of a metaphor-the specific attributes or features that are mapped from the source domain to the target domain-are often implicit and require deep world knowledge and reasoning to infer. For example, understanding why \"time is money\" involves understanding cultural values placed on both time and money as resources. LLMs may lack this nuanced understanding or struggle to articulate the specific grounds of a metaphor. The paper on Chinese metaphor recognition also implicitly points to the challenge of adapting LLM methods to different languages, as metaphorical constructions and common mappings can vary significantly across linguistic and cultural boundaries. The need for high-quality, large-scale annotated datasets covering diverse types of metaphors and languages remains a practical challenge for training and evaluating robust metaphor recognition systems. Finally, evaluating the quality of metaphor interpretation by LLMs is non-trivial, as it often requires human judgment and can be subjective. Developing objective and reliable evaluation metrics that capture the depth of understanding is an ongoing research problem. The systematic review on figurative language processing likely discusses these and other challenges in more detail, providing a broader perspective on the limitations of current LLMs in this area.\n\nAll considered, LLMs have set new state-of-art in metaphor detection, bringing accuracy up and providing human-readable explanations. This is a significant step for figurative language understanding. The integration of explicit metaphor theory into LLM reasoning is a prime example of combining old linguistic insights with new model capabilities. Such synergy could be a model for other tasks. Finally, we will discuss intent detection and aesthetic evaluation, the last two tasks in our survey, before moving to cross-task analysis and future directions.\n\n10 Comparative Analysis and Insights",
      "page_start": 30,
      "page_end": 31
    },
    {
      "section_name": "Similarities And Differences Among Subjective Language Tasks",
      "text": "The subjective language tasks discussed-sentiment analysis, emotion recognition, sarcasm detection, humor detection, stance detection, metaphor recognition, user intent detection, and aesthetics identification-share fundamental similarities, yet they also exhibit distinct characteristics that define their challenges and required LLM capabilities. A core similarity is their inherent subjectivity; these tasks involve interpreting language that reflects personal perspectives, feelings, opinions, or evaluations rather than objective facts. This means they are all highly context-dependent and often require understanding implicit meanings, cultural nuances, and speaker intent. For instance, sarcasm, humor, and metaphor all rely on a discrepancy between literal and intended meaning, which LLMs must infer. Similarly, sentiment, emotion, and stance are often conveyed indirectly. Consequently, all these tasks benefit from LLMs' ability to capture deep contextual understanding and semantic relationships.\n\nHowever, there are also significant differences. Granularity and scope of interpretation vary: sentiment analysis typically deals with broad polarity (positive/negative/neutral), while emotion recognition aims for more specific affective states (joy, anger, etc.). Stance detection focuses on a position towards a target, which can be distinct from general sentiment. Metaphor and sarcasm detection involve identifying specific figurative language constructs. Humor detection targets a particular communicative intent (to amuse). User intent detection is about identifying a goal or purpose, which may or may not be explicitly emotional or evaluative. Aesthetics identification deals with judgments of beauty or artistic merit, a highly abstract and culturally variable concept. The nature of the \"target\" also differs: stance detection is explicitly target-dependent (e.g., stance towards a policy), whereas sentiment or emotion might be more general or directed at an unspecified entity. The type of reasoning required can also vary; metaphor interpretation often involves analogical reasoning, sarcasm detection requires recognizing incongruity and often negative intent, while humor detection might involve understanding punchlines or absurdity. These differences necessitate specialized approaches or fine-tuning for each task, even when leveraging general-purpose LLMs.",
      "page_start": 32,
      "page_end": 32
    },
    {
      "section_name": "Towards Unified Subjective Language Modeling: Potential Of Multi-Task Llm",
      "text": "The shared characteristics among subjective language tasks, such as their reliance on context, implicit meaning, and nuanced interpretation, suggest a significant potential for unified subjective language modeling using multi-task LLMs. Instead of training separate models for sentiment analysis, emotion recognition, sarcasm detection, etc., a single, powerful LLM could be trained to perform all these tasks simultaneously or to share representations and knowledge across them. The underlying hypothesis is that understanding one aspect of subjectivity (e.g., emotion) can inform the understanding of others (e.g., sarcasm or humor). For example, recognizing that a statement conveys negative emotion might be a crucial cue for identifying sarcasm if the literal meaning is positive. A multi-task LLM could learn these inter-task relationships implicitly by being exposed to diverse subjective phenomena during training. This approach could lead to more robust and generalizable models, as knowledge acquired from one task with abundant data (e.g., sentiment analysis) could potentially benefit tasks with scarcer data (e.g., aesthetics identification).\n\nThe development of such unified models faces challenges, including the need for large-scale, multitask datasets where texts are annotated for multiple subjective attributes simultaneously. Designing effective multi-task learning architectures and training strategies that allow for positive knowledge transfer without negative interference (where learning one task harms another) is also critical. Furthermore, the diverse output spaces of these tasks (e.g., categorical labels for sentiment, free-text descriptions for aesthetics) require flexible model architectures. However, the potential benefits are substantial. A unified model could offer a more holistic understanding of subjective language, capturing the interplay between different facets of human expression. It could also be more efficient in terms of development and deployment compared to maintaining multiple specialized models. Research in this direction is actively exploring how to best leverage the capabilities of large foundational models for a broad spectrum of subjective understanding tasks, aiming for AI systems that can comprehend the richness and complexity of human subjectivity in a more integrated manner.\n\n10.3 Multi-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?\n\nThe debate between multi-task fusion (training a single model on multiple tasks) and single-task fine-tuning (fine-tuning a pre-trained LLM separately for each task) is central to developing effective subjective language understanding systems. Each approach has its advantages and disadvantages, and the optimal choice depends on circumstances, including data availability, task similarity, and computational resources. Single-task fine-tuning allows for specialization; the model can be optimized extensively for the nuances of a particular task, potentially leading to higher performance on that benchmark if sufficient task-specific data is available. This approach is straightforward to implement and is widely used. However, it can lead to a proliferation of models if many subjective tasks need to be handled, and it may not leverage the commonalities between related subjective phenomena.\n\nMulti-task fusion, on the other hand, aims to train a single model that can perform across a range of tasks. The advantage is knowledge transfer: learning patterns useful for one task (e.g., detecting negative sentiment) might help in another (e.g., detecting sarcasm, which often involves negative sentiment). This can be particularly beneficial for tasks with limited labeled data, as the model can leverage information from richer tasks. Multi-task learning can also lead to more generalizable and robust representations that capture broader aspects of subjectivity. However, multi-task fusion is more complex to design and train. Challenges include negative transfer (where learning one task interferes with another), imbalanced task difficulties or data sizes, and the need for careful weighting of task losses during training. The effectiveness of multi-task fusion often depends on the relatedness of the tasks; tasks that share underlying linguistic or cognitive mechanisms are more likely to benefit from joint training. Recent trends show a growing interest in exploring multi-task learning paradigms with LLMs, often by extending pre-trained models with shared encoders and task-specific heads, or by using prompts to guide the model towards different tasks. The ultimate goal is to find a balance that harnesses the power of shared learning while preserving task-specific performance.\n\n11 Challenges and Open Issues",
      "page_start": 31,
      "page_end": 31
    },
    {
      "section_name": "Technical Challenges",
      "text": "Despite the impressive capabilities of LLMs, several technical challenges persist in the domain of subjective language understanding. A primary challenge is modeling ambiguity and nuance. Subjective language is often inherently ambiguous, with meanings that can shift based on subtle contextual cues, speaker intent, or cultural background. LLMs, while adept at pattern recognition, can still struggle to capture these fine-grained distinctions, sometimes producing interpretations that are too literal or that miss the underlying subtlety. For example, distinguishing between sarcasm and genuine praise, or understanding a metaphor that relies on uncommon cultural knowledge, remains difficult. Handling implicit meaning is another significant hurdle. Much of subjective expression is not explicitly stated but rather implied through tone, figurative language, or shared understanding. LLMs need to go beyond surface-level semantics to infer these implicit meanings accurately. This requires not only vast amounts of training data but also sophisticated reasoning capabilities.\n\nThe reliability and bias in training data also pose major technical challenges. LLMs learn from the data they are trained on, and if this data contains biases (e.g., cultural, gender, or racial biases) or reflects subjective annotations with low inter-annotator agreement, these issues can be amplified and perpetuated by the model. This can lead to unfair, inaccurate, or stereotypical outputs when dealing with subjective content. Developing techniques for debiasing models and datasets, and for creating more reliable and diverse annotations, is crucial. Furthermore, the computational cost and resource intensiveness of training and deploying large LLMs limit their accessibility and practical application, especially for real-time systems or in resource-constrained environments. While parameter-efficient fine-tuning methods and model compression techniques offer some relief, achieving state-of-the-art performance often still requires substantial resources. Finally, the \"black box\" nature of many LLMs makes it difficult to interpret their reasoning processes, especially for complex subjective judgments. Improving the explainability and interpretability of LLMs is essential for building trust and for debugging models when they make errors in subjective understanding.",
      "page_start": 32,
      "page_end": 32
    },
    {
      "section_name": "Ethical And Societal Implications",
      "text": "The application of LLMs to subjective language understanding raises significant ethical and societal implications that must be carefully considered. One major concern is the perpetuation and amplification of biases. LLMs trained on large, unfiltered datasets from the internet can learn and replicate societal biases related to gender, race, ethnicity, religion, and other sensitive attributes. When these models are used for tasks like sentiment analysis, emotion recognition, or content moderation, they may produce biased or unfair outcomes, leading to discrimination or the marginalization of certain groups. For example, a sentiment analysis model might misinterpret expressions from a particular dialect or cultural group due to a lack of representation in its training data. Privacy concerns are also paramount, especially when LLMs are used to analyze personal communications or expressions of emotion. The data used to train these models, or the data they process in deployment, might contain sensitive personal information. Ensuring that this data is handled securely and ethically, with appropriate consent and anonymization, is critical.\n\nAnother issue is the potential for manipulation and misuse. LLMs that can understand and generate subjective language could be used to create persuasive or manipulative content, such as misinformation, propaganda, or targeted scams. The ability to mimic human-like empathy or opinion could be exploited to deceive users or influence public opinion in unethical ways. The impact on human communication and creativity is also a concern. Over-reliance on AI for tasks like writing, artistic judgment, or emotional support could potentially diminish human skills in these areas or lead to a homogenization of expression. Furthermore, the deployment of subjective language understanding systems in areas like hiring, loan applications, or criminal justice raises serious questions about fairness, accountability, and due process, especially if the decision-making processes of these systems are not transparent or are found to be biased. Addressing these ethical and societal challenges requires a multi-faceted approach involving researchers, policymakers, and industry stakeholders to develop robust ethical guidelines, fairness-aware algorithms, and appropriate regulatory frameworks.",
      "page_start": 33,
      "page_end": 33
    },
    {
      "section_name": "Future Directions",
      "text": "The field of subjective language understanding with LLMs is rapidly evolving, and several promising future directions are emerging. One key direction is the development of more robust and nuanced LLMs that can better handle ambiguity, implicit meaning, and cultural context. This includes advancing models' reasoning capabilities, perhaps by integrating symbolic reasoning or commonsense knowledge bases, to enable deeper understanding beyond surface-level patterns. Research into multimodal subjective understanding will also continue to grow, as human communication is inherently multimodal (text, speech, vision). LLMs that can effectively integrate information from multiple modalities will be better equipped to interpret complex subjective expressions, such as sarcasm in a video or the emotional tone of an audiovisual narrative. Another important direction is improving the fairness, transparency, and interpretability of LLMs. This involves developing techniques for detecting and mitigating biases in models and datasets, as well as creating methods to explain why an LLM made a particular subjective judgment, which is crucial for building trust and accountability.\n\nThe exploration of personalized and adaptive subjective language models is a promising avenue. Future LLMs might adapt their understanding of subjectivity to individual users' communication styles, preferences, and cultural backgrounds, leading to more empathetic and effective interactions. There is a need for better evaluation benchmarks and metrics designed for subjective tasks. Current benchmarks focus on accuracy, which may not fully capture a model's ability to understand subtle nuances or handle diverse perspectives. Developing holistic evaluation frameworks that consider fairness, robustness, and human-aligned judgment will be crucial. Finally, the ethical development and deployment of subjective language understanding systems will remain a critical focus. This includes establishing clear ethical guidelines, promoting responsible AI practices, and fostering interdisciplinary collaboration to ensure that these powerful technologies are used for beneficial and equitable purposes. The integration of insights from linguistics, cognitive science, psychology, and social sciences will continue to be vital for advancing the field in a human-centric manner.\n\n12 Conclusion",
      "page_start": 33,
      "page_end": 34
    },
    {
      "section_name": "Summary Of Findings",
      "text": "This survey has provided a comprehensive overview of the state of subjective language understanding with Large Language Models (LLMs), covering key tasks such as sentiment analysis, emotion recognition, sarcasm detection, humor detection, stance detection, metaphor recognition, user intent detection, and aesthetics identification. We have seen that LLMs, with their capabilities in contextual understanding and semantic representation, have advanced the performance on these tasks compared to traditional methods. The evolution of language models, particularly the advent of Transformerbased architectures and large-scale pre-training, has been instrumental in this progress. Various approaches, including prompt-based learning, supervised fine-tuning (SFT), and reasoning-based methods, are being employed to adapt LLMs to the nuances of subjective language. Multi-model and multimodal LLMs are also emerging as powerful tools for handling the complexities of subjective expression, especially when it involves multiple sources of information.\n\nHowever, the survey also highlights that challenges remain. The inherent subjectivity, ambiguity, and context-dependency of language pose difficulties for LLMs. Tasks like sarcasm detection, metaphor interpretation, and aesthetics identification, which require understanding of implicit meaning and cultural nuances, are particularly challenging. Issues such as bias in training data, the computational cost of LLMs, and the \"black box\" nature of their decision-making processes need to be addressed. The comparative analysis revealed both similarities and differences among subjective tasks, pointing towards the potential for unified modeling approaches but also the need for task-specific considerations. Ethical and societal implications, including privacy concerns and the potential for misuse, underscore the importance of responsible development and deployment of these technologies.\n\n12.2 Subjective Language Understanding as a Key Direction for Future LLM Research Subjective language understanding stands as a critical and challenging frontier for future LLM research. As LLMs become increasingly integrated into human-facing applications, their ability to accurately perceive, interpret, and respond to the rich tapestry of human emotions, opinions, intentions, and figurative expressions becomes paramount for creating truly intelligent and empathetic AI systems. The nuances of subjective language-sarcasm, humor, metaphor, aesthetic judgment-are fundamental to human communication and social interaction. Mastering these aspects will enable LLMs to move beyond mere information processing to engage in more natural, meaningful, and contextually aware dialogues. Future research in this area will not only push the boundaries of NLP but also contribute to a deeper understanding of human cognition and language itself. The development of LLMs that can robustly handle subjectivity will unlock new possibilities in areas such as personalized education, mental health support, creative arts, and cross-cultural communication, making AI a more valuable and trustworthy partner in various aspects of human life.\n\nThe challenges inherent in subjective language understanding, such as ambiguity, context-dependency, and cultural variability, necessitate innovation in LLM architectures, training methodologies, and evaluation techniques. Future research should focus on enhancing LLMs' reasoning capabilities, ability to integrate commonsense and world knowledge, and capacity to learn from limited or noisy data. Exploring multimodal approaches that combine text with other sensory inputs will be crucial for a holistic understanding of subjective expression. Furthermore, addressing issues of bias, fairness, and interpretability will be essential for building trustworthy and ethically sound subjective language understanding systems. The insights gained from tackling subjective language will likely also benefit other areas of AI, leading to more robust and human-like machine intelligence overall.",
      "page_start": 34,
      "page_end": 34
    },
    {
      "section_name": "Calling For A Unified Research Framework And Evaluation Benchmarks",
      "text": "To systematically advance the field of subjective language understanding with LLMs, there is a pressing need for a unified research framework and standardized evaluation benchmarks. Currently, research efforts are often fragmented, with different studies using varied datasets, evaluation metrics, and experimental setups, making it difficult to compare results and track progress effectively. A unified framework would provide common definitions, taxonomies, and methodological guidelines for studying subjective language. This would facilitate collaboration, reproducibility, and the sharing of insights across different research groups and tasks. Such a framework should encompass the diverse aspects of subjectivity, from affective states and opinions to figurative language and aesthetic judgments, acknowledging their interconnections while also respecting their unique characteristics.\n\nCrucially, the development of comprehensive and challenging evaluation benchmarks is essential. These benchmarks should go beyond simple accuracy metrics and aim to assess LLMs' abilities to handle nuance, ambiguity, context-dependency, and cultural diversity. They should include datasets that represent a wide range of subjective phenomena, languages, and domains, including carefully curated adversarial examples to test model robustness. Human evaluation, involving diverse annotators, should be an integral part of these benchmarks to provide a more holistic assessment of model performance aligned with human judgment. Furthermore, benchmarks should be designed to probe not only the \"what\" (e.g., correct classification) but also the \"why\" (e.g., model's reasoning process, where feasible). By establishing such a unified framework and robust benchmarks, the research community can accelerate progress towards LLMs that can truly understand and engage with the complexities of human subjective experience.",
      "page_start": 34,
      "page_end": 35
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: provides a conceptual taxonomy of these tasks, which we describe here. Affective tasks",
      "page": 3
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Abstract": "Subjective language understanding refers to a broad set of natural language process-"
        },
        {
          "Abstract": "ing tasks where the goal is to interpret or generate content that conveys personal"
        },
        {
          "Abstract": "feelings, opinions, or figurative meanings rather than objective facts. With the"
        },
        {
          "Abstract": "advent of large language models (LLMs) such as ChatGPT, LLaMA, and others,"
        },
        {
          "Abstract": "there has been a paradigm shift\nin how we approach these inherently nuanced"
        },
        {
          "Abstract": "tasks.\nIn this survey, we provide a comprehensive review of recent advances in"
        },
        {
          "Abstract": "applying LLMs to subjective language tasks, including sentiment analysis, emotion"
        },
        {
          "Abstract": "recognition, sarcasm detection, humor understanding, stance detection, metaphor"
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "interpretation, intent detection, and aesthetics assessment. We begin by clarifying": "the definition of subjective language from linguistic and cognitive perspectives,"
        },
        {
          "interpretation, intent detection, and aesthetics assessment. We begin by clarifying": "and we outline the unique challenges posed by subjective language (e.g. ambiguity,"
        },
        {
          "interpretation, intent detection, and aesthetics assessment. We begin by clarifying": "figurativeness, context dependence). We then survey the evolution of LLM archi-"
        },
        {
          "interpretation, intent detection, and aesthetics assessment. We begin by clarifying": "tectures and techniques that particularly benefit subjectivity tasks, highlighting why"
        },
        {
          "interpretation, intent detection, and aesthetics assessment. We begin by clarifying": "LLMs are well-suited to model subtle human-like judgments. For each of the eight"
        },
        {
          "interpretation, intent detection, and aesthetics assessment. We begin by clarifying": "tasks, we summarize task definitions, key datasets, state-of-the-art LLM-based"
        },
        {
          "interpretation, intent detection, and aesthetics assessment. We begin by clarifying": "methods, and remaining challenges. We provide comparative insights, discussing"
        },
        {
          "interpretation, intent detection, and aesthetics assessment. We begin by clarifying": "commonalities and differences among tasks and how multi-task LLM approaches"
        },
        {
          "interpretation, intent detection, and aesthetics assessment. We begin by clarifying": "might yield unified models of subjectivity. Finally, we identify open issues such as"
        },
        {
          "interpretation, intent detection, and aesthetics assessment. We begin by clarifying": "data limitations, model bias, and ethical considerations, and suggest future research"
        },
        {
          "interpretation, intent detection, and aesthetics assessment. We begin by clarifying": "directions. We hope this survey will serve as a valuable resource for researchers"
        },
        {
          "interpretation, intent detection, and aesthetics assessment. We begin by clarifying": "and practitioners interested in the intersection of affective computing, figurative"
        },
        {
          "interpretation, intent detection, and aesthetics assessment. We begin by clarifying": "language processing, and large-scale language models."
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "1\nIntroduction": "1.1\nBackground and Motivation"
        },
        {
          "1\nIntroduction": "Human communication is rich with subjective language – expressions of sentiment, emotion,"
        },
        {
          "1\nIntroduction": "opinion, humor, sarcasm, metaphor, and other non-literal or evaluative meanings. Understanding"
        },
        {
          "1\nIntroduction": "such language is crucial for AI systems that interact with humans or analyze human-generated text."
        },
        {
          "1\nIntroduction": "Traditional NLP approaches to these tasks often relied on task-specific models and carefully crafted"
        },
        {
          "1\nIntroduction": "features or annotated data. For example, sentiment analysis has long been tackled with machine"
        },
        {
          "1\nIntroduction": "learning classifiers or pre-trained language models fine-tuned on labeled sentiment corpora, and"
        },
        {
          "1\nIntroduction": "sarcasm detection research evolved from manual pattern-based methods to neural models over the past"
        },
        {
          "1\nIntroduction": "decade. However, these narrow models typically handled each subjective phenomenon in isolation"
        },
        {
          "1\nIntroduction": "and lacked generalization: a model trained for sentiment would not handle humor, and vice versa."
        },
        {
          "1\nIntroduction": "The rise of\nlarge language models (LLMs) has brought new opportunities to address subjective"
        },
        {
          "1\nIntroduction": "language understanding in a more unified and general way. Modern LLMs such as OpenAI’s GPT-4,"
        },
        {
          "1\nIntroduction": "Google’s PaLM, Meta’s LLaMA, etc., have demonstrated remarkable capabilities in natural language"
        },
        {
          "1\nIntroduction": "understanding and generation across a wide range of tasks, via techniques like zero-shot/few-shot"
        },
        {
          "1\nIntroduction": "prompting and instruction tuning. Intuitively, many subjective language tasks might benefit from these"
        },
        {
          "1\nIntroduction": "capabilities: for instance, an LLM might recognize subtle sarcastic cues by virtue of having seen many"
        },
        {
          "1\nIntroduction": "examples in its training data, or it might generate more empathetic responses by leveraging learned"
        },
        {
          "1\nIntroduction": "patterns of emotional expression. Early successes with LLMs (e.g., GPT-3) on tasks like zero-shot"
        },
        {
          "1\nIntroduction": "sentiment analysis suggested that they internalize a great deal of subjective semantic knowledge. As"
        },
        {
          "1\nIntroduction": "a result, the community has shifted toward exploring how prompting or fine-tuning LLMs can solve"
        },
        {
          "1\nIntroduction": "affective and subjective NLP tasks that were previously considered very challenging."
        },
        {
          "1\nIntroduction": "Despite this optimism, subjective language understanding remains unsolved. These tasks often require"
        },
        {
          "1\nIntroduction": "nuanced contextual and commonsense reasoning, understanding of tone and pragmatics, and even a"
        },
        {
          "1\nIntroduction": "theory of mind. There are growing research efforts to evaluate how well LLMs truly “understand”"
        },
        {
          "1\nIntroduction": "emotions, humor, or figurative meanings, and results have been mixed. For example, while LLMs"
        },
        {
          "1\nIntroduction": "have made progress in sentiment analysis and emotion recognition, they still struggle with sarcasm"
        },
        {
          "1\nIntroduction": "and humor. In one study, GPT-4 was found to perform roughly at a human level on sentiment, emotion"
        },
        {
          "1\nIntroduction": "intensity, and political stance classification, but sarcasm detection remained a stumbling block. Such"
        },
        {
          "1\nIntroduction": "findings motivate a closer look at each type of subjective task to identify what unique challenges it"
        },
        {
          "1\nIntroduction": "poses and the progress current LLMs have made toward meeting those challenges."
        },
        {
          "1\nIntroduction": "1.2\nWhat Is Subjective Language"
        },
        {
          "1\nIntroduction": "Subjective language can be defined as any utterance or text whose meaning or interpretation depends"
        },
        {
          "1\nIntroduction": "on personal perspectives, feelings, or opinions, rather than objective facts. From a linguistic perspec-"
        },
        {
          "1\nIntroduction": "tive, subjectivity in language is often indicated by the presence of opinionated words, emotion-laden"
        },
        {
          "1\nIntroduction": "expressions, first-person viewpoints, or figurative devices. For example, the sentence “The movie was"
        },
        {
          "1\nIntroduction": "an absolute masterpiece!” is subjective because it expresses the speaker’s positive evaluation (it’s not"
        },
        {
          "1\nIntroduction": "a verifiable fact, but an opinion). Similarly, “I feel upset about what happened” is subjective, revealing"
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "can be marked in text (e.g., through certain adjectives, intensifiers, or discourse structures), and how"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "they differ from objective statements of fact. A classic NLP problem formulation is subjectivity"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "classification: determining if a given sentence is subjective or objective. This can be seen as a coarse"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "form of subjective language understanding."
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "From a cognitive perspective, subjective language relates to the speaker’s or writer’s internal state"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "– their emotions, attitudes, beliefs, or intentions. Cognitive and psychological studies of language"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "indicate that understanding subjectivity often requires theory of mind (inferring the speaker’s intent"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "or\nfeelings) and empathy.\nFor\ninstance, sarcasm and irony are quintessential subjective uses of"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "language:\nthe literal content diverges from the intended meaning, and the listener must\ninfer the"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "speaker’s true attitude (often the opposite of the literal words). Similarly, humor involves cognitive"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "processes like surprise,\nincongruity, and shared knowledge between the interlocutors. Affective"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "science provides insights into how humans express and perceive emotions through language (e.g."
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "certain metaphors like “heartbroken” to indicate sadness). Thus, subjective language understanding"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "is inherently interdisciplinary, bridging NLP with cognitive psychology."
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "In this survey, subjective language is an umbrella term encompassing affective language (sentiments,"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "emotions, and attitudes) and figurative or non-literal language (sarcasm, humor, metaphor, etc.), as"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "well as other subjectivity phenomena like personal intent or aesthetic preference. All these facets"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "share the quality that purely literal or surface-level analysis often fails – one must grasp the underlying"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "subjective meaning. We will clarify the scope of tasks covered in the next subsection."
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "1.3\nThe Scope of The Paper"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "The Scope of this Paper includes eight\ninterrelated tasks that we categorize as core to Subjective"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "Language Understanding: (1) Sentiment Analysis, (2) Emotion Recognition, (3) Sarcasm Detection,"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "(4) Humor Detection, (5) Stance Detection, (6) Metaphor Recognition, (7) Intent Detection, and (8)"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "Aesthetics Identification. These tasks span a range of applications and research communities, from"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "traditional sentiment analysis in product reviews, to detecting humorous or sarcastic content on social"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "media, to identifying a user’s intent in dialogue systems, to evaluating the aesthetic quality of creative"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "content. By no means is this list exhaustive of all subjective phenomena in language (for example,"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "bias detection, hate speech/offensive tone detection, and moral sentiment analysis are also subjective"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "tasks, but we focus on the eight listed areas as they are most prominently addressed with LLM-era"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "techniques in our surveyed literature). We aim to provide a unified treatment, highlighting common"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "challenges and techniques, while also diving into task-specific details."
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "Figure 1 provides a conceptual taxonomy of these tasks, which we describe here. Affective tasks"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "include sentiment analysis and emotion recognition:\nthese deal with identifying feelings or attitudes"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "expressed in text. Sentiment analysis typically focuses on polarity (positive/negative/neutral sentiment"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "towards a target), whereas emotion recognition assigns more fine-grained emotion categories (happy,"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "sad, angry, etc.) or even emotion intensity levels. Figurative language tasks cover sarcasm, humor, and"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "metaphors. They require understanding non-literal meanings and often involve cultural or contextual"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "knowledge – sarcasm and humor can overlap (sarcasm is often a bitter form of humor), and metaphors"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "are imaginative expressions mapping one concept onto another. Stance detection is about inferring"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "the position (pro/con/neutral) of the author with respect to a specific topic or claim – it’s subjective in"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "that it reveals opinion, though often about external issues (politics, etc.).\nIntent detection (in user"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "conversations or commands) is somewhat different but still subjective:\nit\ninvolves understanding"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "the underlying goal or intention behind an utterance (for example, whether a question is actually"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "a request, or what the user wants to achieve). Finally, aesthetics identification is an emerging area"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "where the task is to evaluate the aesthetic or subjective quality of content – often images (image"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "aesthetics rating) but also text style. It intersects with sentiment and with multi-modal understanding."
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "Despite differences, all these tasks are unified by requiring the model to go beyond literal meaning"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "and often to incorporate world knowledge and cultural context. Our survey specifically investigates"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "how LLMs have been applied to each task, and what advantages or limitations they bring."
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "1.4\nDistinction from Existing LLM Surveys"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "It\nis important\nto clarify how our survey differs from prior surveys, especially those focusing on"
        },
        {
          "an emotional state. Linguists such as Banfield and Wiebe have studied how subjective expressions": "LLMs or affective computing. One closely related work is [229]. Their survey centers on how LLMs"
        }
      ],
      "page": 3
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "can be used for affective computing tasks, mainly sentiment and emotion analysis and affective text": "In contrast, our survey covers a broader notion of subjective language, not"
        },
        {
          "can be used for affective computing tasks, mainly sentiment and emotion analysis and affective text": "emotions but also including stance, figurative language (sarcasm, humor, metaphor), user intent, and"
        },
        {
          "can be used for affective computing tasks, mainly sentiment and emotion analysis and affective text": "aesthetic judgement. Thus, we address a wider range of tasks under the umbrella of subjectivity."
        },
        {
          "can be used for affective computing tasks, mainly sentiment and emotion analysis and affective text": ""
        },
        {
          "can be used for affective computing tasks, mainly sentiment and emotion analysis and affective text": "subjective language. We also include tasks like metaphor and humor which might not be treated"
        },
        {
          "can be used for affective computing tasks, mainly sentiment and emotion analysis and affective text": ""
        },
        {
          "can be used for affective computing tasks, mainly sentiment and emotion analysis and affective text": "Moreover, existing general LLM surveys mention these tasks only briefly, if at all. To our knowledge,"
        },
        {
          "can be used for affective computing tasks, mainly sentiment and emotion analysis and affective text": "this is the first comprehensive survey specifically targeting subjective language understanding in the"
        },
        {
          "can be used for affective computing tasks, mainly sentiment and emotion analysis and affective text": "LLM era. We synthesize results from over 200 recent papers and highlight trends such as prompt"
        },
        {
          "can be used for affective computing tasks, mainly sentiment and emotion analysis and affective text": "engineering for subjectivity, multi-task learning of subjective phenomena, and integrating domain"
        },
        {
          "can be used for affective computing tasks, mainly sentiment and emotion analysis and affective text": "knowledge into LLMs. We also draw on benchmarks and studies evaluating LLMs on these tasks."
        },
        {
          "can be used for affective computing tasks, mainly sentiment and emotion analysis and affective text": "Contribution and Structure of The Paper"
        },
        {
          "can be used for affective computing tasks, mainly sentiment and emotion analysis and affective text": ""
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Contribution and Structure of The Paper": "The contributions of this survey are as follows:"
        },
        {
          "Contribution and Structure of The Paper": "• We define and motivate subjective language understanding as a field, clarifying its scope"
        },
        {
          "Contribution and Structure of The Paper": "and importance in NLP. We connect linguistic definitions of subjectivity with the challenges"
        },
        {
          "Contribution and Structure of The Paper": "faced by AI, providing a conceptual foundation for readers (Section 2)."
        },
        {
          "Contribution and Structure of The Paper": "• We provide an overview of LLMs (Section 3) with a focus on their relevance to subjective"
        },
        {
          "Contribution and Structure of The Paper": "tasks. This includes a brief history of language model evolution leading to current state-of-"
        },
        {
          "Contribution and Structure of The Paper": "the-art models, and a discussion of why the properties of LLMs (such as in-context learning"
        },
        {
          "Contribution and Structure of The Paper": "and knowledge integration) make them promising for subjective language understanding."
        },
        {
          "Contribution and Structure of The Paper": "• For each of the eight\ntasks (Sections 4 - 11), we present a task definition, key datasets,"
        },
        {
          "Contribution and Structure of The Paper": "LLM-based methods, and challenges. We thoroughly review literature in each area:\nfor"
        },
        {
          "Contribution and Structure of The Paper": "instance, how LLMs have been fine-tuned or prompted for sentiment analysis, how they’ve"
        },
        {
          "Contribution and Structure of The Paper": "been evaluated on humor and sarcasm, what novel techniques have been proposed, etc. We"
        },
        {
          "Contribution and Structure of The Paper": "highlight representative papers and methods, and we analyze their strengths and weaknesses"
        },
        {
          "Contribution and Structure of The Paper": "in context. Wherever applicable, we cite quantitative results from papers or benchmarks to"
        },
        {
          "Contribution and Structure of The Paper": "give a sense of the state-of-the-art performance."
        },
        {
          "Contribution and Structure of The Paper": "• We perform a comparative analysis in Section 12, discussing commonalities and differences"
        },
        {
          "Contribution and Structure of The Paper": "among the tasks. We examine, for example, how sarcasm detection and humor detection"
        },
        {
          "Contribution and Structure of The Paper": "overlap in needing cultural knowledge, or how sentiment and emotion recognition differ"
        },
        {
          "Contribution and Structure of The Paper": "in granularity but share methodical approaches. We also discuss the potential of unified"
        },
        {
          "Contribution and Structure of The Paper": "models or multi-task training to handle multiple subjective tasks together, referencing any"
        },
        {
          "Contribution and Structure of The Paper": "multi-task studies we found. We compare single-task fine-tuning versus multi-task (or"
        },
        {
          "Contribution and Structure of The Paper": "instruction-based) approaches in the context of subjectivity: which yields better performance"
        },
        {
          "Contribution and Structure of The Paper": "or efficiency, based on recent experiments."
        },
        {
          "Contribution and Structure of The Paper": "• We outline challenges and open issues (Section 13) that emerged from the literature review."
        },
        {
          "Contribution and Structure of The Paper": "These include technical challenges (e.g., handling context and pragmatics, avoiding LLM"
        },
        {
          "Contribution and Structure of The Paper": "hallucinations in subjective inference, data scarcity for\nless common tasks), as well as"
        },
        {
          "Contribution and Structure of The Paper": "ethical considerations (e.g., the risk of bias when an AI system judges what is “beautiful” or"
        },
        {
          "Contribution and Structure of The Paper": "interprets user emotion, and privacy issues in emotion/intent detection). We also discuss"
        },
        {
          "Contribution and Structure of The Paper": "how subjective language understanding by AI can impact society (for instance, the use of"
        },
        {
          "Contribution and Structure of The Paper": "stance detection in monitoring social media could raise fairness concerns)."
        },
        {
          "Contribution and Structure of The Paper": "• We conclude (Section 14) by summarizing key findings – for example, which tasks LLMs"
        },
        {
          "Contribution and Structure of The Paper": "have significantly advanced and which remain very challenging – and by calling for a unified"
        },
        {
          "Contribution and Structure of The Paper": "research framework and evaluation for subjective language understanding. We emphasize"
        },
        {
          "Contribution and Structure of The Paper": "that as LLMs become central to NLP, it’s crucial to develop standardized benchmarks that"
        },
        {
          "Contribution and Structure of The Paper": "cover the spectrum of subjective tasks, and to encourage research that bridges these areas"
        },
        {
          "Contribution and Structure of The Paper": "rather than treating each in isolation. Ultimately, truly human-like language understanding"
        },
        {
          "Contribution and Structure of The Paper": "by AI will require competence in all\nthese subjective dimensions. We hope our survey"
        },
        {
          "Contribution and Structure of The Paper": "accelerates progress toward that goal."
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "LLM foundations (Section 3) and then diving into each task."
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "2\nDefining Subjective Language Understanding"
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "2.1\nDefinitions of Subjectivity: Linguistic and Cognitive Perspectives"
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "Subjectivity has been a topic of interest\nin both linguistics and cognitive science, each providing"
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "a complementary perspective. From the linguistic perspective, subjectivity in language is about"
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "the expression of personal stance. Linguist Janet Besnier noted that subjectivity is “the linguistic"
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "encoding of the speaker’s perspective” – this can manifest as opinions, evaluations, or other attitude"
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "markers in text. Classic work by Wiebe et al.\n(2004) in computational\nlinguistics distinguished"
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "subjective sentences (those containing opinions, sentiments, or feelings) from objective sentences"
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "(factual descriptions). Linguistically, clues to subjectivity include: opinion adjectives (e.g. “beautiful,”"
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "“terrible”), modal verbs and hedges (which indicate uncertainty or perspective, e.g. “I think,” “proba-"
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "bly”), first-person references (“I believe...”), and intensifiers (“very happy,” “extremely costly”). Even"
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "punctuation or tone words (exclamation marks, emotive interjections like “ugh”) signal subjectivity."
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "These linguistic markers have been used historically to build subjectivity lexicons and classifiers."
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "For example, a sentence like “In my opinion, this is a huge mistake!” is clearly subjective due to the"
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "phrase “in my opinion” and the evaluative term “huge mistake.” On the other hand, “The water boils"
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "at 100°C.” is objective. However, there are many gray areas and subtle cases; a sentence can convey a"
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "subjective attitude without explicit markers, especially if context is required."
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "From the cognitive perspective, subjectivity ties into how humans process language and infer others’"
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "mental states. Cognitive scientists consider Theory of Mind (ToM) – the ability to attribute thoughts,"
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "intentions, or emotions to others – as crucial for understanding subjective aspects of communication."
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "When someone says “Sure, I just love getting stuck in traffic for hours,” an listener with theory of mind"
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "will recognize the likely sarcastic intent (the speaker’s true attitude is the opposite of the literal words)."
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "Thus, cognitively, subjective language often demands inference beyond the literal\ntext,\ninvolving"
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "knowledge of speaker intentions, cultural context, and sometimes shared experiences. Emotion"
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "understanding is another cognitive aspect: humans have an innate ability to read emotional cues in"
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "language (certain words or even the rhythm of text can imply an emotional state). Cognitive and"
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "social psychology also discuss how people use language to perform actions. For instance, being polite"
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "or rude, being humorous or serious. These aspects highlight that subjective language understanding"
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "is not just a textual analysis problem, but an exercise in modeling human-like interpretations."
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "In summary,\nlinguistically we can describe subjectivity through observable markers in language,"
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "while cognitively we explain subjectivity by the mental processes a listener/reader uses to interpret"
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "those utterances. An effective AI system must bridge both: detect the markers and patterns, and apply"
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "reasoning to interpret them correctly."
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "2.2\nKey Characteristics of Subjective Language"
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "What makes subjective language particularly challenging for computational models? We outline a"
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "few key characteristics:"
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "Ambiguity and Subtlety\nSubjective expressions are often ambiguous. The same phrase can have"
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "different meanings depending on context or\ntone.\nFor example, “Yeah,\nright.” could be sincere"
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "agreement or a sarcastic dismissal, depending on context and perhaps the speaker’s intonation."
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "Subjective language relies heavily on context (both linguistic context and real-world context). Small"
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "cues can flip the interpretation. This subtlety is why tasks like sarcasm detection are hard – there is"
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "no single keyword that always signals sarcasm."
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "Figurative and Non-literal meaning\nMuch of subjective language is non-literal. Metaphors,"
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "idioms, and jokes involve meaning that cannot be obtained by straightforward dictionary lookup. For"
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "instance, “kick the bucket” meaning “to die” or “spill the tea” meaning “to gossip” are idiomatic and"
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "subjective. Similarly, metaphors like “a rollercoaster of emotions” convey subjective experience via"
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "analogy. LLMs have shown some ability to interpret idioms and metaphors, which is a positive sign."
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "But generating or identifying non-literal language remains challenging. The non-literal nature often"
        },
        {
          "subjective language understanding and present a taxonomy of tasks (Section 2), before discussing": "overlaps with humor and sarcasm."
        }
      ],
      "page": 5
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "commonsense or cultural knowledge. A joke might\nrely on a cultural\nreference; a sentimental"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "statement might assume knowledge of what’s considered positive or negative in a domain. Stance"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "detection requires knowing the topic discussed. For example, “We need another Einstein in our time.”"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "– to understand the stance, one needs to know Einstein = symbol of genius, implying we lack genius"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "now. LLMs have a lot of world knowledge, giving them an edge in subjective tasks compared to"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "earlier models. However, knowledge can be a double-edged sword if not properly constrained – e.g.,"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "an LLM might hallucinate facts to justify an emotional inference."
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "Highly Subjective Evaluation\nSubjective tasks often lack a single “ground truth” among humans."
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "This is reflected in inter-annotator disagreement for datasets. Emotion or sentiment labels can vary"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "between annotators. Humor is famously subjective: one person’s joke might fall flat for another."
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "Aesthetic judgments differ widely. This characteristic means models might reflect one plausible"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "interpretation even if it doesn’t match a gold label. It complicates both training and evaluation. Recent"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "works have used distributional evaluation or multiple human ratings to mitigate this, and LLMs might"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "output a probability or score that correlates with degree of human agreement."
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "Influence of Personal and Societal Biases\nSubjective language ties to personal perspective, which"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "can reflect biases. Models learning from subjective data risk absorbing biases (e.g., associating certain"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "sentiments with demographic groups, or having skewed humor that might be offensive). We highlight"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "this because it’s both a characteristic and an ethical challenge: understanding subjective language"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "requires recognizing whose perspective is reflected (for instance, the stance in a tweet may depend on"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "the tweeter’s political alignment). LLMs need mechanisms to handle this – either by being neutral or"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "not amplifying harmful biases. This is discussed more in Section 13 on ethical implications."
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "These characteristics show why subjective language understanding is a tough problem for AI and why"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "success here is a good proxy for genuine natural language “understanding,” as it goes beyond surface"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "text. Next, we classify the tasks under subjective language understanding in a unified taxonomy."
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "2.3\nA Unified Taxonomy of Subjective Tasks"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "We identified 8 key tasks as the focus. Here, we briefly define each and position it in our taxonomy:"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "Sentiment Analysis\nDetermine the sentiment polarity expressed in a given text, often categorized as"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "positive, negative, or neutral. Sometimes “sentiment analysis” also includes aspect-based sentiment"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "analysis (polarity toward specific aspects of an entity) and intensity (strength of sentiment).\nIt"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "traditionally answers questions like, “Is this product review positive or negative?” or “How does"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "this tweet’s author\nfeel about\ntopic X?”.\nIn our\ntaxonomy, sentiment analysis is a fundamental"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "subjective task concerning evaluative attitude. It is usually considered “simpler” than full emotion"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "recognition because it deals with broad valence (good/bad) rather than specific emotions. However, it"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "is ubiquitous in industry (e.g., opinion mining) and is a cornerstone of affective NLP."
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "Emotion Recognition\nIdentify the emotion(s) expressed in a text. This could be a classification into"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "categories (joy, sadness, anger, fear, etc.) or a regression in an emotional dimension (such as valence,"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "arousal). Emotion recognition can be seen as richer labeling than sentiment: “I am furious about"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "the delay” has negative sentiment, but more specifically the emotion is anger. Emotion recognition"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "might involve multiple labels if more than one emotion is present. We also include related tasks like"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "emotion cause detection under this umbrella, although the main focus is classification of emotion"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "from text. This lies in the affective branch of our taxonomy, alongside sentiment."
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "Sarcasm Detection\nDetermine if a given text\nis sarcastic or not. Sarcasm is usually a form of"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "verbal irony where the intended meaning is opposite to the literal wording, often to mock or convey"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "contempt. For instance, “Oh, great, another Monday morning meeting.\nI’m so excited.” is likely"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "sarcastic. This task is binary (sarcastic vs not), though some research considers degrees of sarcasm"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "or types of sarcastic expression. Sarcasm detection is a prototypical figurative language task in our"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "taxonomy, requiring high-level pragmatic inference.\nIt’s notoriously hard because it depends on"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "subtle cues and sometimes knowledge of the speaker’s personality or context. We include irony"
        },
        {
          "Presence of Implicit Context or Knowledge\nUnderstanding subjective content often requires": "detection here as well, as computationally the two overlap a lot."
        }
      ],
      "page": 6
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "it\nis). Humor detection overlaps with sarcasm in that both involve non-literal cues and surprise,"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "but humor is broader – not all humor is sarcastic; it could be puns, absurdity, etc. This task might"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "be binary (humorous vs not) or involve scoring jokes by funniness.\nIt’s subjective because humor"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "reception varies across audiences. It sits with sarcasm under figurative language understanding. An"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "example: “I told my computer I needed a break, and now it won’t stop sending me KitKat ads.” A"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "model should detect this is a joke (wordplay on “break”). Humor understanding might also involve"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "explaining the joke, but our focus is mainly on detection/classification and understanding."
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "Stance Detection\nGiven a text and a specific target or claim, determine whether the author’s stance"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "is in favor, against, or neutral toward the target. For example, in a debate forum post about climate"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "change, does the author support or oppose the existence of human-induced climate change? Stance"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "is similar to sentiment, but specifically anchored to a target proposition and not necessarily about"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "personal feelings – one can have a stance on an issue without an emotional tone. Still, it’s subjective"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "as it reflects opinion. Stance detection can be closed-target or open-target. This task is important"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "in analyzing social media, fake news, and online conversations.\nIn our taxonomy it\nis somewhat"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "between affective and opinion tasks – we categorize it under subjective opinion analysis."
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "Metaphor Recognition\nDetermine which words or phrases in a text are used metaphorically (as"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "opposed to literally), or more generally identify and interpret metaphors. For example, in “After the"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "argument, a wave of anger washed over him,” the phrase “wave of anger” is metaphorical. Metaphor"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "recognition can be a token-level sequence labeling task (label each word as literal or metaphoric)"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "or a classification of a phrase/sentence as containing metaphor.\nIt’s a figurative language task."
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "Interpretation of metaphor is a related challenge – e.g., GPT-4 has shown an ability to interpret novel"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "metaphors by providing explanations. In our scope, we primarily consider recognition. Metaphors"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "are subjectively used to convey concepts in a more vivid way, often tied to creativity and cognition."
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "Intent Detection\nIntent detection involves classifying a user’s utterance according to its underlying"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "intent. It’s a key component in task-oriented dialogue systems. Although this seems more “semantic”"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "than “subjective,” we include it because recognizing user intent\nis related to interpreting implicit"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "meaning in their request – essentially a pragmatic understanding task. For instance, the user query"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "“I’m hungry” has the intent FindRestaurant implicitly. Or in open-ended conversation, “It’s cold here”"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "could be an indirect intent for the thermostat to be turned up. Intent detection also includes detecting"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "intent strength or ambiguity. It’s subjective as the model must infer the human’s goal from context,"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "and different users might phrase intentions in diverse, personal ways."
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "Aesthetics Identification\nThis is a relatively novel task in NLP – assessing the aesthetic quality"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "or style of content. Traditionally, this has been more common in computer vision (image aesthetics"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "rating), but with multi-modal models and stylistic text generation,\nit’s coming to NLP. Here we"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "consider tasks like: given an image and possibly a description, rate its aesthetic appeal; or given a"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "piece of text, judge its writing style aesthetics (is it eloquent, is it engaging). The Textual Aesthetics"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "work (Jiang et al., 2024)\nintroduced a dataset and method to fine-tune LLMs to produce more"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "aesthetically pleasing text outputs. And on the image side, AesBench (Huang et al., 2024) is a"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "benchmark that asks LLM-based vision-language models to perform various aesthetic understanding"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "tasks on images. This task is subjective by nature – “beauty is in the eye of the beholder.” It intersects"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "with sentiment (pleasing vs not pleasing) but goes beyond, into artistic elements and human preference."
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "We place it in its own category, touching both affective and cognitive."
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "This taxonomy shows the diverse landscape we cover. Relationships exist between tasks: sarcasm"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "and humor are linked, sentiment and stance both deal with evaluation but target differently, emotion"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "and intent sometimes intersect. One ambition of the field is to handle overlapping phenomena jointly."
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "2.4\nWhy LLMs Matter for Subjectivity"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "We expect LLMs to be particularly suitable for subjective language understanding for several reasons,"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "supported by recent research:"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "In-Context Learning & Few-Shot Ability\nLLMs can perform tasks with little to no task-specific"
        },
        {
          "Humor Detection\nIdentify if a text is intended to be humorous or not (and possibly, how funny": "training, by virtue of prompting. This is very useful for tasks where we might not have large labeled"
        }
      ],
      "page": 7
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "of instruction can yield reasonable answers, whereas smaller models would fail without explicit"
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "training. This makes it feasible to tackle low-resource subjective tasks. The ability to incorporate a"
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "few examples in the prompt (few-shot learning) can further improve performance, essentially allowing"
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "the model to adapt on the fly to the style of the task or domain."
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "Knowledge and Common Sense\nLLMs embed a vast amount of world knowledge and common"
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "sense acquired during pre-training. Many subjective interpretations require such knowledge. For"
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "instance, understanding the humor\nin “My phone’s battery is the Usain Bolt of dying” requires"
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "knowing Usain Bolt is extremely fast (so the phone dies fast – a humor through metaphor). A well-"
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "trained LLM likely knows about Bolt and can connect “fast at dying” as a humorous exaggeration. The"
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "knowledge aspect also helps in stance detection (knowing background of topics), and in metaphors"
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "(knowing typical mappings and even rare ones). This is something earlier task-specific models lacked;"
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "they’d see words but not truly “know” facts or cultural references."
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "Advanced Language Generation for Explanations\nFor subjective tasks, generating explanations"
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "or justifications is valuable (for interpretability and possibly improving accuracy). LLMs can produce"
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "natural language explanations via chain-of-thought prompting or by design. For example, an LLM"
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "might detect sarcasm better if prompted to explain the joke and then decide—essentially using its"
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "generative prowess to reason. Some approaches use chain-of-thought (CoT) prompting, where the"
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "model thinks step by step about why a sentence might be sarcastic. This capability of explaining"
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "makes LLMs flexible, turning implicit tasks into explicit reasoning processes (e.g., “The sentence"
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "says X but likely means Y, because ...”)."
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "Multi-task and Transfer Learning at Scale\nLLMs are typically trained on diverse internet text."
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "This means,\nfor\ninstance,\nthey’ve seen both factual\ntext\n(Wikipedia articles) and subjective text"
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "(tweets, novels, reviews) to some extent. This exposure might allow transfer learning internally;"
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "the model could transfer what it “learned” about sentiment while reading movie reviews to help in"
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "understanding sentiment in a new context. The scale of training might also let it capture patterns that"
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "smaller models miss. Research has indeed indicated that certain abilities (like understanding idioms"
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "or performing basic reasoning) emerge only as model scale increases."
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "Unified Handling of Language and Multi-modality\nSome of the latest “LLM” systems are multi-"
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "modal. For tasks like aesthetics, which involve images, or emotion recognition from multimodal"
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "cues,\nthese architectures extend the LLM paradigm. The extension of these to subjective queries"
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "(e.g., “Is this person in the image happy or sad?” or “Rate the aesthetics of this photograph”) is"
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "a current research frontier. LLMs provide a coherent way to integrate modalities – by converting"
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "everything to a “language” (descriptions, dialogues) and then processing with a powerful language"
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "reasoning core. This could be more effective than earlier multi-modal systems that treated vision and"
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "text separately. Our survey will touch on some multimodal aspects (especially in aesthetics and in a"
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "few humor/sarcasm datasets that have context or images)."
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "In summary, LLMs matter for subjectivity because they bring general intelligence-like capabilities"
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "to NLP: flexibility, knowledge, and adaptability. However, as we will see, they are not a panacea."
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "There are also reasons LLMs might struggle or require augmentation: e.g.,\nthey might\nlack true"
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "understanding of emotion (they predict patterns but don’t “feel”), they might have biases, and they"
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "might produce convincing but incorrect interpretations. Throughout the survey, we will evaluate how"
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "well the promise of LLMs translates into actual task performance, citing concrete results."
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "Having set the stage, we will first provide a brief overview of LLMs — their evolution and current"
        },
        {
          "datasets. For example, prompting GPT-4 with “Is the following statement sarcastic? . . . ” and a bit": "state of the art (Section 3) — before exploring each subjective language task in Sections 4–11."
        }
      ],
      "page": 8
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "unlabeled text and task fine-tuning. GPT-2[145] (2019) expanded to 1.5B parameters, showcasing"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "coherent\ntext generation.\nThe breakthrough came with GPT-3[19]\n(2020), at 175B parameters,"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "demonstrating strong zero-shot and few-shot\nlearning across\ntasks\nlike sentiment analysis and"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "translation without explicit training—emerging as a general-purpose NLP tool. This paradigm was"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "quickly adopted,\nleading to other LLMs like Google’s T5[146], BERT-like encoders, and larger"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "models such as PaLM[34] (540B) and Megatron-Turing NLG[160] (530B)."
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "In 2022–2023, instruction tuning and interactive LLMs, known as chatbot models, emerged. OpenAI’s"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "InstructGPT[134] and ChatGPT (based on GPT-3.5) were fine-tuned with human feedback to better"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "follow instructions and conversational cues, aligning with human preferences for greater practical"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "effectiveness. GPT-4[1] (2023) enhanced performance, especially in complex reasoning tasks, though"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "its architecture and size remain unconfirmed, with estimates suggesting >170B parameters and"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "novel training methods. Concurrently, Meta AI released LLaMA[177] and LLaMA-2[178] (7B–70B"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "parameters), open-source models that democratized LLM research. Other entrants included Claude by"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "Anthropic and Baidu’s ERNIE. Current state-of-the-art LLMs often involve ensembles or instruction-"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "tuned versions of these base models, with open-source projects like Alpaca[168] and Vicuna[32]"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "fine-tuning LLaMA for ChatGPT-like functionality."
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "In the context of subjective language, models specifically to handle such tasks have emerged: e.g.,"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "a model named SentimentGPT[85] was proposed by Kheiri & Karimi (2023) which analyzes how"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "GPT-based models depart from classical ML in sentiment analysis. Specialized variants or prompting"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "techniques (like emotion-aware LLMs) have been developed. Some research has tried to incorporate"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "psychological theories into LLMs by fine-tuning or prompting[214]. Furthermore, the line between"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "“language model” and “multimodal model” is blurring – GPT-4 and others can accept\nimages as"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "input in addition to text, allowing them to describe an image’s emotional content or aesthetics. This"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "versatility positions LLMs as central hubs for processing subjective information across modalities."
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "To summarize this evolution: we went from task-specific small models,\nto moderate pre-trained"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "models fine-tuned per task, to gargantuan models that can perform all tasks with minimal task-specific"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "tuning. This is a paradigm shift:\ninstead of building a separate classifier for sarcasm, we can now"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "prompt one general model to do sarcasm detection, perhaps even alongside other tasks. It opens the"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "door for multi-task subjective language models, which we discuss later in the survey (Section 12)."
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "3.2\nCurrent State-of-the-Art Models"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "The current landscape of Large Language Models (LLMs) for subjective language understanding is"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "characterized by a diverse array of models and techniques, broadly categorizable into prompt-based,"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "Supervised Fine-Tuning (SFT)-based, and reasoning-based approaches. Prominent models frequently"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "cited in recent\nliterature include OpenAI’s GPT series (GPT-3.5, GPT-4, GPT-4o[74]), Google’s"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "Gemini[170]\n(Gemini 1.5 Flash[171], Gemini 1.5 Pro, Gemini 2.0 Flash), Meta’s Llama series"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "(Llama-2, Llama-3[48], Llama-3.1), Mistral AI’s models (Mistral 7B[81], Mixtral 8x7B[82]), and"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "others like Qwen-2[203], and DeepSeek-R1[60] models."
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "Prompt-based LLMs\nleverage the inherent capabilities of pre-trained models by providing care-"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "fully crafted input prompts to guide their\nresponses for specific tasks.\nThis includes zero-shot"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "prompting, where the model performs a task without any prior examples, and few-shot prompting,"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "where a small number of examples are included in the prompt to demonstrate the desired output. For"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "subjective tasks, the design of the prompt is critical, as it can influence the model’s perspective and"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "reasoning. For example, techniques like Chain-of-Thought (CoT)[189] prompting, which encourage"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "the model to generate intermediate reasoning steps, have been applied to improve performance on"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "tasks requiring deeper understanding. However, research indicates that CoT prompting, especially for"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "larger LLMs, might suffer from \"posterior collapse,\" where the model relies more on pre-existing"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "reasoning priors than on the evidence presented in the prompt, particularly in complex subjective"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "domains like emotion and morality."
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "SFT-based LLMs\ninvolve taking a pre-trained LLM and further\ntraining it\n(fine-tuning) on a"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "specific dataset relevant to a particular subjective task. This process adapts the general knowledge of"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "the LLM to the nuances of the target domain. For instance, models like RoBERTa[108] and BERT[40]"
        },
        {
          "exemplifies\nthis\nshift.\nGPT-1[144]\n(2018) with\n117M parameters highlighted pre-training on": "have been fine-tuned for tasks such as subjectivity detection in news articles or sentiment analysis."
        }
      ],
      "page": 9
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "well to out-of-distribution data or other subjective tasks without further adaptation. Parameter-efficient"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "fine-tuning (PEFT) methods like LoRA[71] (Low-Rank Adaptation) and QLoRA[39] are also gaining"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "traction, allowing for adaptation with reduced computational cost."
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "Reasoning-based LLMs\nfocus on enhancing the model’s ability to perform logical\ninference"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "and understand complex relationships, which is crucial for many subjective tasks. This includes"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "methods that explicitly guide the model’s reasoning process. For example, the \"Reasoning through"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "Perspective Transition\" (RPT) method enables LLMs to dynamically select among direct, role, and"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "third-person perspectives to solve subjective problems more effectively by ranking perspectives and"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "choosing the most suitable one for a given scenario. Another approach, \"Reasoning in Conversation\""
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "(RiC), simulates dialogues to mine useful contextual information for subjective tasks like metaphor"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "recognition and dark humor detection, rather than relying solely on chain-of-thought rationales. These"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "methods aim to overcome the limitations of standard prompting by encouraging more structured and"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "adaptable reasoning. The development of models like GPT-4, which are reported to have improved"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "reasoning capabilities, also falls under this umbrella."
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "The choice of model and approach often depends on the specific task, the availability of labeled data,"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "computational resources, and the desired level of interpretability and generalization. For instance,"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "while proprietary models like GPT-4 often lead in performance, open-source models like Llama"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "and Mistral provide flexibility for customization and fine-tuning . The ongoing research explores"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "hybrid approaches, knowledge distillation from larger to smaller models, and methods to improve the"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "robustness and reliability of LLMs in subjective understanding."
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "3.3\nMulti-Model LLMs for Subjective Language Understanding"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "The concept of Multi-Model LLMs is increasingly significant\nin addressing the complexities of"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "subjective language understanding. This approach recognizes that a single LLM may be insufficient"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "to capture all aspects of subjectivity, particularly with multimodal inputs or tasks requiring diverse"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "expertise. For example, in sarcasm detection, visual cues accompanying text can be vital for clarifying"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "meaning. The Commander-GPT[228] framework is proposed for multimodal sarcasm detection,"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "where a central LLM (e.g., GPT-4) coordinates specialized models (\"generals\") skilled in areas like"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "image content analysis or textual analysis. This ensemble approach aims to leverage the strengths"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "of different models for more robust sarcasm recognition than a single model can achieve. Similarly,"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "in Speech Emotion Recognition (SER), systems are developed that combine audio encoders (e.g.,"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "Whisper-large-v3[143]) with LLMs (e.g., Gemma-2-2B-it[172]) to process both speech signals and"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "transcriptions, forming a unified multimodal architecture. These systems align features from different"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "modalities and manage token overload from high-dimensional audio embeddings."
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "Another dimension of Multi-Model encompasses ensemble methods or collaborative agent frame-"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "works, wherein multiple LLM instances or diverse models collaborate. For subjectivity detection"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "in news, an ensemble of multiple LLMs is employed, combining predictions via majority voting to"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "enhance robustness and mitigate biases. In stance detection, the COLA[92] framework utilizes LLMs"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "in a three-stage collaborative process, assigning distinct roles to address challenges like multi-aspect"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "knowledge and advanced reasoning, enabling nuanced analysis beyond a single LLM’s capacity."
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "Additionally, hybrid approaches integrating smaller, fine-tuned models (e.g., BERT) with larger LLMs"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "(e.g., GPT-4, Llama-3) are emerging. For intent detection, uncertain predictions from a fine-tuned"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "BERT may be routed to an LLM, with BERT information dynamically generating prompts for the"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "LLM to reduce label space, balancing computational efficiency with advanced LLM capabilities."
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "These multi-model strategies signify a shift towards developing sophisticated systems for subjective"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "language understanding, surpassing reliance on a singular LLM."
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "To conclude this section, LLMs have rapidly become the toolkit of choice for subjective language"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "understanding. We now have a variety of ways to use them (direct prompting, fine-tuning, etc.) and a"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "variety of models to choose from. The remaining sections will detail each task. We will see that for"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "tasks with limited data (like humor, sarcasm), creative prompting and large models (GPT-4) often"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "lead the pack, whereas for tasks with lots of data (like sentiment), fine-tuned smaller models can still"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "compete or outperform in some cases – though the gap is closing as LLMs get instruction-tuned on"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "sentiment during their general training. Next, we dive into Sentiment Analysis as the first task, which"
        },
        {
          "While fine-tuning can lead to high performance on the specific dataset, it may not always generalize": "historically is one of the most studied and will illustrate many general points."
        }
      ],
      "page": 10
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "4\nSentiment Analysis": "4.1\nTask Definition of Sentiment Analysis"
        },
        {
          "4\nSentiment Analysis": "Sentiment analysis, also known as opinion mining, is a core task in NLP that focuses on identifying,"
        },
        {
          "4\nSentiment Analysis": "extracting, quantifying, and studying affective states and subjective information from text. The"
        },
        {
          "4\nSentiment Analysis": "primary goal is to determine the attitude or emotional tone of a writer or speaker with respect to a"
        },
        {
          "4\nSentiment Analysis": "particular topic, product, person, or entity. This attitude can be categorized in various ways, most"
        },
        {
          "4\nSentiment Analysis": "commonly as positive, negative, or neutral. More fine-grained approaches may also identify the"
        },
        {
          "4\nSentiment Analysis": "intensity of the sentiment (e.g., very positive, slightly negative) or detect specific emotions. Sentiment"
        },
        {
          "4\nSentiment Analysis": "analysis can be performed at different levels of granularity: document-level (classifying the overall"
        },
        {
          "4\nSentiment Analysis": "sentiment of an entire document), sentence-level (determining sentiment for individual sentences),"
        },
        {
          "4\nSentiment Analysis": "or aspect-level (identifying sentiment towards specific aspects or features of an entity mentioned in"
        },
        {
          "4\nSentiment Analysis": "the text, e.g., \"The camera is good, but the battery life is poor\"). The task is crucial for a wide range"
        },
        {
          "4\nSentiment Analysis": "of applications, including brand monitoring, market research, customer feedback analysis, product"
        },
        {
          "4\nSentiment Analysis": "recommendation, and social media analytics. The challenge lies in accurately interpreting nuanced"
        },
        {
          "4\nSentiment Analysis": "language, sarcasm, irony, and context-dependent expressions that can alter the perceived sentiment."
        },
        {
          "4\nSentiment Analysis": "4.2\nDataset of Sentiment Analysis"
        },
        {
          "4\nSentiment Analysis": "Sentiment analysis has been built on a set of well-established supervised benchmarks spanning"
        },
        {
          "4\nSentiment Analysis": "reviews and social media. Core movie and product review resources include MR (movie reviews,"
        },
        {
          "4\nSentiment Analysis": "also known as the Polarity dataset), the Stanford Sentiment Treebank (SST; phrase-level labels with"
        },
        {
          "4\nSentiment Analysis": "SST-2 binary and SST-5 five-class variants), IMDb (50k balanced reviews), Amazon product reviews"
        },
        {
          "4\nSentiment Analysis": "(millions of star ratings), and Yelp Reviews (hundreds of thousands, widely used in LLM studies)."
        },
        {
          "4\nSentiment Analysis": "Multi-domain review collections (e.g., books, electronics) are used to test domain shift. Large Twitter"
        },
        {
          "4\nSentiment Analysis": "datasets became standard as well: Sentiment140 (1.6M tweets, balanced binary) and the Twitter"
        },
        {
          "4\nSentiment Analysis": "US Airline Sentiment dataset (14,160 tweets with positive/neutral/negative) are common baselines."
        },
        {
          "4\nSentiment Analysis": "The SemEval-2017 Task 4 Twitter benchmarks remain central for topic-oriented sentiment. Earlier"
        },
        {
          "4\nSentiment Analysis": "works also use the University of Michigan dataset and a series of domain-specific Twitter corpora,"
        },
        {
          "4\nSentiment Analysis": "including Tariyal et al.’s 1,150 product-review tweets, Hemakala and Santhoshkumar’s 14,640 Indian"
        },
        {
          "4\nSentiment Analysis": "airline tweets, and Rahat et al.’s 10k tweets."
        },
        {
          "4\nSentiment Analysis": "Beyond overall polarity, several datasets drive fine-grained and pragmatic analysis. SemEval-2014"
        },
        {
          "4\nSentiment Analysis": "Task 4 established Aspect-Based Sentiment Analysis (ABSA), requiring sentiment toward specific"
        },
        {
          "4\nSentiment Analysis": "aspects in text. Nuanced social media phenomena are captured by SemEval-2018 Irony in Tweets"
        },
        {
          "4\nSentiment Analysis": "and sarcasm/emoji-focused resources. Extending this line, [12] released\n5,929 tweets about nuclear"
        },
        {
          "4\nSentiment Analysis": "power with explicit sarcasm annotations to study how irony and emoji shift sentiment labels. Financial"
        },
        {
          "4\nSentiment Analysis": "sentiment has long been supported by the Financial PhraseBank and by stock-related Twitter corpora;"
        },
        {
          "4\nSentiment Analysis": "more recently,\n[38] introduced a Reddit-based market sentiment dataset\nlabeled bullish, bearish,"
        },
        {
          "4\nSentiment Analysis": "or neutral\nto address data scarcity in finance. Multilingual product-review datasets (e.g., Arabic,"
        },
        {
          "4\nSentiment Analysis": "Chinese) broaden coverage across languages, and niche multimodal or “aesthetic” sentiment resources"
        },
        {
          "4\nSentiment Analysis": "illustrate crossovers with vision-language and aspect-centric judgments."
        },
        {
          "4\nSentiment Analysis": "In the LLM era (2022–2025), classic benchmarks continue to anchor evaluation while new practices"
        },
        {
          "4\nSentiment Analysis": "and specialized datasets expand the landscape. Studies routinely test zero-/few-shot LLMs on SST-"
        },
        {
          "4\nSentiment Analysis": "2/SST-5, MR/Polarity, IMDb, Amazon/Yelp, and Twitter/SemEval sets; for example, [226] report"
        },
        {
          "4\nSentiment Analysis": "LLM results on SST-2 and MR. Prompt-based evaluation suites[12] have also appeared, complement-"
        },
        {
          "4\nSentiment Analysis": "ing large-scale benchmarks with targeted probes. Meanwhile, domain-specific datasets—especially"
        },
        {
          "4\nSentiment Analysis": "in finance (e.g., Reddit market sentiment) and in sarcasm-aware settings—highlight persistent chal-"
        },
        {
          "4\nSentiment Analysis": "lenges that remain even when models perform strongly on standard corpora. Taken together, today’s"
        },
        {
          "4\nSentiment Analysis": "sentiment datasets span binary, ternary, and five-class labeling; phrase- and aspect-level annotation;"
        },
        {
          "4\nSentiment Analysis": "multiple domains and languages; and scales from thousands to over a million instances, providing"
        },
        {
          "4\nSentiment Analysis": "comprehensive coverage for training and assessing LLM-based sentiment analysis."
        },
        {
          "4\nSentiment Analysis": "4.3\nLLM methods of Sentiment Analysis"
        },
        {
          "4\nSentiment Analysis": "Large language models (LLMs) have reset expectations for sentiment analysis, yet recent evaluations"
        },
        {
          "4\nSentiment Analysis": "urge caution. Broad benchmarking shows LLMs do well on simpler settings but\nlag on complex"
        },
        {
          "4\nSentiment Analysis": "tasks requiring structured outputs or deeper inference, motivating a more realistic evaluation agenda"
        }
      ],
      "page": 11
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "extremes, sarcasm, and irony [107]. Mechanistically, sentiment appears to lie along a largely linear"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "direction in activation space; causal ablations at key tokens (e.g., commas) degrade zero-shot accuracy,"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "offering both interpretability and a warning about brittleness [175]. Fairness audits reveal persistent"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "social biases despite fine-tuning, especially around age, underscoring the need for bias testing in"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "deployment [142]. Surveys synthesize these trade-offs across domains, noting computational cost,"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "domain sensitivity, and ethics as recurring themes, and framing finance as a distinctive setting where"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "“what is financial sentiment” itself demands care [54][116][88]."
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "Few-shot Prompting\nFew-shot prompting is label-efficient but variably reliable.\nTechniques"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "such as SuperICL and bootstrapping strengthen generative LLMs for financial news, producing"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "stable, explainable signals that improve portfolio construction [127]. Complementarily, AI-generated"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "exemplars can aid context extraction,\nthough their benefits depend on prompt design and task"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "complexity [4]. Evidence across domains shows the data regime is pivotal:\nin data-scarce software"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "engineering corpora, larger LLMs achieve zero-shot SOTA, whereas with sufficient labels, fine-tuned"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "small LMs retake the lead [222]. Zero-shot multilingual ABSA remains challenging; leaner prompts"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "often outperform elaborate self-consistency or self-debate strategies, especially in English [191]. In"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "Chinese healthcare ABSA, compact sLLMs are competitive and efficient, follow instructions well,"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "and support privacy-preserving deployment [208]. Detailed prompts help zero/few-shot ABSA but"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "become less critical after fine-tuning [158]. Overall, few-shot methods offer speed and low labeling"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "cost but can be unstable across domains and remain vulnerable to irony and subtle cues [223][107]."
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "Chain-of-Thought Reasoning\nReasoning-oriented prompting can improve reliability and trans-"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "parency but\nintroduces latency and new hallucination pathways.\nIn finance, Domain Knowledge"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "Chain-of-Thought (DK-CoT) integrates domain expertise with CoT, boosting robustness and weighted"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "F1 for news sentiment [27]. For weak supervision, Reddit pipelines pair CoT with multiple reasoning"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "paths to stabilize weak labels and train efficient downstream models [38].\nFor policy analytics,"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "multi-task reasoning frameworks jointly infer travel modes, sentiments, and rationales from tweets,"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "enabling insights without manual labels [150]. Nevertheless, in multilingual ABSA, complex self-"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "improvement or self-debate prompts do not consistently outperform simple zero-shot baselines,"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "indicating diminishing returns from heavier reasoning prompts across languages [191]."
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "Fine-Tuning and Ensemble Approaches\nFine-tuning, ensembling, and continual learning deliver"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "durable gains when compute and data allow. On the high end, fine-tuned GPT-3.5 sets SOTA"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "on SemEval-2014 ABSA, albeit at higher cost [158]. On the efficiency frontier, compact models"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "excel on the speed–accuracy trade-off: EmoBERTTiny surpasses 7B-chat LLM baselines with"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "millisecond inference, making it well suited for real-time use [164]. For ensembling, RGPT adaptively"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "reweights hard instances and aggregates historical predictions to boost specialized LLM classifiers,"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "outperforming SOTA LLMs and even average human performance on multiple benchmarks [226]."
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "For non-stationary settings, continual\nlearning with domain-decoupled adapters preserves prior"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "knowledge while acquiring new domains and performs domain positioning at\ninference without"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "explicit IDs, achieving SOTA across 19 ABSA datasets [45]. In finance, a domain-specific LLaMA-2"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "paired with summarization of long filings improves return prediction and robustness, and even lifts"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "traditional models [33]. Cross-model comparisons suggest GPT-4 generalizes best, FinBERT excels"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "on structured financial text, and T5 lags in recall/generalization [154], echoing reviews that highlight"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "FinBERT’s reliability and the cost–benefit calculus of task-specific fine-tuning [116][222]."
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "LLMs for Data Augmentation/Annotation\nLLMs are effective labelers and data generators. In"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "low-resource ABSA, few-shot prompting to synthesize annotations raises F1, especially for aspect-"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "level sentiment with modest seed data [68]. At scale, weak-labeling pipelines provide tractable"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "supervision: CoT-stabilized Reddit market sentiment\n[38], GPT-4–labeled Baijiu stock forums"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "followed by LLaMA fine-tuning [241], and multi-LLM majority voting for large social studies [185]."
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "In health-related social media, domain-aware prompting and targeted fine-tuning outperform lexicon"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "baselines yet still fall short of high accuracy, motivating hybrid workflows and practical prompting"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "guidance [64]. Overall, the advantages are rapid coverage and flexible domain adaptation; the risks"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "are label noise, ethical and copyright constraints, and amplification of existing biases [38][142]."
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "Handling Nuances and Context\nHandling nuance and context often calls for architectural or"
        },
        {
          "[223]. Evidence suggests LLMs exhibit basic sentiment sensitivity but struggle with strong polarity": "retrieval enhancements. Retrieval-augmented LLMs ground instructions in external evidence, mitigat-"
        }
      ],
      "page": 12
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "accuracy [219]. Summarization layers condense long filings into analysis-ready text, boosting sen-"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "timent fidelity and return predictiveness [33]. Multi-source fusion of Twitter/news sentiment with"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "dynamic asset models improves both short- and long-horizon stock forecasts [157]. For trading, LLM-"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "based, sentiment-driven strategies with improved prompting deliver profitable, stable performance"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "with explainable rationales [127], and financial DK-CoT further stresses cost-effective reliability and"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "class-weighted metrics given asymmetric downside risks [27]. Nonetheless, sarcasm, brevity, and"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "domain shifts remain difficult [107], multilingual ABSA is brittle [191], and the linear sentiment"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "mechanism is both a lever for control and a single-point vulnerability—motivating more realistic"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "benchmarks and protocols [175][223]."
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "A practical recipe emerges. When labels are scarce, start with few-shot prompting or weak-label"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "pipelines; add CoT/DK-CoT for interpretability and stability in finance or policy analyses. Under"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "tight\nlatency or privacy budgets, prefer compact or small LLMs fine-tuned for the domain. For"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "shifting domains, adopt continual\nlearning with decoupled adapters and retrieval augmentation."
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "In finance, combine summarization with domain knowledge to translate sentiment into actionable"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "returns. At every stage, integrate fairness auditing and robust evaluation practices to counter bias and"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "over-optimism, guided by domain surveys and reviews that articulate the cost, robustness, and ethical"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "trade-offs intrinsic to LLM-based sentiment analysis."
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "4.4\nKey Challenges of Sentiment Analysis"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "Despite the significant progress enabled by LLMs in sentiment analysis, several key challenges persist."
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "One prominent challenge is the accurate identification and classification of neutral sentiment. Neutral"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "statements often lack explicit emotional cues or may contain a mix of positive and negative aspects"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "that cancel each other out, making them difficult for models to categorize correctly. For example,"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "a statement like \"The product arrived on time\" is factual and neutral, but models might incorrectly"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "assign a positive sentiment\nif they overemphasize words like \"on time\" without considering the"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "overall neutrality of the expression. The ResearchGate article on BERT applications specifically"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "points out that the detection of neutral reviews is a problem impacting model accuracy. This difficulty"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "is compounded when neutral expressions are subtle or when the model\nis trained on imbalanced"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "datasets where neutral examples are underrepresented. Improving the model’s ability to distinguish"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "between genuinely neutral content and weakly positive/negative content remains an active area of"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "research. This often involves curating more balanced datasets, developing more sophisticated feature"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "representations, or employing techniques that specifically target the nuances of neutral language."
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "Another significant challenge is the subjectivity and inherent ambiguity in human language, which"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "directly impacts sentiment analysis. Sentiment is not always explicitly stated and can be conveyed"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "through sarcasm, irony, figurative language, or cultural context, all of which are difficult for models"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "to interpret accurately. For instance, a statement like \"Great, another Monday!\" might be interpreted"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "as positive by a naive model focusing on the word \"great,\" while a human would easily recognize"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "the negative sentiment conveyed through sarcasm. The inherent ambiguity means that even human"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "annotators may disagree on the sentiment label for a particular piece of text, leading to noisy training"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "data and affecting model performance. The subjective nature of sentiment also means that what"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "one person perceives as positive, another might see as negative or neutral, depending on their"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "personal experiences, beliefs, and cultural background. This variability makes it challenging to"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "create universally applicable sentiment analysis models. Addressing this requires not only more"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "sophisticated models but also a deeper understanding of pragmatics and context, potentially through"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "the integration of commonsense knowledge and world knowledge into LLMs."
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "Finally,\nthe presence of false or deceptive reviews in datasets poses a considerable challenge to"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "the accuracy and reliability of sentiment analysis models. On many online platforms, particularly"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "e-commerce and review sites, businesses or individuals may post fake positive reviews to boost"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "their own reputation or fake negative reviews to damage a competitor’s. These deceptive reviews"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "are often crafted to mimic genuine expressions of sentiment, making them difficult for automated"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "systems to detect. When models are trained on datasets contaminated with such false reviews, they"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "can learn incorrect associations and produce unreliable sentiment predictions. The ResearchGate"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "article suggests that future research could focus on constructing false review categorization models"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "to mitigate this issue. This involves developing techniques to identify and filter deceptive content"
        },
        {
          "ing pretraining–task mismatch and short-text context gaps, and thereby improving financial sentiment": "before it is used for training sentiment analysis models, or to build models inherently more robust to"
        }
      ],
      "page": 13
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "such noise. This is critical for applications where sentiment analysis supports decision-making, as": "predictions based on manipulated data can lead to erroneous conclusions and unfair outcomes."
        },
        {
          "such noise. This is critical for applications where sentiment analysis supports decision-making, as": "In summary, LLMs bring excellent generalization and an ability to incorporate context and world"
        },
        {
          "such noise. This is critical for applications where sentiment analysis supports decision-making, as": "knowledge into sentiment analysis. With the right prompting,"
        },
        {
          "such noise. This is critical for applications where sentiment analysis supports decision-making, as": "task-specific models, especially in zero or few-shot settings. Fine-tuning and advanced prompting"
        },
        {
          "such noise. This is critical for applications where sentiment analysis supports decision-making, as": "further close the gap for hard cases, making LLMs the new state of the art for sentiment analysis in"
        },
        {
          "such noise. This is critical for applications where sentiment analysis supports decision-making, as": "many evaluations. Yet, ensuring they correctly handle tricky linguistic phenomena remains an active"
        },
        {
          "such noise. This is critical for applications where sentiment analysis supports decision-making, as": "research challenge. The lessons learned in sentiment analysis – about prompting, augmentation, and"
        },
        {
          "such noise. This is critical for applications where sentiment analysis supports decision-making, as": "hybrid deployment – carry over to other subjective tasks, as we explore next."
        }
      ],
      "page": 14
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "categories plus Neutral that enabled fine-grained classification and robust transfer.\nIt has become"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "a default benchmark for LLMs and smaller fine-tuned models alike.\nIn dialogue and empathy-"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "focused settings, EmpatheticDialogues[147] (32 emotions) supports empathetic response modeling,"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "while MELD and IEMOCAP remain central for contextual and multimodal ERC. Specialized tasks"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "expanded the scope: RECCON[138] targets emotion cause extraction within conversations, and"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "Affect\nin Tweets from SemEval-2018 remains a standard for intensity modeling. Together,\nthese"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "corpora benchmark discriminative classification, intensity estimation, and causal reasoning across"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "single-utterance and contextual settings."
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "Recent work (2022–2025) emphasizes context-rich, task-oriented, and ambiguity-aware evaluation"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "aligned with LLM capabilities. EmoWOZ[52] introduces emotional variation in task-oriented dia-"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "logues, probing whether systems detect shifts such as anger versus neutrality in service conversations."
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "New evaluations target uncertainty and mixed affect; [70] propose an Ambiguous Emotion Dataset"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "with high annotator disagreement to test whether models can recognize uncertain or blended emotions,"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "and report results across multiple standard datasets. Surveys such as [29] document a broadening"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "agenda from classification to emotionally aware response generation and Theory-of-Mind assess-"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "ments, while reinforcing that discriminative emotion recognition remains a foundational\ntestbed."
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "Across this landscape, datasets differ in granularity (categorical vs. dimensional), domain (tweets,"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "Reddit, dialogues, narratives), and annotation scheme (single- vs. multi-label, intensity, cause), and"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "many are used to probe LLMs’ strengths and weaknesses under context, subjectivity, and ambiguity."
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "At the same time, multimodal image/video resources, together with ERC counterparts such as MELD,"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "underscore an ongoing trend toward richer, context-sensitive, and comprehensive evaluation."
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "5.3\nLLM methods of Emotion Recognition"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "Prompting and Adaptive Emotional Reasoning\nPrompt- and reasoning-centric approaches use"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "lightweight controls to elicit\nlatent affective abilities in general-purpose LLMs. EmotionPrompt"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "injects affective cues into instructions, improving induction-style tasks, broad capability benchmarks,"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "and human-rated generative quality [97]. Emotional Chain-of-Thought aligns intermediate reasoning"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "with human emotional guidelines,\nincreasing harmlessness and positivity [101].\nTask-adaptive"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "long reasoning (Emotion-o1) adjusts chain length to difficulty and jointly rewards accuracy, depth,"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "diversity, and logical consistency, improving advanced affective tasks such as sarcasm detection [161]."
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "For noisy speech–text pipelines, Revise–Reason–Recognize combines emotion-specific prompts"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "(acoustic,\nlinguistic, psychological) with ASR correction to maintain robustness [100]. Training-"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "free in-context learning that pairs image-similarity retrieval with chain-of-thought enables context-"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "aware visual emotion understanding without retraining [96]. Reinforcement learning with verifiable"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "rewards improves explainability, accuracy, and out-of-distribution robustness for omnimodal emotion"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "recognition, while attributing modality contributions [235]."
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "Instruction Tuning and Parameter-Efficient Specialization\nParameter-efficient customization"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "enables cost-effective specialization of LLMs for affective computing. DialogueLLM performs"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "instruction tuning on multimodal dialogues and injects visual context as knowledge, reaching state-"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "of-the-art results on emotion recognition in conversation (ERC) with modest compute [224]. Adapter-"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "based approaches such as P-Tuning v2 and LoRA allow LLMs to surpass dedicated baselines"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "across multiple emotion datasets, demonstrating transferability and efficiency [135]. In low-resource"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "settings, knowledge-augmented few-shot learning that couples contrastive embedding training with"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "prompt-based self-prediction enhances sentiment and affect analysis [204]. For multi-label scenarios,"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "ambiguity-aware prompting enables reliable modeling of overlapping emotions, particularly when"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "dialogue and speech cues are available [70]. Extending beyond recognition, fine-tuned LLMs can"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "infer emotion-regulation strategies from observed behavior—outperforming Bayesian baselines even"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "without post-interview data—highlighting potential for coaching and therapeutic applications [126]."
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "Complementarily, cross-context fusion with LoRA and targeted domain adaptation further advances"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "continuous affect prediction in challenging multimodal benchmarks [213]."
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "Multimodal and Omni-Modal Emotion Integration\nMultimodal instruction tuning is accelerating"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "perception-rich emotional\nintelligence in LLMs. Emotion-LLaMA integrates audio–visual–text"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "encoders with instruction tuning on MERR to couple recognition with reasoning, achieving state-of-"
        },
        {
          "The modern large-scale era is anchored by GoEmotions[36], a 58k-comment Reddit corpus with 27": "the-art results across multiple corpora and zero-shot video settings [31]. Omni-Emotion advances"
        }
      ],
      "page": 15
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "curates high-quality, human-reviewed datasets for both recognition and explanation [205]. AffectGPT"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "combines pre-fusion multimodal alignment with training on MER-Caption to support open-vocabulary"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "emotion captioning, evaluated via MER-UniBench [103]. On the visual front, EmoVIT pioneers"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "affect-oriented visual\ninstruction tuning by generating emotion-specific instructions, excelling at"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "classification and affective reasoning [196]. Face-centric EMO-LLaMA further leverages instruction"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "data and facial priors\n(global/local\nfeatures, demographics)\nto deliver SOTA-comparable FER,"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "covering micro-expressions and audio–vision fusion [198]. For speech-centric applications, EMOVA"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "provides end-to-end omni-modality with disentangled speech tokenization and controllable style for"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "expressive spoken dialogue [25], while SECap moves beyond discrete labels to natural-language"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "emotion captions through HuBERT and Q-Former\ninterfaces to LLaMA [199].\nFrom a privacy"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "standpoint, DEEMO demonstrates strong recognition and reasoning using de-identified video/audio"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "and non-facial body cues, reducing identity exposure [98]. For compositional affect, LVLMs adapted"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "via two-stage tuning—basic emotions followed by compound optimization—achieve SOTA with"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "zero-shot generalization [215], and remain effective for context-aware detection using training-free"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "retrieval or light fine-tuning [96]. Complementary visual–affective modeling with multi-perspective"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "projection and EmoPrompt further strengthens nuanced emotion reasoning in MLLMs [206]."
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "Benchmarking Emotional Intelligence: Strengths, Gaps, and Risks\nA rapidly maturing evalua-"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "tion ecosystem is revealing strengths, limitations, and risks. Grounded in psychological theory and"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "spanning English and Chinese, EmoBench assesses emotion understanding and application, show-"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "ing LLMs—despite progress—still fall short of average human performance [152]. EmoBench-M"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "extends evaluation to multimodal settings and indicates MLLMs continue to lag humans on core emo-"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "tional intelligence scenarios [72]. From a reliability perspective, EmotionHallucer audits “emotion"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "hallucinations” across perceptual and knowledge dimensions, finds widespread errors, and proposes a"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "mitigation framework with measurable gains [197]. With respect to empathy, EmotionQueen probes"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "key, mixed, and implicit events as well as intention recognition, revealing strong performance on"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "explicit tasks but persistent limits for implicit affect [28]. For multimodal emotion understanding,"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "MER-UniBench offers a dedicated benchmark [103], while AEB and the EmoLLMs suite stan-"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "dardize multi-task affective evaluation and annotation [109]. Large-scale comparisons further show"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "that LLMs can surpass humans in empathy ratings,\nthough performance varies by emotion [190];"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "psychometric tests often place top LLMs at or above average human EQ, yet with mechanisms"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "distinct from human reasoning and uneven skill profiles across EI branches [188][182]. In image-only"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "emotion recognition, specialized CNNs still hold a slight edge over general LLMs, although LLMs"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "remain practical under data scarcity [128]. Collectively, these benchmarks chart clear progress while"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "highlighting open challenges in multimodality, implicit emotion inference, and hallucination control."
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "Interactive Systems and Emotional Support\nEnd-user systems highlight promise and caveats."
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "Embodied “Virtual Humans” couple LLMs with realistic avatars and explicit psychological con-"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "structs (e.g., personality, mood) to steer affective valence in semi-guided dialogue, achieving high"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "naturalness and realism, although arousal control remains difficult [113]. In child-facing settings, a"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "state machine–guided chatbot elicits sharing of personal events and emotions and is perceived as a"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "“close friend” in laboratory studies [153]. For psychotherapy support, fusing emotion-aware embed-"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "dings with LLMs and retrieving context from sessions improves empathy, coherence, and fluency"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "[148]. Beyond clinical use, LLM-generated arguments are as persuasive as human ones and show"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "cognitive effort and moral language—implications for civic education and risks of misinformation"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "[20]. Nonetheless,\nin emotional-support conversations current LLMs exhibit strategy biases and"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "miscalibrated preferences that hinder effectiveness, underscoring the need for external oversight and"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "bias mitigation before reliable deployment [83]. Methodologically, ambiguity-aware prompting and"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "behavior-level strategy recognition broaden coverage of real-world affective ambiguity and regulation"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "[70][126]."
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "Mechanistic Affective Modeling and Causal Extraction\nMechanistic and theory-driven accounts"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "are increasingly aligning model behavior with affective science. At the representation level, converg-"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "ing evidence for emotion-selective neuron groups in LLMs—together with ablation studies showing"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "cross-layer compensation—implies distributed, model-dependent circuitry for affect [94]. From"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "a cognitive-science perspective, a comprehensive survey maps advances in LLM-based emotion"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "cognition onto the sensation–perception–attention pipeline and situates techniques ranging from"
        },
        {
          "video MLLMs with fine-grained facial and acoustic modeling,\nincluding micro-expressions, and": "contrastive learning to theory-of-mind-style reasoning [29]. For causal explanation, emotion-cause"
        }
      ],
      "page": 16
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "context and utterance-pair communication [104]. On the data side, hybrid human–AI\nlabeling"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "pipelines show GPT-4 can flag low-quality annotations, improving reliability and efficiency in affect"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "datasets while remaining perceptually distinct from human raters [133]. Taken together with audits"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "of hallucination and generalization, these strands chart paths toward theory-grounded, trustworthy"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "emotional intelligence, including improved handling of ambiguity and regulation [231][70][126]."
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "Overall, emotion recognition with large models now follows a coherent\ntrajectory:\nlightweight"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "prompting delivers immediate gains; instruction tuning with parameter-efficient adapters consolidates"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "capability; multimodal and omni-modal architectures capture real-world signals; and theory-grounded"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "benchmarks surface blind spots in implicit understanding and hallucination. Coupling explainable"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "reinforcement learning, privacy-preserving design, and hybrid human–AI annotation improves re-"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "liability, while retrieval grounding and bias mitigation safeguard sensitive deployments. Selecting"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "methods by data budget,\nlatency, and modality turns a diverse toolkit\ninto a robust, accurate, and"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "responsible strategy for affective AI."
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "5.4\nKey Challenges of Emotion Recognition"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "Despite significant progress, emotion recognition using LLMs faces several key challenges, primarily"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "stemming from the inherent nature of human emotions and the limitations of current models. One of"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "the most prominent challenges is the ambiguity and subjectivity of emotional expression. Human"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "emotions are complex and often nuanced, making it difficult to assign a single, definitive label. Textual"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "expressions can be interpreted differently by different\nindividuals or even by the same individual"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "under varying contexts. This is reflected in low inter-annotator agreement in many emotion datasets."
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "LLMs, while powerful, can struggle to capture this inherent ambiguity, often providing a single"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "emotion label that might not fully represent the subtlety of the expressed feeling. Forcing complex,"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "mixed emotions into discrete, predefined categories is an oversimplification that can lead to models"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "trained on an incomplete or skewed representation of reality. The AER-LLM study specifically"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "addresses this by focusing on recognizing ambiguous emotions, but it remains a core challenge for"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "the field. The subjective experience of emotion is also shaped by cultural and individual factors,"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "which are often not adequately accounted for in datasets or models."
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "Another significant challenge is the context-dependency of emotions. The meaning of a word or"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "phrase, and the emotion it conveys, can drastically change depending on the surrounding text, the"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "speaker’s intent, and the broader situational context. While LLMs are adept at capturing some level"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "of context, fully understanding long-range dependencies and subtle contextual cues that disambiguate"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "emotional meaning remains difficult. For example, sarcasm, irony, or humor can completely invert"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "the apparent emotional valence of a statement, and detecting these figurative language uses is a"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "challenge in itself. Furthermore,\nthe reliability and bias in datasets pose a major hurdle. Many"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "emotion recognition datasets are created using majority voting from multiple annotators, which can"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "obscure the inherent ambiguity and lead to a \"flattened\" representation of emotions. Datasets may"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "also suffer from biases related to the demographics of the annotators or the sources of the text (e.g.,"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "specific social media platforms), leading to models that perform well on similar data but generalize"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "poorly to new domains or populations. The \"observer effect,\" where the act of being monitored alters"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "a user’s emotional expression, can also compromise data fidelity, especially in real-world settings."
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "The interpretability and explainability of LLM-based emotion recognition systems also present"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "challenges. While LLMs can achieve high accuracy, understanding why a model made a particular"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "emotional prediction is often difficult. This \"black box\" nature can be problematic, especially in"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "sensitive applications like mental health monitoring or human-robot\ninteraction, where trust and"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "transparency are crucial. Research into \"emotion neurons\" attempts to shed light on the internal"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "representations of emotions within LLMs, but\nthis is still an emerging area. Moreover, ethical"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "considerations are paramount. The deployment of emotion recognition systems raises concerns about"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "privacy, surveillance, and the potential for misuse, particularly if the systems are not robust or fair"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "across different demographic groups . Ensuring that these technologies are developed and deployed"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "responsibly is a critical ongoing challenge. Finally, resource limitations for low-resource languages"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "and the computational cost of training and deploying large LLMs can also hinder the widespread"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "adoption and further development of sophisticated emotion recognition systems . Addressing these"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "multifaceted challenges requires interdisciplinary collaboration and continued innovation in model"
        },
        {
          "triplet extraction benefits from multimodal, multi-scale heterogeneous graphs that foreground causal": "architecture, dataset creation, and evaluation methodologies."
        }
      ],
      "page": 17
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "such phenomenon that heavily intersects with sentiment and emotion is sarcasm, which we discuss"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "next, as it often flips sentiment and adds complexity to emotion recognition tasks."
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "6\nSarcasm Detection"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "6.1\nTask Definition of Sarcasm Detection"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "Sarcasm detection is a specialized task within natural\nlanguage understanding that\nfocuses on"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "identifying whether a piece of\ntext\nis intended to be sarcastic.\nSarcasm is a form of figurative"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "language where the speaker or writer says the opposite of what they truly mean, often for humorous,"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "ironic, or critical effect. The core challenge in sarcasm detection lies in the discrepancy between"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "the literal meaning of the words and the intended, often opposite, meaning. This discrepancy is"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "signaled through contextual cues, tone of voice (in spoken language), linguistic patterns, or shared"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "knowledge between the communicator and the audience. For example,\nthe statement \"Oh, great,"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "another meeting!\" is likely sarcastic if the speaker is known to dislike meetings or if the context"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "suggests a negative sentiment towards meetings. Accurately detecting sarcasm is crucial for a deeper"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "understanding of sentiment and opinion, as misinterpreting a sarcastic statement as literal can lead to"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "a misunderstanding of the speaker’s intent. The task is particularly relevant in analyzing social media"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "text, product reviews, and online discussions, where sarcasm is frequently employed. The output"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "of a sarcasm detection system is typically a binary label (sarcastic or not sarcastic), although some"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "approaches may attempt to identify the target of the sarcasm or its underlying sentiment."
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "6.2\nDataset of Sarcasm Detection"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "Research on sarcasm and irony detection has been driven by datasets drawn largely from social media"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "and curated benchmarks. Early Twitter corpora collected via distant supervision with hashtags such"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "as #sarcasm (e.g., the widely used Ptáˇcek Twitter corpus) established a scalable but noisy paradigm."
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "SemEval-2018 Task 3 on Irony Detection in English Tweets standardized evaluation with both"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "binary and fine-grained labels (e.g., Non-irony, Verbal Irony, Situational Irony), and many studies"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "use its binary setting for comparability. Outside social media, the News Headlines dataset contrasts"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "satirical headlines from The Onion with genuine headlines from HuffPost, offering a style-specific"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "but domain-limited benchmark frequently used to test transfer."
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "Context-rich and multimodal resources broadened coverage. The Reddit Self-Annotated Corpus"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "(SARC)[86] leverages user markers (e.g., “/s”), provides both balanced and large unbalanced splits"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "with hundreds of thousands of comments, and supplies conversational structure (parent/child and"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "thread hierarchy) critical for pragmatic cues. CASCADE[239] focuses explicitly on dialogue context"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "by labeling the final utterance in multi-turn discussions as sarcastic or not. MUStARD[21] and its"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "extension MUStARD++[14] compile sarcastic and non-sarcastic dialogue snippets from TV shows"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "with aligned video/audio and transcripts; despite being multimodal, their text transcripts are widely"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "used for text-only experiments targeting conversational sarcasm."
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "Recent datasets emphasize annotation quality, multilinguality, and speech. SemEval-2022 Task 6"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "(iSarcasmEval) addresses the noise of hashtag supervision by asking original authors to annotate"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "intended sarcasm in English and Arabic and to provide literal rephrasings for sarcastic tweets, yielding"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "smaller but high-fidelity pairs that support supervised learning and analysis of meaning contrast. In"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "2025, PodSarc introduced a large spoken sarcasm benchmark from a podcast, pairing audio with"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "transcripts and using LLM-assisted labels that were human-validated. Concurrently, LLM-based"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "studies have evaluated across “widely used benchmark datasets” spanning tweets,\nforums, and"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "dialogues (e.g., those above). For instance, [95] report state-of-the-art results on SemEval-2018 and"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "MUStARD using text-only prompting, while broader assessments such as multi-agent approaches"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "like [102] underscore the continuing role of these benchmarks."
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "Together, these datasets cover short quips, threaded conversations, news headlines, and audiovisual"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "dialogue, with diverse annotation methodologies (self-annotation, author intent, expert/crowd labels)."
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "They reveal design trade-offs: distant supervision scales but is noisy; author-intent labels and paired"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "rephrasings increase reliability but reduce size; conversational and multimodal context\nimproves"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "ecological validity. This variety enables comprehensive evaluation of sarcasm detectors and LLMs,"
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "while highlighting persistent challenges of domain shift, context dependence, and pragmatic nuance."
        },
        {
          "The successes in emotion recognition lay a foundation for tackling other subjective phenomena. One": "18"
        }
      ],
      "page": 18
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "6.3\nLLM methods of Sarcasm Detection": "Prompted Reasoning for Sarcasm\nPragmatic and metacognitive prompting enrich LLMs’ ca-"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "pacity to infer implied meanings and reconcile contextual mismatches, delivering state-of-the-art"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "performance [95].\nIn a complementary direction, SarcasmCue formalizes cue-centric reason-"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "ing—contradictions, graphs, bags, and tensors—showing that non-sequential cue aggregation can"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "boost smaller models, whereas stronger models benefit more from structured chains and graphs [209]."
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "Moreover, chain-of-thought rationales aid entity-level sentiment in news and can transfer to sarcasm;"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "however,\ntheir effectiveness is inconsistent and improves with self-consistency [90]. Fine-tuning"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "still outperforms zero-shot prompting for sarcasm on large GPT variants [56], and LLaMA-3 often"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "succeeds on shorter inputs yet struggles as length increases [117]. More broadly, benchmarking"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "indicates that supervised PLMs surpass LLMs on sarcasm [225], and scaling alone does not guarantee"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "pragmatic competence—sarcasm continues to lag metaphor under psychiatric-style probing [200]."
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "Additionally, specialized fine-tuning on iSarcasmEval with efficient PEFT/QLoRA yields strong"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "gains, underscoring the importance of target-domain supervision and explicit intention cues [69]."
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "Multimodal Understanding and OOD Robustness\nGenerative, instruction-following multimodal"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "systems that retrieve demonstrations sidestep overfitting-prone fusion stacks and improve out-of-"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "distribution generalization on RedEval while achieving in-domain SOTA [166]. On the reasoning"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "front, MiDRE blends internal incongruity reasoning with external LVLM rationales and adaptively"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "weights them to outperform prior methods [80]; DMDP injects deep, modality-disentangled prompts"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "for few-shot settings and cross-dataset generalization [79]; and CofiPara first uses LMM-generated"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "rationales to train coarse sarcasm and then targets fine-grained sarcasm entities [105]. Comple-"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "mentarily, EilMoB extracts emotion-aware textual incongruity from image–text pairs and bridges"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "modalities to exploit cross-source tensions [234]. In parallel, agentic VLLM pipelines that triangulate"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "superficial form, semantics, and sentiment consistently lift zero-shot performance on MMSD2.0"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "[186]. However, evaluations expose a seeing–understanding gap: high perceptual accuracy coexists"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "with sizable sarcasm-comprehension errors rooted in pragmatic and affective reasoning deficits [227],"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "and explanation quality does not reliably track model scale [7]. Taken together, a unified benchmark"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "(MHSDB) underscores that robust multimodal fusion and carefully chosen integration strategies are"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "pivotal for nuanced humor and sarcasm [47]."
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "Multi-Agent Orchestration Pipelines\nDecomposing the challenge of complex sarcasm into coordi-"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "nated expert roles enhances both robustness and interpretability. In this paradigm, Commander-GPT"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "dispatches focused sub-tasks—keyword extraction, sentiment estimation, and cross-modal verifica-"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "tion—to specialized LLMs and fuses their outputs through a coordinating controller [228]. From a"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "complementary angle, CAF-I formalizes irony via multi-agent collaboration that separates context,"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "semantics, and rhetoric,\nthen aggregates them with a decision agent and iterative feedback [110]."
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "Through the lens of deliberation, LDGNet stages debates among LLM “debaters” and employs a"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "learned judge to surface latent world knowledge, producing reliable sentiment decisions across both"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "in-domain and OOD settings [237]. Extending these ideas to audio-only conditions, LLM-guided an-"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "notation pipelines with human-in-the-loop gating introduce new speech sarcasm resources (PodSarc)"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "and enable competitive bimodal systems, bringing agentic supervision to low-visibility modalities"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "[102]. Taken together, systematic decomposition, structured interaction, and principled adjudication"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "emerge as a coherent design pattern for pragmatic inference under uncertainty."
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "Commonsense, Incongruity, and Knowledge Alignment\nCommonsense-centered approaches"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "treat emotional incongruity as a primary signal for sarcasm. In this framing, EICR combines retrieval-"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "augmented LLMs, dependency-graph refinement, adaptive reasoning skeletons, and adversarial"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "contrastive learning to isolate sentiment-inconsistent subgraphs while suppressing spurious correla-"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "tions [140]. From a temporal perspective, KA-LLM models evolving events by building dynamic"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "knowledge graphs over topic–target pairs and aligning them with hybrid objectives, thereby explain-"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "ing how sarcasm triggers shift over time [195]. On the multimodal front, recent methods extract"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "or synthesize textual “incongruity carriers” to narrow modality gaps—EilMoB’s emotion-aware"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "incongruity modeling and CofiPara’s rationale-guided pretraining exemplify this trend [234][105]."
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "Complementarily, external rationales generated by LVLMs, though often noisy, supply useful cues"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "that move beyond shallow captions and steer incongruity resolution [80]. Looking back, earlier con-"
        },
        {
          "6.3\nLLM methods of Sarcasm Detection": "textual paradigms—such as CASCADE’s incorporation of user and discussion features—anticipated"
        }
      ],
      "page": 19
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "implicit sarcasm that lacks overt cues [238][151]."
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "Nuances, Augmentation, and Linguistic Variety\nLanguage nuance remains pivotal. At the domain"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "level, a nuclear-industry study shows topic-specific LLMs struggle with sarcasm while general-domain"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "models perform better; robustness improves with adversarial text augmentation and targeted sarcasm"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "removal, whereas emojis tend to amplify rather than flip sentiment [12]. Across language varieties, the"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "BESSTIE benchmark finds degraded transfer from inner-circle to outer-circle English—especially for"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "sarcasm—underscoring the need for variety-specific resources and adaptation [162]. In cross-lingual"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "settings, Indonesian sarcasm experiments indicate that fine-tuned PLMs outperform zero-shot LLMs,"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "and naive augmentation does not remedy class imbalance [165]. On the evaluation side, out-of-"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "distribution suites like RedEval and explanation audits expose metric pitfalls—embedding-based"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "scores can assign high similarity to contradictory explanations—calling for more reliable assessment"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "protocols [166][7]. From an optimization standpoint, dynamic adjustment during multi-task fine-"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "tuning (DAO) stabilizes learning across heterogeneous sentiment subtasks, a strategy well-suited to"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "sarcasm’s imbalanced, multi-objective regimes [44]."
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "Benchmarks and Evaluation Practices\nRecent resources are making evaluation more compre-"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "hensive and equitable.\nIn head-to-head comparisons, SarcasmBench assesses LLMs and PLMs"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "across datasets and prompts, finding GPT-4 the strongest among LLMs yet still behind supervised"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "PLMs; moreover, few-shot\ninstruction-only prompting often outperforms chain-of-thought [225]."
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "At\nthe multimodal scale, MHSDB standardizes humor and sarcasm evaluation across languages"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "and modalities, with fusion approaches consistently beating unimodal baselines [47]. From a soci-"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "olinguistic angle, BESSTIE systematically probes English varieties to reveal persistent equity gaps"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "[162]. Methodologically, MORE-based audits show that automatic metrics can misjudge explanation"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "faithfulness [7], while Visual Room tasks disentangle perception from pragmatic comprehension"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "to quantify the “understanding gap” [227]. Even so, core datasets like SARC 2.0 pol-bal remain"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "valuable for contrasting tuned and zero-shot paradigms across successive GPT generations [57]."
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "Historically, Reddit-based studies continue to highlight the centrality of conversational context and"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "user history [238]. Meanwhile, new speech corpora such as PodSarc expand modality coverage [102],"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "and regional resources like IdSarcasm sustain non-English evaluation [165]."
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "Lessons From Sentiment and ABSA\nProgress in sentiment analysis offers transferable tools for"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "sarcasm detection. At the modeling level, instruction-tuned financial LLMs show that small supervised"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "instruction sets can imbue numeracy and domain fluency beyond generic chat models [218][77],"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "while at the optimization level, dynamic adaptive strategies improve the stability of multi-task fine-"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "tuning across diverse sentiment objectives [44]. At the reasoning level, chain-of-thought rationales"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "strengthen entity-specific sentiment decisions and, when paired with self-consistency, suggest prompt-"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "engineering routes for sarcasm [90]. At\nthe task granularity level, ABSA comparisons highlight"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "domain sensitivity and the value of strong PLMs/LLMs (DeBERTa, PaLM, GPT) for fine-grained"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "aspect judgments—capabilities adjacent to pinpointing sarcasm targets [125]. In applied contexts,"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "ChatGPT aligns closely with human ABSA in hospitality [3], design-aware position encoding"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "enriches generative ABSA with implicit knowledge [63], and prompt-engineered sentiment analysis"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "can discriminate subtle clinical\nlanguage in fibromyalgia screening [181].\nFrom an evaluation"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "perspective, broader audits indicate that LLMs still lag humans on sentiment, humor, and metaphor,"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "yet remain sensitive to prompt\nimprovements [212]. From a domain perspective, case studies on"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "nuclear discourse show that sarcasm and sentiment\nintertwine with policy frames,\ntopicality, and"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "stylistic signals, motivating joint modeling and specialized augmentation [91][12]."
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "Overall, recent advances in sarcasm detection leveraging Large Language Models (LLMs) reveal"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "a clear\ntrajectory from single-task fine-tuning toward prompt-engineered,\nreasoning-aware, and"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "multi-agent/multimodal systems. Benchmarks and empirical studies consistently show that purely"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "scaling models does not guarantee pragmatic comprehension, particularly when sarcasm hinges"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "on cultural, contextual, or emotional\nincongruity.\nTechniques such as pragmatic metacognitive"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "prompting, structured cue reasoning, commonsense integration, and dynamic knowledge alignment"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "improve robustness, while agentic frameworks and modality-bridging architectures enable richer"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "interpretation across text,\nimage, and audio. Evaluation work underscores persistent gaps across"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "varieties,\nlanguages, and OOD scenarios, urging more equitable, context-aware resources. Cross-"
        },
        {
          "today’s knowledge-infused strategies and, at\nthe same time, highlight enduring difficulties with": "pollination from sentiment and ABSA research, along with nuanced handling of\ntopic-specific"
        }
      ],
      "page": 20
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "language cues, suggests that future sarcasm detection will benefit from domain adaptation, explicit": "reasoning steps, and hybrid integration of statistical, commonsense, and multimodal signals to"
        },
        {
          "language cues, suggests that future sarcasm detection will benefit from domain adaptation, explicit": "approach human-like interpretive capability."
        },
        {
          "language cues, suggests that future sarcasm detection will benefit from domain adaptation, explicit": "6.4\nKey Challenges of Sarcasm Detection"
        },
        {
          "language cues, suggests that future sarcasm detection will benefit from domain adaptation, explicit": "Sarcasm detection remains a challenging task for LLMs due to several\ninherent difficulties. One"
        },
        {
          "language cues, suggests that future sarcasm detection will benefit from domain adaptation, explicit": "primary challenge is the heavy reliance on context. The interpretation of an utterance as sarcastic"
        },
        {
          "language cues, suggests that future sarcasm detection will benefit from domain adaptation, explicit": "often depends on a wide array of contextual factors, including world knowledge, shared understanding"
        },
        {
          "language cues, suggests that future sarcasm detection will benefit from domain adaptation, explicit": "between interlocutors,\nthe speaker’s typical style, and the specific situation. LLMs, despite their"
        },
        {
          "language cues, suggests that future sarcasm detection will benefit from domain adaptation, explicit": "extensive pre-training, may still struggle to access and integrate all relevant contextual information,"
        },
        {
          "language cues, suggests that future sarcasm detection will benefit from domain adaptation, explicit": "especially if it’s not explicitly stated in the immediate text. For example, understanding a sarcastic"
        },
        {
          "language cues, suggests that future sarcasm detection will benefit from domain adaptation, explicit": "comment about a recent event requires knowledge of that event. Another significant challenge is the"
        },
        {
          "language cues, suggests that future sarcasm detection will benefit from domain adaptation, explicit": "subtlety and variability of sarcastic cues. Sarcasm can be expressed in many different ways, and the"
        },
        {
          "language cues, suggests that future sarcasm detection will benefit from domain adaptation, explicit": "cues can be very subtle, such as a slight change in word choice, a particular sentence structure, or"
        },
        {
          "language cues, suggests that future sarcasm detection will benefit from domain adaptation, explicit": "even the absence of expected emotional markers. These cues can be difficult for models to learn,"
        },
        {
          "language cues, suggests that future sarcasm detection will benefit from domain adaptation, explicit": "especially when they are sparse or overlap with non-sarcastic language patterns. The ambiguity"
        },
        {
          "language cues, suggests that future sarcasm detection will benefit from domain adaptation, explicit": "between sarcasm and other forms of figurative language like irony, humor, or hyperbole also poses a"
        },
        {
          "language cues, suggests that future sarcasm detection will benefit from domain adaptation, explicit": "challenge. Distinguishing these closely related concepts can be difficult even for humans, and models"
        },
        {
          "language cues, suggests that future sarcasm detection will benefit from domain adaptation, explicit": "may misclassify one for the other."
        },
        {
          "language cues, suggests that future sarcasm detection will benefit from domain adaptation, explicit": "Furthermore, dataset bias and quality are ongoing concerns. Many sarcasm detection datasets are"
        },
        {
          "language cues, suggests that future sarcasm detection will benefit from domain adaptation, explicit": "created from specific sources like social media, which may not be representative of sarcasm in other"
        },
        {
          "language cues, suggests that future sarcasm detection will benefit from domain adaptation, explicit": "domains or genres. The annotation process itself can be subjective, and inter-annotator agreement is"
        },
        {
          "language cues, suggests that future sarcasm detection will benefit from domain adaptation, explicit": "not always high, leading to noisy labels. Sarcasm is also highly culture-dependent; what is considered"
        },
        {
          "language cues, suggests that future sarcasm detection will benefit from domain adaptation, explicit": "sarcastic in one culture may not be in another, or the cues might differ. LLMs trained on data primarily"
        },
        {
          "language cues, suggests that future sarcasm detection will benefit from domain adaptation, explicit": "from one cultural context may not generalize well\nto others. The lack of vocal or visual cues in"
        },
        {
          "language cues, suggests that future sarcasm detection will benefit from domain adaptation, explicit": "text-based sarcasm is another hurdle. In spoken communication, tone of voice, facial expressions,"
        },
        {
          "language cues, suggests that future sarcasm detection will benefit from domain adaptation, explicit": "and body language provide crucial signals for sarcasm. Text-based models must\nrely solely on"
        },
        {
          "language cues, suggests that future sarcasm detection will benefit from domain adaptation, explicit": "linguistic cues, making the task inherently harder. Finally, adversarial attacks, where subtle changes"
        },
        {
          "language cues, suggests that future sarcasm detection will benefit from domain adaptation, explicit": "are made to a text\nto fool a model\ninto misclassifying sarcasm, highlight\nthe brittleness of some"
        },
        {
          "language cues, suggests that future sarcasm detection will benefit from domain adaptation, explicit": "current approaches. Addressing these challenges requires continued research into more context-aware,"
        },
        {
          "language cues, suggests that future sarcasm detection will benefit from domain adaptation, explicit": "robust, and nuanced LLM architectures and training methodologies."
        },
        {
          "language cues, suggests that future sarcasm detection will benefit from domain adaptation, explicit": "We now turn to humor detection, a related challenge that overlaps with sarcasm—sarcasm is a form"
        },
        {
          "language cues, suggests that future sarcasm detection will benefit from domain adaptation, explicit": "of humor, though not all humor is sarcastic, and both involve non-literal intent—yet it introduces"
        },
        {
          "language cues, suggests that future sarcasm detection will benefit from domain adaptation, explicit": "distinct demands on background knowledge and linguistic creativity. These added complexities are"
        },
        {
          "language cues, suggests that future sarcasm detection will benefit from domain adaptation, explicit": "precisely what current LLMs are being tested on."
        }
      ],
      "page": 21
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "other sources to form binary detection sets; variants target specific subtypes such as roast/insult humor."
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "Beyond English, multilingual resources emerged, notably the Spanish HAHA (Humor Analysis)"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "datasets at IberLEF (with humor presence and funniness ratings), Hinglish puns collections, and"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "Chinese releases such as CHumor 1.0. Early multimodal and conversational angles came from"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "UR-FUNNY (humor in TED-talk conversations) and MUStARD (multimodal sarcasm, overlapping"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "with humorous cues). Researchers also began to exploit aligned or minimally contrastive pairs to"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "better capture what “makes” text funny,\nincluding The Onion satire with human-edited “serious”"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "counterparts (the Unfunny Corpus) and aligned topic-matched joke/non-joke pairs."
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "From 2020 to 2021,\nshared tasks\nconsolidated high-quality,\ncarefully annotated benchmarks."
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "SemEval-2020 Task 7 introduced Humicroedit, in which single-word edits turn news headlines hu-"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "morous, supporting pairwise ranking and analysis of humor-inducing transformations. SemEval-2021"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "Task 7 (HaHackathon) released a large English dataset—primarily tweets and short texts—with mul-"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "tiple annotators per item, covering humor detection (yes/no), funniness rating, and offense in humor;"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "the “Humor and Offense” (HAHO) references typically refer to this split. These tasks highlighted"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "subjectivity via dense annotation and established standard evaluation settings. In parallel, Twitter"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "hashtag (#humor) collections and several Kaggle humor-detection datasets (e.g., HahahaClf) offered"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "additional short-text benchmarks."
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "Since 2022, datasets have broadened in modality, context, and language while being used to probe"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "large language models (LLMs).\nStudies have evaluated LLMs (e.g., GPT-3) on SemEval-2021,"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "Humicroedit, Pun-of-the-Day and Hinglish pun sets, and Reddit\njoke vs non-joke discrimination,"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "often finding humor—especially wordplay—remains challenging. Conversational and workplace-"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "context corpora (e.g., WRIME and other dialogue resources, including dinner-party dialogues with"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "humorous turns) test whether models recognize humor in context and alongside social variables"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "such as appropriateness and offense. Aligned-pair designs gained traction: beyond Humicroedit,"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "satire–serious headline pairs and other minimally contrastive text pairs have been shown to help"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "models learn portable humor cues, with reports that classifiers trained on such pairs generalize well"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "across datasets. These efforts underscore how dataset choices—humor type (puns, satire, insults),"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "text length, conversational context, and offensiveness—strongly shape detection performance."
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "Recent directions extend humor detection into new settings and modalities.\nTargeted datasets"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "for emotionally supportive dialogues have been proposed[141], separating humor generation in"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "a specified style from humor\nrecognition in context\n(e.g.,\nrecognizing a counselor’s gentle joke"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "and its appropriateness). In vision-and-language, HumorDB[78] has been introduced for graphical"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "humor, providing images (cartoons, photos) labeled for funniness, funniness ratings, and minimally"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "contrastive pairs that differ only in a humor-bearing element; initial results show vision–language"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "models perform above chance yet below human levels. Parallel “co-creativity” evaluations—such"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "as AI-assisted meme captioning—link detection to generation and collaborative use. Together with"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "established resources like Kaggle short-joke corpora, Reddit\njokes, Pun of the Day, Humicroedit,"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "UR-FUNNY, MUStARD, SemEval-2021, HAHA (Spanish), Hinglish puns, CHumor 1.0, WRIME,"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "and aligned satire–serious pairs, this expanding ecosystem supports robust, comparative evaluation of"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "humor detection across text, dialogue, and images."
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "7.3\nLLM methods of Humor Detection"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "Benchmarking and Dataset-Driven Approaches\nLarge-scale, high-quality datasets remain the"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "foundation for advancing humor recognition. Chumor 1.0 and 2.0 [65][65][66], sourced from Ruo Zhi"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "Ba, target culturally nuanced Chinese humor, revealing state-of-the-art (SOTA) LLMs perform only"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "slightly above chance, with human explanations far superior. TalkFunny[30] extends this by capturing"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "explainable humor responses with chain-of-humor annotations, enabling evaluation of conversational"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "humor comprehension. HumorBench[129] and HumorDB[78] introduce English cartoon-caption"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "and visual humor datasets, respectively, exposing persistent performance gaps between human and"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "model understanding. MHSDB[47] and YesBut[73] widen scope to multimodal/multilingual humor,"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "showing fusion of modalities consistently outperforms unimodal baselines, but contradiction-based"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "narrative humor remains elusive. These benchmarks underscore that data realism, cultural specificity,"
        },
        {
          "corpora are mostly one-liners or brief anecdotes and are often paired with non-jokes sampled from": "and multi-modality are crucial for robust humor understanding evaluation."
        }
      ],
      "page": 22
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "gies provide informative baselines for humor detection. From a low-resource perspective, few-shot"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "prompting of GPT-4 and Gemini on Croatian tweets [9] yields LLM–human agreement on par with"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "human–human agreement, indicating feasibility for rapid dataset bootstrapping. At the modality level,"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "multimodal prompting that incorporates speech audio [10] improves explanations of phonetic humor"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "by recovering prosodic cues that purely text-based models miss. In workplace settings, [155] shows"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "that current LLMs misjudge contextual appropriateness, underscoring the gap between surface-level"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "humor detection and situational awareness. These studies position prompting as a lightweight entry"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "point to humor recognition while revealing the brittleness of context-sensitive judgments."
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "Fine-Tuning and Representation Learning\nWhen domain alignment is critical, supervised adap-"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "tation surpasses prompting. From a task-alignment perspective, CYUT’s CLEF JOKER submission"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "[193] fine-tuned LLaMA 3 and RoBERTa for humor-genre classification, outperforming zero-shot"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "GPT-4, though test-set generalization lagged. From a representation-learning angle, [50] leveraged"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "hidden LLM representations with cross-validation to achieve competitive accuracy without fine-"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "tuning, while noting ambiguous class boundaries. In language-specific settings, specialized Chinese"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "humor models such as CFunModel [216] integrate multi-task learning on aggregated humor corpora,"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "surpassing general-purpose LLMs on recognition benchmarks. Taken together, these studies suggest"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "that controlled adaptation improves humor sensitivity, provided overfitting is managed."
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "Cultural, Linguistic, and Translation-Aware Methods\nHumor recognition becomes more chal-"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "lenging when linguistic or cultural gaps arise. From a cross-lingual perspective, Jokes or Gibberish?"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "[137] examines humor preservation in English–Thai translation and finds that explanation-augmented"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "prompting (GPT-Ex) yields the highest joke retention, particularly for idioms and cultural references."
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "From a cross-cultural angle, [61] quantifies humor intensity in Chinese and English family jokes"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "via ambiguity, sentiment, and incongruity indicators, revealing divergences in humor structure. In"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "slang-heavy Chinese contexts, DuanzAI [149] boosts LLM comprehension of slang-based humor"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "through phonetic matching and pinyin–hanzi disambiguation. These approaches highlight the value"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "of embedding cultural and linguistic priors into recognition systems for culturally situated humor."
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "Multimodal Humor Understanding\nHumor often spans text, images, and audio, necessitating"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "multimodal processing. From a representation perspective, ClassicMemes-50-Templates [37] and"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "MemeMind [17] address meme classification and explanation using vision–language embeddings."
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "From the knowledge integration angle, BottleHumor [75] leverages the information bottleneck to"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "iteratively distill relevant world knowledge for multimodal humor explanation.\nIn terms of fusion"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "strategies, MHSDB [47] and YesBut [73] show that multimodal feature fusion outperforms unimodal"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "approaches; however, models still struggle to comprehend implicit contradictions conveyed in visuals."
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "Safety, Ethics, and Robustness\nBeyond accuracy, humor recognition intersects with safety and"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "ethical concerns. HumorReject[194] fine-tunes LLMs to respond to harmful prompts with indirect"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "refusals, decoupling safety from denial templates. [122] found that safety filters often erase minority"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "perspectives in comedic contexts, reinforcing hegemonic norms; they advocate artist-centric align-"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "ment. Red-teaming LVLMs revealed that dark-humor prompts can bypass safety tuning, generating"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "toxic or insulting content. These works highlight the need to blend cultural sensitivity, adversarial"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "testing, and humor-aware refusal strategies when deploying humor recognition or interaction systems."
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "Humor detection is converging on a data–model–alignment playbook: realistic, culturally grounded"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "multimodal benchmarks;\nlightweight prompting for quick gains;\ntargeted adaptation and repre-"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "sentation reuse for domain fit; and culture- and translation-aware priors. Multimodal fusion and"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "knowledge-centric approaches advance explanation and situational awareness, while humor-aware"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "refusals and adversarial evaluation integrate safety into deployment. Ultimately, humor serves as a"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "sharp probe of commonsense, pragmatics, and cross-modal reasoning, paving a practical path from"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "benchmarking to robust, culturally sensitive interaction."
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "7.4\nKey Challenges of Humor Detection"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "Humor detection presents challenges for LLMs, primarily due to the subjective and culturally"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "dependent nature of humor. What one individual or culture finds hilarious, another might find"
        },
        {
          "Prompting and Few-Shot Baselines\nEven without task-specific fine-tuning, prompt-based strate-": "offensive, confusing, or not funny. This subjectivity makes it difficult to create applicable humor"
        }
      ],
      "page": 23
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "detection models and to establish a clear \"ground truth\" for training data. Annotators may disagree on": "whether a particular text is humorous, leading to noisy labels and potentially biased models. Another"
        },
        {
          "detection models and to establish a clear \"ground truth\" for training data. Annotators may disagree on": "challenge is the diversity and complexity of humor. Humor can manifest in countless forms, including"
        },
        {
          "detection models and to establish a clear \"ground truth\" for training data. Annotators may disagree on": "puns, satire, irony, slapstick, absurdity, and observational humor, each with its own linguistic and"
        },
        {
          "detection models and to establish a clear \"ground truth\" for training data. Annotators may disagree on": "cognitive mechanisms. LLMs may struggle to learn a unified representation that captures all these"
        },
        {
          "detection models and to establish a clear \"ground truth\" for training data. Annotators may disagree on": "varied types effectively."
        },
        {
          "detection models and to establish a clear \"ground truth\" for training data. Annotators may disagree on": "knowledge, while understanding satire requires awareness of social norms and critique."
        },
        {
          "detection models and to establish a clear \"ground truth\" for training data. Annotators may disagree on": "The reliance on implicit meaning, common sense, and world knowledge is another hurdle. Many"
        },
        {
          "detection models and to establish a clear \"ground truth\" for training data. Annotators may disagree on": "jokes rely on unstated premises, cultural references, or an understanding of typical scenarios that are"
        },
        {
          "detection models and to establish a clear \"ground truth\" for training data. Annotators may disagree on": "then subverted. LLMs, despite their vast training data, may not always possess the depth of world"
        },
        {
          "detection models and to establish a clear \"ground truth\" for training data. Annotators may disagree on": ""
        },
        {
          "detection models and to establish a clear \"ground truth\" for training data. Annotators may disagree on": "resolution theory of humor suggests that humor arises from the perception of an incongruity that is"
        },
        {
          "detection models and to establish a clear \"ground truth\" for training data. Annotators may disagree on": "then resolved in a playful or unexpected way. Modeling this cognitive process of identifying and"
        },
        {
          "detection models and to establish a clear \"ground truth\" for training data. Annotators may disagree on": ""
        },
        {
          "detection models and to establish a clear \"ground truth\" for training data. Annotators may disagree on": "A statement might be funny in one context but not in another. Capturing and representing the relevant"
        },
        {
          "detection models and to establish a clear \"ground truth\" for training data. Annotators may disagree on": "context, especially in short texts or isolated utterances, can be difficult. Finally, evaluating humor"
        },
        {
          "detection models and to establish a clear \"ground truth\" for training data. Annotators may disagree on": "detection systems is challenging. Standard metrics like accuracy may not fully capture a model’s"
        },
        {
          "detection models and to establish a clear \"ground truth\" for training data. Annotators may disagree on": ""
        },
        {
          "detection models and to establish a clear \"ground truth\" for training data. Annotators may disagree on": "Developing more nuanced evaluation methods that can assess a model’s deeper understanding of"
        },
        {
          "detection models and to establish a clear \"ground truth\" for training data. Annotators may disagree on": "humor is an ongoing research area."
        },
        {
          "detection models and to establish a clear \"ground truth\" for training data. Annotators may disagree on": "In summary, LLMs have made noticeable progress in recognizing humor and even explaining certain"
        },
        {
          "detection models and to establish a clear \"ground truth\" for training data. Annotators may disagree on": "kinds of jokes, but they are far from truly understanding all humor as humans do. They tend to be"
        },
        {
          "detection models and to establish a clear \"ground truth\" for training data. Annotators may disagree on": "formulaic and miss subtle context. Humor detection research with LLMs is pushing boundaries by"
        },
        {
          "detection models and to establish a clear \"ground truth\" for training data. Annotators may disagree on": "introducing style-aware evaluation, co-creativity studies, and multimodal humor tasks. These efforts"
        },
        {
          "detection models and to establish a clear \"ground truth\" for training data. Annotators may disagree on": "highlight both the capability and the limits of current models. The insights gained (e.g., need for"
        },
        {
          "detection models and to establish a clear \"ground truth\" for training data. Annotators may disagree on": "multi-step reasoning and context modeling) echo those in sarcasm and metaphor tasks. We next look"
        },
        {
          "detection models and to establish a clear \"ground truth\" for training data. Annotators may disagree on": ""
        },
        {
          "detection models and to establish a clear \"ground truth\" for training data. Annotators may disagree on": "especially in zero-shot and multi-agent settings."
        }
      ],
      "page": 24
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "target. Related lines include rumor-related stance tasks with conversational labels such as support,"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "deny, query, and discuss (as in SemEval), and the Fake News Challenge (FNC-1), which frames"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "stance between headlines and articles as agree, disagree, discuss, or unrelated. Broader-document"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "settings appear in debate/forum corpora such as PERSPECTRum[26] and in argumentation resources"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "like ArgMin, as well as stance in news commentaries. Multilingual threads include datasets around"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "specific political contexts (e.g., stance on Catalan independence). Mohammad’s releases surrounding"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "the SemEval stance task consolidated early public resources and practices for evaluation."
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "As the field matured, a subsequent phase emphasized cross-target and event-driven generalization."
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "P-STANCE[99] collects tweets expressing stance toward U.S. political figures and is designed for"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "cross-target evaluation (training on one figure, testing on another), probing target transfer. COVID-"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "19[55] datasets capture stance toward fast-evolving public-health topics (e.g., masking), adding noise,"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "sarcasm, and shifting narratives typical of crisis-time social media. These corpora broadened domains"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "and targets while keeping tweet-scale inputs well matched to general-purpose language models."
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "More recently, datasets increasingly meet LLM-oriented needs: broader topical coverage, more"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "languages, and richer signals. VAST[5] (Varied Stance Topics) extends target breadth and domains to"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "test open-domain stance recognition. VaxxStance[2] focuses on vaccine-related stance, supporting"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "research on public-health discourse and implicit attitudes. MAWQIF[6] expands Arabic stance"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "resources, advancing cross-lingual and low-resource evaluation. Recent corpora also explore multi-"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "modality (text plus images or user/profile cues) and finer-grained or implicit labels, making annotation"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "harder and class balance more uneven. These datasets are central to benchmarking zero-shot and cross-"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "target capabilities of LLMs and to studying robustness in realistic, multilingual settings, including"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "misinformation and rapidly evolving events. Together, the earlier benchmarks (e.g., SemEval-2016,"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "FNC-1, debate/news datasets) and the latest resources (e.g., VAST, VaxxStance, MAWQIF) provide"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "complementary testbeds for stance detection, enabling systematic comparison of methods while"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "highlighting persistent challenges such as implicit stance, domain shift, and cross-lingual transfer."
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "8.3\nLLM methods of Stance Detection"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "Symbolic and Logic-Augmented Reasoning\nWithin Symbolic and Logic-Augmented Reasoning,"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "fusing symbolic constraints with LLMs yields more interpretable and consistent stance decisions."
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "From a rule-encoding perspective, FOLAR encodes First-Order Logic (FOL) rules elicited by Chain-"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "of-Thought into a Logic Tensor Network and applies multi-decision fusion to curb bias [35]. From"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "the lens of rationale unification, LogiMDF consolidates divergent LLM rationales via a Logical"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "Fusion Schema and models them with a multi-view hypergraph network to reconcile inconsistencies"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "[217]. From the angle of prompt-based knowledge integration, prompt-tuned fusion frameworks"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "leverage multi-prompt learning and explanation-guided supervision to incorporate LLM-acquired"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "knowledge, strengthening reasoning while filtering noise [43][42]. For cross-target transfer, perfor-"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "mance improves when LLMs surface target-oriented analytical perspectives and natural language"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "explanations that are then fused into the predictor [41]. At the memory-augmentation level, semi-"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "parametric “experienced experts” dynamically retrieve domain-specialized memories to stabilize"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "reasoning and reduce hallucinations [187]. In sum, symbolic and logic-augmented fusion enhances"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "the interpretability and consistency of stance reasoning."
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "Chain-of-Thought and Explicit Rationales\nAcross tasks, explicit\nreasoning consistently im-"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "proves zero- and few-shot stance detection. From a methodological perspective, Chain-of-Stance"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "decomposes the decision process into stance-aware steps and delivers substantial gains without"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "task-specific fine-tuning [115], while Stance Reasoner performs zero-shot inference by generating"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "background-grounded reasoning chains that steer the final stance, enhancing both interpretability and"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "generalization [169]. In practical terms, CoT-derived explanations can supervise downstream models"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "or calibrate prompt tuning, achieving strong performance at modest cost [43][42]. From an annotation"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "perspective, GPT-4’s zero-shot CoT emerges as a competitive and economical alternative to few-shot"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "prompting [112]. From a knowledge discovery standpoint, CoT also serves as a knowledge elicitation"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "tool for logic extraction and cross-target analysis pipelines [41][35]. Chain-of-Thought and explicit"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "rationales constitute a unifying paradigm that enhances accuracy, data efficiency, and interpretability"
        },
        {
          "Favor/Against/None labels, showing that\ntweets can convey stance without explicitly naming the": "while enabling scalable knowledge discovery in stance detection."
        }
      ],
      "page": 25
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "faceted knowledge and enforce cross-agent consistency to improve decision quality.\nIn this vein,"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "COLA orchestrates role-infused expert agents—linguistic, domain, and social-media specialists—that"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "debate and consolidate a stance, providing explainability without requiring additional training data"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "[92]. Extending structured deliberation, ZSMD sets up support-versus-oppose debaters augmented"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "with background knowledge and introduces a referee to resolve disagreements, thereby improving"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "zero-shot performance and capturing nuance [114]. On the efficiency front, CoVer amortizes LLM"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "reasoning over batches and employs a small model\nto verify logical consistency and aggregate"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "predictions, substantially reducing LLM calls while maintaining state-of-the-art results [202]. Multi-"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "Agent Collaboration and Consistency—through role specialization, structured debate with arbitration,"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "and systematic consistency checking—yield a unified, cost-conscious pipeline that enhances accuracy,"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "robustness, and explainability in stance assessment."
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "Knowledge Injection and Retrieval Augmentation\nInjecting structured knowledge helps bridge"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "target–text gaps and stabilizes zero-shot and cross-target\nsettings.\nAt\nthe representation level,"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "prompted LLMs extract\ntarget–text\nrelations that are fed into a generation model and coupled"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "with prototypical contrastive alignment to strengthen decoding [230]. From a retrieval perspective,"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "retrieval-augmented pipelines ground tweet–claim relations with evidence and LLM reasoning to"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "enhance stance truthfulness [240]. On the training side, multi-task fine-tuning with debate data"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "and knowledge retrieval complements LLM semantics and boosts zero-shot performance [51]. For"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "low-resource transfer, knowledge can be infused and aligned from diverse sources [201]. In terms of"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "data coverage, synthetic open-domain stance corpora generated by ChatGPT expand coverage while"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "remaining cost-effective [233]. Knowledge Injection and Retrieval Augmentation operate as syner-"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "gistic levers that ground representations and decoding with explicit evidence, improve truthfulness,"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "and extend generalization across domains, targets, and resource levels at cost."
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "Fine-Tuning, Reinforcement, and Data Curation\nModern LLMs—including midsize models"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "fine-tuned on public datasets—now surpass prior benchmarks and offer strong efficiency–accuracy"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "tradeoffs [59]. Methodologically, reinforcement tuning with hybrid rewards can surface high-quality"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "LLM-annotated examples and enable joint stance detection and rumor verification under\nlabel"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "scarcity [207]. From a data-annotation standpoint, LLMs themselves are viable labelers: few-shot"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "and zero-shot chain-of-thought GPT-4 labeling approaches approximate supervised baselines at lower"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "cost [112]. From a domain-adaptation angle, domain-specific corpora such as δ-Stance show that"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "while proprietary LLMs capture polarity, supervised fine-tuning is essential for modeling intensity"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "and supports cross-domain transfer [62].\nIn terms of data augmentation, synthetic open-domain"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "datasets complement human labels and improve generalization to unseen targets [233]. Fine-Tuning,"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "Reinforcement, and Data Curation function as mutually reinforcing pillars, yielding systems that are"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "accurate, sample-efficient, and robust across domains and targets."
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "Multimodal and Multilingual Stance Understanding\nFrom a cross-lingual perspective, VLMs"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "underuse visual cues and over-rely on textual content, with performance strongly shaped by language"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "support and model size [179]. With respect to multimodal conversational use, complexity increases;"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "new datasets and MLLM architectures that learn joint text-image representations achieve state-of-the-"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "art results yet still reveal substantial headroom [131]. In terms of multi-turn dialogue, progress remains"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "limited:\neven specialized attention mechanisms yield only modest gains on recent benchmarks,"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "highlighting unresolved issues in long-range dependencies and dialogue-role modeling [132]. From"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "an application and safety standpoint, stance-driven generation systems demonstrate downstream utility"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "and safety-aware content creation in advocacy contexts [184]. Overall,\nthe field is advancing but"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "unevenly, with improved representation learning tempered by persistent challenges in cross-lingual"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "grounding, long-context reasoning, and controllable safe generation."
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "User-Level Stance and Political Bias\nFrom a theory-driven standpoint, agendas call for shifting"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "from message-level\nto user-level modeling,\nintegrating psychological features and LLM-inferred"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "attributes to better capture stance formation [13]. Methodologically, unsupervised pipelines that"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "map user timelines to socio-political statements via LLM-based NLI generalize across elections and"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "cultures, approaching supervised scores [53]. Political bias remains consequential: LLMs skew liberal"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "and are sensitive to demographic cues, underscoring careful prompt design [136]. At the dataset level,"
        },
        {
          "Multi-Agent Collaboration and Consistency\nCollaborative agent architectures integrate multi-": "effects dominate performance variance in political stance tasks, and target ambiguity exacerbates"
        }
      ],
      "page": 26
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "errors, calling for clearer target specification and robust prompting [130]. Overall, advances will": "hinge on user-centered modeling, bias-aware prompting, and clearer targets."
        },
        {
          "errors, calling for clearer target specification and robust prompting [130]. Overall, advances will": "A comprehensive survey inventories LLM-driven stance detection across learning regimes, modalities,"
        },
        {
          "errors, calling for clearer target specification and robust prompting [130]. Overall, advances will": "and target relations, mapping applications (misinformation, politics, health, moderation) and open"
        },
        {
          "errors, calling for clearer target specification and robust prompting [130]. Overall, advances will": "challenges (implicit stance, bias, explainability, low-resource, real-time, compute). The emerging"
        },
        {
          "errors, calling for clearer target specification and robust prompting [130]. Overall, advances will": "toolbox—logic-infused reasoning, multi-agent collaboration, knowledge retrieval/injection, and data-"
        },
        {
          "errors, calling for clearer target specification and robust prompting [130]. Overall, advances will": "centric supervision—charts a coherent path toward interpretable, scalable, and generalizable stance"
        },
        {
          "errors, calling for clearer target specification and robust prompting [130]. Overall, advances will": "detection systems that transfer across targets, modalities, and users."
        },
        {
          "errors, calling for clearer target specification and robust prompting [130]. Overall, advances will": "8.4\nKey Challenges of Stance Detection"
        },
        {
          "errors, calling for clearer target specification and robust prompting [130]. Overall, advances will": "Despite the significant progress enabled by Large Language Models (LLMs) in stance detection,"
        },
        {
          "errors, calling for clearer target specification and robust prompting [130]. Overall, advances will": "several key challenges persist, limiting the robustness and general applicability of current systems."
        },
        {
          "errors, calling for clearer target specification and robust prompting [130]. Overall, advances will": "For instance, implicit stance expression, cultural biases in training data, and the computational costs"
        },
        {
          "errors, calling for clearer target specification and robust prompting [130]. Overall, advances will": "associated with LLMs. Implicit stance expression is a major hurdle because individuals often convey"
        },
        {
          "errors, calling for clearer target specification and robust prompting [130]. Overall, advances will": "their opinions indirectly, using sarcasm, irony, or subtle linguistic cues that are difficult for models to"
        },
        {
          "errors, calling for clearer target specification and robust prompting [130]. Overall, advances will": "interpret accurately without a deep understanding of context and world knowledge. LLMs, despite"
        },
        {
          "errors, calling for clearer target specification and robust prompting [130]. Overall, advances will": "their advanced capabilities, can still struggle with such nuanced language, leading to misclassification."
        },
        {
          "errors, calling for clearer target specification and robust prompting [130]. Overall, advances will": "Cultural biases present\nin the vast corpora used to pretrain LLMs can also propagate into stance"
        },
        {
          "errors, calling for clearer target specification and robust prompting [130]. Overall, advances will": "detection models, causing them to perform differently across various demographic groups or cultural"
        },
        {
          "errors, calling for clearer target specification and robust prompting [130]. Overall, advances will": "contexts. This can lead to unfair or inaccurate predictions, particularly when dealing with sensitive"
        },
        {
          "errors, calling for clearer target specification and robust prompting [130]. Overall, advances will": "topics or diverse user bases. Addressing these biases requires careful dataset curation, debiasing"
        },
        {
          "errors, calling for clearer target specification and robust prompting [130]. Overall, advances will": "techniques, and culturally-aware model development."
        },
        {
          "errors, calling for clearer target specification and robust prompting [130]. Overall, advances will": "Another challenge is the computational expense of training and deploying LLMs, especially for"
        },
        {
          "errors, calling for clearer target specification and robust prompting [130]. Overall, advances will": "real-time applications or resource-constrained environments. While parameter-efficient fine-tuning"
        },
        {
          "errors, calling for clearer target specification and robust prompting [130]. Overall, advances will": "methods offer relief, the inference latency and hardware requirements for state-of-the-art LLMs can"
        },
        {
          "errors, calling for clearer target specification and robust prompting [130]. Overall, advances will": "be prohibitive. Furthermore, the dynamic nature of language and the emergence of slang, neologisms,"
        },
        {
          "errors, calling for clearer target specification and robust prompting [130]. Overall, advances will": "and discourse patterns mean that models can quickly become outdated if not continuously updated"
        },
        {
          "errors, calling for clearer target specification and robust prompting [130]. Overall, advances will": "or retrained. The evaluation of stance detection models presents challenges, as human annotators"
        },
        {
          "errors, calling for clearer target specification and robust prompting [130]. Overall, advances will": "may disagree on the stance label for ambiguous texts, making it difficult to establish a ground truth."
        },
        {
          "errors, calling for clearer target specification and robust prompting [130]. Overall, advances will": "Developing evaluation metrics that can capture the nuances of stance and account for inter-annotator"
        },
        {
          "errors, calling for clearer target specification and robust prompting [130]. Overall, advances will": "disagreement is an ongoing area of research. These challenges highlight the need for further research"
        },
        {
          "errors, calling for clearer target specification and robust prompting [130]. Overall, advances will": "in areas like explainable stance reasoning, low-resource adaptation, and the development of real-time"
        },
        {
          "errors, calling for clearer target specification and robust prompting [130]. Overall, advances will": "deployment frameworks for LLM-based stance detection systems."
        },
        {
          "errors, calling for clearer target specification and robust prompting [130]. Overall, advances will": "Stance detection benefits from LLMs’ language mastery and reasoning. The post-ChatGPT era has"
        },
        {
          "errors, calling for clearer target specification and robust prompting [130]. Overall, advances will": "yielded methodologies – sequential reasoning, multi-agent frameworks – that have pushed stance"
        },
        {
          "errors, calling for clearer target specification and robust prompting [130]. Overall, advances will": "detection performance to new highs, even in zero-shot settings. Yet, challenges like implicit stance"
        },
        {
          "errors, calling for clearer target specification and robust prompting [130]. Overall, advances will": "and model bias ensure it remains an active field. The innovations, such as structured reasoning about"
        },
        {
          "errors, calling for clearer target specification and robust prompting [130]. Overall, advances will": "opinions, could be relevant to other subjective tasks, since stance co-occurs with sentiment, emotion,"
        },
        {
          "errors, calling for clearer target specification and robust prompting [130]. Overall, advances will": "and figurative language. One such overlapping task is metaphor recognition, which we examine next,"
        },
        {
          "errors, calling for clearer target specification and robust prompting [130]. Overall, advances will": "where LLMs are used to detect when language is used non-literally."
        }
      ],
      "page": 27
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "LLMs possess broad semantic knowledge:\nthey “know” word meanings and can detect expectation-"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "violating usages, much like humans rely on Selectional Preference Violation as a cue for metaphor."
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "Post-ChatGPT models have been applied to metaphor tasks to see if they grasp abstract figurative"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "language and even to generate metaphors."
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "9.2\nDataset of Metaphor Recognition"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "Research on metaphor Recognition has been anchored by several\nfoundational datasets created"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "before 2022. The VU Amsterdam Metaphor Corpus[163] (VUA/VUAMC) remains the primary"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "benchmark:\nit provides token-level metaphor annotations across genres (news, fiction, academic,"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "conversation) following MIP/MIPVU, covers all parts of speech, and contains tens of thousands"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "of\nlabels;\nit also underpinned the 2018 and 2020 shared tasks. Verb-focused resources include"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "TroFi[15] ( 3k sentences for\n50 target verbs labeled as literal vs metaphorical) and MOH-X[123]"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "(647 verb instances), which are frequently paired for evaluation. Other established sets target specific"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "constructions or populations: LCC datasets[124] emphasize adjective–noun metaphors; the TOEFL"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "metaphor dataset[89] annotates second-language learner sentences; and the Stab news corpus marks"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "sentence-level metaphor presence. While mainstream benchmarks frame the problem as word-level"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "tagging, some studies also consider multi-word or idiomatic metaphors."
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "Recently, the landscape expanded toward evaluation of deeper interpretation and LLM robustness. The"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "Metaphor Understanding Challenge Dataset (MUNCH) [176] is a notable LLM-oriented benchmark"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "that couples naturally occurring metaphorical sentences from four genres with over 10,000 human-"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "written apt paraphrases and 1,500 inapt paraphrases, enabling tests that distinguish genuine metaphor"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "understanding from lexical overlap; it also spans varying levels of novelty and is openly available. In"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "Chinese, a recent shared-task-style resource (“Task 9”)[24] provides 34,463 metaphorical sentences"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "annotated with tenor, vehicle, and ground, plus two 500-sentence validation sets aligned with the"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "test format, supporting component-level analysis beyond binary identification. Complementing this,"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "CMDAG[156] is a 28K-sentence Chinese literary corpus annotated for tenor, vehicle, and ground"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "that uniquely leverages grounds as chain-of-thought to steer metaphor generation; code is available."
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "Newer datasets also explore metaphor novelty and multilingual coverage (e.g., Russian). Consistent"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "with these trends, recent methods [106] continue to report results on VUA/VUAMC and the smaller"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "verb datasets (MOH-X, TroFi), underscoring their role as standard testbeds."
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "Complementing core resources, domain-specific corpora have been curated to probe generalization,"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "including classical, metaphor-rich texts such as the Bhagavad Gita and the Sermon on the Mount[23]."
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "Multimodal efforts link language to gesture or vision to study how metaphors align with nonverbal"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "cues, and some datasets combine figurative categories (e.g., hyperbole with metaphor[236])\nto"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "encourage unified modeling. Finally, a subset of tasks explicitly targets concurrent or multi-word"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "metaphors, though word-level tagging remains the dominant formulation. Together, these datasets"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "enable both traditional identification and deeper interpretation, and they offer varied genres, languages,"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "and novelty levels for comprehensive evaluation."
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "9.3\nLLM methods of Metaphor Recognition"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "Theory-Guided Prompting Pipelines\nRecent advances have shifted metaphor recognition from"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "superficial multimodal fusion to cognitively grounded prompting and scaffolding. On the cognitive"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "side, Chain-of-Cognition prompting encourages models to reason about source–target mappings and"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "cross-modal associations rather than merely combining modalities [220]. On the instructional side,"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "Theory-guided Scaffolding Instruction operationalizes metaphor theory through staged questions"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "and a knowledge graph, yielding interpretable decisions and enabling recovery when models falter"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "[174]. From a decision-making perspective, Dual-Perspective Metaphor Detection integrates implicit"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "datastore cues with explicit\ntheory-driven prompts and self-judgment\nto improve reliability and"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "explainability [106].\nIn Chinese multimodal\nscenarios, a Chain-of-Thought bi-level optimizer"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "approximates human cognition by modeling hierarchical mappings [221]. As for context, lightweight"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "injection proves effective:\nintroducing hypothetical scenarios before proverbs markedly improves"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "word-level detection [58]. Meanwhile, few-shot GPT-3, although exhibiting partial knowledge of"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "mappings, suffers from source hallucination and overreliance on lexical triggers—underscoring the"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "need for guided reasoning [183]. Taken together,\nthese advances point\ntoward more human-like,"
        },
        {
          "infer speaker intent, and produce more coherent, context-appropriate text. This is plausible because": "reliable, and interpretable metaphor recognition."
        }
      ],
      "page": 28
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "on aligning heterogeneous cues through cognitively plausible bridges. Beyond simple caption fusion,"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "Chain-of-Cognition prompting elicits textual entity relations and ties them to visual evidence for"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "cross-domain mapping [220]. Under\nlow-resource conditions,\nimaginative frames grounded in"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "Conceptual Metaphor Theory stimulate cross-modal association and enable data-efficient, retrieval-"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "augmented reasoning [173]. On the efficiency front, CDGLT introduces controlled “concept drift”"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "via SLERP-perturbed CLIP embeddings and tunes only LayerNorms to bridge literal–figurative gaps"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "at\nlow cost [139].\nIn Chinese settings, CM3D and a Chain-of-Thought mapping model provide"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "annotated domains and interpretable alignment signals [221]. On the generation and supervision"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "side, a co-creation pipeline that expands linguistic metaphors into textual entailments for diffusion"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "models yields high-quality visual metaphors and intrinsic/extrinsic evaluation signals useful\nfor"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "recognition supervision [22]. Empirically, however, II-Bench shows MLLMs lag humans on implied"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "meanings—especially for abstract or sentiment-laden images—spotlighting sentiment reasoning as a"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "key bottleneck [111]. Targeted sentiment-aware reasoning may help close this gap."
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "Pretraining, Corpora, and Benchmarks\nDedicated resources and pretraining schemes are cat-"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "alyzing measurable progress. On the pretraining front, MetaPro 2.0 couples a large paraphrase-rich"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "VMC-P corpus with Anomalous Language Modeling, markedly improving identification and literal"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "paraphrasing of figurative expressions [119]. On the diagnostic side, MUNCH differentiates genuine"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "interpretation from mere lexical similarity using apt/inapt paraphrases across genres, revealing per-"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "sistent LLM mapping gaps [176]. On the resource side, the Figurative Archive aggregates Italian"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "metaphors with psycholinguistic ratings and corpus metrics, enabling controlled studies of familiarity"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "and concreteness effects [18]. In Chinese contexts, CMDAG contributes a large corpus with tenors,"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "vehicles, and grounds; supervising with grounds as Chain-of-Thought improves generative quality and"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "yields explicit features reusable for recognition [156]. For multimodal Chinese, CM3D brings cross-"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "modal mappings into the ecosystem [221]. On the evaluation front, domain-specific studies—from"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "religious texts showing cross-translation consistency [23] to large-scale analyses of the Book of"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "Songs revealing cognitive variation [11]—stress cross-cultural robustness. Taken together,\nthese"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "corpora and training paradigms target anomalous language head-on and help standardize evaluation."
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "Continued multilingual expansion will further strengthen generalization."
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "Context, Domain, and Emotion as Signals\nContextualization, domain adaptation, and affective"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "cues are decisive for recognition. On contextualization, prompted contexts close the abstraction"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "gap in proverb-level detection [58].\nIn translation, domain adaptation reduces metaphor errors;"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "literary-adapted NMT and LLMs compare favorably with commercial MT despite a 64–80% accuracy"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "ceiling [84]. Methodologically, multi-agent reasoning maps culturally laden Traditional Chinese"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "Medicine metaphors to Western medical concepts, illustrating cross-paradigm grounding as a route to"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "reliable mapping [167]. On the affect side, emotion knowledge helps disambiguate figurative devices:"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "modeling bidirectional dynamics between hyperbole and metaphor with emotion-aware features"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "delivers large F1 gains and reduces type confusion [236]. For interdisciplinary reading and political"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "discourse, dialogic/on-demand metaphor generation and prompt-engineered analyses make opaque"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "jargon accessible while preserving critical reflection [211][120]. Across traditions, religious and"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "classical corpora expose invariances and differences that can calibrate domain-sensitive recognizers"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "[23][11]. Together, these directions chart a practical path toward robust metaphor recognition."
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "Creativity-Aware Signals For Recognition\nRecognition improves when systems internalize anal-"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "ogy structure and creativity constraints. At scale, larger LMs better separate metaphors from faulty"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "analogies via perplexity, yet metaphorical fluency remains hard—evidence of structural awareness"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "without full creative competence [16]. On data generation and supervision, human–AI co-creation"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "of visual metaphors surfaces entailments and image–text correspondences that supervise detectors"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "and stress-test cross-domain alignment [22]. From an assessment perspective, automatic scoring of"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "metaphor creativity supplies scalar signals aligned with human judgments, a promising auxiliary"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "objective for recognition models [46]. In tooling, authoring systems that scaffold extended metaphor"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "creation make explicit coherence, extension, and revision steps—signals robust recognizers should"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "verify [87]. For evaluation, comparative studies of novel literary metaphors map divergences between"
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "human and model interpretations, yielding granular error taxonomies for training and analysis [76]."
        },
        {
          "Multimodal Recognition With Imaginative Bridges\nMultimodal metaphor understanding hinges": "Together, these strands point toward recognition that is structurally grounded and creatively aware."
        }
      ],
      "page": 29
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "often hallucinates source domains, mislabels literal as figurative (and the reverse), and overrelies on"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "lexical cues at the expense of context [183]. In vision–language settings, MLLMs trail humans on"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "implied meanings, and sentiment hints can artificially inflate scores—evidence of shallow affective"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "reasoning [111]. Conceptually, critics urge reframing “hallucination” as “confabulation,” which"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "better captures context-shaped fabrication in figurative inference [159];\nrelated links to absolute"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "metaphors and psychosis theories point to structural blind spots in token-based reasoning [67]. From"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "a comparative cognition standpoint, analyses reveal domain preferences and biases that depart from"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "human metaphor usage, highlighting fairness and generalization risks [118]. On the reliability"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "front, self-judgment with theory-guided prompts [106], emotion-informed multitask training [236],"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "and scaffolded stepwise support [174] offer pragmatic controls that raise the floor for trustworthy"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "recognition. Continued stress-testing across domains will be essential."
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "Metaphor recognition is shifting from shallow fusion to grounded, theory-guided pipelines: chain-"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "of-cognition prompts, scaffolded instruction, and self-judgment align source–target mappings with"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "visual evidence for interpretable decisions. Imaginative multimodal bridges and low-cost adapters"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "improve cross-domain alignment, while corpora and anomalous-language pretraining standardize"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "evaluation and boost generalization. Domain and emotion signals reduce errors; creativity-aware"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "supervision adds structural discipline. Yet LLMs still hallucinate and miss implied sentiment. Next,"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "unifying cognitive scaffolds with retrieval, sentiment-aware modules, and uncertainty—backed by"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "multilingual, domain-rich benchmarks—promises more robust, human-like understanding."
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "9.4\nKey Challenges of Metaphor Recognition"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "Metaphor recognition presents key challenges for Large Language Models (LLMs), primarily stem-"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "ming from the nuanced, context-dependent, and culturally specific nature of metaphorical language."
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "One challenge, as highlighted by experiments with the MUNCH dataset, is that LLMs may struggle"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "to perform full metaphor interpretation, sometimes relying on lexical similarity rather than genuine"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "cross-domain mapping. This means that even if an LLM correctly identifies a word as metaphorical,"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "it might not accurately understand the intended meaning or the specific way the source domain"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "illuminates the target domain. The interpretation of novel metaphors, which are creative and not part"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "of common parlance, is particularly difficult because LLMs primarily learn from existing text corpora"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "and may not have encountered these specific figurative uses before."
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "Another significant challenge is the ambiguity in distinguishing metaphorical usage from literal usage,"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "especially for polysemous words (words with multiple meanings). LLMs need to disambiguate word"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "senses based on context, which can be complex when both literal and metaphorical interpretations"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "are plausible. Furthermore, the \"grounds\" of a metaphor—the specific attributes or features that are"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "mapped from the source domain to the target domain—are often implicit and require deep world"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "knowledge and reasoning to infer. For example, understanding why \"time is money\" involves under-"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "standing cultural values placed on both time and money as resources. LLMs may lack this nuanced"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "understanding or struggle to articulate the specific grounds of a metaphor. The paper on Chinese"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "metaphor recognition also implicitly points to the challenge of adapting LLM methods to different"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "languages, as metaphorical constructions and common mappings can vary significantly across linguis-"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "tic and cultural boundaries. The need for high-quality, large-scale annotated datasets covering diverse"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "types of metaphors and languages remains a practical challenge for training and evaluating robust"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "metaphor recognition systems. Finally, evaluating the quality of metaphor interpretation by LLMs is"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "non-trivial, as it often requires human judgment and can be subjective. Developing objective and"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "reliable evaluation metrics that capture the depth of understanding is an ongoing research problem."
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "The systematic review on figurative language processing likely discusses these and other challenges"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "in more detail, providing a broader perspective on the limitations of current LLMs in this area."
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "All considered, LLMs have set new state-of-art in metaphor detection, bringing accuracy up and pro-"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "viding human-readable explanations. This is a significant step for figurative language understanding."
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "The integration of explicit metaphor theory into LLM reasoning is a prime example of combining"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "old linguistic insights with new model capabilities. Such synergy could be a model for other tasks."
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "Finally, we will discuss intent detection and aesthetic evaluation,\nthe last two tasks in our survey,"
        },
        {
          "Limits, Biases, and Reliability Controls\nEmpirical audits caution against overconfidence: GPT-3": "before moving to cross-task analysis and future directions."
        }
      ],
      "page": 30
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "10\nComparative Analysis and Insights": "10.1\nSimilarities and Differences among Subjective Language Tasks"
        },
        {
          "10\nComparative Analysis and Insights": "The subjective language tasks discussed—sentiment analysis, emotion recognition, sarcasm detection,"
        },
        {
          "10\nComparative Analysis and Insights": "humor detection, stance detection, metaphor recognition, user intent detection, and aesthetics identifi-"
        },
        {
          "10\nComparative Analysis and Insights": "cation—share fundamental similarities, yet they also exhibit distinct characteristics that define their"
        },
        {
          "10\nComparative Analysis and Insights": "challenges and required LLM capabilities. A core similarity is their inherent subjectivity; these tasks"
        },
        {
          "10\nComparative Analysis and Insights": "involve interpreting language that reflects personal perspectives, feelings, opinions, or evaluations"
        },
        {
          "10\nComparative Analysis and Insights": "rather\nthan objective facts. This means they are all highly context-dependent and often require"
        },
        {
          "10\nComparative Analysis and Insights": "understanding implicit meanings, cultural nuances, and speaker intent. For instance, sarcasm, humor,"
        },
        {
          "10\nComparative Analysis and Insights": "and metaphor all rely on a discrepancy between literal and intended meaning, which LLMs must infer."
        },
        {
          "10\nComparative Analysis and Insights": "Similarly, sentiment, emotion, and stance are often conveyed indirectly. Consequently, all these tasks"
        },
        {
          "10\nComparative Analysis and Insights": "benefit from LLMs’ ability to capture deep contextual understanding and semantic relationships."
        },
        {
          "10\nComparative Analysis and Insights": "However, there are also significant differences. Granularity and scope of interpretation vary: sentiment"
        },
        {
          "10\nComparative Analysis and Insights": "analysis typically deals with broad polarity (positive/negative/neutral), while emotion recognition"
        },
        {
          "10\nComparative Analysis and Insights": "aims for more specific affective states (joy, anger, etc.).\nStance detection focuses on a position"
        },
        {
          "10\nComparative Analysis and Insights": "towards a target, which can be distinct from general sentiment. Metaphor and sarcasm detection"
        },
        {
          "10\nComparative Analysis and Insights": "involve identifying specific figurative language constructs. Humor detection targets a particular"
        },
        {
          "10\nComparative Analysis and Insights": "communicative intent (to amuse). User intent detection is about identifying a goal or purpose, which"
        },
        {
          "10\nComparative Analysis and Insights": "may or may not be explicitly emotional or evaluative. Aesthetics identification deals with judgments"
        },
        {
          "10\nComparative Analysis and Insights": "of beauty or artistic merit, a highly abstract and culturally variable concept. The nature of the \"target\""
        },
        {
          "10\nComparative Analysis and Insights": "also differs: stance detection is explicitly target-dependent (e.g., stance towards a policy), whereas"
        },
        {
          "10\nComparative Analysis and Insights": "sentiment or emotion might be more general or directed at an unspecified entity. The type of reasoning"
        },
        {
          "10\nComparative Analysis and Insights": "required can also vary; metaphor interpretation often involves analogical reasoning, sarcasm detection"
        },
        {
          "10\nComparative Analysis and Insights": "requires recognizing incongruity and often negative intent, while humor detection might\ninvolve"
        },
        {
          "10\nComparative Analysis and Insights": "understanding punchlines or absurdity. These differences necessitate specialized approaches or"
        },
        {
          "10\nComparative Analysis and Insights": "fine-tuning for each task, even when leveraging general-purpose LLMs."
        },
        {
          "10\nComparative Analysis and Insights": "10.2\nTowards Unified Subjective Language Modeling: Potential of Multi-task LLM"
        },
        {
          "10\nComparative Analysis and Insights": "The shared characteristics among subjective language tasks, such as their reliance on context, implicit"
        },
        {
          "10\nComparative Analysis and Insights": "meaning, and nuanced interpretation, suggest a significant potential for unified subjective language"
        },
        {
          "10\nComparative Analysis and Insights": "modeling using multi-task LLMs. Instead of training separate models for sentiment analysis, emotion"
        },
        {
          "10\nComparative Analysis and Insights": "recognition, sarcasm detection, etc., a single, powerful LLM could be trained to perform all these tasks"
        },
        {
          "10\nComparative Analysis and Insights": "simultaneously or to share representations and knowledge across them. The underlying hypothesis is"
        },
        {
          "10\nComparative Analysis and Insights": "that understanding one aspect of subjectivity (e.g., emotion) can inform the understanding of others"
        },
        {
          "10\nComparative Analysis and Insights": "(e.g., sarcasm or humor). For example, recognizing that a statement conveys negative emotion might"
        },
        {
          "10\nComparative Analysis and Insights": "be a crucial cue for identifying sarcasm if the literal meaning is positive. A multi-task LLM could"
        },
        {
          "10\nComparative Analysis and Insights": "learn these inter-task relationships implicitly by being exposed to diverse subjective phenomena"
        },
        {
          "10\nComparative Analysis and Insights": "during training. This approach could lead to more robust and generalizable models, as knowledge"
        },
        {
          "10\nComparative Analysis and Insights": "acquired from one task with abundant data (e.g., sentiment analysis) could potentially benefit tasks"
        },
        {
          "10\nComparative Analysis and Insights": "with scarcer data (e.g., aesthetics identification)."
        },
        {
          "10\nComparative Analysis and Insights": "The development of such unified models faces challenges, including the need for large-scale, multi-"
        },
        {
          "10\nComparative Analysis and Insights": "task datasets where texts are annotated for multiple subjective attributes simultaneously. Designing"
        },
        {
          "10\nComparative Analysis and Insights": "effective multi-task learning architectures and training strategies that allow for positive knowledge"
        },
        {
          "10\nComparative Analysis and Insights": "transfer without negative interference (where learning one task harms another) is also critical. Fur-"
        },
        {
          "10\nComparative Analysis and Insights": "thermore,\nthe diverse output spaces of these tasks (e.g., categorical labels for sentiment, free-text"
        },
        {
          "10\nComparative Analysis and Insights": "descriptions for aesthetics) require flexible model architectures. However, the potential benefits are"
        },
        {
          "10\nComparative Analysis and Insights": "substantial. A unified model could offer a more holistic understanding of subjective language, captur-"
        },
        {
          "10\nComparative Analysis and Insights": "ing the interplay between different facets of human expression. It could also be more efficient in terms"
        },
        {
          "10\nComparative Analysis and Insights": "of development and deployment compared to maintaining multiple specialized models. Research in"
        },
        {
          "10\nComparative Analysis and Insights": "this direction is actively exploring how to best leverage the capabilities of large foundational models"
        },
        {
          "10\nComparative Analysis and Insights": "for a broad spectrum of subjective understanding tasks, aiming for AI systems that can comprehend"
        },
        {
          "10\nComparative Analysis and Insights": "the richness and complexity of human subjectivity in a more integrated manner."
        }
      ],
      "page": 31
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "The debate between multi-task fusion (training a single model on multiple tasks) and single-task"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "fine-tuning (fine-tuning a pre-trained LLM separately for each task) is central to developing effective"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "subjective language understanding systems. Each approach has its advantages and disadvantages,"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "and the optimal choice depends on circumstances,\nincluding data availability,\ntask similarity, and"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "computational resources. Single-task fine-tuning allows for specialization; the model can be optimized"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "extensively for the nuances of a particular task, potentially leading to higher performance on that"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "benchmark if sufficient task-specific data is available. This approach is straightforward to implement"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "and is widely used. However, it can lead to a proliferation of models if many subjective tasks need to"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "be handled, and it may not leverage the commonalities between related subjective phenomena."
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "Multi-task fusion, on the other hand, aims to train a single model that can perform across a range"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "of tasks. The advantage is knowledge transfer:\nlearning patterns useful for one task (e.g., detecting"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "negative sentiment) might help in another (e.g., detecting sarcasm, which often involves negative"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "sentiment). This can be particularly beneficial for tasks with limited labeled data, as the model can"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "leverage information from richer tasks. Multi-task learning can also lead to more generalizable and"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "robust representations that capture broader aspects of subjectivity. However, multi-task fusion is"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "more complex to design and train. Challenges include negative transfer (where learning one task"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "interferes with another), imbalanced task difficulties or data sizes, and the need for careful weighting"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "of task losses during training. The effectiveness of multi-task fusion often depends on the relatedness"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "of the tasks; tasks that share underlying linguistic or cognitive mechanisms are more likely to benefit"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "from joint training. Recent trends show a growing interest in exploring multi-task learning paradigms"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "with LLMs, often by extending pre-trained models with shared encoders and task-specific heads, or"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "by using prompts to guide the model towards different tasks. The ultimate goal is to find a balance"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "that harnesses the power of shared learning while preserving task-specific performance."
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "11\nChallenges and Open Issues"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "11.1\nTechnical Challenges"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "Despite the impressive capabilities of LLMs, several\ntechnical challenges persist\nin the domain"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "of subjective language understanding. A primary challenge is modeling ambiguity and nuance."
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "Subjective language is often inherently ambiguous, with meanings that can shift based on subtle"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "contextual cues, speaker intent, or cultural background. LLMs, while adept at pattern recognition,"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "can still struggle to capture these fine-grained distinctions, sometimes producing interpretations that"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "are too literal or that miss the underlying subtlety. For example, distinguishing between sarcasm and"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "genuine praise, or understanding a metaphor that relies on uncommon cultural knowledge, remains"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "difficult. Handling implicit meaning is another significant hurdle. Much of subjective expression is"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "not explicitly stated but rather implied through tone, figurative language, or shared understanding."
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "LLMs need to go beyond surface-level semantics to infer these implicit meanings accurately. This"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "requires not only vast amounts of training data but also sophisticated reasoning capabilities."
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "The reliability and bias in training data also pose major technical challenges. LLMs learn from the"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "data they are trained on, and if this data contains biases (e.g., cultural, gender, or racial biases) or"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "reflects subjective annotations with low inter-annotator agreement, these issues can be amplified and"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "perpetuated by the model. This can lead to unfair, inaccurate, or stereotypical outputs when dealing"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "with subjective content. Developing techniques for debiasing models and datasets, and for creating"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "more reliable and diverse annotations, is crucial. Furthermore, the computational cost and resource"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "intensiveness of training and deploying large LLMs limit their accessibility and practical application,"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "especially for real-time systems or in resource-constrained environments. While parameter-efficient"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "fine-tuning methods and model compression techniques offer some relief, achieving state-of-the-art"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "performance often still requires substantial resources. Finally, the \"black box\" nature of many LLMs"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "makes it difficult to interpret their reasoning processes, especially for complex subjective judgments."
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "Improving the explainability and interpretability of LLMs is essential\nfor building trust and for"
        },
        {
          "10.3\nMulti-task Fusion vs. Single-task Fine-tuning: Which Is More Effective?": "debugging models when they make errors in subjective understanding."
        }
      ],
      "page": 32
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "11.2": "",
          "Ethical and Societal Implications": "The application of LLMs to subjective language understanding raises significant ethical and societal"
        },
        {
          "11.2": "",
          "Ethical and Societal Implications": "implications that must be carefully considered. One major concern is the perpetuation and amplifica-"
        },
        {
          "11.2": "",
          "Ethical and Societal Implications": "tion of biases. LLMs trained on large, unfiltered datasets from the internet can learn and replicate"
        },
        {
          "11.2": "",
          "Ethical and Societal Implications": "societal biases related to gender, race, ethnicity, religion, and other sensitive attributes. When these"
        },
        {
          "11.2": "",
          "Ethical and Societal Implications": "models are used for tasks like sentiment analysis, emotion recognition, or content moderation, they"
        },
        {
          "11.2": "",
          "Ethical and Societal Implications": "may produce biased or unfair outcomes, leading to discrimination or the marginalization of certain"
        },
        {
          "11.2": "",
          "Ethical and Societal Implications": "groups. For example, a sentiment analysis model might misinterpret expressions from a particular"
        },
        {
          "11.2": "",
          "Ethical and Societal Implications": "dialect or cultural group due to a lack of representation in its training data. Privacy concerns are"
        },
        {
          "11.2": "",
          "Ethical and Societal Implications": "also paramount, especially when LLMs are used to analyze personal communications or expressions"
        },
        {
          "11.2": "",
          "Ethical and Societal Implications": "of emotion. The data used to train these models, or the data they process in deployment, might"
        },
        {
          "11.2": "",
          "Ethical and Societal Implications": "contain sensitive personal information. Ensuring that this data is handled securely and ethically, with"
        },
        {
          "11.2": "appropriate consent and anonymization, is critical.",
          "Ethical and Societal Implications": ""
        },
        {
          "11.2": "Another issue is the potential for manipulation and misuse. LLMs that can understand and generate",
          "Ethical and Societal Implications": ""
        },
        {
          "11.2": "",
          "Ethical and Societal Implications": "subjective language could be used to create persuasive or manipulative content, such as misinfor-"
        },
        {
          "11.2": "",
          "Ethical and Societal Implications": "mation, propaganda, or targeted scams. The ability to mimic human-like empathy or opinion could"
        },
        {
          "11.2": "",
          "Ethical and Societal Implications": "be exploited to deceive users or influence public opinion in unethical ways. The impact on human"
        },
        {
          "11.2": "",
          "Ethical and Societal Implications": "communication and creativity is also a concern. Over-reliance on AI for tasks like writing, artistic"
        },
        {
          "11.2": "",
          "Ethical and Societal Implications": "judgment, or emotional support could potentially diminish human skills in these areas or lead to a"
        },
        {
          "11.2": "",
          "Ethical and Societal Implications": "homogenization of expression. Furthermore, the deployment of subjective language understanding"
        },
        {
          "11.2": "systems in areas like hiring,",
          "Ethical and Societal Implications": "loan applications, or criminal"
        },
        {
          "11.2": "",
          "Ethical and Societal Implications": "fairness, accountability, and due process, especially if the decision-making processes of these systems"
        },
        {
          "11.2": "",
          "Ethical and Societal Implications": "are not transparent or are found to be biased. Addressing these ethical and societal challenges requires"
        },
        {
          "11.2": "",
          "Ethical and Societal Implications": "a multi-faceted approach involving researchers, policymakers, and industry stakeholders to develop"
        },
        {
          "11.2": "",
          "Ethical and Societal Implications": "robust ethical guidelines, fairness-aware algorithms, and appropriate regulatory frameworks."
        }
      ],
      "page": 33
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "12\nConclusion": "12.1\nSummary of Findings"
        },
        {
          "12\nConclusion": "This survey has provided a comprehensive overview of the state of subjective language understanding"
        },
        {
          "12\nConclusion": "with Large Language Models (LLMs), covering key tasks such as sentiment analysis, emotion"
        },
        {
          "12\nConclusion": "recognition, sarcasm detection, humor detection, stance detection, metaphor recognition, user intent"
        },
        {
          "12\nConclusion": "detection, and aesthetics identification. We have seen that LLMs, with their capabilities in contextual"
        },
        {
          "12\nConclusion": "understanding and semantic representation, have advanced the performance on these tasks compared"
        },
        {
          "12\nConclusion": "to traditional methods. The evolution of language models, particularly the advent of Transformer-"
        },
        {
          "12\nConclusion": "based architectures and large-scale pre-training, has been instrumental\nin this progress. Various"
        },
        {
          "12\nConclusion": "approaches, including prompt-based learning, supervised fine-tuning (SFT), and reasoning-based"
        },
        {
          "12\nConclusion": "methods, are being employed to adapt LLMs to the nuances of subjective language. Multi-model and"
        },
        {
          "12\nConclusion": "multimodal LLMs are also emerging as powerful tools for handling the complexities of subjective"
        },
        {
          "12\nConclusion": "expression, especially when it involves multiple sources of information."
        },
        {
          "12\nConclusion": "However, the survey also highlights that challenges remain. The inherent subjectivity, ambiguity, and"
        },
        {
          "12\nConclusion": "context-dependency of language pose difficulties for LLMs. Tasks like sarcasm detection, metaphor"
        },
        {
          "12\nConclusion": "interpretation, and aesthetics identification, which require understanding of implicit meaning and"
        },
        {
          "12\nConclusion": "cultural nuances, are particularly challenging. Issues such as bias in training data, the computational"
        },
        {
          "12\nConclusion": "cost of LLMs, and the \"black box\" nature of their decision-making processes need to be addressed."
        },
        {
          "12\nConclusion": "The comparative analysis revealed both similarities and differences among subjective tasks, pointing"
        },
        {
          "12\nConclusion": "towards the potential for unified modeling approaches but also the need for task-specific consider-"
        },
        {
          "12\nConclusion": "ations. Ethical and societal implications, including privacy concerns and the potential for misuse,"
        },
        {
          "12\nConclusion": "underscore the importance of responsible development and deployment of these technologies."
        },
        {
          "12\nConclusion": "12.2\nSubjective Language Understanding as a Key Direction for Future LLM Research"
        },
        {
          "12\nConclusion": "Subjective language understanding stands as a critical and challenging frontier\nfor\nfuture LLM"
        },
        {
          "12\nConclusion": "research. As LLMs become increasingly integrated into human-facing applications,\ntheir ability"
        },
        {
          "12\nConclusion": "to accurately perceive,\ninterpret, and respond to the rich tapestry of human emotions, opinions,"
        },
        {
          "12\nConclusion": "intentions, and figurative expressions becomes paramount for creating truly intelligent and empathetic"
        },
        {
          "12\nConclusion": "AI systems. The nuances of subjective language—sarcasm, humor, metaphor, aesthetic judgment—are"
        },
        {
          "12\nConclusion": "fundamental to human communication and social interaction. Mastering these aspects will enable"
        },
        {
          "12\nConclusion": "LLMs to move beyond mere information processing to engage in more natural, meaningful, and"
        },
        {
          "12\nConclusion": "contextually aware dialogues. Future research in this area will not only push the boundaries of"
        },
        {
          "12\nConclusion": "NLP but also contribute to a deeper understanding of human cognition and language itself. The"
        },
        {
          "12\nConclusion": "development of LLMs that can robustly handle subjectivity will unlock new possibilities in areas such"
        },
        {
          "12\nConclusion": "as personalized education, mental health support, creative arts, and cross-cultural communication,"
        },
        {
          "12\nConclusion": "making AI a more valuable and trustworthy partner in various aspects of human life."
        },
        {
          "12\nConclusion": "The challenges inherent in subjective language understanding, such as ambiguity, context-dependency,"
        },
        {
          "12\nConclusion": "and cultural variability, necessitate innovation in LLM architectures, training methodologies, and"
        },
        {
          "12\nConclusion": "evaluation techniques. Future research should focus on enhancing LLMs’ reasoning capabilities,"
        },
        {
          "12\nConclusion": "ability to integrate commonsense and world knowledge, and capacity to learn from limited or noisy"
        },
        {
          "12\nConclusion": "data. Exploring multimodal approaches that combine text with other sensory inputs will be crucial"
        },
        {
          "12\nConclusion": "for a holistic understanding of subjective expression. Furthermore, addressing issues of bias, fairness,"
        },
        {
          "12\nConclusion": "and interpretability will be essential for building trustworthy and ethically sound subjective language"
        },
        {
          "12\nConclusion": "understanding systems. The insights gained from tackling subjective language will likely also benefit"
        },
        {
          "12\nConclusion": "other areas of AI, leading to more robust and human-like machine intelligence overall."
        },
        {
          "12\nConclusion": "12.3\nCalling for a Unified Research Framework and Evaluation Benchmarks"
        },
        {
          "12\nConclusion": "To systematically advance the field of subjective language understanding with LLMs,\nthere is a"
        },
        {
          "12\nConclusion": "pressing need for a unified research framework and standardized evaluation benchmarks. Currently,"
        },
        {
          "12\nConclusion": "research efforts are often fragmented, with different studies using varied datasets, evaluation metrics,"
        },
        {
          "12\nConclusion": "and experimental setups, making it difficult\nto compare results and track progress effectively. A"
        },
        {
          "12\nConclusion": "unified framework would provide common definitions, taxonomies, and methodological guidelines"
        },
        {
          "12\nConclusion": "for studying subjective language. This would facilitate collaboration, reproducibility, and the sharing"
        },
        {
          "12\nConclusion": "of insights across different research groups and tasks. Such a framework should encompass the"
        }
      ],
      "page": 34
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "diverse aspects of subjectivity, from affective states and opinions to figurative language and aesthetic": "judgments, acknowledging their interconnections while also respecting their unique characteristics."
        },
        {
          "diverse aspects of subjectivity, from affective states and opinions to figurative language and aesthetic": "Crucially, the development of comprehensive and challenging evaluation benchmarks is essential."
        },
        {
          "diverse aspects of subjectivity, from affective states and opinions to figurative language and aesthetic": "These benchmarks should go beyond simple accuracy metrics and aim to assess LLMs’ abilities"
        },
        {
          "diverse aspects of subjectivity, from affective states and opinions to figurative language and aesthetic": "to handle nuance, ambiguity, context-dependency, and cultural diversity.\nThey should include"
        },
        {
          "diverse aspects of subjectivity, from affective states and opinions to figurative language and aesthetic": "datasets that represent a wide range of subjective phenomena, languages, and domains, including"
        },
        {
          "diverse aspects of subjectivity, from affective states and opinions to figurative language and aesthetic": "carefully curated adversarial examples to test model robustness. Human evaluation, involving diverse"
        },
        {
          "diverse aspects of subjectivity, from affective states and opinions to figurative language and aesthetic": "annotators, should be an integral part of these benchmarks to provide a more holistic assessment of"
        },
        {
          "diverse aspects of subjectivity, from affective states and opinions to figurative language and aesthetic": "model performance aligned with human judgment. Furthermore, benchmarks should be designed to"
        },
        {
          "diverse aspects of subjectivity, from affective states and opinions to figurative language and aesthetic": "probe not only the \"what\" (e.g., correct classification) but also the \"why\" (e.g., model’s reasoning"
        },
        {
          "diverse aspects of subjectivity, from affective states and opinions to figurative language and aesthetic": "process, where feasible). By establishing such a unified framework and robust benchmarks,\nthe"
        },
        {
          "diverse aspects of subjectivity, from affective states and opinions to figurative language and aesthetic": "research community can accelerate progress towards LLMs that can truly understand and engage"
        },
        {
          "diverse aspects of subjectivity, from affective states and opinions to figurative language and aesthetic": "with the complexities of human subjective experience."
        },
        {
          "diverse aspects of subjectivity, from affective states and opinions to figurative language and aesthetic": "References"
        }
      ],
      "page": 35
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "with the complexities of human subjective experience.": "References"
        },
        {
          "with the complexities of human subjective experience.": "[1]\nJosh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni"
        },
        {
          "with the complexities of human subjective experience.": "Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4"
        },
        {
          "with the complexities of human subjective experience.": "technical report. arXiv preprint arXiv:2303.08774, 2023."
        },
        {
          "with the complexities of human subjective experience.": "[2] Rodrigo Agerri, Roberto Centeno, Marıa Espinosa, Joseba Fernandez de Landa, and Alvaro"
        },
        {
          "with the complexities of human subjective experience.": "Rodrigo. Vaxxstance: A dataset for cross-lingual stance detection on vaccines. 2021."
        },
        {
          "with the complexities of human subjective experience.": "[3] Mariana Água, Nuno António, Marco P Carrasco, and Carimo Rassal.\nLarge language"
        },
        {
          "with the complexities of human subjective experience.": "models powered aspect-based sentiment analysis for enhanced customer insights. Tourism &"
        },
        {
          "with the complexities of human subjective experience.": "Management Studies, 21(1):1–19, 2025."
        },
        {
          "with the complexities of human subjective experience.": "[4] Rabbia Ahmed, Sadaf Abdul Rauf, and Seemab Latif. Leveraging large language models"
        },
        {
          "with the complexities of human subjective experience.": "and prompt settings for context-aware financial sentiment analysis.\nIn 2024 5th International"
        },
        {
          "with the complexities of human subjective experience.": "Conference on Advancements in Computational Sciences (ICACS), pages 1–9. IEEE, 2024."
        },
        {
          "with the complexities of human subjective experience.": "[5] Emily Allaway and Kathleen McKeown. Zero-shot stance detection: A dataset and model"
        },
        {
          "with the complexities of human subjective experience.": "using generalized topic representations. arXiv preprint arXiv:2010.03640, 2020."
        },
        {
          "with the complexities of human subjective experience.": "[6] Nora Saleh Alturayeif, Hamzah Abdullah Luqman, and Moataz Aly Kamaleldin Ahmed."
        },
        {
          "with the complexities of human subjective experience.": "Mawqif: A multi-label arabic dataset for target-specific stance detection.\nIn Proceedings of"
        },
        {
          "with the complexities of human subjective experience.": "the Seventh Arabic Natural Language Processing Workshop (WANLP), pages 174–184, 2022."
        },
        {
          "with the complexities of human subjective experience.": "[7]\nIkhlasul Amal and Annisa Nur Ramadhani. How well do vision-language models explain"
        },
        {
          "with the complexities of human subjective experience.": "sarcasm? an evaluation of multimodal explanation quality for social media posts. Artificial"
        },
        {
          "with the complexities of human subjective experience.": "Intelligence Systems and Its Applications, 1(1):31–55, 2025."
        },
        {
          "with the complexities of human subjective experience.": "Intent detection in the age of llms. arXiv\n[8] Gaurav Arora, Shreya Jain, and Srujana Merugu."
        },
        {
          "with the complexities of human subjective experience.": "preprint arXiv:2410.01627, 2024."
        },
        {
          "with the complexities of human subjective experience.": "[9] Petra Bago and Nikola Bakari´c. Few-shot prompting, full-scale confusion: Evaluating large"
        },
        {
          "with the complexities of human subjective experience.": "language models for humor detection in croatian tweets.\nIn Proceedings of the 10th Workshop"
        },
        {
          "with the complexities of human subjective experience.": "on Slavic Natural Language Processing (Slavic NLP 2025), pages 9–16, 2025."
        },
        {
          "with the complexities of human subjective experience.": "[10] Ashwin Baluja. Text is not all you need: Multimodal prompting helps llms understand humor."
        },
        {
          "with the complexities of human subjective experience.": "arXiv preprint arXiv:2412.05315, 2024."
        },
        {
          "with the complexities of human subjective experience.": "[11] Hui Bao, Kai He, Yige Wang, and Zeyu Gao.\nExploring cognitive difference in poetry"
        },
        {
          "with the complexities of human subjective experience.": "collection via large language models and metaphors: A case study of\nthe book of songs."
        },
        {
          "with the complexities of human subjective experience.": "Cognitive Computation, 17(3):106, 2025."
        },
        {
          "with the complexities of human subjective experience.": "[12] Naman Bhargava, Mohammed I Radaideh, O Hwang Kwon, Aditi Verma, and Majdi\nI"
        },
        {
          "with the complexities of human subjective experience.": "Radaideh. On the impact of language nuances on sentiment analysis with large language"
        },
        {
          "with the complexities of human subjective experience.": "models: Paraphrasing, sarcasm, and emojis. arXiv preprint arXiv:2504.05603, 2025."
        }
      ],
      "page": 35
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "Simons, and Liang Ze Wong. Rethinking stance detection: A theoretically-informed research"
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "agenda for user-level\ninference using language models.\narXiv preprint arXiv:2502.02074,"
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "2025."
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "[14] Swapnil Bhosale, Abhra Chaudhuri, Alex Lee Robert Williams, Divyank Tiwari, Anjan Dutta,"
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "Xiatian Zhu, Pushpak Bhattacharyya, and Diptesh Kanojia.\nSarcasm in sight and sound:"
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "arXiv preprint\nBenchmarking and expansion to improve multimodal sarcasm detection."
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "arXiv:2310.01430, 2023."
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "Julia Birke. A clustering approach for the unsupervised recognition of nonliteral language.\n[15]"
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "2005."
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "[16]\nJoanne Boisson, Asahi Ushio, Hsuvas Borkakoty, Kiamehr Rezaee, Dimosthenis Antypas, Zara"
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "Siddique, Nina White, and Jose Camacho-Collados. How are metaphors processed by language"
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "the 28th Conference on Computational\nmodels?\nthe case of analogies.\nIn Proceedings of"
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "Natural Language Learning, pages 365–387, 2024."
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "[17] Diederik Booij. Mememind framework: Leveraging large language models for meme classifi-"
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "cation and xai. Master’s thesis, 2025."
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "[18] Maddalena Bressler, Veronica Mangiaterra, Paolo Canal, Federico Frau, Fabrizio Luciani,"
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "Biagio Scalingi, Chiara Barattieri di San Pietro, Chiara Battaglini, Chiara Pompei, Fortunata"
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "Romeo, et al. Figurative archive: an open dataset and web-based application for the study of"
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "metaphor. arXiv preprint arXiv:2503.00444, 2025."
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "[19] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhari-"
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "wal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language"
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "models are few-shot learners. Advances in neural information processing systems, 33:1877–"
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "1901, 2020."
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "[20] Carlos Carrasco-Farre.\nLarge language models are as persuasive as humans, but how?"
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "about\nthe cognitive effort and moral-emotional\nlanguage of llm arguments. arXiv preprint"
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "arXiv:2404.09329, 2024."
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "[21] Santiago Castro, Devamanyu Hazarika, Verónica Pérez-Rosas, Roger Zimmermann, Rada"
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "Mihalcea, and Soujanya Poria. Towards multimodal sarcasm detection (an _obviously_ perfect"
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "paper). arXiv preprint arXiv:1906.01815, 2019."
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "[22] Tuhin Chakrabarty, Arkadiy Saakyan, Olivia Winn, Artemis Panagopoulou, Yue Yang, Mar-"
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "ianna Apidianaki, and Smaranda Muresan.\nI spy a metaphor: Large language models and"
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "diffusion models co-create visual metaphors. arXiv preprint arXiv:2305.14724, 2023."
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "[23] Rohitash Chandra, Abhishek Tiwari, Naman Jain, and Sushrut Badhe. Large language models"
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "for metaphor detection: Bhagavad gita and sermon on the mount.\nIEEE Access, 12:84452–"
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "84469, 2024."
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "Semeval-2016 task 9: Chinese se-\n[24] Wanxiang Che, Yanqiu Shao, Ting Liu, and Yu Ding."
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "mantic dependency parsing.\nIn Proceedings of the 10th International Workshop on Semantic"
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "Evaluation (SemEval-2016), pages 1074–1080, 2016."
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "[25] Kai Chen, Yunhao Gou, Runhui Huang, Zhili Liu, Daxin Tan, Jing Xu, Chunwei Wang,"
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "Yi Zhu, Yihan Zeng, Kuo Yang, et al. Emova: Empowering language models to see, hear and"
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "speak with vivid emotions.\nIn Proceedings of the Computer Vision and Pattern Recognition"
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "Conference, pages 5455–5466, 2025."
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "[26] Sihao Chen, Daniel Khashabi, Wenpeng Yin, Chris Callison-Burch, and Dan Roth. Seeing"
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "things from a different angle: Discovering diverse perspectives about claims. arXiv preprint"
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "arXiv:1906.03538, 2019."
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "[27] Weisi Chen, Wulong Liu, Jiaxin Zheng, and Xu Zhang. Leveraging large language model as"
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "news sentiment predictor in stock markets: a knowledge-enhanced strategy. Discov. Comput.,"
        },
        {
          "[13] Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph JP": "28(1):74, 2025."
        }
      ],
      "page": 36
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": ""
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": ""
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": "[29] Yuyan Chen and Yanghua Xiao. Recent advancement of emotion cognition in large language"
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": ""
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": "[30] Yuyan Chen, Yichen Yuan, Panjun Liu, Dayiheng Liu, Qinghao Guan, Mengfei Guo, Haiming"
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": ""
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": ""
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": ""
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": "[31] Zebang Cheng, Zhi-Qi Cheng, Jun-Yan He, Kai Wang, Yuxiang Lin, Zheng Lian, Xiaojiang"
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": ""
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": ""
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": ""
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": "[32] Wei-Lin Chiang, Zhuohan Li, Ziqing Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin"
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": ""
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": ""
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": ""
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": "[33]"
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": ""
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": ""
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": "[34] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam"
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": ""
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": ""
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": ""
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": "[35] Genan Dai, Jiayu Liao, Sicheng Zhao, Xianghua Fu, Xiaojiang Peng, Hu Huang, and Bowen"
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": ""
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": ""
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": "[36] Dorottya Demszky, Dana Movshovitz-Attias, Jeongwoo Ko, Alan Cowen, Gaurav Nemade, and"
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": ""
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": ""
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": "[37] Shiling Deng, Serge Belongie, and Peter Ebert Christensen. Large vision-language models for"
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": ""
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": ""
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": ""
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": ""
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": "[39] Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. Qlora: Efficient"
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": ""
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": ""
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": "[40]"
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": ""
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": ""
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": ""
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": "[41] Daijun Ding, Rong Chen, Liwen Jing, Bowen Zhang, Xu Huang, Li Dong, Xiaowen Zhao,"
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": ""
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": ""
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": ""
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": "[42] Daijun Ding, Genan Dai, Cheng Peng, Xiaojiang Peng, Bowen Zhang, and Hu Huang. Dis-"
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": ""
        },
        {
          "[28] Yuyan Chen, Hao Wang, Songzhou Yan, Sijia Liu, Yueze Li, Yi Zhao, and Yanghua Xiao.": ""
        }
      ],
      "page": 37
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "Leveraging chain-of-thought to enhance stance detection with prompt-tuning. Mathematics,"
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "12(4):568, 2024."
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "[44] Hongcheng Ding, Xuanze Zhao, Ruiting Deng, Shamsul Nahar Abdullah, Deshinta Arrova"
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "Dewi, and Zixiao Jiang. Dynamic adaptive optimization for effective sentiment analysis"
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "fine-tuning on large language models. arXiv preprint arXiv:2408.11856, 2024."
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "[45] Xuanwen Ding, Jie Zhou, Liang Dou, Qin Chen, Yuanbin Wu, Chengcai Chen, and Liang He."
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "Boosting large language models with continual learning for aspect-based sentiment analysis."
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "CoRR, abs/2405.05496, 2024."
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "[46] PV DiStefano, JD Patterson, and R Beaty. Automatic scoring of metaphor creativity with large"
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "language models. psyarxiv, 2023."
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "[47] Zhongren Dong, Donghao Wang, Ciqiang Chen, Dong-Yan Huang, and Zixing Zhang. Mhsdb:"
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "A comprehensive benchmark for multimodal humor and sarcasm detection leveraging founda-"
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "tion models.\nIn ICASSP 2025-2025 IEEE International Conference on Acoustics, Speech and"
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "Signal Processing (ICASSP), pages 1–5. IEEE, 2025."
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "[48] Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle,"
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al. The llama 3 herd"
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "of models. arXiv e-prints, pages arXiv–2407, 2024."
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "[49]\nJeffrey L Elman. Finding structure in time. Cognitive science, 14(2):179–211, 1990."
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "[50] Pierre Epron, Gaël Guibon, and Miguel Couceiro. Orpailleur & synalp at clef 2024 task 2:"
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "Good old cross validation for large language models yields the best humorous detection.\nIn"
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "Working Notes of the Conference and Labs of the Evaluation Forum (CLEF 2024), volume"
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "3740, pages 1841–1856. CEUR-WS. org, 2024."
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "[51] Qinlong Fan, Jicang Lu, Yepeng Sun, Qiankun Pi, and Shouxin Shang. Enhancing zero-shot"
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "stance detection via multi-task fine-tuning with debate data and knowledge augmentation."
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "Complex & Intelligent Systems, 11(2):151, 2025."
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "[52] Shutong Feng, Nurul Lubis, Christian Geishauser, Hsien-chin Lin, Michael Heck, Carel van"
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "Niekerk, and Milica Gaši´c. Emowoz: A large-scale corpus and labelling scheme for emotion"
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "recognition in task-oriented dialogue systems. arXiv preprint arXiv:2109.04919, 2021."
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "[53] Margherita Gambini, Caterina Senette, Tiziano Fagni, and Maurizio Tesconi. Evaluating large"
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "language models for user stance detection on x (twitter). Machine Learning, 113(10):7243–"
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "7266, 2024."
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "[54] Himanshu Gautam, Abhishek Gaur, and Dharmendra Kumar Yadav. A survey on the impact"
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "International Journal of Data\nof pre-trained language models in sentiment classification task."
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "Science and Analytics, pages 1–39, 2025."
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "[55] Kyle Glandt, Sarthak Khanal, Yingjie Li, Doina Caragea, and Cornelia Caragea.\nStance"
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "detection in covid-19 tweets.\nIn Proceedings of the 59th annual meeting of the association"
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "for computational linguistics and the 11th international joint conference on natural language"
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "processing (long papers), volume 1, 2021."
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "[56] M Gole, WP Nwadiugwu, and A Miranskyy. On sarcasm detection with openai gpt-based"
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "models. 2023. URL: https://doi. org/10.48550/arXiv, 2312."
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "[57] Montgomery Gole, Williams-Paul Nwadiugwu, and Andriy Miranskyy. On sarcasm detection"
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "with openai gpt-based models.\nIn 2024 34th International Conference on Collaborative"
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "Advances in Software and COmputiNg (CASCON), pages 1–6. IEEE, 2024."
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "[58] Gamze Goren and Carlo Strapparava. Context matters: Enhancing metaphor recognition"
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "the 2024 Joint International Conference on Computational\nin proverbs.\nIn Proceedings of"
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pages 3825–3830,"
        },
        {
          "[43] Daijun Ding, Xianghua Fu, Xiaojiang Peng, Xiaomao Fan, Hu Huang, and Bowen Zhang.": "2024."
        }
      ],
      "page": 38
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "large language models. arXiv preprint arXiv:2404.12171, 2024."
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "[60] Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu,"
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "Shirong Ma, Peiyi Wang, Xiao Bi, et al. Deepseek-r1: Incentivizing reasoning capability in"
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "llms via reinforcement learning. arXiv preprint arXiv:2501.12948, 2025."
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "[61] Yihui Guo. A cross-cultural study of humor intensity in chinese and english family jokes: A"
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "large language model-based approach. International Journal of Linguistics Studies, 5(2):01–10,"
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "2025."
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "[62] Ankita Gupta, Douglas Rice, and Brendan O’Connor.\n-stance: A large-scale real world"
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "dataset of stances in legal argumentation.\nIn Proceedings of the 63rd Annual Meeting of the"
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "Association for Computational Linguistics (Volume 1: Long Papers), pages 31450–31467,"
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "2025."
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "[63] Yi Han and Mohsen Moghaddam. Design knowledge as attention emphasizer in large lan-"
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "Journal of Computing and Information Science in\nguage model-based sentiment analysis."
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "Engineering, 25(2):021007, 2025."
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "[64] Lu He, Samaneh Omranian, Susan McRoy, and Kai Zheng. Using large language models for"
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "sentiment analysis of health-related social media data: empirical evaluation and practical tips."
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "medRxiv, 2024."
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "[65] Ruiqi He, Yushu He, Longju Bai, Jiarui Liu, Zhenjie Sun, Zenghao Tang, He Wang, Hanchen"
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "Xia, and Naihao Deng. Chumor 1.0: A truly funny and challenging chinese humor understand-"
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "ing dataset from ruo zhi ba. arXiv preprint arXiv:2406.12754, 2024."
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "[66] Ruiqi He, Yushu He, Longju Bai, Jiarui Liu, Zhenjie Sun, Zenghao Tang, He Wang, Hanchen"
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "Xia, Rada Mihalcea, and Naihao Deng. Chumor 2.0: Towards better benchmarking chinese"
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "the Association for Computational\nhumor understanding from (ruo zhi ba).\nIn Findings of"
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "Linguistics: ACL 2025, pages 21799–21818, 2025."
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "[67] Marc Heimann and Anne-Friederike Hübener. The extimate core of understanding: absolute"
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "metaphors, psychosis and large language models. AI & SOCIETY, 40(3):1265–1276, 2025."
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "[68] Nils Constantin Hellwig, Jakob Fehle, and Christian Wolff. Exploring large language models"
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "for the generation of synthetic training samples for aspect-based sentiment analysis in low"
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "resource settings. Expert Syst. Appl., 261:125514, 2025."
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "[69] Fachry Dennis Heraldi and Zakhralativa Ruskanda. Effective intended sarcasm detection using"
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "fine-tuned llama 2 large language models. In 2024 11th International Conference on Advanced"
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "Informatics: Concept, Theory and Application (ICAICTA), pages 1–6. IEEE, 2024."
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "[70] Xin Hong, Yuan Gong, Vidhyasaharan Sethu, and Ting Dang. Aer-llm: Ambiguity-aware emo-"
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "tion recognition leveraging large language models.\nIn ICASSP 2025-2025 IEEE International"
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 1–5. IEEE, 2025."
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "[71] Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang,"
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "Lu Wang, Weizhu Chen, et al. Lora: Low-rank adaptation of large language models.\nICLR,"
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "1(2):3, 2022."
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "[72] H Hu, Y Zhou, L You, H Xu, Q Wang, Z Lian, FR Yu, F Ma, and L Cui. Emobench-m:"
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "Benchmarking emotional intelligence for multimodal large language models (2025)."
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "[73] Zhe Hu, Tuo Liang, Jing Li, Yiren Lu, Yunlai Zhou, Yiran Qiao, Jing Ma, and Yu Yin. Cracking"
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "the code of juxtaposition: Can ai models understand the humorous contradictions. Advances"
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "in Neural Information Processing Systems, 37:47166–47188, 2024."
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "[74] Aaron Hurst, Adam Lerer, Adam P Goucher, Adam Perelman, Aditya Ramesh, Aidan Clark,"
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "AJ Ostrow, Akila Welihinda, Alan Hayes, Alec Radford, et al. Gpt-4o system card. arXiv"
        },
        {
          "[59]\nIlker Gül, Rémi Lebret, and Karl Aberer. Stance detection on social media with fine-tuned": "preprint arXiv:2410.21276, 2024."
        }
      ],
      "page": 39
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "explanation using the information bottleneck principle.\narXiv preprint arXiv:2502.18331,"
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "2025."
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "[76] Nicholas Ichien, Du Stamenkoviƒá, Keith Holyoak, et al.\nInterpretation of novel\nliterary"
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "the Annual Meeting of\nthe Cognitive\nmetaphors by humans and gpt-4.\nIn Proceedings of"
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "Science Society, volume 46, 2024."
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "[77] Pau Rodriguez Inserte, Mariam Nakhlé, Raheel Qader, Gaetan Caillaut, and Jingshu Liu. Large"
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "language model adaptation for financial sentiment analysis. arXiv preprint arXiv:2401.14777,"
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "2024."
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "[78] Veedant Jain, Felipe dos Santos Alves Feitosa, and Gabriel Kreiman.\nIs ai fun? humordb: a cu-"
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "rated dataset and benchmark to investigate graphical humor. arXiv preprint arXiv:2406.13564,"
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "2024."
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "[79] Soumyadeep Jana, Abhrajyoti Kundu, and Sanasam Ranbir Singh. Dual modality-aware gated"
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "prompt tuning for few-shot multimodal sarcasm detection. arXiv preprint arXiv:2507.04468,"
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "2025."
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "[80] Soumyadeep Jana, Abhrajyoti Kundu, and Sanasam Ranbir Singh. Think twice before you"
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "judge: Mixture of dual reasoning experts for multimodal sarcasm detection. arXiv preprint"
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "arXiv:2507.04458, 2025."
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "[81] Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh"
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile"
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "Saulnier, Lélio Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut"
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "Lavril, Thomas Wang, Timothée Lacroix, and William El Sayed. Mistral 7b, 2023."
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "[82] Albert Q Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris"
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "Bamford, Devendra Singh Chaplot, Diego de las Casas, Emma Bou Hanna, Florian Bressand,"
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "et al. Mixtral of experts. arXiv preprint arXiv:2401.04088, 2024."
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "[83] Dongjin Kang, Sunghwan Kim, Taeyoon Kwon, Seungjun Moon, Hyunsouk Cho, Youngjae Yu,"
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "Dongha Lee, and Jinyoung Yeo. Can large language models be good emotional supporter? mit-"
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "igating preference bias on emotional support conversation. arXiv preprint arXiv:2402.13211,"
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "2024."
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "[84] Alina Karakanta, Mayra Nas, and Aletta G Dorst. Metaphors in literary machine translation:"
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "Close but no cigar?\nProceedings of Machine Translation Summit XX Volume, 1:276–286,"
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "2025."
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "[85] Kiana Kheiri and Hamid Karimi. Sentimentgpt: Exploiting gpt for advanced sentiment analysis"
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "and its departure from current machine learning. arXiv preprint arXiv:2307.10234, 2023."
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "[86] Mikhail Khodak, Nikunj Saunshi, and Kiran Vodrahalli. A large self-annotated corpus for"
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "sarcasm.\nIn Proceedings of the Linguistic Resource and Evaluation Conference (LREC), 2018."
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "[87]\nJeongyeon Kim, Sangho Suh, Lydia B Chilton, and Haijun Xia. Metaphorian: Leveraging large"
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "language models to support extended metaphor creation for science writing.\nIn Proceedings of"
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "the 2023 ACM Designing Interactive Systems Conference, pages 115–135, 2023."
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "[88] Kemal Kirtac and Guido Germano.\nLarge language models in finance: what\nis financial"
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "sentiment? arXiv preprint arXiv:2503.03612, 2025."
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "[89] Beata Beigman Klebanov, Chee Wee Leong, and Michael Flor. A corpus of non-native written"
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "english annotated for metaphor.\nIn Proceedings of the 2018 Conference of the North American"
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "Chapter of the Association for Computational Linguistics: Human Language Technologies,"
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "Volume 2 (Short Papers), pages 86–91, 2018."
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "[90] Alapan Kuila and Sudeshna Sarkar. Deciphering political entity sentiment in news with large"
        },
        {
          "[75] EunJeong Hwang, Peter West, and Vered Shwartz.\nBottlehumor:\nSelf-informed humor": "language models: Zero-shot and few-shot strategies. arXiv preprint arXiv:2404.04361, 2024."
        }
      ],
      "page": 40
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "Joynt, and Majdi I Radaideh. Sentiment analysis of the united states public support of nuclear"
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "power on social media using large language models. Renewable and Sustainable Energy"
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "Reviews, 200:114570, 2024."
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "[92] Xiaochong Lan, Chen Gao, Depeng Jin, and Yong Li. Stance detection with collaborative"
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "role-infused llm-based agents.\nIn Proceedings of the international AAAI conference on web"
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "and social media, volume 18, pages 891–903, 2024."
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "[93] Yinyu Lan, Yanru Wu, Wang Xu, Weiqiang Feng, and Youhao Zhang. Chinese fine-grained"
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "financial sentiment analysis with large language models. CoRR, abs/2306.14096, 2023."
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "[94]\nJaewook Lee, Woojin Lee, Oh-Woog Kwon, and Harksoo Kim. Do large language models"
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "have “emotion neurons”? investigating the existence and role.\nIn Findings of the Association"
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "for Computational Linguistics: ACL 2025, pages 15617–15639, 2025."
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "[95]\nJoshua Lee, Wyatt Fong, Alexander Le, Sur Shah, Kevin Han, and Kevin Zhu. Pragmatic"
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "arXiv preprint\nmetacognitive prompting improves llm performance on sarcasm detection."
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "arXiv:2412.04509, 2024."
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "Jiawei Chen, Peng Zhai, and Lihua Zhang.\n[96] Yuxuan Lei, Dingkang Yang, Zhaoyu Chen,"
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "Large vision-language models as emotion recognizers in context awareness. arXiv preprint"
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "arXiv:2407.11300, 2024."
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "[97] Cheng Li, Jindong Wang, Yixuan Zhang, Kaijie Zhu, Wenxin Hou, Jianxun Lian, Fang Luo,"
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "Qiang Yang, and Xing Xie.\nLarge language models understand and can be enhanced by"
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "emotional stimuli. arXiv preprint arXiv:2307.11760, 2023."
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "[98] Deng Li, Bohao Xing, Xin Liu, Baiqiang Xia, Bihan Wen, and Heikki Kälviäinen. Deemo:"
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "De-identity multimodal emotion recognition and reasoning. arXiv preprint arXiv:2504.19549,"
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "2025."
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "[99] Yingjie Li, Tiberiu Sosea, Aditya Sawant, Ajith Jayaraman Nair, Diana Inkpen, and Cornelia"
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "Caragea. P-stance: A large dataset for stance detection in political domain.\nIn Findings of the"
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "association for computational linguistics: ACL-IJCNLP 2021, pages 2355–2365, 2021."
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "[100] Yuanchao Li, Yuan Gong, Chao-Han Huck Yang, Peter Bell, and Catherine Lai. Revise, reason,"
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "and recognize: Llm-based emotion recognition via emotion-specific prompts and asr error"
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "correction.\nIn ICASSP 2025-2025 IEEE International Conference on Acoustics, Speech and"
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "Signal Processing (ICASSP), pages 1–5. IEEE, 2025."
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "[101] Zaijing Li, Gongwei Chen, Rui Shao, Yuquan Xie, Dongmei Jiang, and Liqiang Nie. Enhancing"
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "emotional generation capability of large language models via emotional chain-of-thought."
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "arXiv preprint arXiv:2401.06836, 2024."
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "Leveraging large\n[102] Zhu Li, Yuqing Zhang, Xiyuan Gao, Shekhar Nayak, and Matt Coler."
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "arXiv preprint\nlanguage models\nfor\nsarcastic speech annotation in sarcasm detection."
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "arXiv:2506.00955, 2025."
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "[103] Zheng Lian, Haoyu Chen, Lan Chen, Haiyang Sun, Licai Sun, Yong Ren, Zebang Cheng, Bin"
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "Liu, Rui Liu, Xiaojiang Peng, et al. Affectgpt: A new dataset, model, and benchmark for emo-"
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "tion understanding with multimodal large language models. arXiv preprint arXiv:2501.16566,"
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "2025."
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "[104] Qiao Liang, Ying Shen, Tiantian Chen, and Lin Zhang. M3hg: Multimodal, multi-scale, and"
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "multi-type node heterogeneous graph for emotion cause triplet extraction in conversations.\nIn"
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "Findings of the Association for Computational Linguistics: ACL 2025, pages 11416–11431,"
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "2025."
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "[105] Hongzhan Lin, Zixin Chen, Ziyang Luo, Mingfei Cheng, Jing Ma, and Guang Chen. Cofipara:"
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "a coarse-to-fine paradigm for multimodal sarcasm target identification with large multimodal"
        },
        {
          "[91] O Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed I Radaideh, Jacob Cooper, Veda": "models. arXiv preprint arXiv:2405.00390, 2024."
        }
      ],
      "page": 41
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": ""
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": ""
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": "[107] Yang Liu, Xichou Zhu, Zhou Shen, Yi Liu, Min Li, Yujun Chen, Benzi John, Zhenzhen Ma,"
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": ""
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": ""
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": "[108] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy,"
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": ""
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": ""
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": "[109] Zhiwei Liu, Kailai Yang, Qianqian Xie, Tianlin Zhang, and Sophia Ananiadou. Emollms: A"
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": ""
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": ""
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": ""
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": "[110] Ziqi Liu, Ziyang Zhou, and Mingxuan Hu. Caf-i: A collaborative multi-agent framework for"
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": ""
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": "[111] Ziqiang Liu, Feiteng Fang, Xi Feng, Xeron Du, Chenhao Zhang, Noah Wang, Qixuan Zhao,"
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": ""
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": ""
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": ""
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": "[112] Chandreen R Liyanage, Ravi Gokani, and Vijay Mago. Gpt-4 as an x data annotator: Unravel-"
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": ""
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": "[113]"
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": ""
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": ""
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": "[114]"
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": ""
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": "[115]"
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": ""
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": ""
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": "[116] Manish Barath Mahendran, Aswin Kumar Gokul, Poornima Lakshmi, and S Pavithra. Com-"
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": ""
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": ""
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": ""
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": "[117] Zhelu Mai, Jinran Zhang, Zhuoer Xu, and Zhaomin Xiao. Is llama 3 good at sarcasm detection?"
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": ""
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": ""
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": "[118] Rui Mao, Guanyi Chen, Xiao Li, Mengshi Ge, and Erik Cambria. A comparative analysis of"
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": ""
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": "[119] Rui Mao, Kai He, Claudia Ong, Qian Liu, and Erik Cambria. Metapro 2.0: Computational"
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": ""
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": ""
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": "[120] Haohan Meng, Xiaoyu Li, and Jinhua Sun. Large language models prompt engineering as a"
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": ""
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": ""
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": "[121] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient estimation of word"
        },
        {
          "[106] Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, and Jinsong Su. A dual-perspective metaphor": ""
        }
      ],
      "page": 42
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "bar: Can language models serve as creativity supporttools for comedy? an evaluation of llms’"
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "humour alignment with comedians.\nIn Proceedings of the 2024 ACM Conference on Fairness,"
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "Accountability, and Transparency, pages 1622–1636, 2024."
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "[123] Saif Mohammad, Ekaterina Shutova, and Peter Turney. Metaphor as a medium for emotion:"
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "An empirical study.\nIn Proceedings of the fifth joint conference on lexical and computational"
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "semantics, pages 23–33, 2016."
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "[124] Michael Mohler, Mary Brunson, Bryan Rink, and Marc Tomlinson.\nIntroducing the lcc"
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "the Tenth International Conference on Language\nmetaphor datasets.\nIn Proceedings of"
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "Resources and Evaluation (LREC’16), pages 4221–4227, 2016."
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "[125] Nimra Mughal, Ghulam Mujtaba, Sarang Shaikh, Aveenash Kumar, and Sher Muhammad"
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "Daudpota. Comparative analysis of deep natural networks and large language models for"
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "aspect-based sentiment analysis.\nIEEE Access, 12:60943–60959, 2024."
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "[126] Philipp Müller, Alexander Heimerl, Sayed Muddashir Hossain, Lea Siegel, Jan Alexandersson,"
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "Patrick Gebhard, Elisabeth André, and Tanja Schneeberger. Recognizing emotion regulation"
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "strategies from human behavior with large language models.\nIn 2024 12th International"
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "Conference on Affective Computing and Intelligent Interaction (ACII), pages 210–218. IEEE,"
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "2024."
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "[127] Yejoon Mun and Namhyoung Kim. Leveraging large language models for sentiment analysis"
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "and investment strategy development in financial markets. Journal of Theoretical and Applied"
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "Electronic Commerce Research, 20(2):77, 2025."
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "[128] Mohammad Nadeem, Shahab Saquib Sohail, Laeeba Javed, Faisal Anwer, Abdul Khader Jilani"
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "Saudagar, and Khan Muhammad. Vision-enabled large language and deep learning models for"
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "image-based emotion recognition. Cognitive Computation, 16(5):2566–2579, 2024."
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "[129] Reuben Narad, Siddharth Suresh, Jiayi Chen, Pine SL Dysart-Bricken, Bob Mankoff, Robert"
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "Nowak, Jifan Zhang, and Lalit Jain. Which llms get the joke? probing non-stem reasoning"
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "abilities with humorbench. arXiv preprint arXiv:2507.21476, 2025."
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "[130] Lynnette Hui Xian Ng, Iain J Cruickshank, and Roy Lee. Examining the influence of political"
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "the\nbias on large language model performance in stance classification.\nIn Proceedings of"
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "International AAAI Conference on Web and Social Media, volume 19, pages 1315–1328, 2025."
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "[131] Fuqiang Niu, Zebang Cheng, Xianghua Fu, Xiaojiang Peng, Genan Dai, Yin Chen, Hu Huang,"
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "and Bowen Zhang. Multimodal multi-turn conversation stance detection: A challenge dataset"
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "and effective model.\nIn Proceedings of the 32nd ACM international conference on multimedia,"
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "pages 3867–3876, 2024."
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "[132] Fuqiang Niu, Min Yang, Ang Li, Baoquan Zhang, Xiaojiang Peng, and Bowen Zhang. A"
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "arXiv preprint\nchallenge dataset and effective models for conversational stance detection."
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "arXiv:2403.11145, 2024."
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "[133] Minxue Niu, Yara El-Tawil, Amrit Romana, and Emily Mower Provost. Rethinking emotion"
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "annotations in the era of large language models.\nIEEE Transactions on Affective Computing,"
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "2025."
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "[134] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin,"
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models"
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "Advances in neural\ninformation processing\nto follow instructions with human feedback."
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "systems, 35:27730–27744, 2022."
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "[135] Liyizhe Peng, Zixing Zhang, Tao Pang, Jing Han, Huan Zhao, Hao Chen, and Björn W"
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "Schuller. Customising general\nlarge language models for specialised emotion recognition"
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "tasks.\nIn ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal"
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "Processing (ICASSP), pages 11326–11330. IEEE, 2024."
        },
        {
          "[122] Piotr Mirowski, Juliette Love, Kory Mathewson, and Shakir Mohamed. A robot walks into a": "43"
        }
      ],
      "page": 43
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "trasmey Keo, Watey Diep, and Yu-Gang Jiang. Whose side are you on?\ninvestigating the"
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "political stance of large language models. arXiv preprint arXiv:2403.13840, 2024."
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "[137] Mondheera Pituxcoosuvarn and Yohei Murakami.\nJokes or gibberish? humor retention in"
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "translation with neural machine translation vs.\nlarge language model. Humor Retention in"
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "Translation with Neural Machine Translation vs. Large Language Model."
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "[138] Soujanya Poria, Navonil Majumder, Devamanyu Hazarika, Deepanway Ghosal, Rishabh"
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "Bhardwaj, Samson Yu Bai Jian, Pengfei Hong, Romila Ghosh, Abhinaba Roy, Niyati Chhaya,"
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "et al. Recognizing emotion cause in conversations. Cognitive Computation, 13(5):1317–1332,"
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "2021."
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "[139] Wenhao Qian, Zhenzhen Hu, Zijie Song, and Jia Li. Concept drift guided layernorm tuning"
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "the 2025 International\nfor efficient multimodal metaphor identification.\nIn Proceedings of"
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "Conference on Multimedia Retrieval, pages 1100–1108, 2025."
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "[140] Ziqi Qiu, Jianxing Yu, Yufeng Zhang, Hanjiang Lai, Yanghui Rao, Qinliang Su, and Jian Yin."
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "Detecting emotional incongruity of sarcasm by commonsense reasoning.\nIn Proceedings of"
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "the 31st International Conference on Computational Linguistics, pages 9062–9073, 2025."
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "[141] Kexin Quan, Pavithra Ramakrishnan, and Jessie Chin. Can ai take a joke—or make one? a"
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "study of humor generation and recognition in llms.\nIn Proceedings of the 2025 Conference on"
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "Creativity and Cognition, pages 431–437, 2025."
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "[142] Mohammed I Radaideh, O Hwang Kwon, and Majdi I Radaideh. Fairness and social bias"
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "quantification in large language models for sentiment analysis. Knowledge-Based Systems,"
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "page 113569, 2025."
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "[143] Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, and Ilya"
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "Sutskever. Robust speech recognition via large-scale weak supervision.\nIn International"
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "conference on machine learning, pages 28492–28518. PMLR, 2023."
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "Improving language\n[144] Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et al."
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "understanding by generative pre-training. 2018."
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "[145] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al."
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "Language models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019."
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "[146] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena,"
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "Yanqi Zhou, Wei Li, and Peter J Liu. Exploring the limits of transfer learning with a unified"
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "text-to-text transformer. Journal of machine learning research, 21(140):1–67, 2020."
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "[147] Hannah Rashkin, Eric Michael Smith, Margaret Li, and Y-Lan Boureau.\nTowards empa-"
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "arXiv preprint\nthetic open-domain conversation models: A new benchmark and dataset."
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "arXiv:1811.00207, 2018."
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "[148] Abdur Rasool, Muhammad Irfan Shahzad, Hafsa Aslam, Vincent Chan, and Muhammad Ali"
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "Arshad. Emotion-aware embedding fusion in large language models (flan-t5, llama 2, deepseek-"
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "r1, and chatgpt 4) for intelligent response generation. AI, 6(3):56, 2025."
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "[149] Yesian Rohn. Duanzai: Slang-enhanced llm with prompt for humor understanding. arXiv"
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "preprint arXiv:2405.15818, 2024."
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "[150] Kangrui Ruan, Xinyang Wang, and Xuan Di. From twitter to reasoner: Understand mobility"
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "travel modes and sentiment using large language models. CoRR, abs/2411.02666, 2024."
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "[151] Darrel Nathaniel Sabera and Dinar Ajeng Kristiyanti. Comparative analysis of large language"
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "model as feature extraction methods in sarcasm detection using classification algorithms.\nIn"
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "2025 4th International Conference on Electronics Representation and Algorithm (ICERA),"
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "pages 352–357. IEEE, 2025."
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "[152] Sahand Sabour, Siyang Liu, Zheyuan Zhang, June M Liu, Jinfeng Zhou, Alvionna S Sunaryo,"
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "Juanzi Li, Tatia Lee, Rada Mihalcea, and Minlie Huang. Emobench: Evaluating the emotional"
        },
        {
          "[136] Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Pu-": "intelligence of large language models. arXiv preprint arXiv:2402.12071, 2024."
        }
      ],
      "page": 44
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "to prompt children to share their emotions about personal events.\nIn Proceedings of the 2024"
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "CHI Conference on Human Factors in Computing Systems, pages 1–20, 2024."
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "[154] Haranadha Reddy Busireddy Seshakagari, Aravindan Umashankar, T Harikala, L Jayasree,"
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "and Jeffrey Severance. Dynamic financial sentiment analysis and market forecasting through"
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "large language models.\nInternational Journal of Human Computations and Intelligence,"
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "4(1):397–410, 2025."
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "[155] Mohammadamin Shafiei and Hamidreza Saffari. Not all jokes land: Evaluating large language"
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "models understanding of workplace humor. arXiv preprint arXiv:2506.01819, 2025."
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "[156] Yujie Shao, Xinrong Yao, Xingwei Qu, Chenghua Lin, Shi Wang, Stephen W Huang, Ge Zhang,"
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "and Jie Fu. Cmdag: A chinese metaphor dataset with annotated grounds as cot for boosting"
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "metaphor generation. arXiv preprint arXiv:2402.13145, 2024."
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "[157] Zhiqi Shao, Xusheng Yao, Feng Chen, Ze Wang, and Junbin Gao. Revisiting time-varying"
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "dynamics in stock market forecasting: A multi-source sentiment analysis approach with large"
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "language model. Decis. Support Syst., 190:114362, 2025."
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "[158] Paul F. Simmering and Paavo Huoviala. Large language models for aspect-based sentiment"
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "analysis. CoRR, abs/2310.18025, 2023."
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "[159] Andrew L Smith, Felix Greaves, and Trishan Panch. Hallucination or confabulation? neu-"
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "roanatomy as metaphor in large language models. PLOS Digital Health, 2(11):e0000388,"
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "2023."
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "[160] Shaden Smith, Mostofa Patwary, Brandon Norick, Patrick LeGresley, Samyam Rajbhandari,"
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "Jared Casper, Zhun Liu, Shrimai Prabhumoye, George Zerveas, Vijay Korthikanti, et al. Using"
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "deepspeed and megatron to train megatron-turing nlg 530b, a large-scale generative language"
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "model. arXiv preprint arXiv:2201.11990, 2022."
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "[161] Changhao Song, Yazhou Zhang, and Peng Zhang. Emotion-o1: Adaptive long reasoning for"
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "emotion understanding in llms. arXiv preprint arXiv:2505.22548, 2025."
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "[162] Dipankar Srirag, Aditya Joshi, Jordan Painter, and Diptesh Kanojia. Besstie: A benchmark for"
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "sentiment and sarcasm classification for varieties of english. arXiv preprint arXiv:2412.04726,"
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "2024."
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "[163] Gerard J Steen, Aletta G Dorst, Tina Krennmayr, Anna A Kaal, and J Berenike Herrmann. A"
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "method for linguistic metaphor identification. 2010."
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "[164] William Stigall, Md Abdullah Al Hafiz Khan, Dinesh Chowdary Attota, Francis Nweke,"
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "and Yong Pei. Large language models performance comparison of emotion and sentiment"
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "classification. In Proceedings of the 2024 ACM Southeast Conference, ACM SE 2024, Marietta,"
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "GA, USA, April 18-20, 2024, pages 60–68. ACM, 2024."
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "[165] Derwin Suhartono, Wilson Wongso, and Alif Tri Handoyo.\nIdsarcasm: Benchmarking and"
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "evaluating language models for indonesian sarcasm detection.\nIEEE Access, 12:87323–87332,"
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "2024."
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "[166] Binghao Tang, Boda Lin, Haolong Yan, and Si Li. Leveraging generative large language"
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "models with visual instruction and demonstration retrieval for multimodal sarcasm detection."
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "In Proceedings of the 2024 Conference of the North American Chapter of the Association for"
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages"
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "1732–1742, 2024."
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "[167]\nJiacheng Tang, Nankai Wu, Fan Gao, Chengxiao Dai, Mengyao Zhao, and Xinjie Zhao. From"
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "metaphor to mechanism: How llms decode traditional chinese medicine symbolic language for"
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "modern clinical relevance. arXiv preprint arXiv:2503.02760, 2025."
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "[168] Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin,"
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "Percy Liang,\nand Tatsunori B Hashimoto.\nAlpaca:\nA strong,\nreplicable\ninstruction-"
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "following model. Stanford Center for Research on Foundation Models. https://crfm. stanford."
        },
        {
          "[153] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. Chacha:\nleveraging large language models": "edu/2023/03/13/alpaca. html, 3(6):7, 2023."
        }
      ],
      "page": 45
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "[169] Maksym Taranukhin, Vered Shwartz, and Evangelos Milios. Stance reasoner: Zero-shot stance": "detection on social media with explicit reasoning. arXiv preprint arXiv:2403.14895, 2024."
        },
        {
          "[169] Maksym Taranukhin, Vered Shwartz, and Evangelos Milios. Stance reasoner: Zero-shot stance": "[170] Gemini Team, Rohan Anil, Sebastian Borgeaud, Jean-Baptiste Alayrac, Jiahui Yu, Radu"
        },
        {
          "[169] Maksym Taranukhin, Vered Shwartz, and Evangelos Milios. Stance reasoner: Zero-shot stance": ""
        },
        {
          "[169] Maksym Taranukhin, Vered Shwartz, and Evangelos Milios. Stance reasoner: Zero-shot stance": "of highly capable multimodal models. arXiv preprint arXiv:2312.11805, 2023."
        },
        {
          "[169] Maksym Taranukhin, Vered Shwartz, and Evangelos Milios. Stance reasoner: Zero-shot stance": "[171] Gemini Team, Petko Georgiev, Ving Ian Lei, Ryan Burnell, Libin Bai, Anmol Gulati, Garrett"
        },
        {
          "[169] Maksym Taranukhin, Vered Shwartz, and Evangelos Milios. Stance reasoner: Zero-shot stance": ""
        },
        {
          "[169] Maksym Taranukhin, Vered Shwartz, and Evangelos Milios. Stance reasoner: Zero-shot stance": ""
        },
        {
          "[169] Maksym Taranukhin, Vered Shwartz, and Evangelos Milios. Stance reasoner: Zero-shot stance": ""
        },
        {
          "[169] Maksym Taranukhin, Vered Shwartz, and Evangelos Milios. Stance reasoner: Zero-shot stance": ""
        },
        {
          "[169] Maksym Taranukhin, Vered Shwartz, and Evangelos Milios. Stance reasoner: Zero-shot stance": "et al.\nGemma 2:\nImproving open language models at a practical"
        },
        {
          "[169] Maksym Taranukhin, Vered Shwartz, and Evangelos Milios. Stance reasoner: Zero-shot stance": "arXiv:2408.00118, 2024."
        },
        {
          "[169] Maksym Taranukhin, Vered Shwartz, and Evangelos Milios. Stance reasoner: Zero-shot stance": "[173] Yuan Tian, Minzheng Wang, Nan Xu, and Wenji Mao. Imara: An imaginative frame augmented"
        },
        {
          "[169] Maksym Taranukhin, Vered Shwartz, and Evangelos Milios. Stance reasoner: Zero-shot stance": "method for low-resource multimodal metaphor detection and explanation."
        },
        {
          "[169] Maksym Taranukhin, Vered Shwartz, and Evangelos Milios. Stance reasoner: Zero-shot stance": "Association for Computational Linguistics: NAACL 2025, pages 3953–3967, 2025."
        },
        {
          "[169] Maksym Taranukhin, Vered Shwartz, and Evangelos Milios. Stance reasoner: Zero-shot stance": "[174] Yuan Tian, Nan Xu, and Wenji Mao. A theory guided scaffolding instruction framework for"
        },
        {
          "[169] Maksym Taranukhin, Vered Shwartz, and Evangelos Milios. Stance reasoner: Zero-shot stance": ""
        },
        {
          "[169] Maksym Taranukhin, Vered Shwartz, and Evangelos Milios. Stance reasoner: Zero-shot stance": ""
        }
      ],
      "page": 46
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "Lu, Min Li, and Libo Qin. S3 agent: unlocking the power of vllm for zero-shot multi-modal"
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "ACM Transactions on Multimedia Computing, Communications and\nsarcasm detection."
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "Applications, 2024."
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "[187] Xiaolong Wang, Yile Wang, Sijie Cheng, Peng Li, and Yang Liu. Deem: Dynamic experienced"
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "expert modeling for stance detection. arXiv preprint arXiv:2402.15264, 2024."
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "[188] Xuena Wang, Xueting Li, Zi Yin, Yue Wu, and Jia Liu.\nEmotional\nintelligence of\nlarge"
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "language models. Journal of Pacific Rim Psychology, 17:18344909231213958, 2023."
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "[189]\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le,"
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models."
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "Advances in neural information processing systems, 35:24824–24837, 2022."
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "[190] Anuradha Welivita and Pearl Pu. Are large language models more empathetic than humans?"
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "arXiv preprint arXiv:2406.05063, 2024."
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "[191] Chengyan Wu, Bolei Ma, Zheyu Zhang, Ningyuan Deng, Yanqing He, and Yun Xue. Eval-"
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "uating zero-shot multilingual aspect-based sentiment analysis with large language models."
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "International Journal of Machine Learning and Cybernetics, June 2025."
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "[192] Lifang Wu, Lehao Xing, Ge Shi, Sinuo Deng, and Jie Yang. Sect: Sentiment-enriched continual"
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "training for image sentiment analysis.\nIn International Conference on Image and Graphics,"
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "pages 93–105. Springer, 2023."
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "[193] Shih-Hung Wu, Yu-Feng Huang, and Tsz-Yeung Lau. Humour classification by fine-tuning"
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "llms: Cyut at clef 2024 joker\nlab subtask humour classification according to genre and"
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "the Conference and Labs of\nthe Evaluation Forum (CLEF\ntechnique.\nIn Working Notes of"
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "2024). CEUR Workshop Proceedings, pages 1933–1947, 2024."
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "[194] Zihui Wu, Haichang Gao, Jiacheng Luo, and Zhaoxiang Liu. Humorreject: Decoupling llm"
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "safety from refusal prefix via a little humor. arXiv preprint arXiv:2501.13677, 2025."
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "[195] Mengyu Xiang, Yuxuan Song, Qiudan Li, Shu Wu, and Daniel Dajun Zeng. Dynamic detection"
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "of sarcasm topic-target pairs via llm-based knowledge alignment.\nIn Companion Proceedings"
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "of the ACM on Web Conference 2025, pages 1422–1425, 2025."
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "[196] Hongxia Xie, Chu-Jun Peng, Yu-Wen Tseng, Hung-Jen Chen, Chan-Feng Hsu, Hong-Han"
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "Shuai, and Wen-Huang Cheng. Emovit: Revolutionizing emotion insights with visual instruc-"
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "tion tuning.\nIn Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern"
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "Recognition, pages 26596–26605, 2024."
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "[197] Bohao Xing, Xin Liu, Guoying Zhao, Chengyu Liu, Xiaolan Fu, and Heikki Kälviäinen."
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "Emotionhallucer: Evaluating emotion hallucinations in multimodal large language models."
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "arXiv preprint arXiv:2505.11405, 2025."
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "[198] Bohao Xing, Zitong Yu, Xin Liu, Kaishen Yuan, Qilang Ye, Weicheng Xie, Huanjing Yue,"
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "Jingyu Yang, and Heikki Kälviäinen. Emo-llama: Enhancing facial emotion understanding"
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "with instruction tuning. arXiv preprint arXiv:2408.11424, 2024."
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "[199] Yaoxun Xu, Hangting Chen, Jianwei Yu, Qiaochu Huang, Zhiyong Wu, Shi-Xiong Zhang,"
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "Guangzhi Li, Yi Luo, and Rongzhi Gu. Secap: Speech emotion captioning with large language"
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "model.\nIn Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, pages"
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "19323–19331, 2024."
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "[200] Hiromu Yakura. Evaluating large language models’ ability using a psychiatric screening tool"
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "based on metaphor and sarcasm scenarios. Journal of Intelligence, 12(7):70, 2024."
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "[201] Ming Yan, Tianyi Zhou Joey, and W Tsang Ivor.\nCollaborative knowledge infusion for"
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "low-resource stance detection. Big Data Mining and Analytics, 7(3):682–698, 2024."
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "[202] Yu Yan, Sheng Sun, Zixiang Tang, Teli Liu, and Min Liu. Collaborative stance detection via"
        },
        {
          "[186] Peng Wang, Yongheng Zhang, Hao Fei, Qiguang Chen, Yukai Wang, Jiasheng Si, Wenpeng": "small-large language model consistency verification. arXiv preprint arXiv:2502.19954, 2025."
        }
      ],
      "page": 47
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "[203] An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li,": "Chengyuan Li, Dayiheng Liu, Fei Huang, Guanting Dong, Haoran Wei, Huan Lin, Jialong"
        },
        {
          "[203] An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li,": "Tang, Jialin Wang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Ma, Jianxin Yang, Jin Xu,"
        },
        {
          "[203] An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li,": "Jingren Zhou, Jinze Bai, Jinzheng He, Junyang Lin, Kai Dang, Keming Lu, Keqin Chen, Kexin"
        },
        {
          "[203] An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li,": "Yang, Mei Li, Mingfeng Xue, Na Ni, Pei Zhang, Peng Wang, Ru Peng, Rui Men, Ruize Gao,"
        },
        {
          "[203] An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li,": "Runji Lin, Shijie Wang, Shuai Bai, Sinan Tan, Tianhang Zhu, Tianhao Li, Tianyu Liu, Wenbin"
        },
        {
          "[203] An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li,": "Ge, Xiaodong Deng, Xiaohuan Zhou, Xingzhang Ren, Xinyu Zhang, Xipin Wei, Xuancheng"
        },
        {
          "[203] An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li,": "Ren, Xuejing Liu, Yang Fan, Yang Yao, Yichang Zhang, Yu Wan, Yunfei Chu, Yuqiong Liu,"
        },
        {
          "[203] An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li,": "Zeyu Cui, Zhenru Zhang, Zhifang Guo, and Zhihao Fan. Qwen2 technical report, 2024."
        },
        {
          "[203] An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li,": "[204] Haowei Yang, Yun Zi, Honglin Qin, Hongye Zheng, and Yuxiang Hu. Advancing emotional"
        },
        {
          "[203] An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li,": "analysis with large language models. Journal of Computer Science and Software Applications,"
        },
        {
          "[203] An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li,": "4(3):8–15, 2024."
        },
        {
          "[203] An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li,": "[205] Qize Yang, Detao Bai, Yi-Xing Peng, and Xihan Wei. Omni-emotion: Extending video"
        },
        {
          "[203] An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li,": "mllm with detailed face and audio modeling for multimodal emotion analysis. arXiv preprint"
        },
        {
          "[203] An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li,": "arXiv:2501.09502, 2025."
        },
        {
          "[203] An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li,": "[206] Qu Yang, Mang Ye, and Bo Du. Emollm: Multimodal emotional understanding meets large"
        },
        {
          "[203] An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li,": "language models. arXiv preprint arXiv:2406.16442, 2024."
        },
        {
          "[203] An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li,": "[207] Ruichao Yang, Wei Gao, Jing Ma, Hongzhan Lin, and Bo Wang. Reinforcement tuning for"
        },
        {
          "[203] An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li,": "detecting stances and debunking rumors jointly with large language models. arXiv preprint"
        },
        {
          "[203] An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li,": "arXiv:2406.02143, 2024."
        },
        {
          "[203] An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li,": "[208] Yunchu Yang, Jiaxuan Li, Jielong Guo, Patrick Cheong-Iao Pang, Yapeng Wang, Xu Yang,"
        },
        {
          "[203] An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li,": "and Sio Kei Im. Performance evaluation and application potential of small\nlarge language"
        },
        {
          "[203] An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li,": "models in complex sentiment analysis tasks.\nIEEE Access, 13:49007–49017, 2025."
        },
        {
          "[203] An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li,": "[209] B Yao, Y Zhang, Q Li, and J Qin.\nIs sarcasm detection a step-by-step reasoning process in"
        },
        {
          "[203] An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li,": "large language models?(2024). arXiv preprint arXiv:2407.12725."
        },
        {
          "[203] An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li,": "Is sarcasm detection a step-by-step\n[210] Ben Yao, Yazhou Zhang, Qiuchi Li, and Jing Qin."
        },
        {
          "[203] An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li,": "the AAAI Conference on\nreasoning process in large language models?\nIn Proceedings of"
        },
        {
          "[203] An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li,": "Artificial Intelligence, volume 39, pages 25651–25659, 2025."
        },
        {
          "[203] An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li,": "[211] Matin Yarmand, Courtney N Reed, Udayan Tandon, Eric B Hekler, Nadir Weibel, and April Yi"
        },
        {
          "[203] An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li,": "Wang. Towards dialogic and on-demand metaphors for interdisciplinary reading.\nIn Pro-"
        }
      ],
      "page": 48
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "arXiv preprint\nanalysis by instruction tuning of general-purpose large language models."
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "arXiv:2306.12659, 2023."
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "[219] Boyu Zhang, Hongyang Yang, Tianyu Zhou, Muhammad Ali Babar, and Xiao-Yang Liu."
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "Enhancing financial sentiment analysis via retrieval augmented large language models.\nIn"
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "Proceedings of\nthe fourth ACM international conference on AI in finance, pages 349–356,"
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "2023."
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "[220] Dongyu Zhang, Xingyuan Lu, Mulin Zhuang, Senqi Yang, and Hongjun Chen. Multimodal"
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "metaphor recognition based on chain-of-cognition prompting. Cognitive Systems Research,"
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "91:101356, 2025."
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "[221] Dongyu Zhang, Shengcheng Yin, Jingwei Yu, Zhiyao Wu, Zhen Li, Chengpei Xu, Xiaoxia"
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "Wang, and Feng Xia. Towards multimodal metaphor understanding: A chinese dataset and"
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "model for metaphor mapping identification. arXiv preprint arXiv:2501.02434, 2025."
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "[222] Ting Zhang, Ivana Clairine Irsan, Ferdian Thung, and David Lo. Revisiting sentiment analysis"
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "for software engineering in the era of large language models. ACM Transactions on Software"
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "Engineering and Methodology, 34(3):1–30, 2025."
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "[223] Wenxuan Zhang, Yue Deng, Bing Liu, Sinno Jialin Pan, and Lidong Bing. Sentiment analysis"
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "in the era of large language models: A reality check. arXiv preprint arXiv:2305.15005, 2023."
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "[224] Y Zhang, M Wang, Y Wu, Li Q Tiwari Prayag, B Wang, and J Qin. Dialoguellm: context and"
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "emotion knowledge-tuned large language models for emotion recognition in conversations."
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "arxiv. org, 2023."
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "[225] Y Zhang, C Zou, Z Lian, P Tiwari, and J Qin.\nSarcasmbench: Towards evaluating large"
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "language models on sarcasm understanding (no. arxiv: 2408.11319). arxiv, 2024."
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "[226] Yazhou Zhang, Mengyao Wang, Qiuchi Li, Prayag Tiwari, and Jing Qin. Pushing the limit of"
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "llm capacity for text classification.\nIn Companion Proceedings of the ACM on Web Conference"
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "2025, pages 1524–1528, 2025."
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "[227] Yazhou Zhang, Chunwang Zou, Qimeng Liu, Lu Rong, Ben Yao, Zheng Lian, Qiuchi Li, Peng"
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "Zhang, and Jing Qin. Are mlms trapped in the visual room? arXiv preprint arXiv:2505.23272,"
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "2025."
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "[228] Yazhou Zhang, Chunwang Zou, Bo Wang, and Jing Qin. Commander-gpt: Fully unleashing"
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "arXiv preprint\nthe sarcasm detection capability of multi-modal\nlarge language models."
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "arXiv:2503.18681, 2025."
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "[229] Yiqun Zhang, Xiaocui Yang, Xingle Xu, Zeran Gao, Yijie Huang, Shiyi Mu, Shi Feng, Daling"
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "Wang, Yifei Zhang, Kaisong Song, et al. Affective computing in the era of large language"
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "models: A survey from the nlp perspective. arXiv preprint arXiv:2408.04638, 2024."
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "[230] Zhao Zhang, Yiming Li, Jin Zhang, and Hui Xu. Llm-driven knowledge injection advances"
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "the 2024 Conference of\nthe\nzero-shot and cross-target stance detection.\nIn Proceedings of"
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "North American Chapter of the Association for Computational Linguistics: Human Language"
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "Technologies (Volume 2: Short Papers), pages 371–378, 2024."
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "[231] Zixing Zhang, Liyizhe Peng, Tao Pang, Jing Han, Huan Zhao, and Björn W Schuller. Re-"
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "IEEE\nfashioning emotion recognition modeling:\nthe advent of generalized large models."
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "Transactions on Computational Social Systems, 11(5):6690–6704, 2024."
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "[232] Chenye Zhao and Cornelia Caragea. Ez-stance: A large dataset for english zero-shot stance"
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "detection.\nIn Proceedings of the 62nd Annual Meeting of the Association for Computational"
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "Linguistics (Volume 1: Long Papers), pages 15697–15714, 2024."
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "[233] Chenye Zhao, Yingjie Li, Cornelia Caragea, and Yue Zhang. Zerostance: Leveraging chatgpt"
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "for open-domain stance detection via dataset generation.\nIn Findings of the Association for"
        },
        {
          "[218] Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu.\nInstruct-fingpt: Financial sentiment": "Computational Linguistics ACL 2024, pages 13390–13405, 2024."
        }
      ],
      "page": 49
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "[234] Haochen Zhao, Yongxiu Xu, Xinkui Lin, Jiarui Lu, Hongbo Xu, and Yubin Wang. Eilmob:": ""
        },
        {
          "[234] Haochen Zhao, Yongxiu Xu, Xinkui Lin, Jiarui Lu, Hongbo Xu, and Yubin Wang. Eilmob:": ""
        },
        {
          "[234] Haochen Zhao, Yongxiu Xu, Xinkui Lin, Jiarui Lu, Hongbo Xu, and Yubin Wang. Eilmob:": ""
        },
        {
          "[234] Haochen Zhao, Yongxiu Xu, Xinkui Lin, Jiarui Lu, Hongbo Xu, and Yubin Wang. Eilmob:": "[235]"
        },
        {
          "[234] Haochen Zhao, Yongxiu Xu, Xinkui Lin, Jiarui Lu, Hongbo Xu, and Yubin Wang. Eilmob:": ""
        },
        {
          "[234] Haochen Zhao, Yongxiu Xu, Xinkui Lin, Jiarui Lu, Hongbo Xu, and Yubin Wang. Eilmob:": "[236] Li Zheng, Sihang Wang, Hao Fei, Zuquan Peng, Fei Li, Jianming Fu, Chong Teng, and"
        },
        {
          "[234] Haochen Zhao, Yongxiu Xu, Xinkui Lin, Jiarui Lu, Hongbo Xu, and Yubin Wang. Eilmob:": ""
        },
        {
          "[234] Haochen Zhao, Yongxiu Xu, Xinkui Lin, Jiarui Lu, Hongbo Xu, and Yubin Wang. Eilmob:": ""
        },
        {
          "[234] Haochen Zhao, Yongxiu Xu, Xinkui Lin, Jiarui Lu, Hongbo Xu, and Yubin Wang. Eilmob:": "[237] Hengyang Zhou, Jinwu Yan, Yaqing Chen, Rongman Hong, Wenbo Zuo, and Keyan Jin."
        },
        {
          "[234] Haochen Zhao, Yongxiu Xu, Xinkui Lin, Jiarui Lu, Hongbo Xu, and Yubin Wang. Eilmob:": ""
        },
        {
          "[234] Haochen Zhao, Yongxiu Xu, Xinkui Lin, Jiarui Lu, Hongbo Xu, and Yubin Wang. Eilmob:": ""
        },
        {
          "[234] Haochen Zhao, Yongxiu Xu, Xinkui Lin, Jiarui Lu, Hongbo Xu, and Yubin Wang. Eilmob:": ""
        },
        {
          "[234] Haochen Zhao, Yongxiu Xu, Xinkui Lin, Jiarui Lu, Hongbo Xu, and Yubin Wang. Eilmob:": "[238]"
        },
        {
          "[234] Haochen Zhao, Yongxiu Xu, Xinkui Lin, Jiarui Lu, Hongbo Xu, and Yubin Wang. Eilmob:": ""
        },
        {
          "[234] Haochen Zhao, Yongxiu Xu, Xinkui Lin, Jiarui Lu, Hongbo Xu, and Yubin Wang. Eilmob:": "[239] Runlong Zhou and Yi Zhang. Cascade your datasets for cross-mode knowledge retrieval of"
        },
        {
          "[234] Haochen Zhao, Yongxiu Xu, Xinkui Lin, Jiarui Lu, Hongbo Xu, and Yubin Wang. Eilmob:": ""
        },
        {
          "[234] Haochen Zhao, Yongxiu Xu, Xinkui Lin, Jiarui Lu, Hongbo Xu, and Yubin Wang. Eilmob:": "[240] Zhengyuan Zhu, Zeyu Zhang, Haiqi Zhang, and Chengkai Li. Ratsd: Retrieval augmented"
        },
        {
          "[234] Haochen Zhao, Yongxiu Xu, Xinkui Lin, Jiarui Lu, Hongbo Xu, and Yubin Wang. Eilmob:": ""
        },
        {
          "[234] Haochen Zhao, Yongxiu Xu, Xinkui Lin, Jiarui Lu, Hongbo Xu, and Yubin Wang. Eilmob:": ""
        },
        {
          "[234] Haochen Zhao, Yongxiu Xu, Xinkui Lin, Jiarui Lu, Hongbo Xu, and Yubin Wang. Eilmob:": "[241] Yong Zhuang, Feilong Wang, Dickson K. W. Chiu, and Kevin K. W. Ho. Leveraging large"
        },
        {
          "[234] Haochen Zhao, Yongxiu Xu, Xinkui Lin, Jiarui Lu, Hongbo Xu, and Yubin Wang. Eilmob:": ""
        },
        {
          "[234] Haochen Zhao, Yongxiu Xu, Xinkui Lin, Jiarui Lu, Hongbo Xu, and Yubin Wang. Eilmob:": ""
        }
      ],
      "page": 50
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Shyamal Anadkat, et al. Gpt-4 technical report",
      "authors": [
        "Josh Achiam",
        "Steven Adler",
        "Sandhini Agarwal",
        "Lama Ahmad",
        "Ilge Akkaya",
        "Florencia Leoni Aleman",
        "Diogo Almeida",
        "Janko Altenschmidt",
        "Sam Altman"
      ],
      "year": "2023",
      "venue": "Shyamal Anadkat, et al. Gpt-4 technical report",
      "arxiv": "arXiv:2303.08774"
    },
    {
      "citation_id": "2",
      "title": "Vaxxstance: A dataset for cross-lingual stance detection on vaccines",
      "authors": [
        "Rodrigo Agerri",
        "Roberto Centeno",
        "Marıa Espinosa",
        "Joseba Fernandez De Landa",
        "Alvaro Rodrigo"
      ],
      "year": "2021",
      "venue": "Vaxxstance: A dataset for cross-lingual stance detection on vaccines"
    },
    {
      "citation_id": "3",
      "title": "Large language models powered aspect-based sentiment analysis for enhanced customer insights",
      "authors": [
        "Mariana Água",
        "Nuno António",
        "Marco Carrasco",
        "Carimo Rassal"
      ],
      "year": "2025",
      "venue": "Tourism & Management Studies"
    },
    {
      "citation_id": "4",
      "title": "Leveraging large language models and prompt settings for context-aware financial sentiment analysis",
      "authors": [
        "Rabbia Ahmed",
        "Sadaf Abdul Rauf",
        "Seemab Latif"
      ],
      "venue": "2024 5th International Conference on Advancements in Computational Sciences (ICACS)"
    },
    {
      "citation_id": "5",
      "title": "Zero-shot stance detection: A dataset and model using generalized topic representations",
      "authors": [
        "Emily Allaway",
        "Kathleen Mckeown"
      ],
      "year": "2020",
      "venue": "Zero-shot stance detection: A dataset and model using generalized topic representations",
      "arxiv": "arXiv:2010.03640"
    },
    {
      "citation_id": "6",
      "title": "Mawqif: A multi-label arabic dataset for target-specific stance detection",
      "authors": [
        "Nora Saleh Alturayeif",
        "Hamzah Abdullah Luqman",
        "Moataz Aly",
        "Kamaleldin Ahmed"
      ],
      "year": "2022",
      "venue": "Proceedings of the Seventh Arabic Natural Language Processing Workshop (WANLP)"
    },
    {
      "citation_id": "7",
      "title": "How well do vision-language models explain sarcasm? an evaluation of multimodal explanation quality for social media posts",
      "authors": [
        "Ikhlasul Amal",
        "Annisa Nur"
      ],
      "year": "2025",
      "venue": "Artificial Intelligence Systems and Its Applications"
    },
    {
      "citation_id": "8",
      "title": "Intent detection in the age of llms",
      "authors": [
        "Gaurav Arora",
        "Shreya Jain",
        "Srujana Merugu"
      ],
      "year": "2024",
      "venue": "Intent detection in the age of llms",
      "arxiv": "arXiv:2410.01627"
    },
    {
      "citation_id": "9",
      "title": "Few-shot prompting, full-scale confusion: Evaluating large language models for humor detection in croatian tweets",
      "authors": [
        "Petra Bago",
        "Nikola Bakarić"
      ],
      "year": "2025",
      "venue": "Proceedings of the 10th Workshop on Slavic Natural Language Processing (Slavic NLP 2025)"
    },
    {
      "citation_id": "10",
      "title": "Text is not all you need: Multimodal prompting helps llms understand humor",
      "authors": [
        "Ashwin Baluja"
      ],
      "year": "2024",
      "venue": "Text is not all you need: Multimodal prompting helps llms understand humor",
      "arxiv": "arXiv:2412.05315"
    },
    {
      "citation_id": "11",
      "title": "Exploring cognitive difference in poetry collection via large language models and metaphors: A case study of the book of songs",
      "authors": [
        "Hui Bao",
        "Kai He",
        "Yige Wang",
        "Zeyu Gao"
      ],
      "year": "2025",
      "venue": "Cognitive Computation"
    },
    {
      "citation_id": "12",
      "title": "On the impact of language nuances on sentiment analysis with large language models: Paraphrasing, sarcasm, and emojis",
      "authors": [
        "Naman Bhargava",
        "O Mohammed I Radaideh",
        "Aditi Hwang Kwon",
        "Majdi Verma",
        "Radaideh"
      ],
      "year": "2025",
      "venue": "On the impact of language nuances on sentiment analysis with large language models: Paraphrasing, sarcasm, and emojis",
      "arxiv": "arXiv:2504.05603"
    },
    {
      "citation_id": "13",
      "title": "Rethinking stance detection: A theoretically-informed research agenda for user-level inference using language models",
      "authors": [
        "Prasanta Bhattacharya",
        "Hong Zhang",
        "Yiming Cao",
        "Wei Gao",
        "Brandon Loh",
        "Joseph Jp Simons",
        "Liang Ze Wong"
      ],
      "year": "2025",
      "venue": "Rethinking stance detection: A theoretically-informed research agenda for user-level inference using language models",
      "arxiv": "arXiv:2502.02074"
    },
    {
      "citation_id": "14",
      "title": "Sarcasm in sight and sound: Benchmarking and expansion to improve multimodal sarcasm detection",
      "authors": [
        "Swapnil Bhosale",
        "Abhra Chaudhuri",
        "Alex Lee",
        "Robert Williams",
        "Divyank Tiwari",
        "Anjan Dutta",
        "Xiatian Zhu",
        "Pushpak Bhattacharyya",
        "Diptesh Kanojia"
      ],
      "year": "2023",
      "venue": "Sarcasm in sight and sound: Benchmarking and expansion to improve multimodal sarcasm detection",
      "arxiv": "arXiv:2310.01430"
    },
    {
      "citation_id": "15",
      "title": "A clustering approach for the unsupervised recognition of nonliteral language",
      "authors": [
        "Julia Birke"
      ],
      "year": "2005",
      "venue": "A clustering approach for the unsupervised recognition of nonliteral language"
    },
    {
      "citation_id": "16",
      "title": "How are metaphors processed by language models? the case of analogies",
      "authors": [
        "Joanne Boisson",
        "Asahi Ushio",
        "Hsuvas Borkakoty",
        "Kiamehr Rezaee",
        "Dimosthenis Antypas",
        "Zara Siddique",
        "Nina White",
        "Jose Camacho-Collados"
      ],
      "year": "2024",
      "venue": "Proceedings of the 28th Conference on Computational Natural Language Learning"
    },
    {
      "citation_id": "17",
      "title": "Mememind framework: Leveraging large language models for meme classification and xai",
      "authors": [
        "Diederik Booij"
      ],
      "year": "2025",
      "venue": "Mememind framework: Leveraging large language models for meme classification and xai"
    },
    {
      "citation_id": "18",
      "title": "Figurative archive: an open dataset and web-based application for the study of metaphor",
      "authors": [
        "Maddalena Bressler",
        "Veronica Mangiaterra",
        "Paolo Canal",
        "Federico Frau",
        "Fabrizio Luciani",
        "Biagio Scalingi",
        "Chiara Barattieri Di San Pietro",
        "Chiara Battaglini",
        "Chiara Pompei",
        "Fortunata Romeo"
      ],
      "year": "2025",
      "venue": "Figurative archive: an open dataset and web-based application for the study of metaphor",
      "arxiv": "arXiv:2503.00444"
    },
    {
      "citation_id": "19",
      "title": "Language models are few-shot learners",
      "authors": [
        "Tom Brown",
        "Benjamin Mann",
        "Nick Ryder",
        "Melanie Subbiah",
        "Jared Kaplan",
        "Prafulla Dhariwal",
        "Arvind Neelakantan",
        "Pranav Shyam",
        "Girish Sastry",
        "Amanda Askell"
      ],
      "year": "2020",
      "venue": "Advances in neural information processing systems"
    },
    {
      "citation_id": "20",
      "title": "Large language models are as persuasive as humans, but how? about the cognitive effort and moral-emotional language of llm arguments",
      "authors": [
        "Carlos Carrasco-Farre"
      ],
      "year": "2024",
      "venue": "Large language models are as persuasive as humans, but how? about the cognitive effort and moral-emotional language of llm arguments",
      "arxiv": "arXiv:2404.09329"
    },
    {
      "citation_id": "21",
      "title": "Towards multimodal sarcasm detection (an _obviously_ perfect paper)",
      "authors": [
        "Santiago Castro",
        "Devamanyu Hazarika",
        "Verónica Pérez-Rosas",
        "Roger Zimmermann",
        "Rada Mihalcea",
        "Soujanya Poria"
      ],
      "year": "2019",
      "venue": "Towards multimodal sarcasm detection (an _obviously_ perfect paper)",
      "arxiv": "arXiv:1906.01815"
    },
    {
      "citation_id": "22",
      "title": "Marianna Apidianaki, and Smaranda Muresan. I spy a metaphor: Large language models and diffusion models co-create visual metaphors",
      "authors": [
        "Tuhin Chakrabarty",
        "Arkadiy Saakyan",
        "Olivia Winn",
        "Artemis Panagopoulou",
        "Yue Yang"
      ],
      "year": "2023",
      "venue": "Marianna Apidianaki, and Smaranda Muresan. I spy a metaphor: Large language models and diffusion models co-create visual metaphors",
      "arxiv": "arXiv:2305.14724"
    },
    {
      "citation_id": "23",
      "title": "Large language models for metaphor detection: Bhagavad gita and sermon on the mount",
      "authors": [
        "Rohitash Chandra",
        "Abhishek Tiwari",
        "Naman Jain",
        "Sushrut Badhe"
      ],
      "year": "2024",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "24",
      "title": "Semeval-2016 task 9: Chinese semantic dependency parsing",
      "authors": [
        "Wanxiang Che",
        "Yanqiu Shao",
        "Ting Liu",
        "Yu Ding"
      ],
      "year": "2016",
      "venue": "Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)"
    },
    {
      "citation_id": "25",
      "title": "Emova: Empowering language models to see, hear and speak with vivid emotions",
      "authors": [
        "Kai Chen",
        "Yunhao Gou",
        "Runhui Huang",
        "Zhili Liu",
        "Daxin Tan",
        "Jing Xu",
        "Chunwei Wang",
        "Yi Zhu",
        "Yihan Zeng",
        "Kuo Yang"
      ],
      "year": "2025",
      "venue": "Proceedings of the Computer Vision and Pattern Recognition Conference"
    },
    {
      "citation_id": "26",
      "title": "Seeing things from a different angle: Discovering diverse perspectives about claims",
      "authors": [
        "Sihao Chen",
        "Daniel Khashabi",
        "Wenpeng Yin",
        "Chris Callison-Burch",
        "Dan Roth"
      ],
      "year": "2019",
      "venue": "Seeing things from a different angle: Discovering diverse perspectives about claims",
      "arxiv": "arXiv:1906.03538"
    },
    {
      "citation_id": "27",
      "title": "Leveraging large language model as news sentiment predictor in stock markets: a knowledge-enhanced strategy",
      "authors": [
        "Weisi Chen",
        "Wulong Liu",
        "Jiaxin Zheng",
        "Xu Zhang"
      ],
      "year": "2025",
      "venue": "Discov. Comput"
    },
    {
      "citation_id": "28",
      "title": "Emotionqueen: A benchmark for evaluating empathy of large language models",
      "authors": [
        "Yuyan Chen",
        "Hao Wang",
        "Songzhou Yan",
        "Sijia Liu",
        "Yueze Li",
        "Yi Zhao",
        "Yanghua Xiao"
      ],
      "year": "2024",
      "venue": "Emotionqueen: A benchmark for evaluating empathy of large language models",
      "arxiv": "arXiv:2409.13359"
    },
    {
      "citation_id": "29",
      "title": "Recent advancement of emotion cognition in large language models",
      "authors": [
        "Yuyan Chen",
        "Yanghua Xiao"
      ],
      "year": "2024",
      "venue": "Recent advancement of emotion cognition in large language models",
      "arxiv": "arXiv:2409.13354"
    },
    {
      "citation_id": "30",
      "title": "Talk funny! a large-scale humor response dataset with chain-of-humor interpretation",
      "authors": [
        "Yuyan Chen",
        "Yichen Yuan",
        "Panjun Liu",
        "Dayiheng Liu",
        "Qinghao Guan",
        "Mengfei Guo",
        "Haiming Peng",
        "Bang Liu",
        "Zhixu Li",
        "Yanghua Xiao"
      ],
      "year": "2024",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence"
    },
    {
      "citation_id": "31",
      "title": "Emotion-llama: Multimodal emotion recognition and reasoning with instruction tuning",
      "authors": [
        "Zebang Cheng",
        "Zhi-Qi Cheng",
        "Jun-Yan He",
        "Kai Wang",
        "Yuxiang Lin",
        "Zheng Lian",
        "Xiaojiang Peng",
        "Alexander Hauptmann"
      ],
      "year": "2024",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "32",
      "title": "Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality",
      "authors": [
        "Wei-Lin Chiang",
        "Zhuohan Li",
        "Ziqing Lin",
        "Ying Sheng",
        "Zhanghao Wu",
        "Hao Zhang",
        "Lianmin Zheng",
        "Siyuan Zhuang",
        "Yonghao Zhuang",
        "Joseph Gonzalez"
      ],
      "year": "2023",
      "venue": "Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality"
    },
    {
      "citation_id": "33",
      "title": "Finance-specific large language models: Advancing sentiment analysis and return prediction with llama 2",
      "authors": [
        "I-Chan Chiu",
        "Mao-Wei Hung"
      ],
      "year": "2025",
      "venue": "Pacific-Basin Finance Journal"
    },
    {
      "citation_id": "34",
      "title": "Palm: Scaling language modeling with pathways",
      "authors": [
        "Aakanksha Chowdhery",
        "Sharan Narang",
        "Jacob Devlin",
        "Maarten Bosma",
        "Gaurav Mishra",
        "Adam Roberts",
        "Paul Barham",
        "Hyung Chung",
        "Charles Sutton",
        "Sebastian Gehrmann"
      ],
      "year": "2023",
      "venue": "Journal of Machine Learning Research"
    },
    {
      "citation_id": "35",
      "title": "Large language model enhanced logic tensor network for stance detection",
      "authors": [
        "Genan Dai",
        "Jiayu Liao",
        "Sicheng Zhao",
        "Xianghua Fu",
        "Xiaojiang Peng",
        "Hu Huang",
        "Bowen Zhang"
      ],
      "year": "2025",
      "venue": "Neural Networks"
    },
    {
      "citation_id": "36",
      "title": "Goemotions: A dataset of fine-grained emotions",
      "authors": [
        "Dorottya Demszky",
        "Dana Movshovitz-Attias",
        "Jeongwoo Ko",
        "Alan Cowen",
        "Gaurav Nemade",
        "Sujith Ravi"
      ],
      "year": "2020",
      "venue": "Goemotions: A dataset of fine-grained emotions",
      "arxiv": "arXiv:2005.00547"
    },
    {
      "citation_id": "37",
      "title": "Large vision-language models for knowledge-grounded data annotation of memes",
      "authors": [
        "Shiling Deng",
        "Serge Belongie",
        "Peter Christensen"
      ],
      "year": "2025",
      "venue": "Large vision-language models for knowledge-grounded data annotation of memes",
      "arxiv": "arXiv:2501.13851"
    },
    {
      "citation_id": "38",
      "title": "Llms to the moon? reddit market sentiment analysis with large language models",
      "authors": [
        "Xiang Deng",
        "Vasilisa Bashlovkina",
        "Feng Han",
        "Simon Baumgartner",
        "Michael Bendersky"
      ],
      "year": "2023",
      "venue": "Companion Proceedings of the ACM Web Conference 2023"
    },
    {
      "citation_id": "39",
      "title": "Qlora: Efficient finetuning of quantized llms",
      "authors": [
        "Tim Dettmers",
        "Artidoro Pagnoni",
        "Ari Holtzman",
        "Luke Zettlemoyer"
      ],
      "year": "2023",
      "venue": "Advances in neural information processing systems"
    },
    {
      "citation_id": "40",
      "title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "authors": [
        "Jacob Devlin",
        "Ming-Wei Chang",
        "Kenton Lee",
        "Kristina Toutanova"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 conference of the North American chapter of the association for computational linguistics: human language technologies"
    },
    {
      "citation_id": "41",
      "title": "Cross-target stance detection by exploiting target analytical perspectives",
      "authors": [
        "Daijun Ding",
        "Rong Chen",
        "Liwen Jing",
        "Bowen Zhang",
        "Xu Huang",
        "Li Dong",
        "Xiaowen Zhao",
        "Ge Song"
      ],
      "year": "2024",
      "venue": "ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
    },
    {
      "citation_id": "42",
      "title": "Distantly supervised explainable stance detection via chain-of-thought supervision",
      "authors": [
        "Daijun Ding",
        "Genan Dai",
        "Cheng Peng",
        "Xiaojiang Peng",
        "Bowen Zhang",
        "Hu Huang"
      ],
      "year": "2024",
      "venue": "Mathematics"
    },
    {
      "citation_id": "43",
      "title": "Leveraging chain-of-thought to enhance stance detection with prompt-tuning",
      "authors": [
        "Daijun Ding",
        "Xianghua Fu",
        "Xiaojiang Peng",
        "Xiaomao Fan",
        "Hu Huang",
        "Bowen Zhang"
      ],
      "year": "2024",
      "venue": "Mathematics"
    },
    {
      "citation_id": "44",
      "title": "Dynamic adaptive optimization for effective sentiment analysis fine-tuning on large language models",
      "authors": [
        "Hongcheng Ding",
        "Xuanze Zhao",
        "Ruiting Deng",
        "Nahar Shamsul",
        "Deshinta Abdullah",
        "Zixiao Arrova Dewi",
        "Jiang"
      ],
      "year": "2024",
      "venue": "Dynamic adaptive optimization for effective sentiment analysis fine-tuning on large language models",
      "arxiv": "arXiv:2408.11856"
    },
    {
      "citation_id": "45",
      "title": "Boosting large language models with continual learning for aspect-based sentiment analysis",
      "authors": [
        "Xuanwen Ding",
        "Jie Zhou",
        "Liang Dou",
        "Qin Chen",
        "Yuanbin Wu",
        "Chengcai Chen",
        "Liang He"
      ],
      "year": "2024",
      "venue": "Boosting large language models with continual learning for aspect-based sentiment analysis"
    },
    {
      "citation_id": "46",
      "title": "Automatic scoring of metaphor creativity with large language models",
      "authors": [
        "Pv Distefano",
        "Patterson",
        "Beaty"
      ],
      "year": "2023",
      "venue": "psyarxiv"
    },
    {
      "citation_id": "47",
      "title": "Mhsdb: A comprehensive benchmark for multimodal humor and sarcasm detection leveraging foundation models",
      "authors": [
        "Zhongren Dong",
        "Donghao Wang",
        "Ciqiang Chen",
        "Dong-Yan Huang",
        "Zixing Zhang"
      ],
      "year": "2025",
      "venue": "ICASSP 2025-2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
    },
    {
      "citation_id": "48",
      "title": "The llama 3 herd of models. arXiv e-prints",
      "authors": [
        "Abhimanyu Dubey",
        "Abhinav Jauhri",
        "Abhinav Pandey",
        "Abhishek Kadian",
        "Ahmad Al-Dahle",
        "Aiesha Letman",
        "Akhil Mathur",
        "Alan Schelten",
        "Amy Yang",
        "Angela Fan"
      ],
      "year": "2024",
      "venue": "The llama 3 herd of models. arXiv e-prints"
    },
    {
      "citation_id": "49",
      "title": "Finding structure in time",
      "authors": [
        "Jeffrey L Elman"
      ],
      "year": "1990",
      "venue": "Cognitive science"
    },
    {
      "citation_id": "50",
      "title": "Orpailleur & synalp at clef 2024 task 2: Good old cross validation for large language models yields the best humorous detection",
      "authors": [
        "Pierre Epron",
        "Gaël Guibon",
        "Miguel Couceiro"
      ],
      "year": "2024",
      "venue": "Working Notes of the Conference and Labs of the Evaluation Forum (CLEF 2024)"
    },
    {
      "citation_id": "51",
      "title": "Enhancing zero-shot stance detection via multi-task fine-tuning with debate data and knowledge augmentation",
      "authors": [
        "Qinlong Fan",
        "Jicang Lu",
        "Yepeng Sun",
        "Qiankun Pi",
        "Shouxin Shang"
      ],
      "year": "2025",
      "venue": "Complex & Intelligent Systems"
    },
    {
      "citation_id": "52",
      "title": "Emowoz: A large-scale corpus and labelling scheme for emotion recognition in task-oriented dialogue systems",
      "authors": [
        "Shutong Feng",
        "Nurul Lubis",
        "Christian Geishauser",
        "Hsien-Chin Lin",
        "Michael Heck",
        "Carel Van Niekerk",
        "Milica Gašić"
      ],
      "year": "2021",
      "venue": "Emowoz: A large-scale corpus and labelling scheme for emotion recognition in task-oriented dialogue systems",
      "arxiv": "arXiv:2109.04919"
    },
    {
      "citation_id": "53",
      "title": "Evaluating large language models for user stance detection on x (twitter)",
      "authors": [
        "Margherita Gambini",
        "Caterina Senette",
        "Tiziano Fagni",
        "Maurizio Tesconi"
      ],
      "year": "2024",
      "venue": "Machine Learning"
    },
    {
      "citation_id": "54",
      "title": "A survey on the impact of pre-trained language models in sentiment classification task",
      "authors": [
        "Himanshu Gautam",
        "Abhishek Gaur",
        "Dharmendra Kumar"
      ],
      "year": "2025",
      "venue": "International Journal of Data Science and Analytics"
    },
    {
      "citation_id": "55",
      "title": "Stance detection in covid-19 tweets",
      "authors": [
        "Kyle Glandt",
        "Sarthak Khanal",
        "Yingjie Li",
        "Doina Caragea",
        "Cornelia Caragea"
      ],
      "year": "2021",
      "venue": "Proceedings of the 59th annual meeting of the association for computational linguistics and the 11th international joint conference on natural language processing"
    },
    {
      "citation_id": "56",
      "title": "On sarcasm detection with openai gpt-based models",
      "authors": [
        "Gole",
        "Nwadiugwu",
        "Miranskyy"
      ],
      "year": "2023",
      "venue": "On sarcasm detection with openai gpt-based models",
      "doi": "10.48550/arXiv"
    },
    {
      "citation_id": "57",
      "title": "On sarcasm detection with openai gpt-based models",
      "authors": [
        "Montgomery Gole",
        "Williams-Paul Nwadiugwu",
        "Andriy Miranskyy"
      ],
      "year": "2024",
      "venue": "2024 34th International Conference on Collaborative Advances in Software and COmputiNg (CASCON)"
    },
    {
      "citation_id": "58",
      "title": "Context matters: Enhancing metaphor recognition in proverbs",
      "authors": [
        "Gamze Goren",
        "Carlo Strapparava"
      ],
      "year": "2024",
      "venue": "Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)"
    },
    {
      "citation_id": "59",
      "title": "Stance detection on social media with fine-tuned large language models",
      "authors": [
        "Ilker Gül",
        "Rémi Lebret",
        "Karl Aberer"
      ],
      "year": "2024",
      "venue": "Stance detection on social media with fine-tuned large language models",
      "arxiv": "arXiv:2404.12171"
    },
    {
      "citation_id": "60",
      "title": "Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning",
      "authors": [
        "Dejian Daya Guo",
        "Haowei Yang",
        "Junxiao Zhang",
        "Ruoyu Song",
        "Runxin Zhang",
        "Qihao Xu",
        "Shirong Zhu",
        "Peiyi Ma",
        "Xiao Wang",
        "Bi"
      ],
      "year": "2025",
      "venue": "Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning",
      "arxiv": "arXiv:2501.12948"
    },
    {
      "citation_id": "61",
      "title": "A cross-cultural study of humor intensity in chinese and english family jokes: A large language model-based approach",
      "authors": [
        "Yihui Guo"
      ],
      "year": "2025",
      "venue": "International Journal of Linguistics Studies"
    },
    {
      "citation_id": "62",
      "title": "-stance: A large-scale real world dataset of stances in legal argumentation",
      "authors": [
        "Ankita Gupta",
        "Douglas Rice",
        "Brendan O' Connor"
      ],
      "year": "2025",
      "venue": "Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "63",
      "title": "Design knowledge as attention emphasizer in large language model-based sentiment analysis",
      "authors": [
        "Yi Han",
        "Mohsen Moghaddam"
      ],
      "year": "2025",
      "venue": "Journal of Computing and Information Science in Engineering"
    },
    {
      "citation_id": "64",
      "title": "Using large language models for sentiment analysis of health-related social media data: empirical evaluation and practical tips",
      "authors": [
        "Lu He",
        "Samaneh Omranian",
        "Susan Mcroy",
        "Kai Zheng"
      ],
      "year": "2024",
      "venue": "medRxiv"
    },
    {
      "citation_id": "65",
      "title": "Chumor 1.0: A truly funny and challenging chinese humor understanding dataset from ruo zhi ba",
      "authors": [
        "Ruiqi He",
        "Yushu He",
        "Longju Bai",
        "Jiarui Liu",
        "Zhenjie Sun",
        "Zenghao Tang",
        "He Wang",
        "Hanchen Xia",
        "Naihao Deng"
      ],
      "year": "2024",
      "venue": "Chumor 1.0: A truly funny and challenging chinese humor understanding dataset from ruo zhi ba",
      "arxiv": "arXiv:2406.12754"
    },
    {
      "citation_id": "66",
      "title": "Chumor 2.0: Towards better benchmarking chinese humor understanding from (ruo zhi ba)",
      "authors": [
        "Ruiqi He",
        "Yushu He",
        "Longju Bai",
        "Jiarui Liu",
        "Zhenjie Sun",
        "Zenghao Tang",
        "He Wang",
        "Hanchen Xia",
        "Rada Mihalcea",
        "Naihao Deng"
      ],
      "year": "2025",
      "venue": "Findings of the Association for Computational Linguistics: ACL 2025"
    },
    {
      "citation_id": "67",
      "title": "The extimate core of understanding: absolute metaphors, psychosis and large language models",
      "authors": [
        "Marc Heimann",
        "Anne-Friederike Hübener"
      ],
      "year": "2025",
      "venue": "AI & SOCIETY"
    },
    {
      "citation_id": "68",
      "title": "Exploring large language models for the generation of synthetic training samples for aspect-based sentiment analysis in low resource settings",
      "authors": [
        "Nils Constantin Hellwig",
        "Jakob Fehle",
        "Christian Wolff"
      ],
      "year": "2025",
      "venue": "Expert Syst. Appl"
    },
    {
      "citation_id": "69",
      "title": "Effective intended sarcasm detection using fine-tuned llama 2 large language models",
      "authors": [
        "Dennis Fachry",
        "Zakhralativa Heraldi",
        "Ruskanda"
      ],
      "year": "2024",
      "venue": "2024 11th International Conference on Advanced Informatics: Concept, Theory and Application (ICAICTA)"
    },
    {
      "citation_id": "70",
      "title": "Aer-llm: Ambiguity-aware emotion recognition leveraging large language models",
      "authors": [
        "Xin Hong",
        "Yuan Gong",
        "Vidhyasaharan Sethu",
        "Ting Dang"
      ],
      "year": "2025",
      "venue": "ICASSP 2025-2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
    },
    {
      "citation_id": "71",
      "title": "Lora: Low-rank adaptation of large language models",
      "authors": [
        "J Edward",
        "Yelong Hu",
        "Phillip Shen",
        "Zeyuan Wallis",
        "Yuanzhi Allen-Zhu",
        "Shean Li",
        "Lu Wang",
        "Weizhu Wang",
        "Chen"
      ],
      "year": "2022",
      "venue": "ICLR"
    },
    {
      "citation_id": "72",
      "title": "Emobench-m: Benchmarking emotional intelligence for multimodal large language models",
      "authors": [
        "Y Hu",
        "L Zhou",
        "H You",
        "Q Xu",
        "Z Wang",
        "Lian",
        "F Yu",
        "L Ma",
        "Cui"
      ],
      "year": "2025",
      "venue": "Emobench-m: Benchmarking emotional intelligence for multimodal large language models"
    },
    {
      "citation_id": "73",
      "title": "Cracking the code of juxtaposition: Can ai models understand the humorous contradictions",
      "authors": [
        "Zhe Hu",
        "Tuo Liang",
        "Jing Li",
        "Yiren Lu",
        "Yunlai Zhou",
        "Yiran Qiao",
        "Jing Ma",
        "Yu Yin"
      ],
      "year": "2024",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "74",
      "title": "Gpt-4o system card",
      "authors": [
        "Aaron Hurst",
        "Adam Lerer",
        "Adam Goucher",
        "Adam Perelman",
        "Aditya Ramesh",
        "Aidan Clark",
        "Akila Ostrow",
        "Alan Welihinda",
        "Alec Hayes",
        "Radford"
      ],
      "year": "2024",
      "venue": "Gpt-4o system card",
      "arxiv": "arXiv:2410.21276"
    },
    {
      "citation_id": "75",
      "title": "Bottlehumor: Self-informed humor explanation using the information bottleneck principle",
      "authors": [
        "Eunjeong Hwang",
        "Peter West",
        "Vered Shwartz"
      ],
      "year": "2025",
      "venue": "Bottlehumor: Self-informed humor explanation using the information bottleneck principle",
      "arxiv": "arXiv:2502.18331"
    },
    {
      "citation_id": "76",
      "title": "Interpretation of novel literary metaphors by humans and gpt-4",
      "authors": [
        "Nicholas Ichien",
        "Du Stamenkoviƒá",
        "Keith Holyoak"
      ],
      "year": "2024",
      "venue": "Proceedings of the Annual Meeting of the Cognitive Science Society"
    },
    {
      "citation_id": "77",
      "title": "Large language model adaptation for financial sentiment analysis",
      "authors": [
        "Mariam Pau Rodriguez Inserte",
        "Raheel Nakhlé",
        "Gaetan Qader",
        "Jingshu Caillaut",
        "Liu"
      ],
      "year": "2024",
      "venue": "Large language model adaptation for financial sentiment analysis",
      "arxiv": "arXiv:2401.14777"
    },
    {
      "citation_id": "78",
      "title": "Felipe dos Santos Alves Feitosa, and Gabriel Kreiman. Is ai fun? humordb: a curated dataset and benchmark to investigate graphical humor",
      "authors": [
        "Veedant Jain"
      ],
      "year": "2024",
      "venue": "Felipe dos Santos Alves Feitosa, and Gabriel Kreiman. Is ai fun? humordb: a curated dataset and benchmark to investigate graphical humor",
      "arxiv": "arXiv:2406.13564"
    },
    {
      "citation_id": "79",
      "title": "Dual modality-aware gated prompt tuning for few-shot multimodal sarcasm detection",
      "authors": [
        "Soumyadeep Jana",
        "Abhrajyoti Kundu",
        "Sanasam Ranbir Singh"
      ],
      "year": "2025",
      "venue": "Dual modality-aware gated prompt tuning for few-shot multimodal sarcasm detection",
      "arxiv": "arXiv:2507.04468"
    },
    {
      "citation_id": "80",
      "title": "Think twice before you judge: Mixture of dual reasoning experts for multimodal sarcasm detection",
      "authors": [
        "Soumyadeep Jana",
        "Abhrajyoti Kundu",
        "Sanasam Ranbir Singh"
      ],
      "year": "2025",
      "venue": "Think twice before you judge: Mixture of dual reasoning experts for multimodal sarcasm detection",
      "arxiv": "arXiv:2507.04458"
    },
    {
      "citation_id": "81",
      "title": "",
      "authors": [
        "Albert Jiang",
        "Alexandre Sablayrolles",
        "Arthur Mensch",
        "Chris Bamford",
        "Devendra Singh Chaplot",
        "Diego De Las Casas",
        "Florian Bressand",
        "Gianna Lengyel",
        "Guillaume Lample",
        "Lucile Saulnier",
        "Renard Lélio",
        "Marie-Anne Lavaud",
        "Pierre Lachaux",
        "Teven Stock",
        "Thibaut Le Scao",
        "Thomas Lavril",
        "Timothée Wang",
        "William Lacroix",
        "Sayed"
      ],
      "year": "2023",
      "venue": ""
    },
    {
      "citation_id": "82",
      "title": "",
      "authors": [
        "Alexandre Albert Q Jiang",
        "Antoine Sablayrolles",
        "Arthur Roux",
        "Blanche Mensch",
        "Chris Savary",
        "Devendra Bamford",
        "Diego Singh Chaplot",
        "Emma De Las Casas",
        "Florian Hanna",
        "Bressand"
      ],
      "year": "2024",
      "venue": "",
      "arxiv": "arXiv:2401.04088"
    },
    {
      "citation_id": "83",
      "title": "Can large language models be good emotional supporter? mitigating preference bias on emotional support conversation",
      "authors": [
        "Dongjin Kang",
        "Sunghwan Kim",
        "Taeyoon Kwon",
        "Seungjun Moon",
        "Hyunsouk Cho",
        "Youngjae Yu",
        "Dongha Lee",
        "Jinyoung Yeo"
      ],
      "year": "2024",
      "venue": "Can large language models be good emotional supporter? mitigating preference bias on emotional support conversation",
      "arxiv": "arXiv:2402.13211"
    },
    {
      "citation_id": "84",
      "title": "Metaphors in literary machine translation: Close but no cigar?",
      "authors": [
        "Alina Karakanta",
        "Mayra Nas",
        "Aletta Dorst"
      ],
      "year": "2025",
      "venue": "Proceedings of Machine Translation Summit XX"
    },
    {
      "citation_id": "85",
      "title": "Sentimentgpt: Exploiting gpt for advanced sentiment analysis and its departure from current machine learning",
      "authors": [
        "Kiana Kheiri",
        "Hamid Karimi"
      ],
      "year": "2023",
      "venue": "Sentimentgpt: Exploiting gpt for advanced sentiment analysis and its departure from current machine learning",
      "arxiv": "arXiv:2307.10234"
    },
    {
      "citation_id": "86",
      "title": "A large self-annotated corpus for sarcasm",
      "authors": [
        "Mikhail Khodak",
        "Nikunj Saunshi",
        "Kiran Vodrahalli"
      ],
      "year": "2018",
      "venue": "Proceedings of the Linguistic Resource and Evaluation Conference (LREC)"
    },
    {
      "citation_id": "87",
      "title": "Metaphorian: Leveraging large language models to support extended metaphor creation for science writing",
      "authors": [
        "Jeongyeon Kim",
        "Sangho Suh",
        "Lydia Chilton",
        "Haijun Xia"
      ],
      "year": "2023",
      "venue": "Proceedings of the 2023 ACM Designing Interactive Systems Conference"
    },
    {
      "citation_id": "88",
      "title": "Large language models in finance: what is financial sentiment",
      "authors": [
        "Kemal Kirtac",
        "Guido Germano"
      ],
      "year": "2025",
      "venue": "Large language models in finance: what is financial sentiment",
      "arxiv": "arXiv:2503.03612"
    },
    {
      "citation_id": "89",
      "title": "A corpus of non-native written english annotated for metaphor",
      "authors": [
        "Beata Beigman Klebanov",
        "Chee Leong",
        "Michael Flor"
      ],
      "year": "2018",
      "venue": "Proceedings of the 2018 Conference of the North American Chapter"
    },
    {
      "citation_id": "90",
      "title": "Deciphering political entity sentiment in news with large language models: Zero-shot and few-shot strategies",
      "authors": [
        "Alapan Kuila",
        "Sudeshna Sarkar"
      ],
      "year": "2024",
      "venue": "Deciphering political entity sentiment in news with large language models: Zero-shot and few-shot strategies",
      "arxiv": "arXiv:2404.04361"
    },
    {
      "citation_id": "91",
      "title": "Sentiment analysis of the united states public support of nuclear power on social media using large language models",
      "authors": [
        "Katie Hwang Kwon",
        "Naman Vu",
        "Mohammed Bhargava",
        "Jacob Radaideh",
        "Veda Cooper",
        "Majdi Joynt",
        "Radaideh"
      ],
      "year": "2024",
      "venue": "Renewable and Sustainable Energy Reviews"
    },
    {
      "citation_id": "92",
      "title": "Stance detection with collaborative role-infused llm-based agents",
      "authors": [
        "Xiaochong Lan",
        "Chen Gao",
        "Depeng Jin",
        "Yong Li"
      ],
      "year": "2024",
      "venue": "Proceedings of the international AAAI conference on web and social media"
    },
    {
      "citation_id": "93",
      "title": "Chinese fine-grained financial sentiment analysis with large language models",
      "authors": [
        "Yinyu Lan",
        "Yanru Wu",
        "Wang Xu",
        "Weiqiang Feng",
        "Youhao Zhang"
      ],
      "year": "2023",
      "venue": "Chinese fine-grained financial sentiment analysis with large language models"
    },
    {
      "citation_id": "94",
      "title": "Do large language models have \"emotion neurons\"? investigating the existence and role",
      "authors": [
        "Jaewook Lee",
        "Woojin Lee",
        "Oh-Woog Kwon",
        "Harksoo Kim"
      ],
      "year": "2025",
      "venue": "Findings of the Association for Computational Linguistics: ACL 2025"
    },
    {
      "citation_id": "95",
      "title": "Pragmatic metacognitive prompting improves llm performance on sarcasm detection",
      "authors": [
        "Joshua Lee",
        "Wyatt Fong",
        "Alexander Le",
        "Sur Shah",
        "Kevin Han",
        "Kevin Zhu"
      ],
      "year": "2024",
      "venue": "Pragmatic metacognitive prompting improves llm performance on sarcasm detection",
      "arxiv": "arXiv:2412.04509"
    },
    {
      "citation_id": "96",
      "title": "Large vision-language models as emotion recognizers in context awareness",
      "authors": [
        "Yuxuan Lei",
        "Dingkang Yang",
        "Zhaoyu Chen",
        "Jiawei Chen",
        "Peng Zhai",
        "Lihua Zhang"
      ],
      "year": "2024",
      "venue": "Large vision-language models as emotion recognizers in context awareness",
      "arxiv": "arXiv:2407.11300"
    },
    {
      "citation_id": "97",
      "title": "Large language models understand and can be enhanced by emotional stimuli",
      "authors": [
        "Cheng Li",
        "Jindong Wang",
        "Yixuan Zhang",
        "Kaijie Zhu",
        "Wenxin Hou",
        "Jianxun Lian",
        "Fang Luo",
        "Qiang Yang",
        "Xing Xie"
      ],
      "year": "2023",
      "venue": "Large language models understand and can be enhanced by emotional stimuli",
      "arxiv": "arXiv:2307.11760"
    },
    {
      "citation_id": "98",
      "title": "De-identity multimodal emotion recognition and reasoning",
      "authors": [
        "Deng Li",
        "Bohao Xing",
        "Xin Liu",
        "Baiqiang Xia",
        "Bihan Wen",
        "Heikki Kälviäinen",
        "Deemo"
      ],
      "year": "2025",
      "venue": "De-identity multimodal emotion recognition and reasoning",
      "arxiv": "arXiv:2504.19549"
    },
    {
      "citation_id": "99",
      "title": "P-stance: A large dataset for stance detection in political domain",
      "authors": [
        "Yingjie Li",
        "Tiberiu Sosea",
        "Aditya Sawant",
        "Jayaraman Ajith",
        "Diana Nair",
        "Cornelia Inkpen",
        "Caragea"
      ],
      "year": "2021",
      "venue": "Findings of the association for computational linguistics: ACL-IJCNLP 2021"
    },
    {
      "citation_id": "100",
      "title": "Revise, reason, and recognize: Llm-based emotion recognition via emotion-specific prompts and asr error correction",
      "authors": [
        "Yuanchao Li",
        "Yuan Gong",
        "Chao-Han Huck",
        "Peter Yang",
        "Catherine Bell",
        "Lai"
      ],
      "year": "2025",
      "venue": "ICASSP 2025-2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
    },
    {
      "citation_id": "101",
      "title": "Enhancing emotional generation capability of large language models via emotional chain-of-thought",
      "authors": [
        "Zaijing Li",
        "Gongwei Chen",
        "Rui Shao",
        "Yuquan Xie",
        "Dongmei Jiang",
        "Liqiang Nie"
      ],
      "year": "2024",
      "venue": "Enhancing emotional generation capability of large language models via emotional chain-of-thought",
      "arxiv": "arXiv:2401.06836"
    },
    {
      "citation_id": "102",
      "title": "Leveraging large language models for sarcastic speech annotation in sarcasm detection",
      "authors": [
        "Zhu Li",
        "Yuqing Zhang",
        "Xiyuan Gao",
        "Shekhar Nayak",
        "Matt Coler"
      ],
      "year": "2025",
      "venue": "Leveraging large language models for sarcastic speech annotation in sarcasm detection",
      "arxiv": "arXiv:2506.00955"
    },
    {
      "citation_id": "103",
      "title": "Affectgpt: A new dataset, model, and benchmark for emotion understanding with multimodal large language models",
      "authors": [
        "Zheng Lian",
        "Haoyu Chen",
        "Lan Chen",
        "Haiyang Sun",
        "Licai Sun",
        "Yong Ren",
        "Zebang Cheng",
        "Bin Liu",
        "Rui Liu",
        "Xiaojiang Peng"
      ],
      "year": "2025",
      "venue": "Affectgpt: A new dataset, model, and benchmark for emotion understanding with multimodal large language models",
      "arxiv": "arXiv:2501.16566"
    },
    {
      "citation_id": "104",
      "title": "M3hg: Multimodal, multi-scale, and multi-type node heterogeneous graph for emotion cause triplet extraction in conversations",
      "authors": [
        "Qiao Liang",
        "Ying Shen",
        "Tiantian Chen",
        "Lin Zhang"
      ],
      "year": "2025",
      "venue": "Findings of the Association for Computational Linguistics: ACL 2025"
    },
    {
      "citation_id": "105",
      "title": "Cofipara: a coarse-to-fine paradigm for multimodal sarcasm target identification with large multimodal models",
      "authors": [
        "Hongzhan Lin",
        "Zixin Chen",
        "Ziyang Luo",
        "Mingfei Cheng",
        "Jing Ma",
        "Guang Chen"
      ],
      "year": "2024",
      "venue": "Cofipara: a coarse-to-fine paradigm for multimodal sarcasm target identification with large multimodal models",
      "arxiv": "arXiv:2405.00390"
    },
    {
      "citation_id": "106",
      "title": "A dual-perspective metaphor detection framework using large language models",
      "authors": [
        "Yujie Lin",
        "Jingyao Liu",
        "Yan Gao",
        "Ante Wang",
        "Jinsong Su"
      ],
      "year": "2025",
      "venue": "ICASSP 2025-2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
    },
    {
      "citation_id": "107",
      "title": "Do large language models possess sensitive to sentiment? arXiv preprint",
      "authors": [
        "Yang Liu",
        "Xichou Zhu",
        "Zhou Shen",
        "Yi Liu",
        "Min Li",
        "Yujun Chen",
        "Benzi John",
        "Zhenzhen Ma",
        "Tao Hu",
        "Zhi Li"
      ],
      "year": "2024",
      "venue": "Do large language models possess sensitive to sentiment? arXiv preprint",
      "arxiv": "arXiv:2409.02370"
    },
    {
      "citation_id": "108",
      "title": "A robustly optimized bert pretraining approach",
      "authors": [
        "Yinhan Liu",
        "Myle Ott",
        "Naman Goyal",
        "Jingfei Du",
        "Mandar Joshi",
        "Danqi Chen",
        "Omer Levy",
        "Mike Lewis",
        "Luke Zettlemoyer",
        "Veselin Stoyanov",
        "Roberta"
      ],
      "year": "2019",
      "venue": "A robustly optimized bert pretraining approach",
      "arxiv": "arXiv:1907.11692"
    },
    {
      "citation_id": "109",
      "title": "Emollms: A series of emotional large language models and annotation tools for comprehensive affective analysis",
      "authors": [
        "Zhiwei Liu",
        "Kailai Yang",
        "Qianqian Xie",
        "Tianlin Zhang",
        "Sophia Ananiadou"
      ],
      "year": "2024",
      "venue": "Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining"
    },
    {
      "citation_id": "110",
      "title": "Caf-i: A collaborative multi-agent framework for enhanced irony detection with large language models",
      "authors": [
        "Ziqi Liu",
        "Ziyang Zhou",
        "Mingxuan Hu"
      ],
      "year": "2025",
      "venue": "Caf-i: A collaborative multi-agent framework for enhanced irony detection with large language models",
      "arxiv": "arXiv:2506.08430"
    },
    {
      "citation_id": "111",
      "title": "Ii-bench: An image implication understanding benchmark for multimodal large language models",
      "authors": [
        "Ziqiang Liu",
        "Feiteng Fang",
        "Xi Feng",
        "Xeron Du",
        "Chenhao Zhang",
        "Noah Wang",
        "Qixuan Zhao",
        "Liyang Fan",
        "Chengguang Gan",
        "Hongquan Lin"
      ],
      "year": "2024",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "112",
      "title": "Gpt-4 as an x data annotator: Unraveling its performance on a stance classification task",
      "authors": [
        "Ravi Chandreen R Liyanage",
        "Vijay Gokani",
        "Mago"
      ],
      "year": "2024",
      "venue": "PloS one"
    },
    {
      "citation_id": "113",
      "title": "Developing conversational virtual humans for social emotion elicitation based on large language models",
      "authors": [
        "Jose Llanes-Jurado",
        "Lucía Gómez-Zaragozá",
        "Maria Minissi",
        "Mariano Alcañiz",
        "Javier Marín-Morales"
      ],
      "year": "2024",
      "venue": "Expert Systems with Applications"
    },
    {
      "citation_id": "114",
      "title": "Exploring multi-agent debate for zero-shot stance detection: A novel approach",
      "authors": [
        "Junxia Ma",
        "Changjiang Wang",
        "Lu Rong",
        "Bo Wang",
        "Yaoli Xu"
      ],
      "year": "2025",
      "venue": "Applied Sciences"
    },
    {
      "citation_id": "115",
      "title": "Chain of stance: Stance detection with large language models",
      "authors": [
        "Junxia Ma",
        "Changjiang Wang",
        "Hanwen Xing",
        "Dongming Zhao",
        "Yazhou Zhang"
      ],
      "year": "2024",
      "venue": "CCF International Conference on Natural Language Processing and Chinese Computing"
    },
    {
      "citation_id": "116",
      "title": "Comparative advances in financial sentiment analysis: A review of bert, finbert, and large language models",
      "authors": [
        "Manish Barath Mahendran",
        "Aswin Kumar Gokul",
        "Poornima Lakshmi",
        "Pavithra"
      ],
      "year": "2025",
      "venue": "2025 3rd International Conference on Intelligent Data Communication Technologies and Internet of Things (IDCIoT)"
    },
    {
      "citation_id": "117",
      "title": "Is llama 3 good at sarcasm detection? a comprehensive study",
      "authors": [
        "Zhelu Mai",
        "Jinran Zhang",
        "Zhuoer Xu",
        "Zhaomin Xiao"
      ],
      "year": "2024",
      "venue": "Proceedings of the 2024 7th International Conference on Machine Learning and Machine Intelligence (MLMI)"
    },
    {
      "citation_id": "118",
      "title": "A comparative analysis of metaphorical cognition in chatgpt and human minds",
      "authors": [
        "Rui Mao",
        "Guanyi Chen",
        "Xiao Li",
        "Mengshi Ge",
        "Erik Cambria"
      ],
      "year": "2025",
      "venue": "Cognitive Computation"
    },
    {
      "citation_id": "119",
      "title": "Metapro 2.0: Computational metaphor processing on the effectiveness of anomalous language modeling",
      "authors": [
        "Rui Mao",
        "Kai He",
        "Claudia Ong",
        "Qian Liu",
        "Erik Cambria"
      ],
      "year": "2024",
      "venue": "Findings of the Association for Computational Linguistics ACL 2024"
    },
    {
      "citation_id": "120",
      "title": "Large language models prompt engineering as a method for embodied cognitive linguistic representation: a case study of political metaphors in trump's discourse",
      "authors": [
        "Haohan Meng",
        "Xiaoyu Li",
        "Jinhua Sun"
      ],
      "year": "2025",
      "venue": "Frontiers in Psychology"
    },
    {
      "citation_id": "121",
      "title": "Efficient estimation of word representations in vector space",
      "authors": [
        "Tomas Mikolov",
        "Kai Chen",
        "Greg Corrado",
        "Jeffrey Dean"
      ],
      "year": "2013",
      "venue": "Efficient estimation of word representations in vector space",
      "arxiv": "arXiv:1301.3781"
    },
    {
      "citation_id": "122",
      "title": "A robot walks into a bar: Can language models serve as creativity supporttools for comedy? an evaluation of llms' humour alignment with comedians",
      "authors": [
        "Piotr Mirowski",
        "Juliette Love",
        "Kory Mathewson",
        "Shakir Mohamed"
      ],
      "year": "2024",
      "venue": "Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency"
    },
    {
      "citation_id": "123",
      "title": "Metaphor as a medium for emotion: An empirical study",
      "authors": [
        "Saif Mohammad",
        "Ekaterina Shutova",
        "Peter Turney"
      ],
      "year": "2016",
      "venue": "Proceedings of the fifth joint conference on lexical and computational semantics"
    },
    {
      "citation_id": "124",
      "title": "Introducing the lcc metaphor datasets",
      "authors": [
        "Michael Mohler",
        "Mary Brunson",
        "Bryan Rink",
        "Marc Tomlinson"
      ],
      "year": "2016",
      "venue": "Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC'16)"
    },
    {
      "citation_id": "125",
      "title": "Comparative analysis of deep natural networks and large language models for aspect-based sentiment analysis",
      "authors": [
        "Nimra Mughal",
        "Ghulam Mujtaba",
        "Sarang Shaikh",
        "Aveenash Kumar",
        "Sher Daudpota"
      ],
      "year": "2024",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "126",
      "title": "Recognizing emotion regulation strategies from human behavior with large language models",
      "authors": [
        "Philipp Müller",
        "Alexander Heimerl",
        "Lea Sayed Muddashir Hossain",
        "Jan Siegel",
        "Patrick Alexandersson",
        "Elisabeth Gebhard",
        "Tanja André",
        "Schneeberger"
      ],
      "year": "2024",
      "venue": "2024 12th International Conference on Affective Computing and Intelligent Interaction (ACII)"
    },
    {
      "citation_id": "127",
      "title": "Leveraging large language models for sentiment analysis and investment strategy development in financial markets",
      "authors": [
        "Yejoon Mun",
        "Namhyoung Kim"
      ],
      "year": "2025",
      "venue": "Journal of Theoretical and Applied Electronic Commerce Research"
    },
    {
      "citation_id": "128",
      "title": "Vision-enabled large language and deep learning models for image-based emotion recognition",
      "authors": [
        "Mohammad Nadeem",
        "Saquib Shahab",
        "Laeeba Sohail",
        "Faisal Javed",
        "Abdul Anwer",
        "Jilani Khader",
        "Khan Saudagar",
        "Muhammad"
      ],
      "year": "2024",
      "venue": "Cognitive Computation"
    },
    {
      "citation_id": "129",
      "title": "Which llms get the joke? probing non-stem reasoning abilities with humorbench",
      "authors": [
        "Reuben Narad",
        "Siddharth Suresh",
        "Jiayi Chen",
        "S Pine",
        "Bob Dysart-Bricken",
        "Robert Mankoff",
        "Jifan Nowak",
        "Lalit Zhang",
        "Jain"
      ],
      "year": "2025",
      "venue": "Which llms get the joke? probing non-stem reasoning abilities with humorbench",
      "arxiv": "arXiv:2507.21476"
    },
    {
      "citation_id": "130",
      "title": "Examining the influence of political bias on large language model performance in stance classification",
      "authors": [
        "Lynnette Hui",
        "Xian Ng",
        "Iain Cruickshank",
        "Roy Lee"
      ],
      "year": "2025",
      "venue": "Proceedings of the International AAAI Conference on Web and Social Media"
    },
    {
      "citation_id": "131",
      "title": "Multimodal multi-turn conversation stance detection: A challenge dataset and effective model",
      "authors": [
        "Fuqiang Niu",
        "Zebang Cheng",
        "Xianghua Fu",
        "Xiaojiang Peng",
        "Genan Dai",
        "Yin Chen",
        "Hu Huang",
        "Bowen Zhang"
      ],
      "year": "2024",
      "venue": "Proceedings of the 32nd ACM international conference on multimedia"
    },
    {
      "citation_id": "132",
      "title": "A challenge dataset and effective models for conversational stance detection",
      "authors": [
        "Fuqiang Niu",
        "Min Yang",
        "Ang Li",
        "Baoquan Zhang",
        "Xiaojiang Peng",
        "Bowen Zhang"
      ],
      "year": "2024",
      "venue": "A challenge dataset and effective models for conversational stance detection",
      "arxiv": "arXiv:2403.11145"
    },
    {
      "citation_id": "133",
      "title": "Rethinking emotion annotations in the era of large language models",
      "authors": [
        "Minxue Niu",
        "Yara El-Tawil",
        "Amrit Romana",
        "Emily Provost"
      ],
      "year": "2025",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "134",
      "title": "Training language models to follow instructions with human feedback",
      "authors": [
        "Long Ouyang",
        "Jeffrey Wu",
        "Xu Jiang",
        "Diogo Almeida",
        "Carroll Wainwright",
        "Pamela Mishkin",
        "Chong Zhang",
        "Sandhini Agarwal",
        "Katarina Slama",
        "Alex Ray"
      ],
      "year": "2022",
      "venue": "Advances in neural information processing systems"
    },
    {
      "citation_id": "135",
      "title": "Customising general large language models for specialised emotion recognition tasks",
      "authors": [
        "Liyizhe Peng",
        "Zixing Zhang",
        "Tao Pang",
        "Jing Han",
        "Huan Zhao",
        "Hao Chen",
        "Björn Schuller"
      ],
      "year": "2024",
      "venue": "ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
    },
    {
      "citation_id": "136",
      "title": "Whose side are you on? investigating the political stance of large language models",
      "authors": [
        "Pagnarasmey Pit",
        "Xingjun Ma",
        "Mike Conway",
        "Qingyu Chen",
        "James Bailey",
        "Henry Pit",
        "Putrasmey Keo",
        "Watey Diep",
        "Yu-Gang Jiang"
      ],
      "year": "2024",
      "venue": "Whose side are you on? investigating the political stance of large language models",
      "arxiv": "arXiv:2403.13840"
    },
    {
      "citation_id": "137",
      "title": "Jokes or gibberish? humor retention in translation with neural machine translation vs. large language model. Humor Retention in Translation with Neural Machine Translation vs",
      "authors": [
        "Mondheera Pituxcoosuvarn",
        "Yohei Murakami"
      ],
      "venue": "Jokes or gibberish? humor retention in translation with neural machine translation vs. large language model. Humor Retention in Translation with Neural Machine Translation vs"
    },
    {
      "citation_id": "138",
      "title": "Recognizing emotion cause in conversations",
      "authors": [
        "Soujanya Poria",
        "Navonil Majumder",
        "Devamanyu Hazarika",
        "Deepanway Ghosal",
        "Rishabh Bhardwaj",
        "Samson Yu Bai Jian",
        "Pengfei Hong",
        "Romila Ghosh",
        "Abhinaba Roy",
        "Niyati Chhaya"
      ],
      "year": "2021",
      "venue": "Computation"
    },
    {
      "citation_id": "139",
      "title": "Concept drift guided layernorm tuning for efficient multimodal metaphor identification",
      "authors": [
        "Wenhao Qian",
        "Zhenzhen Hu",
        "Zijie Song",
        "Jia Li"
      ],
      "year": "2025",
      "venue": "Proceedings of the 2025 International Conference on Multimedia Retrieval"
    },
    {
      "citation_id": "140",
      "title": "Detecting emotional incongruity of sarcasm by commonsense reasoning",
      "authors": [
        "Ziqi Qiu",
        "Jianxing Yu",
        "Yufeng Zhang",
        "Hanjiang Lai",
        "Yanghui Rao",
        "Qinliang Su",
        "Jian Yin"
      ],
      "year": "2025",
      "venue": "Proceedings of the 31st International Conference on Computational Linguistics"
    },
    {
      "citation_id": "141",
      "title": "Can ai take a joke-or make one? a study of humor generation and recognition in llms",
      "authors": [
        "Kexin Quan",
        "Pavithra Ramakrishnan",
        "Jessie Chin"
      ],
      "year": "2025",
      "venue": "Proceedings of the 2025 Conference on Creativity and Cognition"
    },
    {
      "citation_id": "142",
      "title": "Fairness and social bias quantification in large language models for sentiment analysis. Knowledge-Based Systems",
      "authors": [
        "O Mohammed I Radaideh",
        "Majdi Hwang Kwon",
        "Radaideh"
      ],
      "year": "2025",
      "venue": "Fairness and social bias quantification in large language models for sentiment analysis. Knowledge-Based Systems"
    },
    {
      "citation_id": "143",
      "title": "Robust speech recognition via large-scale weak supervision",
      "authors": [
        "Alec Radford",
        "Jong Kim",
        "Tao Xu",
        "Greg Brockman",
        "Christine Mcleavey",
        "Ilya Sutskever"
      ],
      "year": "2023",
      "venue": "International conference on machine learning"
    },
    {
      "citation_id": "144",
      "title": "Improving language understanding by generative pre-training",
      "authors": [
        "Alec Radford",
        "Karthik Narasimhan",
        "Tim Salimans",
        "Ilya Sutskever"
      ],
      "year": "2018",
      "venue": "Improving language understanding by generative pre-training"
    },
    {
      "citation_id": "145",
      "title": "Language models are unsupervised multitask learners",
      "authors": [
        "Alec Radford",
        "Jeffrey Wu",
        "Rewon Child",
        "David Luan",
        "Dario Amodei",
        "Ilya Sutskever"
      ],
      "year": "2019",
      "venue": "OpenAI blog"
    },
    {
      "citation_id": "146",
      "title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
      "authors": [
        "Colin Raffel",
        "Noam Shazeer",
        "Adam Roberts",
        "Katherine Lee",
        "Sharan Narang",
        "Michael Matena",
        "Yanqi Zhou",
        "Wei Li",
        "Peter Liu"
      ],
      "year": "2020",
      "venue": "Journal of machine learning research"
    },
    {
      "citation_id": "147",
      "title": "Towards empathetic open-domain conversation models: A new benchmark and dataset",
      "authors": [
        "Eric Hannah Rashkin",
        "Margaret Smith",
        "Y-Lan Li",
        "Boureau"
      ],
      "year": "2018",
      "venue": "Towards empathetic open-domain conversation models: A new benchmark and dataset",
      "arxiv": "arXiv:1811.00207"
    },
    {
      "citation_id": "148",
      "title": "Emotion-aware embedding fusion in large language models (flan-t5, llama 2, deepseekr1, and chatgpt 4) for intelligent response generation",
      "authors": [
        "Abdur Rasool",
        "Muhammad Irfan Shahzad",
        "Hafsa Aslam",
        "Vincent Chan",
        "Muhammad Ali"
      ],
      "year": "2025",
      "venue": "AI"
    },
    {
      "citation_id": "149",
      "title": "Duanzai: Slang-enhanced llm with prompt for humor understanding",
      "authors": [
        "Yesian Rohn"
      ],
      "year": "2024",
      "venue": "Duanzai: Slang-enhanced llm with prompt for humor understanding",
      "arxiv": "arXiv:2405.15818"
    },
    {
      "citation_id": "150",
      "title": "From twitter to reasoner: Understand mobility travel modes and sentiment using large language models",
      "authors": [
        "Xinyang Kangrui Ruan",
        "Xuan Wang",
        "Di"
      ],
      "year": "2024",
      "venue": "From twitter to reasoner: Understand mobility travel modes and sentiment using large language models"
    },
    {
      "citation_id": "151",
      "title": "Comparative analysis of large language model as feature extraction methods in sarcasm detection using classification algorithms",
      "authors": [
        "Nathaniel Darrel",
        "Dinar Sabera",
        "Kristiyanti Ajeng"
      ],
      "year": "2025",
      "venue": "2025 4th International Conference on Electronics Representation and Algorithm (ICERA)"
    },
    {
      "citation_id": "152",
      "title": "Evaluating the emotional intelligence of large language models",
      "authors": [
        "Sahand Sabour",
        "Siyang Liu",
        "Zheyuan Zhang",
        "June Liu",
        "Jinfeng Zhou",
        "S Alvionna",
        "Juanzi Sunaryo",
        "Tatia Li",
        "Rada Lee",
        "Minlie Mihalcea",
        "Huang",
        "Emobench"
      ],
      "year": "2024",
      "venue": "Evaluating the emotional intelligence of large language models",
      "arxiv": "arXiv:2402.12071"
    },
    {
      "citation_id": "153",
      "title": "Chacha: leveraging large language models to prompt children to share their emotions about personal events",
      "authors": [
        "Woosuk Seo",
        "Chanmo Yang",
        "Young-Ho Kim"
      ],
      "year": "2024",
      "venue": "Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems"
    },
    {
      "citation_id": "154",
      "title": "Dynamic financial sentiment analysis and market forecasting through large language models",
      "authors": [
        "Haranadha Reddy",
        "Busireddy Seshakagari",
        "Aravindan Umashankar",
        "T Harikala",
        "L Jayasree",
        "Jeffrey Severance"
      ],
      "year": "2025",
      "venue": "International Journal of Human Computations and Intelligence"
    },
    {
      "citation_id": "155",
      "title": "Not all jokes land: Evaluating large language models understanding of workplace humor",
      "authors": [
        "Mohammadamin Shafiei",
        "Hamidreza Saffari"
      ],
      "year": "2025",
      "venue": "Not all jokes land: Evaluating large language models understanding of workplace humor",
      "arxiv": "arXiv:2506.01819"
    },
    {
      "citation_id": "156",
      "title": "Cmdag: A chinese metaphor dataset with annotated grounds as cot for boosting metaphor generation",
      "authors": [
        "Yujie Shao",
        "Xinrong Yao",
        "Xingwei Qu",
        "Chenghua Lin",
        "Shi Wang",
        "Stephen Huang",
        "Ge Zhang",
        "Jie Fu"
      ],
      "year": "2024",
      "venue": "Cmdag: A chinese metaphor dataset with annotated grounds as cot for boosting metaphor generation",
      "arxiv": "arXiv:2402.13145"
    },
    {
      "citation_id": "157",
      "title": "Revisiting time-varying dynamics in stock market forecasting: A multi-source sentiment analysis approach with large language model",
      "authors": [
        "Zhiqi Shao",
        "Xusheng Yao",
        "Feng Chen",
        "Ze Wang",
        "Junbin Gao"
      ],
      "year": "2025",
      "venue": "Decis. Support Syst"
    },
    {
      "citation_id": "158",
      "title": "Large language models for aspect-based sentiment analysis",
      "authors": [
        "Paul Simmering",
        "Paavo Huoviala"
      ],
      "year": "2023",
      "venue": "Large language models for aspect-based sentiment analysis"
    },
    {
      "citation_id": "159",
      "title": "Hallucination or confabulation? neuroanatomy as metaphor in large language models",
      "authors": [
        "L Andrew",
        "Felix Smith",
        "Trishan Greaves",
        "Panch"
      ],
      "year": "2023",
      "venue": "PLOS Digital Health"
    },
    {
      "citation_id": "160",
      "title": "Using deepspeed and megatron to train megatron-turing nlg 530b, a large-scale generative language model",
      "authors": [
        "Shaden Smith",
        "Mostofa Patwary",
        "Brandon Norick",
        "Patrick Legresley",
        "Samyam Rajbhandari",
        "Jared Casper",
        "Zhun Liu",
        "Shrimai Prabhumoye",
        "George Zerveas",
        "Vijay Korthikanti"
      ],
      "year": "2022",
      "venue": "Using deepspeed and megatron to train megatron-turing nlg 530b, a large-scale generative language model",
      "arxiv": "arXiv:2201.11990"
    },
    {
      "citation_id": "161",
      "title": "Emotion-o1: Adaptive long reasoning for emotion understanding in llms",
      "authors": [
        "Changhao Song",
        "Yazhou Zhang",
        "Peng Zhang"
      ],
      "year": "2025",
      "venue": "Emotion-o1: Adaptive long reasoning for emotion understanding in llms",
      "arxiv": "arXiv:2505.22548"
    },
    {
      "citation_id": "162",
      "title": "Besstie: A benchmark for sentiment and sarcasm classification for varieties of english",
      "authors": [
        "Dipankar Srirag",
        "Aditya Joshi",
        "Jordan Painter",
        "Diptesh Kanojia"
      ],
      "year": "2024",
      "venue": "Besstie: A benchmark for sentiment and sarcasm classification for varieties of english",
      "arxiv": "arXiv:2412.04726"
    },
    {
      "citation_id": "163",
      "title": "A method for linguistic metaphor identification",
      "authors": [
        "Aletta Gerard J Steen",
        "Tina Dorst",
        "Anna Krennmayr",
        "J Berenike Kaal",
        "Herrmann"
      ],
      "year": "2010",
      "venue": "A method for linguistic metaphor identification"
    },
    {
      "citation_id": "164",
      "title": "Large language models performance comparison of emotion and sentiment classification",
      "authors": [
        "William Stigall",
        "Md Abdullah",
        "Al Hafiz Khan",
        "Dinesh Chowdary Attota",
        "Francis Nweke",
        "Yong Pei"
      ],
      "year": "2024",
      "venue": "Proceedings of the 2024 ACM Southeast Conference, ACM SE 2024"
    },
    {
      "citation_id": "165",
      "title": "Idsarcasm: Benchmarking and evaluating language models for indonesian sarcasm detection",
      "authors": [
        "Derwin Suhartono",
        "Wilson Wongso",
        "Alif Tri Handoyo"
      ],
      "year": "2024",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "166",
      "title": "Leveraging generative large language models with visual instruction and demonstration retrieval for multimodal sarcasm detection",
      "authors": [
        "Binghao Tang",
        "Boda Lin",
        "Haolong Yan",
        "Si Li"
      ],
      "year": "2024",
      "venue": "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies"
    },
    {
      "citation_id": "167",
      "title": "From metaphor to mechanism: How llms decode traditional chinese medicine symbolic language for modern clinical relevance",
      "authors": [
        "Jiacheng Tang",
        "Nankai Wu",
        "Fan Gao",
        "Chengxiao Dai",
        "Mengyao Zhao",
        "Xinjie Zhao"
      ],
      "year": "2025",
      "venue": "From metaphor to mechanism: How llms decode traditional chinese medicine symbolic language for modern clinical relevance",
      "arxiv": "arXiv:2503.02760"
    },
    {
      "citation_id": "168",
      "title": "Alpaca: A strong, replicable instructionfollowing model. Stanford Center for Research on Foundation Models",
      "authors": [
        "Rohan Taori",
        "Ishaan Gulrajani",
        "Tianyi Zhang",
        "Yann Dubois",
        "Xuechen Li",
        "Carlos Guestrin",
        "Percy Liang",
        "Tatsunori B Hashimoto"
      ],
      "venue": "Alpaca: A strong, replicable instructionfollowing model. Stanford Center for Research on Foundation Models"
    },
    {
      "citation_id": "169",
      "title": "Stance reasoner: Zero-shot stance detection on social media with explicit reasoning",
      "authors": [
        "Maksym Taranukhin",
        "Vered Shwartz",
        "Evangelos Milios"
      ],
      "year": "2024",
      "venue": "Stance reasoner: Zero-shot stance detection on social media with explicit reasoning",
      "arxiv": "arXiv:2403.14895"
    },
    {
      "citation_id": "170",
      "title": "a family of highly capable multimodal models",
      "authors": [
        "Gemini Team",
        "Rohan Anil",
        "Sebastian Borgeaud",
        "Jean-Baptiste Alayrac",
        "Jiahui Yu",
        "Radu Soricut",
        "Johan Schalkwyk",
        "Andrew Dai",
        "Anja Hauth",
        "Katie Millican"
      ],
      "year": "2023",
      "venue": "a family of highly capable multimodal models",
      "arxiv": "arXiv:2312.11805"
    },
    {
      "citation_id": "171",
      "title": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
      "authors": [
        "Gemini Team",
        "Petko Georgiev",
        "Ian Ving",
        "Ryan Lei",
        "Libin Burnell",
        "Anmol Bai",
        "Garrett Gulati",
        "Damien Tanzer",
        "Zhufeng Vincent",
        "Shibo Pan",
        "Wang"
      ],
      "year": "2024",
      "venue": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
      "arxiv": "arXiv:2403.05530"
    },
    {
      "citation_id": "172",
      "title": "Gemma 2: Improving open language models at a practical size",
      "authors": [
        "Gemma Team",
        "Morgane Riviere",
        "Shreya Pathak",
        "Giuseppe Sessa",
        "Cassidy Hardin",
        "Surya Bhupatiraju",
        "Léonard Hussenot",
        "Thomas Mesnard",
        "Bobak Shahriari",
        "Alexandre Ramé"
      ],
      "year": "2024",
      "venue": "Gemma 2: Improving open language models at a practical size",
      "arxiv": "arXiv:2408.00118"
    },
    {
      "citation_id": "173",
      "title": "Imara: An imaginative frame augmented method for low-resource multimodal metaphor detection and explanation",
      "authors": [
        "Minzheng Yuan Tian",
        "Nan Wang",
        "Wenji Xu",
        "Mao"
      ],
      "year": "2025",
      "venue": "Findings of the Association for Computational Linguistics: NAACL 2025"
    },
    {
      "citation_id": "174",
      "title": "A theory guided scaffolding instruction framework for llm-enabled metaphor reasoning",
      "authors": [
        "Nan Yuan Tian",
        "Wenji Xu",
        "Mao"
      ],
      "year": "2024",
      "venue": "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies"
    },
    {
      "citation_id": "175",
      "title": "Linear representations of sentiment in large language models",
      "authors": [
        "Curt Tigges",
        "John Oskar",
        "Atticus Hollinsworth",
        "Neel Geiger",
        "Nanda"
      ],
      "year": "2023",
      "venue": "Linear representations of sentiment in large language models",
      "arxiv": "arXiv:2310.15154"
    },
    {
      "citation_id": "176",
      "title": "Metaphor understanding challenge dataset for llms",
      "authors": [
        "Xiaoyu Tong",
        "Rochelle Choenni",
        "Martha Lewis",
        "Ekaterina Shutova"
      ],
      "year": "2024",
      "venue": "Metaphor understanding challenge dataset for llms",
      "arxiv": "arXiv:2403.11810"
    },
    {
      "citation_id": "177",
      "title": "Open and efficient foundation language models",
      "authors": [
        "Hugo Touvron",
        "Thibaut Lavril",
        "Gautier Izacard",
        "Xavier Martinet",
        "Marie-Anne Lachaux",
        "Timothée Lacroix",
        "Baptiste Rozière",
        "Naman Goyal",
        "Eric Hambro",
        "Faisal Azhar"
      ],
      "year": "2023",
      "venue": "Open and efficient foundation language models",
      "arxiv": "arXiv:2302.13971"
    },
    {
      "citation_id": "178",
      "title": "Llama 2: Open foundation and fine-tuned chat models",
      "authors": [
        "Hugo Touvron",
        "Louis Martin",
        "Kevin Stone",
        "Peter Albert",
        "Amjad Almahairi",
        "Yasmine Babaei",
        "Nikolay Bashlykov",
        "Soumya Batra",
        "Prajjwal Bhargava",
        "Shruti Bhosale"
      ],
      "year": "2023",
      "venue": "Llama 2: Open foundation and fine-tuned chat models",
      "arxiv": "arXiv:2307.09288"
    },
    {
      "citation_id": "179",
      "title": "Exploring vision language models for multimodal and multilingual stance detection",
      "authors": [
        "Jake Vasilakes",
        "Carolina Scarton",
        "Zhixue Zhao"
      ],
      "year": "2025",
      "venue": "Exploring vision language models for multimodal and multilingual stance detection",
      "arxiv": "arXiv:2501.17654"
    },
    {
      "citation_id": "180",
      "title": "Attention is all you need",
      "authors": [
        "Ashish Vaswani",
        "Noam Shazeer",
        "Niki Parmar",
        "Jakob Uszkoreit",
        "Llion Jones",
        "Aidan Gomez",
        "Łukasz Kaiser",
        "Illia Polosukhin"
      ],
      "year": "2017",
      "venue": "Advances in neural information processing systems"
    },
    {
      "citation_id": "181",
      "title": "Large language model-driven sentiment analysis for facilitating fibromyalgia diagnosis",
      "authors": [
        "Vincenzo Venerito",
        "Florenzo Iannone"
      ],
      "venue": "RMD open"
    },
    {
      "citation_id": "182",
      "title": "The emotional intelligence of the gpt-4 large language model",
      "authors": [
        "D Gleb",
        "Vzorinab",
        "M Alexey",
        "Anna Bukinichac",
        "Irina Sedykha",
        "Elena Vetrovab",
        "Sergienkob"
      ],
      "year": "2024",
      "venue": "Psychology in Russia: State of the art"
    },
    {
      "citation_id": "183",
      "title": "Does gpt-3 grasp metaphors? identifying metaphor mappings with generative language models",
      "authors": [
        "Lennart Wachowiak",
        "Dagmar Gromann"
      ],
      "year": "2023",
      "venue": "Proceedings of the 61st annual meeting of the association for computational linguistics"
    },
    {
      "citation_id": "184",
      "title": "Memecraft: Contextual and stance-driven multimodal meme generation",
      "authors": [
        "Han Wang",
        "Ka-Wei Lee"
      ],
      "year": "2024",
      "venue": "Proceedings of the ACM Web Conference 2024"
    },
    {
      "citation_id": "185",
      "title": "Public sentiment analysis of data center energy consumption using social media data and large language models",
      "authors": [
        "Hongyu Wang",
        "Weiqi Hua",
        "Jinqing Peng",
        "Maomao Hu"
      ],
      "year": "2025",
      "venue": "Energy and Buildings"
    },
    {
      "citation_id": "186",
      "title": "S3 agent: unlocking the power of vllm for zero-shot multi-modal sarcasm detection",
      "authors": [
        "Peng Wang",
        "Yongheng Zhang",
        "Hao Fei",
        "Qiguang Chen",
        "Yukai Wang",
        "Jiasheng Si",
        "Wenpeng Lu",
        "Min Li",
        "Libo Qin"
      ],
      "year": "2024",
      "venue": "ACM Transactions on Multimedia Computing, Communications and Applications"
    },
    {
      "citation_id": "187",
      "title": "Deem: Dynamic experienced expert modeling for stance detection",
      "authors": [
        "Xiaolong Wang",
        "Yile Wang",
        "Sijie Cheng",
        "Peng Li",
        "Yang Liu"
      ],
      "year": "2024",
      "venue": "Deem: Dynamic experienced expert modeling for stance detection",
      "arxiv": "arXiv:2402.15264"
    },
    {
      "citation_id": "188",
      "title": "Emotional intelligence of large language models",
      "authors": [
        "Xuena Wang",
        "Xueting Li",
        "Zi Yin",
        "Yue Wu",
        "Jia Liu"
      ],
      "year": "2023",
      "venue": "Journal of Pacific Rim Psychology"
    },
    {
      "citation_id": "189",
      "title": "Chain-of-thought prompting elicits reasoning in large language models",
      "authors": [
        "Jason Wei",
        "Xuezhi Wang",
        "Dale Schuurmans",
        "Maarten Bosma",
        "Fei Xia",
        "Ed Chi",
        "V Quoc",
        "Denny Le",
        "Zhou"
      ],
      "year": "2022",
      "venue": "Advances in neural information processing systems"
    },
    {
      "citation_id": "190",
      "title": "Are large language models more empathetic than humans? arXiv preprint",
      "authors": [
        "Anuradha Welivita",
        "Pearl Pu"
      ],
      "year": "2024",
      "venue": "Are large language models more empathetic than humans? arXiv preprint",
      "arxiv": "arXiv:2406.05063"
    },
    {
      "citation_id": "191",
      "title": "Evaluating zero-shot multilingual aspect-based sentiment analysis with large language models",
      "authors": [
        "Chengyan Wu",
        "Bolei Ma",
        "Zheyu Zhang",
        "Ningyuan Deng",
        "Yanqing He",
        "Yun Xue"
      ],
      "year": "2025",
      "venue": "International Journal of Machine Learning and Cybernetics"
    },
    {
      "citation_id": "192",
      "title": "Sect: Sentiment-enriched continual training for image sentiment analysis",
      "authors": [
        "Lifang Wu",
        "Lehao Xing",
        "Ge Shi",
        "Sinuo Deng",
        "Jie Yang"
      ],
      "year": "2023",
      "venue": "International Conference on Image and Graphics"
    },
    {
      "citation_id": "193",
      "title": "Humour classification by fine-tuning llms: Cyut at clef 2024 joker lab subtask humour classification according to genre and technique",
      "authors": [
        "Shih-Hung Wu",
        "Yu-Feng Huang",
        "Tsz-Yeung Lau"
      ],
      "year": "2024",
      "venue": "Working Notes of the Conference and Labs of the Evaluation Forum (CLEF 2024)"
    },
    {
      "citation_id": "194",
      "title": "Humorreject: Decoupling llm safety from refusal prefix via a little humor",
      "authors": [
        "Zihui Wu",
        "Haichang Gao",
        "Jiacheng Luo",
        "Zhaoxiang Liu"
      ],
      "year": "2025",
      "venue": "Humorreject: Decoupling llm safety from refusal prefix via a little humor",
      "arxiv": "arXiv:2501.13677"
    },
    {
      "citation_id": "195",
      "title": "Dynamic detection of sarcasm topic-target pairs via llm-based knowledge alignment",
      "authors": [
        "Mengyu Xiang",
        "Yuxuan Song",
        "Qiudan Li",
        "Shu Wu",
        "Daniel Zeng"
      ],
      "year": "2025",
      "venue": "Companion Proceedings of the ACM on Web Conference 2025"
    },
    {
      "citation_id": "196",
      "title": "Emovit: Revolutionizing emotion insights with visual instruction tuning",
      "authors": [
        "Hongxia Xie",
        "Chu-Jun Peng",
        "Yu-Wen Tseng",
        "Hung-Jen Chen",
        "Chan-Feng Hsu",
        "Hong-Han Shuai",
        "Wen-Huang Cheng"
      ],
      "year": "2024",
      "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition"
    },
    {
      "citation_id": "197",
      "title": "Evaluating emotion hallucinations in multimodal large language models",
      "authors": [
        "Bohao Xing",
        "Xin Liu",
        "Guoying Zhao",
        "Chengyu Liu",
        "Xiaolan Fu",
        "Heikki Kälviäinen",
        "Emotionhallucer"
      ],
      "year": "2025",
      "venue": "Evaluating emotion hallucinations in multimodal large language models",
      "arxiv": "arXiv:2505.11405"
    },
    {
      "citation_id": "198",
      "title": "Emo-llama: Enhancing facial emotion understanding with instruction tuning",
      "authors": [
        "Bohao Xing",
        "Zitong Yu",
        "Xin Liu",
        "Kaishen Yuan",
        "Qilang Ye",
        "Weicheng Xie",
        "Huanjing Yue",
        "Jingyu Yang",
        "Heikki Kälviäinen"
      ],
      "year": "2024",
      "venue": "Emo-llama: Enhancing facial emotion understanding with instruction tuning",
      "arxiv": "arXiv:2408.11424"
    },
    {
      "citation_id": "199",
      "title": "Secap: Speech emotion captioning with large language model",
      "authors": [
        "Yaoxun Xu",
        "Hangting Chen",
        "Jianwei Yu",
        "Qiaochu Huang",
        "Zhiyong Wu",
        "Shi-Xiong Zhang",
        "Guangzhi Li",
        "Yi Luo",
        "Rongzhi Gu"
      ],
      "year": "2024",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence"
    },
    {
      "citation_id": "200",
      "title": "Evaluating large language models' ability using a psychiatric screening tool based on metaphor and sarcasm scenarios",
      "authors": [
        "Hiromu Yakura"
      ],
      "year": "2024",
      "venue": "Journal of Intelligence"
    },
    {
      "citation_id": "201",
      "title": "Collaborative knowledge infusion for low-resource stance detection",
      "authors": [
        "Ming Yan",
        "Tianyi Zhou",
        "W Tsang"
      ],
      "year": "2024",
      "venue": "Big Data Mining and Analytics"
    },
    {
      "citation_id": "202",
      "title": "Collaborative stance detection via small-large language model consistency verification",
      "authors": [
        "Yu Yan",
        "Sheng Sun",
        "Zixiang Tang",
        "Teli Liu",
        "Min Liu"
      ],
      "year": "2025",
      "venue": "Collaborative stance detection via small-large language model consistency verification",
      "arxiv": "arXiv:2502.19954"
    },
    {
      "citation_id": "203",
      "title": "",
      "authors": [
        "An Yang",
        "Baosong Yang",
        "Binyuan Hui",
        "Bo Zheng",
        "Bowen Yu",
        "Chang Zhou",
        "Chengpeng Li",
        "Chengyuan Li",
        "Dayiheng Liu",
        "Fei Huang",
        "Guanting Dong",
        "Haoran Wei",
        "Huan Lin",
        "Jialong Tang",
        "Jialin Wang",
        "Jian Yang",
        "Jianhong Tu",
        "Jianwei Zhang",
        "Jianxin Ma",
        "Jianxin Yang",
        "Jin Xu",
        "Jingren Zhou",
        "Jinze Bai",
        "Jinzheng He",
        "Junyang Lin",
        "Kai Dang",
        "Keming Lu",
        "Keqin Chen",
        "Kexin Yang",
        "Mei Li",
        "Mingfeng Xue",
        "Na Ni",
        "Pei Zhang",
        "Peng Wang",
        "Ru Peng",
        "Rui Men",
        "Ruize Gao",
        "Runji Lin",
        "Shijie Wang",
        "Shuai Bai",
        "Sinan Tan",
        "Tianhang Zhu",
        "Tianhao Li",
        "Tianyu Liu",
        "Wenbin Ge",
        "Xiaodong Deng",
        "Xiaohuan Zhou",
        "Xingzhang Ren",
        "Xinyu Zhang",
        "Xipin Wei",
        "Xuancheng Ren",
        "Xuejing Liu",
        "Yang Fan",
        "Yang Yao",
        "Yichang Zhang",
        "Yu Wan",
        "Yunfei Chu"
      ],
      "year": "2024",
      "venue": ""
    },
    {
      "citation_id": "204",
      "title": "Advancing emotional analysis with large language models",
      "authors": [
        "Haowei Yang",
        "Yun Zi",
        "Honglin Qin",
        "Hongye Zheng",
        "Yuxiang Hu"
      ],
      "year": "2024",
      "venue": "Journal of Computer Science and Software Applications"
    },
    {
      "citation_id": "205",
      "title": "Omni-emotion: Extending video mllm with detailed face and audio modeling for multimodal emotion analysis",
      "authors": [
        "Qize Yang",
        "Detao Bai",
        "Yi-Xing Peng",
        "Xihan Wei"
      ],
      "year": "2025",
      "venue": "Omni-emotion: Extending video mllm with detailed face and audio modeling for multimodal emotion analysis",
      "arxiv": "arXiv:2501.09502"
    },
    {
      "citation_id": "206",
      "title": "Emollm: Multimodal emotional understanding meets large language models",
      "authors": [
        "Qu Yang",
        "Mang Ye",
        "Bo Du"
      ],
      "year": "2024",
      "venue": "Emollm: Multimodal emotional understanding meets large language models",
      "arxiv": "arXiv:2406.16442"
    },
    {
      "citation_id": "207",
      "title": "Reinforcement tuning for detecting stances and debunking rumors jointly with large language models",
      "authors": [
        "Ruichao Yang",
        "Wei Gao",
        "Jing Ma",
        "Hongzhan Lin",
        "Bo Wang"
      ],
      "year": "2024",
      "venue": "Reinforcement tuning for detecting stances and debunking rumors jointly with large language models",
      "arxiv": "arXiv:2406.02143"
    },
    {
      "citation_id": "208",
      "title": "Performance evaluation and application potential of small large language models in complex sentiment analysis tasks",
      "authors": [
        "Yunchu Yang",
        "Jiaxuan Li",
        "Jielong Guo",
        "Patrick Cheong-Iao",
        "Yapeng Pang",
        "Xu Wang",
        "Sio Yang",
        "Im Kei"
      ],
      "year": "2025",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "209",
      "title": "Is sarcasm detection a step-by-step reasoning process in large language models?",
      "authors": [
        "Y Yao",
        "Q Zhang",
        "Li",
        "Qin"
      ],
      "year": "2024",
      "venue": "Is sarcasm detection a step-by-step reasoning process in large language models?",
      "arxiv": "arXiv:2407.12725"
    },
    {
      "citation_id": "210",
      "title": "Is sarcasm detection a step-by-step reasoning process in large language models?",
      "authors": [
        "Ben Yao",
        "Yazhou Zhang",
        "Qiuchi Li",
        "Jing Qin"
      ],
      "year": "2025",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence"
    },
    {
      "citation_id": "211",
      "title": "Towards dialogic and on-demand metaphors for interdisciplinary reading",
      "authors": [
        "Matin Yarmand",
        "Courtney Reed",
        "Udayan Tandon",
        "Eric Hekler",
        "Nadir Weibel",
        "April Yi"
      ],
      "year": "2025",
      "venue": "Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems"
    },
    {
      "citation_id": "212",
      "title": "Can chatgpt be served as the sentiment expert? an evaluation of chatgpt on sentiment and metaphor analysis",
      "authors": [
        "Zhang Yazhou",
        "Wang Mengyao",
        "Rong Lu",
        "Yu Yang",
        "Zhao Dongming",
        "Qin Jing"
      ],
      "year": "2024",
      "venue": "Acta Scientiarum Naturalium Universitatis Pekinensis"
    },
    {
      "citation_id": "213",
      "title": "Exploring the power of cross-contextual large language model in mimic emotion prediction",
      "authors": [
        "Guofeng Yi",
        "Yuguang Yang",
        "Yu Pan",
        "Yuhang Cao",
        "Jixun Yao",
        "Xiang Lv",
        "Cunhang Fan",
        "Zhao Lv",
        "Jianhua Tao",
        "Shan Liang"
      ],
      "year": "2023",
      "venue": "Proceedings of the 4th on Multimodal Sentiment Analysis Challenge and Workshop: Mimicked Emotions, Humour and Personalisation"
    },
    {
      "citation_id": "214",
      "title": "What's next in affective modeling? large language models",
      "authors": [
        "Nutchanon Yongsatianchot",
        "Tobias Thejll-Madsen",
        "Stacy Marsella"
      ],
      "year": "2023",
      "venue": "2023 11th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW)"
    },
    {
      "citation_id": "215",
      "title": "Compound expression recognition via large vision-language models",
      "authors": [
        "Jun Yu",
        "Xilong Lu"
      ],
      "year": "2025",
      "venue": "Compound expression recognition via large vision-language models",
      "arxiv": "arXiv:2503.11241"
    },
    {
      "citation_id": "216",
      "title": "Cfunmodel: A\" funny\" language model capable of chinese humor generation and processing",
      "authors": [
        "Zhenghan Yu",
        "Xinyu Hu",
        "Xiaojun Wan"
      ],
      "year": "2025",
      "venue": "Cfunmodel: A\" funny\" language model capable of chinese humor generation and processing",
      "arxiv": "arXiv:2503.20417"
    },
    {
      "citation_id": "217",
      "title": "Logic augmented multi-decision fusion framework for stance detection on social media",
      "authors": [
        "Bowen Zhang",
        "Jun Ma",
        "Xianghua Fu",
        "Genan Dai"
      ],
      "year": "2025",
      "venue": "Information Fusion"
    },
    {
      "citation_id": "218",
      "title": "Instruct-fingpt: Financial sentiment analysis by instruction tuning of general-purpose large language models",
      "authors": [
        "Boyu Zhang",
        "Hongyang Yang",
        "Xiao-Yang Liu"
      ],
      "year": "2023",
      "venue": "Instruct-fingpt: Financial sentiment analysis by instruction tuning of general-purpose large language models",
      "arxiv": "arXiv:2306.12659"
    },
    {
      "citation_id": "219",
      "title": "Enhancing financial sentiment analysis via retrieval augmented large language models",
      "authors": [
        "Boyu Zhang",
        "Hongyang Yang",
        "Tianyu Zhou",
        "Muhammad Ali Babar",
        "Xiao-Yang Liu"
      ],
      "year": "2023",
      "venue": "Proceedings of the fourth ACM international conference on AI in finance"
    },
    {
      "citation_id": "220",
      "title": "Multimodal metaphor recognition based on chain-of-cognition prompting",
      "authors": [
        "Dongyu Zhang",
        "Xingyuan Lu",
        "Mulin Zhuang",
        "Senqi Yang",
        "Hongjun Chen"
      ],
      "year": "2025",
      "venue": "Cognitive Systems Research"
    },
    {
      "citation_id": "221",
      "title": "Towards multimodal metaphor understanding: A chinese dataset and model for metaphor mapping identification",
      "authors": [
        "Dongyu Zhang",
        "Shengcheng Yin",
        "Jingwei Yu",
        "Zhiyao Wu",
        "Zhen Li",
        "Chengpei Xu",
        "Xiaoxia Wang",
        "Feng Xia"
      ],
      "year": "2025",
      "venue": "Towards multimodal metaphor understanding: A chinese dataset and model for metaphor mapping identification",
      "arxiv": "arXiv:2501.02434"
    },
    {
      "citation_id": "222",
      "title": "Revisiting sentiment analysis for software engineering in the era of large language models",
      "authors": [
        "Ting Zhang",
        "Ivana Clairine Irsan",
        "Ferdian Thung",
        "David Lo"
      ],
      "year": "2025",
      "venue": "ACM Transactions on Software Engineering and Methodology"
    },
    {
      "citation_id": "223",
      "title": "Sinno Jialin Pan, and Lidong Bing. Sentiment analysis in the era of large language models: A reality check",
      "authors": [
        "Wenxuan Zhang",
        "Yue Deng",
        "Bing Liu"
      ],
      "year": "2023",
      "venue": "Sinno Jialin Pan, and Lidong Bing. Sentiment analysis in the era of large language models: A reality check",
      "arxiv": "arXiv:2305.15005"
    },
    {
      "citation_id": "224",
      "title": "Dialoguellm: context and emotion knowledge-tuned large language models for emotion recognition in conversations",
      "authors": [
        "M Zhang",
        "Y Wang",
        "Li Q Tiwari Wu",
        "B Prayag",
        "Wang",
        "Qin"
      ],
      "year": "2023",
      "venue": "Dialoguellm: context and emotion knowledge-tuned large language models for emotion recognition in conversations"
    },
    {
      "citation_id": "225",
      "title": "Towards evaluating large language models on sarcasm understanding",
      "authors": [
        "C Zhang",
        "Z Zou",
        "P Lian",
        "J Tiwari",
        "Qin",
        "Sarcasmbench"
      ],
      "year": "2024",
      "venue": "Towards evaluating large language models on sarcasm understanding"
    },
    {
      "citation_id": "226",
      "title": "Pushing the limit of llm capacity for text classification",
      "authors": [
        "Yazhou Zhang",
        "Mengyao Wang",
        "Qiuchi Li",
        "Prayag Tiwari",
        "Jing Qin"
      ],
      "year": "2025",
      "venue": "Companion Proceedings of the ACM on Web Conference 2025"
    },
    {
      "citation_id": "227",
      "title": "Are mlms trapped in the visual room? arXiv preprint",
      "authors": [
        "Yazhou Zhang",
        "Chunwang Zou",
        "Qimeng Liu",
        "Lu Rong",
        "Ben Yao",
        "Zheng Lian",
        "Qiuchi Li",
        "Peng Zhang",
        "Jing Qin"
      ],
      "year": "2025",
      "venue": "Are mlms trapped in the visual room? arXiv preprint",
      "arxiv": "arXiv:2505.23272"
    },
    {
      "citation_id": "228",
      "title": "Commander-gpt: Fully unleashing the sarcasm detection capability of multi-modal large language models",
      "authors": [
        "Yazhou Zhang",
        "Chunwang Zou",
        "Bo Wang",
        "Jing Qin"
      ],
      "year": "2025",
      "venue": "Commander-gpt: Fully unleashing the sarcasm detection capability of multi-modal large language models",
      "arxiv": "arXiv:2503.18681"
    },
    {
      "citation_id": "229",
      "title": "Affective computing in the era of large language models: A survey from the nlp perspective",
      "authors": [
        "Yiqun Zhang",
        "Xiaocui Yang",
        "Xingle Xu",
        "Zeran Gao",
        "Yijie Huang",
        "Shiyi Mu",
        "Shi Feng",
        "Daling Wang",
        "Yifei Zhang",
        "Kaisong Song"
      ],
      "year": "2024",
      "venue": "Affective computing in the era of large language models: A survey from the nlp perspective",
      "arxiv": "arXiv:2408.04638"
    },
    {
      "citation_id": "230",
      "title": "Llm-driven knowledge injection advances zero-shot and cross-target stance detection",
      "authors": [
        "Zhao Zhang",
        "Yiming Li",
        "Jin Zhang",
        "Hui Xu"
      ],
      "year": "2024",
      "venue": "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies"
    },
    {
      "citation_id": "231",
      "title": "Refashioning emotion recognition modeling: the advent of generalized large models",
      "authors": [
        "Zixing Zhang",
        "Liyizhe Peng",
        "Tao Pang",
        "Jing Han",
        "Huan Zhao",
        "Björn Schuller"
      ],
      "year": "2024",
      "venue": "IEEE Transactions on Computational Social Systems"
    },
    {
      "citation_id": "232",
      "title": "Ez-stance: A large dataset for english zero-shot stance detection",
      "authors": [
        "Chenye Zhao",
        "Cornelia Caragea"
      ],
      "year": "2024",
      "venue": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "233",
      "title": "Zerostance: Leveraging chatgpt for open-domain stance detection via dataset generation",
      "authors": [
        "Chenye Zhao",
        "Yingjie Li",
        "Cornelia Caragea",
        "Yue Zhang"
      ],
      "year": "2024",
      "venue": "Findings of the Association for Computational Linguistics ACL 2024"
    },
    {
      "citation_id": "234",
      "title": "Eilmob: Emotion-aware incongruity learning and modality bridging network for multi-modal sarcasm detection",
      "authors": [
        "Haochen Zhao",
        "Yongxiu Xu",
        "Xinkui Lin",
        "Jiarui Lu",
        "Hongbo Xu",
        "Yubin Wang"
      ],
      "year": "2025",
      "venue": "Proceedings of the 2025 International Conference on Multimedia Retrieval"
    },
    {
      "citation_id": "235",
      "title": "R1-omni: Explainable omni-multimodal emotion recognition with reinforcement learning",
      "authors": [
        "Jiaxing Zhao",
        "Xihan Wei",
        "Liefeng Bo"
      ],
      "year": "2025",
      "venue": "R1-omni: Explainable omni-multimodal emotion recognition with reinforcement learning",
      "arxiv": "arXiv:2503.05379"
    },
    {
      "citation_id": "236",
      "title": "Enhancing hyperbole and metaphor detection with their bidirectional dynamic interaction and emotion knowledge",
      "authors": [
        "Li Zheng",
        "Sihang Wang",
        "Hao Fei",
        "Zuquan Peng",
        "Fei Li",
        "Jianming Fu",
        "Chong Teng",
        "Donghong Ji"
      ],
      "year": "2025",
      "venue": "Enhancing hyperbole and metaphor detection with their bidirectional dynamic interaction and emotion knowledge",
      "arxiv": "arXiv:2506.15504"
    },
    {
      "citation_id": "237",
      "title": "Ldgnet: Llms debate-guided network for multimodal sarcasm detection",
      "authors": [
        "Hengyang Zhou",
        "Jinwu Yan",
        "Yaqing Chen",
        "Rongman Hong",
        "Wenbo Zuo",
        "Keyan Jin"
      ],
      "year": "2025",
      "venue": "ICASSP 2025-2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
    },
    {
      "citation_id": "238",
      "title": "An evaluation of state-of-the-art large language models for sarcasm detection",
      "authors": [
        "Juliann Zhou"
      ],
      "year": "2023",
      "venue": "An evaluation of state-of-the-art large language models for sarcasm detection",
      "arxiv": "arXiv:2312.03706"
    },
    {
      "citation_id": "239",
      "title": "Cascade your datasets for cross-mode knowledge retrieval of language models",
      "authors": [
        "Runlong Zhou",
        "Yi Zhang"
      ],
      "year": "2025",
      "venue": "Cascade your datasets for cross-mode knowledge retrieval of language models",
      "arxiv": "arXiv:2504.01450"
    },
    {
      "citation_id": "240",
      "title": "Ratsd: Retrieval augmented truthfulness stance detection from social media posts toward factual claims",
      "authors": [
        "Zhengyuan Zhu",
        "Zeyu Zhang",
        "Haiqi Zhang",
        "Chengkai Li"
      ],
      "year": "2025",
      "venue": "Findings of the Association for Computational Linguistics: NAACL 2025"
    },
    {
      "citation_id": "241",
      "title": "Leveraging large language models to examine the interaction between investor sentiment and stock performance",
      "authors": [
        "Yong Zhuang",
        "Feilong Wang",
        "K Dickson",
        "Kevin Chiu",
        "Ho"
      ],
      "year": "2025",
      "venue": "Eng. Appl. Artif. Intell"
    }
  ]
}