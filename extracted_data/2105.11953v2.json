{
  "paper_id": "2105.11953v2",
  "title": "Emotion Recognition In Horses With Convolutional Neural Networks",
  "published": "2021-05-25T14:04:43Z",
  "authors": [
    "Luis A. Corujo",
    "Peter A. Gloor",
    "Emily Kieson",
    "Timo Schloesser"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Creating intelligent systems capable of recognizing emotions is a difficult task, especially when looking at emotions in animals. This paper describes the process of designing a \"proof of concept\" system to recognize emotions in horses. This system is formed by two elements, a detector and a model. The detector is a fast region-based convolutional neural network that detects horses in an image. The model is a convolutional neural network that predicts the emotions of those horses. These two elements were trained with multiple images of horses until they achieved high accuracy in their tasks. In total, 400 images of horses were collected and labeled to train both the detector and the model while 40 were used to test the system. Once the two components were validated, they were combined into a testable system that would detect equine emotions based on established behavioral ethograms indicating emotional affect through head, neck, ear, muzzle and eye position. The system showed an accuracy of 80% on the validation set and 65% on the test set, demonstrating that it is possible to predict emotions in animals using autonomous intelligent systems. Such a system has multiple applications including further studies in the growing field of animal emotions as well as in the veterinary field to determine the physical welfare of horses or other livestock.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "There is currently no scientific consensus on defining emotion since an emotion is a subjective mental state associated with the nervous system  [1] , but there is growing research in emotions in animals related to defining emotions as subjective affect that creates both physiological and behavioral responses  [2] . There is extensive research in the human world regarding emotional affects and the effects on behavior and emotional expressions (most of which are based on subjective interviews or standardized questionnaires). As humans, we can gauge emotions based on facial cues, voice tone, posture and other hints  [3] . However, our prediction might be wrong, and a person who appears to be happy may in reality be sad  [4, 5] . This suggests that observers can perceive emotions from the subject but that the truth of the emotion may be lost in interpretation. Animals experience emotions in a similar way that can be just as difficult to discern. Since Charles Darwin, who was one of the first to write about this topic, many scientists have done research in the field of animal emotions. Jaak Panksepp, one of the pioneers in affective neuroscience, identified seven different emotions that animals can feel  [6] . Most of the research has been done in mammals because of their similarity to humans and because many of them produce facial expressions that bear a clear resemblance to the expressions seen in humans  [7] .\n\nThere is also growing research indicating the emotional breadth of animals and the ability to measure it through similar physiological and behavioral measures  [2, 8] . While the field of research on dog emotions has continued to flourish, research in agricultural animal emotions is growing at a slower rate. There is, however, a large body of research supporting the use of heart rate variability (HRV) in farm animals and the correlation with cortisol (as an indicator of stress) and behavioral responses as a means of assessing emotional states in domestic livestock  [9, 10] .\n\nHorses are still considered livestock by the United States Department of Agriculture (USDA) and have also been studied for correlations between physiological markers (HRV and cortisol) and behavioral pa erns, suggesting that there is a possibility of assessing equine emotional states through behavioral indicators. Studies in stress behaviors, for example, link elevated plasma cortisol levels with increased HRV and specific behavioral pa erns, such as elevated head and neck position, widened eyes, variations in ear positions (ranging from forward to indicate alert/a entive to pinned back against the head to indicate higher levels of distress), and increased muscle tension and body movements  [11] [12] [13] . Furthermore, existing ethograms in equine behaviors of feral and semi-feral horse herds show that behavioral expression in feral herds also supports the connection between behavioral expression, intention, and potential emotional affect when taken in the context of social interactions and communication  [14] [15] [16] .\n\nCorrelations between physiological measurements and behavioral parameters have already been used to study the psychological and emotional welfare of horses  [17] [18] [19]  and qualitative measures of behavioral indicators have also been used to assess equine emotional state  [20, 21] . Furthermore, with the development of Equine Facial Action Coding System (EquiFACS)  [22]  and the Equine Pain Face coding system  [23] , researchers and practitioners have become even more aware of the ability to look at muscles in both body and face to assess expressions of physical and psychological health, especially related to pain and discomfort. Such facial recognition has been incorporated into machine learning and video coding software to help researchers and practitioners develop be er techniques to decipher pain in equids  [24] [25] [26] . The use of these measures and assessment tools supports the development of standardized methods of assessing behavioral parameters and suggesting emotional affect based on existing studies in behavior, physiological measures, and species-specific ethograms.\n\nTechnology already exists to examine emotional expressions in humans. With the improvements in technology during the last few decades, researchers have studied multiple ways of how to recognize emotions in humans using different techniques, such as Markov models, artificial neural networks, and Bayesian networks, among others.\n\nThe automation of emotion recognition employs three main approaches: First, there are knowledge-based techniques that predict emotions based on semantic and syntactic knowledge; statistical methods, which commonly are machine learning algorithms that predict emotions given a big enough data set; and hybrid approaches, which are a combination of the previous two. Many companies have been successful in predicting emotions in humans using these approaches. A good example is the work done by Affectiva  [27] , a company founded at Massachuse s Institute of Technology (MIT) that uses facial and voice cues to predict emotions. So, the question arises of whether we can create an intelligent system with the ability to predict emotions of animals based on body and facial expressions. Most of the research conducted on animal emotions has been done in mammals, mainly from a psychological and neuroscience perspective  [7, 28] , with growing work done in looking at equine emotional facial expressions using the EquiFACs and Pain Face coding systems  [22, 23] .\n\nIn addition, most of the research focuses on the ability of animals to interpret our emotions and not on how we can interpret theirs. Within the group of those that focus on interpreting the expressions of the animals, most of them do it without using an intelligent or autonomous system. A good example is AnimalFacs, a tool for identifying facial movements in non-human species. The researchers explain how we, as humans, can analyze the facial expressions of different primates, dogs, cats and horses  [7, 22, 29] .\n\nThere is emerging research done on how to interpret animal emotions using an autonomous or intelligent system. One example is the work done by Laura Niklas and Kim Ferres in predicting dog emotions from images  [30] . Another example is the work done at the University of Augsburg on recognizing dog emotions from bark sequences using an autonomous model  [31] . Extant facial emotional recognition software in equids focuses primarily on pain expressions  [24] [25] [26] , with more research needed to classify and code a wider range of emotional expressions. Thus, the idea of predicting animal emotions this way is something that has not yet been explored in depth.\n\nThis paper explores the possibility of creating an intelligent system capable of predicting the emotion of a horse from its face and neck traits based on existing research and ethograms connecting specific head, neck, eye, nose, and ear positions with specific stress levels and emotional valence  [14] [15] [16] 21, [32] [33] [34] . In order to do this, two different elements must be created.\n\nFirst, we need to develop a detector capable of recognizing a horse in an image. More specifically, it needs to detect a region of interest (ROI from now on), which in this case, will be the head and neck of a horse. The task of the detector is a prerequisite for the second part, if the detector does not recognize the appropriate ROI, the second part of the system will not be able to predict the emotion correctly regardless of how well it can accomplish that task.\n\nSecondly, we need a model that, once it receives the detected ROI, is capable of predicting the emotion of the horse. This means this model must be able to detect facial cues and different neck positions and relate them to the appropriate emotion.\n\nAltogether, this should be an intelligent system capable of detecting a horse, analyzing its face and neck features, and predicting its emotion with reasonable accuracy.",
      "page_start": 1,
      "page_end": 3
    },
    {
      "section_name": "Materials And Methods",
      "text": "",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Defining A Horse Emotion Tracking Framework",
      "text": "The first step consists of defining the different emotions, independent of interactions with other horses. Physical markers, head, ear, and neck positions are based on research linking behaviors for arousal and physiological stress with only \"annoyed\" suggesting a negative valence based on previous studies on animal interactions and agonistic behaviors  [14] [15] [16] 21, [32] [33] [34] . The emotion of \"alarmed\" was used to indicated heightened arousal based on eye and ear position using existing ethograms with the understanding that the behavioral indicators of this emotion may also indicate heightened vigilance or alertness in addition to alarm  [16] . The four emotional markers of \"alarmed\", \"annoyed\", \"curious\", and \"relaxed\" were chosen due to their representative variations of arousal level and emotional expression within the existing equid ethograms, with \"relaxed\" representing the lowest level of arousal and \"alarmed\" representing the highest. The initial photographs were marked and defined by the researchers according to existing ethograms. The term \"alarmed\" refers to a heightened state of awareness in which the horse demonstrated behaviors indicating higher arousal levels without significant movement of the feet. Horses have a wide range of facial expressions used to express psychological state as well as communicate with other conspecifics, especially with eyes, ears, and head and neck position  [15, 16, [35] [36] [37] [38] .\n\nAlthough previous studies of horses have investigated their facial expressions in specific contexts, e.g., pain, until now, there has been no methodology available that documents all the possible facial movements of the horse and provides a way to record all potential facial configurations. This is essential for an objective description of horse facial expressions across a range of contexts that reflect different emotional states. Facial Action Coding Systems (FACS) provide a systematic methodology of identifying and coding facial expressions on the basis of underlying facial musculature and muscle movement across species  [29] . FACS are anatomically based and document all possible facial movements rather than a configuration of movements associated with a particular situation. Consequently, FACS can be applied as a tool for a wide range of research questions. The Equine Facial Action Coding System (EquiFACS) provides a system to measure facial expressions in horses based on musculature and skeletal configurations in equids  [22] . On its own, EquiFACS enables researchers to look at distinctive facial movements and changes and, when combined with species-specific knowledge of behaviors, contexts, and behavioral ethograms, creates opportunities to develop connections between these facial configurations and emotional expressions  [22] . Portions of EquiFACS focus on the appearance of the sclera (the whites of the eyes), shape of the eye, tension in the nose, lip, and muzzle, and ear position based on the tension and use of different facial muscles in the horse. EquiFACS also looks at additional musculature and shape changes of the face, lip, nose, eye and ear positions, which are easily differentiated from one another and appear as markers of behavioral pa erns indicative of different levels of arousal and emotional expression in known ethograms of equine behavior  [15, 16, 22, 36] . By combining distinctive expressions supported by EquiFACS with known behavioral expressions of equines, we were able to generalize basic emotional expressions of equines based on distinctive changes in nose, lip, eye, and ear positions.\n\nThe reliability of others to be able to learn this system (EquiFACS) and consistently code behavioral sequences was high, and this included people with no previous experience of horses  [22] . A wide range of facial movements was identified, including many that are also seen in primates and other domestic animals (dogs and cats). EquiFACS provides a method that can be used to document the facial movements associated with different social contexts and thus to address questions relevant to understanding social cognition and comparative psychology, as well as informing current veterinary and animal welfare practices  [22, 38, 39] . These previous results indicate that a combination of head orientation with facial expression, specifically involving both the eyes and ears, is necessary for communicating social a ention. The earlier findings emphasize that in order to understand how a ention is communicated in non-human animals, it is essential to consider a broad range of cues  [22, 38, 39] . Recent developments in understanding horse facial expression suggest that they have many detailed ways of expressing intention and communication. The use of such detailed facial coding systems like EquiFACS and Pain Face helps develop even be er mechanisms for determining levels of stress and pain, especially in close proximity when the nuances of emotional and physical expression need more a ention. In order to simplify the emotional coding tool for this experiment and to test a novel system that could be both portable and useful for the layperson, we broke these up into four emotions (figure  1 ) which were defined with respect to neck and facial cues that could be judged from a distance:",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Alarmed",
      "text": "• Eyes: open eyes with li le or no sclera.\n\n• Ears: stiffly forward.\n\n• Nose: open nostrils, usually slightly tense mouth or muzzle. • Neck: above parallel, head higher than back.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Annoyed",
      "text": "• Eyes: open with perhaps some sclera.\n\n• Ears: stiffly back or pinned back, close to the horse's head.\n\n• Nose: nostrils slightly closed, tense mouth or muzzle.\n\n• Neck: usually parallel or above parallel.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Curious",
      "text": "• Eyes: open with li le or no sclera.\n\n• Ears: pointing forward/sides but relaxed.\n\n• Nose: open nostrils, relaxed mouth and muzzle.\n\n• Neck: usually parallel to ground but may be slightly below or above.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Relaxed",
      "text": "• Eyes: partially to mostly shut.\n\n• Ears: relaxed, opening pointing to the sides.\n\n• Nose: relaxed mouth and muzzle.\n\n• Neck: approximately parallel or below.\n\nOnce the emotions were defined, the second step was to collect the data. In this case, a total of 440 images of horses were collected from private sources where the horses were familiar and the context of the photo was known to help guide the coding of expressions where all four criteria were met. There were a total of 110 images per emotion labeled by two of the authors based on the coding system above that was derived from the aforementioned research on behavioral ethograms. Images were of horses at liberty in large paddocks or pastures with no equipment or observed human presence or interactions. These images were split in training and validation sets in order to train the detector and the model.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Detector",
      "text": "To train the detector, 400 images were used as training data, while the 40 left were used as test data. Every picture was rescaled to 200 pixels in height, keeping the original ratio. This was done to facilitate the work of the detector since having fewer pixels requires less computations, and there is no significant information loss when rescaling to this size. All images were labeled. In this case, labeling the images meant to manually highlight the ROI that the detector was supposed to find.\n\nThe architecture used for animal detection was the faster region-based convolutional neural network (faster R-CNN)  [40] , a well-established architecture for object detection. This architecture is composed of three different parts. First, the convolutional layers, which filter the images in order to extract useful features; secondly, the RPN (Region Proposal Network), whose duty is to identify the possible regions where objects (in this case horses) can be located; and finally, a dense neural network that predicts what kind of object is in each proposed region (in our case, whether there is a horse in each proposed region or not).\n\nDuring the first epochs of training, the detector had difficulties detecting any ROIs, but as training progressed, it began making more accurate detections. After 4000 epochs, it was capable of finding the region of interest with high precision.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Model",
      "text": "Next, a model to predict the emotions was created. This model received images of 150x150 pixels (the rescaled ROI found by the detector) and output predictions (Alarmed, Annoyed, Curious or Relaxed).\n\nThe architecture of this model (figure  2 ) was formed by a convolutional base, a fla ening layer, two fully connected layers (256 and 128 nodes respectively), and a softmax layer (4 nodes, 1 for each emotion). Three different convolutional bases were tested, the base from ResNet50v2, Xception, and VGG16, all with weights from the imagenet dataset. To train the model, only the last convolutional block of layers and the layers on top of this one were trained. They were trained for 25 epochs using 400 pictures (100 for each category) as the data set and 40 pictures (10 for each category) as the test set. Training the first layers of the base didn't make sense in this case. The reason was that these layers learn common pa erns that are present in all images, such as corners or straight lines, and since this base was trained using the 14 million images of the imagenet dataset (a popular dataset to train object recognition models), achieving be er performance with only 400 images was unlikely.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Final Steps",
      "text": "Lastly, in order to facilitate the use of this system, a desktop graphical user interface (GUI) was created. The GUI allows any user to upload an image, processes this image, and displays the ROI with a rectangle (which should be the head and neck of a horse) and the predicted emotion.\n\nIn a nutshell, the system created consists of two separate parts, a detector and a model. The detector receives an image previously rescaled to 200 pixels in height and outputs a ROI, a region of the image with a horse. This ROI is rescaled to 150x150 pixels and is passed to the model, which predicts and outputs the final emotion. A diagram of the entire process can be seen in figure  3 .",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Results",
      "text": "The work resulted in a detector capable of finding a horse's face in an image, a model capable of predicting the emotion of a horse given a picture of its head, and a user-friendly GUI. All of these partial results are discussed in more detail below.\n\nThe detector's precision is very high, and it labeled all 40 test images without a single error. Some of these detections are shown in figure  4 . In order to select the best performing convolutional base, 5-fold cross-validation was performed for each of the models. As displayed in figure  5 , the base training set was divided into five equal chunks consisting of 80 images. Using stratified cross-validation, an equal distribution of all four emotion labels was enforced.\n\nFor each split, a different chunk was selected as the validation set, which results in splits containing 320 training and 80 validation images. After the datasets had been formed, a model was trained for each convolutional base and then validated. Thus, each image was tested exactly once and used for training four times. The accuracy of all five iterations was averaged, and the overall performance of a model was calculated. 5-fold cross-validation reduces variance and ensures that the best convolutional base is selected for the final model. Furthermore, there is a risk of overfi ing due to the relatively small dataset, and we wanted to ensure the generalization ability of the model by exploiting the full potential of the dataset.     Based on the VGG16 convolutional base, the model was then trained with the entire training set consisting of 400 images. Testing the model with the remaining 40 images resulted in a testing accuracy of 65%. Figure  9  shows the confusion matrix of this final evaluation. Figure  10  shows some selected test images with a GradCAM overlay, which visualizes activations of the last convolution layer in a heatmap. Finally, the entire system is brought together by the desktop GUI, which includes the two parts and makes them straightforward for anyone to use. This makes it easy for a user to upload an image and see the ROI and the emotion detected. The graphical user interface is shown in figure  11 .",
      "page_start": 7,
      "page_end": 8
    },
    {
      "section_name": "Discussion",
      "text": "This paper describes how an AI-based system capable of detecting emotions of animals was created and able to assess behaviors indicating emotions in horses. The system does so in an autonomous way and with good results. This proves that we are capable of creating a system that can recognize emotions of a non-human animal species that has the ability to produce facial expressions and that it might be possible to detect these emotions by other methods, such as measuring the animal's heart rate, its temperature, or recording the sounds that they produce and feeding all this data into a system similar to the one created here  [41] . While the system works with reasonable accuracy, it is worth pointing out that it could be improved in many ways.\n\nFirst of all, we have to keep in mind that predicting emotions is a complex task, it is hard for humans and it is even harder for animals.\n\nSecondly, there were only 440 labeled images in total, which is not a large number for systems like this one.\n\nObtaining the 440 horse emotion pictures was the most time-consuming part of our research, as these pictures were not publicly available and had to be manually taken and labeled by the authors. Future research obtaining more labeled horse emotion pictures will be essential, and we hope to initiate a citizen science initiative towards that goal. Having more images, thousands or millions of them split evenly between every emotion will make future emotion prediction models more accurate and generalizable.\n\nThirdly, only the head and neck of the horse were used to predict its emotion, analyzing cues from the entire body would most likely yield be er results; however, since we would have more features to analyze, more data would be needed. In addition, if the entire body is used, the emotions have to be reviewed, since they were defined only by cues found in the head and neck of the horse.\n\nFourthly, ear, neck and body positions indicative of any general emotion at a distance may also indicate more severe problems upon closer examination. Many of the studies on equine pain face, for example, show ear and neck positions similar to those of relaxed horses. In order to use such a tool to improve our understanding of equine emotions and promote be er equine welfare, this generalized emotional assessment tool could be combined with the existing research and machine learning in equine facial expressions to eventually create a more robust program that takes into account not only the generalized emotional expression, but also the nuances of pain or distress that could be mistaken for something else. This lack of differentiation between subtle emotion pa erns is also evident in the confusion matrix in Figure  9 , which reveals that emotions are often confused with the \"curious\" and \"relaxed\" states of a horse.\n\nFinally, another way to improve the results obtained in this paper would be to use information from other sources in combination with the images. Sensors to measure heart rate and temperature could be put on horses, their sound could be recorded, etc.\n\nWith additional adjustments, this tool could serve as an important means of supporting the need to look at animal behavior and emotions as a way to improve animal welfare in various agricultural industries including in clinical veterinary se ings  [9, 10, 42] . There is a growing push to create be er assessment tools that look at improving equine psychological welfare in domestic states through more robust measurements of emotional affect via behavioral observations  [21, 43]  and an automated system that relies on research-based behavioral assessments rather than objective interpretations could help improve accuracy of assessment of the psychological welfare of domestic livestock.",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Conclusions",
      "text": "In conclusion, this is a first \"proof of concept\" system that illustrates that deep learning through convolutional neural networks is able to identify emotions in horses. It provides a powerful foundation on which to build new and more accurate systems to predict animal emotions.",
      "page_start": 12,
      "page_end": 12
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: ) which were defined with respect to neck and",
      "page": 4
    },
    {
      "caption": "Figure 1: Horse emotions.",
      "page": 4
    },
    {
      "caption": "Figure 2: ) was formed by a convolutional base, a flattening layer, two fully",
      "page": 6
    },
    {
      "caption": "Figure 2: Model architecture.",
      "page": 6
    },
    {
      "caption": "Figure 3: System process diagram.",
      "page": 7
    },
    {
      "caption": "Figure 4: Figure 4. Detector predictions.",
      "page": 7
    },
    {
      "caption": "Figure 5: , the base training set was divided into five equal chunks consisting of",
      "page": 7
    },
    {
      "caption": "Figure 5: Five-fold cross-validation.",
      "page": 8
    },
    {
      "caption": "Figure 6: displays the average accuracy for each convolutional model base, with accuracy defined as the",
      "page": 8
    },
    {
      "caption": "Figure 6: Five-fold cross-validation average accuracy over 25 epochs.",
      "page": 8
    },
    {
      "caption": "Figure 7: and 8 show the average loss values, i.e., the number of classification errors and the",
      "page": 8
    },
    {
      "caption": "Figure 7: Five-fold cross-validation average loss over 25 epochs.",
      "page": 8
    },
    {
      "caption": "Figure 8: Five-fold cross-validation average AUC over 25 epochs.",
      "page": 9
    },
    {
      "caption": "Figure 9: shows the confusion matrix of this final evaluation.",
      "page": 9
    },
    {
      "caption": "Figure 9: Confusion matrix of the final model.",
      "page": 9
    },
    {
      "caption": "Figure 10: shows some selected test images with a GradCAM overlay, which visualizes activations of the",
      "page": 10
    },
    {
      "caption": "Figure 10: GradCAM overlays of chosen test images.",
      "page": 10
    },
    {
      "caption": "Figure 11: Figure 11. Graphical user interface.",
      "page": 10
    },
    {
      "caption": "Figure 9: , which reveals that emotions are often confused with the \"curious\" and “relaxed” states of a horse.",
      "page": 11
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "1.\nGendron, M. Deﬁning Emotion: A Brief History. Emot. Rev. 2010, 2 (4), 371–372.": "2.\nKremer, L.; Klein Holkenborg, S. E.\nJ.; Reimert,\nI.; Bolhuis,\nJ. E.; Webb, L. E. The Nuts and Bolts of\nAnimal Emotion. Neurosci. Biobehav. Rev. 2020, 113, 273–286."
        },
        {
          "1.\nGendron, M. Deﬁning Emotion: A Brief History. Emot. Rev. 2010, 2 (4), 371–372.": "3.\nZuckerman, M.; Lipets, M. S.; Koivumaki, J. H.; Rosenthal, R. Encoding and Decoding Nonverbal Cues\nof Emo-Tion. Journal of Personality and Social Psychology 1975, 32 (6)."
        },
        {
          "1.\nGendron, M. Deﬁning Emotion: A Brief History. Emot. Rev. 2010, 2 (4), 371–372.": "4.\nDePaulo, B. M. Decoding Discrepant Nonverbal Cues. J. Pers. Soc. Psychol. 1978, 36 (3), 313–323."
        },
        {
          "1.\nGendron, M. Deﬁning Emotion: A Brief History. Emot. Rev. 2010, 2 (4), 371–372.": "5.\nCreek, L. V.; Watkins,\nJ. T. Responses\nto\nIncongruent Verbal\nand Nonverbal Emotional Cues. J.\nCommun. 1972, 22 (3), 311–316."
        },
        {
          "1.\nGendron, M. Deﬁning Emotion: A Brief History. Emot. Rev. 2010, 2 (4), 371–372.": "6.\nPanksepp,\nJ. Aﬀective Consciousness: Core Emotional Feelings\nin Animals and Humans. Conscious.\nCogn. 2005, 14 (1), 30–80."
        },
        {
          "1.\nGendron, M. Deﬁning Emotion: A Brief History. Emot. Rev. 2010, 2 (4), 371–372.": "7.\nWaller, B. M.; Peirce, K.; Caeiro, C. C.; Scheider, L.; Burrows, A. M.; McCune, S.; Kaminski,\nJ.\nPaedomorphic Facial Expressions Give Dogs a Selective Advantage. PLoS One 2013, 8 (12), e82686."
        },
        {
          "1.\nGendron, M. Deﬁning Emotion: A Brief History. Emot. Rev. 2010, 2 (4), 371–372.": "8.\nPaul, E. S.; Sher, S.; Tamie\u0000o, M.; Winkielman, P.; Mendl, M. T. Towards a Comparative Science of\nEmotion: Aﬀect\nand Consciousness\nin Humans\nand Animals. Neurosci.\nBiobehav. Rev. 2020, 108,\n749–770."
        },
        {
          "1.\nGendron, M. Deﬁning Emotion: A Brief History. Emot. Rev. 2010, 2 (4), 371–372.": "9.\nLeliveld, L. M. C.; Düpjan, S.; Tuchscherer, A.; Puppe, B. Behavioural and Physiological Measures\nIndicate Subtle Variations in the Emotional Valence of Young Pigs. Physiol. Behav. 2016, 157, 116–124."
        },
        {
          "1.\nGendron, M. Deﬁning Emotion: A Brief History. Emot. Rev. 2010, 2 (4), 371–372.": "10.\nvon Borell, E.; Langbein, J.; Després, G.; Hansen, S.; Leterrier, C.; Marchant-Forde, J.; Marchant-Forde,\nR.; Minero, M.; Mohr, E.; Prunier, A.; Valance, D.; Veissier,\nI. Heart Rate Variability as a Measure of\nAutonomic Regulation of Cardiac Activity for Assessing Stress and Welfare in Farm Animals\n-- a\nReview. Physiol. Behav. 2007, 92 (3), 293–316."
        },
        {
          "1.\nGendron, M. Deﬁning Emotion: A Brief History. Emot. Rev. 2010, 2 (4), 371–372.": "11.\nBudzyńska, M.\nStress Reactivity and Coping in Horse Adaptation to Environment. J. Equine Vet.\nSci. 2014, 34 (8), 935–941."
        },
        {
          "1.\nGendron, M. Deﬁning Emotion: A Brief History. Emot. Rev. 2010, 2 (4), 371–372.": "12. Yarnell, K.; Hall, C.; Bille\u0000, E. An Assessment of\nthe Aversive Nature of an Animal Management\nProcedure (Clipping) Using Behavioral and Physiological Measures. Physiol. Behav. 2013, 118, 32–39."
        },
        {
          "1.\nGendron, M. Deﬁning Emotion: A Brief History. Emot. Rev. 2010, 2 (4), 371–372.": "13.\nJohnson, R. A.;\nJohnson, P.\nJ.; Megarani, D. V.; Patel, S. D.; Yaglom, H. D.; Osterlind, S.; Grindler, K.;\nVogelweid, C. M.; Parker, T. M.; Pascua, C. K.; Crowder, S. M. Horses Working in Therapeutic Riding\nPrograms: Cortisol, Adrenocorticotropic Hormone, Glucose, and Behavior Stress Indicators. J. Equine\nVet. Sci. 2017, 57, 77–85."
        },
        {
          "1.\nGendron, M. Deﬁning Emotion: A Brief History. Emot. Rev. 2010, 2 (4), 371–372.": "14. McDonnell, S. M.; Haviland,\nJ. C. S. Agonistic Ethogram of\nthe Equid Bachelor Band. Appl. Anim.\nBehav. Sci. 1995, 43 (3), 147–188."
        },
        {
          "1.\nGendron, M. Deﬁning Emotion: A Brief History. Emot. Rev. 2010, 2 (4), 371–372.": "15. Arnold, G. W.; Grassia, A. Ethogram of Agonistic Behaviour for Thoroughbred Horses. Appl. Anim.\nEthol. 1982, 8 (1–2), 5–25."
        },
        {
          "1.\nGendron, M. Deﬁning Emotion: A Brief History. Emot. Rev. 2010, 2 (4), 371–372.": "16. McDonnell, S. M.; Poulin, A. Equid Play Ethogram. Appl. Anim. Behav. Sci. 2002, 78 (2–4), 263–290."
        },
        {
          "1.\nGendron, M. Deﬁning Emotion: A Brief History. Emot. Rev. 2010, 2 (4), 371–372.": "17. Rietmann, T. R.;\nStuart, A. E. A.; Bernasconi, P.; Stauﬀacher, M.; Auer,\nJ. A.; Weishaupt, M. A.\nAssessment of Mental Stress in Warmblood Horses: Heart Rate Variability in Comparison to Heart Rate\nand Selected Behavioural Parameters. Appl. Anim. Behav. Sci. 2004, 88 (1–2), 121–136."
        },
        {
          "1.\nGendron, M. Deﬁning Emotion: A Brief History. Emot. Rev. 2010, 2 (4), 371–372.": "18. Żelazna, R.;\nJezierski, T. Behavioural Reactions of Horses\n(Equus Caballus)\nto Separation Stress in\nConspeciﬁcs. A Pilot\nStudy\non\nEmotional\nContagion\nin\nthe Horse. Animal\nScience\nPapers\nand\nReports 2018, 36 (3), 333–338."
        },
        {
          "1.\nGendron, M. Deﬁning Emotion: A Brief History. Emot. Rev. 2010, 2 (4), 371–372.": "19.\nLansade, L.; Nowak, R.; Lainé, A. L.; Leterrier, C.; Bonneau, C.; Parias, C.; Bertin, A. Facial Expression\nand Oxy-Tocin as Possible Markers of Positive Emotions in Horses. Scientiﬁc reports 2018, 8 (1), 1–11."
        },
        {
          "1.\nGendron, M. Deﬁning Emotion: A Brief History. Emot. Rev. 2010, 2 (4), 371–372.": "20. Hin\u0000e, S.; Murphy, E.; Bachmann, I.; Wemelsfelder, F.; Würbel, H. Qualitative Behaviour Assessment\nof Horses Exposed to Short-Term Emotional Treatments. Appl. Anim. Behav. Sci. 2017, 196, 44–51."
        },
        {
          "1.\nGendron, M. Deﬁning Emotion: A Brief History. Emot. Rev. 2010, 2 (4), 371–372.": "21. Hall, C.; Randle, H.; Pearson, G.; Preshaw, L.; Waran, N. Assessing Equine Emotional State. Appl. Anim.\nBehav. Sci. 2018, 205, 183–193."
        },
        {
          "1.\nGendron, M. Deﬁning Emotion: A Brief History. Emot. Rev. 2010, 2 (4), 371–372.": "22. Wathan,\nJ.; Burrows, A. M.; Waller, B. M.; McComb, K. EquiFACS: The Equine Facial Action Coding\nSystem. PLoS One 2015, 10 (8), e0131738."
        }
      ],
      "page": 12
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "23. Gleerup, K. B.; Forkman, B.; Lindegaard, C.; Andersen, P. H. An Equine Pain Face. Vet. Anaesth.\nAnalg. 2015, 42 (1), 103–114.": "24. Andersen, P. H.; Gleerup, K. B.; Wathan,\nJ.; Coles, B.; Kjellstrom, H.; Broomé, S.; Forster, D. Can a\nMachine Learn to See Horse Pain? An Interdisciplinary Approach Towards Automated Decoding of\nFacial Expressions of Pain in the Horse; 2018; pp 6–8."
        },
        {
          "23. Gleerup, K. B.; Forkman, B.; Lindegaard, C.; Andersen, P. H. An Equine Pain Face. Vet. Anaesth.\nAnalg. 2015, 42 (1), 103–114.": "25. Rashid, M.; Broome, S.; Andersen, P. H.; Gleerup, K. B.; Lee, Y.\nJ. What Should I Annotate ? An\nAutomatic Tool\nfor Finding Video Segments for EquiFACS Annotation. Measuring Beaviour 2018, June,\n6–8."
        },
        {
          "23. Gleerup, K. B.; Forkman, B.; Lindegaard, C.; Andersen, P. H. An Equine Pain Face. Vet. Anaesth.\nAnalg. 2015, 42 (1), 103–114.": "26. Rashid, M.; Silventoinen, A.; Gleerup, K. B.; Andersen, P. H. Equine Facial Action Coding System for\nDetermination\nof\nPain-Related\nFacial\nResponses\nin\nVideos\nof\nHorses. bioRxiv,\n2020.\nh\u0000ps://doi.org/10.1101/2020.03.31.018374."
        },
        {
          "23. Gleerup, K. B.; Forkman, B.; Lindegaard, C.; Andersen, P. H. An Equine Pain Face. Vet. Anaesth.\nAnalg. 2015, 42 (1), 103–114.": "27. McDuﬀ, D.; Kaliouby, R. E.; Picard, R. W. Crowdsourcing Facial Responses to Online Videos. IEEE\nTrans. Aﬀect. Comput. 2012, 3 (4), 456–468."
        },
        {
          "23. Gleerup, K. B.; Forkman, B.; Lindegaard, C.; Andersen, P. H. An Equine Pain Face. Vet. Anaesth.\nAnalg. 2015, 42 (1), 103–114.": "28.\nThe Emotional Lives of Companion Animals: A\u0000achment and Subjec-Tive Claims by Owners of Cats\nand Dogs. Anthrozo os 2016, 29 (1), 88."
        },
        {
          "23. Gleerup, K. B.; Forkman, B.; Lindegaard, C.; Andersen, P. H. An Equine Pain Face. Vet. Anaesth.\nAnalg. 2015, 42 (1), 103–114.": "29. Vick, S.-J.; Waller, B. M.; Parr, L. A.; Smith Pasqualini, M. C.; Bard, K. A. A Cross-Species Comparison\nof Facial Morphology and Movement\nin Humans and Chimpanzees Using the Facial Action Coding\nSystem (FACS). J. Nonverbal Behav. 2007, 31 (1), 1–20."
        },
        {
          "23. Gleerup, K. B.; Forkman, B.; Lindegaard, C.; Andersen, P. H. An Equine Pain Face. Vet. Anaesth.\nAnalg. 2015, 42 (1), 103–114.": "30. Niklas, L, Ferres, K. Creating a Smart System to Detect Dog Emotions Based on Facial Expressions.\nIn seminar thesis coins seminar, university of cologne; 2019."
        },
        {
          "23. Gleerup, K. B.; Forkman, B.; Lindegaard, C.; Andersen, P. H. An Equine Pain Face. Vet. Anaesth.\nAnalg. 2015, 42 (1), 103–114.": "31. Hantke, S.; Cummins, N.; Schuller, B. What Is My Dog Trying to Tell Me? The Automatic Recognition\nof the Con-Text and Perceived Emotion of Dog Barks; IEEE, 2018; pp 5134–5138."
        },
        {
          "23. Gleerup, K. B.; Forkman, B.; Lindegaard, C.; Andersen, P. H. An Equine Pain Face. Vet. Anaesth.\nAnalg. 2015, 42 (1), 103–114.": "32.\nStewart, M.; Stra\u0000on, R. B.; Beausoleil, N. J.; Staﬀord, K. J.; Worth, G. M.; Waran, N. K. Assessment of\nPositive Emotions in Horses: Implications for Welfare and Performance. J. Vet. Behav. 2011, 6 (5), 296."
        },
        {
          "23. Gleerup, K. B.; Forkman, B.; Lindegaard, C.; Andersen, P. H. An Equine Pain Face. Vet. Anaesth.\nAnalg. 2015, 42 (1), 103–114.": "33.\nPeters,\nS. M.;\nBleijenberg, E. H.;\nvan Dierendonck, M. C.;\nvan der Harst,\nJ. E.;\nSpruijt, B. M.\nCharacterization of Anticipatory Behaviour\nin Domesticated Horses\n(Equus Caballus). Appl. Anim.\nBehav. Sci. 2012, 138 (1–2), 60–69."
        },
        {
          "23. Gleerup, K. B.; Forkman, B.; Lindegaard, C.; Andersen, P. H. An Equine Pain Face. Vet. Anaesth.\nAnalg. 2015, 42 (1), 103–114.": "34. Mendl, M.; Burman, O. H. P.; Paul, E. S. An Integrative and Functional Framework for the Study of\nAnimal Emotion and Mood. Proc. Biol. Sci. 2010, 277 (1696), 2895–2904."
        },
        {
          "23. Gleerup, K. B.; Forkman, B.; Lindegaard, C.; Andersen, P. H. An Equine Pain Face. Vet. Anaesth.\nAnalg. 2015, 42 (1), 103–114.": "35. Hall, C.; Heleski, C. The Role of the Ethogram in Equitation Science. Appl. Anim. Behav. Sci. 2017, 190,\n102–110."
        },
        {
          "23. Gleerup, K. B.; Forkman, B.; Lindegaard, C.; Andersen, P. H. An Equine Pain Face. Vet. Anaesth.\nAnalg. 2015, 42 (1), 103–114.": "36.\nJørgensen, G. H. M.; Liestøl, S. H. O.; Bøe, K. E. Eﬀects of Enrichment\nItems on Activity and Social\nInteractions in Do-Mestic Horses (Equus Caballus. Appl. Anim. Behav. Sci 2011, 78, 263–290."
        },
        {
          "23. Gleerup, K. B.; Forkman, B.; Lindegaard, C.; Andersen, P. H. An Equine Pain Face. Vet. Anaesth.\nAnalg. 2015, 42 (1), 103–114.": "37. Malavasi, R.; Huber, L. Evidence of Heterospeciﬁc Referential Communication from Domestic Horses\n(Equus Caballus) to Humans. Anim. Cogn. 2016, 19 (5), 899–909."
        },
        {
          "23. Gleerup, K. B.; Forkman, B.; Lindegaard, C.; Andersen, P. H. An Equine Pain Face. Vet. Anaesth.\nAnalg. 2015, 42 (1), 103–114.": "38. Wathan,\nJ.; McComb,\nK.\nThe\nEyes\nand\nEars Are Visual\nIndicators\nof A\u0000ention\nin Domestic\nHorses. Curr. Biol. 2014, 24 (15), R677-9."
        },
        {
          "23. Gleerup, K. B.; Forkman, B.; Lindegaard, C.; Andersen, P. H. An Equine Pain Face. Vet. Anaesth.\nAnalg. 2015, 42 (1), 103–114.": "39. Wathan,\nJ.; Proops, L.; Grounds, K.; McComb, K. Horses Discriminate between Facial Expressions of\nConspeciﬁcs. Sci. Rep. 2016, 6 (1). h\u0000ps://doi.org/10.1038/srep38322."
        },
        {
          "23. Gleerup, K. B.; Forkman, B.; Lindegaard, C.; Andersen, P. H. An Equine Pain Face. Vet. Anaesth.\nAnalg. 2015, 42 (1), 103–114.": "40. Ren, S.; He, K.; Girshick, R.; Sun, J.; C., L.; D., N.; Lee, D. D. Faster R-Cnn: Towards Real-Time Object\nDetection with\nRegion\nProposal Net-Works. Advances\nin Neural\nInfor-mation\nProcessing\nSystems\n28 2015, M, 91–99."
        },
        {
          "23. Gleerup, K. B.; Forkman, B.; Lindegaard, C.; Andersen, P. H. An Equine Pain Face. Vet. Anaesth.\nAnalg. 2015, 42 (1), 103–114.": "41.\nStolz,\nK.; Heyder,\nT.; Gloor,\nP. A.;\nPosegga, O. Measuring Human-Animal\nInteraction with\nSmartwatches: An Initial Experiment.\nIn Studies\non Entrepreneurship, Structural Change and Industrial\nDynamics; Springer International Publishing: Cham, 2019; pp 165–182."
        },
        {
          "23. Gleerup, K. B.; Forkman, B.; Lindegaard, C.; Andersen, P. H. An Equine Pain Face. Vet. Anaesth.\nAnalg. 2015, 42 (1), 103–114.": "42.\nBoissy, A.; Manteuﬀel, G.; Jensen, M. B.; Moe, R. O.; Spruijt, B.; Keeling, L. J.; Winckler, C.; Forkman, B.;\nDimitrov,\nI.; Langbein,\nJ.; Bakken, M.; Veissier,\nI.; Aubert, A. Assessment of Positive Emotions\nin\nAnimals to Improve Their Welfare. Physiol. Behav. 2007, 92 (3), 375–397."
        }
      ],
      "page": 13
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Defining Emotion: A Brief History",
      "authors": [
        "M Gendron"
      ],
      "venue": "Emot. Rev"
    },
    {
      "citation_id": "2",
      "title": "The Nuts and Bolts of Animal Emotion",
      "authors": [
        "L Kremer",
        "S Klein Holkenborg",
        "I Reimert",
        "J Bolhuis",
        "L Webb"
      ],
      "year": "2020",
      "venue": "Neurosci. Biobehav. Rev"
    },
    {
      "citation_id": "3",
      "title": "Encoding and Decoding Nonverbal Cues of Emo-Tion",
      "authors": [
        "M Zuckerman",
        "M Lipets",
        "J Koivumaki",
        "R Rosenthal"
      ],
      "year": "1975",
      "venue": "Journal of Personality and Social Psychology"
    },
    {
      "citation_id": "4",
      "title": "Decoding Discrepant Nonverbal Cues",
      "authors": [
        "B Depaulo"
      ],
      "year": "1978",
      "venue": "J. Pers. Soc. Psychol"
    },
    {
      "citation_id": "5",
      "title": "Responses to Incongruent Verbal and Nonverbal Emotional Cues",
      "authors": [
        "L Creek",
        "J Watkins"
      ],
      "year": "1972",
      "venue": "J. Commun"
    },
    {
      "citation_id": "6",
      "title": "Affective Consciousness: Core Emotional Feelings in Animals and Humans",
      "authors": [
        "J Panksepp"
      ],
      "year": "2005",
      "venue": "Conscious. Cogn"
    },
    {
      "citation_id": "7",
      "title": "Paedomorphic Facial Expressions Give Dogs a Selective Advantage",
      "authors": [
        "B Waller",
        "K Peirce",
        "C Caeiro",
        "L Scheider",
        "A Burrows",
        "S Mccune",
        "J Kaminski"
      ],
      "year": "2013",
      "venue": "PLoS One"
    },
    {
      "citation_id": "8",
      "title": "Towards a Comparative Science of Emotion: Affect and Consciousness in Humans and Animals",
      "authors": [
        "E Paul",
        "S Sher",
        "M Tamie O",
        "P Winkielman",
        "M Mendl"
      ],
      "year": "2020",
      "venue": "Neurosci. Biobehav. Rev"
    },
    {
      "citation_id": "9",
      "title": "Behavioural and Physiological Measures Indicate Subtle Variations in the Emotional Valence of Young Pigs",
      "authors": [
        "L Leliveld",
        "S Düpjan",
        "A Tuchscherer",
        "B Puppe"
      ],
      "year": "2016",
      "venue": "Physiol. Behav"
    },
    {
      "citation_id": "10",
      "title": "Heart Rate Variability as a Measure of Autonomic Regulation of Cardiac Activity for Assessing Stress and Welfare in Farm Animals --a Review",
      "authors": [
        "E Von Borell",
        "J Langbein",
        "G Després",
        "S Hansen",
        "C Leterrier",
        "J Marchant-Forde",
        "R Marchant-Forde",
        "M Minero",
        "E Mohr",
        "A Prunier",
        "D Valance",
        "I Veissier"
      ],
      "year": "2007",
      "venue": "Physiol. Behav"
    },
    {
      "citation_id": "11",
      "title": "Stress Reactivity and Coping in Horse Adaptation to Environment",
      "authors": [
        "M Budzyńska"
      ],
      "year": "2014",
      "venue": "J. Equine Vet. Sci"
    },
    {
      "citation_id": "12",
      "title": "An Assessment of the Aversive Nature of an Animal Management Procedure (Clipping) Using Behavioral and Physiological Measures",
      "authors": [
        "K Yarnell",
        "C Hall",
        "E Bille"
      ],
      "year": "2013",
      "venue": "Physiol. Behav"
    },
    {
      "citation_id": "13",
      "title": "Horses Working in Therapeutic Riding Programs: Cortisol, Adrenocorticotropic Hormone, Glucose, and Behavior Stress Indicators",
      "authors": [
        "R Johnson",
        "P Johnson",
        "D Megarani",
        "S Patel",
        "H Yaglom",
        "S Osterlind",
        "K Grindler",
        "C Vogelweid",
        "T Parker",
        "C Pascua",
        "S Crowder"
      ],
      "year": "2017",
      "venue": "J. Equine Vet. Sci"
    },
    {
      "citation_id": "14",
      "title": "Agonistic Ethogram of the Equid Bachelor Band. Appl. Anim. Behav. Sci",
      "authors": [
        "S Mcdonnell",
        "J Haviland"
      ],
      "year": "1995",
      "venue": "Agonistic Ethogram of the Equid Bachelor Band. Appl. Anim. Behav. Sci"
    },
    {
      "citation_id": "15",
      "title": "Ethogram of Agonistic Behaviour for Thoroughbred Horses",
      "authors": [
        "G Arnold",
        "A Grassia"
      ],
      "year": "1982",
      "venue": "Appl. Anim. Ethol"
    },
    {
      "citation_id": "16",
      "title": "Equid Play Ethogram. Appl. Anim. Behav. Sci",
      "authors": [
        "S Mcdonnell",
        "A Poulin"
      ],
      "year": "2002",
      "venue": "Equid Play Ethogram. Appl. Anim. Behav. Sci"
    },
    {
      "citation_id": "17",
      "title": "Assessment of Mental Stress in Warmblood Horses: Heart Rate Variability in Comparison to Heart Rate and Selected Behavioural Parameters",
      "authors": [
        "T Rietmann",
        "A Stuart",
        "P Bernasconi",
        "M Stauffacher",
        "J Auer",
        "M Weishaupt"
      ],
      "year": "2004",
      "venue": "Appl. Anim. Behav. Sci"
    },
    {
      "citation_id": "18",
      "title": "Behavioural Reactions of Horses (Equus Caballus) to Separation Stress in Conspecifics. A Pilot Study on Emotional Contagion in the Horse",
      "authors": [
        "R Żelazna",
        "T Jezierski"
      ],
      "year": "2018",
      "venue": "Animal Science Papers and Reports"
    },
    {
      "citation_id": "19",
      "title": "Facial Expression and Oxy-Tocin as Possible Markers of Positive Emotions in Horses",
      "authors": [
        "L Lansade",
        "R Nowak",
        "A Lainé",
        "C Leterrier",
        "C Bonneau",
        "C Parias",
        "A Bertin"
      ],
      "year": "2018",
      "venue": "Scientific reports"
    },
    {
      "citation_id": "20",
      "title": "Qualitative Behaviour Assessment of Horses Exposed to Short-Term Emotional Treatments",
      "authors": [
        "S Hin E",
        "E Murphy",
        "I Bachmann",
        "F Wemelsfelder",
        "H Würbel"
      ],
      "year": "2017",
      "venue": "Appl. Anim. Behav. Sci"
    },
    {
      "citation_id": "21",
      "title": "Assessing Equine Emotional State. Appl. Anim. Behav. Sci",
      "authors": [
        "C Hall",
        "H Randle",
        "G Pearson",
        "L Preshaw",
        "N Waran"
      ],
      "year": "2018",
      "venue": "Assessing Equine Emotional State. Appl. Anim. Behav. Sci"
    },
    {
      "citation_id": "22",
      "title": "EquiFACS: The Equine Facial Action Coding System",
      "authors": [
        "J Wathan",
        "A Burrows",
        "B Waller",
        "K Mccomb"
      ],
      "year": "2015",
      "venue": "PLoS One"
    },
    {
      "citation_id": "23",
      "title": "An Equine Pain Face",
      "authors": [
        "K Gleerup",
        "B Forkman",
        "C Lindegaard",
        "P Andersen"
      ],
      "year": "2015",
      "venue": "Vet. Anaesth. Analg"
    },
    {
      "citation_id": "24",
      "title": "Can a Machine Learn to See Horse Pain? An Interdisciplinary Approach Towards Automated Decoding of Facial Expressions of Pain in the Horse",
      "authors": [
        "P Andersen",
        "K Gleerup",
        "J Wathan",
        "B Coles",
        "H Kjellstrom",
        "S Broomé",
        "D Forster"
      ],
      "year": "2018",
      "venue": "Can a Machine Learn to See Horse Pain? An Interdisciplinary Approach Towards Automated Decoding of Facial Expressions of Pain in the Horse"
    },
    {
      "citation_id": "25",
      "title": "What Should I Annotate ? An Automatic Tool for Finding Video Segments for EquiFACS Annotation",
      "authors": [
        "M Rashid",
        "S Broome",
        "P Andersen",
        "K Gleerup",
        "Y Lee"
      ],
      "year": "2018",
      "venue": "Measuring Beaviour"
    },
    {
      "citation_id": "26",
      "title": "Equine Facial Action Coding System for Determination of Pain-Related Facial Responses in Videos of Horses",
      "authors": [
        "M Rashid",
        "A Silventoinen",
        "K Gleerup",
        "P Andersen"
      ],
      "year": "2020",
      "venue": "bioRxiv",
      "doi": "10.1101/2020.03.31.018374"
    },
    {
      "citation_id": "27",
      "title": "Crowdsourcing Facial Responses to Online Videos",
      "authors": [
        "D Mcduff",
        "R Kaliouby",
        "R Picard"
      ],
      "venue": "IEEE Trans. Affect. Comput"
    },
    {
      "citation_id": "28",
      "title": "The Emotional Lives of Companion Animals: A achment and Subjec-Tive Claims by Owners of Cats and Dogs. Anthrozo os",
      "year": "2016",
      "venue": "The Emotional Lives of Companion Animals: A achment and Subjec-Tive Claims by Owners of Cats and Dogs. Anthrozo os"
    },
    {
      "citation_id": "29",
      "title": "A Cross-Species Comparison of Facial Morphology and Movement in Humans and Chimpanzees Using the Facial Action Coding System (FACS)",
      "authors": [
        "S.-J Vick",
        "B Waller",
        "L Parr",
        "M Smith Pasqualini",
        "K Bard"
      ],
      "year": "2007",
      "venue": "J. Nonverbal Behav"
    },
    {
      "citation_id": "30",
      "title": "Creating a Smart System to Detect Dog Emotions Based on Facial Expressions",
      "authors": [
        "L Niklas",
        "K Ferres"
      ],
      "year": "2019",
      "venue": "Creating a Smart System to Detect Dog Emotions Based on Facial Expressions"
    },
    {
      "citation_id": "31",
      "title": "What Is My Dog Trying to Tell Me? The Automatic Recognition of the Con-Text and Perceived Emotion of Dog Barks",
      "authors": [
        "S Hantke",
        "N Cummins",
        "B Schuller"
      ],
      "year": "2018",
      "venue": "What Is My Dog Trying to Tell Me? The Automatic Recognition of the Con-Text and Perceived Emotion of Dog Barks"
    },
    {
      "citation_id": "32",
      "title": "Assessment of Positive Emotions in Horses: Implications for Welfare and Performance",
      "authors": [
        "M Stewart",
        "R Stra On",
        "N Beausoleil",
        "K Stafford",
        "G Worth",
        "N Waran"
      ],
      "year": "2011",
      "venue": "J. Vet. Behav"
    },
    {
      "citation_id": "33",
      "title": "Characterization of Anticipatory Behaviour in Domesticated Horses",
      "authors": [
        "S Peters",
        "E Bleijenberg",
        "M Van Dierendonck",
        "J Van Der Harst",
        "B Spruijt"
      ],
      "year": "2012",
      "venue": "Characterization of Anticipatory Behaviour in Domesticated Horses"
    },
    {
      "citation_id": "34",
      "title": "An Integrative and Functional Framework for the Study of Animal Emotion and Mood",
      "authors": [
        "M Mendl",
        "O Burman",
        "E Paul"
      ],
      "year": "1696",
      "venue": "Proc. Biol. Sci"
    },
    {
      "citation_id": "35",
      "title": "The Role of the Ethogram in Equitation",
      "authors": [
        "C Hall",
        "C Heleski"
      ],
      "year": "2017",
      "venue": "Science. Appl. Anim. Behav. Sci"
    },
    {
      "citation_id": "36",
      "title": "Effects of Enrichment Items on Activity and Social Interactions in Do-Mestic Horses",
      "authors": [
        "G Jørgensen",
        "S Liestøl",
        "K Bøe"
      ],
      "year": "2011",
      "venue": "Effects of Enrichment Items on Activity and Social Interactions in Do-Mestic Horses"
    },
    {
      "citation_id": "37",
      "title": "Evidence of Heterospecific Referential Communication from Domestic Horses (Equus Caballus) to Humans",
      "authors": [
        "R Malavasi",
        "L Huber"
      ],
      "year": "2016",
      "venue": "Anim. Cogn"
    },
    {
      "citation_id": "38",
      "title": "The Eyes and Ears Are Visual Indicators of A ention in Domestic Horses",
      "authors": [
        "J Wathan",
        "K Mccomb"
      ],
      "year": "2014",
      "venue": "Curr. Biol"
    },
    {
      "citation_id": "39",
      "title": "Horses Discriminate between Facial Expressions of Conspecifics",
      "authors": [
        "J Wathan",
        "L Proops",
        "K Grounds",
        "K Mccomb"
      ],
      "year": "2016",
      "venue": "Sci. Rep",
      "doi": "10.1038/srep38322"
    },
    {
      "citation_id": "40",
      "title": "Towards Real-Time Object Detection with Region Proposal Net-Works",
      "authors": [
        "S Ren",
        "K He",
        "R Girshick",
        "J Sun",
        "N Lee",
        "D Faster R-Cnn"
      ],
      "year": "2015",
      "venue": "Advances in Neural Infor-mation Processing Systems 28"
    },
    {
      "citation_id": "41",
      "title": "Measuring Human-Animal Interaction with Smartwatches: An Initial Experiment",
      "authors": [
        "K Stolz",
        "T Heyder",
        "P Gloor",
        "O Posegga"
      ],
      "year": "2019",
      "venue": "Studies on Entrepreneurship, Structural Change and Industrial Dynamics"
    },
    {
      "citation_id": "42",
      "title": "Assessment of Positive Emotions in Animals to Improve Their Welfare",
      "authors": [
        "A Boissy",
        "G Manteuffel",
        "M Jensen",
        "R Moe",
        "B Spruijt",
        "L Keeling",
        "C Winckler",
        "B Forkman",
        "I Dimitrov",
        "J Langbein",
        "M Bakken",
        "I Veissier",
        "A Aubert"
      ],
      "year": "2007",
      "venue": "Physiol. Behav"
    },
    {
      "citation_id": "43",
      "title": "What We Can Measure, We Can Manage: The Importance of Using Robust Welfare Indicators in Equitation",
      "authors": [
        "N Waran",
        "H Randle"
      ],
      "year": "2017",
      "venue": "Science. Appl. Anim. Behav. Sci"
    }
  ]
}