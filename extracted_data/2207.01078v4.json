{
  "paper_id": "2207.01078v4",
  "title": "Araus: A Large-Scale Dataset And Baseline Models Of Affective Responses To Augmented Urban Soundscapes",
  "published": "2022-07-03T17:09:09Z",
  "authors": [
    "Kenneth Ooi",
    "Zhen-Ting Ong",
    "Karn N. Watcharasupat",
    "Bhan Lam",
    "Joo Young Hong",
    "Woon-Seng Gan"
  ],
  "keywords": [
    "Soundscape",
    "dataset",
    "regression",
    "deep neural network",
    "soundscape augmentation",
    "auditory masking"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Choosing optimal maskers for existing soundscapes to effect a desired perceptual change via soundscape augmentation is non-trivial due to extensive varieties of maskers and a dearth of benchmark datasets with which to compare and develop soundscape augmentation models. To address this problem, we make publicly available the ARAUS (Affective Responses to Augmented Urban Soundscapes) dataset, which comprises a five-fold cross-validation set and independent test set totaling 25,440 unique subjective perceptual responses to augmented soundscapes presented as audio-visual stimuli. Each augmented soundscape is made by digitally adding \"maskers\" (bird, water, wind, traffic, construction, or silence) to urban soundscape recordings at fixed soundscape-to-masker ratios. Responses were then collected by asking participants to rate how pleasant, annoying, eventful, uneventful, vibrant, monotonous, chaotic, calm, and appropriate each augmented soundscape was, in accordance with ISO/TS 12913-2:2018. Participants also provided relevant demographic information and completed standard psychological questionnaires. We perform exploratory and statistical analysis of the responses obtained to verify internal consistency and agreement with known results in the literature. Finally, we demonstrate the benchmarking capability of the dataset by training and comparing four baseline models for urban soundscape pleasantness: a low-parameter regression model, a high-parameter convolutional neural network, and two attention-based networks in the literature.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Related Datasets",
      "text": "Publicly available, large-scale audio datasets have been made available as unlabeled data and/or labeled data for several \"objective\" acoustic tasks such as acoustic scene classification  [21, 22] , sound event localization and detection  [23] , and anomaly detection  [24] . However, affective audio datasets tend to be smaller and rarely reach the scale of those developed for objective tasks. In particular, to the best of our knowledge, there is no publicly-available affective soundscape dataset at the scale of the proposed ARAUS dataset.\n\nIn this section, a selection of large-scale and affective audio datasets is reviewed. A brief overview of key details for the datasets discussed is shown in Table  1 .",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Large-Scale Audio Datasets",
      "text": "The largest curated audio dataset is arguably AudioSet, which at the time of its initial release contained 1.7M 10second segments of audio from YouTube videos organized in a systematic ontology for audio tagging  [25] . Strong labels have subsequently been provided for a subset of audio  [26] , and at the time of writing, AudioSet has grown to about 2.1M segments, with 120K being strongly labeled  [27] . However, the publicly available version of the data constituting AudioSet is in the form of 128-dimensional VGGish features  [28]  due to potential copyright issues related to the use of raw audio from YouTube videos, which limits its use as a public dataset.\n\nAlternatives to AudioSet include UrbanSound8K  [29] , ESC-50  [30] , and FSD50K  [31] , which contain labelled Creative Commons-licensed tracks from Freesound  [32]  and serve as publicly-available benchmark datasets for weak audio classification. However, the nature of the stimuli in these datasets tends to be monophonic or same-class polyphonic. While this is useful in reducing the complexity and noise in inputs to train robust sound event classification models, the full complexities of real-life acoustic environments necessary for soundscape research are rarely represented in these datasets. Individual monophonic stimuli may be used to compose synthetic soundscapes like in the URBAN-SED dataset  [33] , which used the tracks in UrbanSound8K, but the focus of UrbanSound8K on just 10 possible event classes may be insufficient to emulate the variety of sound sources possible in real-life urban environments.\n\nTherefore, multiple efforts have been made to record real-life acoustic environments, which are generally polyphonic in nature, and provide them as publicly available datasets for use in sound and soundscape research. These include Urban Soundscapes of the World (USotW)  [34] ; Eigen-Scape  [35] ; SONYC Urban Sound Tagging (SONYC-UST)  [36]  and SONYC-UST-V2  [37] ; TUT Acoustic Scenes  [38, 39]  and TAU Urban Acoustic Scenes (TAU-UAS)  [40, 41, 42] ; Singapore Polyphonic Urban Audio (SINGA:PURA)  [43] ; Ambisonics Recordings of Typical Environments (ARTE)  [44] ; and Sony-TAu Realistic Spatial Soundscapes 2022 (STARSS22)  [45] .\n\nHowever, the aforementioned datasets contain no corresponding \"subjective\" labels concerning the affective perception of the recorded environments. This limits their use as datasets for soundscape augmentation, because knowing how individual soundscapes are perceived by humans is crucial in analyzing and modeling their perception. In addition, with the exception of USotW, the recordings were not compliant with ISO/TS 12913-2:2018  [20]  due to them preceding the publication of the standard, or being made for a different purpose. Hence, they may not be immediately suitable for use under the ISO 12913 paradigm, which the ARAUS dataset was designed under.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Affective Sound Datasets",
      "text": "Nonetheless, audio datasets with labels specific to perceptual indicators of the stimuli also exist. For example, the International Affective Digitized Sounds (IADS) dataset  [46]  has had labels for discrete emotional categories elicited by the 167 individual stimuli provided by  [47] , with an expanded version (IADS-E) provided by  [48] . The largely monophonic stimuli in IADS, however, suffer from the same drawbacks as datasets based on Freesound. As a workaround, the Emo-Soundscapes dataset  [49]  used individual clips from Freesound to synthetically generate 1213 soundscapes, each 6 s long, and obtained corresponding valence-arousal labels based on the Self-Assessment Manikin (SAM)  [50]  from participants on the CrowdFlower platform.\n\nIn contrast, datasets with perceptual labels for real-life audio recordings include the Athens Urban Soundscape (ATHUS) dataset  [51] , which contains 978 crowd-sourced recordings with corresponding labels for subjectively-rated soundscape quality on a five-point Likert scale, as well as the International Soundscape Database (ISD)  [52] , which as of v0.2.1, consists of 1258 30-second long recordings in 13 European cities and corresponding perceptual responses collected using the Soundscape Indices (SSID) Protocol  [53] . The perceptual responses collected using the SSID Protocol were largely inspired by the Method A questionnaire in ISO/TS 12913-2:2018  [20] .\n\nHowever, the relatively smaller sample sizes of these datasets, as compared to large-scale datasets like AudioSet, may preclude their use in developing high-parameter models, such as deep neural networks, which have shown stateof-the-art performance in various \"objective\" acoustic tasks. Hence, the ARAUS dataset was designed at a relatively large scale to be amenable to high-parameter models.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Data Collection Methodology",
      "text": "Since the primary focus of this study is to create a database of affective responses to augmented soundscapes that is extensive yet extensible, the data collection methodology must necessarily be modular and repeatable to ensure valid analysis of results and enable possible future extensions to the dataset, similar to the philosophy of USotW  [34]  and ISD  [52] .\n\nHence, the ARAUS dataset was designed as a five-fold cross-validation dataset with an independent test set, such that additional folds or data for each fold can be added following the same data collection methodology described in this section. Such a design also allows for each fold to be treated as an independent dataset for training of ensemble models or meta-learning.\n\nTo design the cross-validation set, we prepared separate recordings of real-life \"base\" urban soundscapes and of maskers that could potentially be used to augment those \"base\" urban soundscapes. The same procedure was used to split the urban soundscape and masker recordings independently into five folds to ensure no data leakage, and combine them within their folds into augmented soundscapes that form the audio-visual stimuli in the ARAUS dataset. The audio-visual stimuli were presented to participants in laboratory conditions and their affective responses to the stimuli were collected. However, responses belonging to participants who responded in an \"overly inconsistent\" manner were dropped from the dataset (see Section 3.9) and new participants were recruited to replace the dropped responses such that each fold in the five-fold cross-validation set had an equal number of data samples. A summary of the data collection methodology is shown in Fig.  1 , and full details of each step are provided in the following subsections.\n\nThe test set was designed in the same manner as the cross-validation set, but used no urban soundscapes, maskers, or participants already in the cross-validation set.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Base Urban Soundscapes",
      "text": "For the five-fold cross-validation set, all base urban soundscapes were taken from the Urban Soundscapes of the World (USotW) database  [34] . The USotW database contains 127 publicly available recordings of urban soundscapes covering an extensive variety of urban environments from various cities around the world. The urban environments range from parks to busy streets, and the cities include those in Asia, Europe, and North America, which allows the ARAUS dataset to be broad-ranging in its coverage of real-life urban soundscapes. The urban soundscapes in the USotW dataset were also chosen by the USotW team via clustering of locations reported by local experts to be \"full of life and exciting\", \"chaotic and restless\", \"calm and tranquil\", and \"lifeless and boring\", which are adjectives spanning the perceptual space generated by the \"Pleasantness\" and \"Eventfulness\" axes of the ISO/TS 12913-3:2019 circumplex model  [11] . This heightens the suitability of the USotW database for use in the investigation of the affective qualities of soundscapes that the ARAUS dataset aims to enable.\n\nEach 60-second binaural recording in the USotW database was split into two halves of 30 s for the creation of the audio-visual stimuli in the ARAUS dataset. Consequently, the audio-visual stimuli in the ARAUS dataset are all 30 s in length, which is in line with the stimulus length used in several soundscape studies, such as those in  [54, 55, 56] . Upon splitting the recordings into two halves, we discarded any half with (1) audible electrical noise (such as those caused by a faulty microphone or loose connection), in order to reflect only accurately-captured real-life soundscapes;\n\n(2) measured in-situ L A,eq values below 52 dB, in order to ensure that reproduction levels were significantly above the noise floor of the laboratory location with the highest noise floor (about 37 dB; see Fig.  3 ) where the subjective responses were obtained; and/or (3) measured in-situ L A,eq values above 77 dB in order to ensure safe listening levels  [57]  for the participants.\n\nFor each half of the binaural recordings that was not discarded, a 0°-azimuth, 0°-elevation field of view (FoV) was cropped out of their corresponding 360°-videos from the USotW database to form the audio-visual stimulus corresponding to that urban soundscape.\n\nFor the test set, six urban soundscapes were recorded in locations within Nanyang Technological University (NTU), Singapore. The recordings were made in a similar manner as those in the USotW database and were made using equipment in accordance with the SSID Protocol  [53] . Postprocessing of the test set recordings for use as part of the stimuli for the ARAUS dataset was done in the same manner as that for the five-fold cross-validation set.\n\nIn total, this formed a base of 234 urban soundscape recordings for the five-fold cross-validation set of the ARAUS dataset, and an additional base of six soundscapes (not overlapping with the other 234) for the independent test set. Further details on the exact recordings used can be found in Appendix A.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Maskers",
      "text": "The masker recordings for both the five-fold crossvalidation set and the independent test set were derived from source tracks found in the public databases Freesound  [32]  and Xeno-canto  [58] . Both databases host tracks with Creative Commons licenses, with Xeno-canto being a repository of bird calls and Freesound being a more general repository of sound samples and recordings.\n\nThe source tracks from both databases that we determined to be relevant to the ARAUS dataset fell into one of the following classes: bird, construction, traffic, water, and wind. Water  [59, 60, 61] , bird  [54, 61, 62] , and wind  [63]  sounds have previously been investigated in soundscape studies as natural-sound maskers. On the other hand, sounds from traffic and construction are ubiquitous noise sources in urban environments  [64] , and are commonly investigated in soundscape literature  [65, 66, 67] . Therefore, the selection of maskers covers a variety of urban sounds investigated in the soundscape literature for the ARAUS dataset.\n\nThe source tracks for maskers corresponding to the \"bird\" class were first obtained by randomly picking a selection of high-quality tracks of birds on Xeno-canto. Each source track corresponded to bird(s) from a single species, as labeled on Xeno-canto. Additional tracks for the \"bird\" class and all other classes were obtained via the corresponding search term on Freesound, and picking a selection of \"highquality\" tracks containing 30-second sections of sound that corresponded only to that particular masker class, as determined by manual listening. However, the exact number of sources of a single masker class present in a given track was variable, so for instance, a given track of the \"bird\" class could contain vocalizations from one, two, or more birds, but all tracks of the \"bird\" class contain only bird vocalizations. Further details on the source tracks used to create the maskers are given in Appendix A.\n\nEach source track was then processed individually to create 30-second single-channel masker recordings. Singlechannel recordings of maskers were used because  [68]  previously found single-channel recordings to be sufficient to replicate the perceived affective quality of soundscapes, which the ARAUS dataset aims to collect responses for. For source tracks that were originally multi-channel, only the first channel was used for consistency. Source tracks originally longer than 30 s were trimmed to 30 s, while those originally shorter than 30 s were either padded with silence or looped. Finally, noise reduction via spectral gating and high-pass filtering was performed for source tracks in the \"bird\" class to reduce ambient and/or microphone noise in the track. All pre-processing was done manually using Audacity (v2.3.2).\n\nIn total, this formed a set of 280 masker candidates (56 per fold) that were used to generate the stimuli for the fivefold cross-validation set, and a set of seven maskers for the independent test set. The breakdown of the number of masker recordings by class was 80 bird, 40 construction, 40 traffic, 80 water, and 40 wind for the cross-validation set; and 2 bird, 1 construction, 1 traffic, 1 water, 2 wind for the independent test set.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Fold Allocation",
      "text": "After preparing the urban soundscape recordings and maskers in Sections 3.1 and 3.2, the tracks were assigned into the five folds of the cross-validation set such that the distributions of psychoacoustic properties of the urban soundscapes and maskers were similar across the five folds. Since psychoacoustic indicators of a given soundscape have nontrivial and non-spurious correlations with corresponding perceptual indicators  [69] , taking psychoacoustic indicators into account was necessary to minimize distributional shifts across the folds.\n\nThe assignment procedure consisted of the following steps carried out for the urban soundscape recordings, and independently each class of masker tracks.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Track Calibration",
      "text": "Each recording track was calibrated to a pre-defined Aweighted equivalent sound pressure level (L A,eq ). For the base urban soundscapes, the in-situ L A,eq measured at the time of recording for the urban soundscape recordings was used, while a constant value of 65 dB was used for the maskers, similar to  [70] .",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Acoustic And Psychoacoustic Indicator Computation",
      "text": "For all recordings, summary statistics for acoustic and psychoacoustic indicators, as recommended by ISO/TS 12913-3:2019  [11] , were calculated independently for each channel using ArtemiS SUITE (HEAD Acoustics). The indicators comprised sharpness  [71] , loudness  [72] , fluctuation strength  [73] , roughness  [73] , tonality  [74, 75] , L A,eq  [76] , and C-weighted equivalent sound pressure level (L C,eq )  [76] . Finally, band powers summed over third-octave bands with center frequencies from 5 Hz to 20 kHz were also calculated. Table  2  shows the summary statistics calculated for each indicator.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Table 2",
      "text": "Acoustic and psychoacoustic indicators used as channel-wise summary statistics. The set of summary statistics indicated as \"common\" were the mean, maximum, exceedance levels for the 5th percentile, exceedance levels for each decile, and exceedance levels for the 95th percentile. Minimum values for sharpness, loudness, fluctuation strength, roughness, and tonality were zero for all stimuli and hence omitted from analysis.\n\nIndicator Unit Summary statistics Sharpness  [71]  acum common Loudness  [72]  sone common + root mean cube Fluctuation strength  [73]  vacil common Roughness  [73]  asper common Tonality  [74, 75]  tuHMS common L A,eq  [76]  dB common + minimum L C,eq  [76]  dB common + minimum Spectral powers dB third-octave band-wise sum (center freq. 5 Hz to 20 kHz)\n\nWith the exception of tonality in  [74] , the MATLAB Audio Toolbox 1 provides standards-compliant implementations of all other psychoacoustic indicators used. Opensource implementations of the psychoacoustic indicators used are either currently available, or have been indicated as planned, as part of the MOSQITO Toolbox  [77] .",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Dimensionality Reduction",
      "text": "The summary statistics were then used as individual input features to a principal component analysis (PCA), and to project each recording to a principal component space with enough dimensions to achieve 90 % explained variance. Further details on the PCA can be found in Appendix D.\n\nThe primary reason for using PCA in the assignment of folds was to remove correlations between multiple variables, which is desirable for noise and dimensionality reduction prior to clustering as illustrated by  [78] , which removed correlated variables when clustering of soundscape recordings across 8 acoustic indices.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Clustering And Fold Assignment",
      "text": "With the coordinates of each recording in the principal component space, the recordings were organized into clusters of five using a self-organizing map (SOM)  [79] .\n\nFor each cluster of five recordings, each recording in the cluster was randomly assigned to a distinct fold of the cross-validation set. To prevent data leakage, the assignment was done based on psychoacoustic indicators computed from their original 60-second long binaural recordings from the USotW database, such that the 30-second halves in the ARAUS dataset originating from the same original binaural recording were always assigned to the same fold.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Generation Of Stimuli",
      "text": "Each stimulus in the ARAUS dataset is an augmented soundscape to be presented as a 30-second audio-visual stimulus to a human participant, and the procedure used to generate each stimulus is shown in Fig.  2 .\n\n1. https://www.mathworks.com/products/audio.html The audio for the augmented soundscapes was made by combining the 30-second binaural recordings of urban soundscapes in Section 3.1 with the 30-second singlechannel recordings of maskers obtained in Section 3.2 at various gain levels, via element-wise addition of their respective gain-adjusted time-domain signals. For the purposes of stimulus generation, we also included silence in the set of possible maskers, since the addition of silence simply replicates the condition where no masker is added.\n\nFor the five-fold cross-validation set, the urban soundscapes and maskers were chosen randomly from the same fold for combination to prevent data leakage and provide a sample of all possible combinations. Since the fold allocation procedure described in Section 3.3 ensured that the sets of urban soundscapes and maskers used for each fold of the cross-validation set were disjoint, the augmented soundscapes generated from them were disjoint between each fold of the cross-validation set as well. On the other hand, for the independent test set, the urban soundscapes and maskers were exhaustively combined to cover all 48 possible combinations.\n\nBefore combining the urban soundscape and masker recordings for the five-fold cross-validation set, the urban soundscape recordings were calibrated to the in-situ L A,eq levels measured at the time of recording, and the maskers were calibrated to specific soundscape-to-masker ratios (SMR) with respect to the urban soundscape, chosen randomly from the set {-6, -3, 0, +3, +6} dB. For example, if the urban soundscape recording had an in-situ L A,eq of 65 dB and an SMR of +3 dB was randomly chosen, then the masker would be calibrated to an L A,eq of 62 dB. This gave a total of 65 520 possible augmented soundscapes from which we sampled for the ARAUS dataset. All calibration was done via the automated method described by  [80] . On the other hand, for the independent test set, a fixed SMR of 0 dB was used for all combinations. This was to limit the number of stimuli presented to each participant in the test set and the effect of listener fatigue, since the participants assigned to the test set were required to rate all combinations exhaustively, as explained in Section 3.7.\n\nLastly, the single-channel recordings were added to each channel of the binaural tracks, in a manner similar to that in  [81]  with a fixed stereo panning coefficient of 0.5. This audio was then overlaid onto the 0°-azimuth, 0°-elevation field of view cropped from the 360°video recordings from the USotW database taken at the same time as the binaural urban soundscape recordings to form the audio-visual stimuli.",
      "page_start": 5,
      "page_end": 6
    },
    {
      "section_name": "Participant Recruitment",
      "text": "Prior ethical approval was obtained from the Institutional Review Board, NTU (Ref. IRB 2020-08-035) before participant recruitment and response collection. Participants were recruited via online messaging channels, posters, and emails.\n\nIn total, 642 unique participants were recruited to provide their responses for the ARAUS dataset, of which 37 (5.76 %) had their responses rejected. Hence, responses from only 605 participants were included in the final dataset. We rejected responses from participants who (1) failed a hearing test (19 participants, 2.96 %); (2) failed more than three out of seven consistency checks described in Section 3.9 (17 participants, 2.65 %); or (3) provided the same responses to any item in the Affective Response Questionnaire (ARQ) described in Section 3.7 for all stimuli they were presented, thereby providing no useful information to the dataset (3 participants, 0.47 %). Two of the rejected participants failed both the hearing test and more than three out of seven consistency checks.\n\nParticipants aged under 30 were considered to have failed the hearing test if they had a mean threshold of hearing above 20 dB and participants aged 30 and above were considered to have failed if they had a mean threshold of hearing above 30 dB via pure-tone audiometry using the uHear application on a mobile phone (Apple iPhone 4S) and earbuds (Apple EarPods). The tested frequencies were 0.5, 1, 2, 4, and 6 kHz. These were within the standard ranges used for screening in pure tone audiometry  [82]  and previous soundscape research  [83] . The higher threshold of 30 dB was applied to participants aged 30 and above to balance the risk of age bias (since age is highly correlated with hearing ability  [84] ) against the need to ensure that hearing loss did not interfere with the perception of the augmented soundscapes in the ARAUS dataset.\n\nThe participants were each assigned a fold such that each fold of the five-fold cross-validation set had responses from 120 participants. The independent test set had responses from 5 participants. The age and gender distributions of the participants are shown in Table  3 , and further information on participant demographics can be found in Appendix C. Due to the test sites for the data collection process being located within university campuses (as shown in Fig.  3 ), a majority of the 605 participants whose responses were included in the ARAUS dataset were students (443 participants, 73.2 %) who were in the process of obtaining their bachelor's degree (380 participants, 62.8 %). Participants were also relatively young (mean age 26.7 years, standard deviation 10.0 years) compared to those in the ISD (mean age 33.8 years, standard deviation 14.57 years)  [85] , but slightly older compared to those in the IADS-2 (college students)  [46]  and IADS-E (mean age 21.32 years, standard deviation 2.38 years)  [48]  datasets.",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "Listening Conditions",
      "text": "Participants were presented with all audio-visual stimuli via closed-back headphones (Beyerdynamic Custom One Pro) powered by an external sound card (SoundBlaster E5). The video was presented via a 23-inch monitor (Philips 236E SoftBlue) and measured 21.5 cm by 12 cm on the screen.\n\nParticipants sat facing about 1 m from the monitor. Due to the large number of participants involved in the experiment, participants listened to the stimuli in one of four quiet rooms, three located in NTU and one in the Singapore University of Technology and Design (SUTD). Photos of each of the four quiet rooms are shown in Fig.  3 .",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Affective Response Questionnaire",
      "text": "For each audio-visual stimulus, participants were instructed to perform their evaluations given the following prompt:\n\nImagine that you are standing at the location shown in the video, listening to the sound environment playing through the headphones.\n\n2. To safeguard their identities, the small number (2 participants, 0.33 %) of participants identifying as neither male nor female were randomly assigned as \"male\" or \"female\" in the public release of the ARAUS dataset, each with a probability of 50 %. After completely experiencing the stimulus at least once, participants were presented with a set of 9 questions from the Method A questionnaire in ISO/TS 12913-2:2018  [20] , which we refer to as the \"Affective Response Questionnaire\" (ARQ). The first 8 questions were related to the perceived affective quality of the sound they heard over the headphones:\n\nTo what extent do you agree or disagree that the present surrounding sound environment is {pleasant, eventful, chaotic, vibrant, uneventful, calm, annoying, monotonous}? The last question was related to the appropriateness of the location depicted in the video they saw on the monitor with respect to the sound they heard over the headphones:\n\nTo what extent is the present surrounding sound environment appropriate to the pleasant place? Participants responded to all questions on a five-point Likert scale via a computerized graphical user interface (GUI) depicted in Fig.  4 , and we coded their responses to values in {1, 2, 3, 4, 5} to match the scale.\n\nFor the cross-validation set, participants responded to the ARQ for 42 unique, randomly-selected stimuli from the fold that they were assigned to. For the independent test set, all participants responded to the ARQ for the same 48 exhaustively-generated stimuli.\n\nIn addition to the \"main\" 42 (48) stimuli shown to each participant in the cross-validation (test) set, we presented each participant with three auxiliary stimuli. Participants were also required to provide responses to the ARQ for these stimuli, but the responses are not part of the ARAUS dataset, because these stimuli were the same for every participant, and did not serve the same purpose as the main stimuli in the ARAUS dataset. These stimuli were namely: (1) A \"pre-experiment\" stimulus, which was shown as the first stimulus before presenting the main stimuli for the cross-validation/test set. (2) An \"attention\" stimulus, which was identical to the \"pre-experiment\" stimulus and shown in between two randomly selected \"main\" stimuli for the crossvalidation/test set. For this stimulus, the GUI had special instructions for the participant to choose specific options for the ARQ before they could proceed. (3) A \"post-experiment\" stimulus, which was identical to the \"pre-experiment\" stimulus and shown as the last stimulus after presenting the main stimuli for the crossvalidation/test set. ARQ responses to this stimulus were used for internal consistency checks, as described in Section 3.9.",
      "page_start": 7,
      "page_end": 8
    },
    {
      "section_name": "Participant Information Questionnaire",
      "text": "Since the ISO 12913-1:2014 definition of \"soundscape\" mandates that acoustic environments must be perceived in context  [86] , information specific to the listeners who participated in the study was also necessary to understand the context behind listener perceptions of the augmented soundscapes presented as stimuli. Hence, we administered another questionnaire, which we dub the \"Participant Information Questionnaire\" (PIQ), to each participant after they had completed the ARQs for the stimuli shown to them.\n\nThe PIQ consisted of items related to basic demographic information and standard psychological questionnaires.\n\nItems related to basic demographic information consisted of age, gender, spoken languages, citizenship status, education status, occupational status, dwelling type, ethnicity, and length of residence of the participant.\n\nThe psychological questionnaires administered were (1) a shortened, 10-item version of the Weinstein Noise Sensitivity Scale (WNSS-10)  [87] ; (2) a shortened, 10-item version of the Perceived Stress Scale (PSS-10)  [88] ; (3) the WHO-5 Well-Being Index  [89] ; and (4) the Positive and Negative Affect Schedule (PANAS)  [90] .\n\nThe relevance of the questionnaires is evident in the fact that noise sensitivity  [91]  and stress level  [92]  play a significant role in the affective perception of soundscapes, the WHO-5 Well-Being Index is used in the Soundscape Indices Protocol (SSID)  [53] , and  [93]  previously used PANAS as a measure of participants' mood in a study of the emotional salience of sounds in soundscapes. The PSS-10 has been validated by the same authors of the original 14-item questionnaire  [94] , but the particular version (WNSS-10) of the Weinstein Noise Sensitivity Scale used for the ARAUS dataset has not previously been validated in the literature. Nonetheless, the internal reliability of WNSS-10 is affirmed based on the results of the analysis obtained in Section 4.2.\n\nFull details of the PIQ with individual questions, options, and response coding for each section of the questionnaire can be found in Appendix B.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Consistency Checks",
      "text": "In order to ensure a baseline level of data quality in the responses to the ARQ, seven consistency checks were performed on each participant's responses. The consistency checks were designed as single-value metrics, and a participant was considered to have failed a consistency check if the corresponding value of the metric was at least 1. If a participant failed more than three out of seven consistency checks, their responses were dropped from the dataset.\n\nTo describe the single-value metrics, we first define r pl , r ev , r ch , r vi , r ue , r ca , r an , r mo , r ap ∈ {1, 2, 3, 4, 5} as the responses to the ARQ in Section 3.7 regarding the extent to which the sound environment in a given stimulus was respectively pleasant, eventful, chaotic, vibrant, uneventful, calm, annoying, monotonous, and appropriate.\n\nThe seven consistency checks consist of three types of checks. The first check measures the mean absolute difference (MAD) between ARQ responses on the \"preexperiment\" and \"post-experiment\" stimuli. Since the \"preexperiment\" and \"post-experiment\" stimuli were identical, a perfectly consistent participant would have provided the same responses to both presentations.\n\nSince the affective descriptors \"pleasant\" and \"annoying\" are on opposite axes of the ISO/TS 12913-3:2019 circumplex model of soundscape perception  [11] , a perfectly consistent participant would have provided the same response for \"pleasant\" and \"annoying\" if the Likert coding of either were to be reversed. The same considerations apply to the other three pairs of opposite attributes on the circumplex model. Therefore, the next four checks consider the MADs between the four pairs of r p and (6 -r q ), where (p, q) is a pair of opposite descriptors.\n\nLastly, the mean squared error (MSE) between r pl and (3+2P ), and that between r ev and (3+2E) across all stimuli presented was computed, where\n\nrespectively are the normalized values of \"ISO Pleasantness\" and \"ISO Eventfulness\" as suggested in  [95] , and k = 8+ √ 32 is a normalization constant such that P, E ∈ [-1, 1]. Since the affective descriptor \"pleasant\" theoretically parallels the principal axis of \"Pleasantness\" in the ISO/TS 12913-3:2019 circumplex model of soundscape perception, a perfectly consistent participant would have provided responses matching the magnitude in both directions. The rescaling of P as (3 + 2P ) was necessary to match the range of values of r pl for a valid comparison. Similar considerations apply for the affective descriptor \"eventful\" to the principal axis \"Eventfulness\".",
      "page_start": 8,
      "page_end": 9
    },
    {
      "section_name": "Data Analysis",
      "text": "After the data collection described in Section 3 had been completed, we performed analyses to verify data quality and empirical consistency with known literature.\n\nFirstly, the ARQ responses were analyzed to compare the effect of different maskers on the normalized ISO Pleasantness P of the augmented soundscapes, and validate that the stimuli in the ARAUS dataset spanned the perceptual space generated by the ISO Pleasantness and ISO Eventfulness axes. Statistical and internal reliability tests were then performed on the PIQ responses and consistency check metrics to ensure that the distribution of data and responses in each fold of the cross-validation set did not significantly differ. This allowed us to assess the degree to which the methodological efforts to minimize domain shift between folds were successful.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Affective Response Questionnaire",
      "text": "To investigate the effect each masker had on the ISO Pleasantness of the urban soundscapes it was augmented to, we first used the ARQ responses to compute the ISO Pleasantness values for all the stimuli in the ARAUS dataset using Equation  (1) . The difference in ISO Pleasantness for each base urban soundscape (i.e., augmented with silence) and the same urban soundscape augmented with each masker was computed. These differences were averaged across all soundscapes for which the same masker, regardless of the SMR, was presented to obtain the mean change in ISO Pleasantness effected by each masker across different soundscapes. This allowed us to determine which maskers were optimal for augmentation, at least on average in a naive sense across the urban soundscapes in the ARAUS dataset.\n\nFigure  5  shows the mean change in ISO Pleasantness value as a function of masker used to augment soundscape, aggregated over soundscapes and SMRs used. Out of the 287 maskers in the ARAUS dataset, mean positive changes in ISO Pleasantness were only observed in maskers belonging to the bird and water classes. However, not all of the bird and water maskers showed mean positive changes, corroborating the findings by  [92]  that not all natural sounds are necessarily perceived as pleasant. Nevertheless, augmentation with 64 (78.0 %) of the bird maskers and 16 (19.5 %) of the water maskers, each out of 82, resulted in effective mean positive changes in ISO Pleasantness, which supports findings in  [14, 54, 70]  where specific bird and water sounds were found to have improved the perceived pleasantness of urban soundscapes.\n\nIn contrast, mean negative changes in ISO Pleasantness were observed for all wind, traffic, and construction maskers in the ARAUS dataset. While the decrease in ISO Pleasantness due to the addition of traffic  [96]  and construction  [97]  maskers is expected, the decrease in ISO Pleasantness for all wind sounds used as maskers was contrary to the results in narrative interviews reported by  [92]  that people tended to perceive wind rustling through trees as pleasant. This could be due to the range of SMRs used for the ARAUS dataset, which ranged only from -6 to +6 dB. The mean in-situ L A,eq of the tracks in the USotW database used for the ARAUS dataset was about 65 dB, but natural wind sounds in reallife environments tend to have a mean L A,eq of about 55 dB or less  [98] , which means that an SMR of +10 dB or higher may have been more appropriate to achieve an increase in perceived pleasantness for wind maskers instead. At the SMRs used for the ARAUS dataset, the wind maskers may have been added at overly high levels, rendering them to be perceived similarly to the traffic maskers due to their similar spectral characteristics and potentially contributing to the decrease in ISO Pleasantness. Additionally, the laboratorybased nature of the data collection process caused the wind maskers to be heard without perceiving natural movements of the air that would be present in an in-situ study, which could have resulted in an artificial or unpleasant situation for the participants.\n\nTo investigate how well the ARAUS dataset stimuli and the base urban soundscapes from the USotW database spanned the perceptual space generated by the \"Pleasantness-Eventfulness\" axes, we first computed the normalized values of P and E according to Equations (  1 ) and (  2 ) for each individual ARQ response in the ARAUS dataset. Then, we plotted a heat map and scatter plot of the responses on the P -E axes, as shown in Fig.  6 . We can see that both the ARAUS dataset stimuli and the USotW soundscapes covered the positive, neutral, and negative regions of both the ISO Pleasantness and the ISO Eventfulness axes, thereby validating their use in analysis related to the ISO 12913 standard.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Participant Information Questionnaire",
      "text": "Since items in the PIQ such as the participant's age  [99]  and education status  [100]  can affect the affective perception of soundscapes, the participants in each fold of the cross-validation set of the ARAUS dataset should ideally be drawn from distributions with similar demographics. This was not enforced during the participant recruitment and fold allocation process, thus a post hoc analysis of the PIQ responses was performed to assess the demographic distributions. The post hoc analysis was performed via standard statistical tests for equality of distributions.\n\nFor items in the PIQ coded as categorical variables, χ 2tests were conducted between the responses obtained in each fold of the cross-validation set (treated as observed frequencies) and those obtained in the entire cross-validation set (treated as expected frequencies). No significant differences were observed, at 5 % significance levels, in the distribution of all categorical variables between folds, with the lowest p-value being 0.1070 for the participants' gender.\n\nFor items in the PIQ coded as continuous variables, Kruskal-Wallis tests were conducted by treating each fold as an independent group. The Kruskal-Wallis tests showed no significant differences at 5 % significance levels in the distribution of all continuous variables between folds, with the lowest p-value being 0.3090 for the extent to which participants were annoyed by noise over the past 12 months.\n\nTogether, these results indicate that the distribution of participants in a given fold did not significantly differ from the participants in any other fold, which reinforces the validity of using the five-fold cross-validation set of the ARAUS dataset to generate models for populations sharing similar characteristics to that of the entirety of the crossvalidation set. Full results of the statistical tests and explicit distributions of responses by fold and PIQ item are detailed in Appendix C.\n\nFor the psychological questionnaires used in the PIQ (WNSS-10, PSS-10, WHO-5, and PANAS), Cronbach's α [101] and McDonald's ω  [102]  were computed as standard internal reliability coefficients to independently verify if their items in aggregate were indeed measuring the same construct. This served as a validation study for WNSS-10 and a replication study for the other questionnaires.\n\nThe internal reliability study results are shown in Table  4 . All values of the internal reliability coefficients are above 0.8, which can be considered \"high\" given the number of items in each questionnaire  [103] . Therefore, all items in each questionnaire indeed measured the same construct. In particular, the Cronbach's α value for of 0.835 for WNSS-10 parallels similar validation studies for different iterations of the questionnaires of the original 21-item version  [104] , thereby confirming the reliability of the previously unvalidated version used for the ARAUS dataset.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Consistency Checks",
      "text": "In a similar manner to the PIQ, Kruskal-Wallis tests for each of the seven single-value consistency metrics were  performed by treating the ARQ responses in each fold as independent groups. Full results are presented in Appendix C.\n\nNo significant differences were observed, at 5 % significance levels, in the distribution of all continuous variables between folds, with the lowest p-value being 0.2545 for the MAD between \"vibrant\" and reversed \"monotonous\" ratings. This indicates that the distribution of response consistency in a given fold did not significantly differ from the responses in any other fold, reinforcing the validity of using the five-fold cross-validation set of the ARAUS dataset to generate generalizable and unbiased models, at least from",
      "page_start": 9,
      "page_end": 10
    },
    {
      "section_name": "Affective Response Modeling",
      "text": "To illustrate how the ARAUS dataset can be used for systematic and fair benchmarking of models for affective perception, four models were trained to predict the ISO Pleasantness, as defined in Equation (  1 ), of a given augmented soundscape using the ARAUS dataset. The models were a relatively low-parameter regression model, a convolutional neural network (CNN), and two different probabilistic perceptual attribute predictor (PPAP) models  [105, 106] . A dummy model that always predicts the mean of the training data labels was additionally used as a naive benchmark.\n\nUsing a five-fold cross-validation scheme, each model was trained five times, each with a different fold of the crossvalidation set used as the validation set (5040 samples) and the remaining four folds used as the training set (20 160 samples). For models sensitive to random initialization, results from 10 different seeds per validation fold were recorded, totalling 50 runs. After training, each model was evaluated on the independent test set (48 samples).",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Models",
      "text": "",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Regularized Linear Regression",
      "text": "The linear regression models used acoustic and psychoacoustic indicators of an augmented soundscape as input features to predict its ISO Pleasantness. Firstly, the statistics detailed in Section 3.3.2 were computed for each binaural augmented soundscape in the ARAUS dataset, which gave 264 possible input features to be used for regression. The features, without prior dimensionality reduction, were used Fig.  7 . Baseline CNN model architecture, adapted from  [41]  to train elastic net models  [107]  with L 1 and L 2 regularization weights of 0.5 and 0.25, respectively.\n\nElastic net models are designed for parameter sparsity, since the elastic net loss function will cause most weights to be set to zeroes after training concludes. This indirectly allows the method to automatically choose suitable parameters for regression from an initial larger selection, and makes it more computationally efficient than stepwise regression.",
      "page_start": 10,
      "page_end": 11
    },
    {
      "section_name": "Convolutional Neural Network",
      "text": "The CNN models were trained to predict the ISO Pleasantness of an augmented soundscape using its log-mel spectrogram. Firstly, the channel-wise log-mel spectrograms were computed for each binaural augmented soundscape in the ARAUS dataset, with a Hann window length of 4096 samples, 50 % overlap between windows, and 64 mel frequency bands from 20 Hz to 20 kHz.\n\nThe log-mel spectrograms (as 644-by-64-by-2 tensors) were then used as input to the CNN models with the model architecture shown in Fig.  7 . The architecture is identical to the baseline model architecture used for the acoustic scene classification task (Task 1B) of the DCASE 2020 Challenge  [41] . However, due to the slightly larger input dimensions of the ARAUS data, the modified models shown in Fig.  7  contained about 142K parameters, compared to the original 116K in  [41] , with the only difference being the input dimensions of the final dense layer.\n\nThe CNN models were trained over 100 epochs with an Adam optimizer  [108]  with learning rate 1 × 10 -4 and batch size 32. The training was stopped early if the validation set MSE did not improve for 10 consecutive epochs. This process was repeated for 10 runs per validation fold to obtain the mean performance of the models.",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Probabilistic Perceptual Attribute Predictor",
      "text": "The PPAP models were used to model the subjectivity in ARQ responses by outputting predictions for ISO Pleasantness based on probability distributions rather than deterministic values. As described in  [105, 106] , we trained the PPAP models using the normal distribution N (µ, σ 2 ), with the loss function being the log-probability of the groundtruth response being observed, given the output distribution parameters µ and σ.\n\nUsing the ARAUS dataset responses, we trained two different variations of the PPAP models: one performing augmentation in the time domain (i.e., taking in log-mel spectrograms of the augmented soundscapes as initial input)  [105] , and one performing augmentation in the feature domain (i.e., taking in log-mel spectrograms of base urban soundscapes and maskers separately as initial inputs, and subsequently performing augmentation on features extracted from them)  [106] , both with multi-head attention in the feature mapping blocks. The parameters for the computation of the log-mel spectrograms and the training procedure for the PPAP models were similar to that of the CNN models.",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Results And Discussion",
      "text": "The label means for the normalized ISO Pleasantness P were 0.0208, 0.0317, 0.0307, 0.0281, and 0.0225 when folds 1, 2, 3, 4, and 5 were respectively left out as the validation fold for the derivation of the dummy models. Hence, these were also the exact predictions given by all dummy models regardless of the soundscape presented. Considering that P ∈ [-1, 1], the difference in label means by fold is also insubstantial, since they are within 0.5 % of the full range. In fact, the distributions of the training set labels themselves have no significant difference by fold, as shown in Fig.  8 .\n\nAfter training the elastic net models, the weights for all but three input features were set to zero regardless of the fold used as the validation set. Taking the mean of weights for the regression models across the 5-fold cross-validation set, this gave the general regression model\n\nwhere N max is the maximum loudness (in sone), M f is the power (in dB) at the one-third octave band with center frequency f , the prediction for the normalized ISO Pleasantness value P is denoted as P , and the regression coefficients are not normalized.\n\nThis implies that of the 264 acoustic and psychoacoustic parameters used as input features to train the regression models, the features that most significantly impacted the ISO Pleasantness were N max , M 10 kHz and M 12.5 kHz , at least based on the responses in the ARAUS dataset. Incidentally, The negative coefficients of the features in Equation (  3 ) also suggest that increasing the peak loudness and highfrequency components of an augmented soundscape correlate with a decrease in its perceived pleasantness, corroborating the respective findings by  [109]  and  [110]  regarding general acoustic environments. Lastly, Table  5  compares the performance of the four baseline models and the dummy model with respect to the MSEs achieved across their training, validation, and test sets in the 5-fold cross-validation scheme used to train them. All baseline models performed better than the dummy model in the training, validation, and test sets, which suggests that the features trained in all the baseline models to make ISO Pleasantness predictions were indeed meaningful.\n\nIn addition, the CNN and PPAP models performed significantly better than the elastic net models, with the lowest mean train, validation, and test set MSE of 0.1086, 0.1212, and 0.0838 observed with the PPAP performing feature-domain augmentation  [106] , the CNN  [41] , and the PPAP performing feature-domain augmentation  [106] , respectively. This is expected due to the vast difference in the numbers of parameters used by the CNN and PPAP models (142-515K) for prediction, in comparison to the regression models (4 parameters) and dummy model. Nevertheless, none of the models were overfitted to the dataset, as can be seen from the relatively similar values for training and validation set MSEs across all models, which demonstrates the versatility of the ARAUS dataset for use in training generalizable high-parameter models.\n\nNotably, the test set MSE values are also smaller than that of the validation set, which could be due to the relative size of the test set (48 samples) as compared to the validation set (5040 samples) making the test set \"easier\" from the perspective of the prediction models than their respective validation sets.",
      "page_start": 11,
      "page_end": 12
    },
    {
      "section_name": "Limitations And Future Work",
      "text": "While the ARAUS dataset utilized recordings of in-situ urban soundscapes as part of its stimuli, the laboratorybased data collection process means that models trained using the ARAUS dataset may require confirmation of their ecological validity with follow-up in-situ experiments or soundwalks. The range of SMRs used for the generation of the augmented soundscapes in the ARAUS dataset (from -6 to +6 dB) is also a potential limitation of the dataset, since real-life or virtual sound sources used for augmentation in general could have relative differences outside of the chosen range, so future data collection related to the ARAUS dataset could consider increasing the range of SMRs used for the generation of stimuli, which could be done by changing input parameter settings in the provided replication code. Not all combinations of urban soundscapes, maskers, and SMRs were exhaustively generated for the current iteration of the ARAUS dataset, so responses could also be collected exhaustively in the future to make the dataset fully comprehensive. Responses could alternatively be collected continuously over time, instead of just once after the presentation of each stimulus, in order to study the consistency of participants' affective responses over time. The visual content of the stimuli could also be varied, such as by using video recordings captured at completely different locations, for the same audio recording, in order to investigate changes in affective responses due purely to changes in the visual content.\n\nMoreover, since the participants in the ARAUS dataset were mostly young university students, the results and analysis obtained may not necessarily translate equivalently to a more general population of people exposed to urban soundscapes. The inclusion of only five participants in the test set, as compared to 120 in each fold of the crossvalidation set, is also a primary limitation of the dataset. At the scale of the test set, person-to-person differences in perception could dominate any other factor contributing to perception, thereby causing the test set to serve more as a small focus group of participants rather than a general sample representative of the same population as the cross-validation set. Hence, future extensions to the ARAUS dataset could concentrate on enlarging the test set and obtaining responses from participants from an older demographic, to allow for improved benchmarking of models trained using the dataset.\n\nThe models described in this article were also trained using the individual augmented soundscapes in the ARAUS dataset in isolation from each other, so they did not account for the effects of temporal successions of different maskers, and hence different augmented soundscapes. Naïvely applying them to choose a time series of optimal maskers for an extended duration of time could lead to a dissonant succession of maskers that may inadvertently result in an unpleasant augmented soundscape overall, despite the individual maskers being predicted as optimal for individual time windows. Further work on these models could thus look into generalizing them to extended durations of time. The models could also be fine-tuned via transfer learning methods on the affective soundscape datasets in Table  1  (which possess labels of a different nature), and be compared with other benchmarks to assess the amenability of the ARAUS dataset to transfer learning.\n\nLastly, other perceptual indicators other than those defined in ISO/TS 12913-2:2018, such as the perceived loudness or tranquility, could also be used as part of the ARQ to expand its scope and allow the ARAUS dataset to possess greater generalizability.",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Conclusion",
      "text": "In conclusion, we presented the Affective Responses to Augmented Urban Soundscapes (ARAUS) dataset, which functions as a benchmark dataset for comparisons of prediction models for the affective perception of urban and augmented soundscapes. We first presented a systematic methodology for the collection of data, which can be replicated or extended upon. Subsequently, we analyzed the responses obtained for the ARAUS dataset, and provided benchmark models for predicting the perceptual attribute of ISO Pleasantness. To the best of our knowledge, the ARAUS dataset is currently the largest soundscape dataset with perceptual labels, but is not without its inherent limitations as described in Section 6.\n\nNonetheless, we hope that the ARAUS dataset becomes a beneficial and enduring resource for the soundscape community, by assisting soundscape researchers in developing more accurate, robust models for soundscape perception.",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "Appendix A Source Files For Araus Dataset",
      "text": "This appendix contains details of the exact source files used to generate the augmented soundscapes in the ARAUS dataset. Table  A .1 shows the breakdown (by fold) of the soundscape recordings from the Urban Sounds of the World (USotW) database used as base soundscapes for the five-fold cross-validation set of the ARAUS dataset. The first half of R0091 was used as the \"pre-experiment\", \"attention\", and \"post-experiment\" stimulus, so R0091 is not considered to be part of any fold in the ARAUS dataset. Table  A .2 shows the breakdown (by fold) of the source recordings from Freesound and Xeno-Canto used as maskers for both the five-fold cross-validation set and independent test set. Panoramic photos and GPS coordinates of the locations recorded for the independent test set of the ARAUS dataset are shown in   3) How much has indoor/outdoor noise bothered, disturbed, or annoyed you over the past 12 months?\n\n4) How would you describe your satisfaction of the overall quality of the acoustic environment in Singapore? Items marked with single asterisks (*) were reverse coded. In other words, \"Strongly disagree\" was coded as \"5\" and \"Strongly agree\" was coded as \"1\" for these items. The asterisks were not shown in the digital form presented to the participants.",
      "page_start": 18,
      "page_end": 22
    },
    {
      "section_name": "6) Shortened Perceived Stress Scale:",
      "text": "The questions in this scale ask you about your feelings and thoughts during the last month. In each case, you will be asked to indicate how often you felt or thought a certain way. Although some of the questions are similar, there are differences between them and you should treat each one as a separate question. The best approach is to answer each question fairly quickly. That is, don't try to count up the number of times you felt a particular way, but rather indicate the alternative that seems like a reasonable estimate.\n\n[0] Never;  [1]  Almost never;  [2]  Sometimes;  [3]  Fairly often;  [4]  Very often\n\nIn the last month, how often have you... a) been upset because of something that happened unexpectedly? b) felt that you were unable to control the important things in your life? c) felt nervous and \"stressed\"? d) felt confident about your ability to handle your personal problems? e) felt that things were going your way? f) found that you could not cope with all the things that you had to do? g) been able to control irritations in your life? h) felt that you were on top of things? i) been angered because of things that were outside of your control? j) felt difficulties were piling up so high that you could not overcome them?\n\nItems corresponding to Positive Affect (marked with the oplus symbol ⊕ ) and Negative Affect (marked with the ominus symbol ⊖ ) were tallied to give separate Positive Affect and Negative Affect scores. The oplus and ominus symbols were not shown in the digital form presented to the participants.",
      "page_start": 22,
      "page_end": 22
    },
    {
      "section_name": "Appendix C Distributions And Statistical Test Results For Piq And Arq",
      "text": "This appendix collates the detailed distributions and statistical test results for the PIQ and ARQ described in Section 4.   C .3 presents the Kruskal-Wallis test results for the single-value metrics described in Section 3.9.",
      "page_start": 24,
      "page_end": 24
    },
    {
      "section_name": "7Hvw",
      "text": ")ROG     and last (\"consistency check\") stimuli, (b) MAD between reversed \"pleasant\" (6 -r pl ) and \"annoying\" (ran) responses across all stimuli, (c) MAD between reversed \"eventful\" (6 -rev) and \"uneventful\" (rue) responses across all stimuli, (d) MAD between reversed \"calm\" (6 -rca) and \"chaotic\" (r ch ) responses across all stimuli, (e) MAD between reversed \"vibrant\" (6 -r vi ) and \"monotonous\" (rmo) responses across all stimuli, (f) Mean squared error (MSE) between \"pleasant\" (r pl ) and rescaled \"ISO Pleasantness\" (3 + 2P ) responses across stimuli, (g) MSE between \"eventful\" (rev) and rescaled \"ISO Eventfulness\" (3 + 2E) responses across stimuli.",
      "page_start": 25,
      "page_end": 25
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Framework of the study methodology.",
      "page": 3
    },
    {
      "caption": "Figure 1: , and full details",
      "page": 3
    },
    {
      "caption": "Figure 3: ) where the subjective responses",
      "page": 4
    },
    {
      "caption": "Figure 2: 1. https://www.mathworks.com/products/audio.html",
      "page": 5
    },
    {
      "caption": "Figure 2: Illustration of stimulus generation procedure for a single stimulus.",
      "page": 6
    },
    {
      "caption": "Figure 3: Test sites at (top left) Academic Media Studio, SUTD, (top right)",
      "page": 7
    },
    {
      "caption": "Figure 4: GUI used to administer the ARQ for the ARAUS dataset.",
      "page": 7
    },
    {
      "caption": "Figure 4: , and we coded their responses to",
      "page": 7
    },
    {
      "caption": "Figure 5: shows the mean change in ISO Pleasantness",
      "page": 9
    },
    {
      "caption": "Figure 6: We can see",
      "page": 9
    },
    {
      "caption": "Figure 5: Mean change in ISO Pleasantness value as a function of each of the 287 (280 cross-validation, 7 test set) maskers used to augment",
      "page": 10
    },
    {
      "caption": "Figure 6: Heat map (grayscale boxes) and scatter plot (yellow points)",
      "page": 10
    },
    {
      "caption": "Figure 7: Baseline CNN model architecture, adapted from [41]",
      "page": 11
    },
    {
      "caption": "Figure 7: The architecture is identical to",
      "page": 11
    },
    {
      "caption": "Figure 7: contained about 142K parameters, compared to the origi-",
      "page": 11
    },
    {
      "caption": "Figure 8: Violin plots of distributions of normalized ISO Pleasantness",
      "page": 11
    },
    {
      "caption": "Figure 8: After training the elastic net models, the weights for all",
      "page": 11
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "",
          "Column_2": "",
          "\u0000\u0014": "",
          "Column_4": "",
          "\u0000\u0013": "",
          "Column_7": "",
          "\u0000\u0015": "",
          "Column_10": "",
          "\u0000\u0016": "",
          "Column_13": "",
          "Column_16": "",
          "\u0000<\u0000H\u0000V": "\u00001\u0000R"
        },
        {
          "Column_1": "",
          "Column_2": "",
          "\u0000\u0014": "\u0000\u0013\u0000",
          "Column_4": "",
          "\u0000\u0013": "\u0000\u0013",
          "Column_7": "",
          "\u0000\u0015": "\u0000\u001b",
          "Column_10": "",
          "\u0000\u0016": "\u0000\u0013\u0000\u001a",
          "Column_13": "",
          "Column_16": "",
          "\u0000<\u0000H\u0000V": ""
        }
      ],
      "page": 25
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "",
          "\u0000\u0014": "",
          "Column_3": "",
          "Column_4": "",
          "\u0000\u0013": "",
          "Column_7": "",
          "\u0000\u0015": "",
          "Column_10": "",
          "\u0000\u0016": "",
          "Column_13": "",
          "Column_16": "",
          "\u0000<\u0000H\u0000V": "",
          "Column_20": "\u0000<\u0000H\u0000V",
          "Column_21": ""
        },
        {
          "Column_1": "",
          "\u0000\u0014": "\u0000\u0016",
          "Column_3": "",
          "Column_4": "",
          "\u0000\u0013": "\u0000\u001b",
          "Column_7": "",
          "\u0000\u0015": "\u0000\u0018",
          "Column_10": "",
          "\u0000\u0016": "\u0000\u0017",
          "Column_13": "",
          "Column_16": "",
          "\u0000<\u0000H\u0000V": "",
          "Column_20": "\u00001\u0000R\n\u00001\u0000\u0011\u0000$\u0000\u0011",
          "Column_21": ""
        },
        {
          "Column_1": "",
          "\u0000\u0014": "\u0000\u0019",
          "Column_3": "",
          "Column_4": "",
          "\u0000\u0013": "\u0000\u0015",
          "Column_7": "",
          "\u0000\u0015": "\u0000\u0016",
          "Column_10": "",
          "\u0000\u0016": "\u0000\u0016",
          "Column_13": "",
          "Column_16": "",
          "\u0000<\u0000H\u0000V": "",
          "Column_20": "",
          "Column_21": ""
        }
      ],
      "page": 25
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "",
          "\u0000\u0014": "",
          "Column_3": "",
          "Column_4": "",
          "\u0000\u0013": "",
          "Column_7": "",
          "\u0000\u0015": "",
          "Column_10": "",
          "\u0000\u0016": "",
          "Column_13": "",
          "Column_16": "",
          "\u0000<\u0000H\u0000V": "",
          "Column_20": "\u0000<\u0000H\u0000V",
          "Column_21": ""
        },
        {
          "Column_1": "",
          "\u0000\u0014": "",
          "Column_3": "",
          "Column_4": "",
          "\u0000\u0013": "",
          "Column_7": "",
          "\u0000\u0015": "",
          "Column_10": "",
          "\u0000\u0016": "",
          "Column_13": "",
          "Column_16": "",
          "\u0000<\u0000H\u0000V": "",
          "Column_20": "\u00001\u0000R\n\u00001\u0000\u0011\u0000$\u0000\u0011",
          "Column_21": ""
        },
        {
          "Column_1": "",
          "\u0000\u0014": "\u0000\u0017",
          "Column_3": "",
          "Column_4": "",
          "\u0000\u0013": "\u0000\u001b",
          "Column_7": "",
          "\u0000\u0015": "\u0000\u001b",
          "Column_10": "",
          "\u0000\u0016": "\u0000\u0016",
          "Column_13": "",
          "Column_16": "",
          "\u0000<\u0000H\u0000V": "",
          "Column_20": "",
          "Column_21": ""
        },
        {
          "Column_1": "",
          "\u0000\u0014": "\u0000\u0018",
          "Column_3": "",
          "Column_4": "",
          "\u0000\u0013": "\u0000\u0015",
          "Column_7": "",
          "\u0000\u0015": "\u0000\u0013",
          "Column_10": "",
          "\u0000\u0016": "\u0000\u0017",
          "Column_13": "",
          "Column_16": "",
          "\u0000<\u0000H\u0000V": "",
          "Column_20": "",
          "Column_21": ""
        }
      ],
      "page": 25
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "\u0000<\u0000H\u0000V": "\u00001\u0000R"
        }
      ],
      "page": 25
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "",
          "Column_2": "",
          "\u0000\u0014": "",
          "Column_4": "",
          "Column_5": "\u0000\u0018",
          "Column_6": "\u0000\u001b",
          "Column_7": "",
          "Column_8": "\u0000\u0019",
          "Column_9": "\u0000\u0017",
          "Column_10": "",
          "Column_11": "\u0000\u0018",
          "Column_12": "\u0000\u0014",
          "Column_13": "",
          "Column_14": "\u0000\u0018",
          "Column_15": "\u0000\u0015",
          "Column_16": "",
          "Column_17": "\u0000\u0018",
          "Column_18": "\u0000\u0014",
          "\u0000)\u0000H\u0000P\u0000D\u0000O\u0000H": "\u00000\u0000D\u0000O\u0000H"
        },
        {
          "Column_1": "",
          "Column_2": "",
          "\u0000\u0014": "\u0000\u0017",
          "Column_4": "",
          "Column_5": "\u0000\u0019",
          "Column_6": "\u0000\u0015",
          "Column_7": "",
          "Column_8": "\u0000\u0018",
          "Column_9": "\u0000\u0019",
          "Column_10": "",
          "Column_11": "\u0000\u0019",
          "Column_12": "\u0000",
          "Column_13": "",
          "Column_14": "\u0000\u0019",
          "Column_15": "\u0000\u001b",
          "Column_16": "",
          "Column_17": "\u0000\u0019",
          "Column_18": "\u0000",
          "\u0000)\u0000H\u0000P\u0000D\u0000O\u0000H": ""
        }
      ],
      "page": 25
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "",
          "Column_2": "\u0000\u0016",
          "Column_3": "",
          "Column_4": "",
          "\u0000\u0014": "",
          "\u0000\u0015\n\u0000\u0017": "",
          "Column_7": "",
          "\u0000\u0019": "\u0000\u001a",
          "Column_10": "",
          "\u0000\u0013\n\u0000\u001a": "",
          "Column_13": "",
          "\u0000\u001b\n\u0000\u0018": "",
          "Column_15": "",
          "Column_16": "",
          "Column_17": "",
          "\u0000\u001a\n\u0000\u0019": "",
          "\u00002\u0000W\u0000K\u0000H\u0000U\u0000V": "\u0000&\u0000K\u0000L\u0000Q\u0000H\u0000V\u0000H\n\u00000\u0000D\u0000O\u0000D\u0000\\",
          "Column_20": ""
        },
        {
          "Column_1": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "\u0000\u0014": "\u0000",
          "\u0000\u0015\n\u0000\u0017": "\u0000\u0019",
          "Column_7": "",
          "\u0000\u0019": "\u0000\u0013",
          "Column_10": "",
          "\u0000\u0013\n\u0000\u001a": "\u0000\u0018",
          "Column_13": "",
          "\u0000\u001b\n\u0000\u0018": "\u0000\u0014\u0000\u0013",
          "Column_15": "\u0000\u0014",
          "Column_16": "",
          "Column_17": "\u0000\u0014",
          "\u0000\u001a\n\u0000\u0019": "\u0000\u0013\u0000\u0016",
          "\u00002\u0000W\u0000K\u0000H\u0000U\u0000V": "\u0000,\u0000Q\u0000G\u0000L\u0000D\u0000Q",
          "Column_20": ""
        },
        {
          "Column_1": "",
          "Column_2": "\u0000\u0015",
          "Column_3": "",
          "Column_4": "",
          "\u0000\u0014": "",
          "\u0000\u0015\n\u0000\u0017": "\u0000\u001b",
          "Column_7": "",
          "\u0000\u0019": "\u0000\u001a",
          "Column_10": "",
          "\u0000\u0013\n\u0000\u001a": "\u0000\u001b",
          "Column_13": "",
          "\u0000\u001b\n\u0000\u0018": "\u0000\u0019",
          "Column_15": "",
          "Column_16": "",
          "Column_17": "",
          "\u0000\u001a\n\u0000\u0019": "\u0000\u0017",
          "\u00002\u0000W\u0000K\u0000H\u0000U\u0000V": "",
          "Column_20": ""
        }
      ],
      "page": 25
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "",
          "\u0000\u0014": "",
          "Column_3": "",
          "Column_4": "",
          "\u0000\u0015": "\u0000\u0015",
          "\u0000": "",
          "Column_7": "",
          "\u0000\u0016": "\u0000\u0019",
          "Column_10": "",
          "Column_13": "",
          "\u0000\u0018": "\u0000\u0018",
          "Column_16": "",
          "\u0000\u0017": "\u0000\u001a",
          "\u00002\u0000W\u0000K\u0000H\u0000U\u0000V": "",
          "Column_20": "\u0000+\u0000L\u0000J\u0000K\n\u00006\u0000F\u0000K\u0000\u0011\n\u00003\u0000R\u0000O\u0000\\\u0000\u0011",
          "Column_21": ""
        },
        {
          "Column_1": "",
          "\u0000\u0014": "\u0000\u0016",
          "Column_3": "",
          "Column_4": "",
          "\u0000\u0015": "",
          "\u0000": "\u0000\u0017",
          "Column_7": "",
          "\u0000\u0016": "",
          "Column_10": "",
          "Column_13": "",
          "\u0000\u0018": "",
          "Column_16": "",
          "\u0000\u0017": "",
          "\u00002\u0000W\u0000K\u0000H\u0000U\u0000V": "",
          "Column_20": "\u0000%\u0000D\u0000F\u0000K\u0000\u0011\n\u0000'\u0000H\u0000J\u0000\u0011",
          "Column_21": ""
        },
        {
          "Column_1": "",
          "\u0000\u0014": "",
          "Column_3": "",
          "Column_4": "",
          "\u0000\u0015": "\u0000\u0018",
          "\u0000": "\u0000\u0016",
          "Column_7": "",
          "\u0000\u0016": "\u0000\u001a",
          "Column_10": "",
          "Column_13": "",
          "\u0000\u0018": "\u0000\u001a",
          "Column_16": "",
          "\u0000\u0017": "\u0000\u0015",
          "\u00002\u0000W\u0000K\u0000H\u0000U\u0000V": "",
          "Column_20": "",
          "Column_21": ""
        },
        {
          "Column_1": "",
          "\u0000\u0014": "\u0000\u0014",
          "Column_3": "",
          "Column_4": "",
          "\u0000\u0015": "",
          "\u0000": "",
          "Column_7": "",
          "\u0000\u0016": "",
          "Column_10": "",
          "Column_13": "",
          "\u0000\u0018": "",
          "Column_16": "",
          "\u0000\u0017": "",
          "\u00002\u0000W\u0000K\u0000H\u0000U\u0000V": "",
          "Column_20": "",
          "Column_21": ""
        },
        {
          "Column_1": "",
          "\u0000\u0014": "",
          "Column_3": "",
          "Column_4": "",
          "\u0000\u0015": "\u0000\u0014",
          "\u0000": "\u0000\u0017",
          "Column_7": "",
          "\u0000\u0016": "\u0000\u0017",
          "Column_10": "",
          "Column_13": "",
          "\u0000\u0018": "\u0000\u0016",
          "Column_16": "",
          "\u0000\u0017": "\u0000\u001a",
          "\u00002\u0000W\u0000K\u0000H\u0000U\u0000V": "",
          "Column_20": "",
          "Column_21": ""
        }
      ],
      "page": 25
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "",
          "Column_2": "",
          "\u0000\u0014": "",
          "Column_4": "",
          "\u0000\u0016": "",
          "\u0000\u0015": "",
          "Column_7": "",
          "\u0000\u0018": "",
          "Column_10": "",
          "\u0000\u001b": "",
          "Column_13": "",
          "\u0000": "",
          "Column_16": "",
          "\u0000\u0019": "",
          "\u00002\u0000W\u0000K\u0000H\u0000U\u0000V": "\u00002\u0000W\u0000K\u0000H\u0000U\u0000V",
          "Column_20": ""
        },
        {
          "Column_1": "",
          "Column_2": "",
          "\u0000\u0014": "",
          "Column_4": "",
          "\u0000\u0016": "",
          "\u0000\u0015": "",
          "Column_7": "",
          "\u0000\u0018": "",
          "Column_10": "",
          "\u0000\u001b": "",
          "Column_13": "",
          "\u0000": "",
          "Column_16": "",
          "\u0000\u0019": "",
          "\u00002\u0000W\u0000K\u0000H\u0000U\u0000V": "\u00006\u0000W\u0000X\u0000G\u0000H\u0000Q\u0000W\n\u0000(\u0000P\u0000S\u0000O\u0000R\u0000\\\u0000\u0010",
          "Column_20": ""
        },
        {
          "Column_1": "",
          "Column_2": "",
          "\u0000\u0014": "\u0000",
          "Column_4": "",
          "\u0000\u0016": "",
          "\u0000\u0015": "\u0000",
          "Column_7": "",
          "\u0000\u0018": "\u0000\u0019",
          "Column_10": "",
          "\u0000\u001b": "\u0000\u0019",
          "Column_13": "",
          "\u0000": "\u0000\u0018",
          "Column_16": "",
          "\u0000\u0019": "\u0000\u0013",
          "\u00002\u0000W\u0000K\u0000H\u0000U\u0000V": "\u0000H\u0000G",
          "Column_20": ""
        },
        {
          "Column_1": "",
          "Column_2": "",
          "\u0000\u0014": "",
          "Column_4": "",
          "\u0000\u0016": "\u0000\u001b",
          "\u0000\u0015": "",
          "Column_7": "",
          "\u0000\u0018": "",
          "Column_10": "",
          "\u0000\u001b": "",
          "Column_13": "",
          "\u0000": "",
          "Column_16": "",
          "\u0000\u0019": "",
          "\u00002\u0000W\u0000K\u0000H\u0000U\u0000V": "",
          "Column_20": ""
        },
        {
          "Column_1": "",
          "Column_2": "",
          "\u0000\u0014": "",
          "Column_4": "",
          "\u0000\u0016": "",
          "\u0000\u0015": "",
          "Column_7": "",
          "\u0000\u0018": "\u0000",
          "Column_10": "",
          "\u0000\u001b": "\u0000\u0019",
          "Column_13": "",
          "\u0000": "",
          "Column_16": "",
          "\u0000\u0019": "\u0000\u0017",
          "\u00002\u0000W\u0000K\u0000H\u0000U\u0000V": "",
          "Column_20": ""
        }
      ],
      "page": 25
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "",
          "Column_2": "\u0000\u0017",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "\u0000\u001a",
          "Column_6": "\u0000\u0014",
          "Column_7": "",
          "Column_8": "\u0000\u001a",
          "Column_9": "\u0000\u0015",
          "Column_10": "",
          "Column_11": "\u0000\u001b",
          "Column_12": "\u0000\u0013",
          "Column_13": "",
          "Column_14": "\u0000\u001a",
          "Column_15": "\u0000\u001a",
          "Column_16": "",
          "Column_17": "\u0000\u001a",
          "Column_18": "\u0000\u0019",
          "\u00002\u0000W\u0000K\u0000H\u0000U\u0000V": "\u00001\u0000\u0011\u0000$\u0000\u0011\n\u0000%\u0000D\u0000F\u0000K\u0000\u0011",
          "Column_20": ""
        },
        {
          "Column_1": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "",
          "Column_10": "",
          "Column_11": "",
          "Column_12": "",
          "Column_13": "",
          "Column_14": "",
          "Column_15": "",
          "Column_16": "",
          "Column_17": "",
          "Column_18": "",
          "\u00002\u0000W\u0000K\u0000H\u0000U\u0000V": "\u0000'\u0000H\u0000J\u0000\u0011",
          "Column_20": ""
        },
        {
          "Column_1": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "\u0000\u0016",
          "Column_6": "\u0000\u001b",
          "Column_7": "",
          "Column_8": "\u0000\u0016",
          "Column_9": "\u0000\u0017",
          "Column_10": "",
          "Column_11": "\u0000\u0015",
          "Column_12": "\u0000\u0017",
          "Column_13": "",
          "Column_14": "",
          "Column_15": "",
          "Column_16": "",
          "Column_17": "\u0000\u0016",
          "Column_18": "\u0000\u0013",
          "\u00002\u0000W\u0000K\u0000H\u0000U\u0000V": "",
          "Column_20": ""
        },
        {
          "Column_1": "",
          "Column_2": "\u0000\u0014",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "\u0000\u0014",
          "Column_6": "\u0000\u0014",
          "Column_7": "",
          "Column_8": "\u0000\u0014",
          "Column_9": "\u0000\u0017",
          "Column_10": "",
          "Column_11": "\u0000\u0014",
          "Column_12": "\u0000\u0019",
          "Column_13": "",
          "Column_14": "\u0000\u0016\n\u0000\u001b",
          "Column_15": "\u0000\u0018",
          "Column_16": "",
          "Column_17": "\u0000\u0014",
          "Column_18": "\u0000\u0017",
          "\u00002\u0000W\u0000K\u0000H\u0000U\u0000V": "",
          "Column_20": ""
        }
      ],
      "page": 25
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "",
          "\u0000\u0014": "",
          "Column_3": "",
          "Column_4": "",
          "\u0000\u0018\n\u0000\u0015": "",
          "Column_7": "",
          "\u0000\u0016\n\u0000\u0019": "",
          "Column_10": "",
          "\u0000\u0016\n\u0000\u001b": "",
          "Column_13": "",
          "\u0000\u0017\n\u0000": "",
          "Column_16": "",
          "\u0000\u001b": "",
          "\u00003\u0000X\u0000E\u0000\u0011\u0000\u0003\u0000$\u0000S\u0000W\u0000\u0011": "\u00003\u0000X\u0000E\u0000\u0011\u0000\u0003\u0000$\u0000S\u0000W\u0000\u0011",
          "Column_20": ""
        },
        {
          "Column_1": "",
          "\u0000\u0014": "\u0000\u0015",
          "Column_3": "",
          "Column_4": "",
          "\u0000\u0018\n\u0000\u0015": "\u0000\u0016",
          "Column_7": "",
          "\u0000\u0016\n\u0000\u0019": "\u0000\u0015",
          "Column_10": "",
          "\u0000\u0016\n\u0000\u001b": "\u0000\u0014",
          "Column_13": "",
          "\u0000\u0017\n\u0000": "\u0000\u0017",
          "Column_16": "",
          "\u0000\u001b": "\u0000\u0018\n\u0000\u0017",
          "\u00003\u0000X\u0000E\u0000\u0011\u0000\u0003\u0000$\u0000S\u0000W\u0000\u0011": "\u0000'\u0000R\u0000U\u0000P\n\u00003\u0000U\u0000L\u0000Y\u0000\u0011\u0000\u0003\u00003\u0000W\u0000\\\u0000\u0011",
          "Column_20": ""
        },
        {
          "Column_1": "",
          "\u0000\u0014": "",
          "Column_3": "",
          "Column_4": "",
          "\u0000\u0018\n\u0000\u0015": "",
          "Column_7": "",
          "\u0000\u0016\n\u0000\u0019": "",
          "Column_10": "",
          "\u0000\u0016\n\u0000\u001b": "",
          "Column_13": "",
          "\u0000\u0017\n\u0000": "",
          "Column_16": "",
          "\u0000\u001b": "",
          "\u00003\u0000X\u0000E\u0000\u0011\u0000\u0003\u0000$\u0000S\u0000W\u0000\u0011": "\u00003\u0000U\u0000L\u0000Y\u0000\u0011\u0000\u0003\u0000$\u0000S\u0000W\u0000\u0011",
          "Column_20": ""
        },
        {
          "Column_1": "",
          "\u0000\u0014": "\u0000\u001a",
          "Column_3": "",
          "Column_4": "",
          "\u0000\u0018\n\u0000\u0015": "\u0000\u0013",
          "Column_7": "",
          "\u0000\u0016\n\u0000\u0019": "\u0000",
          "Column_10": "",
          "\u0000\u0016\n\u0000\u001b": "\u0000\u001b",
          "Column_13": "",
          "\u0000\u0017\n\u0000": "\u0000\u0016",
          "Column_16": "",
          "\u0000\u001b": "\u0000\u0016",
          "\u00003\u0000X\u0000E\u0000\u0011\u0000\u0003\u0000$\u0000S\u0000W\u0000\u0011": "",
          "Column_20": ""
        }
      ],
      "page": 25
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "",
          "Column_2": "",
          "\u0000\u0015": "\u0000",
          "Column_4": "",
          "\u0000\u0016\u0000\u0014": "\u0000\u001b\u0000",
          "Column_6": "",
          "\u0000\u0016": "\u0000",
          "\u0000\u001b": "\u0000\u0015",
          "Column_9": "",
          "Column_12": "",
          "\u0000\u0018": "\u0000\u0018",
          "Column_15": "",
          "\u0000\u0013": "\u0000\u0013",
          "\u0000<\u0000H\u0000V\n\u00001\u0000R": ""
        }
      ],
      "page": 25
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "",
          "Column_2": "",
          "\u0000\u0015": "\u0000",
          "Column_4": "",
          "\u0000\u0015\u0000\u001a": "\u0000\u001c\u0000\u0016",
          "Column_6": "",
          "\u0000": "\u0000\u0014",
          "Column_9": "",
          "\u0000\u0016": "\u0000\u001a",
          "\u0000\u0017": "\u0000\u0019",
          "Column_12": "",
          "Column_15": "",
          "\u0000\u0019": "\u0000\u0017",
          "\u0000\u0003\u0000\u0014\u0000\u0013\u0000\u0003\u0000\\\u0000U\u0000V\n\u0000\u001f\u0000\u0003\u0000\u0014\u0000\u0013\u0000\u0003\u0000\\\u0000U\u0000V": ""
        }
      ],
      "page": 25
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Ambient sound assessment of urban environments: Field studies in two French cities",
      "authors": [
        "M Raimbault",
        "C Lavandier",
        "M Bérengier"
      ],
      "year": "2003",
      "venue": "Applied Acoustics"
    },
    {
      "citation_id": "2",
      "title": "A framework for improving urban soundscapes",
      "authors": [
        "P Jennings",
        "R Cain"
      ],
      "year": "2013",
      "venue": "Applied Acoustics"
    },
    {
      "citation_id": "3",
      "title": "Noise pollution and annoyance: An urban soundscapes study",
      "authors": [
        "K De Paiva",
        "M Vianna",
        "R Alves Cardoso",
        "Rodrigues"
      ],
      "year": "2015",
      "venue": "Noise and Health"
    },
    {
      "citation_id": "4",
      "title": "Towards soundscape indices",
      "authors": [
        "J Kang"
      ],
      "year": "2019",
      "venue": "23rd International Congress on Acoustics"
    },
    {
      "citation_id": "5",
      "title": "Exposure-response relationships for transportation noise",
      "authors": [
        "H Miedema",
        "H Vos"
      ],
      "year": "1998",
      "venue": "The Journal of the Acoustical Society of America"
    },
    {
      "citation_id": "6",
      "title": "Models for soundscape perception and their use in planning",
      "authors": [
        "B Coensel",
        "D Botteldooren"
      ],
      "year": "2007",
      "venue": "Proceedings of Inter-Noise"
    },
    {
      "citation_id": "7",
      "title": "A field experiment on the impact of sounds from a jet-and-basin fountain on soundscape quality in an urban park",
      "authors": [
        "O Axelsson",
        "M Nilsson",
        "B Hellstr",
        "P Lundén"
      ],
      "year": "2014",
      "venue": "Landscape and Urban Planning"
    },
    {
      "citation_id": "8",
      "title": "Audio-visual preferences, perception, and use of water features in openplan offices",
      "authors": [
        "Z Abdalrahman",
        "L Galbrun"
      ],
      "year": "2020",
      "venue": "Journal of the Acoustical Society of America"
    },
    {
      "citation_id": "9",
      "title": "The effects of spatial separations on water sound and traffic noise sources on soundscape assessment",
      "authors": [
        "J Hong"
      ],
      "year": "2020",
      "venue": "Building and Environment"
    },
    {
      "citation_id": "10",
      "title": "Towards an urban vibrancy model: A soundscape approach",
      "authors": [
        "F Aletta",
        "J Kang"
      ],
      "year": "2018",
      "venue": "International Journal of Environmental Research and Public Health"
    },
    {
      "citation_id": "11",
      "title": "International Organization for Standardization, ISO 12913-3:2019 -Acoustics -Soundscape -Part 3: Data analysis",
      "venue": "International Organization for Standardization, ISO 12913-3:2019 -Acoustics -Soundscape -Part 3: Data analysis"
    },
    {
      "citation_id": "12",
      "title": "International Organization for Standardization",
      "authors": [
        "Switzerland Geneva"
      ],
      "year": "2019",
      "venue": "International Organization for Standardization"
    },
    {
      "citation_id": "13",
      "title": "Interactive soundscape augmentation by natural sounds in a noise polluted urban park",
      "authors": [
        "T Van Renterghem"
      ],
      "year": "2019",
      "venue": "Landscape and Urban Planning"
    },
    {
      "citation_id": "14",
      "title": "Deployment of an IoT System for Adaptive In-Situ Soundscape Augmentation",
      "authors": [
        "T Wong"
      ],
      "year": "2022",
      "venue": "Proceedings of Inter-Noise"
    },
    {
      "citation_id": "15",
      "title": "On the study of effects on different types of natural sounds on the perception of combined sound environment with road traffic noise",
      "authors": [
        "T Leung",
        "C Chau",
        "S Tang"
      ],
      "year": "2016",
      "venue": "Proceedings of Inter-Noise"
    },
    {
      "citation_id": "16",
      "title": "A mixed-reality approach to soundscape assessment of outdoor urban environments augmented with natural sounds",
      "authors": [
        "J Hong"
      ],
      "year": "2020",
      "venue": "Building and Environment"
    },
    {
      "citation_id": "17",
      "title": "Modeling soundscape pleasantness using perceptual assessments and acoustic measurements along paths in urban context",
      "authors": [
        "P Aumond",
        "A Can",
        "B Coensel",
        "D Botteldooren",
        "C Ribeiro",
        "C Lavandier"
      ],
      "year": "2017",
      "venue": "Acta Acustica united with Acustica"
    },
    {
      "citation_id": "18",
      "title": "Representation of the soundscape quality in urban areas through colours",
      "authors": [
        "V Puyana-Romero",
        "G Ciaburro",
        "G Brambilla",
        "C Garz Ón",
        "L Maffei"
      ],
      "year": "2019",
      "venue": "Noise Mapping"
    },
    {
      "citation_id": "19",
      "title": "Soundscape assessment: Towards a validated translation of perceptual attributes in different languages",
      "authors": [
        "F Aletta"
      ],
      "year": "2020",
      "venue": "Proceedings of Inter-Noise"
    },
    {
      "citation_id": "20",
      "title": "A systematic review of prediction models for the experience of urban soundscapes",
      "authors": [
        "M Lionello",
        "F Aletta",
        "J Kang"
      ],
      "year": "2020",
      "venue": "Applied Acoustics"
    },
    {
      "citation_id": "21",
      "title": "International Organization for Standardization, ISO 12913-2 Acoustics -Soundscape -Part 2: Data collection and reporting requirements",
      "year": "2018",
      "venue": "International Organization for Standardization, ISO 12913-2 Acoustics -Soundscape -Part 2: Data collection and reporting requirements"
    },
    {
      "citation_id": "22",
      "title": "Audio-visual scene classification: analysis of DCASE 2021 Challenge submissions",
      "authors": [
        "S Wang",
        "T Heittola",
        "A Mesaros",
        "T Virtanen"
      ],
      "year": "2021",
      "venue": "Proceedings of DCASE 2021 Workshop"
    },
    {
      "citation_id": "23",
      "title": "Low-complexity acoustic scene classification for multi-device audio: Analysis of DCASE 2021 challenge systems",
      "authors": [
        "I Martín-Morat Ó",
        "T Heittola",
        "A Mesaros",
        "T Virtanen"
      ],
      "year": "2021",
      "venue": "Proceedings of DCASE 2021 Workshop"
    },
    {
      "citation_id": "24",
      "title": "A Dataset of Dynamic Reverberant Sound Scenes with Directional Interferers for Sound Event Localization and Detection",
      "authors": [
        "A Politis",
        "S Adavanne",
        "D Krause",
        "A Deleforge",
        "P Srivastava",
        "T Virtanen"
      ],
      "year": "2021",
      "venue": "Proceedings of DCASE 2021 Workshop"
    },
    {
      "citation_id": "25",
      "title": "Description and Discussion on DCASE 2021 Challenge Task 2: Unsupervised Anomalous Sound Detection for Machine Condition Monitoring under Domain Shifted Conditions",
      "authors": [
        "Y Kawaguchi"
      ],
      "year": "2021",
      "venue": "Proceedings of DCASE 2021 Workshop"
    },
    {
      "citation_id": "26",
      "title": "Audio Set: An ontology and human-labeled dataset for audio events",
      "authors": [
        "J Gemmeke"
      ],
      "year": "2017",
      "venue": "Proceedings of IEEE ICASSP"
    },
    {
      "citation_id": "27",
      "title": "The benefit of temporally-strong labels in audio event classification",
      "authors": [
        "S Hershey"
      ],
      "year": "2021",
      "venue": "Proceedings of IEEE ICASSP 2021"
    },
    {
      "citation_id": "28",
      "title": "AudioSet: Temporally-Strong Labels Download",
      "year": "2021",
      "venue": "AudioSet: Temporally-Strong Labels Download"
    },
    {
      "citation_id": "29",
      "title": "CNN architectures for large-scale audio classification",
      "year": "2017",
      "venue": "Proceedings of IEEE ICASSP 2017"
    },
    {
      "citation_id": "30",
      "title": "A dataset and taxonomy for urban sound research",
      "authors": [
        "J Salamon",
        "C Jacoby",
        "J Bello"
      ],
      "year": "2014",
      "venue": "Proceedings of the 2014 ACM Multimedia Conference"
    },
    {
      "citation_id": "31",
      "title": "ESC: Dataset for environmental sound classification",
      "authors": [
        "K Piczak"
      ],
      "year": "2015",
      "venue": "Proceedings of the 2015 ACM Multimedia Conference"
    },
    {
      "citation_id": "32",
      "title": "FSD50K: An Open Dataset of Human-Labeled Sound Events",
      "authors": [
        "E Fonseca",
        "X Favory",
        "J Pons",
        "F Font",
        "X Serra"
      ],
      "year": "2022",
      "venue": "IEEE/ACM Transactions on Audio Speech and Language Processing"
    },
    {
      "citation_id": "33",
      "title": "Freesound Technical Demo",
      "authors": [
        "F Font",
        "G Roma",
        "X Serra"
      ],
      "year": "2013",
      "venue": "Proceedings of the 2013 ACM Multimedia Conference"
    },
    {
      "citation_id": "34",
      "title": "Scaper: a library for soundscape synthesis and augmentation",
      "authors": [
        "J Salamon",
        "D Macconnell",
        "M Cartwright",
        "P Li",
        "J Bello"
      ],
      "year": "2017",
      "venue": "Scaper: a library for soundscape synthesis and augmentation"
    },
    {
      "citation_id": "35",
      "title": "Urban Soundscapes of the World: Selection and reproduction of urban acoustic environments with soundscape in mind",
      "authors": [
        "B Coensel",
        "K Sun",
        "D Botteldooren"
      ],
      "year": "2017",
      "venue": "Proceedings of Inter-Noise"
    },
    {
      "citation_id": "36",
      "title": "EigenScape: A Database of Spatial Acoustic Scene Recordings",
      "authors": [
        "M Ciufo",
        "D Thomas"
      ],
      "year": "2017",
      "venue": "Applied Sciences"
    },
    {
      "citation_id": "37",
      "title": "SONYC Urban Sound Tagging (SONYC-UST): A Multilabel Dataset from an Urban Acoustic Sensor Network",
      "authors": [
        "M Cartwright"
      ],
      "year": "2019",
      "venue": "Proceedings of DCASE 2019 Workshop"
    },
    {
      "citation_id": "38",
      "title": "SONYC-UST-V2: An Urban Sound Tagging Dataset with Spatiotemporal Context",
      "year": "2020",
      "venue": "Proceedings of DCASE 2020 Workshop"
    },
    {
      "citation_id": "39",
      "title": "TUT database for acoustic scene classification and sound event detection",
      "authors": [
        "A Mesaros",
        "T Heittola",
        "T Virtanen"
      ],
      "year": "2016",
      "venue": "Proceedings of EUSIPCO 2016"
    },
    {
      "citation_id": "40",
      "title": "DCASE 2017 challenge setup: tasks, datasets and baseline system",
      "authors": [
        "A Mesaros"
      ],
      "year": "2017",
      "venue": "Proceedings of DCASE 2017 Workshop"
    },
    {
      "citation_id": "41",
      "title": "A multidevice dataset for urban acoustic scene classification",
      "authors": [
        "A Mesaros",
        "T Heittola",
        "T Virtanen"
      ],
      "year": "2018",
      "venue": "Proceedings of DCASE 2018 Workshop"
    },
    {
      "citation_id": "42",
      "title": "Acoustic scene classification in DCASE 2020 Challenge: generalization across devices and low complexity solutions",
      "authors": [
        "T Heittola",
        "A Mesaros",
        "T Virtanen"
      ],
      "year": "2020",
      "venue": "Proceedings of DCASE 2020 Workshop"
    },
    {
      "citation_id": "43",
      "title": "A curated dataset of urban scenes for audio-visual scene analysis",
      "authors": [
        "S Wang",
        "A Mesaros",
        "T Heittola",
        "T Virtanen"
      ],
      "year": "2021",
      "venue": "Proceedings of IEEE ICASSP 2021"
    },
    {
      "citation_id": "44",
      "title": "A Strongly-Labelled Polyphonic Dataset of Urban Sounds with Spatiotemporal Context",
      "authors": [
        "K Ooi"
      ],
      "year": "2021",
      "venue": "Proceedings of APSIPA ASC 2021"
    },
    {
      "citation_id": "45",
      "title": "The Ambisonic Recordings of Typical Environments (ARTE) database",
      "authors": [
        "A Weisser"
      ],
      "year": "2019",
      "venue": "Acta Acustica united with Acustica"
    },
    {
      "citation_id": "46",
      "title": "STARSS22: A dataset of spatial recordings of real scenes with spatiotemporal annotations of sound events",
      "authors": [
        "A Politis"
      ],
      "year": "2022",
      "venue": "STARSS22: A dataset of spatial recordings of real scenes with spatiotemporal annotations of sound events",
      "doi": "10.5281/zenodo.6387880"
    },
    {
      "citation_id": "47",
      "title": "Affective ratings of sounds and instruction manual",
      "authors": [
        "M Bradley",
        "P Lang"
      ],
      "year": "2007",
      "venue": "Affective ratings of sounds and instruction manual"
    },
    {
      "citation_id": "48",
      "title": "Affective auditory stimuli: Characterization of the International Affective Digitized Sounds (IADS) by discrete emotional categories",
      "authors": [
        "R Stevenson",
        "T James"
      ],
      "year": "2008",
      "venue": "Behavior Research Methods"
    },
    {
      "citation_id": "49",
      "title": "Affective auditory stimulus database: An expanded version of the International Affective Digitized Sounds (IADS-E)",
      "authors": [
        "W Yang"
      ],
      "year": "2018",
      "venue": "Behavior Research Methods"
    },
    {
      "citation_id": "50",
      "title": "Emosoundscapes: A dataset for soundscape emotion recognition",
      "authors": [
        "J Fan",
        "M Thorogood",
        "P Pasquier"
      ],
      "year": "2017",
      "venue": "Proceedings of ACII 2017"
    },
    {
      "citation_id": "51",
      "title": "Measuring emotion: The self-assessment manikin and the semantic dif-ferential",
      "authors": [
        "M Bradley",
        "P Lang"
      ],
      "year": "1994",
      "venue": "Journal of Behavior Therapy and Experimental Psychiatry"
    },
    {
      "citation_id": "52",
      "title": "Athens Urban Soundscape (ATHUS): A Dataset for Urban Soundscape Quality Recognition",
      "authors": [
        "T Giannakopoulos",
        "M Orfanidi",
        "S Perantonis"
      ],
      "year": "2019",
      "venue": "Proceedings of 25th International Conference on Multimedia Modeling"
    },
    {
      "citation_id": "53",
      "title": "The International Soundscape Database: An integrated multimedia database of urban soundscape surveys -questionnaires with acoustical and contextual information",
      "authors": [
        "A Mitchell"
      ],
      "year": "2021",
      "venue": "The International Soundscape Database: An integrated multimedia database of urban soundscape surveys -questionnaires with acoustical and contextual information",
      "doi": "10.5281/Zenodo.5914762"
    },
    {
      "citation_id": "54",
      "title": "The Soundscape Indices (SSID) Protocol : A Method for Urban Soundscape Surveys -Questionnaires with Acoustical and Contextual Information",
      "year": "2020",
      "venue": "Applied Sciences"
    },
    {
      "citation_id": "55",
      "title": "Assessment of the masking effects of birdsong on the road traffic noise environment",
      "authors": [
        "Y Hao",
        "J Kang",
        "H Wortche"
      ],
      "year": "2016",
      "venue": "Journal of the Acoustical Society of America"
    },
    {
      "citation_id": "56",
      "title": "Developing a multivariate model for predicting the noise annoyance responses due to combined water sound and road traffic noise exposure",
      "authors": [
        "T Leung",
        "C Chau",
        "S Tang",
        "J Xu"
      ],
      "year": "2017",
      "venue": "Applied Acoustics"
    },
    {
      "citation_id": "57",
      "title": "Assessing the changing urban sound environment during the COVID-19 lockdown period using short-term acoustic measurements",
      "authors": [
        "F Aletta",
        "T Oberman",
        "A Mitchell",
        "H Tong",
        "J Kang"
      ],
      "year": "2020",
      "venue": "Noise Mapping"
    },
    {
      "citation_id": "58",
      "title": "What is the risk of noise-induced hearing loss at 80, 85, 90 dB(A) and above?",
      "authors": [
        "M Lutman"
      ],
      "year": "2000",
      "venue": "Occupational Medicine"
    },
    {
      "citation_id": "59",
      "title": "Xeno-canto: a 21st century way to appreciate Neotropical bird song",
      "authors": [
        "B Planqué",
        "W.-P Vellinga"
      ],
      "year": "2008",
      "venue": "Neotropical Birding"
    },
    {
      "citation_id": "60",
      "title": "Acoustical characteristics of water sounds for soundscape enhancement in urban open spaces",
      "authors": [
        "J Jeon",
        "P Lee",
        "J You",
        "J Kang"
      ],
      "year": "2012",
      "venue": "Journal of the Acoustical Society of America"
    },
    {
      "citation_id": "61",
      "title": "Acoustical and perceptual assessment of water sounds and their use over road traffic noise",
      "authors": [
        "L Galbrun",
        "T Ali"
      ],
      "year": "2013",
      "venue": "Journal of the Acoustical Society of America"
    },
    {
      "citation_id": "62",
      "title": "Effects of natural sounds on the perception of road traffic noise",
      "authors": [
        "B Coensel",
        "S Vanwetswinkel",
        "D Botteldooren"
      ],
      "year": "2011",
      "venue": "JASA Express Letters"
    },
    {
      "citation_id": "63",
      "title": "The phantom chorus: birdsong boosts human well-being in protected areas",
      "authors": [
        "D Ferraro"
      ],
      "year": "1941",
      "venue": "Proceedings of the Royal Society B"
    },
    {
      "citation_id": "64",
      "title": "Evaluation of natural sounds in urban greenery: Potential impact for urban nature preservation",
      "authors": [
        "M Hedblom",
        "I Knez",
        "Ode Sang",
        "B Gunnarsson"
      ],
      "year": "2017",
      "venue": "Royal Society Open Science"
    },
    {
      "citation_id": "65",
      "title": "World Health Organization Regional Office for Europe, Environmental Noise Guidelines for the European Region. Copenhagen: The Regional Office for Europe of the World Health Organization",
      "year": "2018",
      "venue": "World Health Organization Regional Office for Europe, Environmental Noise Guidelines for the European Region. Copenhagen: The Regional Office for Europe of the World Health Organization"
    },
    {
      "citation_id": "66",
      "title": "Sound-masking technique for combined noise exposure in open public spaces",
      "authors": [
        "J You",
        "J Jeon"
      ],
      "year": "2008",
      "venue": "Proceedings of ICBEN 2008"
    },
    {
      "citation_id": "67",
      "title": "Application of a recently introduced index for acoustic complexity to an avian soundscape with traffic noise",
      "authors": [
        "N Pieretti",
        "A Farina"
      ],
      "year": "2013",
      "venue": "Journal of the Acoustical Society of America"
    },
    {
      "citation_id": "68",
      "title": "Spatial variations in pedestrian soundscape evaluation of traffic noise",
      "authors": [
        "X Lu",
        "J Tang",
        "P Zhu",
        "F Guo",
        "J Cai",
        "H Zhang"
      ],
      "year": "2020",
      "venue": "Environmental Impact Assessment Review"
    },
    {
      "citation_id": "69",
      "title": "Soundscape evaluation: Binaural or monaural?",
      "authors": [
        "C Xu",
        "J Kang"
      ],
      "year": "2019",
      "venue": "Journal of the Acoustical Society of America"
    },
    {
      "citation_id": "70",
      "title": "A Review of the Use of Psychoacoustic Indicators on Soundscape Studies",
      "authors": [
        "M Engel",
        "A Fiebig",
        "C Pfaffenbach",
        "J Fels"
      ],
      "year": "2021",
      "venue": "Current Pollution Reports"
    },
    {
      "citation_id": "71",
      "title": "Effects of adding natural sounds to urban noises on the perceived loudness of noise and soundscape quality",
      "authors": [
        "J Hong"
      ],
      "year": "2020",
      "venue": "Science of the Total Environment"
    },
    {
      "citation_id": "72",
      "title": "Measurement technique for the simulation of the auditory sensation of sharpness",
      "year": "2009",
      "venue": "Measurement technique for the simulation of the auditory sensation of sharpness"
    },
    {
      "citation_id": "73",
      "title": "International Organization for Standardization, ISO 532-1: Acoustics -Methods for calculating loudness -Part 1: Zwicker method",
      "year": "2014",
      "venue": "International Organization for Standardization, ISO 532-1: Acoustics -Methods for calculating loudness -Part 1: Zwicker method"
    },
    {
      "citation_id": "74",
      "title": "Psychoacoustics -Facts and Models",
      "authors": [
        "H Fastl",
        "E Zwicker"
      ],
      "year": "2001",
      "venue": "Psychoacoustics -Facts and Models"
    },
    {
      "citation_id": "75",
      "title": "ECMA-418-2:2020 -Psychoacoustic metrics for ITT equipment -Part 2 (models based on human perception",
      "year": "2020",
      "venue": "ECMA-418-2:2020 -Psychoacoustic metrics for ITT equipment -Part 2 (models based on human perception"
    },
    {
      "citation_id": "76",
      "title": "ECMA-74 -Acoustics -Measurement of airborne noise emitted by information technology and telecommunications equipment",
      "year": "2021",
      "venue": "ECMA-74 -Acoustics -Measurement of airborne noise emitted by information technology and telecommunications equipment"
    },
    {
      "citation_id": "77",
      "title": "International Organization for Standardization, ISO 1996-1:2016 Acoustics -Description , measurement and assessment of environmental noise -Part 1: Basic quantities and assessment procedures",
      "year": "2016",
      "venue": "International Organization for Standardization, ISO 1996-1:2016 Acoustics -Description , measurement and assessment of environmental noise -Part 1: Basic quantities and assessment procedures"
    },
    {
      "citation_id": "78",
      "title": "MOSQITO: An open-source and free toolbox for sound quality metrics in the industry and education",
      "authors": [
        "R San Millán-Castillo",
        "E Latorre-Iglesias",
        "D Jiménez-Caminero",
        "J Álvarez-Jimeno",
        "M Glesser",
        "S Wanty"
      ],
      "year": "2021",
      "venue": "Proceedings of Inter-Noise"
    },
    {
      "citation_id": "79",
      "title": "Looking for the -scape in the sound: Discriminating soundscapes categories in the Sonoran Desert using indices and clustering",
      "authors": [
        "C Flowers",
        "F Le Tourneau",
        "N Merchant",
        "B Heidorn",
        "R Ferriere",
        "J Harwood"
      ],
      "year": "2021",
      "venue": "Ecological Indicators"
    },
    {
      "citation_id": "80",
      "title": "Self-organizing maps",
      "authors": [
        "T Kohonen"
      ],
      "year": "2001",
      "venue": "Self-organizing maps"
    },
    {
      "citation_id": "81",
      "title": "Automation of binaural headphone audio calibration on an artificial head",
      "authors": [
        "K Ooi",
        "Y Xie",
        "B Lam",
        "W Gan"
      ],
      "year": "2021",
      "venue": "MethodsX"
    },
    {
      "citation_id": "82",
      "title": "USM-SED -A Dataset for Polyphonic Sound Event Detection in Urban Sound Monitoring Scenarios",
      "authors": [
        "J Abeßer"
      ],
      "year": "2021",
      "venue": "USM-SED -A Dataset for Polyphonic Sound Event Detection in Urban Sound Monitoring Scenarios"
    },
    {
      "citation_id": "83",
      "title": "Audiometry screening and interpretation",
      "authors": [
        "J Walker",
        "L Cleveland",
        "J Davis",
        "J Seales"
      ],
      "year": "2013",
      "venue": "American Family Physician"
    },
    {
      "citation_id": "84",
      "title": "Using Virtual Reality for assessing the role of noise in the audio-visual design of an urban public space",
      "authors": [
        "G Echevarria Sanchez",
        "T Van Renterghem",
        "K Sun",
        "B Coensel",
        "D Botteldooren"
      ],
      "year": "2017",
      "venue": "Landscape and Urban Planning"
    },
    {
      "citation_id": "85",
      "title": "Extended high-frequency audiometry in healthy adults with different age groups",
      "authors": [
        "M Wang",
        "Y Ai",
        "Y Han",
        "Z Fan",
        "P Shi",
        "H Wang"
      ],
      "year": "2021",
      "venue": "Journal of Otolaryngology -Head and Neck Surgery"
    },
    {
      "citation_id": "86",
      "title": "Investigating urban soundscapes of the COVID-19 lockdown: A predictive soundscape modeling approach",
      "authors": [
        "M Andrew",
        "T Oberman",
        "F Aletta",
        "M Kachlicka",
        "M Lionello",
        "M Erfanian",
        "J Kang"
      ],
      "year": "2021",
      "venue": "Investigating urban soundscapes of the COVID-19 lockdown: A predictive soundscape modeling approach"
    },
    {
      "citation_id": "87",
      "title": "International Organization for Standardization, ISO 12913-1:2014 -Acoustics -Soundscape -Part 1: Definition and conceptual framework",
      "year": "2014",
      "venue": "International Organization for Standardization, ISO 12913-1:2014 -Acoustics -Soundscape -Part 1: Definition and conceptual framework"
    },
    {
      "citation_id": "88",
      "title": "Individual differences in reactions to noise: A longitudinal study in a college dormitory",
      "authors": [
        "N Weinstein"
      ],
      "year": "1978",
      "venue": "of Applied Psychology"
    },
    {
      "citation_id": "89",
      "title": "A Global Measure of Perceived Stress",
      "authors": [
        "S Cohen",
        "T Kamarck",
        "R Mermelstein"
      ],
      "year": "1983",
      "venue": "Journal of Health and Social Behavior"
    },
    {
      "citation_id": "90",
      "title": "Wellbeing measures in primary health care",
      "year": "1998",
      "venue": "Wellbeing measures in primary health care"
    },
    {
      "citation_id": "91",
      "title": "Development and Validation of Brief Measures of Positive and Negative Affect: The PANAS Scales",
      "authors": [
        "D Watson",
        "L Clark",
        "A Tellegan"
      ],
      "year": "1988",
      "venue": "Journal of Personality and Social Psychology"
    },
    {
      "citation_id": "92",
      "title": "The relationship between noise sensitivity and soundscape appraisal of care professionals in their work environment: a case study in Nursing Homes in Flanders, Belgium",
      "authors": [
        "F Aletta"
      ],
      "year": "2018",
      "venue": "Proceedings of Euro-Noise"
    },
    {
      "citation_id": "93",
      "title": "Sound and Soundscape in Restorative Natural Environments: A Narrative Literature Review",
      "authors": [
        "E Ratcliffe"
      ],
      "year": "2021",
      "venue": "Frontiers in Psychology"
    },
    {
      "citation_id": "94",
      "title": "A questionnaire investigating the emotional salience of sounds",
      "authors": [
        "M Masullo"
      ],
      "year": "2021",
      "venue": "Applied Acoustics"
    },
    {
      "citation_id": "95",
      "title": "Perceived stress in a probability sample of the United States",
      "authors": [
        "S Cohen",
        "G Williamson"
      ],
      "year": "1988",
      "venue": "The Social Psychology of Health"
    },
    {
      "citation_id": "96",
      "title": "How to analyse and represent quantitative soundscape data",
      "authors": [
        "A Mitchell",
        "F Aletta",
        "J Kang"
      ],
      "year": "2022",
      "venue": "JASA Express Letters"
    },
    {
      "citation_id": "97",
      "title": "A systematic review on environmental noise and annoyance",
      "authors": [
        "R Guski",
        "D Schreckenberg",
        "R Schuemer"
      ],
      "year": "2017",
      "venue": "International Journal of Environmental Research and Public Health"
    },
    {
      "citation_id": "98",
      "title": "Noise and the city: Leveraging crowdsourced big data to examine the spatio-temporal relationship between urban development and noise annoyance",
      "authors": [
        "A Hong",
        "B Kim",
        "M Widener"
      ],
      "year": "2020",
      "venue": "Environment and Planning B: Urban Analytics and City Science"
    },
    {
      "citation_id": "99",
      "title": "Effect of a row of trees behind noise barriers in wind",
      "authors": [
        "T Van Renterghem",
        "D Botteldooren"
      ],
      "year": "2002",
      "venue": "Acta Acustica united with Acustica"
    },
    {
      "citation_id": "100",
      "title": "Acoustic comfort evaluation in urban open public spaces",
      "authors": [
        "W Yang",
        "J Kang"
      ],
      "year": "2005",
      "venue": "Applied Acoustics"
    },
    {
      "citation_id": "101",
      "title": "Soundscape Perceptions and Preferences for Different Groups of Users in Urban Recreational Forest Parks",
      "authors": [
        "X Fang"
      ],
      "year": "2021",
      "venue": "Forests"
    },
    {
      "citation_id": "102",
      "title": "Coefficient alpha and the internal structure of tests",
      "authors": [
        "L Cronbach"
      ],
      "year": "1951",
      "venue": "Psychometrika"
    },
    {
      "citation_id": "103",
      "title": "Test Theory: A Unified Treatment. Mahwah",
      "authors": [
        "R Mcdonald"
      ],
      "year": "1999",
      "venue": "Test Theory: A Unified Treatment. Mahwah"
    },
    {
      "citation_id": "104",
      "title": "The Use of Cronbach's Alpha When Developing and Reporting Research Instruments in Science Education",
      "authors": [
        "K Taber"
      ],
      "year": "2018",
      "venue": "Research in Science Education"
    },
    {
      "citation_id": "105",
      "title": "Weinstein Noise Sensitivity Scale (WNSS)",
      "authors": [
        "D Worthington"
      ],
      "year": "2018",
      "venue": "The Sourcebook of Listening Research: Methodology and"
    },
    {
      "citation_id": "106",
      "title": "Probably Pleasant? A Neural-Probabilistic Approach to Automatic Masker Selection for Urban Soundscape Augmentation",
      "authors": [
        "K Ooi",
        "K Watcharasupat",
        "B Lam",
        "Z.-T Ong",
        "W.-S Gan"
      ],
      "year": "2022",
      "venue": "Proceedings of IEEE ICASSP 2022"
    },
    {
      "citation_id": "107",
      "title": "Autonomous In-Situ Soundscape Augmentation via Joint Selection of Masker and Gain",
      "authors": [
        "K Watcharasupat",
        "K Ooi",
        "B Lam",
        "T Wong",
        "Z.-T Ong",
        "W.-S Gan"
      ],
      "year": "2022",
      "venue": "Autonomous In-Situ Soundscape Augmentation via Joint Selection of Masker and Gain"
    },
    {
      "citation_id": "108",
      "title": "Regularization and variable selection via the elastic net",
      "authors": [
        "H Zou",
        "T Hastie"
      ],
      "year": "2005",
      "venue": "Journal of the Royal Statistical Society. Series B: Statistical Methodology"
    },
    {
      "citation_id": "109",
      "title": "Adam: A method for stochastic optimization",
      "authors": [
        "D Kingma",
        "J Ba"
      ],
      "year": "2015",
      "venue": "Proceedings of ICLR 2015"
    },
    {
      "citation_id": "110",
      "title": "Effects of environmental sound quality on soundscape preference in a public urban space",
      "authors": [
        "K Ma",
        "C Mak",
        "H Wong"
      ],
      "year": "2021",
      "venue": "Applied Acoustics"
    },
    {
      "citation_id": "111",
      "title": "The perceptual dimensionality of environmental sounds",
      "authors": [
        "G Kidd",
        "C Watson"
      ],
      "year": "2003",
      "venue": "Noise Control Engineering Journal"
    },
    {
      "citation_id": "112",
      "title": "Y/N] If your response is",
      "venue": "Y/N] If your response is"
    },
    {
      "citation_id": "113",
      "title": "Among the languages/dialects you speak",
      "venue": "Among the languages/dialects you speak"
    },
    {
      "citation_id": "114",
      "title": "",
      "authors": [
        "Male"
      ],
      "venue": ""
    },
    {
      "citation_id": "115",
      "title": "",
      "authors": [
        "Chinese"
      ],
      "venue": ""
    },
    {
      "citation_id": "116",
      "title": "",
      "authors": [
        "Malay"
      ],
      "venue": ""
    },
    {
      "citation_id": "117",
      "title": "No qualification",
      "venue": "No qualification"
    },
    {
      "citation_id": "118",
      "title": "Primary (PSLE), elementary school or equivalent",
      "venue": "Primary (PSLE), elementary school or equivalent"
    },
    {
      "citation_id": "119",
      "title": "GCE 'N' & 'O' level), middle school or equivalent",
      "authors": [
        "Secondary"
      ],
      "venue": "GCE 'N' & 'O' level), middle school or equivalent"
    },
    {
      "citation_id": "120",
      "title": "Junior College ('A' level), high school or equivalent",
      "venue": "Junior College ('A' level), high school or equivalent"
    },
    {
      "citation_id": "121",
      "title": "Polytechnic and Arts Institution (Diploma level)",
      "venue": "Polytechnic and Arts Institution (Diploma level)"
    },
    {
      "citation_id": "122",
      "title": "University (Bachelor's Degree)",
      "venue": "University (Bachelor's Degree)"
    },
    {
      "citation_id": "123",
      "title": "University (Master's Degree)",
      "venue": "University (Master's Degree)"
    },
    {
      "citation_id": "124",
      "title": "What is your occupational status?",
      "venue": "What is your occupational status?"
    },
    {
      "citation_id": "125",
      "title": "Unemployed If your response is \"Student",
      "venue": "Unemployed If your response is \"Student"
    },
    {
      "citation_id": "126",
      "title": "What is the highest level of education you are currently undergoing?",
      "venue": "What is the highest level of education you are currently undergoing?"
    },
    {
      "citation_id": "127",
      "title": "Other [2] Primary (PSLE), elementary school or equivalent",
      "venue": "Other [2] Primary (PSLE), elementary school or equivalent"
    },
    {
      "citation_id": "128",
      "title": "GCE 'N' & 'O' level), middle school or equivalent",
      "authors": [
        "Secondary"
      ],
      "venue": "GCE 'N' & 'O' level), middle school or equivalent"
    },
    {
      "citation_id": "129",
      "title": "Junior College ('A' level), high school or equivalent",
      "venue": "Junior College ('A' level), high school or equivalent"
    },
    {
      "citation_id": "130",
      "title": "Polytechnic and Arts Institution (Diploma level)",
      "venue": "Polytechnic and Arts Institution (Diploma level)"
    },
    {
      "citation_id": "131",
      "title": "University (Bachelor's Degree)",
      "venue": "University (Bachelor's Degree)"
    },
    {
      "citation_id": "132",
      "title": "University (Master's Degree)",
      "venue": "University (Master's Degree)"
    },
    {
      "citation_id": "133",
      "title": "Housing Development Board (HDB) flat or other public apartment",
      "venue": "Housing Development Board (HDB) flat or other public apartment"
    },
    {
      "citation_id": "134",
      "title": "Hall of Residence or other student dormitory",
      "venue": "Hall of Residence or other student dormitory"
    },
    {
      "citation_id": "135",
      "title": "Landed property",
      "venue": "Landed property"
    },
    {
      "citation_id": "136",
      "title": "Due to the risk of identification considering a very small number of participants chose this option, where participants responded \"Other/prefer not to say",
      "venue": "Due to the risk of identification considering a very small number of participants chose this option, where participants responded \"Other/prefer not to say"
    },
    {
      "citation_id": "137",
      "title": "Well Being Index: For each of the statements below",
      "venue": "Well Being Index: For each of the statements below"
    },
    {
      "citation_id": "138",
      "title": "Less than half of the time",
      "venue": "Less than half of the time"
    },
    {
      "citation_id": "139",
      "title": "I have felt cheerful and in good spirits",
      "venue": "I have felt cheerful and in good spirits"
    },
    {
      "citation_id": "140",
      "title": "I have felt calm and relaxed",
      "venue": "I have felt calm and relaxed"
    },
    {
      "citation_id": "141",
      "title": "I have felt active and vigorous",
      "venue": "I have felt active and vigorous"
    },
    {
      "citation_id": "142",
      "title": "I woke up feeling fresh and rested",
      "venue": "I woke up feeling fresh and rested"
    },
    {
      "citation_id": "143",
      "title": "Positive and Negative Affect Schedule c : In the last two weeks",
      "venue": "Positive and Negative Affect Schedule c : In the last two weeks"
    },
    {
      "citation_id": "144",
      "title": "",
      "authors": [
        "Moderately"
      ],
      "venue": ""
    },
    {
      "citation_id": "145",
      "title": "Quite a bit",
      "venue": "Quite a bit"
    },
    {
      "citation_id": "146",
      "title": "",
      "authors": [
        "Extremely"
      ],
      "venue": ""
    }
  ]
}