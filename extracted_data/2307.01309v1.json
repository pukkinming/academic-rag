{
  "paper_id": "2307.01309v1",
  "title": "Social Impressions Of The Nao Robot And Its Impact On Physiology",
  "published": "2023-07-03T19:26:18Z",
  "authors": [
    "Ruchik Mishra",
    "Karla Conn Welch"
  ],
  "keywords": [
    "social impressions",
    "NAO robot",
    "classification",
    "CNN",
    "Gramian Angular Field",
    "physiological signal processing"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "The social applications of robots possess intrinsic challenges with respect to social paradigms and heterogeneity of different groups. These challenges can be in the form of social acceptability, anthropomorphism, likeability, past experiences with robots etc. In this paper, we have considered a group of neurotypical adults to describe how different voices and motion types of the NAO robot can have effect on the perceived safety, anthropomorphism, likeability, animacy, and perceived intelligence of the robot. In addition, prior robot experience has also been taken into consideration to perform this analysis using a one-way Analysis of Variance (ANOVA). Further, we also demonstrate that these different modalities instigate different physiological responses in the person. This classification has been done using two different deep learning approaches, 1) Convolutional Neural Network (CNN), and 2) Gramian Angular Fields on the Blood Volume Pulse (BVP) data recorded. Both of these approaches achieve better than chance accuracy (>25%) for a 4 class classification.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "I. Introduction",
      "text": "Autism Spectrum Disorder (ASD), as an umbrella term, has been associated with challenges in social communication and interaction along with restrictive and repetitive behaviors according to the Diagnostic Statistical Manual  [3] . The world ASD population is around 1.5 percent  [35] , with 1 out of 54 children being diagnosed in the United States alone  [2] ,  [4] . More recently, this number has increased by 104%  [29] . Since, there is no cure for autism  [7] ,  [29] , there exist numerous treatments/interventions, as presented by the authors in  [12] ,  [28] , not all of which are scientifically proven to have positive results  [18] ,  [20] ,  [31] .\n\nTo mitigate the scientific shortcomings of some of these studies, Evidence Based Practices (EBP) have presented numerous interventions that have been chosen as a result of positive scientific evidence  [33] . Among them, Technology-Aided Instruction and Intervention (TAII) has been on the rise since a few decades now as is evident from the works of  [9] ,  [10] ,  [30] ,  [40] , some of which have also been used to form the guidelines for EBP like  [13] ,  [32] . Apart from following the EBP, it is also essential to take into account the acceptability of the robot in a therapeutic scenario that involves a human-robot interaction (HRI). Due to the heterogeneity Fig.  1 : Social impressions of the NAO robot during HRI and its impact on physiology. Statistical Inference Block evaluates the importance of different modalities of the robot with respect to perceived features (pf). The Deep Learning block presents a time series classification approach to differentiate between the difference in physiology during different conditions A-D.\n\nof the ASD population, these responses can vary based on the individual  [37] . In addition to considering the social acceptability of the robot, factors such as repeated exposure to a robot  [27] , features of robots to be considered in therapy  [19] , anthropomorphic appearance and intonation  [38]  etc. have also been studied. The reason for these studies can be attributed to the fact that these interventions are directed towards bringing about positive effects in the individual with ASD.\n\nAnother aspect that can be associated with social acceptability of the robot during therapy is the uncanny valley, as has been studied by the authors in  [36] . Since the human-arXiv:2307.01309v1 [cs.RO] 3 Jul 2023 Figure  2a  shows the model input of the raw signals. Figure  2b  shows the use of Gramian Angular Fields with the CNN model. like traits of a robot can stir discomfort in people surrounding it; this phenomena, introduced in  [24] , has been explored using different modalities of HRI  [22] . Since the effect of the uncanny valley has been shown to be more profound on the ASD population than on neurotypicals  [11] , it becomes imperative to validate individual communication modality in a robotic intervention to be analyzed on the neurotypical population first. Since the uncanny valley is associated with the features of the robots in terms of the appearance and its anthropomorphic appeal, it can have an effect on the affective states of the individual  [38] .\n\nIn this work, we have presented a one-to-one HRI as shown in Figure  1  with neurotypical adults. We start with the use of the humanoid NAO robot for a neurotypical population with four different conditions (A-D) (see Section II-B for more details). The participants' prior experience with robots has also been considered in this study. We have analysed the response of the participants on five pf of the robot namely, perceived safety, anthropomorphism, likeability, animacy, and perceived intelligence. We have analysed if the different conditions (A-D) have any effect on the users' perception of the five perceived robot features. In addition, we have compared the effects of varying amounts of prior experience with robots among the participants on pf under the four conditions (A-D). Further, the effect of these conditions on the physiological signals have been differentiated using deep learning algorithms.\n\nThis paper has been arranged in the following way: Section II describes the methodology used in this paper followed by the results in Section III. Further, Section IV outlines the future questions we would like to address in our study followed by the conclusion in Section V.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Ii. Methodology",
      "text": "",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "A. Data Acquisition",
      "text": "We have considered 30 neurotypical adults for this study. The mean age of all the participants was 21.4 years with a standard deviation of 3.36 years. Out of the 30 adults, 43% were male participants and the rest were female participants. During the sessions, the participants' audio, video and physiology was recorded. The physiological signals were recorded using the Empatica E4 wrist band. For the purpose of this study, just the BVP data was used for our deep learning based classification approaches. Before conducting this study, it was approved by the University's Institute Review Board (IRB). In addition, consent was taken from all the participants before the activity. There was no compensation involved for the participants involved in this research.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "B. Impressions Of The Nao Robot",
      "text": "The participants were given a set of pre-defined questions to use to interact with the NAO robot. The modalities of the NAO robot were tested under four different scenarios:\n\n• Default NAO voice with smooth motions (Condition A),\n\n• Amazon Polly Justin voice  [26]  with smooth motions (Condition B), • Default NAO voice with jerky motions (Condition C),\n\n• Amazon Polly Justin voice with jerky motions (Condition D). The participants' reactions to their impressions of the NAO robot were then assessed through the Godspeed and Robotic Social Attributes Scale (RoSAS)  [8]  questionnaires across five categories: 1) perceived safety (PS), 2) anthropomorphism (AP), 3) animacy (AM), 4) likeability (LK) and, 5) perceived intelligence (PI), similar to the authors in  [5] . The scores for these categories were recorded after each of the robot conditions (A-D). Since the participants had varying backgrounds in terms of prior experience with robots in their personal or professional lives, this difference in experience with robots has been accounted for while assessing perceived safety, anthropomorphism, animacy, likeability, and perceived intelligence. The experience of a participant with robots was recorded on a scale of 0-3, where 0 stands for no familiarity whereas 3 stands for intermediate level of familiarity (e.g., completed projects with robots). All of these statistical inferences were made using the one-way Analysis of Variance (ANOVA)  [21] ,  [34]  as has been discussed in later sections.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "C. Effect On Physiology",
      "text": "Since the BVP data is recorded during HRI, we use it to examine whether these physiological responses are differentiable using our deep learning algorithm. The BVP data is collected using a windowing approach. Since we use two different approaches for classification from the literature, the problem formulation for both of them have been explained.\n\n1) Problem formulation: The first approach comprises of just CNNs for time series classification of the BVP signal. Given the univariate BVP signal data, X = {x 1 , x 2 . . . , x n }, split the time series into windows as has been shown in equation\n\nwhere i is the number of training data point made from splitting the time series each into p steps, j denotes the stride length we used, and Y denotes the labels w.r.t. the conditions A-D. This basic formulation is used to find the multivariate function g(x) using our proposed Deep Learning approaches.\n\n2) Deep Learning for classification: The first approach used for our classification problem is based on CNNs on the raw time series signal which has been split into smaller windows. The network architecture has been shown in Figure  2 . For the second architecture, instead of using raw signals as inputs, we convert the split signals from equation 1 into images based on Gramian Angular Fields  [39] ,  [41] . In this work, we use the Gramian Angular Field Difference (GADF) as defined in  [39]  as:\n\n(2)\n\nwhere X are the polar coordinates of the time-series BVP signal X , and I is the unit vector  [39] . The definition of the polar coordinate X can be expressed as in  [39] :\n\nIn the above equation, the values of the BVP signal X can be scaled between [-1, 1] as has been mentioned in the expression of xi -1 or between [0, 1] as has been mentioned by the expression of xi 0 .",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Iii. Results And Discussions",
      "text": "A. Effects of Conditions (A-D) on user experience 1) Test for equal variances: The first step is to check the null hypothesis (H o ) in equation 4 for each of the features: PS, AP, AM, LK and, PI.\n\nFrom the p-values, obtained using Bonferroni 95% confidence intervals for standard deviations, we can reject the null hypothesis for PS, LK, and AM (p-value≤ 0.05) which means that the variances for these groups are different  [14] ,  [15] . On the other hand, we accept the null hypothesis for anthropomorphism and perceived intelligence (p-value> 0.05), which means that for each of these features, we can consider the variances of conditions A-D to be equal.\n\n2) ANOVA for each perceived feature: For this we consider the data of all the 30 participants included in this study irrespective of their previous exposure to robots. We use Welch's one-way ANOVA  [21] ,  [34]  for perceived safety, likeability, and animacy since we do not assume equal variances as was shown from the results in Figure  3 . We compare the difference between conditions A-D by making a hypothesis similar to that in equation 4, but this time with the means of the values:\n\nH 1 : ∃µ i ̸ = µ j for i ̸ = j where i, j = {A, B, C, D} (5b)\n\nThe main effects plot for each of the perceived features has been shown in Figure  4a -4e, and the p-values for them have been shown in Figure  4f . From the p-values it can be seen that for perceived safety, anthropomorphism, likeability and animacy, we can reject the null hypothesis (H o ) since the pvalue ≤ 0.05, whereas we accept H o for perceived intelligence (p-value > 0.05). This means that under different conditions A-D, a user has different levels of perception of PS, AP, LK, and AM; but the perceived intelligence of the robot remains unaffected. From the main effects plot in Figures  4a-4d , we can also conclude that:\n\n• Perceived safety: B>A>C>D. This means that the modality of the Amazon Polly Justin voice of the NAO robot with smooth motions was perceived to be the safest among users. • Anthropomorphism: A>B>D>C. The users perceived the NAO robot's default voice with smooth motions to be most anthropomorphic (human-like).\n\n• Likeability: A>C>B>D. The participants liked the NAO's default voice with its smooth motions most, similar to the case of anthropomorphism. • Animacy: A>B>C>D. Condition A still has the most preference for animacy as compared to the other conditions.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "B. Effects Of Experience With Robots",
      "text": "In this section, we compare the effects of varying robot experiences for each of the significantly perceived features (p-value ≤ 0.05) evaluated from the previous section (i.e perceived safety, anthropomorphism, likeability, and animacy). We have considered 4 levels of robot experiences:  We use a similar hypothesis as in equation 5 for finding the effect of robot experience on the perceived features:\n\nThe details of test of variances, p-values for all combinations of conditions and features have been shown in Table  II . It can be seen that prior experience with robots does not have any effect on the participants under any of the conditions (A-D) as far as perceived safety of robots during the interaction is concerned. The same holds for animacy too. On the other hand, under some conditions (A-D), anthropomorphism and likeability of the robot depend on prior experience with robotics has been highlighted in Table  II . The main effects plot of these significant values have been shown in Figure  5 . Based on these graphs, we conclude that for condition A, novice participants (level-'2') found the robot to be more anthropomorphic than the other participants. Similarly, participants with experience level-'3' found the robot more likeable for conditions A, C, and D.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "C. Effects On Physiological Response",
      "text": "From equation 1, we can see that the sliding window approach has j strides in between two consecutive windows. The approach has been adopted from the authors in  [26]  where an eight-second sliding window is used with a twosecond stride length. We analyzed the effect of different stride length on the train, test, and validation accuracy of both of our models. All the code for these deep learning models was run on Google Colab's premium version. The learning rate used for each of these simulations was 0.001 with Adam optimization and accuracy as the metric. The framework used for this work was Tensorflow.\n\nAs can be seen from Figure  6 , the effective length of 0.25 (Figure  7a ) fetched the maximum test accuracy (0.8179) followed by the effective length of 0.39 (Figure  7b ) with a test accuracy of 0.6767 and effective length of 0.5 with a test accuracy of 0.5831. In addition, the validation accuracies are also in agreement with the test accuracies for each of the effective length values. Hence, as the effective length increases, the validation and test accuracies of the model decreases.\n\n2) CNN model with Gramian Angular Field: The training and test accuracy for this case has been shown in Figure  7 . As can be seen from the low test accuracies of using the Gramian Angular Field, the effective length did not have any influence on the test accuracies. This can be attributed to the trend stationarity of the BVP signal  [1] .\n\n3) Proof of trend stationarity of BVP signal: We have used the Augmented Dickey-Fuller (ADF) test  [6]  and the Kwiatkowski-Phillips-Schmidt-Shin (KPSS) Test  [25]  for testing the trend stationarity of the BVP signal. Equation  8 shows For ADF test, we can reject the Null hypothesis (H o ) as pvalue = 0.1 > 0.05, whereas in case of KPSS test, we accept H o (p-value = 0 < 0.05). Hence, the BVP signal is trendstationary  [17]  which is consistent with the observations by authors in  [1] .",
      "page_start": 5,
      "page_end": 6
    },
    {
      "section_name": "Iv. Limitations And Future Work",
      "text": "For the user acceptance part of this paper, we would like to further test the impressions of children with ASD to the robot's modalities for comparing the perceived features of the NAO robot. In addition, we would like to expand the capability of the NAO robot to be able to understand and respond to candid conversations rather than pre-defined questions which is aligned with the aims in  [23] . For the classification problem described, we would like to include the use of autoencoders for denoising the BVP signal  [16] ,  [42]  towards making an end-to-end deep learning pipeline for classification.",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "V. Conclusion",
      "text": "In this paper, we present a study that involves the use of the humanoid NAO robot for a neurotypical population with four different conditions (A-D) of varying voice types and motions during HRI (see Section II-B for more details). The participants' prior experience with robots has also considered in this study. We have analysed the response of the participants on five perceived features (pf) of the robot namely, perceived safety, anthropomorphism, likeability, animacy, and perceived intelligence. We have analysed if the different conditions (A-D) have any effect on the users' perception of the five perceived robot features. In addition, we have compared the effects of varying amounts of prior experience with robots among the participants on pf under the four conditions (A-D).\n\nIn the end, we demonstrated the effect of these conditions on the physiology (here BVP) of the participants. Based on the performance of our deep learning approach, we were able to classify the physiological responses of the participants under different conditions with more than chance (> 25%) accuracy. Between the two approaches used for classification, using the raw signals with a CNN model (test acc: 0.8179 %) worked better than using GAF (test accuracy: 0.59%) attributing to the trend stationarity of the BVP signal.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Ethical Impact Statement",
      "text": "As described in Section II, prior IRB approval was taken before conducting this study. Informed consent was taken from all the participants. In addition, they had an option to opt out of the study at any stage.\n\nThe data collected during this study had no gender or racial bias. We had a close to equal male to female ratio (Male= 43%, Female= 57%). However, efforts were not made to ensure cross cultural data collection. Additional research would be needed to address the social impressions of the NAO robot across cultures.\n\nFor the deep learning model used, the generalization is performed across the subject data collected currently. Although, only BVP data was used as a physiological marker for differentiating between the conditions A-D. This distinction might not be generalizable across different physiological signals like Electrodermal Activity (EDA) or temperature.",
      "page_start": 7,
      "page_end": 7
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Social impressions of the NAO robot during HRI and",
      "page": 1
    },
    {
      "caption": "Figure 2: Deep learning models used for the two approaches. Figure 2a shows the model input of the raw signals. Figure 2b",
      "page": 2
    },
    {
      "caption": "Figure 1: with neurotypical adults. We start with the use of",
      "page": 2
    },
    {
      "caption": "Figure 2: For the second architecture, instead of using raw signals",
      "page": 3
    },
    {
      "caption": "Figure 3: We compare the difference",
      "page": 3
    },
    {
      "caption": "Figure 4: a-4e, and the p-values for them have",
      "page": 3
    },
    {
      "caption": "Figure 4: f. From the p−values it can be seen",
      "page": 3
    },
    {
      "caption": "Figure 3: Test for equal variance in the populations for conditions A, B, C, and D each for perceived safety, anthropomorphism,",
      "page": 4
    },
    {
      "caption": "Figure 4: One-way ANOVA for finding significance of conditions A-D for different perceived robot features.",
      "page": 4
    },
    {
      "caption": "Figure 5: Effect of experience with robotics on different perceived features under different conditions.",
      "page": 5
    },
    {
      "caption": "Figure 5: Based on these",
      "page": 5
    },
    {
      "caption": "Figure 6: Effect of using different sliding window size and stride length on the accuracy of classification using the raw singal.",
      "page": 6
    },
    {
      "caption": "Figure 7: Effect of using different sliding window size and stride length on the accuracy of classification using Gramian Angular",
      "page": 6
    },
    {
      "caption": "Figure 6: , the effective length of 0.25 (Fig-",
      "page": 6
    },
    {
      "caption": "Figure 7: b) with a test accuracy",
      "page": 6
    },
    {
      "caption": "Figure 7: As can be seen from the low test accuracies of using the",
      "page": 6
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Perceived features": "",
          "p−values": "Condition A"
        },
        {
          "Perceived features": "Perceived Safety",
          "p−values": "0.912"
        },
        {
          "Perceived features": "",
          "p−values": "0.592"
        },
        {
          "Perceived features": "Anthrpomorphism",
          "p−values": "0.042"
        },
        {
          "Perceived features": "",
          "p−values": "0.013"
        },
        {
          "Perceived features": "Likeability",
          "p−values": "0.586"
        },
        {
          "Perceived features": "",
          "p−values": "0.000"
        },
        {
          "Perceived features": "Animacy",
          "p−values": "0.073"
        },
        {
          "Perceived features": "",
          "p−values": "0.911"
        }
      ],
      "page": 5
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Fatma Latifoglu, and Vedat Bilgic. Spectral analysis of photoplethysmographic signals: The importance of preprocessing",
      "authors": [
        "Sadık Saime Akdemir Akar",
        "Kara"
      ],
      "year": "2013",
      "venue": "Biomedical Signal Processing and Control"
    },
    {
      "citation_id": "2",
      "title": "Use of telehealth for facilitating the diagnostic assessment of autism spectrum disorder (asd): A scoping review",
      "authors": [
        "Jodie Manahil Alfuraydan",
        "Lisa Croxall",
        "Mike Hurt",
        "Sinead Kerr",
        "Brophy"
      ],
      "year": "2020",
      "venue": "PloS one"
    },
    {
      "citation_id": "3",
      "title": "American Psychiatric Association, et al. Diagnostic and statistical manual of mental disorders: DSM-5",
      "year": "2013",
      "venue": "American Psychiatric Association, et al. Diagnostic and statistical manual of mental disorders: DSM-5"
    },
    {
      "citation_id": "4",
      "title": "Prevalence of autism spectrum disorder among children aged 8 years-autism and developmental disabilities monitoring network, 11 sites, united states",
      "authors": [
        "Jon Baio"
      ],
      "year": "2010",
      "venue": "Prevalence of autism spectrum disorder among children aged 8 years-autism and developmental disabilities monitoring network, 11 sites, united states"
    },
    {
      "citation_id": "5",
      "title": "Measurement instruments for the anthropomorphism, animacy, likeability, perceived intelligence, and perceived safety of robots",
      "authors": [
        "Christoph Bartneck",
        "Dana Kulić",
        "Elizabeth Croft",
        "Susana Zoghbi"
      ],
      "year": "2009",
      "venue": "International journal of social robotics"
    },
    {
      "citation_id": "6",
      "title": "Kpss: Stata module to compute kwiatkowskiphillips-schmidt-shin test for stationarity",
      "authors": [
        "Christopher Baum"
      ],
      "year": "2018",
      "venue": "Kpss: Stata module to compute kwiatkowskiphillips-schmidt-shin test for stationarity"
    },
    {
      "citation_id": "7",
      "title": "Is autism curable?",
      "authors": [
        "Sven Bölte"
      ],
      "year": "2014",
      "venue": "Developmental Medicine & Child Neurology"
    },
    {
      "citation_id": "8",
      "title": "The robotic social attributes scale (rosas) development and validation",
      "authors": [
        "Colleen Carpinella",
        "Alisa Wyman",
        "Michael Perez",
        "Steven Stroessner"
      ],
      "year": "2017",
      "venue": "Proceedings of the 2017 ACM/IEEE International Conference on human-robot interaction"
    },
    {
      "citation_id": "9",
      "title": "Towards interactive robots in autism therapy: Background, motivation and challenges",
      "authors": [
        "Kerstin Dautenhahn",
        "Iain Werry"
      ],
      "year": "2004",
      "venue": "Pragmatics & Cognition"
    },
    {
      "citation_id": "10",
      "title": "Towards adaptive autonomous robots in autism therapy: Varieties of interactions",
      "authors": [
        "Kerstin Dautenhahn",
        "Iain Werry",
        "Tamie Salter",
        "Rene Boekhorst"
      ],
      "year": "2003",
      "venue": "Proceedings 2003 IEEE International Symposium on Computational Intelligence in Robotics and Automation. Computational Intelligence in Robotics and Automation for the New Millennium"
    },
    {
      "citation_id": "11",
      "title": "Uncanny valley, robot and autism: Perception of the uncanniness in an emotional gait",
      "authors": [
        "Matthieu Destephe",
        "Massimiliano Zecca",
        "Kenji Hashimoto",
        "Atsuo Takanishi"
      ],
      "year": "2014",
      "venue": "2014 IEEE International Conference on Robotics and Biomimetics"
    },
    {
      "citation_id": "12",
      "title": "Autism interventions: a critical update",
      "authors": [
        "Francis"
      ],
      "year": "2005",
      "venue": "Developmental medicine and child neurology"
    },
    {
      "citation_id": "13",
      "title": "'emotiplay': a serious game for learning about emotions in children with autism: results of a cross-cultural evaluation",
      "authors": [
        "Steve Shimrit Fridenson-Hayo",
        "Berggren",
        "Shahar Lassalle",
        "Delia Tal",
        "N Pigat",
        "Helen O' Meir-Goren",
        "S Reilly",
        "Sven Ben-Zur",
        "Simon Bölte",
        "Baron-Cohen"
      ],
      "year": "2017",
      "venue": "European child & adolescent psychiatry"
    },
    {
      "citation_id": "14",
      "title": "Simple solution to a common statistical problem: interpreting multiple tests",
      "authors": [
        "Toufigh Gordi",
        "Harry Khamis"
      ],
      "year": "2004",
      "venue": "Clinical therapeutics"
    },
    {
      "citation_id": "15",
      "title": "A stagewise rejective multiple test procedure based on a modified bonferroni test",
      "authors": [
        "Gerhard Hommel"
      ],
      "year": "1988",
      "venue": "Biometrika"
    },
    {
      "citation_id": "16",
      "title": "Reconstruction of time series with missing value using 2d representation-based denoising autoencoder",
      "authors": [
        "Tao Huamin",
        "Xiao Deng Qiuqun",
        "Shanzhu"
      ],
      "year": "2020",
      "venue": "Journal of Systems Engineering and Electronics"
    },
    {
      "citation_id": "17",
      "title": "Statistical tests to check stationarity in time series",
      "authors": [
        "Vijay Kumar"
      ],
      "year": "2021",
      "venue": "Statistical tests to check stationarity in time series"
    },
    {
      "citation_id": "18",
      "title": "The evidence-based practices for children, youth, and young adults with autism report: Concerns and critiques",
      "authors": [
        "Justin Leaf",
        "Sara Sato",
        "Asim Javed",
        "Shannon Arthur",
        "Ashley Creem",
        "Julia Joseph H Cihon",
        "Misty Ferguson",
        "Oppenheim-Leaf"
      ],
      "year": "2021",
      "venue": "The evidence-based practices for children, youth, and young adults with autism report: Concerns and critiques"
    },
    {
      "citation_id": "19",
      "title": "Which robot features can stimulate better responses from children with autism in robot-assisted therapy?",
      "authors": [
        "Jaeryoung Lee",
        "Hiroki Takehashi",
        "Chikara Nagai",
        "Goro Obinata",
        "Dimitar Stefanov"
      ],
      "year": "2012",
      "venue": "International Journal of Advanced Robotic Systems"
    },
    {
      "citation_id": "20",
      "title": "The persistence of fad interventions in the face of negative scientific evidence: Facilitated communication for autism as a case example",
      "authors": [
        "Julia Scott O Lilienfeld",
        "James Marshall",
        "Howard Todd",
        "Shane"
      ],
      "year": "2014",
      "venue": "Evidence-Based Communication Assessment and Intervention"
    },
    {
      "citation_id": "21",
      "title": "Comparing Welch ANOVA, a Kruskal-Wallis test, and traditional ANOVA in case of heterogeneity of variance",
      "authors": [
        "Hangcheng Liu"
      ],
      "year": "2015",
      "venue": "Comparing Welch ANOVA, a Kruskal-Wallis test, and traditional ANOVA in case of heterogeneity of variance"
    },
    {
      "citation_id": "22",
      "title": "Uncanny valley for interactive social agents: An experimental study",
      "authors": [
        "Nidhi Mishra",
        "Manoj Ramanathan",
        "Gauri Tulsulkar",
        "Nadia Magnenat Thalmann"
      ],
      "year": "2022",
      "venue": "Virtual Reality & Intelligent Hardware"
    },
    {
      "citation_id": "23",
      "title": "Towards adaptive and personalized robotic therapy for children with autism spectrum disorder",
      "authors": [
        "Ruchik Mishra"
      ],
      "year": "2022",
      "venue": "2022 10th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW)"
    },
    {
      "citation_id": "24",
      "title": "Bukimi no tani (the uncanny valley)",
      "authors": [
        "Masahiro Mori"
      ],
      "year": "1970",
      "venue": "Energy"
    },
    {
      "citation_id": "25",
      "title": "Augmented dickey fuller test",
      "authors": [
        "Rizwan Mushtaq"
      ],
      "year": "2011",
      "venue": "Augmented dickey fuller test"
    },
    {
      "citation_id": "26",
      "title": "Deep ppg: large-scale heart rate estimation with convolutional neural networks",
      "authors": [
        "Attila Reiss",
        "Ina Indlekofer",
        "Philip Schmidt",
        "Kristof Van Laerhoven"
      ],
      "year": "2019",
      "venue": "Sensors"
    },
    {
      "citation_id": "27",
      "title": "Effects of repeated exposure to a humanoid robot on children with autism",
      "authors": [
        "Ben Robins",
        "Kerstin Dautenhahn",
        "Rene Boekhorst",
        "Aude Billard"
      ],
      "year": "2004",
      "venue": "Designing a more inclusive world"
    },
    {
      "citation_id": "28",
      "title": "Project aim: Autism intervention meta-analysis for studies of young children",
      "authors": [
        "Micheal Sandbank",
        "Kristen Bottema-Beutel",
        "Shannon Crowley",
        "Margaret Cassidy",
        "Kacie Dunham",
        "Jacob Feldman",
        "Jenna Crank",
        "Susanne Albarran",
        "Sweeya Raj",
        "Prachy Mahbub"
      ],
      "year": "2020",
      "venue": "Psychological bulletin"
    },
    {
      "citation_id": "29",
      "title": "Autism spectrum disorder: When there is no cure, there are countless of treatments",
      "authors": [
        "Dincer Saral",
        "Seray Olcay",
        "Halil Ozturk"
      ],
      "year": "2022",
      "venue": "Journal of Autism and Developmental Disorders"
    },
    {
      "citation_id": "30",
      "title": "Robots for use in autism research",
      "authors": [
        "Brian Scassellati",
        "Henny Admoni",
        "Maja Matarić"
      ],
      "year": "2012",
      "venue": "Annual review of biomedical engineering"
    },
    {
      "citation_id": "31",
      "title": "Complementary and alternative treatments for autism part 2: identifying and avoiding non-evidence-based treatments",
      "authors": [
        "Alison Singer",
        "Ramita Ravi"
      ],
      "year": "2015",
      "venue": "AMA journal of ethics"
    },
    {
      "citation_id": "32",
      "title": "Using a social robot to teach gestural recognition and production in children with autism spectrum disorders",
      "authors": [
        "Wing-Chee So",
        "Kit-Yi Wong",
        "Ka-Yee Lam",
        "Wan-Yi Lam",
        "Anthony Tsz-Fung",
        "Tsz-Lok Chui",
        "Hoi-Man Lee",
        "Chun-Hung Ng",
        "Daniel Chan",
        "-Wing Chun",
        "Fok"
      ],
      "year": "2018",
      "venue": "Disability and Rehabilitation: Assistive Technology"
    },
    {
      "citation_id": "33",
      "title": "Evidencebased practices for children, youth, and young adults with autism",
      "authors": [
        "Jessica Steinbrenner",
        "Kara Hume",
        "L Samuel",
        "Kristi Odom",
        "Sallie Morin",
        "Brianne Nowell",
        "Susan Tomaszewski",
        "Nancy Szendrey",
        "Serife Mcintyre",
        "Melissa Yücesoy-Özkan",
        "Savage"
      ],
      "year": "2020",
      "venue": "Evidencebased practices for children, youth, and young adults with autism"
    },
    {
      "citation_id": "34",
      "title": "Multiple comparisons in model i one-way anova with unequal variances",
      "authors": [
        "C Ajit",
        "Tamhane"
      ],
      "year": "1977",
      "venue": "Communications in Statistics-Theory and Methods"
    },
    {
      "citation_id": "35",
      "title": "A new machine learning model based on induction of rules for autism detection",
      "authors": [
        "Fadi Thabtah",
        "David Peebles"
      ],
      "year": "2020",
      "venue": "Health informatics journal"
    },
    {
      "citation_id": "36",
      "title": "A bayesian model of the uncanny valley effect for explaining the effects of therapeutic robots in autism spectrum disorder",
      "authors": [
        "Yuki Ueyama"
      ],
      "year": "2015",
      "venue": "PloS one"
    },
    {
      "citation_id": "37",
      "title": "Adherence and acceptability of a robot-assisted pivotal response treatment protocol for children with autism spectrum disorder",
      "authors": [
        "Iris Van Den Berk-Smeekens",
        "Martine Van Dongen-Boomsma",
        "Manon De Korte",
        "Jenny C Den Boer",
        "Iris Oosterling",
        "C Nienke",
        "Jan Peters-Scheffer",
        "Emilia Buitelaar",
        "Tino Barakova",
        "Lourens",
        "G Wouter",
        "Staal"
      ],
      "year": "2020",
      "venue": "Scientific reports"
    },
    {
      "citation_id": "38",
      "title": "Effects of robots' intonation and bodily appearance on robot-mediated communicative treatment outcomes for children with autism spectrum disorder",
      "authors": [
        "Caroline L Van Straten",
        "Iris Smeekens",
        "Emilia Barakova",
        "Jeffrey Glennon",
        "Jan Buitelaar",
        "Aoju Chen"
      ],
      "year": "2018",
      "venue": "Personal and Ubiquitous Computing"
    },
    {
      "citation_id": "39",
      "title": "Imaging time-series to improve classification and imputation",
      "authors": [
        "Zhiguang Wang",
        "Tim Oates"
      ],
      "year": "2015",
      "venue": "Imaging time-series to improve classification and imputation",
      "arxiv": "arXiv:1506.00327"
    },
    {
      "citation_id": "40",
      "title": "Can social interaction skills be taught by a social agent? the role of a robotic mediator in autism",
      "authors": [
        "Iain Werryz",
        "Kerstin Dautenhahn",
        "Bernard Ogden",
        "William Harwinz"
      ],
      "year": "2001",
      "venue": "Cognitive Technology: Instruments of Mind: 4th International Conference"
    },
    {
      "citation_id": "41",
      "title": "Human activity recognition based on gramian angular field and deep convolutional neural network",
      "authors": [
        "Hongji Xu",
        "Juan Li",
        "Hui Yuan",
        "Qiang Liu",
        "Shidi Fan",
        "Tiankuo Li",
        "Xiaojie Sun"
      ],
      "year": "2020",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "42",
      "title": "Denoising temporal convolutional recurrent autoencoders for time series classification",
      "authors": [
        "Zhong Zheng",
        "Zijun Zhang",
        "Long Wang",
        "Xiong Luo"
      ],
      "year": "2022",
      "venue": "Information Sciences"
    }
  ]
}