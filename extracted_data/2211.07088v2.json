{
  "paper_id": "2211.07088v2",
  "title": "Recognition Of Cardiac Mri Orientation Via Deep Neural Networks And A Method To Improve Prediction Accuracy",
  "published": "2022-11-14T03:35:15Z",
  "authors": [
    "Houxin Zhou"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "In most medical image processing tasks, the orientation of an image would affect computing result. However, manually reorienting images wastes time and effort. In this paper, we study the problem of recognizing orientation in cardiac MRI and using deep neural network to solve this problem. For multiple sequences and modalities of MRI, we propose a transfer learning strategy, which adapts our proposed model from a single modality to multiple modalities. We also propose a prediction method that uses voting. The results shows that deep neural network is an effective way in recognition of cardiac MRI orientation and the voting prediction method could improve accuracy.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "When medical images were stored, they may have different image orientations. In the further segmentation or computing, this difference may affect the results, since current deep neural network (DNN) systems generally only take the input and output of images as matrices or tensors, without considering the imaging orientation and real world coordinate. So it is crucial to recognize it before the further computing. This work is aimed to provide a study of the Cardiac Magnetic Resonance (CMR) image orientation, for fitting the coordinate system of human reality, and to develop an efficient method for recognition of the orientation.\n\nDeep neural network has performed outstandingly in computer vision and gradually replaced the traditional methods. DNN also take a important role in medical image processing, such as image segmentation  [3]  and myocardial pathology analysis  [2] . For CMR images, standardization of all the images is a prerequisite for further computing tasks based on DNN-based methodologies.\n\nMost studies in the field of medical image processing have only focused on the further computing, so they have to spend a lot of manpower to do the preprocess. If we can auto adjust the images, it will save lots of time. Nevertheless, recognizing the orientation of different modality CMR images and adjusting them into standard format could be as challenging as the further computing tasks  [1] . In a broad sense, recognition orientation is also a kind of image classification task, so DNN is of no doubts an effective way to solve this problem. In this work, we still use DNN as our main method.\n\nIn most image classification problem like ImageNet, we do some transformation to the image but these transformation do not change the label, for example we rotate a dog image and it's still a dog image. However, the orientation could be changed if we do transformation like flipping to the images. In this work, we utilize this character to built a predicting model. Combining DNN and predicting model, we built a framework for recognition of Orientation. This work is aimed at designing a DNN-based approach to achieve orientation recognition for multiple CMR modalities. Figure  1  presents the pipeline of our proposed method. The main contributions of this work are summarized as follows:\n\nFigure  1 : The pipeline of our proposed method. Firstly, we do some transformatioin to the image(See 2.1 and 2.3). Then, the images are taken as input to the DNN model and generate orientations. Finally, we apply inverse transformation to these orientations and vote to get the result.\n\n1. We propose a scheme to standardize the CMR image orientation and categorize all the orientations for classification.\n\n2. We present a DNN-based orientation recognition method for CMR image and transfer it to other modalities.\n\n3. We propose a predicting method to improve the accuracy for orientation recognition.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Method",
      "text": "In this section, we introduce our proposed method for orientation recognition. Our proposed method is based on Deep Neural Network which was proved effective in image classification.\n\nIn CMR Image Orientation Categorization, we improved the predicting accuracy by the following four steps. Firstly, we apply invertible operators to the image to get another 7 images. Then we predict these images and get 8 orientations. Finally, we use inverse transformation to these orientations and then vote to get the result.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Cmr Image Orientation Categorization",
      "text": "Due to different data sources and scanning habits, the orientation of different CMR images may be different, and the orientation vector corresponding to the image itself may not correspond correctly. This may cause problems in tasks such as image segmentation or registration. Taking a 2D image as an example, we set the orientation of an image as the initial image and set the four corners of the image to 1 2 3 4 , Then the orientation of the 2D MR image may have the following 8 variations, which is listed in Table  1 .\n\nFor each image X t from dataset, the target is to find the correct orientation from 8 classes. We denote the correct orientation of image X t as i t and denote the correctly adjusted image X t as Y t If we view each orientation as a function f , we can get a function set {f i , i = 0 . . . 7} and (X t , Y t , i t ) satisfy the equation f it (Y t ) = X t . In the following, function set {f i , i = 0 . . . 7} is referred to as F .",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Deep Neural Network",
      "text": "Suppose given image X t , X t is then normalized. We denote the processed X t as X t . CNN take the (X t , i t ) as input. In the proposed framework, the orientation recognition network consists of 3 convolution layers and 2 fully connected layers. The orientation predicted is denoted as Ôi . We use the standard categorical loss to calculate the loss between predicted orientation Ôi and orientation label O i . The orientation loss is formulated as below:",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Improved Prediction Method",
      "text": "As we can see in 2.1, we regard label i t as function f it . It can be easily proved that f i • f j ∈ F for any i and j, so we can not only view f i as a function but an operator whose define domain and value domain are both F . For convenience, we denote the operator f i as g i . Surpprisingly, we can prove that operator g i is a surjection in F for any i, which can be simply explained by the following matrix A. In matrix\n\n0 1 2 3 4 5 6 7 1 0 3 2 5 4 7 6 2 3 0 1 6 7 4 5 3 2 1 0 7 6 5 4 4 6 5 7 0 2 1 3 5 7 4 6 1 3 0 2 6 4 7 5 2 0 3 1 7 5 6 4 3 1 2 0\n\nBecause F is a finate set, g i is a injection and invertible. For any operator g i , it exist an inverse operator and we denote it as g - i . Operator g - i is also a surjection and injection in F , which can be simply explained by the following matrix A -. In matrix\n\nFor simplification, we omit f and use g - i (j) = k to express the results above.\n\n0 1 2 3 4 5 6 7 1 0 3 2 5 4 7 6 2 3 0 1 6 7 4 5 3 2 1 0 7 6 5 4 4 6 5 7 0 2 1 3 6 4 7 5 2 0 3 1 5 7 4 6 1 3 0 2 7 5 6 4 3 1 2 0\n\nBased on the above premise, we built the predicting method by the follow 4 steps. Figure  1  shows the method by a flow chart.\n\n1. Apply (f 0 , f 1 . . . , f 7 ) to the image X t to get 8 images. We denote these images as (X t0 , X t1 , . . . , X t7 ) 2. Take these 8 images as input to DNN and get 8 orientations (i t0 , i t1 , . . . , i t7 ).\n\n3. Apply (g - 0 , g - 1 , . . . , g - 7 ) to these 8 labels and get another 8 labels (g - 0 (i t 0 ), g - 1 (i t1 ), . . . , g - 7 (i t7 )).\n\n4. The labels which occur most in (g - 1 (i t 0 ), g - 2 (i t1 ), . . . , g - 7 (i t7 )) is the final result.\n\n3 Experiment",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Experiment Setup",
      "text": "We evaluate orientation recognition network on the MyoPS dataset  [2, 3] . The MyoPS dataset provides the three-sequence Cardiac Magnetic Resonance (LGE, T2 and C0) and three anatomy masks, including myocardium (Myo), left ventricle (LV), and right ventricle (RV), some of the three-sequence Cardiac Magnetic Resonance is shown as Figure  2  . MyoPS further provides two pathology masks (myocardial infarct and edema) from the 45 patients.\n\nFor the simplified orientation recognition network, we train model for single modality on the MyoPS dataset, then transfer the model to other modalities. For each sequence, we resample each slice of each 3d image and the corresponding labels to an in-plane resolution of 1.367 × 1.367 mm.  We divide slices into three sub-sets, i.e., the training set, validation set and test set, at the ratio of 50%, 30% and 20%. Three sub-sets don't have slices from same patient. Then, for each standard 2d image, we apply all function from F to it to expand dataset. For training set, image slices are cropped or padded to 256 × 256 for the orientation recognition network, and apply random augmentation. For test set and validation set, the images are only resized to 256 × 256.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Orientation Recognition Network",
      "text": "During each training iteration, a batch of the three-channel images X' is fed into the orientation recognition network. Then, the network outputs the predicted orientation network.\n\nFigure  3  and Table  2  shows the training process and accuracy of the three sequences on test set. The results show that the model get quite high accuracy in three modalities. Howeverm the size of test data is small, random factors influence the result heavily. In the following, we redivide the data, retrain the model, and analyses sensitivity of the model.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Sensitivity Analysis",
      "text": "When using deep learning method to solve the problem, the volume of data is always the most important factor. In medical image processing, it is difficult to get a lot of data, so analysing the sensitivity of model is necessary. We redivided the data set into training set and test set 5 times, and the proportion of training set was 60%, 50%, 40%, 30% and 20% respectively. In each divided data set, we retrain the model in training set and compute accuracy in test set. The accuracy variation is shown in Table  3 . There is not a distinct difference among the accuracy while the volume of data decrease. Therefore DNN is a suitable method in CMR orientation recognition with high accuracy and low sensitivity.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Comparison Between Improved Prediction And Direct Prediction",
      "text": "Table  3  shows the difference of accuracy between improved prediction and direct prediction. We can find that improved prediction always have higher accuracy in our experiment. However, it is not inevitable, because the vote may make the original correct decision wrong. Sometimes, the improved prediction have a lower accuracy, but in an average sense, the improved prediction is better than direct prediction.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Conclusion",
      "text": "DNN model get quite high accuracy in recognition of CMR image orientation and transfer learning make it easy to be transferred to other modalities . Thanks to the data expansion and augmentation, the model only need a few data. The improved prediction we proposed further increase the accuracy. We are sure that DNN model combining with transfer learning and improved prediction can be used in other recognition of orientation tasks.",
      "page_start": 6,
      "page_end": 6
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: presents the pipeline of our proposed method.",
      "page": 2
    },
    {
      "caption": "Figure 1: The pipeline of our proposed method. Firstly, we do some transformatioin to",
      "page": 2
    },
    {
      "caption": "Figure 1: shows the method by a ﬂow chart.",
      "page": 4
    },
    {
      "caption": "Figure 2: the three-sequence Cardiac Magnetic Resonance",
      "page": 5
    },
    {
      "caption": "Figure 3: and Table 2 shows the training process and accuracy of the three sequences",
      "page": 5
    },
    {
      "caption": "Figure 3: Training images",
      "page": 5
    }
  ],
  "tables": [
    {
      "caption": "Table 1: Orientation categorization of 2D CMR Images. Here, sx, sy and sz respectively",
      "data": [
        {
          "No.": "0",
          "Operation\nImage\nCorrespondence of coordinates": "initial state"
        },
        {
          "No.": "1",
          "Operation\nImage\nCorrespondence of coordinates": "horizontal ﬂip"
        },
        {
          "No.": "2",
          "Operation\nImage\nCorrespondence of coordinates": "vertical ﬂip"
        },
        {
          "No.": "3",
          "Operation\nImage\nCorrespondence of coordinates": "Rotate 180◦ clockwise"
        },
        {
          "No.": "4",
          "Operation\nImage\nCorrespondence of coordinates": "Flip along the upper left-lower right corner"
        },
        {
          "No.": "5",
          "Operation\nImage\nCorrespondence of coordinates": "Rotate 90◦ clockwise"
        },
        {
          "No.": "6",
          "Operation\nImage\nCorrespondence of coordinates": "Rotate 270◦ clockwise"
        },
        {
          "No.": "7",
          "Operation\nImage\nCorrespondence of coordinates": "Flip along the bottom left-top right corner"
        }
      ],
      "page": 3
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Recognition and Standardization of Cardiac MRI Orientation via Multi-tasking Learning and Deep Neural Networks",
      "authors": [
        "Ke Zhang",
        "Xiahai Zhuang"
      ],
      "year": "2020",
      "venue": "Myocardial Pathology Segmentation Combining Multi-Sequence Cardiac Magnetic Resonance Images"
    },
    {
      "citation_id": "2",
      "title": "Multivariate mixture model for cardiac segmentation from multisequence mri",
      "authors": [
        "Xiahai Zhuang"
      ],
      "year": "2016",
      "venue": "International Conference on Medical Image Computing and Computer-Assisted Intervention"
    },
    {
      "citation_id": "3",
      "title": "Multivariate mixture model for myocardial segmentation combining multi-source images",
      "authors": [
        "Xiahai Zhuang"
      ],
      "year": "2019",
      "venue": "IEEE transactions on pattern analysis and machine intelligence"
    }
  ]
}