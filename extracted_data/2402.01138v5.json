{
  "paper_id": "2402.01138v5",
  "title": "Graph Neural Networks In Eeg-Based Emotion Recognition: A Survey",
  "published": "2024-02-02T04:30:58Z",
  "authors": [
    "Chenyu Liu",
    "Xinliang Zhou",
    "Yihao Wu",
    "Ruizhi Yang",
    "Zhongruo Wang",
    "Liming Zhai",
    "Ziyu Jia",
    "Yang Liu"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Compared to other modalities, EEG-based emotion recognition can intuitively respond to the emotional patterns in the human brain and, therefore, has become one of the most concerning tasks in the brain-computer interfaces field. Since dependencies within brain regions are closely related to emotion, a significant trend is to develop Graph Neural Networks (GNNs) for EEG-based emotion recognition. However, brain region dependencies in emotional EEG have physiological bases that distinguish GNNs in this field from those in other time series fields. Besides, there is neither a comprehensive review nor guidance for constructing GNNs in EEG-based emotion recognition. In the survey, our categorization reveals the commonalities and differences of existing approaches under a unified framework of graph construction. We analyze and categorize methods from three stages in the framework to provide clear guidance on constructing GNNs in EEG-based emotion recognition. In addition, we discuss several open challenges and future directions, such as Temporal full-connected graph and Graph condensation.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Emotion is an integral and complex aspect of human cognition that is decisive in human decision-making, behavior, and social interaction. Therefore, Emotion Recognition is essential in areas such as the diagnosis of mental disorders and Brain-Computer Interfaces (BCIs). Human emotions have various external manifestations, such as body language, voice, expression, and physiological signals. Among them, the Electroencephalogram (EEG) signals are perceived as a product of coordinated neural activity and electrical signal transmission within the human brain, which can directly and objectively reveal genuine human emotion compared to other manifestations and thus are known as one of the most unique and vital data in emotion recognition. EEG records emotional activity from different brain regions and, therefore, can reflect the complex interactions between brain regions in emotional states and the strong correlation between specific brain regions and specific emotions  [Min et al., 2022] . In summary, inferring and exploiting complex dependencies between brain regions in emotional EEG has become a significant research direction in EEG-based emotion recognition. Graph Neural Networks (GNNs) emerge as a powerful tool for modeling dependencies of emotional EEG within the network neuroscience framework. As networks that manipulate graph-structured data, GNNs can effectively extract features utilizing dependencies between brain regions in emotional EEG. These dependencies represent the connectivity patterns and interactions of brain regions in emotional states, which are directly associated with specific emotional activities. Therefore, benefiting from its dependencies inference ability, GNNs designed for EEG-based emotion recognition can improve classification tasks compared to traditional analysis methods and potentially uncover new insights in neuroscience. As shown in Fig.  1 , there has been a significant growth in the number and proportion of methods using GNNs in the EEG-based emotion recognition field over the last six years.\n\nMotivated by the increasing number of recent papers proposing GNNs for EEG-based emotion recognition, and the design of these GNNs differs from methods in other timeseries tasks, there is an urgent need for a comprehensive review of the GNNs in this field. First, there is currently no unified treatment for GNN structure in the EEG-based emotion recognition field. Second, brain region dependencies in emo-tional states have specific physiological bases, distinguishing GNNs in EEG-based emotion recognition from those used in other time-series fields. Therefore, we categorize existing GNNs in EEG-based emotion recognition based on stages within a unified GNN construction framework. Specifically, this categorization splits the existing methods regarding nodelevel, edge-level, and graph-level stages and proposes a taxonomic view for each stage. In summary, the contributions of this survey are summarized below:\n\n• This survey provides a comprehensive and systematic review of existing GNNs in EEG-based emotion recognition. To the best of our knowledge, this is the first and only survey work on such a topic.\n\n• We propose a novel categorization of existing GNNs in EEG-based emotion recognition, which provides clear guidance for constructing specific GNNs according to a unified framework.\n\n• We summarise and highlight future directions to facilitate GNN-based works in EEG-based emotion recognition.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Overview Of Categorization",
      "text": "In recent years, EEG-based emotion recognition has seen an influx of methods with GNNs. These methods focus on different aspects of designing GNNs to infer dependencies within emotional EEG. They generally answer these three critical questions during the graph construction process: What features are chosen as nodes? How to calculate edges? Which graph structure is utilized? Therefore, categorizing these methods at the model level is not instructive nor sufficiently in-depth. To better understand these methods and propose a construction guideline for GNNs in EEG-based emotion recognition, our categorization is based on a unified framework with its corresponding stages.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Framework For Specific Gnns",
      "text": "EEG-based emotion recognition task for GNNs can be indicated as taking emotional EEG X ∈ R C×S and corresponding label Y ∈ R 1 as input, constructing graphs and predicting emotional labels Y ′ R 1 via graph embedding. Let G(V, E) denote a graph. V ∈ R Nv×D represents the node set, where",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Stages Of Framework",
      "text": "Node-level Stage indicates the process of selecting features as nodes V. Instead of focusing on the detailed composition and parameters of the node embedding extractor, this survey focuses on the composition of node features. Therefore, we categorize this stage according to the type of node features, as shown in Fig.  3 (a) . These two categories are Univariate node, which utilizes a single feature, and Hybrid node, which employs multiple features. The details of each category will be explained in the Section. 3. Edge-level Stage represents the calculation of the edge matrix E. The edge matrix represents the relationships between electrode nodes. Matrices representing such relationships differ in different methods, such as the adjacency matrix or the Laplace matrix. We uniformly regard them as edge matrices. Depending on whether the model parameters are involved in the calculation, we categorize the Edge-level Stage of the existing methods into two categories: Model-independent edge and Model-dependent edge, as shown in Fig.  3 (b ). The subcategories of each category will be explained in detail in Section. 4. Graph-level Stage denotes the process of modeling different types of graph structures G. The basic units utilized by existing methods for reasoning about graph embedding are Graph Convolutional Networks (GCNs) or Graph Attention Networks (GATs). The perspective of this survey is not on the detailed model components but on the graph structure used to represent the dependencies within emotional EEG. The graph structure of existing methods can be categorized into four types, as shown in Fig  3 (c ). Multi-graph indicates that the model employs a multi-stream structure to simultaneously construct different graphs to incorporate multiple dependencies of emotional EEG. Hierarchical graph denotes that the model organizes nodes into multiple groups to infer dependency between brain regions related to emotion. Time series graph is a series of graphs in the temporal dimension that represent the temporal dependency of emotional EEG. Sparse graph structure represents sparsely connected graphs that match the concentration of brain activity in emotional states. The sub-categories of each category will be explained in detail in Section. 5. Univariate node is further categorized into Temporal domain node, Frequency domain node, and raw signal node. Hybrid node contains Temporal&Frequency node and Aggregation node.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Univariate Node",
      "text": "Univariate nodes refer to the most common way of using a single feature as nodes. The vast majority of existing methods utilize this method. It contains three categories, as shown in Table  1 .\n\nTemporal domain node implies that the model employs the temporal domain feature as nodes. This is the most commonly used node in the current methods, especially the differential entropy (DE) feature. The popularity of the DE feature, in addition to the fact that many open-source EEGbased emotion recognition datasets include this feature, such as SEED  [Zheng and Lu, 2015] , DE feature itself is suitable for measuring the uncertainty or randomness of the signal, which is adequate for describing the diverse dependencies in the emotional EEG. In addition to this, HD-GCN  [Ye et al., 2022]  and SparseDGCNN  [Zhang et al., 2021]  employ the Differential Asymmetry of Synchronisation for Multivariate Signals (DASM) feature.\n\nFrequency Domain node indicates that utilizing frequency domain features as nodes. The most commonly used is the Power Spectral Density (PSD) feature obtained by Fourier Transform to describe the power distribution of the signal in the frequency domain. From comparing the experiment results of existing methods, the performance of using Frequency domain node is generally slightly worse than using Temporal domain node.\n\nRaw Signal node represents directly using the raw emotional EEG as nodes. This node is the least common in EEG-based emotion recognition tasks because raw emotional EEG is highly individualized, which remains more emotionindependent disturbances. Besides, The dimension of Raw signal node is higher compared to other nodes. However, this node maximizes information retention and enables endto-end training of the model.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Hybrid Node",
      "text": "Hybrid node implies that the node mixes a variety of features.\n\nIt is consistent with the goal of Multi-graph mentioned in",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Model-Dependent Edge",
      "text": "Model-dependent edge refers to the computation of edges using model parameters. The edges containing model parameters can be dynamically updated with training so that the model can be generalized over different data. Compared to Model-independent edges that are limited by prior knowledge or vector relationships, Model-dependent edge can capture more complex brain region relationships in emotional EEG without manually adjusting when handling different signals.\n\nHowever, additional parameters make it challenging to balance accuracy and computational burden. Model-dependent edge contains four categories, as shown in Table . 3. Parametric edge refers to directly using the model parameter matrix as the edge matrix. As the most direct method of using model parameters, Parametric edge is the most commonly used edge of Model-dependent edge. Parametric edge is updated as follows:\n\nwhere ρ denotes the learning rate. ∂L ∂E refers to the partial derivative of the loss L to E i,j . Weighted edge indicates that the edge matrix can be viewed as the product of the node relationships and the model parameters used as weights. Therefore, the essential meaning of Weighted edge depends on the node relationships. Weighted edge can introduce prior knowledge or vector calculations to constrain the edge by setting it as the node relationships. The weighted edge implementation of existing methods is as follows:\n\nwhere W represents the model parameter utilized as weight. ξ(•) is activation function. f [•, •] denotes the relationship function between nodes. Siam-GCAN  [Zeng et al., 2022]  and DBGC-AFFNet-AFTL  [Sun et al., 2022]  utilize distance between nodes as the relationship function. LR-GCN  [Jin et al., 2021]  and STFCGAT  [Li et al., 2023b]  concatenate any two nodes to perform a linear transformation as the relationship function.\n\nBias edge adding model parameters as bias terms to the node relationships as the edge matrix. It differs from Weighted edge only in the meaning of the parameters. The implementation of Bias edge is as follows:\n\nwhere W represents the model parameter utilized as bias.\n\nMRGCN  [Qiu et al., 2023]  utilizes the calculation of the physical distance between nodes as the relationship function. OGSSL  [Peng et al., 2022a]  applies the similarity between nodes as the relationship function.\n\nSubspace edge denotes the projection of nodes to subspace by parameters to obtain similarity as edges. It is similar in principle to the Attention mechanism and allows the model to capture the complex relationship between every two nodes. However, it adds more model complexity and computational cost than other Model-dependent edges. MD-AGCN  [Li et al., 2021b] , JSCFE  [Peng et al., 2022b] , and ASTG-LSTM  [Li et al., 2021c]  use the following to implement Subspace edge:\n\n) W 1 and W 2 are projection matrices for two nodes.",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "Graph-Level Stage",
      "text": "",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Multi-Graph",
      "text": "Multi-graph allows the model to capture different emotional EEG dependencies simultaneously by concatenating multiple types of graph embedding. Various relational dependencies exist in emotional EEG, such as temporal dependency, frequency dependency, local brain region dependency, etc. The multi-graph structure can learn and consider different dependencies simultaneously, which helps to build relationships in emotional EEG more comprehensively. However, the multistream graph modeling process increases the computational burden. The existing Multi-graph can be subdivided into three categories, as shown in Table . 4. Horizontal&Vertical graph captures both vertical and horizontal spatial dependencies of brain regions. There are dif-",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Graph Baseline",
      "text": "Horizontal&Vertical BiHDM  [Li et al., 2020 ] ERHGCN  [Zheng et al., 2021]  Temporal&Frequency MD-AGCN  [Li et al., 2021b]  HetEmotionNet  [Jia et al., 2021]  DBGC-ATFFNet-AFTL  [Sun et al., 2022]  Local&Global GECNN  [Song et al., 2021b]  HD-  GCN [Ye et al., 2022]  AHGCN  [Xue et al., 2022]  MRGCN  [Qiu et al., 2023]  LGGNet  [Ding et al., 2023]  ferences in the horizontal and vertical connectivity patterns of brain regions so that the Horizon&Vertical structure can model more physiologically plausible spatial dependency. ERHGCN  [Zheng et al., 2021]  and BiHDM  [Li et al., 2020]  both utilize this graph. BiHDM further constructed different horizontal and vertical graphs in the left and right hemispheres based on the existence of imbalance between hemispheres. Temporal&Frequency graph combines the temporal dependency and frequency dependency of the emotional EEG signal. Temporal dependence allows the model to notice amplitude features that are highly correlated with emotion. Frequency dependence encompasses activating the corresponding frequency band in a particular emotion, such as the increase in the α band during the positive emotion. Existing methods MD-AGCN  [Li et al., 2021b] , HetEmotionNet  [Jia et al., 2021] , and DBGC-AFFNet-AFTL  [Sun et al., 2022]  all adopt a similar two-stream structure, where each stream corresponds to the temporal-spatial and frequency-spatial space, and finally graph embedding are concatenated and fed into the classifier. Local&Globle graph combines global dependency between brain regions and local dependency within brain regions. In emotional states, global dependence responds to interactions between brain regions, such as activity in surrounding brain regions caused by activity in specific brain regions. Local dependence focuses on relationships within specific brain regions, e.g., activity within the frontal lobe and cortex is associated with positive emotions. GECNN  [Song et al., 2021b] , HD-GCN  [Ye et al., 2022] ,  AHGCN[Xue et al., 2022] , and\n\nLGGNet  [Ding et al., 2023]  all infer the spatial dependencies of all channels and channels within specific brain regions. Similarly, MRGCN  [Qiu et al., 2023]  introduces short-range and long-range spatial dependencies corresponding to localized intra-region correlations and inter-region correlations.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Hierachical Graph",
      "text": "Hierarchical graph groups channels to allow the model to capture local spatial dependency within specific brain regions. The spatial dependency of emotional EEG consists of interregion and intra-region dependencies. The former corresponds to the region-level synergy between different brain regions under emotion, and the latter corresponds to the neurallevel activity within the brain region associated with a specific emotion, e.g., the frontal cortex and lobe are related to positive emotions. Therefore, the hierarchical graph struc-   MPGCN [Zhao et al., 2022]  MST-GNN  [Liu et al., 2022a ] MDGCN-  SRCNN [Bao et al., 2022]  Predetermined hierarchy R2G-STNN  [Li et al., 2019]  VPR  [Zhang et al., 2020]  V-IAG  [Song et al., 2021a]  HD-  GCN [Ye et al., 2022]  GMSS  [Li et al., 2022b]  LGGNet  [Ding et al., 2023]  ture allows the model to effectively utilize the signal features contained in these local brain regions that are directly related to emotions. The difference with the Local&Globle multigraph structure is that the hierarchical graph structure does not necessarily employ a multi-stream process, thus reducing the computational burden. The existing Hierarchical graph contains two categories, as shown in Table . 5. Dynamic hierarchy graph indicates that the model adaptively groups channels and then infers spatial dependency between groups. There are significant individual differences in emotional EEG between subjects, which implies that different subjects will have subtle differences in brain region correlations during the same emotion. Therefore, dynamic hierarchy can reduce the effect of individual differences.  AHGCN [Xue et al., 2022] , SCC-MPGCN  [Zhao et al., 2022] , and MDGCN-SRCNN  [Bao et al., 2022]  firstly infer channellevel spatial dependency, then implement a trainable weight assignment matrix to assign different electrodes to different brain regions, and finally build region-level spatial graph. MST-GNN  [Liu et al., 2022a]  also implements channel-level dependency first, and then, based on the minimum spanning tree, it starts to search for children nodes with the strongest correlation so that each branch can be regarded as a group. Predetermined hierarchy graph denotes the setting of the brain regions to which the electrodes belong based on existing prior knowledge. Prior knowledge refers to the cytoarchitecture of the brain, i.e., the division of brain regions according to the function. Predetermined hierarchy graph is physiologically reasonable and does not introduce additional computational burden. GMSS  [Li et al., 2022b] , R2G-STNN  [Li et al., 2019] , and VPR  [Zhang et al., 2020]  apply a local-toglobal process. They divide electrodes into multiple regions in advance based on prior knowledge and first infer spatial dependency within regions and then between regions. In contrast, V-IAG  [Song et al., 2021a]  utilizes a global-to-local process. It first infers fully connected spatial dependency and then divides electrode regions and aggregates region-level nodes to construct relationships between regions. HD-GCN  [Ye et al., 2022], and LGGNet [Ding et al., 2023]  adopt the multi-graph structure in Section. 5.1, where local and global dependencies are reasoned in parallel and then concatenated together.",
      "page_start": 5,
      "page_end": 6
    },
    {
      "section_name": "Time Series Graph",
      "text": "Time series graph indicates that the model decomposes the signal into multiple time slices and constructs temporal de-   et al., 2023]  pendency between slices. The temporal dependency of emotional EEG directly reflects the relationship between signal amplitude change and emotion. A high degree of activation within 300ms in the frontal cortex channels is usually associated with positive emotions, while a low degree of activation is usually associated with negative emotions. Therefore, Time series graph enables the model to construct and exploit the spatial and temporal dependencies of emotional EEG. Typically, it is implemented by splitting the input signal into multiple time slices to model spatial graphs within slices and then deriving the temporal dependency between slices by temporal graph or temporal encoder, as shown in Table . 6.\n\nTemporal graph represents the model regards spatial graph embedding of time slices as nodes to construct a temporal graph. CR-GAT  [Liu et al., 2022b]  and  GIGN [Ding and Guan, 2023]  employ a GNN in the temporal dimension to construct a temporal graph by regarding time slices as nodes. MD-AGCN  [Li et al., 2021b]  couples the spatial graphs of all time slices and then takes the average as a temporal graph.\n\nTemporal encoder represents that the model combines GNN and temporal encoder to derive the spatial and temporal dependencies of the emotional EEG. This derivation process is usually divided into two steps; firstly, the GNN is used to infer the spatial dependency within the time slice and update the spatial graph embedding; then, the graph embedding of all the time slices is concatenated together and fed into a temporal encoder.  ST-GCLSTM [Feng et al., 2022] , ASTG-LSTM  [Li et al., 2021c]  and R2G-STNN  [Li et al., 2019]  use LSTM as the temporal encoder. Similarly, HetEmotionNet  [Jia et al., 2021]  uses  GRUs, and EmoGT [Jiang et al., 2023]  utilizes a transformer encoder.",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "Sparse Graph",
      "text": "Sparse graph implies that the graph connectivity relations are sparse. There is a concentration of brain activity in areas directly related to emotion, which means that most connections are weakly associated with emotion. Therefore, specific emotions can be identified by the electrical signals that are active around specific brain regions, such as the frontal cortex and lobe. The sparse graph structure reduces the influence of irrelevant information and retains only the essential connections related to a specific emotion. It differs from the hierarchical structure in that it couples specific groups of channels to achieve fewer connections, whereas the sparse graph structure retains fewer edges by filtering directly on top of the fully connected graph. Existing methods set Threshold or add Sparse weights to the loss function to retain a specific number of edges to form a sparse graph. DAGAM  [Xu et al., 2023]  and SOGNN  [Li et al., 2021a]  set Threshold k to achieve sparsity. DAGAM proposes self-attention graph pooling that regards the Score matrix as the sparse weight matrix and retrains top-k elements to retrain top score edges. SOGNN utilizes a 1 × 2 max pooling layer to retrain top-k edges. SGA-LSTM  [Liu et al., 2019] , and SparseDGCNN  [Zhang et al., 2021]  set Sparse weight to measure the contributions of different channels. The sparse weight is added to the loss to update the edge matrix. The sparsity is achieved when some elements of the edge matrix are close to 0.",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "Future Directions",
      "text": "In this paper, we categorize existing methods from the perspective of three stages of constructing and v t i , while relations between different electrodes across time slice are ignored, such as v t-1 i and v t j . This hetero-electrode relationship across time slice corresponds to a delayed response in the emotional state of the brain, i.e., there is asynchrony in the interaction between brain regions. The existence of delays between specific brain regions and surrounding brain regions for brain region activity elicited by emotional excitation implies that this asynchronous relationship contains information directly related to emotion. Therefore, a more complete temporal dependency constructed by the Temporal fully-connected graph is expected to improve the accuracy of emotion recognition. Graph condensation aims to compress a large and complex graph structure into a simple and compact representation and retain essential emotion-related information. Both coarsening and sparsifying are promising techniques for future EEGbased emotion recognition. Emotional EEG tends to move towards high resolution. Current GNNs in EEG-based emotion recognition utilize fully connected graphs, where nodes usually have an excessive number of neighbors, which provides redundant information and even noise. As the number of electrodes increases, this defect becomes more significant. Therefore, graph condensation techniques can not only improve training efficiency but also weaken the influence of emotionally irrelevant information. The activity of brain regions in emotional states is focused, which implies that the information of specific brain regions is sufficient to identify specific emotions, while most of the connections are emotionally irrelevant. In practice, GNNs in EEG-based emotion recognition are trained to preserve localization. Existing GNNs in this field generally need to run the training process at least once to find the optimal graph condensation, so if the optimal graph is identified earlier, e.g., by training for only a few epochs, then this will significantly increase the running process of GNNs to build emotional representation. Heterogeneous graph can compose different types of entities (i.e., different physiological signals). It can not only provide the graph structure of the data associations but also provide higher-level semantics of the physiological signals.\n\nMost of the current EEG-based emotion recognition datasets contain multiple physiological signals, while the heterogeneous graph is rarely used. Human emotion regulation includes multiple physiological systems, such as the cardiovascular and exocrine systems. Therefore, emotional dependencies exist not only in the interactions between brain regions but also in the activities of multiple physiological systems (organs) regulated by the brain. For example, the correlation between the heart and the striatum region increases when positive emotions are generated; the correlation between the heart and the right prefrontal cortex increases when negative emotions are generated. Heterogeneous graphs can expand the emotional dependencies of specific brain regions with other physiological organs based on the construction of emotional dependencies within the brain. In other words, Heterogeneous graphs benefit from the ability to construct more comprehensive dependencies and become a promising direction for EEG-based emotion recognition. Dynamic graph refers to a graph whose structure changes dynamically over time. It differs from dynamically updated GNNs in EEG-based emotion recognition, meaning the graph structure can be updated automatically as training proceeds. This belongs to model-level dynamic, while the dynamic graph is graph structure-level dynamic. Given dynamic graph G(V, E), V = {(v, t s , t e )} and E = {(e, t s , t e )}. t s and t e are timestamps when edges and nodes appear and disappear. Existing methods reason about the temporal dependency of emotional EEG by cropping time slices and constructing spatial graphs independently. The former indicates that the graph can be updated, and the latter indicates that what the graph represents is the dynamic temporal dependency in emotional EEG. Although temporal graphs or encoders can be used to build temporal dependencies between slices, such dependencies do not incorporate hetero-electrode relations across time slices, i.e., changes of edges across time. In contrast, the dynamic dependency depicted by the dynamic graphs encompasses changes in the edges and, therefore, corresponds to the complete time dependency of the emotional EEG.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Conclusion",
      "text": "Graph neural networks have greatly facilitated the development of EEG-based emotion recognition. This survey provides a comprehensive study of existing GNNs in this field. In-depth discussions and summaries of the reviewed methods are presented, as well as categorization according to the three stages of graph construction. Future directions for GNN design addressing the existing challenges are also proposed. We hope that this survey will provide clear guidance for building GNNs in the field of EEG-based emotion recognition.",
      "page_start": 7,
      "page_end": 7
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Number of GNN-based methods and non-GNN-based",
      "page": 1
    },
    {
      "caption": "Figure 1: , there has been a significant",
      "page": 1
    },
    {
      "caption": "Figure 2: First, the Node-level Stage repre-",
      "page": 2
    },
    {
      "caption": "Figure 2: Unified framework of EEG-based emotion recognition.",
      "page": 2
    },
    {
      "caption": "Figure 3: (a). These two categories are Univariate",
      "page": 2
    },
    {
      "caption": "Figure 3: (b). The sub-",
      "page": 2
    },
    {
      "caption": "Figure 3: (c). Multi-graph indicates",
      "page": 2
    },
    {
      "caption": "Figure 3: An overview of the categorization. The existing method was split into three stages for further categorization. These three steps",
      "page": 3
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Parametric": "Weight",
          "DGCNN [Song et al., 2018]\nSGA-LSTM [Liu et al., 2019]\nGCB-Net [Zhang et al., 2019]\nHD-GCN [Ye et al., 2022]\nAHGCN [Xue et al., 2022]\nGIGN [Ding and Guan, 2023]\nEmoGT [Jiang et al., 2023]": "LR-GCN [Jin et al., 2021]\nSiam-GCAN [Zeng et al., 2022]\nDBGC-ATFFNet-AFTL [Sun et al., 2022]\nSTFCGAT [Li et al., 2023b]"
        },
        {
          "Parametric": "Bias",
          "DGCNN [Song et al., 2018]\nSGA-LSTM [Liu et al., 2019]\nGCB-Net [Zhang et al., 2019]\nHD-GCN [Ye et al., 2022]\nAHGCN [Xue et al., 2022]\nGIGN [Ding and Guan, 2023]\nEmoGT [Jiang et al., 2023]": "OGSSL [Peng et al., 2022a]\nMRGCN [Qiu et al., 2023]"
        },
        {
          "Parametric": "Subspace",
          "DGCNN [Song et al., 2018]\nSGA-LSTM [Liu et al., 2019]\nGCB-Net [Zhang et al., 2019]\nHD-GCN [Ye et al., 2022]\nAHGCN [Xue et al., 2022]\nGIGN [Ding and Guan, 2023]\nEmoGT [Jiang et al., 2023]": "MD-AGCN [Li et al., 2021b]\nASTG-LSTM [Li et al., 2021c]\nJSCFE [Peng et al., 2022b]"
        }
      ],
      "page": 5
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Ding and Guan, 2023] Yi Ding and Cuntai Guan. Gign: Learning graph-in-graph representations of eeg signals for continuous emotion recognition",
      "year": "2021",
      "venue": "2023 45th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)"
    },
    {
      "citation_id": "2",
      "title": "Hetemotionnet: two-stream heterogeneous graph recurrent neural network for multi-modal emotion recognition",
      "authors": [
        "Du"
      ],
      "year": "2021",
      "venue": "2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)"
    },
    {
      "citation_id": "3",
      "title": "From regional to global brain: A novel hierarchical spatial-temporal neural network model for eeg emotion recognition",
      "authors": [
        "Li"
      ],
      "year": "2019",
      "venue": "IEEE Transactions on Cognitive and Developmental Systems"
    },
    {
      "citation_id": "4",
      "title": "Cross-subject eeg emotion recognition with selforganized graph neural network",
      "authors": [
        "Li"
      ],
      "year": "2021",
      "venue": "Frontiers in Neuroscience"
    },
    {
      "citation_id": "5",
      "title": "A multi-domain adaptive graph convolutional network for eeg-based emotion recognition",
      "authors": [
        "Li"
      ],
      "year": "2021",
      "venue": "Proceedings of the 29th ACM International Conference on Multimedia"
    },
    {
      "citation_id": "6",
      "title": "Attention-based spatiotemporal graphic lstm for eeg emotion recognition",
      "authors": [
        "Li"
      ],
      "year": "2021",
      "venue": "2021 International Joint Conference on Neural Networks (IJCNN)"
    },
    {
      "citation_id": "7",
      "title": "Semi-supervised eeg emotion recognition model based on enhanced graph fusion and gcn",
      "authors": [
        "Li"
      ],
      "year": "2022",
      "venue": "Journal of Neural Engineering"
    },
    {
      "citation_id": "8",
      "title": "Eeg-based emotion recognition using trainable adjacency relation driven graph convolutional network",
      "authors": [
        "Li"
      ],
      "year": "2022",
      "venue": "IEEE Transactions on Cognitive and Developmental Systems"
    },
    {
      "citation_id": "9",
      "title": "Emotion recognition using spatial-temporal eeg features through convolutional graph attention network",
      "authors": [
        "Li"
      ],
      "year": "2023",
      "venue": "Journal of Neural Engineering"
    },
    {
      "citation_id": "10",
      "title": "Minimum spanning tree based graph neural network for emotion classification using eeg",
      "authors": [
        "Liu"
      ],
      "year": "2019",
      "venue": "International Conference on Neural Information Processing"
    },
    {
      "citation_id": "11",
      "title": "Emotion downregulation targets interoceptive brain regions while emotion upregulation targets other affective brain regions",
      "authors": [
        "Liu"
      ],
      "year": "2022",
      "venue": "2022 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)"
    },
    {
      "citation_id": "12",
      "title": "Ogssl: A semi-supervised classification model coupled with optimal graph learning for eeg emotion recognition",
      "authors": [
        "Peng"
      ],
      "year": "2022",
      "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering"
    },
    {
      "citation_id": "13",
      "title": "Crosssession emotion recognition by joint label-common and label-specific eeg features exploration",
      "authors": [
        "Peng"
      ],
      "year": "2022",
      "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering"
    },
    {
      "citation_id": "14",
      "title": "A multi-head residual connection gcn for eeg emotion recognition",
      "authors": [
        "Qiu"
      ],
      "year": "2023",
      "venue": "Computers in Biology and Medicine"
    },
    {
      "citation_id": "15",
      "title": "Neurophysiological architecture of functional magnetic resonance images of human brain",
      "year": "2005",
      "venue": "Cerebral cortex"
    },
    {
      "citation_id": "16",
      "title": "Eeg emotion recognition using dynamical graph convolutional neural networks",
      "authors": [
        "Song"
      ],
      "year": "2018",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "17",
      "title": "Graph-embedded convolutional neural network for image-based eeg emotion recognition",
      "authors": [
        "Song"
      ],
      "year": "2021",
      "venue": "IEEE Transactions on Emerging Topics in Computing"
    },
    {
      "citation_id": "18",
      "title": "A dual-branch dynamic graph convolution based adaptive transformer feature fusion network for eeg emotion recognition",
      "authors": [
        "Sun"
      ],
      "year": "2022",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "19",
      "title": "Hierarchical dynamic graph convolutional network with interpretability for eeg-based emotion recognition",
      "authors": [
        "Xu"
      ],
      "year": "2022",
      "venue": "2022 International Joint Conference on Neural Networks (IJCNN)"
    },
    {
      "citation_id": "20",
      "title": "Siam-gcan: a siamese graph convolutional attention network for eeg emotion recognition",
      "authors": [
        "Zeng"
      ],
      "year": "2019",
      "venue": "IEEE Transactions on Instrumentation and Measurement"
    },
    {
      "citation_id": "21",
      "title": "Variational pathway reasoning for eeg emotion recognition",
      "authors": [
        "Zhang"
      ],
      "year": "2020",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence"
    },
    {
      "citation_id": "22",
      "title": "Scc-mpgcn: Self-attention coherence clustering based on multi-pooling graph convolutional network for eeg emotion recognition",
      "authors": [
        "Zhang"
      ],
      "year": "2015",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "23",
      "title": "Eeg-based emotion recognition using regularized graph neural networks",
      "authors": [
        "Zheng"
      ],
      "year": "2020",
      "venue": "2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)"
    }
  ]
}