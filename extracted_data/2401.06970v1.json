{
  "paper_id": "2401.06970v1",
  "title": "Temporalaugmenter: An Ensemble Recurrent Based Deep Learning Approach For Signal Classification",
  "published": "2024-01-13T03:53:47Z",
  "authors": [
    "Nelly Elsayed",
    "Constantinos L. Zekios",
    "Navid Asadizanjani",
    "Zag ElSayed"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Ensemble modeling has been widely used to solve complex problems as it helps to improve overall performance and generalization. In this paper, we propose a novel TemporalAugmenter approach based on ensemble modeling for augmenting the temporal information capturing for long-term and short-term dependencies in data integration of two variations of recurrent neural networks in two learning streams to obtain the maximum possible temporal extraction. Thus, the proposed model augments the extraction of temporal dependencies. In addition, the proposed approach reduces the preprocessing and prior stages of feature extraction, which reduces the required energy to process the models built upon the proposed TemporalAugmenter approach, contributing towards green AI. Moreover, the proposed model can be simply integrated into various domains including industrial, medical, and human-computer interaction applications. Our proposed approach empirically evaluated the speech emotion recognition, electrocardiogram signal, and signal quality examination tasks as three different signals with varying complexity and different temporal dependency features. Ensemble modeling is one of the solutions to overcome the model overfitting and improve the model performance by integrating multiple individual learning steams to create a robust and accurate predictive model, especially for complex tasks  (Ganaie et al. 2022; Sagi and Rokach 2018) . The ensemble modeling concept improves the overall model generalization, robustness, and stability and improves the overall model accuracy (",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Hassan And Verma 2007).",
      "text": "There are different types of data depending on the primary source of data capturing, including discrete and sequential datasets  (Dietterich 2002; Chmielewski and Grzymala-Busse 1996) . The sequential data can be categorized into temporal data, where data points are collected, observed, and recorded at the same specific time intervals (e.g., videos, voice recording, time series, biological signal), and sequential (non-temporal) data that involves sequences where the order is significant. However, the observation time is not considered (e.g., text data, ordered events, and DNA sequences). The temporal data is complex due to the temporal information and the point-in-time information that the learning model must capture to perform the required task on the data. Thus, not all traditional learning models can solve temporal data based problems and tasks. Recurrent neural based architectures are the most suitable for capturing the temporal dependency information carried in the temporal data. There are several recurrent neural network based architectures such as the recurrent neural network (RNN) long short-term memory (LSTM) and its different variants  (Greff et al. 2017; Elsayed, ElSayed, and Maida 2022; Gers, Schraudolph, and Schmidhuber 2002) , the gated recurrent unit (GRU) and different variants  (Chung et al. 2014; Dey and Salem 2017) , the LiteLSTM  (Elsayed, ElSayed, and Maida 2023) , and the minimal gated unit MGU  (Zhou et al. 2016) . Each recurrent based network has its strengthes in capturing the long-term or short-term temporal dependencies. However, with the complex data, they require additional preprocessing or support for feature extracting to enhance the overall performance of capturing the point-totime information.\n\nThus, in this paper, we propose a novel ensemble approach for augmenting the temporal information in temporal data based long-term and short-term dependencies capturing architectures: long short-term memory (LSTM) and the gated recurrent unit (GRU) in two streams that are capable of improving the overall performance. Moreover, we performed an empirical investigation of the influence of the convolutional neural network as a feature extractor prior to short-term temporal dependencies capturing architecture on improving the model performance; in addition, it eliminates the requirement of the data preprocessing stage. Finally, we employed the proposed approach on three different temporal tasks from different data sources and varied complexity, including speech emotion recognition, electrocardiogram clas-",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Temporal Augmenter Ensemble Approach",
      "text": "The proposed temporal augmenter approach is shown in Fig.  1    (Elsayed, ElSayed, and Maida 2022) . The proposed approach consists of two stacked streams. The first stream employs a recurrent neural network architecture that is capable of extracting and learning the long-term temporal dependencies in the data. The second stream employs the recurrent neural network architecture that is capable of extracting and learning the short-term dependencies in the data. Adding one convolutional layer before each recurrent stream would improve the spatial features from the data, contributing to improving the overall approach performance at both temporal and spatial dependencies extraction and learning. Integrating the convolutional layer recurrent architectures has shown empirically and overall higher performance in several 1D applications including  (Elsayed et al. 2022; Pan et al. 2020; Sajjad et al. 2020; Elsayed, ElSayed, and Bayoumi 2023) . In this proposed approach, we empirically found that the optimal integration between the temporal dependencies extraction in the recurrent model and the convolution neural network (CNN) can be found while using the CNN as only one layer for extracting features prior to the recurrent network. Thus, the proposed approach reduces the required computations for the preprocessing of the signal due to the capability of the one-layer CNN to extract sufficient features, eliminating the requirements of signal preprocessing.\n\nFor the long-term dependency learning stream, in this approach, we employ the long short-term memory (LSTM) architecture as the main component for long-term dependency learning  (Greff et al. 2016) . The memory cell of the LSTM provided the capability of memorizing the long-term dependencies due to maintaining the long-term dependencies information in the learning stream. By reflecting the forget gate in the memory cell, the memory maintains the time dependencies that have long-term effects through the time in the memory, leading the LSTM to maintain a robust memorization of long-term dependencies from the data.\n\nFor the short-term dependencies learning stream, we selected the gated recurrent unit (GRU) as the primary component to learn the short-term dependencies in the data. The GRU is a smaller recurrent neural network architecture that consists of two gates: update z and reset gates r  (Greff et al. 2017) . The main concept was to share the weights between two gates at the LSTM (input and forget) gates into one update gate and remove the memory cell to produce a smaller budget recurrent architecture that can be employed in applications where the sequences are small (e.g., short-term dependencies)  (Chung et al. 2014 ). In addition, the GRU eliminates the output squashing function and the constant error carrocel (CEC) compared to the LSTM  (Chung et al. 2014; Elsayed, ElSayed, and Maida 2023) . The reset gate in the GRU maps the output gate of the LSTM. Thus, the GRU requires less budget to implement compared to the LSTM, and it is capable of learning short-term dependencies efficiently. Thus, the GRU has shown significant results and outperformed the LSTM in several applications where the time dependency in the data is short-term, such as  (Shen et al. 2018; Elsayed, Maida, and   Models that are based on our proposed TemporalAugmenter approach aim to employ both the LSTM as the longterm dependencies learning architecture with the GRU as a short-term dependencies learner into a model that is capable of capturing the long-term dependencies in temporal data as well as the short-term dependencies. Thus, the proposed TemporalAugmenter approach-based model can exceed the state-of-the-art models in multiple applications with different temporal data sources.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Experiments Setup",
      "text": "In our experiment, we targeted three different tasks: speech emotion recognition, electrocardiogram (ECG or EKG) classification, and radar signal quality classification tasks. These tasks are based on three different source of temporal data that vary in complexity and features behavior through time.\n\nIn our experiments, we implemented the models based on the proposed TemporalAugmenter approach. Figure  2  shows the model layers and order, which has been implemented based on the proposed TemporalAugmenter ensemble approach. The major differences between the experiments are in the number of epochs, batch size, optimization function, input size, and the number of classification categories. For the implementation, we used a computer with an Intel(R) Core(TM) i-9 CPU @ 3.00 GHz processor with 32-GB memory and NVIDIA GeForce RTX 2080 Ti graphics card. For the implementation, we used Tensorflow 2.4.0, Numpy 1.19.5, Pandas 1.2.4, Librosa 0.9.1, and Python 3.3.8 on a Windows 10 OS computer.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Task I: Speech Emotion Recognition Dataset Description",
      "text": "In this task, we used audio-based speech emotion datasets, and we implemented the models to use the audio data di- rectly without any mapping to spectrograms or assigning images or videos with the data. Thus, the proposed Tem-poralAugmenter approach aims to capture the temporal and spatial features from the spoken speech to determine the individual's emotions during the speech. We used the Toronto Emotional Speech Set (TESS) dataset benchmark  (Dupuis and Pichora-Fuller 2010) . This data was recorded in the Toronto area by two actresses who have English as their first spoken language. This dataset consists of 2800 stimuli that represent seven different emotion categories. These emotions are anger, disgust, fear, happiness, surprise/pleasant, sadness, and neutral. The major advantage of this dataset is that the dataset is balanced between the number of stimuli among each of the seven classes.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Results And Analysis",
      "text": "In this experiment, the data was split to train, validate, and test with a ratio of 70%:10%:20%, respectively. The data has been scaled using standardscaler  (Nabi and Nabi 2016) . The short-term dependency stream 1D CNN that has 128 kernels of size one and the he uniform function function as the ker-  nel initializer. Then, the GRU number of units is set to 10, with glorot uniform function as the kernel initializer. The long-term dependency stream started with a similar 1D CNN followed by the LSTM that has ten units, and the kernel initialization function is glorot uniform and orthogonal function as the recurrent initializer. Then, the two streams concatenated, followed by two dense layers of 64 and 32, units with the rectified linear unit (ReLU)  (Teh and Hinton 2000; Elsayed, Maida, and Bayoumi 2018b)  as the activation functions. For training the model, the batch size has been set to 32 and the number of epochs to 20. RMSProp has been used as the optimization function with learning rate lr = 0.001, momentum = 0.0, and ϵ = 1e -07. The categorical cross-  entropy is set as the loss function. Max pooling and dropouts have been applied in both the long-term and short-term dependency streams. Fig.  3  shows the proposed model training versus validation accuracy and loss. Table  1  shows the proposed model's overall statistics over the TESS dataset.\n\nTable  2  shows the statistics of the model over each of the seven emotions, where (OP) and (AUC) are the areas under the Receiver Operating Characteristic (ROC) curve. Table  3  compares the proposed model and the state-of-the-art speech emotion recognition models over the TESS dataset.   including normal heart beat (N), supraventricular premature beat (S), premature ventricular contraction (V), fusion of paced and normal beat (F), and unclassifiable beat (Q).",
      "page_start": 4,
      "page_end": 6
    },
    {
      "section_name": "Results And Analysis",
      "text": "For the experiment, we divided into training, validation, and testing by the ratio 60%, 20%, and 20%, respectively. The batch size is set to 128, and the number of epochs to 50. The first ratio of dropout layers at the long-term and shortterm steams was set to 50%, maintaining the rest at the 30% ratio. Adam optimizer been used with learning rate lr = 0.001, and ϵ = 1e -07. The proposed model training versus validation accuracy and loss diagrams are shown in Figure  4 . Table  4  shows the proposed model's overall statistics over the MIT-BIH dataset. Table  5  shows the statistics of the model over each of the five ECG categories. Table  6  compares the proposed model and the state-of-the-art classification models over the MIT-BIH dataset.\n\nTask III: Radar Signal Quality Classification",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Dataset Description",
      "text": "In this experiment, we used the Ionosphere Depletion dataset benchmark collected by a Goose Bay system to evaluate the Ionosphere. The dataset consists of 351 data samples. The pulse numbers of the Good Bay system were 17. Each data sample in the dataset is described by two attributes per pulse number, corresponding to the complex values returned by the function resulting from the complex electromagnetic signal. Thus, the total number of attributes is 34. The data consists of two categories, bad signal and good signal, which are decoded to zero and one in the implementation. The dataset is unbalanced.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Results And Analysis",
      "text": "In this experiment, we split the data to train, validate, and test the dataset with ratios 60%, 20%, and 20%, respectively. The Adam optimizer has been used with a learning rate lr = 0.001, and ϵ = 1e -07.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Conclusion And Social Impact",
      "text": "Manipulating temporal data requires robust methodologies that can capture both temporal and point-to-time information. Several applications are based on classifying temporal data, such as biosignals classification for diagnostics, speech emotion recognition, stock market prediction, energy consumption, time series anomaly detection, and radar signal classification. This paper proposed a simple ensemble based approach, TemporalAugmenter, based on integrating longterm and short-term dependency learning streams to capture precise temporal dependencies in temporal data. In addition, we found empirically that one convolutional layer prior to a recurrent architecture can help enhance the model performance. Furthermore, the proposed approach can be used directly without extracting additional features, preprocessing, or converting the signal to spectrograms, which reduces the power and energy required for model implementation, contributing towards green AI and reducing CO 2 footprint. Thus, models that are based on the proposed TemporalAugmenter approach can be implemented within different temporal data based application domains.",
      "page_start": 6,
      "page_end": 6
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: The proposed ensemble TemporalAugmenter approach for both long-term and short-term dependencies capturing in",
      "page": 2
    },
    {
      "caption": "Figure 2: The proposed model based on the TemporalAug-",
      "page": 2
    },
    {
      "caption": "Figure 1: (Elsayed, ElSayed, and Maida 2022). The proposed",
      "page": 2
    },
    {
      "caption": "Figure 3: The proposed TemporalAugmenter approach train-",
      "page": 3
    },
    {
      "caption": "Figure 2: shows the model layers and order, which has been imple-",
      "page": 3
    },
    {
      "caption": "Figure 4: The proposed TemporalAugmenter approach train-",
      "page": 4
    },
    {
      "caption": "Figure 5: The proposed TemporalAugmenter approach train-",
      "page": 5
    },
    {
      "caption": "Figure 3: shows the proposed model train-",
      "page": 5
    },
    {
      "caption": "Figure 4: Table 4 shows the proposed model’s overall statis-",
      "page": 6
    }
  ],
  "tables": [
    {
      "caption": "Table 1: The proposed model overall statistics for speech",
      "data": [
        {
          "Merits": "95% CI\nAccuracy\nF1 Score\nFalse Negative Rate\nFalse Positive Rate\nTrue Negative Rate\nTrue Positve Rate\nKappa\nKappa 95% CI\nKappa Standard Error\nTotal params\nTrainable params\nNon-trainable params",
          "Value": "(0.9783,0.9967)\n99.64%\n0.9875\n0.0125\n0.00208\n0.99792\n0.9875\n0.9854\n(0.97465,0.99615)\n0.00548\n8,027,819\n8,027,819\n0"
        }
      ],
      "page": 3
    },
    {
      "caption": "Table 3: Comparison between the proposed model and the",
      "data": [
        {
          "Statistical\nAnalysis": "",
          "Emotion Category": "Angry\nDisgust\nFear\nHappiness\nSurprise\nSadness\nNeutral"
        },
        {
          "Statistical\nAnalysis": "Accuracy\nF1 Score\nAUC\nError rate\nFalse Negative Rate\nFalse Positive Rate\nSpecificity\nSensitivity",
          "Emotion Category": "100%\n99.643%\n99.464%\n99.821%\n99.643%\n99.286%\n99.643%\n1.0\n0.9878\n0.97902\n0.99355\n0.9875\n0.97826\n0.98571\n1.0\n0.99286\n0.97945\n0.99359\n0.99792\n0.99131\n0.99184\n0.0\n0.00357\n0.00536\n0.00179\n0.00357\n0.00714\n0.00357\n0.0\n0.0122\n0.0411\n0.01282\n0.0\n0.01099\n0.01429\n0.0\n0.00209\n0.0\n0.0\n0.00416\n0.0064\n0.00204\n1.0\n0.99791\n1.0\n1.0\n0.99584\n0.9936\n0.99796\n1.0\n0.9878\n0.9589\n0.98718\n1.0\n0.98901\n0.98571"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table 3: Comparison between the proposed model and the",
      "data": [
        {
          "Model": "(Venkataramanan\nand\nRa-\njamohan 2019)",
          "Method": "Combining 2D CNN and Global\nAvg. Pooling",
          "Acc.": "66.00%"
        },
        {
          "Model": "(Sundarprasad 2018)",
          "Method": "Combining\nPCA,\nSVM, Mel-\nFrequeny,\nand Cepstrum Fea-\ntures",
          "Acc.": "90.00%"
        },
        {
          "Model": "(Krishnan,\nJoseph Raj,\nand\nRajangam 2021)",
          "Method": "SoA\nClasssifier\nand\nEntropy\nFeatures\nfrom Principle\nIMF\nmodes",
          "Acc.": "93.30%"
        },
        {
          "Model": "(Lotfidereshgi\nand Gournay\n2017)",
          "Method": "Liquid State Machine",
          "Acc.": "82.35%"
        },
        {
          "Model": "(Zhang, Zhao, and Lei 2013)",
          "Method": "Kernel Isomap",
          "Acc.": "80.85%"
        },
        {
          "Model": "(Zhang, Zhao, and Lei 2013)",
          "Method": "PCA",
          "Acc.": "72.35%"
        },
        {
          "Model": "(Bhargava and Polzehl 2013)",
          "Method": "Artificial Neural Nets",
          "Acc.": "80.600%"
        },
        {
          "Model": "(Bhargava and Polzehl 2013)",
          "Method": "SVM",
          "Acc.": "80.270%"
        },
        {
          "Model": "(Elsayed et al. 2022)",
          "Method": "1DCNN and GRU",
          "Acc.": "94.285%"
        },
        {
          "Model": "(Parry et al. 2019)",
          "Method": "CNN and LSTM",
          "Acc.": "49.48%"
        },
        {
          "Model": "(Zhao, Mao, and Chen 2019)",
          "Method": "2D-CNN and LSTM",
          "Acc.": "70.00%"
        },
        {
          "Model": "Our",
          "Method": "TemporalAugmenter",
          "Acc.": "98.75%"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table 3: Comparison between the proposed model and the",
      "data": [
        {
          "Merits": "95% CI\nAccuracy\nF1 Score\nFalse Negative Rate\nFalse Positive Rate\nTrue Negative Rate\nTrue Positve Rate\nKappa\nKappa 95% CI\nKappa Standard Error\nTotal params\nTrainable params\nNon-trainable params",
          "Value": "(0.98293,0.98619)\n98.456%\n0.98456\n0.01544\n0.00208\n0.99614\n0.00386\n0.98456\n(0.94317,0.95404)\n0.00277\n52,073\n52,073\n0"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table 6: Comparison between the proposed model and the Table7:TheproposedmodeloverallstatisticsfortheRadar",
      "data": [
        {
          "Statistical\nAnalysis": "",
          "ECG Category": "N\nS\nV\nF\nQ"
        },
        {
          "Statistical\nAnalysis": "Accuracy\nF1 Score\nAUC\nError rate\nFalse Negative Rate\nFalse Positive Rate\nSpecificity\nSensitivity",
          "ECG Category": "98.726%\n99.287%\n99.415%\n99.694%\n99.79%\n0.99232\n0.84942\n0.95586\n0.77888\n0.9856\n0.97164\n0.89475\n0.97698\n0.86367\n0.98913\n0.01274\n0.00713\n0.00585\n0.00306\n0.0021\n0.00453\n0.20863\n0.04282\n0.2716\n0.02114\n0.0522\n0.00187\n0.00323\n0.00106\n0.00059\n0.9478\n0.99813\n0.99677\n0.99894\n0.99941\n0.99547\n0.79137\n0.95718\n0.7284\n0.97886"
        }
      ],
      "page": 5
    },
    {
      "caption": "Table 6: Comparison between the proposed model and the Table7:TheproposedmodeloverallstatisticsfortheRadar",
      "data": [
        {
          "Merits": "95% CI\nAccuracy\nF1 Score\nFalse Negative Rate\nFalse Positive Rate\nTrue Negative Rate\nTrue Positve Rate\nKappa\nKappa 95% CI\nKappa Standard Error\nTotal params\nTrainable params\nNon-trainable params",
          "Value": "(0.91095, 1.0)\n95.775%\n0.95775\n0.04225\n0.04225\n0.95775\n0.95775\n0.90839\n(0.80693,1.00)\n0.05176\n21,214\n21,214\n0"
        }
      ],
      "page": 5
    },
    {
      "caption": "Table 6: Comparison between the proposed model and the Table7:TheproposedmodeloverallstatisticsfortheRadar",
      "data": [
        {
          "Model": "(Martis et al. 2013a)",
          "Method": "DWT and SVM",
          "Acc.": "93.8%"
        },
        {
          "Model": "(Elsayed and Zaghloul 2020)",
          "Method": "DWT and Random Forest",
          "Acc.": "94.6%"
        },
        {
          "Model": "(Asl,\nSetarehdan,\nand Mo-\nhebbi 2008)",
          "Method": "DWT and LDA and RR",
          "Acc.": "94.2%"
        },
        {
          "Model": "(Osowski and Linh 2001)",
          "Method": "Hybrid fuzzy NN",
          "Acc.": "96.1%"
        },
        {
          "Model": "(Acharya et al. 2017)",
          "Method": "CNN and Augmentation",
          "Acc.": "93.5%"
        },
        {
          "Model": "(Kachuee,\nFazeli,\nand\nSar-\nrafzadeh 2018)",
          "Method": "Deep residual CNN",
          "Acc.": "93.4%"
        },
        {
          "Model": "(Elsayed and Zaghloul 2020)",
          "Method": "ELM",
          "Acc.": "96.4%"
        },
        {
          "Model": "(Martis et al. 2013b)",
          "Method": "SVM with RBF Kernel",
          "Acc.": "93.5%"
        },
        {
          "Model": "(Zhou, Jin, and Dong 2017)",
          "Method": "CNN and LSTM",
          "Acc.": "98.03%"
        },
        {
          "Model": "(Acharya et al. 2017)",
          "Method": "Daubechies Wavelet",
          "Acc.": "94.3%"
        },
        {
          "Model": "Our",
          "Method": "TemporalAugmenter",
          "Acc.": "98.45%"
        }
      ],
      "page": 5
    },
    {
      "caption": "Table 6: Comparison between the proposed model and the Table7:TheproposedmodeloverallstatisticsfortheRadar",
      "data": [
        {
          "Statistical\nAnalysis": "",
          "Radar Signal Category": "Class 0\nClass 1"
        },
        {
          "Statistical\nAnalysis": "Accuracy\nF1 Score\nAUC\nError rate\nFalse Negative Rate\nFalse Positive Rate\nSpecificity\nSensitivity",
          "Radar Signal Category": "0.95775\n0.95775\n0.96703\n0.94118\n0.94444\n0.94444\n0.04225\n0.04225\n0.0\n0.11111\n0.11111\n0.0\n0.88889\n1.0\n1.0\n0.88889"
        }
      ],
      "page": 5
    },
    {
      "caption": "Table 9: Comparison between the proposed model and",
      "data": [
        {
          "Model": "(Basheer et al. 2024)",
          "Method": "AADS",
          "Acc.": "76.13%"
        },
        {
          "Model": "(Basheer et al. 2024)",
          "Method": "Streaming TEDA",
          "Acc.": "52.38%"
        },
        {
          "Model": "(Basheer et al. 2024)",
          "Method": "MAD",
          "Acc.": "22.35%"
        },
        {
          "Model": "(Basheer et al. 2024)",
          "Method": "xStream",
          "Acc.": "21.38%"
        },
        {
          "Model": "(Basheer et al. 2024)",
          "Method": "RRCF",
          "Acc.": "12.65%"
        },
        {
          "Model": "(Sigillito et al. 1989)\n(Sigillito et al. 1989)",
          "Method": "linear perceptron\nMLFN",
          "Acc.": "90.67%\n83.8%"
        },
        {
          "Model": "Our",
          "Method": "TemporalAugmenter",
          "Acc.": "95.775%"
        }
      ],
      "page": 6
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "A deep convolutional neural network model to classify heartbeats",
      "authors": [
        "U Acharya",
        "S Oh",
        "Y Hagiwara",
        "J Tan",
        "M Adam",
        "A Gertych",
        "R And San Tan",
        "V Adewopo",
        "N Elsayed"
      ],
      "year": "2017",
      "venue": "Smart city transportation: Deep learning ensemble approach for traffic accident detection",
      "arxiv": "arXiv:2310.10038"
    },
    {
      "citation_id": "2",
      "title": "Ensemble-learning framework for intrusion detection to enhance internet of things' devices security",
      "year": "2017",
      "venue": "Machine Learning with Applications"
    },
    {
      "citation_id": "3",
      "title": "Ensemble of averages: Improving model selection and boosting performance in domain generalization",
      "authors": [
        "Arpit"
      ],
      "year": "2022",
      "venue": "Neural Information Processing Systems"
    },
    {
      "citation_id": "4",
      "title": "Support vector machine-based arrhythmia classification using reduced features of heart rate variability signal",
      "authors": [
        "Setarehdan Asl",
        "B Mohebbi ; Asl",
        "S Setarehdan",
        "M Mohebbi"
      ],
      "year": "2008",
      "venue": "Artificial intelligence in medicine"
    },
    {
      "citation_id": "5",
      "title": "Improving automatic emotion recognition from speech using rhythm and temporal feature",
      "authors": [
        "Basheer"
      ],
      "year": "2013",
      "venue": "Knowledge-Based Systems",
      "arxiv": "arXiv:1303.1761"
    },
    {
      "citation_id": "6",
      "title": "Global discretization of continuous attributes as preprocessing for machine learning",
      "authors": [
        "J Brownlee",
        "Grzymala-Busse ; Chmielewski",
        "M Chmielewski",
        "J Grzymala-Busse",
        "Chung"
      ],
      "year": "1994",
      "venue": "Structural, Syntactic, and Statistical Pattern Recognition: Joint IAPR International Workshops SSPR 2002 and SPR",
      "arxiv": "arXiv:1412.3555"
    },
    {
      "citation_id": "7",
      "title": "A simple extreme learning machine model for detecting heart arrhythmia in the electrocardiography signal",
      "authors": [
        "Pichora-Fuller ; Dupuis",
        "K Dupuis",
        "M Pichora-Fuller",
        "N Elsayed",
        "Z Zaghloul",
        "N Elsayed",
        "Z Elsayed",
        "N Asadizanjani",
        "M Ozer",
        "A Abdelgawad",
        "M Bayoumi"
      ],
      "year": "2010",
      "venue": "2020 IEEE 63rd International Midwest Symposium on Circuits and Systems (MWSCAS)",
      "arxiv": "arXiv:2302.02013"
    },
    {
      "citation_id": "8",
      "title": "Litelstm architecture for deep recurrent neural networks",
      "authors": [
        "Elsayed Elsayed",
        "Maida Elsayed",
        "N Elsayed",
        "Z Maida",
        "A Elsayed",
        "N Elsayed",
        "Z Maida"
      ],
      "year": "2022",
      "venue": "Litelstm architecture based on weights sharing for recurrent neural networks",
      "arxiv": "arXiv:2301.04794"
    },
    {
      "citation_id": "9",
      "title": "Deep gated recurrent and convolutional network hybrid model for univariate time series classification",
      "authors": [
        "Maida Elsayed",
        "N Bayoumi ; Elsayed",
        "A Maida",
        "M Bayoumi",
        "Maida Elsayed",
        "N Bayoumi ; Elsayed",
        "A Maida",
        "M Bayoumi"
      ],
      "year": "2018",
      "venue": "2018 IEEE 30th International Conference on Tools with Artificial Intelligence (ICTAI)",
      "arxiv": "arXiv:1812.07683"
    },
    {
      "citation_id": "10",
      "title": "Gated recurrent neural networks empirical utilization for time series classification",
      "authors": [
        "Maida Elsayed",
        "N Bayoumi ; Elsayed",
        "A Maida",
        "M Bayoumi"
      ],
      "year": "2019",
      "venue": "2019 International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber"
    },
    {
      "citation_id": "11",
      "title": "Arrhythmia supraventricular premature beat detection in electrocardiography signal using deep gated recurrent model",
      "authors": [
        "Zaghloul Elsayed",
        "N Li ; Elsayed",
        "Z Zaghloul",
        "C Li",
        "A Ferreira",
        "M Figueiredo",
        "M Galar",
        "A Fernandez",
        "E Barrenechea",
        "H Bustince",
        "F Herrera"
      ],
      "year": "2011",
      "venue": "SoutheastCon 2021"
    },
    {
      "citation_id": "12",
      "title": "Ensemble deep learning: A review",
      "authors": [
        "Ganaie"
      ],
      "year": "2022",
      "venue": "Engineering Applications of Artificial Intelligence"
    },
    {
      "citation_id": "13",
      "title": "Gated recurrent unit-based heart sound analysis for heart failure screening",
      "authors": [
        "Zheng Gao",
        "S Guo ; Gao",
        "Y Zheng",
        "X Guo"
      ],
      "year": "2020",
      "venue": "Biomedical engineering online"
    },
    {
      "citation_id": "14",
      "title": "Learning precise timing with lstm recurrent networks",
      "authors": [
        "Schraudolph Gers",
        "F Schmidhuber ; Gers",
        "N Schraudolph",
        "J Schmidhuber",
        "M Golmohammadi",
        "S Ziyabari",
        "V Shah",
        "E Von Weltin",
        "C Campbell",
        "I Obeid",
        "J Picone",
        "K Greff",
        "R Srivastava",
        "J Koutník",
        "B Steunebrink",
        "J Schmidhuber"
      ],
      "year": "2002",
      "venue": "IEEE Signal Processing in Medicine and Biology Symposium (SPMB)"
    },
    {
      "citation_id": "15",
      "title": "LSTM: A search space odyssey",
      "authors": [
        "Greff"
      ],
      "year": "2017",
      "venue": "IEEE Transactions on Neural Networks and Learning Systems"
    },
    {
      "citation_id": "16",
      "title": "Gan ensemble for anomaly detection",
      "authors": [
        "Chen Han",
        "X Liu ; Han",
        "X Chen",
        "L.-P Liu"
      ],
      "year": "2021",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence"
    },
    {
      "citation_id": "17",
      "title": "Evaluation of gated recurrent neural networks in music classification tasks",
      "authors": [
        "Hassan",
        "S Verma ; Hassan",
        "B Verma",
        "J Jakubik"
      ],
      "year": "2007",
      "venue": "Information Systems Architecture and Technology: Proceedings of 38th International Conference on Information Systems Architecture and Technology-ISAT 2017: Part I"
    },
    {
      "citation_id": "18",
      "title": "A review of hybrid and ensemble in deep learning for natural language processing",
      "authors": [
        "Liang Jia",
        "J Liang ; Jia",
        "W Liang",
        "Y Liang"
      ],
      "year": "2023",
      "venue": "A review of hybrid and ensemble in deep learning for natural language processing",
      "arxiv": "arXiv:2312.05589"
    },
    {
      "citation_id": "19",
      "title": "Ecg heartbeat classification: A deep transferable representation",
      "authors": [
        "Fazeli Kachuee",
        "M Sarrafzadeh ; Kachuee",
        "S Fazeli",
        "M Sarrafzadeh"
      ],
      "year": "2018",
      "venue": "2018 IEEE international conference on healthcare informatics (ICHI)"
    },
    {
      "citation_id": "20",
      "title": "Insights into lstm fully convolutional networks for time series classification",
      "authors": [
        "Majumdar Karim",
        "F Darabi ; Karim",
        "S Majumdar",
        "H Darabi"
      ],
      "year": "2019",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "21",
      "title": "Neural network ensemble operators for time series forecasting",
      "authors": [
        "Barrow Kourentzes",
        "N Crone ; Kourentzes",
        "D Barrow",
        "S Crone"
      ],
      "year": "2014",
      "venue": "Expert Systems with Applications"
    },
    {
      "citation_id": "22",
      "title": "Emotion classification from speech signal based on empirical mode decomposition and non-linear features: Speech emotion recognition",
      "authors": [
        "Joseph Krishnan",
        "Raj",
        "P Rajangam ; Krishnan",
        "A Joseph Raj",
        "V Rajangam"
      ],
      "year": "2021",
      "venue": "Complex & Intelligent Systems"
    },
    {
      "citation_id": "23",
      "title": "Ensembles of natural language processing systems for portable phenotyping solutions",
      "authors": [
        "Liu"
      ],
      "year": "2019",
      "venue": "Journal of biomedical informatics"
    },
    {
      "citation_id": "24",
      "title": "A novel ensemble learning paradigm for medical diagnosis with imbalanced data",
      "authors": [
        "Liu"
      ],
      "year": "2020",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "25",
      "title": "Application of higher order cumulant features for cardiac health diagnosis using ecg signals",
      "authors": [
        "Gournay ; Lotfidereshgi",
        "R Lotfidereshgi",
        "P Gournay",
        "R Martis",
        "U Acharya",
        "C Lim",
        "K Mandana",
        "A Ray",
        "C Chakraborty"
      ],
      "year": "2013",
      "venue": "2017 IEEE international conference on acoustics, speech and signal processing (ICASSP)"
    },
    {
      "citation_id": "26",
      "title": "Ensemble boosting and bagging based machine learning models for groundwater potential prediction",
      "authors": [
        "Martis"
      ],
      "year": "2001",
      "venue": "IEEE engineering in medicine and biology magazine"
    },
    {
      "citation_id": "27",
      "title": "Machine learning at scale. Pro Spark Streaming: The Zen of Real-Time Analytics Using Apache Spark",
      "authors": [
        "Nabi ; Nabi",
        "Z Nabi",
        "Z Nabi"
      ],
      "year": "2016",
      "venue": "Machine learning at scale. Pro Spark Streaming: The Zen of Real-Time Analytics Using Apache Spark"
    },
    {
      "citation_id": "28",
      "title": "Ensemble to improve gesture recognition",
      "year": "2014",
      "venue": "International Journal of Automated Identification Technology"
    },
    {
      "citation_id": "29",
      "title": "Diversity and generalization in neural network ensembles",
      "authors": [
        "Cabañas Ortega",
        "L Masegosa ; Ortega",
        "R Cabañas",
        "A Masegosa",
        "S Osowski"
      ],
      "year": "2001",
      "venue": "International Conference on Artificial Intelligence and Statistics"
    },
    {
      "citation_id": "30",
      "title": "Water level prediction model based on gru and cnn",
      "authors": [
        "M Zhou",
        "H Cao",
        "J Liu",
        "Y Hao",
        "J Li",
        "S Chen"
      ],
      "year": "2020",
      "venue": "Ieee Access"
    },
    {
      "citation_id": "31",
      "title": "Analysis of Deep Learning Architectures for Cross-Corpus Speech Emotion Recognition",
      "authors": [
        "Parry"
      ],
      "year": "2019",
      "venue": "Proc. Interspeech"
    },
    {
      "citation_id": "32",
      "title": "Hybrid multi-label classification model for medical applications based on adaptive synthetic data and ensemble learning",
      "authors": [
        "Ponti Jr",
        "; Ponti",
        "M Priyadharshini",
        "M Banu",
        "A Sharma",
        "B Chowdhury",
        "S Rabie",
        "K Shongwe"
      ],
      "year": "2011",
      "venue": "2011 24th SIBGRAPI Conference on Graphics, Patterns, and Images Tutorials"
    },
    {
      "citation_id": "33",
      "title": "A novel cnn-gru-based hybrid approach for short-term residential load forecasting",
      "authors": [
        "O Sagi",
        "L Rokach",
        "M Sajjad",
        "Z Khan",
        "A Ullah",
        "T Hussain",
        "W Ullah",
        "M Lee",
        "S Baik"
      ],
      "year": "1249",
      "venue": "Sagi and Rokach"
    },
    {
      "citation_id": "34",
      "title": "An ensem-ble technique to detect fabricated news article using machine learning and natural language processing techniques",
      "authors": [
        "Sangamnerkar"
      ],
      "year": "2020",
      "venue": "2020 International Conference for Emerging Technology (INCET)"
    },
    {
      "citation_id": "35",
      "title": "Ensemble feature selection: homogeneous and heterogeneous approaches",
      "authors": [
        "Seijo-Pardo"
      ],
      "year": "2017",
      "venue": "Knowledge-Based Systems"
    },
    {
      "citation_id": "36",
      "title": "Deep learning with gated recurrent unit networks for financial sequence predictions",
      "authors": [
        "Shen"
      ],
      "year": "2018",
      "venue": "Procedia computer science"
    },
    {
      "citation_id": "37",
      "title": "Classification of radar returns from the ionosphere using neural networks",
      "authors": [
        "Sigillito"
      ],
      "year": "1989",
      "venue": "Johns Hopkins APL Technical Digest"
    },
    {
      "citation_id": "38",
      "title": "Ensemble-learning approaches for network security and anomaly detection",
      "authors": [
        "N Sundarprasad",
        "Y Teh",
        "G Hinton",
        "E Tsogbaatar",
        "M Bhuyan",
        "Y Taenaka",
        "D Fall",
        "K Gonchigsumlaa",
        "E Elmroth",
        "Y Kadobayashi",
        "J Vanerio",
        "P Casas"
      ],
      "year": "2000",
      "venue": "Proceedings of the Workshop on Big Data Analytics and Machine Learning for Data Communication Networks"
    },
    {
      "citation_id": "39",
      "title": "Speech enhancement from fused features based on deep neural network and gated recurrent unit network",
      "authors": [
        "Rajamohan ; Venkataramanan",
        "K Venkataramanan",
        "H Rajamohan",
        "Y Wang",
        "J Han",
        "T Zhang",
        "D Qing"
      ],
      "year": "2019",
      "venue": "Emotion recognition from speech",
      "arxiv": "arXiv:1912.10458"
    },
    {
      "citation_id": "40",
      "title": "Ensemble strategies for a medical diagnostic decision support system: A breast cancer diagnosis application",
      "authors": [
        "West"
      ],
      "year": "2005",
      "venue": "European Journal of Operational Research"
    },
    {
      "citation_id": "41",
      "title": "Automatic detection of power quality disturbance using convolutional neural network structure with gated recurrent unit",
      "authors": [
        "Yigit"
      ],
      "year": "2021",
      "venue": "Mobile Information Systems"
    },
    {
      "citation_id": "42",
      "title": "Speech emotion recognition using an enhanced kernel isomap for human-robot interaction",
      "authors": [
        "Yu"
      ],
      "year": "2013",
      "venue": "Enhancing certifiable robustness via a deep model ensemble",
      "arxiv": "arXiv:1910.14655"
    },
    {
      "citation_id": "43",
      "title": "Speech emotion recognition using deep 1d & 2d cnn lstm networks",
      "authors": [
        "Mao Zhao",
        "Chen Zhao",
        "J Mao",
        "X Chen"
      ],
      "year": "2019",
      "venue": "Biomedical signal processing and control"
    },
    {
      "citation_id": "44",
      "title": "Ensemble algorithms for unsupervised anomaly detection",
      "authors": [
        "Mehrotra Zhao",
        "Mohan Zhao",
        "Z Mehrotra",
        "K Mohan",
        "C Zhou",
        "G.-B Wu",
        "J Zhang",
        "C.-L Zhou"
      ],
      "year": "2015",
      "venue": "Current Approaches in Applied Artificial Intelligence: 28th International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2015"
    },
    {
      "citation_id": "45",
      "title": "Premature ventricular contraction detection combining deep neural networks and rules inference",
      "authors": [
        "Jin Zhou",
        "Dong Zhou",
        "F -Y.; Jin",
        "L.-P Dong"
      ],
      "year": "2017",
      "venue": "Artificial intelligence in medicine"
    }
  ]
}