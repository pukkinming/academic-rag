{
  "paper_id": "2402.09269v2",
  "title": "Personalized Large Language Models",
  "published": "2024-02-14T15:55:30Z",
  "authors": [
    "Stanisław Woźniak",
    "Bartłomiej Koptyra",
    "Arkadiusz Janz",
    "Przemysław Kazienko",
    "Jan Kocoń"
  ],
  "keywords": [
    "NLP",
    "LLM",
    "Personalization"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Large language models (LLMs) have significantly advanced Natural Language Processing (NLP) tasks in recent years. However, their universal nature poses limitations in scenarios requiring personalized responses, such as recommendation systems and chatbots. This paper investigates methods to personalize LLMs, comparing fine-tuning and zero-shot reasoning approaches on subjective tasks. Results demonstrate that personalized fine-tuning improves model reasoning compared to non-personalized models. Experiments on datasets for emotion recognition and hate speech detection show consistent performance gains with personalized methods across different LLM architectures. These findings underscore the importance of personalization for enhancing LLM capabilities in subjective text perception tasks.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "I. Introduction",
      "text": "In recent years, large language models (LLMs) have revolutionized Natural Language Processing (NLP) tasks in a variety of areas, demonstrating remarkable capabilities in text generation, sentiment analysis, machine translation, and more. These models are based on a transformer architecture  [1]  with a large number of parameters. Training such large models requires massive amounts of text data, enabling them to capture complex language patterns and generate consistent and contextually relevant text.\n\nHowever, while LLMs have impressive generation capabilities, their universal nature is a limitation in scenarios where personalized responses are desired or required. Then, personalization becomes critical in applications such as recommendation systems, chatbots, and personalized content generation, where understanding and tailoring to individual subjective preferences and profiles is critical to user satisfaction and engagement.\n\nSince the language models are zero-shot reasoners  [2] , one can solve downstream tasks with prompt-based inference. In this way, we can obtain personalized answers by incorporating user-specific information into the instructions, i.e., in-context learning  [3] . However, this approach does not update the model weights, so such personalization is impermanent, limited by the context length, and insufficient for specific downstream tasks. Another method we consider is to fine-tune the model in a personalized way. One of our goals is to investigate whether there is a difference between fine-tuning and zeroshot reasoning of LLMs on the subjective tasks.\n\nOur contributions in this paper include: (1) a novel examination of fine-tuning versus zero-shot and few-shot reasoning in LLMs for personalizing subjective text perception, highlighting the superior performance of personalized fine-tuning; (2) a comprehensive evaluation across diverse datasets for emotion recognition and hate speech detection, demonstrating the significant advantages of personalization; (3) the proposal of new methods to enhance the LLM's responsiveness to individual user contexts, advancing subjective text analysis capabilities; (4) empirical validation of our approaches across various LLM architectures, underscoring their efficacy and adaptability; and  (5)  the release of research repository 1 , including code and datasets, to support reproducibility and further advancements in LLM personalization.\n\nOur methodology is based on personalization through the use of basic user-specific context, which consists of user IDs. We utilized multiple fine-tuning approaches and fewshot in-context learning techniques to personalize LLMs for two distinct subjective tasks. Furthermore, we fine-tuned the models in both the classification and the text generation tasks. The results obtained in this work demonstrate that personalization methods based on simplified user-specific information, such as user IDs, have significant potential to enhance LLM performance by up to 165%.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Ii. Related Work",
      "text": "AI has been increasingly applied to subjective tasks such as sentiment recognition, hate speech detection, and emotion recognition, leveraging techniques like deep learning and natural language processing. Models like transformers  [1] , including BERT and GPT  [4] ,  [5] , have shown strong performance by capturing contextual information in text. However, these tasks remain challenging due to the ambiguity and variability in human language, often requiring large, welllabeled datasets to improve accuracy  [6] ,  [7] . Bias in training data and model fairness are also critical concerns, as they can affect the system's performance across different demographic groups. Despite these challenges, AI continues to advance in handling these nuanced tasks, showing promise in real-world applications.\n\nRecent research highlights an interest in personalizing language models, emphasizing their significance across conversational interfaces, recommendation systems, and managing sensitive content  [8] -  [13] . Studies like  [14] -  [29]  underscore the importance of tailoring NLP models to individual beliefs and preferences to enhance the handling of offensive content and controversial topics. Models that incorporate personal perspectives, as demonstrated in  [17]  and  [30] , offered superior predictions by acknowledging individual emotional responses. Kazienko et al.  [31]  extend this approach by developing deep learning models that account for individual differences, significantly outperforming traditional models in subjective tasks. Moreover, a study in  [32]  evaluates the performance of ChatGPT and GPT-4 in generating personalized responses, revealing that such customization improves predictive performance.\n\nThe bulk of this research has focused on adapting conventional neural network architectures, like LSTM and transformers (BERT, RoBERTa), for personalization in NLP, demonstrating the benefits of aligning models with user-specific characteristics, especially for sensitive or subjective content. However, recent exploration into large language models (LLMs) like ChatGPT and GPT-4, as noted in  [32] , showcases their potential in few-shot scenarios without task-specific training, highlighting the advanced capabilities of LLMs to cater to individual user requests effectively.\n\nFine-tuning allows the models to adapt to specific downstream tasks, potentially leading to better performance. On the other hand, LLMs are sophisticated zero-shot reasoners  [2] . One can use their abilities to solve downstream tasks with in-context-learning  [33]  and extensive prompt-based inference  [34] . Fine-tuning can be computationally expensive and time-consuming, especially for large language models. Finetuning a language model on task-specific data can improve its performance on the task, but it may come at the cost of reduced performance on other tasks. This is due to the risk of catastrophic forgetting  [35] , where the model may forget some of the knowledge learned during pre-training and alignment processes  [36] -  [38] . Techniques such as multitask learning or balancing pre-training and task-specific data might be beneficial for retaining the performance of LLMs in multiple downstream tasks.\n\nTo the best of our knowledge, LLM fine-tuning for subjective tasks via user ID inputs, such as personalized emotion recognition or personalized hate speech detection, has not been extensively evaluated, and further research is needed in this area.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Iii. Concept Of Personalizing Llms For Subjective Text Perception",
      "text": "In human communication, interpretation and perception of texts depends not only on the textual content itself. For that reason, especially for subjective tasks like emotion recognition, hate speech, humor, or even sentiment analysis, LLMs should respect individual human preferences and beliefs, making their responses more personalized. Then, the models should be provided with information about the user either at the learning / fine-tuning stage (persistent) or at generation (impersistent). The concept of personalized LLM approaches (and non-personalized baselines) are presented in Fig.  1 .",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "A. Problem Definition",
      "text": "The primary challenge in personalizing LLMs for subjective text perception lies in the model's ability to incorporate individual user preferences, biases, and contexts into its processing mechanism. Given a user u and a text input T , the goal is to generate a response Ŷu that aligns with u's subjective perception of T . The prediction is defined as:\n\nwhere f is the function modeled by the LLM, and C u represents the contextual user u information, which includes user preferences, historical interactions, and any other relevant user-specific data.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "B. Personalized Text Classification",
      "text": "We propose a personalization approach that modifies the LLM's behavior based on C u . This can be achieved by adjusting the model's parameters θ or by manipulating the input space to include personalized prompts. The objective function for personalization can be expressed as:\n\nwhere L is a loss function measuring the discrepancy between the generated response and a set of responses Y u deemed appropriate by user u. The personalization can be implemented through fine-tuning, where θ is adjusted, or through in-context learning, where C u is appended to T to guide the model's predictions.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Iv. Non-Personalized Baselines For Subjective Text Classification",
      "text": "In evaluating the impact of personalization on LLMs, it is essential to establish non-personalized baselines. These baselines represent the model's performance without any adaptation to individual user contexts or preferences. We consider three primary non-personalized approaches: querying an original instruction-tuned model, classification with a new embedding head layer, and generative fine-tuning. Each method offers a different perspective on how LLMs handle subjective text classification in a non-personalized setting.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "A. Querying Instruction-Tuned Language Models (Q)",
      "text": "This approach involves utilizing a pre-trained LLM that has been instruction-tuned but not further adapted to any specific user data. Given a text input T , the model generates a response Ŷ based on the instructions embedded during training:\n\nwhere f θ represents the pre-trained LLM parameterized by θ, and T is the input text. This method evaluates the model's ability to follow instructions and generate appropriate classifications without any additional context or fine-tuning.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "B. Classification Head And Model Fine-Tuning (Cls)",
      "text": "In the classification approach, a new embedding head layer is introduced to the LLM for the specific task of text classification. The model is then fine-tuned. The objective function for fine-tuning can be defined as:\n\n) where L CLS is the classification loss function, θ ′ are the parameters of the fine-tuned model including the new classification head, T is the input text, and Y u represents user labels. This setup aims to adapt the LLM to perform the task better, still without considering any user-specific personalization.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "C. Generative Fine-Tuning Via Language Modeling (Lm)",
      "text": "Generative fine-tuning treats text classification as a text generation problem. The model is fine-tuned to generate a textual label as output, given a descriptive prompt and the input text: min θ ′′ L LM (θ ′′ ; L, L u , T ) where L LM is a loss function suitable for text generation tasks (e.g., cross-entropy loss summed over all positions in the sequence.), θ ′′ are the parameters of the fine-tuned generative model, T is the input text, and L u is the textual label corresponding to T . Unlike the classification approach, which directly predicts labels, this method generates labels as part of a continuous text output.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "V. Methods Of Llm Personalization",
      "text": "Personalizing Large Language Models (LLMs) aims to tailor the model's responses to align with individual user preferences, history, and contextual nuances. This section outlines a formal description for various personalization techniques, including few-shot personalization, personalized classification, and personalized language modeling. These methods leverage user-specific data to enhance the model's relevance and accuracy in subjective text perception tasks.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "A. Few-Shot Personalization (Q-Ns)",
      "text": "Few-shot personalization leverages a small number of examples to guide the model towards user-specific interpretations or responses. This technique involves modifying the input prompt to include N examples (E 1 , E 2 , . . . , E N ) ∈ E u that reflect the user's texts and his perspective or preferences of these texts, which follows a typical In-Context-Learning setting. The input T with user context C u are used to generate a response Ŷu :\n\nwhere f θ is the pre-trained LLM parameterized by θ, T is the original input text, and examples\n\nfor user-annotated texts T ′ i . This method aims to prime the model with a context that mirrors the user's viewpoint, thereby personalizing its output.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "B. Personalized Classification (Cls-P)",
      "text": "Personalized classification adapts the LLM to specific users by incorporating user identifiers directly into the model's training process. This approach fine-tunes the model's parameters θ to minimize the loss between the predicted labels and true labels, taking into account user-specific data. The objective function for personalized classification:\n\nwhere L CLS-P is the personalized classification loss function, θ ′ are the parameters of the personalized model, T is the input text, Y u are the user labels, and C u represents the contextual information (user ID) specific to the user u. This method produces more accurate and personalized label predictions.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "C. Personalized Languge Modeling (Lm-P)",
      "text": "In personalized language modeling, the goal is to fine-tune the LLM so that its generated text is tailored to the individual user's language use, preferences, or style. In our case, these are user labels in the text version. Like the classification approach, this method fine-tunes the model but focuses on generating personalized text outputs rather than predicting labels. The objective can be defined as:\n\nwhere L LM -P is the loss function for personalized language modeling, θ ′′ are the parameters of the fine-tuned generative model, T is the input text, L u is the desired textual output for user u, and C u contains the user-specific contextual information (user ID). This allows the model to generate relevant responses aligned with the user's preferences.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Vi. Experiments",
      "text": "We undertook a comprehensive set of experiments to rigorously evaluate our hypotheses, primarily focusing on multilabel classification tasks using several large language models. Our experimental design included all of the approaches described in section V. However, in this section, we provide a detailed description of the experimental scenarios, explaining the models and datasets used to investigate the effectiveness of our methods. Additionally, we have used all the models and datasets described below for scientific purposes, which is in accordance with their licenses.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "A. Datasets",
      "text": "In our experiments, we used two English-language datasets: GoEmotions  [39]  and Unhealthy Conversations  [40] . Both corpora encompass annotations contributed by numerous individual annotators, each reflecting their subjective perspectives and opinions in a multi-label classification task. Datasets were partitioned based on textual content, resulting in distinct training, validation, and test sets delineated by individual texts. Empty annotations were omitted from consideration. Each partition was refined to exclude outlier annotators, defined as those with annotation frequencies significantly deviating from the dataset's norm. Specifically, annotators contributing less than 5% of annotations compared to the highest individual annotator were eliminated. Subsequently, the dataset was further refined to incorporate annotations from all annotators across each partition, ensuring comprehensive coverage of annotated data within each subset.\n\nGoEmotions: The GoEmotion dataset under the Apache-2.0 license comprises nearly 58k Reddit comments annotated by 82 distinct annotators, resulting in a total of over 211k individual annotations. Each annotator labeled the data using 28 unique emotional categories, including admiration, amusement, anger, annoyance, approval, caring, confusion, curiosity, desire, disappointment, disapproval, disgust, embarrassment, excitement, fear, gratitude, grief, joy, love, nervousness, optimism, pride, realization, relief, remorse, sadness, surprise, and neutral sentiment. Following the application of our datacleaning procedure, the dataset was refined to include annotations from 72 annotators. This refinement yielded a training split containing over 146k samples, with validation and test splits each comprising over 18k samples.\n\nUnhealthy Conversations: The second dataset, termed \"Unhealthy Conversation\", encompasses approximately 230k annotations contributed by 588 annotators across more than 44k distinct online news comments. Each comment was categorized as either healthy or unhealthy, with additional annotations denoting seven attributes: antagonistic, hostile, dismissive, condescending, sarcastic, generalization, or unfair generalization. Following preprocessing procedures, the dataset was refined to comprise a training set consisting of roughly 168k samples, along with validation and test sets, each containing over 20k samples. In the refined iteration of the dataset, the number of annotators was reduced to 427. This dataset is published under the CC BY-NC-SA 4.0 license",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "B. Models",
      "text": "This study investigates the performance of small and moderate-sized language models developed by different research groups. The following models were selected for the experimental part.\n\nMistral: Mistral 7B  [41]  is a language model under the Apache-2.0 license that outperforms previous models such as Llama across diverse benchmarks and approaches the coding performance of Code-Llama 7B  [42] . With the use of groupedquery attention (GQA) and sliding window attention (SWA), Mistral 7B enhances performance and efficiency in comparison to even larger models such as Llama-2-13B  [43] .\n\nFlan-T5: Flan-T5  [44]  is an LLM based on the T5 text-totext transformer model, which is a common encoder-decoder language modeling architecture. Flan-T5 is specifically designed for natural language understanding and generation tasks, showing the impact of parameter scaling and instructionbased fine-tuning. The model demonstrates that instruction fine-tuning scales effectively with both the number of tasks and the size of the model. In our experimental part, we used Flan-T5-XL model which has 3B parameters under Apache-2.0 license.  2 Phi-2: The Phi-2 model  [45]  is a 2.7 billion-parameter small language model (SLM) published under MIT license that challenges the notion that bigger models are always better. It achieves reliable performance in reasoning and language understanding, outperforming models of greater size. This is attributed to different model scaling and the use of high-quality (textbook-quality) training data. Despite its smaller size, Phi-2 demonstrates great performance on specific benchmarks without the need for alignment through Reinforcement Learning from Human Feedback (RLHF)  [46] .  3 StableLM: StableLM models include 3B and 7B parameter decoder-only language models, refined through fine-tuning on diverse chat and instruction-following datasets.  4  Utilizing the NeoX transformer architecture  [47] , these auto-regressive models are designed for chat-based applications.  5  In experiments, we utilised 3 billion-parameter model available at HuggingFace  6  , where it was added under the license CC-BY-NC-SA 4.0.\n\nChatGPT: ChatGPT is a group of models developed by OpenAI under OpenAI API license. Two of the models used in this research are GPT-3.5 and GPT-4. Currently, GPT-4 is one of the best models for multiple tasks, such as zero-shot reasoning.  7",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "C. Experimental Setting",
      "text": "Our experimental setup takes into account the perspective of both datasets (Sec. VI-A) and models (Sec. VI-B). We designed the settings to provide an understanding of the performance and effectiveness of personalized fine-tuning and in-context learning methods across different methods and subjective tasks.\n\nMost of the LLMs selected for our study have a transformer architecture with a decoder-only configuration. Notably, these models required less computational resources for fine-tuning than models with an encoder-decoder architecture, such as Flan-T5. The experiments on language modeling methods with Flan-T5 model were omitted. In the language modeling setting (LM), we compared solely the decoder-only models. However, for the remaining methods, we compared its performance with Mistral 7B model, which has a decoder-only architecture more than twice the size of Flan-T5.\n\nFor fine-tuning and evaluation, our computational infrastructure consisted of four NVIDIA GeForce RTX 3090 GPUs, each with 24 GB of vRAM. Due to memory limitations, we employed modern fine-tuning techniques. We load the models using 4-bit NormalFloat (NF4) quantization and use qLoRA  [48]  on all linear layers with the exception of the very last layer. In the case of CLS scenario the last layer is a newly initialised full layer, and in case of the LM task it is the LM head loaded in full precision. We do training in floating point 16-bit (fp16) for the StableLM and Mistral models and in BFloat16 (bf16) for the Flan-T5 and Phi-2 models. We made these implementations in Python using the PyTorch 8  library and HuggingFace libraries such as transformers 9  and peft  10  . Given ChatGPT's remarkable performance in few-shot prompting, we wanted to examine its effectiveness in query methods (Q-0S vs. Q-1S and Q-2S) compared to the models from Section VI-B. Our investigation included both versions of ChatGPT: GPT-3.5 and GPT-4.\n\nPrompts: Since Large Language Models (LLMs) operate as prompt-based reasoners, the input data for each experiment consisted of an instruction specifying the task to be performed by the model. Each prompt also included the text to be classified and a list of labels from which the model was expected to select the appropriate ones. The prompts we used are shown in the appendix A.\n\nIn fine-tuned personalized approaches (LM-P, CLS-P), we directly added the user ID to the prompt by inserting the line: \"### User ID: <user ID>\". Additionally, in the query (Q-0S, Q-1S, Q-2S) and language modeling (LM, LM- P) methods, we included a one-sentence request to the model within the prompt, specifying the expected format of the response:\n\n\"Please compose your response as a list of chosen labels, separated by commas.\"\n\nIn the Q-1S and Q-2S scenarios, we additionally included example texts and their correct responses within the prompt. Each example was separated from the instruction using a template on a new line: \"### Example <N>: <example> \\n### Example <N> Response: <example's response>\". Where in the Q-1S scenario, the token <N> was left empty, while in the Q-2S scenario, <N> was replaced with the number 1 or 2, depending on the example.",
      "page_start": 5,
      "page_end": 6
    },
    {
      "section_name": "Vii. Results And Discussion",
      "text": "To compare the results across different approaches, we defined a gain metric to quantify the percentage increase in quality of the personalized model relative to the baseline model:\n\nThe results indicate that personalization of subjective task classification has a consistent impact on model performance, leading to significant performance gains (Fig.  2  and Fig.  3 ). This is empirically evident in personalized fine-tuning, i.e., CLS-P and LM-P settings vs CLS and LM. Moreover, finetuning within LM-P and CLS-P settings generally leads to better performance than zero-shot Q-0S and few-shot Q-1S, Q-2S settings. This suggests that while few-shot learning can adapt models to specific tasks without extensive retraining, fine-tuning remains a more effective strategy for maximizing model performance on specialized tasks. The performance gains from personalization are more pronounced in the Unhealthy Conversations dataset than in the GoEmotions dataset -see Table  II  and Table  I . This is in line with the research conducted in  [32] , which shows that the optimal prompt-based personalization strategy (Q-1S and Q-2S settings) needs to be tailored to the specific characteristics and challenges of the task. The performance of few-shot settings varies across models and datasets, indicating that the effectiveness of few-shot learning might depend on the specific characteristics of models and the task. The GPT-family models from OpenAI, i.e., the GPT-3.5 and GPT-4, are the most consistent in few-shot settings -the performance of Q-0S < Q-1S < Q-2S (see Table  II ) -meaning they benefit more from an extended user context. On the other hand, the Mistral model does not fully utilize an extended user context in Q-1S and Q-2S few-shot settings despite undergoing an instruction fine-tuning procedure  [41]  as GPT-family models. Like Mistral, the instruction-based finetuning in Flan-T5 does not correspond well with personalized prompt-based approaches for subjective tasks.\n\nThe Phi-2 model was at a clear disadvantage with our prompts, as the model was not trained to follow instructions, not did it go through an alignment process known as Reinforcement Learning with Human Feedback (RLHF) or Direct Policy Optimization (DPO)  [49] .\n\nIn our analysis, we observe a clear difference between Language Modeling (LM) and Classification (CLS) tasks, especially when considering their effectiveness in personalized settings across various datasets. Specifically, when dealing with the GoEmotions dataset, the personalized classification (CLS-P) method outperforms the personalized language modeling (LM-P) approach. This difference can be attributed to the GoEmotions dataset containing a wide range of labels, making it more challenging for language modeling techniques to capture subtle emotional nuances effectively. On the other hand, when evaluating the Unhealthy Conversations dataset, personalized language modeling (LM-P) shows notably better performance in one out of three experiments compared to personalized classification (CLS-P).  The performance differences between LM-P and CLS-P are less pronounced for Unhealthy Conversations than for GoEmotions. This is likely because Unhealthy Conversations has fewer labels, which suggests that label complexity has a significant impact on the effectiveness of personalized finetuning strategies. Tailoring fine-tuning approaches to the specific challenges presented by the task at hand is crucial. Dataset characteristics play a significant role in optimizing model performance.\n\nTable III presents a comparison between Flan-T5, an encoder-decoder 3B parameter model, and Mistral, a decoderonly 7B model which is more than twice its size. Despite the potentially higher gains observed with the decoder-only model, the encoder-decoder architecture achieves better performance after fine-tuning (CLS vs CLS-P settings).",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Viii. Conclusions And Future Work",
      "text": "Our research underlines the crucial role of personalization in enhancing large language models (LLMs) for tasks involving subjective text perception. Through comprehensive experiments, we established that personalized fine-tuning significantly outperforms conventional zero-shot and few-shot learning methods, especially in the context of datasets with varying label complexities, such as GoEmotions and Unhealthy Conversations. The findings suggest that the success of personalization strategies is linked to the dataset's characteristics, underscoring the need for task-specific personalization approaches.\n\nThe study also reveals that LLMs' architecture and size critically influence the efficacy of personalization. Models like Mistral and the GPT family, which can follow detailed prompts and extended user contexts, show better improvements to models not specifically trained for instruction following or alignment through reinforcement learning.\n\nFuture research directions include examining the impact of personalization across a broader array of LLMs and subjective tasks and incorporating more contextual factors into personalization strategies. This could further enhance the precision and user-relevance of LLM outputs in personalized NLP applications.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Appendix",
      "text": "",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Goemotions Prompts",
      "text": "Prompt for Q-0S and LM scenarios Categorize the following text by selecting the most appropriate emotion from the provided list. Emotions can be subtle or overt, so analyze the text carefully to make an accurate classification. Please compose your response as a list of chosen emotions, separated by commas. Prompt for Q-1S scenario Knowing that for the given example was provided the response given below categorize the following text by selecting the most appropriate label from the provided list. Labels represent different types of communication styles or tones, where each category denotes a specific attitude or approach that someone might exhibit when communicating with others. Analyze text carefully to make an accurate categorization. Please compose your response as a list of chosen emotions, separated by commas.",
      "page_start": 8,
      "page_end": 8
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: A. Problem Definition",
      "page": 2
    },
    {
      "caption": "Figure 1: Non-personalized vs. personalized setups.",
      "page": 3
    },
    {
      "caption": "Figure 2: Performance gains of personalized vs. non-personalized methods on",
      "page": 5
    },
    {
      "caption": "Figure 3: Performance gains of personalized vs. non-personalized methods on",
      "page": 6
    },
    {
      "caption": "Figure 2: and Fig. 3).",
      "page": 6
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "### Example:\n<example text>\n### Example Response:\n<user’s annotations for\nthe example>\n### Text:\n<text>\n### Emotions:\n- <list of\nthe all possible labels from hyphens>\n### Response:": "Prompt\nfor Q-2S scenario"
        },
        {
          "### Example:\n<example text>\n### Example Response:\n<user’s annotations for\nthe example>\n### Text:\n<text>\n### Emotions:\n- <list of\nthe all possible labels from hyphens>\n### Response:": "Knowing that for the given examples were provided the responses\ngiven below categorize\nthe\nfollowing text by selecting the most\nappropriate\nemotion\nfrom the\nprovided\nlist. Emotions\ncan\nbe\nsubtle or overt, so analyze the text carefully to make an accurate\nclassification. Please\ncompose your\nresponse\nas\na\nlist of\nchosen\nemotions, separated by commas.\n### Example 1:\n<first example text>\n### Example 1 Response:\n<user’s annotations for\nthe first example>\n### Example 2:\n<second example text>\n### Example 2 Response:\n<user’s annotations for\nthe second example>\n### Text:\n<text>\n### Emotions:\n- <list of\nthe all possible labels from hyphens>\n### Response:"
        },
        {
          "### Example:\n<example text>\n### Example Response:\n<user’s annotations for\nthe example>\n### Text:\n<text>\n### Emotions:\n- <list of\nthe all possible labels from hyphens>\n### Response:": "Prompt\nfor CLS-P scenario"
        },
        {
          "### Example:\n<example text>\n### Example Response:\n<user’s annotations for\nthe example>\n### Text:\n<text>\n### Emotions:\n- <list of\nthe all possible labels from hyphens>\n### Response:": "Categorize\nthe\nfollowing text\nfor\nthe\nspecified user by selecting\nthe most\nappropriate\nemotion\nfrom the\nprovided\nlist. Emotions\ncan be subtle or overt,\nso analyze the text carefully to make an\naccurate classification.\n### User\nID:\n<user\nID>\n### Text:\n<text>\n### Emotions:\n- <list of\nthe all possible labels from hyphens>\n### Response:"
        },
        {
          "### Example:\n<example text>\n### Example Response:\n<user’s annotations for\nthe example>\n### Text:\n<text>\n### Emotions:\n- <list of\nthe all possible labels from hyphens>\n### Response:": "Prompt\nfor LM-P scenario"
        },
        {
          "### Example:\n<example text>\n### Example Response:\n<user’s annotations for\nthe example>\n### Text:\n<text>\n### Emotions:\n- <list of\nthe all possible labels from hyphens>\n### Response:": "Categorize\nthe\nfollowing text\nfor\nthe\nspecified user by selecting\nthe most\nappropriate\nemotion\nfrom the\nprovided\nlist. Emotions\ncan be subtle or overt,\nso analyze the text carefully to make an\naccurate classification. Please compose your\nresponse as a list of\nchosen emotions, separated by commas.\n### User\nID:\n<user\nID>"
        }
      ],
      "page": 9
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "GoEmotions Prompts": "Prompt\nfor Q-0S and LM scenarios"
        },
        {
          "GoEmotions Prompts": "Categorize\nthe\nfollowing text by selecting the most\nappropriate\nemotion from the provided list. Emotions can be subtle or overt,\nso analyze\nthe\ntext\ncarefully to make\nan accurate\nclassification.\nPlease\ncompose\nyour\nresponse\nas\na\nlist\nof\nchosen\nemotions,\nseparated by commas.\n### Text:\n<text>\n### Emotions:\n- <list of\nthe all possible labels from hyphens>\n### Response:"
        },
        {
          "GoEmotions Prompts": "Prompt\nfor CLS scenario"
        },
        {
          "GoEmotions Prompts": "Categorize\nthe\nfollowing text by selecting the most\nappropriate\nemotion from the provided list. Emotions can be subtle or overt,\nso analyze the text carefully to make an accurate classification.\n### Text:\n<text>\n### Emotions:\n- <list of\nthe all possible labels from hyphens>\n### Response:"
        },
        {
          "GoEmotions Prompts": "Prompt\nfor Q-1S scenario"
        },
        {
          "GoEmotions Prompts": "Knowing that\nfor\nthe given example was provided the\nresponse\ngiven below categorize\nthe\nfollowing text by selecting the most\nappropriate\nemotion\nfrom the\nprovided\nlist. Emotions\ncan\nbe\nsubtle or overt, so analyze the text carefully to make an accurate\nclassification. Please\ncompose your\nresponse\nas\na\nlist of\nchosen\nemotions, separated by commas."
        }
      ],
      "page": 9
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Knowing that for the given examples were provided the responses\ngiven below categorize\nthe\nfollowing text by selecting the most\nappropriate label from the provided list. Labels represent different\ntypes\nof\ncommunication\nstyles\nor\ntones, where\neach\ncategory\ndenotes a specific attitude or approach that someone might exhibit\nwhen communicating with others. Analyze text carefully to make\nan accurate categorization. Please compose your response as a list\nof chosen emotions, separated by commas.\n### Example 1:\n<first example text>\n### Example 1 Response:\n<user’s annotations for\nthe first example>\n### Example 2:\n<second example text>\n### Example 2 Response:\n<user’s annotations for\nthe second example>\n### Text:\n<text>\n### Labels:\n- <list of\nthe all possible labels from hyphens>\n### Response:": "Prompt\nfor CLS-P scenario"
        },
        {
          "Knowing that for the given examples were provided the responses\ngiven below categorize\nthe\nfollowing text by selecting the most\nappropriate label from the provided list. Labels represent different\ntypes\nof\ncommunication\nstyles\nor\ntones, where\neach\ncategory\ndenotes a specific attitude or approach that someone might exhibit\nwhen communicating with others. Analyze text carefully to make\nan accurate categorization. Please compose your response as a list\nof chosen emotions, separated by commas.\n### Example 1:\n<first example text>\n### Example 1 Response:\n<user’s annotations for\nthe first example>\n### Example 2:\n<second example text>\n### Example 2 Response:\n<user’s annotations for\nthe second example>\n### Text:\n<text>\n### Labels:\n- <list of\nthe all possible labels from hyphens>\n### Response:": "Categorize\nthe\nfollowing text\nfor\nthe\nspecified user by selecting\nthe most appropriate label from the provided list. Labels represent\ndifferent\ntypes\nof\ncommunication\nstyles\nor\ntones, where\neach\ncategory\ndenotes\na\nspecific\nattitude\nor\napproach\nthat\nsomeone\nmight\nexhibit when\ncommunicating with\nothers. Analyze\ntext\ncarefully to make an accurate categorization.\n### User\nID:\n<user\nID>\n### Text:\n<text>\n### Labels:\n- <list of\nthe all possible labels from hyphens>\n### Response:"
        },
        {
          "Knowing that for the given examples were provided the responses\ngiven below categorize\nthe\nfollowing text by selecting the most\nappropriate label from the provided list. Labels represent different\ntypes\nof\ncommunication\nstyles\nor\ntones, where\neach\ncategory\ndenotes a specific attitude or approach that someone might exhibit\nwhen communicating with others. Analyze text carefully to make\nan accurate categorization. Please compose your response as a list\nof chosen emotions, separated by commas.\n### Example 1:\n<first example text>\n### Example 1 Response:\n<user’s annotations for\nthe first example>\n### Example 2:\n<second example text>\n### Example 2 Response:\n<user’s annotations for\nthe second example>\n### Text:\n<text>\n### Labels:\n- <list of\nthe all possible labels from hyphens>\n### Response:": "Prompt\nfor LM-P scenario"
        },
        {
          "Knowing that for the given examples were provided the responses\ngiven below categorize\nthe\nfollowing text by selecting the most\nappropriate label from the provided list. Labels represent different\ntypes\nof\ncommunication\nstyles\nor\ntones, where\neach\ncategory\ndenotes a specific attitude or approach that someone might exhibit\nwhen communicating with others. Analyze text carefully to make\nan accurate categorization. Please compose your response as a list\nof chosen emotions, separated by commas.\n### Example 1:\n<first example text>\n### Example 1 Response:\n<user’s annotations for\nthe first example>\n### Example 2:\n<second example text>\n### Example 2 Response:\n<user’s annotations for\nthe second example>\n### Text:\n<text>\n### Labels:\n- <list of\nthe all possible labels from hyphens>\n### Response:": "Categorize\nthe\nfollowing text\nfor\nthe\nspecified user by selecting\nthe most appropriate label from the provided list. Labels represent\ndifferent\ntypes\nof\ncommunication\nstyles\nor\ntones, where\neach\ncategory\ndenotes\na\nspecific\nattitude\nor\napproach\nthat\nsomeone\nmight\nexhibit when\ncommunicating with\nothers. Analyze\ntext\ncarefully to make an accurate categorization. Please compose your\nresponse as a list of chosen labels, separated by commas.\n### User\nID:\n<user\nID>\n### Text:\n<text>\n### Labels:\n- <list of\nthe all possible labels from hyphens>\n### Response:"
        }
      ],
      "page": 10
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Unhealthy Conversation Prompts": "Prompt\nfor Q-0S and LM scenarios"
        },
        {
          "Unhealthy Conversation Prompts": "Categorize\nthe\nfollowing text by selecting the most\nappropriate\nlabel\nfrom the provided list. Labels\nrepresent different\ntypes of\ncommunication\nstyles\nor\ntones, where\neach\ncategory\ndenotes\na\nspecific\nattitude\nor\napproach\nthat\nsomeone might\nexhibit when\ncommunicating with\nothers. Analyze\ntext\ncarefully\nto make\nan\naccurate categorization. Please compose your\nresponse as a list of\nchosen labels, separated by commas.\n### Text:\n<text>\n### Labels:\n- <list of\nthe all possible labels from hyphens>\n### Response:"
        },
        {
          "Unhealthy Conversation Prompts": "Prompt\nfor CLS scenario"
        },
        {
          "Unhealthy Conversation Prompts": "Categorize\nthe\nfollowing text by selecting the most\nappropriate\nlabel\nfrom the provided list. Labels\nrepresent different\ntypes of\ncommunication\nstyles\nor\ntones, where\neach\ncategory\ndenotes\na\nspecific\nattitude\nor\napproach\nthat\nsomeone might\nexhibit when\ncommunicating with\nothers. Analyze\ntext\ncarefully\nto make\nan\naccurate categorization.\n### Text:\n<text>\n### Labels:\n- <list of\nthe all possible labels from hyphens>\n### Response:"
        },
        {
          "Unhealthy Conversation Prompts": "Prompt\nfor Q-1S scenario"
        },
        {
          "Unhealthy Conversation Prompts": "Knowing that\nfor\nthe given example was provided the\nresponse\ngiven below categorize\nthe\nfollowing text by selecting the most\nappropriate label from the provided list. Labels represent different\ntypes\nof\ncommunication\nstyles\nor\ntones, where\neach\ncategory\ndenotes a specific attitude or approach that someone might exhibit\nwhen communicating with others. Analyze text carefully to make\nan accurate categorization. Please compose your response as a list\nof chosen emotions, separated by commas.\n### Example:\n<example text>\n### Example Response:\n<user’s annotations for\nthe example>\n### Text:\n<text>\n### Labels:\n- <list of\nthe all possible labels from hyphens>\n### Response:"
        },
        {
          "Unhealthy Conversation Prompts": "Prompt\nfor Q-2S scenario"
        }
      ],
      "page": 10
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Attention is all you need",
      "authors": [
        "A Vaswani",
        "N Shazeer",
        "N Parmar",
        "J Uszkoreit",
        "L Jones",
        "A Gomez",
        "Ł Kaiser",
        "I Polosukhin"
      ],
      "year": "2017",
      "venue": "Advances in neural information processing systems"
    },
    {
      "citation_id": "2",
      "title": "Large language models are zero-shot reasoners",
      "authors": [
        "T Kojima",
        "S Gu",
        "M Reid",
        "Y Matsuo",
        "Y Iwasawa"
      ],
      "year": "2022",
      "venue": "Advances in neural information processing systems"
    },
    {
      "citation_id": "3",
      "title": "A survey for in-context learning",
      "authors": [
        "Q Dong",
        "L Li",
        "D Dai",
        "C Zheng",
        "Z Wu",
        "B Chang",
        "X Sun",
        "J Xu",
        "Z Sui"
      ],
      "year": "2022",
      "venue": "A survey for in-context learning",
      "arxiv": "arXiv:2301.00234"
    },
    {
      "citation_id": "4",
      "title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "authors": [
        "M.-W Kenton",
        "L Toutanova"
      ],
      "year": "2019",
      "venue": "Proceedings of naacL-HLT"
    },
    {
      "citation_id": "5",
      "title": "Senticnet 8: Fusing emotion ai and commonsense ai for interpretable, trustworthy, and explainable affective computing",
      "authors": [
        "E Cambria",
        "X Zhang",
        "R Mao",
        "M Chen",
        "K Kwok"
      ],
      "venue": "International Conference on Human-Computer Interaction (HCII)"
    },
    {
      "citation_id": "6",
      "title": "Emotion norms for 6000 polish word meanings with a direct mapping to the polish wordnet",
      "authors": [
        "M Wierzba",
        "M Riegel",
        "J Kocoń",
        "P Miłkowski",
        "A Janz",
        "K Klessa",
        "K Juszczyk",
        "B Konat",
        "D Grimling",
        "M Piasecki"
      ],
      "year": "2021",
      "venue": "Emotion norms for 6000 polish word meanings with a direct mapping to the polish wordnet"
    },
    {
      "citation_id": "7",
      "title": "Deep emotions across languages: A novel approach for sentiment propagation in multilingual wordnets",
      "authors": [
        "J Kocoń"
      ],
      "year": "2023",
      "venue": "2023 IEEE International Conference on Data Mining Workshops (ICDMW)"
    },
    {
      "citation_id": "8",
      "title": "Autogen: A personalized large language model for academic enhancement-ethics and proof of principle",
      "authors": [
        "S Porsdam Mann",
        "B Earp",
        "N Møller",
        "S Vynn",
        "J Savulescu"
      ],
      "year": "2023",
      "venue": "The American Journal of Bioethics"
    },
    {
      "citation_id": "9",
      "title": "Llm-rec: Personalized recommendation via prompting large language models",
      "authors": [
        "H Lyu",
        "S Jiang",
        "H Zeng",
        "Y Xia",
        "J Luo"
      ],
      "year": "2023",
      "venue": "Llm-rec: Personalized recommendation via prompting large language models",
      "arxiv": "arXiv:2307.15780"
    },
    {
      "citation_id": "10",
      "title": "Conversational health agents: A personalized llm-powered agent framework",
      "authors": [
        "M Abbasian",
        "I Azimi",
        "A Rahmani",
        "R Jain"
      ],
      "year": "2023",
      "venue": "Conversational health agents: A personalized llm-powered agent framework",
      "arxiv": "arXiv:2310.02374"
    },
    {
      "citation_id": "11",
      "title": "Palr: Personalization aware llms for recommendation",
      "authors": [
        "Z Chen"
      ],
      "year": "2023",
      "venue": "Palr: Personalization aware llms for recommendation",
      "arxiv": "arXiv:2305.07622"
    },
    {
      "citation_id": "12",
      "title": "Tidybot: Personalized robot assistance with large language models",
      "authors": [
        "J Wu",
        "R Antonova",
        "A Kan",
        "M Lepert",
        "A Zeng",
        "S Song",
        "J Bohg",
        "S Rusinkiewicz",
        "T Funkhouser"
      ],
      "year": "2023",
      "venue": "Tidybot: Personalized robot assistance with large language models",
      "arxiv": "arXiv:2305.05658"
    },
    {
      "citation_id": "13",
      "title": "Neurosymbolic ai for personalized sentiment analysis",
      "authors": [
        "L Zhu",
        "R Mao",
        "E Cambria",
        "B Jansen"
      ],
      "year": "2024",
      "venue": "Proceedings of HCII"
    },
    {
      "citation_id": "14",
      "title": "Offensive, aggressive, and hate speech analysis: From data-centric to human-centered approach",
      "authors": [
        "J Kocoń",
        "A Figas",
        "M Gruza",
        "D Puchalska",
        "T Kajdanowicz",
        "P Kazienko"
      ],
      "year": "2021",
      "venue": "Information Processing & Management"
    },
    {
      "citation_id": "15",
      "title": "Controversy and conformity: from generalized to personalized aggressiveness detection",
      "authors": [
        "K Kanclerz",
        "A Figas",
        "M Gruza",
        "T Kajdanowicz",
        "J Kocoń",
        "D Puchalska",
        "P Kazienko"
      ],
      "year": "2021",
      "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing"
    },
    {
      "citation_id": "16",
      "title": "Learning personal human biases and representations for subjective tasks in natural language processing",
      "authors": [
        "J Kocoń",
        "M Gruza",
        "J Bielaniewicz",
        "D Grimling",
        "K Kanclerz",
        "P Miłkowski",
        "P Kazienko"
      ],
      "year": "2021",
      "venue": "2021 IEEE International Conference on Data Mining (ICDM)"
    },
    {
      "citation_id": "17",
      "title": "Personal bias in prediction of emotions elicited by textual opinions",
      "authors": [
        "P Miłkowski",
        "M Gruza",
        "K Kanclerz",
        "P Kazienko",
        "D Grimling",
        "J Kocoń"
      ],
      "year": "2021",
      "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: Student Research Workshop"
    },
    {
      "citation_id": "18",
      "title": "Deep-sheep: Sense of humor extraction from embeddings in the personalized context",
      "authors": [
        "J Bielaniewicz",
        "K Kanclerz",
        "P Miłkowski",
        "M Gruza",
        "K Karanowski",
        "P Kazienko",
        "J Kocoń"
      ],
      "year": "2022",
      "venue": "2022 IEEE International Conference on Data Mining Workshops (ICDMW)"
    },
    {
      "citation_id": "19",
      "title": "Studemo: A non-aggregated review dataset for personalized emotion recognition",
      "authors": [
        "A Ngo",
        "A Candri",
        "T Ferdinan",
        "J Kocoń",
        "W Korczynski"
      ],
      "year": "2022",
      "venue": "Proceedings of the 1st Workshop on Perspectivist Approaches to NLP@ LREC2022"
    },
    {
      "citation_id": "20",
      "title": "What if ground truth is subjective? personalized deep neural hate speech detection",
      "authors": [
        "K Kanclerz",
        "M Gruza",
        "K Karanowski",
        "J Bielaniewicz",
        "P Miłkowski",
        "J Kocoń",
        "P Kazienko"
      ],
      "year": "2022",
      "venue": "Proceedings of the 1st Workshop on Perspectivist Approaches to NLP@ LREC2022"
    },
    {
      "citation_id": "21",
      "title": "Multitask personalized recognition of emotions evoked by textual content",
      "authors": [
        "P Miłkowski",
        "S Saganowski",
        "M Gruza",
        "P Kazienko",
        "M Piasecki",
        "J Kocoń"
      ],
      "year": "2022",
      "venue": "2022 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops)"
    },
    {
      "citation_id": "22",
      "title": "Modeling uncertainty in personalized emotion prediction with normalizing flows",
      "authors": [
        "P Miłkowski",
        "K Karanowski",
        "P Wielopolski",
        "J Kocoń",
        "P Kazienko",
        "M Zięba"
      ],
      "year": "2023",
      "venue": "2023 IEEE International Conference on Data Mining Workshops (ICDMW)"
    },
    {
      "citation_id": "23",
      "title": "Towards model-based data acquisition for subjective multi-task nlp problems",
      "authors": [
        "K Kanclerz",
        "J Bielaniewicz",
        "M Gruza",
        "J Kocoń",
        "S Woźniak",
        "P Kazienko"
      ],
      "year": "2023",
      "venue": "2023 IEEE International Conference on Data Mining Workshops (ICDMW)"
    },
    {
      "citation_id": "24",
      "title": "Pals: Personalized active learning for subjective tasks in nlp",
      "authors": [
        "K Kanclerz",
        "K Karanowski",
        "J Bielaniewicz",
        "M Gruza",
        "P Miłkowski",
        "J Kocoń",
        "P Kazienko"
      ],
      "year": "2023",
      "venue": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "25",
      "title": "Clarin-emo: Training emotion recognition models using human annotation and chatgpt",
      "authors": [
        "B Koptyra",
        "A Ngo",
        "Ł Radliński",
        "J Kocoń"
      ],
      "year": "2023",
      "venue": "International Conference on Computational Science"
    },
    {
      "citation_id": "26",
      "title": "Multi-modal personalized hate speech analysis using differential dataset cartography",
      "authors": [
        "J Kocon",
        "J Baran",
        "K Kanclerz"
      ],
      "year": "2023",
      "venue": "DE-FACTIFY@ AAAI"
    },
    {
      "citation_id": "27",
      "title": "Capturing human perspectives in nlp: Questionnaires, annotations, and biases",
      "authors": [
        "W Mieleszczenko-Kowszewicz",
        "K Kanclerz",
        "J Bielaniewicz",
        "M Oleksy",
        "M Gruza",
        "S Wozniak",
        "E Dzieciol",
        "P Kazienko",
        "J Kocon"
      ],
      "year": "2023",
      "venue": "NLPerspectives@ ECAI"
    },
    {
      "citation_id": "28",
      "title": "Personalized models resistant to malicious attacks for human-centered trusted ai",
      "authors": [
        "T Ferdinan",
        "J Kocoń"
      ],
      "year": "2023",
      "venue": "The AAAI-23 Workshop on Artificial Intelligence Safety"
    },
    {
      "citation_id": "29",
      "title": "Fortifying nlp models against poisoning attacks: The power of personalized prediction architectures",
      "year": "2024",
      "venue": "Information Fusion"
    },
    {
      "citation_id": "30",
      "title": "Useridentifier: Implicit user representations for simple and effective personalized sentiment analysis",
      "authors": [
        "F Mireshghallah",
        "V Shrivastava",
        "M Shokouhi",
        "T Berg-Kirkpatrick",
        "R Sim",
        "D Dimitriadis"
      ],
      "year": "2022",
      "venue": "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies"
    },
    {
      "citation_id": "31",
      "title": "Human-centered neural reasoning for subjective content processing: Hate speech, emotions, and humor",
      "authors": [
        "P Kazienko",
        "J Bielaniewicz",
        "M Gruza",
        "K Kanclerz",
        "K Karanowski",
        "P Miłkowski",
        "J Kocoń"
      ],
      "year": "2023",
      "venue": "Information Fusion"
    },
    {
      "citation_id": "32",
      "title": "Chatgpt: Jack of all trades, master of none",
      "authors": [
        "J Kocoń",
        "I Cichecki",
        "O Kaszyca",
        "M Kochanek",
        "D Szydło",
        "J Baran"
      ],
      "year": "2023",
      "venue": "Information Fusion"
    },
    {
      "citation_id": "33",
      "title": "Language models are few-shot learners",
      "authors": [
        "T Brown",
        "B Mann",
        "N Ryder",
        "M Subbiah",
        "J Kaplan",
        "P Dhariwal",
        "A Neelakantan",
        "P Shyam",
        "G Sastry",
        "A Askell"
      ],
      "year": "2020",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "34",
      "title": "Tree of thoughts: Deliberate problem solving with large language models",
      "authors": [
        "S Yao",
        "D Yu",
        "J Zhao",
        "I Shafran",
        "T Griffiths",
        "Y Cao",
        "K Narasimhan"
      ],
      "year": "2023",
      "venue": "Thirty-seventh Conference on Neural Information Processing Systems"
    },
    {
      "citation_id": "35",
      "title": "Catastrophic forgetting in connectionist networks",
      "authors": [
        "R French"
      ],
      "year": "1999",
      "venue": "Trends in cognitive sciences"
    },
    {
      "citation_id": "36",
      "title": "Examining forgetting in continual pre-training of aligned large language models",
      "authors": [
        "C.-A Li",
        "H.-Y Lee"
      ],
      "year": "2024",
      "venue": "Examining forgetting in continual pre-training of aligned large language models",
      "arxiv": "arXiv:2401.03129"
    },
    {
      "citation_id": "37",
      "title": "Understanding catastrophic forgetting in language models via implicit inference",
      "authors": [
        "S Kotha",
        "J Springer",
        "A Raghunathan"
      ],
      "year": "2023",
      "venue": "Understanding catastrophic forgetting in language models via implicit inference",
      "arxiv": "arXiv:2309.10105"
    },
    {
      "citation_id": "38",
      "title": "Investigating the catastrophic forgetting in multimodal large language models",
      "authors": [
        "Y Zhai",
        "S Tong",
        "X Li",
        "M Cai",
        "Q Qu",
        "Y Lee",
        "Y Ma"
      ],
      "year": "2023",
      "venue": "ArXiv"
    },
    {
      "citation_id": "39",
      "title": "GoEmotions: A dataset of fine-grained emotions",
      "authors": [
        "D Demszky",
        "D Movshovitz-Attias",
        "J Ko",
        "A Cowen",
        "G Nemade",
        "S Ravi"
      ],
      "year": "2020",
      "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "40",
      "title": "Six attributes of unhealthy conversations",
      "authors": [
        "I Price",
        "J Gifford-Moore",
        "J Flemming",
        "S Musker",
        "M Roichman",
        "G Sylvain",
        "N Thain",
        "L Dixon",
        "J Sorensen"
      ],
      "year": "2020",
      "venue": "Proceedings of the Fourth Workshop on Online Abuse and Harms"
    },
    {
      "citation_id": "41",
      "title": "Mistral 7b",
      "authors": [
        "A Jiang",
        "A Sablayrolles",
        "A Mensch",
        "C Bamford",
        "D Chaplot",
        "D Casas",
        "F Bressand",
        "G Lengyel",
        "G Lample",
        "L Saulnier"
      ],
      "year": "2023",
      "venue": "Mistral 7b",
      "arxiv": "arXiv:2310.06825"
    },
    {
      "citation_id": "42",
      "title": "Code llama: Open foundation models for code",
      "authors": [
        "B Roziere",
        "J Gehring",
        "F Gloeckle",
        "S Sootla",
        "I Gat",
        "X Tan",
        "Y Adi",
        "J Liu",
        "T Remez",
        "J Rapin"
      ],
      "year": "2023",
      "venue": "Code llama: Open foundation models for code",
      "arxiv": "arXiv:2308.12950"
    },
    {
      "citation_id": "43",
      "title": "Llama 2: Open foundation and fine-tuned chat models",
      "authors": [
        "H Touvron",
        "L Martin",
        "K Stone",
        "P Albert",
        "A Almahairi",
        "Y Babaei",
        "N Bashlykov",
        "S Batra",
        "P Bhargava",
        "S Bhosale"
      ],
      "year": "2023",
      "venue": "Llama 2: Open foundation and fine-tuned chat models",
      "arxiv": "arXiv:2307.09288"
    },
    {
      "citation_id": "44",
      "title": "Scaling instruction-finetuned language models",
      "authors": [
        "H Chung",
        "L Hou",
        "S Longpre",
        "B Zoph",
        "Y Tay",
        "W Fedus",
        "Y Li",
        "X Wang",
        "M Dehghani",
        "S Brahma"
      ],
      "year": "2022",
      "venue": "Scaling instruction-finetuned language models",
      "arxiv": "arXiv:2210.11416"
    },
    {
      "citation_id": "45",
      "title": "Textbooks are all you need ii: phi-1.5 technical report",
      "authors": [
        "Y Li",
        "S Bubeck",
        "R Eldan",
        "A Del Giorno",
        "S Gunasekar",
        "Y Lee"
      ],
      "year": "2023",
      "venue": "Textbooks are all you need ii: phi-1.5 technical report",
      "arxiv": "arXiv:2309.05463"
    },
    {
      "citation_id": "46",
      "title": "Training language models to follow instructions with human feedback",
      "authors": [
        "L Ouyang",
        "J Wu",
        "X Jiang",
        "D Almeida",
        "C Wainwright",
        "P Mishkin",
        "C Zhang"
      ],
      "year": "2022",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "47",
      "title": "Gpt-neox-20b: An open-source autoregressive language model",
      "authors": [
        "S Black",
        "S Biderman",
        "E Hallahan",
        "Q Anthony",
        "L Gao",
        "L Golding",
        "H He",
        "C Leahy",
        "K Mcdonell",
        "J Phang"
      ],
      "year": "2022",
      "venue": "Gpt-neox-20b: An open-source autoregressive language model",
      "arxiv": "arXiv:2204.06745"
    },
    {
      "citation_id": "48",
      "title": "QLoRA: Efficient finetuning of quantized LLMs",
      "authors": [
        "T Dettmers",
        "A Pagnoni",
        "A Holtzman",
        "L Zettlemoyer"
      ],
      "year": "2023",
      "venue": "Thirty-seventh Conference on Neural Information Processing Systems"
    },
    {
      "citation_id": "49",
      "title": "Direct preference optimization: Your language model is secretly a reward model",
      "authors": [
        "R Rafailov",
        "A Sharma",
        "E Mitchell",
        "C Manning",
        "S Ermon",
        "C Finn"
      ],
      "year": "2023",
      "venue": "Thirty-seventh Conference on Neural Information Processing Systems"
    }
  ]
}