{
  "paper_id": "2403.12087v1",
  "title": "Group Movie Selection Using Multi-Channel Emotion Recognition",
  "published": "2024-03-11T12:02:01Z",
  "authors": [
    "Elnara Kadyrgali",
    "Adilet Yerkin",
    "Yerdauit Torekhan",
    "Pakizar Shamoi"
  ],
  "keywords": [
    "emotion recognition",
    "group movie recommendation",
    "audio emotion",
    "color emotion",
    "text emotion",
    "recommender systems",
    "multi-channel emotion detection"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Social activities often done in groups include watching television or movies. Choosing a film that appeals to the emotional inclinations of a varied group can be tricky. One of the most difficult aspects of making group movie suggestions is achieving agreement among members. At the same time, emotion is the most important component that connects the film and the viewer. Current research proposes a methodology for group movie selection that employs emotional analysis from numerous sources, such as film posters, soundtracks, and text. Our research stands at the intersection of emotion recognition technology in music, text, color images, and group decision-making, providing a practical tool for navigating the complex dynamics of film selection in a group setting. The survey participants were given emotion categories and asked to select the emotions that best suited a particular movie. Preliminary comparison results between real and predicted scores show the effectiveness of using emotion detection for group movie recommendation. Such systems have the potential to enhance movie recommendation systems.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "In film selection, achieving consensus among individuals with diverse preferences can be challenging.\n\nEmotion is the most vital factor that connects the movie and the human. In contemporary entertainment, viewing a movie is more than just visual and auditory stimulation; it explores the complex domain of human emotions.\n\nWatching television or movies are examples of social activities typically done in groups  [3] . The difficulty of selecting a film that satisfies a diverse group's overall emotional preferences can pose a significant challenge. Facilitating consensus among group members is one of the most significant challenges in group movie recommendations. Emotions are crucial in this perspective, as we primarily watch movies to experience emotions.\n\nEmotion recognition studies can be classified based on approaches used in research. Studies of the first category focus on analyzing a single component to detect the emotion. In contrast, the second ones use multi-componential approaches in emotion analysis, integrating more human-like applications.\n\nSeveral studies have examined the problem of group movie recommendation using various methods.\n\nThe study  [1]  introduces \"Happy movie,\" a Facebook-integrated application that enhances group movie recommendations by using personality, social trust, and past preferences, aiming to improve consensus and address the limitations of existing systems. Another work focuses on enhancing movie recommender systems by incorporating visual data, specifically movie posters, to tackle the challenges of information overload, sparsity, and cold-start issues  [2] . The other study introduces a recommendation system tailored for ephemeral groups attending the cinema, using the Slope One algorithm for individual predictions and the Multiplicative Utilitarian Strategy for group recommendations  [3] .\n\nSome studies propose the use of ML and NLP techniques for this task. For example, a novel approach to movie recommendations  [6]  incorporates a knowledge graph that captures human emotions from movie reviews using machine learning techniques. By integrating users' emotional states, extracted from chat messages, with this graph, a chatbot prototype effectively tailors movie suggestions. A similar study  [7]  presented a model that uses social networks and microblogging data and sentiment analysis to enhance program recommendations on online media sites like YouTube and Hulu, addressing the \"cold-start\" problem by mining user preferences for similarity between movies and TV episodes.\n\nMultiple studies focused on genre classification as a basis for proving movie recommendations for groups  [4] [5] .\n\nA hybrid approach to movie recommendations was proposed, integrating tags and human ratings to address the limitations of current services that often overlook the depth of user annotations  [8] . Some other approaches include a combination of k-means clustering and genetic algorithms  [9] , a user-based collaborative filtering method, calculating user similarity by integrating both ratings and social connections  [10] , graph attention network (GAT)  [11] , CNN-based deep learning model that integrates basic movie attributes such as genre, cast, director, keywords, and descriptions, ratings  [12] .\n\nAs we see, a limited number of studies focused on consensus-oriented group recommendation of movies based on emotional features. Recognizing this issue, this paper introduces a novel methodology using emotional analysis to facilitate the group movie selection process. By analyzing emotional data from various sources, including film posters, main soundtrack, and description, our method offers a comprehensive view of the emotional landscape associated with each movie.\n\nThis approach is grounded in the understanding that films are designed to evoke specific emotional responses. Posters usually encapsulate the essence of the film, soundtracks enhance the emotional tone, and descriptions provide the context, and together, they form a multifaceted emotional profile. By integrating these elements, our methodology aims to match a film's emotional tone with the collective mood and preferences of the group, thereby simplifying the decision-making process.\n\nThe research aims to answer the following questions: The proposed approach is presented in Figure  1 . As can be seen, the emotions present in the movie are detected from three channels: Description (text features), Soundtrack (audio features), and Poster (color features). They are then aggregated using the weighted average.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "A. Data Collection",
      "text": "We have gathered data from the Internet Movie Database (IMDb)  [15] , an online repository of information about movies, television shows, and other useful information associated with them. We chose 12 movies from different genres, including comedy, romance, horror, drama, fantasy, and various years. The three main objects for each movie were collected from the database: the storyline of the movies, posters, and one of the soundtracks' excerpts with a 30-second duration. Finally, those films were selected for further analysis: Titanic (1997), Bride Wars (  2009",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "B. Emotion Detection A. Emotion Detection In Movie Description",
      "text": "We used text2emotion 0.0.5  [13]  to detect emotions presented in the movie description. Five emotion categories were used, including Happy, Angry, Sad, Surprise, and Fear. Text2emotions provides a dictionary containing keys as emotion categories and values as scores for each emotion category. Although there are five emotions, not all are represented in the text. We only consider those with a non-zero score.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "B. Emotion Detection In Poster",
      "text": "To detect emotions from colors present in a movie poster, we employed the novel fuzzy sets-based method for categorizing emotions  [14] , which fits well with the imprecise and subjective nature of human assessments. It is easy to modify the suggested approach to fit our situation. The study uses fuzzy colors  [18]  (n=120) and range of emotions (n=10) to get fuzzy color distributions for ten emotions (anger, shyness, happiness, sadness, gratitude, shame, fear, trust, love, and surprise). Ultimately, they are transformed into a crisp domain, gaining a knowledge base of primary color-to-emotion correlations. The study identified the strong correlations between particular emotions and colors (2AFC score=0.77). We utilize these correlations and Jaccard's similarity to detect the emotions in the poster image. Considering our context, we use a subset of emotions from  [10] : anger, happiness, sadness, fear, love, and surprise.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "C. Emotion Detection In Movie Soundtrack",
      "text": "Low-level music features including beat, pitch, rhythm, valence, and tempo are used in the music emotion recognition  [17] . Soundtrack analysis was performed using a pre-trained model based on a deep neural network algorithm, performed in  [16] , that obtained an F1 score of 0.91 on the authors' test set. The model is trained to recognize eight emotion categories (neutral, calm, happy, sad, angry, fearful, disgust, and surprise). We divided the initial 30-second duration audio files into ten partitions for accurate analysis. For every audio file that is supplied as input, the network may process vectors containing 40 audio features, which represent the audio frame's numerical form. We use the main five emotions (Happy, Angry, Sad, Surprise, and Fear) from  [16] , which is our main focus. As output, we got the emotional class suitable for the input audio excerpts, which is properly encoded (Happy=2; Sad=3; Angry=4; Fearful=5; Surprised=7). So, using ten emotional labels observed in each of the ten partitions of one whole excerpt, we formulate the dictionary with scores based on prevalence for every emotion category and keys representing emotion categories like the output of the text emotion analysis. An example is provided in Fig.  2  FIGURE 2. EXAMPLE OF EMOTION EXTRACTION FROM IMAGE. METHOD IS ADAPTED FROM  [14]  C. Jaccard Similarity We calculated the Jaccard similarity coefficient, using Equation 1, between the emotional composition of each film in our database (set 1) and the best-loved film of each participant (set 2). This process gives a Jaccard value indicating the similarity between the emotional composition of the films and the participants' preferred ùëõ choices. We also use it to evaluate the performance of our method by finding the similarity between real and predicted ratings.\n\n(1) ùêΩ(ùê¥, ùêµ) = where = Jaccard distance, = set 1, = set 2. Emotion ùêΩ ùê¥ ùêµ was included to the set using the following threshold for the emotion score -threshold=0.1. Analyzing the distribution of the emotion scores (see Figure  3 ) for our predicted values, we observed that each emotion has a significance of the first quartile(Q1) of more than 0.1. So, the threshold was selected as 0.1. ùëö ùëñ ùëõ III.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Experimental Results",
      "text": "",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "A. Performance Evaluation",
      "text": "We conducted a survey to analyze participants' emotional responses to 12 films shown in Table  1 , with reactions categorized as Happy, Anger, Surprise, Sad, and Fear. Respondents were instructed to indicate only the films that they watched and to select all applicable emotions that they experienced while watching, permitting multiple emotional responses for each question (see Fig.  4 ). As a result, we obtained human ratings for emotion distribution in the movie. The specific emotion score for a certain movie was calculated as the proportion of selection of this emotion among all choices made for this movie. The results are shown in Table  2 .\n\nThe predicted scores for happiness, anger, surprise, sadness, and fear emotions, obtained from 3 different channels, are aggregated according to  (2) . The results are shown in Table  4 . We calculated the Pearson correlation coefficient between each emotion channel (text, colors, audio) and real human ratings to evaluate which emotion channel has the biggest impact on human impression. The highest correlation is between human ratings and text description emotion channel (0.43). Now, we can compare the prediction power of our method by finding the similarity index between predicted emotion scores and the scores given by survey participants. Using the aggregated results of predicted scores (see Table  4 ) and real human scores (Table  2 ), we calculated the Jaccard distance (1) between the real and the expected values of emotions for each movie (see Table  3 ). Afterward, we estimated the average similarity coefficient to be 0.58.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "B. Example: Group Movie Selection",
      "text": "Let us show the example of selecting a movie for a group of people using the proposed approach. Given four movie viewers and a pool of 12 movie options (shown in Table  1 ), we aim to ensure satisfaction and provide the best movie recommendation for the participants.\n\nEach participant provided information about their best-loved film, a reference point for their preferences (see Table  5 ). Using the methods described in Section II, we conducted an emotional analysis of three primary sources associated with each film: the film poster (picture), the main soundtrack (music), and the film description (text). Emotional data containing -happiness, anger, surprise, sadness, and fear from the input are shown in Table  4 , and emotional data of best-loved films of each participant is provided in Table  5 .    Emotional scores from the three sources were aggregated using Eq. 2, for each of the 12 offered movies and four favorite movies. After that, we calculated the Jaccard similarity coefficient between each film's emotional composition and each participant's best-loved film. This process gives a Jaccard value indicating the similarity between the emotional composition of the 12 films and the participants' preferred choices, shown in Tables  4  and 5 . The Box plot of predicted emotion scores is shown in Fig.  3 . The set of films with the mean Jaccard value equal to the highest coefficient, having the greatest similarity to the participants' best-loved films, was identified as the best choice for the group. After that, we filtered them by genre. As a result, we obtained two movies with the highest recommendation scores of 0.8, namely \"Titanic\" and \"Me Before You.\" The least recommended movie for this group is \"Passengers,\" with a score of 0.34.\n\nIV.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Conclusion",
      "text": "In this paper, we provide a multi-modal emotion recognition approach that uses emotional analysis to identify the most suitable film for a group of participants. Our method integrates emotional data from multiple sources, including film posters, main soundtracks of film, and film descriptions, to provide a comprehensive understanding of the emotional landscape associated with each film.\n\nEmotional analysis represents a promising approach to facilitate consensus and satisfaction in group film selection scenarios. By incorporating emotional data from multiple channels and employing the Jaccard similarity coefficient, our methodological approach provides a method for optimal film selection that considers individual preferences and emotional components of films.\n\nIn future works, we plan to collect bigger datasets and conduct more extensive experiments with real groups of people. In addition, we plan to integrate the genre information into the algorithm.",
      "page_start": 6,
      "page_end": 6
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: PROPOSED APPROACH FOR GROUP MOVIE RECOMMENDATIONS",
      "page": 2
    },
    {
      "caption": "Figure 1: As can be seen, the emotions present in the movie are",
      "page": 2
    },
    {
      "caption": "Figure 2: FIGURE 2. EXAMPLE OF EMOTION EXTRACTION FROM IMAGE. METHOD IS",
      "page": 3
    },
    {
      "caption": "Figure 3: PREDICTED EMOTION SCORE DISTRIBUTION",
      "page": 3
    },
    {
      "caption": "Figure 4: ). As a result, we obtained human",
      "page": 4
    },
    {
      "caption": "Figure 4: SURVEY ON MOVIE EMOTION RECOGNITION",
      "page": 4
    },
    {
      "caption": "Figure 3: TABLE 6. INPUT PARAMETERS OF PARTICIPANTS‚Äô FAVORITE FILMS",
      "page": 5
    }
  ],
  "tables": [
    {
      "caption": "Table 4: ) and real human scores (Table2),we",
      "data": [
        {
          "id": "1",
          "Movie": "Titanic",
          "Emotion score of survey participants": "{'Happy': 0.12,\n'Angry': 0.07,\n'Surprise':\n0.1,\n'Sad': 0.45,\n'Fear': 0.25}"
        },
        {
          "id": "2",
          "Movie": "Bride wars",
          "Emotion score of survey participants": "{'Happy': 0.45,\n'Angry': 0.14,\n'Surprise':\n0.27,\n'Sad': 0.05,\n'Fear': 0.09}"
        },
        {
          "id": "‚Ä¶",
          "Movie": "‚Ä¶",
          "Emotion score of survey participants": "‚Ä¶"
        },
        {
          "id": "12",
          "Movie": "The holiday",
          "Emotion score of survey participants": "{'Happy': 0.55,\n'Angry': 0.05,\n'Surprise':\n0.18,\n'Sad': 0.14,\n'Fear': 0.09}"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table 4: ) and real human scores (Table2),we",
      "data": [
        {
          "id": "1",
          "Movie": "Titanic",
          "Description text": "84 years later, a 100\nyear-old woman\nnamed Rose DeWitt\nBukater tells the\nstory to her\ngranddaughter Lizzy\nCalvert, ‚Ä¶",
          "Soundtra\nck": "My Heart\nWill Go On\nby Celine\nDion",
          "Poster": ""
        },
        {
          "id": "2",
          "Movie": "Bride\nwars",
          "Description text": "In Manhattan, the\nlawyer Liv and the\nschool teacher Emma\nhave been best\nfriends since their\nchildhood. They both\nare proposed ‚Ä¶",
          "Soundtra\nck": "Somethin‚Äô\nSpecial by\nColbie\nCaillat",
          "Poster": ""
        },
        {
          "id": "‚Ä¶",
          "Movie": "‚Ä¶",
          "Description text": "‚Ä¶",
          "Soundtra\nck": "‚Ä¶",
          "Poster": "‚Ä¶"
        },
        {
          "id": "12",
          "Movie": "The\nholiday",
          "Description text": "Iris is in love with a\nman who is about to\nmarry another\nwoman. Across the\nglobe, Amanda\nrealizes the man she\nlives with has been\nunfaithful...",
          "Soundtra\nck": "Last\nChristmas\nby Wham!",
          "Poster": ""
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "id": "1",
          "Movie": "Titanic",
          "Emotion score of films\nfrom description text": "{'Happy': 0.17,\n'Angry':\n0.0,\n'Surprise': 0.0,\n'Sad':\n0.33,\n'Fear': 0.5}",
          "Emotion score of films\nfrom soundtrack": "{'Happy': 0.0,\n'Angry':\n0.33,\n'Surprise': 0.0,\n'Sad':\n0.33,\n'Fear': 0.33}",
          "Emotion score of films\nfrom poster": "{'Happy': 0.78,\n'Angry':\n0.56,\n'Surprise': 0.75,\n'Sad': 0.67, 'Fear': 0.78}",
          "Average emotion score\nof films": "{'Happy': 0.22,\n'Angry': 0.2,\n'Surprise': 0.13,\n'Sad': 0.39,\n'Fear': 0.49}"
        },
        {
          "id": "2",
          "Movie": "Bride wars",
          "Emotion score of films\nfrom description text": "{'Happy': 0.75,\n'Angry':\n0.0,\n'Surprise': 0.0,\n'Sad':\n0.0,\n'Fear': 0.25}",
          "Emotion score of films\nfrom soundtrack": "{'Happy': 0.13,\n'Angry':\n0.63,\n'Surprise': 0.0,\n'Sad':\n0.25,\n'Fear': 0.0}",
          "Emotion score of films\nfrom poster": "{'Happy': 0.56,\n'Angry':\n0.33,\n'Surprise': 0.71,\n'Sad': 0.44, 'Fear': 0.56}",
          "Average emotion score\nof films": "{'Happy': 0.51,\n'Angry':\n0.27,\n'Surprise': 0.12,\n'Sad':\n0.16,\n'Fear': 0.22}"
        },
        {
          "id": "‚Ä¶",
          "Movie": "‚Ä¶",
          "Emotion score of films\nfrom description text": "‚Ä¶",
          "Emotion score of films\nfrom soundtrack": "‚Ä¶",
          "Emotion score of films\nfrom poster": "‚Ä¶",
          "Average emotion score\nof films": "‚Ä¶"
        },
        {
          "id": "12",
          "Movie": "The holiday",
          "Emotion score of films\nfrom description text": "{'Happy': 0.38,\n'Angry':\n0.08,\n'Surprise': 0.08,\n'Sad': 0.31,\n'Fear': 0.15}",
          "Emotion score of films\nfrom soundtrack": "{'Happy': 0.0,\n'Angry': 0.0,\n'Surprise': 0.0,\n'Sad': 1.0,\n'Fear': 0.0}",
          "Emotion score of films\nfrom poster": "{'Happy': 0.78,\n'Angry':\n0.75,\n'Surprise': 0.56,\n'Sad': 0.67, 'Fear': 0.78}",
          "Average emotion score\nof films": "{'Happy': 0.32,\n'Angry':\n0.17,\n'Surprise': 0.13,\n'Sad':\n0.6,\n'Fear': 0.21}"
        }
      ],
      "page": 5
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "id": "1",
          "Movie": "The Notebook",
          "Emotion score of films\nfrom description text": "{'Happy': 0.45,\n'Angry':\n0.05,\n'Surprise': 0.15,\n'Sad': 0.25,\n'Fear': 0.1}",
          "Emotion score of films\nfrom soundtrack": "{'Happy': 0.25,\n'Angry':\n0.0,\n'Surprise': 0,\n'Sad':\n0.5,\n'Fear': 0.25}",
          "Emotion score of films\nfrom poster": "{'Happy': 0.56,\n'Angry':\n0.33,\n'Surprise': 0.71,\n'Sad': 0.44, 'Fear': 0.56}",
          "Average emotion score\nof films": "{'Happy': 0.4,\n'Angry': 0.08,\n'Surprise': 0.19,\n'Sad': 0.37,\n'Fear': 0.23}"
        },
        {
          "id": "2",
          "Movie": "Split",
          "Emotion score of films\nfrom description text": "{'Happy': 0.0,\n'Angry':\n0.22,\n'Surprise': 0.11, 'Sad':\n0.22,\n'Fear': 0.44}",
          "Emotion score of films\nfrom soundtrack": "{'Happy': 0.5,\n'Angry':\n0.25,\n'Surprise': 0,\n'Sad':\n0.25,\n'Fear': 0.0}",
          "Emotion score of films\nfrom poster": "{'Happy': 0.56,\n'Angry':\n0.5,\n'Surprise': 0.33,\n'Sad':\n0.44,\n'Fear': 0.56}",
          "Average emotion score\nof films": "{'Happy': 0.26,\n'Angry':\n0.28,\n'Surprise': 0.11, 'Sad':\n0.27,\n'Fear': 0.31}"
        },
        {
          "id": "3",
          "Movie": "Oppenheimer",
          "Emotion score of films\nfrom description text": "{'Happy': 0.25,\n'Angry':\n0.0,\n'Surprise': 0.25,\n'Sad':\n0.0,\n'Fear': 0.5}",
          "Emotion score of films\nfrom soundtrack": "{'Happy': 0.0,\n'Angry': 1.0,\n'Surprise': 0,\n'Sad': 0.0,\n'Fear': 0.0}",
          "Emotion score of films\nfrom poster": "{'Happy': 0.33,\n'Angry':\n0.43,\n'Surprise': 0.25,\n'Sad': 0.38, 'Fear': 0.33}",
          "Average emotion score\nof films": "{'Happy': 0.18,\n'Angry':\n0.41,\n'Surprise': 0.17,\n'Sad':\n0.06,\n'Fear': 0.31}"
        },
        {
          "id": "4",
          "Movie": "Barbie",
          "Emotion score of films\nfrom description text": "{'Happy': 0.06,\n'Angry':\n0.03,\n'Surprise': 0.09,\n'Sad': 0.41,\n'Fear': 0.41}",
          "Emotion score of films\nfrom soundtrack": "{'Happy': 0.0,\n'Angry': 0.0,\n'Surprise': 1,\n'Sad': 0.0,\n'Fear': 0.0}",
          "Emotion score of films\nfrom poster": "{'Happy': 0.36,\n'Angry':\n0.3,\n'Surprise': 0.3,\n'Sad':\n0.27,\n'Fear': 0.36}",
          "Average emotion score\nof films": "{'Happy': 0.09,\n'Angry':\n0.07,\n'Surprise': 0.43,\n'Sad':\n0.25,\n'Fear': 0.27}"
        }
      ],
      "page": 5
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "3": "4",
          "Oppenh\neimer": "Barbie",
          "A dramatization of\nthe life story of J.\nRobert Oppenheimer,\nthe physicist who had\na large hand in the\ndevelopment of ‚Ä¶": "Barbie the Doll lives\nin bliss in the\nmatriarchal society of\nBarbieland feeling\ngood about her role\nin the world in the\nvarious iterations of\nBarbies ‚Ä¶",
          "Can You\nHear The\nMusic by\nLudwig\nG√∂ransson": "Dance the\nNight by\nDua Lipa"
        }
      ],
      "page": 5
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "id": "1",
          "Movie": "The\nNotebo\nok",
          "Description text": "With almost religious\ndevotion, Duke, a\nkind octogenarian\ninmate of a peaceful\nnursing home, reads\ndaily a captivating\nstory‚Ä¶",
          "Soundtra\nck": "I'll Be\nSeeing You\nby Billie\nHoliday",
          "Poster": ""
        },
        {
          "id": "2",
          "Movie": "Split",
          "Description text": "Though Kevin\n(James McAvoy) has\nevidenced 23\npersonalities to his\ntrusted psychiatrist,\nDr. Fletcher (Betty\nBuckley), there ‚Ä¶",
          "Soundtra\nck": "In\nSeptember\nby Slam\nAllen",
          "Poster": ""
        }
      ],
      "page": 5
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "HappyMovie: A Facebook Application for Recommending Movies to Groups",
      "authors": [
        "L Quijano-Sanchez",
        "J Recio-Garcia",
        "B Diaz-Agudo"
      ],
      "year": "2011",
      "venue": "2011 IEEE 23rd International Conference on Tools with Artificial Intelligence",
      "doi": "10.1109/ICTAI.2011.44"
    },
    {
      "citation_id": "2",
      "title": "Building Movie Recommender Systems Utilizing Poster's Visual Features: A Survey Study",
      "authors": [
        "A Rahmatabadi",
        "A Bastanfard",
        "A Amini",
        "H Saboohi"
      ],
      "year": "2022",
      "venue": "2022 10th RSI International Conference on Robotics and Mechatronics (ICRoM)",
      "doi": "10.1109/ICRoM57054.2022.10025210"
    },
    {
      "citation_id": "3",
      "title": "Let's go to the cinema! A movie recommender system for ephemeral groups of users",
      "authors": [
        "G Fern√°ndez",
        "W L√≥pez",
        "F Olivera",
        "B Rienzi",
        "P Rodr√≠guez-Bocca"
      ],
      "year": "2014",
      "venue": "XL Latin American Computing Conference (CLEI)",
      "doi": "10.1109/CLEI.2014.6965161"
    },
    {
      "citation_id": "4",
      "title": "An Adaptive Aggregation Method Based on Movie Genre for Group Recommendation",
      "authors": [
        "W Li",
        "J Xu",
        "Q Bao",
        "R Shen",
        "H Yuan",
        "M Xu"
      ],
      "year": "2020",
      "venue": "2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI)",
      "doi": "10.1109/ICTAI50040.2020.00022"
    },
    {
      "citation_id": "5",
      "title": "A movie recommendation algorithm based on genre correlations, Expert Systems with Applications",
      "authors": [
        "Sang-Min Choi",
        "Sang-Ki Ko",
        "Yo-Sub Han"
      ],
      "year": "2012",
      "venue": "A movie recommendation algorithm based on genre correlations, Expert Systems with Applications",
      "doi": "10.1016/j.eswa.2012.01.132"
    },
    {
      "citation_id": "6",
      "title": "Representing emotions with knowledge graphs for movie recommendations",
      "authors": [
        "Arno Breitfuss",
        "Karen Errou",
        "Anelia Kurteva",
        "Anna Fensel"
      ],
      "year": "2021",
      "venue": "Future Generation Computer Systems",
      "doi": "10.1016/j.future.2021.06.001"
    },
    {
      "citation_id": "7",
      "title": "An intelligent movie recommendation system through group-level sentiment analysis in microblogs",
      "authors": [
        "Hui Li",
        "Jiangtao Cui",
        "Bingqing Shen",
        "Jianfeng Ma"
      ],
      "year": "2016",
      "venue": "Neurocomputing",
      "doi": "10.1016/j.neucom.2015.09.134"
    },
    {
      "citation_id": "8",
      "title": "A hybrid approach for movie recommendation via tags and ratings",
      "authors": [
        "Shouxian Wei",
        "Xiaolin Zheng",
        "Deren Chen",
        "Chaochao Chen"
      ],
      "year": "2016",
      "venue": "Electronic Commerce Research and Applications",
      "doi": "10.1016/j.elerap.2016.01.003"
    },
    {
      "citation_id": "9",
      "title": "An improved collaborative movie recommendation system using computational intelligence",
      "authors": [
        "Zan Wang",
        "Xue Yu",
        "Nan Feng",
        "Zhenhua Wang"
      ],
      "year": "2014",
      "venue": "Journal of Visual Languages & Computing",
      "doi": "10.1016/j.jvlc.2014.09.011"
    },
    {
      "citation_id": "10",
      "title": "A collaborative filtering recommendation framework utilizing social networks",
      "authors": [
        "Aamir Fareed",
        "Saima Hassan",
        "Samir Brahim Belhaouari",
        "Zahid Halim"
      ],
      "year": "2023",
      "venue": "Machine Learning with Applications",
      "doi": "10.1016/j.mlwa.2023.100495"
    },
    {
      "citation_id": "11",
      "title": "A Group Recommendation System for Movies Using Deep Learning",
      "authors": [
        "W. -H Liao",
        "Y. -T Lin",
        "C. -Y Lin",
        "S. -C Kuai"
      ],
      "year": "2023",
      "venue": "2023 International Conference on Consumer Electronics -Taiwan (ICCE-Taiwan)",
      "doi": "10.1109/ICCE-Taiwan58799.2023.10226648"
    },
    {
      "citation_id": "12",
      "title": "Movie Popularity and Target Audience Prediction Using the Content-Based Recommender System",
      "authors": [
        "S Sahu",
        "R Kumar",
        "M Pathan",
        "J Shafi",
        "Y Kumar",
        "M Ijaz"
      ],
      "year": "2022",
      "venue": "IEEE Access",
      "doi": "10.1109/ACCESS.2022.3168161"
    },
    {
      "citation_id": "13",
      "title": "",
      "authors": [
        "M Llc"
      ],
      "year": "2020",
      "venue": ""
    },
    {
      "citation_id": "14",
      "title": "Color-Emotion Associations in Art: Fuzzy Approach",
      "authors": [
        "M Muratbekova",
        "P Shamoi"
      ],
      "year": "2024",
      "venue": "IEEE ACCESS"
    },
    {
      "citation_id": "15",
      "title": "Internet Movie Database (IMDb)",
      "venue": "Internet Movie Database (IMDb)"
    },
    {
      "citation_id": "16",
      "title": "Emotions Understanding Model from Spoken Language using Deep Neural Networks and Mel-Frequency Cepstral Coefficients",
      "authors": [
        "M De Pinto",
        "M Polignano",
        "P Lops",
        "G Semeraro"
      ],
      "year": "2020",
      "venue": "2020 IEEE Conference on Evolving and Adaptive Intelligent Systems (EAIS)",
      "doi": "10.1109/EAIS48028.2020.9122698"
    },
    {
      "citation_id": "17",
      "title": "Music Emotion Recognition Using K-Nearest Neighbors Algorithm",
      "authors": [
        "A Ualibekova",
        "P Shamoi"
      ],
      "year": "2022",
      "venue": "2022 International Conference on Smart Information Systems and Technologies (SIST)",
      "doi": "10.1109/SIST54437.2022.9945814"
    },
    {
      "citation_id": "18",
      "title": "Comparative Overview of Color Models for Content-Based Image Retrieval",
      "authors": [
        "P Shamoi",
        "D Sansyzbayev",
        "N Abiley"
      ],
      "year": "2022",
      "venue": "2022 International Conference on Smart Information Systems and Technologies (SIST), Nur-Sultan",
      "doi": "10.1109/SIST54437.2022.9945709"
    }
  ]
}