{
  "paper_id": "2406.04758v1",
  "title": "Think Out Loud: Emotion Deducing Explanation In Dialogues",
  "published": "2024-06-07T08:58:29Z",
  "authors": [
    "Jiangnan Li",
    "Zheng Lin",
    "Lanrui Wang",
    "Qingyi Si",
    "Yanan Cao",
    "Mo Yu",
    "Peng Fu",
    "Weiping Wang",
    "Jie Zhou"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Humans convey emotions through daily dialogues, making emotion understanding a crucial step of affective intelligence. To understand emotions in dialogues, machines are asked to recognize the emotion for an utterance (Emotion Recognition in Dialogues, ERD); based on the emotion, then find causal utterances for the emotion (Emotion Cause Extraction in Dialogues, ECED). The setting of the two tasks requires first ERD and then ECED, ignoring the mutual complement between emotion and cause. To fix this, some new tasks are proposed to extract them simultaneously. Although the current research on these tasks has excellent achievements, simply identifying emotion-related factors by classification modeling lacks realizing the specific thinking process of causes stimulating the emotion in an explainable way. This thinking process especially reflected in the reasoning ability of Large Language Models (LLMs) is under-explored. To this end, we propose a new task \"Emotion Deducing Explanation in Dialogues\" (EDEN). EDEN recognizes emotion and causes in an explicitly thinking way. That is, models need to generate an explanation text, which first summarizes the causes; analyzes the inner activities of the speakers triggered by the causes using common sense; then guesses the emotion accordingly. To support the study of EDEN, based on the existing resources in ECED, we construct two EDEN datasets by human effort. We further evaluate different models on EDEN and find that LLMs are more competent than conventional PLMs. Besides, EDEN can help LLMs achieve better recognition of emotions and causes, which explores a new research direction of explainable emotion understanding in dialogues.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Introduction",
      "text": "Understanding emotions expressed by humans in their dialogues is an inevitably essential step of intelligent affective computing for the purpose of research  [10, 40]  and practice  [33] . Emotion and its cause are two fundamental factors of emotion understanding, boosting the emergence of Emotion Recognition in Dialogues (ERD)  [5, 22, 29]  and Emotion Cause Extraction in Dialogues (ECED)  [30] . ERD predicts the emotion for an utterance, and ECED then finds causal utterances for the given emotion. However, the pipeline-style setting ignores the mutual indication of emotion and cause  [48] . To solve this problem, the pair extraction of emotional and causal utterances is proposed (ECPEC)  [21] , but ECPEC does not predict the specific emotion of the emotional utterance. To this end, researchers  [44, 45]  propose to extract the triplets of these utterances and the emotion (ECTEC) as shown in Fig.  1 .\n\nAlthough research  [20, 52, 45, 42, 50]  on these emotion-understanding tasks has achieved excellent achievements, classification modeling only gives outcomes of emotion-related factors, lacking in realizing how the emotion is stimulated by its causes. That is, models do not explicitly analyze the appraisal  [37] , which is theoretically related to human psychological activities developing from emotional triggers  [1] . This leads to models failing to deeply reason the process of emotion arousal in an explainable and explicit thinking way. Especially, with the flourishing of Large Language Models (LLMs), such an explainable thinking process is crucial for LLMs to achieve better cognition, which is under-explored.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Emotion Deducing Explanation",
      "text": "The emotion is Happiness, and the explanation is like:\n\nI have a sweet tooth. I can not help but think about having something sweet between meals.\n\nA new candy shop just opened around the corner last week. They have a variety of candies and it is always full of people.\n\nSpeaker A expresses their craving for sweets and learns about a new candy shop from Speaker B. They feel excited about the possibility of visiting the new candy shop, where they can find a wide variety of candies and fulfill their sweet cravings. This eagerness, which arises from their initial desire and the potential fulfillment at the newly discovered shop, brings a sense of happiness to Speaker A. Therefore, Speaker A displays happiness. To achieve explainable emotion understanding, we propose a new task called \"Emotion Deducing Explanation in Dialogues\" (EDEN ). EDEN fully considers the mutual complement of emotion and cause and recognizes them simultaneously by generating an explanation text. As shown in Fig.  1 , only giving a dialogue whose last utterance is the target to analyze, EDEN generates the explanation text by: summarizing the emotion triggers from the dialogue context (red highlights), analyzing the speaker's inner activities towards these triggers (green highlights), and giving the specific emotion aroused from the inner activities (yellow highlights). We call this thinking process as emotion deducing. Specifically, the analysis of inner activities needs commonsense of events and mental state  [36, 35] , which sets a requirement of the reasoning ability of models.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Emotion Recognition",
      "text": "To support the study of EDEN, we start from the existing data resources of ECEC and ECTEC, which have provided emotion and cause annotations, and construct two datasets by human effort: DailyDialogue (EDEN-DD) and Friends (EDEN-FR). Based on the curated datasets, we adapted experiments on a range of models including conventional pretrained models (PLMs), ChatGPT, and fine-tuned LLaMA (which we propose it as EDEN-LLaMA). We show that PLMs are not competent to EDEN and the reasoning ability of LLMs can be activated by EDEN to achieve better emotion understanding. With EDEN, our method can achieve better emotion/cause recognition compared to previous models. Besides, we also show that LLMs' ability to compositional and multi-hop reasoning still requires to be strengthened. Overall, EDEN provides a new research direction of explainable emotion understanding in dialogues, which is more challenging than previous tasks.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Related Work",
      "text": "Emotion Understanding in Dialogues involves a range of classification tasks: emotion recognition (ERD)  [5, 29, 22] , cause (ECED)  [30] , emotion-cause pair (ECPEC)  [21] , and triplets (ECTEC)  [44]  extractions. These tasks lack reasoning human inner activities due to the absent commonsense reasoning ability of the used PLMs  [16] . To this end, a lot of works focus on introducing commonsense knowledge  [39, 35, 2, 15]  to enhance this. For ERD, the knowledge is embedded in dialogue context modeling  [11, 19, 54] , and cooperates with topic  [55]  and sentimental  [49]  information. For ECED, the knowledge is used to find causal clues  [20] , is structurally modeled according to its types  [52] , and is constructed to be a bipartite graph  [50] . For ECTEC, the knowledge is used to enhance the understanding of implicit expressions  [45] . Although the introduction of knowledge can bring interpretability to some extent, the reasoning ability of models is enhanced by external knowledge supplier  [2] , which is often noisy  [20]  and is not naturally reflected by the models themselves. With the emergence of LLMs  [28, 41] , the powerful thinking process of them can manifest such ability.\n\nRecently, ChatGPT has been used to generate commonsense knowledge for ERD  [43] . The CoT-style explanation for emotion cause is explored  [14] . However, there is no work providing human-curated data resources and systematic studies for explainable understanding of both emotion and cause.\n\nCommonsense Reasoning and Explainability are two factors highly related to our task. The commonsense in our task mainly focuses on events and speakers' mental state. ATOMIC  [35, 15, 47]  and SocialIQA  [36]  are the most popular resources for this purpose, which is usually trained for knowledge generation  [2] , but they serve for single events without context. GLUCOSE  [27]  is proposed for contextual commonsense reasoning in stories and CICERO  [12, 38]  is for dialogues. However, these resources only support a round of reasoning at a time, which is suitable for complicated analysis of several aspects. As for explainability, the explanation for sarcasm is proposed for single sentences  [7]  and dialogues  [17] . EMER  [23]  explains the emotion by analyzing a video clip with a short subtitle, mainly focusing on the audio and visual modalities. These works do not explore explanations around emotion and cause in dialogues.\n\n3 Our EDEN Dataset",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Problem Definition",
      "text": "Formally, for a dialogue D = [u 1 , ..., u n ], the last utterance u n is an utterance with an unknown emotion (the target utterance). u i contains several factors: its turn id i, corresponding speaker s i , and content text t i . Now, models only know that u n said by s n shows an unknown emotion, the model should generate the explanation to deduce the emotion and guess the emotion e k from ['happiness (joy)', 'surprise', 'sadness', 'anger', 'disgust', 'fear']: M odel(D, u n ) →\"The emotion is e k . E\", where E is the explanation acting as the Chain of Thought (CoT) for emotion recognition.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Data Collection",
      "text": "As there is no available data for EDEN, we intend to construct the resource by further human annotation on existing datasets. The existing dataset should satisfy two conditions: First, utterances should be labeled with their emotions; Second, causal utterances should also be annotated beforehand.\n\nFor this purpose, we collect two datasets: RECCON  [30]  in emotion cause extraction and ECF  [44]  in emotion-cause triplet extraction. From RECCON, we pick up its DailyDialogue part, which consists of considerable dyadic dialogues, denoted as \"DD\". As for ECF, we directly use its whole unimodal data. As the data of ECF are multi-party dialogues from a popular TV series called \"Friends\", we denote it as \"FR\".\n\nData Preparing. In our setting, only the target utterance along with its history are input for analysis. Therefore, we construct m samples if a dialogue contains m non-neutral utterances. Furthermore, we find that most of the causal utterances are located near the target utterance and less than 15 turns away.\n\nTo this end, we set the history context window to 15. Those causal utterances out of the window will be truncated, and if a target utterance does not have in-window causal utterances, the sample will be removed. We prepared 5331 samples for DD where the number of training/dev/test data is 4645/157/529, and 6741 samples for FR, whose case is 4874/591/1276.\n\nFor human annotation, the burdens of writing the explanation from scratch are heavy and exhausting. Therefore, we utilize ChatGPT to help with the annotation. We input a sample with the emotion and its causal utterances to ChatGPT and instruct ChatGPT to generate the original explanation of how causes lead to the emotion in a Chain-of-Thought style. Following  [46] , we also use a two-round prompt to let ChatGPT first elaborate on the analysis and then summarize the analysis. The prompt is shown in Fig.  4 , Appendix A. To further assist human annotators, we also utilize ChatGPT to generate the topic of the dialogue, which can help annotators quickly understand the dialogue.\n\nHuman Annotations. As we have mentioned in previous paragraphs, ChatGPT will generate the original analysis. To this end, annotators need to read the analysis and assess its reasonability. If the analysis makes sense by providing a reliable reasoning chain, annotators can save the labor by only paraphrasing the original analysis to the format of our task's requirement. Otherwise, annotators rewrite the explanation according to their own reasoning.\n\nWe hired a group of Chinese undergraduates who are in major of computer sciences to make sure they can easily understand the study of computational linguistics and AI terminologies. Besides, all (1) The emotion triggers are required to be extracted from the given causal utterances based on the dialogue. These triggers can be events happening in the dialogue  [30] , and even the speaker's external verbal words when the dialogue provides less information for an exact event. For these events, the annotators are encouraged to refine and summarize them instead of directly copying spans from the dialogue (copying spans is still acceptable).\n\n(2) The analysis from the emotion trigger to the target emotion should focus on the speaker's psychological activities towards the events, requiring humans' social commonsense about the effect of the events  [35] ; speakers' intent, reaction, attribute, and behavior  [35] .\n\n(3) Summarize emotion triggers, organize the analysis, and give the emotion, as illustrated in Fig.  1 . Before the formal annotation, annotators are assigned a subset of samples separated into 5 parts for the training. They annotate one part and submit it to a conversational AI expert. This part is passed when the expert approves or otherwise is returned for revision. After an average of 3 iterations, the annotator can reach a standard. For the formal annotations, annotators rate ChatGPT's analysis and produce the final explanation. The quality of ChatGPT's analysis is ranked by 3 levels: good (3 scores), okay (2 scores), and needing improvement (1 score). The annotating interface is shown in Fig.  10 , Appendix E.\n\nAs errors are always unavoidable, we utilize ChatGPT to correct grammar errors and typos. More importantly, ChatGPT is asked not to change the original structure and meaning. After the postprocess, we evaluated a subset and found that ChatGPT can remove these errors with minor changes.\n\nAnnotating Quality. To evaluate the quality of the annotated data, we randomly and respectively pick up 50 samples from DD and FR. We hire 3 conversational AI researchers as inspectors. The verification mainly focuses on 3 aspects: fluency -whether the explanation is fluent and has no clear description; correctness -whether the emotion triggers are extracted from the causal utterances based on the dialogue; rationality -whether the explanation provides a reasonable analysis from the triggers to the target emotion. The three aspects can be scored:  [1, 2, 3] . The average scores of the 3 aspects and the agreement between inspectors are illustrated in Tab. 1. The results show that the annotated data achieves substantial or almost perfect agreements among inspectors. Data Statistics. The basic data statistics are shown in Tab. 2. It can be seen that the real-time dialogue length of FR is longer than that of DD. However, the utterances in DD are more informative than FR as utterances in FR often contain meaningless exclamation words like \"ah\" and \"yeah\", informal expressions, and American slang and memes because the data is from American comedy. For more illustrations, as shown in Fig.  2  (a), the emotion distributions are different in DD and FR, where DD shows a more evident long-tail distribution than FR. Table  3 : Comparison between EDEN and other affection-related dataset. * denotes that only partial data has such a function. † denotes that commonsense reasoning does not focus on how causes lead to emotion. \"t\" denotes \"textual\" modality; \"a\" for \"audio\"; \"v\" for \"visual\". dataset task format modality dialogue emotion predict emotional cause realize commonsense reason explanation CoT style IEMOCAP  [5]  emotion classification t,a,v ✓ ✓ DailyDialogue  [22]  emotion classification t ✓ ✓ RECCON  [30]  cause classification t ✓ ✓ ConvECPE  [21]  cause classification (pair) t ✓ ✓ ECF  [44]  cause classification (triplets) t,a,v ✓ ✓ ✓ CICEROv2  [38]  commonsense reason t ✓ ✓ * ✓ * ✓ † SED  [17]  sarcasm explanation t,a,v ✓ ✓ EMER  [23]  emotion explanation t,a,v\n\nAs for annotators' evaluation to ChatGPT's original analysis, we compute the average scores for DD and FR separately. The score for DD is 2.03 and for FR is 2.14, where the detailed score distribution can be viewed in Fig.  2 (b ). The reason for FR having more good ChatGPT analyses is that dialogues in FR provide less information. Story understanding in Friends requires more context in the whole scene shot or even global information  [34] . However, samples in FR are short clips, and annotators tend to trust ChatGPT's analysis when few clues can be found in dialogues. In general, the result shows that ChatGPT possesses an acceptable ability to analyze inner activities and reason commonsense, but it still has space for improvement.\n\nBesides, we also compute the average scores of samples with different numbers of causal utterances, whose results are depicted in Fig.  2 (c ). The reason for only considering up to 3 causal utterances is that the number of samples with >3 causal utterances is far fewer. As seen from the figure, ChatGPT tends to perform slightly worse with the number of causal utterances increasing.",
      "page_start": 3,
      "page_end": 5
    },
    {
      "section_name": "Comparisons With Other Tasks",
      "text": "Tab. 3 compares EDEN and other highly related datasets. As shown in the table, EDEN predicts both emotion and cause, which can be regarded as a substitution for these classification tasks.\n\nAlthough CICERO provides two types of commonsense for emotion and cause independently, emotion reasoning still directly predicts emotion, and cause reasoning is not exclusive to emotion. Besides, CICERO reasons a type of commonsense at a time, which cannot make more challenging reasoning from emotional causes to emotion as EDEN does. EMER also explains emotions, but it is for a single sentence, not suitable for dialogues. The explanation of EMER mainly focuses on audio and visual modalities, and the analysis of text does not consider emotion causes or specific inner activities of speakers. Conversely, EDEN is proposed to deeply model cause and emotion through mental state analysis and other types of commonsense reasoning.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Method",
      "text": "",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Conventional Models",
      "text": "Small SOTA methods in ERD and ECED. As EDEN predicts emotion and cause together, the performance of SOTA methods to identify these two factors can be a reference. For ERD, TFD  [42] , a framework to reduce major label biases, and BHG  [50] , which constructs a bipartite graph for utterances and commonsense knowledge, are selected. For ECED, BHG is still the SOTA method.\n\nPretrained Language Models. Exploring whether previous pretrained models are competent to EDEN is crucial. BART  [18]  and GPT2  [31]  can be representative for this purpose. For BART, we form the source and target as:\n\n, where C ≤t is the dialogue; t i is the target utterance and s i is the target speaker; A is the output containing the explanation. For GPT2, we form the source and target as: \"Dialogue is: C ≤t ; The target utterance is: s i : t i . Your explanation to s i 's emotion at the target snippet: → A <|endoftext|>\".",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Chatgpt With In-Context Learning",
      "text": "As the most famous LLM, ChatGPT demonstrates excellent reasoning ability to text understanding.\n\nWe study the performance of ChatGPT. To achieve this, we have tried a zero-shot style template to prompt it, but the outcome shows extremely low scores on some automatic metrics. Therefore, we mainly focus on In-Context Learning  [3]  and denote the method as ChatGPT N -shots. Instead of randomly sampling demonstrations from the training set, we utilize Sentence-BERT  [32]  to encode the embedding of the target utterance t i of every sample; we further compute the similarity scores between them and rank training samples accordingly; the top-N samples are selected as demonstrations. The prompt template for ChatGPT 5-shots is illustrated in Fig.  5 , Appendix A.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Eden-Llama",
      "text": "Besides ChatGPT, we also explore the reasoning ability of LLaMA2  [41] . As EDEN provides training data, we fine-tune LLaMA2 with LoRA adaption  [13] . For LoRA fine-tuning, we set the instruction as Fig.  6 , Appendix A. In the instruction, several factors, that may affect the behavior of LLaMA2, will be considered: the candidate emotion list, the target speaker, and the identification of the target utterance. We denote the fine-tuned LLaMA2 as EDEN-LLaMA.\n\nHybrid training. Although we evaluate EDEN-DD and EDEN-FR independently, the emotion labels of them share the Ekman's emotion theory  [9] . We train EDEN-LLaMA using all the training data of DD and FR, and denote it EDEN-LLaMA hybrid. It will not directly compare with others.\n\nSupplementary commonsense pretraining. EDEN requires the ability of commonsense reasoning to analyze a speaker's inner activities. Although LLMs have such an ability, we are still curious about whether additional training on commonsense knowledge bases can further activate such an ability.\n\nTo this end, we collect three types of commonsense resources focusing on events: ATOMIC  [35] , GLUCOSE  [27] , CICEROv2  [38] . ATOMIC focuses on events in a single sentence; GLUCOSE executes contextual reasoning in a story context; CICEROv2 is in a dialogue context. To perform instruct tuning, we construct a template pool for them, and every piece of knowledge can transfer into an instruction. We adapt instruct pretraining on them, and the trained LoRA continues EDEN training. We denote the method as EDEN-LLaMA sup.\n\n5 Experiments",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "Evaluating Metrics",
      "text": "Automatic metrics for generation. We conventionally use BLEU, ROUGE-L, METEOR, and CIDEr scores like other generation tasks. Specifically, the speaker name in EDEN-DD is formed like \"Speaker A\" and we think this may lead to a relatively high BLEU-(≤2) score. Therefore, BLEU-(3/4) is used for EDEN-DD. EDEN-FR does not have such a case, and BLEU-(2/3) is used.\n\nMetrics for emotion and cause recognition. The emotion is easy to extract. However, the problem is that ChatGPT sometimes does not follow instructions to pick up the emotion from the emotion list. To reduce this, we train an emotion evaluator (based on RoBERTa  [25] ) on EDEN to classify an explanation, whose emotion is not in the emotion list. The intent is that the explanation will provide clear emotion-related expressions for the evaluator to learn and use. Emotion is evaluated by a weighted F1 score denoted as EF. As for cause, the explanation does not copy original causal utterances but summarizes them, which makes the direct evaluation impossible. Nevertheless, the summarized causes are still semantically similar to causal utterances. Therefore, we train a cause evaluator to predict 0/1 with the input of \"\n\n, where u t is the target utterance; u c is a candidate utterance; E is the explanation. To this end, the evaluator will learn the correlation if a causal utterance is mentioned in the explanation. Based on the outcome of the Cause Evaluator, the cause is evaluated by an F1 score denoted as CF.\n\nReasonableness. We define reasonableness as how reasonable and correct the explanation deduces the emotion from causes, which comprehensively considers the correctness of emotion prediction, cause extraction, and analyzing process. It ought to be done by humans, requiring huge labor. Instead, we follow G-EVAL  [24]  to evaluate it using GPT4, which is said to have good human alignment. We illustrate reasonableness (1≤ • ≤3) in Fig.  7 , Appendix A, which provides the detailed criteria.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Implementations",
      "text": "We use BART-large, GPT2-large, LLaMA2-7b-chat, LLaMA2-13b-chat for EDEN. For the emotion evaluator, we use RoBERTa-large, which will train 5 times for average; for the cause evaluator, due to the sequence length, we use Longformer-large  [25] , which also trains 5 times for average. As for Reasonableness, on the 100 randomly sampled samples, GEVAL will be done 20 times for average. More details of implementation can be seen in Appendix B.",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "Experiment Outcomes",
      "text": "Main Results. The performance of different methods on EDEN-DD and EDEN-FR is shown in Tab. 4 and Tab. 5. First, let us pay attention to BART and GPT2. Their results of automatic metrics on both datasets show no advantage to EDEN-LLaMA, and the number of trained parameters of these PLMs is way larger than that of EDEN-LLaMA, which indicates that PLMs are not capable of EDEN. The reason may be that PLMs lack powerful reasoning ability and depend on co-occurrence features between emotion and some emotional expressions. This can be seen from their good performance in emotion recognition while low reasonableness scores. Accordingly, we illustrate a case that PLMs can correctly predict the emotion but make factual errors in reasoning in Fig.  3 (a) . In this case, BART and GPT-2 wrongly analyze that A reduced the price for B. Conversely, EDEN-LLaMA correctly explains A's inner satisfaction with their pricing strategy. Second, we analyze the performance of Chat-GPT. Although Chat-GPT is not fine-tuned for EDEN, ChatGPT shows acceptable results in automatic metrics. However, its EF is not as good as other methods because ChatGPT sometimes does not follow the instruction to select an emotion from the emotion list. The reason may be that ChatGPT has learned massive data with different emotion systems. For example, it predicts \"curiosity\", \"disappointment\", which may come from GoEmotions  [6] . These emotions are easily confused with \"surprise\", \"happiness\", and other negative emotions. As for the CF, ChatGPT tends to analyze history utterances with emotions while a history utterance with an emotion is not necessarily to be a cause. This makes ChatGPT have a lower precision score for the cause compared with EDEN-LLaMA. As for ChatGPT's reasoning ability, with the number of demonstrations increasing, all the metrics increase, especially the score of reasonableness. This indicates that more demonstrations in in-context learning can activate ChatGPT's reasoning ability. To illustrate this, Fig.  3  (b) gives a case of analyzing \"Joe\" and \"Joey\". EDEN-LLaMA and ChatGPT 1-shot wrongly explain that \"Joey\" is a big name. However, ChatGPT 5-shots can understand the commonsense of adding \"y\" to be informal, cute, and childish. Finally, we analyze the performance of variants of EDEN-LLaMA. As shown by EDEN-LLaMA hybrid, more EDEN data can slightly improve most metrics except for Reasonableness. This indicates that LLaMA also learns some co-occurrence features. Besides, the topics, speaker conditions, and dialogue styles in these two datasets are of evident difference, which may introduce some gaps to LLaMA's reasoning learning. As for EDEN-LLaMA sup, the improvement in EDEN-FR is more evident. This indicates that external commonsense knowledge can help predict emotion and cause, which aligns with previous works  [11, 19, 20, 52, 50] . However, commonsense pretraining shows no improvement in reasonableness. The reason may be that these commonsense data only support single-step reasoning. Reasoning speakers' inner activities is more complicated as multi-hop or compositional reasoning may be required.\n\nDirectly generating the explanation. The explanation E in EDEN acts as a CoT for emotion recognition in the form of \"The emotion is e t . E\". In this part, we let models only generate E, which is equivalent to the CoT going first and then predicting emotion. The results are shown in Tab. 8. It can be seen that both the prediction and the explanation are affected, especially to PLMs and EDEN-LLaMA. The reason may be the erroneous accumulation (which is also said to be hallucination by  [51] ). The findings align with the study of CoT in ScienceQA  [26] . Compared to the emotion, the impact on the cause is less because the cause is generated first. The drop in CF also shows the mutual indication of emotion and cause. It is worth noting that ChatGPT is less affected. This demonstrates its consistency in deducing emotion as it is one of the most powerful LLMs.\n\nInstruction Ablation. The instruction for EDEN-LLaMA (denoted as \"full\") considers several factors: the emotion list, the target speaker, the turn id of the target utterance, and the target utterance.\n\nB It looks so beautiful. How much is it? Four hundred yuan.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "A",
      "text": "That's a bit more than I wanted to pay. Can you cut the price down a bit?",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "B",
      "text": "Gold：Speaker B accepts the price of the mural and wants to take it. When Speaker B agrees to purchase the mural at the fixed price, Speaker A feels happy and satisfied that they were able to make a successful sale without compromising on the price. Therefore, Speaker A shows happiness.\n\n[happiness]\n\n[causal utterance]\n\nEDEN-LLaMA-7b：Speaker B decides to buy the mural despite initially expressing hesitation about the price. This decision affirms Speaker A's work and validates their pricing strategy, leading to a sense of satisfaction and accomplishment. Speaker A's happiness is a result of successfully selling the mural at a price that meets their expectations and fulfilling Speaker B's desire to own it. Therefore, Speaker A is happy. BART-large：Speaker A's response to Speaker B's question about the price of a mural shows that they are willing to reduce it and provide an affordable solution for their customer, which can make them feel valued and happy. Therefore, Speaker A expresses happiness. GPT2-large：Speaker B expresses their appreciation of the mural and offers to wrap it for free if Speaker A will reduce the price by 50%. This gesture shows that they value the work and appreciate its beauty, which makes Speaker A feel valued as well. Therefore, Speaker A displays happy emotions.\n\nI'm sorry. Ours is a fixed price shop and I can assure you this is the best price you can get for a mural like this.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "A",
      "text": "Maybe you are right. OK, I'll take it.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "B",
      "text": "Well, I'll have it wrapped for you.\n\nA Gold：Joey believes that his name \"Joey\" will weaken his perceived status or seriousness. The context of the conversation, centered around finding a more neutral and less ethnic stage name, amplifies his dissatisfaction with his current name. Joey's use of the phrase \"this big\" suggests he feels his name makes him seem insignificant or juvenile, which is why he is leaning towards changing it to 'Joe.' This indicates his displeasure or disgust with the connotations of his current name. Thus, Joey shows disgust.\n\nChatGPT-5shots：Joey expresses dissatisfaction with the name \"Joey\" and feels that it makes him sound childish or less serious. This emotional response is evoked by the phraseology of the speaker as he says \"Joey makes me sound like I am, I dunno, this big.\" The use of the phrase \"this big\" suggests a feeling of insignificance or being belittled, leading to a sense of sadness or disappointment. Joey's desire for a more neutral and mature-sounding name, coupled with his perception of how the name \"Joey\" affects others' perception of him, influences his emotional state. Therefore, Joey exhibits sadness in response to his perceived lack of seriousness associated with his current name.\n\nEDEN-LLaMA-13b：Joey thinks that his name is too big. Joey may be a very humble person, so he thinks that his name is too big, which makes him feel embarrassed. Therefore, he expresses his sadness.\n\nChatGPT-1shot：Joey expresses his discomfort with his own name, Joey, and how it makes him feel like he is being perceived as big or larger than he actually is. This emotion is triggered by the fact that Joey's agent suggested a more neutral name and Joey's belief that he should go by Joe instead. Joey's insecurity stems from his desire to be seen in a certain way and his fear of being perceived as something he doesn't want to be. In this case, the phraseology used by Joey (\"this big\") emphasizes his insecurity and the negative perception he associates with his current name. Therefore, based on these emotional causes, the emotion of Joey at the last utterance can be determined as insecurity.\n\nChandler: How about Joey ... Pepponi ? Joey: No , still too ethnic . My agent thinks I should have a name that is more neutral . Chandler: Joey ... Switzerland ? Joey: Plus , you know , I think it should be Joe . Joey: You know, Joey makes me sound like I am, I dunno, this big. [disgust]   Gary: So you wanna get some dinner? Phoebe: Yeah! Sure! Yep! Phoebe: Gary:\n\nGold：Phoebe said she was afraid of gunshots and would hide in Gary's arms if she heard them. Gary and Phoebe may have a crush on each other, so Phoebe's words resonate with Gary, leading him to make jokes about going to the bad neighborhood. In doing so, he expresses his joy.\n\nChatGPT-5shots：The phrase \"maybe you and I should take a walk through a bad neighborhood\" is a sarcastic and confrontational response from Gary. His statement implies that Phoebe's remark about throwing her body on him in case of a gunshot is over-dramatic and unnecessary. This triggers Gary's anger because he perceives Phoebe's comment as an exaggeration or an attempt to appear heroic, which he finds irritating. Gary's sarcastic suggestion of walking through a bad neighborhood is his way of challenging Phoebe and expressing his frustration at her exaggerated response. Therefore, Gary shows anger.\n\nEDEN-LLaMA-13b：Phoebe said she would throw herself on Gary if she heard a gunshot. Gary's response was to suggest taking a walk through a bad neighborhood. Phoebe's statement was likely perceived as overly dramatic or even threatening, which could have made Gary feel uncomfortable or even scared. Therefore, Gary expressed anger. We ablate these factors by removing the turn id (\"speaker-utterance\"); removing the target utterance (\"speaker-turn\"); removing the target utterance and its turn id (\"speaker\"); only keeping the emotion list (\"emotion\"); removing all factors (\"none\"). The performance of EDEN-LLaMA-7b on dev sets is illustrated in Tab. 7. The results show that considering the speaker, the target utterance, and the emotion list is important as these factors can guide models to realize the carrier of the emotion. Besides, if EDEN-LLaMA is not told the emotion range, it acts like ChatGPT to predict emotions out of the emotion list.\n\nError Analysis. We study the error case based on the most intuitive factor: emotion. By collecting samples that both ChatGPT 5-shots and EDEN-LLaMA-13b make the same error prediction, we can obtain confusion matrices of emotion on EDEN-DD and EDEN-FR, which is illustrated in Fig.  9 , Appendix D. It is shown that negative emotions are confused with each other and \"surprise\" is confused with all other emotions. The reason for the case of \"surprise\" is that \"surprise\" naturally has any valence, which means it can be positive or negative  [4] . As the distinction between emotions with the same valence is subtle, it requires more refined reasoning to appraisal  [37] . Besides, emotions with different valences (e.g., \"happiness\" and \"anger\") also show confusion. We utilize the pysentiment tool to compute the polarity score of the target utterance ϵ u and its dialogue ϵ d . For positive utterances, ϵ u =0.08 (±0.55) and ϵ c =0.01 (±0.45) . For negative utterances, ϵ u =0.35 (±0.60) and ϵ c =0.28 (±0.31) . This indicates that these samples contain expressions whose literal sentiment is opposite to the target emotion, and models tend to utilize this shallow semantic information. By viewing these samples, we found that part of the reasons may come from models' to-be-strengthened ability to compositional and multi-hop reasoning. As shown in Fig.  3  (c), the dialogue contains negative expressions like \"bad neighborhood\". Models depend on them regardless of the compositional realization of the cozy atmosphere in the context and the true intents of Phoebe and Gary.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Conclusion And Limitations",
      "text": "In this work, we propose a new task called \"Emotion Deducing Explanation in Dialogues\" (EDEN ) to thoroughly and interpretably evaluate models' ability to find emotional triggers and rationally reason the process of these triggers stimulating the emotion. To support EDEN, we curated two datasets EDEN-DD and EDEN-FR by human efforts. We further adapted experiments with a range of models on these datasets and found that LLMs are more competent on EDEN and their reasoning ability can be activated by EDEN to achieve better emotion and cause recognition. EDEN provides a new research direction of explainable emotion understanding in dialogues, which can replace previous counterparts in the era of LLMs.\n\nLimitations. The huge human labor of EDEN makes its size hard to scale. Besides, we only annotate emotional utterances due to the burden and there are considerable neutral utterances without explanation. In future works, we will explore more effective annotating methods.\n\n[ SYSTEM ] You are given a dialogue between speaker A and speaker B . The last utterance is a targeted utterance showing a kind of emotion . Some of the former contextual utterances of the targeted utterance or the targeted utterance itself are labeled as the causal utterances to the emotion of the targeted utterance . Your goal is to explain why these labeled utterances are the causes .\n\n[ USER ] Given the dialogue :\n\n(1) { s1 } : { u1 } ... ( n ) { sn } : { un }\n\nIn the dialogue , ( n ) is the targeted utterance showing the emotion of { target_emotion } . ( i ) , ... , ( j ) are labeled as the causal utterances . Please explain step -by -step why ( i ) , ... , ( j ) are the cause to speaker { sn } 's { target_emotion } at ( n ) based on the dialogue .\n\n[ Assistant ] The detailed explanation generated by ChatGPT .\n\n[ USER ] Please summarize your explanation .",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "A Prompt Templates Used In Our Experiments",
      "text": "In our work, ChatGPT and LLaMA are the main models for assistance and experiments. Due to the limited space in the main body, we illustrate the prompt templates we used in this appendix chapter.\n\nTo assist the annotation process, ChatGPT is used to generate the original analysis based on the gold emotion and causes. The two-round prompt template is shown in Fig.  4 , where {sn} is a speaker; {un} is {sn}'s utterance at the n-th turn; {target_emotion} is the gold emotion; (i),...,(j) are the ids of gold causal utterances.\n\nChatGPT uses in-context learning to generate EDEN explanation. Fig.  5  illustrates the prompt template for ChatGPT 5-shots. In the figure, [example 1] is a demonstration containing its dialogue clip and gold explanation; {sn} is the target speaker; {tn} is the utterance at the n-th turn.\n\nEDEN-LLaMA performs instruct tuning using the prompt template in Fig.  6 , which is denoted as \"full\". As mentioned in the main body, the \"full\" prompt considers several factors: the target speaker {target_speaker}; their utterance {last_utterance} at the {last_turn}-th turn; the emotion list [\"sadness\", \"fear\", \"disgust\", \"happiness\", \"anger\", \"surprise\"]. If {last_turn} is removed, the target speaker and their utterance are kept, which is denoted as the \"speaker-utterance\" prompt. If {last_utterance} is removed, the target speaker and the turn id of the last utterance are kept, which is denoted as the \"speaker-turn\" prompt. If both {last_utterance} and {last_turn} are removed, the target speaker is still kept and models need to learn the last utterance by words \"the last utterance\" in the prompt, which is denoted as the \"speaker\" prompt. If {last_utterance}, {last_turn}, and {last_speaker} are removed, only the emotion list remains, which is denoted as the \"emotion\" prompt. Removing all these factors, the prompt is called \"none\".\n\nThe prompt template for Reasonableness is shown in Fig.  7 . In the prompt, detailed criteria for the scoring are colored rose red. It can be seen that only correctly predicting the emotion and causes is not enough to get a high score, which sets a requirement of properly and rationally commonsense reasoning.\n\n[ SYSTEM ] Please analyze how the emotional causes lead to a speaker ' s emotion in a dialogue .\n\n[ USER ] Give a dialogue clip where a speaker is expressing a kind of emotion at the last utterance . You should identify the emotion of the speaker and explain how the emotional triggers lead to the emotion . For the explanation , you should firstly find the emotion -triggering causes , which can be events happened in the dialogue , sensory input , or phraseology of the speaker . Then , you should explain why these emotional causes can lead to the speaker ' s possible emotion by analyzing speakers ' mind -thinking and psychological activities or reasoning with commonsense . Lastly , determine the emotion based on your explanation about the causes ' effects . There are 6 types of emotions can be guessed at : [ happiness , sadness , fear , surprise , anger , disgust ] . Your explanation should be formed as a paragraph of text , and the number of words in your explanation should be around  50 -200.  Below are some examples that explain how the causes deduce the emotion :  [ SYSTEM ] Explain the process of a speaker ' s emotion arising in a dialogue .\n\n[ USER ] Provide a dialogue clip below : { dialogue_clip } In the dialogue clip , { target_speaker } expresses a non -neutral emotion at the last utterance ( { last_turn } ) , where the last utterance ( { last_turn } ) is \" { last_utterance } \". Your goal is to identify the emotion of { target_speaker } at ( { last_turn } ) and explain how the dialogue evokes the emotion . Your explanation should follow such a format : Firstly , identify the potential events or factors triggering this emotion . Subsequently , infer how these events or factors elicit the emotion through common -sense reasoning or an analysis of the speaker ' s psychological activities . Finally , determine the type of emotion induced by these evident triggers . The emotion of { target_speaker } at ( { last_turn } ) can be \" sadness \" , \" fear \" , \" disgust \" , \" happiness \" , \" anger \" , or \" surprise \" . Your answer is : [ SYSTEM ] You are a quality rater [ USER ] Your task is to rate the explanation on one metric . Please make sure you read and understand these instructions carefully . Please keep this dialogue open while reviewing , and refer to it as needed .\n\nEvaluation Criteria : Reasonableness (1 -3) Does the input explanation generated by a machine serve as a reasonable and correct analysis to how the emotion of a target speaker is deduced from the dialogue ? -A score of 1 ( no ) can be that the input explanation makes a wrong emotion prediction .\n\n-A score of 1 ( no ) can be that the input explanation makes a right emotion prediction but finds a wrong emotional causes from the dialogue .\n\n-A score of 1 ( no ) can be that the input explanation makes a right emotion prediction but wrongly analyzes how the emotional causes lead to the emotion by making factual errors or improperly commonsense reasoning . Besides , the explanation is lengthy and redundant .\n\n-A score of 2 ( somewhat ) means that the input explanation can guess the right emotion , finds partial emotional causes from the dialogue , and partially makes an acceptable analysis of why the emotional causes lead to the emotion in a commonsense way , but still has some improper deductions and need improvement according to the potential explanation .\n\n-A score of 3 ( yes ) means that the input explanation can start from the right and accurate emotion causes and properly deduce how the emotional causes lead to the right emotion by analyzing speakers ' psychological activities well and showing human commonsense . You can refer to the potential explanation for demonstration .\n\nEvaluation Steps : 1. Read the conversation . Read the target speaker and the target emotion .\n\n2. Read the potential explanation for analyzing how the emotional causes in the dialogue lead to the target speaker ' s emotion .\n\n3. Evaluate the Reasonableness of the input explanation based on the given dialogue . 4. Assign a rating score of 1 , 2 , or 3 for Reasonableness based on the evaluation criteria .\n\nQuestion : By reading the dialogue and the potential explanation which is a good demonstration , does the input explanation serve as a reasonable and correct analysis to how the emotion { en } of { sn } at ( n ) is deduced from the dialogue ? ( On a scale of 1 -3 , with 1 meaning the explanation is logically erroneous and 3 meaning the explanation is reasonable ) Dialogue :\n\n(1) { s1 } : { u1 } ... ( n ) { sn } : { un } Potential explanation : { gold_explanation } Input explanation : { g e ner ated_e xplan ation } Evaluation Form ( Answer by starting with \" Analysis :\" to analyze the given example regarding the evaluation criteria as concise as possible , and then give the numeric rating on the next line by \" Rating :\") :\n\n-Reasonableness :",
      "page_start": 15,
      "page_end": 15
    },
    {
      "section_name": "B Implementation Details And Hyper-Parameters",
      "text": "For the training details, generative models are fine-tuned with PyTorch distributed data-parallel mode with mixed precision of BFloat16 and TensorFloat32. The batch size per device is set to 4 and the world size is set to 4. The number of epochs is set to 5. For fully fine-tuned BART and GPT2, the learning rate is set to 1e-5 as usual and the learning rate of LoRA is set to 1e-4. For LoRA fine-tuning, the rank r is set to 8; the alpha is set to 16; the dropout rate is set to 0.05; LoRA adaptors are attached to the query, key, and value parameters; the backbone is frozen to int8. As the world size is 4 and BF16/TF32 is used, we use 4 pieces of A100 GPU whose memory size is 40G for experiments. Of course, fewer computation resources also support the training.\n\nFor complimentary commonsense pretraining, ATOMC  [35] , GLUCOSE  [27] , and CICEROv2  [38]  are utilized as the training data. In ATOMIC, the knowledge of oEffect, oReact, oWant, xAttr, xEffect, xIntent, xReact, xReason, xWant, Causes, Desires, HasProperty, and NotDesires are used, which contributes 550424 items of data. In GLUCOSE, all the 10 types of knowledge about Causes/Enables, Motivates, Results-in, which contributes 304099 items of data. In CICEROv2, all the mutual data are used, which contributes 5495 items of data. The complimentary commonsense pretraining sets the batch size per device to 8 using accumulation steps of 4 and trains for 4 epochs. Other hyperparameters for it are the same as those in the last paragraphs. As we mentioned in the main body, we set a prompt template pool to transfer the knowledge into natural language. Due to the limited space for the demonstration, we show the transferring in our code.\n\nThe temperature is set to 1.0 for ChatGPT and GPT4 for generations. For other generative models, the temperature is set to 0.2 adding a repetition penalty of 1.2. The maximum number of new tokens is 200. TFD  [42]  and BHG  [50]  are re-implemented based on their official code 34 using a piece of 40G A100 GPU.",
      "page_start": 18,
      "page_end": 19
    },
    {
      "section_name": "C Eden For Emotion-Cause Triplet Extraction",
      "text": "To achieve emotion-cause triplets extraction in dialogues using EDEN , there are two points that need to be solved: (1) EDEN only deals with samples whose last utterance is in an unknown emotion and skips those dialogues whose last utterance is neutral. The reason for this is that neutral utterances appear frequently in dialogues and our human labor cannot cover such huge burdens. (2) EDEN generates natural text instead of triplets in numbers.\n\nFor point 1, we propose to train a binary emotion predictor B. For every dialogue clip, inputting the clip and its last utterance, B identifies whether the last utterance possesses an emotion. If it has an emotion, the label will be 1, otherwise, the label will be 0 to indicate neutral. Samples predicted to be 1 will be input to EDEN-LLaMA-7b for EDEN analysis. To solve point 2, we utilize our Cause Evaluator to guess causal utterances for the last utterance. Since the emotion is easy to extract from the explanation, the final triplets can be constructed. We denote the framework as EDEN-ECTEC, whose flow chart is depicted in Fig.  8 .",
      "page_start": 18,
      "page_end": 18
    },
    {
      "section_name": "D Additional Error Cases",
      "text": "We study the error cases by collecting samples on that both ChatGPT 5-shots and EDEN-LLaMA-13b make the same and wrong emotion prediction. Fig.  9  provides two confusion matrices, where the left one is for EDEN-DD and the right one is for EDEN-FR. Both matrices have removed their diagonal. The blocks with darker colors are emphasized to show that confusion frequently happens (1) between negative emotions; and (2) between \"surprise\" and all other emotions. By the way, the pysentiment tool is in this url  5  .",
      "page_start": 19,
      "page_end": 19
    },
    {
      "section_name": "E The Annotating Interface",
      "text": "The annotating interface screenshot is shown in Fig.  10 , where all the gold labels and additional topic information are given. The annotators are required to read the ChatGPT explanation, score it, and make revisions accordingly.\n\n-The gold emotion is provided to the annotator -Causal utterances are provided to the annotator The topic information may help annotators quickly understand the dialogue.\n\n-The type of causes (RECCON-DailyDialogue)\n\nThe dialogue content",
      "page_start": 19,
      "page_end": 19
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: ∗Corresponding author.",
      "page": 1
    },
    {
      "caption": "Figure 1: A case of EDEN",
      "page": 2
    },
    {
      "caption": "Figure 1: , only giving a dialogue",
      "page": 2
    },
    {
      "caption": "Figure 4: , Appendix A. To further assist human annotators, we also utilize ChatGPT to",
      "page": 3
    },
    {
      "caption": "Figure 2: (a) the emotion distributions in DD and FR; (b) The number of samples whose original",
      "page": 4
    },
    {
      "caption": "Figure 1: Table 1: The average scores for 3 as-",
      "page": 4
    },
    {
      "caption": "Figure 10: , Appendix E.",
      "page": 4
    },
    {
      "caption": "Figure 2: (a), the emotion distributions are different in DD and FR, where DD shows a more",
      "page": 4
    },
    {
      "caption": "Figure 2: (b). The reason for FR having more good ChatGPT analyses is",
      "page": 5
    },
    {
      "caption": "Figure 2: (c). The reason for only considering up to 3 causal utterances is",
      "page": 5
    },
    {
      "caption": "Figure 5: , Appendix A.",
      "page": 6
    },
    {
      "caption": "Figure 6: , Appendix A. In the instruction, several factors, that may affect the behavior of LLaMA2,",
      "page": 6
    },
    {
      "caption": "Figure 7: , Appendix A, which provides the detailed criteria.",
      "page": 6
    },
    {
      "caption": "Figure 3: (a). In this case, BART",
      "page": 7
    },
    {
      "caption": "Figure 3: (b) gives a case",
      "page": 8
    },
    {
      "caption": "Figure 3: (a) A case of BART and GPT2 reasoning with factual errors. (b) A case of the activation of",
      "page": 9
    },
    {
      "caption": "Figure 3: (c), the dialogue contains negative expressions like",
      "page": 9
    },
    {
      "caption": "Figure 4: The two-round prompt template for ChatGPT to generate the original explanation with the",
      "page": 15
    },
    {
      "caption": "Figure 4: , where {sn} is a speaker;",
      "page": 15
    },
    {
      "caption": "Figure 5: illustrates the prompt",
      "page": 15
    },
    {
      "caption": "Figure 6: , which is denoted",
      "page": 15
    },
    {
      "caption": "Figure 7: In the prompt, detailed criteria for the",
      "page": 15
    },
    {
      "caption": "Figure 5: Prompt template for ChatGPT 5-shots.",
      "page": 16
    },
    {
      "caption": "Figure 6: Prompt template for EDEN-LLaMA, which is called “full”.",
      "page": 16
    },
    {
      "caption": "Figure 7: Prompt template for Reasonableness. The text with rose color is the detailed criteria of",
      "page": 17
    },
    {
      "caption": "Figure 8: The framework of EDEN-ECTEC to extract emotion-cause triplets from dialogues.",
      "page": 18
    },
    {
      "caption": "Figure 8: 3https://github.com/TuGengs/TFD",
      "page": 18
    },
    {
      "caption": "Figure 9: provides two confusion matrices, where the left",
      "page": 19
    },
    {
      "caption": "Figure 9: Confusion matrices of emotions calculated from the same erroneous samples of ChatGPT",
      "page": 19
    },
    {
      "caption": "Figure 10: , where all the gold labels and additional topic",
      "page": 19
    },
    {
      "caption": "Figure 10: The annotating interface screenshot.",
      "page": 19
    },
    {
      "caption": "Figure 3: (b)(c) are shown in Fig. 11 and",
      "page": 20
    },
    {
      "caption": "Figure 12: In these figures, models fail to make a promising analysis due to the to-be-strengthened",
      "page": 20
    },
    {
      "caption": "Figure 11: Other models on the case of “Joey changing name” in Fig. 3 (b).",
      "page": 20
    },
    {
      "caption": "Figure 12: Other models on the case of “Phoebe and Gary flirting” in Fig. 3 (c).",
      "page": 20
    }
  ],
  "tables": [
    {
      "caption": "Table 6: The performance of different methods extracting",
      "data": [
        {
          "Method": "",
          "EDEN-DD": "B-3\nB-4\nR-L\nMT\nCr\nEF\nCF",
          "EDEN-FR": "B-3\nB-4\nR-L\nMT\nCr\nEF\nCF"
        },
        {
          "Method": "BART-lg\nGPT2-lg",
          "EDEN-DD": "14.93\n10.01\n27.25\n32.68\n12.42\n82.85\n65.51\n12.87\n8.63\n26.87\n29.55\n11.87\n82.94\n64.36",
          "EDEN-FR": "16.93\n10.29\n23.07\n26.25\n17.04\n55.94\n70.62\n13.50\n8.23\n21.67\n22.65\n14.79\n51.25\n65.32"
        },
        {
          "Method": "ChatGPT-5s",
          "EDEN-DD": "11.53\n7.26\n28.22\n40.04\n5.28\n79.57\n65.87",
          "EDEN-FR": "13.53\n7.89\n23.97\n34.35\n5.02\n61.69\n74.71"
        },
        {
          "Method": "E-LLaMA-7b\nE-LLaMA-13b",
          "EDEN-DD": "17.18\n11.69\n30.02\n33.72\n16.96\n81.81\n66.56\n17.88\n12.16\n30.20\n34.87\n16.11\n86.39\n66.40",
          "EDEN-FR": "18.52\n11.40\n24.21\n26.57\n16.71\n59.10\n73.31\n19.43\n12.07\n24.97\n27.88\n19.77\n62.20\n74.15"
        }
      ],
      "page": 8
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "EDEN-LLaMA-7b：Joey's agent suggests a name change to make him sound more neutral, which Joey \ndisagrees with. Joey believes that his name is not neutral and that it makes him sound big. This suggests that \nJoey is not happy with his name and feels that it does not accurately reflect his personality. Therefore, Joey \nshows sadness.": "EDEN-LLaMA-7b sup：Joey thinks that \"Joey\" makes him sound like a big person. Joey may have been teased \nby others for having a name that is too big, so he expresses his disgust."
        },
        {
          "EDEN-LLaMA-7b：Joey's agent suggests a name change to make him sound more neutral, which Joey \ndisagrees with. Joey believes that his name is not neutral and that it makes him sound big. This suggests that \nJoey is not happy with his name and feels that it does not accurately reflect his personality. Therefore, Joey \nshows sadness.": "EDEN-LLaMA-13b sup：Joey thinks that his name sounds too big. Joey may have a complex about his name, \nso he thinks it sounds too big. People often feel sad when they have a complex about something. Therefore, \nJoey shows sadness."
        },
        {
          "EDEN-LLaMA-7b：Joey's agent suggests a name change to make him sound more neutral, which Joey \ndisagrees with. Joey believes that his name is not neutral and that it makes him sound big. This suggests that \nJoey is not happy with his name and feels that it does not accurately reflect his personality. Therefore, Joey \nshows sadness.": "BART-large：Joey thinks that Joey's name is too ethnic and makes him sound like he is big. This may be \nbecause Joey has a crush on Chandler, which can make his feelings for Chandler hurt. Therefore, Joey shows \nsadness."
        },
        {
          "EDEN-LLaMA-7b：Joey's agent suggests a name change to make him sound more neutral, which Joey \ndisagrees with. Joey believes that his name is not neutral and that it makes him sound big. This suggests that \nJoey is not happy with his name and feels that it does not accurately reflect his personality. Therefore, Joey \nshows sadness.": "GPT2-large：Joey suggests naming his band after Switzerland. It can be assumed that Joey likes Switzerland \nand wants to give it a good name, so he proposes a new name for his band. Therefore, he expresses his joy."
        }
      ],
      "page": 20
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "EDEN-LLaMA-7b：Phoebe's statement implies that she is physically attracted to Gary, which could be \nperceived as flirtatious or even sexual. Gary's response suggests that he is not interested in Phoebe's \nadvances and may even feel threatened or uncomfortable. Therefore, Gary shows anger.": "ChatGPT-1shots：The emotion-triggering cause in the dialogue is Phoebe's statement in utterance (3), \\\"Oh, \nyou know what? If I heard a shot right now, I would throw my body on you.\\\" This statement can be seen as a \nthreat or a provocative remark. Gary's response in utterance (4), \\\"Oh yeah? Well maybe you and I should take \na walk through a bad neighborhood,\\\" indicates his anger towards Phoebe's suggestion. Gary's mind-thinking \nand psychological activities may include feelings of frustration, annoyance, and the perception of Phoebe's \nstatement as disrespectful or inappropriate. This aligns with the common interpretation that anger is \ncharacterized by feelings of displeasure, resentment, and a desire to retaliate. Therefore, Gary's emotion can \nbe inferred as anger."
        },
        {
          "EDEN-LLaMA-7b：Phoebe's statement implies that she is physically attracted to Gary, which could be \nperceived as flirtatious or even sexual. Gary's response suggests that he is not interested in Phoebe's \nadvances and may even feel threatened or uncomfortable. Therefore, Gary shows anger.": "EDEN-LLaMA-7b sup：Phoebe says she would throw her body on Gary if she heard a gunshot. Phoebe's \nstatement is a threat, and Gary responds by suggesting that they go for a walk in a bad neighborhood. This may \nbe a way for Gary to express his anger towards Phoebe's behavior, as he is trying to make her feel \nuncomfortable. Therefore, Gary shows anger."
        },
        {
          "EDEN-LLaMA-7b：Phoebe's statement implies that she is physically attracted to Gary, which could be \nperceived as flirtatious or even sexual. Gary's response suggests that he is not interested in Phoebe's \nadvances and may even feel threatened or uncomfortable. Therefore, Gary shows anger.": "EDEN-LLaMA-13b sup：Phoebe expresses her love for Gary, but Gary suggests that they go to a dangerous \nneighborhood. Gary may feel that Phoebe's love is not sincere, so he expresses his anger."
        }
      ],
      "page": 20
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Social psychology",
      "authors": [
        "Elliot Aronson",
        "Timothy Wilson",
        "Samuel Sommers"
      ],
      "year": "2005",
      "venue": "Social psychology"
    },
    {
      "citation_id": "2",
      "title": "COMET: commonsense transformers for automatic knowledge graph construction",
      "authors": [
        "Antoine Bosselut",
        "Hannah Rashkin",
        "Maarten Sap",
        "Chaitanya Malaviya",
        "Asli Celikyilmaz",
        "Yejin Choi"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019"
    },
    {
      "citation_id": "3",
      "title": "Language models are few-shot learners",
      "authors": [
        "B Tom",
        "Benjamin Brown",
        "Nick Mann",
        "Melanie Ryder",
        "Jared Subbiah",
        "Prafulla Kaplan",
        "Arvind Dhariwal",
        "Pranav Neelakantan",
        "Girish Shyam",
        "Amanda Sastry",
        "Sandhini Askell",
        "Ariel Agarwal",
        "Gretchen Herbert-Voss",
        "Tom Krueger",
        "Rewon Henighan",
        "Aditya Child",
        "Daniel Ramesh",
        "Jeffrey Ziegler",
        "Clemens Wu",
        "Christopher Winter",
        "Mark Hesse",
        "Eric Chen",
        "Mateusz Sigler",
        "Scott Litwin",
        "Benjamin Gray",
        "Jack Chess",
        "Christopher Clark",
        "Sam Berner",
        "Alec Mccandlish",
        "Ilya Radford",
        "Dario Sutskever",
        "Amodei"
      ],
      "year": "2020",
      "venue": "Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems"
    },
    {
      "citation_id": "4",
      "title": "Toward a theory of personal space expectations and their violations",
      "authors": [
        "K Judee",
        "Stephen Burgoon",
        "Jones"
      ],
      "year": "1976",
      "venue": "Human communication research"
    },
    {
      "citation_id": "5",
      "title": "IEMOCAP: interactive emotional dyadic motion capture database",
      "authors": [
        "Carlos Busso",
        "Murtaza Bulut",
        "Chi-Chun Lee",
        "Abe Kazemzadeh",
        "Emily Mower",
        "Samuel Kim",
        "Jeannette Chang",
        "Sungbok Lee",
        "Shrikanth Narayanan"
      ],
      "year": "2008",
      "venue": "Lang. Resour. Evaluation"
    },
    {
      "citation_id": "6",
      "title": "Goemotions: A dataset of fine-grained emotions",
      "authors": [
        "Dorottya Demszky",
        "Dana Movshovitz-Attias",
        "Jeongwoo Ko",
        "Alan Cowen",
        "Gaurav Nemade",
        "Sujith Ravi"
      ],
      "year": "2020",
      "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020"
    },
    {
      "citation_id": "7",
      "title": "Nice perfume. how long did you marinate in it? multimodal sarcasm explanation",
      "authors": [
        "Poorav Desai",
        "Tanmoy Chakraborty",
        "Md Akhtar"
      ],
      "year": "2022",
      "venue": "Thirty-Sixth AAAI Conference on Artificial Intelligence, AAAI 2022, Thirty-Fourth Conference on Innovative Applications of Artificial Intelligence, IAAI 2022, The Twelveth Symposium on Educational in Artificial Intelligence, EAAI 2022 Virtual Event"
    },
    {
      "citation_id": "8",
      "title": "ECPE-2D: emotion-cause pair extraction based on joint two-dimensional representation, interaction and prediction",
      "authors": [
        "Zixiang Ding",
        "Rui Xia",
        "Jianfei Yu"
      ],
      "year": "2020",
      "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020"
    },
    {
      "citation_id": "9",
      "title": "Facial expression and emotion",
      "authors": [
        "Paul Ekman"
      ],
      "year": "1993",
      "venue": "American psychologist"
    },
    {
      "citation_id": "10",
      "title": "Emotion recognition in conversations: A survey focusing on context, speaker dependencies, and fusion methods",
      "authors": [
        "Yao Fu",
        "Shaoyang Yuan",
        "Chi Zhang",
        "Juan Cao"
      ],
      "year": "2023",
      "venue": "Electronics"
    },
    {
      "citation_id": "11",
      "title": "COSMIC: commonsense knowledge for emotion identification in conversations",
      "authors": [
        "Deepanway Ghosal",
        "Navonil Majumder",
        "Alexander Gelbukh",
        "Rada Mihalcea",
        "Soujanya Poria"
      ],
      "year": "2020",
      "venue": "Findings of the Association for Computational Linguistics: EMNLP 2020"
    },
    {
      "citation_id": "12",
      "title": "CI-CERO: A dataset for contextualized commonsense inference in dialogues",
      "authors": [
        "Deepanway Ghosal",
        "Siqi Shen",
        "Navonil Majumder",
        "Rada Mihalcea",
        "Soujanya Poria"
      ],
      "year": "2022",
      "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "13",
      "title": "Lora: Low-rank adaptation of large language models",
      "authors": [
        "Edward Hu",
        "Yelong Shen",
        "Phillip Wallis",
        "Zeyuan Allen-Zhu",
        "Yuanzhi Li",
        "Shean Wang",
        "Lu Wang",
        "Weizhu Chen"
      ],
      "year": "2022",
      "venue": "The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event"
    },
    {
      "citation_id": "14",
      "title": "Ecr-chain: Advancing generative language models to better emotion-cause reasoners through reasoning chains",
      "authors": [
        "Zhaopei Huang",
        "Jinming Zhao",
        "Qin Jin"
      ],
      "year": "2024",
      "venue": "Ecr-chain: Advancing generative language models to better emotion-cause reasoners through reasoning chains"
    },
    {
      "citation_id": "15",
      "title": "(comet-) atomic 2020: On symbolic and neural commonsense knowledge graphs",
      "authors": [
        "Jena Hwang",
        "Chandra Bhagavatula",
        "Le Ronan",
        "Jeff Bras",
        "Keisuke Da",
        "Antoine Sakaguchi",
        "Yejin Bosselut",
        "Choi"
      ],
      "year": "2021",
      "venue": "Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021, Virtual Event"
    },
    {
      "citation_id": "16",
      "title": "Negated and misprimed probes for pretrained language models: Birds can talk, but cannot fly",
      "authors": [
        "Nora Kassner",
        "Hinrich Schütze"
      ],
      "year": "2020",
      "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020"
    },
    {
      "citation_id": "17",
      "title": "When did you become so smart, oh wise one?! sarcasm explanation in multi-modal multi-party dialogues",
      "authors": [
        "Shivani Kumar",
        "Atharva Kulkarni",
        "Md Akhtar",
        "Tanmoy Chakraborty"
      ],
      "year": "2022",
      "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "18",
      "title": "BART: denoising sequence-to-sequence pretraining for natural language generation, translation, and comprehension",
      "authors": [
        "Mike Lewis",
        "Yinhan Liu",
        "Naman Goyal",
        "Marjan Ghazvininejad",
        "Abdelrahman Mohamed",
        "Omer Levy",
        "Veselin Stoyanov",
        "Luke Zettlemoyer"
      ],
      "year": "2020",
      "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020"
    },
    {
      "citation_id": "19",
      "title": "Past, present, and future: Conversational emotion recognition through structural modeling of psychological knowledge",
      "authors": [
        "Jiangnan Li",
        "Zheng Lin",
        "Peng Fu",
        "Weiping Wang"
      ],
      "year": "2021",
      "venue": "Findings of the Association for Computational Linguistics: EMNLP 2021, Virtual Event / Punta Cana"
    },
    {
      "citation_id": "20",
      "title": "Neutral utterances are also causes: Enhancing conversational causal emotion entailment with social commonsense knowledge",
      "authors": [
        "Jiangnan Li",
        "Fandong Meng",
        "Zheng Lin",
        "Rui Liu",
        "Peng Fu",
        "Yanan Cao",
        "Weiping Wang",
        "Jie Zhou"
      ],
      "year": "2022",
      "venue": "Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence"
    },
    {
      "citation_id": "21",
      "title": "ECPEC: emotioncause pair extraction in conversations",
      "authors": [
        "Wei Li",
        "Yang Li",
        "Vlad Pandelea",
        "Mengshi Ge",
        "Luyao Zhu",
        "Erik Cambria"
      ],
      "year": "2023",
      "venue": "IEEE Trans. Affect. Comput"
    },
    {
      "citation_id": "22",
      "title": "Dailydialog: A manually labelled multi-turn dialogue dataset",
      "authors": [
        "Yanran Li",
        "Hui Su",
        "Xiaoyu Shen",
        "Wenjie Li",
        "Ziqiang Cao",
        "Shuzi Niu"
      ],
      "year": "2017",
      "venue": "Proceedings of the Eighth International Joint Conference on Natural Language Processing"
    },
    {
      "citation_id": "23",
      "title": "Explainable multimodal emotion reasoning",
      "authors": [
        "Zheng Lian",
        "Licai Sun",
        "Mingyu Xu",
        "Haiyang Sun",
        "Ke Xu",
        "Zhuofan Wen",
        "Shun Chen",
        "Bin Liu",
        "Jianhua Tao"
      ],
      "year": "2023",
      "venue": "Explainable multimodal emotion reasoning"
    },
    {
      "citation_id": "24",
      "title": "G-eval: NLG evaluation using gpt-4 with better human alignment",
      "authors": [
        "Yang Liu",
        "Dan Iter",
        "Yichong Xu",
        "Shuohang Wang",
        "Ruochen Xu",
        "Chenguang Zhu"
      ],
      "year": "2023",
      "venue": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023"
    },
    {
      "citation_id": "25",
      "title": "Roberta: A robustly optimized BERT pretraining approach",
      "authors": [
        "Yinhan Liu",
        "Myle Ott",
        "Naman Goyal",
        "Jingfei Du",
        "Mandar Joshi",
        "Danqi Chen",
        "Omer Levy",
        "Mike Lewis",
        "Luke Zettlemoyer",
        "Veselin Stoyanov"
      ],
      "year": "2019",
      "venue": "Roberta: A robustly optimized BERT pretraining approach"
    },
    {
      "citation_id": "26",
      "title": "Learn to explain: Multimodal reasoning via thought chains for science question answering",
      "authors": [
        "Pan Lu",
        "Swaroop Mishra",
        "Tanglin Xia",
        "Liang Qiu",
        "Kai-Wei Chang",
        "Song-Chun Zhu",
        "Oyvind Tafjord",
        "Peter Clark",
        "Ashwin Kalyan"
      ],
      "year": "2022",
      "venue": "Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems"
    },
    {
      "citation_id": "27",
      "title": "GLUCOSE: generalized and contextualized story explanations",
      "authors": [
        "Nasrin Mostafazadeh",
        "Aditya Kalyanpur",
        "Lori Moon",
        "David Buchanan",
        "Lauren Berkowitz",
        "Or Biran",
        "Jennifer Chu-Carroll"
      ],
      "year": "2020",
      "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "28",
      "title": "Optimizing language models for dialogue",
      "authors": [
        "Openai",
        "Chatgpt"
      ],
      "year": "2022",
      "venue": "Optimizing language models for dialogue"
    },
    {
      "citation_id": "29",
      "title": "MELD: A multimodal multi-party dataset for emotion recognition in conversations",
      "authors": [
        "Soujanya Poria",
        "Devamanyu Hazarika",
        "Navonil Majumder",
        "Gautam Naik",
        "Erik Cambria",
        "Rada Mihalcea"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019"
    },
    {
      "citation_id": "30",
      "title": "Recognizing emotion cause in conversations",
      "authors": [
        "Soujanya Poria",
        "Navonil Majumder",
        "Devamanyu Hazarika",
        "Deepanway Ghosal",
        "Rishabh Bhardwaj",
        "Samson Yu Bai Jian",
        "Pengfei Hong",
        "Romila Ghosh",
        "Abhinaba Roy",
        "Niyati Chhaya",
        "Alexander Gelbukh",
        "Rada Mihalcea"
      ],
      "year": "2021",
      "venue": "Cogn. Comput"
    },
    {
      "citation_id": "31",
      "title": "Language models are unsupervised multitask learners",
      "authors": [
        "Alec Radford",
        "Jeffrey Wu",
        "Rewon Child",
        "David Luan",
        "Dario Amodei",
        "Ilya Sutskever"
      ],
      "year": "2019",
      "venue": "OpenAI blog"
    },
    {
      "citation_id": "32",
      "title": "Sentence-bert: Sentence embeddings using siamese bertnetworks",
      "authors": [
        "Nils Reimers",
        "Iryna Gurevych"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019"
    },
    {
      "citation_id": "33",
      "title": "A chatbot for mental health support: exploring the impact of emohaa on reducing mental distress in china",
      "authors": [
        "Sahand Sabour",
        "Wen Zhang",
        "Xiyao Xiao",
        "Yuwei Zhang",
        "Yinhe Zheng",
        "Jiaxin Wen",
        "Jialu Zhao",
        "Minlie Huang"
      ],
      "year": "2023",
      "venue": "Frontiers Digit. Health"
    },
    {
      "citation_id": "34",
      "title": "Tvshowguess: Character comprehension in stories as speaker guessing",
      "authors": [
        "Yisi Sang",
        "Xiangyang Mou",
        "Mo Yu",
        "Shunyu Yao",
        "Jing Li",
        "Jeffrey Stanton"
      ],
      "year": "2022",
      "venue": "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2022"
    },
    {
      "citation_id": "35",
      "title": "ATOMIC: an atlas of machine commonsense for if-then reasoning",
      "authors": [
        "Maarten Sap",
        "Le Ronan",
        "Emily Bras",
        "Chandra Allaway",
        "Nicholas Bhagavatula",
        "Hannah Lourie",
        "Brendan Rashkin",
        "Noah Roof",
        "Yejin Smith",
        "Choi"
      ],
      "year": "2019",
      "venue": "The Thirty-Third AAAI Conference on Artificial Intelligence, AAAI 2019, The Thirty-First Innovative Applications of Artificial Intelligence Conference, IAAI 2019, The Ninth AAAI Symposium on Educational Advances in Artificial Intelligence"
    },
    {
      "citation_id": "36",
      "title": "Social iqa: Commonsense reasoning about social interactions",
      "authors": [
        "Maarten Sap",
        "Hannah Rashkin",
        "Derek Chen",
        "Ronan Le Bras",
        "Yejin Choi"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019"
    },
    {
      "citation_id": "37",
      "title": "Appraisal processes in emotion: Theory, methods, research",
      "authors": [
        "Klaus Scherer",
        "Angela Schorr",
        "Tom Johnstone"
      ],
      "year": "2001",
      "venue": "Appraisal processes in emotion: Theory, methods, research"
    },
    {
      "citation_id": "38",
      "title": "Multiview contextual commonsense inference: A new dataset and task",
      "authors": [
        "Siqi Shen",
        "Deepanway Ghosal",
        "Navonil Majumder",
        "Henry Lim",
        "Rada Mihalcea",
        "Soujanya Poria"
      ],
      "year": "2022",
      "venue": "Multiview contextual commonsense inference: A new dataset and task"
    },
    {
      "citation_id": "39",
      "title": "Conceptnet 5.5: An open multilingual graph of general knowledge",
      "authors": [
        "Robyn Speer",
        "Joshua Chin",
        "Catherine Havasi"
      ],
      "year": "2017",
      "venue": "Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence"
    },
    {
      "citation_id": "40",
      "title": "Recent trends in deep learning based textual emotion cause extraction",
      "authors": [
        "Xinxin Su",
        "Zhen Huang",
        "Yunxiang Zhao",
        "Yifan Chen",
        "Yong Dou",
        "Hengyue Pan"
      ],
      "venue": "IEEE ACM Trans. Audio Speech Lang. Process"
    },
    {
      "citation_id": "41",
      "title": "",
      "authors": [
        "Hugo Touvron",
        "Louis Martin",
        "Kevin Stone",
        "Peter Albert",
        "Amjad Almahairi",
        "Yasmine Babaei",
        "Nikolay Bashlykov",
        "Soumya Batra",
        "Prajjwal Bhargava",
        "Shruti Bhosale",
        "Dan Bikel",
        "Lukas Blecher",
        "Cristian Canton-Ferrer",
        "Moya Chen",
        "Guillem Cucurull",
        "David Esiobu",
        "Jude Fernandes",
        "Jeremy Fu",
        "Wenyin Fu",
        "Brian Fuller",
        "Cynthia Gao",
        "Vedanuj Goswami",
        "Naman Goyal",
        "Anthony Hartshorn",
        "Saghar Hosseini",
        "Rui Hou",
        "Hakan Inan",
        "Marcin Kardas",
        "Viktor Kerkez",
        "Madian Khabsa",
        "Isabel Kloumann",
        "Artem Korenev",
        "Punit Singh Koura",
        "Marie-Anne Lachaux",
        "Thibaut Lavril",
        "Jenya Lee",
        "Diana Liskovich",
        "Yinghai Lu",
        "Yuning Mao",
        "Xavier Martinet",
        "Todor Mihaylov",
        "Pushkar Mishra",
        "Igor Molybog",
        "Yixin Nie",
        "Andrew Poulton",
        "Jeremy Reizenstein",
        "Rashi Rungta",
        "Kalyan Saladi",
        "Alan Schelten",
        "Ruan Silva"
      ],
      "year": "2023",
      "venue": ""
    },
    {
      "citation_id": "42",
      "title": "A training-free debiasing framework with counterfactual reasoning for conversational emotion detection",
      "authors": [
        "Geng Tu",
        "Ran Jing",
        "Bin Liang",
        "Min Yang",
        "Kam-Fai Wong",
        "Ruifeng Xu"
      ],
      "year": "2023",
      "venue": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023"
    },
    {
      "citation_id": "43",
      "title": "An empirical study on multiple knowledge from chatgpt for emotion recognition in conversations",
      "authors": [
        "Geng Tu",
        "Bin Liang",
        "Bing Qin",
        "Kam-Fai Wong",
        "Ruifeng Xu"
      ],
      "year": "2023",
      "venue": "Findings of the Association for Computational Linguistics: EMNLP 2023"
    },
    {
      "citation_id": "44",
      "title": "Multimodal emotion-cause pair extraction in conversations",
      "authors": [
        "Fanfan Wang",
        "Zixiang Ding",
        "Rui Xia",
        "Zhaoyu Li",
        "Jianfei Yu"
      ],
      "year": "2023",
      "venue": "IEEE Trans. Affect. Comput"
    },
    {
      "citation_id": "45",
      "title": "Generative emotion cause triplet extraction in conversations with commonsense knowledge",
      "authors": [
        "Fanfan Wang",
        "Jianfei Yu",
        "Rui Xia"
      ],
      "year": "2023",
      "venue": "Findings of the Association for Computational Linguistics: EMNLP 2023"
    },
    {
      "citation_id": "46",
      "title": "Zero-shot cross-lingual summarization via large language models",
      "authors": [
        "Jiaan Wang",
        "Yunlong Liang",
        "Fandong Meng",
        "Beiqi Zou",
        "Zhixu Li",
        "Jianfeng Qu",
        "Jie Zhou"
      ],
      "year": "2023",
      "venue": "Proceedings of the 4th New Frontiers in Summarization Workshop"
    },
    {
      "citation_id": "47",
      "title": "Symbolic knowledge distillation: from general language models to commonsense models",
      "authors": [
        "Peter West",
        "Chandra Bhagavatula",
        "Jack Hessel",
        "Jena Hwang",
        "Liwei Jiang",
        "Ronan Le Bras",
        "Ximing Lu",
        "Sean Welleck",
        "Yejin Choi"
      ],
      "year": "2022",
      "venue": "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2022"
    },
    {
      "citation_id": "48",
      "title": "Emotion-cause pair extraction: A new task to emotion analysis in texts",
      "authors": [
        "Rui Xia",
        "Zixiang Ding"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019"
    },
    {
      "citation_id": "49",
      "title": "Knowledge-interactive network with sentiment polarity intensity-aware multi-task learning for emotion recognition in conversations",
      "authors": [
        "Yunhe Xie",
        "Kailai Yang",
        "Chengjie Sun",
        "Bingquan Liu",
        "Zhenzhou Ji"
      ],
      "year": "2021",
      "venue": "Findings of the Association for Computational Linguistics: EMNLP 2021, Virtual Event / Punta Cana"
    },
    {
      "citation_id": "50",
      "title": "A bipartite graph is all we need for enhancing emotional reasoning with commonsense knowledge",
      "authors": [
        "Kailai Yang",
        "Tianlin Zhang",
        "Shaoxiong Ji",
        "Sophia Ananiadou"
      ],
      "year": "2023",
      "venue": "Proceedings of the 32nd ACM International Conference on Information and Knowledge Management, CIKM 2023"
    },
    {
      "citation_id": "51",
      "title": "Multimodal chain-of-thought reasoning in language models",
      "authors": [
        "Zhuosheng Zhang",
        "Aston Zhang",
        "Mu Li",
        "Hai Zhao",
        "George Karypis",
        "Alex Smola"
      ],
      "year": "2023",
      "venue": "Multimodal chain-of-thought reasoning in language models"
    },
    {
      "citation_id": "52",
      "title": "Knowledge-bridged causal interaction network for causal emotion entailment",
      "authors": [
        "Weixiang Zhao",
        "Yanyan Zhao",
        "Zhuojun Li",
        "Bing Qin"
      ],
      "year": "2023",
      "venue": "Thirty-Seventh AAAI Conference on Artificial Intelligence, AAAI 2023, Thirty-Fifth Conference on Innovative Applications of Artificial Intelligence, IAAI 2023, Thirteenth Symposium on Educational Advances in Artificial Intelligence, EAAI 2023"
    },
    {
      "citation_id": "53",
      "title": "Ueca-prompt: Universal prompt for emotion cause analysis",
      "authors": [
        "Xiaopeng Zheng",
        "Zhiyue Liu",
        "Zizhen Zhang",
        "Zhaoyang Wang",
        "Jiahai Wang"
      ],
      "year": "2022",
      "venue": "Proceedings of the 29th International Conference on Computational Linguistics, COLING 2022"
    },
    {
      "citation_id": "54",
      "title": "Knowledge-enriched transformer for emotion detection in textual conversations",
      "authors": [
        "Peixiang Zhong",
        "Di Wang",
        "Chunyan Miao"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019"
    },
    {
      "citation_id": "55",
      "title": "Topic-driven and knowledgeaware transformer for dialogue emotion detection",
      "authors": [
        "Lixing Zhu",
        "Gabriele Pergola",
        "Lin Gui",
        "Deyu Zhou",
        "Yulan He"
      ],
      "year": "2021",
      "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021"
    }
  ]
}