{
  "paper_id": "2311.10343v1",
  "title": "Enhancing Student Engagement In Online Learning Through Facial Expression Analysis And Complex Emotion Recognition Using Deep Learning",
  "published": "2023-11-17T06:07:54Z",
  "authors": [
    "Rekha R Nair",
    "Tina Babu",
    "Pavithra K"
  ],
  "keywords": [
    "Facial Emotion Detection",
    "CNN",
    "Pattern detection"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "In response to the COVID-19 pandemic, traditional physical classrooms have transitioned to online environments, necessitating effective strategies to ensure sustained student engagement. A significant challenge in online teaching is the absence of realtime feedback from teachers on students learning progress. This paper introduces a novel approach employing deep learning techniques based on facial expressions to assess students engagement levels during online learning sessions. Human emotions cannot be adequately conveyed by a student using only the basic emotions, including anger, disgust, fear, joy, sadness, surprise, and neutrality. To address this challenge, proposed a generation of four complex emotions such as confusion, satisfaction, disappointment, and frustration by combining the basic emotions. These complex emotions are often experienced simultaneously by students during the learning session. To depict these emotions dynamically,utilized a continuous stream of image frames instead of discrete images. The proposed work utilized a Convolutional Neural Network (CNN) model to categorize the fundamental emotional states of learners accurately. The proposed CNN model demonstrates strong performance, achieving a 95% accuracy in precise categorization of learner emotions.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Covid 19 Pandemic has made all the educational schools across the world adapt teaching online  [1] . Distance learning remains a vital and ongoing process that provides essential support to both students and educators in their teaching and learning endeavors across the globe  [2] . Technology and online learning materials can help students develop successful self-directed learning techniques  [3] . There are various obstacles in education, such as invigilation and learning coordination, as a result of the widespread adoption of distance learning in the modem world  [4] . In higher education, distance learning has provided a useful substitute for conventional instruction. It might be challenging for university lecturers to comprehend the emotions and unusual behaviors of their pupils during class  [5] . While online learning has achieved considerable success and popularity, it still faces a challenge in adapting pedagogical approaches in real-time based on the learner's evolving behavior and emotions, a capability that is more readily achievable in traditional face-to-face learning settings  [6] . As a result, the learning process can become somewhat mechanized, which significantly influences the depth of knowledge acquisition. Conventional methods often rely on the analysis of facial expressions in photographs to gauge a learner's emotional state. However, it's crucial to recognize that human emotions are inherently intricate and multifaceted, extending beyond fundamental feelings such as anger, disgust, fear, joy, sadness, surprise, and neutrality  [7] . However, it is possible to take into account a mixture of two or more emotions that may appear on the face over time  [8] . The four complex emotions that are a composite of fundamental human emotions such as confusion, satisfaction, disappointment, and frustration that a learner frequently experiences in concert throughout a learning session. Instead of using discrete pictures, the usage of a fixed set of continuous image frames to accurately represent these mixed feelings. To categorize the fundamental emotions and subsequently determine the learners' state of mind, called a CNN model. Convolutional neural networks (CNN) have helped a number of effective artificial intelligence algorithms, particularly deep learning algorithms, become wellknown in the computer vision sector. It has often been used in image classification and recognition  [9]   [10] . It is important to note that achieving a high level of accuracy in image processing is essential for the successful implementation of face detection and recognition systems. This precision is a fundamental requirement to ensure that the system is not only effective but also reliable in its performance.\n\nThis paper endeavors to introduce an enhanced face recognition approach with the primary objective of improving the effectiveness of emotion recognition. This advanced technique is designed to surpass the accuracy levels achieved by traditional methods. It leverages a combination of software techniques, computer vision algorithms, and deep learning models, specifically CNNs, to establish an innovative system. This system empowers educators with the capability to efficiently orchestrate classroom activities and enhance communication with their students during lessons, all while ensuring students' engagement and monitoring their behavioral state in the classroom. The main emphasis of this research is as follows:\n\n• To identify the basic facial emotions in learning session.\n\n• To give the accurate combinational emotion detection for identified emotions.\n\n• To detect learners state of mind accurately.\n\nThere are various obstacles in education, such as invigilation and learning coordination, because of the widespread adoption of distance learning in the modem world. Understanding students' emotions and unusual behavior during class sessions is a challenge for university instructors. Detection of state of mind by facial expressions of online learners is difficult with models trained with basic emotions. To solve this problem, a new novel deep learning model which detects state of mind by combinatorial facial emotions using CNN algorithm to be developed.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Materials And Methods",
      "text": "",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Proposed Methodology",
      "text": "Employing CNN as a deep learning system, this study utilizes them to process input images, assess and categorize different features and objects present in the images, and differentiate between them effectively. The CNN is harnessed to scrutinize real-time  video frames with the purpose of predicting the probability of each of the seven core emotional states manifesting. Furthermore, the analysis model relies on real-time input derived from the CNN models' output data to discern the emotional states of students, offering a means of detecting their state of mind during educational interactions learning process, it has been found that the learner's emotions alter gradually rather than abruptly. Additionally, during the learning process, the learner's face displays variations in emotion for a while (at least for 3 to 5 seconds). To gauge a learner's mental state while they are learning, a series of photos must be collected throughout time. For purposes of generalization, were assume that a change in human feeling may occur in around 6 seconds. To assign scores to each class of fundamental emotion, the facial expressions within each image are accurately recognized. The predominant emotion in the facial image receives a notably high confidence score. Different score values are computed for each specific emotion, as a single face may display a range of emotional nuances. This approach allows for a nuanced assessment of the emotions expressed.\n\nIn order to discern the array of emotions within an image, the emotion recognition module harnesses a pre-trained CNN classifier. By employing a sequence of six consecutive images as a \"window frame,\" the state of mind detection module is capable of assessing the learner's emotional patterns over the preceding six seconds. The resulting emotional pattern provides insight into the learner's current mental state and emotional condition.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Implementation",
      "text": "The architectural layout of our CNN model is depicted in Figure  2 . This structure comprises five convolution layers, each equipped with a Rectified Linear Unit (ReLu) activation function. Additionally, there are three pooling layers, two fully connected layers, and an output layer. The specific functionalities and parameter settings for each layer are detailed as follows:\n\n• In the convolution layer, the feature map is generated from the input images and is achieved by employing convolution kernels configured with a size of 3 x 3. • The purpose of the max pooling layer is to reduce dimension of the data while retaining crucial features and patterns. Each max pooling layer is configured with a stride value of 2 and a pooling window size of 2x2. This design choice ensures effective dimensionality reduction while preserving significant information. • The flatten layer transforms the 2-dimensional data into a 1-dimensional format, making it suitable for input to a fully connected layer. Conversion process allows for seamless integration into subsequent network components. • The dense layer or the fully connected layer, acts as a collection of two or more interconnected neural networks. The 1-dimensional data obtained from the flattening layer is provided as input to the input nodes of each dense layer. This architecture allows for intricate neural network interactions, enhancing the model capacity to capture complex patterns and relationships within the data. • The output layer is composed of seven nodes, each utilizing the SoftMax activation function. Each of these nodes corresponds to a distinct category of emotions, allowing the network to predict and classify different sets of emotions.\n\nThe CNN model is being implemented through the Python programming language. This constructed model is subsequently subjected to further training and testing using a facial expression dataset to assess its accuracy and performance",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Learners Verification",
      "text": "Emotions and states of mind are inherently subjective and often resist precise quantification or formal expression. Consequently, to accurately gauge the implicit state of mind in learners, it is imperative to obtain validation from the individuals involved. To assess the accuracy of our emotion model and the approach for recognizing emotional patterns, it is essential to validate the classified emotion patterns with the learners themselves. In this regard, the approach is undergoing assessment and validation involving 40 graduate-level course participants. This evaluation entails a brief online tutorial followed by a machine learning test session. During the learning session, video recordings of each candidate are taken at different time points to ascertain and understand the learner's state of mind.  Once the learning session concludes, the recorded video is meticulously analyzed frame by frame, aiming to extract the emotional patterns and, consequently, the learner's evolving state of mind over time. The mechanism for detecting emotion patterns operates at 6-second intervals to derive the learner's state of mind. These identified states of mind are then aggregated throughout the entire learning session. To validate the accuracy of this process, the candidates are invited to provide feedback regarding the correctness of the aggregated learner's state of mind as assessed. This hypothesis posits that the learners possess the capacity to accurately recognize and respond to their own states of mind.",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "Experimental Result And Analysis",
      "text": "The module for acknowledgment consists of two phases:\n\n• the extraction of highlights to create a test informative index and • Combining: CNN is used to describe an event of test data into an emotion class.\n\nThe CNN order is a fantastic grouping method. CNN's classification relies heavily on the premise that similar views belong in similar groupings.\n\nBy running our CNN model for about 50 epochs (considered to be a dataset passed forward and backward through CNN), we were able to gather information about the efficacy and accuracy of the model. Next, test images are used to evaluate the model. Additional assessment of the model is conducted for real-time emotion analysis using a range of input video and webcam sequences. The result of each frame is appropriately recorded, and any errors that occur during misclassification are also noted. As a result, the relevant measures are subsequently executed.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "The Cnn Performance Metric For Identifying Emotions",
      "text": "The performance of the proposed system is shown in Table  1",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Conclusion",
      "text": "The proposed study has demonstrated the effectiveness of ensemble models in forecasting dengue disease occurrences in the Chandigarh region of India. The primary objective of the work was to introduce a robust ensemble model for time series data forecasting, which can find applications in a wide range of disciplines beyond epidemiology. The work compared ensemble models with three established time series forecasting methods and found that they consistently outperformed the latter. The insights gained from this study can inform decision-making processes in public health, facilitate early intervention strategies, and contribute to more effective disease control and prevention efforts. In future, further refinement of ensemble models and the incorporation of additional data sources could lead to even more precise and timely disease forecasts.",
      "page_start": 6,
      "page_end": 6
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Proposed model for emotion recognition system.",
      "page": 3
    },
    {
      "caption": "Figure 2: Proposed CNN model and its",
      "page": 3
    },
    {
      "caption": "Figure 2: This structure",
      "page": 4
    },
    {
      "caption": "Figure 3: Basic emotion pattern recognition from a series of image.",
      "page": 5
    },
    {
      "caption": "Figure 3: , it is concluded that the proposed model produces good",
      "page": 6
    }
  ],
  "tables": [
    {
      "caption": "Table 1: CNN’sperformancemetricfordetectingemotions Table 2. Confusionmetricoftheproposedapproach",
      "data": [
        {
          "Metric": "True Positive",
          "Value": "15"
        },
        {
          "Metric": "False Positive",
          "Value": "8"
        },
        {
          "Metric": "True negative",
          "Value": "10"
        },
        {
          "Metric": "False Negative",
          "Value": "7"
        }
      ],
      "page": 5
    },
    {
      "caption": "Table 1: CNN’sperformancemetricfordetectingemotions Table 2. Confusionmetricoftheproposedapproach",
      "data": [
        {
          "Metric": "Accuracy",
          "Value": "95"
        },
        {
          "Metric": "Precision",
          "Value": "89"
        },
        {
          "Metric": "Recall",
          "Value": "79"
        },
        {
          "Metric": "F1-Score",
          "Value": "98"
        }
      ],
      "page": 5
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Emotion detection-based video recommendation system using machine learning and deep learning framework",
      "authors": [
        "A Bokhare",
        "T Kothari"
      ],
      "year": "2023",
      "venue": "SN Computer Science"
    },
    {
      "citation_id": "2",
      "title": "Facial emotion detection using thermal and visual images based on deep learning techniques",
      "authors": [
        "R Rashmi",
        "U Snekhalatha",
        "A Salvador"
      ],
      "year": "2023",
      "venue": "The Imaging Science Journal"
    },
    {
      "citation_id": "3",
      "title": "Visualization of covid bimodal scan using dnn",
      "authors": [
        "A Tripathi",
        "A Basavapattana",
        "R Nair"
      ],
      "year": "2021",
      "venue": "2021 12th International Conference on Computing Communication and Networking Technologies"
    },
    {
      "citation_id": "4",
      "title": "Facial emotion detection of thermal and digital images based on machine learning techniques",
      "authors": [
        "B Sathyamoorthy",
        "U Snehalatha",
        "T Rajalakshmi"
      ],
      "year": "2023",
      "venue": "Biomedical Engineering: Applications, Basis and Communications"
    },
    {
      "citation_id": "5",
      "title": "Facial emotion recognition and music recommendation system using cnn-based deep learning techniques",
      "authors": [
        "B Bakariya",
        "A Singh",
        "H Singh"
      ],
      "year": "2023",
      "venue": "Evolving Systems"
    },
    {
      "citation_id": "6",
      "title": "Human emotion detection and classification using modified viola-jones and convolution neural network",
      "authors": [
        "K Karilingappa",
        "D Jayadevappa",
        "S Ganganna"
      ],
      "year": "2023",
      "venue": "IAES International Journal of Artificial Intelligence"
    },
    {
      "citation_id": "7",
      "title": "Exploring emotion analysis using artificial intelligence, geospatial information systems, and extended reality for urban services",
      "authors": [
        "S Rokhsaritalemi",
        "A Sadeghi-Niaraki",
        "S Choi"
      ],
      "year": "2023",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "8",
      "title": "Insect classification framework based on a novel fusion of high-level and shallow features",
      "authors": [
        "R Haarika",
        "T Babu",
        "R Nair"
      ],
      "year": "2023",
      "venue": "International Conference on Machine Learning and Data Engineering"
    },
    {
      "citation_id": "9",
      "title": "Face mask detection using mask r-cnn to control the spread of covid-19",
      "authors": [
        "V Mohan",
        "A Gowda",
        "R Nair"
      ],
      "year": "2023",
      "venue": "2023 International Conference on Recent Trends in Electronics and Communication"
    },
    {
      "citation_id": "10",
      "title": "Multiresolution approach on medical image fusion by modified local energy. Signal, Image and Video Processing",
      "authors": [
        "R Nair",
        "T Babu",
        "T Singh"
      ],
      "year": "2023",
      "venue": "Multiresolution approach on medical image fusion by modified local energy. Signal, Image and Video Processing"
    }
  ]
}