{
  "paper_id": "2207.12135v1",
  "title": "Label Uncertainty Modeling And Prediction For Speech Emotion Recognition Using T-Distributions",
  "published": "2022-07-25T12:38:20Z",
  "authors": [
    "Navin Raj Prabhu",
    "Nale Lehmann-Willenbrock",
    "Timo Gerkmann"
  ],
  "keywords": [
    "uncertainty",
    "subjectivity",
    "distribution learning",
    "t-distribution",
    "Bayesian networks",
    "speech emotion recognition"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "As different people perceive others' emotional expressions differently, their annotation in terms of arousal and valence are per se subjective. To address this, these emotion annotations are typically collected by multiple annotators and averaged across annotators in order to obtain labels for arousal and valence. However, besides the average, also the uncertainty of a label is of interest, and should also be modeled and predicted for automatic emotion recognition. In the literature, for simplicity, label uncertainty modeling is commonly approached with a Gaussian assumption on the collected annotations. However, as the number of annotators is typically rather small due to resource constraints, we argue that the Gaussian approach is a rather crude assumption. In contrast, in this work we propose to model the label distribution using a Student's t-distribution which allows us to account for the number of annotations available. With this model, we derive the corresponding Kullback-Leibler divergence based loss function and use it to train an estimator for the distribution of emotion labels, from which the mean and uncertainty can be inferred. Through qualitative and quantitative analysis, we show the benefits of the t-distribution over a Gaussian distribution. We validate our proposed method on the AVEC'16 dataset. Results reveal that our t-distribution based approach improves over the Gaussian approach with state-ofthe-art uncertainty modeling results in speech-based emotion recognition, along with an optimal and even faster convergence.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "I. Introduction",
      "text": "Emotions can be inner subjective experiences, but in order to become socially relevant, they need to be expressed in social context (e.g.,  [1] ). Therefore, emotions are typically studied as emotional expressions that others subjectively perceive and respond to  [2] . A common theoretical backdrop for analyzing emotions is the two-dimensional pleasure and arousal framework  [3] , which describes emotional expressions in two continuous, bipolar, and orthogonal dimensions: pleasuredispleasure (valence) and activation-deactivation (arousal). One way in which emotions become expressed in social interactions, and therefore accessible for social signal processing (SSP), concerns speech signals. Speech emotion recognition (SER) research spans roughly two decades  [2] , with ever improving state-of-the-art results. As a consequence, affective This work was supported by the Landesforschungsförderung Hamburg (LFF-FV79), under the \"Mechanisms of Change in Dynamic Social Interaction\" project. sciences and SER has shown increasing prominence in highcritical and socially relevant domains, e.g. health, security, and employee well-being  [2] ,  [4] ,  [5] .\n\nA crucial challenge when studying emotional expressions and trying to establish a ground truth using the pleasurearousal framework concerns the significant degree of subjectivity surrounding the perceptions of these expressions  [2] . Commonly, majority voting  [6]  or evaluator-weighted mean (EWE)  [7]  have been used as approximations to obtain groundtruth labels. However, in the context of reliable real-world applications, it is required for SER systems to not only model ground-truth labels but also account for subjectivity based label uncertainty  [2] ,  [8] .\n\nIn SER, label uncertainty has been approached using softlabels  [5] , multi-task learning (MTL)  [9] ,  [10] , stochastic models  [11] ,  [12] , and label distribution learning  [13] ,  [14] . The subjective annotations of emotion creates a label distribution which explains the uncertainty in emotions  [5] . In this light, label distribution learning techniques for label uncertainty in SER are gaining research focus, with improved performances  [13] ,  [14] . However, a problem with label distribution learning in SER is the limited annotations available  [5] ,  [14] , due to resource inefficient task of gaining more annotations  [5] .\n\nEmotion annotations as label distributions are usually modeled by making a Gaussian assumption on them for mathematical convenience  [13] ,  [14] . However, a Gaussian assumption with limited samples is not well justified  [15] ,  [16] , as the central limit theorem (CLT) which primarily backs Gaussian distributions does not hold with insufficient numbers of sam-978-1-6654-5908-2/22/$31.00 ©2022 IEEE arXiv:2207.12135v1 [eess.AS] 25 Jul 2022 ples  [17] . Publicly available SER datasets commonly comprise of only three to six annotations  [18] -  [22] , and well agree that gaining more annotations is resource inefficient  [5] ,  [23] . In this light, it is important for machine learning (ML) models to account for the limited annotations and model the label distribution accordingly. Alternately, Student's t-distribution, also known as t-distribution, is a probability distribution that also accounts for the number of samples available while modeling  [15] . Noting this, and the resource constraints in gaining more annotations, the t-distribution becomes a more appropriate choice for modeling emotion annotations.\n\nIn machine learning, two types of uncertainty can be distinguished. Label uncertainty captures data inherent noise whereas model uncertainty accounts for the uncertainty in model parameters  [24] . Stochastic and probabilistic models have mainly been deployed for uncertainty modeling  [25] -  [27] . Bayes by Backpropagation (BBB) for Bayesian neural networks (BNN)  [27]  uses simple gradient updates to optimize weight distributions for stochastic outputs, thereby are promising candidates for label distribution learning in SER.\n\nIn this paper, we propose to model emotion annotations as a t-distribution, in contrast to a Gaussian assumption  [13] ,  [14] . To the best of our knowledge, this is the first time the problem of limited emotion annotations is tackled from an ML perspective, a common challenge in affective computing and SSP  [23] . For this, we adopt a BBB-based stochastic uncertainty model, as proposed in  [14] , to include a t-distribution instead of a Gaussian. To this end, we introduce a Kullback-Leibler (KL) divergence loss for label uncertainty that quantifies distribution similarity between stochastic emotion predictions, modeled as a Gaussian distribution, and ground-truth emotion annotations, modeled as a t-distribution. Subsequently, we present analyses to reveal the benefits of using t-distribution over a Gaussian. Finally, we show that the BBB-based uncertainty model trained on the proposed t-distribution based KL-divergence loss can aptly capture label uncertainty with state-of-the-art results, along with a robust loss curve.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Ii. Related Work",
      "text": "",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "A. Ground-Truth Labels",
      "text": "To handle subjectivity in emotional expressions, annotations {y 1 , y 2 , .., y a } for emotions are collected from a annotators  [20] ,  [22] . The ground-truth label is then obtained as the mean m over all annotations from a annotators  [28] ,  [29] ,\n\nAlternatively, the EWE, which weights annotations with interannotator correlations, has been proposed and referred to as the gold-standard m  [7] . Both m and m based approximation of ground-truth leads to loss of information on subjectivity  [5] .\n\nTraditional SER approaches, given a raw audio sequence of T frames X = [x 1 , x 2 , ..., x T ], aim to estimate either the m t or m t for each time frame t ∈ [1, T ], referred to as m t . The concordance correlation coefficient (CCC) has been widely used as a loss function for this task  [2] . For Pearson correlation r, the CCC between m and m, for T frames, is formulated as\n\nwhere\n\n, and µ m , σ 2 m are obtained similarly for m.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "B. Label Uncertainty In Ser",
      "text": "Alternative to exclusively modeling m t or m t , works have attempted to model ground truth that also explains interannotator disagreement, for example by means of soft labels  [5]  and entropy of disagreement  [30] . Fayek et al.  [31]  and Tarantino et al.  [32]  proposed to learn soft labels instead of m t with improved performance. Steidl et al.  [30]  quantified label uncertainty using the entropy measure, and trained a model to minimize the difference in entropy between model outputs and annotator disagreement. Sridhar et al.  [5]  proposed an auto-encoder based learning technique to jointly model soft-and hard-labels of emotion annotations, and subsequently estimating label uncertainty as the entropy on soft-labels.\n\nLabel uncertainty has also been approached as a prediction task by estimating either the moments of the distribution  [9] ,  [10]  or the distribution in itself  [13] ,  [14] . Han et al.  [9] ,  [10]  used an MTL approach to model the unbiased standard deviation s of a annotators as an auxiliary task,\n\n(\n\nSridhar et al.  [11]  introduced a Monte-Carlo dropout model to obtain uncertainty estimates from the distribution of stochastic outputs. Foteinopoulou et al.  [13]  trained a MTL network using a KL divergence loss that models emotion annotations as a uni-variate Gaussian with mean m and unknown variance. Raj Prabhu et al.  [14]  introduced a stochastic BNN and trained them on Gaussian emotion annotations. Notwithstanding their improved performances, in  [13] ,  [14]  Gaussian emotion annotations are assumed, despite only having limited annotations. Apart from the apparent mathematical incorrectness of this assumption, they are susceptible to unreliable m and s for lower values of a and sparsely distributed annotations  [14] .",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "C. On Distributions",
      "text": ") is a continuous probability distribution for a real-valued random variable y, with general form of its probability density function  [16]\n\nThe parameters µ and σ are the mean and standard deviation of the distribution, respectively. Due to its simplicity and intelligibility, Gaussian distributions are often used to model random variables whose distribution are unknown  [13] ,  [14] ,  [27] . Their importance is however backed by the CLT which only holds as the number of observations of the random variable grows  [17] . However, due to the resource constraints in collecting annotations, in most human-behaviour research  [23]  and in SER  [18] -  [21] , we do not have sufficient annotations to assume a Gaussian distribution on them. As this is a common challenge for reliable real-world applications, it is important for SER algorithms to account for limited annotations and model annotation distributions accordingly. Kotz and Nadarajah  [15] , and, Bishop and Nasrabadi  [16] , note that in scenarios of limited observations and samples the t-distribution becomes more robust and realistic over a Gaussian.\n\nStudent's t-distribution is a probability distribution that arises when estimating the moments of a normally distributed population in situations where the sample size is small  [15] ,  [33] , with the probability density function given by  [34] -  [36] ,\n\nwhere ν denotes the degrees of freedom and B(., .) is the Beta function, for Gamma function Γ, formulated as,\n\nThe density function (  5 ) resembles the bell shape of a normally distributed variable, except that it has heavier tails, meaning that it better captures values that fall far from its mean  [15] ,  [16] . The degree of freedom ν, also known as the normality parameter, controls the normality of the distribution, and is correlated with the σ parameter  [15] ,  [16] . The standard deviation σ in (  5 ) is scaled by ν and is formulated as\n\nAs ν increases, the t-distribution approaches the normal distribution  [36] .\n\nIII. PROPOSED t-DISTRIBUTION LABEL UNCERTAINTY MODEL To better represent subjectivity in annotations of emotional expressions, we propose to estimate the emotion annotation distribution Y t for each frame t. For this, in contrast to a Gaussian assumption Y t ∼ N (m t , s t )  [13] ,  [14] , we model the annotations as a t-distribution with degrees of freedom ν:\n\nThus, the goal is to obtain an estimate Y t of Y t .",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "A. Model Architecture",
      "text": "We adopt an end-to-end architecture, initially proposed by Raj Prabhu et al.  [14] , which uses a feature extractor  [37]  to learn temporal-paralinguistic features from x t , and a BBBbased uncertainty layer  [27]  to estimate Y t . We include the t-distribution modeling as part of the architecture, and the architecture proposed here can be seen in Figure  1 .\n\nUnlike a standard neuron which optimizes a deterministic weight w, the BBB-based neuron learns a probability distribution on the weight P (w|D), parametrized by θ = (µ w , σ w ) using a Gaussian N (µ w , σ w ), given the training data D  [27] . For an optimized θ, the predictive distribution Y t for an audio frame x t , is given by P ( y t |x t ) = E P (w|D) [P ( y t |x t , w)], where y t are realizations of Y t . Stochastic outputs in BBB are achieved using multiple forward passes n with stochastically sampled weights w, thereby modeling Y t using the n stochastic estimates. Following  [27] , the BBB-based MLP is trained on the negative evidence lower bound (ELBO),\n\nlog q(w (i) |θ)-log P (w (i) )-log P (D|w (i) ),  (9)  where q(w|θ) is the variational posterior that minimizes the KL divergence with the true Bayesian posterior, and w (i) is the i th sampled weight from q(w|θ). Finally, as suggested in  [14] , during testing the uncertainty estimate s t is the standard deviation of Y t , and mean estimate m t is the realization y t obtained using the mean of the optimized weights µ w .",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "B. T-Distribution Label Uncertainty Loss Derivation",
      "text": "To capture the label uncertainty, we derive a KL divergence based loss function, between the Gaussian stochastic outputs Y and the t-distribution ground-truth Y. Note that assuming a Gaussian distribution on the stochastic outputs Y is a fair assumption as the number of stochastic outputs to model Y can be controlled using n in  (9) . As the number of sample observations for a distribution approaches thirty a tdistribution converges to a stable Gaussian  [35] ,  [36] . Noting this, we intend to choose a n greater than 30 and thereby assume Y to be Gaussian. As a positive side effect, we result in deriving the KL divergence between a Gaussian and a tdistribution, in contrast to between two t-distributions, with the later involving mathematical complexities in calculating intractable expectations for a loss function.\n\nFor a Gaussian Y (see (  4 )), and a t-distributed Y (see (  5 )), the L KL is formulated as  [38] ,  [39] ,\n\nwhere H(., .) is the cross-entropy between two distributions, and H(.) is the entropy of a distribution. Similar to  [14] , in  (10) , we choose the true distribution Y t to precede its estimate Y t , promoting a mean-seeking approximation rather than a mode-seeking one and capturing the full distribution  [40] .\n\nThe cross-entropy term H(., .) in  (10) , using (4), can be further formulated as, 2: Analysis of the t-distribution based KL divergence L KL  (13) , in comparison with Gaussian L KL  (14) .\n\nNoting that Y t (y)y 2 dy = µ 2 + σ 2 , Y t (y) y dy = µ, and Y t (y) dy = 1, where µ and σ are parameters of the t-distribution Y t , p(y | ν, µ, σ), the equation (  11 ) becomes,\n\nFinally, using (  12 ) in  (10) , our proposed KL divergence is\n\nWe implement (13) as a custom loss function using the pytorch package  [41] , by extending the studentT sub-package 1 .\n\nSimilarly, as used in  [14] , the KL divergence between two Gaussians N (µ, σ 2 ) and N ( µ, σ 2 ) is given by  [16] ,  [41]\n\nWhile the two loss-functions (  14 ) and (  13 ) have their second term in common, two differences can be noted. Firstly, as  (14)  calculates the divergence between two similar distributions, Y t and Y t ,  (14)  includes the logarithm of the ratio between the two Gaussian's standard deviation in its formulation. However, in  (13) , the deviations of Y t and Y t are separately quantified using terms 1  2 log(2π σ 2 ) and H(Y t ), respectively. Secondly, the number of annotators is included in (13) by scaling σ t with normality factor ν, using  (7) . The implication of these differences, and the quantitative differences between (  14 ) and (  13 ) are presented and analyzed in the following section.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "C. T-Distribution Loss Analysis",
      "text": "In contrast to  [14] , where the loss function is L KL between two Gaussians, and to  [13] , where L KL is between a Gaussian and a Dirac delta, our proposed loss  (13)  formulates the KL divergence between a Gaussian and a t-distribution to capture label uncertainty when only limited annotations are available. 1 Code for the models and the loss functions introduced are available at https://github.com/sp-uhh/label-uncertainty-ser\n\nTo validate the derivation and to further understand the advantages of the t-distribution L KL (13) over the Gaussian L KL  (14) , we plot the L KL values as a function of varying σ of Y t , for (  13 ) and (  14 ). We perform this analysis under four different scenarios, by varying parameters σ and ν, i) Figure  2a  for scenario σ = 0.5 and ν = 6, ii) Figure  2b  for scenario σ = 1.0 and ν = 6, iii) Figure  2c  for scenario σ = 1.0 and ν = 12, and, iv) Figure  2d  for scenario σ = 1.0 and ν = 30.\n\nFrom Figure  2 , firstly, we see that L KL behaves differently when the ground-truth Y t is modeled as a t-distribution  (13) , in comparison to the Gaussian assumption  (14) . Specifically, from Figure  2a , for σ = 0.5 and ν = 6, we see that the minimum L KL  (13)  is achieved only at σ = 0.61, in contrast to the Gaussian (  14 ) σ = σ = 0.5. While the Gaussian attempts exactly fitting the model to the ground-truth σ = 0.5, the t-distribution tries to fit on a more relaxed σ = 0.61 by also considering the reduced degree of freedom ν = 6. This behaviour is similar to that observed during the confidence intervals calculation using a Gaussian and t-distribution  [42] , where a t-distribution shows relaxation on σ with respect to ν. Moreover, Bishop and Nasrabadi  [16]  associate this relaxed σ towards the increased robustness of the t-distribution to outliers and sparse distributions.\n\nSecondly, we note that the observed relaxation on σ is dependent on two factors, 1) the standard-deviation of the stochastic outputs σ, and 2) the degree of freedom of the ground-truth ν. From figures 2a and 2b, we see that, while ν is constant, the relaxation on σ increases along with an increase in σ. At σ = 0.5 a relaxation of 0.11 is made by tdistribution (13) from 0.5 to 0.61, while a larger relaxation of 0.22 is made for σ = 1.0. Similarly, from figures 2c and 2d, we see that, while σ is constant, as ν increases the relaxation on σ decreases. That is, the t-distribution (13) starts behaving similar to that of the Gaussian, inline with literature that states that as the degree of freedom ν of t-distribution increases, the distribution converges into a Gaussian  [15] ,  [35] ,  [36] . This is also inline with our initial motivation behind using the tdistribution, which we expected to account for the number of annotators ν while fitting on annotation distribution Y.\n\nFrom a machine learning and SER perspective, from Figure  2, we note several benefits that t-distribution loss term L KL (13) brings forth in-terms of label uncertainty modeling. Firstly, training on a t-distribution based L KL (13) leads to training on a relaxed s t , and thereby can lead to better capturing of the whole ground-truth label distribution. Moreover, the resulting loss function is mathematically more solid than a Gaussian assumption as in  [13] ,  [14] , when less than thirty annotations are available. Secondly, we note that the t-distribution L KL (13) values are always higher for lower values of σ and σ, in all cases. This, in comparison to the Gaussian L KL  (14) , might lead to larger penalization of the model through the L KL loss, and may thereby promote better and quicker convergence during training. Finally, the t-distribution L KL (13) also adapts to different datasets with different number of annotators by considering the number of annotations available during training.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "D. Training Loss",
      "text": "The proposed uncertainty training loss is formulated as,\n\nIntuitively, L CCC (m) (2) optimizes for mean predictions m, L BBB (9) optimizes for BBB weight distributions, and L KL  (13)  optimizes for the label distribution Y t as a t-distribution.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Iv. Experimental Setup A. Dataset",
      "text": "To validate our model, we use the AVEC'16  [29]  version of the RECOLA dataset  [20] . In this work, we only utilize the audio signals collected at 16 kHz, from the multimodal signals recorded. The dataset consists of continuous arousal and valence annotations by a = 6 annotators at 40 ms frame-rate. As illustrated in Figure  3 , in the AVEC'16  [29]  dataset, arousal and valence annotations are distributed on average with µ m = 0.01 and µ m = 0.11, and µ s = 0.23 and µ s = 0.14, respectively, where µ s = 1 T T t=1 s t . This reveals the significant level of subjectivity present in the dataset, where s t distributions are heavy-tailed with usually high s t and µ s . The dataset is divided into speaker disjoint partitions for training, development and testing, with nine 300 s recordings each. As the annotations for the test partition are not publicly available, all results are computed on the development partition.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "B. Baselines",
      "text": "To evaluate the performance of our proposed approach, we use MTL-and BBB-based uncertainty models  [14] . From  [10]  we use the perception uncertainty (MTL PU) and single-task models (STL), and from  [14]  the model uncertainty (MU) and label uncertainty (MU+LU) algorithms. Similar to  [14] , for a fair comparison, we reimplemented the baselines from  [10] , thereby also enabling us to compare the models interms of their s estimates, which were not presented in  [10] . The method proposed in this work, t-distribution based label uncertainty, will be called henceforth as t-LU, for convenience.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "C. Choice Of Hyperparameters",
      "text": "The hyperparameters of the feature extractor are fixed as suggested in  [37] , similar to  [43] ,  [44] . The hyperparameters of the uncertainty layer are adopted from  [14] , who show stateof-the-art results in label uncertainty modeling. For example, as prior distribution P (w) a simple Gaussian prior with unit standard deviation N (0, 1) was used. Similarly, the posterior distribution P (w|D) is initialized using the same heuristics.\n\nIn this work, we assume a Gaussian on Y t , and noted previously that n ≥ 30 is required for the assumption to hold. In this light, and keeping the time-complexity in mind, we fixed n = 30. For training, we use the Adam optimizer with learning rate 10 -4 . The batch size used was 5, with a sequence length of 300 frames, 40 ms each. All the models were trained for a fixed 100 epochs. The best model is selected and used for testing when best L (15) is observed on train partition.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "D. Validation Measures",
      "text": "To validate the proposed method's mean and standard deviation estimates, we use L CCC (m) and L CCC (s) metrics, respectively, widely used in literature  [10] ,  [37] ,  [44] . However, L CCC (m) and L CCC (s) validates mean and standard deviation estimates separately. To further jointly validate mean and standard deviation estimates, as label distribution Y t , we use the L KL measure. A similar measure is used in  [14] , but with a Gaussian assumption on Y t and hence can be biased. However, for a fair comparison, we validate all the models in comparison using L KL based on their respective distribution assumptions on Y t , as the models are trained in a similar fashion. The proposed t-LU method is validated and trained on the tdistribution L KL  (13) , and the baselines from  [10]  and  [14]  are validated and trained on Gaussian L KL  (14) . Nevertheless, from the experiments we also noted that the proposed t-LU performs better in-terms of both (  13 ) and (  14 ).",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "V. Results And Discussion",
      "text": "Table  I  shows the average performance of the baselines and the proposed model, in terms of their mean m, standard deviation s, and distribution Y t estimations, L CCC (m), L CCC (s) and L KL , respectively. Comparisons with respect to L CCC (s) and L KL are not presented for the STL as this algorithm does not contain uncertainty modeling. Statistical significance is estimated using one-tailed t-test on error distributions, asserting significance for p-values ≤ 0.05, similar to  [5] . TABLE I: Comparison on mean m, standard deviation s, and label distribution estimations Y, in terms of L ccc (m), L ccc (s), and L KL , respectively. Larger CCC indicates improved performance as indicated by ↑. Lower KL indicates improved performance as indicated by ↓. ** indicates that the respective approach achieves statistically significant better results than all other approaches in comparison. * indicates that it achieves statistically significant better results over only some of the approaches in comparison.\n\n(a) For arousal Lccc(m) ↑ Lccc(s) ↑ L KL ↓ STL  [10]  0.7192 --MTL PU  [10]  0.7336 0.2861 0.7965 MU  [14]  0.7559 0.0764 0.6900 MU+LU  [14]  0.7437 0.3402 0.2576 t-LU (proposed) 0.7665** 0.3752** 0.2349**",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "(B) For Valence",
      "text": "Lccc(m) ↑ Lccc(s) ↑ L KL ↓ STL  [10]  0.3878 --MTL PU  [10]  0.4163 0.0292 0.9981 MU  [14]  0.3248 0.0359 0.6334 MU+LU  [14]  0.2831 0.0422 0.4054 t-LU (proposed) 0.3768* 0.0481* 0.3914* -0.5 0.0 0.5\n\nModel Uncertainty (MU) -0.5 0.0 0.5\n\nModel + Label Uncertainty (MU + LU) 0 50 100 150 200 250 300 Time (seconds) -0.5 0.0 0.5 1.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "2.",
      "text": "3.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "4.",
      "text": "",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "T-Label",
      "text": "",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "T-Label Uncertainty (T-Lu)",
      "text": "",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Predicted -M",
      "text": "Groundtruth -m Predicted -s Groundtruth -s (b) For valence.\n\nFig.  4 : Label distribution Y t estimation results for a test subject.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "A. Comparison On Mean Estimates",
      "text": "In terms of mean estimates L CCC (m) of arousal, Table  Ia  shows that the proposed t-LU model performs best in comparison with the baselines, with statistical significance. While the t-LU model achieves an L CCC (m) of 0.7665, the BBB-based baselines, MU+LU and MU, achieve 0.7437 and 0.7559, respectively. This also reveals the superiority of the proposed t-distribution L KL (13) over the Gaussian L KL  (14) , with t-LU outperforming MU+LU. Moreover, in  [14] , it was noted that training on KL loss with the Gaussian assumption (14) makes a compromise on L CCC (m) performances with improving L CCC (s). However, the proposed t-LU is free from this compromise with t-LU outperforming MU. Finally, we also note that the proposed t-LU performs significantly better than the MTL-based uncertainty baseline MTL PU, and also the STL which does not model uncertainty.\n\nIn terms of mean estimates L CCC (m) of valence, concerning Table  Ib , it is noted that the the proposed t-LU performs significantly better than the BBB-based models, MU+LU and MU. While the t-LU model achieves an L CCC (m) of 0.3768, the BBB-based baselines, MU+LU and MU, achieve 0.2831 and 0.3248, respectively. Similar to arousal, for valence, we see that t-LU is free from compromises on L CCC (m), as in  [14] . However, the proposed t-LU does not improve over the MTL-based baselines, MTL PU and STL. It is a common trend in SER literature that the audio modality inadequately explains the valence dimension of emotion  [43] . However, a probable explanation for this is that the MTL-based architectures are generally better than the BBB-based, in-terms of L CCC (m) of valence. Results present by  Han et al. [10]  also show similar behaviour where MTL-based architectures show significant improvements specifically in mean estimates of valence  [10] .",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "B. Comparison On Uncertainty Estimates",
      "text": "While the proposed t-LU achieves significantly improved results over the baselines for mean estimates, especially for the arousal dimension, the main goal of this paper is to aptly capture label uncertainty in emotions, in terms of L CCC (s) and L KL . Concerning the uncertainty estimates in arousal, Table  Ia  shows that the proposed t-LU achieves state-of-the-art results, with significant improvements over the baselines. For instance, the MU+LU model, the best performing baseline, achieves a L CCC (s) and L KL of 0.3402 and 0.2576, respectively, while t-LU significantly improves by achieving 0.3752 and 0.2349, respectively. This performance, in terms of both the measures, explains the advantage of the t-distribution based KL loss term  (13)  in label uncertainty modeling. The t-distribution L KL , as seen in Figure  2 , promotes the model to fit on a more relaxed s t and penalizes more for tighter standard deviations, thereby leading to better capturing the label distribution.\n\nFor valence, unlike the L CCC (m) performance, Table  Ib  shows that the proposed t-LU achieves improved performance in-terms of the uncertainty estimates, over all the baselines in comparison. It is further noted that t-LU improves with statistical significance over the MTL-based baselines, however improves without statistical significance in comparison with the BBB-based baselines. While the MU+LU, best performing baseline, achieves a L CCC (s) and L KL of 0.0422 and 0.405, respectively, t-LU improves by achieving 0.0481 and 0.3914, respectively. However, the lack of statistical significance over some baselines, as well as the generally rather low performance of all approaches, could be owed to the common observation that speech inadequately explains valence  [43] .",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "C. Qualitative Analysis On Distribution Estimation",
      "text": "To further validate the results, we plot the mean m and standard deviation s of the estimated distributions for a test subject, seen for arousal in Figure  4a , and valence in Figure  4b . Moreover, some parts of the plots are boxed and numbered to note performance differences. For arousal, in Figure  4a , further backing the results in Table  Ia , the proposed t-LU model better captures m and s of the annotation distribution, in comparison with MU and MU+LU. For example, in the box numbered 2 in Figure  4a , the proposed t-LU captures the whole annotation distribution Y t , resembles the Ground-truth -s best. This further highlights the robustness of training on a relaxed σ t through a t-distribution. Moreover, in box 2, we also note that t-LU, by best capturing s, also improves notably in terms of the mean estimates m. This can be noted in all boxes 1-4, where t-LU best captures the whole arousal annotation distribution, by improving on both s and m estimations.\n\nFor valence, in Figure  4b , backing results in Table  Ib , we note that the proposed t-LU improves significantly in-terms of the mean estimates m, with only small improvements on standard deviation estimates s. This can be seen for instance in box 1, where t-LU notably improves in terms of m estimations, over MU and MU+LU, while only small improvements in terms of s estimations can be observed. Overall, we note that the proposed speech-based uncertainty model better captures the annotation distribution of arousal than that of valence.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "D. Analysis On Training Loss Curve",
      "text": "To further study the advantages of the proposed tdistribution L KL (13) during the training phase, we compare the testing loss curve of (13) with the Gaussian L KL in MU+LU  (14) . The comparison can be seen for arousal in Figure  5a , and for valence in Figure  5b .\n\nFor both the arousal and the valence dimension, Figure  5  illustrates two crucial advantages of the proposed t-distribution L KL (13) as a loss term in the training phase. Firstly, we see that in the initial epochs, before epoch 20, the proposed loss term converges quicker than the Gaussian L KL  (14) . This is the result of the proposed L KL (13) loss term which penalizes more for lower s t values, in comparison to the     (14)  and proposed t-distribution L KL  (13) .\n\nGaussian L KL  (14) , as seen in Section III-C, thereby achieving faster convergence. Secondly, it is noted that during the later epochs, after 60 epoch, the Gaussian L KL  (14)  shows signs of overfitting with increasing testing loss. However, at the same time, the proposed L KL (13) converges to the best minima during the later epochs. The proposed L KL achieves minima L KL at the epoch 85, with L KL of 0.2349 for arousal and 0.3914 for valence, while the Gaussian achieves a minima well before the later epochs, at epoch 54, with L KL of 0.2532 for arousal and 0.3958 for valence. The proposed L KL is free from overfitting in the later stages of training and also learns the optima at this stage. This behaviour can be attributed to the nature of the proposed L KL which promotes the model to learn a more relaxed s t , as seen in Section III-C, thereby introducing more regularization to the model, resulting in preventing overfitting and converging on an improved s t .",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Vi. Conclusions",
      "text": "Label uncertainty modeling in emotion recognition is commonly approached by assuming a Gaussian distribution on the ground-truth emotion annotations, however with only limited annotations. In contrast, in this work, we assumed a Student's t-distribution on the ground-truth emotion annotations, which also accounts for the number of annotations available. This is the first time in literature an attempt was made to handle the limited emotion annotations available, from a machine learning perspective. For this, we proposed and derived a KL divergence based loss term that aims to capture emotion annotation distribution as a t-distribution. The derived t-distribution loss term is also mathematically more sound than the Gaussian assumption, for limited annotations. Subsequently, we showed that the proposed t-distribution loss term leads to training on a relaxed standard deviation, which is adaptable with respect to the number of annotations available. Moreover, we also validated our approach on a publicly available dataset. Quantitative analysis of the results showed that the proposed tdistribution loss term improves over the Gaussian assumption with state-of-the-art results in mean and standard deviation estimations, in-terms of both the CCC and KL divergence measures. Finally, we also showed, through the analysis of the loss curves, that the proposed loss term leads to faster and improved convergence, and is less prone to overfitting.",
      "page_start": 7,
      "page_end": 7
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Overview of the proposed architecture and loss LKL.",
      "page": 1
    },
    {
      "caption": "Figure 1: Unlike a standard neuron which optimizes a deterministic",
      "page": 3
    },
    {
      "caption": "Figure 2: Analysis of the t-distribution based KL divergence LKL (13), in comparison with Gaussian LKL (14).",
      "page": 4
    },
    {
      "caption": "Figure 2: a for scenario bσ = 0.5 and ν = 6, ii) Figure 2b for scenario",
      "page": 4
    },
    {
      "caption": "Figure 2: c for scenario bσ = 1.0 and",
      "page": 4
    },
    {
      "caption": "Figure 2: d for scenario bσ = 1.0 and ν = 30.",
      "page": 4
    },
    {
      "caption": "Figure 2: , ﬁrstly, we see that LKL behaves differently",
      "page": 4
    },
    {
      "caption": "Figure 2: a, for bσ = 0.5 and ν = 6, we see that the",
      "page": 4
    },
    {
      "caption": "Figure 3: Distribution of standard deviations st in dataset [29]",
      "page": 5
    },
    {
      "caption": "Figure 3: , in the AVEC’16 [29]",
      "page": 5
    },
    {
      "caption": "Figure 4: Label distribution Yt estimation results for a test subject.",
      "page": 6
    },
    {
      "caption": "Figure 2: , promotes the model to ﬁt on a more relaxed",
      "page": 6
    },
    {
      "caption": "Figure 4: a, and valence in Figure",
      "page": 7
    },
    {
      "caption": "Figure 4: a, the proposed t-LU captures the",
      "page": 7
    },
    {
      "caption": "Figure 4: b, backing results in Table Ib, we",
      "page": 7
    },
    {
      "caption": "Figure 5: a, and for valence in Figure 5b.",
      "page": 7
    },
    {
      "caption": "Figure 5: illustrates two crucial advantages of the proposed t-distribution",
      "page": 7
    },
    {
      "caption": "Figure 5: Loss curve comparison between Gaussian LKL (14)",
      "page": 7
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "5.0=LKL 16.0=LKL t-distribution Yt\n0.8 Gaussian Yt\nLKL nimgra nimgra\n0.6\necnegreviD\n30.0=LKL\n0.0=LKL\n0.4\nLK\nnim nim\n0.2\nLKL=0\n0.0\n0.4 0.6 0.8 1.0\nStandard deviation σ of t": "",
          "5.0=LK\nnimgra\n0.0=LK\nnim": "",
          "16.0=LK\nL\nnimgra\n30.0=LK\nL\nnim": "",
          "t-distribution Yt\nGaussian Yt\nL\nL\nKL=0": "L"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "1.6 t-distribution Yt\n0.1=LKL 22.1=LKL Gaussian Yt\n1.4\n1.2 LKL\nnimgra nimgra\n1.0 ecnegreviD\n0.8\n30.0=LKL\n0.0=LKL\n0.6\nLK\n0.4\nnim nim\n0.2\nLKL=0\n0.0\n0.5 1.0 1.5 2.0 2.5\nStandard deviation σ of t": "",
          "0.1=LK\nnimgra\n0.0=LK\nnim": "",
          "22.1=LK\nL\nnimgra\n30.0=LK\nL\nnim": "",
          "t-distribution Yt\nGaussian Yt\nL\nL\nKL=0": "L"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "0.1=LKL 1.1=LKL t-distribution Yt\n1.0 Gaussian Yt\nnimgra nimgra\n0.8 LKL\necnegreviD\n0.6\n10.0=LKL\n0.0=LKL\n0.4\nLK\nnim nim\n0.2\nLKL=0\n0.0\n0.5 1.0 1.5 2.0 2.5\nStandard deviation σ of t": "",
          "0.1=LK\nnimgra\n0.0=LK\nnim": "",
          "L\nL": "",
          "1.1=LKL t-distribution Yt\nGaussian Yt\nnimgra\n10.0=LKL\nnim\nKL=0": "L"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "0.1=LKL 40.1=LKL t-distribution Yt\nGaussian Yt\n0.8\nLKL nimgra nimgra\n0.6\necnegreviD\n0.0=LKL 0.0=LKL\n0.4\nLK\nnim nim\n0.2\nLKL=0\n0.0\n0.5 1.0 1.5 2.0 2.5\nStandard deviation σ of t": "",
          "0.1=LK\nnimgra\n0.0=LK\nnim": "",
          "40.1=LKL t-distribution Yt\nGaussian Yt\nL\nnimgra\n0.0=LKL\nL\nnim\nKL=0": "L"
        }
      ],
      "page": 4
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "How emotions regulate social life: The emotions as social information (easi) model",
      "authors": [
        "G Van Kleef"
      ],
      "year": "2009",
      "venue": "Current directions in psychological science"
    },
    {
      "citation_id": "2",
      "title": "Speech emotion recognition: two decades in a nutshell, benchmarks, and ongoing trends",
      "authors": [
        "B Schuller"
      ],
      "year": "2018",
      "venue": "Communications of the ACM"
    },
    {
      "citation_id": "3",
      "title": "A circumplex model of affect",
      "authors": [
        "J Russell"
      ],
      "year": "1980",
      "venue": "Journal of personality and social psychology"
    },
    {
      "citation_id": "4",
      "title": "The rise of affectivism",
      "authors": [
        "D Dukes",
        "K Abrams",
        "R Adolphs",
        "M Ahmed",
        "A Beatty",
        "K Berridge",
        "S Broomhall",
        "T Brosch",
        "J Campos",
        "Z Clay"
      ],
      "year": "2021",
      "venue": "Nature Human Behaviour"
    },
    {
      "citation_id": "5",
      "title": "Generative approach using softlabels to learn uncertainty in predicting emotional attributes",
      "authors": [
        "K Sridhar",
        "W.-C Lin",
        "C Busso"
      ],
      "year": "2021",
      "venue": "2021 9th International Conference on Affective Computing and Intelligent Interaction (ACII)"
    },
    {
      "citation_id": "6",
      "title": "Iemocap: Interactive emotional dyadic motion capture database",
      "authors": [
        "C Busso",
        "M Bulut",
        "C.-C Lee",
        "A Kazemzadeh",
        "E Mower",
        "S Kim",
        "J Chang",
        "S Lee",
        "S Narayanan"
      ],
      "year": "2008",
      "venue": "Language resources and evaluation"
    },
    {
      "citation_id": "7",
      "title": "Evaluation of natural emotions using self assessment manikins",
      "authors": [
        "M Grimm",
        "K Kroschel"
      ],
      "year": "2005",
      "venue": "IEEE Workshop on Automatic Speech Recognition and Understanding"
    },
    {
      "citation_id": "8",
      "title": "Categorical and dimensional affect analysis in continuous input: Current trends and future directions",
      "authors": [
        "H Gunes",
        "B Schuller"
      ],
      "year": "2013",
      "venue": "Image and Vision Computing"
    },
    {
      "citation_id": "9",
      "title": "From hard to soft: Towards more human-like emotion recognition by modelling the perception uncertainty",
      "authors": [
        "J Han",
        "Z Zhang",
        "M Schmitt",
        "M Pantic",
        "B Schuller"
      ],
      "year": "2017",
      "venue": "Proceedings of the 25th ACM Int. Conf. on Multimedia"
    },
    {
      "citation_id": "10",
      "title": "Exploring perception uncertainty for emotion recognition in dyadic conversation and music listening",
      "authors": [
        "J Han",
        "Z Zhang",
        "Z Ren",
        "B Schuller"
      ],
      "year": "2020",
      "venue": "Cognitive Computation"
    },
    {
      "citation_id": "11",
      "title": "Modeling uncertainty in predicting emotional attributes from spontaneous speech",
      "authors": [
        "K Sridhar",
        "C Busso"
      ],
      "year": "2020",
      "venue": "ICASSP -IEEE Int. Conf. on Acoustics, Speech and Signal Processing"
    },
    {
      "citation_id": "12",
      "title": "Stochastic Process Regression for Cross-Cultural Speech Emotion Recognition",
      "authors": [
        "M Kumar",
        "E Sanchez",
        "G Tzimiropoulos",
        "T Giesbrecht",
        "M Valstar"
      ],
      "year": "2021",
      "venue": "Proc. Interspeech"
    },
    {
      "citation_id": "13",
      "title": "Estimating continuous affect with label uncertainty",
      "authors": [
        "N Foteinopoulou",
        "C Tzelepis",
        "I Patras"
      ],
      "year": "2021",
      "venue": "2021 9th International Conference on Affective Computing and Intelligent Interaction (ACII)"
    },
    {
      "citation_id": "14",
      "title": "End-to-end label uncertainty modeling for speech-based arousal recognition using bayesian neural networks",
      "authors": [
        "N Prabhu",
        "G Carbajal",
        "N Lehmann-Willenbrock",
        "T Gerkmann"
      ],
      "year": "2022",
      "venue": "End-to-end label uncertainty modeling for speech-based arousal recognition using bayesian neural networks"
    },
    {
      "citation_id": "15",
      "title": "Multivariate t-distributions and their applications",
      "authors": [
        "S Kotz",
        "S Nadarajah"
      ],
      "year": "2004",
      "venue": "Multivariate t-distributions and their applications"
    },
    {
      "citation_id": "16",
      "title": "Pattern recognition and machine learning",
      "authors": [
        "C Bishop",
        "N Nasrabadi"
      ],
      "year": "2006",
      "venue": "Pattern recognition and machine learning"
    },
    {
      "citation_id": "17",
      "title": "A history of the central limit theorem: From classical to modern probability theory",
      "authors": [
        "H Fischer"
      ],
      "year": "2010",
      "venue": "A history of the central limit theorem: From classical to modern probability theory"
    },
    {
      "citation_id": "18",
      "title": "The MSPconversation corpus",
      "authors": [
        "L Martinez-Lucas",
        "M Abdelwahab",
        "C Busso"
      ],
      "year": "2020",
      "venue": "Interspeech 2020"
    },
    {
      "citation_id": "19",
      "title": "Building naturalistic emotionally balanced speech corpus by retrieving emotional speech from existing podcast recordings",
      "authors": [
        "R Lotfian",
        "C Busso"
      ],
      "year": "2019",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "20",
      "title": "Introducing the RECOLA multimodal corpus of remote collaborative and affective interactions",
      "authors": [
        "F Ringeval",
        "A Sonderegger",
        "J Sauer",
        "D Lalanne"
      ],
      "year": "2013",
      "venue": "10th IEEE Int. Conf. and Workshops on Automatic Face and Gesture Recognition (FG)"
    },
    {
      "citation_id": "21",
      "title": "Sewa db: A rich database for audio-visual emotion and sentiment research in the wild",
      "authors": [
        "J Kossaifi",
        "R Walecki",
        "Y Panagakis",
        "J Shen",
        "M Schmitt",
        "F Ringeval",
        "J Han",
        "V Pandit",
        "A Toisoul",
        "B Schuller"
      ],
      "year": "2019",
      "venue": "IEEE transactions on pattern analysis and machine intelligence"
    },
    {
      "citation_id": "22",
      "title": "Defining and Quantifying Conversation Quality in Spontaneous Interactions",
      "authors": [
        "N Prabhu",
        "C Raman",
        "H Hung"
      ],
      "year": "2020",
      "venue": "Comp. Pub. of 2020 Int. Conf. on Multimodal Interaction"
    },
    {
      "citation_id": "23",
      "title": "Automatic nonverbal analysis of social interaction in small groups: A review",
      "authors": [
        "D Gatica-Perez"
      ],
      "year": "2009",
      "venue": "Image and Vision Computing"
    },
    {
      "citation_id": "24",
      "title": "Uncertainty in bayesian deep label distribution learning",
      "authors": [
        "R Zheng",
        "S Zhang",
        "L Liu",
        "Y Luo",
        "M Sun"
      ],
      "year": "2021",
      "venue": "Applied Soft Computing"
    },
    {
      "citation_id": "25",
      "title": "A probabilistic u-net for segmentation of ambiguous images",
      "authors": [
        "S Kohl",
        "B Romera-Paredes",
        "C Meyer",
        "J De Fauw",
        "J Ledsam",
        "K Maier-Hein",
        "S Eslami",
        "D Jimenez Rezende",
        "O Ronneberger"
      ],
      "year": "2018",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "26",
      "title": "Conditional neural processes,\" in Int. Conf. on Machine Learning",
      "authors": [
        "M Garnelo",
        "D Rosenbaum",
        "C Maddison",
        "T Ramalho",
        "D Saxton",
        "M Shanahan",
        "Y Teh",
        "D Rezende",
        "S Eslami"
      ],
      "year": "2018",
      "venue": "Conditional neural processes,\" in Int. Conf. on Machine Learning"
    },
    {
      "citation_id": "27",
      "title": "Weight uncertainty in neural network",
      "authors": [
        "C Blundell",
        "J Cornebise",
        "K Kavukcuoglu",
        "D Wierstra"
      ],
      "year": "2015",
      "venue": "International Conference on Machine Learning"
    },
    {
      "citation_id": "28",
      "title": "Active learning for speech emotion recognition using deep neural network",
      "authors": [
        "M Abdelwahab",
        "C Busso"
      ],
      "year": "2019",
      "venue": "2019 8th Int. Conf. on Affective Computing and Intelligent Interaction (ACII)"
    },
    {
      "citation_id": "29",
      "title": "AVEC 2016: Depression, Mood, and Emotion Recognition Workshop and Challenge",
      "authors": [
        "M Valstar",
        "J Gratch",
        "B Schuller",
        "F Ringeval",
        "D Lalanne",
        "M Torres",
        "S Scherer",
        "G Stratou",
        "R Cowie",
        "M Pantic"
      ],
      "year": "2016",
      "venue": "Proceedings of the 6th International Workshop on Audio/Visual Emotion Challenge, ser. AVEC '16"
    },
    {
      "citation_id": "30",
      "title": "of all things the measure is man\" automatic classification of emotions and interlabeler consistency",
      "authors": [
        "S Steidl",
        "M Levit",
        "A Batliner",
        "E Noth",
        "H Niemann"
      ],
      "year": "2005",
      "venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing"
    },
    {
      "citation_id": "31",
      "title": "Modeling subjectiveness in emotion recognition with deep neural networks: Ensembles vs soft labels",
      "authors": [
        "H Fayek",
        "M Lech",
        "L Cavedon"
      ],
      "year": "2016",
      "venue": "2016 international joint conference on neural networks (IJCNN)"
    },
    {
      "citation_id": "32",
      "title": "Self-attention for speech emotion recognition",
      "authors": [
        "L Tarantino",
        "P Garner",
        "A Lazaridis"
      ],
      "year": "2019",
      "venue": "Proc. Interspeech"
    },
    {
      "citation_id": "33",
      "title": "Probability & statistics for engineers & scientists",
      "authors": [
        "R Walpole",
        "R Myers",
        "S Myers",
        "K Ye"
      ],
      "year": "2007",
      "venue": "Probability & statistics for engineers & scientists"
    },
    {
      "citation_id": "34",
      "title": "Doing bayesian data analysis",
      "authors": [
        "J Kruschke"
      ],
      "year": "2010",
      "venue": "Europe's Journal of Psychology"
    },
    {
      "citation_id": "35",
      "title": "Objective prior for the number of degrees of freedom of at distribution",
      "authors": [
        "C Villa",
        "S Walker"
      ],
      "year": "2014",
      "venue": "Bayesian Analysis"
    },
    {
      "citation_id": "36",
      "title": "Objective priors for the number of degrees of freedom of a multivariate t distribution and the t-copula",
      "authors": [
        "C Villa",
        "F Rubio"
      ],
      "year": "2018",
      "venue": "Computational Statistics & Data Analysis"
    },
    {
      "citation_id": "37",
      "title": "End-to-End Speech Emotion Recognition Using Deep Neural Networks",
      "authors": [
        "P Tzirakis",
        "J Zhang",
        "B Schuller"
      ],
      "year": "2018",
      "venue": "ICASSP -Int. Conf. on Acoustics, Speech and Signal Processing"
    },
    {
      "citation_id": "38",
      "title": "On information and sufficiency",
      "authors": [
        "S Kullback",
        "R Leibler"
      ],
      "year": "1951",
      "venue": "The annals of mathematical statistics"
    },
    {
      "citation_id": "39",
      "title": "Machine learning: a probabilistic perspective",
      "authors": [
        "K Murphy"
      ],
      "year": "2012",
      "venue": "Machine learning: a probabilistic perspective"
    },
    {
      "citation_id": "40",
      "title": "Deep Learning",
      "authors": [
        "I Goodfellow",
        "Y Bengio",
        "A Courville"
      ],
      "year": "2016",
      "venue": "Deep Learning"
    },
    {
      "citation_id": "41",
      "title": "Pytorch: An imperative style, high-performance deep learning library",
      "authors": [
        "A Paszke",
        "S Gross",
        "F Massa",
        "A Lerer",
        "J Bradbury",
        "G Chanan",
        "T Killeen",
        "Z Lin",
        "N Gimelshein",
        "L Antiga"
      ],
      "year": "2019",
      "venue": "Advances in neural information processing systems"
    },
    {
      "citation_id": "42",
      "title": "Essential statistics",
      "authors": [
        "D Rees"
      ],
      "year": "2001",
      "venue": "American Statistician"
    },
    {
      "citation_id": "43",
      "title": "End-to-end multimodal affect recognition in real-world environments",
      "authors": [
        "P Tzirakis",
        "J Chen",
        "S Zafeiriou",
        "B Schuller"
      ],
      "year": "2021",
      "venue": "Information Fusion"
    },
    {
      "citation_id": "44",
      "title": "Speech emotion recognition using semantic information",
      "authors": [
        "P Tzirakis",
        "A Nguyen",
        "S Zafeiriou",
        "B Schuller"
      ],
      "year": "2021",
      "venue": "ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing"
    }
  ]
}