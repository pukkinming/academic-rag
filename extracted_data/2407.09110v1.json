{
  "paper_id": "2407.09110v1",
  "title": "The Magic Xroom: A Flexible Vr Platform For Controlled Emotion Elicitation And Recognition",
  "published": "2024-07-12T09:21:19Z",
  "authors": [
    "S. M. Hossein Mousavi",
    "Matteo Besenzoni",
    "Davide Andreoletti",
    "Achille Peternier",
    "Silvia Giordano"
  ],
  "keywords": [
    "Affective computing",
    "Emotion Elicitation",
    "Emotion Recognition",
    "Virtual Reality (VR)",
    "theory of flow",
    "Magic Xroom"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Affective computing has recently gained popularity, especially in the field of human-computer interaction systems, where effectively evoking and detecting emotions is of paramount importance to enhance users' experience. However, several issues are hindering progress in the field. In fact, the complexity of emotions makes it difficult to understand their triggers and control their elicitation. Additionally, effective emotion recognition requires analyzing multiple sensor data, such as facial expressions and physiological signals. These factors combined make it hard to collect high-quality datasets that can be used for research purposes (e.g., development of emotion recognition algorithms). Despite these challenges, Virtual Reality (VR) holds promise as a solution. By providing a controlled and immersive environment, VR enables the replication of real-world emotional experiences and facilitates the tracking of signals indicative of emotional states. However, controlling emotion elicitation remains a challenging task also within VR. This research paper introduces the Magic Xroom, a VR platform designed to enhance control over emotion elicitation by leveraging the theory of flow. This theory establishes a mapping between an individual's skill levels, task difficulty, and perceived emotions. In the Magic Xroom, the user's skill level is continuously assessed, and task difficulty is adjusted accordingly to evoke specific emotions. Furthermore, user signals are collected using sensors, and virtual panels are utilized to determine the ground truth emotional states, making the Magic Xroom an ideal platform for collecting extensive datasets. The paper provides detailed implementation information, highlights the main properties of the Magic Xroom, and presents examples of virtual scenarios to illustrate its abilities and capabilities.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Affective computing is an interdisciplinary field at the intersection of computer science, psychology, and cognitive science that primarily concentrates on the elicitation and recognition of emotions  [1] . The task of emotion elicitation is aimed to evoke emotional responses in individuals, while emotion recognition focuses on the development of systems that can accurately detect human emotions from a set of observations (such as facial expressions). These areas encounter notable challenges, such as the precise control of elicitation factors to evoke specific target emotions and the accurate detection of emotions.\n\nVirtual Reality (VR)  [2]  has emerged as a powerful tool to address these challenges in affective computing due to its unique properties. Firstly, its immersive and interactive nature enhances the potential for evoking stronger emotional responses in users. More specifically, VR creates realistic virtual environments which allow individuals to deeply engage with the environment and hence, elicit more intense emotions. Secondly, VR enables precise control over environmental factors, such as colors and sounds, allowing one to tailor the virtual experience to elicit specific emotions.\n\nAs shown in Refs.  [3, 4] , this level of control enhances the accuracy and consistency of emotion elicitation. Lastly, VR offers the capability to track users' generated signals, including their movements through the VR headset and physiological signals captured by external devices, that can be used to develop systems for automatic emotion recognition. We note that, since VR elicits stronger and more spontaneous emotions, and tracking does not interfere with the user's experience, VR represents an ideal means for comprehensive data collection.\n\nWhile VR offers numerous benefits, the process of controlling emotion elicitation remains a challenging task, as it is not yet clear which factors truly impact the evoked emotions. In fact, there is currently a lack of comprehensive guidelines based on robust theoretical foundations for conducting experiments in the field of emotion elicitation. In this paper, we claim that the theory of flow  [5]  can help increase the control over the emotion elicitation process. The theory of flow identifies a direct relationship between an individual's skill level, task difficulty, and emotional state. According to this theory, when an individual is fully immersed and engaged in an activity that matches her skill level, she experiences a state of flow associated with increased enjoyment and satisfaction. Conversely, when skills are insufficient for the task's difficulty, anxiety arises, and when skills surpass the task's difficulty, boredom ensues. We argue that, by accurately assessing a user's skill level and modifying the task difficulty accordingly, the desired emotions can be effectively elicited. This paper describes our implementation of a VR application, referred to as the Magic Xroom, for the systematic experimentation with hypotheses on the main factors of emotion elicitation. In particular, we leverage the properties of VR, namely, its flexibility and ability to evoke strong emotions, and of the theory of flow, namely the connection between skills, difficulty, and emotion, to build a platform for controlled emotion elicitation, which will serve the purposes of collecting extensive datasets for further research in the field of affective computing. In the Magic Xroom, the skills of participants are continuously monitored to determine their baseline, and the difficulty of the tasks they perform within the VR environment is adapted accordingly, aiming to strike the ideal balance between challenge and skill level to induce the desired emotional state. By allowing for dynamic adjustments of task parameters, the Magic Xroom ensures a precise and controlled approach to emotion elicitation, which can be further improved by customizing contextual factors, such as lighting, sounds, and other stimuli. Moreover, to gain deeper insights into users' emotional states, the Magic Xroom equips users with a comprehensive sensor suite that monitors physiological responses including heart rate, skin conductance, and facial expressions. Please note that the measures collected by the sensors can always be synchronized, ensuring that the information from different sensors can be effectively combined. This approach offers increased flexibility within the system, as it does not mandate the simultaneous activation of all sensors during data collection. By allowing individual sensors to function independently, the Magic Xroom becomes a modular and adaptive system, accommodating various sensor configurations beyond the basic VR setup. Additionally, the platform incorporates virtual panels for users to provide explicit feedback, enabling the collection of ground truth emotional labels.\n\nThe remainder of the paper is structured as follows. Section 2 reviews existing works in the field of emotion elicitation, specifically focusing on VR-based solutions. Section 3 elaborates on the use of VR and the theory of flow for enhanced emotion elicitation. Section 4 focuses on the description of the Magic Xroom. Finally, Section 5 concludes the paper.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Related Work",
      "text": "The majority of the literature on elicitation strategies primarily focuses on traditional media formats such as images  [6] ,  [7] ,  [8] , sound  [9, 10] ,  [11] , and video  [10, 12] ,  [13] . These traditional media-based methods offer significant advantages in terms of scalability (as capturing and sharing pictures, audio, and video with a large user base is relatively straightforward) and flexibility (as it is easy to adjust key parameters, such as colors in images). However, one notable drawback of these methods is their limited immersion and engagement, which can impact the authenticity of emotional responses, which are not as strong or genuine as they would in real-life situations. To address this limitation, recent research has proposed using VR as an elicitation medium. VR-based methods offer immersive and multi-dimensional experiences  [14] , which significantly enhance users' emotional responses. For instance, Ref  [15]  demonstrated that immersive VR environments effectively enhance the emotional experience through visual stimuli, resulting in increased arousal and valence of the evoked emotions. Along this line, VR has been proven effective in eliciting the target emotion in training  [16]  and gaming activities  [17, 18] . Then, several studies have considered the theory of flow in VR. For example, Ref.  [16]  investigated the factors that contribute to the experience of flow during virtual surfing, while Ref.  [19]  examined the relationship between flow state and learning outcomes in car detailing training. The findings of these studies indicated that individuals who experienced a flow state had superior learning outcomes. However, these works do not employ the theory of flow as a means for improving the control over emotion elicitation, as we instead do in the development of the Magic Xroom.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Virtual Reality And Theory Of Flow For Emotion Elicitation",
      "text": "VR is a groundbreaking technology that merges the real and virtual worlds, immersing users in computer-generated 3-Dimensional (3-D) environments  [20] . This immersive experience is made possible through specialized hardware such as Head Mounted Displays (HMDs)  [21]  and handheld controllers, enabling interactive and engaging encounters that surpass traditional screen-based interactions.\n\nWhen it comes to emotion elicitation, VR holds several advantages over conventional media. By immersing users in dynamic virtual environments, VR has the potential to evoke more authentic and intense emotional responses. Additionally, VR offers a high level of control over environmental factors, allowing for the exploration of various conditions and hypotheses related to emotion elicitation. However, the absence of theoretical guidelines on effectively inducing target emotions has impeded progress in the field.\n\nIn this study, we propose integrating the theory of flow into the process of emotion elicitation. The theory of flow is a psychological theory developed by Mihaly Csikszentmihalyi that explores the relationship between task difficulty, individual skills, and emotional states. It is named after the concept of flow state, which occurs when the level of task difficulty aligns with an individual's skill level. Flow state is characterized by complete engagement, intense focus, a sense of timelessness, and a deep sense of satisfaction and fulfillment. Conversely, individuals with low skills facing highly challenging tasks often experience anxiety, while those with high skills performing easy tasks tend to feel bored.\n\nBy considering the connection between a user's skills, task difficulty, and emotions, we can adopt a more controlled approach to eliciting emotions. Manipulating the factors that trigger specific emotions allows us to fine-tune the elicitation process accordingly. Our primary objective is to manipulate environmental elements to induce targeted emotions, thereby enhancing the overall effectiveness of the emotion elicitation process. For instance, increasing task difficulty can elicit negative emotions, while decreasing difficulty can elicit positive emotions. To the best of our knowledge, this research represents the first attempt to leverage the theory of flow to achieve a more controlled and precise approach to emotion elicitation. In the next Section, we will describe the current implementation of the VR application that we realized for controlled emotion elicitation.",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "The Magic Xroom",
      "text": "The Magic Xroom is an innovative and immersive standalone VR application developed using the Unity game engine 1  and the SteamVR framework 2  . The purpose of creating the Magic Xroom is to improve the process of evoking and identifying emotions in a controlled setting. Essentially, the Magic Xroom provides a controlled and consistent environment for conducting experiments and collecting data. This enables researchers to methodically investigate different facets of emotional reactions. As a result, it serves as a valuable resource for advancing research, creating more accurate emotion recognition algorithms, and refining emotional models. The subsequent sections outline the phases of emotion elicitation and emotional recognition in greater detail.\n\nEmotion Elicitation. The Magic Xroom engages users through sensory inputs and interactive tasks to elicit emotional responses. Following the theory of flow, task parameters (e.g., difficulty levels) need to be dynamically adjusted based on users' skills. To reach this aim, users' skills are continuously monitored throughout the experience, enabling the Magic Xroom to modify the virtual environment based on their performance. Moreover, task difficulty is carefully calibrated to elicit the intended emotions while parameters such as the available experiment time can be adjusted to create situations that induce emotions such as anxiety or stress.\n\nEmotion Recognition. To accurately capture the emotions experienced by users, the Magic Xroom equips individuals with a comprehensive set of sensors that continuously collect diverse data throughout their interaction with the application. These sensors monitor physiological responses, such as heart rate, skin conductance, and facial expressions, providing valuable insights into users' emotional states. More specifically, Galvanic Skin Response (GSR) units are used to capture the electrical characteristics (e.g., conductance) of the skin, and the Optical Pulse/PhotoPlethysmoGram (PPG) signal, which is then used to estimate heart rate variability.\n\nAdditionally, VR eye trackers are used to measure eye movement and focus, while face and mouth trackers are used to capture mouth, jaw, and chin movements. Furthermore, explicit user feedback is collected through intuitive virtual panels, allowing users to provide ground truth emotional labels.",
      "page_start": 5,
      "page_end": 6
    },
    {
      "section_name": "Key Advantages",
      "text": "The advantages of the Magic XRoom are the following:\n\n• Controlled Emotion Elicitation: The Magic XRoom enables the manipulation of task parameters to induce targeted emotional responses, facilitating accurate analysis and evaluation of emotional states.\n\n• Immersive Experiences: The Magic XRoom utilizes interactive tasks, audio cues, and realistic visuals to enhance emotional impact and elicit authentic responses.\n\n• Scalability: With minimal hardware requirements, such as a VR headset and controllers, the Magic XRoom is a scalable tool for widespread utilization of emotion elicitation techniques through VR.\n\n•  Tasks progress with increased difficulty, either by increasing the complexity of the target configuration or by reducing the available time and/or moves. The goal is to induce anxiety in the user due to the limited time available to think of a solution paired with limited movements, leading to one or two maximum sets of possible moves to solve the puzzle.",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "Future Work",
      "text": "The Magic Xroom is currently being implemented and there are several future tasks that are being planned. Firstly, a system that can automatically assess users' skills will be realized. This system will be crucial to adjust the difficulty level to evoke a specific emotion based on the theory of flow.\n\nOne possible approach to evaluate and measure individuals' abilities automatically is to establish a set of task-dependent performance metrics. Secondly, we will develop additional virtual environments for the Magic Xroom. The tower of Hanoi was in fact merely a basic example of a virtual scene created. Lastly, the Magic Xroom will be utilized for extensive data collection. The collected data will inherently consist of multiple modalities as it will leverage various sensors that users will be equipped with (e.g., sensors embedded into the VR headset, along with additional devices, such as smartwatches for monitoring physiological parameters).",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Conclusion",
      "text": "This paper outlines the current implementation of the Magic XRoom, an immersive virtual reality (VR) application designed to enhance control over the elicitation of emotions by applying the theory of flow. The paper discusses the main features of the Magic XRoom, highlights its key benefits, and provides an example of a virtual scenario that has already been developed, i.e., the Tower of Hanoi. The development of the platform is still in progress, with future efforts focusing primarily on incorporating essential functionalities, such as an automated assessment system for individuals' skills and the creation of additional virtual scenarios. Once the development phase is completed, the Magic XRoom will be utilized extensively for data collection purposes.",
      "page_start": 7,
      "page_end": 7
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Feedback and Tower of Hanoi",
      "page": 6
    }
  ],
  "tables": [],
  "citations": [
    {
      "citation_id": "1",
      "title": "Affective computing",
      "authors": [
        "R Picard"
      ],
      "year": "2000",
      "venue": "Affective computing"
    },
    {
      "citation_id": "2",
      "title": "Virtual reality",
      "authors": [
        "J Zheng",
        "K Chan",
        "I Gibson"
      ],
      "year": "1998",
      "venue": "Ieee Potentials"
    },
    {
      "citation_id": "3",
      "title": "A review, current challenges, and future possibilities on emotion recognition using machine learning and physiological signals",
      "authors": [
        "P Bota",
        "C Wang",
        "A Fred",
        "H Da",
        "Silva"
      ],
      "year": "2019",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "4",
      "title": "Emotion recognition from physiological signal analysis: A review",
      "authors": [
        "M Egger",
        "M Ley",
        "S Hanke"
      ],
      "year": "2019",
      "venue": "Electronic Notes in Theoretical Computer Science"
    },
    {
      "citation_id": "5",
      "title": "The psychology of optimal experience",
      "authors": [
        "M Csikszentmihalyi"
      ],
      "year": "1990",
      "venue": "The psychology of optimal experience"
    },
    {
      "citation_id": "6",
      "title": "Reproducible assessment of valence and arousal based on an eeg wearable device",
      "authors": [
        "A Apicella",
        "P Arpaia",
        "A Cataldo",
        "G D'errico",
        "D Marocco",
        "G Mastrati",
        "N Moccaldi",
        "A Pollastro",
        "B Ricciardi",
        "E Vallefuoco"
      ],
      "year": "2022",
      "venue": "2022 IEEE International Conference on Metrology for Extended Reality"
    },
    {
      "citation_id": "7",
      "title": "Detection and analysis of erps for social cognition evaluation",
      "authors": [
        "Y Cabarcas-Mena",
        "K Gutierrez-Ruiz",
        "K Campo-Landines",
        "S Contreras-Ortiz"
      ],
      "year": "2022",
      "venue": "2022 IEEE ANDESCON"
    },
    {
      "citation_id": "8",
      "title": "Virtual reality enhances eeg-based neurofeedback for emotional self-regulation",
      "authors": [
        "P Arpaia",
        "D Coyle",
        "G D'errico",
        "E Benedetto",
        "L De Paolis",
        "N Bois",
        "S Grassini",
        "G Mastrati",
        "N Moccaldi",
        "E Vallefuoco"
      ],
      "year": "2022",
      "venue": "Extended Reality: First International Conference, XR Salento 2022"
    },
    {
      "citation_id": "9",
      "title": "Affective auditory stimulus database: An expanded version of the international affective digitized sounds (iads-e)",
      "authors": [
        "W Yang",
        "K Makita",
        "T Nakao",
        "N Kanayama",
        "M Machizawa",
        "T Sasaoka",
        "A Sugata",
        "R Kobayashi",
        "R Hiramoto",
        "S Yamawaki"
      ],
      "year": "2018",
      "venue": "Behavior Research Methods"
    },
    {
      "citation_id": "10",
      "title": "Sensor and feature selection for lightweight emotion recognition on resource-constrained smartwatches",
      "authors": [
        "D Andreoletti",
        "O Ayoub",
        "A Peternier",
        "T Leidi",
        "S Giordano"
      ],
      "year": "2022",
      "venue": "2022 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress"
    },
    {
      "citation_id": "11",
      "title": "Comparison of different emotion stimulation modalities: an eeg signal analysis",
      "authors": [
        "A Farabbi",
        "E Polo",
        "R Barbieri",
        "L Mainardi"
      ],
      "year": "2022",
      "venue": "2022 44th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)"
    },
    {
      "citation_id": "12",
      "title": "Emotion elicitation with stimuli datasets in automatic affect recognition studies-umbrella review",
      "authors": [
        "P Jemioło",
        "D Storman",
        "B Giżycka",
        "A Ligęza"
      ],
      "year": "2021",
      "venue": "Human-Computer Interaction-INTERACT 2021: 18th IFIP TC 13 International Conference"
    },
    {
      "citation_id": "13",
      "title": "Selecting video stimuli for emotion elicitation via online survey",
      "authors": [
        "S Ismail",
        "N Aziz",
        "S Ibrahim",
        "C Khan",
        "M Rahman"
      ],
      "year": "2021",
      "venue": "Human-Centric Computing and Information Sciences"
    },
    {
      "citation_id": "14",
      "title": "Virtual reality for emotion elicitation-a review",
      "authors": [
        "R Somarathna",
        "T Bednarz",
        "G Mohammadi"
      ],
      "year": "2022",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "15",
      "title": "Can virtual reality increase emotional responses (arousal and valence)? a pilot study",
      "authors": [
        "S Estupiñán",
        "F Rebelo",
        "P Noriega",
        "C Ferreira",
        "E Duarte"
      ],
      "year": "2014",
      "venue": "Design, User Experience, and Usability. User Experience Design for Diverse Interaction Platforms and Environments: Third International Conference"
    },
    {
      "citation_id": "16",
      "title": "Surfing in virtual reality: An application of extended technology acceptance model with flow theory",
      "authors": [
        "Y.-C Huang",
        "L.-N Li",
        "H.-Y Lee",
        "M Browning",
        "C.-P Yu"
      ],
      "year": "2023",
      "venue": "Computers in Human Behavior Reports"
    },
    {
      "citation_id": "17",
      "title": "An empirical study of players' emotions in vr racing games based on a dataset of physiological data",
      "authors": [
        "M Granato",
        "D Gadia",
        "D Maggiorini",
        "L Ripamonti"
      ],
      "year": "2020",
      "venue": "Multimedia Tools and Applications"
    },
    {
      "citation_id": "18",
      "title": "Induction and profiling of strong multi-componential emotions in virtual reality",
      "authors": [
        "B Meuleman",
        "D Rudrauf"
      ],
      "year": "2018",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "19",
      "title": "Virtual reality for car-detailing skill development: Learning outcomes of procedural accuracy and performance quality predicted by vr self-efficacy, vr using anxiety, vr learning interest and flow experience",
      "authors": [
        "K.-H Tai",
        "J.-C Hong",
        "C.-R Tsai",
        "C.-Z Lin",
        "Y.-H Hung"
      ],
      "year": "2022",
      "venue": "Computers & Education"
    },
    {
      "citation_id": "20",
      "title": "Mental vision: a computer graphics platform for virtual reality, science and education",
      "authors": [
        "A Peternier"
      ],
      "year": "2009",
      "venue": "Mental vision: a computer graphics platform for virtual reality, science and education"
    },
    {
      "citation_id": "21",
      "title": "Survey on depth perception in head mounted displays: distance estimation in virtual reality, augmented reality, and mixed reality",
      "authors": [
        "F Jamiy",
        "R Marsh"
      ],
      "year": "2019",
      "venue": "IET Image Processing"
    }
  ]
}