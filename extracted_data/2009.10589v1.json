{
  "paper_id": "2009.10589v1",
  "title": "The Use Of Ai For Thermal Emotion Recognition: A Review Of Problems And Limitations In Standard Design And Data",
  "published": "2020-09-22T14:58:59Z",
  "authors": [
    "Catherine Ordun",
    "Edward Raff",
    "Sanjay Purushotham"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "With the increased attention on thermal imagery for Covid-19 screening, the public sector may believe there are new opportunities to exploit thermal as a modality for computer vision and AI. Thermal physiology research has been ongoing since the late nineties. This research lies at the intersections of medicine, psychology, machine learning, optics, and affective computing. We will review the known factors of thermal vs. RGB imaging for facial emotion recognition. But we also propose that thermal imagery may provide a semi-anonymous modality for computer vision, over RGB, which has been plagued by misuse in facial recognition. However, the transition to adopting thermal imagery as a source for any human-centered AI task is not easy and relies on the availability of high fidelity data sources across multiple demographics and thorough validation. This paper takes the reader on a short review of machine learning in thermal FER and the limitations of collecting and developing thermal FER data for AI training. Our motivation is to provide an introductory overview into recent advances for thermal FER and stimulate conversation about the limitations in current datasets.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Computer vision algorithms that use data from the visible spectrum (e.g. RGB) face a variety of challenges when it comes to human Facial Emotion Recognition (FER) due to the representation of superficial facial features laying on the epidermis. Physiological response from stress, fatigue, or other stimuli cannot be visualized on RGB but can be visualized through thermal imagery due to the changes in temperature detected sub-cutaneously. Thermal image data that can capture temperature changes correlated to human vital signs can be a powerful set of data for telemedicine applications supporting healthcare providers as a diagnostic tool for assessing inflammation and stress  (Kosonogov et al., 2017) . Skin temperature can correlate to certain vital signs and offers a non-invasive method to remotely assess patients. As the cost of high resolution thermal sensors decline and more researchers release thermal FER datasets, there is a great potential to apply thermal imagery for telemedicine purposes. Since the Covid-19 pandemic, governments around the world have begun using thermal sensors combined with Figure  1 : RGB, near infrared and thermal images of a resting (up) and fatigued (down) face. In the thermal images, darker pixels corresponds to colder and lighter to hotter.  (Lopez, del Blanco, and Garcia, 2017)  AI tools for Covid temperature screening  (Ting et al., 2020) . From the U.K, China, Italy, Australia, to the U.S., multiple companies are offering the promise of integrated thermal sensing with facial recognition (FR)  (Van Natta et al., 2020) . We believe that with broader adoption of thermal FR due to changes in HIPAA rules due to Covid-19, it will only be natural that researchers will want to advance their technology towards emotion screening. We caution that before leaping to thermal FER, researchers should be fully aware of the restrictions and limitations of thermal imagery and the problems that may underlie existing thermal FER databases. The adoption of thermal imagery as a source for any humancentered AI task is not easy. Thus, the goal of this paper is to present the state of the literature and discuss the challenges hindering the full adoption of AI as a tool for thermal FER.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Advantages Of Thermal Over Visible",
      "text": "When the public sector thinks about FER and facial recognition (FR), the go-to modality is the visible spectrum usually encoded as RGB. RGB images have dominated the area of FER, indicative through a variety of well known facial arXiv:2009.10589v1 [cs.CV] 22 Sep 2020 databases used in AI. 1 But, FR using RGB databases has become a controversial area of computer science, requiring careful consideration of its flaws and innate assumptions within the data and how it is applied (Martinez-Martin, 2019;  Buolamwini and Gebru, 2018; Greene, Hoffmann, and Stark, 2019; Singer and Metz, 2019; Lohr, 2018) . Beyond the original intended academic purposes, some RGB databases have been taken down in order to prevent industry FR training  (Murgia, 2019) . In the wake of Black Lives Matters protests in June 2020, Microsoft and IBM discontinued their development of FR, where Amazon invoked a one year moratorium on FR based on evidence of algorithmic discrimination against communities of color  (Matsakis, 2020) . Of particular value to the public sector, is whether thermal imagery for FER affords any level of privacy protection and bias mitigation. The answer may stem from the separation of thermal imagery from other machine learning tasks, known to increase recognition and decrease anonymity.\n\nFigure  2 : Example of data from the Iris dataset  (Hammoud)  We believe that long-wave Infrared Radiation (LWIR) used alone, as a data source for FER, may be able to provide some form of anonymity for healthcare applications to minimize racial, ethnic, and potentially gender bias, when compared to RGB for FER. Through its low, grey-scale resolution 2 and reliance on temperature vectors driven by underlying vasculature  (Ioannou, Gallese, and Merla, 2014) , rather than superficial skin tone, texture, and pigmentation, thermal imagery can be more challenging to easily identify individuals. But there still remains a variety of issues to preserve privacy. For example, anonymity may not be possible if thermal FER is combined with the machine learning task of FR, especially since thermal FR is well researched with multiple methods proposed to detect and recognize individuals. The concept of separating FR from other tasks is not uncommon.  Van Natta et al. (2020) , question whether during Covid-19 temperature monitoring, there is even a need to conduct FR given how the 1 CK+ , FER 2013 , FERET , EmotioNet, RECOLA, Affectiva-MIT Facial Expression Dataset, NovaEmotions, MultiPIE, Mc-Master Shoulder Pain, AffectNet, Aff-Wild2, the Japanese Female Facial Facial Expression database, and CASME II for microexpressions 2 Thermal imaging manufacturers offer a variety of color palettes for visualizing temperature beyond \"white hot\" such as \"iron bow\" and \"rainbow\". It should be cautioned that some manufacturers offer fusion visualizations that fuse the RGB and thermal images together thereby improving resolution.\n\noverall purpose is to identify infection as opposed to identity. It is important to caution, that although thermal FR is more challenging than the visible domain, it is feasible to use thermal imagery as a \"soft\" biometric due to its invariance under lighting and pose  (Reid et al., 2013; Friedrich and Yeshurun, 2002) . For example, superficial vascular networks are unique to each person's face as proposed by  Buddharaju et al. (2007) , and can be extracted through methods like anisotropic diffusion to identify minutiae points akin to fingerprints as shown in Figure  3 . Further, combining RGB with thermal can increase recognition accuracy. For example,  Nguyen and Park (2016)  used a combination of thermal and visible full body images for gender detection, finding that their proposed method of score-level fusion (training two separate SVM classifiers) combining thermal and visible led to a decrease in error of 14.672 equal error rate (EER) when compared to using thermal only (19.583 EER) and visible only (16.540 EER).   (Buddharaju et al., 2007)  In addition, there has been research in the computer and electrical engineering fields to develop sensor-level privacy for thermal sensors in situations where people need to be sensed and tracked, but not identified. Work by  Pittaluga, Zivkovic, and Koppal (2016)  demonstrated different techniques to include digitization that masks human temperatures measurements thereby obscuring any ability to detect faces shown in Figure  4 , manipulating the sensor noise parameters as the thermal image is being generated, and algorithms to under or overexpose specific pixels that are designated as \"no capture\" zones. Still in research, these techniques require different levels of hardware and firmware upgrades based on the thermal sensor.\n\nThermal imagery has additional technical advantages including how it is (1) invariant to lighting conditions unlike RGB, allowing the detection of physiological response (heat) to occur in low light or total darkness; (2) is a reliable and accurate correlation to standard physiological measures like respiration and heart rate; (3) is non-invasive i.e., requiring no skin contact whatsoever, making it convenient and non-intrusive and potentially relevant for noncommunicative persons; (4) resistant to intentional deceit since physiological responses cannot be faked, whereas visible facial expressions can be controlled; and (5) is able to reveal facial disguises (i.e. wigs, masks) since these materials have high reflectivity and display as the brightest on thermograms compared to human skin which is among the darkest objects with low reflectivity  (Pavlidis and Symosek, Figure 4 : Digitization privacy in different scenes: digitization results in scenes with people, computers and buildings. The left column are the input 16 bit images and the right column is the simulated output.  (Pittaluga, Zivkovic, and Koppal, 2016) 2000) . In addition, thermal imagery offers physiological signals of social interactions from person to person. In terms of deceit detection, it is valuable to note that RGB images can also be used to detect microexpressions using databases like CASME II. Microexpressions are genuine, quick facial movements that may be uncontrollable or unnoticeable by the individual, and therefore have been studied as an indication of deception  (Yan et al., 2014) . The RGB images used for studying microexpressions, however, are different than standard RGB FR datasets. They consist of video sequences captured using spontaneous natural elicitation, captured at a high frame rate of 200 fps, and labeled with facial action units (FAUs) which are encoded combination of facial movements based on Paul Ekman's Facial Action Coding System (FACS)  (Ekman, 1999) .",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Physiology And Thermal Fer",
      "text": "A brief explanation of thermal radiation helps to understand how facial skin acts as a radiating surface. Thermal radiation is emitted by all objects above absolute zero (-273.15 • C). Human skin is estimated at 0.98 to 0.99  (Yoshitomi et al., 2000) . The principal of thermal image generation is well understood by the Stefan-Boltzmann law that states total emitted radiation over time by a black body is proportional to T 4 where T is temperature in Kelvins: W = σT 4 where W is radiant emittance (W/cm 2 ), is emissivity, σ is the Stefan-Boltzmann constant (5.6705 • 10 -12 W/cm 2 K 4 ), and T is Temperature (K).\n\nA black body is an object that absorbs all electromagnetic radiation it comes in contact with. No electromagnetic radiation passes through the black body and none is reflected. Since no visible light is reflected or transmitted, the object Figure  5 : Long-Wave IR falls in the wavelength range of 8 µm to 15 µm looks black upon visualization from thermal imagery, when it is cold. Thermal sensors respond to infrared radiation (IR) and produce visualizations of surface temperature. Because LWIR operates in a sub-band of the electromagnetic spectrum per Figure  5  it is invariant to illuminating conditions meaning that it can operate in low light to complete darkness. By imaging temperature variations to emotionally induced stimuli such as videos or pictures, thermograms reveal genuine responses to social situations. This occurs through activation of the autonomic nervous system (ANS) where emotional arousal leads to a perfusion of blood vessels innervated at the surface of the skin  (Ioannou, Gallese, and Merla, 2014) . These images are called thermograms and are the data captured in thermal FER datasets, with labels based of the emotional response elicited (i.e. happiness, disgust, sadness, deceit, stress, etc.). Although today's need for a touch-less system are paramount, the concept of using thermograms for contact-less physiological monitoring is not new and rooted in the intersection of physiological research  (Selinger 2016; Buddharaju 2007; Pavlidis 2000; Ionnou 2014 ) and affective computing  (Wilder 1996; Yoshitomi 2000; Goulart 2019 ). These include applications for FER where different emotions are detected from thermal facial images alone, in addition to person re-identification on thermal imagery, for FR. Since 1996  (Wilder et al., 1996)  there have been numerous studies evaluating how thermograms correlate with vital measures. In 2007, Pavlidis  (Pavlidis et al., 2007)  demonstrated that thermal imagery is a reliable measure to assess emotional arousal where different regions of the face (zygo- maticus, frontal, orbital, buccal, oral, nasal) correlate with different emotional responses. Thermal imagery also visualizes the physiology of perspiration  (Pavlidis et al., 2012; Ebisch et al., 2012) , cutaneous and subcutaneous temperature variations  (Hahn et al., 2012; Merla et al., 2004) , blood flow  (Puri et al., 2005) , cardiac pulse  (Garbey et al., 2007) , and metabolic breathing patterns  (Pavlidis et al., 2012)  and has been used to monitor heat stress and exertion  (Bourlai et al., 2012) . The reliability of thermal temperature readings have been repeatedly shown to be consistent and correlate accurately with gold standard physiological measures of electrocardiography (ECG), piezoelectric thorax stripe for breathing monitoring, nasal thermistors, skin conductance, or galvanic skin response (GSR)  (Pavlidis et al., 2007; Sonkusare et al., 2019) .\n\nWe can even observe these changes with the naked eye, such as embarrassment causing a person to blush  (Sonkusare et al., 2019) , or fear leading to pallor  (Kosonogov et al., 2017) . Merla  (Merla, 2014 ) offered a survey of thermal studies in psychophysiology from 1990 to 2013, demonstrating a series of emotional responses detected on thermal imagery such as startle response, fear of pain, lie detection, mental workload, empathy, and guilt. These responses occur in different regions of the face, or ROIs. Salazar-Lopez found high arousal images elicited temperature increases on the tip of the nose  (Salazar-López et al., 2015) . Kosnogov  (Kosonogov et al., 2017)  found that more arousing an image, the faster and greater the thermal response on the tip of the nose. He speculated that the speed and magnitude of these thermal responses were linked to autonomic adjustments normal to emotional situations. Zhu  (Zhu, Tsiamyrtzis, and Pavlidis, 2007)  found that deception was detected through increased forehead temperature and Puri  (Puri et al., 2005)  found the forehead to be correlated with stress. Social responses based on one-on-one personal contact can also be observed. For example, Ebisch  (Ebisch et al., 2012)  found \"affective syn-chronization\" of facial thermal responses between mother and child, where distress temperatures at the tip of the nose were mimicked by the mother as she watched her child in distress. Fernandez  (Fernández-Cuevas et al., 2015)  summarizes analysis by Ioannou, Gallese, and Merla (2014) describing whether temperature increases, decreases, or stays the same based on different emotions and ROIs provided in Figure  7 .",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Ai And Thermal Fer",
      "text": "Since 2000 with  (Yoshitomi et al., 2000) , machine learning in thermal FER has grown slowly to include emotion classification by  (Khan, Ingleby, and Ward, 2006; Nhan and Chau, 2009; Wang et al., 2014a; Jarlier et al., 2011; Wang et al., 2014b; Trujillo et al., 2005)  with gradual adoption of AI methods such as neural networks. The ability to move away from manual, hand-crafted feature extraction to automatic learning through neural networks has already proven advantageous for thermal-to-visible image translation through GANs  (Mallat et al., 2019; Kniaz et al., 2018 ; Chen and  Where Li identified 74 papers, we only identified 14 thermal FER datasets in Table  1  whose numbers have increased since 2018 possibly due to the decreasing cost of thermal cameras and the easier ability to purchase them online. Further, we identified only eleven AI thermal FER papers, shown in  Figure  9 : The Tufts Face Database  (Panetta et al., 2018)  manual feature extraction using geometric methods to learning latent representations using deep learning. These works do not consistently release code and have varied levels of explanation around experimental design and arousal stimulus, which we summarized in Table  3 . This makes it challenging to reproduce, much less compare across studies.\n\nResearchers in thermal emotion recognition such as Goulart et al. (  2019 ) agree, particularly since there is no standard thermal FER imaging benchmark dataset consistently used across studies. In an empirical review reproducing 255 ma- chine learning papers, Raff  (Raff, 2019)  notes that papers which are scientifically sound and complete, should be independently reproducible based solely on explanation, details, and descriptions. Failures in reproducibility can occur when language or notation is unclear, when the algorithm is missing details about implementation or equations, and when nuanced details are left out. In Table  1  we catalog the few available (via request or publicly) thermal datasets that have been used for tasks including FR and FER. They vary in scope, where some do not have emotion labels at all, making it difficult to benchmark and standardize results that may eventually impact psychological and health-related decisions. One example of a recently developed thermal FER dataset is by Tufts University shown in Figure  9 .\n\n5 Thermal FER Data Challenges Some researchers have noticed the lack of variation across thermal FR dataset that fail to account for diverse emotional states, alcohol intake or exercise, and ambient temperature, leading them to doubt the rigor of the reported results especially in real life conditions  (Shoja Ghiass, 2014) .\n\nAssuming that the lack of a comprehensive thermal FER benchmark dataset is one factor that hinders the advancement of AI research, we can begin exploring the challenges of designing such a dataset. But, developing a thermal FER dataset is different than simply crawling the web for RGB faces. The collection of thermal FER data requires an experiment unto itself, needing institutional review board (IRB) approval, subject recruitment, experimental design, and specialized equipment. As a result, thermal FER datasets are expensive in terms of time and labor. We have observed some trends across databases that if addressed in the development of a single high-fidelity dataset, may carve a path for greater adoption of thermal AI FER studies. We justify these assertions based on research in the psycho-physiology domain, below.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Include Video Sequences",
      "text": "Video sequences present timing of the arc of expression onset and delay. It is important to capture intensity and duration of expression which has been found consistent with automatic movement and neuropsychological models  (Tian, Kanade, and Cohn, 2005) .  Levenson (1988)  indicated that duration of an emotional response is 0.5 4 seconds. But Nguyen  (Nguyen et al., 2013)  cites mistakes in many of the leading thermal recognition databases. In the USTC-NVIE database their procedure for data acquisition had video gaps between each emotion clip at 1-2 minutes which is too short for participants to establish a neutral emotion status. Research indicates that for thermal response (cutaneous skin temperature), there is a delay after stimulus that needs to be accounted for and recorded  (Ioannou, Gallese, and Merla, 2014)  and temperature change can occur in less than 30 seconds upon stimulation  (Pavlidis et al., 2012) . Temperature changes at the tip of the nose can occur as fast as 10 seconds after stimulus and last 20 -30 seconds regardless of distress or soothing  (Ebisch et al., 2012) . In a more recent paper,  (Sonkusare et al., 2019)  were able to quantify the temporal dynamics of thermal response when compared to gold standard measures like Galvanic Skin Response (GSR) demonstrating that thermal response occurred only 2 seconds later than GSR when exposed to an auditory stimulus. Static images without a time axis can be incomplete and will fail to capture the complete physiological signal and emotional response.",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "Enable Spontaneous Response",
      "text": "Many existing thermal databases that are focused only on FR have discrete, posed affects based on the labeling defined by Ekman  (Ekman 1999) . But affective researchers argue that spontaneous emotional reactions are more realistic since, \"people show blends of emotional displayshence, the classification of human non-verbal affective feedback into a single basic-emotion category may not be realistic.\"  (Gunes and Pantic, 2010; McDuff, Girard, and El Kaliouby, 2017) . Further, multiple emotions typically occur as opposed to a single discrete response. For example, in a 1993 study by  Gross et al. 85  subjects self-reported a variety of feelings after watching a close-up arm amputation medical video  (Gross and Levenson, 1993) .\n\nAnother argument against discrete labels is the possibility that people express emotions as internalizers or externalizers, meaning different people suppress emotional expres-Figure  10 : Multiple feelings self-reported after exposure to high arousal video  (Gross and Levenson, 1993)  sion in different ways making it difficult to truly capture expression in a basic, discrete manner  (Gross and Levenson, 1993) . To elicit spontaneous response, emotion researchers use static images such as the International Affective Picture System  (Kosonogov et al., 2017)  or short clips of emotional videos  (Nguyen et al., 2013) . In a recent 2019 study by  Sonkusare et al. (2019) , they use an auditory stimulus described in Figure  11  to mimic a startle response, spontaneously.",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "Provide Social Or Personal Context",
      "text": "In a similar vein to spontaneous, natural emotion collection, providing social context in an experimental setting will change the nature of the emotion recorded. Context labeling to account for elicitation methods that are prompted spontaneously through personal elicitation (i.e. images, videos), versus social interaction with another person (or robot per  (Goulart et al., 2019) ) may signal different physiological responses reflected in thermal imagery. Factors that influence these responses may include interpersonal distance, gaze direction, and opposite gender in the interaction  (Kosonogov et al., 2017; Gunes and Pantic, 2010) . A sociodynamic model of emotions  (Mesquita and Boiger, 2014)  asserts that emotions \"emerge in interplay with and derive their specific function from the social context. This means that emotional experience and behavior will be differently constructed across various contexts\". For example, Goulart  (Goulart et al., 2019)  analyzed emotional response for 17 children during a human-child robot interaction experiment shown in Figure  12 . Using Principle Component Analysis (PCA) and Linear Discriminant Analysis (LDA), they inferred happiness and surprise as the most frequently expressed, which were consistent with what the children self-reported upon interacting with the New-Mobile Autonomous Robot for Interaction with Autistics (N-MARIA) robot.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Collect Multimodal Pairs",
      "text": "In 2000 Yoshitomi  (Yoshitomi et al., 2000)  classified discrete affects by combining visible, thermal, and audio signals from 21 test subjects, achieving 85% accuracy.  Zhu, Tsiamyrtzis, and Pavlidis (2007)  discussed multimodal data as \"cross scale\" data for biomedical research, or interconnections of different types of data using AI to infer mappings even if some data is missing. In essence, both were developing multimodal machine learning models, where multiple modalities, or types of information, may be combined to increase the accuracy of models  (Baltrušaitis, Ahuja, and Morency, 2018) . The approach to collect pairs is not new.\n\nNguyen collected thermal FER pairs for the KTFE database  (Nguyen et al., 2013)  and the Iris  (Hammoud) , Eurecom  (Mallat and Dugelay, 2018) , and University of Notre Dame (UND) also have pairs which offer greater flexibility for different AI use cases like image translation for person reidentification. This includes research into thermal-to-visible GANs  (Mallat and Dugelay, 2018; Kniaz et al., 2018; Chen and Ross, 2019; Zhang et al., 2018) . With paired images capturing the RGB and LWIR images simultaneously using a camera equipped with a dual sensor, offers a mapping between both modalities for an AI algorithm to learn.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Document Experimental Setup",
      "text": "Documenting experimental setup is important in order to minimize bias in the resulting thermogram, which can be affected by a variety of environmental and human subject conditions. Ioannao  (Ioannou, Gallese, and Merla, 2014)  articulates in his paper on the potential and limitations of thermal imaging in physiology that, \"Cutaneous thermal responses to external stimuli of psychophysiological valence could result in small temperature variations of the ROIs. Thus, it is extremely important to ensure that the observed temperature variations are not artifacts due to either environmental physiological causes or simply subject motion.\" Some of these can be minimized, the methods of which should be recorded and shared in the paper so that other thermal FER data collection trials can be repeated or improved to control for these external factors.\n\nFigure  14 : Experimental Setup for Iris dataset capture  (Kong et al., 2007)  In Table  3  we provide a sample of experimental parameters from several thermal FER papers and show how they vary from paper to paper. This demonstrates non-standard setups over the years of thermal FER research that could affect the reusability and generalization of these data for AI experiments. But, different papers vary in the extent of how much they document their experimental protocol provided in an example set of papers in Table  3 . Multiple factors need to be managed in order to minimize variables in the environment that influence thermal capture, leading to potentially misleading thermograms such as 1) Cold or warm air, as well as humidity, 2) Facial expressions (e.g. open mouth), 3) Physi-cal conditions (e.g. lack of sleep, alcohol, caffeine), 4) Mental state (i.e. fear, stress, excitement), 5) Opaque to glasses, 6) Skin temperature variance through the day  (Kosonogov et al., 2017) .  Experimental design also includes the demographics of recruited subjects. Very few details are provided about race and ethnicity shown in Table  3  for the exception of  (Lopez, del Blanco, and Garcia, 2017)",
      "page_start": 8,
      "page_end": 9
    },
    {
      "section_name": "Accounting For Sensor Differences",
      "text": "Lastly, the cost of thermal sensors through vendors like FLIR, have decreased over the past decade with increasingly higher quality resolution made accessible to the public. Prior papers have extensively used the Iris and Equinox (now discontinued) datasets. But with the release of more custom datasets as shown in Table  1 , is it fair to compare the output of thermal images from one sensor against another, which may have different optical properties? Or, is it sufficient that each sensor operates in the LWIR band? Many researchers have used different thermal sensors over the years: Pavlidis detected anxiety in thermal imagery in 2000 using an uncooled thermal camera with a spectral band of 8µm-14µm manufactured by Raytheon (the ExplorIR model)  (Pavlidis and Symosek, 2000) , Nguyen in 2014 used a NEC R300 collecting in the 8µm-14µm band  (Nguyen et al., 2013) , Aureli in 2015 used a FLIR SC660, an uncooled microbolometer sensor that collects in the 7.5µm 13µm band  (Aureli et al., 2015) , and Eurecom researchers in 2018 used a FLIR Duo-Pro, an uncooled VOx Microbolometer sensor operating in 7.5µm13.5 µm  (Mallat and Dugelay, 2018) . Table  3  provides a selection of thermal cameras used across various thermal FER studies as examples of how the cameras vary from study to study.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Recommendations",
      "text": "It is daunting to attempt to design a universal, thermal FER benchmark dataset that can account for the myriad of challenges we described. Extensive funding for time, labor, and evaluation would be required. Some challenges are easier to mitigate than others, for example improving the documentation of experimental setup possibly using templates by Gebru et al. (  2018 ) and  Mitchell et al. (2019)  versus designing physiological stimuli. But, there may be more feasible short-term solutions that emphasize quality of reviewing the limitations of individual datasets and annotating each with a new labeling system. First, we have observed there are a number of custom datasets as described in Table  2  and are confident that our review missed several proprietary, unpublished, non-English, or classified thermal FER datasets. As a result, there are likely multiple thermal FER databases available all collected with a different set of subjects, experimental setups, and labeling. Offering these in a central online location, would be one step towards inventorying the breadth of data already available worldwide. Third, despite our review of the thermal FR and FER literature, we struggled to identify any research to evaluate the limits of obfuscating age, gender, ethnicity, and race using thermal imagery. Although some papers affirmed that their dataset consisted of diverse demographics  (Chang et al., 2006)  per Figure  16 , none to our knowledge, conducted quantitative tests with human reviewers and inter-rater statistics to test whether or not sensitive demographics could be masked. We believe that in order to assert that thermal imagery can afford any privacy protection and minimize bias, tests must be developed using IRB approval. More broadly, future work should take careful consideration into the scientific questions their research is tackling and the impact it may have in developing or prolonging undesired biases  (Friedman and Nissenbaum, 1996) . Biometrics related research is inherently sensitive and solutions can be valuable to society  (Jai, 2016) . As such researchers should make sure they are familiar with ethical concerns that have occurred in neighboring application areas  (Ensign et al., 2018; Chouldechova, 2017; Kleinberg, Mullainathan, and Raghavan, 2016)  and remain open to understanding new perspective in which their research may be helpful or detrimental, and could be improved to reduce potential risks  (Skirpan and Gorelick, 2017; Goldsmith and Burton, 2017; Sylvester and Raff, 2018) .",
      "page_start": 9,
      "page_end": 10
    },
    {
      "section_name": "Conclusion",
      "text": "In this paper, we introduced the advantages of using thermal imagery over RGB for facial FER and provided a survey of thermal FER AI papers, datasets, and selected samples of experimental design protocols. There are several technical benefits of using thermal imagery compared to RGB images for FER, one of which potentially being semi-anonymity. However, there are few labeled, standard thermal affective data sets available for AI training. We have provided a summary of the proposed challenges, with our insights on the consequences, mitigation, and opportunities for each in Table 4.",
      "page_start": 10,
      "page_end": 10
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: RGB, near infrared and thermal images of a resting",
      "page": 1
    },
    {
      "caption": "Figure 2: Example of data from the Iris dataset (Hammoud)",
      "page": 2
    },
    {
      "caption": "Figure 3: Further, combining RGB",
      "page": 2
    },
    {
      "caption": "Figure 3: Vascular network extraction: (a) Original seg-",
      "page": 2
    },
    {
      "caption": "Figure 4: , manipulating the sensor noise pa-",
      "page": 2
    },
    {
      "caption": "Figure 4: Digitization privacy in different scenes: digitiza-",
      "page": 3
    },
    {
      "caption": "Figure 5: Long-Wave IR falls in the wavelength range of",
      "page": 3
    },
    {
      "caption": "Figure 5: it is invariant to illuminating conditions",
      "page": 3
    },
    {
      "caption": "Figure 6: Thermal representation for extraction of ROIs by",
      "page": 3
    },
    {
      "caption": "Figure 7: Figure 7: Skin thermal variations in the considered regions",
      "page": 4
    },
    {
      "caption": "Figure 8: Any internet",
      "page": 5
    },
    {
      "caption": "Figure 8: Growth of lab-controlled, small size data to “in-",
      "page": 5
    },
    {
      "caption": "Figure 9: The Tufts Face Database (Panetta et al., 2018)",
      "page": 5
    },
    {
      "caption": "Figure 10: Multiple feelings self-reported after exposure to",
      "page": 7
    },
    {
      "caption": "Figure 11: to mimic a startle response, sponta-",
      "page": 7
    },
    {
      "caption": "Figure 11: Example of an emotional stimulus by Sonkusare",
      "page": 7
    },
    {
      "caption": "Figure 12: Using Principle Component Analysis (PCA) and",
      "page": 7
    },
    {
      "caption": "Figure 12: Experimental setup showing the child-robot inter-",
      "page": 7
    },
    {
      "caption": "Figure 13: Example of TV-GAN trained on multimodal pairs",
      "page": 8
    },
    {
      "caption": "Figure 14: Experimental Setup for Iris dataset capture (Kong",
      "page": 8
    },
    {
      "caption": "Figure 15: (Fern´andez-Cuevas et",
      "page": 8
    },
    {
      "caption": "Figure 15: Factors inﬂuencing thermal imagery of humans",
      "page": 8
    },
    {
      "caption": "Figure 16: Participants from diverse multimodal dataset col-",
      "page": 9
    },
    {
      "caption": "Figure 16: , none to our knowledge, conducted",
      "page": 10
    }
  ],
  "tables": [
    {
      "caption": "Table 3: providesaselectionofthermalcamerasusedacrossvarious",
      "data": [
        {
          "Challenge\nConsequence\nMitigation\nOpportunities": "Including labeled videos in thermal\nSpatio-temporal labeling of thermal\nInclude video sequences\nStatic\nimages\nfail\nto\ncapture\nthe\nFER dataset.\nonset, delay, duration of physiolog-\ncomplete\ntemporal\ndynamics\nof\nical response.\nemotional response."
        },
        {
          "Challenge\nConsequence\nMitigation\nOpportunities": "Add spontaneous elicitation where\nNatural, “in the wild” expressions\nEnable spontaneous response\nDiscrete posed expressions may not\npossible, in addition to discrete set.\nthat offer\naccurate\nrepresentations\ninvoke\nrealistic\nphysiological\nre-\nof emotion.\nsponse."
        },
        {
          "Challenge\nConsequence\nMitigation\nOpportunities": "Provide social or personal context\nThermal data collected without so-\nIf\nappropriate,\nlabel\nsocial\ncon-\nSocial\ninteraction thermal FER ex-\ncial stimuli may not be useable for\ntext or if controlling for, document\npressions, with labeled context and\nhow social response has been mini-\nscenarios.\nsocial use cases.\nmized."
        },
        {
          "Challenge\nConsequence\nMitigation\nOpportunities": "May\nrequire\ndual\nsensor,\nor\nex-\nMultimodal pairs for various social,\nCollect multimodal pairs\nNo\nopportunity\nto\nincrease\nac-\nspontaneous\nelicited thermal FER\nperimental design for simultaneous\ncuracy\nor\nlearn\nfrom additional\ncapture using two cameras.\ndomains.\nmodality mappings\nif\nonly\none\nmodality (thermal) is collected."
        },
        {
          "Challenge\nConsequence\nMitigation\nOpportunities": "Report at minimum, the parameters\nStandard thermal FER experimen-\nDocument experimental setup\nConfounding through uncontrolled\nshown in in Table 3.\ntal protocol\nfor design and demo-\nenvironmental variables can lead to\ngraphic documentation.\nmisleading images."
        },
        {
          "Challenge\nConsequence\nMitigation\nOpportunities": "Accounting for Sensor Differences\nUntested margin\nof\nerror\nfor\nim-\nNo mitigation strategy. This\nis an\nAssessment with optical engineers\nages collected using different\nther-\nopen research question.\nto determine margin of error across\nmal sensors.\nsensors for human thermal FER."
        }
      ],
      "page": 9
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Behavioral and facial thermal variations in 3-to 4-month-old infants during the still-face paradigm",
      "authors": [
        "T Aureli",
        "A Grazia",
        "D Cardone",
        "A Merla"
      ],
      "year": "2015",
      "venue": "Frontiers in psychology"
    },
    {
      "citation_id": "2",
      "title": "Multimodal machine learning: A survey and taxonomy",
      "authors": [
        "T Baltrušaitis",
        "C Ahuja",
        "L.-P Morency"
      ],
      "year": "2018",
      "venue": "IEEE transactions on pattern analysis and machine intelligence"
    },
    {
      "citation_id": "3",
      "title": "Use of thermal imagery for estimation of core body temperature during precooling, exertion, and recovery in wildland firefighter protective clothing",
      "authors": [
        "T Bourlai",
        "R Pryor",
        "J Suyama",
        "S Reis",
        "D Hostler"
      ],
      "year": "2012",
      "venue": "Use of thermal imagery for estimation of core body temperature during precooling, exertion, and recovery in wildland firefighter protective clothing"
    },
    {
      "citation_id": "4",
      "title": "Physiology-based face recognition in the thermal infrared spectrum",
      "authors": [
        "P Buddharaju",
        "I Pavlidis",
        "P Tsiamyrtzis",
        "M Bazakos"
      ],
      "year": "2007",
      "venue": "IEEE transactions on pattern analysis and machine intelligence"
    },
    {
      "citation_id": "5",
      "title": "Gender shades: Intersectional accuracy disparities in commercial gender classification",
      "authors": [
        "J Buolamwini",
        "T Gebru"
      ],
      "year": "2018",
      "venue": "Conference on fairness, accountability and transparency"
    },
    {
      "citation_id": "6",
      "title": "An indoor and outdoor, multimodal, multispectral and multi-illuminant database for face recognition",
      "authors": [
        "H Chang",
        "H Harishwaran",
        "M Yi",
        "A Koschan",
        "B Abidi",
        "M Abidi"
      ],
      "year": "2006",
      "venue": "2006 Conference on Computer Vision and Pattern Recognition Workshop (CVPRW'06"
    },
    {
      "citation_id": "7",
      "title": "Matching thermal to visible face images using a semantic-guided generative adversarial network",
      "authors": [
        "C Chen",
        "A Ross"
      ],
      "year": "2019",
      "venue": "Gesture Recognition"
    },
    {
      "citation_id": "8",
      "title": "Fair prediction with disparate impact: A study of bias in recidivism prediction instruments",
      "authors": [
        "A Chouldechova"
      ],
      "year": "2017",
      "venue": "FAT ML Workshop"
    },
    {
      "citation_id": "9",
      "title": "Mother and child in synchrony: thermal facial imprints of autonomic contagion",
      "authors": [
        "S Ebisch",
        "T Aureli",
        "D Bafunno",
        "D Cardone",
        "G Romani",
        "A Merla"
      ],
      "year": "2012",
      "venue": "Biological psychology"
    },
    {
      "citation_id": "10",
      "title": "Basic emotions. Handbook of cognition and emotion",
      "authors": [
        "P Ekman"
      ],
      "year": "1999",
      "venue": "Basic emotions. Handbook of cognition and emotion"
    },
    {
      "citation_id": "11",
      "title": "Runaway Feedback Loops in Predictive Policing",
      "authors": [
        "D Ensign",
        "S Friedler",
        "S Neville",
        "C Scheidegger",
        "S Venkatasubramanian"
      ],
      "year": "2018",
      "venue": "Proceedings of the 1st Conference on Fairness, Accountability and Transparency"
    },
    {
      "citation_id": "12",
      "title": "Classification of factors influencing the use of infrared thermography in humans: A review",
      "authors": [
        "I Fernández-Cuevas",
        "J Marins",
        "J Lastras",
        "P Carmona",
        "S Cano",
        "M García-Concepción",
        "M Sillero-Quintana"
      ],
      "year": "2015",
      "venue": "Infrared Physics & Technology"
    },
    {
      "citation_id": "13",
      "title": "Bias in Computer Systems",
      "authors": [
        "B Friedman",
        "H Nissenbaum"
      ],
      "year": "1996",
      "venue": "ACM Trans. Inf. Syst"
    },
    {
      "citation_id": "14",
      "title": "Seeing people in the dark: Face recognition in infrared images",
      "authors": [
        "G Friedrich",
        "Y Yeshurun"
      ],
      "year": "2002",
      "venue": "International Workshop on Biologically Motivated Computer Vision"
    },
    {
      "citation_id": "15",
      "title": "Contact-free measurement of cardiac pulse based on the analysis of thermal imagery",
      "authors": [
        "M Garbey",
        "N Sun",
        "A Merla",
        "I Pavlidis"
      ],
      "year": "2007",
      "venue": "IEEE transactions on Biomedical Engineering"
    },
    {
      "citation_id": "16",
      "title": "Datasheets for datasets",
      "authors": [
        "T Gebru",
        "J Morgenstern",
        "B Vecchione",
        "J Vaughan",
        "H Wallach",
        "Iii Daumeé",
        "H Crawford"
      ],
      "year": "2018",
      "venue": "Datasheets for datasets",
      "arxiv": "arXiv:1803.09010"
    },
    {
      "citation_id": "17",
      "title": "Infrared face recognition: A comprehensive review of methodologies and databases",
      "authors": [
        "R Ghiass",
        "O Arandjelović",
        "A Bendada",
        "X Maldague"
      ],
      "year": "2014",
      "venue": "Pattern Recognition"
    },
    {
      "citation_id": "18",
      "title": "Why Teaching Ethics to AI Practitioners Is Important",
      "authors": [
        "J Goldsmith",
        "E Burton"
      ],
      "year": "2017",
      "venue": "The AAAI-17 workshop on AI, Ethics, and Society"
    },
    {
      "citation_id": "19",
      "title": "Emotion analysis in children through facial emissivity of infrared thermal imaging",
      "authors": [
        "C Goulart",
        "C Valadão",
        "D Delisle-Rodriguez",
        "E Caldeira",
        "T Bastos"
      ],
      "year": "2019",
      "venue": "PloS one"
    },
    {
      "citation_id": "20",
      "title": "Better, nicer, clearer, fairer: A critical assessment of the movement for ethical artificial intelligence and machine learning",
      "authors": [
        "D Greene",
        "A Hoffmann",
        "L Stark"
      ],
      "year": "2019",
      "venue": "Proceedings of the 52nd Hawaii International Conference on System Sciences"
    },
    {
      "citation_id": "21",
      "title": "Scface -surveillance cameras face database",
      "authors": [
        "M Grgic"
      ],
      "venue": "Scface -surveillance cameras face database"
    },
    {
      "citation_id": "22",
      "title": "Emotional suppression: physiology, self-report, and expressive behavior",
      "authors": [
        "J Gross",
        "R Levenson"
      ],
      "year": "1993",
      "venue": "Journal of personality and social psychology"
    },
    {
      "citation_id": "23",
      "title": "Automatic, dimensional and continuous emotion recognition",
      "authors": [
        "H Gunes",
        "M Pantic"
      ],
      "year": "2010",
      "venue": "International Journal of Synthetic Emotions"
    },
    {
      "citation_id": "24",
      "title": "Hot or not? thermal reactions to social contact",
      "authors": [
        "A Hahn",
        "R Whitehead",
        "M Albrecht",
        "C Lefevre",
        "D Perrett"
      ],
      "year": "2012",
      "venue": "Biology letters"
    },
    {
      "citation_id": "25",
      "title": "Deepfake detection challenge",
      "authors": [
        "T Hamdi"
      ],
      "year": "2020",
      "venue": "Deepfake detection challenge"
    },
    {
      "citation_id": "26",
      "title": "Otcbvs benchmark dataset collection",
      "authors": [
        "R Hammoud"
      ],
      "venue": "Otcbvs benchmark dataset collection"
    },
    {
      "citation_id": "27",
      "title": "Fusion of visual and thermal signatures with eyeglass removal for robust face recognition",
      "authors": [
        "J Heo",
        "S Kong",
        "B Abidi",
        "M Abidi"
      ],
      "year": "2004",
      "venue": "2004 Conference on Computer Vision and Pattern Recognition Workshop"
    },
    {
      "citation_id": "28",
      "title": "A comparative study of thermal face recognition methods in unconstrained environments",
      "authors": [
        "G Hermosilla",
        "J Ruiz-Del Solar",
        "R Verschae",
        "M Correa"
      ],
      "year": "2012",
      "venue": "Pattern Recognition"
    },
    {
      "citation_id": "29",
      "title": "The autonomic signature of guilt in children: a thermal infrared imaging study",
      "authors": [
        "S Ioannou",
        "S Ebisch",
        "T Aureli",
        "D Bafunno",
        "H Ioannides",
        "D Cardone",
        "B Manini",
        "G Romani",
        "V Gallese",
        "A Merla"
      ],
      "year": "2013",
      "venue": "PloS one"
    },
    {
      "citation_id": "30",
      "title": "Thermal infrared imaging in psychophysiology: potentialities and limits",
      "authors": [
        "S Ioannou",
        "V Gallese",
        "A Merla"
      ],
      "year": "2014",
      "venue": "Psychophysiology"
    },
    {
      "citation_id": "31",
      "title": "50 years of biometric research: Accomplishments, challenges",
      "year": "2016",
      "venue": "50 years of biometric research: Accomplishments, challenges"
    },
    {
      "citation_id": "32",
      "title": "Thermal analysis of facial muscles contractions",
      "authors": [
        "S Jarlier",
        "D Grandjean",
        "S Delplanque",
        "K N'diaye",
        "I Cayeux",
        "M Velazco",
        "D Sander",
        "P Vuilleumier",
        "K Scherer"
      ],
      "year": "2011",
      "venue": "IEEE transactions on affective computing"
    },
    {
      "citation_id": "33",
      "title": "Automated facial expression classification and affect interpretation using infrared measurement of facial skin temperature variations",
      "authors": [
        "M Khan",
        "M Ingleby",
        "R Ward",
        "J Kleinberg",
        "S Mullainathan",
        "M Raghavan"
      ],
      "year": "2006",
      "venue": "FAT ML Workshop"
    },
    {
      "citation_id": "34",
      "title": "Thermalgan: Multimodal color-to-thermal image translation for person re-identification in multispectral dataset",
      "authors": [
        "V Kniaz",
        "V Knyaz",
        "J Hladuvka",
        "W Kropatsch",
        "V Mizginov"
      ],
      "year": "2018",
      "venue": "ECCV"
    },
    {
      "citation_id": "35",
      "title": "Multiscale fusion of visible and thermal ir images for illumination-invariant face recognition",
      "authors": [
        "S Kong",
        "J Heo",
        "F Boughorbel",
        "Y Zheng",
        "B Abidi",
        "A Koschan",
        "M Yi",
        "M Abidi"
      ],
      "year": "2007",
      "venue": "International Journal of Computer Vision"
    },
    {
      "citation_id": "36",
      "title": "A fully annotated thermal face database and its application for thermal facial expression recognition",
      "authors": [
        "M Kopaczka",
        "R Kolk",
        "D Merhof"
      ],
      "year": "2018",
      "venue": "IEEE International Instrumentation and Measurement Technology Conference"
    },
    {
      "citation_id": "37",
      "title": "Facial thermal variations: A new marker of emotional arousal",
      "authors": [
        "V Kosonogov",
        "L De Zorzi",
        "J Honore",
        "E Martínez-Velázquez",
        "J.-L Nandrino",
        "J Martinez-Selva",
        "H Sequeira"
      ],
      "year": "2017",
      "venue": "PloS one"
    },
    {
      "citation_id": "38",
      "title": "Iit delhi near ir face database version",
      "authors": [
        "A Kumar"
      ],
      "venue": "Iit delhi near ir face database version"
    },
    {
      "citation_id": "39",
      "title": "Emotion and the autonomic nervous system: A prospectus for research on autonomic specificity. Social psychophysiology: Theory and clinical applications",
      "authors": [
        "R Levenson"
      ],
      "year": "1988",
      "venue": "Emotion and the autonomic nervous system: A prospectus for research on autonomic specificity. Social psychophysiology: Theory and clinical applications"
    },
    {
      "citation_id": "40",
      "title": "Deep facial expression recognition: A survey",
      "authors": [
        "S Li",
        "W Deng"
      ],
      "year": "2018",
      "venue": "Deep facial expression recognition: A survey",
      "arxiv": "arXiv:1804.08348"
    },
    {
      "citation_id": "41",
      "title": "Facial recognition is accurate, if you're a white guy",
      "authors": [
        "S Lohr"
      ],
      "year": "2018",
      "venue": "Facial recognition is accurate, if you're a white guy"
    },
    {
      "citation_id": "42",
      "title": "Detecting exercise-induced fatigue using thermal imaging and deep learning",
      "authors": [
        "M Lopez",
        "C Del Blanco",
        "N Garcia"
      ],
      "year": "2017",
      "venue": "2017 Seventh International Conference on Image Processing Theory, Tools and Applications (IPTA)"
    },
    {
      "citation_id": "43",
      "title": "A benchmark database of visible and thermal paired face images across multiple variations",
      "authors": [
        "K Mallat",
        "J.-L Dugelay"
      ],
      "year": "2018",
      "venue": "BIOSIG"
    },
    {
      "citation_id": "44",
      "title": "Cross-spectrum thermal to visible face recognition based on cascaded image synthesis",
      "authors": [
        "K Mallat",
        "N Damer",
        "F Boutros",
        "A Kuijper",
        "J.-L Dugelay"
      ],
      "year": "2019",
      "venue": "International Conference on Biometrics (ICB)"
    },
    {
      "citation_id": "45",
      "title": "Mom feels what her child feels: thermal signatures of vicarious autonomic response while watching children in a stressful situation",
      "authors": [
        "B Manini",
        "D Cardone",
        "S Ebisch",
        "D Bafunno",
        "T Aureli",
        "A Merla"
      ],
      "year": "2013",
      "venue": "Frontiers in human neuroscience"
    },
    {
      "citation_id": "46",
      "title": "What are important ethical implications of using facial recognition technology in health care?",
      "authors": [
        "N Martinez-Martin"
      ],
      "year": "2019",
      "venue": "AMA journal of ethics"
    },
    {
      "citation_id": "47",
      "title": "Amazon won't let police use its facialrecognition tech for one year",
      "authors": [
        "L Matsakis"
      ],
      "year": "2020",
      "venue": "Amazon won't let police use its facialrecognition tech for one year"
    },
    {
      "citation_id": "48",
      "title": "Large-scale observational evidence of cross-cultural differences in facial behavior",
      "authors": [
        "D Mcduff",
        "J Girard",
        "R El Kaliouby"
      ],
      "year": "2017",
      "venue": "Journal of Nonverbal Behavior"
    },
    {
      "citation_id": "49",
      "title": "Emotion detection through functional infrared imaging: preliminary results",
      "authors": [
        "A Merla",
        "L Di Donato",
        "P Rossini",
        "G Romani"
      ],
      "year": "2004",
      "venue": "Biomedizinische Technick"
    },
    {
      "citation_id": "50",
      "title": "Revealing psychophysiology and emotions through thermal infrared imaging",
      "authors": [
        "A Merla"
      ],
      "year": "2014",
      "venue": "PhyCS"
    },
    {
      "citation_id": "51",
      "title": "Emotions in context: A sociodynamic model of emotions",
      "authors": [
        "B Mesquita",
        "M Boiger"
      ],
      "year": "2014",
      "venue": "Emotion Review"
    },
    {
      "citation_id": "52",
      "title": "Model cards for model reporting",
      "authors": [
        "M Mitchell",
        "S Wu",
        "A Zaldivar",
        "P Barnes",
        "L Vasserman",
        "B Hutchinson",
        "E Spitzer",
        "I Raji",
        "T Gebru"
      ],
      "year": "2019",
      "venue": "Proceedings of the conference on fairness, accountability, and transparency"
    },
    {
      "citation_id": "53",
      "title": "Microsoft quietly deletes largest public face recognition data set",
      "authors": [
        "M Murgia"
      ],
      "year": "2019",
      "venue": "Microsoft quietly deletes largest public face recognition data set"
    },
    {
      "citation_id": "54",
      "title": "Body-based gender recognition using images from visible and thermal cameras",
      "authors": [
        "D Nguyen",
        "K Park"
      ],
      "year": "2016",
      "venue": "Sensors"
    },
    {
      "citation_id": "55",
      "title": "A thermal facial emotion database and its analysis",
      "authors": [
        "H Nguyen",
        "K Kotani",
        "F Chen",
        "B Le"
      ],
      "year": "2013",
      "venue": "Pacific-Rim Symposium on Image and Video Technology"
    },
    {
      "citation_id": "56",
      "title": "Classifying affective states using thermal infrared imaging of the human face",
      "authors": [
        "B Nhan",
        "T Chau"
      ],
      "year": "2009",
      "venue": "IEEE Transactions on Biomedical Engineering"
    },
    {
      "citation_id": "57",
      "title": "A comprehensive database for benchmarking imaging systems",
      "authors": [
        "K Panetta",
        "Q Wan",
        "S Agaian",
        "S Rajeev",
        "S Kamath",
        "R Rajendran",
        "S Rao",
        "A Kaszowska",
        "H Taylor",
        "A Samani"
      ],
      "year": "2018",
      "venue": "A comprehensive database for benchmarking imaging systems"
    },
    {
      "citation_id": "58",
      "title": "The imaging issue in an automatic face/disguise detection system",
      "authors": [
        "I Pavlidis",
        "P Symosek"
      ],
      "year": "2000",
      "venue": "Proceedings IEEE Workshop on Computer Vision Beyond the Visible Spectrum: Methods and Applications"
    },
    {
      "citation_id": "59",
      "title": "Interacting with human physiology",
      "authors": [
        "I Pavlidis",
        "J Dowdall",
        "N Sun",
        "C Puri",
        "J Fei",
        "M Garbey"
      ],
      "year": "2007",
      "venue": "Computer Vision and Image Understanding"
    },
    {
      "citation_id": "60",
      "title": "Fast by nature-how stress patterns define human experience and performance in dexterous tasks",
      "authors": [
        "I Pavlidis",
        "P Tsiamyrtzis",
        "D Shastri",
        "A Wesley",
        "Y Zhou",
        "P Lindner",
        "P Buddharaju",
        "R Joseph",
        "A Mandapati",
        "B Dunkin"
      ],
      "year": "2012",
      "venue": "Scientific Reports"
    },
    {
      "citation_id": "61",
      "title": "Sensor-level privacy for thermal cameras",
      "authors": [
        "F Pittaluga",
        "A Zivkovic",
        "S Koppal"
      ],
      "year": "2016",
      "venue": "IEEE International Conference on Computational Photography (ICCP)"
    },
    {
      "citation_id": "62",
      "title": "Stresscam: non-contact measurement of users' emotional states through thermal imaging",
      "authors": [
        "C Puri",
        "L Olson",
        "I Pavlidis",
        "J Levine",
        "J Starren"
      ],
      "year": "2005",
      "venue": "CHI'05 extended abstracts on Human factors in computing systems"
    },
    {
      "citation_id": "63",
      "title": "A step toward quantifying independently reproducible machine learning research",
      "authors": [
        "E Raff"
      ],
      "year": "2019",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "64",
      "title": "Soft biometrics for surveillance: an overview",
      "authors": [
        "D Reid",
        "S Samangooei",
        "C Chen",
        "M Nixon",
        "A Ross"
      ],
      "year": "2013",
      "venue": "Handbook of statistics"
    },
    {
      "citation_id": "65",
      "title": "The mental and subjective skin: Emotion, empathy, feelings and thermography",
      "authors": [
        "E Salazar-López",
        "E Domínguez",
        "V Ramos",
        "J De La Fuente",
        "A Meins",
        "O Iborra",
        "G Gálvez",
        "M Rodríguez-Artacho",
        "E Gómez-Milán"
      ],
      "year": "2015",
      "venue": "The mental and subjective skin: Emotion, empathy, feelings and thermography"
    },
    {
      "citation_id": "66",
      "title": "Face liveness detection using thermal face-cnn with external knowledge",
      "authors": [
        "J Seo",
        "I.-J Chung"
      ],
      "year": "2019",
      "venue": "Symmetry"
    },
    {
      "citation_id": "67",
      "title": "Face recognition using infrared vision",
      "authors": [
        "R Shoja Ghiass"
      ],
      "year": "2014",
      "venue": "Face recognition using infrared vision"
    },
    {
      "citation_id": "68",
      "title": "Improved rgb-dt based face recognition",
      "authors": [
        "M Simón",
        "C Corneanu",
        "K Nasrollahi",
        "O Nikisins",
        "S Escalera",
        "Y Sun",
        "H Li",
        "Z Sun",
        "T Moeslund",
        "M Greitans"
      ],
      "year": "2016",
      "venue": "Iet Biometrics"
    },
    {
      "citation_id": "69",
      "title": "Many facial-recognition systems are biased, says u.s. study",
      "authors": [
        "N Singer",
        "C Metz"
      ],
      "year": "2019",
      "venue": "Many facial-recognition systems are biased, says u.s. study"
    },
    {
      "citation_id": "70",
      "title": "The Authority of \"Fair\" in Machine Learning. In FAT ML Workshop",
      "authors": [
        "M Skirpan",
        "M Gorelick"
      ],
      "year": "2017",
      "venue": "The Authority of \"Fair\" in Machine Learning. In FAT ML Workshop"
    },
    {
      "citation_id": "71",
      "title": "Detecting changes in facial temperature induced by a sudden auditory stimulus based on deep learning-assisted face tracking",
      "authors": [
        "S Sonkusare",
        "D Ahmedt-Aristizabal",
        "M Aburn",
        "V Nguyen",
        "T Pang",
        "S Frydman",
        "S Denman",
        "C Fookes",
        "M Breakspear",
        "C Guo"
      ],
      "year": "2019",
      "venue": "Scientific reports"
    },
    {
      "citation_id": "72",
      "title": "What About Applied Fairness?",
      "authors": [
        "J Sylvester",
        "E Raff"
      ],
      "year": "2018",
      "venue": "Machine Learning: The Debates (ML-D) organized as part of the Federated AI Meeting"
    },
    {
      "citation_id": "73",
      "title": "Facial expression analysis. In Handbook of face recognition",
      "authors": [
        "Y.-L Tian",
        "T Kanade",
        "J Cohn"
      ],
      "year": "2005",
      "venue": "Facial expression analysis. In Handbook of face recognition"
    },
    {
      "citation_id": "74",
      "title": "Digital technology and covid-19",
      "authors": [
        "D Ting",
        "L Carin",
        "V Dzau",
        "T Wong"
      ],
      "year": "2020",
      "venue": "Nature medicine"
    },
    {
      "citation_id": "75",
      "title": "Automatic feature localization in thermal images for facial expression recognition",
      "authors": [
        "L Trujillo",
        "G Olague",
        "R Hammoud",
        "B Hernandez"
      ],
      "year": "2005",
      "venue": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)-Workshops"
    },
    {
      "citation_id": "76",
      "title": "rise and regulation of thermal facial recognition technology during the covid-19 pandemic",
      "authors": [
        "M Van Natta",
        "P Chen",
        "S Herbek",
        "R Jain",
        "N Kastelic",
        "E Katz",
        "M Struble",
        "V Vanam",
        "N Vattikonda"
      ],
      "year": "2020",
      "venue": "rise and regulation of thermal facial recognition technology during the covid-19 pandemic"
    },
    {
      "citation_id": "77",
      "title": "A natural visible and infrared facial expression database for expression recognition and emotion inference",
      "authors": [
        "S Wang",
        "Z Liu",
        "S Lv",
        "Y Lv",
        "G Wu",
        "P Peng",
        "F Chen",
        "X Wang"
      ],
      "year": "2010",
      "venue": "IEEE Transactions on Multimedia"
    },
    {
      "citation_id": "78",
      "title": "Emotion recognition from thermal infrared images using deep boltzmann machine",
      "authors": [
        "S Wang",
        "M He",
        "Z Gao",
        "S He",
        "Q Ji"
      ],
      "year": "2014",
      "venue": "Frontiers of Computer Science"
    },
    {
      "citation_id": "79",
      "title": "Fusion of visible and thermal images for facial expression recognition",
      "authors": [
        "S Wang",
        "S He",
        "Y Wu",
        "M He",
        "Q Ji"
      ],
      "year": "2014",
      "venue": "Frontiers of Computer Science"
    },
    {
      "citation_id": "80",
      "title": "Comparison of visible and infra-red imagery for face recognition",
      "authors": [
        "J Wilder",
        "P Phillips",
        "C Jiang",
        "S Wiener"
      ],
      "year": "1996",
      "venue": "Proceedings of the Second International Conference on Automatic Face and Gesture Recognition"
    },
    {
      "citation_id": "81",
      "title": "Casme ii: An improved spontaneous micro-expression database and the baseline evaluation",
      "authors": [
        "W.-J Yan",
        "X Li",
        "S.-J Wang",
        "G Zhao",
        "Y.-J Liu",
        "Y.-H Chen",
        "X Fu"
      ],
      "year": "2014",
      "venue": "PloS one"
    },
    {
      "citation_id": "82",
      "title": "Effect of sensor fusion for recognition of emotional states using voice, face image and thermal image of face",
      "authors": [
        "Y Yoshitomi",
        "S.-I Kim",
        "T Kawano",
        "T Kilazoe"
      ],
      "year": "2000",
      "venue": "Proceedings 9th IEEE International Workshop on Robot and Human Interactive Communication. IEEE RO-MAN 2000"
    },
    {
      "citation_id": "83",
      "title": "Directional binary code with application to polyu near-infrared face database",
      "authors": [
        "B Zhang",
        "L Zhang",
        "D Zhang",
        "L Shen"
      ],
      "year": "2010",
      "venue": "Pattern Recognition Letters"
    },
    {
      "citation_id": "84",
      "title": "Tv-gan: Generative adversarial network based thermal to visible face recognition",
      "authors": [
        "T Zhang",
        "A Wiliem",
        "S Yang",
        "B Lovell"
      ],
      "year": "2018",
      "venue": "ICB"
    },
    {
      "citation_id": "85",
      "title": "Forehead thermal signature extraction in lie detection",
      "authors": [
        "Z Zhu",
        "P Tsiamyrtzis",
        "I Pavlidis"
      ],
      "year": "2007",
      "venue": "2007 29th Annual International Conference of the IEEE Engineering in Medicine and Biology Society"
    }
  ]
}