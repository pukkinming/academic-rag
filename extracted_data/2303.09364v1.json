{
  "paper_id": "2303.09364v1",
  "title": "Tollywood Emotions: Annotation Of Valence-Arousal In Telugu Song Lyrics",
  "published": "2023-03-16T14:47:52Z",
  "authors": [
    "R Guru Ravi Shanker",
    "B Manikanta Gupta",
    "BV Koushik",
    "Vinoo Alluri"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Emotion recognition from a given music track has heavily relied on acoustic features, social tags, and metadata but is seldom focused on lyrics. There are no datasets of Indian language songs that contain both valence and arousal manual ratings of lyrics. We present a new manually annotated dataset of Telugu songs' lyrics collected from Spotify with valence and arousal annotated on a discrete scale. A fairly high inter-annotator agreement was observed for both valence and arousal. Subsequently, we create two music emotion recognition models by using two classification techniques to identify valence, arousal and respective emotion quadrant from lyrics. Support vector machine (SVM) with term frequency-inverse document frequency (TF-IDF) features and fine-tuning the pretrained XLMRoBERTa (XLM-R) model were used for valence, arousal and quadrant classification tasks. Fine-tuned XLMRoBERTa performs better than the SVM by improving macro-averaged F1-scores of 54.69%, 67.61%, 34.13% to 77.90%, 80.71% and 58.33% for valence, arousal and quadrant classifications, respectively, on 10-fold cross-validation. In addition, we compare our lyrics annotations with Spotify's annotations of valence and energy (same as arousal), which are based on entire music tracks. The implications of our findings are discussed. Finally, we make the dataset publicly available with lyrics, annotations and Spotify IDs.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Sentiment analysis deals with identifying affective connotations of text. Typically, humans annotate a corpus, following which a model is trained to classify new samples  (Pang et al., 2002; Apoorva and Mamidi, 2017) . Most studies involve a categorical approach in which text is classified as either positive or negative in valence or arousal. Valence refers to pleasantness, while arousal refers to en-ergy. One of the most widely used emotion models is Russell's circumplex Valence-Arousal (VA) model of affect  (Russell, 1980)  and has been specifically used in tasks involving automatic emotion recognition  (Çano and Morisio, 2017; Malheiro et al., 2016) . Furthermore, it has been demonstrated that this model offers to distribute emotions in a 360-degree, four-quadrant VA space.\n\nLyrics play an integral role in evoking emotions and contribute to musical enjoyment. However, they are often neglected in tasks involving music emotion recognition  (Eerola et al., 2009; Patra et al., 2013) . There have been lyrics datasets using a dimensional approach containing both valence and arousal values in English  (Çano and Morisio, 2017; Malheiro et al., 2016) . However, the very few that exist in Indian languages have limited annotations to either valence or arousal but not both. For example, BolLy is a Hindi dataset annotated for valence  (Apoorva and Mamidi, 2017) , similar datasets exists for Manipuri (Devi and Saharia, 2020), Bengali  (Nath et al., 2020), Telugu (Gangula and Mamidi, 2018)  while another study has annotated Telugu lyrics for arousal  (Reddy and Mamidi, 2018) . Also, most lyrics datasets in Indian languages are not publicly available  (Devi and Saharia, 2020; Apoorva and Mamidi, 2017; Patra et al., 2015) . We need both valence and arousal dimensions to capture the entire gamut of emotions.\n\nTelugu is a morphologically rich language which makes automatic emotion identification difficult in contrast to languages poor in morphology, such as English. In our study, we create a manually annotated lyrics dataset in Telugu, which contains average valence and arousal perceptual ratings. Further, to identify valence, arousal, and quadrant from lyrics, we employ two methods, Support Vector Machine (SVM)  (Cortes and Vapnik, 1995)  with TF-IDF  (Robertson, 2004)  features and fine-tuning pre-trained XLM-RoBERTa (XLM-R)  (Conneau et al., 2019)  model for emotion recognition on the arXiv:2303.09364v1 [cs.CL] 16 Mar 2023 dataset. They have been extensively used for text classification, including emotion recognition. SVM is a supervised learning algorithm that projects the input to a higher dimensional plane and finds hyperplanes to differentiate two or more classes. XLM-R is a multilingual pre-trained model for many South Asian languages, including Telugu, and Hindi, amongst others. It uses RoBERTa  (Liu et al., 2019)  transformer architecture as its base for pre-training, which improves BERT  (Devlin et al., 2018)  by training on longer sequences and more data. It performs very well on downstream natural language processing(NLP) tasks like sentiment analysis and other natural language inference (NLI) tasks. It is also competitive with strong monolingual models on NLI tasks. It also helps to deal with codemix text  (Ou and Li, 2020) .\n\nRecently there have been studies  (Liew et al., 2021; Lee et al., 2021)  that use Spotify features to find cultural differences. Since lyrics' emotions are mostly congruent with music emotions, we aim to verify congruence between the lyrical perceptual emotion values and Spotify-retrieved emotion values. This has implications in using Spotify features for music emotion recognition, especially in the context of culturally diverse music. We release the Telugu lyrics dataset with average valence and arousal values along with Spotify IDs 1 .",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Related Work",
      "text": "Before the availability of large text collection and online resources, sentiment analysis was based only on surveys and public opinions  (Knutson, 1945) . Now, there are annotated corpora for sentiment analysis in English  (Maas et al., 2011)  as well as in other Indian languages such as Telugu (Gangula and Mamidi, 2018), Hindi  (Shrivastava and Kumar, 2020)  amongst others. Mostly the task has been done on short context texts like tweets  (Agarwal et al., 2011) , and reviews (Gangula and Mamidi, 2018) compared to long context text like poems and lyrics. Both categorical and dimensional approaches for emotion recognition are widely accepted for lyrics. MER  (Malheiro et al., 2016)  dataset contains 180 English songs with manually annotated valence and arousal discrete values from -4 to 4. The existing datasets present in the Indian language's lyrics are limited to either valence or arousal categories.\n\nThe task of emotion recognition has evolved 1 https://developer.spotify.com/documentation/web-api/ from using simple lexicon-based methods  (Ohana and Tierney, 2009)  to using transformer models  (Agrawal et al., 2021) . Numerous studies use NLP techniques like bag-of-words (El-Din, 2016), TF-IDF features (Apoorva and Mamidi, 2017), word vectors  (Nath et al., 2020) , and models like convolutional neural network  (Nath et al., 2020) , recurrent neural networks (RNN)  (Abdillah et al., 2020)  for sentiment analysis. Recently, fine-tuned transformer XLNet model performed better than RNN-based techniques  (Agrawal et al., 2021)  for lyrics emotion recognition task because of its ability to capture longer contexts. Hence, we also compare the performance of context-free (SVM with TF-IDF) and context-based (fine-tuning pre-trained XLM-R) on the dataset. Spotify features based on music tracks like valence, energy, danceability, and instrumentalness, amongst others, have been popularly used in many studies  (Surana et al., 2020; Lee et al., 2021)  for various tasks such as analyses on music listening habits on streaming platforms and exploring differences in mood perception, respectively. However, several studies have evidenced culture-specific differences in emotion perception, and to music,  (Lee et al., 2021; Saarikallio et al., 2021) . Although valence and energy features from Spotify rely on the entire music track and not just lyrics alone, owing to the typical congruence between emotions conveyed by lyrics and musical features, one can expect a moderately high correlation between Spotify features and annotated features. Hence we additionally compare manual annotations of our dataset with Spotify's features.\n\n3 The Dataset",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Construction Of The Dataset",
      "text": "For the construction of the lyrics dataset, we chose Tollywood (Telugu film industry) songs from playlists that were available on Spotify. Telugu songs are generally positive, as noted by (Reddy and Mamidi, 2018) and hence we initially observed around 70% of the songs annotated were positive on valence and high on arousal. To balance the number of songs in each quadrant, we chose songs from 9 diverse playlists, such as \"Happy Vibes Telugu\", \"Sad Melodies Telugu\", \"Sleepy Telugu\", and \"Angry Telugu\", amongst others.\n\nLyrics were scraped manually in their original script from Spotify, if available. For those not available, alternative websites such as LyricsTape 2 , Lyrics Telugu 3 amongst others, were used for scraping the lyrics. Each track has an associated unique Spotify ID, based on which we removed 19 duplicates. Finally, a total of 481 song lyrics with their Spotify IDs were scraped.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Annotation",
      "text": "We use Russell's circumplex model for annotating the lyrics based on valence and arousal. Three annotators, native Telugu speakers, annotated the lyrics of each song for valence and arousal on a discrete five-point scale ranging from -2 to 2. The annotations were solely based on lyrics without listening to the song's audio.\n\nTo check the reliability and internal consistency of the dataset, we calculated Krippendorff's alpha  (Krippendorff, 2011)  for ordinal data. As a result, acceptable alphas of 0.716 and 0.782 were obtained for valence and arousal, respectively, implying fair agreement among the annotators.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Dataset Release Information",
      "text": "The dataset has been made publicly available at https://tinyurl.com/mu2zkjtc. It contains average valence and arousal values for 481 Telugu songs, as shown in Figure  1 . We also provide Spotify ID for each song which helps extract music-related features from Spotify for further analysis.\n\nOut of the 481 songs, 325 lyrics were perceived as positive valence and 156 as negative valence. Similarly, 271 and 210 lyrics were positive and negative arousal lyrics, respectively. We achieved a final quadrant split, as shown in Figure  2 . In order to create automatic music emotion recognition models based on our annotated dataset, we use two supervised machine learning approaches, that is, context-based and context-free classification.\n\nTo this end, we perform three classification tasks, namely valence classification (VC), arousal classification (AC) and quadrant classification (QC).\n\nThough our dataset has average valence and arousal annotations on a continuous scale, we chose to perform classification instead of regression owing to the bimodal distribution of the ratings (See Figure  1 ). VC involves the prediction of whether the valence is positive or negative for a given track's lyrics. Similarly, AC predicts whether the arousal is high or low. QC involves predicting the quadrant the lyrics belong to.\n\nFor the SVM-based (context-free) classifications, we use the popularly employed TF-IDF features to represent lyrics to give as input to SVM for the classification task. SVM with linear kernel and TF-IDF have been implemented using 'scikit-learn'  (Pedregosa et al., 2011)  library with default values. This is an elementary context-free method with basic features of TF-IDF for text classification.\n\nFor fine-tuned XLM-R model (context-based), we use the pre-trained(xlm-roberta-base) for Sequence Classification task from the Hugging face 4  library to fine-tune our dataset. We use a learning rate of 2e-6 for VC and AC, and 4e-6 for QC with AdamW optimizer  (Loshchilov and Hutter, 2017) . We also use the default max sequence length of 512 and a batch size of 8 for our implementation. We perform 10-fold cross-validation on our dataset and report the average accuracy (also known as the micro-averaged F1-score) and macro-averaged F1-score (F1). The macro-averaged F1-score (F 1 ) is given by the formula 1.\n\nP x , R x and F 1 x are the standard precision, recall and F1-score of a particular class x, and n is the total number of classes.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Spotify Features",
      "text": "Spotify provides valence and arousal for each track in addition to several other features like danceability, and instrumentalness, amongst others. Spotify doesn't provide the algorithm used to calculate its features but is based on musical tracks in their entirety. The valence and arousal values from Spotify are continuous and lie in the range of 0 to 1. Tracks with a valence or arousal greater than 0.5 are considered to be positive or high, and less than 0.5 are considered to be negative or low, respectively.\n\nTo examine the association between the average annotated VA values, and Spotify's VA values, we performed Spearman's correlation. In order to get quadrant-specific insights, we also perform Spearman's correlation between the same quadrant-wise.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Results",
      "text": "",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Classification",
      "text": "As expected, we observe a far superior performance of the context-based fine-tuning XLM-R model compared to the context-free SVM with TF-IDF, as shown in Table  1 . Nearly ten percentage of song lyrics contain few verses in English or Hindi. This is due to the changing trends of Indian songs in which lyrics are code mixed with other languages. This may explain the better performance of finetuned XLM-R (Ou and Li, 2020) compared to SVM with TF-IDF features.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Spotify Analysis",
      "text": "We observe a small yet significant correlation (r = 0.167, p < 0.01) between annotated and Spotifyretrieved valence and a moderate positive correlation (r = 0.533, p < 0.01) between annotated arousal and Spotify-retrieved arousal. Quadrant-wise correlation analyses revealed significant positive correlations for high arousal quadrants Q1 (r = 0.475, p < 0.01) and Q2 (r = 0.269, p < 0.05) with Spotifyretrieved arousal. For Q4 lyrics, valence annotations correlated (r = 0.225, p < 0.05) positively with Spotify-retrieved valence.\n\nThough we are comparing lyrics annotations with music annotations, the agreement value is less than expected. From Figure  3 , we can observe the difference in the classification of quadrants based on Spotify-retrieved values and annotated values. One possible explanation for low agreement between Spotify and human annotations for Telugu songs is the difference in the mapping of musical features, which could be attributed to cultural differences.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Conclusion And Future Work",
      "text": "In this study, for the first time, we created a dataset of Telugu song lyrics manually annotated for both valence and arousal. In addition, we also provide Spotify IDs. The differences between annotated VA ratings and Spotify VA values highlight the need to build cultural-specific models for better song recommendations, especially since there has been a staggering increase of Indian users on Spotify (ETI). Furthermore, this dataset can be used to train models to predict emotions from Telugu text, especially lyrics. Further improvements can be made to balance the dataset across quadrants. This study can be extended to other South Asian language songs for training a multilingual lyrics emotion prediction model.",
      "page_start": 6,
      "page_end": 6
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Histogram of Annotated Values",
      "page": 3
    },
    {
      "caption": "Figure 1: We also pro-",
      "page": 3
    },
    {
      "caption": "Figure 2: 2https://www.lyricstape.com/",
      "page": 3
    },
    {
      "caption": "Figure 2: Song distribution in VA plane",
      "page": 3
    },
    {
      "caption": "Figure 3: Distribution of Spotify-retrieved VA values",
      "page": 4
    },
    {
      "caption": "Figure 3: , we can observe the",
      "page": 4
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Method": "SVM",
          "Accuracy": "69.43%",
          "F1": "54.69%"
        },
        {
          "Method": "XLM-R",
          "Accuracy": "80.88%",
          "F1": "77.90%"
        },
        {
          "Method": "SVM",
          "Accuracy": "68.60%",
          "F1": "67.61%"
        },
        {
          "Method": "XLM-R",
          "Accuracy": "81.51%",
          "F1": "80.71%"
        },
        {
          "Method": "SVM",
          "Accuracy": "48.63%",
          "F1": "34.13%"
        },
        {
          "Method": "XLM-R",
          "Accuracy": "62.58%",
          "F1": "58.33%"
        }
      ],
      "page": 4
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "India among Spotify's top engagement markets: Gustav Gyllenhammar,VP",
      "venue": "India among Spotify's top engagement markets: Gustav Gyllenhammar,VP"
    },
    {
      "citation_id": "2",
      "title": "Emotion classification of song lyrics using bidirectional lstm method with glove word representation weighting",
      "authors": [
        "Jiddy Abdillah",
        "Ibnu Asror",
        "Yanuar Firdaus",
        "Arie Wibowo"
      ],
      "year": "2020",
      "venue": "Jurnal RESTI (Rekayasa Sistem Dan Teknologi Informasi)"
    },
    {
      "citation_id": "3",
      "title": "Sentiment analysis of twitter data",
      "authors": [
        "Apoorv Agarwal",
        "Boyi Xie",
        "Ilia Vovsha",
        "Owen Rambow",
        "Rebecca Passonneau"
      ],
      "year": "2011",
      "venue": "Proceedings of the workshop on language in social media (LSM 2011)"
    },
    {
      "citation_id": "4",
      "title": "Transformer-based approach towards music emotion recognition from lyrics",
      "authors": [
        "Yudhik Agrawal",
        "Ramaguru Guru",
        "Ravi Shanker",
        "Vinoo Alluri"
      ],
      "year": "2021",
      "venue": "European Conference on Information Retrieval"
    },
    {
      "citation_id": "5",
      "title": "Bolly: Annotation of sentiment polarity in bollywood lyrics dataset",
      "authors": [
        "Apoorva Drushti",
        "Radhika Mamidi"
      ],
      "year": "2017",
      "venue": "International conference of the pacific association for computational linguistics"
    },
    {
      "citation_id": "6",
      "title": "Moodylyrics: A sentiment annotated lyrics dataset",
      "year": "2017",
      "venue": "Proceedings of the 2017 International Conference on Intelligent Systems, Metaheuristics & Swarm Intelligence"
    },
    {
      "citation_id": "7",
      "title": "Unsupervised cross-lingual representation learning at scale",
      "authors": [
        "Alexis Conneau",
        "Kartikay Khandelwal",
        "Naman Goyal",
        "Vishrav Chaudhary",
        "Guillaume Wenzek",
        "Francisco Guzmán",
        "Edouard Grave",
        "Myle Ott",
        "Luke Zettlemoyer",
        "Veselin Stoyanov"
      ],
      "year": "2019",
      "venue": "Unsupervised cross-lingual representation learning at scale",
      "arxiv": "arXiv:1911.02116"
    },
    {
      "citation_id": "8",
      "title": "Supportvector networks",
      "authors": [
        "Corinna Cortes",
        "Vladimir Vapnik"
      ],
      "year": "1995",
      "venue": "Machine learning"
    },
    {
      "citation_id": "9",
      "title": "Exploiting topic modelling to classify sentiment from lyrics",
      "authors": [
        "Maibam Debina",
        "Navanath Saharia"
      ],
      "year": "2020",
      "venue": "International Conference on Machine Learning, Image Processing, Network Security and Data Sciences"
    },
    {
      "citation_id": "10",
      "title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "authors": [
        "Jacob Devlin",
        "Ming-Wei Chang",
        "Kenton Lee",
        "Kristina Toutanova"
      ],
      "year": "2018",
      "venue": "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "arxiv": "arXiv:1810.04805"
    },
    {
      "citation_id": "11",
      "title": "Prediction of multidimensional emotional ratings in music from audio using multivariate regression models",
      "authors": [
        "Tuomas Eerola",
        "Olivier Lartillot",
        "Petri Toiviainen"
      ],
      "year": "2009",
      "venue": "Ismir"
    },
    {
      "citation_id": "12",
      "title": "Enhancement bag-ofwords model for solving the challenges of sentiment analysis",
      "year": "2016",
      "venue": "International Journal of Advanced Computer Science and Applications"
    },
    {
      "citation_id": "13",
      "title": "Resource creation towards automated sentiment analysis in telugu (a low resource language) and integrating multiple domain sources to enhance sentiment prediction",
      "authors": [
        "Rama Rohit",
        "Reddy Gangula",
        "Radhika Mamidi"
      ],
      "year": "2018",
      "venue": "Proceedings of the eleventh international conference on language resources and evaluation"
    },
    {
      "citation_id": "14",
      "title": "Japanese opinion surveys: the special need and the special difficulties",
      "authors": [
        "Andie Knutson"
      ],
      "year": "1945",
      "venue": "Public Opinion Quarterly"
    },
    {
      "citation_id": "15",
      "title": "Computing krippendorff's alpha-reliability",
      "authors": [
        "Klaus Krippendorff"
      ],
      "year": "2011",
      "venue": "Computing krippendorff's alpha-reliability"
    },
    {
      "citation_id": "16",
      "title": "Cross-cultural mood perception in pop songs and its alignment with mood detection algorithms",
      "authors": [
        "Harin Lee",
        "Frank Hoeger",
        "Marc Schoenwiesner",
        "Minsu Park",
        "Nori Jacoby"
      ],
      "year": "2021",
      "venue": "Cross-cultural mood perception in pop songs and its alignment with mood detection algorithms",
      "arxiv": "arXiv:2108.00768"
    },
    {
      "citation_id": "17",
      "title": "Cultural differences in music features across taiwanese, japanese and american markets",
      "authors": [
        "Kongmeng Liew",
        "Yukiko Uchida",
        "Igor De Almeida"
      ],
      "year": "2021",
      "venue": "PeerJ Computer Science"
    },
    {
      "citation_id": "18",
      "title": "Roberta: A robustly optimized bert pretraining approach",
      "authors": [
        "Yinhan Liu",
        "Myle Ott",
        "Naman Goyal",
        "Jingfei Du",
        "Mandar Joshi",
        "Danqi Chen",
        "Omer Levy",
        "Mike Lewis",
        "Luke Zettlemoyer",
        "Veselin Stoyanov"
      ],
      "year": "2019",
      "venue": "Roberta: A robustly optimized bert pretraining approach",
      "arxiv": "arXiv:1907.11692"
    },
    {
      "citation_id": "19",
      "title": "Decoupled weight decay regularization",
      "authors": [
        "Ilya Loshchilov",
        "Frank Hutter"
      ],
      "year": "2017",
      "venue": "Decoupled weight decay regularization",
      "arxiv": "arXiv:1711.05101"
    },
    {
      "citation_id": "20",
      "title": "Learning word vectors for sentiment analysis",
      "authors": [
        "Andrew Maas",
        "Raymond Daly",
        "Peter Pham",
        "Dan Huang",
        "Andrew Ng",
        "Christopher Potts"
      ],
      "year": "2011",
      "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies"
    },
    {
      "citation_id": "21",
      "title": "Emotionally-relevant features for classification and regression of music lyrics",
      "authors": [
        "Ricardo Malheiro",
        "Renato Panda",
        "Paulo Gomes",
        "Rui Pedro"
      ],
      "year": "2016",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "22",
      "title": "Textual lyrics based emotion analysis of bengali songs",
      "authors": [
        "Devjyoti Nath",
        "Anirban Roy",
        "Kumari Sumitra",
        "Amlan Shaw",
        "Shanta Ghorai",
        "Phani"
      ],
      "year": "2020",
      "venue": "2020 International Conference on Data Mining Workshops (ICDMW)"
    },
    {
      "citation_id": "23",
      "title": "Sentiment classification of reviews using sentiwordnet",
      "authors": [
        "Bruno Ohana",
        "Brendan Tierney"
      ],
      "year": "2009",
      "venue": "Proceedings of IT&T"
    },
    {
      "citation_id": "24",
      "title": "Ynu@ dravidiancodemix-fire2020: Xlm-roberta for multi-language sentiment analysis",
      "authors": [
        "Xiaozhi Ou",
        "Hongling Li"
      ],
      "year": "2020",
      "venue": "FIRE (Working Notes)"
    },
    {
      "citation_id": "25",
      "title": "Thumbs up? sentiment classification using machine learning techniques",
      "authors": [
        "Bo Pang",
        "Lillian Lee",
        "Shivakumar Vaithyanathan"
      ],
      "year": "2002",
      "venue": "Thumbs up? sentiment classification using machine learning techniques"
    },
    {
      "citation_id": "26",
      "title": "Automatic music mood classification of hindi songs",
      "authors": [
        "Gopal Braja",
        "Dipankar Patra",
        "Sivaji Das",
        "Bandyopadhyay"
      ],
      "year": "2013",
      "venue": "Proceedings of the 3rd Workshop on Sentiment Analysis where AI meets Psychology"
    },
    {
      "citation_id": "27",
      "title": "Mood classification of hindi songs based on lyrics",
      "authors": [
        "Gopal Braja",
        "Dipankar Patra",
        "Sivaji Das",
        "Bandyopadhyay"
      ],
      "year": "2015",
      "venue": "Proceedings of the 12th international conference on natural language processing"
    },
    {
      "citation_id": "28",
      "title": "Scikit-learn: Machine learning in python",
      "authors": [
        "Fabian Pedregosa",
        "Gaël Varoquaux",
        "Alexandre Gramfort",
        "Vincent Michel",
        "Bertrand Thirion",
        "Olivier Grisel",
        "Mathieu Blondel",
        "Peter Prettenhofer",
        "Ron Weiss",
        "Vincent Dubourg"
      ],
      "year": "2011",
      "venue": "Journal of machine Learning research"
    },
    {
      "citation_id": "29",
      "title": "Addition of code mixed features to enhance the sentiment prediction of song lyrics",
      "year": "2018",
      "venue": "Addition of code mixed features to enhance the sentiment prediction of song lyrics",
      "arxiv": "arXiv:1806.03821"
    },
    {
      "citation_id": "30",
      "title": "Understanding inverse document frequency: on theoretical arguments for idf",
      "authors": [
        "Stephen Robertson"
      ],
      "year": "2004",
      "venue": "Journal of documentation"
    },
    {
      "citation_id": "31",
      "title": "A circumplex model of affect",
      "authors": [
        "Russell James"
      ],
      "year": "1980",
      "venue": "Journal of personality and social psychology"
    },
    {
      "citation_id": "32",
      "title": "Emotions of music listening in finland and in india: comparison of an individualistic and a collectivistic culture",
      "authors": [
        "Suvi Saarikallio",
        "Vinoo Alluri",
        "Johanna Maksimainen",
        "Petri Toiviainen"
      ],
      "year": "2021",
      "venue": "Psychology of Music"
    },
    {
      "citation_id": "33",
      "title": "A sentiment analysis system for the hindi language by integrating gated recurrent unit with genetic algorithm",
      "authors": [
        "Kush Shrivastava",
        "Shishir Kumar"
      ],
      "year": "2020",
      "venue": "Int. Arab J. Inf. Technol"
    },
    {
      "citation_id": "34",
      "title": "Static and dynamic measures of active music listening as indicators of depression risk",
      "authors": [
        "Aayush Surana",
        "Yash Goyal",
        "Vinoo Alluri"
      ],
      "year": "2020",
      "venue": "Static and dynamic measures of active music listening as indicators of depression risk",
      "arxiv": "arXiv:2009.13685"
    }
  ]
}