{
  "paper_id": "2203.02635v2",
  "title": "Training Privacy-Preserving Video Analytics Pipelines By Suppressing Features That Reveal Information About Private Attributes",
  "published": "2022-03-05T01:31:07Z",
  "authors": [
    "Chau Yi Li",
    "Andrea Cavallaro"
  ],
  "keywords": [
    "feature learning",
    "video analytics",
    "privacy",
    "private attributes"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Deep neural networks are increasingly deployed for scene analytics, including to evaluate the attention and reaction of people exposed to out-of-home advertisements. However, the features extracted by a deep neural network that was trained to predict a specific, consensual attribute (e.g. emotion) may also encode and thus reveal information about private, protected attributes (e.g. age or gender). In this work, we focus on such leakage of private information at inference time. We consider an adversary with access to the features extracted by the layers of a deployed neural network and use these features to predict private attributes. To prevent the success of such an attack, we modify the training of the network using a confusion loss that encourages the extraction of features that make it difficult for the adversary to accurately predict private attributes. We validate this training approach on image-based tasks using a publicly available dataset. Results show that, compared to the original network, the proposed PrivateNet can reduce the leakage of private information of a state-ofthe-art emotion recognition classifier by 2.88% for gender and by 13.06% for age group, with a minimal effect on task accuracy.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Deep neural network classifiers are used to understand the reactions of audiences to advertisements in public spaces and during interactions with wayfinding kiosks. Such reactions are typically measured using computer vision by first detecting faces and then analysing attributes associated with facial expressions. However, neural networks trained to extract features that predict a task-specific, consensual attribute (the target task), may also encode information about private attributes  [1] , such as gender and age  [2] . An adversary with access to the information extracted by the layers of a deep neural network can therefore use the pipeline for purposes different from the consensual ones.\n\nAn adversary may perpetrate a membership or attribute inference attack. Privacy-preserving methods to protect from membership inference attacks focus on preventing the identi-fication of individuals whose data were included in a training dataset  [3] [4] [5] [6]  or are ingested by a deployed system. Methods that protect from attribute inference attacks aim to prevent the prediction of (private) attributes from a training dataset  [6]  or from a classification pipeline deployed on a system, such as a smart kiosk. The latter scenario is the scope of our work: we consider a system whose untrusted rich execution environment is compromised by malware, but is equipped with security measures that ensure confidentiality and integrity of the visual data (e.g. a limited-memory, isolated Trusted Execution Environment, or TEE). The memory limitation of a TEE can only host a few of the last layers of a feed-forward network, typically the layers after the backbone structure or only the fully-connected layer  [7] . We consider the adversary to have access to the untrusted execution environment of the system and thus in a position to exploit the features extracted by these intermediate layers to infer private information  [8] . Existing works that aim to prevent attribute inference attacks modify the input data with adversarial perturbations  [9]  or train the network to cause mis-classification of private attributes, for instance using the cross-entropy loss  [10] .\n\nIn this work, we aim to prevent the estimation of private information at inference time by training the network to extract features that are useful for the target task only and that cause a known adversary classifier to perform similarly to a random classifier on a protected attribute. To conceal the private information from the adversary classifier, we train the pipeline with a confusion loss. The proposed approach does not modify the network architecture or the number of its parameters, and hence has no latency impact on the inference pipeline. In the specific implementation reported in this paper, we consider visual emotion recognition as the target task, and age and gender as protected attributes  1  . We also investigate the robustness of the proposed approach by training an adversary to classify the private information from the privacypreserving network.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Method",
      "text": "Let C(‚Ä¢) be a D-class deep neural network classifier of N layers that, given an image x, predicts its consensual class as one in the set:\n\nLet F i (x) be the output of layer i of C(‚Ä¢), with i ‚àà {1, ..., N }.\n\nThe output of the last layer N is a vector that represents the confidence of C that x belongs to any of the classes:\n\nLet A(‚Ä¢) be an adversary K-class classifier that aims to predict a protected, private class from the output, F i (x), of an intermediate layer as one in the set:\n\nLet M be the number of layers in A(‚Ä¢). The output of the last layer M is a vector representing the confidence of A(‚Ä¢) that F i (x) belongs to any of the (private) classes:\n\nLet X be a set of face images, each annotated with an emotion (target) attribute, ≈∑, and a private attribute, ≈ù. We measure the leakage of private information as the accuracy, T ≈ù, of the private attribute inference from X :\n\nwhere | ‚Ä¢ | is the cardinality of a set. The higher T ≈ù, the higher the leakage of private information through C(‚Ä¢).\n\nA classifier C(‚Ä¢) that is privacy-preserving should maintain a high accuracy in the prediction of the consensual task, while concealing the private attributes from the adversary classifier A(‚Ä¢), i.e. T ≈ù should be close to a random classifier.\n\nTo predict the consensual class, the classifier C(‚Ä¢) is typically trained with a cross-entropy loss:\n\nwhere exp(‚Ä¢) is the exponential function.\n\nTo prevent the leakage of private information associated with a protected attribute, we propose to obfuscate with a confusion loss, L con , the features in the intermediate layers that are useful to the adversary:\n\nwhere Fig.  1 . Architecture of the ARM network  [11]  used as the emotion recognition classifier. Given an image x, the network outputs the probability p y i , i ‚àà {1, .., 7}, of each emotion class (Eq. 2). An adversary could infer private, protected attributes from the features extracted by the intermediate layers of the network (red dashed arrows). Coloured blocks represent layers with trainable parameters. the layers preceding it, backpropagating the confusion loss through the entire network optimizes the layers preceding the targeted layer to extract generic features that cause the adversary to perform similarly to a random classifier on the protected attribute. Thus, in training we encourage the deep neural network to extract privacy-preserving features by combining Eq. 6 and 7 as the overall loss function, L:\n\nwhere Œª determines the relative importance between the losses: Œª < 0.5 gives more importance to maintaining the utility and Œª > 0.5 gives more importance to confusing the adversary.\n\nWe use as dataset the Real-world Affective Faces Database (RAF-DB)  [12] , which contains 15,338 images. Each image was annotated, on average, by 40 annotators into D = 7 emotion attributes (surprise, fear, disgust, happiness, sadness, anger, and neutral) and demographics including race, gender and age group. Specifically, we focus on gender (K = 2, male and female)  2  and age group (K = 5, namely 0-3, 4-19, 20-39, 40-69, and over 70). As for the emotion classifier C(‚Ä¢), we use the Amend Representation Module network proposed by Shi and Zhou  [11] . On RAF-DB, the ARM network attains a state-of-the-art emotion recognition accuracy of 91.10%. The ARM network aims to remove the distortion from the edges of the image on the features, referred to as albino erosion. The ARM network consists of a ResNet-18  [13]  backbone, an Amend Representation Module (ARM), and a fully connected layer. The output of the ResNet-18 backbone is a feature map of size 7 √ó 7 and 512 channels. An ARM consists of 3 blocks, namely a feature Table  1 . The leakage of private information is measured as the accuracy of an adversary classifier that infers private attributes from the features extracted from the ARM network  [11] , trained for emotion recognition. Note that the accuracy of the adversary is lower than that of a network classifying the original image but higher than that of a random classifier. rearrangement block, a convolution layer that is followed by batch normalisation, and a sharing affinity block. The rearrangement block distributes the backbone feature map into 2 channels, each of size 112 √ó 112, while maintaining the relative positions between the features in the same channel  [14] , whereas the sharing affinity block ensures the global average representation of faces in the mini-batch is propagated. For this paper, we choose to study the leakage of private information from the features extracted by the ResNet-18 backbone and that by the ARM, which represent layers that cannot be executed in the TEE. Fig.  1  shows the network architecture and the features studied in this paper.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Attribute",
      "text": "",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Results",
      "text": "In this section, we discuss the utility and the privacy level of the proposed privacy-preserving network, PrivateNet. The utility of the classifier network is its accuracy on emotion recognition. The privacy level provided for a private attribute by the network is how close the accuracy of an adversary classifier is to a random guess on that attribute. Furthermore, the robustness of the network is the difference in accuracy between the adversary accessing the features of the original network (Tab. 1) and the privacy-preserving networks. The more negative the percentage difference, the more robust the privacy-preserving network.\n\nTo establish a fair comparison with the private information that can be inferred from the original image and to ensure that any difference is due to the input and not to the change in the architecture, we use the same ARM network architecture in our experiments. The adversary for the backbone features consists of an ARM and a fully connected layer, whereas that for ARM features consists of a fully connected layer only. All networks are trained on an Nvidia Tesla V100-SXM2 GPU, using a learning rate of 0.001 with ADAM optimiser, with 200 epochs. The networks were tested on the same GPU.\n\nTab. 1 reports the accuracy of the adversaries on features extracted through different layers of the networks to infer two private attributes, namely gender and age. A random classifier would achieve an accuracy of 50% for gender (K = 2) and 20% for age (K = 5). The classification accuracy of Table  2 . Utility, privacy and robustness of privacy-preserving networks trained with an adversarial loss  [10]  and with the proposed confusion loss (Eq. 7). The level of privacy guaranteed for an attribute is measured as the accuracy of an adversary classifier on the features of the network. The lower the accuracy, the more difficult to infer private information from the features. Robustness is the difference in the accuracy of the adversary classifier on the features of the original network (Tab. 1) and the privacy-preserving network, reported in relative percentage difference. The more negative the difference, the less susceptible (i.e. more robust) the privacy-preserving network to the adversary classifier. The results of the most robust network are shown in bold.  KEY   the ARM network architecture, using the original images as baselines, is 88.22% for gender and 73.53% for age. The leakage of private information decreases along the network, as the network extracts features that are more relevant to the target task. In particular, the accuracy of the adversaries on the gender attribute drops from 74.97%, with features extracted by the backbone, to 63.30%, with features extracted by the ARM. Nonetheless, the adversary classifier can still predict the private attributes with high accuracy from the extracted features. For example, the adversary classifier who has access to the backbone feature can predict the gender attribute with 73.75% accuracy (83.59% of the baseline accuracy) and the age attribute with 68.20% accuracy (88.17% of the baseline).\n\nTab. 2 compares the utility, privacy and robustness of 8 networks, trained with 2 loss functions, namely the proposed confusion loss and the adversarial loss by Edwards and Storkey  [10] , against 2 known adversaries on the backbone and ARM features, for 2 private attributes, namely gender and age. In the rest of the paper, we refer to the networks in the format loss-feature-attribute, hence confusion-featureattribute is an example of the proposed PrivateNet. The utility of the 8 networks ranges from 88.43% to 89.86%, corresponding to a slight drop (1.36% to 2.93%) from the original ARM network (accuracy of 91.10%). Therefore training the network in a privacy-preserving way only slightly reduces the network performance for the consensual task.\n\nFor the binary (K = 2) gender attribute, the accuracy of",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Utility",
      "text": "",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Known Adversary Ideal Utility",
      "text": "Unknown adversary Random classifier Fig.  2 . Impact of the relative weighting of the cross-entropy loss and the proposed confusion loss (Œª in Eq. 8) on the accuracy of the consensual task (utility) and of adversaries that use the backbone features to predict the age group (K = 5). Note that Œª = 1 means that the network is not trained for the target task and therefore we do not report the accuracy of the unknown adversary for this value. Dashed lines show the ideal behaviours, i.e. maximum utility for the consensual attribute and random results for the private attribute. the known adversary on PrivateNet is 51.27% on confusionbackbone-gender and 49.91% on confusion-ARM-gender. Thus the confusion loss has achieved the goal of obfuscating the known adversary to perform similarly to a random classifier (50%). However, the high accuracy of the unknown adversary (72.81% and 62.43% on backbone and ARM features, respectively) indicates that the networks are not robust against the attack of an adversary that is unknown at the time of training. Training the network with adversarial loss forces the known adversary to mis-classify the binary attribute (from male to female and from female to male), hence the accuracy of the known adversary on adversarial-backbonegender is lower than that on confusion-backbone-gender (43.53%). However, the accuracy of an unknown adversary on adversarial-backbone-gender (87.84%) is higher than that of confusion-backbone-gender, and also higher than that of the original network (68.20%). Moreover, while training with the confusion loss has increased the robustness by 2.88% on confusion-backbone-gender and decreased it by 1.75% on confusion-ARM-gender, training with the adversarial loss decreases the robustness against an unknown adversary by 18.04% and 37.99% on adversarial-backbone-gender and adversarial-ARM-gender, respectively. Therefore, training with an adversarial loss in fact encourages the network to extract features that are more useful for inferring the binary attribute, hence reducing the ability of the network to protect the attribute.\n\nFor the age group attribute (K = 5), training with the Fig.  2  reports the results obtained when varying the relative weight of the cross-entropy and confusion losses (Œª in Eq. 8) on the consensual task and the robustness of the proposed privacy-preserving network. Note that Œª = 0 is equivalent to the original ARM network that is optimised for emotion recognition only; increasing Œª gives more importance to the confusion loss; and Œª = 1 discards the cross-entropy loss and hence the network is optimised for misleading the known adversary only. As Œª increases, the utility (emotion recognition accuracy) decreases, as expected. While training with most values of Œª can cause the accuracy of the known adversary to be close to that of a random classifier, the robustness of the PrivateNet increases with Œª. Tab. 3 reports the inference time of the proposed networks on RAF-DB. As the numbers of parameters are the same, the inference times of the networks are similar to that of the original ARM network (10.76¬±0.34 milliseconds).\n\nTo summarise, PrivateNet maintains comparable utility in emotion recognition, while protecting the private attributes from known and unknown adversaries. Also, this approach to privacy preservation has no impact on the inference time of the network.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Conclusion",
      "text": "We addressed the problem of private information leakage through the features extracted by the intermediate layers of a deep learning classifier. Unlike works that use an adversarial loss to cause the mis-classification of a private attribute, we obfuscate its associated features using a confusion loss. The proposed approach was validated in a scenario where the goal is to conceal age group and gender attributes from a known adversary with access to the output of the layers of an emotion recognition network. The proposed PrivateNet reduces the accuracy of the adversary to close to that of a random classifier, with negligible effects on the accuracy of the target task. Moreover, the proposed confusion loss is preferable to the adversarial loss in reducing the leakage of private information with an unknown adversary classifier.\n\nFuture work will consider more granular private attributes and the protection of multiple private attributes in a single network.",
      "page_start": 4,
      "page_end": 4
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Architecture of the ARM network [11] used as the",
      "page": 2
    },
    {
      "caption": "Figure 1: shows the network architecture",
      "page": 3
    },
    {
      "caption": "Figure 2: Impact of the relative weighting of the cross-entropy",
      "page": 4
    },
    {
      "caption": "Figure 2: reports the results obtained when varying the rel-",
      "page": 4
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": "Ô¨Åcation of individuals whose data were included in a training"
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": "dataset [3‚Äì6] or are ingested by a deployed system. Methods"
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": ""
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": "that protect from attribute inference attacks aim to prevent the"
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": ""
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": "prediction of (private) attributes from a training dataset [6] or"
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": ""
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": "from a classiÔ¨Åcation pipeline deployed on a system, such as"
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": ""
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": "a smart kiosk. The latter scenario is the scope of our work:"
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": ""
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": "we consider a system whose untrusted rich execution envi-"
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": ""
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": "ronment\nis compromised by malware, but\nis equipped with"
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": ""
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": "security measures that ensure conÔ¨Ådentiality and integrity of"
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": ""
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": "the visual data (e.g.\na limited-memory,\nisolated Trusted Ex-"
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": ""
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": "ecution Environment, or TEE). The memory limitation of a"
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": ""
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": "TEE can only host a few of the last\nlayers of a feed-forward"
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": ""
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": "network,\ntypically the layers after the backbone structure or"
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": ""
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": "only the fully-connected layer\n[7]. We consider\nthe adver-"
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": ""
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": "sary to have access to the untrusted execution environment"
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": ""
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": "of\nthe system and thus in a position to exploit\nthe features"
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": ""
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": "extracted by these intermediate layers to infer private infor-"
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": ""
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": "mation [8]. Existing works that aim to prevent attribute infer-"
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": ""
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": "ence attacks modify the input data with adversarial perturba-"
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": ""
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": "tions [9] or train the network to cause mis-classiÔ¨Åcation of pri-"
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": ""
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": "vate attributes, for instance using the cross-entropy loss [10]."
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": ""
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": ""
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": "In this work, we aim to prevent\nthe estimation of private"
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": "information at\ninference time by training the network to ex-"
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": "tract features that are useful for the target\ntask only and that"
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": "cause a known adversary classiÔ¨Åer to perform similarly to a"
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": "random classiÔ¨Åer on a protected attribute. To conceal the pri-"
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": ""
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": "vate information from the adversary classiÔ¨Åer, we train the"
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": "pipeline with a confusion loss. The proposed approach does"
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": ""
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": "not modify the network architecture or the number of its pa-"
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": ""
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": "rameters, and hence has no latency impact on the inference"
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": ""
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": "pipeline.\nIn the speciÔ¨Åc implementation reported in this pa-"
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": ""
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": "per, we consider visual emotion recognition as the target task,"
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": ""
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": "and age and gender as protected attributes1. We also inves-"
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": ""
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": "tigate the robustness of the proposed approach by training an"
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": ""
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": "adversary to classify the private information from the privacy-"
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": ""
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": "preserving network."
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": ""
        },
        {
          "Centre for Intelligent Sensing, Queen Mary University of London, UK": ""
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "The output of the last\nlayer N is a vector that represents the": "conÔ¨Ådence of C that x belongs to any of the classes:"
        },
        {
          "The output of the last\nlayer N is a vector that represents the": ""
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "(2)\nFN (x) = (py\n2, . . . , py\n1, py"
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "D)."
        },
        {
          "The output of the last\nlayer N is a vector that represents the": ""
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "Let A(¬∑) be an adversary K-class classiÔ¨Åer\nthat aims to"
        },
        {
          "The output of the last\nlayer N is a vector that represents the": ""
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "predict a protected, private class from the output, Fi(x), of"
        },
        {
          "The output of the last\nlayer N is a vector that represents the": ""
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "an intermediate layer as one in the set:"
        },
        {
          "The output of the last\nlayer N is a vector that represents the": ""
        },
        {
          "The output of the last\nlayer N is a vector that represents the": ""
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "(3)\nS = {s1, s2, . . . , sK}."
        },
        {
          "The output of the last\nlayer N is a vector that represents the": ""
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "Let M be the number of layers in A(¬∑). The output of the"
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "last\nlayer M is a vector representing the conÔ¨Ådence of A(¬∑)"
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "that Fi(x) belongs to any of the (private) classes:"
        },
        {
          "The output of the last\nlayer N is a vector that represents the": ""
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "(4)\nQM (Fi(x)) = (ps\n1, ps\n2, . . . , ps\nK)."
        },
        {
          "The output of the last\nlayer N is a vector that represents the": ""
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "Let X be a set of\nface images, each annotated with an"
        },
        {
          "The output of the last\nlayer N is a vector that represents the": ""
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "emotion (target) attribute, ÀÜy, and a private attribute, ÀÜs. We"
        },
        {
          "The output of the last\nlayer N is a vector that represents the": ""
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "measure\nthe\nleakage\nof\nprivate\ninformation\nas\nthe\naccu-"
        },
        {
          "The output of the last\nlayer N is a vector that represents the": ""
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "racy, TÀÜs, of the private attribute inference from X :"
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "|{x ‚àà X : A(Fi(x)) = ÀÜs}|"
        },
        {
          "The output of the last\nlayer N is a vector that represents the": ",\n(5)\nTÀÜs ="
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "|X |"
        },
        {
          "The output of the last\nlayer N is a vector that represents the": ""
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "where | ¬∑ | is the cardinality of a set. The higher TÀÜs, the higher"
        },
        {
          "The output of the last\nlayer N is a vector that represents the": ""
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "the leakage of private information through C(¬∑)."
        },
        {
          "The output of the last\nlayer N is a vector that represents the": ""
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "A classiÔ¨Åer C(¬∑) that\nis privacy-preserving should main-"
        },
        {
          "The output of the last\nlayer N is a vector that represents the": ""
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "tain a high accuracy in the prediction of the consensual\ntask,"
        },
        {
          "The output of the last\nlayer N is a vector that represents the": ""
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "while\nconcealing the private\nattributes\nfrom the\nadversary"
        },
        {
          "The output of the last\nlayer N is a vector that represents the": ""
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "classiÔ¨Åer A(¬∑), i.e. TÀÜs should be close to a random classiÔ¨Åer."
        },
        {
          "The output of the last\nlayer N is a vector that represents the": ""
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "To predict the consensual class, the classiÔ¨Åer C(¬∑) is typi-"
        },
        {
          "The output of the last\nlayer N is a vector that represents the": ""
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "cally trained with a cross-entropy loss:"
        },
        {
          "The output of the last\nlayer N is a vector that represents the": ""
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "(cid:32)\n(cid:33)"
        },
        {
          "The output of the last\nlayer N is a vector that represents the": ""
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "(cid:16)\n(cid:17)\nexp(pÀÜy)"
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "= ‚àí log\n,\n(6)\nLCE\ny, FN (x)"
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "(cid:80)"
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "i )\ni exp(py"
        },
        {
          "The output of the last\nlayer N is a vector that represents the": ""
        },
        {
          "The output of the last\nlayer N is a vector that represents the": ""
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "where exp(¬∑) is the exponential function."
        },
        {
          "The output of the last\nlayer N is a vector that represents the": ""
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "To prevent\nthe leakage of private information associated"
        },
        {
          "The output of the last\nlayer N is a vector that represents the": ""
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "with a protected attribute, we propose to obfuscate with a con-"
        },
        {
          "The output of the last\nlayer N is a vector that represents the": ""
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "the features in the intermediate layers that\nfusion loss, Lcon,"
        },
        {
          "The output of the last\nlayer N is a vector that represents the": ""
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "are useful to the adversary:"
        },
        {
          "The output of the last\nlayer N is a vector that represents the": ""
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "(cid:16)\n(cid:17)"
        },
        {
          "The output of the last\nlayer N is a vector that represents the": ""
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "(7)\nLcon\nFi(x)\n= (cid:107)QM (Fi(x)) ‚àí U D(cid:107)2,"
        },
        {
          "The output of the last\nlayer N is a vector that represents the": ""
        },
        {
          "The output of the last\nlayer N is a vector that represents the": ""
        },
        {
          "The output of the last\nlayer N is a vector that represents the": ") denotes equal probability for each\nwhere U D = ( 1"
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "1D\nD , ...,"
        },
        {
          "The output of the last\nlayer N is a vector that represents the": ""
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "private attribute class, hence causing the adversary to perform"
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "similarly to a random classiÔ¨Åer.\nAs\nthe features extracted"
        },
        {
          "The output of the last\nlayer N is a vector that represents the": ""
        },
        {
          "The output of the last\nlayer N is a vector that represents the": "by an intermediate layer embeds\nthe features extracted by"
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "2. METHOD": "",
          "Amend representation": "Resnet-18 backbone\nmodule (ARM)"
        },
        {
          "2. METHOD": "Let C(¬∑) be a D-class deep neural network classiÔ¨Åer of N lay-",
          "Amend representation": ""
        },
        {
          "2. METHOD": "",
          "Amend representation": "\""
        },
        {
          "2. METHOD": "ers that, given an image x, predicts its consensual class as one",
          "Amend representation": "ùëù!\n\""
        },
        {
          "2. METHOD": "",
          "Amend representation": "ùëù#"
        },
        {
          "2. METHOD": "in the set:",
          "Amend representation": "\"\nùëù$"
        },
        {
          "2. METHOD": "",
          "Amend representation": "7x7 conv\n3x3 max pool\n3x3 residual\n3x3 residual\n3x3 residual\n3x3 residual\n3x3 residual\n3x3 residual\nrearrangement\n31 x 31 conv\nbatch norm\nshare affinity\nfully connected\n\"\nùë•"
        },
        {
          "2. METHOD": "(1)\nY = {y1, y2, . . . , yD}.",
          "Amend representation": "ùëù%\n\""
        },
        {
          "2. METHOD": "",
          "Amend representation": "ùëù&"
        },
        {
          "2. METHOD": "",
          "Amend representation": "\""
        },
        {
          "2. METHOD": "",
          "Amend representation": "ùëù‚Äô"
        },
        {
          "2. METHOD": "Let Fi(x) be the output of layer i of C(¬∑), with i ‚àà {1, ..., N }.",
          "Amend representation": "\"\nùëù("
        },
        {
          "2. METHOD": "The output of the last\nlayer N is a vector that represents the",
          "Amend representation": ""
        },
        {
          "2. METHOD": "conÔ¨Ådence of C that x belongs to any of the classes:",
          "Amend representation": ""
        },
        {
          "2. METHOD": "",
          "Amend representation": "backbone feature\nARM feature"
        },
        {
          "2. METHOD": "(2)\nFN (x) = (py\n2, . . . , py\n1, py",
          "Amend representation": ""
        },
        {
          "2. METHOD": "D).",
          "Amend representation": ""
        },
        {
          "2. METHOD": "",
          "Amend representation": "Fig. 1. Architecture of\nthe ARM network [11] used as the"
        },
        {
          "2. METHOD": "Let A(¬∑) be an adversary K-class classiÔ¨Åer\nthat aims to",
          "Amend representation": ""
        },
        {
          "2. METHOD": "",
          "Amend representation": "emotion recognition classiÔ¨Åer.\nGiven an image x,\nthe net-"
        },
        {
          "2. METHOD": "predict a protected, private class from the output, Fi(x), of",
          "Amend representation": ""
        },
        {
          "2. METHOD": "",
          "Amend representation": "work outputs the probability py\ni , i ‚àà {1, .., 7}, of each emo-"
        },
        {
          "2. METHOD": "an intermediate layer as one in the set:",
          "Amend representation": ""
        },
        {
          "2. METHOD": "",
          "Amend representation": "tion class (Eq. 2). An adversary could infer private, protected"
        },
        {
          "2. METHOD": "",
          "Amend representation": "attributes from the features extracted by the intermediate lay-"
        },
        {
          "2. METHOD": "(3)\nS = {s1, s2, . . . , sK}.",
          "Amend representation": ""
        },
        {
          "2. METHOD": "",
          "Amend representation": "ers of the network (red dashed arrows). Coloured blocks rep-"
        },
        {
          "2. METHOD": "Let M be the number of layers in A(¬∑). The output of the",
          "Amend representation": "resent layers with trainable parameters."
        },
        {
          "2. METHOD": "last\nlayer M is a vector representing the conÔ¨Ådence of A(¬∑)",
          "Amend representation": ""
        },
        {
          "2. METHOD": "that Fi(x) belongs to any of the (private) classes:",
          "Amend representation": ""
        },
        {
          "2. METHOD": "",
          "Amend representation": "the layers preceding it, backpropagating the confusion loss"
        },
        {
          "2. METHOD": "(4)\nQM (Fi(x)) = (ps\n1, ps\n2, . . . , ps\nK).",
          "Amend representation": "through the entire network optimizes the layers preceding the"
        },
        {
          "2. METHOD": "",
          "Amend representation": "targeted layer to extract generic features that cause the adver-"
        },
        {
          "2. METHOD": "Let X be a set of\nface images, each annotated with an",
          "Amend representation": ""
        },
        {
          "2. METHOD": "",
          "Amend representation": "sary to perform similarly to a random classiÔ¨Åer on the pro-"
        },
        {
          "2. METHOD": "emotion (target) attribute, ÀÜy, and a private attribute, ÀÜs. We",
          "Amend representation": ""
        },
        {
          "2. METHOD": "",
          "Amend representation": "tected attribute. Thus, in training we encourage the deep neu-"
        },
        {
          "2. METHOD": "measure\nthe\nleakage\nof\nprivate\ninformation\nas\nthe\naccu-",
          "Amend representation": ""
        },
        {
          "2. METHOD": "",
          "Amend representation": "ral network to extract privacy-preserving features by combin-"
        },
        {
          "2. METHOD": "racy, TÀÜs, of the private attribute inference from X :",
          "Amend representation": "ing Eq. 6 and 7 as the overall loss function, L:"
        },
        {
          "2. METHOD": "|{x ‚àà X : A(Fi(x)) = ÀÜs}|",
          "Amend representation": ""
        },
        {
          "2. METHOD": ",\n(5)\nTÀÜs =",
          "Amend representation": "(8)\nL = (1 ‚àí Œª)LCE + ŒªLcon,"
        },
        {
          "2. METHOD": "|X |",
          "Amend representation": ""
        },
        {
          "2. METHOD": "",
          "Amend representation": "where Œª determines\nthe\nrelative\nimportance\nbetween\nthe"
        },
        {
          "2. METHOD": "where | ¬∑ | is the cardinality of a set. The higher TÀÜs, the higher",
          "Amend representation": ""
        },
        {
          "2. METHOD": "",
          "Amend representation": "losses: Œª < 0.5 gives more\nimportance\nto maintaining the"
        },
        {
          "2. METHOD": "the leakage of private information through C(¬∑).",
          "Amend representation": ""
        },
        {
          "2. METHOD": "",
          "Amend representation": "utility and Œª > 0.5 gives more importance to confusing the"
        },
        {
          "2. METHOD": "A classiÔ¨Åer C(¬∑) that\nis privacy-preserving should main-",
          "Amend representation": ""
        },
        {
          "2. METHOD": "",
          "Amend representation": "adversary."
        },
        {
          "2. METHOD": "tain a high accuracy in the prediction of the consensual\ntask,",
          "Amend representation": ""
        },
        {
          "2. METHOD": "",
          "Amend representation": "We use as dataset the Real-world Affective Faces Database"
        },
        {
          "2. METHOD": "while\nconcealing the private\nattributes\nfrom the\nadversary",
          "Amend representation": ""
        },
        {
          "2. METHOD": "",
          "Amend representation": "(RAF-DB) [12], which contains 15,338 images. Each image"
        },
        {
          "2. METHOD": "classiÔ¨Åer A(¬∑), i.e. TÀÜs should be close to a random classiÔ¨Åer.",
          "Amend representation": ""
        },
        {
          "2. METHOD": "",
          "Amend representation": "was\nannotated,\non average,\nby 40 annotators\ninto D = 7"
        },
        {
          "2. METHOD": "To predict the consensual class, the classiÔ¨Åer C(¬∑) is typi-",
          "Amend representation": ""
        },
        {
          "2. METHOD": "",
          "Amend representation": "emotion attributes\n(surprise,\nfear,\ndisgust,\nhappiness,\nsad-"
        },
        {
          "2. METHOD": "cally trained with a cross-entropy loss:",
          "Amend representation": ""
        },
        {
          "2. METHOD": "",
          "Amend representation": "ness, anger, and neutral) and demographics including race,"
        },
        {
          "2. METHOD": "(cid:32)\n(cid:33)",
          "Amend representation": ""
        },
        {
          "2. METHOD": "",
          "Amend representation": "gender\nand age group.\nSpeciÔ¨Åcally, we\nfocus on gender"
        },
        {
          "2. METHOD": "(cid:16)\n(cid:17)\nexp(pÀÜy)",
          "Amend representation": ""
        },
        {
          "2. METHOD": "= ‚àí log\n,\n(6)\nLCE\ny, FN (x)",
          "Amend representation": "(K = 2, male and female)2 and age group (K = 5, namely"
        },
        {
          "2. METHOD": "(cid:80)",
          "Amend representation": ""
        },
        {
          "2. METHOD": "i )\ni exp(py",
          "Amend representation": ""
        },
        {
          "2. METHOD": "",
          "Amend representation": "0-3, 4-19, 20-39, 40-69, and over 70). As for\nthe emotion"
        },
        {
          "2. METHOD": "",
          "Amend representation": "classiÔ¨Åer C(¬∑), we use\nthe Amend Representation Module"
        },
        {
          "2. METHOD": "where exp(¬∑) is the exponential function.",
          "Amend representation": ""
        },
        {
          "2. METHOD": "",
          "Amend representation": "network proposed by Shi and Zhou [11]. On RAF-DB,\nthe"
        },
        {
          "2. METHOD": "To prevent\nthe leakage of private information associated",
          "Amend representation": ""
        },
        {
          "2. METHOD": "",
          "Amend representation": "ARM network attains a state-of-the-art emotion recognition"
        },
        {
          "2. METHOD": "with a protected attribute, we propose to obfuscate with a con-",
          "Amend representation": ""
        },
        {
          "2. METHOD": "",
          "Amend representation": "accuracy of 91.10%.\nThe ARM network aims\nto remove"
        },
        {
          "2. METHOD": "the features in the intermediate layers that\nfusion loss, Lcon,",
          "Amend representation": ""
        },
        {
          "2. METHOD": "",
          "Amend representation": "the distortion from the edges of\nthe image on the features,"
        },
        {
          "2. METHOD": "are useful to the adversary:",
          "Amend representation": ""
        },
        {
          "2. METHOD": "",
          "Amend representation": "referred to as albino erosion. The ARM network consists of"
        },
        {
          "2. METHOD": "(cid:16)\n(cid:17)",
          "Amend representation": ""
        },
        {
          "2. METHOD": "",
          "Amend representation": "a ResNet-18 [13] backbone, an Amend Representation Mod-"
        },
        {
          "2. METHOD": "(7)\nLcon\nFi(x)\n= (cid:107)QM (Fi(x)) ‚àí U D(cid:107)2,",
          "Amend representation": ""
        },
        {
          "2. METHOD": "",
          "Amend representation": "ule (ARM), and a fully connected layer.\nThe output of\nthe"
        },
        {
          "2. METHOD": "",
          "Amend representation": "ResNet-18 backbone is a feature map of size 7 √ó 7 and 512"
        },
        {
          "2. METHOD": ") denotes equal probability for each\nwhere U D = ( 1",
          "Amend representation": ""
        },
        {
          "2. METHOD": "1D\nD , ...,",
          "Amend representation": ""
        },
        {
          "2. METHOD": "",
          "Amend representation": "channels. An ARM consists of 3 blocks, namely a feature"
        },
        {
          "2. METHOD": "private attribute class, hence causing the adversary to perform",
          "Amend representation": ""
        },
        {
          "2. METHOD": "similarly to a random classiÔ¨Åer.\nAs\nthe features extracted",
          "Amend representation": ""
        },
        {
          "2. METHOD": "",
          "Amend representation": "2We excluded the images with unsure gender class, which contribute"
        },
        {
          "2. METHOD": "by an intermediate layer embeds\nthe features extracted by",
          "Amend representation": "to 6.3% of the dataset."
        }
      ],
      "page": 2
    },
    {
      "caption": "Table 1: The leakage of private information is measured Table2. Utility,privacyandrobustnessofprivacy-preserving",
      "data": [
        {
          "Table 1.": "as the accuracy of an adversary classiÔ¨Åer",
          "The leakage of private information is measured": "that\ninfers private",
          "Table 2. Utility, privacy and robustness of privacy-preserving": "networks trained with an adversarial\nloss [10] and with the"
        },
        {
          "Table 1.": "attributes",
          "The leakage of private information is measured": "from the\nfeatures\nextracted from the ARM net-",
          "Table 2. Utility, privacy and robustness of privacy-preserving": "proposed confusion loss (Eq. 7). The level of privacy guaran-"
        },
        {
          "Table 1.": "work [11],",
          "The leakage of private information is measured": "trained for emotion recognition. Note that the ac-",
          "Table 2. Utility, privacy and robustness of privacy-preserving": "teed for an attribute is measured as the accuracy of an adver-"
        },
        {
          "Table 1.": "curacy of the adversary is lower than that of a network clas-",
          "The leakage of private information is measured": "",
          "Table 2. Utility, privacy and robustness of privacy-preserving": "sary classiÔ¨Åer on the features of the network. The lower the"
        },
        {
          "Table 1.": "sifying the original",
          "The leakage of private information is measured": "image but higher\nthan that of a random",
          "Table 2. Utility, privacy and robustness of privacy-preserving": "accuracy,\nthe more difÔ¨Åcult\nto infer private information from"
        },
        {
          "Table 1.": "classiÔ¨Åer.",
          "The leakage of private information is measured": "",
          "Table 2. Utility, privacy and robustness of privacy-preserving": "the features. Robustness is the difference in the accuracy of"
        },
        {
          "Table 1.": "",
          "The leakage of private information is measured": "Random\nBaseline on\nAdversary on feature",
          "Table 2. Utility, privacy and robustness of privacy-preserving": "the adversary classiÔ¨Åer on the features of the original network"
        },
        {
          "Table 1.": "Attribute",
          "The leakage of private information is measured": "",
          "Table 2. Utility, privacy and robustness of privacy-preserving": ""
        },
        {
          "Table 1.": "",
          "The leakage of private information is measured": "classiÔ¨Åer\noriginal image Backbone\nARM",
          "Table 2. Utility, privacy and robustness of privacy-preserving": "(Tab. 1) and the privacy-preserving network, reported in rela-"
        },
        {
          "Table 1.": "Gender",
          "The leakage of private information is measured": "50\n88.22\n74.97\n63.30",
          "Table 2. Utility, privacy and robustness of privacy-preserving": "tive percentage difference. The more negative the difference,"
        },
        {
          "Table 1.": "Age",
          "The leakage of private information is measured": "20\n77.35\n68.20\n57.20",
          "Table 2. Utility, privacy and robustness of privacy-preserving": "the less susceptible (i.e. more robust) the privacy-preserving"
        },
        {
          "Table 1.": "",
          "The leakage of private information is measured": "",
          "Table 2. Utility, privacy and robustness of privacy-preserving": "network to the adversary classiÔ¨Åer.\nThe results of\nthe most"
        },
        {
          "Table 1.": "",
          "The leakage of private information is measured": "",
          "Table 2. Utility, privacy and robustness of privacy-preserving": "robust network are shown in bold.\nKEY ‚Äì Att.:\nattribute;"
        },
        {
          "Table 1.": "rearrangement block, a convolution layer that",
          "The leakage of private information is measured": "is followed by",
          "Table 2. Utility, privacy and robustness of privacy-preserving": ""
        },
        {
          "Table 1.": "",
          "The leakage of private information is measured": "",
          "Table 2. Utility, privacy and robustness of privacy-preserving": "Adv.: adversarial; Prop.: proposed; K: known adversary; U:"
        },
        {
          "Table 1.": "batch normalisation, and a sharing afÔ¨Ånity block. The rear-",
          "The leakage of private information is measured": "",
          "Table 2. Utility, privacy and robustness of privacy-preserving": ""
        },
        {
          "Table 1.": "",
          "The leakage of private information is measured": "",
          "Table 2. Utility, privacy and robustness of privacy-preserving": "unknown adversary."
        },
        {
          "Table 1.": "rangement block distributes the backbone feature map into 2",
          "The leakage of private information is measured": "",
          "Table 2. Utility, privacy and robustness of privacy-preserving": ""
        },
        {
          "Table 1.": "",
          "The leakage of private information is measured": "",
          "Table 2. Utility, privacy and robustness of privacy-preserving": "Att. Feature\nLoss Utility\nPrivacy\nRobustness"
        }
      ],
      "page": 3
    },
    {
      "caption": "Table 1: The leakage of private information is measured Table2. Utility,privacyandrobustnessofprivacy-preserving",
      "data": [
        {
          "network to the adversary classiÔ¨Åer.\nThe results of\nthe most": "robust network are shown in bold.\nKEY ‚Äì Att.:\nattribute;"
        },
        {
          "network to the adversary classiÔ¨Åer.\nThe results of\nthe most": ""
        },
        {
          "network to the adversary classiÔ¨Åer.\nThe results of\nthe most": "Adv.: adversarial; Prop.: proposed; K: known adversary; U:"
        },
        {
          "network to the adversary classiÔ¨Åer.\nThe results of\nthe most": ""
        },
        {
          "network to the adversary classiÔ¨Åer.\nThe results of\nthe most": "unknown adversary."
        },
        {
          "network to the adversary classiÔ¨Åer.\nThe results of\nthe most": ""
        },
        {
          "network to the adversary classiÔ¨Åer.\nThe results of\nthe most": "Att. Feature\nLoss Utility\nPrivacy\nRobustness"
        },
        {
          "network to the adversary classiÔ¨Åer.\nThe results of\nthe most": ""
        },
        {
          "network to the adversary classiÔ¨Åer.\nThe results of\nthe most": "K\nU\nK\nU"
        },
        {
          "network to the adversary classiÔ¨Åer.\nThe results of\nthe most": ""
        },
        {
          "network to the adversary classiÔ¨Åer.\nThe results of\nthe most": "Adv.\n88.43\n56.47 88.50\n-24.68% +18.04%"
        },
        {
          "network to the adversary classiÔ¨Åer.\nThe results of\nthe most": "Backbone"
        },
        {
          "network to the adversary classiÔ¨Åer.\nThe results of\nthe most": "Prop.\n89.40\n51.27 72.81 -31.61% -2.88%"
        },
        {
          "network to the adversary classiÔ¨Åer.\nThe results of\nthe most": "Gender"
        },
        {
          "network to the adversary classiÔ¨Åer.\nThe results of\nthe most": "Adv.\n89.51\n43.53 87.84 -36.17% +37.99%"
        },
        {
          "network to the adversary classiÔ¨Åer.\nThe results of\nthe most": "ARM"
        },
        {
          "network to the adversary classiÔ¨Åer.\nThe results of\nthe most": ""
        },
        {
          "network to the adversary classiÔ¨Åer.\nThe results of\nthe most": "Prop.\n89.47\n49.91 62.43\n-26.82% +1.75%"
        },
        {
          "network to the adversary classiÔ¨Åer.\nThe results of\nthe most": ""
        },
        {
          "network to the adversary classiÔ¨Åer.\nThe results of\nthe most": "Adv.\n89.63\n10.72 62.58 -83.06% -8.24%"
        },
        {
          "network to the adversary classiÔ¨Åer.\nThe results of\nthe most": "Backbone"
        },
        {
          "network to the adversary classiÔ¨Åer.\nThe results of\nthe most": "Age\nProp.\n89.83\n20.18 59.29\n-68.12% -13.06%"
        },
        {
          "network to the adversary classiÔ¨Åer.\nThe results of\nthe most": "Adv.\n89.47\n10.72 54.17 -81.26% -5.30%"
        },
        {
          "network to the adversary classiÔ¨Åer.\nThe results of\nthe most": "ARM"
        },
        {
          "network to the adversary classiÔ¨Åer.\nThe results of\nthe most": "Prop.\n89.86\n21.28 56.88\n-62.80%\n-0.56%"
        }
      ],
      "page": 3
    },
    {
      "caption": "Table 3: Inference time of the privacy-preserving network,",
      "data": [
        {
          "Utility": "Ideal utility",
          "Known adversary": "Unknown adversary"
        },
        {
          "Utility": "Random classiÔ¨Åer",
          "Known adversary": ""
        },
        {
          "Utility": "",
          "Known adversary": ""
        },
        {
          "Utility": "",
          "Known adversary": ""
        },
        {
          "Utility": "",
          "Known adversary": ""
        },
        {
          "Utility": "",
          "Known adversary": ""
        },
        {
          "Utility": "",
          "Known adversary": ""
        },
        {
          "Utility": "",
          "Known adversary": ""
        },
        {
          "Utility": "",
          "Known adversary": ""
        },
        {
          "Utility": "",
          "Known adversary": ""
        },
        {
          "Utility": "",
          "Known adversary": ""
        },
        {
          "Utility": "",
          "Known adversary": ""
        },
        {
          "Utility": "",
          "Known adversary": ""
        },
        {
          "Utility": "",
          "Known adversary": ""
        }
      ],
      "page": 4
    },
    {
      "caption": "Table 3: Inference time of the privacy-preserving network,",
      "data": [
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": ""
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "adversarial-"
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "the\naccuracy\nof\nthe\nadversary\nis\n10.72% on"
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": ""
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "backbone-age and 20.18% on confusion-backbone-age. How-"
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "ever,\nthe\naccuracy\nof\nan\nunknown\nadversary\nis\n62.58%"
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": ""
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "adversarial-backbone-age\nconfusion-\non\nand\n59.29% on"
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": ""
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "backbone-age.\nOverall,\nthe proposed PrivateNet are more"
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": ""
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "robust than networks trained with the adversarial loss."
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": ""
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "Fig. 2 reports the results obtained when varying the rel-"
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": ""
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "ative weight of the cross-entropy and confusion losses (Œª in"
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": ""
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "Eq. 8) on the consensual\ntask and the robustness of the pro-"
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": ""
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "posed privacy-preserving network. Note that Œª = 0 is equiv-"
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": ""
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "alent to the original ARM network that is optimised for emo-"
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": ""
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "tion recognition only;\nincreasing Œª gives more importance to"
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "the confusion loss; and Œª = 1 discards the cross-entropy loss"
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "and hence the network is optimised for misleading the known"
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": ""
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "adversary only. As Œª increases,\nthe utility (emotion recog-"
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": ""
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "nition accuracy) decreases, as expected. While training with"
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": ""
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "most values of Œª can cause the accuracy of\nthe known ad-"
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": ""
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "versary to be close to that of a random classiÔ¨Åer,\nthe robust-"
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": ""
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "ness of\nthe PrivateNet\nincreases with Œª.\nTab. 3 reports the"
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": ""
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "inference time of the proposed networks on RAF-DB. As the"
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": ""
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "numbers of parameters are the same,\nthe inference times of"
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": ""
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "the networks are similar to that of the original ARM network"
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": ""
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "(10.76¬±0.34 milliseconds)."
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": ""
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "To summarise, PrivateNet maintains comparable utility in"
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": ""
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "emotion recognition, while protecting the private attributes"
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": ""
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "from known and unknown adversaries. Also,\nthis approach"
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": ""
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "to privacy preservation has no impact on the inference time of"
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": ""
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "the network."
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": ""
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": ""
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "4. CONCLUSION"
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": ""
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "We\naddressed the problem of private\ninformation leakage"
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "through the features extracted by the intermediate layers of a"
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "deep learning classiÔ¨Åer. Unlike works that use an adversar-"
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": ""
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "ial\nloss to cause the mis-classiÔ¨Åcation of a private attribute,"
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "we obfuscate its associated features using a confusion loss."
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "The proposed approach was validated in a scenario where"
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "the goal\nis to conceal age group and gender attributes from"
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "a known adversary with access to the output of the layers of"
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "an emotion recognition network.\nThe proposed PrivateNet"
        },
        {
          "adversary\nbetter\nthan\ntraining\nit with\nthe\nconfusion\nloss:": "reduces\nthe accuracy of\nthe adversary to close to that of a"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "the target\ntask. Moreover,\nthe proposed confusion loss\nis",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": "Conference on Computer and Communications Secu-"
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "preferable to the adversarial\nloss in reducing the leakage of",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": "rity, November 2021."
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "private information with an unknown adversary classiÔ¨Åer.",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": ""
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": "[9] Chau Yi Li, Ali Shahin Shamsabadi, Ricardo Sanchez-"
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "Future work will consider more granular private attributes",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": ""
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": "Matilla,\nRiccardo Mazzon,\nand Andrea\nCavallaro,"
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "and the protection of multiple private attributes\nin a single",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": ""
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": "‚ÄúScene privacy protection,‚Äù in Proceedings of IEEE In-"
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "network.",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": ""
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": "ternational Conference on Acoustics, Speech and Signal"
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": "Processing, May 2019, pp. 2502‚Äì2506."
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "5. REFERENCES",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": ""
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": "[10] Harrison Edwards and Amos Storkey,\n‚ÄúCensoring rep-"
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "[1] Congzheng\nSong,\nThomas\nRistenpart,\nand\nVitaly",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": ""
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": "resentations with an adversary,‚Äù in Proceedings of Inter-"
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "Shmatikov,\n‚ÄúMachine learning models that\nremember",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": ""
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": "national Conference in Learning Representations, May"
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "too much,‚Äù in Proceedings of ACM SIGSAC Conference",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": ""
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": "2016, pp. 1‚Äì14."
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "on Computer and Communications Security, November",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": ""
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "2017, p. 587‚Äì601.",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": "[11]\nJiawei Shi and Songhao Zhu,\n‚ÄúLearning to amend fa-"
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": "cial expression representation via de-albino and afÔ¨Ån-"
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "[2] Hwansoo\nLee,\nSiew Fan Wong,\nJungjoo Oh,\nand",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": ""
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": "ity,‚Äù arXiv:2103.10189, September 2021."
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "Younghoon Chang,\n‚ÄúInformation privacy concerns and",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": ""
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "demographic characteristics: Data from a Korean media",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": "[12] Shan Li and Weihong Deng,\n‚ÄúReliable crowdsourcing"
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "panel survey,‚Äù Government Information Quarterly, vol.",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": "and deep locality-preserving learning for unconstrained"
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "36, no. 2, pp. 294‚Äì303, 2019.",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": "IEEE Transactions on\nfacial expression recognition,‚Äù"
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": "Image Processing, vol. 28, no. 1, pp. 356‚Äì370, Septem-"
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "[3] Reza Shokri, Marco Stronati, Congzheng Song, and Vi-",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": ""
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": "ber 2019."
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "taly Shmatikov, ‚ÄúMembership inference attacks against",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": ""
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "machine learning models,‚Äù in Proceedings of IEEE Sym-",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": "[13] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian"
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "posium on Security and Privacy, May 2017, pp. 3‚Äì18.",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": "Sun,\n‚ÄúDeep residual\nlearning for\nimage recognition,‚Äù"
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": "in Proceedings of IEEE Conference on Computer Vision"
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "[4] Milad Nasr, Reza Shokri, and Amir Houmansadr, ‚ÄúMa-",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": ""
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": "and Pattern Recognition, June 2016, pp. 770‚Äì778."
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "chine learning with membership privacy using adver-",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": ""
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "sarial regularization,‚Äù\nin Proceedings of ACM SIGSAC",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": "[14] Wenzhe Shi, Jose Caballero, Ferenc Husz¬¥ar, Johannes"
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "Conference on Computer and Communications Secu-",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": "Totz, Andrew P. Aitken, Rob Bishop, Daniel Rueckert,"
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "rity, October 2018, p. 634‚Äì646.",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": "and Zehan Wang,\n‚ÄúReal-time single image and video"
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": "super-resolution using an efÔ¨Åcient\nsub-pixel\nconvolu-"
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "[5] Ahmed Salem, Yang Zhang, Mathias Humbert, Pascal",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": ""
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": "tional neural network,‚Äù\nin IEEE Conference on Com-"
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "Berrang, Mario Fritz, and Michael Backes, ‚ÄúML-leaks:",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": ""
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": "puter Vision and Pattern Recognition,\nJune 2016, pp."
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "Model and data independent membership inference at-",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": ""
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": "1874‚Äì1883."
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "An-\ntacks and defenses on machine learning models,‚Äù",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": ""
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "nual Network and Distributed System Security Sympo-",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": ""
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "sium, February 2019.",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": ""
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "[6] Luca Melis, Congzheng Song, Emiliano De Cristofaro,",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": ""
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "and Vitaly Shmatikov,\n‚ÄúExploiting unintended feature",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": ""
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "leakage in collaborative learning,‚Äù Proceedings of IEEE",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": ""
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "Symposium on Security and Privacy, pp. 691‚Äì706, May",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": ""
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "2018.",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": ""
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "[7] Fan Mo, Ali Shahin Shamsabadi, Kleomenis Katevas,",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": ""
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "Soteris Demetriou,\nIlias Leontiadis, Andrea Cavallaro,",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": ""
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "and Hamed Haddadi, ‚ÄúDarknetz:\ntowards model privacy",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": ""
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "at the edge using trusted execution environments,‚Äù Pro-",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": ""
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "ceedings of the 18th International Conference on Mobile",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": ""
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "Systems, Applications, and Services, p. 161‚Äì174, June",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": ""
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "2020.",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": ""
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "[8] Mohammad Malekzadeh,\nAnastasia Borovykh,\nand",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": ""
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "Deniz G¬®und¬®uz,\n‚ÄúHonest-but-curious nets: Sensitive at-",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": ""
        },
        {
          "random classiÔ¨Åer, with negligible effects on the accuracy of": "tributes of private inputs can be secretly coded into the",
          "classiÔ¨Åers‚Äô outputs,‚Äù\nin Proceedings of ACM SIGSAC": ""
        }
      ],
      "page": 5
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "",
      "authors": [
        "References"
      ],
      "venue": ""
    },
    {
      "citation_id": "2",
      "title": "Machine learning models that remember too much",
      "authors": [
        "Congzheng Song",
        "Thomas Ristenpart",
        "Vitaly Shmatikov"
      ],
      "year": "2017",
      "venue": "Proceedings of ACM SIGSAC Conference on Computer and Communications Security"
    },
    {
      "citation_id": "3",
      "title": "Information privacy concerns and demographic characteristics: Data from a Korean media panel survey",
      "authors": [
        "Hwansoo Lee",
        "Fan Siew",
        "Jungjoo Wong",
        "Younghoon Oh",
        "Chang"
      ],
      "year": "2019",
      "venue": "Government Information Quarterly"
    },
    {
      "citation_id": "4",
      "title": "Membership inference attacks against machine learning models",
      "authors": [
        "Reza Shokri",
        "Marco Stronati",
        "Congzheng Song",
        "Vitaly Shmatikov"
      ],
      "year": "2017",
      "venue": "Proceedings of IEEE Symposium on Security and Privacy"
    },
    {
      "citation_id": "5",
      "title": "Machine learning with membership privacy using adversarial regularization",
      "authors": [
        "Milad Nasr",
        "Reza Shokri",
        "Amir Houmansadr"
      ],
      "year": "2018",
      "venue": "Proceedings of ACM SIGSAC Conference on Computer and Communications Security"
    },
    {
      "citation_id": "6",
      "title": "ML-leaks: Model and data independent membership inference attacks and defenses on machine learning models",
      "authors": [
        "Ahmed Salem",
        "Yang Zhang",
        "Mathias Humbert",
        "Pascal Berrang",
        "Mario Fritz",
        "Michael Backes"
      ],
      "year": "2019",
      "venue": "Annual Network and Distributed System Security Symposium"
    },
    {
      "citation_id": "7",
      "title": "Exploiting unintended feature leakage in collaborative learning",
      "authors": [
        "Luca Melis",
        "Congzheng Song",
        "Emiliano De Cristofaro",
        "Vitaly Shmatikov"
      ],
      "year": "2018",
      "venue": "Proceedings of IEEE Symposium on Security and Privacy"
    },
    {
      "citation_id": "8",
      "title": "Darknetz: towards model privacy at the edge using trusted execution environments",
      "authors": [
        "Fan Mo",
        "Ali Shahin Shamsabadi",
        "Kleomenis Katevas",
        "Soteris Demetriou",
        "Ilias Leontiadis",
        "Andrea Cavallaro",
        "Hamed Haddadi"
      ],
      "year": "2020",
      "venue": "Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services"
    },
    {
      "citation_id": "9",
      "title": "Honest-but-curious nets: Sensitive attributes of private inputs can be secretly coded into the classifiers' outputs",
      "authors": [
        "Mohammad Malekzadeh",
        "Anastasia Borovykh",
        "Deniz G√ºnd√ºz"
      ],
      "year": "2021",
      "venue": "Proceedings of ACM SIGSAC Conference on Computer and Communications Security"
    },
    {
      "citation_id": "10",
      "title": "Scene privacy protection",
      "authors": [
        "Chau Yi",
        "Ali Shahin Shamsabadi",
        "Ricardo Sanchez-Matilla",
        "Riccardo Mazzon",
        "Andrea Cavallaro"
      ],
      "year": "2019",
      "venue": "Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing"
    },
    {
      "citation_id": "11",
      "title": "Censoring representations with an adversary",
      "authors": [
        "Harrison Edwards",
        "Amos Storkey"
      ],
      "year": "2016",
      "venue": "Proceedings of International Conference in Learning Representations"
    },
    {
      "citation_id": "12",
      "title": "Learning to amend facial expression representation via de-albino and affinity",
      "authors": [
        "Jiawei Shi",
        "Songhao Zhu"
      ],
      "year": "2021",
      "venue": "Learning to amend facial expression representation via de-albino and affinity",
      "arxiv": "arXiv:2103.10189"
    },
    {
      "citation_id": "13",
      "title": "Reliable crowdsourcing and deep locality-preserving learning for unconstrained facial expression recognition",
      "authors": [
        "Shan Li",
        "Weihong Deng"
      ],
      "year": "2019",
      "venue": "IEEE Transactions on Image Processing"
    },
    {
      "citation_id": "14",
      "title": "Deep residual learning for image recognition",
      "authors": [
        "Kaiming He",
        "Xiangyu Zhang",
        "Shaoqing Ren",
        "Jian Sun"
      ],
      "year": "2016",
      "venue": "Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
    },
    {
      "citation_id": "15",
      "title": "Real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network",
      "authors": [
        "Wenzhe Shi",
        "Jose Caballero",
        "Ferenc Husz√°r",
        "Johannes Totz",
        "Andrew Aitken",
        "Rob Bishop",
        "Daniel Rueckert",
        "Zehan Wang"
      ],
      "year": "2016",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition"
    }
  ]
}