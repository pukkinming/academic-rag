{
  "paper_id": "2102.07127v1",
  "title": "Affective State Recognition Through Eeg Signals Feature Level Fusion And Ensemble Classifier",
  "published": "2021-02-14T10:56:08Z",
  "authors": [
    "Md. Mahbubur Rahman",
    "Akash Poddar",
    "Md. Golam Rabiul Alam",
    "Samrat Kumar Dey"
  ],
  "keywords": [
    "Emotion Recognition",
    "EEG",
    "Classifier",
    "Feature Fusion"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Human affects are complex paradox and an active research domain in affective computing. Affects are traditionally determined through a self-report based psychometric questionnaire or through facial expression recognition. However, few state-of-the-arts pieces of research have shown the possibilities of recognizing human affects from psychophysiological and neurological signals. In this article, electroencephalogram (EEG) signals are used to recognize human affects. The electroencephalogram (EEG) of 100 participants are collected where they are given to watch one-minute video stimuli to induce different affective states. The videos with emotional tags have a variety range of affects including happy, sad, disgust, and peaceful. The experimental stimuli are collected and analyzed intensively. The interrelationship between the EEG signal frequencies and the ratings given by the participants are taken into consideration for classifying affective states. Advanced feature extraction techniques are applied along with the statistical features to prepare a fused feature vector of affective state recognition. Factor analysis methods are also applied to select discriminative features. Finally, several popular supervised machine learning classifier is applied to recognize different affective states from the discriminative feature vector. Based on the experiment, the designed random forest classifier produces 89.06% accuracy in classifying four basic affective states.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Introduction",
      "text": "Affective state or human emotion is a mental state linked to the nervous system. Therefore, analyzing signals from human nervous systems would be the source of affective state recognition. The electroencephalogram (EEG) produces the activity signals of the brain which is the central part of the human nervous system. All these signals are called brain waves and can be distinguished by the features they carry.\n\nThus the brain waves carry characteristics of the emotion and the emotional state of the brain or human can be identified by analyzing the brain wave. Identification of emotion using brain waves can be utilized for different purposes. In medical science, this can be used to mine moods for detecting bipolar disorders. In the industrial sector, the level of job satisfaction of the workers can be measured by analyzing their affective state. There had been much research in the field of emotion detection using facial expression recognition.\n\nYet, true emotion may not be extracted from artificial or fake facial expressions. Some of the earlier researches [1]  [2]  utilized 32 channel EEG and other peripheral sensors to detect emotion. However, those lab experiments with too many sensors are not suitable for real-time usage. Conversely, in the proposed emotion detection system we utilized two channels EEG for collecting brain waves. The system can be used in real-time environment and very easy to operate. Human emotions create physiological signals which are generated from the brain. These are incorporated with thoughts, feelings, behavioural responses, and a degree of pleasure or displeasure  [3] . The emotions of ours can impel us to take action and dominate the decisions in lives. Emotion can be referred as joy, anger, disgust, sadness, fear and surprise of human feelings. In other words, Emotion recognition is a method used to use hi-tech image processing tools to read the emotions on a human face. Human-computer interaction (HCI) is computer technology, focused on the interfaces between humans and computers. There are different approaches of extensive scales of emotion, such like: Plutichik's emotion wheel  [4] , valence-arousal scale by Russell et al.,  [5] . According to this process, each emotional state can be plotted into a two-dimensional plane where horizontal and vertical axes represent arousal and valence respectively. This system requires distinct features to be plotted in the plane. There are many brain signals emitted from the brain and only very few are utilized in the abovestated system. In our proposed system, total of seven types of signals are extracted from the device.\n\nHowever, not all the signals carry distinct characteristics those can be analysed and the better system can be brought into the light. There had been many challenges that research team faced in different stages of this research. One of the major challenge is a noise-free lab environment to get a strong dataset. For the data collection, a noise-free lab environment was not available. There are only two channels in the device to read the brain waves. This fact is a limitation for this experiment as other devices got a number of brain wave reading channels. However, it is otherwise a requirement of the research as this fact makes this methodology more acceptable in the industrial utilization of the workers. The objectives of this research are to recognize real-time emotions from two-channel EEG brain waves by extracting advanced and discriminative EEG features for differentiating affective states. Also, to perform feature level fusion of statistical features and advanced EEG features for the vast discriminative feature vector generation by applying factor analysis methods for selecting discriminative features, and finally, to design a multiple supervised learning classifier to classify affective states efficiently.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Relevant Work",
      "text": "",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Methodology",
      "text": "The system model of the proposed affective state recognition framework is presented in Figure  1 . This section discussed the detail methodology of the proposed system.    1 .",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Data Pre-Processing",
      "text": "After the completion of data collection, the next step that have been followed is pre-processing the data.\n\nData rescaling is an important part of data preparation before applying machine-learning algorithms. It enhance the result and reduces unnecessary data. Therefore, the steps followed by the research group is selection of significant features, reduction of overfitting data, and normalization. In this step of selection of significant features, we have basically reduced the feature size for our experiment. The features which\n\nshows significance with the research objectives, we have kept those for detail investigation. Out of initial 12 features, we have observed the relevance of eight (  8 ) features (delta, theta, alphaLow, alphaHigh, betaLow, betaHigh, gammaLow, gammaMid). As such, data size dimension has reduced to (row x column)\n\n= 24000 x 8 = 192000 values. In the step of reduction of over fitting data, we have removed the unnecessary data that were identified as irrelevant bases on their values. Moreover, our data may contain attributes with a mixture of scales for various quantities. Since, many machine-learning methods are more effective if the data attributes have the same scale therefore, we have also utilized data normalization process. Here, due to normalization, all the values are set in between 0 and 1, and the outliers are also removed as well. All our features are more consistent with each other, which will allow us to evaluate the output of our future models more efficiently.",
      "page_start": 8,
      "page_end": 9
    },
    {
      "section_name": "Feature Extraction",
      "text": "After the following statistical feature applied to the dataset, total number of features stands 8 (raw features) The arithmetic mean is the average of the values located within a time window. The median is the middle value when a data set is ordered from least to greatest. Following Equation (1) represents the distortion or asymmetry in a symmetrical bell curve, or normal distribution, in a set of data.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "ùëÜùëòùëíùë§ùëõùëíùë†ùë† = ùê∏[",
      "text": "(ùë•-ùúá) 3",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "ùúé ]‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶. (1)",
      "text": "There is a skew of zero in a normal distribution, while, for example, a lognormal distribution would show some degree of right skew.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "ùêæ(ùë†) = ùê∏(ùë†",
      "text": "",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶. (5)",
      "text": "This study group has added parts of the signal product to get Wigner distributed multiplied at some point at a certain point at a certain time by the signal, since past was equal to future. Therefore, we mentally fold the left part of the signal to the right and check whether if there are a simultaneous overlaps for determining Wigner distribution properties. If there is, then at the time t, those properties will now be present. Wigner-Ville distribution (WVD) compared the information of the signal with its own information at other times and frequencies. For the frequency domain, Wigner distribution in both domains is essentially identical.\n\nAnother significant point is that the distribution of Wigner is equally weighing the distant times to the close moments. The distribution of Wigner is therefore extremely non local.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Feature Selection",
      "text": "XGBoost is an optimized library for distributed gradient boosting, designed to be extremely powerful, scalable and portable. Under the Gradient Boosting paradigm, it applies machine-learning algorithms.\n\nXGBoost offers a parallel tree boost (also known as GBDT, GBM) that easily and reliably addresses several data science issues. The mRMR is an approach to feature selection that aims to pick characteristics with a high class (output) correlation and a low correlation between themselves. The F-statistic can be used for continuous characteristics to calculate the class correlation (relevance) and the Pearson correlation coefficient can be used to calculate the correlation between characteristics (redundancy). After that, by applying a greedy search to maximize the objective function, which is a function of importance and redundancy, features are chosen one by one. MID (Mutual Information Difference criterion) and MIQ (Mutual Information Quotient criterion) representing the difference or the significance and redundancy quotient, respectively, are two widely used forms of the objective function. For temporal data, some pre-processing techniques are needed for the mRMR feature selection approach to flatten temporal data into a single matrix in advance. This may contribute to the loss of potentially valuable information in temporal data (such as temporal order information). Figure  3  and Figure  4  highlights the statistical feature selection and advanced feature selection after applying XGBoost feature section approach.",
      "page_start": 10,
      "page_end": 11
    },
    {
      "section_name": "Dimensionality Reduction",
      "text": "After applying the Principle Component Analysis (PCA), it is found to have 98% of the variance just applying only 20+ statistical features and similarly 98% variance can also be achieved by applying 10+ advanced features. Linear Discriminant Analysis (LDA) is another approach that follows the supervised learning based dimensionality reduction technique. In LDA, it is assumed that the input data follows a\n\nGaussian distribution otherwise; it may possibly lead to poor classification results. We have achieved the is another approach that is basically a non-linear dimensionality reduction technique which is typically used to visualize high dimensional datasets. In t-SNE, a Gaussian distribution is used to model the higher dimensional space, while a Student's t-distribution is used to model the lower-dimensional space. This approach is also carried out in this research to avoid an imbalance in the neighbouring points distance distribution caused by the translation into a lower-dimensional space. SNE starts by converting the highdimensional Euclidean distances between data points into conditional probabilities that represent similarities. Moreover, it is extremely imperative in capturing both the local and global structure of the highly dimensional data. Instead of looking at directions/axes which maximize information or class separation, t-SNE converts the Euclidean distances between points into conditional probabilities. A studentt distribution is then used on these probabilities which serve as metrics to calculate the similarity between one data points to another.",
      "page_start": 12,
      "page_end": 13
    },
    {
      "section_name": "Model Specification",
      "text": "Several supervised classification models have been applied to detect affective states. However, the random forest outperforms the XGboost, Na√Øve Bayes (NB), Gradient boosting classifier, and Multi-layer perceptron.",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "Random Forest",
      "text": "Random forest is a decision tree based classifier with large numbers of decision trees are used as the classifiers. Each and every trees are constructed from bootstrapped dataset. The majority voting is applied as the ensemble mechanism to decide the final class.\n\nThe GINI impurity (G) is used to determine best splitting criteria (Equation  6 ).",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "Performance Evaluation",
      "text": "The overall study of emotion recognition and its features can be illustrated through the Figure  1 . In statistical feature, we have applied XGB Classifier, Ridge Classifier CV, Ada Boost Classifier, Random Forest Classifier, SGD Classifier, Gaussian NB, Perceptron and others on unscaled statistical feature dataset. However, since none of them could produce accuracy to the expected level therefore we only mention the details about the best five (5) algorithms for our case (Table  2 ). In advanced feature (Table  3 ), we have applied on unscaled advanced feature dataset. However, since none of them could produce accuracy to the expected level therefore we only mention the details about the best five (5) algorithms for our case.  After combining both the statistical and advanced features, we have designed the Table  5 . As discussed earlier that we have applied XGBoost and mRMR on advanced and statistical feature dataset for data selection. The mentioned two techniques would select the features that have impact on emotion accuracy and neglect the excess features. We combined those selected features of advanced and statistical dataset and applied machine-learning algorithm on them. For all the cases, epoch is 10,000. Earlier we have applied the machine-learning algorithm on combined dataset of advanced and statistical features and found accuracy more than 86%. Now applied the machine learning algorithms on the dataset of selected features from both the dataset, and we achieved accuracy more than 86%. Therefore, it is quite evident that by using the selected features only, we can achieve the same accuracy, which means that by using lesser features in lesser time we may achieve the expected accuracy. In the same way, we have also applied the above mentioned classifiers and others on unscaled advanced and statistical combined selected feature dataset.\n\nSince, all of them could not produce accuracy to the expected level therefore we only mention the details about the finest Four (4) algorithms for our case. We have selected features from fusion of statistical and advanced feature using mRMR. From PCA, we observe that around 30 features are required to achieve 100% variance. However the case is little different in advanced feature dataset where the numbers of accurately identified cases have reduced to some extent due to lesser contribution of advanced feature to the system. However, the scenario will change when there is fusion in advanced and statistical features. A Receiver Operator Characteristic (ROC) curve is a graphical plot used to show the diagnostic ability of binary classifiers. The ROC curves in statistical dataset show that the curve are in the top-left corner which implies the better performance of the dataset. However the ROC curves in advanced feature dataset were not as satisfactory as of statistical features. There are fluctuations from gross accuracy and could not help to produce fine area under the curve. When the advanced and statistical features are fused together in the ROC curve, they produce performance better than those of advanced features (Figure  7 ).",
      "page_start": 14,
      "page_end": 15
    },
    {
      "section_name": "Conclusion",
      "text": "The versatility and complex human nature have made the human affective state recognition as a challenging problem in affective computing domain. However, this research used two channel EEG brain waves for real-time recognition of human affects. The EEG signal is collected from 100 participants where 15 video stimuli of different affects are used. The fusion of advanced and statistical features are used to train the affective state recognition system. The strategy of feature level fusion enhanced the accuracy level and finally reached to 89.66%. This accuracy level is more than the depth feature based emotion recognition approach of 87.5% accuracy. It is also better than radio frequency based emotion analyser (72%) and SVM based emotion classifier (82.9%). As the affect recognition is increasingly used in different kinds of games and virtual reality so the proposed affective state recognition system could be used to give players more natural control over their social avatars.",
      "page_start": 16,
      "page_end": 16
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: The system model of the proposed affective state recognition framework",
      "page": 6
    },
    {
      "caption": "Figure 2: Based on linear regression method, arousal and valence in each movies",
      "page": 6
    },
    {
      "caption": "Figure 2: Arousal Valence Scale of Emotion",
      "page": 7
    },
    {
      "caption": "Figure 3: and Figure 4 highlights the statistical feature selection",
      "page": 11
    },
    {
      "caption": "Figure 3: Feature importance of statistical feature set through applying XGBoost feature selection method.",
      "page": 11
    },
    {
      "caption": "Figure 4: Feature importance of advanced EEG feature set through applying XGBoost feature selection method",
      "page": 11
    },
    {
      "caption": "Figure 5: after applying LDA in statistical features. t-distributed Stochastic Neighbour Embedding (t-SNE)",
      "page": 12
    },
    {
      "caption": "Figure 5: Dimensionality reduction through LDA applied on statistical features",
      "page": 12
    },
    {
      "caption": "Figure 6: K-Fold Cross Validation Technique",
      "page": 13
    },
    {
      "caption": "Figure 7: ROC curve of SAD, HAPPY, DISGUST and PEACEFULL affective states.",
      "page": 16
    }
  ],
  "tables": [
    {
      "caption": "Table 1: Table 1: Mind wave Channel Types",
      "data": [
        {
          "Brainwave Type": "Delta",
          "Frequency range": "0.1 Hz to 3 Hz",
          "Mental State and conditions": "Deep, dreamless sleep, non REM-sleep, unconscious"
        },
        {
          "Brainwave Type": "Theta",
          "Frequency range": "4 Hz to 7 Hz",
          "Mental State and conditions": "Intuitive, creative, recall, fantasy, imaginary, dream"
        },
        {
          "Brainwave Type": "Alpha",
          "Frequency range": "8 Hz to 12 Hz",
          "Mental State and conditions": "Relaxed (but not drowsy) tranquil, conscious"
        },
        {
          "Brainwave Type": "Low Beta",
          "Frequency range": "12 Hz to 15 Hz",
          "Mental State and conditions": "Formerly SMR, relaxed yet focused, integrated"
        },
        {
          "Brainwave Type": "Midrange Beta",
          "Frequency range": "16 Hz to 20 Hz",
          "Mental State and conditions": "Thinking , aware of self & surroundings"
        },
        {
          "Brainwave Type": "High Beta",
          "Frequency range": "21 Hz to 30 Hz",
          "Mental State and conditions": "Alertness, agitation"
        }
      ],
      "page": 7
    },
    {
      "caption": "Table 2: Training and testing accuracy of different classifiers applied on statistical features of EEG",
      "data": [
        {
          "MLA Name": "XGB Classifier",
          "MLA Train Accuracy (%)": "100.00",
          "MLA Test Accuracy (%)": "86.21"
        },
        {
          "MLA Name": "Ridge Classifier CV",
          "MLA Train Accuracy (%)": "94.12",
          "MLA Test Accuracy (%)": "79.31"
        },
        {
          "MLA Name": "Extra Tress Classifier",
          "MLA Train Accuracy (%)": "100.00",
          "MLA Test Accuracy (%)": "75.86"
        },
        {
          "MLA Name": "Linear SVC",
          "MLA Train Accuracy (%)": "78.82",
          "MLA Test Accuracy (%)": "72.41"
        },
        {
          "MLA Name": "Decision Tree Classifier",
          "MLA Train Accuracy (%)": "100.00",
          "MLA Test Accuracy (%)": "65.51"
        }
      ],
      "page": 14
    },
    {
      "caption": "Table 2: Training and testing accuracy of different classifiers applied on statistical features of EEG",
      "data": [
        {
          "M\nLA Name": "AdaBoost Classifier",
          "MLA Train Accuracy (%)": "52.56",
          "MLA Test Accuracy (%)": "85.19"
        },
        {
          "M\nLA Name": "GaussianNB",
          "MLA Train Accuracy (%)": "69.23",
          "MLA Test Accuracy (%)": "77.78"
        },
        {
          "M\nLA Name": "Decision Tree Classifier",
          "MLA Train Accuracy (%)": "100.00",
          "MLA Test Accuracy (%)": "74.07"
        },
        {
          "M\nLA Name": "SGDC Classifier",
          "MLA Train Accuracy (%)": "65.38",
          "MLA Test Accuracy (%)": "66.67"
        },
        {
          "M\nLA Name": "XGB Classifier",
          "MLA Train Accuracy (%)": "100.00",
          "MLA Test Accuracy (%)": "66.67"
        }
      ],
      "page": 14
    },
    {
      "caption": "Table 2: Training and testing accuracy of different classifiers applied on statistical features of EEG",
      "data": [
        {
          "MLA Name": "Extra \nTrees \nClassifier",
          "Precision \n(Macro) \n(%)": "75.8929",
          "Precision \n(Micro) \n(%)": "75.8621",
          "Precision \n(Weighted) \n(%)": "86.4532",
          "Recall \n(Macro) \n(%)": "81.4286",
          "Recall \n(Micro) \n(%)": "75.8621",
          "Recall \n(Weighted) \n(%)": "75.8621",
          "F1-score \n(Macro) \n(%)": "73.0769",
          "F1-score \n(Micro) \n(%)": "75.8621",
          "F1-score \n(Weighted) \n(%)": "75.9861"
        },
        {
          "MLA Name": "XGB \nClassifier",
          "Precision \n(Macro) \n(%)": "68.75",
          "Precision \n(Micro) \n(%)": "72.4138",
          "Precision \n(Weighted) \n(%)": "87.069",
          "Recall \n(Macro) \n(%)": "58.9286",
          "Recall \n(Micro) \n(%)": "72.4138",
          "Recall \n(Weighted) \n(%)": "72.4138",
          "F1-score \n(Macro) \n(%)": "62.8105",
          "F1-score \n(Micro) \n(%)": "72.4138",
          "F1-score \n(Weighted) \n(%)": "78.3593"
        },
        {
          "MLA Name": "Bagging \nClassifier",
          "Precision \n(Macro) \n(%)": "70.00",
          "Precision \n(Micro) \n(%)": "72.4138",
          "Precision \n(Weighted) \n(%)": "83.3333",
          "Recall \n(Macro) \n(%)": "67.8571",
          "Recall \n(Micro) \n(%)": "72.4138",
          "Recall \n(Weighted) \n(%)": "72.4138",
          "F1-score \n(Macro) \n(%)": "66.069",
          "F1-score \n(Micro) \n(%)": "72.4138",
          "F1-score \n(Weighted) \n(%)": "76.2756"
        }
      ],
      "page": 14
    },
    {
      "caption": "Table 5: Table 5: Training and testing accuracy of different classifiers applied on fused advanced and statistical",
      "data": [
        {
          "MLA Name": "Random Forest Classifier",
          "MLA Train Accuracy (%)": "100.00",
          "MLA Test Accuracy (%)": "89.66"
        },
        {
          "MLA Name": "XGB Classifier",
          "MLA Train Accuracy (%)": "100.00",
          "MLA Test Accuracy (%)": "86.21"
        },
        {
          "MLA Name": "Gradient Boosting Classifier",
          "MLA Train Accuracy (%)": "100.00",
          "MLA Test Accuracy (%)": "82.76"
        },
        {
          "MLA Name": "Perceptron",
          "MLA Train Accuracy (%)": "59.77",
          "MLA Test Accuracy (%)": "79.31"
        },
        {
          "MLA Name": "Gaussian NB",
          "MLA Train Accuracy (%)": "71.26",
          "MLA Test Accuracy (%)": "79.31"
        }
      ],
      "page": 15
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Emotion Recognition from EEG Signals Using Multidimensional Information in EMD Domain",
      "year": "2021",
      "venue": "Emotion Recognition from EEG Signals Using Multidimensional Information in EMD Domain"
    },
    {
      "citation_id": "2",
      "title": "DEAP: A Database for Emotion Analysis ;Using Physiological Signals",
      "authors": [
        "S Koelstra",
        "C Muhl",
        "M Soleymani",
        "J Lee",
        "A Yazdani",
        "T Ebrahimi",
        "T Pun",
        "A Nijholt",
        "I Patras"
      ],
      "year": "2012",
      "venue": "IEEE Transactions on Affective Computing",
      "doi": "10.1109/T-AFFC.2011.15"
    },
    {
      "citation_id": "3",
      "title": "Emotion in the perspective of an integrated nervous system1Published on the World Wide Web on 27",
      "authors": [
        "A Damasio"
      ],
      "year": "1998",
      "venue": "Brain Research Reviews",
      "doi": "10.1016/S0165-0173(97)00064-7"
    },
    {
      "citation_id": "4",
      "title": "The Nature of Emotions: Human emotions have deep evolutionary roots, a fact that may explain their complexity and provide tools for clinical practice",
      "authors": [
        "R Plutchik"
      ],
      "year": "2001",
      "venue": "American Scientist"
    },
    {
      "citation_id": "5",
      "title": "The circumplex model of affect: An integrative approach to affective neuroscience, cognitive development, and psychopathology",
      "authors": [
        "J Posner",
        "J Russell",
        "B Peterson"
      ],
      "year": "2005",
      "venue": "Development and Psychopathology",
      "doi": "10.1017/S0954579405050340"
    },
    {
      "citation_id": "6",
      "title": "Facial Expression Recognition Using Visual Saliency and Deep Learning",
      "authors": [
        "V Mavani",
        "S Raman",
        "K Miyapuram"
      ],
      "year": "2017",
      "venue": "2017 IEEE International Conference on Computer Vision Workshops (ICCVW)",
      "doi": "10.1109/ICCVW.2017.327"
    },
    {
      "citation_id": "7",
      "title": "Human emotion recognition using deep belief network architecture, Information Fusion",
      "authors": [
        "M Hassan",
        "Md Alam",
        "Md Uddin",
        "S Huda",
        "A Almogren",
        "G Fortino"
      ],
      "year": "2019",
      "venue": "Human emotion recognition using deep belief network architecture, Information Fusion",
      "doi": "10.1016/j.inffus.2018.10.009"
    },
    {
      "citation_id": "8",
      "title": "Using deep and convolutional neural networks for accurate emotion classification on DEAP dataset",
      "authors": [
        "S Tripathi",
        "S Acharya",
        "R Sharma",
        "S Mittal",
        "S Bhattacharya"
      ],
      "year": "2017",
      "venue": "Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence"
    },
    {
      "citation_id": "9",
      "title": "Healthcare IoT-Based Affective State Mining Using a Deep Convolutional Neural Network",
      "authors": [
        "M Alam",
        "S Abedin",
        "S Moon",
        "A Talukder",
        "C Hong"
      ],
      "year": "2019",
      "venue": "IEEE Access",
      "doi": "10.1109/ACCESS.2019.2919995"
    },
    {
      "citation_id": "10",
      "title": "Wavelet-based emotion recognition system using EEG signal | SpringerLink",
      "year": "2021",
      "venue": "Wavelet-based emotion recognition system using EEG signal | SpringerLink",
      "doi": "10.1007/s00521-015-2149-8"
    },
    {
      "citation_id": "11",
      "title": "Emotion Recognition Using Physiological Signals: Laboratory vs",
      "authors": [
        "M Ragot",
        "N Martin",
        "S Em",
        "N Pallamin",
        "J.-M Diverrez"
      ],
      "year": "2018",
      "venue": "Advances in Human Factors in Wearable Technologies and Game Design",
      "doi": "10.1007/978-3-319-60639-2_2"
    },
    {
      "citation_id": "12",
      "title": "Emotion Recognition from EEG Signals Using Multidimensional Information in EMD Domain",
      "authors": [
        "N Zhuang",
        "Y Zeng",
        "L Tong",
        "C Zhang",
        "H Zhang",
        "B Yan"
      ],
      "year": "2017",
      "venue": "BioMed Research International",
      "doi": "10.1155/2017/8317357"
    },
    {
      "citation_id": "13",
      "title": "Task Learning Framework for Emotion Recognition Using 2D Continuous Space",
      "authors": [
        "R Xia",
        "Y Liu",
        "Multi"
      ],
      "year": "2017",
      "venue": "IEEE Transactions on Affective Computing",
      "doi": "10.1109/TAFFC.2015.2512598"
    },
    {
      "citation_id": "14",
      "title": "Emotion Recognition from Multiband EEG Signals Using CapsNet",
      "authors": [
        "H Chao",
        "L Dong",
        "Y Liu",
        "B Lu"
      ],
      "year": "2019",
      "venue": "Sensors",
      "doi": "10.3390/s19092212"
    },
    {
      "citation_id": "15",
      "title": "Internal Emotion Classification Using EEG Signal With Sparse Discriminative Ensemble",
      "authors": [
        "H Ullah",
        "M Uzair",
        "A Mahmood",
        "M Ullah",
        "S Khan",
        "F Cheikh"
      ],
      "year": "2019",
      "venue": "Internal Emotion Classification Using EEG Signal With Sparse Discriminative Ensemble",
      "doi": "10.1109/ACCESS.2019.2904400"
    },
    {
      "citation_id": "16",
      "title": "Multimodal Multi-task Learning for Dimensional and Continuous Emotion Recognition",
      "authors": [
        "S Chen",
        "Q Jin",
        "J Zhao",
        "S Wang"
      ],
      "year": "2017",
      "venue": "Proceedings of the 7th Annual Workshop on Audio/Visual Emotion Challenge",
      "doi": "10.1145/3133944.3133949"
    },
    {
      "citation_id": "17",
      "title": "Human Emotion Recognition with Electroencephalographic Multidimensional Features by Hybrid Deep Neural Networks",
      "authors": [
        "Y Li",
        "J Huang",
        "H Zhou",
        "N Zhong"
      ],
      "year": "2017",
      "venue": "Applied Sciences",
      "doi": "10.3390/app7101060"
    }
  ]
}