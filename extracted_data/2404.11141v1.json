{
  "paper_id": "2404.11141v1",
  "title": "Context-Aware Siamese Networks For Efficient Emotion Recognition In Conversation",
  "published": "2024-04-17T07:36:40Z",
  "authors": [
    "Barbara Gendron",
    "Gaël Guibon"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "The advent of deep learning models has made a considerable contribution to the achievement of Emotion Recognition in Conversation (ERC). However, this task still remains an important challenge due to the plurality and subjectivity of human emotions. Previous work on ERC provides predictive models using mostly graph-based conversation representations. In this work, we propose a way to model the conversational context that we incorporate into a metric learning training strategy, with a two-step process. This allows us to perform ERC in a flexible classification scenario and to end up with a lightweight yet efficient model. Using metric learning through a Siamese Network architecture, we achieve 57.71 in macro F1 score for emotion classification in conversation on DailyDialog dataset, which outperforms the related work. This state-of-the-art result is promising regarding the use of metric learning for emotion recognition, yet perfectible compared to the microF1 score obtained.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Computer Mediated Communication (CMC) is constantly evolving and new means of communicating are emerging. With the advent of conversational agents, there is a need to detect emotions within a conversation. Although many modalities are now considered in the communication process, the textual modality still remains essential for fast and easy everyday communication, through messaging applications, social media, and other networking platforms. Textual modality, however, is ambiguous, it does not preserve the extra-linguistic context, especially for dyadic human-to-human conversations. One main ambiguity that arises in CMC is the emotional state of the speaker, often misinterpreted by humans through short, and unpolished messages. This motivates Emotion Recognition in Conversation (ERC), a trending research topic dedicated not only to identifying emotion in messages, but also on taking into account the conversational context to recognize emotions. ERC has been shown to be challenging, especially with respect to the way to represent the context  (Ghosal et al., 2021) . Lately, it has seen a surge of multimodal models and graph-related approaches which often try to map the pattern of each speaker and better represent the conversational context, often resulting in good performance at the cost of efficiency. One additional issue ERC models are facing is their dependency on labels, models are mainly supervised and face the issue of extreme label imbalance due to emotional utterances being so scarce.\n\nIn this paper, we tackle these two challenges by incorporating the conversational context into metric learning, while heavily controlling the data imbalance by multiple means. Considering that we want to tackle information across emotions to make our model usable for variant of emotions that goes beyond the scope of the 6 basic emotions, we do not use supervised contrastive learning  (Khosla et al., 2020)  in our method. Instead, we focus on a twostep process to update the model both using direct label predictions through a Cross entropy loss, and relative label assignment through the contrastive loss. This two-step process is quite straight forward while using isolated elements, such as isolated utterances. However, as far as we know, the contextual representation through contrastive learning for ERC has yet to be used. This represents our main contribution in this paper as we present a model that can achieve competitive performance compared to the state of the art while rendering the adaptation to other emotion labels feasible. Thus, our model can be applied and adapted in multiple contexts requiring emotion recognition of different label granularities.\n\nOur main contribution lies in the development of a metric-learning training strategy for emotion recognition on utterances using the conversational context. The presented model leverages sentence embeddings and Transformer encoder layers  (Vaswani et al., 2017; Devlin et al., 2019)  to represent dialogue utterances and deploy attention on the conversational context. Our method involves Siamese Networks  (Koch et al., 2015)  in the setup but can be adapted to any metric-learning model. We further demonstrate that our approach outperforms some of the latest state-of-the-art Large Lan-guage Models (LLMs) such as light versions of Falcon or LLaMA 2  (Touvron et al., 2023) . In addition, our method is efficient in the sense that it involves lightweight, adaptable and quickly trainable models, which still yield state-of-the-art performance on DailyDialog in macroF1 score with 57.71% and satisfactory results on microF1 with 57.75%.\n\nIn the following sections, we first review related work on ERC (Section 2). We then dive in our methodology (Section 3) and describe the experimental setup we use (Section 4). We then evaluate our models compared to a baseline without any conversational context and to SotA models for ERC in Section 5. Finally, we end up with key findings and perspectives for future work in section 6.\n\nWe will make our code and models available on github and Hugging Face models hub.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Related Work",
      "text": "ERC. Although most of the studies on ERC has been held on multi-modal datasets  (Song et al., 2022; Li et al., 2022; Hu et al., 2022) , thus leveraging multi-modality, there are still some models developed for emotion recognition on textual conversation only, whether it be on multi-modal datasets restricted to text such as IEMOCAP  (Busso et al., 2008)  or MELD  (Poria et al., 2019) , or on fully textual dataset such as DailyDialog  (Li et al., 2017) . The advent of deep learning enables significant progress in ERC on text, starting by the use of Recurrent Neural Networks (RNN)  (Rumelhart et al., 1985; Jordan, 1986)  by  Poria et al. (2017) . Further work using recurring structures followed, such as DialogueRNN  (Majumder et al., 2019; Ghosal et al., 2020) . This model leverages the attention mechanism  (Bahdanau et al., 2014)  encountered in Transformer architecture  (Vaswani et al., 2017) . Graphbased methods also proved efficient as shown in  (Ghosal et al., 2019) , not only as such but also when considering external knowledge, as  Lee and Choi (2021)  use a graph convolutional network (GCN) to perform ERC by extracting relations between dialogue instances.\n\nExisting work on ERC relies mainly on evaluating their model using micro F1 score excluding the majority neutral label. However, recent work actually skipped this evaluation to instead only focus on the macro version of this metric  (Pereira et al., 2023) , while other considered the Matthew Coefficient Correlation as an indication suitable for this task  (Guibon et al., 2021) .\n\nIn this work, we focus on DailyDialog, which consists in artificially human-generated conversations about daily life concerns, with utterance-wise emotion labelling.  Liang et al. (2022)  propose a model based on Graph Neural Networks (GNN) and CRF that achieves 64.01% in micro F1.\n\nAlthough it is known not to provide the best performance compared to few-shot learning approaches  (Dumoulin et al., 2021) , meta-learning allows better generalization through a more robust training  (Finn et al., 2017; Antoniou et al., 2019) , which is particularly adapted in the case of emotion detection due to both variability and complexity of human feelings  (Plutchik, 2001) .\n\nMetric learning. As reviewed by  (Hospedales et al., 2022) , a meta-learning approach consists in a meta-optimizer that describes meta-learner updates, a meta-representation that stores the acquired knowledge and the meta-objective oriented towards the desired task. This optimization-based meta-learning setup provides end-to-end algorithms often based on episodic scenarios  (Ravi and Larochelle, 2016; Finn et al., 2017; Mishra et al., 2017)  that reflect the \"learning to learn\" strategy. Besides, learning to learn implies second order gradient computations which is costly. Palliative solutions to this problem, such as implicit differentiation  (Lorraine et al., 2020) , still involve a trade-off between performance and memory cost  (Hospedales et al., 2022) . Therefore, variants has emerged such as metric learning, which meta-objective is the meta-representation learning itself. Starting with Siamese Networks  (Koch et al., 2015) , this model structure leverages parameter sharing between identical sub-networks to learn a distance between data samples. Relation Networks  (Sung et al., 2018 ) also consider a distance metric, departing from the traditional Euclidean approach. Matching Networks  (Vinyals et al., 2016)  leverage training examples to identify weighted nearest neighbors. Prototypical Networks  (Snell et al., 2017)  compute average class representations and utilize cosine distance for element comparison. This model has been adapted to perform ERC in a few-shot setting by  (Guibon et al., 2021)  in a way that outperformed few-shot learning baselines.\n\nIn this work, we focus on Siamese Network architecture. It has the advantage to be conceptually simple, rendering it easily controllable and scalable. Nevertheless, the model structure proposed in this paper is easily adaptable to more complex metalearning setups. Siamese Networks have been used, for instance, in NLP for intention detection on text  (Ren and Xue, 2020) , in computer vision for facial recognition  (Hayale et al., 2023) , and in complex representation learning  (Jin et al., 2021) .",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Methodology",
      "text": "In this work, we use a metric-learning architecture based to learn emotions as they relate to each other, thus extracting meta-information from the data. The model is a Siamese network  (Koch et al., 2015)  with three identical sub-networks, whose outputs are compared using the triplet loss  (Schultz and Joachims, 2003) . Initially applied to computer vision problems  (Chechik et al., 2010; Schroff et al., 2015) , triplet loss is defined on a triplet of data samples (a, p, n) so that if a and p belong to the same class and n belongs to a different class, then:\n\nwhere the margin parameter is a strictly positive number. Given a triplet (A.P.N ) corresponding to respectively anchor. positive and negative. the positive sample should be closer to the anchor than the negative sample in order to minimize the triplet loss.\n\nWhile the triplet loss could be used in several strategies, ranging from only retrieving the most difficult triplets (when the positive is far from the anchor, meanwhile the anchor is close to the negative) to skipping the most easy ones (i.e. when the positive is closer to the anchor), we only tackle the overall strategy by considering each triplets in our data, due to the limited size of the data.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Isolated Representations.",
      "text": "As the aim of our experiments is to characterize the contribution of conversational context to emotion prediction, we first developed a baseline model on isolated utterances. This formally refers to computing emotion predictions for utterances independently of their context. To do this, we first consider a mapping for each utterance word to its associated FastText embedding  (Bojanowski et al., 2017) . From such embeddings, aforementioned (a, p, n) triplets are randomly sampled and given as input for the Siamese network, whose sub-network gradually improves in emotion prediction as triplet loss backpropagates.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Contextual Representations.",
      "text": "Regarding the contextual case, we build contextual utterance representations upon a BERT-like encoding. Sentence embeddings are preferred to word-piece embeddings (like BERT produces) as they provide lighter utterance representations. After the dialog is mapped to its associated series of pretrained embeddings, these outputs are concatenated forming a dialog representation, and contextual information is considered by deploying attention over it. Concretely, a Transformer encoder layer is stacked to the gathered frozen pre-trained embeddings. This newly conversation-aware dialog representation is then split at [SEP] tokens to end up with contextual representations at the utterance level, on which the emotion prediction is performed. In order to fit contextual utterance representations to the emotion prediction objective, we add an emotion classifier that is pre-trained on DailyDialog training set. The classifier is not frozen to ensure a complete backpropagation. Meanwhile, contextual representations are optimized according to the metric learning objective, using triplet loss. The whole is illustrated in figure  2 . This training scenario enables both individual and relative emotion learning, in such a way that each learning phase strengthens the other. Thanks to this meta-learning setting, meta-information about emotions is extracted, and we can expect that this model is able to achieve relevant classification on unseen labels in a few-shot setting.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Experimental Protocol",
      "text": "Data. All the experiments have been carried out on DailyDialog dataset  (Li et al., 2017 ) that provides more than 10,000 dialogues about daily concerns along with utterance-wise emotion labelling. In addition to providing utterance-level emotion labeling, an advantage in using DailyDialog is that it is relatively small, therefore it is quite easy to handle the entries and run tests on it. There exist six emotional labels (anger, disgust, fear, happiness, sadness and surprise) and a neutral label. Regarding emotion prediction, the evaluation is carried out only on the emotional labels following previous work procedure  (Ghosal et al., 2021; Zhong et al., 2019) . We use the original dataset splits (train, validation and test) from  (Li et al., 2017)   Training specificities. Whether it be for the isolated utterance model or for the contextual one, the emotion prediction is always performed at the utterance level, therefore the triplets are always utterance triplets. This involves balance issues as DailyDialog dataset is very imbalanced regarding emotion labels (Figure  4 ). Indeed, the class rebalancing induced by sampling triplets according to a uniform distribution does not sufficiently mitigate bias during training and prevents the loss from converging due to excessive oversampling in frequent classes. Thus, we addressed the imbalance problem all along the training pipeline, by implementing a random sampler weighted with inverse label frequencies to account for the rareness of some emotional labels like fear or disgust.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Evaluation.",
      "text": "For quantitative evaluation we needed to account for both performance and relevancy of the training procedure so that generalization abilities enabled by the meta-learning architec-1 https://www.sbert.net/ ture are actually usable. This way, we selected, in addition to usual performance metrics, a highly demanding metric: Matthews Correlation Coefficient (MCC)  (Cramér, 1946) . This measures a Pearson correlation  (Pearson, 1895)  between the predicted and the actual class, giving more precise information on classification quality than F1 score  (Baldi et al., 2000) . Using T P . T N . F P and F N as respectively the number of true positives, true negatives, false positives and false negatives, MCC was originally defined in  (Matthews, 1975)  as:\n\nComparison with LLMs. In order to place the results of our isolated and contextual models into perspective, we compare our models with state-ofthe-art LLMs, namely LlaMA  (Touvron et al., 2023)  and Falcon  (Penedo et al., 2023) . Both are considered with instruction fine-tuning and evaluated on text generation inference in a zero-shot setting. We developed a prompt asking for prediction on the last utterance of each DailyDialog test set dialog, regarding the conversational context. For both LLM, we went through an iterative process to find the most adapted prompt in the sense that the model actually generates only one label. The prompt is the same for each model of the same type (either Llama or Falcon). We experienced more difficulty on prompt tuning with Falcon as the model generates happiness on 86% of DailyDialog test set. Both prompts full texts are provided in Figure  3 .",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Results",
      "text": "Table  2  gives an overview of the different results obtained by the research community on ERC with DailyDialog. This actually shows a slow progression since 2017 where  Poria et al. (2017)  proposed",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Model Name Macrof1* Microf1* Mcc",
      "text": "State-of-the-art models on ERC CNN+cLSTM  (Poria et al., 2017)  -50.24 -KET  (Zhong et al., 2019)  -53.37 -COSMIC  (Ghosal et al., 2020)  51.05 58.48 -RoBERTa  (Ghosal et al., 2020)  48.20 55.16 -Rpe-RGAT  (Ishiwatari et al., 2020)  -54.31 -Glove-DRNN  (Ghosal et al., 2021)  41.8 55.95 -roBERTa-DRNN  (Ghosal et al., 2021) 49.65  57.32 -CNN  (Ghosal et al., 2021)  36.87 50.32 -DAG-ERC  (Shen et al., 2021)  -59.33 -TODKAT  (Zhu et al., 2021)  52.56 58.47 -SKAIG  (Li et al., 2021)  51.95 59.75 -Sentic GAT  (Tu et al., 2022)  -54.45 -CauAIN  (Zhao et al., 2022)  -58.21 -DialogueRole  (Ong et al., 2022)  -60.95 -S+PAGE  (Liang et al., 2022)  -64.07 -DualGAT  (Zhang et al., 2023)  -61.84 -CD-ERC  (Pereira et al., 2023)  51.23 --Llama2-7b  (Touvron et al., 2023)  9.70 24.92 0.08 Llama2-13b  (Touvron et al., 2023)  22.26 43.37 0.15 Falcon-7b  (Penedo et al., 2023)  07 to evaluate the model on the micro F1 score excluding the majority class (i.e. the neutral class). This became the first baseline for this task, achieving 50.24 in micro F1 score. On the other hand, the current SotA model now achieves 64.07 in micro F1 score  (Liang et al., 2022)  which amounts to a 14 points improvement during 6 years. As visible in Table  2 , the community mainly followed this pattern and evaluation scheme. However, in this paper we think it is important to also consider the macro F1 score, excluding the majority class, as it shows the overall performance on all emotions. Some work already decided to do so since 2020  (Ghosal et al., 2020) , leading to an improvement of 2.5 points in 3 years. This reinforces the claim that the ERC task is indeed challenging.\n\nCompared to these results, our SentEmoContext model achieves 57.75 in micro F1 score, which is a decent but somewhat modest result, in terms of metric comparison. However, Table 2 also shows the average performance of our model over 10 runs. Our SentEmoContext is SotA on the macro F1 score with 57.71 points, outperforming CD-ERC  (Pereira et al., 2023 ) by 6.48 points, which is considerable since they only focused on this metric, and TODKAT  (Zhu et al., 2021)  by 5.15 points. We also evaluate our model using the multiclass MCC  (Matthews, 1975; Baldi et al., 2000)  score in order to ensure the model is not deciding randomly. Given a MCC score ranges from -1 to 1, and 0 indicating randomness, the 0.49 MCC score of SentEmoContext model indicates our approach is both balanced and accurate in terms of predictions  (Chicco and Jurman, 2020) . Of course, we cannot compare to other ERC works with the MCC metric, as they did not used it. However, we think it is important to consider it as an additional metric to indicate the quality of the classification, minimizing the effect of the highly imbalanced data from conversations.\n\nGiven these results, our SentEmoContext performs really well considering we only need 20 minutes per epoch, and train it using only 5 epochs. This makes a striking difference with existing approaches using multiple streams per speaker  (Pereira et al., 2023) , graph modeling for context and knowledge representation  (Zhong et al., 2019; Li et al., 2021) , or other heavy representation in their model  (Liang et al., 2022) . In addition to this, our model is stable with a standard deviation of only 0.01 on average across the three metrics, which reinforces the quality of such an efficient approach.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Comparison With Emotion Classifiers On Utterance Level",
      "text": "Table  3  shows the results of direct emotion classification on utterances. For this task, we only considered the 6 emotion labels, excluding the neutral one not only from the evaluation, but also from the training. By doing so we want to determine the difference between our approach and a dedicated emotion classifier. This also serve as an ablation study for our SentEmoContext model since this step is part of its training. With Table  3 , we can see our model leverages both the embedded conversational context and the metric learning scheme to increase all metrics. We can especially note the difference in terms of macroF1 score, which shows the importance of the triplet loss representation in our model. Indeed, the emotion utterance classifiers are trained using batches balanced on the whole training set distribution and a weighted cross entropy loss. Results shows it is not enough to deal with an extreme imbalanced data such as conversations.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Llm-Related Limitations",
      "text": "LLMs results on a zero-shot setting are visible in Table  4 . These serves as an indication on the performance of such models, albeit in their lightweight version, in the ERC task. Even though these generative models are not designed for this quite pecu-liar task, they still manage to outperform utterance emotion classifiers from Table  3 , which can be considered as a display of emergent capacities from LLMs  (Srivastava et al., 2022) . While Table  1  shows the characteristics from the dataset, it omits to present the main characteristic from conversational data in terms of emotion labels: the extreme imbalance. Most of the difficulty from ERC comes from the label definition, the context but also from the imbalance factor that prevents the model from easily learning emotion representation in the context. Figure  4  shows the distribution of the labels in DailyDialog, without the neutral one. Considering the latter is the majority label and is excluded from the evaluation metrics by all the ERC community, the fact that even in the emotion labels the data is that imbalanced proves to be challenging and needs to be addressed. We actually stem from  Guibon et al. (2023)  to tackle the imbalance characteristic in two-steps. First, we balance the data loader to yield somewhat balanced batches given the training set weights. Second, we weight the cross entropy loss from the emotion classifier considering the remaining imbalance on each batch.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Imbalance Factor",
      "text": "In addition to this, in this paper we add another way to address the imbalance. By considering triplets we remove the imbalance factor while using hidden states that come from balanced representation. We think this partly explains the effectiveness and the efficiency of our model, considering its limited size compared to the related work.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Discussions & Limitations",
      "text": "The work we present in this paper still possesses some limitations. We hereby draw some conclusion from them.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Llms Limitations",
      "text": "The first limitation we faced with LLMs is the requirement of high memory GPUs to test them. This explains why in Table  4  we only consider the lightweight version of these two open source LLM. While Llama 7b and 13b gave answers in a good format, i.e. with only one label chosen, Falcon did not behave the way we wanted. In order to solve this, we look for the first mentioned emotion in the output to consider it as a label. Also, it is important to note that we did not want to tackle OpenAI's ChatGPT due to the fact that we do not have a clear control on the model version, size and approach used behind its API, but also because we wanted to consider open source models, and open source data as we will release both our models and source code to the community.\n\nAn additional possible limitation on LLMs is the context size. In ERC, context size is key but with LLMs adding examples in the prompt to do fewshot learning would take a lot of space in the overall context, the prompt being part of the context. This explains our decision to only consider zero-shot in this paper for LLMs, even though we should also consider prompt tuning to enhance them on this specific task.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Model Size And Efficiency",
      "text": "Our SentEmoContext is efficient. It yields state-ofthe-art results on macro F1 score and good results on microF1. But our model trains relatively fast and does not require a lot of epochs to converge. We think this efficiency along with the limited memory needed to train, is due to both our two-step backpropagation and to the fact that we are using utterance embedded representations with sentence transformers. Thus, our model can efficiently tackle long conversational contexts with a limited cost in memory.\n\nMoreover, Table  5  shows the difference between the models we used, in terms of size, parameters, and number of layers. Our model is relatively small considering the recent advances and related work in ERC, but also compared to LLMs.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Relative Label Representation",
      "text": "Our approach actually learn twice from the data, first by using a supervised setting, and then by actually considering the relative distances between encoded element, updating through the triplet loss. This enables the use of our model to different conversation datasets with different labels. The only requirement to extend the scope of this model would be to consider another triplet sampling strategy by ignoring the labels, such as the batch-hard strategy  (Do et al., 2019) .",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Conclusion",
      "text": "In this paper, we present our SentEmoContext model which comes from an approach mixing utterance level representation, metric learning and Siamese Networks. this model efficiently represent the conversational context, which makes it achieves state-of-the-art macroF1 score with 57.71, and satisfactory microF1 scores with 57.75 With SentEmoContext we use contrastive learning with balanced samplers to overcome to minimize the imbalance factor, which is inherent to conversational data. We also leverage sentence bert to both minimize the memory required for training considering the whole conversational context, and to actually represent the conversational context by considering utterances as the minimal unit. This led to a more robust and efficient training method that does not require a lot of epochs to obtain satisfactory results. We also show small to average size open source LLMs are still behind on emotion recognition in conversation as it requires a lot context to be incorporated in the prompt and is not specifically relevant to generative models.\n\nIn our future work, we want to consider applying this approach on other dataset, with added modalities in order to stress test our model. We also plan to use it on slightly different labels, as our model learns relative positions toward labels. Thus, we plan to adapt it to a more meta-learning setting.",
      "page_start": 9,
      "page_end": 9
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Illustration of the triplet loss principle.",
      "page": 3
    },
    {
      "caption": "Figure 2: This training scenario en-",
      "page": 3
    },
    {
      "caption": "Figure 2: Illustration of the three main steps of the training procedure in the case of conversation-aware",
      "page": 4
    },
    {
      "caption": "Figure 4: ). Indeed, the class re-",
      "page": 4
    },
    {
      "caption": "Figure 3: Prompts for llama and falcon",
      "page": 6
    },
    {
      "caption": "Figure 4: Histograms of only the emotion label",
      "page": 6
    },
    {
      "caption": "Figure 4: shows the",
      "page": 6
    }
  ],
  "tables": [
    {
      "caption": "Table 1: Daily Dialog Stats",
      "page": 3
    },
    {
      "caption": "Table 1: Main statistics for DailyDialog dataset",
      "page": 3
    },
    {
      "caption": "Table 2: gives an overview of the different results",
      "page": 4
    },
    {
      "caption": "Table 2: All results for ERC on DailyDialog. Metrics are all computed on the official test set. DRNN",
      "page": 5
    },
    {
      "caption": "Table 2: , the community mainly followed this pattern",
      "page": 5
    },
    {
      "caption": "Table 2: also shows",
      "page": 5
    },
    {
      "caption": "Table 3: shows the results of direct emotion classi-",
      "page": 6
    },
    {
      "caption": "Table 3: , we can see",
      "page": 6
    },
    {
      "caption": "Table 4: These serves as an indication on the per-",
      "page": 6
    },
    {
      "caption": "Table 3: , which can be con-",
      "page": 6
    },
    {
      "caption": "Table 1: shows the characteristics from the",
      "page": 6
    },
    {
      "caption": "Table 3: Comparison with a direct emotion classification at the utterance level. The all-MiniLM-L6-v2",
      "page": 7
    },
    {
      "caption": "Table 4: Results using two open-source LLMs with specific prompts. (An example of the prompt is given",
      "page": 7
    },
    {
      "caption": "Table 4: we only consider the",
      "page": 7
    },
    {
      "caption": "Table 5: shows the difference between",
      "page": 7
    },
    {
      "caption": "Table 5: Insights about model sizes, comparing the pretrained sentence Transformers used in our",
      "page": 8
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "How to train your maml",
      "authors": [
        "Bibliographical References",
        "Antreas Antoniou",
        "Harri Edwards",
        "Amos Storkey"
      ],
      "year": "2019",
      "venue": "Sev-enth International Conference on Learning Representations"
    },
    {
      "citation_id": "2",
      "title": "Neural machine translation by jointly learning to align and translate",
      "authors": [
        "Dzmitry Bahdanau",
        "Kyunghyun Cho",
        "Y Bengio"
      ],
      "year": "2014",
      "venue": "3rd International Conference on Learning Representations"
    },
    {
      "citation_id": "3",
      "title": "Assessing the accuracy of prediction algorithms for classification: An overview",
      "authors": [
        "Pierre Baldi",
        "Søren Brunak",
        "Yves Chauvin",
        "Claus Andersen",
        "Henrik Nielsen"
      ],
      "year": "2000",
      "venue": "Bioinformatics"
    },
    {
      "citation_id": "4",
      "title": "Enriching word vectors with subword information",
      "authors": [
        "Piotr Bojanowski",
        "Edouard Grave",
        "Armand Joulin",
        "Tomas Mikolov"
      ],
      "year": "2017",
      "venue": "Transactions of the Association for Computational Linguistics",
      "doi": "10.1162/tacl_a_00051"
    },
    {
      "citation_id": "5",
      "title": "Large scale online learning of image similarity through ranking",
      "authors": [
        "Gal Chechik",
        "Varun Sharma",
        "Uri Shalit",
        "Samy Bengio"
      ],
      "year": "2010",
      "venue": "J. Mach. Learn. Res"
    },
    {
      "citation_id": "6",
      "title": "The advantages of the matthews correlation coefficient (mcc) over f1 score and accuracy in binary classification evaluation",
      "authors": [
        "Davide Chicco",
        "Giuseppe Jurman"
      ],
      "year": "2020",
      "venue": "BMC genomics"
    },
    {
      "citation_id": "7",
      "title": "Mathematical Methods of Statistics (PMS-9)",
      "authors": [
        "Harald Cramér"
      ],
      "year": "1946",
      "venue": "Mathematical Methods of Statistics (PMS-9)",
      "doi": "10.1515/9781400883868"
    },
    {
      "citation_id": "8",
      "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "authors": [
        "Jacob Devlin",
        "Ming-Wei Chang",
        "Kenton Lee",
        "Kristina Toutanova"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
      "doi": "10.18653/v1/N19-1423"
    },
    {
      "citation_id": "9",
      "title": "A theoretically sound upper bound on the triplet loss for improving the efficiency of deep distance metric learning",
      "authors": [
        "Thanh-Toan Do",
        "Toan Tran",
        "Ian Reid",
        "Vijay Kumar",
        "Tuan Hoang",
        "Gustavo Carneiro"
      ],
      "year": "2019",
      "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition"
    },
    {
      "citation_id": "10",
      "title": "A unified few-shot classification benchmark to compare transfer and meta learning approaches",
      "authors": [
        "Neil Vincent Dumoulin",
        "Utku Houlsby",
        "Xiaohua Evci",
        "Ross Zhai",
        "Sylvain Goroshin",
        "Hugo Gelly",
        "Larochelle"
      ],
      "year": "2021",
      "venue": "Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track"
    },
    {
      "citation_id": "11",
      "title": "Model-agnostic meta-learning for fast adaptation of deep networks",
      "authors": [
        "Chelsea Finn",
        "Pieter Abbeel",
        "Sergey Levine"
      ],
      "year": "2017",
      "venue": "Proceedings of the 34th International Conference on Machine Learning"
    },
    {
      "citation_id": "12",
      "title": "COSMIC: COmmonSense knowledge for eMotion identification in conversations",
      "authors": [
        "Deepanway Ghosal",
        "Navonil Majumder"
      ],
      "year": "2020",
      "venue": "Findings of the Association for Computational Linguistics: EMNLP 2020",
      "doi": "10.18653/v1/2020.findings-emnlp.224"
    },
    {
      "citation_id": "13",
      "title": "Exploring the role of context in utterance-level emotion, act and intent classification in conversations: An empirical study",
      "authors": [
        "Deepanway Ghosal",
        "Navonil Majumder",
        "Rada Mihalcea",
        "Soujanya Poria"
      ],
      "year": "2021",
      "venue": "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
      "doi": "10.18653/v1/2021.findings-acl.124"
    },
    {
      "citation_id": "14",
      "title": "DialogueGCN: A graph convolutional neural network for emotion recognition in conversation",
      "authors": [
        "Deepanway Ghosal",
        "Navonil Majumder",
        "Soujanya Poria",
        "Niyati Chhaya",
        "Alexander Gelbukh"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
      "doi": "10.18653/v1/D19-1015"
    },
    {
      "citation_id": "15",
      "title": "Fewshot emotion recognition in conversation with sequential prototypical networks",
      "authors": [
        "Matthieu Gaël Guibon",
        "Hélène Labeau",
        "Luce Flamein",
        "Chloé Lefeuvre",
        "Clavel"
      ],
      "year": "2021",
      "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "16",
      "title": "An adaptive layer to leverage both domain and task specific information from scarce data",
      "authors": [
        "Matthieu Gaël Guibon",
        "Luce Labeau",
        "Chloé Lefeuvre",
        "Clavel"
      ],
      "year": "2023",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence",
      "doi": "10.1609/aaai.v37i6.25940"
    },
    {
      "citation_id": "17",
      "title": "Deep siamese neural networks for facial expression recognition in the wild",
      "authors": [
        "Wassan Hayale",
        "Pooran Singh Negi",
        "Mohammad Mahoor"
      ],
      "year": "2023",
      "venue": "IEEE Transactions on Affective Computing",
      "doi": "10.1109/TAFFC.2021.3077248"
    },
    {
      "citation_id": "18",
      "title": "Long Short-Term Memory",
      "authors": [
        "Sepp Hochreiter",
        "Jürgen Schmidhuber"
      ],
      "year": "1997",
      "venue": "Neural Computation",
      "doi": "10.1162/neco.1997.9.8.1735"
    },
    {
      "citation_id": "19",
      "title": "Meta-learning in neural networks: A survey",
      "authors": [
        "Timothy Hospedales",
        "Antreas Antoniou",
        "Paul Micaelli",
        "Amos Storkey"
      ],
      "year": "2022",
      "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
    },
    {
      "citation_id": "20",
      "title": "UniMSE: Towards unified multimodal sentiment analysis and emotion recognition",
      "authors": [
        "Guimin Hu",
        "Ting-En Lin",
        "Yi Zhao",
        "Guangming Lu",
        "Yuchuan Wu",
        "Yongbin Li"
      ],
      "year": "2022",
      "venue": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
      "doi": "10.18653/v1/2022.emnlp-main.534"
    },
    {
      "citation_id": "21",
      "title": "Relation-aware graph attention networks with relational position encodings for emotion recognition in conversations",
      "authors": [
        "Taichi Ishiwatari",
        "Yuki Yasuda",
        "Taro Miyazaki",
        "Jun Goto"
      ],
      "year": "2020",
      "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
      "doi": "10.18653/v1/2020.emnlp-main.597"
    },
    {
      "citation_id": "22",
      "title": "Multi-scale contrastive siamese networks for self-supervised graph representation learning",
      "authors": [
        "Ming Jin",
        "Yizhen Zheng",
        "Yuan-Fang Li",
        "Chen Gong",
        "Chuan Zhou",
        "Shirui Pan"
      ],
      "year": "2021",
      "venue": "Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI-21",
      "doi": "10.24963/ijcai.2021/204"
    },
    {
      "citation_id": "23",
      "title": "Serial order: a parallel distributed processing approach",
      "authors": [
        "M I Jordan"
      ],
      "year": "1985",
      "venue": "Serial order: a parallel distributed processing approach"
    },
    {
      "citation_id": "24",
      "title": "Supervised contrastive learning",
      "authors": [
        "Prannay Khosla",
        "Piotr Teterwak",
        "Chen Wang",
        "Aaron Sarna",
        "Yonglong Tian",
        "Phillip Isola",
        "Aaron Maschinot",
        "Ce Liu",
        "Dilip Krishnan"
      ],
      "year": "2020",
      "venue": "Advances in neural information processing systems"
    },
    {
      "citation_id": "25",
      "title": "Siamese neural networks for one-shot image recognition",
      "authors": [
        "Gregory Koch",
        "Richard Zemel",
        "Ruslan Salakhutdinov"
      ],
      "year": "2015",
      "venue": "Siamese neural networks for one-shot image recognition"
    },
    {
      "citation_id": "26",
      "title": "Graph based network with contextualized representations of turns in dialogue",
      "authors": [
        "Bongseok Lee",
        "Yong Choi"
      ],
      "year": "2021",
      "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
      "doi": "10.18653/v1/2021.emnlp-main.36"
    },
    {
      "citation_id": "27",
      "title": "Past, present, and future: Conversational emotion recognition through structural modeling of psychological knowledge",
      "authors": [
        "Jiangnan Li",
        "Zheng Lin",
        "Peng Fu",
        "Weiping Wang"
      ],
      "year": "2021",
      "venue": "Findings of the Association for Computational Linguistics: EMNLP 2021",
      "doi": "10.18653/v1/2021.findings-emnlp.104"
    },
    {
      "citation_id": "28",
      "title": "EmoCaps: Emotion capsule based model for conversational emotion recognition",
      "authors": [
        "Zaijing Li",
        "Fengxiao Tang",
        "Ming Zhao",
        "Yusen Zhu"
      ],
      "year": "2022",
      "venue": "Findings of the Association for Computational Linguistics: ACL 2022",
      "doi": "10.18653/v1/2022.findings-acl.126"
    },
    {
      "citation_id": "29",
      "title": "S+PAGE: A speaker and position-aware graph neural network model for emotion recognition in conversation",
      "authors": [
        "Chen Liang",
        "Jing Xu",
        "Yangkun Lin",
        "Chong Yang",
        "Yongliang Wang"
      ],
      "year": "2022",
      "venue": "Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing"
    },
    {
      "citation_id": "30",
      "title": "",
      "authors": [
        "Yinhan Liu",
        "Myle Ott",
        "Naman Goyal",
        "Jingfei Du",
        "Mandar Joshi",
        "Danqi Chen",
        "Omer Levy",
        "Mike Lewis",
        "Luke Zettlemoyer",
        "Veselin Stoyanov"
      ],
      "year": "2019",
      "venue": ""
    },
    {
      "citation_id": "31",
      "title": "Optimizing millions of hyperparameters by implicit differentiation",
      "authors": [
        "Jonathan Lorraine",
        "Paul Vicol",
        "David Duvenaud"
      ],
      "year": "2020",
      "venue": "Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics"
    },
    {
      "citation_id": "32",
      "title": "Dialoguernn: An attentive rnn for emotion detection in conversations",
      "authors": [
        "Navonil Majumder",
        "Soujanya Poria",
        "Devamanyu Hazarika",
        "Rada Mihalcea",
        "Alexander Gelbukh",
        "Erik Cambria"
      ],
      "year": "2019",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence",
      "doi": "10.1609/aaai.v33i01.33016818"
    },
    {
      "citation_id": "33",
      "title": "Comparison of the predicted and observed secondary structure of t4 phage lysozyme",
      "authors": [
        "Brian Matthews"
      ],
      "year": "1975",
      "venue": "Biochimica et biophysica acta"
    },
    {
      "citation_id": "34",
      "title": "A simple neural attentive metalearner",
      "authors": [
        "Nikhil Mishra",
        "Mostafa Rohaninejad",
        "Xi Chen",
        "P Abbeel"
      ],
      "year": "2017",
      "venue": "International Conference on Learning Representations"
    },
    {
      "citation_id": "35",
      "title": "Is discourse role important for emotion recognition in conversation?",
      "authors": [
        "Donovan Ong",
        "Jian Su",
        "Bin Chen",
        "Anh Luu",
        "Ashok Narendranath",
        "Yue Li",
        "Shuqi Sun",
        "Yingzhan Lin",
        "Haifeng Wang"
      ],
      "year": "2022",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence",
      "doi": "10.1609/aaai.v36i10.21361"
    },
    {
      "citation_id": "36",
      "title": "Vii. note on regression and inheritance in the case of two parents. proceedings of the royal society of London",
      "authors": [
        "Karl Pearson"
      ],
      "year": "1895",
      "venue": "Vii. note on regression and inheritance in the case of two parents. proceedings of the royal society of London"
    },
    {
      "citation_id": "37",
      "title": "The refinedweb dataset for falcon llm: Outperforming curated corpora with web data, and web data only",
      "authors": [
        "Guilherme Penedo",
        "Quentin Malartic",
        "Daniel Hesslow",
        "Ruxandra Cojocaru",
        "Alessandro Cappelli",
        "Hamza Alobeidli",
        "Baptiste Pannier",
        "Ebtesam Almazrouei",
        "Julien Launay"
      ],
      "year": "2023",
      "venue": "The refinedweb dataset for falcon llm: Outperforming curated corpora with web data, and web data only"
    },
    {
      "citation_id": "38",
      "title": "Context-dependent embedding utterance representations for emotion recognition in conversations",
      "authors": [
        "Patrícia Pereira",
        "Helena Moniz",
        "Isabel Dias",
        "Joao Carvalho"
      ],
      "year": "2023",
      "venue": "Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, & Social Media Analysis",
      "doi": "10.18653/v1/2023.wassa-1.21"
    },
    {
      "citation_id": "39",
      "title": "The Nature of Emotions",
      "authors": [
        "Robert Plutchik"
      ],
      "year": "2001",
      "venue": "American Scientist",
      "doi": "10.1511/2001.4.344"
    },
    {
      "citation_id": "40",
      "title": "Context-dependent sentiment analysis in user-generated videos",
      "authors": [
        "Soujanya Poria",
        "Erik Cambria",
        "Devamanyu Hazarika",
        "Navonil Majumder",
        "Amir Zadeh",
        "Louis-Philippe Morency"
      ],
      "year": "2017",
      "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/P17-1081"
    },
    {
      "citation_id": "41",
      "title": "Optimization as a model for few-shot learning",
      "authors": [
        "Sachin Ravi",
        "Hugo Larochelle"
      ],
      "year": "2016",
      "venue": "International Conference on Learning Representations"
    },
    {
      "citation_id": "42",
      "title": "Intention detection based on siamese neural network with triplet loss",
      "authors": [
        "Fuji Ren",
        "Siyuan Xue"
      ],
      "year": "2020",
      "venue": "IEEE Access",
      "doi": "10.1109/ACCESS.2020.2991484"
    },
    {
      "citation_id": "43",
      "title": "Learning internal representations by error propagation",
      "authors": [
        "Geoffrey David E Rumelhart",
        "Ronald Hinton",
        "Williams"
      ],
      "year": "1985",
      "venue": "Learning internal representations by error propagation"
    },
    {
      "citation_id": "44",
      "title": "Facenet: A unified embedding for face recognition and clustering",
      "authors": [
        "Florian Schroff",
        "Dmitry Kalenichenko",
        "James Philbin"
      ],
      "year": "2015",
      "venue": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
      "doi": "10.1109/CVPR.2015.7298682"
    },
    {
      "citation_id": "45",
      "title": "Learning a distance metric from relative comparisons",
      "authors": [
        "Matthew Schultz",
        "Thorsten Joachims"
      ],
      "year": "2003",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "46",
      "title": "Directed acyclic graph network for conversational emotion recognition",
      "authors": [
        "Weizhou Shen",
        "Siyue Wu",
        "Yunyi Yang",
        "Xiaojun Quan"
      ],
      "year": "2021",
      "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
      "doi": "10.18653/v1/2021.acl-long.123"
    },
    {
      "citation_id": "47",
      "title": "Prototypical networks for few-shot learning",
      "authors": [
        "Jake Snell",
        "Kevin Swersky",
        "Richard Zemel"
      ],
      "year": "2017",
      "venue": "Proceedings of the 31st International Conference on Neural Information Processing Systems, NIPS'17"
    },
    {
      "citation_id": "48",
      "title": "Mpnet: Masked and permuted pre-training for language understanding",
      "authors": [
        "Kaitao Song",
        "Xu Tan",
        "Tao Qin",
        "Jianfeng Lu",
        "Tie-Yan Liu"
      ],
      "year": "2020",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "49",
      "title": "Supervised prototypical contrastive learning for emotion recognition in conversation",
      "authors": [
        "Xiaohui Song",
        "Longtao Huang",
        "Hui Xue",
        "Songlin Hu"
      ],
      "year": "2022",
      "venue": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
      "doi": "10.18653/v1/2022.emnlp-main.347"
    },
    {
      "citation_id": "50",
      "title": "Beyond the imitation game: Quantifying and extrapolating the capabilities of language models",
      "authors": [
        "Aarohi Srivastava"
      ],
      "year": "2022",
      "venue": "Beyond the imitation game: Quantifying and extrapolating the capabilities of language models",
      "arxiv": "arXiv:2206.04615"
    },
    {
      "citation_id": "51",
      "title": "Learning to compare: Relation network for few-shot learning",
      "authors": [
        "Flood Sung",
        "Yongxin Yang",
        "Li Zhang",
        "Tao Xiang",
        "H Philip",
        "Timothy Torr",
        "Hospedales"
      ],
      "year": "2018",
      "venue": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "doi": "10.1109/CVPR.2018.00131"
    },
    {
      "citation_id": "52",
      "title": "",
      "authors": [
        "Hugo Touvron",
        "Louis Martin",
        "Kevin Stone",
        "Peter Albert",
        "Amjad Almahairi",
        "Yasmine Babaei",
        "Nikolay Bashlykov",
        "Soumya Batra",
        "Prajjwal Bhargava",
        "Shruti Bhosale",
        "Dan Bikel",
        "Lukas Blecher",
        "Cristian Canton Ferrer",
        "Moya Chen",
        "Guillem Cucurull",
        "David Esiobu",
        "Jude Fernandes",
        "Jeremy Fu",
        "Wenyin Fu",
        "Brian Fuller",
        "Cynthia Gao",
        "Vedanuj Goswami",
        "Naman Goyal",
        "Anthony Hartshorn",
        "Saghar Hosseini",
        "Rui Hou",
        "Hakan Inan",
        "Marcin Kardas",
        "Viktor Kerkez",
        "Madian Khabsa",
        "Isabel Kloumann",
        "Artem Korenev",
        "Punit Singh Koura",
        "Marie-Anne Lachaux",
        "Thibaut Lavril",
        "Jenya Lee",
        "Diana Liskovich",
        "Yinghai Lu",
        "Yuning Mao",
        "Xavier Martinet",
        "Todor Mihaylov",
        "Pushkar Mishra",
        "Igor Molybog",
        "Yixin Nie",
        "Andrew Poulton",
        "Jeremy Reizenstein",
        "Rashi Rungta",
        "Kalyan Saladi",
        "Alan Schelten",
        "Ruan Silva",
        "Eric Smith",
        "Ranjan Subramanian",
        "Ellen Xiaoqing",
        "Binh Tan",
        "Ross Tang",
        "Adina Taylor",
        "Jian Williams",
        "Puxin Xiang Kuan",
        "Zheng Xu",
        "Iliyan Yan",
        "Yuchen Zarov",
        "Angela Zhang",
        "Melanie Fan",
        "Kambadur"
      ],
      "venue": ""
    },
    {
      "citation_id": "53",
      "title": "Context-and sentimentaware networks for emotion recognition in conversation",
      "authors": [
        "Geng Tu",
        "Jintao Wen",
        "Cheng Liu",
        "Dazhi Jiang",
        "Erik Cambria"
      ],
      "year": "2022",
      "venue": "IEEE Transactions on Artificial Intelligence",
      "doi": "10.1109/TAI.2022.3149234"
    },
    {
      "citation_id": "54",
      "title": "",
      "authors": [
        "Ashish Vaswani",
        "Noam Shazeer",
        "Niki Parmar",
        "Jakob Uszkoreit",
        "Llion Jones",
        "Aidan Gomez",
        "Lukasz Kaiser",
        "Illia Polosukhin"
      ],
      "year": "2017",
      "venue": ""
    },
    {
      "citation_id": "55",
      "title": "Matching networks for one shot learning",
      "authors": [
        "Oriol Vinyals",
        "Charles Blundell",
        "Timothy Lillicrap",
        "Koray Kavukcuoglu",
        "Daan Wierstra"
      ],
      "year": "2016",
      "venue": "Proceedings of the 30th International Conference on Neural Information Processing Systems, NIPS'16"
    },
    {
      "citation_id": "56",
      "title": "Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers",
      "authors": [
        "Wenhui Wang",
        "Furu Wei",
        "Li Dong",
        "Hangbo Bao",
        "Nan Yang",
        "Ming Zhou"
      ],
      "year": "2020",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "57",
      "title": "DualGATs: Dual graph attention networks for emotion recognition in conversations",
      "authors": [
        "Duzhen Zhang",
        "Feilong Chen",
        "Xiuyi Chen"
      ],
      "year": "2023",
      "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/2023.acl-long.408"
    },
    {
      "citation_id": "58",
      "title": "Cauain: Causal aware interaction network for emotion recognition in conversations",
      "authors": [
        "Weixiang Zhao",
        "Yanyan Zhao",
        "Xin Lu"
      ],
      "year": "2022",
      "venue": "Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence, IJCAI-22",
      "doi": "10.24963/ijcai.2022/628"
    },
    {
      "citation_id": "59",
      "title": "Knowledge-enriched transformer for emotion detection in textual conversations",
      "authors": [
        "Peixiang Zhong",
        "Di Wang",
        "Chunyan Miao"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
      "doi": "10.18653/v1/D19-1016"
    },
    {
      "citation_id": "60",
      "title": "Topic-driven and knowledge-aware transformer for dialogue emotion detection",
      "authors": [
        "Lixing Zhu",
        "Gabriele Pergola",
        "Lin Gui",
        "Deyu Zhou",
        "Yulan He"
      ],
      "year": "2021",
      "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the International Joint Conference on Natural Language Processing",
      "doi": "10.18653/v1/2021.acl-long.125"
    },
    {
      "citation_id": "61",
      "title": "Iemocap: interactive emotional dyadic motion capture database",
      "authors": [
        "Language Resource",
        "References Busso",
        "Murtaza Bulut",
        "Chi-Chun Lee",
        "Abe Kazemzadeh",
        "Emily Mower",
        "Samuel Kim",
        "Jeannette Chang",
        "Sungbok Lee",
        "Shrikanth Narayanan"
      ],
      "year": "2008",
      "venue": "Language Resources and Evaluation"
    },
    {
      "citation_id": "62",
      "title": "DailyDialog: A manually labelled multi-turn dialogue dataset",
      "authors": [
        "Yanran Li",
        "Hui Su",
        "Xiaoyu Shen",
        "Wenjie Li",
        "Ziqiang Cao",
        "Shuzi Niu"
      ],
      "year": "2017",
      "venue": "Proceedings of the Eighth International Joint Conference on Natural Language Processing"
    },
    {
      "citation_id": "63",
      "title": "MELD: A multimodal multi-party dataset for emotion recognition in conversations",
      "authors": [
        "Soujanya Poria",
        "Devamanyu Hazarika",
        "Navonil Majumder",
        "Gautam Naik",
        "Erik Cambria",
        "Rada Mihalcea"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/P19-1050"
    }
  ]
}