{
  "paper_id": "2508.08050v1",
  "title": "9Th Workshop On Sign Language Translation And Avatar Technologies (Sltat 2025)",
  "published": "2025-08-11T14:50:21Z",
  "authors": [
    "Fabrizio Nunnari",
    "Cristina Luna Jiménez",
    "Rosalee Wolfe",
    "John C. McDonald",
    "Michael Filhol",
    "Eleni Efthimiou",
    "Evita Fotinea",
    "Thomas Hanke"
  ],
  "keywords": [
    "Sign language",
    "signing avatars",
    "sign language technology",
    "sign language animation"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "The Sign Language Translation and Avatar Technology (SLTAT) workshops continue a series of gatherings to share recent advances in improving deaf / human communication through non-invasive means. This 2025 edition, the 9th since its first appearance in 2011, is hosted by the International Conference on Intelligent Virtual Agents (IVA), giving the opportunity for contamination between two research communities, using digital humans as either virtual interpreters or as interactive conversational agents. As presented in this summary paper, SLTAT sees contributions beyond avatar technologies, with a consistent number of submissions on sign language recognition, and other work on data collection, data analysis, tools, ethics, usability, and affective computing.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Those born deaf constitute an invisible and underserved segment of society  [8] . The deaf communities around the world face continual challenges in their daily interaction with hearing, non-signing populations. The language barrier causes difficulties in accessing health care, education, and job opportunities as well as legal consultation. For these critical services, the gold standard for facilitating communication has been and still is hiring a sign language interpreter. However, in daily life, it is impossible for an interpreter to be omnipresent at the many short but important conversations that occur, such as those at a store counter, over a hotel desk, or in an office foyer. An automatic translation system between spoken and signed languages would ease communication obstacles and improve inclusivity while providing a low-cost, non-invasive alternative to cochlear implants  [9] .\n\nThe Sign Language Translation and Avatar Technologies workshop, established in 2011, focuses on three main topics: symbolic translation of sign language, animation of sign language using avatars, and usability evaluation of practical translation and animation systems. At the workshop, a mix of oral presentations as well as poster presentations covering active work and proposed research encourages discussion and collaboration among researchers who come from a wide variety of disciplines, ranging from machine learning and sign language linguistics to mathematics and art.\n\nIn a real sense, the SLTAT workshop is coming home this year, because this event was first offered as a standalone workshop in Berlin back in January 2011. Since then, it has been an international symposium with events offered in Germany, Scotland, The United States, France, Canada, and Greece. During this time, it has been hosted at conferences venues such as ACM-ASSETS, ICASSP, LREC, and HCI International. A complete history of the workshop and its past venues can be found on the SLTAT website: http://sltat.cs.depaul.edu.\n\nThis year we are pleased to be welcomed by the 25th ACM International Conference on Intelligent Virtual Agents (IVA2025, https://iva.acm.org/ 2025/). This will give the opportunity to get close to a community of researchers who have been focusing on the creation and animation of interactive virtual agents for 25 years. The workshop information for this year can be found on the SLTAT 2025 home page: https://sltat2025.github.io.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Submissions",
      "text": "In total, the workshop achieved 34 submissions of full articles between 4 and 8 pages, of which 30 were accepted and presented at the conference. This year, Figure  2 : Distribution of authors per country of their institutions the workshop achieved a record number of 43 actual reviewers, who reviewed an average of two to three articles after a double-blind peer review process. Among the reviewers, both linguistics and computer science experts participated and enriched the review process.\n\nA total of 87 different authors participated in the writing and editing process of the 30 submissions, belonging to institutions located in Germany, France, United Kingdom, Japan, Spain, Netherlands, Greece, Switzerland, United States, Sweden, and South Korea; highlighting active Sign Language research communities around the world (see Figure  2 ).\n\nThe workshop invited submissions in the broad ambit of Sign Language including articles related to translation and recognition technologies, incorporating manual and non-manual features (e.g., mouthing); avatar animation, including linguistically annotation to improve signs animation, as well as flexible facial gestures and mouthing; and in usability, accepting articles focused on evaluating previously mentioned models and editing and preprocessing tools oriented to Sign Language applications. Additionally, this year articles in the ambit of affective computing applied to Sign Language were encouraged, as well as reviews and articles with a focus on ethics and human-centric developments together with the deaf community. The topic distribution is summarized in Table  1 .\n\nTen of the 30 accepted articles scoped sign language recognition, translation, or sign spotting. In this regard, the use of models derived from transformers was a prominent resource in the proposed systems; as well as other techniques related to synthetic data as augmentation.\n\nNine other papers were related to Sign Language Production, avatars, and the evaluation of motion capture systems.\n\nFive articles belonged to the broad group of datasets, features analysis, and processing tools to automatically edit realistic videos or annotate.\n\nFour articles also addressed relevant ethical issues in sign language and performed a human-centric usability test. Among them, the involvement of the deaf community in research projects and the impact of remote sign language interpretation were discussed.\n\nFinally, two articles focused on the combined field of sign language and affective computing to address first steps on how to express and combine linguistic features with emotional and facial features to improve sign language prosody.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Conference Organization",
      "text": "With more than 40 expected participants, the SLTAT workshop has now reached the size of a small conference. However, rather than switching to a full onstage conference format, the organizers aim to max-",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Topic Count",
      "text": "Sign language recognition, translation, sign spotting 10 Sign language production, avatars, MoCap systems 9 Datasets, features analysis, processing tools 5 Ethical issues and usability 4 Sign language and affective computing 2\n\nTotal 30\n\nTable  1 : Topic distribution of the accepted papers.\n\nimize the chances of face-to-face conversations with other researchers. This, in our opinion, fosters exchange of ideas and collaborations among members of a growing but still tight community. Thus, the workshop is organized with two short on-stage presentations and two long and populated poster sessions. This increases the number of work that can be accepted and presented in a 1-day workshop format, leaves space for informal meetings among participants, and last but not least, for the sake of body health, provides a good alternation between sitting and standing positions.\n\nOnly six papers will be presented in the two oral/signed on-stage format. The remaining 24 accepted papers will be presented during the two poster sessions.\n\nThe workshop organization will provide two International Sign Language interpreters. They will provide interpretation during the on-stage presentation and will be available for 1-to-1 interpretation during the poster sessions.\n\nThe schedule of presentations has been devised to take crip time into account, addressing the importance of flexible time structures in accessible settings  [5] .",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Discussion",
      "text": "After 40+ years of research  [1, 6] , only recently has the use of avatars as the mean of synthesis for sign language started to see application in the industry. Research on the topic is lively and starts now to focus on improving motion naturalness via better animation techniques and emotional expressivity.\n\nIn the other direction, the use of neural-based machine learning techniques quickly advanced the recog-nition of sign language  [4, 7] . Research prototypes are already available.\n\nHowever, despite the steadily increasing interest in the topic, there seems to be still an unfair imbalance between the huge number of technologists approaching the topic with respect to linguists and representatives of the Deaf community. The lack of communication between technologists and linguistically competent researchers has already been recognized and criticized  [3, 2] .\n\nAs organizers and coordinators of many initiatives related to SL and technology, we are witnessing increasing awareness (by technologists) of the culture behind signed languages. However, we believe that future editions will still need to increase the effort for an interdisciplinary work: a better inclusion of the linguistic community for theory-informed technological solutions and a better inclusion of the deaf community to steer technological developments towards the real needs of the every day life of deaf users.",
      "page_start": 4,
      "page_end": 4
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: The avatar Paula finger spelling S-L-T-A-T in ASL.",
      "page": 2
    },
    {
      "caption": "Figure 2: Distribution of authors per country of their",
      "page": 2
    }
  ],
  "tables": [
    {
      "caption": "Table 1: Ten of the 30 accepted articles scoped sign lan-",
      "page": 3
    },
    {
      "caption": "Table 1: Topic distribution of the accepted papers.",
      "page": 3
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Evolution and Trends in Sign Language Avatar Systems: Unveiling a 40-Year Journey via Systematic Review",
      "authors": [
        "Maryam Aziz",
        "Achraf Othman"
      ],
      "year": "2023",
      "venue": "Multimodal Technologies and Interaction"
    },
    {
      "citation_id": "2",
      "title": "Sign Language Recognition, Generation, and Translation: An Interdisciplinary Perspective",
      "authors": [
        "Danielle Bragg",
        "Oscar Koller",
        "Mary Bellard",
        "Larwan Berke",
        "Patrick Boudreault",
        "Annelies Braffort",
        "Naomi Caselli",
        "Matt Huenerfauth",
        "Hernisa Kacorri",
        "Tessa Verhoef",
        "Christian Vogler",
        "Meredith Ringel"
      ],
      "year": "2019",
      "venue": "The 21st International ACM SIGACCESS Conference on Computers and Accessibility"
    },
    {
      "citation_id": "3",
      "title": "Ableist Language Teching over Sign Language Research",
      "authors": [
        "Carl Börstell"
      ],
      "year": "2023",
      "venue": "Proceedings of the Second Workshop on Resources and Representations for Under-Resourced Languages and Domains (RESOURCEFUL-2023)"
    },
    {
      "citation_id": "4",
      "title": "Machine Translation from Signed to Spoken Languages: State of the Art and Challenges. Universal Access in the Information Society",
      "authors": [
        "Dimitar Mathieu De Coster",
        "Mieke Shterionov",
        "Joni Van Herreweghe",
        "Dambre"
      ],
      "year": "2023",
      "venue": "Machine Translation from Signed to Spoken Languages: State of the Art and Challenges. Universal Access in the Information Society"
    },
    {
      "citation_id": "5",
      "title": "Cripping Time -Understanding the Life Course through the Lens of Ableism",
      "authors": [
        "Karin Ljuslinder",
        "Katie Ellis",
        "Lotta Vikström"
      ],
      "year": "2020",
      "venue": "Scandinavian Journal of Disability Research"
    },
    {
      "citation_id": "6",
      "title": "A survey on the animation of signing avatars: From sign representation to utterance synthesis",
      "authors": [
        "Lucie Naert",
        "Caroline Larboulette",
        "Sylvie Gibet"
      ],
      "year": "2020",
      "venue": "Computers & Graphics"
    },
    {
      "citation_id": "7",
      "title": "A survey on Sign Language machine translation. Expert Systems with Applications",
      "authors": [
        "Adrián Núñez-Marcos",
        "Olatz Perez-De Viñaspre",
        "Gorka Labaka"
      ],
      "year": "2023",
      "venue": "A survey on Sign Language machine translation. Expert Systems with Applications"
    },
    {
      "citation_id": "8",
      "title": "Evita Fotinea, and Annelies Braffort",
      "authors": [
        "Rosalee Wolfe",
        "John Mcdonald",
        "Thomas Hanke",
        "Sarah Ebling",
        "Davy Van Landuyt",
        "Frankie Picron",
        "Verena Krausneker",
        "Eleni Efthimiou"
      ],
      "year": "2022",
      "venue": "Evita Fotinea, and Annelies Braffort"
    }
  ]
}