{
  "paper_id": "2301.01887v1",
  "title": "A Novel Exploitative And Explorative Gwo-Svm Algorithm For Smart Emotion Recognition",
  "published": "2023-01-05T03:16:28Z",
  "authors": [
    "Xucun Yan",
    "Zihuai Lin",
    "Zhiyun Lin",
    "Branka Vucetic"
  ],
  "keywords": [
    "Emotion recognition",
    "IoT",
    "Smart health",
    "ECG signals",
    "GWO",
    "SVM"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Emotion recognition or detection is broadly utilized in patient-doctor interactions for diseases such as schizophrenia and autism and the most typical techniques are speech detection and facial recognition. However, features extracted from these behavior-based emotion recognitions are not reliable since humans can disguise their emotions. Recording voices or tracking facial expressions for a long term is also not efficient. Therefore, our aim is to find a reliable and efficient emotion recognition scheme, which can be used for non-behavior-based emotion recognition in real-time. This can be solved by implementing a single-channel electrocardiogram (ECG) based emotion recognition scheme in a lightweight embedded system. However, existing schemes have relatively low accuracy. For instance, the accuracy is about 82.78% by using a least squares support vector machine (SVM). Therefore, we propose a reliable and efficient emotion recognition scheme-exploitative and explorative grey wolf optimizer based SVM (X-GWO-SVM) for ECG-based emotion recognition. Two datasets, one raw self-collected iRealcare dataset, and the widely-used benchmark WESAD dataset are used in the X-GWO-SVM algorithm for emotion recognition. Leave-single-subject-out cross-validation yields a mean accuracy of 93.37% for the iRealcare dataset and a mean accuracy of 95.93% for the WESAD dataset. This work demonstrates that the X-GWO-SVM algorithm can be used for emotion recognition and the algorithm exhibits superior performance in reliability compared to the use of other supervised machine learning methods in earlier works. It can be implemented in a lightweight embedded system, which is much more efficient than existing solutions based on deep neural networks.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "I. Introduction",
      "text": "T HE use of the Internet of Things (IoT) is growing steadily over the years. It is expected that by 2025, there will be approximately 27 billion connected IoT devices  [1] . At present, the IoT is one of the main promoters of technological innovation and one of the areas with greater potential for social and economic transformation  [2] -  [4] . Through a network of sensors and actuators connected to a wireless network  [5] -  [14] , the operator has the power to remotely gather data. Alternatively, actuators could be programmed to actuate automatically according to values reported by the sensor.\n\nEmotion recognition or detection based on IoT wireless sensing and networking has gained lots of attention since it Xucun Yan, Zihuai Lin and Branka Vucetic are with School of Electrical and Information Engineering, University of Sydney, New South Wales 2006, Australia (e-mail: xucun.yan@sydney.edu.au; zihuai.lin@sydney.edu.au; branka.vucetic@sydney.edu.au).\n\nZhiyun Lin is with the Department of Electrical and Electronic Engineering, Southern University of Science and Technology, Shenzhen 518055, China, and Peng Cheng Laboratory, Shenzhen 518066, China (email: linzy@sustech.edu.cn). Corresponding author: Zhiyun Lin can be broadly utilized in interfaces between humans and computers and patient-doctor interactions for diseases such as schizophrenia and autism. Most emotion detection methods are based on behaviors such as speech detection and face recognition  [15] ,  [16] . However, features extracted from the abovementioned behavior-based emotion recognition are not adequate for identifying emotions, because the behavior induced by emotion can be disguised by artifacts of human social masking  [17] . For example, emotion recognition based on facial expressions can be easily misled by a poker face. Using physiological signals, such as electroencephalograms (EEGs)  [18] -  [20] , electromyograms (EMGs), and electrocardiograms (ECGs)  [21] , is an alternative to identify emotions since physiological signals are one of the most notable means to manifest the central nervous system in which emotions are processed  [22] .\n\nUsing physiological cues for emotion identification has two advantages over prior approaches to emotion recognition. The first is that physiological signals generated from automatic reactions are difficult to disguise. The second is that wearable emotion monitoring can continually record physiological information. This differs from the instance of voice recognition where data may only be recorded when individuals are speaking. However, using multi-channel biosignals to recognize human emotions is not suitable for practical applications because subjects may be hindered during daily life activities  [23] . It has been proved that ECG signals are a suitable physiological channel with acceptable recognition abilities  [17] .\n\nHowever, according to  [24] -  [27] , the accuracy of emotion detection based on a single ECG channel fluctuates a lot for various datasets compared to that of other approaches such as facial emotion recognition. On the one hand, recent efforts in emotion recognition using ECG signals have largely relied on relatively simple supervised learning techniques  [28] , such as random forest (RF), support vector machine (SVM), Knearest neighbor (K-NN), etc. However, these methods have relatively low accuracy (for instance, the accuracy is about 82.78%  [17]  by using least squares SVM). On the other hand, the current maximum level of single ECG channelbased emotion recognition accuracy reaches 96.9%  [29]  for Wearable Stress and Affect Detection (WESAD) database and 88.2%  [29]  for a dataset for multi-modal research of affect, personality traits, and mood in individuals and groups (AMIGOS)  [27] , which utilizes self-supervised convolutional neural network (CNN) model. Facial emotion recognition accuracy achieves 92.07%  [30]  for MMI Facial Expression Database and 94.91%  [30]  for the Japanese Female Facial Expression Database, which uses CNN embedded with re-current neural network (RNN)  [26] . Nevertheless, these deep neural network-based techniques, e.g., CNN, RNN, etc, tend to achieve high accuracy but are complex with low computation efficiency, which cannot be implemented in a lightweight embedded system operating in real-time. Therefore, seeking a simple supervised learning scheme to accurately, stably, and efficiently recognize emotions based on a single ECG channel in a lightweight embedded system is necessary.\n\nTowards this objective, this paper aims to develop a novel exploitative and explorative GWO-SVM (X-GWO-SVM) for ECG-based emotion recognition. The goal is to achieve good classification accuracy (as high as utilizing complex neural networks) while simultaneously reducing computation so that it can be implemented in a lightweight embedded system. The idea is motivated from the fact that the SVM algorithm can be used to solve single-channel ECG-based emotion recognition issue with lightweight embedded system implementation. However, the existing SVM works do not offer a good classification accuracy performance for ECG-based recognition due to difficulties in finding appropriate hyper-parameters while preventing overfitting of the training data.\n\nIn general, the selection of hyperparameters is a non-convex optimization issue. Therefore, many heuristic algorithms such as genetic algorithm (GA), particle swarm optimization (PSO), and grey wolf optimizer (GWO)  [31] -  [34]  are introduced to tackle it. Compared with PSO and a set of search algorithms, GWO provides better performance in computation reduction (e.g., in feature subset selection  [35] ). Moreover, the GWO approach has been demonstrated to be more stable against initialization than PSO and GA  [35] . However, as discussed in  [36] , conventional GWO-based SVM (GWO-SVM) techniques are still easy to fall into local solutions.\n\nIn this work, an improved method, the X-GWO-SVM method, is proposed. The proposed X-GWO-SVM method is the first to apply GWO-SVM idea to solve ECG-based recognition, and as shown in this paper, this method has higher recognition accuracy than existing SVM and PSO-SVM techniques for ECG emotion recognition use. It can effectively avoid the algorithm falling into a local solution by increasing the exploration ability, and speed up the convergence by increasing the exploitation ability. In this paper, two datasets, one raw self-collected iRealcare dataset, and the widely used benchmark WESAD dataset are used in the X-GWO-SVM algorithm for emotion recognition. Leave-single-subject-out cross-validation yields a mean accuracy of 93.37% and an F1score of 93.38% for the iRealcare dataset and a mean accuracy of 95.93% and an F1-score of 95.56% for the WESAD dataset.\n\nThe main contributions of this paper are summarized as follows:\n\n1) We use a self-built wearable IoT ECG patch with only one ECG channel to collect four emotions, i.e., happiness, tension, peacefulness and excitement, by playing different videos. 2) We designed a novel X-GWO-SVM algorithm to internally learn hyperparameters on SVM. It can effectively avoid the algorithm falling into a local solution by increasing the exploration ability, and speed up the convergence by increasing the exploitation ability.\n\n3) This novel X-GWO-SVM algorithm can accurately and efficiently recognize emotions for single-channel ECGbased signals and be implemented in a lightweight embedded system operating in real-time. It improves accuracy compared to existing simple machine learning methods and dramatically reduces complexity compared to some novel deep neural networks. Thus, the efficiency is also increased compared to other time-consuming emotion recognition methods. The outline of the rest of the paper is given below. Section II introduces our database and an expanded dataset. Our model formulation is described in Section III. In Sections IV and Sec-tionV, we present results and discussions, respectively, before concluding with a discussion of potential future directions in Section VI.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Ii. Dataset",
      "text": "ECG signals are composed of the P wave, T wave, and QRS complex, which represent the three phases of an ECG pulse. In atrial systole, the P wave is the contraction pulse. The QRS complex signifies ventricular depolarization. The T wave represents ventricular re-polarization  [37] . An ECG device records the electrical changes caused by the activities of the heart, which are collected by electrodes over the skin for a period of time. It has been proved that ECG signals are a suitable physiological channel with acceptable recognition abilities  [17]  to identify emotions. Therefore, single-channel ECG signals are used in this study. In order to verify the general representation ability of X-GWO-SVM, two datasets of ECG signals are used, one raw self-collected iRealcare dataset with 5 subjects and the other widely-used benchmark WESAD dataset with 15 subjects.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "A. Description Of Irealcare Dataset",
      "text": "Data collection is one of the most important steps for emotion detection. The definition of different emotions must be explicit in this phase. If the definition is not clear, confusion may occur among different emotions in the classification phase and the classification performance will be influenced negatively. However, emotions normally instantaneously occur and hold for a short period. The longer the period is, the more irrelevant data is included in ECG signals. Thus, it is hard to properly label the corresponding emotion class.\n\nTo avoid the aforementioned issue, we self-collect a dataset with high quality and a short period for each emotion, making sure accurate data collection and labeling processes. The ECG signals are recorded by a low-cost wearable IoT ECG patch, called iRealcare  [38] -  [42]  with 128 Hz sampling rates. The data collected by the iRealcare IoT ECG sensor can be transmitted to a smartphone application (APP) via Bluetooth Low Energy (BLE) and then to a cloud. From the cloud, we can acquire the raw ECG signals. Signals are recorded for four emotions including happiness, tension, peacefulness, and excitement. Except for peacefulness, each emotion is generated based on an external environmental stimulus, which is similar to the published datasets stimulating subjects through audio or video  [43] . The peacefulness describes the normal state, for which the ECG signals are recorded without any external stimulus. Signals for happiness, tension, and excitement are recorded when subjects watch comedies, watch thriller movies and do exercises, respectively. Generally, the record duration should be short as we discussed before. Therefore, the record time is in a range of 3.22-6.16 minutes for each emotion.\n\nIt should be noticed that we only record the period that subjects are actually in that emotion condition and ignore the transition period. Clearly, the definition of different emotions under this external stimulus setting is clear and subjects are easy to get into a specific emotion. Taking into account differences among different subjects, 5 subjects are involved and each subject is recorded with four emotion types. For each subject, there are 192-229 samples for peacefulness, 99-141 samples for excitement, 156-236 samples for happiness and 166-205 samples for tension. More information on the iRealcare database is shown in Table  I  and segmentation details are described in Section III-A2.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "B. Description Of Wesad Dataset",
      "text": "The dataset, accessible in  [43] , is comprised of recordings of 15 subjects (aged  [24] [25] [26] [27] [28] [29] [30] [31] [32] [33] [34] [35]  watching video clips and doing public speaking and mental arithmetic tasks. The dataset is recorded with a wrist-based device (including the following sensors: photoplethysmography, accelerometer, electrodermal activity, and body temperature) and a chest-based device (including the following sensors: ECG, accelerometer, electromyogram, respiration, and body temperature). This dataset offers a fusion of physiological parameters to efficiently identify human emotions, as these represent the body's instinctive reactions. However, it is not suitable for practical applications, and it may hinder subjects during daily life activities  [23] . Therefore, in this paper, we only study single ECG channel signals for this dataset. The ECG signal is acquired from a RespiBAN Professional using a three-lead configuration with 700Hz sampling rates. Three types of emotions (baseline, stress and amusement) are annotated by subjects  [43] . Amusement condition signals are collected when subjects watch funny video clips. Stress condition signals are collected when subjects are asked to provide public speaking. Baseline condition signals are collected when subjects sit/stand at a table and read magazines. For each subject, there are 9 samples for amusement, 15-18 samples for stress, and 28-29 samples for baseline. The segmentation details are described in Section III-A2.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Iii. Method A. Preprocessing",
      "text": "Normally, ECG signals are non-linear with low signal amplitudes. The frequency range of ECG signals is from 0.05Hz to 100Hz and the dynamic range is below 4mV  [44] . Thus, the collected ECG signals are susceptible to being disturbed by external factors such as interference. To acquire ECG signals with low interference, we conduct the pre-processing of the raw ECG signals. During the data collection and transmission stage, ECG signals are mainly affected by baseline drift, power line interference, and electrode contact noise. The baseline drift is caused by body movement and breathing. It can make the entire ECG signal shift down or up at the horizontal axis. The frequency of baseline drift is around 0.5Hz and it will influence the analysis of ECG signals. The powerline interference is characterized by 50 or 60Hz, which can be caused by the electromagnetic field of nearby facilities and electromagnetic interference of the power lines. Since the iRealcare sensor used BLE instead of cables, the power-line interference will not affect the collected ECG signals from the sensor. The electrode contact noise is caused by the variance of impedance when the skin is stretched. This frequency is typically between 1 and 10Hz  [45] .\n\n1) Filtering: The finite impulse response (FIR) filter is used to filter the aforementioned noises. It is a reliable and simple filter. Moreover, the output of a FIR filter is not distorted because it is a linear filter  [46] . FIR filters are created utilizing window-based techniques, such as the Hamming window, Rectangular window, Hanning window, and the Blackman window. These different windows are used to design the low pass filter and high pass filter with cut-off frequencies. For our band-pass FIR filter, the cut-off frequencies are set to 3Hz and 100Hz, respectively.\n\n2) Segmentation and splitting: For the iRealcare dataset, the aforementioned 20 groups are denoised, non-overlapping segmented with 200 data points (1.56s), and then split into training and test sets. Non-overlapping is designated between segments to avoid any potential data leakage between training and test data. It should be noticed that the selection of the window size (200 data points) is empirical. Prior research employing these datasets utilized a broad variety of window sizes. For instance,  [43]  has chosen 5-second windows for WESAD whereas  [47]  has used 1-second windows for the same dataset. Specifically, the training set consists of 16 groups, each of which has four emotions, whereas the test set consists of 4 groups. Similar to the iRealcare dataset, the WESAD dataset is also filtered by a FIR filter, non-overlapping segmented with 14000 data points (20s), and then 12 subjects are treated as a training set while the rest 3 subjects form a test set.\n\nFig.  1  depicts four emotion segments with 200 randomly chosen ECG signal data samples from the iRealcare dataset. We can see that for the emotion of peacefulness, the subject's heart rate is comparatively sluggish. However, it is hard to identify the other three emotions based on the original ECG signals. As a result, the design of an efficient feature extraction approach is necessitated.\n\n3) Discrete cosine transform (DCT): In this paper, we use the DCT methods to extract the main information of ECG signals in the frequency domain  [48] . It is computed for a compressed version of input ECG signals containing significant information, and only a small subset of the coefficients is maintained as a feature vector. The main merit of the DCT is its high computational speed which is suitable for data compression  [49] . To improve performance, the Z-score normalization technique is invoked prior to recognition to account for small perturbations in motion artifacts caused by electrodes' movement on the skin surface.\n\nThe DCT uses a sum of N cosine functions at different\n\nand N is the length of the data sequence  [50] .\n\nDuring DCT, data samples from each ECG segment are translated into the frequency domain, generating a series of DCT coefficients with length N . Then, the generated DCT coefficients are arranged in a decreasing order based on their absolute values. DCT coefficients with larger absolute values are treated as significant features which will be fed into the proposed X-GWO-SVM scheme. Descending DCT coefficients with dimension u (u ≤ N ) can be selected as the extracted features. The determination of a proper dimension u of extracted features will be discussed in Section IV by comparing classification performances at different values. Fig.  2  shows corresponding extracted features with dimension u = 95, i.e., coefficients with the largest 95 absolute values, from the aforementioned ECG segments (plotted in Fig.  1 ). It should be noticed that the first coefficient takes the highest energy (highlighted with red color), which stores the most significant features. To observe details on the rest coefficients, we zoom in the rest of coefficients (the 2 nd to 95 t h coefficients) for each emotion. Compared to the original ECG signals, the four emotions are clearly differentiated between segments following feature extraction.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "B. Exploitative And Explorative Grey Wolf Optimizer Based Support Vector Machine",
      "text": "For the first time, the X-GWO-SVM approach is proposed for ECG emotion identification in this work. The hyperparameter-free property of the proposed method provides a new way for radial basis function-based SVM (RBF-SVM) learning. In general, classifying the non-linearly separable data with RBF-SVM requires two hyperparameter which are\n\nwhere P is the number of training samples; i is a slack variable which is added to relax the constraints of linear SVM; w T Ψ(x i ) + b is the decision function; y i is the class label; x i is the sample; C is the penalty parameter and it controls the trade-off between the size of the margin and the slack variable penalty; γ is a spacial parameter which controls data distribution in a new feature space  [51] ,  [52] . Obviously, hyperparameter (C and γ) tuning for RBF-SVM is necessary but complex. Thus, the proposed method can internally learn hyperparameters by emphasizing the importance of the α wolf and non-linearly updating coefficient vectors used in GWO. Moreover, this method has higher recognition accuracy than the existing GWO-SVM and PSO-SVM techniques for ECG emotion recognition use, and it can effectively avoid the algorithm falling into a local solution by increasing the exploration ability and speed up the convergence ability by increasing the exploitation ability. Fig.  3  demonstrates our X-GWO-SVM method, which is inspired by the activity of grey wolves. There are 4 types of grey wolves, named alpha (α), beta (β), delta (δ), and omega (ω), simulating the leadership hierarchy. These wolves continuously search for prey, the optimal solution in our case, and hunting (optimization) is guided by the fittest solution, second and third best solutions, α, β and δ, respectively. The ω wolves follow these three wolves. A total number of search agents (wolves) is represented by n. C o and γ o are two elements of the searched optimal solution ξ 1 . The X-GWO-SVM method has 10 steps as described below.\n\n1) The X-GWO-SVM related parameters are initialized, i.e., maximum iteration L; the number of search agents n; positions of α (ξ 1 ), β (ξ 2 ) and δ (ξ 3 ); positions of search agents (wolves) η 1 , η 2 , ..., η i , ..., η n . η i ∈ R d and ξ i ∈ R d are d-dimensional vectors. In this case, d is equal to 2, representing two optimal hyperparameters (C and γ) required for search. 2) If the current iteration time t is less than the maximum iteration L, go to the subsequent steps; otherwise, proceed directly to step 9). 3) For each agent, train RBF-SVM with current position elements η i = (C i , γ i ). 4) Predict trained RBF-SVM with the test set for each agent and output its loss as a fitness value based on Eq. (  5 ):\n\nwhere M is the number of test samples and h i represents the predicted value for the i th test sample. 5) Sort all fitness values in ascending order and assign positions which have the corresponding top three fitness values as ξ 1 , ξ 2 and ξ 3 , respectively. The mathematical expressions are\n\n6) Update exploration-exploitation regulation function φ(t) based on Eq. (  9 ):\n\n7) For each search agent, update its position η i based on following equations:\n\nwhere and | • | represent Hadamard product operation and element wise absolute value operations, respectively; t is the iteration number; 1 ∈ R 2 and its elements are all ones; b i ∈ R 2 and c i ∈ R 2 are coefficient vectors.\n\nThe coefficients r i ∈ R 2 and s i ∈ R 2 are random vectors, where elements are in the range 0 to 1. 8) Accumulate iterative time and go back to step 2). 9) Output the optimal parameters ξ 1 = (C o , γ o ) and the trained SVM model. 10) Calculate the classification accuracy of the model based on the test set and end the X-GWO-SVM algorithm.\n\nWe demonstrate improvements of the proposed X-GWO-SVM algorithm with respect to its exploration and exploitation ability in following two subsections.\n\n1) Exploration: Conventionally, components of φ(t) are linearly decreased from 2 to 0 over the course of iterations  [53] , which models wolves approaching the prey. In our design, we set components of φ(t) non-linearly decrease from 2 to 0 with slower declining rate near 2 and faster declining rate near 0 (referring to Eq. (  9 )). Fig.  4  (a) demonstrates the components of φ(t) linearly (blue stars) and non-linearly (black circles) decreased from 2 to 0 over the course of iterations when the maximum iteration time L is set to 100. Clearly, for the designed nonlinear decreasing method, we can observe that there is slow declining at the left side of the black dash line (iteration time = 94), aiming to explore a larger range and increase exploration compared to the conventional linear way.\n\nAs discussed in  [53] , b i (t) with random values greater than 1 or less than -1 is used to oblige the search agent to diverge from the prey, which emphasizes exploration and allows the X-GWO-SVM algorithm to search globally. It should be noticed that the fluctuation range of b i (t) is also decreased under an effect of φ(t). Components of b i (t) are random values in the interval [-φ(t), φ(t)], where components of φ(t) are non-linearly decreased from 2 to 0 over the course of iterations  [53] . Fig.  4  (b) shows a variation of b i (t) when linear and nonlinear φ(t) are applied. The blue and grey shadows indicate variation trends for b i (t) when linear φ(t) and nonlinear φ(t) are applied, respectively. Obviously, the value of b i (t) (black circles) for nonlinear φ(t) applied has a larger range compared with the value of b i (t) (blue stars) for linear φ(t) at the left side of the black dash line, i.e., |b i (t)| > 1. In other words, the next search range for the fittest position in the nonlinear case smoothly attenuates before iteration reaches a threshold-94 in this figure, making sure a large exploration range.\n\n2) Exploitation (convergence): In  [53] , when updating the positions, the weights for α, β, and δ wolves are all the same. While for our proposed approach, when updating the positions, we assign more weight to the α wolf (referring to Eq. (  10 )), which emphasizes the importance of the α wolf. Consequently, the fittest solution from the previous iteration can be retained and continually influences the subsequent updating step, ensuring a faster convergence.\n\nWe can observe from Fig.  4  (a) that, for the designed nonlinear decreasing method, there is a much faster decay at the right side of the black dash line. To clearly track the convergence of φ(t), red-filled circles are utilized for the nonlinear case after the 94 th iteration. The convergence tends to speed up as the iteration continuously increases, whereas, The corresponding variations for components of b i (t) based on the components of φ(t) linearly (blue circles) and non-linearly (black circles) decreased over the course of iterations. The maximum iteration time L is set to 100 for both cases. The black dash line lies at the 94 th iteration. The red-filled circles aim to clearly indicate variations of φ(t) and b i (t) for the nonlinear case after the 94 th iteration.\n\nfor the conventional linear decreasing method, the components of φ(t) just evenly decrease from 2 to 0.\n\nAs we discussed before, the value of b i (t) is influenced by the value of φ(t). Therefore, a similar phenomenon can be observed in Fig.  4 (b) , where the value of b i (t) converges much faster than the linear case at the right side of the black dash line, i.e., |b i (t)| < 1. In other words, the next search range for the fittest position in the nonlinear case dramatically decreases after iteration time reaches 94.\n\nTo sum up, the proposed X-GWO-SVM algorithm does not require hyperparameter tuning on SVM in order to get good accuracy. Additionally, it improves the way of updating position by involving the fittest position α, which emphasizes the importance of the α wolf and keeps the effect of the fittest solution for the next iteration. We also enhance the ability of exploitation by nonlinearly decreasing the value of φ(t). The algorithm improves its global search ability by increasing the exploration ability and speeds up the convergence ability by increasing the exploitation ability.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "C. Measurements",
      "text": "The classification performance of various methods can be evaluated by standard statistical measurements: accuracy (ACC) and F1-score (F1), defined as\n\nwhere TP (true positive) is the number of samples correctly predicted as the current class; TN (true negative) means the number of correctly predicted as other classes; FP (false positive) indicates the number of samples incorrectly detected as the current class; FN (false negative) denotes the number of samples incorrectly detected as other classes. Accuracy is the general measurement of the correctly predicted ratio of the total testing samples for each dataset, indicating the method's capability to classify emotions correctly. The F1-score, on the other hand, more accurately captures the ideal model for the unbalanced class distribution. The goal is to maximize these two measures as representations of effective models.",
      "page_start": 5,
      "page_end": 7
    },
    {
      "section_name": "Iv. Results",
      "text": "",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "A. Feature Dimension Selection",
      "text": "As aforementioned in Section III-A3, determination of a proper number of extracted features is necessary. Therefore, we perform feature importance selection in the range of 20 to 135 with step size 5 under the X-GWO-SVM method for iRealcare dataset. Each simulation result is repeated 10 times for random selection of training and test samples. Fig.  7  illustrates the accuracy versus the dimension of the feature under the X-GWO-SVM algorithm with 10-fold crossvalidation for the iRealcare dataset. Clearly, the recognition accuracy displays the tendency to rise up at the beginning and decline in late. The highest mean accuracy is 93.37% located at the feature dimension equal to 95. Moreover, its corresponding box plot (filled with orange color) has relatively low variance, indicating the stability of this feature dimension. After getting the most discriminative result with feature dimension 95, we apply it to other comparison methods.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "B. Exploration-Exploitation Regulation Function Selection",
      "text": "As we demonstrated the significance of explorationexploitation regulation function φ(t) in Section III-B, various exploration-exploitation regulation functions are used in our experiments here to demonstrate that our choice of φ(t) used in the X-GWO-SVM algorithm is the best. Expressions on them are shown in Eqs. (  15 ) to  (19)    be noticed that the conventional linear exploration-exploitation regulation function, a benchmark, is expressed in Eq.  (15) . Additionally, the one we proposed in the X-GWO-SVM in Eq. (  9 ) is rewritten as f φ4 (t) in Eq.  (18) .\n\nBased on Fig.  6 , we can observe that both f φ2 and f φ3 are deformed from the Sigmoid function, which dramatically decrease from 2 to 0 at the beginning and the end of the iteration, respectively. The function f φ4 and function f φ5 successively alleviate this decreasing trend on a basis of function 1\n\nx and cos, respectively. To evaluate the effects of exploration-exploitation regulation function, we apply 10-fold cross-validation to the proposed X-GWO-SVM, varying exploration-exploitation regulation functions based on the aforementioned five functions. The evaluated results on exploration-exploitation regulation functions are shown in  computation time. A similar conclusion can be derived for results on the WESAD dataset, where the highest accuracy (95.93%) and F1-score (95.56%) are from the combination of X-GWO-SVM with f φ4 . To this end, we have determined the optimal feature dimension-95, and exploration-exploitation regulation function-f φ4 . Therefore, later evaluations of the proposed X-GWO-SVM are based on these two settings.  C. Classification Performance of Proposed Model 1) Classification Performance for of iRealcare dataset: One may suspect that only one of the improvements on X-GWO-SVM can achieve a considerable performance. Thus, we investigate the other three methods: 1) using the GWO-SVM method, where none of the improvement on GWO is applied; 2) using the nonlinear φ(t) based grey wolf optimizer (N-GWO-SVM) method, where only the nonlinearly decreasing value of φ(t) is used; 3) using PSO-SVM method, where the conventional PSO algorithm is used for searching optimal hyperparameters.\n\nTables IV to VII show the classification performance for the hyperparameter optimizer-based techniques stated above. The following metrics are reported: accuracy, F1-score, variation of accuracy, and training duration of the schemes. All of them are calculated from 10 repeated classification trials for each scheme (rows in Tabs. IV to VII). Table  IV  shows that GWO-SVM performs significantly better than PSO-SVM for peacefulness (84.07% vs. 83.20%), excitement (97.67% vs. 84.87%), and tension (94.73% vs. 91.13%), but N-GWO-SVM only slightly improved performance on peacefulness (84.60%) and excitement (97.93%). Except for a slightly lower performance on happiness compared to the PSO-SVM scheme (95.07% vs 95.40%), the proposed X-GWO-SVM scheme provides a significant performance boost over others. It has the highest accuracy for peacefulness, excitement, and tension of 86.03%, 98.03%, and 94.33%, respectively. Table V presents similar results for the mean F1 score. The proposed X-GWO-SVM scheme provides a significant performance boost over others.  The variance result in Table VI suggests a similar conclusion. Compared to the conventional PSO-SVM scheme or GWO-SVM scheme, except for the variance on peacefulness (6.01E-04 vs 6.00E-04), our proposed method also shows the lowest variance of accuracy on excitement (6.04E-05), happiness (1.38E-04) and tension (7.65E-05), indicating its stability.\n\nTable  VII  shows the mean accuracy, the mean variance and the mean training time of 10-fold cross-validation results. Note that, the proposed X-GWO-SVM scheme has the highest  To demonstrate the the significance of our X-GWO-SVM scheme, we also examine other nonparametric classification methods using similar features on the iRealcare dataset, such as RF and K-NN. The results are shown in Table  VIII . All of them are calculated from 10 repeated classification trials for each scheme. It is apparent from the results that the X-GWO-SVM scheme has the highest accuracy performance. Actually, RF is more stable than the X-GWO-SVM, while its accuracy and F1-score are much lower than the proposed scheme (81.71% vs 93.37%, 82.35% vs 93.38%, respectively). In addition, the X-GWO-SVM completely outperforms K-NN in terms of reliability and stability. Overall, the proposed X-GWO-SVM strategy is more stable and more effective at achieving high mean accuracy on the iRealcare dataset than the existing methods.\n\n2) Classification Performance for WESAD dataset: To demonstrate the reliability and stability of the proposed X-GWO-SVM method, we further examine it on the WESAD dataset in terms of accuracy and F1-score, compared with other existing methods. By applying the feature dimension selection in the range of 4000 to 10000 with step size 500 under the X-GWO-SVM approach as we described in Section IV-B, the best feature dimension is found to be 5000. Fig.  7  illustrates the accuracy versus the dimension of the feature under the X-GWO-SVM algorithm with 10-cross validation for the WESAD dataset. Clearly, the recognition accuracy has a similar pattern to Fig.  6 , in which it increases initially and decreases afterwards. The highest mean accuracy is 95.93% located at the feature dimension equal to 5000. The corresponding box plot has the highest accuracy-96.30%, the lowest accuracy-94.44%, and the mean F1-score-95.56%. Moreover, its corresponding box plot also has a relatively low mean variance (5.49E-05), indicating the stability of this feature dimension. The mean training time is 113.07s, in this case.\n\nTable IX presents a comparison between the proposed classification scheme and the state-of-the-art methods published for single channel ECG-based emotion recognition methods on the WESAD dataset. The same testing dataset ensures that the comparison is persuasive and feasible. It can be observed from Table  IX  that the proposed classification approach outperforms all simple machine learning methods, such as RF, K-NN, linear discriminant analysis, and decision tree. Though slightly inferior to that of self-supervised CNN, the proposed X-GWO-SVM technique exhibits comparable classification performance among deep neural networks. However, considering the computation complexity, the proposed method is much simpler and more efficient than the selfsupervised CNN. Our algorithm has successfully been loaded into a lightweight embedded system with a prediction time of 2.659ms per 200-points iRealcare sample and 4.648ms per 14000-points WESAD sample. Details on these results will be discussed in Section V-C3. Overall, the proposed X-GWO-SVM method achieves comparable accuracy and F1score (Fig.  7  and Table  IX  ) among neural network-based deep learning classifiers on the WESAD dataset and has an overwhelming performance on other existing techniques.",
      "page_start": 8,
      "page_end": 9
    },
    {
      "section_name": "V. Discussion",
      "text": "The X-GWO-SVM algorithm, for the first time, is proposed and also the first time used in single channel ECG-based emotion recognition. By designing a suitable explorationexploitation regulation function and updating technique, we are able to increase the exploration ability and exploitation ability with the proposed approach. Two ECG datasets are used: one raw self-collected iRealcare dataset and one credible WESAD dataset. The X-GWO-SVM technique effectively avoids the algorithm from falling into a local solution; hence, it has a greater recognition accuracy than the existing GWO-SVM and PSO-SVM techniques for ECG emotion recognition.\n\nThe algorithm enables accurate, stable, and efficient emotion recognition based on single-channel ECG-based signals, which fills a gap for GWO-SVM research on ECG-based emotion recognition and also has the potential for clinical use.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "A. Evaluation Of Datasets",
      "text": "Despite the restricted number of subjects in the iRealcare dataset, the number of samples for each subject is sufficient since the time of data collection for each emotion is sufficient. It is true that the WESAD dataset contains a larger number of subjects; however, the sample length required for this dataset to achieve high accuracy, which is 14000, drastically reduces the actual number of samples, for example, 9 samples for each subject on amusement, 15-18 samples for each subject on stress, and 28-29 samples for each subject on the baseline. On the contrary, the sample length required for the iRealcare dataset to achieve high accuracy, which is only 200. Therefore, the number of samples for the iRealcare dataset is much larger than the one in the WESAD dataset.\n\nThe reason for the caused aforementioned situation might come from the way of giving external stimulus and recording data. For the iRealcare dataset, ECG signals for happiness, tension, and excitement are recorded when subjects watch comedies, watch thriller movies and do exercises, respectively. It should be noticed that emotions normally instantaneously occur and hold for a short period. Therefore, we only record the period that subjects are actually in that emotion condition and ignore the transition period. Clearly, the definition of different emotions under this external stimulus setting is clear and subjects are easy to get into a specific emotion. However, for the WESAD dataset, amusement condition signals are collected when subjects watch funny video clips; stress condition signals are collected when subjects are asked to provide public speaking and mental arithmetic tasks; baseline condition signals are collected when subjects sit/stand at a table and read magazines. In fact, subjects tend to take some time to transfer from one emotion condition to the other. However, such a transition period is also recorded in the WESAD dataset. Thus, the sample length need to be long enough to make sure not just the transition period is included. The shorter the time, the more probable it is that only transitional periods will be included in the sample.\n\nTo sum up, in spite of the fact that the iRealcare dataset has limited subjects, the actual number of samples is much larger than the one in the WESAD dataset. Moreover, due to the exclusive emotion transition period for the WESAD dataset, the selection of sample length for the iRealcare dataset is more flexible than the WESAD dataset. We use the widely-used WESAD dataset as a benchmark for further comparison to validate our proposed X-GWO-SVM algorithm.",
      "page_start": 10,
      "page_end": 11
    },
    {
      "section_name": "B. Evaluation Of Exploration-Exploitation Regulation Function Selection",
      "text": "We study the impact of exploration-exploitation regulation functions on emotion recognition performance. For this study, we select possible base functions that control the significance of each exploration-exploitation regulation function as listed in Eqs.  (15)  to  (19) . Table  II  and Table  III  show the emotion recognition performance for five explorationexploitation regulation functions on the iRealcare dataset and WESAD dataset, respectively. This analysis provides in-depth insight into the effect of the exploration-exploitation regulation functions associated with the emotion recognition outcome. Furthermore, this analysis helps us narrow down the most suitable exploration-exploitation regulation function in order to achieve the best performance.\n\nAs we mentioned in Section III-B, the declining rate of the exploration-exploitation regulation function at the beginning and end with respect to the iteration time represents the exploration and exploitation ability of the proposed X-GWO-SVM. From Table  II  and Table  III , we notice that for the exploration-exploitation regulation function f φ3 , where the function is formed on a basis of the sigmoid function, the model performance on emotion recognition is poor since it is under-explored and under-exploited. However, for those exploration-exploitation regulation functions lying above the benchmark function f φ1 , the model shows significantly better performance. Interestingly, the performance drops when exploration-exploitation regulation functions decline too fast (f φ2 ) or too slow (f φ5 ). The function f φ4 gives the highest performance for emotion recognition compared to others since it has the most suitable diverging and converging performance to the X-GWO-SVM algorithm. Moreover, the fact that f φ4 outperformed other functions for both datasets is also indicative of its stability.\n\nIn summary, the analysis above shows that for all the exploration-exploitation regulation functions, when the declining rate of the function at the beginning is too large or too small, for example, f φ3 or f φ2 , emotion recognition accuracy drops due to the under-exploration or over-exploration. This results in the X-GWO-SVM more easily falling into local solutions. Similarly, when the declining rate of the function at the end is too large or too small, f φ2 or f φ3 , the performance also drops due to the under-exploitation or over-exploitation in such cases becomes too difficult for the algorithm to properly find the global solution. Hence, we conclude that there is a tradeoff between exploration and exploitation for the explorationexploitation regulation functions associated with the proposed X-GWO-SVM algorithm, for which the proper explorationexploitation regulation function f φ4 is applied resulting in avoiding falling into local solutions.",
      "page_start": 10,
      "page_end": 11
    },
    {
      "section_name": "C. Evaluation Of Reliability, Stability And Efficiency Of X-Gwo-Svm",
      "text": "This section discusses the performance of X-GWO-SVM for emotion recognition in terms of reliability, stability, and efficiency.\n\n1) Reliability: In our work, when only fusing explorationexploitation regulation function f φ4 with GWO-SVM, i.e., N-GWO-SVM, the classification accuracy and F1-score get improved (referring to Table  IV , Table  V  and Table VII ). This improvement indicates that involving a nonlinear explorationexploitation regulation function can improve the recognition performance. Similarly, the classification accuracy and F1score get further enhanced when the importance of the α wolf is emphasized, i.e., X-GWO-SVM, which shows the equivalent importance of the improvement on the X-GWO-SVM.\n\nThe classification performance of X-GWO-SVM is superior to the classification performance of other hyperparameter optimizer-based systems, such as PSO-SVM and GWO-SVM. This indicates the high reliability of the proposed algorithm over existing common hyperparameter optimizer-based schemes. Furthermore, the X-GWO-SVM has the highest accuracy and F1-score among simple machine learning methods, such as RF, K-NN, decision tree, and linear discriminant analysis (Table VIII and Table  IX ). Our analysis indicates that the X-GWO-SVM is more effective than simple machine learning approaches at avoiding local solutions. For the deep learning neural networks, such as CNN, the X-GWO-SVM can still outperform them except for a more complex singleself-supervised CNN  [29] . Though the accuracy and F1-score of the X-GWO-SVM are slightly lower than the one from the self-supervised CNN, considering the efficiency, which will be discussed in Section V-C3, our algorithm is still competitive.\n\n2) Stability: The variance of the proposed method and existing works is computed to evaluate the stability of the methods. All simulation results are applied with 10-fold crossvalidation. Similar to the discussion in Section V-C1, the X-GWO-SVM is the most stable algorithm among existing common hyperparameter optimizer-based schemes. Besides, similar results on both the iRealcare dataset and the WESAD dataset also indicate the stability of the proposed method.\n\n3) Efficiency: Our works are implemented through both MATLAB version R2021b and Python 3.7 for feature extraction, model training, and prediction. For MATLAB, the computation is performed on a laptop with 11th Gen Intel(R) Core(TM) i7-11800H (2.2GHz and 32GB of RAM). The computation time for classifying a 200-points (1.56s) iRealcare sample and a 14000-points (20s) WESAD sample roughly spends 0.355ms and 0.778ms, respectively, using our proposed method. For Python, the computation is performed in JETSON NANO with Quad-core ARM Cortex-A57 MPCore Processor (1.43GHz and 4GB of RAM). The computation time for classifying a 200-points (1.56s) iRealcare sample and a 14000points (20s) WESAD sample roughly spends 2.659ms and 4.648ms, respectively, using our proposed method.\n\nCompared with the self-supervised CNN, a deep neural network, the proposed X-GWO-SVM is much simpler. The twostep self-supervised architecture involves deep convolutional blocks and several fully connected layers in  [29] , which may not be realized in lightweight embedded systems. Whereas, our algorithm has successfully been loaded into JETSON NANO, an embedded system-on-module and developer kit with a prediction time of 2.659ms per 200-points iRealcare sample and 4.648ms per 14000-points WESAD sample. This provides a way to embed an ECG patch with the proposed algorithm, achieving edge computing for emotion recognition on ECG signals.\n\nMoreover, the X-GWO-SVM is the most efficient algorithm among existing common hyperparameter optimizerbased schemes, which is evaluated by the training time. The other interesting point that can be found in Table  VII  is that all GWO-SVM-based techniques take shorter training time than the PSO-SVM work, which is compatible with  [35] 's conclusion.",
      "page_start": 10,
      "page_end": 11
    },
    {
      "section_name": "D. Limitations And Future Directions",
      "text": "The possible limitation of the current study would be that we only investigate four exploration-exploitation regulation functions, i.e., f φ2 , f φ3 , f φ4 , and f φ5 . Moreover, the dataset we collected is still insufficient and other existing published datasets, e.g., AMIGOS  [27] , Augsburg Biosignal Toolbox (AuBT)  [54] , etc., have not been verified by the proposed X-GWO-SVM algorithm. In future work, we will use other exploration-exploitation regulation functions for the proposed algorithm to explore their effectiveness in emotion recognition. Additionally, more published datasets will be examined by our method.\n\nBesides, through the results and conclusions reported in  [29] , we also observed that deep learning is competitive in emotion recognition, which may further improve the performance of our proposed strategy. Thus in our future work, we will try to find an effective deep learning method and embedded GWO methods to further improve emotion recognition performance.",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Vi. Conclusion",
      "text": "In this paper, we presented an X-GWO-SVM technique that improves the exploration and exploitation abilities of single channel ECG-based emotion recognition. In order to classify different emotions, this research used two reliable datasets: one trustworthy WESAD dataset and one raw self-collected iRealcare dataset. The single channel ECG signals could well be employed in the X-GWO-SVM algorithm for emotion recognition, according to 10-fold cross-validation results from 5 subjects for the iRealcare dataset and 15 subjects for the WE-SAD dataset. The algorithm performed better than past efforts that used various supervised machine learning techniques. It also provides a way to implement in the lightweight embedded system, which is much more efficient than existing solutions of using deep neural networks. The method has the potential to be used in clinical settings and also fills a gap in GWO-SVM research on ECG-based emotion identification. In our future work, we will apply radio sensing techniques, such as  [42] ,  [55] -  [58] , instead of wearable devices for emotion recognition. We will also develop privacy preservation algorithms  [59] -  [62]  to protect the users' privacy.",
      "page_start": 11,
      "page_end": 11
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: depicts four emotion segments with 200 randomly",
      "page": 3
    },
    {
      "caption": "Figure 1: The ECG segments with 200 points (1.56s) from four emotions",
      "page": 4
    },
    {
      "caption": "Figure 2: shows corresponding extracted features with dimension",
      "page": 4
    },
    {
      "caption": "Figure 2: The extracted features from ECG segments with dimension of 95",
      "page": 4
    },
    {
      "caption": "Figure 3: Flow chart of the X-GWO-SVM algorithm. Total number of",
      "page": 5
    },
    {
      "caption": "Figure 3: demonstrates our X-GWO-SVM method, which is",
      "page": 5
    },
    {
      "caption": "Figure 4: (a) demonstrates",
      "page": 6
    },
    {
      "caption": "Figure 4: (b) shows a variation of bi(t) when",
      "page": 6
    },
    {
      "caption": "Figure 4: (a) that, for the designed",
      "page": 6
    },
    {
      "caption": "Figure 4: (a) Components of φ(t) linearly (blue circles) and non-linearly",
      "page": 6
    },
    {
      "caption": "Figure 4: (b), where the value of bi(t) converges",
      "page": 6
    },
    {
      "caption": "Figure 7: illustrates the accuracy versus the dimension of the",
      "page": 7
    },
    {
      "caption": "Figure 6: It should",
      "page": 7
    },
    {
      "caption": "Figure 5: The accuracy versus the dimension of the feature under the X-",
      "page": 7
    },
    {
      "caption": "Figure 6: , we can observe that both fφ2 and fφ3",
      "page": 7
    },
    {
      "caption": "Figure 6: Variations of components of φ(t) for different exploration-",
      "page": 8
    },
    {
      "caption": "Figure 7: illustrates the accuracy versus the dimension of",
      "page": 9
    },
    {
      "caption": "Figure 6: , in which it increases",
      "page": 9
    },
    {
      "caption": "Figure 7: and Table IX ) among neural network-based",
      "page": 9
    },
    {
      "caption": "Figure 7: The accuracy versus the dimension of the feature under the X-",
      "page": 9
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "th\nPeacefulness si\n220\nby\n200 Fi\n180 u\n0 0.5 1 1.5 fr\nExcitment It\n220 en\n) 200 si\nV\nm 180 w\n( e 0 0.5 1 1.5 fic\ng\na Happiness si\nt\nlo 220 se\nV\n200\n180\n0 0.5 1 1.5\nTension\n220\n200\n180\n0 0.5 1 1.5\nTime(s) t": "",
          "Column_2": "t"
        }
      ],
      "page": 4
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "An implementation of an internet of things system for smart hospitals",
      "authors": [
        "J Leng",
        "Z Lin",
        "P Wang"
      ],
      "year": "2020",
      "venue": "2020 IEEE/ACM Fifth International Conference on Internet-of-Things Design and Implementation (IoTDI)"
    },
    {
      "citation_id": "2",
      "title": "Accumulate Then Transmit: Multi-user Scheduling in Full-Duplex Wireless-Powered IoT Systems",
      "authors": [
        "D Zhai",
        "H Chen",
        "Z Lin",
        "B Li",
        "Vucetic"
      ],
      "year": "2018",
      "venue": "IEEE Internet of Things Journal"
    },
    {
      "citation_id": "3",
      "title": "Optimal Power Splitting for MIMO SWIPT Relaying Systems with Direct Link in IoT Networks",
      "authors": [
        "J Wang",
        "B Li",
        "G Wang",
        "Z Lin",
        "H Wang",
        "G Chen"
      ],
      "year": "2020",
      "venue": "Physical Communication"
    },
    {
      "citation_id": "4",
      "title": "Power and rate adaptation for wireless network coding with opportunistic scheduling",
      "authors": [
        "B Lin",
        "Vucetic"
      ],
      "venue": "2008 IEEE International Symposium on Information Theory"
    },
    {
      "citation_id": "5",
      "title": "Performance analysis of dense small cell networks with dynamic TDD",
      "authors": [
        "M Ding",
        "G Ding",
        "Z Mao",
        "Lin",
        "D Zomaya",
        "López-Pérez"
      ],
      "year": "2018",
      "venue": "IEEE Transactions on Vehicular Technology"
    },
    {
      "citation_id": "6",
      "title": "Network coding based wireless broadcast with performance guarantee",
      "authors": [
        "G Wang",
        "Z Mao",
        "X Lin",
        "Ge",
        "Anderson Bdo"
      ],
      "year": "2014",
      "venue": "IEEE Transactions on Wireless Communications"
    },
    {
      "citation_id": "7",
      "title": "Distributed network-channel codes design with short cycles removal",
      "authors": [
        "Pang",
        "Y Lin",
        "B Li",
        "Vucetic"
      ],
      "year": "2012",
      "venue": "IEEE Wireless Communications Letters"
    },
    {
      "citation_id": "8",
      "title": "Network Code Division Multiplexing for Wireless Relay Networks",
      "authors": [
        "J Yue",
        "Z Lin",
        "B Vucetic",
        "G Mao",
        "M Xiao",
        "B Bai",
        "K Pang"
      ],
      "year": "2015",
      "venue": "IEEE Transactions on Wireless Communications"
    },
    {
      "citation_id": "9",
      "title": "Performance analysis of distributed raptor codes in wireless sensor networks",
      "authors": [
        "J Yue",
        "Z Lin",
        "B Vucetic",
        "G Mao",
        "T Aulin"
      ],
      "year": "2013",
      "venue": "IEEE Transactions on Communications"
    },
    {
      "citation_id": "10",
      "title": "Performance analysis of raptor codes under maximum likelihood decoding",
      "authors": [
        "P Wang",
        "G Mao",
        "Z Lin",
        "W Ding",
        "X Liang",
        "Z Ge",
        "Lin"
      ],
      "year": "2016",
      "venue": "IEEE Transactions on Communications"
    },
    {
      "citation_id": "11",
      "title": "Joint network-channel code design for real wireless relay networks",
      "authors": [
        "K Pang",
        "Z Lin",
        "Y Li",
        "B Vucetic"
      ],
      "year": "2010",
      "venue": "the 6th International Symposium on Turbo Codes & Iterative Information"
    },
    {
      "citation_id": "12",
      "title": "New rate-compatible repetition convolutional codes",
      "authors": [
        "Z Lin",
        "A Svensson"
      ],
      "venue": "IEEE Transactions on Information Theory"
    },
    {
      "citation_id": "13",
      "title": "Design of Network Coding Schemes in Wireless Network",
      "authors": [
        "Z Lin"
      ],
      "year": "2022",
      "venue": "Design of Network Coding Schemes in Wireless Network"
    },
    {
      "citation_id": "14",
      "title": "Emotion detection from speech to enrich multimedia content",
      "authors": [
        "F Yu",
        "E Chang",
        "Y.-Q Xu",
        "H.-Y Shum"
      ],
      "year": "2001",
      "venue": "Proceedings of the Pacific-Rim Conference on Multimedia"
    },
    {
      "citation_id": "15",
      "title": "Facial emotion recognition using multi-modal information",
      "authors": [
        "L De Silva",
        "T Miyasato",
        "R Nakatsu"
      ],
      "year": "1997",
      "venue": "Proceedings of 1997 International Conference on Information, Communications and Signal Processing"
    },
    {
      "citation_id": "16",
      "title": "Automatic ECGbased emotion recognition in music listening",
      "authors": [
        "Y.-L Hsu",
        "J.-S Wang",
        "W.-C Chiang",
        "C.-H Hung"
      ],
      "year": "2017",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "17",
      "title": "Significant low-dimensional spectral-temporal features for seizure detection",
      "authors": [
        "X Yan",
        "D Yang",
        "Z Lin",
        "B Vucetic"
      ],
      "year": "2022",
      "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering"
    },
    {
      "citation_id": "18",
      "title": "Hybrid emotion-aware monitoring system based on brainwaves for internet of medical things",
      "authors": [
        "W Meng",
        "Y Cai",
        "L Yang",
        "W.-Y Chiu"
      ],
      "year": "2021",
      "venue": "IEEE Internet of Things Journal"
    },
    {
      "citation_id": "19",
      "title": "Ssvep based emotion recognition for iot via multiobjective neural architecture search",
      "authors": [
        "Y Du",
        "J Liu",
        "X Wang",
        "P Wang"
      ],
      "year": "2022",
      "venue": "IEEE Internet of Things Journal"
    },
    {
      "citation_id": "20",
      "title": "Robust r-peak detection in low-quality holter ecgs using 1d convolutional neural network",
      "authors": [
        "M Zahid",
        "S Kiranyaz",
        "T Ince",
        "O Devecioglu",
        "M Chowdhury",
        "A Khandakar",
        "A Tahir",
        "M Gabbouj"
      ],
      "year": "2021",
      "venue": "IEEE Transactions on Biomedical Engineering"
    },
    {
      "citation_id": "21",
      "title": "Handbook of Psychophysiology",
      "authors": [
        "J Cacioppo",
        "L Tassinary",
        "G Berntson"
      ],
      "year": "2007",
      "venue": "Handbook of Psychophysiology"
    },
    {
      "citation_id": "22",
      "title": "ECG pattern analysis for emotion detection",
      "authors": [
        "F Agrafioti",
        "D Hatzinakos",
        "A Anderson"
      ],
      "year": "2012",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "23",
      "title": "A novel ECG-based realtime detection method of negative emotions in wearable applications",
      "authors": [
        "Z Cheng",
        "L Shu",
        "J Xie",
        "C Chen"
      ],
      "year": "2017",
      "venue": "Proceedings of 2017 International Conference on Security, Pattern Analysis, and Cybernetics"
    },
    {
      "citation_id": "24",
      "title": "An efficient method to face and emotion detection",
      "authors": [
        "D Reney",
        "N Tripathi"
      ],
      "year": "2015",
      "venue": "Proceedings of 2015 fifth International Conference on Communication Systems and Network Technologies"
    },
    {
      "citation_id": "25",
      "title": "A brief review of facial emotion recognition based on visual information",
      "authors": [
        "B Ko"
      ],
      "year": "2018",
      "venue": "Sensors"
    },
    {
      "citation_id": "26",
      "title": "A review of emotion recognition using physiological signals",
      "authors": [
        "L Shu",
        "J Xie",
        "M Yang",
        "Z Li",
        "Z Li",
        "D Liao",
        "X Xu",
        "X Yang"
      ],
      "year": "2018",
      "venue": "Sensors"
    },
    {
      "citation_id": "27",
      "title": "Electrocardiogram-based emotion recognition systems and their applications in healthcare-a review",
      "authors": [
        "M Hasnul",
        "N Aziz",
        "S Alelyani",
        "M Mohana",
        "A Aziz"
      ],
      "year": "2021",
      "venue": "Sensors"
    },
    {
      "citation_id": "28",
      "title": "Self-supervised ECG representation learning for emotion recognition",
      "authors": [
        "P Sarkar",
        "A Etemad"
      ],
      "year": "2020",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "29",
      "title": "Hybrid deep neural networks for face emotion recognition",
      "authors": [
        "N Jain",
        "S Kumar",
        "A Kumar",
        "P Shamsolmoali",
        "M Zareapoor"
      ],
      "year": "2018",
      "venue": "Pattern Recognition Letters"
    },
    {
      "citation_id": "30",
      "title": "How to tune the RBF SVM hyperparameters? an empirical evaluation of 18 search algorithms",
      "authors": [
        "J Wainer",
        "P Fonseca"
      ],
      "year": "2021",
      "venue": "Artificial Intelligence Review"
    },
    {
      "citation_id": "31",
      "title": "Performance evaluation of hybrid GA-SVM and GWO-SVM models to predict earthquake-induced liquefaction potential of soil: a multi-dataset investigation",
      "authors": [
        "J Zhou",
        "S Huang",
        "M Wang",
        "Y Qiu"
      ],
      "year": "2021",
      "venue": "Engineering with Computers"
    },
    {
      "citation_id": "32",
      "title": "Application of GWO-SVM algorithm in arc detection of pantograph",
      "authors": [
        "B Li",
        "C Luo",
        "Z Wang"
      ],
      "year": "2020",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "33",
      "title": "An improved grey wolf optimization strategy enhanced SVM and its application in predicting the second major",
      "authors": [
        "Y Wei",
        "N Ni",
        "D Liu",
        "H Chen",
        "M Wang",
        "Q Li",
        "X Cui",
        "H Ye"
      ],
      "year": "2017",
      "venue": "Mathematical Problems in Engineering"
    },
    {
      "citation_id": "34",
      "title": "Feature subset selection approach by gray-wolf optimization",
      "authors": [
        "E Emary",
        "H Zawbaa",
        "C Grosan",
        "A Hassenian"
      ],
      "year": "2015",
      "venue": "Proceedings of Afro-European Conference for Industrial Advancement"
    },
    {
      "citation_id": "35",
      "title": "Color difference classification based on optimization support vector machine of improved grey wolf algorithm",
      "authors": [
        "Z Zhou",
        "R Zhang",
        "Y Wang",
        "Z Zhu",
        "J Zhang"
      ],
      "year": "2018",
      "venue": "Optik"
    },
    {
      "citation_id": "36",
      "title": "Detection of ECG characteristic points using wavelet transforms",
      "authors": [
        "C Li",
        "C Zheng",
        "C Tai"
      ],
      "year": "1995",
      "venue": "IEEE Transactions on Biomedical Engineering"
    },
    {
      "citation_id": "37",
      "title": "Wearable electrocardiogram signal monitoring and analysis based on convolutional neural network",
      "authors": [
        "L Meng",
        "K Ge",
        "Y Song",
        "D Yang",
        "Z Lin"
      ],
      "year": "2021",
      "venue": "IEEE Transactions on Instrumentation and Measurement"
    },
    {
      "citation_id": "38",
      "title": "Negative-resnet: noisy ambulatory electrocardiogram signal classification scheme",
      "authors": [
        "Z Chen",
        "Z Lin",
        "P Wang",
        "M Ding"
      ],
      "year": "2021",
      "venue": "Neural Computing and Applications"
    },
    {
      "citation_id": "39",
      "title": "A wearable ECG monitor for deep learning based real-time cardiovascular disease detection",
      "authors": [
        "P Wang",
        "Z Lin",
        "X Yan",
        "Z Chen",
        "M Ding",
        "Y Song",
        "L Meng"
      ],
      "year": "2022",
      "venue": "A wearable ECG monitor for deep learning based real-time cardiovascular disease detection",
      "arxiv": "arXiv:2201.10083"
    },
    {
      "citation_id": "40",
      "title": "Wireless electrocardiograph monitoring based on wavelet convolutional neural network",
      "authors": [
        "X Yan",
        "Z Lin",
        "P Wang"
      ],
      "year": "2020",
      "venue": "Proceedings of 2020 IEEE Wireless Communications and Networking Conference Workshops (WCNCW)"
    },
    {
      "citation_id": "41",
      "title": "Human biometric signals monitoring based on wifi channel state information using deep learning",
      "authors": [
        "M Liu",
        "Z Lin",
        "P Xiao",
        "W Xiang"
      ],
      "year": "2022",
      "venue": "Human biometric signals monitoring based on wifi channel state information using deep learning",
      "arxiv": "arXiv:2203.03980"
    },
    {
      "citation_id": "42",
      "title": "Introducing wesad, a multimodal dataset for wearable stress and affect detection",
      "authors": [
        "P Schmidt",
        "A Reiss",
        "R Duerichen",
        "C Marberger",
        "K Van Laerhoven"
      ],
      "year": "2018",
      "venue": "Proceedings of the 20th ACM International Conference on Multimodal Interaction"
    },
    {
      "citation_id": "43",
      "title": "Noise analysis and different denoising techniques of ECG signal-a survey",
      "authors": [
        "A Velayudhan",
        "S Peter"
      ],
      "year": "2016",
      "venue": "IOSR Journal of Electronics and Communication Engineering"
    },
    {
      "citation_id": "44",
      "title": "Signal processing techniques for removing noise from ECG signals",
      "authors": [
        "R Kher"
      ],
      "year": "2019",
      "venue": "J. Biomed. Eng. Res"
    },
    {
      "citation_id": "45",
      "title": "Comparison of the design of fir and iir filters for a given specification and removal of phase distortion from iir filters",
      "year": "2017",
      "venue": "Proceedings of 2017 International Conference on Advances in Computing, Communication and Control"
    },
    {
      "citation_id": "46",
      "title": "An explainable deep fusion network for affect recognition using physiological signals",
      "authors": [
        "J Lin",
        "S Pan",
        "C Lee",
        "S Oviatt"
      ],
      "year": "2019",
      "venue": "Proceedings of the 28th ACM International Conference on Information and Knowledge Management"
    },
    {
      "citation_id": "47",
      "title": "Visual speech recognition for isolated digits using discrete cosine transform and local binary pattern features",
      "authors": [
        "A Jain",
        "G Rathna"
      ],
      "year": "2017",
      "venue": "Proceedings of 2017 IEEE Global Conference on Signal and Information Processing"
    },
    {
      "citation_id": "48",
      "title": "Face recognition using the discrete cosine transform",
      "authors": [
        "M Hafed",
        "M Ziad",
        "Andlevine"
      ],
      "year": "2001",
      "venue": "International Journal of Computer Vision"
    },
    {
      "citation_id": "49",
      "title": "Discrete cosine transform",
      "authors": [
        "N Ahmed",
        "T Natarajan",
        "K Rao"
      ],
      "year": "1974",
      "venue": "IEEE transactions on Computers"
    },
    {
      "citation_id": "50",
      "title": "Identification of conductive leakage signal in power cable based on multi-classification pso-svm",
      "authors": [
        "Z Qian",
        "C Zhou",
        "J Cheng",
        "Q Wang"
      ],
      "year": "2017",
      "venue": "Proceedings of 2017 IEEE 5th International Symposium on Electromagnetic Compatibility"
    },
    {
      "citation_id": "51",
      "title": "Parameter investigation of support vector machine classifier with kernel functions",
      "authors": [
        "A Tharwat"
      ],
      "year": "2019",
      "venue": "Knowledge and Information Systems"
    },
    {
      "citation_id": "52",
      "title": "Grey wolf optimizer",
      "authors": [
        "S Mirjalili",
        "S Mirjalili",
        "A Lewis"
      ],
      "year": "2014",
      "venue": "Advances in Engineering Software"
    },
    {
      "citation_id": "53",
      "title": "From physiological signals to emotions: Implementing and comparing selected methods for feature extraction and classification",
      "authors": [
        "J Wagner",
        "J Kim",
        "E André"
      ],
      "year": "2005",
      "venue": "Proceedings of 2005 IEEE International Conference on Multimedia and Expo"
    },
    {
      "citation_id": "54",
      "title": "Nonrandom microwave ghost imaging",
      "authors": [
        "X Wang",
        "Z Lin"
      ],
      "year": "2018",
      "venue": "IEEE Transactions on Geoscience and Remote Sensing"
    },
    {
      "citation_id": "55",
      "title": "Microwave surveillance based on ghost imaging and distributed antennas",
      "authors": [
        "X Wang",
        "Z Lin"
      ],
      "year": "2016",
      "venue": "IEEE Antennas and Wireless Propagation Letters"
    },
    {
      "citation_id": "56",
      "title": "Microwave ghost imaging via lte-dl signals",
      "authors": [
        "Z Zhang",
        "R Luo",
        "X Wang",
        "Z Lin"
      ],
      "year": "2018",
      "venue": "2018 International Conference on Radar (RADAR)"
    },
    {
      "citation_id": "57",
      "title": "Wi-fi based device-free microwave ghost imaging indoor surveillance system",
      "authors": [
        "R Luo",
        "Z Zhang",
        "X Wang",
        "Z Lin"
      ],
      "year": "2018",
      "venue": "2018 28th International Telecommunication Networks and Applications Conference (ITNAC)"
    },
    {
      "citation_id": "58",
      "title": "When Machine Learning Meets Privacy: A Survey and Outlook",
      "authors": [
        "B Liu",
        "M Ding",
        "S Shaham",
        "W Rahayu",
        "F Farokhi",
        "Z Lin"
      ],
      "venue": "ACM Computing Surveys, ACM Computing Surveys (IF",
      "doi": "10.1145/3436755"
    },
    {
      "citation_id": "59",
      "title": "Privacy Preservation in Location-Based Services: A Novel Metric and Attack Model",
      "authors": [
        "S Shaham",
        "M Ding",
        "B Liu",
        "S Dang",
        "Z Lin",
        "J Li"
      ],
      "year": "2021",
      "venue": "IEEE Transactions on Mobile Computing",
      "doi": "10.1109/TMC.2020.2993599"
    },
    {
      "citation_id": "60",
      "title": "Privacy-Preserving Location Data Publishing: A Machine Learning Approach",
      "authors": [
        "S Shaham",
        "M Ding",
        "B Liu",
        "S Dang",
        "Z Lin",
        "J Li"
      ],
      "year": "2021",
      "venue": "IEEE Transactions on Knowledge and Data Engineering",
      "doi": "10.1109/TKDE.2020.2964658"
    },
    {
      "citation_id": "61",
      "title": "Privacy-Preserved Optimal Energy Trading, Statistics, and Forecasting for a Neighborhood Area Network",
      "authors": [
        "D Smith",
        "P Wang",
        "M Ding",
        "J Chan",
        "B Spak",
        "X Guan",
        "P Tyler",
        "T Rakotoarivelo",
        "Z Lin",
        "T Abbasi"
      ],
      "year": "2020",
      "venue": "Computer",
      "doi": "10.1109/MC.2020.2972505"
    }
  ]
}