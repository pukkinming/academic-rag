{
  "paper_id": "2010.07209v1",
  "title": "Heartbees: Visualizing Crowd Affects",
  "published": "2020-10-14T16:23:12Z",
  "authors": [
    "Chao Ying Qin",
    "Marios Constantinides",
    "Luca Maria Aiello",
    "Daniele Quercia"
  ],
  "keywords": [
    "fear, anger, anticipation, trust, surprise, disgust, joy, and sadness Bio-feedback system",
    "Boids model",
    "Metaphorical Visualizations",
    "Collective Emotional States",
    "Biophilic design"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Affective sharing within groups strengthens coordination and empathy, leads to better health outcomes, and increases productivity and performance. Existing tools for affective sharing face one main challenge: creating a representation of collective emotional states that is relatable and universally accessible. To overcome this challenge, we propose HeartBees, a bio-feedback system for visualizing collective emotional states, which maps a multi-dimensional emotion model into a metaphorical visualization of flocks of birds. Grounded on Affective Computing literature and physiological sensing, we mapped physiological indicators that could be obtained from wearable devices into a multi-dimensional emotion model, which, in turn, our HeartBees can make use of. We evaluated our nature-inspired interactive system with 353 online participants, whose responses showed good consensus in the way they subjectively perceived the visualizations. Last, we discuss practical applications of HeartBees.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Emotional Intelligence (EI) is the ability of individuals to understand and recognize their own and other people's emotions in such a way that will help them alleviate stress and overcome challenges, communicate effectively, neutralize conflicts, and empathize with others  [36] . At individual level, developing EI helps building strong and lasting relationships, succeed at work, and, ultimately, improve at every aspect of their life. Emotional Intelligence is also an emergent property of groups. Research in the area of organizational behavior has accumulated abundant evidence that affective sharing within groups activates a positive self-reinforcing spiral that strengthens coordination and empathy among members  [47] . Supporting emotional intelligence at the collective level is therefore important to increase both people's wellbeing and their chances of success when cooperating. This objective poses one main challenge: one needs to create a representation of the collective emotional state that is relatable and universally accessible. To overcome this challenge, since the 70s, bio-feedback has been a widely employed mind-body technique to help people gain control over involuntary bodily functions  [17] . Traditionally, bio-feedback systems turn bodily signals (e.g., heart rate) into readable representations that can increase awareness of the connection between physiological states and the body's inner functioning. These systems often use numerical or simple graphical representations such as heartbeats (bpm) or electrocardiography waveforms. While these representations are easily comprehensible among the medical practitioners, they are not always easily interpretable by the general audience  [9] . An alternative way of conveying people's physiological signals is the use of metaphorical visualizations. This type of visualization creates an analogy between characteristics of well-understood, and often universally acceptable images or patterns, and a more poorly understood or complex data source  [57] ; our emotional states is one of them. It is also well-known that the use of Fig.  2 : Starling murmurations: simple rules, complex patterns. From left to right as the birds swoop  [52] , create unique yet complex patterns. These patterns might reflect the complexities of our collective emotional states.\n\nmetaphors and analogies are key aspects of human cognition  [3] , which enable humans to understand abstract information with familiar objects such as images or simulations  [2] . For example, previous systems made use of tangible artifacts that mimic real-world objects  [55] , light  [56] , or movement. Our contribution draws inspiration from this recent line of research. More importantly, the HCI and Ubiquitous Computing research has worked on tools that will help gather knowledge of psychological states from bodily signals at users' everyday environment, beyond medical facilities. In turn, these signals could be translated into our emotional states that bio-feedback systems can make use of. Recent advances in wearable sensing could facilitate systematic monitoring of large populations  [1, 16, 38]  to estimate collective emotional states through machine-learning algorithms  [14, 15, 27, 32] . By applying such models, for example, the Inbodied Interaction paradigm  [39]  foresees the design of interactive systems that listen and adapt to people's bodily signals.\n\nSpecifically, we aim to develop a visualization that maps a multidimensional emotion model, and uses a nature-inspired metaphor to visualize collective emotions of crowds. In so doing, we made two main contributions:\n\n• We developed HeartBees ( §4), a web-based bio-feedback system inspired by the Boids model. It maps a multi-dimensional emotion model in a metaphorical visualization of flocks of birds moving on a plane. In particular, it translates the eight primary emotions from Plutchik's theoretical model of emotions into motion configurations that control the movements of the Boids in the space. Grounded on Affective Computing and physiological sensing literature, we mapped physiological indicators that our HeartBees could make use of.\n\n• We evaluated our system's ability to convey people's emotional states through crowdsourcing ( §5). Our results showed that certain emotions, especially negative ones, were perceived as one would expect, and they were so by a variety of people.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Related Work",
      "text": "Our work relies on principles from Affective Computing, HCI, and InfoVis, which we describe next.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Affective Computing",
      "text": "The ability of machines to recognize and interpret human affects is the subject of Affective Computing  [29] . This branch of computing quantifies people's emotional state into discrete categories based on patterns discovered in various signals and cues such as facial, auditory, textual, gestures or bodily, and physiological signals. In human emotion literature, three most widely used schemas that describe a handful of basic emotions derived from biological responses are the Ekman's  [12]  six emotion model, Plutchik's  [30]  eight emotion categorization, and the positive-negative activation (PANAS) model of emotion created by Watson and Tellegen  [49] , which suggests that positive and negative affect are two separate systems. By employing such models, the scientific community proposed solutions that leverage bodily signals from wearable sensors and mobile phones  [37]  to detect stressful situations, regulate our emotional state  [9] , analyzed auditory input  [10] , textual sentiment in online discussions  [8, 35] , and facial cues from video streams  [24] . In practice, many consumer and enterprise products have been developed to offer behavioral suggestions for self-improvement. Affectiva employs facial video analysis to generate percentage representations of discrete emotional categories such as joy, anger, and fear to help businesses understand how their customers feel. Products such as Feel, Oura, and Moodmetric, to name a few, capture emotional states through physiological indicators (e.g., heart rate, skin conductance, EEG) to generate quantitative or categorical representations of emotional states, and recommend behavioral interventions to improve emotional wellness.\n\nAmong the various physiological indicators that are linked to our psychological and emotional states, heart rate variability (HRV) is a widely used one. HRV is the physiological phenomenon that describes the variation in the time interval between heartbeats, and has been found to be a promising physiological marker to assess humans' Autonomic Nervous System (ANS). In human body, the ANS is responsible for controlling body functions that are not consciously directed, such as the heartbeat or breathing  [6] . The ANS is divided into the sympathetic and parasympathetic nervous system. The former prepares the body for intense physical activity ('fight-or-flight'), while the latter prepares the body for relaxation ('rest and digest')  [6] . By capturing the activity of both components of the ANS, one can assess how well a person responds to physical or emotional stimuli  [7] . Today, wearable devices are fully equipped with 'body-sensors' such as motion, heart rate, skin conductance, and temperature sensors make it possible to gather complex physical measurements outside medical facilities to understand people's emotional states in free-living conditions. Their widespread adoption allows systematic monitoring of large populations  [1, 16, 38]  that can be used to estimate collective emotional states through machine-learning algorithms  [14, 15, 27, 32] . Quiroz et al.  [32]  used smartwatch readings from accelerometers and gyroscopes to detect changes in the way an individual walks, which, in turn, reflects that individual's current mood. Gjoreski et al.  [14]  used Empatica devices to detect stress by combining HRV and electrodermal activity analysis in controlled laboratory conditions, and then applied that knowledge in real-life data. Gloor et al.  [15]  showed that happiness is strongly linked with intense activity by combining data obtained from smartwatches including acceleration, heart rate, light level, and location.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Design For Affective Sharing",
      "text": "To communicate people's emotional state, researchers and practitioners have long before resorted to various bio-feeback systems that convey emotional states into readable representations such as numerical, graphical, material, or artistic, with the aim of increasing awareness of the connection between physiological states and the body's inner functioning  [17] . We draw inspiration from various lines of research including biophilic design, the use of metaphors and technological artifacts in the design, and material data representations. Biophilic Design. 'Biophilia' is humans' inherent connection to nature; our love of life and the natural world  [51] . Biophilic design creates spaces, objects, and technologies that provide a natural and pleasant environment for people to live and work. Contact with natural elements was found to increase the productivity of workers and to decrease mental fatigue  [25] . StressTree  [55]  is an example of bio-feedback system that uses a stylized tree to assist people in relaxation training and stress management by changing shape and size based on people's heart rate variability.\n\nMetaphors and Technological artifacts. Metaphorical visualizations aim to present data in a more evocative, meaningful, and thought provoking way to help an individual or a group of people grasp the underlying complexities of data. They create an analogy between characteristics of well-understood, and often universally acceptable images or patterns, and a more poorly understood or complex data source  [57] ; our emotional states is one of them. It is also well-known that the use of metaphors and analogies are key aspects of human cognition  [3] , which enable humans to understand abstract information with familiar objects such as images or simulations  [2] . Examples include the  use of tangible artifacts that mimic real-world objects  [55] , light  [56] ,\n\nor movement  [26] . Other systems resort to casual visualizations that become more playful (gamification) or more artistic. For example, Chill-Out is a bio-feedback game for relaxation training that maps a user's breathing rate into a game difficulty  [28] , while Cardiomorphologies offers an abstract visual artwork by mapping heartbeat and breath into a series of colorful rings  [23] . Inspiration could also be drawn by observing and studying animals behaviour. For example, murmuration is the phenomenon that results when hundreds, or even thousands, of starlings fly in swooping, creating coordinated patterns through the sky  [54] . While these collective behaviors exhibit characteristics of self-organization, simple repeated interactions yield complex emergent patterns  [5, 42] ; patterns that might reflect the complexity of our emotional states (Figure  2 ).\n\nMaterial data representations. This breed of representations make use of recent advances in digital fabrication, tangible interfaces, and shape-changing displays to offer data physicalizations that support embodied interpretation of our emotional states  [19] . For example, Biolesce  [13]  is a series of iterative installations and sculptures that display the viewer's heart rate in real-time through bioluminescent algae. Others include the use of fabric material as data displays. For example, Devendorf et al.  [11]  created Ebb, a slow, color-changing novel textile display that evokes personal style associations. In a similar vein, Howell et al.  [18]  developed Hint, a thermochromic t-shirt that changes color based on wearer's skin conductance levels to understand how people react under different conversations.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Research Goal",
      "text": "Our broad research goal is to build a bio-feedback system for visualizing crowd affects. Drawing inspiration from various lines of research in HCI and InfoVis, as stated in the previous section, we set out to explore the underlying mapping of a multi-dimensional model into a metaphor that conveys the complexity of our emotional states, and explore its effectiveness. Therefore, developing a visualization for sharing emotional states is a fundamental step towards building an end-to-end bio-feedback system. Our research questions is: RQ: How to create a visual metaphor of basic emotions that is relatable and universally accessible?\n\nWe first motivate our design decisions and implementation of our system, and we then evaluate it in a crowdsourcing deployment study.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Heartbees",
      "text": "We introduce HeartBees (http://social-dynamics.net/heartbees), a webbased tool for visualizing collective emotions based on the Boids model. We first motivate our choice of the Boids model, and we then present the basic mechanics of model and describe how we mapped emotional states to specific boids configurations.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Why Boids?",
      "text": "Behavior models simulate the coordinated behavior in human society wherein each member relies on the decisions of others to guide his or her own actions. The Boids model is a type of behavior model that offers a simple way to depict group dynamics that resonates with the human instinctive interpretation of collective behavior  [39] . Craig Reynolds described it as an approach to simulate the aggregate motion of a flock of birds, a herd of land animals, a school of fish, or a swarm of bees through a distributed behavioral model  [33] . As we previously discussed ( §2), simple repeated interactions in animals' behaviour can produce complex emergent patterns in which a metaphor could be drawn and mapped to our emotional states.\n\nWe used this model as an interactive bio-feedback system to simulate the aggregate physiological behavior of a group of people, in a playful way. Particles that move in a life-like fashion could stimulate what anthropologists and sociologists have called 'collective effervescence'; the synchronicity in thoughts, actions, or emotions in groups and societies  [53] . There is substantial scientific evidence that exposure to synchronicity increases the potential to create positive emotions that weaken interpersonal boundaries  [20, 41] .",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Model Parameters",
      "text": "The Boids model is a collection of independent particles (called 'boids') that follow physical rules determined by their local perception of the environment and their neighbors; such behaviors include wandering, arriving, pursuing, fleeing, and evading  [34] . A flock of N boids simulates a life-like collective motion based on a combination of three rules: separation S, alignment M, and cohesion K, as illustrated in Figure  3 , and can be configured in our interface (Figure  4a ). Separation defines how boids avoid collisions with nearby flockmates, alignment attempts to match a boid's velocity with that of neighbors, and cohesion enables boids to stay closer to nearby flockmates. In addition to these dimensions, the model is initialized with three additional parameters: the particle velocity V ; the range of perception R, which is used as a proximity threshold to trigger alignment and cohesion forces; and a range of separation r, which determines the minimum distance between boids. We implemented the Boids visualization as a web-based application using HTML5/JavaScript and D3  [4] .",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Aesthetics",
      "text": "In addition to the model parameters, our HeartBees web-based application allows users to control the aesthetic output of the visualization (Figure  4 ). Drawing inspiration from fractal patterns observed in nature  [43] , and color psychology  [50] , our visualization encodes these patterns into colored Boids. In particular, one can control the boids' stroke length and stroke width (Figure  4a ) as a way to create an analogy between the Boids movements and the complex patterns observed in nature; previous work found that fractal patterns are aesthetically pleasing and help reduce stress levels  [44] . The stroke length describes the trail of the boids as time passes; the higher its value, the longer the light ray prolongs. When the stroke length set to 100, all movement trails are preserved on the canvas. The stroke width describes the thickness of the colored paint strokes that traces the boids' movement. Furthermore, users can change the canvas background color in which the boids are being drawn (Figure  4b ). Taking inspiration from color psychology  [50] , we aimed at providing coloring options that are universally relatable. Two options are available: (a) a dark background (dark-blue color), and (b) a bright background (white-grey color). Finally, the boids color scheme can be set to cold, warm, or a combination of the two (Figure  4c ). The warm color palette includes combinations of orange, red, Fig.  4 : HeartBees User Interface. Aesthetics parameters (i.e., stroke length and width), canvas background color (i.e., bright and dark), and boids color scheme (i.e., cold and warm) can be manually configured. The example HeartBees visual was generated by setting the stroke length to 100, while the stroke width set to 30. Both cold and warm color schemes were used on the boids drawn on a dark background color canvas.\n\nTable  2 : Mapping HR and HRV parameters (RMSSD and LF/HF) into the eight basic Plutchik's emotions. Adapted version from  [21] .",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Hr Rmssd Lf/Hf",
      "text": "and yellow colors, while the cold color palette consists of green, blue, indigo and violet colors.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Mapping Emotions To Boids' Motion Configurations",
      "text": "Inspired by the collective behavior of animals, we combined the Boids model parameters to create visual patterns that aim at conveying the eight basic emotions in Plutchik's model: Joy, Sadness, Fear, Anger, Trust, Disgust, Surprise, and Anticipation (Figure  1 ). We generated the mapping of flock behavior by varying the coefficients of the three forces, the maximum velocity, the separation radius, and the range of perception. The full list of coefficients is presented in Table  1 . For example, by increasing the degree of alignment the flock stays together, thus giving a sense of trust or joy, and conveying positive emotions. On the contrary, while keeping the degree of separation and cohesion constant, members of the flock separate from each other, thus giving a flavor of negative sensation, and conveying negative emotions such as disgust or fear. Additionally, we used the speed of motion to express \"energy\" exhibited by the flock. For example, anger and anticipation will be very fast motion, while sadness and fear are in the lowest energy spectrum.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Mapping Physiological Indicators To Emotions",
      "text": "Over the last decades, research in Affective Computing has accumulated evidence that links various types of signals to people's emotional states.\n\nAs previously discussed ( §2) these include facial expressions, voice intonation, textual sentiment, or bodily signal obtained from mobile and wearable sensors. While any of these datastreams could be possibly used to detect people's emotional states and, in turn, serve as an input to our HeartBees, we focused on HRV, a promising and widely used physiological indicator that is available thanks to recent advanced in wearable sensing. HRV provides an assessment of our Autonomic Nervous System; for example, one could obtain an assessment whether an individual is stressed or not, feeling happy or frustrated. Grounded on previous reviews on physiology and emotional states, we provide the reader a mapping of heart rate and heart rate variability parameters into Plutchik's multi-dimensional model, and visually illustrate how this type of physiological data can serve our HeartBees prototype (Figure  5 ). Kreibig et al.  [21]  provide an extensive review of these findings that link HRV parameters to our emotional states. Building on this review, we grounded our mapping of physiological indicators to the eight emotional states. For example, previous studies have shown that people feeling joy or other strong positive emotions usually experience an increase in HR and, at the same time, a decrease in both RMSSD and LF/HF. On the contrary, HR and RMSSD decrease and LF/HF increases when experiencing negative emotions such as sadness or fear.\n\nBased on the relevant previous literature, we found that HR, RMSSD, and LF/HF in combination can set apart different emotions quite effectively. By considering a coarse distinction of high vs. low range of the signals, we summarized the mapping between these three metrics and the eight emotions in Table  2 . According to the literature, four dimensions (joy, disgust, anger, anticipation) are characterized by unique footprints of high/low levels of HR, RMSSD, and LF/HF. Two pairs of emotions, namely trust and surprise, and sadness and fear, have similar footprints; a not surprising observation given the complexities of our emotional states.\n\nTo integrate the heart rate sensors (Figure  5 ), we built on top of our previous work in which we demonstrated the feasibility of obtaining, processing, and analyzing physiological data from smartwatches  [31] . Fig.  5 : A schematic overview of HeartBees. Physiological data obtained from wearable devices can be mapped into a multi-dimensional emotion model, which in turn HeartBees translates into a metaphorical visualization of a flock of birds. Fig.  6 : Calmness levels of the eight collective emotional states visualizations as our participants perceived them (responses to Q 2 ). Consistently, as one would expect, joy was perceived as the most relaxing one, while anger and fear were perceived as less relaxing.",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "Evaluation",
      "text": "To evaluate HeartBees, we investigated how people emotionally perceived each visualization, and in so doing, we investigate our RQ. To answer this question, we turned to crowdsourcing.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Online Study",
      "text": "",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Participants And Procedure",
      "text": "We made HeartBees available on Amazon Mechanical Turk (AMT). We ensured to enrol highly reputable AMT workers by targeting workers with 95% HIT approval rate and at least 100 approved HITs, and we received a total of 353 unique responses (each worker evaluated HeartBees once). The online workers were presented with a series of dynamic boids visualizations representing the eight emotions (Table  1 ). Their task was to evaluate which emotions each visualization conveyed and assess its calmness levels. In particular, each worker responded to two questions for each visualization. The first question probed the extent to which each emotional state was easily recognizable in the boids configuration, while the second question explored whether our participants perceived the different visualizations of collective emotional states to be calm, and served as an orthogonal check to the first question. The two questions were as follows: To mitigate possible interface biases, we reshuffled the order with which the eight visualizations of the collective emotional states are presented as well as the potential responses. To make sure we kept only responses in which workers spent a fairly sufficient time to make a judgment, we removed those responses that took less than 7 seconds on average  [48] . The resulting dataset consisted of 340 responses (49% female, µ age = 33.1, σ age = 9.8).",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Analysis",
      "text": "To investigate the extent to which the emotion configurations encoded in the Boids model matched people's perceptions, we analyzed responses to Q 1 . To ensure comparable results across the eight emotions, we normalized our participants' responses by dividing the number of occurrences for each response (i.e., one of the eight available options of Q 1 ) with the total number of occurrences for that response. For the sake of comparing the resulting associations between displayed and perceived emotions, we also gathered data about typical associations between basic emotions found online. This allowed us to assess whether the confusion that people had in identifying some of the emotions could be due to the high similarity between those emotions in the way people conceptualize them. Specifically, we used the 100M photos from the Flickr Creative Commons public dataset  [45] . From the set of all the photos in the dataset, we collected the user-generated tags attached to each picture and we matched them against the EmoLex dictionary  [22]  to extract only those that express any of the eight basic emotions. We then counted the number of times tags expressing emotion i co-occur in the same picture with tags expressing emotion j, for all pairs of emotions. We apply the same normalization we used for the crowdsourcing responses to these co-occurrence counts.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Results",
      "text": "Results of the crowdsourcing task to Q 1 and the external validity check using Flickr data are summarized in Table  3 . The Boids models expressing Joy, Anger, and Sadness were correctly identified by the crowdworkers. Most often, the workers associated fear and disgust respectively to the visualizations that were supposed to convey anger and sadness. These specific pairs of emotions are associated frequently also in the Flickr data, which signals the fact that they might be frequently associated in the human mind; interesting emotional states that fall into the negative spectrum of the emotion wheel. Trust and surprise were not matched correctly, as they were associated most often to the sadness and anger visualizations, respectively. To a certain extent, the same picture was observed in Flickr data as no distinct patterns emerged. Users often associated them not only with positive ones (e.g. associate trust and surprise with joy), but also signals that suggest association with sadness and anger respectively were observed.\n\nResults of the crowdsourcing task related to Q 2 are shown in Figure  6 . We found that, as one would expect, the boids configuration which conveys joy was the one perceived as the most relaxing one with 72% agreement among our participants' responses. On the contrary, Table  3 : Matrix of emotion co-occurrences. Top: Normalized responses to Q 1 (columns represent the users' associations, and rows represent the eight emotions from our visualizations). Bottom: Normalized emotions in Flickr data (columns represent the users' associations, and rows represent emotions extracted using the Emolex dictionary). Trust, surprise, and anticipation were neutral, but skewed towards calmness, while sadness and disgust shared a slightly even higher skewness towards agreement with relaxation levels.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Discussion And Conclusion",
      "text": "Emotional Intelligence is a valuable asset for both individuals and groups. Mechanisms to foster it promote well-being and productivity. We proposed HeartBees, a bio-feedback system for visualizing collective emotional states through the use of a nature-inspired metaphor.\n\nDrawing inspiration from observational studies on animals behaviour, HeartBees simulates a flock of birds that create coordinated patterns. These patterns create a visual metaphor of the complexities of our emotional states, and they do so in a collective way. We evaluated our system's ability to convey the multi-faceted nature of emotions in a crowdsourcing task with 353 participants. We found that consensus emerged among participants' subjective perceptions for three emotions. Negative emotions were broadly recognized, perhaps because of human's inherent ability of perceiving negative emotions better than positive ones  [46] . The ability to effectively convey the presence of negative emotions through visuals provides a useful mean to raise awareness about the distress of groups, and possibly trigger appropriate rebalancing interventions.\n\nOur work has both theoretical and practical implications. From the theoretical standpoint, it offers a framework to integrate concepts and metaphors in a new way of visualizing complex data. We showed, for example, how complex and unconventional data streams such as biosignals could be transformed into abstract, relatable, and universally accessible visuals to convey our collective emotional states. Additionally, our system contributes to the emerging field of Inbodied Interactions  [39] , which foresees future technologies to better align with how our body internally works. From a practical perspective, we foresee that our system could be deployed in a number of settings, including the workplace. This would provide immediate feedback of the workplace's atmosphere and allow managers to assess the 'health' of their teams (e.g., stress levels). As the overarching goal of the visualization was to incorporate elements of collective behavior, HeartBees would allow co-workers to experience synchronicity between them as expressed through their emotions. In so doing, it would nudge people into experiencing more positive emotions. A practical way of deploying such a system in the workplace would be an interactive installation in which the Boids behavior is controlled by the co-workers or by-passers who wear wearable devices such as smartwatches. Importantly, the collective way of visualizing people's emotional states could be deemed appropriate in the workplace due to the privacy-preserving nature of HeartBees. This means that no individual emotions could be identified as our system visualizes data in a collective way.\n\nThis work has two limitations that suggest directions for future work. While high degrees of consensus emerged among the ways our participants subjectively perceived the visualizations, future studies could further evaluate the end-to-end system in a participatory environment in real time. Future studies could also further fine-tune the motion configurations of the Boids model. However, our adjustable interface provides the means of direct manipulation of those parameters, thus allowing practitioners to make use of our solution and experiment with it. The second limitation concerns the aesthetics of the Boids visualization. In future studies, we plan to investigate the role of color, texture, and quantity of objects on screen in conveying the eight emotional states. Furthermore, the way people perceive color depend on gender, cultural background, or personal experiences; thus future studies could investigate the role of these factors too. Future directions also include the exploration of alternative modalities for conveying emotions, including the sonification of HeartBees, not least because the use of particular animals' sounds have been linked to increased laughter in people  [40] .",
      "page_start": 6,
      "page_end": 6
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: HeartBees. A metaphorical visualization that uses the movements of a ﬂock of birds in a plane to represent eight basic",
      "page": 1
    },
    {
      "caption": "Figure 2: Starling murmurations: simple rules, complex patterns. From",
      "page": 2
    },
    {
      "caption": "Figure 3: The underlying mechanics of Reynold’s Boids model [33]. A",
      "page": 3
    },
    {
      "caption": "Figure 3: , and can be conﬁgured in our interface (Figure 4a). Separation",
      "page": 3
    },
    {
      "caption": "Figure 4: ). Drawing inspiration from fractal patterns observed in na-",
      "page": 3
    },
    {
      "caption": "Figure 4: a) as a way to create an analogy",
      "page": 3
    },
    {
      "caption": "Figure 4: b). Taking inspiration from color psychology [50],",
      "page": 3
    },
    {
      "caption": "Figure 4: HeartBees User Interface. Aesthetics parameters (i.e., stroke length and width), canvas background color (i.e., bright and dark), and boids",
      "page": 4
    },
    {
      "caption": "Figure 1: ). We generated",
      "page": 4
    },
    {
      "caption": "Figure 5: ), we built on top of our",
      "page": 4
    },
    {
      "caption": "Figure 5: A schematic overview of HeartBees. Physiological data obtained from wearable devices can be mapped into a multi-dimensional emotion",
      "page": 5
    },
    {
      "caption": "Figure 6: Calmness levels of the eight collective emotional states visualiza-",
      "page": 5
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "joy\nsadness": "fear\nanger",
          "0.05\n0.05\n0.05\n60\n30\n2\n0.05\n0.05\n0.05\n0\n30\n1": "0.1\n0.05\n0.05\n60\n30\n1\n0.01\n0.1\n0.1\n0\n0\n10"
        },
        {
          "joy\nsadness": "trust\ndisgust",
          "0.05\n0.05\n0.05\n60\n30\n2\n0.05\n0.05\n0.05\n0\n30\n1": "0.05\n0.1\n0.05\n60\n30\n2\n0.1\n0.05\n0.1\n60\n60\n5"
        },
        {
          "joy\nsadness": "surprise\nanticipation",
          "0.05\n0.05\n0.05\n60\n30\n2\n0.05\n0.05\n0.05\n0\n30\n1": "0.05\n0.05\n0.1\n60\n60\n5\n0.1\n0.1\n0.05\n60\n30\n4"
        }
      ],
      "page": 3
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Hearts and politics: Metrics for tracking biorhythm changes during brexit and trump",
      "authors": [
        "L Aiello",
        "D Quercia",
        "E Roitmann"
      ],
      "year": "2018",
      "venue": "Proceedings of the 2018 International Conference on Digital Health",
      "doi": "10.1145/3194658.3194678"
    },
    {
      "citation_id": "2",
      "title": "The reification of metaphor as a design tool",
      "authors": [
        "A Blackwell"
      ],
      "year": "2006",
      "venue": "ACM Transactions on Computer-Human Interaction (TOCHI)",
      "doi": "10.1145/1188816.1188820"
    },
    {
      "citation_id": "3",
      "title": "The Analogical Mind: Perspectives from Cognitive Science",
      "authors": [
        "D Boicho",
        "N Kokinov"
      ],
      "year": "2001",
      "venue": "The Analogical Mind: Perspectives from Cognitive Science"
    },
    {
      "citation_id": "4",
      "title": "D 3 data-driven documents",
      "authors": [
        "M Bostock",
        "V Ogievetsky",
        "J Heer"
      ],
      "year": "2011",
      "venue": "IEEE Transactions on Visualization and Computer Graphics",
      "doi": "10.1109/tvcg.2011.185"
    },
    {
      "citation_id": "5",
      "title": "Self-organization in biological systems",
      "authors": [
        "S Camazine",
        "J.-L Deneubourg",
        "N Franks",
        "J Sneyd",
        "E Bonabeau",
        "G Theraula"
      ],
      "year": "2003",
      "venue": "Self-organization in biological systems"
    },
    {
      "citation_id": "6",
      "title": "Heart rate variability: Standards of measurement, physiological interpretation and clinical use. task force of the european society of cardiology and the north american society of pacing and electrophysiology",
      "authors": [
        "A Camm",
        "M Malik",
        "J Bigger",
        "G Breithardt",
        "S Cerutti",
        "R Cohen",
        "P Coumel",
        "E Fallen",
        "H Kennedy",
        "R Kleiger"
      ],
      "year": "1996",
      "venue": "Heart rate variability: Standards of measurement, physiological interpretation and clinical use. task force of the european society of cardiology and the north american society of pacing and electrophysiology",
      "doi": "10.1111/j.1542-474x.1996.tb00275.x"
    },
    {
      "citation_id": "7",
      "title": "Acute mental stress assessment via short term hrv analysis in healthy adults: A systematic review with meta-analysis",
      "authors": [
        "R Castaldo",
        "P Melillo",
        "U Bracale",
        "M Caserta",
        "M Triassi",
        "L Pecchia"
      ],
      "year": "2015",
      "venue": "Biomedical Signal Processing and Control",
      "doi": "10.1016/j.bspc.2015.02.012"
    },
    {
      "citation_id": "8",
      "title": "Ten social dimensions of conversations and relationships",
      "authors": [
        "M Choi",
        "L Aiello",
        "K Varga",
        "D Quercia"
      ],
      "year": "2020",
      "venue": "Proceedings of The Web Conference"
    },
    {
      "citation_id": "9",
      "title": "Emotioncheck: Leveraging bodily signals and false feedback to regulate our emotions",
      "authors": [
        "J Costa",
        "A Adams",
        "M Jung",
        "F Guimbretière",
        "T Choudhury"
      ],
      "year": "2016",
      "venue": "Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing",
      "doi": "10.1145/2971648.2971752"
    },
    {
      "citation_id": "10",
      "title": "Regulating feelings during interpersonal conflicts by changing voice self-perception",
      "authors": [
        "J Costa",
        "M Jung",
        "M Czerwinski",
        "F Guimbretière",
        "T Le",
        "T Choudhury"
      ],
      "year": "2018",
      "venue": "Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems"
    },
    {
      "citation_id": "11",
      "title": "i don't want to wear a screen\" probing perceptions of and possibilities for dynamic displays on clothing",
      "authors": [
        "L Devendorf",
        "J Lo",
        "N Howell",
        "J Lee",
        "N.-W Gong",
        "M Karagozler",
        "S Fukuhara",
        "I Poupyrev",
        "E Paulos",
        "K Ryokai"
      ],
      "year": "2016",
      "venue": "Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems"
    },
    {
      "citation_id": "12",
      "title": "An argument for basic emotions",
      "authors": [
        "P Ekman"
      ],
      "year": "1992",
      "venue": "Cognition & emotion"
    },
    {
      "citation_id": "13",
      "title": "Biolesce",
      "authors": [
        "T Fox"
      ],
      "year": "2014",
      "venue": "Biolesce"
    },
    {
      "citation_id": "14",
      "title": "Monitoring stress with a wrist device using context",
      "authors": [
        "M Gjoreski",
        "M Luštrek",
        "M Gams",
        "H Gjoreski"
      ],
      "year": "2017",
      "venue": "Journal of Biomedical Informatics",
      "doi": "10.1016/j.jbi.2017.08.006"
    },
    {
      "citation_id": "15",
      "title": "Aristotle said \"happiness is a state of activity\"-predicting mood through body sensing with smartwatches",
      "authors": [
        "P Gloor",
        "A Colladon",
        "F Grippa",
        "P Budner",
        "J Eirich"
      ],
      "year": "2018",
      "venue": "Journal of Systems Science and Systems Engineering",
      "doi": "10.1007/s11518-018-5383-7"
    },
    {
      "citation_id": "16",
      "title": "Large scale mood and stress self-assessments on a smartwatch",
      "authors": [
        "K Hänsel",
        "A Alomainy",
        "H Haddadi"
      ],
      "year": "2016",
      "venue": "Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct",
      "doi": "10.1145/2968219.2968305"
    },
    {
      "citation_id": "17",
      "title": "Biofeedback and self-control of physiological functions: Clinical applications",
      "authors": [
        "P Hauri"
      ],
      "year": "1975",
      "venue": "The International Journal of Psychiatry in Medicine",
      "doi": "10.2190/l766-9gfr-hxfd-wffx"
    },
    {
      "citation_id": "18",
      "title": "Biosignals as social cues: Ambiguity and emotional interpretation in social displays of skin conductance",
      "authors": [
        "N Howell",
        "L Devendorf",
        "R Tian",
        "T Vega",
        "N.-W Galvez",
        "I Gong",
        "E Poupyrev",
        "K Paulos",
        "Ryokai"
      ],
      "year": "2016",
      "venue": "Proceedings of the 2016 ACM Conference on Designing Interactive Systems"
    },
    {
      "citation_id": "19",
      "title": "Opportunities and challenges for data physicalization",
      "authors": [
        "Y Jansen",
        "P Dragicevic",
        "P Isenberg",
        "J Alexander",
        "A Karnik",
        "J Kildal",
        "S Subramanian",
        "K Hornbaek"
      ],
      "year": "2015",
      "venue": "Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems"
    },
    {
      "citation_id": "20",
      "title": "Synchronized arousal between performers and related spectators in a fire-walking ritual",
      "authors": [
        "I Konvalinka",
        "D Xygalatas",
        "J Bulbulia",
        "U Schjødt",
        "E.-M Jegindø",
        "S Wallot",
        "G Van Orden",
        "A Roepstorff"
      ],
      "year": "2011",
      "venue": "Synchronized arousal between performers and related spectators in a fire-walking ritual",
      "doi": "10.1073/pnas.1016955108"
    },
    {
      "citation_id": "21",
      "title": "Autonomic nervous system activity in emotion: A review",
      "authors": [
        "S Kreibig"
      ],
      "year": "2010",
      "venue": "Biological psychology",
      "doi": "10.1016/j.biopsycho.2010.03.010"
    },
    {
      "citation_id": "22",
      "title": "Crowdsourcing a word-emotion association lexicon",
      "authors": [
        "S Mohammad",
        "P Turney"
      ],
      "year": "2013",
      "venue": "Computational Intelligence",
      "doi": "10.1111/j.1467-8640.2012.00460.x"
    },
    {
      "citation_id": "23",
      "title": "Creating affective visualisations for a physiologically interactive artwork",
      "authors": [
        "L Muller",
        "G Turner",
        "G Khut",
        "E Edmonds"
      ],
      "year": "2006",
      "venue": "Tenth International Conference on Information Visualisation (IV'06)"
    },
    {
      "citation_id": "24",
      "title": "Continuous prediction of spontaneous affect from multiple cues and modalities in valence-arousal space",
      "authors": [
        "M Nicolaou",
        "H Gunes",
        "M Pantic"
      ],
      "year": "2011",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "25",
      "title": "The relative benefits of green versus lean office space: Three field experiments",
      "authors": [
        "M Nieuwenhuis",
        "C Knight",
        "T Postmes",
        "S Haslam"
      ],
      "year": "2014",
      "venue": "Journal of Experimental Psychology: Applied",
      "doi": "10.1037/xap0000024"
    },
    {
      "citation_id": "26",
      "title": "Blooming",
      "authors": [
        "L Park"
      ],
      "year": "2018",
      "venue": "Blooming"
    },
    {
      "citation_id": "27",
      "title": "Wellbeat: A framework for tracking daily well-being using smartwatches",
      "authors": [
        "S Park",
        "M Constantinides",
        "L Aiello",
        "D Quercia",
        "P Van Gent"
      ],
      "year": "2020",
      "venue": "Wellbeat: A framework for tracking daily well-being using smartwatches"
    },
    {
      "citation_id": "28",
      "title": "Chill-out: Relaxation training through respiratory biofeedback in a mobile casual game",
      "authors": [
        "A Parnandi",
        "B Ahmed",
        "E Shipp",
        "R Gutierrez-Osuna"
      ],
      "year": "2013",
      "venue": "International Conference on Mobile Computing, Applications, and Services"
    },
    {
      "citation_id": "29",
      "title": "Affective computing",
      "authors": [
        "R Picard"
      ],
      "year": "2000",
      "venue": "Affective computing"
    },
    {
      "citation_id": "30",
      "title": "Emotions: A general psychoevolutionary theory. Approaches to emotion",
      "authors": [
        "R Plutchik"
      ],
      "year": "1984",
      "venue": "Emotions: A general psychoevolutionary theory. Approaches to emotion"
    },
    {
      "citation_id": "31",
      "title": "Having a heart time? a wearable-based biofeedback system",
      "authors": [
        "C Qin",
        "J.-H Choi",
        "M Constantinides",
        "L Aiello",
        "D Quercia"
      ],
      "year": "2020",
      "venue": "Proceedings of the 22nd International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct",
      "doi": "10.1145/3406324.3410539"
    },
    {
      "citation_id": "32",
      "title": "Emotion recognition using smart watch sensor data: Mixed-design study",
      "authors": [
        "J Quiroz",
        "E Geangu",
        "M Yong"
      ],
      "year": "2018",
      "venue": "JMIR mental health",
      "doi": "10.2196/10153"
    },
    {
      "citation_id": "33",
      "title": "Flocks, Herds and Schools: A Distributed Behavioral Model",
      "authors": [
        "C Reynolds"
      ],
      "year": "1987",
      "venue": "Flocks, Herds and Schools: A Distributed Behavioral Model",
      "doi": "10.1145/37402.37406"
    },
    {
      "citation_id": "34",
      "title": "Steering behaviors for autonomous characters",
      "authors": [
        "C Reynolds"
      ],
      "year": "1999",
      "venue": "Game Developers Conference"
    },
    {
      "citation_id": "35",
      "title": "Tweet moodifier: Towards giving emotional awareness to twitter users",
      "authors": [
        "F Saldías",
        "R Picard"
      ],
      "year": "2019",
      "venue": "2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII)"
    },
    {
      "citation_id": "36",
      "title": "Emotional intelligence. Imagination, Cognition and Personality",
      "authors": [
        "P Salovey",
        "J Mayer"
      ],
      "year": "1990",
      "venue": "Emotional intelligence. Imagination, Cognition and Personality"
    },
    {
      "citation_id": "37",
      "title": "Stress recognition using wearable sensors and mobile phones",
      "authors": [
        "A Sano",
        "R Picard"
      ],
      "year": "2013",
      "venue": "2013 Humaine Association Conference on Affective Computing and Intelligent Interaction"
    },
    {
      "citation_id": "38",
      "title": "Multitarget affect detection in the wild: An exploratory study",
      "authors": [
        "P Schmidt",
        "R Dürichen",
        "A Reiss",
        "K Van Laerhoven",
        "T Plötz"
      ],
      "year": "2019",
      "venue": "Proceedings of the 23rd International Symposium on Wearable Computers",
      "doi": "10.1145/3341163.3347741"
    },
    {
      "citation_id": "39",
      "title": "in5: a model for inbodied interaction",
      "authors": [
        "Schraefel"
      ],
      "year": "2019",
      "venue": "Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems",
      "doi": "10.1145/3290607.3312977"
    },
    {
      "citation_id": "40",
      "title": "Positive emotional contagion in a new zealand parrot",
      "authors": [
        "R Schwing",
        "X Nelson",
        "A Wein",
        "S Parsons"
      ],
      "year": "2017",
      "venue": "Current Biology",
      "doi": "10.1016/j.cub.2017.02.020"
    },
    {
      "citation_id": "41",
      "title": "Synchrony and cooperation",
      "authors": [
        "C Scott",
        "S Wiltermuth"
      ],
      "year": "2009",
      "venue": "Synchrony and cooperation"
    },
    {
      "citation_id": "42",
      "title": "Collective animal behavior",
      "authors": [
        "D Sumpter"
      ],
      "year": "2010",
      "venue": "Collective animal behavior"
    },
    {
      "citation_id": "43",
      "title": "Order in pollock's chaos",
      "authors": [
        "R Taylor"
      ],
      "year": "2002",
      "venue": "Scientific American"
    },
    {
      "citation_id": "44",
      "title": "Reduction of physiological stress using fractal art and architecture",
      "authors": [
        "R Taylor"
      ],
      "year": "2006",
      "venue": "Reduction of physiological stress using fractal art and architecture"
    },
    {
      "citation_id": "45",
      "title": "Yfcc100m: The new data in multimedia research",
      "authors": [
        "B Thomee",
        "D Shamma",
        "G Friedland",
        "B Elizalde",
        "K Ni",
        "D Poland",
        "D Borth",
        "L.-J Li"
      ],
      "year": "2016",
      "venue": "Yfcc100m: The new data in multimedia research",
      "doi": "10.1145/2812802"
    },
    {
      "citation_id": "46",
      "title": "Not all emotions are created equal: The negativity bias in social-emotional development",
      "authors": [
        "A Vaish",
        "T Grossmann",
        "A Woodward"
      ],
      "year": "2008",
      "venue": "Psychological Bulletin",
      "doi": "10.1037/0033-2909.134.3.383"
    },
    {
      "citation_id": "47",
      "title": "The positive group affect spiral: A dynamic model of the emergence of positive affective similarity in work groups",
      "authors": [
        "F Walter",
        "H Bruch"
      ],
      "year": "2008",
      "venue": "Journal of Organizational Behavior: The International Journal of Industrial, Occupational and Organizational Psychology and Behavior",
      "doi": "10.1002/job.505"
    },
    {
      "citation_id": "48",
      "title": "How many seconds to a first impression?",
      "authors": [
        "E Wargo"
      ],
      "year": "2016",
      "venue": "How many seconds to a first impression?"
    },
    {
      "citation_id": "49",
      "title": "Toward a consensual structure of mood",
      "authors": [
        "D Watson",
        "A Tellegen"
      ],
      "year": "1985",
      "venue": "Psychological bulletin"
    },
    {
      "citation_id": "50",
      "title": "Color psychology: A critical review. Genetic, social, and general psychology monographs",
      "authors": [
        "T Whitfield",
        "T Whiltshire"
      ],
      "year": "1990",
      "venue": "Color psychology: A critical review. Genetic, social, and general psychology monographs"
    },
    {
      "citation_id": "51",
      "title": "",
      "authors": [
        "E Biophilia"
      ],
      "year": "1984",
      "venue": ""
    },
    {
      "citation_id": "52",
      "title": "Starling murmurations: the science behind one of nature's greatest displays",
      "authors": [
        "A Wood",
        "C Beale"
      ],
      "year": "2019",
      "venue": "Starling murmurations: the science behind one of nature's greatest displays"
    },
    {
      "citation_id": "53",
      "title": "Quantifying collective effervescence: Heart-rate dynamics at a fire-walking ritual",
      "authors": [
        "D Xygalatas",
        "I Konvalinka",
        "J Bulbulia",
        "A Roepstorff"
      ],
      "year": "2011",
      "venue": "Quantifying collective effervescence: Heart-rate dynamics at a fire-walking ritual",
      "doi": "10.4161/cib.17609"
    },
    {
      "citation_id": "54",
      "title": "Starling flock networks manage uncertainty in consensus at low cost",
      "authors": [
        "G Young",
        "L Scardovi",
        "A Cavagna",
        "I Giardina",
        "N Leonard"
      ],
      "year": "2013",
      "venue": "PLoS computational biology"
    },
    {
      "citation_id": "55",
      "title": "Stresstree: A metaphorical visualization for biofeedback-assisted stress management",
      "authors": [
        "B Yu",
        "M Funk",
        "J Hu",
        "L Feijs"
      ],
      "year": "2017",
      "venue": "Proceedings of the 2017 Conference on Designing Interactive Systems",
      "doi": "10.1145/3064663.3064729"
    },
    {
      "citation_id": "56",
      "title": "Delight: Biofeedback through ambient light for stress intervention and relaxation assistance",
      "authors": [
        "B Yu",
        "J Hu",
        "M Funk",
        "L Feijs"
      ],
      "year": "2018",
      "venue": "Personal and Ubiquitous Computing",
      "doi": "10.1007/s00779-018-1141-6"
    },
    {
      "citation_id": "57",
      "title": "The shaping of information by visual metaphors",
      "authors": [
        "C Ziemkiewicz",
        "R Kosara"
      ],
      "year": "2008",
      "venue": "IEEE Transactions on Visualization and Computer Graphics",
      "doi": "10.1109/tvcg.2008.171"
    }
  ]
}