{
  "paper_id": "2302.08301v1",
  "title": "The Right To Audit And Power Asymmetries In Algorithm Auditing",
  "published": "2023-02-16T13:57:41Z",
  "authors": [
    "Aleksandra Urman",
    "Ivan Smirnov",
    "Jana Lasser"
  ],
  "keywords": [
    "algorithm auditing",
    "computational social science",
    "power asymmetries"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "In this paper, we engage with and expand on the keynote talk about the \"Right to Audit\" given by Prof. Christian Sandvig at the IC2S2 2021 through a critical reflection on power asymmetries in the algorithm auditing field. We elaborate on the challenges and asymmetries mentioned by Sandvig -such as those related to legal issues and the disparity between early-career and senior researchers. We also contribute a discussion of the asymmetries that were not covered by Sandvig but that we find critically important: those related to other disparities between researchers, incentive structures related to the access to data from companies, targets of auditing and users and their rights. We also discuss the implications these asymmetries have for algorithm auditing research such as the Western-centrism and the lack of the diversity of perspectives. While we focus on the field of algorithm auditing specifically, we suggest some of the discussed asymmetries affect Computational Social Science more generally and need to be reflected on and addressed.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Auditing: Definition And Origins",
      "text": "Sandvig's talk focuses on algorithm auditing -a form of auditing studies that examines contemporary complex algorithms deployed, for instance, for content recommendations and information filtering in the online realm. One commonly used definition of algorithm audits was given by Mittelstadt  [3]  -\"a process of investigating the functionality and impact of decision-making algorithms\" (P. 4994). Mittelstadt also distinguishes between functionality audits, which examine how an algorithm works, and impact audits, which analyse algorithmic outputs and evaluate them for the presence of biases, misrepresentations and other distortions. Algorithm audit studies have emerged relatively recently, with first corresponding papers published approximately ten years ago. (see  [4] ,  [5]  for a review). However, in social sciences audit studies of other types have been conducted for decades  [6] , as Sandvig also notes in his talk. A classic social science audit study is a type of field experiment, i.e. it aims to explore phenomena as they occur naturally rather than in laboratory settings. The goal of the audit study is typically to uncover discrimination, biases, or undesirable effects of a policy, hence, the \"audit\" name.\n\nA typical example of an audit study is an experiment conducted in the early 1970s in the US  [7] . Pairs of observers which were either caucasian or from an ethnic minority visited twenty five apartment houses that were advertised for rent. Observers introduced themselves as couples looking for an apartment. All pairs of observers provided the same backstory and were similar in other aspects. Despite this, less than a half of minority couples were told that apartments are available while for Caucasian pairs, the positive response rate was 80%, indicating ethnic discrimination. Audit studies do not necessarily involve real people, another classic approach involves so-called correspondence studies, where fictional CVs are sent to potential employers. For example, gendered or ethnic names could be randomly assigned to otherwise identical CVs allowing to compare response rates and identify potential discrimination  [8] ,  [9] . Classic social science audit studies, such as those outlined above, have been associated with ethical questions and challenges. In particular, study participants (i.e. landlords, recruiters, etc) do not provide informed consent, they are often lied to, waste their time on fictional applications, and they are often not debriefed. Debriefing with audit studies can cause additional harm to the participants ranging from psychological discomfort (e.g., if a participant rejected a minority candidate and regretted it) to legal consequences. Despite these ethical concerns, audit studies are generally accepted in social sciences as the risk is considered to be minimal and benefits presumably outweigh the risk  [10] . The acceptance of audits is additionally motivated by the fact that there are often no alternative ways to uncover and reliably document discrimination or biases in certain circumstances. Notably, classic audit studies have been deemed legal by the courts  [10]  despite the associated ethical challenges.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Algorithm Audits",
      "text": "As noted in the beginning, Sandvig's talk and this paper focus on a more novel form of audit studies: algorithm audits. Most commonly algorithm audits are employed to study online platforms such as social media or web search engines to assess the factors that contribute to personalization  [4] ,  [11] , evaluate potential price discrimination  [12] , investigate how algorithms affect users' exposure to different types of information  [13] -  [15] , or determine whether certain phenomena or social groups are misrepresented online due to algorithmic information filtering  [16] ,  [17] . A comprehensive review of such audits performed on online platforms can be found in  [5] . In other societally relevant domains where algorithms are used such as policing, hiring, insurance or banking, algorithm audits have also been performed  [18] -  [20]  though they are less common in these areas. Notably, Sandvig's talk was also centred on online platform audits rather than audits in other domains. We suggest that the lower prevalence of audits in these other domains is not due to their lower importance -it is certainly not the case that discrimination in hiring or policing is less consequential than discrimination on social media or online shops -but rather is the result of the power asymmetries that are relevant in the context of algorithm auditing that we will discuss in the following sections. The biggest challenge in this case -as well as with the online platform audits -comes from the obstacles to accessing data from the private companies that own the platforms and are responsible for creating and using the algorithms the researchers would like to audit. In the next subsection, we briefly summarise the main points and arguments from Sandvig's talk that are relevant in this context.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Legal Restrictions In The Context Of Algorithm Auditing And \"The Right To Audit\"",
      "text": "According to the experience of Sandvig and his colleagues, private corporations are highly apprehensive of independent audits conducted by scientists. These companies tend to view their platforms and algorithms as private property hosted on their own private servers, and thus posit that scientists have no inherent right to examine this private property and associated data. Sandvig recalls a situation in which scraping data from online platforms was compared by the corporation to entering a physical store and starting digging a hole in the middle of it \"for scientific purposes\". This position of the private corporations is often supported by legal actions or threats of legal action against the scientists conducting the audits, particularly in the U.S. context that is the focus of Sandvig's talk. For example, Spotify threatened researchers who revealed its history of pirating content with legal actions  [21]  for violating its Terms of Use. Such legal actions could lead to grave consequences, as happened in the infamous case of Aaron Swarz who committed suicide facing the possibility of imprisonment after downloading a large number of scientific articles from JSTOR  [22] . These are just the examples of the companies threatening researchers with legal action that Sandvig provided in his talk, but there are many others. Some recent examples include Meta going after researchers at New York University  [23]  or pressuring the Berlin-based NGO AlgorithmWatch to shut down their study of Instagram with threats of legal action  [24] . Despite the aforementioned legal issues, in some cases, courts ruled that scraping information that is already publicly available on the internet is legal (e.g.,  [25] ). Moreover, in the case filed by Sandvig (Sandvig v. Barr  [1] ), the ruling was ultimately in Sandvig's favor, concluding that researchers can not be persecuted for conducting algorithm auditing, in particular through the creation of fake \"tester\" accounts in order to uncover racial, gender, or other discrimination on online platforms, even if the data collection violates the Terms of Service of online platforms  [26] . Nonetheless, in his talk Sandvig argues that the ruling was too narrow in scope. He calls for a broader right to audit which he understands as \"independent social research as a necessary minimum requirement for computational systems\"  [2] . As we understand it, actions taken by researchers to audit computational systems should be not just not forbidden but explicitly allowed, without the possibility of being restricted by platforms (e.g., through their Terms of Service). In the Q&A session after the talk Sandvig explained, for instance, that even despite the court ruling in Sandvig v. Barr the corporations can still threaten researchers with legal action. Even if the court would rule in the researchers' favour in the end, such lawsuits might be too costly for researchers to afford. Companies could also accuse researchers of scientific misconduct as there is no de facto right to audit yet. According to Sandvig, this right should be an uncontroversial issue. This is because the damage to the platforms from audit studies is lower than damage to the participants of classic audit studies such as landlords while the benefits are higher given the scale of the potential problems. Sandvig posits that the auditing performed by the researchers has negligible impact on the platforms given their vast resources and, in most cases, would be unlikely to be even noticed by the platforms. With the classic audit studies, on the contrary, those audited typically spend a noticeable amount of their work time on the fake requests from the researchers. Thus, Sandvig argues, algorithm audits are less intrusive and have a smaller negative impact on the side that is audited. Additionally, Sandvig suggests that the researchers' right to collect the data from online platforms should be considered uncontroversial because researchers are acting in the public interest. However, we believe that this issue is more complicated and not as uncontroversial as presented by Sandvig, mainly because of the asymmetry of power between different stakeholders. In his talk, Sandvig touches upon some of those asymmetries but does not mention others that we believe are equally important. In the next section, we unpack these asymmetries.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Power Asymmetries And Algorithm Auditing",
      "text": "Asymmetries in the targets of auditing As was mentioned above, the field of algorithm auditing extends beyond online platforms as algorithms are also used in hiring, banking and other socially important domains. Yet, the audits of algorithms by independent researchers are rare in these domains. We argue that this is largely due to the lack of access to the data by the researchers. While in the case of online platforms researchers often can -at least from a technical though not necessarily legal standpoint -access the data and conduct experiments on algorithmic outputs, in the case of the other domains mentioned above, such access and experimentation is most often not even technically possible for outside researchers. In this case, the audit access lies fully with the private corporations which, as Sandvig notes, are usually apprehensive about sharing their data. The situation is arguably even more convoluted when it comes to the algorithmic decision-making employed by governments rather than private corporations. Examples of this include policing and immigration. For instance, it is known that the governments of the UK, Canada, New Zealand and some other (Western) countries employ algorithms in their decision-making processes when it comes to visa requests, deportations and/or other immigration-related issues  [27] . Researchers have highlighted a number of ways in which such algorithms might be biased based on the examples of algorithmic biases from other domains  [27] . Yet, actual algorithm audits that could provide evidence on the absence or presence of such biases and discrimination as a result in immigration-related algorithms -or any other algorithms employed by the governments -do not exist since they are impossible to conduct without access to the data that is handled by government agencies. To sum up, Sandvig highlights that the access to the data from online platforms is often obstructed by various legal issues. However, in the cases when algorithm-relevant data can not be scraped, the access to it is also technically obstructed, resulting in a major imbalance in terms of the entities whose algorithms get audited at all.",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "Asymmetries In Prohibiting Vs. Allowing And Incentive Structures",
      "text": "In this section, we will again shift our attention specifically to online platforms and the asymmetries related to the Terms of Service (ToS)-based obstructions in the access to data, as this was the main focus of Sanvig's talk. As Sandvig notes, platforms usually prohibit scientists from doing audits or other types of studies by adding corresponding statements to their Terms of Service (ToS). These statements can be quite radical, for example: \"You shall not use any robot, spider, scraper, data mining tools, data gathering and extraction tools, or other automated means to access our Service for any purpose, except with the prior express permission of [the platform] in writing\" -as stated in the ToS of the platform ResearchGate  [28] . Sandvig gives even more extreme examples that he and his colleagues encountered, such as the prohibition to \"record anything from the platform even with pen and paper\" or statements like \"no researcher may use this platform\". However, he did not provide the names of the platforms that used such radical formulations in their ToS, and we were unable to identify them, even if it is not hard to imagine that they might exist. In other cases, though, ToS are more permissive, especially when it comes to scraping for non-commercial purposes (such as academic research). For instance, in 2021 TikTok's ToS actually did not prohibit scraping of content as long as it was for non-commercial purposes  [11] . However, by the end of 2022, the ToS were changed, and now TikTok prohibits the extraction of \"any data or content from the Platform using any automated system or software\", regardless of the purpose  [29] .\n\nWe suggest that this shift from more permissive to more prohibitive ToS in terms of scraping, similarly to the prohibitive nature of ToS in general, is related to an asymmetry in the incentives and counter-incentives for online platforms in the context of data access. In fact, there is no obvious downside for the platforms to being overprotective about the access to data. Further, including prohibitive statements in ToS is much easier and cheaper than coming up with and enforcing elaborate rules about data access. Thus, permissive ToS are actually counter-incentivized for the platforms. This results in the ToS often prohibiting web scraping even if companies are in fact completely fine with providing data in certain situations (e.g., for non-commercial purposes such as research). The authors of this paper and their colleagues have had numerous experiences that exemplify this. For example, one of the authors once requested permission to scrape the data from a website. Its owners confirmed that they allow this and were even surprised by the request because they assumed that no permission is required for collecting the data that is already publicly available. However, their ToS published on their website actually prohibited data scraping. In a different case, a representative of a large online platform reached out to the authors of a recently published research study of that platform to talk about it. Though research involved automatically scraping data from the platform -which its ToS prohibit -the representative showed interest in the findings of the research and claimed the platform is not against researchers scraping the data. However, the prohibition could not be excluded from ToS as, according to the representative, the corporation wants to prevent the abuse of ToS by its competitors or other companies who might want to scrape large amounts of data for commercial use. In another case, one of the authors sent an inquiry about the possibility of automatically collecting data from a large online platform. The author received a positive answer from the platform and then asked for a confirmation that could be shown to a journal once the paper is submitted. The initial response was again positive but then the author was told that the legal department of the platform advised against issuing any confirmation. All the examples above once again demonstrate that the companies often tend to include prohibitive statements in their ToS not necessarily because they are against the use of their data for research, but rather to be on the \"safe side\" in terms of the legal issues around the access to their data. We suggest that this can be changed only if the asymmetry in the incentives to allow vs. prohibit data scraping for research shifts drastically, and it becomes more attractive for the companies to allow data access rather than forbid it. There are multiple ways this can be achieved, but we suggest the most likely one will be based on a combination of academia-industry collaborations that would make (some) research findings useful enough for the companies to allow data access and new legal regulations that force the companies to provide access to certain types of data to independent auditors and/or academic researchers (similar to the new mandates of the Digital Services Act in the EU  [30] ).",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Asymmetries In The Ability To Defend",
      "text": "The same asymmetry in the incentives to prohibit vs. to allow data collection exists when it comes to the legal departments at universities, Institutional Review Boards (IRBs) or similar ethical committees. They have no incentive to take a risk by allowing something that might turn out to be illegal or unethical. From our experience and the experience of our colleagues, the typical response from the legal department is to prohibit collecting data, and from the IRB is to say that this lies outside their responsibilities and competencies. In such circumstances, researchers often proceed without having a formal approval and therefore explicit protection by their university, and rely on precedents: online data is routinely collected by other researchers after all. Nevertheless, this leaves the individual researcher vulnerable to legal retaliation by the audited corporations. In such a case, a researcher would face an opponent with a large legal department and practically unlimited financial resources. This asymmetry is exacerbated within the research community: while tenured researchers usually have the legal departments of universities to back them, early career researchers (ECRs) oftentimes do not enjoy this privilege. Another concern for researchers is accusations of unethical behaviour. As research is essentially a public activity, success in science heavily relies on reputation and reputation is asymmetrical. No matter how many \"ethical\" studies a researcher conducted, it is enough to have one study that is considered unethical to ruin a career. For ECRs, their ability to conduct research, support their family and sometimes even their residence permit might depend on getting the next contract. Given these extremely high stakes, ECRs will think twice about engaging in a research project that could potentially lead to backlash from a corporation and endanger their whole research career. This asymmetry is also noted by Sandvig along with the obvious unfairness of it and negative consequences for the ECRs. Sandvig then also suggests that tenured researchers thus should engage in auditing since such research practices do not pose major risks to their careers. While these are valid points that we agree with, there is an additional negative consequence that Sandvig does not explicitly mention. The current (legal) status-based asymmetry between ECRs and tenured researchers in terms of their ability to conduct audits has negative implications for the field of algorithm auditing itself due to the overrepresentation of white male and more privileged scholars among those tenured  [31] . Furthermore, in some disciplines in the U.S. at least, the gender gap among tenured faculty is wider among researchers of foreign origins than among those originally from the country.  [32] . We suggest that the power asymmetry between ECRs and tenured scholars along with the lack of diversity among tenured faculty can lead to a bias in the types of auditing studies that are being conducted. Scholars who are not well established yet might shy away from auditing studies because they are too risky. As a result, valuable perspectives that could inform development of the platforms such as they serve all communities may be overlooked. We will return to this point and provide relevant examples in the next section in which we discuss the assumed homogeneity of researchers.",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "Going Beyond Researchers Vs. Companies",
      "text": "In his talk, Sandvig presents the issue from the researchers vs. corporations perspective. Many of his points rest on the assumption that researchers are a homogenous and benevolent force serving society. In this section, we would like to challenge this assumption as well as discuss its implications for the algorithm auditing field.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Researchers Are Not Homogeneous",
      "text": "As noted in the previous section, one aspect of this issue is admittedly mentioned in Sandvig's talk when he discusses the differences in the status and protections enjoyed by tenured researchers compared to ECRs. Another difference among researchers mentioned in Sandvig's talk is that between foreign and non-foreign researchers, since the former face an additional legal risk in the form of potential visa revocation and deportation if accused of illegal activities. However, we suggest that the issue of non-homogeneity of the research community and its implications for the field are broader than what was mentioned by Sandvig. Different groups of researchers face different risks and also benefit differently. One disparity among researchers that was not mentioned so far is that between scholars from \"prestigious\" and \"not prestigious\" institutions. The former are often better connected than the latter, including in terms of connections to the companies that can be helpful to obtain the data necessary for auditing and other studies in the computational social science domain. Further, even when the access to platform data is formalised in a certain form but still gated -in the sense that not everyone can have access to the data automatically but rather only those researchers who have been somehow vetted -the disparities among researchers in terms of prestige and status might play a role. It is difficult to evaluate however whether and to what extent that is the case since the processes behind the decisions to grant or refuse access to the data are usually opaque. One prominent example is Twitter's Academic API. While the API itself is a great tool that allows researchers to conduct all kinds of research using Twitter data -including research into the workings of Twitter itself -access to the API requires an application process. The outcome of the application is rather unpredictable and no justification is given for negative outcomes. Moreover, once access is denied, no re-application or challenge of the outcome is possible. Our and our colleagues personal experiences highlight the opacity in the process: some of us were denied access to the API from the start, others were first approved, then at some point blocked from the access, and some years later reinstated without a reason, all of this without any explanations about the decisions from the side of Twitter. We have helped numerous students to apply for API access, sometimes with virtually identical applications, some of which got denied while others were approved immediately -an experience which could be framed as an auditing study itself. Another example is the Social Science One initiative that aims to foster collaboration between researchers and companies. Specifically, it enables access to Facebook data for (selected) researchers. Data access is given or refused based on a process similar to obtaining research funding: researchers submit project proposals, and then are granted or refused access to data based on the evaluation of the proposals according to \"academic merit and feasibility; research ethics; likelihood of knowledge resulting from the project advancing social good; qualifications of the proposed team\"  [33] . It is however unclear how exactly the proposals are evaluated, which is problematic as some of the criteria -such as the likelihood of the project to contribute to social good -are rather subjective. Others, such as the evaluation of researchers' qualifications, can be influenced by implicit and explicit biases (e.g., related to the applicant's gender), as studies based on academic funding award procedures show  [34] . In the case of Social Science One there is an apparent gender disparity among those awarded access to the data. In the first cohort of data access awardees -the only cohort on which we found a publicly available list of awardees -only 2 out of 13 Principle Investigators appear to be women 2  , one of them leading a project together with a male PI  [35] . Due to the opacity of the evaluation process and the unavailability of the information on the application success rate, we can only point out this gender disparity as a fact but not infer its actual cause. While evaluation processes of public research funding agencies have similar biases  [34] , information necessary to scrutinise the processes is more widely available or can be acquired via freedom of information requests or similar laws. Restrictive processes to regulate access to platform data by academics are often justified by protecting user privacy or preventing data misuse. However, to date there is no evidence that such screening procedures actually prevent any wrong-doing. It seems like what matters most for being granted access to data is the nationality or country of residence of the researchers, the prestige of their institution and their connections to the corporation providing data access. As a result, initiatives that are often considered as equalising science (e.g. Twitter API allows anyone to get access to a lot of data and do research), can in fact exacerbate inequalities, which in turn affects the field of algorithm auditing itself.",
      "page_start": 8,
      "page_end": 9
    },
    {
      "section_name": "Implications Of The Lack Of Diversity Among Researchers",
      "text": "We suggest that the aforementioned differences among researchers -i.e., those related to the ease of data access and risks associated with engaging in risky algorithm audits -in terms of the scholars' gender, status, nationality, ethnicity or prestige of their institutions, lead to the striking imbalances in the field of algorithm auditing with regard to what gets audited. Specifically, these differences contribute to the field being highly Western-and English-centric as those for whom audits are less risky or easier to implement most often are based at prestigious Western institutions, more likely to be white and male, and less likely to have a migration background. A recent literature review of (online platforms focused) algorithm audits  [5]  and a search for \"algorithm audit studies\" in a scholarly database indicate that the absolute majority of the studies conducted to date focus on 1) Western platforms and 2) content published in English language. There are notable exceptions to this: several studies, authored by academics based in German-speaking countries, have examined content in German  [36] -  [38] . A few others either adopted a comparative approach analysing content across multiple languages  [13]  or audited non-Western platforms and/or focused on content in languages such as Russian or Chinese  [39] -  [45] . However, these studies are exceptions to the general \"rule\" of the Western-and English-centric studies in the algorithm auditing field. Since most large online platforms are, in fact, Western and predominantly, U.S.-based, one could argue that Western-centrism of algorithm audits is not a major issue. In the end, it is plausible to assume -though we do not know this for a fact -that there are no separate algorithms deployed by companies in different jurisdictions and local markets. If this assumption is correct, the analyses of the factors that contribute to personalization on Google or TikTok  [11] ,  [12]  are valid not only for a certain national context, thus Western-centrism should not be much of an issue for such functionality audits. Nonetheless, we suggest it is problematic that, with the exception of TikTok, Baidu or Yandex  [39] -  [45] , no other platforms that were founded outside of the U.S., to the best of our knowledge, have been subjects of algorithm audits so far. Since many of such platforms are founded and based in authoritarian states such as Russia or China and some are known to cooperate with the governments to censor or downgrade political content, auditing them can bring particularly valuable insights about potential algorithmic biases and authoritarian manipulation. In the context of algorithm impact audits, analyses of non-Western platforms and non-English content are arguably even more overdue. Even if the algorithms deployed by the companies across the globe function in the same way in different regions, the pool of content available for an algorithm to select and (de)prioritise from differs depending on the language. Thus, even an algorithm that works in the same way will yield qualitatively different sets of results depending on the language. Further, it is known that the companies tend to invest more resources into content moderation and annotation (that is used as training data for machine learning algorithms) for English language content and, to a lesser degree, other popular and/or Western languages  [46] . Taken together, the differences in the pool of content and in information quality assurance-related efforts depending on the language, result in information inequalities between users depending on their location and/or language. This is documented by the few existing comparative algorithm audits (e.g.,  [13] ,  [39] ), with the inequalities sometimes being potentially life-threatening for the users. For instance, Scherr and colleagues found that there are major linguistic and location-based differences in how frequently information about suicide helplines is presented to Google's users when submitting suicide-related queries, to the point where in some countries such crisis-prevention functionality seems to be not implemented at all  [13] . Such documented information disparities highlight the urgency of conducting more comparative and/or non-English content-focused algorithm audits and giving higher prominence to the fact that the findings of most algorithm impact audits are context-specific, with their findings non-generalizable to other national and linguistic settings.",
      "page_start": 9,
      "page_end": 10
    },
    {
      "section_name": "Researchers Are Not Necessarily A Benevolent Force Serving Larger Society",
      "text": "Coming back to the assumed homogeneity among researchers and Sandvig's talk, we suggest that one aspect that is ignored by Sandvig is an obvious conflict of interest that arises when researchers ask for the possibility to conduct experiments or to access the data. It is important to remember that the main beneficiaries of research are researchers themselves. They don't do research as volunteers or publish their findings anonymously. On the contrary, they are paid for their research and their income and status depend on the visibility of their research. Getting access to unique large scale data sets increases the chances of publication in prestigious journals, promotion, etc. Moreover, researchers are not only interested in accessing the data but they are also interested in restricting data access for other researchers to prevent being \"scooped\". This becomes especially problematic when researchers that have a stake in research that is conducted using a corporation's data are part of an advisory board or other decision mechanism that decides who gets access to the data. While these self-interested motivations of researchers are not necessarily in contradiction with the interests of society as a whole, we suggest it is important to keep in mind that serving the larger society is often not the main motivation of researchers when embarking on a new project.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Users And Their Rights",
      "text": "The omission of a key stakeholder in the algorithm audit debate becomes all the more important when considering that researchers may not be primarily motivated by serving society. Specifically, in Sandvig's talk users of the audited platforms were not discussed. This could be due to the perspective that users in the scholars vs. corporations debate are implicitly assumed to be represented by researchers. This would be in line with the assumption that researchers are acting in the interests of the broader public by default. However, because of the aforementioned potential conflict of interest, we argue researchers in fact do not represent users and their interests do not necessarily align with the interests of the users. We illustrate this misalignment of interests between researchers and users with the example of sock-puppet auditing studies: In algorithm auditing studies the creation of fake accounts on an online platform is a component of a commonly utilised auditing method, sometimes referred to as \"sock-puppet auditing\"  [47]  or \"agent-based testing\"  [48] ,  [49] . However, the creation of fake accounts can have potentially negative effects not only on the platforms -something Sandvig discusses -but also on the users. Sandvig argues that online audits should be uncontroversial because offline audits are uncontroversial and well-established in social sciences as well as less obtrusive towards those audited -in this case, online platforms. This however ignores asymmetries that are introduced by the online environment. Compared to the offline settingsand classic audits conducted by the social scientists -in the online settings, the researchers leave (more) traces that can get in the way of user experiences. In fact, online researchers might leave permanent traces such as fake posts on platforms or buggy commits to software  [50] . Researchers therefore not only use a companies' resources but also permanently alter the environment that users experience. From an ethical perspective, the possible harm of such alterations needs to be balanced with the possible benefit and put into perspective with alterations that other actors on such platforms regularly introduce. When researchers pay to distribute an ad over the ad distribution service of a social media platform to test a platform's audience targeting algorithms, it will likely be one of many ads that a user sees during one usage session of the platform. Such an alteration therefore does not introduce an experience that is drastically different from the everyday experience a user has and might be considered as not very harmful. On the other hand, if a researcher introduces offensive content into a self-help forum used by a vulnerable group of people to audit the platform's content moderation policies, users might be confronted with content that is drastically different from what they are used to seeing and might react very negatively to it. Along the same lines, researchers also need to be careful to not \"poison the well\" for other researchers that want to conduct (auditing) studies on the same platform: if researcher's auditing behaviour is too obvious or disturbs normal operations too much, other research projects might be endangered because users start recognizing researcher's behaviours and alter their own behaviour as a reaction. Last but not least, so far users' perspectives have been barely integrated into the design of algorithm audits. Yet recent research suggests that users are able to identify potential algorithmic harms, albeit which harms exactly they identify largely depends on their experiences and demographics  [51] . This once again highlights the importance of the diversity of perspectives for the algorithm auditing field. DeVos and colleagues suggest that user perspectives can be integrated into algorithm auditing in the future and advocate for user-driven algorithm audits -while acknowledging potential limitations and harms  [51] . We share their perspective and suggest that user-centric audits could help alleviate the current imbalances in the field that we described above, particularly with regard to what gets audited, and thus constitute a fruitful direction for future audits.",
      "page_start": 11,
      "page_end": 12
    },
    {
      "section_name": "Conclusion",
      "text": "In this paper, we have aimed to critically engage with Prof. Christian Sandvig's talk on the \"right to audit\" at IC2S2 2021 through the discussion of power asymmetries that are important in the algorithm auditing field. We have elaborated on some asymmetries and challenges mentioned by Sandvig -such as those related to legal issues and the disparity between early-career and senior researchers. At the same time, we have discussed power asymmetries that were not mentioned in the original talk but that we find critically important: those related to other disparities between researchers, incentive structures related to the access to data from companies, targets of auditing and users and their rights.\n\nWe have highlighted that while in recent years there have been some legal decisions that were in favour of researchers in the context of adversarial auditing such as the ruling in Sandvig v. Barr, the field of algorithm auditing remains somewhat of a grey zone in terms of law which obstructs the ability of the researchers to conduct auditing studies. One major issue that scientists face with regard to this is the risk of legal retaliation or accusations of scientific misconduct from corporations. As Sandvig also highlights in his talk, this issue can discourage researchers, especially those in more precarious positions such as ECRs or foreign citizens, from conducting audits. This and other power asymmetries we discussed above that lead to inequalities in access to data and ability to perform audits have negative consequences for the field as a whole resulting in it being western-centric and lacking diversity of perspectives. Another aspect that needs to be considered in connection to auditing is the ethical implications of conducting (online) audits. While in Sandvig's talk these have been considered for corporations, the needs and concerns of users and other researchers working on the platforms that researchers audit have not been adequately addressed. It is essential to consider the distribution of power among all stakeholders in order to ensure a truly fair and unbiased field of algorithm auditing.\n\nFinally, we would like to note that even though we discussed all the aforementioned power asymmetries in the context of algorithm auditing research, many of them in fact affect Computational Social Science (CSS) more generally with the field as a whole potentially lacking the diversity of perspectives and objects of analysis. We suggest that not only researchers interested in algorithm auditing but the CSS field as a whole needs to critically reflect on the implications of existing disparities and look for the ways to address them.",
      "page_start": 12,
      "page_end": 12
    }
  ],
  "figures": [],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "algorithm auditing": "Authors"
        },
        {
          "algorithm auditing": "Aleksandra Urman1 - University of Zurich, Andreasstrasse 15, 8050 Zurich, Switzerland"
        },
        {
          "algorithm auditing": "Ivan Smirnov - University of Mannheim, 68131 Mannheim, Germany"
        },
        {
          "algorithm auditing": "Jana Lasser - Graz University of Technology (TU Graz), Rechbauerstraße 12, 8010 Graz,"
        },
        {
          "algorithm auditing": "Austria"
        },
        {
          "algorithm auditing": "Abstract:\nIn this paper, we engage with and expand on the keynote talk about\nthe “Right\nto"
        },
        {
          "algorithm auditing": "Audit” given by Prof. Christian Sandvig at\nthe IC2S2 2021 through a critical reflection on power"
        },
        {
          "algorithm auditing": "asymmetries in the algorithm auditing field. We elaborate on the challenges and asymmetries"
        },
        {
          "algorithm auditing": "mentioned\nby Sandvig -\nsuch as\nthose related to legal\nissues and the disparity between"
        },
        {
          "algorithm auditing": "early-career and senior\nresearchers. We also contribute a discussion of\nthe asymmetries that"
        },
        {
          "algorithm auditing": "were\nnot\ncovered\nby Sandvig\nbut\nthat we find critically\nimportant:\nthose related to other"
        },
        {
          "algorithm auditing": "disparities\nbetween\nresearchers,\nincentive\nstructures\nrelated\nto\nthe\naccess\nto\ndata\nfrom"
        },
        {
          "algorithm auditing": "companies, targets of auditing and users and their rights. We also discuss the implications these"
        },
        {
          "algorithm auditing": "asymmetries have for algorithm auditing research such as the Western-centrism and the lack of"
        },
        {
          "algorithm auditing": "the diversity of perspectives. While we focus on the field of algorithm auditing specifically, we"
        },
        {
          "algorithm auditing": "suggest\nsome\nof\nthe\ndiscussed\nasymmetries\naffect Computational\nSocial\nScience more"
        },
        {
          "algorithm auditing": "generally and need to be reflected on and addressed."
        },
        {
          "algorithm auditing": "Keywords: algorithm auditing, computational social science, power asymmetries"
        },
        {
          "algorithm auditing": "In March 2020, a U.S. court\nruled that creating fictitious user accounts on employment sites is"
        },
        {
          "algorithm auditing": "not a crime [1]. This was the culmination of a four year process that started when Prof. Christian"
        },
        {
          "algorithm auditing": "Sandvig from the University of Michigan filed the complaint challenging the Computer Fraud and"
        },
        {
          "algorithm auditing": "Abuse Act,\nthe provision that makes it a crime to use a website in violation of\nits Terms of"
        },
        {
          "algorithm auditing": "Service. The story behind this lawsuit was presented by Sandvig in his keynote talk at\nthe"
        },
        {
          "algorithm auditing": "International Conference on Computational Social Science (IC2S2) 2021 [2].\nIn this talk, he"
        },
        {
          "algorithm auditing": "spoke about studies based on the algorithm auditing methodology, more specifically adversarial"
        },
        {
          "algorithm auditing": "algorithm audits -\ni.e.\nindependent audits that are not commissioned by the creators of\nthe"
        },
        {
          "algorithm auditing": "algorithm and might\nuncover\nproblematic\nalgorithmic\nbehaviour.\nSandvig\ndiscussed\nthe"
        },
        {
          "algorithm auditing": "obstacles scientists face when conducting such studies, predominantly focusing on legal\nissues."
        },
        {
          "algorithm auditing": "In this paper, we critically engage with and expand on Sandvig’s talk. Specifically, we unpack"
        },
        {
          "algorithm auditing": "the asymmetries in the capability to take the risk of\nlegal\nretaliation and access to data for"
        },
        {
          "algorithm auditing": "different\nresearchers and how that might\nlead to biases in which platforms get audited. We also"
        },
        {
          "algorithm auditing": "1 Corresponding author. Email: urman@ifi.uzh.ch"
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "researchers. As Sandvig’s talk was focused on adversarial audits,\nin this paper when talking"
        },
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "about auditing we also mean studies of adversarial nature."
        },
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "Auditing: definition and origins"
        },
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "Sandvig’s\ntalk\nfocuses\non\nalgorithm auditing\n-\na\nform of\nauditing\nstudies\nthat\nexamines"
        },
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "contemporary\ncomplex algorithms deployed,\nfor\ninstance,\nfor content\nrecommendations and"
        },
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "information filtering in the online realm. One commonly used definition of algorithm audits was"
        },
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "given\nby Mittelstadt\n[3]\n-\n“a\nprocess\nof\ninvestigating\nthe\nfunctionality\nand\nimpact\nof"
        },
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "decision-making\nalgorithms”\n(P.\n4994). Mittelstadt\nalso\ndistinguishes\nbetween\nfunctionality"
        },
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "audits, which examine how an algorithm works, and impact audits, which analyse algorithmic"
        },
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "outputs and evaluate them for the presence of biases, misrepresentations and other distortions."
        },
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "Algorithm audit\nstudies\nhave\nemerged\nrelatively\nrecently, with\nfirst\ncorresponding\npapers"
        },
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "published approximately ten years ago.\n(see [4],\n[5]\nfor a review). However,\nin social sciences"
        },
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "audit studies of other\ntypes have been conducted for decades [6], as Sandvig also notes in his"
        },
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "talk. A classic social science audit study is a type of\nfield experiment,\ni.e.\nit aims to explore"
        },
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "phenomena as they occur naturally rather than in laboratory settings. The goal of the audit study"
        },
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "is typically to uncover discrimination, biases, or undesirable effects of a policy, hence, the “audit”"
        },
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "name."
        },
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "A typical example of an audit study is an experiment conducted in the early 1970s in the US [7]."
        },
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "Pairs of observers which were either caucasian or\nfrom an ethnic minority visited twenty five"
        },
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "apartment houses that were advertised for\nrent. Observers introduced themselves as couples"
        },
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "looking for an apartment. All pairs of observers provided the same backstory and were similar in"
        },
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "other aspects. Despite this,\nless than a half of minority couples were told that apartments are"
        },
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "available while for Caucasian pairs,\nthe positive response rate was 80%,\nindicating ethnic"
        },
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "discrimination."
        },
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "Audit studies do not necessarily involve real people, another classic approach involves so-called"
        },
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "correspondence studies, where fictional CVs are sent\nto potential employers. For example,"
        },
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "gendered or ethnic names could be randomly assigned to otherwise identical CVs allowing to"
        },
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "compare response rates and identify potential discrimination [8], [9]."
        },
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "Classic social science audit studies, such as those outlined above, have been associated with"
        },
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "ethical questions and challenges.\nIn particular, study participants (i.e.\nlandlords,\nrecruiters, etc)"
        },
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "do not provide informed consent, they are often lied to, waste their time on fictional applications,"
        },
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "and they are often not debriefed. Debriefing with audit studies can cause additional harm to the"
        },
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "participants\nranging from psychological discomfort\n(e.g.,\nif a participant\nrejected a minority"
        },
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "candidate and regretted it) to legal consequences."
        },
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "Despite these ethical concerns, audit studies are generally accepted in social sciences as the"
        },
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "risk is considered to be minimal and benefits presumably outweigh the risk [10]. The acceptance"
        },
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "of audits is additionally motivated by the fact that there are often no alternative ways to uncover"
        },
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "and reliably document discrimination or biases in certain circumstances. Notably, classic audit"
        },
        {
          "extend the ethical considerations surrounding online auditing studies to platform users and other": "studies have been deemed legal by the courts [10] despite the associated ethical challenges."
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Algorithm audits": "As noted in the beginning, Sandvig’s talk and this paper\nfocus on a more novel\nform of audit"
        },
        {
          "Algorithm audits": "studies:\nalgorithm audits. Most\ncommonly\nalgorithm audits\nare\nemployed\nto\nstudy\nonline"
        },
        {
          "Algorithm audits": "platforms such as social media or web search engines to assess the factors that contribute to"
        },
        {
          "Algorithm audits": "personalization [4],\n[11], evaluate potential price discrimination [12],\ninvestigate how algorithms"
        },
        {
          "Algorithm audits": "affect users’ exposure to different\ntypes of\ninformation [13]–[15], or determine whether certain"
        },
        {
          "Algorithm audits": "phenomena or social groups are misrepresented online due to algorithmic information filtering"
        },
        {
          "Algorithm audits": "[16],\n[17]. A comprehensive review of such audits performed on online platforms can be found in"
        },
        {
          "Algorithm audits": "[5]."
        },
        {
          "Algorithm audits": "In\nother\nsocietally\nrelevant\ndomains where\nalgorithms\nare\nused\nsuch\nas\npolicing,\nhiring,"
        },
        {
          "Algorithm audits": "insurance or banking, algorithm audits have also been performed [18]–[20] though they are less"
        },
        {
          "Algorithm audits": "common in these areas. Notably, Sandvig’s talk was also centred on online platform audits"
        },
        {
          "Algorithm audits": "rather\nthan audits in other domains. We suggest\nthat\nthe lower prevalence of audits in these"
        },
        {
          "Algorithm audits": "other\ndomains\nis\nnot\ndue\nto\ntheir\nlower\nimportance\n-\nit\nis\ncertainly\nnot\nthe\ncase\nthat"
        },
        {
          "Algorithm audits": "discrimination in hiring or policing is less consequential\nthan discrimination on social media or"
        },
        {
          "Algorithm audits": "online shops - but\nrather\nis the result of\nthe power asymmetries that are relevant in the context"
        },
        {
          "Algorithm audits": "of algorithm auditing that we will discuss in the following sections. The biggest challenge in this"
        },
        {
          "Algorithm audits": "case - as well as with the online platform audits - comes from the obstacles to accessing data"
        },
        {
          "Algorithm audits": "from the private companies that own the platforms and are responsible for creating and using"
        },
        {
          "Algorithm audits": "the algorithms the researchers would like to audit.\nIn the next subsection, we briefly summarise"
        },
        {
          "Algorithm audits": "the main points and arguments from Sandvig’s talk that are relevant in this context."
        },
        {
          "Algorithm audits": "Legal\nrestrictions in the context of algorithm auditing and “the right\nto"
        },
        {
          "Algorithm audits": "audit”"
        },
        {
          "Algorithm audits": "According to the experience of Sandvig and his colleagues, private corporations are highly"
        },
        {
          "Algorithm audits": "apprehensive of\nindependent audits conducted by scientists. These companies tend to view"
        },
        {
          "Algorithm audits": "their platforms and algorithms as private property hosted on their own private servers, and thus"
        },
        {
          "Algorithm audits": "posit\nthat scientists have no inherent\nright to examine this private property and associated data."
        },
        {
          "Algorithm audits": "Sandvig recalls a situation in which scraping data from online platforms was compared by the"
        },
        {
          "Algorithm audits": "corporation to entering a physical\nstore and starting digging a hole in the middle of\nit\n“for"
        },
        {
          "Algorithm audits": "scientific purposes”."
        },
        {
          "Algorithm audits": "This position of\nthe private corporations is often supported by legal actions or\nthreats of\nlegal"
        },
        {
          "Algorithm audits": "action against\nthe scientists conducting the audits, particularly in the U.S. context\nthat\nis the"
        },
        {
          "Algorithm audits": "focus of Sandvig’s talk. For example, Spotify threatened researchers who revealed its history of"
        },
        {
          "Algorithm audits": "pirating content with legal actions [21]\nfor violating its Terms of Use. Such legal actions could"
        },
        {
          "Algorithm audits": "lead to grave consequences, as happened in the infamous case of Aaron Swarz who committed"
        },
        {
          "Algorithm audits": "suicide facing the possibility of\nimprisonment after downloading a large number of scientific"
        },
        {
          "Algorithm audits": "articles\nfrom JSTOR\n[22].\nThese\nare\njust\nthe\nexamples\nof\nthe\ncompanies\nthreatening"
        },
        {
          "Algorithm audits": "researchers with legal action that Sandvig provided in his talk, but there are many others. Some"
        }
      ],
      "page": 3
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "the Berlin-based NGO AlgorithmWatch to shut down their study of\nInstagram with threats of"
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "legal action [24]."
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "Despite the aforementioned legal\nissues,\nin some cases, courts ruled that scraping information"
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "that is already publicly available on the internet is legal (e.g., [25]). Moreover, in the case filed by"
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "Sandvig (Sandvig v. Barr\n[1]),\nthe ruling was ultimately in Sandvig’s favor, concluding that"
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "researchers can not be persecuted for conducting algorithm auditing,\nin particular\nthrough the"
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "creation of\nfake “tester” accounts in order\nto uncover\nracial, gender, or other discrimination on"
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "online platforms, even if\nthe data collection violates the Terms of Service of online platforms"
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "[26]. Nonetheless,\nin his talk Sandvig argues that\nthe ruling was too narrow in scope. He calls"
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "for\na\nbroader\nright\nto\naudit which\nhe\nunderstands\nas\n“independent\nsocial\nresearch as a"
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "necessary minimum requirement\nfor computational systems”\n[2]. As we understand it, actions"
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "taken by\nresearchers\nto audit\ncomputational\nsystems\nshould be not\njust not\nforbidden but"
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "explicitly allowed, without\nthe possibility of being restricted by platforms (e.g.,\nthrough their"
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "Terms of Service).\nIn the Q&A session after\nthe talk Sandvig explained,\nfor\ninstance,\nthat even"
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "despite the court\nruling in Sandvig v. Barr\nthe corporations can still\nthreaten researchers with"
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "legal action. Even if\nthe court would rule in the researchers'\nfavour\nin the end, such lawsuits"
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "might be too costly for\nresearchers to afford. Companies could also accuse researchers of"
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "scientific misconduct as there is no de facto right\nto audit yet. According to Sandvig,\nthis right"
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "should be an uncontroversial issue."
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "This is because the\ndamage to the platforms from audit studies is lower\nthan damage to the"
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "participants of classic audit studies such as landlords while the benefits are higher given the"
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "scale of\nthe potential problems. Sandvig posits that\nthe auditing performed by the researchers"
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "has negligible impact on the platforms given their vast\nresources and,\nin most cases, would be"
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "unlikely to be even noticed by the platforms. With the classic audit studies, on the contrary,"
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "those audited typically spend a noticeable amount of\ntheir work time on the fake requests from"
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "the researchers. Thus, Sandvig argues, algorithm audits are less intrusive and have a smaller"
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "negative impact on the side that\nis audited. Additionally, Sandvig suggests that the researchers’"
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "right\nto collect\nthe data from online platforms should\nbe considered uncontroversial because"
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "researchers are acting in the public interest."
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "However, we\nbelieve\nthat\nthis\nissue is more complicated and\nnot as uncontroversial as"
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "presented\nby\nSandvig, mainly\nbecause\nof\nthe\nasymmetry\nof\npower\nbetween\ndifferent"
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "stakeholders.\nIn his\ntalk, Sandvig touches upon some of\nthose asymmetries but does not"
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "mention others that we believe are equally important.\nIn the next section, we unpack these"
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "asymmetries."
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "Power asymmetries and algorithm auditing"
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "Asymmetries in the targets of auditing"
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "As was mentioned above,\nthe field of algorithm auditing extends beyond online platforms as"
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "algorithms are also used in hiring, banking and other socially important domains. Yet, the audits"
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "of algorithms by independent\nresearchers are rare in these domains. We argue that\nthis is"
        },
        {
          "recent examples include Meta going after researchers at New York University [23] or pressuring": "largely due to the lack of access to the data by the researchers. While in the case of online"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "standpoint\n- access the data and conduct experiments on algorithmic outputs, in the case of the"
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "other domains mentioned above,\nsuch access and experimentation is most often not even"
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "technically possible for outside researchers.\nIn this case,\nthe audit access lies fully with the"
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "private corporations which, as Sandvig notes, are usually apprehensive about sharing their"
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "data."
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "The\nsituation\nis\narguably\neven\nmore\nconvoluted\nwhen\nit\ncomes\nto\nthe\nalgorithmic"
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "decision-making employed by governments rather\nthan private corporations. Examples of\nthis"
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "include policing and immigration. For\ninstance,\nit\nis known that\nthe governments of\nthe UK,"
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "Canada,\nNew\nZealand\nand\nsome\nother\n(Western)\ncountries\nemploy\nalgorithms\nin\ntheir"
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "decision-making\nprocesses\nwhen\nit\ncomes\nto\nvisa\nrequests,\ndeportations\nand/or\nother"
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "immigration-related issues [27]. Researchers have highlighted a number of ways in which such"
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "algorithms might be biased based on the examples of algorithmic biases from other domains"
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "[27]. Yet, actual algorithm audits that could provide evidence on the absence or presence of"
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "such biases and discrimination as a result\nin immigration-related algorithms - or any other"
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "algorithms employed by the governments - do not exist since they are impossible to conduct"
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "without access to the data that is handled by government agencies."
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "To\nsum up, Sandvig highlights\nthat\nthe access\nto the data from online platforms\nis often"
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "obstructed by various legal\nissues. However,\nin the cases when algorithm-relevant data can not"
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "be scraped,\nthe access to it\nis also technically obstructed,\nresulting in a major\nimbalance in"
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "terms of the entities whose algorithms get audited at all."
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "Asymmetries in prohibiting vs. allowing and incentive structures"
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "In\nthis\nsection, we will\nagain\nshift\nour\nattention\nspecifically\nto\nonline\nplatforms\nand\nthe"
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "asymmetries related to the Terms of Service (ToS)-based obstructions in the access to data, as"
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "this was the main focus of Sanvig’s talk."
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "As Sandvig notes, platforms usually prohibit\nscientists\nfrom doing audits or other\ntypes of"
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "studies by adding corresponding statements to their Terms of Service (ToS). These statements"
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "can be quite radical,\nfor example:\n“You shall not use any robot, spider, scraper, data mining"
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "tools, data gathering and extraction tools, or other automated means to access our Service for"
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "any purpose, except with the prior express permission of\n[the platform] in writing” – as stated in"
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "the ToS of\nthe platform ResearchGate [28]. Sandvig gives even more extreme examples that he"
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "and his colleagues encountered, such as the prohibition to “record anything from the platform"
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "even with pen and paper” or statements like “no researcher may use this platform”. However, he"
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "did not provide the names of\nthe platforms that used such radical formulations in their ToS, and"
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "we were unable to identify them, even if\nit\nis not hard to imagine that\nthey might exist.\nIn other"
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "cases,\nthough,\nToS\nare more\npermissive,\nespecially\nwhen\nit\ncomes\nto\nscraping\nfor"
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "non-commercial purposes (such as academic research). For\ninstance,\nin 2021 TikTok’s ToS"
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "actually did not prohibit scraping of content as long as it was for non-commercial purposes [11]."
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "However, by the end of 2022,\nthe ToS were changed, and now TikTok prohibits the extraction of"
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "“any data or content\nfrom the Platform using any automated system or software”, regardless of"
        },
        {
          "platforms\nresearchers\noften\ncan\n-\nat\nleast\nfrom a\ntechnical\nthough\nnot\nnecessarily\nlegal": "the purpose [29]."
        }
      ],
      "page": 5
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "similarly to the prohibitive nature of ToS in general,\nis related to an asymmetry in the incentives"
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "and counter-incentives for online platforms in the context of data access.\nIn fact,\nthere is no"
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "obvious downside for\nthe platforms to being overprotective about\nthe access to data. Further,"
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "including prohibitive statements in ToS is much easier and cheaper\nthan coming up with and"
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "enforcing\nelaborate\nrules\nabout\ndata\naccess.\nThus,\npermissive\nToS\nare\nactually"
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "counter-incentivized for\nthe platforms. This results in the ToS often prohibiting web scraping"
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "even if companies are in fact completely fine with providing data in certain situations (e.g.,\nfor"
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "non-commercial purposes such as research)."
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "The authors of\nthis paper and their colleagues have had numerous experiences that exemplify"
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "this. For example, one of\nthe authors once requested permission to scrape the data from a"
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "website.\nIts owners confirmed that\nthey allow this and were even surprised by the request"
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "because they assumed that no permission is required for collecting the data that\nis already"
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "publicly\navailable. However,\ntheir\nToS published\non\ntheir website\nactually prohibited data"
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "scraping.\nIn a different case, a representative of a large online platform reached out\nto the"
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "authors of a recently published research study of\nthat platform to talk about it. Though research"
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "involved\nautomatically\nscraping\ndata\nfrom the\nplatform -\nwhich\nits\nToS\nprohibit\n-\nthe"
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "representative showed interest\nin the findings of\nthe research and claimed the platform is not"
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "against\nresearchers scraping the data. However, the prohibition could not be excluded from ToS"
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "as, according to the representative,\nthe corporation wants to prevent\nthe abuse of ToS by its"
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "competitors or other companies who might want to scrape large amounts of data for commercial"
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "use.\nIn another case, one of\nthe authors sent an inquiry about\nthe possibility of automatically"
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "collecting data from a large online platform. The author\nreceived a positive answer\nfrom the"
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "platform and then asked for a confirmation that could be shown to a journal once the paper\nis"
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "submitted. The initial\nresponse was again positive but\nthen the author was told that\nthe legal"
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "department of the platform advised against issuing any confirmation."
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "All\nthe examples above once again demonstrate that\nthe companies often tend to include"
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "prohibitive statements in their ToS not necessarily because they are against the use of their data"
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "for\nresearch, but\nrather to be on the “safe side” in terms of the legal\nissues around the access to"
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "their data. We suggest\nthat\nthis can be changed only if the asymmetry in the incentives to allow"
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "vs. prohibit data scraping for\nresearch shifts drastically, and it becomes more attractive for\nthe"
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "companies\nto allow data access\nrather\nthan forbid it. There are multiple ways this can be"
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "achieved,\nbut\nwe\nsuggest\nthe most\nlikely\none\nwill\nbe\nbased\non\na\ncombination\nof"
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "academia-industry collaborations that would make (some)\nresearch findings useful enough for"
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "the companies to allow data access and new legal\nregulations that\nforce the companies to"
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "provide access to certain types of data to independent auditors and/or academic researchers"
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "(similar to the new mandates of the Digital Services Act in the EU [30])."
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "Asymmetries in the ability to defend"
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "The same asymmetry in the incentives to prohibit vs.\nto allow data collection exists when it"
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "comes to the legal departments at universities,\nInstitutional Review Boards (IRBs) or similar"
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "ethical committees. They have no incentive to take a risk by allowing something that might turn"
        },
        {
          "We suggest\nthat\nthis shift\nfrom more permissive to more prohibitive ToS in terms of scraping,": "out\nto be illegal or unethical. From our experience and the experience of our colleagues,\nthe"
        }
      ],
      "page": 6
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "typical\nresponse from the legal department\nis to prohibit collecting data, and from the IRB is to": "say\nthat\nthis\nlies\noutside\ntheir\nresponsibilities\nand\ncompetencies.\nIn\nsuch\ncircumstances,"
        },
        {
          "typical\nresponse from the legal department\nis to prohibit collecting data, and from the IRB is to": "researchers often proceed without having a formal approval and therefore explicit protection by"
        },
        {
          "typical\nresponse from the legal department\nis to prohibit collecting data, and from the IRB is to": "their university, and rely on precedents: online data is routinely collected by other\nresearchers"
        },
        {
          "typical\nresponse from the legal department\nis to prohibit collecting data, and from the IRB is to": "after all. Nevertheless,\nthis leaves the individual researcher vulnerable to legal retaliation by the"
        },
        {
          "typical\nresponse from the legal department\nis to prohibit collecting data, and from the IRB is to": "audited corporations.\nIn such a case, a researcher would face an opponent with a large legal"
        },
        {
          "typical\nresponse from the legal department\nis to prohibit collecting data, and from the IRB is to": "department and practically unlimited financial\nresources. This asymmetry is exacerbated within"
        },
        {
          "typical\nresponse from the legal department\nis to prohibit collecting data, and from the IRB is to": "the research community: while tenured researchers usually have the legal departments of"
        },
        {
          "typical\nresponse from the legal department\nis to prohibit collecting data, and from the IRB is to": "universities\nto\nback\nthem,\nearly\ncareer\nresearchers\n(ECRs)\noftentimes\ndo\nnot\nenjoy\nthis"
        },
        {
          "typical\nresponse from the legal department\nis to prohibit collecting data, and from the IRB is to": "privilege. Another concern for\nresearchers is accusations of unethical behaviour. As research is"
        },
        {
          "typical\nresponse from the legal department\nis to prohibit collecting data, and from the IRB is to": "essentially a public activity, success in science heavily relies on reputation and reputation is"
        },
        {
          "typical\nresponse from the legal department\nis to prohibit collecting data, and from the IRB is to": "asymmetrical. No matter how many “ethical” studies a researcher conducted,\nit\nis enough to"
        },
        {
          "typical\nresponse from the legal department\nis to prohibit collecting data, and from the IRB is to": "have one study that\nis considered unethical\nto ruin a career. For ECRs,\ntheir ability to conduct"
        },
        {
          "typical\nresponse from the legal department\nis to prohibit collecting data, and from the IRB is to": "research,\nsupport\ntheir\nfamily and sometimes even their\nresidence permit might depend on"
        },
        {
          "typical\nresponse from the legal department\nis to prohibit collecting data, and from the IRB is to": "getting the next\ncontract. Given these extremely high stakes, ECRs will\nthink\ntwice about"
        },
        {
          "typical\nresponse from the legal department\nis to prohibit collecting data, and from the IRB is to": "engaging in\na research project\nthat could potentially lead to backlash from a corporation and"
        },
        {
          "typical\nresponse from the legal department\nis to prohibit collecting data, and from the IRB is to": "endanger their whole research career."
        },
        {
          "typical\nresponse from the legal department\nis to prohibit collecting data, and from the IRB is to": "This asymmetry is also noted by Sandvig along with the obvious unfairness of\nit and negative"
        },
        {
          "typical\nresponse from the legal department\nis to prohibit collecting data, and from the IRB is to": "consequences for\nthe ECRs. Sandvig then also suggests that\ntenured researchers thus should"
        },
        {
          "typical\nresponse from the legal department\nis to prohibit collecting data, and from the IRB is to": "engage in auditing since such research practices do not pose major risks to their careers. While"
        },
        {
          "typical\nresponse from the legal department\nis to prohibit collecting data, and from the IRB is to": "these are valid points that we agree with,\nthere is an additional negative consequence that"
        },
        {
          "typical\nresponse from the legal department\nis to prohibit collecting data, and from the IRB is to": "Sandvig does not explicitly mention. The current (legal) status-based asymmetry between ECRs"
        },
        {
          "typical\nresponse from the legal department\nis to prohibit collecting data, and from the IRB is to": "and tenured researchers in terms of\ntheir ability to conduct audits has negative implications for"
        },
        {
          "typical\nresponse from the legal department\nis to prohibit collecting data, and from the IRB is to": "the field of algorithm auditing itself due to the overrepresentation of white male and more"
        },
        {
          "typical\nresponse from the legal department\nis to prohibit collecting data, and from the IRB is to": "privileged scholars among those tenured [31]. Furthermore,\nin some disciplines in the U.S. at"
        },
        {
          "typical\nresponse from the legal department\nis to prohibit collecting data, and from the IRB is to": "least,\nthe gender gap among tenured faculty is wider among researchers of foreign origins than"
        },
        {
          "typical\nresponse from the legal department\nis to prohibit collecting data, and from the IRB is to": "among those originally from the country.\n[32]. We suggest\nthat\nthe power asymmetry between"
        },
        {
          "typical\nresponse from the legal department\nis to prohibit collecting data, and from the IRB is to": "ECRs and tenured scholars along with the lack of diversity among tenured faculty can lead to a"
        },
        {
          "typical\nresponse from the legal department\nis to prohibit collecting data, and from the IRB is to": "bias\nin the types of auditing studies\nthat are being conducted. Scholars who are not well"
        },
        {
          "typical\nresponse from the legal department\nis to prohibit collecting data, and from the IRB is to": "established yet might shy away from auditing studies because they are too risky. As a result,"
        },
        {
          "typical\nresponse from the legal department\nis to prohibit collecting data, and from the IRB is to": "valuable perspectives that could inform development of\nthe platforms such as they serve all"
        },
        {
          "typical\nresponse from the legal department\nis to prohibit collecting data, and from the IRB is to": "communities may be overlooked. We will\nreturn to this point and provide relevant examples in"
        },
        {
          "typical\nresponse from the legal department\nis to prohibit collecting data, and from the IRB is to": "the next section in which we discuss the assumed homogeneity of researchers."
        },
        {
          "typical\nresponse from the legal department\nis to prohibit collecting data, and from the IRB is to": "Going beyond researchers vs. companies"
        },
        {
          "typical\nresponse from the legal department\nis to prohibit collecting data, and from the IRB is to": "In his talk, Sandvig presents the issue from the researchers vs. corporations perspective. Many"
        },
        {
          "typical\nresponse from the legal department\nis to prohibit collecting data, and from the IRB is to": "of his points rest on the assumption that researchers are a homogenous and benevolent force"
        },
        {
          "typical\nresponse from the legal department\nis to prohibit collecting data, and from the IRB is to": "serving society. In this section, we would like to challenge this assumption as well as discuss its"
        },
        {
          "typical\nresponse from the legal department\nis to prohibit collecting data, and from the IRB is to": "implications for the algorithm auditing field."
        }
      ],
      "page": 7
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Researchers are not homogeneous": "As noted in the previous section, one aspect of\nthis issue is admittedly mentioned in Sandvig’s"
        },
        {
          "Researchers are not homogeneous": "talk when\nhe\ndiscusses\nthe\ndifferences\nin the status and protections enjoyed by\ntenured"
        },
        {
          "Researchers are not homogeneous": "researchers compared to ECRs. Another difference among researchers mentioned in Sandvig’s"
        },
        {
          "Researchers are not homogeneous": "talk is that between foreign and non-foreign researchers, since the former\nface an additional"
        },
        {
          "Researchers are not homogeneous": "legal\nrisk in the form of potential visa revocation and deportation if accused of\nillegal activities."
        },
        {
          "Researchers are not homogeneous": "However, we suggest\nthat\nthe issue of non-homogeneity of\nthe research community and its"
        },
        {
          "Researchers are not homogeneous": "implications for\nthe field are broader\nthan what was mentioned by Sandvig. Different groups of"
        },
        {
          "Researchers are not homogeneous": "researchers face different risks and also benefit differently."
        },
        {
          "Researchers are not homogeneous": "One disparity among researchers that was not mentioned so far\nis that between scholars from"
        },
        {
          "Researchers are not homogeneous": "“prestigious” and “not prestigious”\ninstitutions. The former are often better connected than the"
        },
        {
          "Researchers are not homogeneous": "latter,\nincluding in terms of connections to the companies that can be helpful\nto obtain the data"
        },
        {
          "Researchers are not homogeneous": "necessary for auditing and other studies in the computational social science domain. Further,"
        },
        {
          "Researchers are not homogeneous": "even when the access to platform data is formalised in a certain form but still gated -\nin the"
        },
        {
          "Researchers are not homogeneous": "sense that not everyone can have access\nto the data automatically but\nrather only those"
        },
        {
          "Researchers are not homogeneous": "researchers who have been somehow vetted -\nthe disparities among researchers in terms of"
        },
        {
          "Researchers are not homogeneous": "prestige and status might play a role.\nIt\nis difficult\nto evaluate however whether and to what"
        },
        {
          "Researchers are not homogeneous": "extent\nthat\nis the case since the processes behind the decisions to grant or refuse access to the"
        },
        {
          "Researchers are not homogeneous": "data are usually opaque."
        },
        {
          "Researchers are not homogeneous": "One prominent example is Twitter’s Academic API. While the API itself is a great tool that allows"
        },
        {
          "Researchers are not homogeneous": "researchers to conduct all kinds of\nresearch using Twitter data – including research into the"
        },
        {
          "Researchers are not homogeneous": "workings of Twitter\nitself – access to the API\nrequires an application process. The outcome of"
        },
        {
          "Researchers are not homogeneous": "the application is\nrather unpredictable and no justification is given for negative outcomes."
        },
        {
          "Researchers are not homogeneous": "Moreover, once access is denied, no re-application or challenge of the outcome is possible. Our"
        },
        {
          "Researchers are not homogeneous": "and our colleagues personal experiences highlight\nthe opacity in the process: some of us were"
        },
        {
          "Researchers are not homogeneous": "denied access to the API\nfrom the start, others were first approved, then at some point blocked"
        },
        {
          "Researchers are not homogeneous": "from the access, and some years\nlater\nreinstated without a reason, all of\nthis without any"
        },
        {
          "Researchers are not homogeneous": "explanations about the decisions from the side of Twitter. We have helped numerous students to"
        },
        {
          "Researchers are not homogeneous": "apply for API access, sometimes with virtually identical applications, some of which got denied"
        },
        {
          "Researchers are not homogeneous": "while others were approved immediately - an experience which could be framed as an auditing"
        },
        {
          "Researchers are not homogeneous": "study itself."
        },
        {
          "Researchers are not homogeneous": "Another example is the Social Science One initiative that aims to foster collaboration between"
        },
        {
          "Researchers are not homogeneous": "researchers and companies. Specifically,\nit enables access to Facebook data for\n(selected)"
        },
        {
          "Researchers are not homogeneous": "researchers. Data access is given or\nrefused based on a process similar\nto obtaining research"
        },
        {
          "Researchers are not homogeneous": "funding:\nresearchers submit project proposals, and then are granted or\nrefused access to data"
        },
        {
          "Researchers are not homogeneous": "based on the evaluation of\nthe proposals according to “academic merit and feasibility; research"
        },
        {
          "Researchers are not homogeneous": "ethics;\nlikelihood of knowledge resulting from the project advancing social good; qualifications of"
        },
        {
          "Researchers are not homogeneous": "the proposed team”\n[33].\nIt\nis however unclear how exactly the proposals are evaluated, which"
        },
        {
          "Researchers are not homogeneous": "is problematic as some of the criteria - such as the likelihood of the project to contribute to social"
        },
        {
          "Researchers are not homogeneous": "good - are rather subjective. Others, such as the evaluation of\nresearchers’ qualifications, can"
        },
        {
          "Researchers are not homogeneous": "be influenced by implicit and explicit biases (e.g.,\nrelated to the applicant’s gender), as studies"
        },
        {
          "Researchers are not homogeneous": "based on academic funding award procedures show [34].\nIn the case of Social Science One"
        },
        {
          "Researchers are not homogeneous": "there is an apparent gender disparity among those awarded access to the data.\nIn the first"
        }
      ],
      "page": 8
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "awardees - only 2 out of 13 Principle Investigators appear to be women2, one of them leading a"
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "project\ntogether with a male PI\n[35]. Due to the opacity of\nthe evaluation process and the"
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "unavailability of\nthe information on the application success rate, we can only point out\nthis"
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "gender disparity as a fact but not\ninfer\nits actual cause. While evaluation processes of public"
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "research funding agencies have similar biases [34],\ninformation necessary to scrutinise the"
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "processes is more widely available or can be acquired via freedom of\ninformation requests or"
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "similar laws."
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "Restrictive processes to regulate access to platform data by academics are often justified by"
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "protecting user privacy or preventing data misuse. However,\nto date there is no evidence that"
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "such screening procedures actually prevent any wrong-doing.\nIt seems like what matters most"
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "for being granted access to data\nis the nationality or country of\nresidence of\nthe researchers,"
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "the prestige of\ntheir\ninstitution and their connections to the corporation providing data access."
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "As a result,\ninitiatives that are often considered as equalising science (e.g. Twitter API allows"
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "anyone to get access to a lot of data and do research), can in fact exacerbate inequalities,"
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "which in turn affects the field of algorithm auditing itself."
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "Implications of the lack of diversity among researchers"
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "We suggest\nthat\nthe aforementioned differences among researchers -\ni.e.,\nthose related to the"
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "ease of data access and risks associated with engaging in risky algorithm audits -\nin terms of"
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "the scholars’ gender, status, nationality, ethnicity or prestige of\ntheir\ninstitutions,\nlead to the"
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "striking\nimbalances\nin\nthe\nfield\nof\nalgorithm auditing with\nregard\nto what\ngets\naudited."
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "Specifically,\nthese differences contribute to the field being highly Western- and English-centric"
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "as\nthose for whom audits are less\nrisky or easier\nto implement most often are based at"
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "prestigious Western institutions, more likely to be white and male, and less likely to have a"
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "migration background. A recent\nliterature review of\n(online platforms focused) algorithm audits"
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "[5] and a search for\n“algorithm audit studies”\nin a scholarly database indicate that\nthe absolute"
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "majority\nof\nthe\nstudies\nconducted\nto\ndate\nfocus on 1) Western platforms and 2)\ncontent"
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "published in English language. There are notable exceptions to this: several studies, authored"
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "by\nacademics\nbased\nin German-speaking\ncountries,\nhave\nexamined\ncontent\nin German"
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "[36]–[38]. A few others\neither\nadopted\na\ncomparative\napproach analysing content across"
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "multiple\nlanguages\n[13]\nor\naudited\nnon-Western\nplatforms\nand/or\nfocused\non\ncontent\nin"
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "languages such as Russian or Chinese [39]–[45]. However,\nthese studies are exceptions to the"
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "general “rule” of the Western- and English-centric studies in the algorithm auditing field."
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "Since most\nlarge online platforms are,\nin fact, Western and predominantly, U.S.-based, one"
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "could argue that Western-centrism of algorithm audits is not a major\nissue.\nIn the end,\nit\nis"
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "plausible to assume -\nthough we do not know this for a fact\n-\nthat\nthere are no separate"
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "algorithms deployed by companies in different jurisdictions and local markets. If this assumption"
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "is correct,\nthe analyses of the factors that contribute to personalization on Google or TikTok [11],"
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "[12] are valid not only for a certain national context,\nthus Western-centrism should not be much"
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "of an issue for such functionality audits. Nonetheless, we suggest it is problematic that, with the"
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "2 We acknowledge that gender is a complex construct and as we relied on visual cues and publicly"
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "available CVs only when determining the gender of the awardees, we can not be certain about the gender"
        },
        {
          "cohort of data access awardees -\nthe only cohort on which we found a publicly available list of": "identities of the PIs, hence we use the term “appear to be” women instead of “are” women."
        }
      ],
      "page": 9
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "the U.S.,\nto the best of our knowledge, have been subjects of algorithm audits so far. Since"
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "many of such platforms are founded and based in authoritarian states such as Russia or China"
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "and some are known to cooperate with the governments\nto censor or downgrade political"
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "content, auditing them can bring particularly valuable insights about potential algorithmic biases"
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "and authoritarian manipulation."
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "In the context of algorithm impact audits, analyses of non-Western platforms and non-English"
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "content are arguably even more overdue. Even if\nthe algorithms deployed by the companies"
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "across the globe function in the same way in different\nregions,\nthe pool of content available for"
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "an algorithm to select and (de)prioritise from differs depending on the language. Thus, even an"
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "algorithm that works in the same way will yield qualitatively different sets of\nresults depending"
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "on the language. Further,\nit\nis known that\nthe companies tend to invest more resources into"
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "content moderation\nand\nannotation\n(that\nis\nused\nas\ntraining\ndata\nfor machine\nlearning"
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "algorithms)\nfor English language content\nand, to a lesser degree, other popular and/or Western"
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "languages [46]. Taken together,\nthe differences in the pool of content and in information quality"
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "assurance-related efforts depending on the language,\nresult\nin information inequalities between"
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "users depending on their\nlocation and/or\nlanguage. This is documented by the few existing"
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "comparative algorithm audits (e.g.,\n[13],\n[39]), with the inequalities sometimes being potentially"
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "life-threatening for\nthe users. For\ninstance, Scherr and colleagues found that\nthere are major"
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "linguistic and location-based differences in how frequently information about suicide helplines is"
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "presented to Google’s users when submitting suicide-related queries,\nto the point where in"
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "some countries such crisis-prevention functionality seems to be not\nimplemented at all\n[13]."
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "Such documented information disparities highlight\nthe urgency of conducting more comparative"
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "and/or non-English content-focused algorithm audits and giving higher prominence to the fact"
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "that\nthe\nfindings\nof most\nalgorithm impact\naudits\nare\ncontext-specific, with\ntheir\nfindings"
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "non-generalizable to other national and linguistic settings."
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "Researchers are not necessarily a benevolent force serving larger society"
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "Coming back to the assumed homogeneity among researchers and Sandvig’s talk, we suggest"
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "that one aspect\nthat\nis ignored by Sandvig is an obvious conflict of\ninterest\nthat arises when"
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "researchers ask for\nthe possibility to conduct experiments or\nto access the data.\nIt\nis important"
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "to remember\nthat\nthe main beneficiaries of research are researchers themselves. They don’t do"
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "research as volunteers or publish their\nfindings anonymously. On the contrary, they are paid for"
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "their\nresearch and their\nincome and status depend on the visibility of\ntheir\nresearch. Getting"
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "access\nto unique large scale data sets increases the chances of publication in prestigious"
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "journals, promotion, etc. Moreover, researchers are not only interested in accessing the data but"
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "they\nare\nalso\ninterested\nin restricting data access\nfor other\nresearchers\nto prevent being"
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "“scooped”.\nThis\nbecomes\nespecially\nproblematic when\nresearchers\nthat\nhave\na\nstake\nin"
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "research that\nis conducted using a corporation’s data are part of an advisory board or other"
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "decision mechanism that decides who gets access to the data. While these self-interested"
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "motivations of\nresearchers are not necessarily in contradiction with the interests of society as a"
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "whole, we suggest\nit\nis important\nto keep in mind that serving the larger society is often not the"
        },
        {
          "exception of TikTok, Baidu or Yandex\n[39]–[45], no other platforms that were founded outside of": "main motivation of researchers when embarking on a new project."
        }
      ],
      "page": 10
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Users and their rights": "The omission of a key stakeholder in the algorithm audit debate becomes all the more important"
        },
        {
          "Users and their rights": "when\nconsidering\nthat\nresearchers may\nnot\nbe\nprimarily motivated\nby\nserving\nsociety."
        },
        {
          "Users and their rights": "Specifically,\nin Sandvig’s talk users of\nthe audited platforms were not discussed. This could be"
        },
        {
          "Users and their rights": "due to the perspective that users in the scholars vs. corporations debate are implicitly assumed"
        },
        {
          "Users and their rights": "to be represented by researchers. This would be in line with the assumption that\nresearchers"
        },
        {
          "Users and their rights": "are\nacting\nin\nthe\ninterests\nof\nthe\nbroader\npublic\nby\ndefault. However,\nbecause\nof\nthe"
        },
        {
          "Users and their rights": "aforementioned potential conflict of interest, we argue researchers in fact do not represent users"
        },
        {
          "Users and their rights": "and their interests do not necessarily align with the interests of the users."
        },
        {
          "Users and their rights": "We illustrate this misalignment of\ninterests between researchers and users with the example of"
        },
        {
          "Users and their rights": "sock-puppet auditing studies:\nIn algorithm auditing studies the creation of\nfake accounts on an"
        },
        {
          "Users and their rights": "online platform is a component of a commonly utilised auditing method, sometimes referred to"
        },
        {
          "Users and their rights": "as “sock-puppet auditing”\n[47] or\n“agent-based testing”\n[48],\n[49]. However,\nthe creation of fake"
        },
        {
          "Users and their rights": "accounts can have potentially negative effects not only on the platforms - something Sandvig"
        },
        {
          "Users and their rights": "discusses - but also on the users. Sandvig argues that online audits should be uncontroversial"
        },
        {
          "Users and their rights": "because offline audits are uncontroversial and well-established in social sciences as well as less"
        },
        {
          "Users and their rights": "obtrusive\ntowards\nthose\naudited\n-\nin\nthis\ncase,\nonline\nplatforms.\nThis\nhowever\nignores"
        },
        {
          "Users and their rights": "asymmetries that are introduced by the online environment. Compared to the offline settings -"
        },
        {
          "Users and their rights": "and classic audits conducted by the social scientists -\nin the online settings,\nthe researchers"
        },
        {
          "Users and their rights": "leave (more)\ntraces that can get\nin the way of user experiences.\nIn fact, online researchers"
        },
        {
          "Users and their rights": "might\nleave permanent\ntraces such as fake posts on platforms or buggy commits to software"
        },
        {
          "Users and their rights": "[50]. Researchers therefore not only use a companies’ resources but also permanently alter the"
        },
        {
          "Users and their rights": "environment\nthat users experience. From an ethical perspective,\nthe possible harm of such"
        },
        {
          "Users and their rights": "alterations\nneeds\nto\nbe\nbalanced with\nthe\npossible\nbenefit\nand put\ninto perspective with"
        },
        {
          "Users and their rights": "alterations that other actors on such platforms regularly introduce. When researchers pay to"
        },
        {
          "Users and their rights": "distribute an ad over\nthe ad distribution service of a social media platform to test a platform’s"
        },
        {
          "Users and their rights": "audience targeting algorithms,\nit will\nlikely be one of many ads that a user sees during one"
        },
        {
          "Users and their rights": "usage session of\nthe platform. Such an alteration therefore does not\nintroduce an experience"
        },
        {
          "Users and their rights": "that\nis drastically different\nfrom the everyday experience a user has and might be considered as"
        },
        {
          "Users and their rights": "not very harmful. On the other hand, if a researcher introduces offensive content into a self-help"
        },
        {
          "Users and their rights": "forum used by a vulnerable group of people to audit\nthe platform’s content moderation policies,"
        },
        {
          "Users and their rights": "users might be confronted with content\nthat\nis drastically different\nfrom what\nthey are used to"
        },
        {
          "Users and their rights": "seeing and might react very negatively to it."
        },
        {
          "Users and their rights": "Along the same lines,\nresearchers also need to be careful\nto not\n“poison the well”\nfor other"
        },
        {
          "Users and their rights": "researchers\nthat want\nto\nconduct\n(auditing)\nstudies on the same platform:\nif\nresearcher’s"
        },
        {
          "Users and their rights": "auditing\nbehaviour\nis\ntoo obvious or disturbs normal operations\ntoo much, other\nresearch"
        },
        {
          "Users and their rights": "projects might be endangered because users start\nrecognizing researcher’s behaviours and"
        },
        {
          "Users and their rights": "alter their own behaviour as a reaction."
        },
        {
          "Users and their rights": "Last but not\nleast, so far users’ perspectives have been barely integrated into the design of"
        },
        {
          "Users and their rights": "algorithm audits.\nYet\nrecent\nresearch\nsuggests\nthat\nusers\nare\nable\nto\nidentify\npotential"
        },
        {
          "Users and their rights": "algorithmic harms, albeit which harms exactly they identify largely depends on their experiences"
        },
        {
          "Users and their rights": "and\ndemographics\n[51].\nThis\nonce\nagain\nhighlights\nthe\nimportance\nof\nthe\ndiversity\nof"
        },
        {
          "Users and their rights": "perspectives\nfor\nthe\nalgorithm auditing\nfield.\nDeVos\nand\ncolleagues\nsuggest\nthat\nuser"
        },
        {
          "Users and their rights": "perspectives can be integrated into algorithm auditing in the future and advocate for user-driven"
        }
      ],
      "page": 11
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "algorithm audits\n- while acknowledging potential\nlimitations and harms [51]. We share their": "perspective and suggest\nthat user-centric audits could help alleviate the current\nimbalances in"
        },
        {
          "algorithm audits\n- while acknowledging potential\nlimitations and harms [51]. We share their": "the field that we described above, particularly with regard to what gets audited, and thus"
        },
        {
          "algorithm audits\n- while acknowledging potential\nlimitations and harms [51]. We share their": "constitute a fruitful direction for future audits."
        },
        {
          "algorithm audits\n- while acknowledging potential\nlimitations and harms [51]. We share their": "Conclusion"
        },
        {
          "algorithm audits\n- while acknowledging potential\nlimitations and harms [51]. We share their": "In this paper, we have aimed to critically engage with Prof. Christian Sandvig’s talk on the “right"
        },
        {
          "algorithm audits\n- while acknowledging potential\nlimitations and harms [51]. We share their": "to audit” at\nIC2S2 2021 through the discussion of power asymmetries that are important\nin the"
        },
        {
          "algorithm audits\n- while acknowledging potential\nlimitations and harms [51]. We share their": "algorithm auditing field. We have elaborated on some asymmetries and challenges mentioned"
        },
        {
          "algorithm audits\n- while acknowledging potential\nlimitations and harms [51]. We share their": "by Sandvig - such as those related to legal\nissues and the disparity between early-career and"
        },
        {
          "algorithm audits\n- while acknowledging potential\nlimitations and harms [51]. We share their": "senior\nresearchers. At\nthe same time, we have discussed power asymmetries that were not"
        },
        {
          "algorithm audits\n- while acknowledging potential\nlimitations and harms [51]. We share their": "mentioned\nin\nthe\noriginal\ntalk\nbut\nthat we\nfind\ncritically\nimportant:\nthose related to other"
        },
        {
          "algorithm audits\n- while acknowledging potential\nlimitations and harms [51]. We share their": "disparities\nbetween\nresearchers,\nincentive\nstructures\nrelated\nto\nthe\naccess\nto\ndata\nfrom"
        },
        {
          "algorithm audits\n- while acknowledging potential\nlimitations and harms [51]. We share their": "companies, targets of auditing and users and their rights."
        },
        {
          "algorithm audits\n- while acknowledging potential\nlimitations and harms [51]. We share their": "We have highlighted that while in recent years there have been some legal decisions that were"
        },
        {
          "algorithm audits\n- while acknowledging potential\nlimitations and harms [51]. We share their": "in favour of\nresearchers in the context of adversarial auditing such as the ruling in Sandvig v."
        },
        {
          "algorithm audits\n- while acknowledging potential\nlimitations and harms [51]. We share their": "Barr,\nthe field of algorithm auditing remains somewhat of a grey zone in terms of\nlaw which"
        },
        {
          "algorithm audits\n- while acknowledging potential\nlimitations and harms [51]. We share their": "obstructs\nthe\nability\nof\nthe researchers\nto conduct auditing studies. One major\nissue that"
        },
        {
          "algorithm audits\n- while acknowledging potential\nlimitations and harms [51]. We share their": "scientists\nface with regard to this\nis\nthe risk of\nlegal\nretaliation or accusations of scientific"
        },
        {
          "algorithm audits\n- while acknowledging potential\nlimitations and harms [51]. We share their": "misconduct\nfrom corporations. As Sandvig also highlights in his talk,\nthis issue can discourage"
        },
        {
          "algorithm audits\n- while acknowledging potential\nlimitations and harms [51]. We share their": "researchers, especially those in more precarious positions such as ECRs or\nforeign citizens,"
        },
        {
          "algorithm audits\n- while acknowledging potential\nlimitations and harms [51]. We share their": "from conducting audits. This and other power asymmetries we discussed above that\nlead to"
        },
        {
          "algorithm audits\n- while acknowledging potential\nlimitations and harms [51]. We share their": "inequalities in access to data and ability to perform audits have negative consequences for the"
        },
        {
          "algorithm audits\n- while acknowledging potential\nlimitations and harms [51]. We share their": "field as a whole resulting in it being western-centric and lacking diversity of perspectives."
        },
        {
          "algorithm audits\n- while acknowledging potential\nlimitations and harms [51]. We share their": "Another aspect\nthat needs to be considered in connection to auditing is the ethical\nimplications"
        },
        {
          "algorithm audits\n- while acknowledging potential\nlimitations and harms [51]. We share their": "of\nconducting\n(online)\naudits. While\nin\nSandvig’s\ntalk\nthese\nhave\nbeen\nconsidered\nfor"
        },
        {
          "algorithm audits\n- while acknowledging potential\nlimitations and harms [51]. We share their": "corporations,\nthe needs and concerns of users and other\nresearchers working on the platforms"
        },
        {
          "algorithm audits\n- while acknowledging potential\nlimitations and harms [51]. We share their": "that\nresearchers audit have not been adequately addressed.\nIt\nis essential\nto consider\nthe"
        },
        {
          "algorithm audits\n- while acknowledging potential\nlimitations and harms [51]. We share their": "distribution of power among all stakeholders in order\nto ensure a truly fair and unbiased field of"
        },
        {
          "algorithm audits\n- while acknowledging potential\nlimitations and harms [51]. We share their": "algorithm auditing."
        },
        {
          "algorithm audits\n- while acknowledging potential\nlimitations and harms [51]. We share their": "Finally, we would like to note that even though we discussed all\nthe aforementioned power"
        },
        {
          "algorithm audits\n- while acknowledging potential\nlimitations and harms [51]. We share their": "asymmetries\nin\nthe\ncontext\nof\nalgorithm auditing\nresearch, many\nof\nthem in\nfact\naffect"
        },
        {
          "algorithm audits\n- while acknowledging potential\nlimitations and harms [51]. We share their": "Computational Social Science (CSS) more generally with the field as a whole potentially lacking"
        },
        {
          "algorithm audits\n- while acknowledging potential\nlimitations and harms [51]. We share their": "the diversity of perspectives and objects of analysis. We suggest\nthat not only researchers"
        },
        {
          "algorithm audits\n- while acknowledging potential\nlimitations and harms [51]. We share their": "interested in algorithm auditing but\nthe CSS field as a whole needs to critically reflect on the"
        },
        {
          "algorithm audits\n- while acknowledging potential\nlimitations and harms [51]. We share their": "implications of existing disparities and look for the ways to address them."
        }
      ],
      "page": 12
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "References": "[1]"
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": "[2]"
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": "[3]"
        },
        {
          "References": ""
        },
        {
          "References": "[4]"
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": "[5]"
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": "[6]"
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": "[7]"
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": "[8]"
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": "[9]"
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": "[10] D. Pager, “The Use of Field Experiments for Studies of Employment Discrimination:"
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": "[11] M. Boeker and A. Urman, “An Empirical Investigation of Personalization Factors on"
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": "[12] A. Hannak, G. Soeller, D. Lazer, A. Mislove, and C. Wilson, “Measuring Price"
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": "[13] S. Scherr, F. Arendt, and M. Haim, “Algorithms without frontiers? How language-based"
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": ""
        },
        {
          "References": "[14] H. K. Dambanemuya and N. Diakopoulos, “Auditing the Information Quality of"
        },
        {
          "References": ""
        },
        {
          "References": ""
        }
      ],
      "page": 13
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "[15]": "",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": "Different Types of News,” Soc. Media Soc., vol. 7, no. 3, p. 20563051211041650, Jul."
        },
        {
          "[15]": "",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": "2021, doi: 10.1177/20563051211041648."
        },
        {
          "[15]": "[16] S. U. Noble, Algorithms of Oppression: How Search Engines Reinforce Racism. NYU",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": ""
        },
        {
          "[15]": "",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": "Press, 2018."
        },
        {
          "[15]": "[17] A. Urman, M. Makhortykh, R. Ulloa, and J. Kulshrestha, “Where the earth is flat and 9/11 is",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": ""
        },
        {
          "[15]": "",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": "an inside job: A comparative algorithm audit of conspiratorial information in web search"
        },
        {
          "[15]": "",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": "results,” Telemat. Inform., vol. 72, p. 101860, Aug. 2022, doi: 10.1016/j.tele.2022.101860."
        },
        {
          "[15]": "[18] P. Ugwudike, “AI audits for assessing design logics and building ethical systems: the case",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": ""
        },
        {
          "[15]": "",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": "of predictive policing algorithms,” AI Ethics, vol. 2, no. 1, pp. 199–208, Feb. 2022, doi:"
        },
        {
          "[15]": "",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": "10.1007/s43681-021-00117-5."
        },
        {
          "[15]": "[19]",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": "F. Mark, The Sociology of Debt. Policy Press, 2020."
        },
        {
          "[15]": "[20] E. Kazim, A. S. Koshiyama, A. Hilliard, and R. Polle, “Systematizing Audit in Algorithmic",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": ""
        },
        {
          "[15]": "",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": "Recruitment,” J. Intell., vol. 9, no. 3, Art. no. 3, Sep. 2021, doi:"
        },
        {
          "[15]": "",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": "10.3390/jintelligence9030046."
        },
        {
          "[15]": "[21] A. Maxwell, “Spotify Threatened Researchers Who Revealed ‘Pirate’ History *",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": ""
        },
        {
          "[15]": "",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": "TorrentFreak.”"
        },
        {
          "[15]": "",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": "https://torrentfreak.com/spotify-threatened-researchers-who-revealed-pirate-history-17100"
        },
        {
          "[15]": "",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": "6/ (accessed Nov. 18, 2022)."
        },
        {
          "[15]": "[22] P. Wei, “Remembering Aaron Swartz’s legacy in light of JSTOR opening access,” The",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": ""
        },
        {
          "[15]": "",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": "Stanford Daily, Mar. 28, 2020."
        },
        {
          "[15]": "",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": "https://stanforddaily.com/2020/03/27/remembering-aaron-swartzs-legacy-in-light-of-jstor-op"
        },
        {
          "[15]": "",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": "ening-access/ (accessed Nov. 18, 2022)."
        },
        {
          "[15]": "[23] M. Scott, “Facebook’s attempt to ban academics runs into trouble,” POLITICO, Aug. 05,",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": ""
        },
        {
          "[15]": "",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": "2021. https://www.politico.eu/article/facebook-nyu-laura-edelson-political-ads/ (accessed"
        },
        {
          "[15]": "",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": "Nov. 18, 2022)."
        },
        {
          "[15]": "[24]",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": "T. Claburn, “Once again, Facebook champions privacy ... of its algorithms: Independent"
        },
        {
          "[15]": "",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": "probe into Instagram shut down.”"
        },
        {
          "[15]": "",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": "https://www.theregister.com/2021/08/13/algorithmwatch_shut_down/ (accessed Nov. 18,"
        },
        {
          "[15]": "",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": "2022)."
        },
        {
          "[15]": "[25] S. Vaughan-Nichols, “Court rules that data scraping is legal in LinkedIn appeal,” ZDNET.",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": ""
        },
        {
          "[15]": "",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": "https://www.zdnet.com/article/court-rules-that-data-scraping-is-legal-in-linkedin-appeal/"
        },
        {
          "[15]": "",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": "(accessed Nov. 18, 2022)."
        },
        {
          "[15]": "[26] N. Gilens and J. Williams, “Federal Judge Rules It Is Not a Crime to Violate a Website’s",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": ""
        },
        {
          "[15]": "",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": "Terms of Service,” Electronic Frontier Foundation, Apr. 06, 2020."
        },
        {
          "[15]": "",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": "https://www.eff.org/deeplinks/2020/04/federal-judge-rules-it-not-crime-violate-websites-ter"
        },
        {
          "[15]": "",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": "ms-service (accessed Nov. 18, 2022)."
        },
        {
          "[15]": "[27] C. Laupman, L.-M. Schippers, and M. Papaléo Gagliardi, “Biased Algorithms and the",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": ""
        },
        {
          "[15]": "",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": "Discrimination upon Immigration Policy,” in Law and Artificial Intelligence: Regulating AI"
        },
        {
          "[15]": "",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": "and Applying AI in Legal Practice, B. Custers and E. Fosch-Villaronga, Eds. The Hague:"
        },
        {
          "[15]": "",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": "T.M.C. Asser Press, 2022, pp. 187–204. doi: 10.1007/978-94-6265-523-2_10."
        },
        {
          "[15]": "[28] ResearchGate, “Terms of Service,” ResearchGate, 2022.",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": ""
        },
        {
          "[15]": "",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": "https://www.researchgate.net/terms-of-service (accessed Nov. 24, 2022)."
        },
        {
          "[15]": "[29]",
          "J. Bandy and N. Diakopoulos, “Curating Quality? How Twitter’s Timeline Algorithm Treats": "TikTok, “Terms Of Service | TikTok,” 2022."
        }
      ],
      "page": 14
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": ""
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": "future,” 2022. https://digital-strategy.ec.europa.eu/en/policies/digital-services-act-package"
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": "(accessed Nov. 24, 2022)."
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": ""
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": "Tenure in Academia,” Soc. Forces, vol. 96, no. 2, pp. 529–560, Dec. 2017, doi:"
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": "10.1093/sf/sox052."
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": "J. Chen, Q. Liu, and M. Kim, “Gender gap in tenure and promotion: Evidence from the"
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": "economics Ph.D. class of 2008,” South. Econ. J., vol. 88, no. 4, pp. 1277–1312, 2022, doi:"
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": "10.1002/soej.12567."
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": ""
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": "https://docs.google.com/document/d/1zu6NdHM_KXoOskCt32W4Zp_t9QL_o4depOUxwV"
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": "15pOw/edit?usp=sharing&usp=embed_facebook (accessed Nov. 24, 2022)."
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": "F. S. Steinþórsdóttir, Þ. Einarsdóttir, G. M. Pétursdóttir, and S. Himmelweit, “Gendered"
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": "inequalities in competitive grant funding: an overlooked dimension of gendered power"
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": "relations in academia,” High. Educ. Res. Dev., vol. 39, no. 2, pp. 362–375, Feb. 2020, doi:"
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": "10.1080/07294360.2019.1666257."
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": ""
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": "Recipients of the Social Media and Democracy Research Grants,” Items."
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": "https://items.ssrc.org/from-our-programs/social-media-and-democracy-research-grants-gra"
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": "ntees/ (accessed Nov. 24, 2022)."
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": ""
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": "Digit. Journal., vol. 7, no. 6, pp. 824–843, Jul. 2019, doi: 10.1080/21670811.2018.1539626."
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": ""
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": "personalization on the diversity of Google News,” Digit. Journal., vol. 6, no. 3, pp. 330–343,"
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": "Mar. 2018, doi: 10.1080/21670811.2017.1338145."
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": "J. Unkel and M. Haim, “Googling Politics: Parties, Sources, and Issue Ownerships on"
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": "Google in the 2017 German Federal Election Campaign,” Soc. Sci. Comput. Rev., vol. 39,"
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": "no. 5, pp. 844–861, Oct. 2021, doi: 10.1177/0894439319881634."
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": ""
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": "like? : Auditing algorithmic curation of visual historical content on Web search engines,”"
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": "First Monday, Oct. 2021, doi: 10.5210/fm.v26i10.11562."
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": ""
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": "conspiracies: How Google and Yandex represented Smart Voting during the 2021"
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": "parliamentary elections in Russia,” Harv. Kennedy Sch. Misinformation Rev., Mar. 2022,"
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": "doi: 10.37016/mr-2020-94."
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": ""
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": "framing of COVID-19 on search engines.” arXiv, Sep. 22, 2022. doi:"
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": "10.48550/arXiv.2209.11120."
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": ""
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": "Google’s search results of Internet events in China,” New Media Soc., vol. 16, no. 2, pp."
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": "212–233, Mar. 2014, doi: 10.1177/1461444813481196."
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": ""
        },
        {
          "https://www.tiktok.com/legal/page/eea/terms-of-service/en (accessed Nov. 24, 2022).": "partially state-controlled search engine Yandex mediated an anti-regime protest event,” Inf."
        }
      ],
      "page": 15
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Commun. Soc., vol. 0, no. 0, pp. 1–17, Jun. 2021, doi: 10.1080/1369118X.2021.1933563.": "F. Toepfl, D. Kravets, A. Ryzhova, and A. Beseler, “Who are the plotters behind the"
        },
        {
          "Commun. Soc., vol. 0, no. 0, pp. 1–17, Jun. 2021, doi: 10.1080/1369118X.2021.1933563.": "pandemic? Comparing Covid-19 conspiracy theories in Google search results across five"
        },
        {
          "Commun. Soc., vol. 0, no. 0, pp. 1–17, Jun. 2021, doi: 10.1080/1369118X.2021.1933563.": "key target countries of Russia’s foreign communication,” Inf. Commun. Soc., vol. 0, no. 0,"
        },
        {
          "Commun. Soc., vol. 0, no. 0, pp. 1–17, Jun. 2021, doi: 10.1080/1369118X.2021.1933563.": "pp. 1–19, Apr. 2022, doi: 10.1080/1369118X.2022.2065213."
        },
        {
          "Commun. Soc., vol. 0, no. 0, pp. 1–17, Jun. 2021, doi: 10.1080/1369118X.2021.1933563.": ""
        },
        {
          "Commun. Soc., vol. 0, no. 0, pp. 1–17, Jun. 2021, doi: 10.1080/1369118X.2021.1933563.": "engines mediate four types of past events in Russia,” Media Cult. Soc., vol. 41, no. 1, pp."
        },
        {
          "Commun. Soc., vol. 0, no. 0, pp. 1–17, Jun. 2021, doi: 10.1080/1369118X.2021.1933563.": "21–37, Jan. 2019, doi: 10.1177/0163443718764565."
        },
        {
          "Commun. Soc., vol. 0, no. 0, pp. 1–17, Jun. 2021, doi: 10.1080/1369118X.2021.1933563.": ""
        },
        {
          "Commun. Soc., vol. 0, no. 0, pp. 1–17, Jun. 2021, doi: 10.1080/1369118X.2021.1933563.": "in global languages harms communities of color,” Prism, Nov. 02, 2021."
        },
        {
          "Commun. Soc., vol. 0, no. 0, pp. 1–17, Jun. 2021, doi: 10.1080/1369118X.2021.1933563.": "http://prismreports.org/2021/11/02/facebook-and-youtubes-refusal-to-moderate-misinforma"
        },
        {
          "Commun. Soc., vol. 0, no. 0, pp. 1–17, Jun. 2021, doi: 10.1080/1369118X.2021.1933563.": "tion-in-global-languages-harms-communities-of-color/ (accessed Nov. 24, 2022)."
        },
        {
          "Commun. Soc., vol. 0, no. 0, pp. 1–17, Jun. 2021, doi: 10.1080/1369118X.2021.1933563.": ""
        },
        {
          "Commun. Soc., vol. 0, no. 0, pp. 1–17, Jun. 2021, doi: 10.1080/1369118X.2021.1933563.": "Methods for Detecting Discrimination on Internet Platforms,” p. 23."
        },
        {
          "Commun. Soc., vol. 0, no. 0, pp. 1–17, Jun. 2021, doi: 10.1080/1369118X.2021.1933563.": ""
        },
        {
          "Commun. Soc., vol. 0, no. 0, pp. 1–17, Jun. 2021, doi: 10.1080/1369118X.2021.1933563.": "Human Behavior,” Journal. Stud., vol. 21, no. 7, pp. 895–911, May 2020, doi:"
        },
        {
          "Commun. Soc., vol. 0, no. 0, pp. 1–17, Jun. 2021, doi: 10.1080/1369118X.2021.1933563.": "10.1080/1461670X.2019.1702892."
        },
        {
          "Commun. Soc., vol. 0, no. 0, pp. 1–17, Jun. 2021, doi: 10.1080/1369118X.2021.1933563.": ""
        },
        {
          "Commun. Soc., vol. 0, no. 0, pp. 1–17, Jun. 2021, doi: 10.1080/1369118X.2021.1933563.": "insights for algorithm auditing,” J. Inf. Sci., p. 01655515221093029, May 2022, doi:"
        },
        {
          "Commun. Soc., vol. 0, no. 0, pp. 1–17, Jun. 2021, doi: 10.1080/1369118X.2021.1933563.": "10.1177/01655515221093029."
        },
        {
          "Commun. Soc., vol. 0, no. 0, pp. 1–17, Jun. 2021, doi: 10.1080/1369118X.2021.1933563.": "J. Leyden, “Ill-advised research on Linux kernel lands computer scientists in hot water,”"
        },
        {
          "Commun. Soc., vol. 0, no. 0, pp. 1–17, Jun. 2021, doi: 10.1080/1369118X.2021.1933563.": "The Daily Swig | Cybersecurity news and views, Apr. 22, 2021."
        },
        {
          "Commun. Soc., vol. 0, no. 0, pp. 1–17, Jun. 2021, doi: 10.1080/1369118X.2021.1933563.": "https://portswigger.net/daily-swig/ill-advised-research-on-linux-kernel-lands-computer-scien"
        },
        {
          "Commun. Soc., vol. 0, no. 0, pp. 1–17, Jun. 2021, doi: 10.1080/1369118X.2021.1933563.": "tists-in-hot-water (accessed Nov. 24, 2022)."
        },
        {
          "Commun. Soc., vol. 0, no. 0, pp. 1–17, Jun. 2021, doi: 10.1080/1369118X.2021.1933563.": ""
        },
        {
          "Commun. Soc., vol. 0, no. 0, pp. 1–17, Jun. 2021, doi: 10.1080/1369118X.2021.1933563.": "Algorithm Auditing: Investigating users’ strategies for uncovering harmful algorithmic"
        },
        {
          "Commun. Soc., vol. 0, no. 0, pp. 1–17, Jun. 2021, doi: 10.1080/1369118X.2021.1933563.": "behavior,” in Proceedings of the 2022 CHI Conference on Human Factors in Computing"
        },
        {
          "Commun. Soc., vol. 0, no. 0, pp. 1–17, Jun. 2021, doi: 10.1080/1369118X.2021.1933563.": "Systems, New York, NY, USA, Apr. 2022, pp. 1–19. doi: 10.1145/3491102.3517441."
        }
      ],
      "page": 16
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Global Freedom of Expression",
      "authors": [
        "\" Columbia",
        "Sandvig V",
        "Barr"
      ],
      "year": "2022",
      "venue": "Global Freedom of Expression"
    },
    {
      "citation_id": "2",
      "title": "Keynote: Computational Social Science and the Right to Audit",
      "authors": [
        "C Sanvdig"
      ],
      "year": "2021",
      "venue": "Keynote: Computational Social Science and the Right to Audit"
    },
    {
      "citation_id": "3",
      "title": "Automation, Algorithms, and Politics| Auditing for Transparency in Content Personalization Systems",
      "authors": [
        "B Mittelstadt"
      ],
      "year": "2016",
      "venue": "Int. J. Commun"
    },
    {
      "citation_id": "4",
      "title": "Measuring personalization of web search",
      "authors": [
        "A Hannak"
      ],
      "year": "2013",
      "venue": "Proceedings of the 22nd international conference on World Wide Web",
      "doi": "10.1145/2488388.2488435"
    },
    {
      "citation_id": "5",
      "title": "Problematic Machine Behavior: A Systematic Literature Review of Algorithm Audits",
      "authors": [
        "J Bandy"
      ],
      "year": "2021",
      "venue": "Proc. ACM Hum.-Comput. Interact",
      "doi": "10.1145/3449148"
    },
    {
      "citation_id": "6",
      "title": "An Introduction to Audit Studies in the Social Sciences",
      "authors": [
        "S Gaddis"
      ],
      "year": "2018",
      "venue": "Audit Studies: Behind the Scenes with Theory",
      "doi": "10.1007/978-3-319-71153-9_1"
    },
    {
      "citation_id": "7",
      "title": "Racial Discrimination in Apartment Rentals1",
      "authors": [
        "D Johnson",
        "R Porter",
        "P Mateljan"
      ],
      "year": "1971",
      "venue": "J. Appl. Soc. Psychol",
      "doi": "10.1111/j.1559-1816.1971.tb00373.x"
    },
    {
      "citation_id": "8",
      "title": "Science faculty's subtle gender biases favor male students",
      "authors": [
        "C Moss-Racusin",
        "J Dovidio",
        "V Brescoll",
        "M Graham",
        "J Handelsman"
      ],
      "year": "2012",
      "venue": "Proc. Natl. Acad. Sci",
      "doi": "10.1073/pnas.1211286109"
    },
    {
      "citation_id": "9",
      "title": "Ethnic Discrimination in Multi-ethnic Societies: Evidence from Russia",
      "authors": [
        "A Bessudnov",
        "A Shcherbak"
      ],
      "year": "2020",
      "venue": "Eur. Sociol. Rev",
      "doi": "10.1093/esr/jcz045"
    },
    {
      "citation_id": "10",
      "title": "The Use of Field Experiments for Studies of Employment Discrimination: Contributions, Critiques, and Directions for the Future",
      "authors": [
        "D Pager"
      ],
      "year": "2007",
      "venue": "Ann. Am. Acad. Pol. Soc. Sci",
      "doi": "10.1177/0002716206294796"
    },
    {
      "citation_id": "11",
      "title": "An Empirical Investigation of Personalization Factors on TikTok",
      "authors": [
        "M Boeker",
        "A Urman"
      ],
      "year": "2022",
      "venue": "Proceedings of the ACM Web Conference 2022",
      "doi": "10.1145/3485447.3512102"
    },
    {
      "citation_id": "12",
      "title": "Measuring Price Discrimination and Steering on E-commerce Web Sites",
      "authors": [
        "A Hannak",
        "G Soeller",
        "D Lazer",
        "A Mislove",
        "C Wilson"
      ],
      "year": "2014",
      "venue": "Proceedings of the 2014 Conference on Internet Measurement Conference",
      "doi": "10.1145/2663716.2663744"
    },
    {
      "citation_id": "13",
      "title": "Algorithms without frontiers? How language-based algorithmic information disparities for suicide crisis information sustain digital divides over time in 17 countries",
      "authors": [
        "S Scherr",
        "F Arendt",
        "M Haim"
      ],
      "year": "2022",
      "venue": "Inf. Commun. Soc",
      "doi": "10.1080/1369118X.2022.2097017"
    },
    {
      "citation_id": "14",
      "title": "Auditing the Information Quality of News-Related Queries on the Alexa Voice Assistant",
      "authors": [
        "H Dambanemuya",
        "N Diakopoulos"
      ],
      "year": "2021",
      "venue": "Proc. ACM Hum.-Comput. Interact",
      "doi": "10.1145/3449157"
    },
    {
      "citation_id": "15",
      "title": "Curating Quality? How Twitter's Timeline Algorithm Treats Different Types of News",
      "authors": [
        "J Bandy",
        "N Diakopoulos"
      ],
      "year": "2021",
      "venue": "Soc. Media Soc",
      "doi": "10.1177/20563051211041648"
    },
    {
      "citation_id": "16",
      "title": "Algorithms of Oppression: How Search Engines Reinforce Racism",
      "authors": [
        "S Noble"
      ],
      "year": "2018",
      "venue": "Algorithms of Oppression: How Search Engines Reinforce Racism"
    },
    {
      "citation_id": "17",
      "title": "Where the earth is flat and 9/11 is an inside job: A comparative algorithm audit of conspiratorial information in web search results",
      "authors": [
        "A Urman",
        "M Makhortykh",
        "R Ulloa",
        "J Kulshrestha"
      ],
      "year": "2022",
      "venue": "Telemat. Inform",
      "doi": "10.1016/j.tele.2022.101860"
    },
    {
      "citation_id": "18",
      "title": "AI audits for assessing design logics and building ethical systems: the case of predictive policing algorithms",
      "authors": [
        "P Ugwudike"
      ],
      "year": "2022",
      "venue": "AI Ethics",
      "doi": "10.1007/s43681-021-00117-5"
    },
    {
      "citation_id": "19",
      "title": "",
      "authors": [
        "F Mark"
      ],
      "year": "2020",
      "venue": ""
    },
    {
      "citation_id": "20",
      "title": "Systematizing Audit in Algorithmic Recruitment",
      "authors": [
        "E Kazim",
        "A Koshiyama",
        "A Hilliard",
        "R Polle"
      ],
      "year": "2021",
      "venue": "J. Intell",
      "doi": "10.3390/jintelligence9030046"
    },
    {
      "citation_id": "21",
      "title": "Spotify Threatened Researchers Who Revealed 'Pirate' History * TorrentFreak",
      "authors": [
        "A Maxwell"
      ],
      "venue": "Spotify Threatened Researchers Who Revealed 'Pirate' History * TorrentFreak"
    },
    {
      "citation_id": "22",
      "title": "Remembering Aaron Swartz's legacy in light of JSTOR opening access",
      "authors": [
        "P Wei"
      ],
      "year": "2020",
      "venue": "Remembering Aaron Swartz's legacy in light of JSTOR opening access"
    },
    {
      "citation_id": "23",
      "title": "Facebook's attempt to ban academics runs into trouble",
      "authors": [
        "M Scott"
      ],
      "year": "2021",
      "venue": "POLITICO"
    },
    {
      "citation_id": "24",
      "title": "Once again, Facebook champions privacy ... of its algorithms: Independent probe into Instagram shut down",
      "authors": [
        "T Claburn"
      ],
      "year": "2022",
      "venue": "Once again, Facebook champions privacy ... of its algorithms: Independent probe into Instagram shut down"
    },
    {
      "citation_id": "25",
      "title": "Court rules that data scraping is legal in LinkedIn appeal",
      "authors": [
        "S Vaughan-Nichols"
      ],
      "year": "2022",
      "venue": "ZDNET"
    },
    {
      "citation_id": "26",
      "title": "Federal Judge Rules It Is Not a Crime to Violate a Website's Terms of Service",
      "authors": [
        "N Gilens",
        "J Williams"
      ],
      "year": "2020",
      "venue": "Federal Judge Rules It Is Not a Crime to Violate a Website's Terms of Service"
    },
    {
      "citation_id": "27",
      "title": "Biased Algorithms and the Discrimination upon Immigration Policy",
      "authors": [
        "C Laupman",
        "L.-M Schippers",
        "M Gagliardi"
      ],
      "year": "2022",
      "venue": "Law and Artificial Intelligence: Regulating AI and Applying AI in Legal Practice, B. Custers and E. Fosch-Villaronga",
      "doi": "10.1007/978-94-6265-523-2_10"
    },
    {
      "citation_id": "28",
      "title": "Terms of Service",
      "authors": [
        "Researchgate"
      ],
      "year": "2022",
      "venue": "Terms of Service"
    },
    {
      "citation_id": "29",
      "title": "Terms Of Service | TikTok",
      "authors": [
        "Tiktok"
      ],
      "year": "2022",
      "venue": "Terms Of Service | TikTok"
    },
    {
      "citation_id": "30",
      "title": "The Digital Services Act package | Shaping Europe's digital future",
      "year": "2022",
      "venue": "The Digital Services Act package | Shaping Europe's digital future"
    },
    {
      "citation_id": "31",
      "title": "Publish and Perish? An Assessment of Gender Gaps in Promotion to Tenure in Academia",
      "authors": [
        "K Weisshaar"
      ],
      "year": "2017",
      "venue": "Soc. Forces",
      "doi": "10.1093/sf/sox052"
    },
    {
      "citation_id": "32",
      "title": "Gender gap in tenure and promotion: Evidence from the economics Ph.D. class of 2008",
      "authors": [
        "J Chen",
        "Q Liu",
        "M Kim"
      ],
      "year": "2022",
      "venue": "South. Econ. J",
      "doi": "10.1002/soej.12567"
    },
    {
      "citation_id": "33",
      "title": "Social Science One URLs RFP",
      "year": "2021",
      "venue": "Social Science One"
    },
    {
      "citation_id": "34",
      "title": "Gendered inequalities in competitive grant funding: an overlooked dimension of gendered power relations in academia",
      "authors": [
        "F Steinþórsdóttir",
        "Þ Einarsdóttir",
        "G Pétursdóttir",
        "S Himmelweit"
      ],
      "year": "2020",
      "venue": "High. Educ. Res. Dev",
      "doi": "10.1080/07294360.2019.1666257"
    },
    {
      "citation_id": "35",
      "title": "The Social Science Research Council Announces the First Recipients of the Social Media and Democracy Research Grants",
      "authors": [
        "A Nelson",
        "J Rhody"
      ],
      "year": "2022",
      "venue": "Items"
    },
    {
      "citation_id": "36",
      "title": "Beyond the Bubble: Assessing the Diversity of Political Search Results",
      "authors": [
        "C Puschmann"
      ],
      "year": "2019",
      "venue": "Digit. Journal",
      "doi": "10.1080/21670811.2018.1539626"
    },
    {
      "citation_id": "37",
      "title": "Burst of the Filter Bubble?: Effects of personalization on the diversity of Google News",
      "authors": [
        "M Haim",
        "A Graefe",
        "H.-B Brosius"
      ],
      "year": "2018",
      "venue": "Digit. Journal",
      "doi": "10.1080/21670811.2017.1338145"
    },
    {
      "citation_id": "38",
      "title": "Googling Politics: Parties, Sources, and Issue Ownerships on Google in the 2017 German Federal Election Campaign",
      "authors": [
        "J Unkel",
        "M Haim"
      ],
      "year": "2021",
      "venue": "Soc. Sci. Comput. Rev",
      "doi": "10.1177/0894439319881634"
    },
    {
      "citation_id": "39",
      "title": "Hey, Google, is it what the Holocaust looked like? : Auditing algorithmic curation of visual historical content on Web search engines",
      "authors": [
        "M Makhortykh",
        "A Urman",
        "R Ulloa"
      ],
      "year": "2021",
      "venue": "First Monday",
      "doi": "10.5210/fm.v26i10.11562"
    },
    {
      "citation_id": "40",
      "title": "A story of (non)compliance, bias, and conspiracies: How Google and Yandex represented Smart Voting during the 2021 parliamentary elections in Russia",
      "authors": [
        "M Makhortykh",
        "A Urman",
        "M Wijermars"
      ],
      "year": "2022",
      "venue": "Harv. Kennedy Sch. Misinformation Rev",
      "doi": "10.37016/mr-2020-94"
    },
    {
      "citation_id": "41",
      "title": "This is what a pandemic looks like: Visual framing of COVID-19 on search engines",
      "authors": [
        "M Makhortykh",
        "A Urman",
        "R Ulloa"
      ],
      "year": "2022",
      "venue": "arXiv",
      "doi": "10.48550/arXiv.2209.11120"
    },
    {
      "citation_id": "42",
      "title": "The business and politics of search engines: A comparative study of Baidu and Google's search results of Internet events in China",
      "authors": [
        "M Jiang"
      ],
      "year": "2014",
      "venue": "New Media Soc",
      "doi": "10.1177/1461444813481196"
    },
    {
      "citation_id": "43",
      "title": "Gauging reference and source bias over time: how Russia's partially state-controlled search engine Yandex mediated an anti-regime protest event",
      "authors": [
        "D Kravets",
        "F Toepfl"
      ],
      "year": "2021",
      "venue": "Inf. Commun. Soc",
      "doi": "10.1080/1369118X.2021.1933563"
    },
    {
      "citation_id": "44",
      "title": "Who are the plotters behind the pandemic? Comparing Covid-19 conspiracy theories in Google search results across five key target countries of Russia's foreign communication",
      "authors": [
        "F Toepfl",
        "D Kravets",
        "A Ryzhova",
        "A Beseler"
      ],
      "year": "2022",
      "venue": "Inf. Commun. Soc",
      "doi": "10.1080/1369118X.2022.2065213"
    },
    {
      "citation_id": "45",
      "title": "Querying the Internet as a mnemonic practice: how search engines mediate four types of past events in Russia",
      "authors": [
        "A Zavadski",
        "F Toepfl"
      ],
      "year": "2019",
      "venue": "Media Cult. Soc",
      "doi": "10.1177/0163443718764565"
    },
    {
      "citation_id": "46",
      "title": "Facebook and YouTube's refusal to moderate misinformation in global languages harms communities of color",
      "authors": [
        "N Nguyen",
        "C Scurato"
      ],
      "year": "2021",
      "venue": "Prism"
    },
    {
      "citation_id": "47",
      "title": "Auditing Algorithms: Research Methods for Detecting Discrimination on Internet Platforms",
      "authors": [
        "C Sandvig",
        "K Hamilton",
        "K Karahalios",
        "C Langbort"
      ],
      "venue": "Auditing Algorithms: Research Methods for Detecting Discrimination on Internet Platforms"
    },
    {
      "citation_id": "48",
      "title": "Agent-based Testing: An Automated Approach toward Artificial Reactions to Human Behavior",
      "authors": [
        "M Haim"
      ],
      "year": "2020",
      "venue": "Journal. Stud",
      "doi": "10.1080/1461670X.2019.1702892"
    },
    {
      "citation_id": "49",
      "title": "Scaling up search engine audits: Practical insights for algorithm auditing",
      "authors": [
        "R Ulloa",
        "M Makhortykh",
        "A Urman"
      ],
      "year": "2022",
      "venue": "J. Inf. Sci",
      "doi": "10.1177/01655515221093029"
    },
    {
      "citation_id": "50",
      "title": "Ill-advised research on Linux kernel lands computer scientists in hot water",
      "authors": [
        "J Leyden"
      ],
      "year": "2021",
      "venue": "The Daily Swig | Cybersecurity news and views"
    },
    {
      "citation_id": "51",
      "title": "Toward User-Driven Algorithm Auditing: Investigating users' strategies for uncovering harmful algorithmic behavior",
      "authors": [
        "A Devos",
        "A Dhabalia",
        "H Shen",
        "K Holstein",
        "M Eslami"
      ],
      "year": "2022",
      "venue": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
      "doi": "10.1145/3491102.3517441"
    }
  ]
}