{
  "paper_id": "2107.13734v1",
  "title": "An Ethical Framework For Guiding The Development Of Affectively-Aware Artificial Intelligence",
  "published": "2021-07-29T03:57:53Z",
  "authors": [
    "Desmond C. Ong"
  ],
  "keywords": [
    "Ethics",
    "Affective Computing",
    "Facial Emotion Recognition",
    "Deep Learning"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "The recent rapid advancements in artificial intelligence research and deployment have sparked more discussion about the potential ramifications of socially-and emotionallyintelligent AI. The question is not if research can produce such affectively-aware AI, but when it will. What will it mean for society when machines-and the corporations and governments they serve-can \"read\" people's minds and emotions? What should developers and operators of such AI do, and what should they not do? The goal of this article is to pre-empt some of the potential implications of these developments, and propose a set of guidelines for evaluating the (moral and) ethical consequences of affectively-aware AI, in order to guide researchers, industry professionals, and policy-makers. We propose a multi-stakeholder analysis framework that separates the ethical responsibilities of AI Developers vis-à-vis the entities that deploy such AIwhich we term Operators. Our analysis produces two pillars that clarify the responsibilities of each of these stakeholders: Provable Beneficence, which rests on proving the effectiveness of the AI, and Responsible Stewardship, which governs responsible collection, use, and storage of data and the decisions made from such data. We end with recommendations for researchers, developers, operators, as well as regulators and law-makers.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "I. Introduction",
      "text": "At the February 2020 meeting of the Association for the Advancement of Artificial Intelligence (AAAI), the premier society for AI research, two invited plenary speakers mentioned Affective Computing in their talks, for completely opposite reasons. The first speaker cited Affective Computing as an example of a world-destroying AI application, as it could empower authoritarian regimes to monitor the inner lives of their citizens. Thirty-six hours later, a second speaker hailed it as a crucial component to building provably safe AI and preventing an AI-led apocalypse 1 . Neither studies affective computing; both are respected AI researchers whose opinions about affective computing could not be further apart.\n\nAny technology can be applied productively, or in questionable ways. In the case of affective computing, conversations about mis-uses are happening more frequently. For example, in the interests of more efficiently screening large quantities of job applicants, companies around the world are utilizing emotion recognition in AI for automated candidate assessment  [1] -  [3] . This has faced backlash  [4] ,  [5]  and has even generated legislation  [6] . Other controversial examples include emotion detection for employee and student monitoring  [7] -  [9] . Psychologists have also questioned whether current emotion recognition models are scientifically validated enough to afford the inferences that companies are drawing  [10] . This has led some AI researchers to start calling for an outright ban on deploying emotion recognition technologies in \"decisions that impact people's lives and access to opportunities\"  [11] . At the last Affective Computing and Intelligent Interaction meeting in September 2019, we-the community of affective computing researchers-convened an inaugural townhall to discuss problematic applications of affective computing technology, and we decided that the conference theme for 2021 would be Ethical Affective Computing. Indeed, many of us feel that we, being the most familiar with the capabilities and limitations of such technology, as well as having done the research that enabled these applications, have a professional responsibility to address these ethical issues head-on.\n\nThe goal of this article is to start a conversation on systematically addressing these ethical issues. Building upon past discussions in affective computing  [12] -  [16]  and current trends in AI ethics more broadly  [17] , we outline an ethical framework for examining the impact of applications of affectively-aware AI. Ethics should not just prescribe what we should not do with such technology, but also illuminate what we should do-and how we should do it. This framework aims to serve as a set of guidelines that relevant stakeholders, including researchers, industry professionals, companies, policy-makers, and regulators, can employ to analyze the associated risks, which is crucial to a human-centered approach to developing affectively-aware AI technologies.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "A. Scope",
      "text": "In this article we specifically focus on issues particular to affectively-aware AI, and avoid discussion of the ethics of AI more generally: We note that of the 84 documents identified by  [17] 's extensive review of AI ethics statements, only a minority (11 documents, or 13%)  [11] ,  [18] -  [27]  mentioned emotion recognition AI, and only 4  [11] ,  [18] -  [20]  and  [28]   in detail. We use the term Affectively-Aware AI to specifically refer to AI that can recognize emotional expressions in people (from facial expressions, body language, language, physiology, and so forth), and perhaps can reason about emotions in context or with cultural awareness. Although the terms \"Affective AI\" or \"Emotional AI\" are commonly used by affective computing researchers and companies, we specifically choose not to use them to sidestep any philosophical discussion of AI that possesses emotions  [29] . We also do not discuss ethical issues with AI expressing emotions (e.g., deception  [14] ). The consequences we discuss rest only on the presumed ability of AI to recognize emotions-Indeed, emotion-recognizing AI make up the vast majority of commercial offerings that already exist today, and that are generating public concern.\n\nWe first begin by briefly summarizing the capabilities and limitations of the technology today, as overblown claims by companies have led to a general misunderstanding about the limits of the technology  [4] . Next, we outline our proposed ethical framework, which analyzes the different stakeholders relevant to affectively-aware AI. In particular, we distinguish the ethical responsibilities held by the AI Developer with the entities that deploy such AI (which we term Operators), in order to clarify the division of responsibilities, and avoid either party absolving responsibility. We describe the two broad ethical pillars in our framework, and the implications that they have on development and deployment of such AI.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "B. Why The Need For Ethical Guidelines",
      "text": "Ethical guidelines are necessary to help guide what professionals should do with the technology they create, in addition to what they should not do. Although ethical guidelines by themselves carry no \"hard\" power-unlike laws and regulations passed by government authorities-they do serve an important role in clarifying social and professional norms. Articulating a clear and unambiguous ethical code provides clarification for activities the field deems acceptable and those it does not, and will help to guide both junior and seasoned researchers. Second, ethical guidelines could inspire individual entities (academic departments, journals, conferences, grant funding agencies) to implement policies that encourage compliance (e.g., a focus on teaching ethics in training curricula, or requiring ethical analysis to supplement paper submissions). Finally, putting forward a researcher-written framework may help regulators align efforts to craft complementary laws.\n\nMany professions and professional organizations have their own ethical codes by which they expect practicing members to adhere to. Perhaps the oldest and most famous is the Hippocratic Oath, and modern versions of this oath exist in many medical schools today. The Association for Computing Machinery (ACM) and the Institute of Electrical and Electronics Engineers (IEEE), the two largest engineering professional bodies, similarly have Codes of Ethics, which focus broadly on principles such as honesty, fairness, and respect for privacy.\n\nMore specific to Affective Computing, the IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems-a committee of respected IEEE engineers-published \"Ethically Aligned Design\" (EAD), a document focusing broadly on AI ethical issues, and which has a chapter dedicated to Affective Computing  [19] . This chapter outlines recommendations for specific application areas: (i) affective systems that are deployed across cultures; (ii) affective systems with which users may develop relationships; (iii) affective systems which manipulate, \"nudge\" or deceive people; (iv) affective systems which may impact human autonomy when deployed in organizations or in societies; and (v) affective systems which display synthetic emotions.\n\nIn order to complement EAD's approach of focusing on issues specific to individual applications, the present paper first outlines a more general, multi-stakeholder framework, elaborating on the responsibilities of both the AI developers and the entities that deploy such AI. Indeed, our proposed pillars encapsulates all the principles elaborated on in EAD  2  , and add several insights and concrete recommendations from reasoning through the two main stakeholders. In doing so, we hope that this document will serve as an elaboration of widely-accepted ethical principles, that is also actionable by researchers, industry professionals and policy-makers.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "C. Summarizing Recent Advancements In Affectively-Aware Ai",
      "text": "Trying to characterize the state of a rapidly-moving field, and so briefly, is a Sisyphean task. However, we feel that it is important, especially for readers outside affective computing, to know what are the capabilities and the limitations of this technology today. There are many scientific/psychological theories of emotion  [30] , such as basic emotion theories  [31] , appraisal theories  [32] , and constructivist theories  [33] . Although a full discussion of these theories is beyond our scope, we invite the interested reader to see Stark and Hoey  [16] , who discuss how different theoretical conceptualizations of emotion should shape the ethical design of AI systems.\n\nThe vast majority of affectively-aware AI is implicitly built upon a basic emotion theory, which assumes that emotions exist as distinct natural categories and can be recognized solely from behaviour. Such AI are usually trained using supervised learning  [34]  to perform single-example classification of stimuli from single modalities, taken out-of-context (e.g., a still photo), into one of several pre-defined categories. By contrast, real-life emotion detection done by humans is multimodal, evolves over time, and has to be done in context  [35] . Although there have been more academic research in recent years on complex multimodal emotion recognition systems  [36] ,  [37] , commercially-available software are still only unimodal, with the most mature being recognition of (still) facial expressions, such as Affectiva's AffDex, Microsoft's Azure API, and Amazon's Rekognition. Furthermore, because of the cost associated with collecting datasets with a larger variety of emotions, most academic research as well as commerical offerings are trained to only recognize a small number of emotions (e.g., 6), which is hardly representative of real-life.\n\nIn a recent comprehensive analysis,  [10]  argued that current technology excels at detecting facial movements, but the mapping from facial movements to the underlying emotions is not one-to-one but many-to-many 3  . Because emotions, which are themselves directly unobservable, produce many types of observable behavior, integrating multimodal behavior can help to triangulate what someone is feeling  [38] ,  [39] . But in many cases, even that is not enough to achieve true emotion understanding. One needs to understand the context  [40] -is this person watching sports or attending a performance review?incorporate external world and cultural knowledge, as well as infer people's mental states, their goals, expectations, and even past histories, in order to take their perspective and truly reason about how they feel  [41] ,  [42] . Current AI do not take these into account, and so may even be fundamentally limited in this endeavour of reading internal states solely from external behavior; we may require substantive changes to AI research paradigms  [43]  in order to achieve AI with a human-centric emotion understanding. If the entities who develop or deploy such systems assume that the readout of such AI systems are veridical \"emotions\" (rather than noisy inferences), without adequately considering context-specificity, social/cultural influences, or even inter-and intra-individual variation, they could end up reading too much into facial movements  4  , and make impactful decisions based on sorely incomplete information.\n\nWhile there is no doubt that our technology will continue to rapidly improve, we feel that at the present moment, affect recognition technology does not yet deliver what many people believe it to. Consumers of such technology need to treat such AI as a(n incomplete) statistical model, and not a magic crystal ball that perfectly discerns people's hidden emotional lives.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Ii. An Ethical Framework",
      "text": "In this section, we outline our proposed ethical framework. To the best of our knowledge, this is the first framework that distinguishes the ethical responsibilities of those that develop the AI from those that deploy or operate the AI.\n\nFirst, we identify the four stakeholders in an interaction involving an affectively-aware AI. There is (at least) one individual whose emotions are being read by the AI; we shall call them Emoters. The AI itself could be embodied, as in a social robot, or disembodied, as in the AI powering a system of surveillance cameras. There are the Operators, who are the entities that deploy the AI, and to whom the AI reports the output of any emotion analysis to. The Operator then makes decisions based on the AI's analysis, or they could delegate any subsequent decision-making to other AI systems. Ultimately, because they are the experts in the domain the AI will be deployed in, they hold ethical responsibility for the proper deployment of the AI, the security and collection of the data, as well as for decisions resulting from the AI's analysis.\n\nThe Developers of the AI had created and delivered the AI to the Operators, but may not be involved in every interaction. Because they are the ones designing, training, and maintaining the AI, and are often the only ones that can modify the AI, the Developers thus hold ethical responsibility over the design and validity of the AI. Finally, Regulators (i.e., lawmakers) are an important class of stakeholders, who may not be involved in any interaction, but have responsibility for advocating for the welfare of their citizens. We note that this general framework covers special cases where the Developer and Operator can be the same entity, as in the case of the deployment of an in-house developed AI, or where the Regulator is also the Operator, as in the case of surveillance for public safety.\n\nThe emerging global consensus, from a recent analysis of global ethics statements  [17] , is that AI systems should empower people, maximizing well-being and minimizing harm, while treating people fairly with transparency, and respecting people's rights to privacy, autonomy and freedom. Although it is obvious that the ethical responsibilities of ensuring this for affectively-aware AI lie with the Developer and Operator, the exact division of labor is less clear-cut. This is undesirable, as it would lead to either party absolving themselves of responsibility, and finger-pointing when an incident happens. Our analysis helps clarify the responsibilities of each party to minimize absolution of responsibility, and will help Regulators to determine appropriately scoped and targeted regulation. In addition, this stakeholder-focused analysis complements earlier academic work that analyzed applications  [12] ,  [13]  and the fit between emotion theory and AI models  [16] .\n\nOur framework rests on two broad ethical \"Pillars\", to convey the idea that both are necessary to support ethical application of affectively-aware AI. The first, Provable Beneficence, concerns proving that the AI will benefit the Emoters, which rests on a necessary pre-requisite that the AI is effective at the function it is supposed to serve, and the primary responsibility of upholding this pillar should lie with the Developer. The second, Responsible Stewardship, concerns the actual deployment of the AI, which also includes storing and using the data responsibly; the primary responsibility for upholding this pillar lies with the Operator.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "A. Provable Beneficence",
      "text": "The first ethical principle in our framework is beneficence: the benefit to the Emoter must outweigh the costs to the Emoter, and any such costs must be minimized. When dealing with AI systems, we can go one step further and demand provable beneficence; that is, steps must be taken to guarantee, to the best of the Developer's ability, that the AI is beneficial and does no harm. Any application of AI should require an analysis of the potential benefits, which depends on specific use-cases (and, in fact, depends also on the Operator-we return to this later). However, a necessary pre-requisite for beneficence is that the AI's predictions must be credible; it must agree with reality and must do what it says it does-without which the AI cannot be said to benefit (and not harm) people even if done with the best of intentions. Thus, provable beneficence entails the following sub-principles: (i) scientific validity, (ii) bias minimization, (iii) generalizability, and (iv) AI transparency and accountability. The responsibility of upholding these subprinciples rests with the Developer.\n\n1) Scientific Validity: In order for an AI to provably benefit the Emoter, its models of emotion must be scientifically valid. Validity refers to the degree to which the AI's measurements or inferences reflects the underlying emotional phenomena it purports to measure. While this may seem obvious, the standards by which validity is assessed differ, even amongst various academic fields. That is why academics hold as the highest gold-standard scientific peer-review done by experts with relevant scientific expertise and who can make proper, contextualized evaluations. However, developers do not all reside in academia, and some may not rely on peer-review as a validation strategy, due to concerns about intellectual property and commercial competition. Society must, however, insist on some independent process of determining scientific validity as a pre-requisite for provable beneficence. Some examples include setting up an internal peer-review system, subjecting the AI design principles to independent review or audit by an external board or auditor, accreditation, or testing using randomized controlled trials or on out-of-sample data.\n\nExpression or Emotion? Scientific validity includes being sensitive to the vast intra-personal, inter-personal, and intercultural differences in emotions and emotion expressions  [44] . Additionally, Developers have to acknowledge the importance of recognizing emotions in the context in which they arise, rather than simply classifying stimuli taken out of context. Many commercially available technology today are unimodal systems that recognize facial expressions from isolated faces. But the mapping from expressions to emotions is complex and a many-to-many mapping  [10] ; without additional modalities or contextual information, unimodal systems are limited in the accuracy that they can achieve. Developers need to work towards building more comprehensive multimodal, contextaware models, in order to improve the validity of their models.\n\n2) Bias Minimization: Developers have to ensure that their AI results in fair treatment of people. To do so, the Developer has to take steps to minimize bias, and to ensure that their data is representative of various groups of people. Machine learning models trained on a finite set of data may learn biases inherent in that data, and thus propagate such bias forward  [45] . For example,  [46]  showed that judgments made by two commercially-available emotion recognition software are biased on race: African American sportsmen are consistently rated as displaying more negative emotions than White Caucasian sportsmen, even when controlling for the intensity of their smiles. These biases could then affect AImade decisions about, for example, which job applicant to hire, unfairly penalizing certain groups.\n\nAnother source of bias is human coders. AI research today involves collecting and labelling large datasets, often through scalable methods like crowd-sourcing on platforms like Amazon Mechanical Turk or Prolific. Relying on untrained coders could lead to data quality problems such as: lack of calibration of ratings and scale-usage, non-standardized understanding of instructions or constructs, cultural differences in emotion concepts  [44] , language barriers, or distracted and unmotivated coders. Indeed, many researchers acknowledge these issues, and compensate by collecting more ratings to average out the noise. This may work for certain idiosyncratic human biases, but if there were systematic biases, such as cultural biases against other races or specific emotions, then crowd-sourcing could further entrench these biases in the data.\n\n3) Generalizability: A third issue is whether AI models can accurately generalize to new, out-of-sample data. Developers are incentivized to maximize their model's performance, but must also be willing to accept more variance in their data, in order to more accurately capture the vast heterogeneity of human emotional experience and expression. This is especially true for representative data from minorities or vulnerable populations. This poses a dilemma, as collecting highervariance data will result in a short-term drop in performance metrics like classification accuracy. Developers can justify this decision as ultimately improving their AI in the long-term.\n\nHow many emotions? Existing datasets tend to be limited in their coverage of emotions: most datasets contain a handful of six to eight emotions. Thus, AI models trained on these datasets will be severely handicapped, as they will not know how to recognize other emotions, leading to potential misclassifications. Recent datasets have sought to expand the number of emotion classes (e.g., 32 classes  [47] ), but it is difficult to provide a \"universal\" answer of how many categories is enough. The Developer should examine each application in consultation with the domain-expert Operator.\n\nTransfer Learning: Consider the case where the Operator wants to deploy the AI in a vastly different setting or population than the Developer's training data, and which the Developer does not have access to. For example, the Developer's AI is trained mostly on White Caucasian faces in Europe or the US, but the Operator wants to deploy it in a predominantly Asian context (in Asia). Or the Developer has trained their AI on adult faces, but the Operator wants to use it in a specific context with elderly people. In such cases, although the responsibility of operation lies with the Operator, the Operator has no access to the inner workings of the AI. The \"know-how\" and the ability to test and modify the AI rests with the Developer, but the Developer has no incentive to spend resources to verify their model on a new population. Who then, bears the burden of responsibility for the generalizability to an entirely new population?\n\nWe argue that the Operator bears the (ethical and in the future, legal) responsibility of the actual AI's deployment and the decisions made from them. But because they cannot easily re-train the AI or verify the generalizability of the AI on the target population, they must enlist the Developer's help to ensure generalizability, by providing the Developer with data to re-train and to evaluate the AI. Thus, the Operator must, as part of contract negotiations, demand proof from the Developer that the predictions of the AI are valid in the Operator's target domain. The Developer similarly must work with the Operator to ensure their AI is accurate on this new domain.\n\n4) AI Transparency and Accountability: Unlike other industries like automobiles and aviation, there is no standard regulatory framework for AI. While airplanes and cars have to undergo vigorous safety inspections, there is no similar quality-assurance process for AI that could make impactful decisions. AI Developers should be required to disclose how their technologies were developed, what types of data were they trained on, and what their limitations are. Recent proposals include releasing Model Cards  [48]  to detail model performance characteristics, including the intended use-cases and contexts, as well as Datasheets for Datasets  [49]  to provide details on the data that the models were trained on (e.g., how were the data collected; what are the demographics of the people involved?). These accompanying reports could be provided as supporting evidence to demonstrate the \"efficacy\" of the product, in this case, the AI model. Regulators could verify such claims by requiring regular audits of AI technology.\n\nNo snake oil, please! Regulating AI Advertising: AI Transparency includes being accurate and honest in advertising. The Operator (and Emoter) may not understand the limitations behind affectively-aware AI, and may believe overblown claims by companies about emotion recognition AI  [4] . Advertisements for certain classes of regulated products such as medical and financial products must contain tempered claims and disclaimers about potential risks (to health and to financial investments, respectively). Unfortunately AI advertising is not subjected to oversight, and so Developers can advertise unrealistic capabilities that are likely not backed up by evidence. Part of the solution may involve regulation, and one approach could be to study advertising regulation models like in medicine, and mandate that AI advertising similarly include a discussion of limitations, risks, and known weaknesses of the models. Specifically for affectively-aware AI, Regulators should mandate that advertising include a discussion of the demographics of the Emoters in the data that the models were trained on (i.e., information in model cards  [48]  and datasheets  [49] ), as well as a discussion of context (e.g., what were Emoters in the dataset doing? What situations were they experiencing?). Another possible solution is self-regulation, where Developers temper their own advertising to potential customers. To justify the short-term cost of more realistic (and less appealing) advertising, Developers should consider that any mismatch between Operator expectations and reality would result in lower consumer confidence in the long-term.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "B. Responsible Stewardship",
      "text": "Next we turn to the pillar of responsible stewardship. The Operator will be using the AI to collect sensitive, personal data about individual Emoters, and will be making decisions based on the results of analysis on such data. The Operator thus becomes the steward of that data, and has an ethical responsibility to the Emoters to ensure proper use and care of their data. This pillar entails the following four sub-principles: (i) adhering to a pre-specified purpose, (ii) studying whether the intended effects differ from actual outcomes, (iii) being judicious about privacy, consent, and data ownership, and (iv) maintaining quality assurance.\n\n1) Pre-specified purpose: We start with the least familiar idea, which may have the most impact: that of adherence to a pre-specified purpose  [50] . Affectively-aware applications have to be defined with a pre-specified purpose, and subject to Operators' internal oversight. This will prevent \"mission creep\", whereby the same data will gradually be used for different purposes that they may not actually be valid for  5  .\n\nAs an example, a bank may start a project to collect emotional information to \"to better understand our customers\", which is an underspecified objective. They may initially use emotion expressed by customers during bank visits to improve customer service. But with initial success and without proper oversight over possible uses of the data, they may one day try to use that data to predict credit-worthiness, which may not be a (scientifically) valid use-case. Furthermore, it would be ethically questionable if customers were initially informed of and gave consent to the purpose of improving customer service, but the data was later used to serve other purposes.\n\nIn order to properly safeguard Emoters, Operators have to focus on the specific application of such AI, and the specific benefits accrued. This has to be spelled out clearly in their strategy. Internal oversight should ensure that data collected about Emoters are minimal and relevant to the specified purpose (for example, does zip code data need to be tied to emotional expressions to improve customer satisfaction?).\n\n2) Distinguish Intended Effects and Actual Outcomes: Also related to the principle of beneficence, Operators have the responsibility to ensure that the actual outcomes of AI deployment match the intended effects. This entails protocols to continually measure outcomes of interest to ensure that they match the intended effects, and that there are no unintended negative side-effects. This may seem obvious, but it is also tempting from a Operator's point of view to just \"trust\" that the AI is working, as there could be a substantial cost involved in monitoring these outcomes (e.g., surveying customers). This is particularly important if there are potentially vulnerable populations that could be at risk for disparate impact, even if done with the best of intentions. For example, if a school decides to implement \"engagement detection\" AI tools to improve the quality of education offered, individual teachers may decide to penalize students if they were not paying \"sufficient\" attention, perhaps by singling them out in front of the class or giving lower participation grades. Would this unfairly penalize students with attention deficit problems, or who may be going through other difficult personal/family issues? This could be an unintentional side-effect that has a negative impact on students. Thus, Operators have to be aware of how the AI is actually being used on-the-ground and monitor the actual outcomes of their decisions.\n\n3) Privacy, Consent, and Data Ownership: The third set of considerations relates to the interrelated issues of privacy, consent, and data ownership. Given that some emotional information are constantly being \"broadcasted\" (much like one's facial identity)  [15] , AI Operators need to establish a reasonable standard of privacy for the collection and use of Emoters' facial expressions and other emotional information, while maintaining Emoters' autonomy over their participation in such interactions and data generated from such interactions.\n\nA Culture of Data Consent: Emoters should have a reasonable expectation of privacy, and should consent to any data collection. In a public space, where it may not be feasible to get individual consent, there should be signs prominently displayed that inform Emoters of the deployment of emotion recognition AI technology. This is true even if an Emoter may be reasonably aware that their emotions may be \"read\", such as when they are interacting with an embodied AI like a service robot with visible cameras and the ability to display its own expressions. The need for highlighting data collection is more pressing when Emoters are reasonably not expecting to have their emotions be \"read\", which could happen with disembodied AI, like an AI taking in information from a collection of security cameras. In a private setting (in a car cabin, at home, using one's personal device), presumably the Emoter is actively using and interacting with the AI, but the Emoters may not be aware of their sharing emotional information, depending on their expectations of the interaction. In these cases, the Operator should seek explicit consent to collect and use Emoters' emotional expressions.\n\nThe exact use of such data should be described clearly to Emoters, and any changes or updates to the software should be reflected explicitly to Emoters. Emoters sould also have the right to opt-out of any data collection, and to request any previously-collected data to be destroyed. Operators should also specify if any data processing is done \"on the edge\" (that is, on the device itself, such that the data does not leave the device), or if the data is sent to some external cloud or server.\n\n4) Quality Assurance: The fourth sub-principle of the Responsible Stewardship pillar is ensuring quality. In a parallel to Developer's efforts to maintain quality, in the context of validity and AI transparency, Operators also need to ensure proper operation of the AI. This entails ensuring the personnel directly interfacing with the AI have undergone adequate training to use the AI, to correctly interpret the output of the AI, and to troubleshoot any possible errors.\n\nThis extends to safeguarding sensitive Emoter data. Operators should implement proper data control procedures, such as strict data access policies, and implement (cyber)security measures to minimize data leaks.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Iii. Discussion",
      "text": "These principles offer a start in thinking through some of the ethical issues at stake when developing and deploying affective-aware AI. We propose that Developers and Operators should, using this framework, recognize the ethical responsibilities placed upon them due to their respective roles as the AI creator or AI user, and accordingly enact strategy and policy.\n\nThere are, of course, difficult questions when one gets into the details. For example, consider the AI candidate assessment tool discussed in the introduction  [3] . Here, the Operator's utility is not aligned with the Emoters', as the Emoter may feel that their emotional information could be used \"against\" them by the Operator and AI. In such cases, how should the risks to the Emoter be weighed against the benefit to the Operator? Or consider the case for emotion recognition for public safety surveillance, where the benefit is to \"Society\" as a whole  [53] . Here, the Operator and the Regulator are the same entity; in the former role they may seek more data and less restrictions on their use, while in the latter role they have to weigh the risks to Emoter privacy. Such a balance has to be resolved via a society-wide discussion of the trade-offs that citizens are willing to tolerate in the name of public safety; The answer will differ for each society, and will evolve over time.",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "A. Recommendations",
      "text": "For Developers, we recommend developing a practice of getting third-party scientific review for developed technology. Peer review by scientific journals and conferences are ideal, but minimally we recommend an external, rotating board of scientific experts that could include lawyers and ethicists who can review the technology as well as use-cases and advertising. Companies can also put into place policies for formal ethical impact assessments (e.g.,  [54] ).\n\nWe also recommend appointing quality-assurance engineers whose job it is to critically test the technology by playing devil's advocate: actively challenging the design of the AI, looking for bias against certain populations, or testing generalizability on different datasets and domains  6  . Designating such an appointment-and designing their incentives and reporting structures appropriately-will, in the long-term, result in more robust and ethical AI.\n\nFor junior developers who work directly with the models and data, we recommend adopting recently-proposed best practices in AI, such as producing detailed Model Cards  [48]  for their AI models that discuss their model performance specifications, and Datasheets  [49]  that describe the characteristics of the datasets that developers might collect to train their models. Developers could also conduct internal audits, especially on specific demographic groups  [55] . These activities could help junior developers to clearly and accurately convey the AI capabilities to senior executives (and consequently, to external parties like Operators, Emoters, and Regulators).\n\nFor Operators, we recommend being involved in discussions of the validity of the AI. During negotiations, challenge the Developer to show proof of validity on the desired usecase, and generalizability on data in the target domain. Operators should also designate (regular) internal oversight for the purpose of data use, and how data is collected and stored.\n\nWe recommend appointing \"consumer advocates\" within the organization whose job it is to take the perspective of the Emoter, and challenge project managers on the necessity and use of such data: \"Did the Emoters consent to this new use?\"; \"How would you [the manager] feel if you were the Emoter?\" These conversations may be difficult to have (and such positions have to be carefully designed so as not to simply stymie activity or add more red tape), but in the long-term they benefit both the Emoter and the Operator.\n\nFor Regulators, we recommend appointing experts, whether in-house or from academia, that can be consulted on such AI technology. Other domains (e.g., medicine, finance, energy) are very well-regulated, but AI technology today does not face such similar regulation. Because AI development is so fast-paced, there may also be confusion about current AI capabilities. Thus, regulation needs to be as fast-moving, and quickly adapt to current AI trends, which may suggest adopting a more agile and responsive model of regulation.\n\nRegulators could also set up an audit program that helps to verify the accuracy of affectively-aware AI. For example, the US National Institutes of Standards and Technology has a long-running Face Recognition Vendor Test (FRVT) program which evaluates vendor-submitted models for facial recognition accuracy under a wide array of conditions such as across demographic groups  [56] . This could serve as a possible model for similarly auditing emotion recognition technology.\n\nRegulators should also consider efforts on the advertising of AI, especially about accurate representation of AI capabilities and limitations. And finally, we recommend that special attention be paid to applications where the Emoter is not in a position of being able to opt-out (e.g., AI-assisted hiring, employee and student monitoring, public safety surveillance).",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Iv. Conclusion And A Call To Action",
      "text": "In summary, although there have been many recent conference panels and discussions on the ethics of affectivelyaware AI, there has not been much progress by affective computing researchers towards providing a formal, guiding framework. In this paper, we propose an ethical framework on which researchers, engineers, industry and regulators, can refer to when evaluating AI applications and deployment. Our novel multi-stakeholder analysis separates the burden of responsibilities of AI Developers from the Operators that deploy such AI, and begins to clarify issues for further action by the relevant entities.\n\nAI Ethics is a habit that the stakeholders, from AI Developers to Operators, from junior engineers to C-suite executives, have to inculcate into their everyday decision-making. We hope that the issues raised will start conversations in individual organizations, and the recommendations will provide concrete, actionable items to work on. We will not achieve ethical (affectively-aware) AI overnight, but it is a shared responsibility that we have to collectively strive for.",
      "page_start": 7,
      "page_end": 7
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Illustration of the four stakeholders involved in an interaction with an",
      "page": 3
    },
    {
      "caption": "Figure 2: The Pillars of Provable Beneﬁcence (upheld by the Developer)",
      "page": 4
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "dco@comp.nus.edu.sg"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "Abstract—The recent rapid advancements\nin artiﬁcial\nintelli-"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "gence\nresearch and deployment have\nsparked more discussion"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": ""
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "about\nthe potential\nramiﬁcations\nof\nsocially-\nand emotionally-"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": ""
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "intelligent AI. The question is not\nif research can produce such"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": ""
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "affectively-aware AI, but when it will. What will\nit mean for"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "society when machines—and the corporations and governments"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "they\nserve—can\n“read”\npeople’s minds\nand\nemotions? What"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "should developers and operators of such AI do, and what should"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": ""
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "they not do? The goal of\nthis article is to pre-empt some of\nthe"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": ""
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "potential\nimplications of\nthese developments, and propose a set"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": ""
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "of guidelines for evaluating the (moral and) ethical consequences"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "of affectively-aware AI,\nin order to guide researchers,\nindustry"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "professionals, and policy-makers. We propose a multi-stakeholder"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "analysis\nframework\nthat\nseparates\nthe\nethical\nresponsibilities"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": ""
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "of AI Developers\nvis-`a-vis\nthe\nentities\nthat deploy\nsuch AI—"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": ""
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "which we\nterm Operators. Our\nanalysis produces\ntwo pillars"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": ""
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "that\nclarify\nthe\nresponsibilities\nof\neach of\nthese\nstakeholders:"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "Provable Beneﬁcence, which rests on proving the effectiveness of"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "the AI, and Responsible Stewardship, which governs responsible"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "collection,\nuse,\nand\nstorage\nof\ndata\nand\nthe\ndecisions made"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": ""
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "from such data. We end with recommendations for researchers,"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": ""
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "developers, operators, as well as regulators and law-makers."
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": ""
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "Index Terms—Ethics; Affective Computing; Facial Emotion"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "Recognition; Deep Learning"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": ""
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "I.\nINTRODUCTION"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": ""
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "At\nthe February 2020 meeting of\nthe Association for\nthe"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": ""
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "Advancement of Artiﬁcial\nIntelligence\n(AAAI),\nthe premier"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": ""
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "society for AI\nresearch,\ntwo invited plenary speakers men-"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": ""
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "tioned Affective Computing\nin\ntheir\ntalks,\nfor\ncompletely"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": ""
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "opposite reasons. The ﬁrst speaker cited Affective Computing"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": ""
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "as an example of a world-destroying AI application, as it could"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": ""
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "empower authoritarian regimes\nto monitor\nthe inner\nlives of"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": ""
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "their citizens. Thirty-six hours\nlater, a second speaker hailed"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": ""
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "it\nas\na\ncrucial\ncomponent\nto building provably safe AI\nand"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": ""
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "preventing\nan AI-led\napocalypse1. Neither\nstudies\naffective"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": ""
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "computing; both are respected AI researchers whose opinions"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": ""
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "about affective computing could not be further apart."
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": ""
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "Any technology can be applied productively, or in question-"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": ""
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "able ways.\nIn the case of affective computing, conversations"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": ""
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "This\nresearch is\nsupported in part by the National Research Foundation,"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "Singapore under\nits AI Singapore Program (AISG Award No: AISG2-RP-"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": ""
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "2020-016), and a Singapore Ministry of Education Academic Research Fund"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "Tier 1 grant\nto DCO."
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "1Henry Kautz\ncited the\nthreat of AI\nthat\ncan infer moods, beliefs,\nand"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "intentions from data, which could be used by state actors to target and suppress"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": ""
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "dissidents. Stuart Russell proposed that inferring emotions is critical to solving"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": ""
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "the value-alignment problem (aligning AI utility functions with human utility"
        },
        {
          "Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore": "functions), which in turn is necessary for provably-safe AI."
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "refer to AI that can recognize emotional expressions in people",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "AI\nethical\nissues,\nand which\nhas\na\nchapter\ndedicated\nto"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "(from facial expressions, body language, language, physiology,",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "Affective Computing [19]. This chapter outlines\nrecommen-"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "and\nso\nforth),\nand\nperhaps\ncan\nreason\nabout\nemotions\nin",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "dations\nfor\nspeciﬁc\napplication\nareas:\n(i)\naffective\nsystems"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "context or with cultural awareness. Although the terms “Affec-",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "that are deployed across cultures;\n(ii) affective systems with"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "tive AI” or “Emotional AI” are commonly used by affective",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "which users may develop relationships;\n(iii) affective systems"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "computing researchers and companies, we speciﬁcally choose",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "which manipulate, “nudge” or deceive people;\n(iv) affective"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "not\nto use them to sidestep any philosophical discussion of AI",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "systems which may impact human autonomy when deployed"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "that possesses emotions\n[29]. We also do not discuss ethical",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "in organizations or in societies; and (v) affective systems which"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "issues with AI expressing emotions (e.g., deception [14]). The",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "display synthetic emotions."
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "consequences we discuss\nrest only on the presumed ability",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "In order\nto complement EAD’s\napproach of\nfocusing on"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "of AI to recognize emotions—Indeed, emotion-recognizing AI",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "issues\nspeciﬁc\nto\nindividual\napplications,\nthe\npresent\npaper"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "make up the vast majority of commercial offerings that already",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "ﬁrst\noutlines\na more\ngeneral, multi-stakeholder\nframework,"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "exist\ntoday, and that are generating public concern.",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "elaborating on the responsibilities of both the AI developers"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "We ﬁrst begin by brieﬂy summarizing the capabilities and",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "and the\nentities\nthat deploy such AI.\nIndeed, our proposed"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "limitations of\nthe technology today, as overblown claims by",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "pillars encapsulates all\nthe principles elaborated on in EAD2,"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "companies have led to a general misunderstanding about\nthe",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "and add several\ninsights and concrete recommendations from"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "limits of\nthe technology [4]. Next, we outline our proposed",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "reasoning\nthrough\nthe\ntwo main\nstakeholders.\nIn\ndoing so,"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "ethical\nframework, which analyzes\nthe different\nstakeholders",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "we hope\nthat\nthis document will\nserve\nas\nan elaboration of"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "relevant\nto affectively-aware AI.\nIn particular, we distinguish",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "widely-accepted ethical principles,\nthat\nis also actionable by"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "the ethical responsibilities held by the AI Developer with the",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "researchers,\nindustry professionals and policy-makers."
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "entities\nthat deploy such AI\n(which we term Operators),\nin",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": ""
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "C.\nSummarizing recent advancements in affectively-aware AI"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "order to clarify the division of responsibilities, and avoid either",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": ""
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "Trying to characterize the state of a rapidly-moving ﬁeld,"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "party\nabsolving\nresponsibility. We\ndescribe\nthe\ntwo\nbroad",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": ""
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "and so brieﬂy,\nis a Sisyphean task. However, we feel\nthat\nit\nis"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "ethical pillars in our framework, and the implications that\nthey",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": ""
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "important, especially for\nreaders outside affective computing,"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "have on development and deployment of such AI.",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": ""
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "to\nknow what\nare\nthe\ncapabilities\nand\nthe\nlimitations\nof"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "B. Why the need for Ethical Guidelines",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": ""
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "this technology today. There are many scientiﬁc/psychological"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "Ethical guidelines are necessary to help guide what profes-",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "theories\nof\nemotion\n[30],\nsuch\nas\nbasic\nemotion\ntheories"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "sionals should do with the technology they create,\nin addition",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "[31], appraisal\ntheories [32], and constructivist\ntheories [33]."
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "to what\nthey should not do. Although ethical guidelines by",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "Although a\nfull discussion of\nthese\ntheories\nis beyond our"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "themselves\ncarry\nno\n“hard”\npower—unlike\nlaws\nand\nregu-",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "scope, we invite the interested reader\nto see Stark and Hoey"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "lations passed by government\nauthorities—they do serve\nan",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "[16], who discuss how different\ntheoretical conceptualizations"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "important\nrole\nin\nclarifying\nsocial\nand\nprofessional\nnorms.",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "of emotion should shape the ethical design of AI systems."
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "Articulating a\nclear\nand unambiguous\nethical\ncode provides",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "The vast majority of affectively-aware AI is implicitly built"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "clariﬁcation for activities the ﬁeld deems acceptable and those",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "upon a basic\nemotion theory, which assumes\nthat\nemotions"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "it does not, and will help to guide both junior and seasoned",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "exist as distinct natural categories and can be recognized solely"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "researchers. Second, ethical guidelines could inspire individual",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "from behaviour. Such AI are usually trained using supervised"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "entities\n(academic\ndepartments,\njournals,\nconferences,\ngrant",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "learning [34] to perform single-example classiﬁcation of stim-"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "funding agencies)\nto implement policies that encourage com-",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "uli\nfrom single modalities,\ntaken out-of-context\n(e.g.,\na\nstill"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "pliance (e.g., a focus on teaching ethics in training curricula,",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "photo),\ninto one of several pre-deﬁned categories. By contrast,"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "or requiring ethical analysis to supplement paper submissions).",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "real-life\nemotion\ndetection\ndone\nby\nhumans\nis multimodal,"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "Finally, putting forward a researcher-written framework may",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "evolves over time, and has to be done in context [35]. Although"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "help regulators align efforts to craft complementary laws.",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "there have been more academic research in recent years on"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "Many professions and professional organizations have their",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "complex multimodal emotion recognition systems [36],\n[37],"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "own ethical codes by which they expect practicing members",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "commercially-available software are still only unimodal, with"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "to\nadhere\nto.\nPerhaps\nthe\noldest\nand most\nfamous\nis\nthe",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "the most mature being recognition of (still) facial expressions,"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "Hippocratic Oath, and modern versions of\nthis oath exist\nin",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "such as Affectiva’s AffDex, Microsoft’s Azure API, and Ama-"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "many medical schools today. The Association for Computing",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "zon’s Rekognition. Furthermore, because of the cost associated"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "Machinery (ACM) and the Institute of Electrical and Electron-",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "with collecting datasets with a larger variety of emotions, most"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "ics Engineers (IEEE),\nthe two largest engineering professional",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "academic research as well as commerical offerings are trained"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "bodies,\nsimilarly have Codes of Ethics, which focus broadly",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "to only recognize a small number of emotions (e.g., 6), which"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "on principles such as honesty, fairness, and respect for privacy.",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "is hardly representative of\nreal-life."
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "More\nspeciﬁc\nto Affective Computing,\nthe\nIEEE Global",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": ""
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "2Our ﬁrst pillar includes EAD’s General Principles of Human Rights, Well-"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "Initiative on Ethics of Autonomous and Intelligent Systems—a",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": ""
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "Being, Effectiveness, Transparency,\nand Accountability; while\nour\nsecond"
        },
        {
          "in detail. We use the term Affectively-Aware AI to speciﬁcally": "committee of respected IEEE engineers—published “Ethically",
          "Aligned Design”\n(EAD),\na\ndocument\nfocusing\nbroadly\non": "includes the remainder: Data Agency, Awareness of Misuse, and Competence."
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "rent\ntechnology excels at detecting facial movements, but\nthe"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "mapping from facial movements to the underlying emotions is"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "not one-to-one but many-to-many3. Because emotions, which"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "are themselves directly unobservable, produce many types of"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "observable behavior,\nintegrating multimodal behavior can help"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "to triangulate what someone is feeling [38], [39]. But\nin many"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "cases, even that\nis not enough to achieve true emotion under-"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "standing. One needs\nto understand the context\n[40]—is\nthis"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "person watching sports or attending a performance review?—"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "incorporate\nexternal world and cultural knowledge,\nas well"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": ""
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "as infer people’s mental states,\ntheir goals, expectations, and"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": ""
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "even past histories,\nin order to take their perspective and truly"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": ""
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "reason\nabout\nhow they\nfeel\n[41],\n[42]. Current AI\ndo\nnot"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": ""
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "fundamentally\ntake\nthese\ninto account,\nand so may even be"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": ""
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "limited\nin\nthis\nendeavour\nof\nreading\ninternal\nstates\nsolely"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": ""
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "from external behavior; we may require substantive changes"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "to AI\nresearch paradigms\n[43]\nin order\nto achieve AI with"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "a human-centric\nemotion understanding.\nIf\nthe\nentities who"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "develop or deploy such systems\nassume\nthat\nthe\nreadout of"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "such AI systems are veridical “emotions” (rather than noisy in-"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "ferences), without adequately considering context-speciﬁcity,"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "social/cultural\ninﬂuences, or\neven inter-\nand intra-individual"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "variation,\nthey\ncould\nend\nup\nreading\ntoo much\ninto\nfacial"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "movements4, and make impactful decisions based on sorely"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "incomplete information."
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "While there is no doubt\nthat our\ntechnology will continue"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "to rapidly improve, we feel\nthat at\nthe present moment, affect"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "recognition technology does not yet deliver what many people"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "believe it\nto. Consumers of such technology need to treat such"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "AI as a(n incomplete) statistical model, and not a magic crystal"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "ball\nthat perfectly discerns people’s hidden emotional\nlives."
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": ""
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "II. AN ETHICAL FRAMEWORK"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": ""
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "In this section, we outline our proposed ethical framework."
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "To the best of our knowledge,\nthis is the ﬁrst\nframework that"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "distinguishes the ethical\nresponsibilities of\nthose that develop"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "the AI\nfrom those that deploy or operate the AI."
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "First, we\nidentify the\nfour\nstakeholders\nin an interaction"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": ""
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "involving\nan\naffectively-aware AI. There\nis\n(at\nleast)\none"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": ""
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "individual whose emotions are being read by the AI; we shall"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": ""
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "call\nthem Emoters. The AI itself could be embodied, as in a"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": ""
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "social\nrobot, or disembodied, as in the AI powering a system"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": ""
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "of\nsurveillance\ncameras. There\nare\nthe Operators, who are"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": ""
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "the entities\nthat deploy the AI, and to whom the AI\nreports"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": ""
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "the\noutput\nof\nany\nemotion\nanalysis\nto. The Operator\nthen"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": ""
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "makes decisions based on the AI’s\nanalysis, or\nthey could"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": ""
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "delegate any subsequent decision-making to other AI systems."
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": ""
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "Ultimately, because\nthey are\nthe\nexperts\nin the domain the"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": ""
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "AI will be deployed in,\nthey hold ethical responsibility for the"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": ""
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": ""
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "3This is likely the case for any single modality, not\njust facial expressions,"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "which are the most well-studied."
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "4We note\nalso that\nthere\nare other\nchallenges\nto the validity of\nsimply"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "“reading emotions from expressions”, namely that people can deliberately alter"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": ""
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "their facial expressions away from their true emotional states for a variety of"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": ""
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "reasons such as: adhering to social and cultural display norms, as part of their"
        },
        {
          "In a recent comprehensive analysis,\n[10] argued that cur-": "job (emotional\nlabor), as a strategy in negotiations."
        }
      ],
      "page": 3
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "Developer. The second, Responsible Stewardship, concerns"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "the actual deployment of\nthe AI, which also includes storing"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "and using the data responsibly;\nthe primary responsibility for"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "upholding this pillar\nlies with the Operator."
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "A. Provable Beneﬁcence"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "The ﬁrst ethical principle in our\nframework is beneﬁcence:"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "the\nbeneﬁt\nto\nthe Emoter must\noutweigh\nthe\ncosts\nto\nthe"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "Emoter, and any such costs must be minimized. When dealing"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "with AI systems, we can go one step further and demand prov-"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "able beneﬁcence;\nthat\nis, steps must be taken to guarantee,\nto"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "the best of the Developer’s ability, that the AI is beneﬁcial and"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "does no harm. Any application of AI should require an analysis"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "of\nthe potential beneﬁts, which depends on speciﬁc use-cases"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "(and,\nin fact, depends also on the Operator—we return to this"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "later). However, a necessary pre-requisite for beneﬁcence is"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "that\nthe AI’s predictions must be credible;\nit must agree with"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "reality and must do what it says it does—without which the AI"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": ""
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "cannot be said to beneﬁt\n(and not harm) people even if done"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": ""
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "with the best of intentions. Thus, provable beneﬁcence entails"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": ""
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "the\nfollowing\nsub-principles:\n(i)\nscientiﬁc\nvalidity,\n(ii)\nbias"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "minimization,\n(iii) generalizability,\nand (iv) AI\ntransparency"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "and accountability. The responsibility of upholding these sub-"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": ""
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "principles rests with the Developer."
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": ""
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "1)\nScientiﬁc Validity:\nIn order for an AI to provably beneﬁt"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": ""
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "the Emoter,\nits models of emotion must be scientiﬁcally valid."
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": ""
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "Validity refers to the degree to which the AI’s measurements"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": ""
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "or\ninferences\nreﬂects\nthe\nunderlying\nemotional\nphenomena"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": ""
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "it\npurports\nto measure. While\nthis may\nseem obvious,\nthe"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": ""
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "standards by which validity is assessed differ, even amongst"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": ""
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "various academic ﬁelds. That\nis why academics hold as\nthe"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": ""
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "highest gold-standard scientiﬁc peer-review done by experts"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": ""
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "with relevant\nscientiﬁc expertise and who can make proper,"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": ""
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "contextualized\nevaluations. However,\ndevelopers\ndo\nnot\nall"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": ""
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "reside in academia, and some may not rely on peer-review as a"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": ""
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "validation strategy, due to concerns about\nintellectual property"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": ""
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "and commercial competition. Society must, however,\ninsist on"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": ""
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "some\nindependent process of determining scientiﬁc validity"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": ""
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "as\na pre-requisite\nfor provable beneﬁcence. Some\nexamples"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "include setting up an internal peer-review system,\nsubjecting"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "the AI design principles\nto independent\nreview or\naudit by"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "an external board or\nauditor,\naccreditation, or\ntesting using"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "randomized controlled trials or on out-of-sample data."
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "Expression or Emotion? Scientiﬁc validity includes being"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "sensitive to the vast\nintra-personal,\ninter-personal, and inter-"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "cultural differences in emotions and emotion expressions [44]."
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "Additionally, Developers have to acknowledge the importance"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "of\nrecognizing emotions\nin the context\nin which they arise,"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "rather\nthan simply classifying stimuli\ntaken out of\ncontext."
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "Many commercially available technology today are unimodal"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "systems that\nrecognize facial expressions from isolated faces."
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "But the mapping from expressions to emotions is complex and"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "a many-to-many mapping [10]; without additional modalities"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "or\ncontextual\ninformation, unimodal\nsystems\nare\nlimited in"
        },
        {
          "responsibility\nof\nupholding\nthis\npillar\nshould\nlie with\nthe": "the accuracy that\nthey can achieve. Developers need to work"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "are incentivized to maximize their model’s performance, but": "must\nalso be willing to accept more variance\nin their data,",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "details on the data that\nthe models were trained on (e.g., how"
        },
        {
          "are incentivized to maximize their model’s performance, but": "in order\nto more accurately capture the vast heterogeneity of",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "were\nthe data\ncollected; what\nare\nthe demographics of\nthe"
        },
        {
          "are incentivized to maximize their model’s performance, but": "human emotional experience and expression. This is especially",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "people involved?). These accompanying reports could be pro-"
        },
        {
          "are incentivized to maximize their model’s performance, but": "true\nfor\nrepresentative\ndata\nfrom minorities\nor\nvulnerable",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "vided as supporting evidence to demonstrate the “efﬁcacy” of"
        },
        {
          "are incentivized to maximize their model’s performance, but": "populations.\nThis\nposes\na\ndilemma,\nas\ncollecting\nhigher-",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "the product, in this case, the AI model. Regulators could verify"
        },
        {
          "are incentivized to maximize their model’s performance, but": "variance data will\nresult\nin a short-term drop in performance",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "such claims by requiring regular audits of AI\ntechnology."
        },
        {
          "are incentivized to maximize their model’s performance, but": "metrics like classiﬁcation accuracy. Developers can justify this",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "AI\nNo snake oil, please! Regulating AI Advertising:"
        },
        {
          "are incentivized to maximize their model’s performance, but": "decision as ultimately improving their AI\nin the long-term.",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "Transparency\nincludes\nbeing\naccurate\nand\nhonest\nin"
        },
        {
          "are incentivized to maximize their model’s performance, but": "How many emotions? Existing datasets tend to be limited",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "advertising. The Operator\n(and Emoter) may not understand"
        },
        {
          "are incentivized to maximize their model’s performance, but": "in their coverage of emotions: most datasets contain a handful",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "the limitations behind affectively-aware AI, and may believe"
        },
        {
          "are incentivized to maximize their model’s performance, but": "of\nsix to eight\nemotions. Thus, AI models\ntrained on these",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "overblown claims by companies about emotion recognition AI"
        },
        {
          "are incentivized to maximize their model’s performance, but": "datasets will be severely handicapped, as they will not know",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "[4]. Advertisements\nfor certain classes of\nregulated products"
        },
        {
          "are incentivized to maximize their model’s performance, but": "how to recognize other emotions,\nleading to potential misclas-",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "such as medical and ﬁnancial products must contain tempered"
        },
        {
          "are incentivized to maximize their model’s performance, but": "siﬁcations. Recent datasets have sought\nto expand the number",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "claims\nand disclaimers\nabout potential\nrisks\n(to health and"
        },
        {
          "are incentivized to maximize their model’s performance, but": "of\nemotion classes\n(e.g., 32 classes\n[47]), but\nit\nis difﬁcult",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "to\nﬁnancial\ninvestments,\nrespectively).\nUnfortunately\nAI"
        },
        {
          "are incentivized to maximize their model’s performance, but": "to provide\na\n“universal”\nanswer of how many categories\nis",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "advertising is not\nsubjected to oversight, and so Developers"
        },
        {
          "are incentivized to maximize their model’s performance, but": "enough. The Developer\nshould examine\neach application in",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "can\nadvertise\nunrealistic\ncapabilities\nthat\nare\nlikely\nnot"
        },
        {
          "are incentivized to maximize their model’s performance, but": "consultation with the domain-expert Operator.",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "backed\nup\nby\nevidence.\nPart\nof\nthe\nsolution may\ninvolve"
        },
        {
          "are incentivized to maximize their model’s performance, but": "the\ncase where\nthe Oper-\nTransfer Learning: Consider",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "regulation,\nand one\napproach could be\nto study advertising"
        },
        {
          "are incentivized to maximize their model’s performance, but": "vastly\ndifferent\nsetting\nator wants\nto\ndeploy\nthe AI\nin\na",
          "and contexts, as well as Datasheets for Datasets [49] to provide": ""
        },
        {
          "are incentivized to maximize their model’s performance, but": "",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "regulation models\nlike\nin medicine,\nand mandate\nthat AI"
        },
        {
          "are incentivized to maximize their model’s performance, but": "or population than the Developer’s\ntraining data, and which",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "advertising\nsimilarly\ninclude\na\ndiscussion\nof\nlimitations,"
        },
        {
          "are incentivized to maximize their model’s performance, but": "the Developer\ndoes\nnot\nhave\naccess\nto.\nFor\nexample,\nthe",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "risks,\nand\nknown weaknesses\nof\nthe models.\nSpeciﬁcally"
        },
        {
          "are incentivized to maximize their model’s performance, but": "Developer’s AI\nis\ntrained mostly on White Caucasian faces",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "for\naffectively-aware AI, Regulators\nshould mandate\nthat"
        },
        {
          "are incentivized to maximize their model’s performance, but": "in Europe or\nthe US, but\nthe Operator wants\nto deploy it\nin",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "advertising include a discussion of\nthe demographics of\nthe"
        },
        {
          "are incentivized to maximize their model’s performance, but": "a predominantly Asian context\n(in Asia). Or\nthe Developer",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "Emoters\nin\nthe\ndata\nthat\nthe models were\ntrained\non\n(i.e.,"
        },
        {
          "are incentivized to maximize their model’s performance, but": "has\ntrained their AI on adult\nfaces, but\nthe Operator wants",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "information\nin model\ncards\n[48]\nand\ndatasheets\n[49]),\nas"
        },
        {
          "are incentivized to maximize their model’s performance, but": "to use\nit\nin a\nspeciﬁc\ncontext with elderly people.\nIn such",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "well as a discussion of context\n(e.g., what were Emoters\nin"
        },
        {
          "are incentivized to maximize their model’s performance, but": "cases,\nalthough the\nresponsibility of operation lies with the",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "the dataset doing? What situations were they experiencing?)."
        },
        {
          "are incentivized to maximize their model’s performance, but": "Operator,\nthe Operator has no access to the inner workings of",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "Another possible solution is self-regulation, where Developers"
        },
        {
          "are incentivized to maximize their model’s performance, but": "the AI. The “know-how” and the ability to test and modify",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "temper their own advertising to potential customers. To justify"
        },
        {
          "are incentivized to maximize their model’s performance, but": "the AI\nrests with the Developer, but\nthe Developer has no",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "the\nshort-term cost\nof more\nrealistic\n(and\nless\nappealing)"
        },
        {
          "are incentivized to maximize their model’s performance, but": "incentive to spend resources\nto verify their model on a new",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "advertising, Developers\nshould\nconsider\nthat\nany mismatch"
        },
        {
          "are incentivized to maximize their model’s performance, but": "population. Who then, bears\nthe burden of\nresponsibility for",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "between Operator\nexpectations\nand\nreality would\nresult\nin"
        },
        {
          "are incentivized to maximize their model’s performance, but": "the generalizability to an entirely new population?",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "lower consumer conﬁdence in the long-term."
        },
        {
          "are incentivized to maximize their model’s performance, but": "We\nargue\nthat\nthe Operator bears\nthe\n(ethical\nand in the",
          "and contexts, as well as Datasheets for Datasets [49] to provide": ""
        },
        {
          "are incentivized to maximize their model’s performance, but": "future,\nlegal) responsibility of the actual AI’s deployment and",
          "and contexts, as well as Datasheets for Datasets [49] to provide": ""
        },
        {
          "are incentivized to maximize their model’s performance, but": "the decisions made from them. But because they cannot easily",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "B. Responsible Stewardship"
        },
        {
          "are incentivized to maximize their model’s performance, but": "re-train the AI or verify the generalizability of\nthe AI on the",
          "and contexts, as well as Datasheets for Datasets [49] to provide": ""
        },
        {
          "are incentivized to maximize their model’s performance, but": "",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "Next we turn to the pillar of responsible stewardship. The"
        },
        {
          "are incentivized to maximize their model’s performance, but": "target\npopulation,\nthey must\nenlist\nthe Developer’s\nhelp\nto",
          "and contexts, as well as Datasheets for Datasets [49] to provide": ""
        },
        {
          "are incentivized to maximize their model’s performance, but": "",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "Operator will be using the AI\nto collect\nsensitive, personal"
        },
        {
          "are incentivized to maximize their model’s performance, but": "ensure generalizability, by providing the Developer with data",
          "and contexts, as well as Datasheets for Datasets [49] to provide": ""
        },
        {
          "are incentivized to maximize their model’s performance, but": "",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "data about\nindividual Emoters, and will be making decisions"
        },
        {
          "are incentivized to maximize their model’s performance, but": "to re-train and to evaluate the AI. Thus,\nthe Operator must, as",
          "and contexts, as well as Datasheets for Datasets [49] to provide": ""
        },
        {
          "are incentivized to maximize their model’s performance, but": "",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "based on the results of analysis on such data. The Operator"
        },
        {
          "are incentivized to maximize their model’s performance, but": "part of contract negotiations, demand proof from the Developer",
          "and contexts, as well as Datasheets for Datasets [49] to provide": ""
        },
        {
          "are incentivized to maximize their model’s performance, but": "",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "thus\nbecomes\nthe\nsteward\nof\nthat\ndata,\nand\nhas\nan\nethical"
        },
        {
          "are incentivized to maximize their model’s performance, but": "that\nthe predictions of the AI are valid in the Operator’s target",
          "and contexts, as well as Datasheets for Datasets [49] to provide": ""
        },
        {
          "are incentivized to maximize their model’s performance, but": "",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "responsibility to the Emoters to ensure proper use and care of"
        },
        {
          "are incentivized to maximize their model’s performance, but": "domain. The Developer similarly must work with the Operator",
          "and contexts, as well as Datasheets for Datasets [49] to provide": ""
        },
        {
          "are incentivized to maximize their model’s performance, but": "",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "their data. This pillar entails the following four sub-principles:"
        },
        {
          "are incentivized to maximize their model’s performance, but": "to ensure their AI\nis accurate on this new domain.",
          "and contexts, as well as Datasheets for Datasets [49] to provide": ""
        },
        {
          "are incentivized to maximize their model’s performance, but": "",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "(i) adhering to a pre-speciﬁed purpose,\n(ii) studying whether"
        },
        {
          "are incentivized to maximize their model’s performance, but": "4) AI Transparency and Accountability: Unlike other\nin-",
          "and contexts, as well as Datasheets for Datasets [49] to provide": ""
        },
        {
          "are incentivized to maximize their model’s performance, but": "",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "the\nintended effects differ\nfrom actual outcomes,\n(iii) being"
        },
        {
          "are incentivized to maximize their model’s performance, but": "dustries\nlike\nautomobiles\nand aviation,\nthere\nis no standard",
          "and contexts, as well as Datasheets for Datasets [49] to provide": ""
        },
        {
          "are incentivized to maximize their model’s performance, but": "",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "judicious about privacy, consent, and data ownership, and (iv)"
        },
        {
          "are incentivized to maximize their model’s performance, but": "regulatory framework for AI. While airplanes and cars have",
          "and contexts, as well as Datasheets for Datasets [49] to provide": ""
        },
        {
          "are incentivized to maximize their model’s performance, but": "",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "maintaining quality assurance."
        },
        {
          "are incentivized to maximize their model’s performance, but": "to\nundergo\nvigorous\nsafety\ninspections,\nthere\nis\nno\nsimilar",
          "and contexts, as well as Datasheets for Datasets [49] to provide": ""
        },
        {
          "are incentivized to maximize their model’s performance, but": "quality-assurance process\nfor AI\nthat\ncould make\nimpactful",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "1) Pre-speciﬁed purpose: We start with the least\nfamiliar"
        },
        {
          "are incentivized to maximize their model’s performance, but": "decisions. AI Developers should be required to disclose how",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "idea, which may have the most\nimpact:\nthat of adherence to"
        },
        {
          "are incentivized to maximize their model’s performance, but": "their\ntechnologies were developed, what\ntypes of data were",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "a pre-speciﬁed purpose\n[50]. Affectively-aware\napplications"
        },
        {
          "are incentivized to maximize their model’s performance, but": "they trained on,\nand what\ntheir\nlimitations\nare. Recent pro-",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "have to be deﬁned with a pre-speciﬁed purpose, and subject"
        },
        {
          "are incentivized to maximize their model’s performance, but": "posals\ninclude\nreleasing Model Cards\n[48]\nto\ndetail model",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "to Operators’\ninternal oversight. This will prevent\n“mission"
        },
        {
          "are incentivized to maximize their model’s performance, but": "performance characteristics,\nincluding the intended use-cases",
          "and contexts, as well as Datasheets for Datasets [49] to provide": "creep”, whereby\nthe\nsame\ndata will\ngradually\nbe\nused\nfor"
        }
      ],
      "page": 5
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "different purposes that\nthey may not actually be valid for5.": "As\nan\nexample,\na\nbank may\nstart\na\nproject\nto\ncollect",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "sonable expectation of privacy, and should consent\nto any data"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "emotional information to “to better understand our customers”,",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "collection.\nIn a public\nspace, where\nit may not be\nfeasible"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "which is an underspeciﬁed objective. They may initially use",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "to get\nindividual consent,\nthere should be signs prominently"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "emotion expressed by customers during bank visits to improve",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "displayed that\ninform Emoters of\nthe deployment of emotion"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "customer service. But with initial success and without proper",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "recognition AI\ntechnology. This\nis\ntrue\neven\nif\nan Emoter"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "oversight over possible uses of\nthe data,\nthey may one day",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "may be reasonably aware that\ntheir emotions may be “read”,"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "try to use that data to predict credit-worthiness, which may",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "such as when they are interacting with an embodied AI\nlike"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "not be a (scientiﬁcally) valid use-case. Furthermore,\nit would",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "a service robot with visible cameras and the ability to display"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "be ethically questionable if customers were initially informed",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "its own expressions. The need for highlighting data collection"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "of\nand gave\nconsent\nto the purpose of\nimproving customer",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "is more pressing when Emoters are reasonably not expecting"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "service, but\nthe data was later used to serve other purposes.",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "to have their emotions be “read”, which could happen with"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "In order\nto properly safeguard Emoters, Operators have to",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "disembodied AI,\nlike\nan AI\ntaking\nin\ninformation\nfrom a"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "focus on the speciﬁc application of such AI, and the speciﬁc",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "collection of\nsecurity cameras.\nIn a private setting (in a car"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "beneﬁts\naccrued. This has\nto be\nspelled out\nclearly in their",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "cabin, at home, using one’s personal device), presumably the"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "strategy.\nInternal oversight\nshould ensure that data collected",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "Emoter\nis\nactively\nusing\nand\ninteracting with\nthe AI,\nbut"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "about\nEmoters\nare minimal\nand\nrelevant\nto\nthe\nspeciﬁed",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "the Emoters may\nnot\nbe\naware\nof\ntheir\nsharing\nemotional"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "purpose (for example, does zip code data need to be tied to",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "information, depending on their expectations of the interaction."
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "emotional expressions to improve customer satisfaction?).",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "In these cases,\nthe Operator\nshould seek explicit consent\nto"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "collect and use Emoters’ emotional expressions."
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "2) Distinguish\nIntended Effects\nand Actual Outcomes:",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": ""
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "The exact use of\nsuch data should be described clearly to"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "Also related to the principle of beneﬁcence, Operators have",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": ""
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "Emoters, and any changes or updates\nto the software should"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "the\nresponsibility to ensure\nthat\nthe\nactual outcomes of AI",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": ""
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "be\nreﬂected explicitly to Emoters. Emoters\nsould also have"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "deployment match the intended effects. This entails protocols",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": ""
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "the right\nto opt-out of any data collection, and to request any"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "to continually measure outcomes of interest to ensure that they",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": ""
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "previously-collected data\nto be destroyed. Operators\nshould"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "match the intended effects, and that\nthere are no unintended",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": ""
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "also specify if any data processing is done “on the edge” (that"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "negative side-effects. This may seem obvious, but\nit\nis also",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": ""
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "is, on the device itself, such that\nthe data does not\nleave the"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "tempting from a Operator’s point of view to just “trust” that",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": ""
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "device), or if the data is sent\nto some external cloud or server."
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "the AI is working, as there could be a substantial cost involved",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": ""
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "in monitoring these outcomes (e.g., surveying customers).",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "4) Quality Assurance: The fourth sub-principle of\nthe Re-"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "sponsible Stewardship pillar\nis ensuring quality.\nIn a parallel"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "This\nis particularly important\nif\nthere are potentially vul-",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": ""
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "to Developer’s\nefforts\nto maintain quality,\nin the\ncontext of"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "nerable populations that could be at risk for disparate impact,",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": ""
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "validity and AI\ntransparency, Operators\nalso need to ensure"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "even\nif\ndone with\nthe\nbest\nof\nintentions. For\nexample,\nif",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": ""
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "proper operation of the AI. This entails ensuring the personnel"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "a\nschool\ndecides\nto\nimplement\n“engagement\ndetection” AI",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": ""
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "directly\ninterfacing with\nthe AI\nhave\nundergone\nadequate"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "tools\nto improve the quality of education offered,\nindividual",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": ""
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "training to use the AI,\nto correctly interpret\nthe output of\nthe"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "teachers may\ndecide\nto\npenalize\nstudents\nif\nthey were\nnot",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": ""
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "AI, and to troubleshoot any possible errors."
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "paying “sufﬁcient” attention, perhaps by singling them out\nin",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": ""
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "front of\nthe class or giving lower participation grades. Would",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "This extends\nto safeguarding sensitive Emoter data. Oper-"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "this unfairly penalize students with attention deﬁcit problems,",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "ators\nshould implement proper data control procedures,\nsuch"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "or who may be going through other difﬁcult personal/family",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "as\nstrict data access policies, and implement\n(cyber)security"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "issues? This\ncould\nbe\nan\nunintentional\nside-effect\nthat\nhas",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "measures to minimize data leaks."
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "a negative\nimpact on students. Thus, Operators have\nto be",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": ""
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "aware of how the AI is actually being used on-the-ground and",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "III. DISCUSSION"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "monitor\nthe actual outcomes of\ntheir decisions.",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": ""
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "These principles offer a start\nin thinking through some of"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "3) Privacy, Consent, and Data Ownership: The third set",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": ""
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "the\nethical\nissues\nat\nstake when\ndeveloping\nand\ndeploying"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "of considerations relates to the interrelated issues of privacy,",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": ""
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "affective-aware AI. We propose that Developers and Operators"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "consent,\nand\ndata\nownership. Given\nthat\nsome\nemotional",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": ""
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "should, using this framework,\nrecognize the ethical\nresponsi-"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "information\nare\nconstantly\nbeing\n“broadcasted”\n(much\nlike",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": ""
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "bilities placed upon them due to their respective roles as the AI"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "one’s\nfacial\nidentity)\n[15], AI Operators need to establish a",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": ""
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "creator or AI user, and accordingly enact strategy and policy."
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "reasonable standard of privacy for\nthe collection and use of",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": ""
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "There are, of course, difﬁcult questions when one gets into"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "Emoters’\nfacial expressions and other emotional\ninformation,",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": ""
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "the details. For example, consider the AI candidate assessment"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "while maintaining Emoters’ autonomy over their participation",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": ""
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "tool discussed in the\nintroduction [3]. Here,\nthe Operator’s"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "in such interactions and data generated from such interactions.",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": ""
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "utility is not aligned with the Emoters’, as the Emoter may feel"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "that\ntheir emotional\ninformation could be used “against” them"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "5Recent examples criticized as mission creep include deploying counter-",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": ""
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "by the Operator and AI.\nIn such cases, how should the risks"
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "terrorism tools for domestic Covid-19 contact\ntracing [51] or using contact-",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": ""
        },
        {
          "different purposes that\nthey may not actually be valid for5.": "tracing data for criminal\ninvestigations [52].",
          "should have\na\nrea-\nA Culture of Data Consent: Emoters": "to the Emoter be weighed against\nthe beneﬁt\nto the Operator?"
        }
      ],
      "page": 6
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "safety surveillance, where the beneﬁt is to “Society” as a whole",
          "stymie activity or add more red tape), but in the long-term they": "beneﬁt both the Emoter and the Operator."
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "[53]. Here, the Operator and the Regulator are the same entity;",
          "stymie activity or add more red tape), but in the long-term they": "For Regulators, we recommend appointing experts, whether"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "in the former role they may seek more data and less restrictions",
          "stymie activity or add more red tape), but in the long-term they": "in-house or\nfrom academia,\nthat can be consulted on such AI"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "on their use, while in the latter\nrole they have to weigh the",
          "stymie activity or add more red tape), but in the long-term they": "technology. Other domains\n(e.g., medicine, ﬁnance,\nenergy)"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "risks to Emoter privacy. Such a balance has to be resolved via",
          "stymie activity or add more red tape), but in the long-term they": "are\nvery well-regulated,\nbut AI\ntechnology\ntoday\ndoes\nnot"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "a\nsociety-wide discussion of\nthe\ntrade-offs\nthat\ncitizens\nare",
          "stymie activity or add more red tape), but in the long-term they": "face\nsuch similar\nregulation. Because AI development\nis\nso"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "willing to tolerate in the name of public safety; The answer",
          "stymie activity or add more red tape), but in the long-term they": "fast-paced,\nthere may\nalso\nbe\nconfusion\nabout\ncurrent AI"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "will differ\nfor each society, and will evolve over\ntime.",
          "stymie activity or add more red tape), but in the long-term they": "capabilities. Thus,\nregulation\nneeds\nto\nbe\nas\nfast-moving,"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "",
          "stymie activity or add more red tape), but in the long-term they": "and quickly adapt\nto current AI\ntrends, which may suggest"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "A. Recommendations",
          "stymie activity or add more red tape), but in the long-term they": "adopting a more agile and responsive model of\nregulation."
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "",
          "stymie activity or add more red tape), but in the long-term they": "Regulators\ncould also set up an audit program that helps"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "For Developers, we\nrecommend developing a practice of",
          "stymie activity or add more red tape), but in the long-term they": ""
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "",
          "stymie activity or add more red tape), but in the long-term they": "to verify the accuracy of affectively-aware AI. For example,"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "getting third-party scientiﬁc review for developed technology.",
          "stymie activity or add more red tape), but in the long-term they": ""
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "",
          "stymie activity or add more red tape), but in the long-term they": "the US National Institutes of Standards and Technology has a"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "Peer\nreview by scientiﬁc journals and conferences are ideal,",
          "stymie activity or add more red tape), but in the long-term they": ""
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "",
          "stymie activity or add more red tape), but in the long-term they": "long-running Face Recognition Vendor Test\n(FRVT) program"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "but minimally we recommend an external,\nrotating board of",
          "stymie activity or add more red tape), but in the long-term they": ""
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "",
          "stymie activity or add more red tape), but in the long-term they": "which evaluates vendor-submitted models\nfor\nfacial\nrecogni-"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "scientiﬁc experts that could include lawyers and ethicists who",
          "stymie activity or add more red tape), but in the long-term they": ""
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "",
          "stymie activity or add more red tape), but in the long-term they": "tion accuracy under a wide array of conditions such as across"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "can review the technology as well as use-cases and advertising.",
          "stymie activity or add more red tape), but in the long-term they": ""
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "",
          "stymie activity or add more red tape), but in the long-term they": "demographic groups [56]. This could serve as a possible model"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "Companies can also put\ninto place policies for\nformal ethical",
          "stymie activity or add more red tape), but in the long-term they": ""
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "",
          "stymie activity or add more red tape), but in the long-term they": "for similarly auditing emotion recognition technology."
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "impact assessments (e.g.,\n[54]).",
          "stymie activity or add more red tape), but in the long-term they": ""
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "",
          "stymie activity or add more red tape), but in the long-term they": "Regulators\nshould also consider efforts on the advertising"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "We also recommend appointing quality-assurance engineers",
          "stymie activity or add more red tape), but in the long-term they": ""
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "",
          "stymie activity or add more red tape), but in the long-term they": "of AI, especially about accurate representation of AI capabil-"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "whose\njob it\nis\nto critically test\nthe\ntechnology by playing",
          "stymie activity or add more red tape), but in the long-term they": ""
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "",
          "stymie activity or add more red tape), but in the long-term they": "ities and limitations. And ﬁnally, we recommend that special"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "devil’s\nadvocate:\nactively challenging the design of\nthe AI,",
          "stymie activity or add more red tape), but in the long-term they": ""
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "",
          "stymie activity or add more red tape), but in the long-term they": "attention be paid to applications where the Emoter\nis not\nin"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "looking for bias against certain populations, or testing general-",
          "stymie activity or add more red tape), but in the long-term they": ""
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "",
          "stymie activity or add more red tape), but in the long-term they": "a position of being able to opt-out\n(e.g., AI-assisted hiring,"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "izability on different datasets and domains6. Designating such",
          "stymie activity or add more red tape), but in the long-term they": ""
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "",
          "stymie activity or add more red tape), but in the long-term they": "employee and student monitoring, public safety surveillance)."
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "an appointment—and designing their incentives and reporting",
          "stymie activity or add more red tape), but in the long-term they": ""
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "structures appropriately—will, in the long-term, result in more",
          "stymie activity or add more red tape), but in the long-term they": "IV. CONCLUSION AND A CALL TO ACTION"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "robust and ethical AI.",
          "stymie activity or add more red tape), but in the long-term they": ""
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "",
          "stymie activity or add more red tape), but in the long-term they": "In summary,\nalthough there have been many recent\ncon-"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "For\njunior developers who work directly with the models",
          "stymie activity or add more red tape), but in the long-term they": ""
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "",
          "stymie activity or add more red tape), but in the long-term they": "ference panels\nand discussions on the\nethics of\naffectively-"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "and\ndata, we\nrecommend\nadopting\nrecently-proposed\nbest",
          "stymie activity or add more red tape), but in the long-term they": ""
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "",
          "stymie activity or add more red tape), but in the long-term they": "aware AI,\nthere\nhas\nnot\nbeen much\nprogress\nby\naffective"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "practices in AI, such as producing detailed Model Cards [48]",
          "stymie activity or add more red tape), but in the long-term they": ""
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "",
          "stymie activity or add more red tape), but in the long-term they": "computing\nresearchers\ntowards\nproviding\na\nformal,\nguiding"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "for their AI models that discuss their model performance spec-",
          "stymie activity or add more red tape), but in the long-term they": ""
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "",
          "stymie activity or add more red tape), but in the long-term they": "framework.\nIn this paper, we propose\nan ethical\nframework"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "iﬁcations, and Datasheets [49] that describe the characteristics",
          "stymie activity or add more red tape), but in the long-term they": ""
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "",
          "stymie activity or add more red tape), but in the long-term they": "on which researchers, engineers,\nindustry and regulators, can"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "of the datasets that developers might collect to train their mod-",
          "stymie activity or add more red tape), but in the long-term they": ""
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "",
          "stymie activity or add more red tape), but in the long-term they": "refer\nto when\nevaluating AI\napplications\nand\ndeployment."
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "els. Developers could also conduct\ninternal audits, especially",
          "stymie activity or add more red tape), but in the long-term they": ""
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "",
          "stymie activity or add more red tape), but in the long-term they": "Our\nnovel multi-stakeholder\nanalysis\nseparates\nthe\nburden"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "on speciﬁc demographic groups\n[55]. These activities could",
          "stymie activity or add more red tape), but in the long-term they": ""
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "",
          "stymie activity or add more red tape), but in the long-term they": "of\nresponsibilities of AI Developers\nfrom the Operators\nthat"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "help junior developers to clearly and accurately convey the AI",
          "stymie activity or add more red tape), but in the long-term they": ""
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "",
          "stymie activity or add more red tape), but in the long-term they": "deploy such AI, and begins to clarify issues for further action"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "capabilities to senior executives (and consequently,\nto external",
          "stymie activity or add more red tape), but in the long-term they": ""
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "",
          "stymie activity or add more red tape), but in the long-term they": "by the relevant entities."
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "parties like Operators, Emoters, and Regulators).",
          "stymie activity or add more red tape), but in the long-term they": ""
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "",
          "stymie activity or add more red tape), but in the long-term they": "AI Ethics is a habit\nthat\nthe stakeholders, from AI Develop-"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "For Operators, we recommend being involved in discus-",
          "stymie activity or add more red tape), but in the long-term they": ""
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "",
          "stymie activity or add more red tape), but in the long-term they": "ers to Operators,\nfrom junior engineers to C-suite executives,"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "sions of the validity of the AI. During negotiations, challenge",
          "stymie activity or add more red tape), but in the long-term they": ""
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "",
          "stymie activity or add more red tape), but in the long-term they": "have\nto\ninculcate\ninto\ntheir\neveryday\ndecision-making. We"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "the Developer\nto show proof of validity on the desired use-",
          "stymie activity or add more red tape), but in the long-term they": ""
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "",
          "stymie activity or add more red tape), but in the long-term they": "hope\nthat\nthe\nissues\nraised will\nstart\nconversations\nin indi-"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "case, and generalizability on data in the target domain. Oper-",
          "stymie activity or add more red tape), but in the long-term they": ""
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "",
          "stymie activity or add more red tape), but in the long-term they": "vidual organizations,\nand the\nrecommendations will provide"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "ators should also designate (regular) internal oversight for the",
          "stymie activity or add more red tape), but in the long-term they": ""
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "",
          "stymie activity or add more red tape), but in the long-term they": "concrete,\nactionable\nitems\nto work on. We will not\nachieve"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "purpose of data use, and how data is collected and stored.",
          "stymie activity or add more red tape), but in the long-term they": ""
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "",
          "stymie activity or add more red tape), but in the long-term they": "ethical\n(affectively-aware) AI\novernight,\nbut\nit\nis\na\nshared"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "We\nrecommend\nappointing\n“consumer\nadvocates” within",
          "stymie activity or add more red tape), but in the long-term they": ""
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "",
          "stymie activity or add more red tape), but in the long-term they": "responsibility that we have to collectively strive for."
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "the organization whose\njob it\nis\nto take\nthe perspective of",
          "stymie activity or add more red tape), but in the long-term they": ""
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "",
          "stymie activity or add more red tape), but in the long-term they": "ACKNOWLEDGMENTS"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "the Emoter, and challenge project managers on the necessity",
          "stymie activity or add more red tape), but in the long-term they": ""
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "and use of\nsuch data: “Did the Emoters consent\nto this new",
          "stymie activity or add more red tape), but in the long-term they": "I am grateful\nto Patricia Chen, Sydney Levine, and three"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "use?”; “How would you [the manager]\nfeel\nif you were the",
          "stymie activity or add more red tape), but in the long-term they": "anonymous reviewers for discussions which helped strengthen"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "Emoter?” These conversations may be difﬁcult\nto have (and",
          "stymie activity or add more red tape), but in the long-term they": "the paper."
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "such positions have to be carefully designed so as not to simply",
          "stymie activity or add more red tape), but in the long-term they": ""
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "",
          "stymie activity or add more red tape), but in the long-term they": "REFERENCES"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "6This is similar in spirit\nto ‘red teams’ in cybersecurity which attempt full-",
          "stymie activity or add more red tape), but in the long-term they": "[1]\nS. Cha, “‘Smile with your eyes’: How to beat South Korea’s AI hiring"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "scale attacks to test an organization’s defenses, but our suggestion differs as",
          "stymie activity or add more red tape), but in the long-term they": "bots and land a job,” Reuters, 2020."
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "the quality-assurance engineer should be a part of the design and engineering",
          "stymie activity or add more red tape), but in the long-term they": "[2] R. Metz, “There’s a new obstacle to landing a job after college: Getting"
        },
        {
          "Or\nconsider\nthe\ncase\nfor\nemotion\nrecognition\nfor\npublic": "process and raise challenges throughout, not\njust on the ﬁnal product.",
          "stymie activity or add more red tape), but in the long-term they": "approved by AI,” CNN Business, 2020."
        }
      ],
      "page": 7
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "Ethical and legal implications,” Paladyn, Journal of Behavioral Robotics,",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "theories of emotion: State of\nthe art and future development,” Emotion"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "vol. 11, no. 1, pp. 199–216, 2020.",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "Review, vol. 5, no. 2, pp. 119–124, 2013."
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "[4] A. Chen and K. Hao, “Emotion AI\nresearchers\nsay overblown claims",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "The mind\nin\n[33] B. Mesquita,\n“A contextualized\nprocess,”\nin\ncontext,"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "give their work a bad name.” MIT Technology Review, 2020.",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "B. Mesquita, L. F. Barrett,\nand E. R. Smith, Eds.\nGuilford Press,"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "[5] D. Harwell, “A face-scanning algorithm increasingly decides whether",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "2010."
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "you deserve the job,” Washington Post, 2019.",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "[34]\nZ. Zeng, M. Pantic, G. I. Roisman, and T. S. Huang, “A survey of affect"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "[6]\n“Artiﬁcial\nintelligence video interview act of 2019,” 2019, passed by the",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "recognition methods: Audio, visual, and spontaneous expressions,” IEEE"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "Illinois General Assembly as Public Act 101-0260 and retrieved from:",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "Transactions\non Pattern Analysis\nand Machine\nIntelligence,\nvol.\n31,"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "http://www.ilga.gov/legislation/publicacts/fulltext.asp?Name=101-0260.",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "no. 1, pp. 39–58, 2009."
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "[7]\nJ. Dzieza, “How hard will\nthe robots make us work?” The Verge, 2020.",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "[35] D. C. Ong, Z. Wu, T. Zhi-Xuan, M. Reddan, I. Kahhale, A. Mattek, and"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "[8] M. Andrejevic\nand N.\nSelwyn,\n“Facial\nrecognition\ntechnology\nin",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "J. Zaki, “Modeling emotion in complex stories:\nthe Stanford Emotional"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "schools: Critical questions and concerns,” Learning, Media and Tech-",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "Narratives Dataset,” IEEE Transactions on Affective Computing, 2019."
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "nology, vol. 45, no. 2, pp. 115–128, 2020.",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "[36]\nS. K. D’mello and J. Kory, “A review and meta-analysis of multimodal"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "[9]\nJ. Li, “A ”brain-reading” headband for\nstudents\nis\ntoo much even for",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "affect detection systems,” ACM Computing Surveys\n(CSUR), vol. 47,"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "Chinese parents,” Quartz, 2019.",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "no. 3, pp. 1–36, 2015."
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "[10]\nL. F. Barrett, R. Adolphs, S. Marsella, A. M. Martinez, and S. D. Pollak,",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "[37]\nS. Poria, E. Cambria, R. Bajpai, and A. Hussain, “A review of affective"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "“Emotional expressions\nreconsidered: Challenges\nto inferring emotion",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "computing: From unimodal analysis to multimodal fusion,” Information"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "in the Public\nfrom human facial movements,” Psychological Science",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "Fusion, vol. 37, pp. 98–125, 2017."
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "Interest, vol. 20, no. 1, pp. 1–68, 2019.",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "[38] D. C. Ong, J. Zaki, and N. D. Goodman, “Affective cognition: Exploring"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "[11] K. Crawford, R. Dobbe, T. Dryer, G. Fried, B. Green, E. Kaziunas,",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "lay theories of emotion,” Cognition, vol. 143, pp. 141–162, 2015."
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "A. Kak, V. Mathur, E. McElroy, A. N. S´anchez, D. Raji, J. L. Rankin,",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "[39]\nS. Anzellotti, S. D. Houlihan, S. Liburd Jr, and R. Saxe, “Leveraging"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "R. Richardson,\nJ. Schultz, and M. Whittaker, “AI Now 2019 Report,”",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "facial\nexpressions\nand\ncontextual\ninformation\nto\ninvestigate\nopaque"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "New York, NY: AI Now Institute, 2019.",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "representations of emotions.” Emotion, 2019."
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "[12] R. Cowie, “The good our ﬁeld can hope to do, the harm it should avoid,”",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "[40]\nL.\nF. Barrett, B. Mesquita,\nand M. Gendron,\n“Context\nin\nemotion"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "IEEE Transactions on Affective Computing, vol. 3, no. 4, pp. 410–423,",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "perception,” Current Directions in Psychological Science, vol. 20, no. 5,"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "2012.",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "pp. 286–290, 2011."
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "[13] A. McStay, Emotional AI: The Rise of Empathic Media.\nSAGE, 2018.",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "[41] D. C. Ong,\nJ. Zaki,\nand N. D. Goodman,\n“Computational models of"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "The Oxford\n[14] R. Cowie,\n“Ethical\nIssues\nin Affective Computing,”\nin",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "emotion inference in theory of mind: A review and roadmap,” Topics in"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "Handbook of Affective Computing.\nOxford University Press, 2015,",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "Cognitive Science, vol. 11, no. 2, pp. 338–357, 2019."
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "pp. 334–348.",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "[42] R. Saxe and S. D. Houlihan, “Formalizing emotion concepts within a"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "[15]\nE. Sedenberg and J. Chuang, “Smile for the camera: Privacy and policy",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "bayesian model of\ntheory of mind,” Current Opinion in Psychology,"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "implications of emotion AI,” arXiv preprint arXiv:1709.00396, 2017.",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "vol. 17, pp. 15–21, 2017."
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "[16]\nL. Stark and J. Hoey, “The ethics of emotion in artiﬁcial\nintelligence",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "[43] D. C. Ong, H. Soh, J. Zaki, and N. Goodman, “Applying probabilistic"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "the 2021 ACM Conference on Fairness,\nsystems,”\nin Proceedings of",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "programming to affective computing,” IEEE Transactions on Affective"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "Accountability, and Transparency, 2021, pp. 782–793.",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "Computing, vol. 12, pp. 306–317, 2021."
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "[17] A. Jobin, M.\nIenca, and E. Vayena, “The global\nlandscape of AI ethics",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "[44] B. Mesquita\nand N. H. Frijda,\n“Cultural Variations\nin Emotions: A"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "guidelines,” Nature Machine\nIntelligence, vol. 1, no. 9, pp. 389–399,",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "Review,” Psychological Bulletin, vol. 112, no. 2, p. 179, 1992."
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "2019.",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "[45]\nJ. Angwin,\nJ. Larson,\nS. Mattu,\nand L. Kirchner,\n“Machine Bias,”"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "[18] M. Whittaker, K. Crawford, R. Dobbe, G. Fried, E. Kaziunas, V. Mathur,",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "ProPublica, 2016."
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "S. M. West, R. Richardson, J. Schultz, and O. Schwartz, “AI Now 2018",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "[46]\nL. Rhue, “Racial inﬂuence on automated perceptions of emotions,” SSRN"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "Report,” New York, NY: AI Now Institute, 2018.",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "3281765, 2018."
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "[19]\n“Ethically Aligned Design: A Vision For Prioritizing Wellbeing With",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "[47] H. Rashkin, E. M. Smith, M. Li,\nand Y.-L. Boureau,\n“Towards Em-"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "Artiﬁcial Intelligence And Autonomous Systems, Version 1,” The IEEE",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "pathetic Open-domain Conversation Models: A New Benchmark and"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "Global Initiative for Ethical Considerations in Artiﬁcial Intelligence and",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "the 57th Annual Meeting of\nthe Association\nDataset,” in Proceedings of"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "Autonomous Systems., 2016.",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "for Computational Linguistics, 2019, pp. 5370–5381."
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "[20]\n“ ´Ethique de la recherche en robotique: Rapport no 1 de la CERNA,”",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "[48] M. Mitchell, S. Wu, A. Zaldivar, P. Barnes, L. Vasserman, B. Hutchin-"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "Commission de r´eﬂexion sur\nl’ ´Ethique de la Recherche en sciences et",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "son, E. Spitzer,\nI. D. Raji,\nand T. Gebru,\n“Model\ncards\nfor model"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "technologies du Num´erique d’Allistene, 2014.",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "reporting,” in Proceedings of the Conference on Fairness, Accountability,"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "[21] D. Dawson, E.\nSchleiger,\nJ. Horton,\nJ. McLaughlin, C. Robinson,",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "and Transparency (ACM FAccT), 2019, pp. 220–229."
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "G. Quezada,\nJ. Scowcroft,\nand S. Hajkowicz,\n“Artiﬁcial\nIntelligence:",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "[49]\nT. Gebru,\nJ. Morgenstern, B. Vecchione,\nJ. W. Vaughan, H. Wallach,"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "Australia’s Ethics Framework,” Data61 CSIRO, Australia, 2019.",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "H. Daum´e III, and K. Crawford, “Datasheets for datasets,” arXiv preprint"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "arXiv:1803.09010, 2018."
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "[22]\n“How Can Humans Keep the Upper Hand? Report on the Ethical Matters",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": ""
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "[50]\n“Responsible bots: 10 guidelines for developers of conversational AI,”"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "Raised by AI Algorithms,” French Data Protection Authority (CNIL),",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": ""
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "Microsoft, 2018."
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "2017.",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": ""
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "[51] N. Sachs and K. Huggard, “Technosurveillance mission creep in Israel’s"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "[23]\n“For a meaningful Artiﬁcial\nIntelligence: Towards a French and Euro-",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": ""
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "COVID-19 response,” Brookings Institution, 2020."
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "pean Strategy,” AI 4 Humanity, 2018.",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": ""
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "[52]\nJ. Tarabay, “Countries vowed to restrict use of COVID-19 data. For one"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "[24]\n“Human rights in the robot age,” Rathenau Instituut, 2017.",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": ""
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "government,\nthe temptation was too great,” Fortune, 2021."
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "[25]\n“Dutch Artiﬁcial\nIntelligence Manifesto,” Special\nInterest Group\non",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": ""
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "[53] M. Standaert, “Smile for the camera:\nthe dark side of China’s emotion-"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "Artiﬁcial\nIntelligence, The Netherlands, 2018.",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": ""
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "recognition tech,” The Guardian, 2021."
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "[26]\n“Report of COMEST on Robotics Ethics,” COMEST/UNESCO, 2017.",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": ""
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "[54]\n“SATORI:\nStakeholders\nActing\nTogether\nOn\nthe\nethical\nimpact"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "[27] A. Campolo, M. Sanﬁlippo, M. Whittaker, and K. Crawford, “AI Now",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": ""
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "assessment\nof Research\nand\nInnovation,”\n2017.\n[Online]. Available:"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "2017 Report,” New York, NY: AI Now Institute, 2017.",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": ""
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "https://satoriproject.eu"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "[28] A. McStay and P. Pavliscak, “Emotional Artiﬁcial\nIntelligence: Guide-",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": ""
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "[55] D. Bryant and A. Howard, “A comparative analysis of emotion-detecting"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "lines for Ethical Use.” COMEST/UNESCO, 2019.",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": ""
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "AI systems with respect to algorithm performance and dataset diversity,”"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "[29] A.\nF. Beavers\nand\nJ.\nP.\nSlattery,\n“On\nthe moral\nimplications\nand",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": ""
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "the 2019 AAAI/ACM Conference on AI, Ethics, and\nin Proceedings of"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "restrictions\nsurrounding affective\ncomputing,”\nin Emotions and Affect",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": ""
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "Society, 2019, pp. 377–382."
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "in Human Factors and Human-Computer Interaction.\nElsevier, 2017,",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": ""
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "[56]\nP. Grother, M. Ngan, and K. Hanaoka, “Face Recognition Vendor Test"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "pp. 143–161.",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": ""
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "(FVRT): Part 3, Demographic Effects,” National\nInstitute of Standards"
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "[30]\nJ.\nJ. Gross and L. Feldman Barrett, “Emotion generation and emotion",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": ""
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": "and Technology, Tech. Rep. NISTIR 8280, 2019."
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "regulation: One or two depends on your point of view,” Emotion Review,",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": ""
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "vol. 3, no. 1, pp. 8–16, 2011.",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": ""
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "[31]\nP. Ekman, “Basic emotions,” in Handbook of Cognition and Emotion,",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": ""
        },
        {
          "[3] C. Fern´andez-Mart´ınez and A. Fern´andez, “AI and recruiting software:": "T. Dalgleish and M. J. Power, Eds., 1999.",
          "[32] A. Moors, P. C. Ellsworth, K. R. Scherer, and N. H. Frijda, “Appraisal": ""
        }
      ],
      "page": 8
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Smile with your eyes': How to beat South Korea's AI hiring bots and land a job",
      "authors": [
        "S Cha"
      ],
      "year": "2020",
      "venue": "Reuters"
    },
    {
      "citation_id": "2",
      "title": "There's a new obstacle to landing a job after college: Getting approved by AI",
      "authors": [
        "R Metz"
      ],
      "year": "2020",
      "venue": "CNN Business"
    },
    {
      "citation_id": "3",
      "title": "AI and recruiting software: Ethical and legal implications",
      "authors": [
        "C Fernández-Martínez",
        "A Fernández"
      ],
      "year": "2020",
      "venue": "Paladyn, Journal of Behavioral Robotics"
    },
    {
      "citation_id": "4",
      "title": "Emotion AI researchers say overblown claims give their work a bad name",
      "authors": [
        "A Chen",
        "K Hao"
      ],
      "year": "2020",
      "venue": "MIT Technology Review"
    },
    {
      "citation_id": "5",
      "title": "A face-scanning algorithm increasingly decides whether you deserve the job",
      "authors": [
        "D Harwell"
      ],
      "year": "2019",
      "venue": "Washington Post"
    },
    {
      "citation_id": "6",
      "title": "Artificial intelligence video interview act of 2019",
      "year": "2019",
      "venue": "General Assembly as Public Act 101-0260 and retrieved from"
    },
    {
      "citation_id": "7",
      "title": "How hard will the robots make us work",
      "authors": [
        "J Dzieza"
      ],
      "year": "2020",
      "venue": "The Verge"
    },
    {
      "citation_id": "8",
      "title": "Facial recognition technology in schools: Critical questions and concerns",
      "authors": [
        "M Andrejevic",
        "N Selwyn"
      ],
      "year": "2020",
      "venue": "Learning, Media and Technology"
    },
    {
      "citation_id": "9",
      "title": "A \"brain-reading\" headband for students is too much even for Chinese parents",
      "authors": [
        "J Li"
      ],
      "year": "2019",
      "venue": "A \"brain-reading\" headband for students is too much even for Chinese parents"
    },
    {
      "citation_id": "10",
      "title": "Emotional expressions reconsidered: Challenges to inferring emotion from human facial movements",
      "authors": [
        "L Barrett",
        "R Adolphs",
        "S Marsella",
        "A Martinez",
        "S Pollak"
      ],
      "year": "2019",
      "venue": "Psychological Science in the Public Interest"
    },
    {
      "citation_id": "11",
      "title": "AI Now",
      "authors": [
        "K Crawford",
        "R Dobbe",
        "T Dryer",
        "G Fried",
        "B Green",
        "E Kaziunas",
        "A Kak",
        "V Mathur",
        "E Mcelroy",
        "A Sánchez",
        "D Raji",
        "J Rankin",
        "R Richardson",
        "J Schultz",
        "M Whittaker"
      ],
      "year": "2019",
      "venue": "AI Now"
    },
    {
      "citation_id": "12",
      "title": "The good our field can hope to do, the harm it should avoid",
      "authors": [
        "R Cowie"
      ],
      "year": "2012",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "13",
      "title": "Emotional AI: The Rise of Empathic Media",
      "authors": [
        "A Mcstay"
      ],
      "year": "2018",
      "venue": "SAGE"
    },
    {
      "citation_id": "14",
      "title": "Ethical Issues in Affective Computing",
      "authors": [
        "R Cowie"
      ],
      "year": "2015",
      "venue": "The Oxford Handbook of Affective Computing"
    },
    {
      "citation_id": "15",
      "title": "Smile for the camera: Privacy and policy implications of emotion AI",
      "authors": [
        "E Sedenberg",
        "J Chuang"
      ],
      "year": "2017",
      "venue": "Smile for the camera: Privacy and policy implications of emotion AI",
      "arxiv": "arXiv:1709.00396"
    },
    {
      "citation_id": "16",
      "title": "The ethics of emotion in artificial intelligence systems",
      "authors": [
        "L Stark",
        "J Hoey"
      ],
      "year": "2021",
      "venue": "Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency"
    },
    {
      "citation_id": "17",
      "title": "The global landscape of AI ethics guidelines",
      "authors": [
        "A Jobin",
        "M Ienca",
        "E Vayena"
      ],
      "year": "2019",
      "venue": "Nature Machine Intelligence"
    },
    {
      "citation_id": "18",
      "title": "AI Now",
      "authors": [
        "M Whittaker",
        "K Crawford",
        "R Dobbe",
        "G Fried",
        "E Kaziunas",
        "V Mathur",
        "S West",
        "R Richardson",
        "J Schultz",
        "O Schwartz"
      ],
      "year": "2018",
      "venue": "AI Now"
    },
    {
      "citation_id": "19",
      "title": "Ethically Aligned Design: A Vision For Prioritizing Wellbeing With Artificial Intelligence And Autonomous Systems, Version 1",
      "year": "2016",
      "venue": "The IEEE Global Initiative for Ethical Considerations in Artificial Intelligence and Autonomous Systems"
    },
    {
      "citation_id": "20",
      "title": "Éthique de la recherche en robotique: Rapport no 1 de la CERNA",
      "year": "2014",
      "venue": "Commission de réflexion sur l' Éthique de la Recherche en sciences et technologies du Numérique d'Allistene"
    },
    {
      "citation_id": "21",
      "title": "Artificial Intelligence: Australia's Ethics Framework",
      "authors": [
        "D Dawson",
        "E Schleiger",
        "J Horton",
        "J Mclaughlin",
        "C Robinson",
        "G Quezada",
        "J Scowcroft",
        "S Hajkowicz"
      ],
      "year": "2019",
      "venue": "Artificial Intelligence: Australia's Ethics Framework"
    },
    {
      "citation_id": "22",
      "title": "How Can Humans Keep the Upper Hand? Report on the Ethical Matters Raised by AI Algorithms",
      "year": "2017",
      "venue": "French Data Protection Authority (CNIL)"
    },
    {
      "citation_id": "23",
      "title": "For a meaningful Artificial Intelligence: Towards a French and European Strategy",
      "year": "2018",
      "venue": "For a meaningful Artificial Intelligence: Towards a French and European Strategy"
    },
    {
      "citation_id": "24",
      "title": "Human rights in the robot age",
      "year": "2017",
      "venue": "Rathenau Instituut"
    },
    {
      "citation_id": "25",
      "title": "Dutch Artificial Intelligence Manifesto",
      "year": "2018",
      "venue": "Special Interest Group on Artificial Intelligence"
    },
    {
      "citation_id": "26",
      "title": "Report of COMEST on Robotics Ethics",
      "year": "2017",
      "venue": "Report of COMEST on Robotics Ethics"
    },
    {
      "citation_id": "27",
      "title": "AI Now 2017 Report",
      "authors": [
        "A Campolo",
        "M Sanfilippo",
        "M Whittaker",
        "K Crawford"
      ],
      "year": "2017",
      "venue": "AI Now 2017 Report"
    },
    {
      "citation_id": "28",
      "title": "Emotional Artificial Intelligence: Guidelines for Ethical Use",
      "authors": [
        "A Mcstay",
        "P Pavliscak"
      ],
      "year": "2019",
      "venue": "Emotional Artificial Intelligence: Guidelines for Ethical Use"
    },
    {
      "citation_id": "29",
      "title": "On the moral implications and restrictions surrounding affective computing",
      "authors": [
        "A Beavers",
        "J Slattery"
      ],
      "year": "2017",
      "venue": "Emotions and Affect in Human Factors and Human-Computer Interaction"
    },
    {
      "citation_id": "30",
      "title": "Emotion generation and emotion regulation: One or two depends on your point of view",
      "authors": [
        "J Gross",
        "L Barrett"
      ],
      "year": "2011",
      "venue": "Emotion Review"
    },
    {
      "citation_id": "31",
      "title": "Basic emotions",
      "authors": [
        "P Ekman"
      ],
      "year": "1999",
      "venue": "Handbook of Cognition and Emotion"
    },
    {
      "citation_id": "32",
      "title": "Appraisal theories of emotion: State of the art and future development",
      "authors": [
        "A Moors",
        "P Ellsworth",
        "K Scherer",
        "N Frijda"
      ],
      "year": "2013",
      "venue": "Emotion Review"
    },
    {
      "citation_id": "33",
      "title": "A contextualized process",
      "authors": [
        "B Mesquita"
      ],
      "year": "2010",
      "venue": "The mind in context"
    },
    {
      "citation_id": "34",
      "title": "A survey of affect recognition methods: Audio, visual, and spontaneous expressions",
      "authors": [
        "Z Zeng",
        "M Pantic",
        "G Roisman",
        "T Huang"
      ],
      "year": "2009",
      "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
    },
    {
      "citation_id": "35",
      "title": "Modeling emotion in complex stories: the Stanford Emotional Narratives Dataset",
      "authors": [
        "D Ong",
        "Z Wu",
        "T Zhi-Xuan",
        "M Reddan",
        "I Kahhale",
        "A Mattek",
        "J Zaki"
      ],
      "year": "2019",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "36",
      "title": "A review and meta-analysis of multimodal affect detection systems",
      "authors": [
        "J Kory"
      ],
      "year": "2015",
      "venue": "ACM Computing Surveys (CSUR)"
    },
    {
      "citation_id": "37",
      "title": "A review of affective computing: From unimodal analysis to multimodal fusion",
      "authors": [
        "S Poria",
        "E Cambria",
        "R Bajpai",
        "A Hussain"
      ],
      "year": "2017",
      "venue": "Information Fusion"
    },
    {
      "citation_id": "38",
      "title": "Affective cognition: Exploring lay theories of emotion",
      "authors": [
        "D Ong",
        "J Zaki",
        "N Goodman"
      ],
      "year": "2015",
      "venue": "Cognition"
    },
    {
      "citation_id": "39",
      "title": "Leveraging facial expressions and contextual information to investigate opaque representations of emotions",
      "authors": [
        "S Anzellotti",
        "S Houlihan",
        "S Liburd",
        "R Saxe"
      ],
      "year": "2019",
      "venue": "Emotion"
    },
    {
      "citation_id": "40",
      "title": "Context in emotion perception",
      "authors": [
        "L Barrett",
        "B Mesquita",
        "M Gendron"
      ],
      "year": "2011",
      "venue": "Current Directions in Psychological Science"
    },
    {
      "citation_id": "41",
      "title": "Computational models of emotion inference in theory of mind: A review and roadmap",
      "authors": [
        "D Ong",
        "J Zaki",
        "N Goodman"
      ],
      "year": "2019",
      "venue": "Topics in Cognitive Science"
    },
    {
      "citation_id": "42",
      "title": "Formalizing emotion concepts within a bayesian model of theory of mind",
      "authors": [
        "R Saxe",
        "S Houlihan"
      ],
      "year": "2017",
      "venue": "Current Opinion in Psychology"
    },
    {
      "citation_id": "43",
      "title": "Applying probabilistic programming to affective computing",
      "authors": [
        "D Ong",
        "H Soh",
        "J Zaki",
        "N Goodman"
      ],
      "year": "2021",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "44",
      "title": "Cultural Variations in Emotions: A Review",
      "authors": [
        "B Mesquita",
        "N Frijda"
      ],
      "year": "1992",
      "venue": "Psychological Bulletin"
    },
    {
      "citation_id": "45",
      "title": "Machine Bias",
      "authors": [
        "J Angwin",
        "J Larson",
        "S Mattu",
        "L Kirchner"
      ],
      "year": "2016",
      "venue": "Machine Bias"
    },
    {
      "citation_id": "46",
      "title": "Racial influence on automated perceptions of emotions",
      "authors": [
        "L Rhue"
      ],
      "year": "2018",
      "venue": "SSRN"
    },
    {
      "citation_id": "47",
      "title": "Towards Empathetic Open-domain Conversation Models: A New Benchmark and Dataset",
      "authors": [
        "H Rashkin",
        "E Smith",
        "M Li",
        "Y.-L Boureau"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "48",
      "title": "Model cards for model reporting",
      "authors": [
        "M Mitchell",
        "S Wu",
        "A Zaldivar",
        "P Barnes",
        "L Vasserman",
        "B Hutchinson",
        "E Spitzer",
        "I Raji",
        "T Gebru"
      ],
      "year": "2019",
      "venue": "Proceedings of the Conference on Fairness, Accountability, and Transparency"
    },
    {
      "citation_id": "49",
      "title": "Datasheets for datasets",
      "authors": [
        "T Gebru",
        "J Morgenstern",
        "B Vecchione",
        "J Vaughan",
        "H Wallach",
        "H Daumé",
        "K Crawford"
      ],
      "year": "2018",
      "venue": "Datasheets for datasets",
      "arxiv": "arXiv:1803.09010"
    },
    {
      "citation_id": "50",
      "title": "Responsible bots: 10 guidelines for developers of conversational AI",
      "year": "2018",
      "venue": "Responsible bots: 10 guidelines for developers of conversational AI"
    },
    {
      "citation_id": "51",
      "title": "Technosurveillance mission creep in Israel's COVID-19 response",
      "authors": [
        "N Sachs",
        "K Huggard"
      ],
      "year": "2020",
      "venue": "Technosurveillance mission creep in Israel's COVID-19 response"
    },
    {
      "citation_id": "52",
      "title": "Countries vowed to restrict use of COVID-19 data. For one government, the temptation was too great",
      "authors": [
        "J Tarabay"
      ],
      "year": "2021",
      "venue": "Fortune"
    },
    {
      "citation_id": "53",
      "title": "Smile for the camera: the dark side of China's emotionrecognition tech",
      "authors": [
        "M Standaert"
      ],
      "year": "2021",
      "venue": "The Guardian"
    },
    {
      "citation_id": "54",
      "title": "SATORI: Stakeholders Acting Together On the ethical impact assessment of Research and Innovation",
      "year": "2017",
      "venue": "SATORI: Stakeholders Acting Together On the ethical impact assessment of Research and Innovation"
    },
    {
      "citation_id": "55",
      "title": "A comparative analysis of emotion-detecting AI systems with respect to algorithm performance and dataset diversity",
      "authors": [
        "D Bryant",
        "A Howard"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society"
    },
    {
      "citation_id": "56",
      "title": "Face Recognition Vendor Test (FVRT): Part 3, Demographic Effects",
      "authors": [
        "P Grother",
        "M Ngan",
        "K Hanaoka"
      ],
      "year": "2019",
      "venue": "NISTIR"
    }
  ]
}