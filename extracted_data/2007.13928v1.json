{
  "paper_id": "2007.13928v1",
  "title": "Variants Of Bert, Random Forests And Svm Approach For Multimodal Emotion-Target Sub-Challenge",
  "published": "2020-07-28T01:15:50Z",
  "authors": [
    "Hoang Manh Hung",
    "Hyung-Jeong Yang",
    "Soo-Hyung Kim",
    "Guee-Sang Lee"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Emotion recognition has become a major problem in computer vision in recent years that made a lot of effort by researchers to overcome the difficulties in this task. In the field of affective computing, emotion recognition has a wide range of applications, such as healthcare, robotics, humancomputer interaction. Due to its practical importance for other tasks, many techniques and approaches have been investigated for different problems and various data sources. Nevertheless, comprehensive fusion of the audio-visual and language modalities to get the benefits from them is still a problem to solve. In this paper, we present and discuss our classification methodology for MuSe-Topic Sub-challenge, as well as the data and results. For the topic classification, we ensemble two language models which are ALBERT and RoBERTa to predict 10 classes of topics. Moreover, for the classification of valence and arousal, SVM and Random forests are employed in conjunction with feature selection to enhance the performance.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Emotion is an indispensable part of human experience. This has a major effect on human cognition, understanding, learning, communication, decision-making and many other scenarios of everyday life. One of the goals of the Affective Computing research is to make computers more human-like so that computers are aware of human emotional states. The emotion recognition has also been a great trend in psychology and in the computer science community because of its usefulness in practice  [1, 2] . As an example, companies are interested in measuring people's comments about their services, and customers focus on feedback from other clients to evaluate the product before they purchase it. In the field of emotion recognition, there are many methods and modalities that have recently been used and focused on (i.e facial expression, speech, text, and physiological signals). The MuSe challenge  [3]  aims to link the communities of Affective Computing and Sentiment Analysis and to compare the advantages of multimodal fusion for audio, vision, and language that assist emotion recognition systems to deal *Corresponding author with behavior in the wild. The MuSe challenge includes 3 sub-challenges: Multimodal Sentiment in-the-Wild Subchallenge (MuSe-Wild), Multimodal Emotion-Target Subchallenge (MuSe-Topic), and Multimodal Trustworthiness Sub-challenge (MuSe-Trust). In this paper, we present our approach to the Muse-Topic sub-challenge, which is required to predict 10-class domain-specific topics as the emotional target and 3 levels of arousal and valence for each segment.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Methods",
      "text": "",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Topic Classification",
      "text": "In this task, 10 classes of the topics including (performance, interior-features, quality-aeshetic, comfort, handling, safety, general-information, cost, user-experience, exterior-features) will be used as labels to predict for each segment. From the experiments and also based on the provided baseline, we recognize that NLP transformer models outperform compared to other methods and modalities like Multimodal transformer (MMT)  [4] , LSTM  [5] , End2You  [6] . That is why we continue to exploit and use NLP transformer models. While BERT  [7]  uses Next Sentence Prediction (NSP) and Masked Language Models (MLM) to help the network learn text representation, RoBERTa  [8]  has shown that using NSP is inefficient. They used a dynamic masking pattern instead of a static one, replaced NSP by FULL-SENTENCES and DOC-SENTENCES approaches, trained with the bigger dataset and sentence length to improve performance. ALBERT  [9]  method tries to incorporate Factorized Embedding Parameterization and Cross Layer Parameter Sharing techniques to reduce the number of parameters to increase scalability for models. They also realized the inefficiency in the NSP and proposed a self-supervised loss for sentence-order prediction (SOP) to support the model focusing on inter-sentence coherence. For this task, we try to ensemble ALBERT and RoBERTa models trained with raw text from the transcripts to get the final result.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Emotion Classification",
      "text": "Our approach is based on Support Vector Machines (SVMs)  [10]  and Random Forests to classify 3 levels of the emotion arXiv:2007.13928v1 [cs.CV] 28 Jul 2020 for both arousal and valence. The difference is that we use the univariate feature selection to select those features that have the strongest relationship with the output variable before the training (shown in Fig.  1  and Fig.  2 ). Based on the observation that there are numerical inputs and categorical outputs, we selected the ANOVA F-value method to perform statistical test.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Experimental Results",
      "text": "In the topic classification, ALBERT and RoBERTa use batch sizes of 16 and 32, respectively, with the sequence length are 50. The Adam optimizer is used along with the learning rate at the start of 10 -5 and the total epochs are 3. The weights for the ensemble of two methods are respectively 0.5 and 0.5 for ALBERT and RoBERTa. We also try to use pseudo label for the training phase. The result is shown in the Table  1 . For the emotion task, the complexity parameter C is set at 0.0538, and the gamma is automatic for SVM. The max depth of Random Forests method is set at 7.4008 and our best score is shown in Table  2 .",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Conclusion",
      "text": "In this paper, we present and discuss our approach for MuSe-Topic sub challenge. We have shown the appropriate methods and parameters to produce high results in predicting topics and emotion states. However, there are still a lot of approaches that we have not experimented with, as well as exploited combinations of the modalities. They still have the potential to investigate for improving performance.",
      "page_start": 2,
      "page_end": 2
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: and Fig. 2). Based on the obser-",
      "page": 2
    },
    {
      "caption": "Figure 1: The univariate values of each vggface feature.",
      "page": 3
    },
    {
      "caption": "Figure 2: The univariate values of each xception feature.",
      "page": 3
    }
  ],
  "tables": [
    {
      "caption": "Table 1: Table 1. Results of topic classiﬁcation",
      "page": 2
    },
    {
      "caption": "Table 2: 4. CONCLUSION",
      "page": 2
    },
    {
      "caption": "Table 2: Results of emotion classiﬁcation",
      "page": 3
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "",
      "authors": [
        "References"
      ],
      "venue": ""
    },
    {
      "citation_id": "2",
      "title": "Deep facial expression recognition: A survey",
      "authors": [
        "Shan Li",
        "Weihong Deng"
      ],
      "year": "2020",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "3",
      "title": "Emotions recognition using eeg signals: A survey",
      "authors": [
        "M Soraia",
        "Manuel Alarcao",
        "Fonseca"
      ],
      "year": "2017",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "4",
      "title": "Muse 2020-the first international multimodal sentiment analysis in real-life media challenge and workshop",
      "authors": [
        "Lukas Stappen",
        "Alice Baird",
        "Georgios Rizos",
        "Panagiotis Tzirakis",
        "Xinchen Du",
        "Felix Hafner",
        "Lea Schumann",
        "Adria Mallol-Ragolta",
        "Björn Schuller",
        "Iulia Lefter"
      ],
      "year": "2020",
      "venue": "Muse 2020-the first international multimodal sentiment analysis in real-life media challenge and workshop",
      "arxiv": "arXiv:2004.14858"
    },
    {
      "citation_id": "5",
      "title": "Multimodal transformer for unaligned multimodal language sequences",
      "authors": [
        "Yao-Hung Hubert Tsai",
        "Shaojie Bai",
        "Paul Liang",
        "J Zico Kolter",
        "Louis-Philippe Morency",
        "Ruslan Salakhutdinov"
      ],
      "year": "2019",
      "venue": "Proceedings of the conference. Association for Computational Linguistics. Meeting"
    },
    {
      "citation_id": "6",
      "title": "Long shortterm memory",
      "authors": [
        "Sepp Hochreiter",
        "Jürgen Schmidhuber"
      ],
      "year": "1997",
      "venue": "Neural computation"
    },
    {
      "citation_id": "7",
      "title": "End2you-the imperial toolkit for multimodal profiling by end-to-end learning",
      "authors": [
        "Panagiotis Tzirakis",
        "Stefanos Zafeiriou",
        "Bjorn Schuller"
      ],
      "year": "2018",
      "venue": "End2you-the imperial toolkit for multimodal profiling by end-to-end learning",
      "arxiv": "arXiv:1802.01115"
    },
    {
      "citation_id": "8",
      "title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "authors": [
        "Jacob Devlin",
        "Ming-Wei Chang",
        "Kenton Lee",
        "Kristina Toutanova"
      ],
      "year": "2018",
      "venue": "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "arxiv": "arXiv:1810.04805"
    },
    {
      "citation_id": "9",
      "title": "A robustly optimized bert pretraining approach",
      "authors": [
        "Yinhan Liu",
        "Myle Ott",
        "Naman Goyal",
        "Jingfei Du",
        "Mandar Joshi",
        "Danqi Chen",
        "Omer Levy",
        "Mike Lewis",
        "Luke Zettlemoyer",
        "Veselin Stoyanov",
        "Roberta"
      ],
      "year": "2019",
      "venue": "A robustly optimized bert pretraining approach",
      "arxiv": "arXiv:1907.11692"
    },
    {
      "citation_id": "10",
      "title": "Albert: A lite bert for self-supervised learning of language representations",
      "authors": [
        "Zhenzhong Lan",
        "Mingda Chen",
        "Sebastian Goodman",
        "Kevin Gimpel",
        "Piyush Sharma",
        "Radu Soricut"
      ],
      "year": "2019",
      "venue": "Albert: A lite bert for self-supervised learning of language representations",
      "arxiv": "arXiv:1909.11942"
    },
    {
      "citation_id": "11",
      "title": "Support vector machines",
      "authors": [
        "Marti Hearst",
        "Susan Dumais",
        "Edgar Osuna",
        "John Platt",
        "Bernhard Scholkopf"
      ],
      "year": "1998",
      "venue": "IEEE Intelligent Systems and their applications"
    }
  ]
}