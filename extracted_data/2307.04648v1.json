{
  "paper_id": "2307.04648v1",
  "title": "Department: Affective Computing And Sentiment Analysis",
  "published": "2023-07-06T15:42:05Z",
  "authors": [
    "Mostafa M. Amin",
    "Erik Cambria",
    "Björn W. Schuller"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "The employment of foundation models is steadily expanding, especially with the launch of ChatGPT and the release of other foundation models. These models have shown the potential of emerging capabilities to solve problems, without being particularly trained to solve. A previous work demonstrated these emerging capabilities in affective computing tasks; the performance quality was similar to traditional Natural Language Processing (NLP) techniques, but falling short of specialised trained models, like fine-tuning of the RoBERTa language model. In this work, we extend this by exploring if ChatGPT has novel knowledge that would enhance existing specialised models when they are fused together. We achieve this by investigating the utility of verbose responses from ChatGPT about solving a downstream task, in addition to studying the utility of fusing that with existing NLP methods. The study is conducted on three affective computing problems, namely sentiment analysis, suicide tendency detection, and big-five personality assessment. The results conclude that ChatGPT has indeed novel knowledge that can improve existing NLP techniques by way of fusion, be it early or late fusion. WITH THE RECENT rapid growth of foundation models [1] as large language models (LLMs) [2], a potential has appeared for emerging capabilities [3] of such models to perform new downstream tasks or solve new problems, that they were not particularly trained on in the first place. This includes models like , GPT-4 [5], LLaMA [6], and RoBERTa [7]. The capabilities of such foundation models are being explored in various domains, like affective computing [8], Neural Machine Translation (NMT) [9], agents playing games [10], sentiment analysis [11], and general artificial intelligence [12].",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Related Work",
      "text": "We focus on related work within the area of foundation models in affective-computing-related tasks (in the text domain) or hybrid formulations between foundation models and traditional NLP methods. Both  [17] ,  [18]  explore a fusion between ChatGPT and other transformer-based models for Named Entity Recognition (NER). All of  [19] ,  [20] ,  [21]  investigate the capabilities of ChatGPT on various NLP tasks including affective computing tasks like sentiment analysis or emotion recognition, and others like NER and text summarisation.  [11]  investigates the performance of ChatGPT in several in sentiment analysis and aspect extraction.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Method",
      "text": "Our method consists of the following components:\n\n1) Prompting ChatGPT to estimate an affective answer about a given input example, thus having two texts representing a given example, namely the original text and the corresponding response of ChatGPT. 2) Process any of the two texts via traditional NLP techniques to represent them as static features vectors; we adopt RoBERTa features extracted by the RoBERTa-base LLM  [7]  or normalised BoW count vectors  [16] . 3) Train classical machine learning models on these features either by applying early fusion, by concatenating the features then training, or late fusion by training two models and averaging their prediction probabilities. In this section, we present first the datasets for the different affective computing problems. Afterwards, we introduce the prompting of Chat-GPT, then the methods for extracting features. Subsequently, we present how we train and tune the machine learning models. Finally, we present a simple baseline based on ChatGPT responses. The pipeline of our method is presented in Figure  1 .",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Datasets",
      "text": "We present here the adopted datasets for the three affective computing problems. A summary of their statistics is in Table  1 .",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Sentiment Dataset",
      "text": "We make use of the Twitter Sentiment140 dataset  [22]  for sentiment anal- ysis.  1  The dataset consists of tweets that were collected from Twitter. Tweets are generally very noisy texts. The dataset consists of tweets and the corresponding binary sentiment labels (positive, or negative). The original dataset consists of 1,600,000 Tweets, however, we filtered these down into a total of 28,000 examples.  2  We do not make use of the original Test portion in the dataset, since it consists of only 497 Tweets, and it also contains a 'neutral' label unlike the rest of the dataset. We split the original training portion into three parts as shown in Table  1 .",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Suicide And Depression Dataset",
      "text": "The Suicide and Depression dataset  [23]  was gathered from the platform Reddit. The collection was gathered under different categories (subreddits), namely \"depression\", \"SuicideWatch\", and \"teenagers\".  3  The 'non-sucide' label was given to the posts from the \"teenagers\" category, while the remaining texts were given the label 'suicide'. After excluding examples longer than 512 characters and downsampling the dataset, we acquired a dataset of size 16,266 that we divide into three portions Train, Dev, and Test as shown in Table  1 , since the original dataset was not split.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Personality Dataset",
      "text": "We make use of the First Impressions (FI) dataset (  [24] ,  [25] ) for the personality task  4  . The big-five personality traits (OCEAN) are the traits used to represent personality, namely, Openness to experience, Conscientiousness, Extraversion, Agreeableness, and Neuroticism. The dataset was gathered by collecting videos from YouTube, and slicing them into 15 seconds clips with one speaker. The personality labels were collected through crowdsourcing using Amazon Mechanical Turk (AMT), by making pair comparisons between different videos. Each personality trait is represented by a continuous regression value within [0, 1]. In our setup, we utilise only the text modality of the entire FI dataset, with its provided split, originating from the transcriptions of the videos. We train regression models (by employing Mean Absolute Error as a loss function)  [26] , because the continuous labels give a granular estimation of the personality labels. For evaluation, we interpret the predicted regression labels as the probability of the positive class, which is equivalent to binarising the labels with the threshold 0.5.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Chatgpt Prompts",
      "text": "To formulate the ChatGPT text modalities, we need to formulate a prompt to ask ChatGPT, in order to obtain a reasonable answer. We formulate a prompt for each specific problem to ask it about the label. First, we design the prompt to ask for a binary label of the corresponding problem, while emphasising narrowing down the answer to only two labels while excluding more 'neutral' labels. Similar to a previous work  [8] , we design the prompts to have the disclaimer It does not have to be fully correct, and ask what is your guess for the answer, instead of What is the answer or Can you guess the answer. This formulation is to avoid ChatGPT from responding that it is not sure about the answer, hence not giving any answer. Unlike  [8] , we ask ChatGPT to be verbose and explain the reasoning behind the answer, since we are processing that with NLP methods (unlike  [8] , where the final label was parsed). A last sentence is added to avoid redundant disclaimer in the response of ChatGPT.\n\nWe make use of the OpenAI API to use ChatGPT 5 , using the the model 'gpt-3.5-turbo-0301'. We do not give a system message, we just use the prompt corresponding to the specific problem as the only user message in the input conversation, with the input text of the example. The assistant response is what we use as the response of ChatGPT. We use the default parameters for generation, namely the answer with highest score (n = 1), and the temperature parameter T = 1.0.\n\nThe prompts for the given problems are given below, by substituting the input {text}. For the personality traits, we query the API five times for each of the five traits by substituting the {trait}.\n\n• The prompt for the sentiment classification: Regarding the number of tokens, a token on average gives 4.3 characters. There is an overhead of 8 tokens that gets added for each call to the API. The prompts using an empty input string for '{text}' consist of 63, 50, 75 tokens, for the sentiment, suicide, and personality prompts, respectively. Processing a prompt of total T tokens (system, prompted input and output) took an average of 0.038T + 1.32 sec.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Text Features",
      "text": "In order to process the text, we need to extract features from it. We employ two ways to extract features, one via the LLM RoBERTa  [7] , and n-gram BoW.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Roberta",
      "text": "Language Model The RoBERTa  [7]  feature set is obtained by the pretrained LLM RoBERTa, which is based on the BERT model with a transformer architecture. The model has two variants; we utilise the smaller variant, namely RoBERTa-base  6  . The model was trained on large datasets with reddit posts and English Wikipedia, and English news  [7] . In order to extract the embedding for a string, it is first encoded with a subword encoder then fed to the RoBERTa model to give a sequential set of features with attention weights. These are reduced through a pooling layer in the model to produce the final static vector of 768 features representing the given string.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Bag Of Words",
      "text": "The BoW feature set is achieved by constructing n-grams, and then using the classical term-frequency inverse-document-frequency (TF-IDF) to count each term while normalising them by the frequency across all documents  [16] . For the input texts, we keep only the most common 10,000 words (i. e. , 1-grams), to give a static vector of 10,000 features representing the text. For the responses of ChatGPT, we utilise the most common 2,000 n-grams (n ∈ {1, 2, 3}). The vectors are scaled by the maximum absolute values to be within the range [-1, 1]. The reason we utilise n-grams for ChatGPT responses is that, it is common that ChatGPT would give prediction expressions like 'high extraversion', or 'sentiment is negative'.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Models And Tuning",
      "text": "Given a feature set (or a fusion thereof) we train a Multi-Layer Perceptron (MLP)  [16]  to predict the final label. We opt to use MLPs, because preliminary experiments showed that MLPs were performing slightly better than Support Vector Machines (SVMs)  [16]  for the given tasks. We construct an MLP with N hidden layers, with U units in the first hidden layer, then each following hidden layer has half the number of neurons of the hidden layer preceding it (we cap this number to be at least 32 units). ReLU is the activation function used for all layers, except for the final layer, where we apply sigmoid to predict the final label within the range [0, 1]. We leverage Adam  [27]  as an optimisation algorithm, with a learning rate α. The loss function is either Mean Absolute Error (MAE) for regression training (for personality training), or otherwise negative log likelihood for classification training. We employ the hyperparameter optimisation toolkit SMAC  [28]  to select the best hyperparameters for each problem/dataset and each input modality (or early fusion combinations thereof). We explore 20 hyperparameters samples for each problem. The hyperparameter space has N ∈ [0, 3], U ∈ [64, 512] (log-sampled), and α ∈ [10 -6 , 10] (log-sampled).",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Fusion",
      "text": "We deploy early fusion by concatenating the features extracted by RoBERTa or BoW, then training one MLP on the concatenated vector similar to training a single method. On the other hand, the late fusion is achieved by averaging the probabilities predicted by the given methods.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Baseline",
      "text": "We employ a simple baseline based on the responses of ChatGPT. In the prompts, we instruct ChatGPT to give a binary label before explaining the answer, hence we construct the baseline to predict a label only if the word corresponding to its class is present in the text. For sentiment analysis, the baseline would predict 'positive' only if the response of ChatGPT contains the word 'positive', and it would predict 'negative' only if the response contains the word 'negative'. For suicide detection, the two classification keywords are 'yes' and 'no'. For personality, the two keywords become 'high' and 'low'. We exclude the evaluation of responses that include both words or neither, which is roughly only 5% of the Test sets in our experiments. The intuition behind this baseline is that it is similar to parsing the labels from the non-verbose response.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Results",
      "text": "We experiment the combinations of three main parameters, the text to be used, the corresponding extracted features to represent the text, and how to fuse them. The texts are either the original text or the corresponding response from ChatGPT. The features are either embeddings obtained by RoBERTa, or using normalised count vectors constructed by a simple n-gram BoW approach. The fusion of the models is either done (early) on the feature level, or (late) on the prediction level by averaging the probabilities of the classes. We also include the baseline results. The main results of the experiments are shown in Table  2 , where we evaluate classification accuracy and Unweighted Average Recall (UAR), which is the unweighted average of the accuracy of classifying each class separately  [29] . Finally, we refer to the combination of input text (original input or ChatGPT response thereof) and NLP processing technique as a modality. Table  2 : Results for all the problems with the different fusion methods. There are two text-based inputs, the original text (Text), or the verbose response of ChatGPT on a question about the original text and the corresponding problem (ChatGPT). Each text input is processed in two ways, using RoBERTa features or BoW. The features are processed with an MLP to give the final binary classification label of the problem. The fusion is either done on the feature level with one MLP (Early), or on the predictions level (Late). Marked in bold are the best results for each combination of problem and fusion. Underlined are the best results for each problem.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Discussion",
      "text": "First of all, both metrics show a wide agreement on the relative performance of a specific model on a specific problem, i. e. , the relative order of models on a specific problem based is roughly similar for both metrics. The results of utilisng the original text (for each of the single modalities Text+RoBERTa and Text+BoW) are close to previous work  [8] , with a slight difference due to the different sampling from the original datasets. The results of the single modality ChatGPT+RoBERTa are decent, comparable to the single modality Text+BoW, but worse than Text+RoBERTa in most cases except for sentiment analysis. The results of ChatGPT+BoW are slightly worse than ChatGPT+RoBERTa. In a similar fashion, these results of ChatGPT are resembling the previous work  [8] , where Chat-GPT was comparable to the Text+BoW modality. Furthermore, the aggregate performances across problems is also similar to  [8] , where ChatGPT was the most superior in sentiment analysis, whilst most inferior in personality assessment.\n\nThe results of fusion are inclined to show that the most competent fusion combination is adopting only Text+RoBERTa and ChatGPT+RoBERTa, whether in early or late fusion; however, the early fusion of these two modalities is showing the most superior performance in most scenarios, except the sentiment analysis. Disregarding the specific combination of these two modalities, late fusion is performing better compared to the corresponding instances of early fusion in most cases of the other modality combinations. For instance, the late fusion of all modalities is better than their early fusion; similarly for the combination of Text+RoBERTa and Text+BoW.\n\nConsequently, the impact of fusion overall is not very straight forward to explain, because the single modality Text+RoBERTa is the best for the personality assessment, while the early fusion of Text+RoBERTa and ChatGPT+RoBERTa is the best for suicide detection, and the late fusion of all modalities is the best for sentiment analysis. The reason for the superiority of the single modality in the personality assessment is probably due to the poor performance of ChatGPT on the given text, since ChatGPT single modalities are the worst ones. On the other hand, if ChatGPT has a decent performance, then applying fusion has definitely a strong improvement impact, be it early or late fusion. However, the superiority of late fusion against early fusion depends primarily on the problem and the data distribution.\n\nFrom the practical advantages of early fusion, it needs hyperparameter tuning only once, compared to the late fusion which needs to tune a model for each modality. On the other hand, the late fusion has an architectural advantage that it can deploy different training sizes for each modality. For instance, it is possible to train Text+RoBERTa with much larger dataset size, while training ChatGPT+RoBERTa on a smaller dataset size; we will evaluate this in future work.\n\nIn the previous work  [8] , the ChatGPT results were labels that were parsed from the non-verbose responses (typically, a binary label like 'low' or 'high', with some variance in the formatting), whereas in this work we process the verbose response by applying NLP methods. The effectiveness of employing the verbose responses is demonstrated by the baseline approach, where the results of the single ChatGPT modalities are close to the baseline. The verbose responses (compared to the non-verbose ChatGPT baseline) lead to better responses for both sentiment analysis and personality assessment, but with some drop in suicide detection. The verbose responses have the additional advantage of avoiding the problem of parsing the label from the response of ChatGPT, since the responses (including the non-verbose) do not always follow the same format despite being prompted to  [8] . The last obvious advantage of verbose responses is the ability to include them in fusion models in various ways, which can lead to a much better performance as discussed earlier.\n\nIn summary, utilising the verbose responses of ChatGPT adds unique information that can yield improvements to the results of existing NLP models. Employing fusion techniques on top of that, whether early or late fusion, will yield bigger improvements. Moreover, it is sufficient in most cases to process the texts only with RoBERTa to extract features, for both the original text and the verbose response of ChatGPT without worrying about parsing the corresponding labels.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Conclusion",
      "text": "In this work, we explored the fusion capabilities of ChatGPT with traditional Natural Language Processing (NLP) models in affective computing problems. We first prompted ChatGPT to give verbose responses to answer binary classification questions for three affective computing downstream tasks, namely sentiment analysis, suicide tendency detection, and big-five personality traits assessment. Additionally, we processed the input texts and the corresponding ChatGPT responses with two NLP techniques, namely fine-tuning RoBERTa language model and n-gram BoW; these features were trained by leveraging Multi-Layer Perceptrons (MLPs). Furthermore, we investigated two fusion methods, early fusion (on the features level) or late fusion (on the prediction level).\n\nThe experiments have demonstrated that leveraging ChatGPT verbose responses bears novel knowledge in affective computing and probably beyond, which should be evaluated next, that can aid existing NLP techniques by ways of fusion, whether early or late fusion. First, we demonstrated the benefit of using verbose responses while processing them with NLP techniques, as compared to parsing classification labels from the non-verbose labels. Subsequently, this provided the possibility of seamlessly fusing ChatGPT responses with existing NLP methods, hence achieving a better performance via both early or late fusions. Furthermore, the experiments have demonstrated that utilising only RoBERTa to process and fuse the input texts and ChatGPT responses (with an inclination to early fusion than late) can be sufficient to reach the best performance.\n\nMostafa M. Amin is currently working toward the Ph.D. degree with the Chair of Embedded Intelligence for Health Care and Wellbeing with University of Augsburg, while working as Senior Research Data Scientist at SyncPilot GmbH in Augsburg, Germany. His research interests include Affective Computing, Audio and Text Analytics. He received a M.Sc. degree in Computer Science from the University of Freiburg, Germany. Contact him at mostafa.mohamed@unia.de Erik Cambria is a professor of Computer Science and Engineering at Nanyang Technological University, Singapore. His research focuses on neurosymbolic AI for explainable natural language processing in domains like sentiment analysis, dialogue systems, and financial forecasting. He is an IEEE Fellow and a recipient of several awards, e. g., IEEE Outstanding Career Award, was listed among the AI's 10 to Watch, and was featured in Forbes as one of the 5 People Building Our AI Future. Contact him at cambria@ntu.edu.sg. Bj örn W. Schuller is currently a professor of Artificial Intelligence with the Department of Computing, Imperial College London, UK, where he heads the Group on Language, Audio, & Music (GLAM). He is also a full professor and the head of the Chair of Embedded Intelligence for Health Care and Wellbeing with the University of Augsburg, Germany, and the Founding CEO/CSO of audEERING. He is an IEEE Fellow alongside other Fellowships. Contact him at schuller@IEEE.org.",
      "page_start": 9,
      "page_end": 9
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Pipelines of the different fusion methods. Each branch shows a single modality of selecting",
      "page": 3
    }
  ],
  "tables": [
    {
      "caption": "Table 1: Datasets sizes statistics, including the",
      "data": [
        {
          "Dataset": "Sentiment",
          "Train": "20,000",
          "Dev": "5,000",
          "Test": "3,000",
          "+ve": "1,516",
          "-ve": "1,484"
        },
        {
          "Dataset": "Suicide",
          "Train": "9,999",
          "Dev": "3,881",
          "Test": "2,375",
          "+ve": "757",
          "-ve": "1,618"
        },
        {
          "Dataset": "Personality\nO\nC\nE\nA\nN",
          "Train": "5,992",
          "Dev": "2,000",
          "Test": "1,997",
          "+ve": "1,336\n1,133\n890\n1,332\n1,122",
          "-ve": "661\n864\n1,107\n665\n875"
        }
      ],
      "page": 3
    },
    {
      "caption": "Table 2: Results for all the problems with the different fusion methods. There are two text-based inputs,",
      "data": [
        {
          "ChatGPT\nText": "RoBERTa\nBoW\nRoBERTa\nBoW",
          "Fusion": "",
          "Sent.": "",
          "Suic.": "",
          "Personality": "Average"
        },
        {
          "ChatGPT\nText": "Baseline",
          "Fusion": "–",
          "Sent.": "77.68",
          "Suic.": "94.48",
          "Personality": "54.34"
        },
        {
          "ChatGPT\nText": "✓",
          "Fusion": "–\n–\n–\n–",
          "Sent.": "77.83\n73.90\n80.27\n79.83",
          "Suic.": "95.37\n90.40\n92.34\n91.92",
          "Personality": "64.12\n61.66\n61.01\n60.71"
        },
        {
          "ChatGPT\nText": "",
          "Fusion": "",
          "Sent.": "",
          "Suic.": "",
          "Personality": ""
        },
        {
          "ChatGPT\nText": "",
          "Fusion": "",
          "Sent.": "",
          "Suic.": "",
          "Personality": ""
        },
        {
          "ChatGPT\nText": "",
          "Fusion": "",
          "Sent.": "",
          "Suic.": "",
          "Personality": ""
        },
        {
          "ChatGPT\nText": "✓",
          "Fusion": "Early\nEarly\nEarly\nEarly\nEarly",
          "Sent.": "81.20\n80.90\n76.27\n80.03\n80.93",
          "Suic.": "96.17\n93.52\n92.97\n91.96\n93.94",
          "Personality": "63.65\n61.79\n62.21\n60.89\n61.53"
        },
        {
          "ChatGPT\nText": "",
          "Fusion": "",
          "Sent.": "",
          "Suic.": "",
          "Personality": ""
        },
        {
          "ChatGPT\nText": "✓",
          "Fusion": "",
          "Sent.": "",
          "Suic.": "",
          "Personality": ""
        },
        {
          "ChatGPT\nText": "",
          "Fusion": "",
          "Sent.": "",
          "Suic.": "",
          "Personality": ""
        },
        {
          "ChatGPT\nText": "✓",
          "Fusion": "",
          "Sent.": "",
          "Suic.": "",
          "Personality": ""
        },
        {
          "ChatGPT\nText": "✓",
          "Fusion": "Late\nLate\nLate\nLate\nLate",
          "Sent.": "81.60\n80.77\n79.40\n81.13\n82.60",
          "Suic.": "96.13\n93.94\n95.54\n92.76\n95.45",
          "Personality": "63.26\n61.68\n63.59\n61.08\n62.66"
        },
        {
          "ChatGPT\nText": "",
          "Fusion": "",
          "Sent.": "",
          "Suic.": "",
          "Personality": ""
        },
        {
          "ChatGPT\nText": "✓",
          "Fusion": "",
          "Sent.": "",
          "Suic.": "",
          "Personality": ""
        },
        {
          "ChatGPT\nText": "",
          "Fusion": "",
          "Sent.": "",
          "Suic.": "",
          "Personality": ""
        },
        {
          "ChatGPT\nText": "✓",
          "Fusion": "",
          "Sent.": "",
          "Suic.": "",
          "Personality": ""
        }
      ],
      "page": 6
    },
    {
      "caption": "Table 2: Results for all the problems with the different fusion methods. There are two text-based inputs,",
      "data": [
        {
          "ChatGPT\nText": "RoBERTa\nBoW\nRoBERTa\nBoW",
          "Fusion": "",
          "Sent.": "",
          "Suic.": "",
          "Personality": "Average"
        },
        {
          "ChatGPT\nText": "Baseline",
          "Fusion": "–",
          "Sent.": "77.44",
          "Suic.": "90.56",
          "Personality": "51.79"
        },
        {
          "ChatGPT\nText": "✓",
          "Fusion": "–\n–\n–\n–",
          "Sent.": "77.82\n73.91\n80.25\n79.81",
          "Suic.": "94.07\n88.46\n90.37\n90.10",
          "Personality": "56.76\n52.77\n51.14\n51.64"
        },
        {
          "ChatGPT\nText": "",
          "Fusion": "",
          "Sent.": "",
          "Suic.": "",
          "Personality": ""
        },
        {
          "ChatGPT\nText": "",
          "Fusion": "",
          "Sent.": "",
          "Suic.": "",
          "Personality": ""
        },
        {
          "ChatGPT\nText": "",
          "Fusion": "",
          "Sent.": "",
          "Suic.": "",
          "Personality": ""
        },
        {
          "ChatGPT\nText": "✓",
          "Fusion": "Early\nEarly\nEarly\nEarly\nEarly",
          "Sent.": "81.19\n80.89\n76.27\n80.02\n80.91",
          "Suic.": "95.89\n92.04\n91.54\n89.99\n92.77",
          "Personality": "55.90\n53.56\n54.58\n51.77\n53.13"
        },
        {
          "ChatGPT\nText": "",
          "Fusion": "",
          "Sent.": "",
          "Suic.": "",
          "Personality": ""
        },
        {
          "ChatGPT\nText": "✓",
          "Fusion": "",
          "Sent.": "",
          "Suic.": "",
          "Personality": ""
        },
        {
          "ChatGPT\nText": "",
          "Fusion": "",
          "Sent.": "",
          "Suic.": "",
          "Personality": ""
        },
        {
          "ChatGPT\nText": "✓",
          "Fusion": "",
          "Sent.": "",
          "Suic.": "",
          "Personality": ""
        },
        {
          "ChatGPT\nText": "✓",
          "Fusion": "Late\nLate\nLate\nLate\nLate",
          "Sent.": "81.59\n80.76\n79.40\n81.11\n82.59",
          "Suic.": "95.12\n92.25\n94.37\n90.78\n94.20",
          "Personality": "54.41\n52.40\n55.14\n51.43\n53.35"
        },
        {
          "ChatGPT\nText": "",
          "Fusion": "",
          "Sent.": "",
          "Suic.": "",
          "Personality": ""
        },
        {
          "ChatGPT\nText": "✓",
          "Fusion": "",
          "Sent.": "",
          "Suic.": "",
          "Personality": ""
        },
        {
          "ChatGPT\nText": "",
          "Fusion": "",
          "Sent.": "",
          "Suic.": "",
          "Personality": ""
        },
        {
          "ChatGPT\nText": "✓",
          "Fusion": "",
          "Sent.": "",
          "Suic.": "",
          "Personality": ""
        }
      ],
      "page": 6
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "On the Opportunities and Risks of Foundation Models",
      "authors": [
        "R Bommasani"
      ],
      "year": "2021",
      "venue": "On the Opportunities and Risks of Foundation Models",
      "arxiv": "arXiv:2108.07258"
    },
    {
      "citation_id": "2",
      "title": "A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT",
      "authors": [
        "C Zhou"
      ],
      "year": "2023",
      "venue": "A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT",
      "arxiv": "arXiv:2302.09419"
    },
    {
      "citation_id": "3",
      "title": "Emergent Abilities of Large Language Models",
      "authors": [
        "J Wei"
      ],
      "year": "2022",
      "venue": "Emergent Abilities of Large Language Models",
      "arxiv": "arXiv:2206.07682"
    },
    {
      "citation_id": "4",
      "title": "Training language models to follow instructions with human feedback",
      "authors": [
        "L Ouyang"
      ],
      "year": "2022",
      "venue": "Training language models to follow instructions with human feedback",
      "arxiv": "arXiv:2203.02155"
    },
    {
      "citation_id": "5",
      "title": "GPT-4",
      "authors": [
        "Openai"
      ],
      "year": "2023",
      "venue": "GPT-4",
      "arxiv": "arXiv:2303.08774"
    },
    {
      "citation_id": "6",
      "title": "LLaMA: Open and Efficient Foundation Language Models",
      "authors": [
        "H Touvron"
      ],
      "year": "2023",
      "venue": "LLaMA: Open and Efficient Foundation Language Models",
      "arxiv": "arXiv:2302.13971"
    },
    {
      "citation_id": "7",
      "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach",
      "authors": [
        "Y Liu"
      ],
      "year": "2019",
      "venue": "RoBERTa: A Robustly Optimized BERT Pretraining Approach",
      "arxiv": "arXiv:1907.11692"
    },
    {
      "citation_id": "8",
      "title": "Will Affective Computing Emerge from Foundation Models and General AI? A First Evaluation on ChatGPT",
      "authors": [
        "M Amin",
        "E Cambria",
        "B Schuller"
      ],
      "year": "2023",
      "venue": "IEEE Intelligent Systems"
    },
    {
      "citation_id": "9",
      "title": "How Good Are GPT Models at Machine Translation? A Comprehensive Evaluation",
      "authors": [
        "A Hendy"
      ],
      "year": "2023",
      "venue": "How Good Are GPT Models at Machine Translation? A Comprehensive Evaluation",
      "arxiv": "arXiv:2302.09210"
    },
    {
      "citation_id": "10",
      "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models",
      "authors": [
        "G Wang"
      ],
      "year": "2023",
      "venue": "Voyager: An Open-Ended Embodied Agent with Large Language Models",
      "arxiv": "arXiv:2305.16291"
    },
    {
      "citation_id": "11",
      "title": "Sentiment Analysis in the Era of Large Language Models: A Reality Check",
      "authors": [
        "W Zhang"
      ],
      "year": "2023",
      "venue": "Sentiment Analysis in the Era of Large Language Models: A Reality Check",
      "arxiv": "arXiv:2305.15005"
    },
    {
      "citation_id": "12",
      "title": "Sparks of Artificial General Intelligence: Early experiments with GPT-4",
      "authors": [
        "S Bubeck"
      ],
      "year": "2023",
      "venue": "Sparks of Artificial General Intelligence: Early experiments with GPT-4",
      "arxiv": "arXiv:2303.12712"
    },
    {
      "citation_id": "13",
      "title": "Computational Paralinguistics: Emotion, Affect and Personality in Speech and Language Processing",
      "authors": [
        "B Schuller",
        "A Batliner"
      ],
      "year": "2013",
      "venue": "Computational Paralinguistics: Emotion, Affect and Personality in Speech and Language Processing"
    },
    {
      "citation_id": "14",
      "title": "Affective Computing and Sentiment Analysis",
      "authors": [
        "E Cambria"
      ],
      "year": "2016",
      "venue": "IEEE Intelligent Systems"
    },
    {
      "citation_id": "15",
      "title": "Distributed Representations of Words and Phrases and their Compositionality",
      "authors": [
        "T Mikolov"
      ],
      "year": "2013",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "16",
      "title": "Pattern Recognition and Machine Learning",
      "authors": [
        "C Bishop"
      ],
      "year": "2006",
      "venue": "Pattern Recognition and Machine Learning"
    },
    {
      "citation_id": "17",
      "title": "Better Low-Resource Entity Recognition Through Translation and Annotation Fusion",
      "authors": [
        "Y Chen",
        "V Shah",
        "A Ritter"
      ],
      "year": "2023",
      "venue": "Better Low-Resource Entity Recognition Through Translation and Annotation Fusion",
      "arxiv": "arXiv:2305.13582"
    },
    {
      "citation_id": "18",
      "title": "Prompt ChatGPT In MNER: Improved multimodal named entity recognition method based on auxiliary refining knowledge from ChatGPT",
      "authors": [
        "J Li"
      ],
      "year": "2023",
      "venue": "Prompt ChatGPT In MNER: Improved multimodal named entity recognition method based on auxiliary refining knowledge from ChatGPT",
      "arxiv": "arXiv:2305.12212"
    },
    {
      "citation_id": "19",
      "title": "ChatGPT: Jack of all trades, master of none",
      "authors": [
        "J Koco"
      ],
      "year": "2023",
      "venue": "Information Fusion"
    },
    {
      "citation_id": "20",
      "title": "Can ChatGPT Understand Too? A Comparative Study on ChatGPT and Fine-tuned BERT",
      "authors": [
        "Q Zhong"
      ],
      "year": "2023",
      "venue": "Can ChatGPT Understand Too? A Comparative Study on ChatGPT and Fine-tuned BERT",
      "arxiv": "arXiv:2302.10198"
    },
    {
      "citation_id": "21",
      "title": "Is ChatGPT a General-Purpose Natural Language Processing Task Solver?",
      "authors": [
        "C Qin"
      ],
      "year": "2023",
      "venue": "Is ChatGPT a General-Purpose Natural Language Processing Task Solver?",
      "arxiv": "arXiv:2302.06476"
    },
    {
      "citation_id": "22",
      "title": "Twitter Sentiment Classification using Distant Supervision",
      "authors": [
        "A Go",
        "R Bhayani",
        "L Huang"
      ],
      "year": "2009",
      "venue": "CS224N project report"
    },
    {
      "citation_id": "23",
      "title": "Suicide and Depression Detection in Social Media Forums",
      "authors": [
        "V Desu"
      ],
      "year": "2022",
      "venue": "Smart Intelligent Computing and Applications"
    },
    {
      "citation_id": "24",
      "title": "Chalearn lap 2016: First Round Challenge on First Impressions -Dataset and Results",
      "authors": [
        "V Ponce-L Ópez"
      ],
      "year": "2016",
      "venue": "European conference on computer vision"
    },
    {
      "citation_id": "25",
      "title": "Design of an Explainable Machine Learning Challenge for Video Interviews",
      "authors": [
        "H Escalante"
      ],
      "year": "2017",
      "venue": "International Joint Conference on Neural Networks (IJCNN)"
    },
    {
      "citation_id": "26",
      "title": "Multi-Modal Score Fusion and Decision Trees for Explainable Automatic Job Candidate Screening From Video CVs",
      "authors": [
        "H Kaya",
        "F Gurpinar",
        "A Salah"
      ],
      "year": "2017",
      "venue": "Conference on Computer Vision and Pattern Recognition Workshops"
    },
    {
      "citation_id": "27",
      "title": "Adam: A Method for Stochastic Optimization",
      "authors": [
        "D Kingma",
        "J Ba"
      ],
      "year": "2015",
      "venue": "3rd International Conference on Learning Representations, Conference Track Proceedings, ICLR"
    },
    {
      "citation_id": "28",
      "title": "SMAC3: A Versatile Bayesian Optimization Package for Hyperparameter Optimization",
      "authors": [
        "M Lindauer"
      ],
      "year": "2022",
      "venue": "Journal of Machine Learning Research"
    },
    {
      "citation_id": "29",
      "title": "The INTERSPEECH 2013 Computational Paralinguistics Challenge: Social Signals, Conflict, Emotion, Autism",
      "authors": [
        "B Schuller"
      ],
      "year": "2013",
      "venue": "Proceedings INTERSPEECH, ISCA"
    },
    {
      "citation_id": "30",
      "title": "IEEE Intelligent Systems",
      "venue": "IEEE Intelligent Systems"
    }
  ]
}