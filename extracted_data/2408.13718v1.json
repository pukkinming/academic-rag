{
  "paper_id": "2408.13718v1",
  "title": "Gpt-4 Emulates Average-Human Emotional Cognition From A Third-Person Perspective",
  "published": "2024-08-11T01:22:09Z",
  "authors": [
    "Ala N. Tak",
    "Jonathan Gratch"
  ],
  "keywords": [
    "emotion recognition",
    "affective computing",
    "large language models",
    "GPT-4",
    "appraisal theory"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "This paper extends recent investigations on the emotional reasoning abilities of Large Language Models (LLMs). Current research on LLMs has not directly evaluated the distinction between how LLMs predict the self-attribution of emotions and the perception of others' emotions. We first look at carefully crafted emotion-evoking stimuli, originally designed to find patterns of brain neural activity representing fine-grained inferred emotional attributions of others. We show that GPT-4 is especially accurate in reasoning about such stimuli. This suggests LLMs agree with humans' attributions of others' emotions in stereotypical scenarios remarkably more than self-attributions of emotions in idiosyncratic situations. To further explore this, our second study utilizes a dataset containing annotations from both the author and a third-person perspective. We find that GPT-4's interpretations align more closely with human judgments about the emotions of others than with self-assessments. Notably, conventional computational models of emotion primarily rely on self-reported ground truth as the gold standard. However, an average observer's standpoint, which LLMs appear to have adopted, might be more relevant for many downstream applications, at least in the absence of individual information and adequate safety considerations.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "I. Introduction",
      "text": "The exploration of large language models (LLMs) in understanding and modeling human emotions has received significant attention in the last two years. These studies have probed the capabilities of models such as the GPT family of LLMs and others in tasks related to causal reasoning  [1] , emotional decision-making and appraisal theory  [2] , emotion classification  [3] -  [5] , emotional intelligence  [6] , emotional dialogue understanding  [7] , generation of emotional text  [8] , and more. A consistent method across these studies is the zero-shot approach (i.e., in-context learning) with prompt engineering, emphasizing the LLMs' ability to perform tasks without explicit training.\n\nWhile the field of affective computing often concentrates on inferring emotions from expressions, typically overlooking the triggering circumstances  [9] , computational emotion models aim to understand the situational context, including how specific aspects may evoke particular emotions and influence future decisions, behaviors, and beliefs  [10] ,  [11] . The foundation of most computational emotion models is appraisal theory  [12] ,  [13] , actually a cluster of theories that share the principle that emotions arise from an evaluation of how current circumstances impact the individual. This evaluation, based on criteria known as appraisal variables, assesses the relevance of a situation to one's goals, its alignment with these goals, and its predictability, among other factors. The specific pattern of these assessments gives rise to particular emotions. For instance, anger is triggered by goal-incongruent events when the person perceives control, whereas sadness emerges from a sense of powerlessness. The intensity of these emotions is further shaped by factors such as the importance of the threatened goal or the unexpectedness of the threat, leading to stronger emotional responses  [14] .\n\nIn this paper, we seek to address a persistent controversy involving appraisal theory as to whether it reflects the actual mechanisms involved in human emotion elicitation  [15] , or whether it serves as a folk psychological theory that observers use to interpret the emotions of others  [16] ,  [17] , or if both perspectives are equally valid (echoing similar controversies as to whether emotion recognition methods are best seen as recognizing felt or perceived emotion). If the former, LLMbased models would be well-suited to emotion recognition. If the latter, they may be better suited to predicting social Current evaluations of LLM abilities have not directly evaluated the distinction between production and perception. For example, Tak and Gratch  [2] ,  [18]  showcased the advantage of using appraisal theory as a lens to shed light on similarities and differences in how humans and LLMs attribute emotions to situations. Though the work only considered self-reported emotions from descriptions of autobiographical memories, and did not contrast the accuracy of these predictions against those of outside observers reading the same descriptions. This study was also limited by the small size of the corpus they used.\n\nWe address these limitations with two studies. We first look at carefully crafted, artificial emotion-evoking stimuli with ratings on a large set of appraisal and emotion dimensions. The stimuli were originally designed to find patterns of brain neural activity representing fine-grained inferred emotional attributions of others. We show that GPT-4  [19] , arguably the most capable LLM currently available, is more accurate in reasoning about such stimuli than free-form self-report vignettes. The performance might also be derived from the differences in perspective. In other words, GPT-4 might view situations as an observer and capture the third-person perspective of the average human. This hypothesis motivates the second study, in which we examine whether GPT-4 processes emotions through an average observer's lens. To this end, we employ a corpus that includes both author and reader annotations of appraisals and emotions. In both studies, we follow the current practice of assessing LLMs' zero-shot in-context learning abilities (temperature set to 0) employing OpenAI's API resources.\n\nOur work builds upon recent efforts to unravel the underlying mechanisms and inner workings of LLMs and AI more broadly. Emotional inference plays a pivotal role across a spectrum of real-world social contexts, including courtroom judg-ments, therapeutic environments, negotiations, and personal relationships. Given its significance, the emotional cognitive capabilities of LLMs and AI at large can pose substantial risks or confer critical benefits. The perspective LLMs adopt in emotional inference is a fundamental component of their cognitive capacity, especially influencing their applicability in various domains. Depending on their intended use, an LLM might be optimally deployed either to recognize the emotions people are actually experiencing or to gauge social perceptions. For instance, a storytelling model should steer clear of endorsing any particular understanding of emotional experiences in the absence of a universal consensus, aiming instead to align with general social perceptions. Conversely, a model designed for personal therapy must closely align with an individual's authentic emotional state. The subsequent sections explore different components of LLM's emotional reasoning with discussions on LLM performance in relation to the nature of inputs (stereotypically crafted stimuli versus spontaneous, free-form scenarios) and the model's perspective (first-person/experiencer versus third-person/observer).",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Ii. Study 1: Crafted Emotion-Evoking Stimuli",
      "text": "Skerry and Saxe  [20]  hypothesized that brain representations involved in inferring others' emotions based on short textual narratives are better captured by appraisal variables than by combinations of basic emotional dimensions. Instead of studying emotions as directly experienced by individuals, i.e., the authentic and subjective/first-person experience of emotions, Skerry and Saxe  [20]  explored how people intuitively understand and theorize about the causes of emotions. In other words, they aimed to explore folk psychological theories  [21]  about emotions (i.e., how emotions are caused). Regardless of whether these ideas are directly tied to immediate emotional Fig.  3 . t-SNE plot generated using human and GPT-4 appraisal scores experiences, such folk psychological theories (e.g., appraisal theory) hold value as they often capture real causal regularities in the world.\n\nIn their study, subjects read 200 stimuli describing situations that would elicit a particular emotion. The reliability of the constructed stimuli was tested by a group of subjects on MTurk who classified the stimuli with 65% accuracy (chance = 5%). The constructed verbal stimuli (2-3 sentences each; M(SEM)= 50.68(0.28) words) describe a character in an emotion-eliciting event who experiences one of 20 different emotions without any mention of the character's reaction. Participants (1521 total responses) are asked to rate the situation on highdimensional appraisal space (38 variables drawn from different theories, particularly Scherer and colleagues  [22] ,  [24] ) and eight basic emotion dimensions (six basic emotions plus valence and arousal).\n\nAiming to replicate and extend the approach in  [2]  on the extensive set of carefully crafted stimuli described above, we prompt GPT-4 to rate the scenarios using the same scales and wordings given to Skerry and Saxe's participants. We repeated each prompt eight times, yielding 1600 data points, enabling us to analyze variability in responses. An example prompt is illustrated in Fig.  1 , which includes the narrative each time generated with a random female name and a minimum additional text to help the model provide standardized output. Skerry and Saxe used random names to avoid bias that might arise from a particular name (like them, we did not examine any effects of name choice). In particular, we aim to examine how accurate GPT-4 would be at predicting people's assessment of others' appraisals (i.e., third-person appraisal derivation), people's attributions of others' emotion (i.e., thirdperson affect derivation), and would it be consistent with appraisal theory in explaining appraisal-emotion mapping?",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "A. Reduced Appraisal Space",
      "text": "Following Skerry and Saxe  [20] , we apply sequential feature selection to reduce appraisals to a smaller feature space as several of the 38 appraisals are highly correlated. The reduced appraisal space eliminates redundant features, helping to capture unique variance across stimuli.\n\nUtilizing an ensemble classifier, we evaluate the contribution of each feature towards accurately classifying the 20 distinct emotion labels and incrementally add features that improve classification accuracy. A model trained on ten appraisal variables classifies the scenarios with 45.8% accuracy compared to 56.6% observed with the full appraisal space (thus, suggesting the reduced space achieves reasonable performance). Below is the list of selected features:\n\n• Pleasantness: Did the situation involve a hedonically positive or pleasant experience for ⟨name⟩? • Expectedness: Did ⟨name⟩ expect this situation to occur? • Agent-cause: Was this situation caused by a person or some other external force (e.g., randomness)? • Self-cause: Was this situation caused by ⟨name⟩ herself or by someone/something else? • Already-occurred: Was ⟨name⟩'s emotion based on something that had already occurred? • Close-others: Did people other than ⟨name⟩ know about the situation that occurred? • Pressure: Was ⟨name⟩ under a lot of pressure in this situation? • Consequences: Was ⟨name⟩'s situation an isolated incident, or did it have long-term consequences? • Safety: Did this situation involve risks for ⟨name⟩ or others? • Self-esteem: Did this situation affect ⟨name⟩'s selfesteem or opinion of herself? Strikingly, using the same ensemble approach with GPT-4 rated appraisals (i.e., using GPT-4 rather than humans to predict appraisal values) achieved 94.5% accuracy with the same reduced set, compared to 99.7% accuracy using the full 39 appraisals. Fig.  2  illustrates the performance of GPT-4 the classify stimuli following their intended labels (i.e., True labels in the two confusion matrices). Fig.  2 .c denotes that GPT-4 outperforms human participants in attributing emotions to stimuli as they were intended by the researchers. It should be noted that the stimuli design and labeling was further validated using participant responses in an iterative process (see  [20] ). It is also noteworthy that less variance with GPT-4's ratings is anticipated as it is essentially a single rater with some random noise. What is remarkable is the degree of classification power achieved by GPT-4's appraisal ratings.\n\nTo further examine the difference between GPT-4 and humans in perceiving the intended stimuli manipulation, we conducted a K-means cluster analysis using human ratings of the ten appraisal features. This way, we only rely on the model and participants' appraisal ratings to differentiate between classes of stimuli in a fully unsupervised manner. The analysis resulted in 12 and 20 stimuli clusters with Silhouette scores of 0.121 and 0.204 using human and GPT-4 ratings, respectively. This indicates that the reduced appraisal space is not enough to distinguish 20 classes (as intended by researchers) reliably based on human ratings; rather, they lead to 12 distinctive and fine-grained emotion labels. On the other hand, GPT-4 seems to exploit a latent learned appraisal mechanism that is able to decode the crafted stimuli into a fine-grained emotion space. Interestingly, ten appraisal features are enough to decode 20 clusters compared to the 12 using human ratings, even though the bottom-up clusters do not necessarily match the top-down/intended 20 emotion classes. Fig.  3  illustrates the t-SNE plot generated using human and GPT-4 appraisal ratings (labeling is based on the majority intended emotion class making up each cluster). This plot illustrates the separability performance of GPT-4's appraisal features compared to humans, even in a two-dimensional space. This lends weight to the idea that GPT-4 is more consistent with the assumptions of appraisal theory than the individual human annotators.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "B. Appraisal Derivation",
      "text": "To examine how well GPT-4 predicts how a person would appraise a situation (i.e., appraisal derivation), we compute Pearson correlations between the ten appraisal variables rated by human participants and the corresponding variables predicted by GPT-4. To this end, we first averaged the scores over each stimulus for humans and GPT-4 to have a mean stimuli score. We observe very high correlations across the ten variables, suggesting the GPT-4 mean responses closely match human mean appraisal scores (Table  I ). GPT-4 seems to struggle to predict if a situation has already occurred (using Fig.  4 . GPT-4 vs. human appraisal score probability distribution the exact question formulation originally given to humans). To investigate the discrepancy further, we compared the rating distribution of all variables. Fig.  4  shows the smoothed rating probability distribution with Jensen-Shannon Divergence (JSD) distance scores. We observe a higher concentration of GPT-4 ratings on either (or both) end of the spectrum, indicating higher variability among human raters with a relatively more tendency toward the mean. The density of alreadyoccurred responses suggests significant disagreement among human participants over the event's time window. Given the remarkable degree of correspondence, this is a critical distinction between the two, warranting further investigation of the potential causes. We examine appraisal inter-correlations for further evidence of correspondence or deviation of behavior. However, Fig.  5  denotes impressive similarity between GPT-4 and human appraisal behavior with slight differences in pressure-safety and pressure-consequences inter-correlations.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "C. Basic Emotion Recognition",
      "text": "Both participants and GPT-4 rated the stimuli on the eight basic emotion dimensions. Table  II  demonstrates the results of Pearson correlation analysis. Similar to the appraisal derivation step findings, very significant correspondence is observed.  Surprise scores the lowest among all emotion dimensions. Fig.  6  illustrates the smoothed probability distribution of emotion ratings and JSD scores. Corresponding to earlier observations on appraisal variables, we see a relatively greater tendency toward the mean among human participants except for surprise and, to a lesser extent, arousal. We observe a peek at higher arousal scores among human participants, which does not exist in GPT-4 distribution. GPT-4 surprise ratings denote a completely distinctive behavior compared to humans. GPT-4 tends to attribute significantly higher surprise to the stimuli. Such deviation requires deeper examination when combined with appraisals of the stimuli.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "D. Appraisal To Emotion Mapping",
      "text": "Finally, we investigate if GPT-4 reports a theoretically plausible relationship between appraisal variables and emotions. Recall that appraisal theories state that emotions arise from specific patterns of appraisals. Here, we examine and compare the pattern underlying human participants and GPT-4 responses. To this end, we conducted multiple linear regression (with backward elimination) to see if/how appraisals predict emotion dimensions. Additionally, for instances where regression coefficients might not offer clear insights, we supplemented our analysis with Pearson correlation to provide a more nuanced understanding of the relationships between variables, particularly in terms of shared variance. Results We see a remarkable match between the overall mapping behavior, which is consistent with the observation reported in  [2] ,  [18] . The variance of all emotion dimensions is explained to a great extent by the reduced appraisal space. Surprise has the least explained variance among human emotions, whereas arousal and disgust require a larger appraisal space to be fully explained by GPT-4 ratings. Regarding major appraisal-emotion mapping differences, pressure, and selfesteem seem to be important predictors of arousal with respect to human ratings but are not significant based on GPT-4 ratings. Similarly, pressure and self-cause are predictors of the human happy dimension but are not predictors of GPT-4 happy scores. GPT-4 leverages its evaluation of close others' involvement in stimuli to predict sadness, a role that pressure plays when it comes to human attribution of sadness to stimuli. GPT-4 attributes disgust to cases that are not expected, whereas human participants highlight the role of long-term consequences when assigning disgust to stimuli. It should be noted that the stated differences are negligible when compared to notable affect derivation pattern similarities between the GPT-4 and human participants.",
      "page_start": 5,
      "page_end": 6
    },
    {
      "section_name": "E. Discussion",
      "text": "In Study 1, we employed a dataset of crafted stimuli rated by external observers, which were systematically manipulated in ways that yield different appraisals and emotions. Except for a few instances, results suggest a remarkable correspondence of mean human scores and mean GPT-4 scores in all processes involved in emotional cognition. The similarities exceed what is reported in  [2] ,  [18]  and others. One interpretation might be that GPT-4 excels when dealing with stereotypical situations rather than free-form self-report idiosyncratic vignettes. Also, GPT-4 might view situations as an observer and capture the third-person perspective of the average human.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Iii. Study 2: Investigating The Perspective",
      "text": "Study 2 tests the hypothesis, suggested by Study 1, that GPT-4 processes emotions through the lens of an average observer. To this end, we employ the crowd-enVENT dataset developed Troiano et al.  [23] , which is, to the best of our knowledge, the only corpus that includes both author and reader annotations of both appraisals and emotions. This valuable corpus enables researchers to compare the agreement of external annotators and self-assessments of the authors. Similar to the first study's corpus, the appraisal scheme used to create crowd-enVENT is primarily based on the scheme proposed by Scherer and colleagues  [24] ,  [26] . Unlike the first study, crowd-enVENT consists of self-reported vignettes (1200 data points). However, strategies are adopted to promote the collection of more idiosyncratic events to induce a higher diversity of events and appraisal dimensions  [23] . In this corpus, participants rate 21 appraisal variables on a scale of 1-5 and pick an emotion from 12 emotion labels plus a \"no emotion\" label. For the sake of brevity, we refer readers to the original paper for detailed descriptive statistics and corpus creation and validation processes. Here, we focus on testing our hypothesis that GPT-4 is aligned more with an average observer's evaluation of emotions and appraisal induced in events.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "A. Appraisal Derivation",
      "text": "We first turn our attention to the correspondence of appraisal ratings between GPT-4, the author's self-assessments, and external human raters. We follow the same procedure as described in Study 1 to generate prompts with minimum additional text for standardized output. Fig  8 provides  a comparison of appraisal rating agreements using Krippendorff's alpha measure  [27] . Krippendorff's alpha is particularly suitable here due to its ability to handle different levels of measurement (nominal, ordinal, interval, and ratio and to accommodate any number of raters. It also enables to have the same agreement measure for both appraisals and emotions. Based on  Fig 8,   we see GPT-4 corresponds significantly better to the average ratings of readers than the authors' original self-assessments. The average reader (considered a single rating) slightly outperforms GPT-4. However, we see the lowest agreement levels among readers (5-way), suggesting high variations in evaluations among human external observers of an emotion-evoking event. In summary, GPT-4 seems to be on par with an average human observer and significantly more in line with a third-person perspective than the self-assessment of the event.\n\nTo delve into the nuances, Fig.  9  showcases the agreement scores for the 21 appraisal variables. GPT-4 aligns more closely with the average third-person perspective in 20 of the 21 appraisals when comparing the \"Avg reader & GPT-4\" and \"Author & GPT-4\" columns. GPT-4 mostly matches the average reader's predictions of the author's self-assessed appraisals or exceeds that in 6 out of the 21 appraisal variables. The lower inter-reader agreements on appraisal features emphasizes individual differences and indicates GPT-4's tendency towards a balanced average-human assessment of emotional situations. Furthermore, a consistent pattern across the four columns indicates that certain appraisals are universally challenging to predict, whether from an individual or a generalized social perspective, hinting at the need for additional situational or personal information for precise appraisal prediction. Variables such as pleasantness, unpleasantness, goalsupport, and congruence, as well as self/other responsibility, are relatively straightforward and show higher agreement levels across comparisons. Conversely, appraisal variables like accept consequence (i.e., accommodative coping) are more dependent on the individual involved. These subtleties call for further research to enhance LLMs' emotional cognition by incorporating individual variability.",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "B. Emotion Recognition",
      "text": "The authors, five human readers, and GPT-4 attributed a label among 13 emotion labels to the self-reported vignettes. Similar to the previous step, we employ Krippendorff's Alpha in this classification task, as it calculates the degree of agreement corrected for the chance to ensure that the agreement among raters is not simply due to random chance. We employ the most representative label for a given vignette (i.e., majority rule) to serve as a proxy for the collective attribution of labels to scenarios or the consensus viewpoint. Fig  8  demonstrates the results of the analysis. Similar to the appraisal derivation step, GPT-4 corresponds significantly more to the majority class selected by readers than the authors' original self-assessments and is on par with average readers in predicting original labels (relative to inter-reader agreement).",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Iv. General Discussion",
      "text": "In the two studies conducted, we explored how GPT-4 processes and interprets emotions from both artificially crafted and self-reported textual narratives following the method presented in  [2] ,  [18] . Our approach illuminates the mechanisms by which how humans and LLM differ in terms of appraising situations, attributing emotions to situations, and, lastly, mapping appraisals to emotions. Tak and Gratch  [2] ,  [18]  applied this approach to autobiographical memories, focusing on how well the two models predict self-reported appraisals and emotions. The results showed the model did not fully recover the significance of all appraisal dimensions and relied only on a few. They also reported that the models were less accurate at predicting arousal than valence and dominance dimensions. However, in  [2] ,  [18] , participants were instructed to recall emotional situations, whereas GPT was given no information about the nature of these situations, including the event's significance to the person. In addition, participants self-selected their own stories, which could inflict biases in what type of stories are remembered. For example, the stories might not vary widely in certain appraisal dimensions. To address these limitations, in Study 1, we employed 200 stimuli describing situations that evoke particular emotions, initially developed to understand brain representations of emotions. GPT-4 was prompted to rate these scenarios on appraisal and emotion scales used by human participants. A feature reduction was performed to identify key appraisal dimensions influencing emotion recognition. Remarkably, GPT-4 demonstrated high accuracy (99.7% with full appraisal space) in classifying emotions, surpassing human participants. Correlation analysis revealed GPT-4's ratings closely aligned with human appraisals across ten variables, though differences in interpreting the temporal aspect of events were noted (i.e., whether an event has already occurred). Differences in how GPT-4 and humans evaluate certain emotions and appraisals were highlighted, especially in the context of surprise and arousal.\n\nGiven the remarkable correspondence across appraisals and emotions, such discrepancies warrant further investigation. In the second study, focusing on whether GPT-4 aligns more with an average observer's evaluation, we utilized another corpus featuring both author and external reader annotations of emotions and appraisals. GPT-4's appraisals were more aligned with average readers than authors' self-assessments, indicating a closer association with an observer's perspective. In emotion recognition, GPT-4 again showed closer alignment with average readers' viewpoints compared to authors' selfassessments.\n\nMost recent evaluations of LLMs' emotion-related abilities generally report higher-than-expected performance. Yongsatianchot et al.  [3]  reported GPT-4 can generate diverse emotional stories, explain emotional events, and do reverse appraisal when given enough context. Broekens et al.  [5]  reported ChatGPT zero-shot performance matches fine-tuned XLMRoBERTa-large in VAD prediction, and it can generate new valid situations based on levels of latent affect representations. According to Elyoseph et al.  [28] , ChatGPT scores significantly higher than those of the general population on the Levels of Emotional Awareness scale. Nevertheless, some limitations are also raised. Several studies highlighted the sensitivity of the LLMs' performance to variations in the prompt formulation  [2]    [5] . LLMs are also found to be biased or limited in various aspects. GPT models found to rate the negative valence to be more negative than humans  [4] . GPT-4 struggled to predict relevance, emotion intensity, and coping responses self-reported by humans and struggled to reason correctly about how emotion has consequences for decisionmaking  [2] .\n\nThe mentioned studies have either used corpora with selfannotated emotions or external observers' annotation as the ground truth. From the first-person perspective, we are bound to rely on participants' memories to recall their feelings from past experiences or their self-assessments in a controlled situation. However, participants often recall intense events or long-lasting emotions and might be unable to report their feelings accurately as they happened in the distant past or contain sequential and varied emotions. The latter approach is also challenging due to the difficulty and the cost of running studies to evoke emotions in controlled settings.\n\nIn the third-person perspective, annotators are expected to predict the emotions of others with the limited available context. Hence, the ground truth represents how participants predict the emotions of others rather than the true experienced emotion. We showed that GPT-4 has essentially learned this general observer's viewpoint. Earlier work has also reported that LLMs are better at approximating \"average human judgments\"  [29] ,  [31] , the \"wisdom of small crowds\"  [30] , or the \"aggregate summary of human knowledge\"  [32]  than they are at capturing variation and human diversity  [33] . Although, at first glance, the third-person perspective might appear as a silver standard, it can offer a level of objectivity and standardization that is challenging to achieve with self-reported data with inherent biases and personal contexts. In the absence of additional individual information and computational models that can reliably account for such individual variability, the third-person perspective is aptly attuned to a more general emotional experience. Furthermore, using third-person data might potentially pose fewer ethical concerns and privacy issues compared to self-reported data, which can be more sensitive and personal. On the other hand, this approach could lead to over-generalization, potentially resulting in reduced diversity and inclusion, and may also perpetuate biases in social perceptions.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Ethical Impact Statement",
      "text": "This paper re-analyzed previously collected de-identified data previously subjected to ethical review. This data is used as a benchmark to scrutinize the underlying mechanisms of how pre-trained language models process human emotion. However, it should be noted that we investigated a single language model, which is constantly being updated; hence, caution must be taken in generalizing these findings to other language models or other versions of the examined model. As predicted by prior research on emotion, strong cultural and demographic differences exist in how emotional situations are construed. Thus, these findings should be replicated across these different groups. Finally, the findings highlight the potential concerns for those seeking to deploy large language models to reason about human emotion or generate emotional content. Given the criticality of potential harm caused by the emotional manipulation of LLMs (or any AI, for that matter), we need constant measurements of LLMs' emotional cognition and manipulation abilities with every new LLM or any updates to current LLMs. We need to have a comprehensive benchmark for such studies.",
      "page_start": 8,
      "page_end": 8
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Example prompt",
      "page": 1
    },
    {
      "caption": "Figure 2: Comparison of human and GPT-4 stimuli classification; (a) human predicted labels, (b) GPT-4 predicted labels, (c) f-1 scores",
      "page": 2
    },
    {
      "caption": "Figure 3: t-SNE plot generated using human and GPT-4 appraisal scores",
      "page": 3
    },
    {
      "caption": "Figure 1: , which includes the narrative each",
      "page": 3
    },
    {
      "caption": "Figure 2: illustrates the performance of GPT-4 the",
      "page": 3
    },
    {
      "caption": "Figure 2: c denotes that GPT-",
      "page": 4
    },
    {
      "caption": "Figure 3: illustrates the t-SNE plot generated using human and",
      "page": 4
    },
    {
      "caption": "Figure 4: GPT-4 vs. human appraisal score probability distribution",
      "page": 4
    },
    {
      "caption": "Figure 4: shows the smoothed rat-",
      "page": 4
    },
    {
      "caption": "Figure 5: denotes impressive similarity between GPT-",
      "page": 4
    },
    {
      "caption": "Figure 5: Inter-correlations of appraisals rated by humans, GPT-4, and the",
      "page": 4
    },
    {
      "caption": "Figure 6: illustrates the smoothed probability distribution of",
      "page": 5
    },
    {
      "caption": "Figure 6: GPT-4 vs. human emotion score probability distribution",
      "page": 5
    },
    {
      "caption": "Figure 7: Human vs. GPT-4 tabular lens model",
      "page": 5
    },
    {
      "caption": "Figure 7: Fig 7 is the tabular version of a lens model [25], which",
      "page": 5
    },
    {
      "caption": "Figure 8: provides a",
      "page": 6
    },
    {
      "caption": "Figure 8: , we see GPT-4 corresponds significantly",
      "page": 6
    },
    {
      "caption": "Figure 8: Comparison of emotion classification and appraisal rating agreement",
      "page": 6
    },
    {
      "caption": "Figure 9: showcases the agreement",
      "page": 6
    },
    {
      "caption": "Figure 8: demonstrates the results of the analysis. Similar to",
      "page": 6
    },
    {
      "caption": "Figure 9: Tabular comparison of agreement across appraisal variables (Krippen-",
      "page": 7
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Feature": "Agent Cause\nSelf Cause\nAlready Occurred\nPressure\nSafety",
          "Value": "0.758***\n0.887***\n0.528***\n0.892***\n0.840***"
        }
      ],
      "page": 4
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Using cognitive psychology to understand GPT-3",
      "authors": [
        "M Binz",
        "E Schulz"
      ],
      "venue": "Proceedings of the National Academy of Sciences",
      "doi": "10.1073/pnas.2218523120"
    },
    {
      "citation_id": "2",
      "title": "Is GPT a Computational Model of Emotion?",
      "authors": [
        "A Tak",
        "J Gratch"
      ],
      "year": "2023",
      "venue": "2023 11th International Conference on Affective Computing and Intelligent Interaction (ACII)",
      "doi": "10.1109/ACII59096.2023.10388119"
    },
    {
      "citation_id": "3",
      "title": "What's Next in Affective Modeling? Large Language Models",
      "authors": [
        "N Yongsatianchot",
        "T Thejll-Madsen",
        "S Marsella"
      ],
      "year": "2023",
      "venue": "11th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos"
    },
    {
      "citation_id": "4",
      "title": "Investigating large language models' perception of emotion using appraisal theory",
      "authors": [
        "N Yongsatianchot",
        "P Torshizi",
        "S Marsella"
      ],
      "year": "2023",
      "venue": "11th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos"
    },
    {
      "citation_id": "5",
      "title": "Fine-grained Affective Processing Capabilities Emerging from Large Language Models",
      "authors": [
        "J Broekens",
        "B Hilpert",
        "S Verberne",
        "K Baraka",
        "P Gebhard",
        "A Plaat"
      ],
      "year": "2023",
      "venue": "11th International Conference on Affective Computing and Intelligent Interaction (ACII)"
    },
    {
      "citation_id": "6",
      "title": "Emotional Intelligence of Large Language Models",
      "authors": [
        "X Wang",
        "X Li",
        "Z Yin",
        "Y Wu",
        "L Jia"
      ],
      "year": "2023",
      "venue": "Emotional Intelligence of Large Language Models",
      "arxiv": "arXiv:2307.09042"
    },
    {
      "citation_id": "7",
      "title": "Is ChatGPT Equipped with Emotional Dialogue Capabilities?",
      "authors": [
        "W Zhao",
        "Y Zhao",
        "X Lu",
        "S Wang",
        "Y Tong",
        "B Qin"
      ],
      "year": "2023",
      "venue": "Is ChatGPT Equipped with Emotional Dialogue Capabilities?",
      "doi": "10.48550/arXiv.2304.09582",
      "arxiv": "arXiv:2304.09582"
    },
    {
      "citation_id": "8",
      "title": "The Inner Sentiments of a Thought",
      "authors": [
        "C Gagne",
        "P Dayan"
      ],
      "year": "2023",
      "venue": "The Inner Sentiments of a Thought",
      "doi": "10.48550/arXiv.2307.01784",
      "arxiv": "arXiv:2307.01784"
    },
    {
      "citation_id": "9",
      "title": "Emotional Expressions Reconsidered: Challenges to Inferring Emotion From Human Facial Movements",
      "authors": [
        "L Barrett",
        "R Adolphs",
        "S Marsella",
        "A Martinez",
        "S Pollak"
      ],
      "year": "2019",
      "venue": "Psychological Science in the Public Interest",
      "doi": "10.1177/1529100619832930"
    },
    {
      "citation_id": "10",
      "title": "Computational Models of Emotion",
      "authors": [
        "S Marsella",
        "J Gratch",
        "P Petta"
      ],
      "year": "2010",
      "venue": "A blueprint for affective computing: A sourcebook and manual"
    },
    {
      "citation_id": "11",
      "title": "Computational Emotion Models: A Thematic Review",
      "authors": [
        "S Ojha",
        "J Vitale",
        "M.-A Williams"
      ],
      "year": "2021",
      "venue": "International Journal of Social Robotics",
      "doi": "10.1007/s12369-020-00713-1"
    },
    {
      "citation_id": "12",
      "title": "The Cognitive Structure of Emotions",
      "authors": [
        "A Ortony",
        "G Clore",
        "A Collins"
      ],
      "year": "1988",
      "venue": "The Cognitive Structure of Emotions"
    },
    {
      "citation_id": "13",
      "title": "Handbook of cognition and emotion",
      "authors": [
        "K Scherer"
      ],
      "year": "2005",
      "venue": "Handbook of cognition and emotion"
    },
    {
      "citation_id": "14",
      "title": "The CognitiveEvolutionary Model of Surprise: A Review of the Evidence",
      "authors": [
        "R Reisenzein",
        "G Horstmann",
        "A Schützwohl"
      ],
      "year": "2017",
      "venue": "Topics in Cognitive Science",
      "doi": "10.1111/tops.12292"
    },
    {
      "citation_id": "15",
      "title": "Emotion and adaptation",
      "authors": [
        "R Lazarus"
      ],
      "year": "1991",
      "venue": "Emotion and adaptation"
    },
    {
      "citation_id": "16",
      "title": "Reading people's minds from emotion expressions in interdependent decision making",
      "authors": [
        "C De Melo",
        "P Carnevale",
        "S Read",
        "J Gratch"
      ],
      "year": "2014",
      "venue": "Journal of personality and social psychology"
    },
    {
      "citation_id": "17",
      "title": "The reverse engineering of emotions-observers of others' emotions as naïve personality psychologists",
      "authors": [
        "S Hareli",
        "U Hess"
      ],
      "year": "2019",
      "venue": "The reverse engineering of emotions-observers of others' emotions as naïve personality psychologists"
    },
    {
      "citation_id": "18",
      "title": "Is GPT a Computational Model of Emotion? Detailed Analysis",
      "authors": [
        "A Tak",
        "J Gratch"
      ],
      "year": "2023",
      "venue": "Is GPT a Computational Model of Emotion? Detailed Analysis",
      "doi": "10.48550/arXiv.2307.13779",
      "arxiv": "arXiv:2307.13779"
    },
    {
      "citation_id": "19",
      "title": "GPT-4 technical report",
      "authors": [
        "Openai"
      ],
      "year": "2023",
      "venue": "GPT-4 technical report",
      "arxiv": "arXiv:2303.08774"
    },
    {
      "citation_id": "20",
      "title": "Neural representations of emotion are organized around abstract event features",
      "authors": [
        "A Skerry",
        "R Saxe"
      ],
      "year": "2015",
      "venue": "Current biology"
    },
    {
      "citation_id": "21",
      "title": "What i s Folk Psychology?",
      "authors": [
        "S Stephen",
        "R Ian"
      ],
      "year": "1994",
      "venue": "Cognition"
    },
    {
      "citation_id": "22",
      "title": "Human Emotion Experiences Can Be Predicted on Theoretical Grounds: Evidence from Verbal Labeling",
      "authors": [
        "K Scherer",
        "B Meuleman"
      ],
      "year": "2013",
      "venue": "PLoS ONE"
    },
    {
      "citation_id": "23",
      "title": "Dimensional Modeling of Emotions in Text with Appraisal Theories: Corpus Creation, Annotation Reliability, and Prediction",
      "authors": [
        "E Troiano",
        "L Oberländer",
        "R Klinger"
      ],
      "year": "2023",
      "venue": "Computational Linguistics",
      "doi": "10.1162/colia00461"
    },
    {
      "citation_id": "24",
      "title": "What are emotions? And how can they be measured?",
      "authors": [
        "K Scherer"
      ],
      "year": "2005",
      "venue": "Social Science Information",
      "doi": "10.1177/0539018405058216"
    },
    {
      "citation_id": "25",
      "title": "Perception and the representative design of psychological experiments",
      "authors": [
        "E Brunswik"
      ],
      "year": "1956",
      "venue": "Perception and the representative design of psychological experiments"
    },
    {
      "citation_id": "26",
      "title": "Driving the emotion process: The Appraisal component",
      "authors": [
        "K Scherer",
        "J Fontaine"
      ],
      "year": "2013",
      "venue": "Driving the emotion process: The Appraisal component",
      "doi": "10.1093/acprof:oso/9780199592746.003.0013"
    },
    {
      "citation_id": "27",
      "title": "Answering the call for a standard reliability measure for coding data",
      "authors": [
        "A Hayes",
        "K Krippendorff"
      ],
      "year": "2007",
      "venue": "Communication methods and measures"
    },
    {
      "citation_id": "28",
      "title": "ChatGPT outperforms humans in emotional awareness evaluations",
      "authors": [
        "Z Elyoseph",
        "D Hadar-Shoval",
        "K Asraf",
        "M Lvovsky"
      ],
      "venue": "Frontiers in Psychology"
    },
    {
      "citation_id": "29",
      "title": "Can AI language models replace human participants?",
      "authors": [
        "D Dillion",
        "N Tandon",
        "Y Gu",
        "K Gray"
      ],
      "year": "2023",
      "venue": "Trends in Cognitive Sciences"
    },
    {
      "citation_id": "30",
      "title": "Large Language Models and the Wisdom of Small Crowds",
      "authors": [
        "S Trott"
      ],
      "year": "2024",
      "venue": "Open Mind"
    },
    {
      "citation_id": "31",
      "title": "Whose opinions do language models reflect?",
      "authors": [
        "S Santurkar",
        "D Esin",
        "L Faisal",
        "L Cinoo",
        "L Percy",
        "H Tatsunori"
      ],
      "year": "2023",
      "venue": "International Conference on Machine Learning"
    },
    {
      "citation_id": "32",
      "title": "GPT-ology, Computational Models",
      "authors": [
        "D Ong"
      ],
      "venue": "Silicon Sampling: How should we think about LLMs in Cognitive Science?\". 2024",
      "arxiv": "arXiv:2406.09464"
    },
    {
      "citation_id": "33",
      "title": "Perils and opportunities in using large language models in psychological research",
      "authors": [
        "S Abdurahman",
        "M Atari",
        "F Karimi-Malekabadi",
        "M Xue",
        "J Trager",
        "P Park",
        "P Golazizian",
        "A Omrani",
        "M Dehghani"
      ],
      "venue": "Perils and opportunities in using large language models in psychological research"
    }
  ]
}