{
  "paper_id": "2509.20153v2",
  "title": "Affective Computing And Emotional Data: Challenges And Implications In Privacy Regulations, The Ai Act, And Ethics In Large Language Models",
  "published": "2025-09-24T14:18:41Z",
  "authors": [
    "Nicola Fabiano"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "This paper examines the integration of emotional intelligence into artificial intelligence systems, with a focus on affective computing and the growing capabilities of Large Language Models (LLMs), such as ChatGPT and Claude, to recognize and respond to human emotions. Drawing on interdisciplinary research that combines computer science, psychology, and neuroscience, the study analyzes foundational neural architectures-CNNs for processing facial expressions and RNNs for sequential data, such as speech and text-that enable emotion recognition. It examines the transformation of human emotional experiences into structured emotional data, addressing the distinction between explicit emotional data collected with informed consent in research settings and implicit data gathered passively through everyday digital interactions. That raises critical concerns about lawful processing, AI transparency, and individual autonomy over emotional expressions in digital environments. The paper explores implications across various domains, including healthcare, education, and customer service, while addressing challenges of cultural variations in emotional expression and potential biases in emotion recognition systems across different demographic groups. From a regulatory perspective, the paper examines emotional data in the context of the GDPR and the EU AI Act frameworks, highlighting how emotional data may be considered sensitive personal data that requires robust safeguards, including purpose limitation, data minimization, and meaningful consent mechanisms. The case study of OpenAI's ChatGPT-4.5, which incorporates improved emotional intelligence capabilities, exemplifies advances in emotionally responsive AI while illustrating the complexity of ensuring the ethical deployment of such systems. The paper concludes by proposing a multidimensional governance framework that integrates technical scrutiny with legal and ethical analysis, emphasizing multi-stakeholder collaboration to safeguard human dignity, autonomy, and rights in the digital age of emotionally aware AI systems.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "The evolution of artificial intelligence (AI) has witnessed a significant shift from systems designed primarily for logical reasoning and task execution to those capable of recognizing, interpreting, and responding to human emotions. This transformation represents a significant advancement in human-computer interaction, as it addresses the emotional dimension of communication that has been traditionally absent from digital interfaces. The field of affective computing, first conceptualized by Rosalind Picard in the late 1990s, has now emerged as a cornerstone of modern AI development, particularly in the realm of Large Language Models (LLMs) such as ChatGPT, Claude, and other conversational agents  (Picard, 1997) .\n\nIntegrating emotional intelligence into AI systems carries profound implications for various domains, including healthcare, education, customer service, and personal assistance. By recognizing emotional states, AI systems can provide more personalized, empathetic, and contextually appropriate responses, potentially enhancing user satisfaction and overall effectiveness. However, this capability also introduces complex challenges related to privacy, consent, data protection, and the fundamental nature of human-AI relationships.\n\nThis paper examines the technological underpinnings, regulatory considerations, and ethical implications of emotionally intelligent AI systems. We begin by examining the neural network architectures that enable machines to process emotional cues, followed by an analysis of how human emotions are transformed into structured data. Subsequently, we investigate the regulatory frameworks governing emotional data, with a focus on the European Union's General Data Protection Regulation (GDPR) and the EU Artificial Intelligence Act. Using the case study of OpenAI's ChatGPT-4.5, we illustrate the practical implications of these advancements. Ultimately, we propose a multidimensional governance approach that strikes a balance between technological innovation and the protection of human dignity and autonomy.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Affective Computing: Technical Foundations And Evolution",
      "text": "",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "The Evolution Of Affective Computing",
      "text": "Affective computing emerged as a distinct field of research in 1997, when MIT Media Lab professor Rosalind Picard published her seminal work, \"Affective Computing,\" which defined the discipline as \"computing that relates to, arises from, or deliberately influences emotions\"  (Picard, 1997) . This multidisciplinary domain integrates concepts from computer science, psychology, neuroscience, and cognitive science to create systems that can detect, understand, and respond to human emotions.\n\nThe evolution of affective computing can be traced through several key developmental phases. Initial efforts in the 1990s and early 2000s focused on identifying basic emotions from facial expressions and vocal patterns using rule-based systems and simple machine learning algorithms. These systems typically operate with predefined emotional categories based on Paul Ekman's six basic emotions: happiness, sadness, anger, fear, disgust, and surprise  (Ekman, 1992) . As research progressed into the 2000s and 2010s, scientists recognized that human emotional expression involves multiple channels. This led to the development of systems that combined facial, vocal, textual, and physiological data for more robust emotion recognition. This period witnessed the creation of multimodal datasets, such as IEMOCAP (\"Interactive Emotional Dyadic Motion Capture\" -  Busso et al., 2008)  and SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal Expression\" -  McKeown et al., 2012) , which facilitated advances in multimodal emotion recognition.\n\nThe advent of deep learning techniques in the 2010s transformed affective computing, enabling more accurate recognition of subtle emotional cues and complex emotional states. Convolutional Neural Networks (CNNs) transformed facial expression analysis, whereas Recurrent Neural Networks (RNNs), followed by Transformer architectures, brought substantial advancements in recognizing emotions from text and speech. From 2015 onward, research shifted toward context-aware systems that consider situational factors, individual differences, cultural variations, and interaction history when interpreting emotional signals and generating responses. Most recently, from 2020 to the present, the emergence of sophisticated LLMs has accelerated the development of emotionally intelligent AI systems that can engage in nuanced emotional conversations, recognize implicit emotional cues in text, and generate contextually appropriate emotional responses.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Neural Network Architectures For Emotion Recognition",
      "text": "The ability of AI systems to recognize and process emotional data relies primarily on two neural network architectures: Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs), as well as more recent Transformer-based models. These architectures serve distinct but complementary functions in analyzing different emotional cues.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Convolutional Neural Networks (Cnns)",
      "text": "CNNs have revolutionized the field of computer vision through their hierarchical structure, which enables the extraction of increasingly complex features from visual data  (LeCun et al., 2015) . In the context of emotion recognition, CNNs are particularly effective for processing facial expressions, a primary channel of emotional communication among humans. These networks apply convolutional filters across image inputs, detecting patterns such as edge orientations, textures, and higher-level features corresponding to specific emotional expressions.\n\nThe effectiveness of CNNs in emotion recognition is exemplified by models such as FER2013 (Facial Expression Recognition) and EmotioNet, which achieve accuracy rates exceeding 70% in classifying basic emotions from facial images  (Goodfellow et al., 2013; Fabian Benitez-Quiroz et al., 2016) . Moreover, advanced architectures like ResNet and EfficientNet have enhanced performance through deeper networks with residual connections and optimized scaling methods  (He et al., 2016; Tan & Le, 2019) .\n\nThe application of CNNs extends beyond static image analysis to dynamic facial expressions in video streams, where temporal convolutional networks (TCNs) can capture the evolution of expressions over time. This capability is crucial for detecting subtle emotional transitions and distinguishing between genuine and feigned expressions, a distinction that often depends on temporal dynamics  (Ekman & Friesen, 1982) .",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Recurrent Neural Networks (Rnns) And Transformers",
      "text": "While CNNs excel at processing spatial data, RNNs are designed to handle sequential information, making them ideal for analyzing temporal aspects of emotional expression in speech, text, and physiological signals  (Hochreiter & Schmidhuber, 1997) . The distinctive feature of RNNs is their internal memory, which enables them to maintain context across sequential inputs -a characteristic essential for understanding emotions that unfold and evolve.\n\nVariants of RNNs, including Long Short-Term Memory (LSTM) networks and Gated Recurrent Units (GRUs), have demonstrated remarkable success in sentiment analysis and emotion recognition from textual and audio data. For instance, DeepMoji, an LSTM-based model trained on a dataset of 1.2 billion tweets containing emojis, achieves state-of-the-art performance in detecting emotions and sentiment in text  (Felbo et al., 2017) .\n\nRecently, Transformer architectures have surpassed traditional RNNs in many natural language processing tasks, including emotion recognition. Models such as BERT (Bidirectional Encoder Representations from Transformers) and its successors leverage attention mechanisms to capture subtle emotional nuances in text by dynamically assessing the contextual relevance of words  (Devlin et al., 2019) . This ability is beneficial for interpreting complex emotional states that are conveyed implicitly, rather than through direct emotional language.\n\nThe latest generation of LLMs, including GPT-4 and Claude, builds upon these Transformer architectures, incorporating vast amounts of textual data that enable them to recognize and respond to emotional cues with unprecedented sophistication. These models can detect basic emotions and complex emotional states, as well as cultural variations in emotional expression and contextual factors that influence emotional interpretation.",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "Multimodal Approaches To Emotion Recognition",
      "text": "Human emotional expression is inherently multimodal, involving a combination of facial expressions, vocal intonations, linguistic choices, body language, and physiological responses. Recognizing this complexity, contemporary AI systems are increasingly adopting multimodal approaches that integrate information from multiple channels to achieve more robust and accurate emotion recognition.\n\nMultimodal fusion techniques combine data from different modalities at various processing levels. Early fusion approaches concatenate raw data from other modalities before feature extraction, allowing the model to learn joint representations directly from the multimodal input. Late fusion methods process each modality independently through separate models, and their predictions are combined at the decision level through weighted averaging or voting methods. Hybrid fusion techniques combine early and late fusion elements, with intermediate features from different modalities being integrated at multiple levels throughout the processing pipeline.\n\nResearch has consistently demonstrated that multimodal approaches outperform unimodal methods in emotion recognition tasks. For example, the IEMOCAP (Interactive Emotional Dyadic Motion Capture) dataset, which includes audio, visual, and textual information from acted emotional scenes, has been used to develop models that achieve accuracy improvements of up to 10% when using multimodal versus unimodal approaches  (Busso et al., 2008) .\n\nRecent advancements in multimodal learning include cross-modal attention mechanisms, which allow models to selectively focus on relevant information across modalities, and contrastive learning techniques that align representations from different modalities in a shared embedding space. These methods are particularly valuable for handling the inherent asynchrony and complementarity of emotional cues across various channels.\n\n3. Emotional Data: Conceptualization, Collection, and Processing",
      "page_start": 5,
      "page_end": 6
    },
    {
      "section_name": "Conceptualizing Emotional Data",
      "text": "The concept of \"emotional data\" represents a significant departure from traditional data types in computing. Unlike factual information, emotional data encompasses subjective, experiential, and often ambiguous aspects of human emotional states. This transformation -from lived emotional experiences to structured, machine-processable data -raises fundamental questions about the nature of emotions and the extent to which they can be captured and represented digitally.\n\nEmotional data can be categorized in several ways. First, we can distinguish between explicit and implicit emotional data. The transformation of emotions into data necessarily involves simplification and abstraction, potentially obscuring the richness and complexity of human emotional experience. As  Barrett (2017)  noted, emotions are not singular, universal phenomena but constructed experiences influenced by cultural, social, and individual factors. This perspective challenges the notion that emotions can be reduced to discrete, objective data points without significant loss of meaning.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Methods Of Emotional Data Collection",
      "text": "The collection of emotional data employs various methodologies, each with distinct strengths, limitations, and ethical implications. Direct self-report methods include questionnaires, experience sampling methods (ESM), and ecological momentary assessment (EMA), in which individuals directly report their emotional states. While these methods provide valuable insights into subjective experiences, they are subject to limitations such as social desirability bias, recall errors, and variations in emotional vocabulary and awareness across individuals  (Robinson & Clore, 2002) . Digital implementations of self-report measures, such as moodtracking applications and emotion rating systems, facilitate the continuous collection of emotional data in naturalistic settings. However, the frequency and intrusiveness of such measures must be balanced against user burden and potential reactivity effects, where reporting emotions influences the emotional experience itself.\n\nObservational approaches capture behavioral manifestations of emotions without requiring explicit reporting from individuals. These methods encompass facial expression analysis, utilizing computer vision techniques to detect and classify facial expressions based on the Facial Action Coding System (FACS) or deep learning approaches. They also include voice analysis, extracting acoustic features such as pitch, tempo, and spectral characteristics to identify emotional cues in speech. Text analysis employs natural language processing techniques to identify emotional content in written communications, encompassing sentiment analysis, emotion classification, and stance detection. Physiological measurements monitor autonomic nervous system responses such as heart rate variability, electrodermal activity, and respiratory patterns, which correlate with emotional states. Additionally, behavioral metrics track user interactions with digital systems, including click patterns, dwell times, and navigation behaviors, which may reflect emotional engagement or frustration.\n\nThe context in which emotional data is collected significantly influences both the nature of the data and the ethical considerations surrounding its use. Emotional data is typically collected in controlled research environments, where explicit informed consent, clear protocols, and institutional oversight are in place. Participants are generally aware of the specific data and how it will be used. Consumer-facing products, however, may collect emotional data through various channels, sometimes without users' full awareness or understanding. This data may be used for personalization, engagement optimization, or marketing. Ambient intelligence environments, such as smart homes, workplaces, and public spaces, increasingly incorporate sensors that can passively collect data indicative of emotional states, often without requiring active user participation in the data collection process. Social media sites, forums, and other digital platforms generate vast repositories of emotional data through user-generated content, engagement metrics, and interaction patterns.\n\nThe distinction between explicit and implicit collection contexts has profound implications for consent, transparency, and user autonomy. While users in research settings typically provide informed consent for specific data collection activities, users of commercial products or public spaces may have limited awareness of emotional data collection and few opportunities to consent or opt out meaningfully.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Representation And Processing Of Emotional Data",
      "text": "Once collected, emotional data undergoes various transformations to facilitate machine processing and analysis. Emotional data may be represented in multiple formats depending on the source and intended application. Feature vectors provide numerical representations of extracted features, such as facial landmark coordinates, acoustic parameters, or linguistic features. Categorical labels classify emotions into predefined categories (e.g., Ekman's six basic emotions: happiness, sadness, fear, disgust, anger, and surprise). Dimensional coordinates position emotional states in multidimensional spaces, most commonly the valence-arousal-dominance (VAD) model. Time-series data captures the dynamics of emotional expression over time, including onset, peak, and decay patterns. Probability distributions represent uncertainty or ambiguity in emotional classification, acknowledging that emotional states often involve blends or transitions between prototypical emotions.\n\nThe processing of emotional data typically involves several stages. Preprocessing encompasses cleaning, normalizing, and aligning raw data, including noise reduction, artifact removal, and temporal synchronization across modalities. Feature extraction identifies relevant attributes that convey emotional information, utilizing handcrafted features informed by domain knowledge and learned features derived through representation learning techniques. Fusion integrates information from multiple sources or modalities to create comprehensive emotional profiles. Classification or regression applies machine learning algorithms to categorize or position emotional states along continuous dimensions. Inter-pretation contextualizes emotional data within broader user profiles, interaction histories, or situational factors to derive meaningful insights. Finally, response generation formulates system responses based on recognized emotional states, potentially incorporating empathetic language, adaptive interface elements, or personalized content.",
      "page_start": 7,
      "page_end": 8
    },
    {
      "section_name": "Regulatory Frameworks For Emotional Data",
      "text": "",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Gdpr And Emotional Data Classification",
      "text": "The European Union's General Data Protection Regulation (GDPR) provides one of the most comprehensive frameworks for understanding the legal status of emotional data. However, it does not explicitly address this category. Several provisions are particularly relevant to handling emotional data in AI systems.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Emotional Data As Personal Data",
      "text": "The GDPR defines personal data as \"any information relating to an identified or identifiable natural person ('data subject')\" (Article 4(1)). Emotional data falls within this broad definition, as it relates directly to an individual's internal states and can often be linked to specific persons. Consequently, the collection and processing of emotional data must adhere to the general data protection principles established in the regulation.\n\nThe principle of lawfulness, fairness, and transparency (Article 5(1)(a)) requires that processing must be based on a legitimate legal ground, conducted fairly, and transparently disclosed to the data subject. For emotional data, this principle demands clear communication about when and how emotional states are being analyzed, a particularly challenging requirement given the often implicit nature of emotional data collection in modern systems.\n\nPurpose limitation (Article 5(1)(b)) stipulates that personal data must be collected for specified, explicit, and legitimate purposes and not further processed in a manner incompatible with those purposes. This principle restricts repurposing emotional data collected for one service (personalization) for unrelated purposes (such as targeted advertising based on emotional vulnerabilities).\n\nData minimization (Article 5(1)(c)) states that personal data shall be \"adequate, relevant and limited to what is necessary in relation to the purposes for which they are processed ('data minimisation')\". This principle challenges the common practice of broad emotional data collection that exceeds functional requirements, often justified by potential future applications or system improvements.\n\nAccuracy (Article 5(1)(d)) requires that personal data shall be \"accurate and, where necessary, kept up to date; every reasonable step must be taken to ensure that personal data that are inaccurate, having regard to the purposes for which they are processed, are erased or rectified without delay ('accuracy')\". This principle is particularly challenging for emotional data, given the inherent subjectivity of emotional interpretation and the potential for misclassification across different demographic groups or cultural contexts.\n\nStorage limitation (Article 5(1)(e)) dictates that personal data should be \"kept in a form that permits the identification of data subjects for no longer than necessary for the purposes for which the personal data are processed \". This principle challenges the indefinite retention of emotional profiles, which may become increasingly comprehensive and invasive over time.\n\nIntegrity and confidentiality (Article 5(1)(f)) mandate that personal data shall be \"processed in a manner that ensures appropriate security of the personal data, including protection against unauthorised or unlawful processing and against accidental loss, destruction or damage, using appropriate technical or organisational measures ('integrity and confidentiality')\". This principle acknowledges the sensitive nature of emotional information and the potential harm that can result from unauthorized access or disclosure.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Emotional Data As Special Category Data",
      "text": "More significantly, emotional data may qualify as \"special category data\" under Article 9 of the GDPR, which includes \"data concerning health\" and potentially \"biometric data to uniquely identify a natural person.\" This classification is particularly relevant when emotional data is derived from physiological measurements that reveal information about mental health conditions, used to infer psychological characteristics or behavioral patterns, collected through biometric methods such as facial expression analysis, or can reveal sensitive aspects of an individual's identity or condition.\n\nIf classified as unique category data, emotional data processing would be prohibited unless a specific exception applies, such as explicit consent (Article 9(2)(a)) or when processing is necessary for scientific research purposes, subject to appropriate safeguards (Article 9(2)(j)). This heightened level of protection recognizes the intimate nature of emotional information and its potential to reveal deeply personal aspects of an individual's life and identity.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Legal Basis For Processing Emotional Data",
      "text": "Under the GDPR, any processing of personal data, including emotional data, requires a lawful basis. Several potential bases may apply for emotional data, each with distinct implications for designing and deploying emotionally intelligent systems.\n\nConsent (Article 6(1)(a)) requires that the data subject has given clear, specific, informed, and unambiguous consent to the processing of their emotional data. While seemingly straightforward, obtaining meaningful consent for the processing of emotional data faces significant challenges. Users may struggle to understand the full implications of emotional analysis, mainly when the technology operates invisibly or implicitly. Furthermore, the power imbalances between individuals and technology providers may undermine the voluntary nature of consent, particularly when emotional analysis is embedded in essential services or platforms.\n\nLegitimate interests (Article 6(1)(f)) states: \"processing is necessary for the purposes of the legitimate interests pursued by the controller or by a third party, except where such interests are overridden by the interests or fundamental rights and freedoms of the data subject which require protection of personal data, in particular where the data subject is a child \". This basis requires a careful balancing test that weighs the benefits of emotional analysis against potential harm to individual rights and freedoms. The intimate and potentially revealing nature of emotional data may often tip this balance toward more effective protection of personal interests, especially in commercial applications where the primary legitimate interest is profit-driven rather than welfare-enhancing.\n\nAccording to Article 6(1)(b), \"processing is necessary for the performance of a contract to which the data subject is party or in order to take steps at the request of the data subject prior to entering into a contract\". That case might be when the user explicitly requests an emotionally responsive service. This basis is most applicable when emotional analysis forms a core function of the service rather than an ancillary feature and when emotional responsiveness is communicated as part of the service offering.\n\nIn the case of research purposes (Article 6(1)(e), in conjunction with Article 89), processing is lawful when it is \"necessary for the performance of a task carried out in the public interest or in the exercise of official authority vested in the controller \". This basis supports the advancement of affective computing research while requiring measures such as data minimization, pseudonymization, and ethical review to protect participant interests.\n\nExplicit consent would typically be required for special category emotional data, with higher standards of specificity and clarity than those needed for standard consent. Alternative legal bases for unique category data include substantial public interest or scientific research purposes, provided that appropriate safeguards are in place. However, these exceptions are interpreted narrowly and are subject to additional requirements.",
      "page_start": 9,
      "page_end": 10
    },
    {
      "section_name": "The Eu Artificial Intelligence Act And Emotional Recognition",
      "text": "The European Union Artificial Intelligence Act represents a significant advancement in regulating AI systems, with specific provisions relevant to emotional analysis and affective computing. The AI Act adopts a risk-based approach, categorizing AI systems based on potential harm. Systems posing unacceptable risks are prohibited entirely, including those that deploy subliminal techniques to manipulate behavior in a harmful way. Highrisk systems with a significant potential impact on health, safety, or fundamental rights are subject to stringent requirements before market introduction. Limited risk systems, including emotion recognition systems, have specific transparency obligations. Systems with minimal risk are subject to limited or no regulation under the Act.\n\nUnder the AI Act, emotion recognition systems are addressed explicitly in Article 50(3), which states: \"Deployers of an emotion recognition system or a biometric categorisation system shall inform the natural persons exposed thereto of the operation of the system, and shall process the personal data in accordance with Regulations (EU) 2016/679 and (EU) 2018/1725 and Directive (EU) 2016/680, as applicable. This obligation shall not apply to AI systems used for biometric categorisation and emotion recognition, which are permitted by law to detect, prevent or investigate criminal offences, subject to appropriate safeguards for the rights and freedoms of third parties, and in accordance with Union law \". This provision establishes a clear transparency obligation for developers and deployers of emotion recognition systems, requiring them to explicitly disclose to individuals when such systems are in use. This represents a significant advancement over previous regulatory frameworks, which did not specifically address emotion recognition technologies.\n\nIf an emotion recognition system is classified as high-risk -such as when used in employment, education, or law enforcement contexts -it would be subject to additional requirements under the AI Act. These requirements include implementing a risk management system that identifies and mitigates risks throughout the system's lifecycle, as well as establishing data governance protocols. This ensures that training, validation, and testing datasets meet quality criteria, including relevance, representativeness, accuracy, and completeness. High-risk systems must also maintain comprehensive technical documentation that details the system's development, functionality, and compliance with requirements. The automatic logging of the AI system's operation must be kept for record-keeping purposes. To ensure transparency, users must have clear information about the system's capabilities, limitations, and intended purpose. Human oversight measures must be implemented to ensure humans can effectively supervise the system. Ultimately, the system must achieve the necessary accuracy, robustness, and cybersecurity levels, including resilience to errors and protection against unauthorized access.\n\nThe AI Act prohibits certain practices, particularly relevant to emotion recognition and manipulation. These include AI systems that deploy subliminal techniques beyond a person's conscious awareness to distort behavior that causes physical or psychological harm. Systems that exploit vulnerabilities of specific groups based on age, disability, or social or economic situation to materially distort behavior in a harmful way are also prohibited. Additionally, the Act prohibits social scoring by public authorities, which involves evaluating or classifying individuals based on their social behavior or personal characteristics, potentially leading to detrimental or unfavorable treatment in unrelated social contexts. These prohibitions provide necessary guardrails against the most harmful potential applications of emotional intelligence in AI systems, particularly those that might exploit emotional vulnerabilities for manipulative purposes.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Other Relevant Regulatory Frameworks",
      "text": "Beyond the GDPR and AI Act, several other regulatory frameworks have implications for emotional data and affective computing. Biometric privacy regulations at the state level, including the Illinois Biometric Information Privacy Act (BIPA), impose specific requirements for collecting and processing biometric identifiers and biometric information. These laws typically require informed written consent before the collection, disclosure of the purpose, and the length of term for which the data will be collected, stored, and used, as well as a publicly available written policy establishing a retention schedule and guidelines for destruction. As emotionally intelligent AI systems increasingly rely on biometric methods for emotion recognition, compliance with these specialized privacy laws becomes increasingly relevant.\n\nConsumer protection authorities have begun addressing the collection of emotional data in commercial contexts.\n\nIn healthcare contexts, emotional data may be subject to specialized health information privacy laws such as the Health Insurance Portability and Accountability Act (HIPAA) in the United States. These regulations impose strict requirements on collecting, using, and disclosing protected health information, which could include emotional data when used for health-related purposes such as mental health assessment or monitoring.\n\nSpecialized protections for children's data, such as the Children's Online Privacy Protection Act (COPPA) in the United States and provisions within the GDPR (Article 8), place additional restrictions on collecting and processing data from children. These protections are particularly relevant to emotional data, given children's potentially heightened vulnerability to emotional analysis and manipulation.\n\n4.2 Case Study: ChatGPT-4.5 and Emotional Intelligence",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Emotion Recognition In Text",
      "text": "OpenAI's release of ChatGPT-4.5 in late 2023 marked a significant advancement in the emotional intelligence capabilities of large language models.\n\nChatGPT-4.5 employs several techniques to recognize emotional content in user inputs.\n\nThe model identifies the overall positive, negative, or neutral sentiment expressed in the text, providing a foundational layer of emotional awareness. Beyond basic sentiment, it categorizes text into specific emotional categories, including primary emotions (joy, sadness, anger, fear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The system assesses the strength or intensity of expressed emotions, distinguishing between mild annoyance and intense rage, for example. It also interprets emotional content within a conversational context, recognizing how emotions evolve throughout an interaction and how prior exchanges inform current emotional states. Beyond explicit emotional statements, the model identifies implicit emotional cues, including sarcasm, passive aggression, excitement, and uncertainty conveyed through word choice, syntax, and stylistic elements.\n\nThese capabilities are implemented through supervised learning on annotated emotional data, such as Reinforcement Learning from Human Feedback (RLHF) in Machine Learning, which prioritizes emotionally appropriate responses, and few-shot learning that enables adaptation to individual users' emotional expression patterns.",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Emotional Response Generation",
      "text": "ChatGPT-4.5's response generation incorporates emotional intelligence through several mechanisms. The model can calibrate its response tone to match the user's emotional state, validating and recognizing expressed emotions through empathetic mirroring. For users expressing distress, the model offers responses designed to facilitate healthy emotional processing, including validation, normalization, reframing, and resource suggestion as part of emotional regulation support. The system modulates emotional content based on conversation context, distinguishing between scenarios where emotional engagement is beneficial versus situations requiring more neutral, factual responses. Through conversation history, the model develops user-specific emotional profiles that inform future interactions, allowing for more personalized emotional support. The model also adapts its emotional responses based on cultural contexts, recognizing variations in emotional display rules, expression norms, and values across different cultural backgrounds.",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "Regulatory Compliance And Ethical Considerations",
      "text": "OpenAI has not implemented user interface elements that indicate real-time emotional analysis, nor are there visual cues, confidence indicators for emotional inferences, or specific disclosures on the emotional interpretability of the model's outputs. The \"About\" section in the ChatGPT interface provides general information about the system's capabilities, limitations, and safety measures. Still, it does not provide detailed guidance or transparency regarding the processing of emotional data.\n\nOpenAI's current privacy approach includes standard user data handling mechanisms, such as data deletion via user controls and retention policies aligned with privacy laws like the GDPR and CCPA. However, there is no publicly documented system of layered consent specifically for emotional data processing, nor is there a separate framework for specifying purposes, managing emotional profiles, or implementing age-specific emotional safeguards. The platform allows users to delete individual conversations, which may include sensitive content; however, this is not tied to a distinct emotional data processing framework.\n\nTo date, OpenAI has not disclosed using on-device emotional analysis or local processing options to minimize cloud-based data handling for emotional content. Additionally, while OpenAI incorporates differential privacy and other techniques in research and model training contexts, these techniques are not explicitly documented as being applied to emotional pattern extraction or anonymized emotional profiles.\n\nDespite the absence of native emotional intelligence systems, the broader emergence of emotionally responsive AI, including third-party applications built on top of large language models, has sparked widespread discussions on ethics and regulation. Scholars, privacy advocates, and ethicists have raised concerns about the potential for emotionally interactive systems to manipulate users, particularly in commercial or political settings. The simulation of empathy by AI has sparked debates about deception, authenticity, and the psychological implications of human-AI interactions. Mental health professionals have warned against overreliance on AI for emotional support, citing the limitations of machine systems in terms of clinical judgment, empathy, and ethical oversight. Due to its intimate and potentially revealing nature, privacy experts argue that emotional data may warrant special protection.\n\nAdditionally, labor theorists have suggested that emotionally interactive systems risk extracting emotional labor from users -data that helps refine model responsivenesswithout compensation or acknowledgment.\n\nOn February 27, 2025, OpenAI released a research preview of OpenAI GPT-4.5 (OpenAI GPT-4.5 System Card), and in the related communication, among other things, it is stated:\n\n«Early testing shows that interacting with GPT-4.5 feels more natural. Its broader knowledge base, stronger alignment with user intent, and improved emotional intelligence make it well-suited for tasks like writing, programming, and solving practical problems-with fewer hallucinations.».\n\nTwo fundamental aspects emerge from the communication above. First, the improvement of emotional intelligence is highlighted, and the term \"improvement\" is very significant. This is precisely to emphasize that this is not an absolute novelty, but rather an existing feature subject to further experimentation. Therefore, the ChatGPT AI system has been enhanced to improve its emotional profile, which should lead users to a better understanding of the requests made to the LLM system and the responses provided by it. Second, OpenAI also states that hallucinations have been reduced in the new 4.5 version of ChatGPT (refer to the section on LLMs for a description of this phenomenon). Hallucinations are one of the primary risks associated with LLMs, as they generate output that cannot be found in reality; often, the content does not exist and is an invention of the system.",
      "page_start": 12,
      "page_end": 13
    },
    {
      "section_name": "Ethical Frameworks And Governance For Emotional Ai",
      "text": "",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "Ethical Principles For Emotionally Intelligent Ai -Autonomy And Dignity",
      "text": "A comprehensive governance framework should explicitly incorporate ethical principles that address the unique characteristics of emotionally intelligent systems.\n\nEmotionally intelligent AI should respect human autonomy and dignity by preserving individual control over emotional expression and its implications. This principle requires that systems avoid manipulative techniques that exploit emotional vulnerabilities, thereby undermining authentic agency. Respecting the authenticity of emotional experience and communication means acknowledging that emotions represent a core aspect of human identity and experience, not merely data to be extracted and optimized. Systems should provide transparent information about their emotional capabilities and limitations, enabling users to understand the nature of their interaction with emotionally responsive AI. Furthermore, meaningful opt-out options for emotional analysis must be available, allowing individuals to engage with AI systems without subjecting their emotional expressions to algorithmic processing. These provisions collectively safeguard the fundamental human dignity intimately connected to emotional authenticity and self-determination.",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "Beneficence And Non-Maleficence",
      "text": "AI systems with emotional capabilities should prioritize user well-being in emotional interactions, aiming to enhance emotional health rather than merely maximize engagement or commercial objectives. This requires careful attention to avoid exacerbating negative emotional states or mental health conditions, which could occur through inappropriate reinforcement, amplification, or exploitation of distress. Developers must recognize the limits of automated emotional support, acknowledging that AI systems cannot fully replace human connection, therapeutic expertise, or contextual understanding in addressing complex emotional needs. Appropriate safeguards for vulnerable users-including individuals experiencing acute psychological distress, those with mental health conditions, and those with limited digital literacy-must be integrated into system design and deployment. Furthermore, ethical guidelines for responding to concerning emotional content, such as expressions of self-harm or suicidal ideation, should be developed in collaboration with mental health professionals and implemented consistently across platforms. These principles ensure that emotional AI is a beneficial complement to human emotional support rather than a potentially harmful substitute.",
      "page_start": 14,
      "page_end": 14
    },
    {
      "section_name": "Justice And Fairness",
      "text": "Ethical deployment of emotional AI requires attention to justice and fairness across multiple dimensions. At its core, this principle demands equitable performance of emotion recognition systems across diverse demographic groups. Research has repeatedly demonstrated that many current affective computing systems exhibit significant disparities in recognition accuracy when analyzing emotional expressions from individuals of different ages, genders, ethnicities, and cultural backgrounds. These disparities often stem from training data imbalances, where specific populations are overrepresented while others remain marginalized or absent. The consequences of such imbalances extend beyond mere technical performance metrics, potentially reinforcing existing social inequalities by providing superior service to privileged groups while delivering substandard experiences to historically underserved populations.\n\nFurthermore, justice in emotional AI necessitates acknowledging and accommodating cultural variations in emotional expression and interpretation. The dominant psychological models of emotion that inform most affective computing systems emerged primarily from Western, educated, industrialized, rich, and democratic (WEIRD) populations, yet are often inappropriately generalized as universal. Cross-cultural research has revealed substantial differences across societies in emotional display rules, vocabulary, interpretation, and expression norms. For instance, the concepts of \"grief\" or the expression of \"joy\" may manifest differently in collectivist versus individualist cultures, while some emotional states may have no direct translation across cultures. Emotionally intelligent systems that fail to account for these cultural differences risk misinterpreting or misrepresenting users' emotional states based on culturally biased assumptions.\n\nAnother crucial aspect of fairness concerns the avoidance of emotional stereotyping based on demographic characteristics. Many current emotion recognition systems implicitly embed problematic assumptions, such as expectations that women will express emotions more intensely than men or that certain ethnic groups display specific emotional patterns. These stereotypes not only lead to inaccurate assessments but can also perpetuate harmful social biases. Just as human assessments of emotion can be distorted by prejudice, algorithmic systems can encode and amplify such biases at scale if not carefully designed and monitored.\n\nJustice in emotional AI also extends to accessibility considerations. People with neurological differences, such as those on the autism spectrum or individuals with facial mobility limitations due to conditions like Parkinson's disease, may express emotions in ways that diverge from normative patterns. Systems designed only to recognize typical emotional expressions may systematically misinterpret or fail to register the emotional states of these individuals, creating significant barriers to equitable access. Truly just emotional AI must accommodate diverse modes of emotional expression, including atypical patterns that may arise from neurological or physical differences.\n\nThe principle of fairness further demands transparent disclosure of emotional AI capabilities and limitations. Users should be informed about the system's emotional recognition functionalities, including information about its accuracy rates across different demographic groups and emotional categories. This transparency enables informed decision-making about whether and how to engage with emotionally intelligent systems, particularly for individuals from groups subject to higher error rates or misinterpretations. Without such disclosure, users cannot meaningfully assess the system's trustworthiness or appropriateness for their needs.\n\nFinally, justice requires meaningful access to redress mechanisms when emotional AI systems cause harm. Users must have practical, accessible means to contest inaccurate emotional assessments, particularly when these assessments lead to adverse outcomes in hiring, education, healthcare, or legal proceedings. These mechanisms should not place undue burdens on affected individuals and should include options for independent verification and correction of systemic biases rather than merely addressing individual complaints.",
      "page_start": 14,
      "page_end": 15
    },
    {
      "section_name": "Multi-Stakeholder Governance Approach",
      "text": "The complex ethical, legal, and social implications of Emotional AI necessitate a governance approach that engages diverse stakeholders in complementary roles. No single entitywhether governmental, corporate, or civil society -possesses the comprehensive perspective needed to address the multifaceted challenges that emotional intelligence systems present. Instead, effective governance requires coordinated action across multiple domains.\n\nRegulatory bodies at national and international levels play essential roles in establishing baseline requirements for emotional AI systems. These include mandatory disclosure of emotional recognition capabilities, minimum standards for accuracy and fairness across demographic groups, limitations on specific applications (such as emotion recognition in high-stakes decision-making), and enforcement mechanisms for violations. The European Union's AI Act represents a significant step in this direction, with its explicit attention to emotion recognition technologies and risk-based regulatory approach. However, formal regulation must be supplemented by more dynamic and responsive governance mechanisms.",
      "page_start": 15,
      "page_end": 15
    },
    {
      "section_name": "Future Directions And Recommendations",
      "text": "As affective computing advances and emotional intelligence becomes increasingly integrated into AI systems, several key research, policy, and practice directions emerge.\n\nFirst, research into emotional diversity must be prioritized to address current limitations in recognizing and responding to human emotional experiences. This includes expanded studies of emotional expression across cultures, investigation of emotional communication in neurodiverse populations, and exploration of complex, mixed, and culturally specific emotional states that may not fit neatly into dominant psychological models. Such research should employ participatory methods that engage diverse communities as collaborators rather than merely subjects of study.\n\nSecond, privacy-preserving techniques for emotion recognition warrant significant investment. Current approaches often require the extensive collection and centralized processing of sensitive, emotional data, creating substantial privacy risks. Techniques like federated learning, differential privacy, and on-device processing could enable emotional intelligence while minimizing data exposure. Similarly, systems should be designed to forget emotional data after use rather than accumulating increasingly comprehensive emotional profiles of individuals over time.\n\nThird, context-sensitive governance frameworks must be developed to address the varying implications of emotional AI across different domains. The appropriate standards, safeguards, and limitations for emotional analysis in healthcare settings differ substantially from those needed in educational contexts, workplace environments, or consumer applications. Domain-specific guidelines should be co-created with relevant stakeholders, including professionals working in these fields and the individuals whose emotional data might be processed.\n\nFourth, interdisciplinary education and training programs are necessary to develop professionals who can navigate the technical, ethical, legal, and social dimensions of emotional AI. Current educational pathways typically separate these domains, resulting in computer scientists with a limited understanding of emotional psychology, psychologists with minimal technical knowledge of AI systems, and legal scholars unfamiliar with both. Integrated approaches to education would better prepare the next generation of researchers, developers, and policymakers to address the complex challenges of emotionally intelligent systems.\n\nFifth, ongoing monitoring and evaluation mechanisms should be established to assess the impacts of emotional AI systems after deployment. These mechanisms should track technical performance metrics, psychological effects on users, social consequences for different communities, and evolving public attitudes toward emotional AI. Findings from such assessments should inform iterative improvements to technical systems and governance frameworks.\n\nUltimately, international cooperation on the governance of emotional AI should be strengthened to prevent regulatory fragmentation and establish shared principles across jurisdictions. While cultural differences may necessitate some variation in specific standards and approaches, core values such as respect for human dignity, protection of vulnerable populations, and preservation of emotional autonomy can provide common ground for global governance efforts.",
      "page_start": 16,
      "page_end": 17
    },
    {
      "section_name": "Conclusion",
      "text": "Integrating emotional intelligence into AI systems represents a transformative opportunity and a significant challenge for technology governance. Affective computing enables more natural and responsive human-computer interaction, opening new possibilities for healthcare, education, and personal well-being applications. However, as machines gain an increased capacity to recognize, interpret, and respond to human emotions, we must carefully consider the implications for privacy, autonomy, fairness, and the fundamental nature of emotional experience.\n\nThis paper examines the technical foundations of affective computing, which involves transforming human emotions into structured data, and the emerging regulatory frameworks governing emotional AI. Through analysis of current approaches and the case study of ChatGPT-4.5, we have identified key challenges in ensuring the responsible development and deployment of emotionally intelligent systems. These challenges cannot be addressed solely through technical solutions or resolved by regulatory intervention alone. Instead, they require a multidimensional approach integrating technical innovation, ethical reflection, legal frameworks, and inclusive stakeholder engagement.\n\nThe path forward demands balancing seemingly competing values: advancing emotional AI capabilities while protecting privacy, enabling personalization while preventing manipulation, recognizing universal aspects of emotion while respecting cultural diversity, and maintaining human connection while incorporating technological mediation. Navigating these tensions requires ongoing dialogue across disciplines and sectors, with a particular focus on voices that have been historically marginalized in technology governance.\n\nAs affective computing evolves, our choices about data practices, system design, regulatory approaches, and governance structures will shape the future relationship between humans and emotionally intelligent machines. By emphasizing human dignity, autonomy, and wellbeing as guiding principles in this development, we can harness the potential of emotional AI while safeguarding the richness and authenticity of human emotional experience in the digital age.",
      "page_start": 17,
      "page_end": 18
    }
  ],
  "figures": [],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "August 29, 2025": "Abstract"
        },
        {
          "August 29, 2025": "This paper examines the integration of emotional\nintelligence into artificial\nintelligence"
        },
        {
          "August 29, 2025": "systems, with a focus on affective computing and the growing capabilities of Large"
        },
        {
          "August 29, 2025": "Language Models (LLMs), such as ChatGPT and Claude, to recognize and respond"
        },
        {
          "August 29, 2025": "to human emotions. Drawing on interdisciplinary research that combines computer"
        },
        {
          "August 29, 2025": "science, psychology, and neuroscience, the study analyzes foundational neural archi-"
        },
        {
          "August 29, 2025": "tectures—CNNs for processing facial expressions and RNNs for sequential data, such"
        },
        {
          "August 29, 2025": "as speech and text—that enable emotion recognition.\nIt examines the transformation"
        },
        {
          "August 29, 2025": "of human emotional experiences into structured emotional data, addressing the dis-"
        },
        {
          "August 29, 2025": "tinction between explicit emotional data collected with informed consent in research"
        },
        {
          "August 29, 2025": "settings and implicit data gathered passively through everyday digital\ninteractions."
        },
        {
          "August 29, 2025": "That raises critical concerns about lawful processing, AI transparency, and individual"
        },
        {
          "August 29, 2025": "autonomy over emotional expressions in digital environments. The paper explores"
        },
        {
          "August 29, 2025": "implications across various domains,\nincluding healthcare, education, and customer"
        },
        {
          "August 29, 2025": "service, while addressing challenges of cultural variations in emotional expression and"
        },
        {
          "August 29, 2025": "potential biases in emotion recognition systems across different demographic groups."
        },
        {
          "August 29, 2025": "From a regulatory perspective, the paper examines emotional data in the context of"
        },
        {
          "August 29, 2025": "the GDPR and the EU AI Act frameworks, highlighting how emotional data may be"
        },
        {
          "August 29, 2025": "considered sensitive personal data that requires robust safeguards,\nincluding purpose"
        },
        {
          "August 29, 2025": "limitation, data minimization, and meaningful consent mechanisms. The case study of"
        },
        {
          "August 29, 2025": "OpenAI’s ChatGPT-4.5, which incorporates improved emotional\nintelligence capabili-"
        },
        {
          "August 29, 2025": "ties, exemplifies advances in emotionally responsive AI while illustrating the complexity"
        },
        {
          "August 29, 2025": "of ensuring the ethical deployment of such systems. The paper concludes by proposing"
        },
        {
          "August 29, 2025": "a multidimensional governance framework that integrates technical scrutiny with legal"
        },
        {
          "August 29, 2025": "and ethical analysis, emphasizing multi-stakeholder collaboration to safeguard human"
        },
        {
          "August 29, 2025": "dignity, autonomy, and rights in the digital age of emotionally aware AI systems."
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Contents": "1"
        },
        {
          "Contents": "2"
        },
        {
          "Contents": ""
        },
        {
          "Contents": ""
        },
        {
          "Contents": ""
        },
        {
          "Contents": ""
        },
        {
          "Contents": ""
        },
        {
          "Contents": "3"
        },
        {
          "Contents": ""
        },
        {
          "Contents": ""
        },
        {
          "Contents": ""
        },
        {
          "Contents": "4"
        },
        {
          "Contents": ""
        },
        {
          "Contents": ""
        },
        {
          "Contents": ""
        },
        {
          "Contents": ""
        },
        {
          "Contents": ""
        },
        {
          "Contents": ""
        },
        {
          "Contents": ""
        },
        {
          "Contents": ""
        },
        {
          "Contents": ""
        },
        {
          "Contents": ""
        },
        {
          "Contents": ""
        },
        {
          "Contents": ""
        },
        {
          "Contents": ""
        },
        {
          "Contents": ""
        },
        {
          "Contents": ""
        },
        {
          "Contents": ""
        },
        {
          "Contents": ""
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "1.\nIntroduction": "The evolution of artificial\nintelligence (AI) has witnessed a significant shift from systems"
        },
        {
          "1.\nIntroduction": "designed primarily for logical reasoning and task execution to those capable of recognizing,"
        },
        {
          "1.\nIntroduction": "interpreting, and responding to human emotions. This transformation represents a significant"
        },
        {
          "1.\nIntroduction": "advancement in human-computer interaction, as it addresses the emotional dimension of"
        },
        {
          "1.\nIntroduction": "communication that has been traditionally absent\nfrom digital\ninterfaces. The field of"
        },
        {
          "1.\nIntroduction": "affective computing, first conceptualized by Rosalind Picard in the late 1990s, has now"
        },
        {
          "1.\nIntroduction": "emerged as a cornerstone of modern AI development, particularly in the realm of Large"
        },
        {
          "1.\nIntroduction": "Language Models\n(LLMs)\nsuch as ChatGPT, Claude, and other conversational agents"
        },
        {
          "1.\nIntroduction": "(Picard, 1997)."
        },
        {
          "1.\nIntroduction": "Integrating emotional\nintelligence into AI systems carries profound implications for various"
        },
        {
          "1.\nIntroduction": "domains,\nincluding healthcare, education, customer service, and personal assistance. By"
        },
        {
          "1.\nIntroduction": "recognizing emotional states, AI systems can provide more personalized, empathetic, and"
        },
        {
          "1.\nIntroduction": "contextually appropriate responses, potentially enhancing user\nsatisfaction and overall"
        },
        {
          "1.\nIntroduction": "effectiveness. However, this capability also introduces complex challenges related to privacy,"
        },
        {
          "1.\nIntroduction": "consent, data protection, and the fundamental nature of human-AI relationships."
        },
        {
          "1.\nIntroduction": "This paper examines the technological underpinnings, regulatory considerations, and ethical"
        },
        {
          "1.\nIntroduction": "implications of emotionally intelligent AI\nsystems. We begin by examining the neural"
        },
        {
          "1.\nIntroduction": "network architectures\nthat enable machines\nto process emotional cues,\nfollowed by an"
        },
        {
          "1.\nIntroduction": "analysis of how human emotions are transformed into structured data.\nSubsequently,"
        },
        {
          "1.\nIntroduction": "we investigate the regulatory frameworks governing emotional data, with a focus on the"
        },
        {
          "1.\nIntroduction": "European Union’s General Data Protection Regulation (GDPR) and the EU Artificial"
        },
        {
          "1.\nIntroduction": "Intelligence Act. Using the case study of OpenAI’s ChatGPT-4.5, we illustrate the practical"
        },
        {
          "1.\nIntroduction": "implications of these advancements. Ultimately, we propose a multidimensional governance"
        },
        {
          "1.\nIntroduction": "approach that strikes a balance between technological\ninnovation and the protection of"
        },
        {
          "1.\nIntroduction": "human dignity and autonomy."
        },
        {
          "1.\nIntroduction": "2.\nAffective Computing: Technical Foundations and Evolution"
        },
        {
          "1.\nIntroduction": "2.0.1\nThe Evolution of Affective Computing"
        },
        {
          "1.\nIntroduction": "Affective computing emerged as a distinct field of\nresearch in 1997, when MIT Media"
        },
        {
          "1.\nIntroduction": "Lab professor Rosalind Picard published her seminal work, \"Affective Computing,\" which"
        },
        {
          "1.\nIntroduction": "defined the discipline as \"computing that relates to, arises from, or deliberately influences"
        },
        {
          "1.\nIntroduction": "emotions\" (Picard, 1997). This multidisciplinary domain integrates concepts from computer"
        },
        {
          "1.\nIntroduction": "science, psychology, neuroscience, and cognitive science to create systems that can detect,"
        },
        {
          "1.\nIntroduction": "understand, and respond to human emotions."
        },
        {
          "1.\nIntroduction": "The evolution of affective computing can be traced through several key developmental"
        },
        {
          "1.\nIntroduction": "phases.\nInitial efforts in the 1990s and early 2000s focused on identifying basic emotions from"
        },
        {
          "1.\nIntroduction": "facial expressions and vocal patterns using rule-based systems and simple machine learning"
        },
        {
          "1.\nIntroduction": "algorithms. These systems typically operate with predefined emotional categories based"
        },
        {
          "1.\nIntroduction": "on Paul Ekman’s six basic emotions: happiness, sadness, anger,\nfear, disgust, and surprise"
        },
        {
          "1.\nIntroduction": "(Ekman, 1992). As\nresearch progressed into the 2000s and 2010s,\nscientists recognized"
        },
        {
          "1.\nIntroduction": "that human emotional expression involves multiple channels. This led to the development"
        },
        {
          "1.\nIntroduction": "of systems that combined facial, vocal,\ntextual, and physiological data for more robust"
        },
        {
          "1.\nIntroduction": "emotion recognition. This period witnessed the creation of multimodal datasets, such as"
        },
        {
          "1.\nIntroduction": "IEMOCAP (\"Interactive Emotional Dyadic Motion Capture\" - Busso et al., 2008) and"
        }
      ],
      "page": 3
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "Expression\" - McKeown et al., 2012), which facilitated advances in multimodal emotion"
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "recognition."
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "The advent of deep learning techniques\nin the 2010s\ntransformed affective computing,"
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "enabling more accurate recognition of subtle emotional cues and complex emotional states."
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "Convolutional Neural Networks (CNNs) transformed facial expression analysis, whereas"
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "Recurrent Neural Networks (RNNs),\nfollowed by Transformer architectures, brought sub-"
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "stantial advancements in recognizing emotions from text and speech. From 2015 onward,"
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "research shifted toward context-aware systems that consider situational\nfactors,\nindividual"
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "differences, cultural variations, and interaction history when interpreting emotional signals"
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "and generating responses. Most\nrecently,\nfrom 2020 to the present,\nthe emergence of"
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "sophisticated LLMs has accelerated the development of emotionally intelligent AI systems"
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "that can engage in nuanced emotional conversations, recognize implicit emotional cues in"
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "text, and generate contextually appropriate emotional responses."
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "2.0.2\nNeural Network Architectures for Emotion Recognition"
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "The ability of AI systems to recognize and process emotional data relies primarily on two"
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "neural network architectures: Convolutional Neural Networks (CNNs) and Recurrent Neural"
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "Networks (RNNs), as well as more recent Transformer-based models. These architectures"
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "serve distinct but complementary functions in analyzing different emotional cues."
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "2.0.3\nConvolutional Neural Networks (CNNs)"
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "CNNs have revolutionized the field of computer vision through their hierarchical structure,"
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "which enables the extraction of\nincreasingly complex features from visual data (LeCun"
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "et al., 2015).\nIn the context of emotion recognition, CNNs are particularly effective for"
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "processing facial expressions, a primary channel of emotional communication among humans."
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "These networks apply convolutional filters across image inputs, detecting patterns such as"
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "edge orientations, textures, and higher-level\nfeatures corresponding to specific emotional"
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "expressions."
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "The effectiveness of CNNs in emotion recognition is exemplified by models such as FER2013"
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "(Facial Expression Recognition) and EmotioNet, which achieve accuracy rates exceeding 70%"
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "in classifying basic emotions from facial\nimages (Goodfellow et al., 2013; Fabian Benitez-"
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "Quiroz et al., 2016). Moreover, advanced architectures like ResNet and EfficientNet have"
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "enhanced performance through deeper networks with residual connections and optimized"
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "scaling methods (He et al., 2016; Tan & Le, 2019)."
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "The application of CNNs extends beyond static image analysis to dynamic facial expressions"
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "in video streams, where temporal convolutional networks (TCNs) can capture the evolution"
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "of expressions over time. This capability is crucial for detecting subtle emotional transitions"
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "and distinguishing between genuine and feigned expressions, a distinction that often depends"
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "on temporal dynamics (Ekman & Friesen, 1982)."
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "2.0.4\nRecurrent Neural Networks (RNNs) and Transformers"
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "While CNNs excel at processing spatial data, RNNs are designed to handle sequential"
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "information, making them ideal\nfor analyzing temporal aspects of emotional expression in"
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "speech, text, and physiological signals (Hochreiter & Schmidhuber, 1997). The distinctive"
        },
        {
          "SEMAINE (\"Sustained Emotionally colored Machine-human Interaction using Nonverbal": "feature of RNNs is their internal memory, which enables them to maintain context across"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "evolve."
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "Variants of RNNs,\nincluding Long Short-Term Memory (LSTM) networks and Gated"
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "Recurrent Units (GRUs), have demonstrated remarkable success in sentiment analysis and"
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "emotion recognition from textual and audio data. For instance, DeepMoji, an LSTM-based"
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "model trained on a dataset of 1.2 billion tweets containing emojis, achieves state-of-the-art"
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "performance in detecting emotions and sentiment in text (Felbo et al., 2017)."
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "Recently, Transformer architectures have surpassed traditional RNNs\nin many natural"
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "language processing tasks,\nincluding emotion recognition. Models such as BERT (Bidirec-"
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "tional Encoder Representations from Transformers) and its successors leverage attention"
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "mechanisms\nto capture subtle emotional nuances\nin text by dynamically assessing the"
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "contextual relevance of words (Devlin et al., 2019). This ability is beneficial\nfor interpreting"
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "complex emotional states that are conveyed implicitly, rather than through direct emotional"
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "language."
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "The latest generation of LLMs,\nincluding GPT-4 and Claude, builds upon these Transformer"
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "architectures,\nincorporating vast amounts of textual data that enable them to recognize"
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "and respond to emotional cues with unprecedented sophistication. These models can detect"
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "basic emotions and complex emotional states, as well as cultural variations in emotional"
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "expression and contextual\nfactors that influence emotional\ninterpretation."
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "2.0.5\nMultimodal Approaches to Emotion Recognition"
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "Human emotional expression is inherently multimodal,\ninvolving a combination of\nfacial"
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "expressions, vocal intonations,\nlinguistic choices, body language, and physiological responses."
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "Recognizing this complexity, contemporary AI systems are increasingly adopting multimodal"
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "approaches that integrate information from multiple channels to achieve more robust and"
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "accurate emotion recognition."
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "Multimodal\nfusion techniques combine data from different modalities at various processing"
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "levels. Early fusion approaches concatenate raw data from other modalities before feature"
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "extraction, allowing the model to learn joint representations directly from the multimodal"
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "input. Late fusion methods process each modality independently through separate models,"
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "and their predictions are combined at the decision level through weighted averaging or"
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "voting methods. Hybrid fusion techniques combine early and late fusion elements, with"
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "intermediate features from different modalities being integrated at multiple levels throughout"
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "the processing pipeline."
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "Research has consistently demonstrated that multimodal approaches outperform unimodal"
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "methods in emotion recognition tasks. For example, the IEMOCAP (Interactive Emotional"
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "Dyadic Motion Capture) dataset, which includes audio, visual, and textual\ninformation"
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "from acted emotional\nscenes, has been used to develop models\nthat achieve accuracy"
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "improvements of up to 10% when using multimodal versus unimodal approaches (Busso et"
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "al., 2008)."
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "Recent advancements in multimodal\nlearning include cross-modal attention mechanisms,"
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "which allow models\nto selectively focus on relevant\ninformation across modalities, and"
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "contrastive learning techniques that align representations from different modalities in a"
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "shared embedding space. These methods are particularly valuable for handling the inherent"
        },
        {
          "sequential\ninputs — a characteristic essential\nfor understanding emotions that unfold and": "asynchrony and complementarity of emotional cues across various channels."
        }
      ],
      "page": 5
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "cessing"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "3.0.1\nConceptualizing Emotional Data"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "The concept of “emotional data”\nrepresents a significant departure from traditional data"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "types in computing. Unlike factual\ninformation, emotional data encompasses subjective,"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "experiential, and often ambiguous aspects of human emotional states. This transformation"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "— from lived emotional\nexperiences\nto structured, machine-processable data — raises"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "fundamental questions about the nature of emotions and the extent to which they can be"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "captured and represented digitally."
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "Emotional data can be categorized in several ways.\nFirst, we can distinguish between"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "explicit and implicit emotional data. Explicit emotional data includes direct self-reports of"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "emotional states, such as survey responses or emotion labels provided by users.\nImplicit"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "emotional data,\nin contrast,\nis derived from behavioral signals that may indicate emotional"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "states,\nsuch as\nfacial\nexpressions, voice patterns,\nor physiological\nresponses.\nSecond,"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "emotional data can be approached either\ncategorically or dimensionally.\nCategorical"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "approaches classify emotions discretely (e.g.,\njoy, sadness, anger).\nIn contrast, dimensional"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "approaches represent emotions along continuous axes such as valence (positive/negative),"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "arousal\n(high/low energy), and dominance (high/low control).\nThird,\nemotional data"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "may be individual or aggregate.\nIndividual emotional data pertains to specific persons"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "and their unique\nemotional\nexperiences, whereas aggregate\nemotional data represents"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "patterns across populations or groups. Finally, emotional data can be context-dependent or"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "context-independent. Context-dependent emotional data incorporates situational\nfactors"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "that influence emotional experiences, while context-independent data focuses solely on the"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "emotional signals."
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "The transformation of emotions into data necessarily involves simplification and abstraction,"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "potentially obscuring the richness and complexity of human emotional experience. As"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "Barrett (2017) noted, emotions are not singular, universal phenomena but constructed"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "experiences influenced by cultural, social, and individual factors. This perspective challenges"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "the notion that emotions can be reduced to discrete, objective data points without significant"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "loss of meaning."
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "3.0.2\nMethods of Emotional Data Collection"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "The collection of emotional data employs various methodologies, each with distinct strengths,"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "limitations, and ethical\nimplications. Direct self-report methods include questionnaires,"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "experience sampling methods (ESM), and ecological momentary assessment (EMA), in which"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "individuals directly report their emotional states. While these methods provide valuable"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "insights into subjective experiences, they are subject to limitations such as social desirability"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "bias, recall errors, and variations in emotional vocabulary and awareness across individuals"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "(Robinson & Clore, 2002). Digital\nimplementations of self-report measures, such as mood-"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "tracking applications and emotion rating systems,\nfacilitate the continuous collection of"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "emotional data in naturalistic settings. However, the frequency and intrusiveness of such"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "measures must be balanced against user burden and potential\nreactivity effects, where"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "reporting emotions influences the emotional experience itself."
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "Observational approaches capture behavioral manifestations of emotions without requiring"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "explicit reporting from individuals. These methods encompass facial expression analysis,"
        },
        {
          "3.\nEmotional Data: Conceptualization, Collection, and Pro-": "utilizing computer vision techniques to detect and classify facial expressions based on the"
        }
      ],
      "page": 6
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "analysis, extracting acoustic features such as pitch,\ntempo, and spectral characteristics"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "to identify emotional cues in speech. Text analysis employs natural\nlanguage processing"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "techniques to identify emotional content in written communications, encompassing sentiment"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "analysis, emotion classification, and stance detection. Physiological measurements monitor"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "autonomic nervous system responses such as heart rate variability, electrodermal activity,"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "and respiratory patterns, which correlate with emotional states. Additionally, behavioral"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "metrics track user interactions with digital systems,\nincluding click patterns, dwell times,"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "and navigation behaviors, which may reflect emotional engagement or frustration."
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "The context in which emotional data is collected significantly influences both the nature of"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "the data and the ethical considerations surrounding its use. Emotional data is typically col-"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "lected in controlled research environments, where explicit informed consent, clear protocols,"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "and institutional oversight are in place. Participants are generally aware of the specific data"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "and how it will be used. Consumer-facing products, however, may collect emotional data"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "through various channels, sometimes without users’\nfull awareness or understanding. This"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "data may be used for personalization, engagement optimization, or marketing. Ambient"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "intelligence environments, such as smart homes, workplaces, and public spaces,\nincreasingly"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "incorporate sensors that can passively collect data indicative of emotional states, often"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "without requiring active user participation in the data collection process. Social media sites,"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "forums, and other digital platforms generate vast repositories of emotional data through"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "user-generated content, engagement metrics, and interaction patterns."
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "The distinction between explicit and implicit collection contexts has profound implications"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "for consent, transparency, and user autonomy. While users in research settings typically"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "provide informed consent for specific data collection activities, users of commercial prod-"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "ucts or public spaces may have limited awareness of emotional data collection and few"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "opportunities to consent or opt out meaningfully."
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "3.0.3\nRepresentation and Processing of Emotional Data"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "Once collected, emotional data undergoes various transformations to facilitate machine"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "processing and analysis. Emotional data may be represented in multiple formats depending"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "on the source and intended application. Feature vectors provide numerical representations"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "of extracted features, such as facial\nlandmark coordinates, acoustic parameters, or linguistic"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "features. Categorical\nlabels classify emotions\ninto predefined categories\n(e.g., Ekman’s"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "six basic emotions: happiness, sadness,\nfear, disgust, anger, and surprise). Dimensional"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "coordinates position emotional\nstates\nin multidimensional\nspaces, most commonly the"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "valence-arousal-dominance\n(VAD) model.\nTime-series data captures\nthe dynamics of"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "emotional expression over time,\nincluding onset, peak, and decay patterns. Probability"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "distributions represent uncertainty or ambiguity in emotional classification, acknowledging"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "that emotional states often involve blends or transitions between prototypical emotions."
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "The processing of emotional data typically involves several stages. Preprocessing encom-"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "passes cleaning, normalizing, and aligning raw data,\nincluding noise reduction, artifact"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "removal, and temporal\nsynchronization across modalities. Feature extraction identifies"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "relevant attributes that convey emotional\ninformation, utilizing handcrafted features in-"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "formed by domain knowledge and learned features derived through representation learning"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "techniques. Fusion integrates information from multiple sources or modalities to create"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "comprehensive emotional profiles. Classification or\nregression applies machine learning"
        },
        {
          "Facial Action Coding System (FACS) or deep learning approaches. They also include voice": "algorithms to categorize or position emotional states along continuous dimensions.\nInter-"
        }
      ],
      "page": 7
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "pretation contextualizes emotional data within broader user profiles,\ninteraction histories,": "or situational\nfactors to derive meaningful\ninsights. Finally, response generation formulates"
        },
        {
          "pretation contextualizes emotional data within broader user profiles,\ninteraction histories,": "system responses based on recognized emotional states, potentially incorporating empathetic"
        },
        {
          "pretation contextualizes emotional data within broader user profiles,\ninteraction histories,": "language, adaptive interface elements, or personalized content."
        },
        {
          "pretation contextualizes emotional data within broader user profiles,\ninteraction histories,": "4.\nRegulatory Frameworks for Emotional Data"
        },
        {
          "pretation contextualizes emotional data within broader user profiles,\ninteraction histories,": "4.0.1\nGDPR and Emotional Data Classification"
        },
        {
          "pretation contextualizes emotional data within broader user profiles,\ninteraction histories,": "The European Union’s General Data Protection Regulation (GDPR) provides one of the"
        },
        {
          "pretation contextualizes emotional data within broader user profiles,\ninteraction histories,": "most\ncomprehensive\nframeworks\nfor understanding the\nlegal\nstatus of\nemotional data."
        },
        {
          "pretation contextualizes emotional data within broader user profiles,\ninteraction histories,": "However,\nit does not explicitly address this category. Several provisions are particularly"
        },
        {
          "pretation contextualizes emotional data within broader user profiles,\ninteraction histories,": "relevant to handling emotional data in AI systems."
        },
        {
          "pretation contextualizes emotional data within broader user profiles,\ninteraction histories,": "4.0.2\nEmotional Data as Personal Data"
        },
        {
          "pretation contextualizes emotional data within broader user profiles,\ninteraction histories,": "The GDPR defines personal data as “any information relating to an identified or identifiable"
        },
        {
          "pretation contextualizes emotional data within broader user profiles,\ninteraction histories,": "natural person (‘data subject’)”\n(Article 4(1)). Emotional data falls within this broad"
        },
        {
          "pretation contextualizes emotional data within broader user profiles,\ninteraction histories,": "definition, as it relates directly to an individual’s internal states and can often be linked"
        },
        {
          "pretation contextualizes emotional data within broader user profiles,\ninteraction histories,": "to specific persons. Consequently, the collection and processing of emotional data must"
        },
        {
          "pretation contextualizes emotional data within broader user profiles,\ninteraction histories,": "adhere to the general data protection principles established in the regulation."
        },
        {
          "pretation contextualizes emotional data within broader user profiles,\ninteraction histories,": "The principle of\nlawfulness,\nfairness, and transparency (Article 5(1)(a)) requires that pro-"
        },
        {
          "pretation contextualizes emotional data within broader user profiles,\ninteraction histories,": "cessing must be based on a legitimate legal ground, conducted fairly, and transparently"
        },
        {
          "pretation contextualizes emotional data within broader user profiles,\ninteraction histories,": "disclosed to the data subject. For emotional data, this principle demands clear communica-"
        },
        {
          "pretation contextualizes emotional data within broader user profiles,\ninteraction histories,": "tion about when and how emotional states are being analyzed, a particularly challenging"
        },
        {
          "pretation contextualizes emotional data within broader user profiles,\ninteraction histories,": "requirement given the often implicit nature of emotional data collection in modern systems."
        },
        {
          "pretation contextualizes emotional data within broader user profiles,\ninteraction histories,": "Purpose limitation (Article 5(1)(b)) stipulates that personal data must be collected for"
        },
        {
          "pretation contextualizes emotional data within broader user profiles,\ninteraction histories,": "specified, explicit, and legitimate purposes and not further processed in a manner incom-"
        },
        {
          "pretation contextualizes emotional data within broader user profiles,\ninteraction histories,": "patible with those purposes. This principle restricts repurposing emotional data collected"
        },
        {
          "pretation contextualizes emotional data within broader user profiles,\ninteraction histories,": "for one service (personalization) for unrelated purposes (such as targeted advertising based"
        },
        {
          "pretation contextualizes emotional data within broader user profiles,\ninteraction histories,": "on emotional vulnerabilities)."
        },
        {
          "pretation contextualizes emotional data within broader user profiles,\ninteraction histories,": "Data minimization (Article 5(1)(c)) states that personal data shall be “adequate, relevant"
        },
        {
          "pretation contextualizes emotional data within broader user profiles,\ninteraction histories,": "and limited to what\nis necessary in relation to the purposes for which they are processed"
        },
        {
          "pretation contextualizes emotional data within broader user profiles,\ninteraction histories,": "(‘data minimisation’)”. This principle challenges the common practice of broad emotional"
        },
        {
          "pretation contextualizes emotional data within broader user profiles,\ninteraction histories,": "data collection that exceeds functional requirements, often justified by potential\nfuture"
        },
        {
          "pretation contextualizes emotional data within broader user profiles,\ninteraction histories,": "applications or system improvements."
        },
        {
          "pretation contextualizes emotional data within broader user profiles,\ninteraction histories,": "Accuracy (Article 5(1)(d))\nrequires\nthat personal data shall be\n“accurate and, where"
        },
        {
          "pretation contextualizes emotional data within broader user profiles,\ninteraction histories,": "necessary, kept up to date; every reasonable step must be taken to ensure that personal"
        }
      ],
      "page": 8
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "in a manner that ensures appropriate security of\nthe personal data,\nincluding protection": "against unauthorised or unlawful processing and against accidental\nloss, destruction or dam-"
        },
        {
          "in a manner that ensures appropriate security of\nthe personal data,\nincluding protection": "age, using appropriate technical or organisational measures (‘integrity and confidentiality’)”."
        },
        {
          "in a manner that ensures appropriate security of\nthe personal data,\nincluding protection": "This principle acknowledges the sensitive nature of emotional\ninformation and the potential"
        },
        {
          "in a manner that ensures appropriate security of\nthe personal data,\nincluding protection": "harm that can result from unauthorized access or disclosure."
        },
        {
          "in a manner that ensures appropriate security of\nthe personal data,\nincluding protection": "4.0.3\nEmotional Data as Special Category Data"
        },
        {
          "in a manner that ensures appropriate security of\nthe personal data,\nincluding protection": "More significantly, emotional data may qualify as “special category data” under Article"
        },
        {
          "in a manner that ensures appropriate security of\nthe personal data,\nincluding protection": "9 of the GDPR, which includes “data concerning health” and potentially “biometric data"
        },
        {
          "in a manner that ensures appropriate security of\nthe personal data,\nincluding protection": "to uniquely identify a natural person.” This classification is particularly relevant when"
        },
        {
          "in a manner that ensures appropriate security of\nthe personal data,\nincluding protection": "emotional data is derived from physiological measurements that reveal\ninformation about"
        },
        {
          "in a manner that ensures appropriate security of\nthe personal data,\nincluding protection": "mental health conditions, used to infer psychological characteristics or behavioral patterns,"
        },
        {
          "in a manner that ensures appropriate security of\nthe personal data,\nincluding protection": "collected through biometric methods such as facial expression analysis, or can reveal sensitive"
        },
        {
          "in a manner that ensures appropriate security of\nthe personal data,\nincluding protection": "aspects of an individual’s identity or condition."
        },
        {
          "in a manner that ensures appropriate security of\nthe personal data,\nincluding protection": "If classified as unique category data, emotional data processing would be prohibited unless"
        },
        {
          "in a manner that ensures appropriate security of\nthe personal data,\nincluding protection": "a specific exception applies, such as explicit consent (Article 9(2)(a)) or when processing is"
        },
        {
          "in a manner that ensures appropriate security of\nthe personal data,\nincluding protection": "necessary for scientific research purposes, subject to appropriate safeguards (Article 9(2)(j))."
        },
        {
          "in a manner that ensures appropriate security of\nthe personal data,\nincluding protection": "This heightened level of protection recognizes the intimate nature of emotional\ninformation"
        },
        {
          "in a manner that ensures appropriate security of\nthe personal data,\nincluding protection": "and its potential to reveal deeply personal aspects of an individual’s life and identity."
        },
        {
          "in a manner that ensures appropriate security of\nthe personal data,\nincluding protection": "4.1\nLegal Basis for Processing Emotional Data"
        },
        {
          "in a manner that ensures appropriate security of\nthe personal data,\nincluding protection": "Under the GDPR, any processing of personal data,\nincluding emotional data, requires a"
        },
        {
          "in a manner that ensures appropriate security of\nthe personal data,\nincluding protection": "lawful basis.\nSeveral potential bases may apply for emotional data, each with distinct"
        },
        {
          "in a manner that ensures appropriate security of\nthe personal data,\nincluding protection": "implications for designing and deploying emotionally intelligent systems."
        },
        {
          "in a manner that ensures appropriate security of\nthe personal data,\nincluding protection": "Consent (Article 6(1)(a)) requires that the data subject has given clear, specific,\ninformed,"
        },
        {
          "in a manner that ensures appropriate security of\nthe personal data,\nincluding protection": "and unambiguous consent\nto the processing of\ntheir emotional data. While seemingly"
        },
        {
          "in a manner that ensures appropriate security of\nthe personal data,\nincluding protection": "straightforward, obtaining meaningful consent for the processing of emotional data faces"
        },
        {
          "in a manner that ensures appropriate security of\nthe personal data,\nincluding protection": "significant challenges. Users may struggle to understand the full\nimplications of emotional"
        },
        {
          "in a manner that ensures appropriate security of\nthe personal data,\nincluding protection": "analysis, mainly when the technology operates invisibly or implicitly. Furthermore, the power"
        },
        {
          "in a manner that ensures appropriate security of\nthe personal data,\nincluding protection": "imbalances between individuals and technology providers may undermine the voluntary"
        },
        {
          "in a manner that ensures appropriate security of\nthe personal data,\nincluding protection": "nature of consent, particularly when emotional analysis is embedded in essential services or"
        },
        {
          "in a manner that ensures appropriate security of\nthe personal data,\nincluding protection": "platforms."
        },
        {
          "in a manner that ensures appropriate security of\nthe personal data,\nincluding protection": "Legitimate interests (Article 6(1)(f)) states:\n“processing is necessary for the purposes of\nthe"
        },
        {
          "in a manner that ensures appropriate security of\nthe personal data,\nincluding protection": "legitimate interests pursued by the controller or by a third party, except where such interests"
        }
      ],
      "page": 9
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "responsiveness is communicated as part of the service offering.": "In the case of research purposes (Article 6(1)(e),\nin conjunction with Article 89), processing"
        },
        {
          "responsiveness is communicated as part of the service offering.": "is\nlawful when it\nis\n“necessary for\nthe performance of a task carried out\nin the public"
        },
        {
          "responsiveness is communicated as part of the service offering.": "interest or in the exercise of official authority vested in the controller ”. This basis supports"
        },
        {
          "responsiveness is communicated as part of the service offering.": "the advancement of affective computing research while requiring measures such as data"
        },
        {
          "responsiveness is communicated as part of the service offering.": "minimization, pseudonymization, and ethical review to protect participant interests."
        },
        {
          "responsiveness is communicated as part of the service offering.": "Explicit consent would typically be required for special category emotional data, with higher"
        },
        {
          "responsiveness is communicated as part of the service offering.": "standards of specificity and clarity than those needed for standard consent. Alternative"
        },
        {
          "responsiveness is communicated as part of the service offering.": "legal bases for unique category data include substantial public interest or scientific research"
        },
        {
          "responsiveness is communicated as part of the service offering.": "purposes, provided that appropriate safeguards are in place. However, these exceptions are"
        },
        {
          "responsiveness is communicated as part of the service offering.": "interpreted narrowly and are subject to additional requirements."
        },
        {
          "responsiveness is communicated as part of the service offering.": "4.1.1\nThe EU Artificial Intelligence Act and Emotional Recognition"
        },
        {
          "responsiveness is communicated as part of the service offering.": "The European Union Artificial\nIntelligence Act represents a significant advancement in"
        },
        {
          "responsiveness is communicated as part of the service offering.": "regulating AI systems, with specific provisions relevant to emotional analysis and affective"
        },
        {
          "responsiveness is communicated as part of the service offering.": "computing.\nThe AI Act adopts a risk-based approach,\ncategorizing AI\nsystems based"
        },
        {
          "responsiveness is communicated as part of the service offering.": "on potential harm. Systems posing unacceptable risks are prohibited entirely,\nincluding"
        },
        {
          "responsiveness is communicated as part of the service offering.": "those that deploy subliminal techniques to manipulate behavior in a harmful way. High-"
        },
        {
          "responsiveness is communicated as part of the service offering.": "risk systems with a significant potential\nimpact on health, safety, or fundamental rights"
        },
        {
          "responsiveness is communicated as part of the service offering.": "are subject to stringent requirements before market introduction. Limited risk systems,"
        },
        {
          "responsiveness is communicated as part of the service offering.": "including emotion recognition systems, have specific transparency obligations. Systems"
        },
        {
          "responsiveness is communicated as part of the service offering.": "with minimal risk are subject to limited or no regulation under the Act."
        },
        {
          "responsiveness is communicated as part of the service offering.": "Under the AI Act, emotion recognition systems are addressed explicitly in Article 50(3),"
        },
        {
          "responsiveness is communicated as part of the service offering.": "which states:\n“Deployers of an emotion recognition system or a biometric categorisation"
        }
      ],
      "page": 10
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "against unauthorized access.": "The AI Act prohibits certain practices, particularly relevant to emotion recognition and"
        },
        {
          "against unauthorized access.": "manipulation. These include AI systems that deploy subliminal techniques beyond a person’s"
        },
        {
          "against unauthorized access.": "conscious awareness to distort behavior that causes physical or psychological harm. Systems"
        },
        {
          "against unauthorized access.": "that exploit vulnerabilities of specific groups based on age, disability, or social or economic"
        },
        {
          "against unauthorized access.": "situation to materially distort behavior in a harmful way are also prohibited. Additionally,"
        },
        {
          "against unauthorized access.": "the Act prohibits social scoring by public authorities, which involves evaluating or classifying"
        },
        {
          "against unauthorized access.": "individuals based on their social behavior or personal characteristics, potentially leading"
        },
        {
          "against unauthorized access.": "to detrimental or unfavorable treatment in unrelated social contexts. These prohibitions"
        },
        {
          "against unauthorized access.": "provide necessary guardrails against the most harmful potential applications of emotional"
        },
        {
          "against unauthorized access.": "intelligence in AI systems, particularly those that might exploit emotional vulnerabilities"
        },
        {
          "against unauthorized access.": "for manipulative purposes."
        },
        {
          "against unauthorized access.": "4.1.2\nOther Relevant Regulatory Frameworks"
        },
        {
          "against unauthorized access.": "Beyond the GDPR and AI Act,\nseveral other\nregulatory frameworks have implications"
        },
        {
          "against unauthorized access.": "for emotional data and affective computing. Biometric privacy regulations at the state"
        },
        {
          "against unauthorized access.": "level,\nincluding the Illinois Biometric Information Privacy Act\n(BIPA),\nimpose specific"
        },
        {
          "against unauthorized access.": "requirements for collecting and processing biometric identifiers and biometric information."
        },
        {
          "against unauthorized access.": "These laws typically require informed written consent before the collection, disclosure of the"
        },
        {
          "against unauthorized access.": "purpose, and the length of term for which the data will be collected, stored, and used, as"
        },
        {
          "against unauthorized access.": "well as a publicly available written policy establishing a retention schedule and guidelines for"
        },
        {
          "against unauthorized access.": "destruction. As emotionally intelligent AI systems increasingly rely on biometric methods"
        },
        {
          "against unauthorized access.": "for emotion recognition, compliance with these specialized privacy laws becomes increasingly"
        },
        {
          "against unauthorized access.": "relevant."
        },
        {
          "against unauthorized access.": "Consumer protection authorities have begun addressing the collection of emotional data in"
        },
        {
          "against unauthorized access.": "commercial contexts."
        },
        {
          "against unauthorized access.": "In healthcare contexts, emotional data may be subject to specialized health information"
        },
        {
          "against unauthorized access.": "privacy laws such as the Health Insurance Portability and Accountability Act (HIPAA) in"
        },
        {
          "against unauthorized access.": "the United States. These regulations impose strict requirements on collecting, using, and"
        },
        {
          "against unauthorized access.": "disclosing protected health information, which could include emotional data when used for"
        },
        {
          "against unauthorized access.": "health-related purposes such as mental health assessment or monitoring."
        },
        {
          "against unauthorized access.": "Specialized protections for children’s data, such as the Children’s Online Privacy Protection"
        },
        {
          "against unauthorized access.": "Act (COPPA) in the United States and provisions within the GDPR (Article 8), place"
        },
        {
          "against unauthorized access.": "additional restrictions on collecting and processing data from children. These protections are"
        },
        {
          "against unauthorized access.": "particularly relevant to emotional data, given children’s potentially heightened vulnerability"
        },
        {
          "against unauthorized access.": "to emotional analysis and manipulation."
        },
        {
          "against unauthorized access.": "4.2\nCase Study: ChatGPT-4.5 and Emotional Intelligence"
        },
        {
          "against unauthorized access.": "4.2.1\nEmotion Recognition in Text"
        },
        {
          "against unauthorized access.": "OpenAI’s release of ChatGPT-4.5 in late 2023 marked a significant advancement in the"
        },
        {
          "against unauthorized access.": "emotional\nintelligence capabilities of\nlarge language models."
        },
        {
          "against unauthorized access.": "ChatGPT-4.5 employs several techniques to recognize emotional content in user inputs."
        },
        {
          "against unauthorized access.": "The model\nidentifies the overall positive, negative, or neutral sentiment expressed in the"
        },
        {
          "against unauthorized access.": "text, providing a foundational\nlayer of emotional awareness.\nBeyond basic sentiment,"
        },
        {
          "against unauthorized access.": "it\ncategorizes\ntext\ninto specific\nemotional\ncategories,\nincluding primary emotions\n(joy,"
        }
      ],
      "page": 11
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "system assesses the strength or intensity of expressed emotions, distinguishing between"
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "mild annoyance and intense rage,\nfor example.\nIt also interprets emotional content within a"
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "conversational context, recognizing how emotions evolve throughout an interaction and how"
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "prior exchanges inform current emotional states. Beyond explicit emotional statements, the"
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "model\nidentifies implicit emotional cues,\nincluding sarcasm, passive aggression, excitement,"
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "and uncertainty conveyed through word choice, syntax, and stylistic elements."
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "These capabilities are implemented through supervised learning on annotated emotional"
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "data, such as Reinforcement Learning from Human Feedback (RLHF) in Machine Learning,"
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "which prioritizes emotionally appropriate responses, and few-shot learning that enables"
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "adaptation to individual users’ emotional expression patterns."
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "4.2.2\nEmotional Response Generation"
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "ChatGPT-4.5’s response generation incorporates emotional\nintelligence through several"
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "mechanisms. The model can calibrate its response tone to match the user’s emotional"
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "state, validating and recognizing expressed emotions through empathetic mirroring. For"
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "users expressing distress, the model offers responses designed to facilitate healthy emotional"
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "processing,\nincluding validation, normalization,\nreframing, and resource\nsuggestion as"
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "part of emotional\nregulation support. The system modulates emotional content based"
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "on conversation context, distinguishing between scenarios where emotional engagement is"
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "beneficial versus situations requiring more neutral,\nfactual responses. Through conversation"
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "history, the model develops user-specific emotional profiles that inform future interactions,"
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "allowing for more personalized emotional support. The model also adapts its emotional"
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "responses based on cultural contexts,\nrecognizing variations\nin emotional display rules,"
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "expression norms, and values across different cultural backgrounds."
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "4.2.3\nRegulatory Compliance and Ethical Considerations"
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "OpenAI has not implemented user interface elements that indicate real-time emotional"
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "analysis, nor are there visual cues, confidence indicators for emotional\ninferences, or specific"
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "disclosures on the emotional\ninterpretability of the model’s outputs. The “About”\nsection"
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "in the ChatGPT interface provides general\ninformation about the system’s capabilities,"
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "limitations, and safety measures. Still,\nit does not provide detailed guidance or transparency"
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "regarding the processing of emotional data."
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "OpenAI’s current privacy approach includes standard user data handling mechanisms, such"
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "as data deletion via user controls and retention policies aligned with privacy laws like the"
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "GDPR and CCPA. However, there is no publicly documented system of\nlayered consent"
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "specifically for emotional data processing, nor is there a separate framework for specifying"
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "purposes, managing emotional profiles, or implementing age-specific emotional safeguards."
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "The platform allows users to delete individual conversations, which may include sensitive"
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "content; however, this is not tied to a distinct emotional data processing framework."
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "To date, OpenAI has not disclosed using on-device emotional analysis or local processing"
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "options to minimize cloud-based data handling for emotional content. Additionally, while"
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "OpenAI incorporates differential privacy and other techniques in research and model training"
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "contexts, these techniques are not explicitly documented as being applied to emotional"
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "pattern extraction or anonymized emotional profiles."
        },
        {
          "sadness, anger,\nfear, surprise, disgust) and secondary (pride, shame, guilt, envy, etc.). The": "Despite the absence of native emotional\nintelligence systems, the broader emergence of"
        }
      ],
      "page": 12
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "emotionally responsive AI,\nincluding third-party applications built on top of\nlarge language": "models, has sparked widespread discussions on ethics and regulation.\nScholars, privacy"
        },
        {
          "emotionally responsive AI,\nincluding third-party applications built on top of\nlarge language": "advocates, and ethicists have raised concerns about the potential for emotionally interactive"
        },
        {
          "emotionally responsive AI,\nincluding third-party applications built on top of\nlarge language": "systems to manipulate users, particularly in commercial or political settings. The simulation"
        },
        {
          "emotionally responsive AI,\nincluding third-party applications built on top of\nlarge language": "of empathy by AI has sparked debates about deception, authenticity, and the psychological"
        },
        {
          "emotionally responsive AI,\nincluding third-party applications built on top of\nlarge language": "implications of human-AI interactions. Mental health professionals have warned against"
        },
        {
          "emotionally responsive AI,\nincluding third-party applications built on top of\nlarge language": "overreliance on AI for emotional support, citing the limitations of machine systems in terms"
        },
        {
          "emotionally responsive AI,\nincluding third-party applications built on top of\nlarge language": "of clinical\njudgment, empathy, and ethical oversight. Due to its intimate and potentially"
        },
        {
          "emotionally responsive AI,\nincluding third-party applications built on top of\nlarge language": "revealing nature, privacy experts argue that emotional data may warrant special protection."
        },
        {
          "emotionally responsive AI,\nincluding third-party applications built on top of\nlarge language": "Additionally,\nlabor\ntheorists have\nsuggested that\nemotionally interactive\nsystems\nrisk"
        },
        {
          "emotionally responsive AI,\nincluding third-party applications built on top of\nlarge language": "extracting emotional\nlabor from users — data that helps refine model responsiveness —"
        },
        {
          "emotionally responsive AI,\nincluding third-party applications built on top of\nlarge language": "without compensation or acknowledgment."
        },
        {
          "emotionally responsive AI,\nincluding third-party applications built on top of\nlarge language": "On February 27, 2025, OpenAI released a research preview of OpenAI GPT-4.5 (OpenAI"
        },
        {
          "emotionally responsive AI,\nincluding third-party applications built on top of\nlarge language": "GPT-4.5 System Card), and in the related communication, among other things,\nit is stated:"
        }
      ],
      "page": 13
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "4.3.2\nBeneficence and Non-maleficence": "AI systems with emotional capabilities should prioritize user well-being in emotional\nin-"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "teractions, aiming to enhance emotional health rather than merely maximize engagement"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "or commercial objectives. This requires careful attention to avoid exacerbating negative"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "emotional states or mental health conditions, which could occur through inappropriate"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "reinforcement, amplification, or exploitation of distress. Developers must recognize the"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "limits of automated emotional support, acknowledging that AI systems cannot fully re-"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "place human connection, therapeutic expertise, or contextual understanding in addressing"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "complex emotional needs. Appropriate safeguards for vulnerable users—including individ-"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "uals experiencing acute psychological distress, those with mental health conditions, and"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "those with limited digital\nliteracy—must be integrated into system design and deployment."
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "Furthermore, ethical guidelines for responding to concerning emotional content, such as"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "expressions of self-harm or suicidal\nideation, should be developed in collaboration with"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "mental health professionals and implemented consistently across platforms. These principles"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "ensure that emotional AI is a beneficial complement to human emotional support rather"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "than a potentially harmful substitute."
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "4.3.3\nJustice and Fairness"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "Ethical deployment of emotional AI requires attention to justice and fairness across multiple"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "dimensions. At its core, this principle demands equitable performance of emotion recognition"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "systems across diverse demographic groups. Research has repeatedly demonstrated that"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "many current affective computing systems exhibit\nsignificant disparities\nin recognition"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "accuracy when analyzing emotional expressions from individuals of different ages, genders,"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "ethnicities, and cultural backgrounds. These disparities often stem from training data"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "imbalances, where specific populations are overrepresented while others remain marginalized"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "or absent. The consequences of such imbalances extend beyond mere technical performance"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "metrics, potentially reinforcing existing social\ninequalities by providing superior service"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "to privileged groups while delivering substandard experiences to historically underserved"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "populations."
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "Furthermore,\njustice\nin emotional AI necessitates acknowledging and accommodating"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "cultural variations in emotional expression and interpretation. The dominant psychological"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "models of emotion that inform most affective computing systems emerged primarily from"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "Western, educated,\nindustrialized, rich, and democratic (WEIRD) populations, yet are often"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "inappropriately generalized as universal. Cross-cultural research has revealed substantial"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "differences across\nsocieties\nin emotional display rules, vocabulary,\ninterpretation, and"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "expression norms. For instance,\nthe concepts of \"grief\" or the expression of \"joy\" may"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "manifest differently in collectivist versus individualist cultures, while some emotional states"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "may have no direct translation across cultures. Emotionally intelligent systems that fail to"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "account for these cultural differences risk misinterpreting or misrepresenting users’ emotional"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "states based on culturally biased assumptions."
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "Another crucial aspect of fairness concerns the avoidance of emotional stereotyping based on"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "demographic characteristics. Many current emotion recognition systems implicitly embed"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "problematic assumptions, such as expectations that women will express emotions more"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "intensely than men or that certain ethnic groups display specific emotional patterns. These"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "stereotypes not only lead to inaccurate assessments but can also perpetuate harmful social"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "biases. Just as human assessments of emotion can be distorted by prejudice, algorithmic"
        },
        {
          "4.3.2\nBeneficence and Non-maleficence": "systems can encode and amplify such biases at scale if not carefully designed and monitored."
        }
      ],
      "page": 14
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "differences,\nsuch as\nthose on the autism spectrum or\nindividuals with facial mobility"
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "limitations due to conditions like Parkinson’s disease, may express emotions in ways that"
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "diverge from normative patterns. Systems designed only to recognize typical emotional"
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "expressions may systematically misinterpret or fail to register the emotional states of these"
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "individuals, creating significant barriers to equitable access. Truly just emotional AI must"
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "accommodate diverse modes of emotional expression,\nincluding atypical patterns that may"
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "arise from neurological or physical differences."
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "The principle of fairness further demands transparent disclosure of emotional AI capabilities"
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "and limitations.\nUsers\nshould be\ninformed about\nthe\nsystem’s\nemotional\nrecognition"
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "functionalities,\nincluding information about its accuracy rates across different demographic"
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "groups and emotional categories. This\ntransparency enables\ninformed decision-making"
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "about whether and how to engage with emotionally intelligent systems, particularly for"
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "individuals from groups subject to higher error rates or misinterpretations. Without such"
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "disclosure, users cannot meaningfully assess the system’s trustworthiness or appropriateness"
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "for their needs."
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "Finally, justice requires meaningful access to redress mechanisms when emotional AI systems"
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "cause harm. Users must have practical, accessible means to contest inaccurate emotional"
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "assessments, particularly when these assessments\nlead to adverse outcomes\nin hiring,"
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "education, healthcare, or legal proceedings. These mechanisms should not place undue"
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "burdens on affected individuals and should include options for independent verification and"
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "correction of systemic biases rather than merely addressing individual complaints."
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "4.3.4\nMulti-stakeholder Governance Approach"
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "The complex ethical,\nlegal, and social\nimplications of Emotional AI necessitate a governance"
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "approach that engages diverse stakeholders in complementary roles. No single entity —"
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "whether governmental, corporate, or civil society —possesses the comprehensive perspective"
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "needed to address the multifaceted challenges that emotional\nintelligence systems present."
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "Instead, effective governance requires coordinated action across multiple domains."
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "Regulatory bodies at national and international\nlevels play essential roles in establishing"
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "baseline requirements for emotional AI systems. These include mandatory disclosure of"
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "emotional recognition capabilities, minimum standards for accuracy and fairness across"
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "demographic groups,\nlimitations on specific applications (such as emotion recognition in"
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "high-stakes decision-making), and enforcement mechanisms for violations. The European"
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "Union’s AI Act represents a significant step in this direction, with its explicit attention"
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "to emotion recognition technologies and risk-based regulatory approach. However,\nformal"
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "regulation must be supplemented by more dynamic and responsive governance mechanisms."
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "Industry self-regulation complements governmental oversight, enabling rapid adaptation to"
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "technological developments and emerging risks.\nIndustry initiatives can establish technical"
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "standards for emotional data protection, ethical, emotional AI certification programs, and"
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "best practice frameworks that exceed minimum regulatory requirements. Organizations"
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "like the IEEE Global\nInitiative 2.0 on Ethics of Autonomous and Intelligent Systems"
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "have begun developing such standards,\nthough implementation remains voluntary and"
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "inconsistent across the sector. More robust industry governance would include independent"
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "assessment mechanisms, transparency in algorithmic impact assessments, and sanctions for"
        },
        {
          "Justice in emotional AI also extends to accessibility considerations. People with neurological": "non-compliance with established standards."
        }
      ],
      "page": 15
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Civil society organizations contribute essential perspectives from communities that may": "be affected by emotional AI, providing critical scrutiny of both regulatory and industry"
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "approaches. These organizations advocate for marginalized groups whose emotional expres-"
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "sions may be misinterpreted or whose vulnerabilities might be exploited by emotionally"
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "intelligent systems. They also conduct independent research on social and psychological\nim-"
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "pacts, develop conceptual\nframeworks for understanding emotional data rights, and educate"
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "the public about interactions with emotionally intelligent systems. The involvement of civil"
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "society helps ensure that governance frameworks address not only technical performance"
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "metrics but also broader societal\nimplications."
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "Academic institutions offer crucial theoretical\nfoundations and empirical evidence to inform"
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "governance approaches.\nInterdisciplinary research spanning computer science, psychology,"
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "ethics,\nlaw, and social sciences provides insights into the technical\nlimitations, psychological"
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "effects, and societal\nimpacts of emotional AI. Academic work can identify emerging risks"
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "before they manifest at scale, evaluate the effectiveness of various governance mechanisms,"
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "and propose innovative approaches to strike a balance between innovation and protecting"
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "fundamental rights and values."
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "User engagement represents the most frequently overlooked but essential component of"
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "effective governance. Users of emotional AI\nsystems\nshould actively define acceptable"
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "practices,\nidentify concerns, and evaluate proposed safeguards. This engagement should"
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "extend beyond token consultation to meaningful participation in system design, policy"
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "development, and impact assessment. User perspectives are particularly valuable in identi-"
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "fying the contextual\nfactors that influence emotional analysis and response appropriateness"
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "in different situations."
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "4.3.5\nFuture Directions and Recommendations"
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "As affective computing advances and emotional\nintelligence becomes increasingly integrated"
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "into AI systems, several key research, policy, and practice directions emerge."
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "First, research into emotional diversity must be prioritized to address current limitations"
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "in recognizing and responding to human emotional experiences. This includes expanded"
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "studies of emotional expression across cultures,\ninvestigation of emotional communication"
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "in neurodiverse populations, and exploration of complex, mixed, and culturally specific"
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "emotional states that may not fit neatly into dominant psychological models. Such research"
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "should employ participatory methods that engage diverse communities as collaborators"
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "rather than merely subjects of study."
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "Second, privacy-preserving techniques for emotion recognition warrant significant investment."
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "Current approaches often require the extensive collection and centralized processing of"
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "sensitive, emotional data, creating substantial privacy risks. Techniques\nlike federated"
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "learning, differential privacy, and on-device processing could enable emotional\nintelligence"
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "while minimizing data exposure. Similarly, systems should be designed to forget emotional"
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "data after use rather than accumulating increasingly comprehensive emotional profiles of"
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "individuals over time."
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "Third, context-sensitive governance frameworks must be developed to address the varying"
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "implications of emotional AI across different domains. The appropriate standards, safe-"
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "guards, and limitations for emotional analysis in healthcare settings differ substantially"
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "from those needed in educational contexts, workplace environments, or consumer applica-"
        },
        {
          "Civil society organizations contribute essential perspectives from communities that may": "tions. Domain-specific guidelines should be co-created with relevant stakeholders,\nincluding"
        }
      ],
      "page": 16
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "professionals working in these fields and the individuals whose emotional data might be": "processed."
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "Fourth,\ninterdisciplinary education and training programs are necessary to develop profes-"
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "sionals who can navigate the technical, ethical,\nlegal, and social dimensions of emotional"
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "AI. Current educational pathways typically separate these domains, resulting in computer"
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "scientists with a limited understanding of emotional psychology, psychologists with minimal"
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "technical knowledge of AI systems, and legal scholars unfamiliar with both.\nIntegrated"
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "approaches to education would better prepare the next generation of researchers, developers,"
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "and policymakers to address the complex challenges of emotionally intelligent systems."
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "Fifth, ongoing monitoring and evaluation mechanisms\nshould be established to assess"
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "the impacts of emotional AI systems after deployment. These mechanisms should track"
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "technical performance metrics, psychological\neffects on users,\nsocial\nconsequences\nfor"
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "different communities, and evolving public attitudes toward emotional AI. Findings from"
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "such assessments should inform iterative improvements to technical systems and governance"
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "frameworks."
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "Ultimately,\ninternational cooperation on the governance of emotional AI should be strength-"
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "ened to prevent regulatory fragmentation and establish shared principles across jurisdictions."
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "While cultural differences may necessitate some variation in specific standards and ap-"
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "proaches, core values such as respect for human dignity, protection of vulnerable populations,"
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "and preservation of emotional autonomy can provide common ground for global governance"
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "efforts."
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "5.\nConclusion"
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "Integrating emotional\nintelligence into AI systems represents a transformative opportunity"
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "and a significant challenge for technology governance. Affective computing enables more"
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "natural and responsive human-computer interaction, opening new possibilities for healthcare,"
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "education, and personal well-being applications. However, as machines gain an increased"
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "capacity to recognize,\ninterpret, and respond to human emotions, we must carefully consider"
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "the implications for privacy, autonomy,\nfairness, and the fundamental nature of emotional"
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "experience."
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "This paper\nexamines\nthe\ntechnical\nfoundations of affective\ncomputing, which involves"
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "transforming human emotions into structured data, and the emerging regulatory frameworks"
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "governing emotional AI. Through analysis of current approaches and the case study of"
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "ChatGPT-4.5, we have identified key challenges in ensuring the responsible development"
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "and deployment of emotionally intelligent systems. These challenges cannot be addressed"
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "solely through technical solutions or resolved by regulatory intervention alone.\nInstead,"
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "they require a multidimensional approach integrating technical\ninnovation, ethical reflection,"
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "legal\nframeworks, and inclusive stakeholder engagement."
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "The path forward demands balancing seemingly competing values: advancing emotional AI"
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "capabilities while protecting privacy, enabling personalization while preventing manipulation,"
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "recognizing universal aspects of emotion while respecting cultural diversity, and maintaining"
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "human connection while incorporating technological mediation. Navigating these tensions"
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "requires ongoing dialogue across disciplines and sectors, with a particular focus on voices"
        },
        {
          "professionals working in these fields and the individuals whose emotional data might be": "that have been historically marginalized in technology governance."
        }
      ],
      "page": 17
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "approaches, and governance structures will shape the future relationship between humans": "and emotionally intelligent machines. By emphasizing human dignity, autonomy, and well-"
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "being as guiding principles in this development, we can harness the potential of emotional"
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "AI while safeguarding the richness and authenticity of human emotional experience in the"
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "digital age."
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "6.\nReferences"
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "Barrett, L. F. (2017). How emotions are made: The secret life of the brain. Houghton"
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "Mifflin Harcourt."
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "Busso, C., Bulut, M., Lee, C. C., Kazemzadeh, A., Mower, E., Kim, S., Chang, J. N., Lee,"
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "S., & Narayanan, S. S. (2008).\nIEMOCAP: Interactive emotional dyadic motion capture"
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "database. Language Resources and Evaluation, 42(4), 335-359."
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "California Privacy Rights Act.\n(2020). California Civil Code § 1798.100-1798.199.100."
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "Devlin, J., Chang, M. W., Lee, K., & Toutanova, K.\n(2019).\nBERT: Pre-training of"
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "deep bidirectional transformers for language understanding.\nIn Proceedings of the 2019"
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "Conference of the North American Chapter of the Association for Computational Linguistics:"
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "Human Language Technologies, Volume 1 (pp. 4171-4186). Ekman, P. (1992). An argument"
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "for basic emotions. Cognition & Emotion, 6(3-4), 169-200."
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "Ekman, P., & Friesen, W. V. (1982). Felt,\nfalse, and miserable smiles. Journal of Nonverbal"
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "Behavior, 6(4), 238-252."
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "REGULATION (EU) 2024/1689 OF THE EUROPEAN PARLIAMENT AND OF THE"
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "COUNCIL of 13 June 2024 laying down harmonised rules on artificial\nintelligence and"
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "amending Regulations (EC) No 300/2008, (EU) No 167/2013, (EU) No 168/2013, (EU)"
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "2018/858, (EU) 2018/1139 and (EU) 2019/2144 and Directives 2014/90/EU, (EU) 2016/797"
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "and (EU) 2020/1828 (Artificial Intelligence Act)."
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "Fabian Benitez-Quiroz, C., Srinivasan, R., & Martinez, A. M. (2016). EmotioNet: An"
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "accurate, real-time algorithm for the automatic annotation of a million facial expressions"
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "in the wild.\nIn Proceedings of\nthe IEEE Conference on Computer Vision and Pattern"
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "Recognition (pp. 5562-5570)."
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "Felbo, B., Mislove, A., Søgaard, A., Rahwan, I., & Lehmann, S. (2017). Using millions of"
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "emoji occurrences to learn any-domain representations for detecting sentiment, emotion"
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "and sarcasm.\nIn Proceedings of the 2017 Conference on Empirical Methods in Natural"
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "Language Processing (pp. 1615-1625)."
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "Goodfellow, I. J., Erhan, D., Carrier, P. L., Courville, A., Mirza, M., Hamner, B., Cukierski,"
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "W., Tang, Y., Thaler, D., Lee, D. H., Zhou, Y., Ramaiah, C., Feng, F., Li, R., Wang,"
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "X., Athanasakis, D., Shawe-Taylor, J., Milakov, M., Park, J.,\n. . . & Bengio, Y. (2013)."
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "Challenges in representation learning: A report on three machine learning contests. Neural"
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "Networks, 64, 59-63."
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep residual\nlearning for image recognition."
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "In Proceedings of\nthe IEEE Conference on Computer Vision and Pattern Recognition"
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "(pp. 770-778)."
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "Hochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural Computation,"
        },
        {
          "approaches, and governance structures will shape the future relationship between humans": "9(8), 1735-1780."
        }
      ],
      "page": 18
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "LeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. Nature, 521(7553), 436-444.": ""
        },
        {
          "LeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. Nature, 521(7553), 436-444.": ""
        },
        {
          "LeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. Nature, 521(7553), 436-444.": "person and a limited agent."
        },
        {
          "LeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. Nature, 521(7553), 436-444.": "Picard, R. W. (1997). Affective computing. MIT Press."
        },
        {
          "LeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. Nature, 521(7553), 436-444.": ""
        },
        {
          "LeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. Nature, 521(7553), 436-444.": "model of emotional self-report. Psychological Bulletin, 128(6), 934-960."
        },
        {
          "LeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. Nature, 521(7553), 436-444.": ""
        },
        {
          "LeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. Nature, 521(7553), 436-444.": "networks.\nIn Proceedings of"
        },
        {
          "LeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. Nature, 521(7553), 436-444.": "(pp. 6105-6114)."
        }
      ],
      "page": 19
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "",
      "authors": [
        "References"
      ],
      "venue": ""
    },
    {
      "citation_id": "2",
      "title": "How emotions are made: The secret life of the brain",
      "authors": [
        "L Barrett"
      ],
      "year": "2017",
      "venue": "How emotions are made: The secret life of the brain"
    },
    {
      "citation_id": "3",
      "title": "IEMOCAP: Interactive emotional dyadic motion capture database",
      "authors": [
        "C Busso",
        "M Bulut",
        "C Lee",
        "A Kazemzadeh",
        "E Mower",
        "S Kim",
        "J Chang",
        "S Lee",
        "S Narayanan"
      ],
      "year": "2008",
      "venue": "Language Resources and Evaluation"
    },
    {
      "citation_id": "4",
      "title": "California Civil Code §",
      "year": "2020",
      "venue": "California Civil Code §"
    },
    {
      "citation_id": "5",
      "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "authors": [
        "J Devlin",
        "M Chang",
        "K Lee",
        "K Toutanova"
      ],
      "year": "1992",
      "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies"
    },
    {
      "citation_id": "6",
      "title": "Felt, false, and miserable smiles",
      "authors": [
        "P Ekman",
        "W Friesen"
      ],
      "year": "1982",
      "venue": "Journal of Nonverbal Behavior"
    },
    {
      "citation_id": "7",
      "title": "OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL of 13 June 2024 laying down harmonised rules on artificial intelligence and amending Regulations (EC) No 300",
      "year": "2008",
      "venue": "REGULATION"
    },
    {
      "citation_id": "8",
      "title": "EmotioNet: An accurate, real-time algorithm for the automatic annotation of a million facial expressions in the wild",
      "authors": [
        "Fabian Benitez-Quiroz",
        "C Srinivasan",
        "R Martinez"
      ],
      "year": "2016",
      "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition"
    },
    {
      "citation_id": "9",
      "title": "Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm",
      "authors": [
        "B Felbo",
        "A Mislove",
        "A Søgaard",
        "I Rahwan",
        "S Lehmann"
      ],
      "year": "2017",
      "venue": "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "10",
      "title": "Challenges in representation learning: A report on three machine learning contests",
      "authors": [
        "I Goodfellow",
        "D Erhan",
        "P Carrier",
        "A Courville",
        "M Mirza",
        "B Hamner",
        "W Cukierski",
        "Y Tang",
        "D Thaler",
        "D Lee",
        "Y Zhou",
        "C Ramaiah",
        "F Feng",
        "R Li",
        "X Wang",
        "D Athanasakis",
        "J Shawe-Taylor",
        "M Milakov",
        "J Park",
        ". Bengio"
      ],
      "year": "2013",
      "venue": "Neural Networks"
    },
    {
      "citation_id": "11",
      "title": "Deep residual learning for image recognition",
      "authors": [
        "K He",
        "X Zhang",
        "S Ren",
        "J Sun"
      ],
      "year": "2016",
      "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition"
    },
    {
      "citation_id": "12",
      "title": "Long short-term memory",
      "authors": [
        "S Hochreiter",
        "J Schmidhuber"
      ],
      "year": "1997",
      "venue": "Neural Computation"
    },
    {
      "citation_id": "13",
      "title": "Deep learning",
      "authors": [
        "Y Lecun",
        "Y Bengio",
        "G Hinton"
      ],
      "year": "2015",
      "venue": "Nature"
    },
    {
      "citation_id": "14",
      "title": "The SEMAINE database: Annotated multimodal records of emotionally colored conversations between a person and a limited agent",
      "authors": [
        "G Mckeown",
        "M Valstar",
        "R Cowie",
        "M Pantic",
        "M Schroder"
      ],
      "year": "2012",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "15",
      "title": "Affective computing",
      "authors": [
        "R Picard"
      ],
      "year": "1997",
      "venue": "Affective computing"
    },
    {
      "citation_id": "16",
      "title": "Belief and feeling: Evidence for an accessibility model of emotional self-report",
      "authors": [
        "M Robinson",
        "G Clore"
      ],
      "year": "2002",
      "venue": "Psychological Bulletin"
    },
    {
      "citation_id": "17",
      "title": "EfficientNet: Rethinking model scaling for convolutional neural networks",
      "authors": [
        "M Tan",
        "Q Le"
      ],
      "year": "2019",
      "venue": "Proceedings of the 36th International Conference on Machine Learning"
    }
  ]
}