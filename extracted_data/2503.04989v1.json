{
  "paper_id": "2503.04989v1",
  "title": "Application Of Integrated Gradients Explainability To Sociopsychological Semantic Markers",
  "published": "2025-03-06T21:35:24Z",
  "authors": [
    "Ali Aghababaei",
    "Jan Nikadon",
    "Magdalena Formanowicz",
    "Maria Laura Bettinsoli",
    "Carmen Cervone",
    "Caterina Suitner",
    "Tomaso Erseghe"
  ],
  "keywords": [
    "Agency",
    "BERTAgent",
    "classification",
    "explainability",
    "integrated gradients",
    "interpretable AI",
    "natural language processing",
    "overfitting",
    "RoBERTa",
    "saliency",
    "sentiment analysis",
    "semantic markers",
    "sociopsychological markers",
    "word-level analysis"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Classification of textual data in terms of sentiment, or more nuanced sociopsychological markers (e.g., agency), is now a popular approach commonly applied at the sentence level. In this paper, we exploit the integrated gradient (IG) method to capture the classification output at the word level, revealing which words actually contribute to the classification process. This approach improves explainability and provides in-depth insights into the text. We focus on sociopsychological markers beyond sentiment and investigate how to effectively train IG in agency, one of the very few markers for which a verified deep learning classifier, BERTAgent, is currently available. Performance and system parameters are carefully tested, alternatives to the IG approach are evaluated, and the usefulness of the result is verified in a relevant application scenario. The method is also applied in a scenario where only a small labeled dataset is available, with the aim of exploiting IG to identify the salient words that contribute to building the different classes that relate to relevant sociopsychological markers. To achieve this, an uncommon training procedure that encourages overfitting is employed to enhance the distinctiveness of each class. The results are analyzed through the lens of social psychology, offering valuable insights.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "E XTRACTING semantic information, for example, senti- ment, from textual data is now a widespread application of natural language processing (NLP) techniques based on available deep learning tools. It is widely applied in various fields, including advertising, financial risk assessment, consumer insights, and government affairs, among others  [1] . The literature on these topics is vast, including, only for the keyword \"sentiment classification,\" more than 2,000 articles per year in the last five years (source: Scopus).\n\nThe deep learning models in use span from convolutional neural networks (CNNs), to recurrent neural networks (RNNs), to long-short term memorys (LSTMs)  [2] . However, the most powerful techniques exploit the socalled \"Transformer architecture,\" using an attention-based deep learning mechanism  [3]  where the language model (e.g., BERT  [4] , RoBERTa  [5] , or GPT  [6] -  [8] ) is pre-trained on huge datasets and is therefore able to fully interpret the complexity of language. The undisputed superiority of pretrained algorithms based on the Transformer architecture is evident from the literature  [9] . 1 Such models have been used to identify sentiment, but also other linguistic features, for example emotions such as anger, sadness, and happiness  [12] ,  [13] , or more nuanced aspects such as offensive language, hate speech, sarcasm, and irony  [14] ,  [15] . More recently, these models have been applied to the identification of agency, which is the focus on goal orientation and achievement  [11] . However, numerous other theoretical constructs such as sexualization, affection, depression, and affiliation can be associated with linguistic markers (see also  [10] ).\n\nAvailable approaches commonly evaluate sentiment, or any other linguistic marker, at the sentence or document level, meaning that each text is classified into a single value. Although extremely valuable, this approach has a limitation: we are not aware of what part of the text (i.e., which words) effectively contributes to the prediction, and the role of text elements (i.e., words) is obscured by the complex deep learning mechanism. However, this information could be highly valuable as an additional signal for researchers, as it provides a more readable result in an \"explainable AI (XAI)\" manner. Using XAI methods helps to determine how specific terms influence the sentiment of a text. These methods offer several benefits, including increasing model accountability for its decisions, providing insight into factors that shape sentiment, and supporting industries such as finance and healthcare, where regulatory frameworks re-1. For sentiment-like detection and classification there exist many alternative methods, other than deep learning, that can be used, such as the widely used and validated dictionary word count (DWC) approach of  [10] . However, these methods lack the power of large language models (e.g., contextual information at the sentence level, automatic management of negations, etc.  [11] ). For this reason, they are not always effective and, therefore, are not considered. quire explanations of model outputs  [16] . A solution to this problem is given by the integrated gradient (IG) approach, which is widely used for interpretable AI recommendations due to its interesting properties: it measures the importance of features by averaging the model output gradient along a straight path and is computationally efficient. Furthermore, it has the desired completeness property, which means that the attributions add up to the target output when a baseline is carefully chosen  [17] . Although IG is classically applied to images, recent research has highlighted its role in NLP, especially in relation to sentiment analysis  [18] -  [21] . Improvements to the baseline IG approach are also available, for example, the sequential-IG approach that computes the importance of each word in a sentence by keeping all other words fixed and only generating interpolations between the baseline and the word of interest  [22] , or the discretized-IG approach, which uses a more effective attribution along non-linear interpolation paths  [23] . Methods alternative to IG exist for interpreting the Transformer architecture, such as DeepLIFT  [24]  or SHAP  [25] ,  [26] , and their effectiveness is analyzed in this paper.\n\nIn this paper, we exploit the integrated gradient (IG) method  [27]  to access entity-level information (i.e., wordlevel) for sociopsychological markers other than sentiment. Specifically, we focus on agency, an important construct, one of the very few markers for which a pre-trained and verified NLP predictor, BERTAgent  [11] , is available. We exploit BERTAgent to both optimize the IG parameters and to verify the suitability of the IG approach for the task. This part covers a scenario where large labeled datasets are available for adequate training of the chosen sociopsychological marker (e.g., agency in the BERTAgent case). However, since a question arises as to what can be done in the most common situation where only labeled datasets of limited or very limited size are accessible (as large labeled datasets are not always available and are often difficult to obtain), we further demonstrate the usefulness of the IG approach in these cases for a diverse collection of alternative markers. Specifically, we devise an NLP training procedure aimed at classification that, unlike the common approach, encourages overfitting so that the subsequent application of the IG rationale can identify those words that most agree with the identification of the different classes (e.g., different levels of markers such as positive, negative, and neutral). In this way, we show how IG is able to provide a detailed description of the classes and, more importantly, of the salient words that differentiate the classes. This is a valuable asset for data explainability and can be particularly useful for building those dictionaries that constitute the starting point in the creation of large labeled datasets.\n\nThe remainder of the paper is organized as follows. In Section 2 we introduce all the algorithms that are used throughout the paper, as well as the datasets used. Section 3 presents the application of IG in a context where a large dataset is available to build a reliable NLP model. For this task, we selected the pre-trained BERTAgent agency predictor available from  [11]  and based on RoBERTa. 2 We 2. We incidentally note that recent studies actually highlighted the effectiveness of RoBERTa over other PLMs in sentiment analysis and emotion detection  [28] .\n\nuse it as a test case to identify the most relevant system parameters for IG, namely, integration step and baseline, as well as to compare the performance of IG with stateof-the-art alternatives using sufficiency, compactness and comprehensiveness criteria  [29] . An application example of the resulting tool is also presented, where highlights in text prepared by experts are compared to the outcome of the IG approach to assess the extent to which the highlighted sections, which pertain to collective action intentions and heavily rely on agentic motives  [30] , are filled with agentic content. The application of IG under a small dataset scenario is presented in Section 4, where alternative sociopsychological markers are discussed, to demonstrate the potential of the proposed approach. An interpretation through the lens of sociopsychological theories further emphasizes the usefulness of the method. Section 5 concludes the paper.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Methods And Materials",
      "text": "We first review the algorithms used throughout the paper, including those that allow explainability at the word level (e.g., IG), the quality measures used to compare their performances and select appropriate system parameters, and the datasets used.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Algorithms For Explainability At The Word Level",
      "text": "To have a complete overview of the performance of algorithmic solutions available in the literature, in addition to the standard IG approach, both recent improvements on IG and alternative approaches were tested. Specifically, we consider the following:\n\n• IG: This is the reference IG algorithm of  [27] , implementing gradient integration along a straight path from a baseline input x 0 to the tested input x in the form\n\nwhere a is the attribution output, F is the classification model (here based on RoBERTa), and ∇ is the gradient operator. x 0 and x represent the input embeddings of words in a sentence. The variable u is an intermediate input vector along the straight-line path connecting the baseline x 0 to the tested input x. IG possesses the completeness property\n\nThis ensures that the attribution sums equal the output of the transformer model whenever the baseline output is zero, F (x 0 ) = 0, which is a desired property. IG is implemented via successive evaluations of the gradient along the line connecting x 0 to x, in the form\n\nwhere ∆ = 1 N (x -x 0 ) is the step vector, N is the number of steps in the Riemann approximation of the integral, × is an entry-wise multiplication among vectors, and ∇ is the gradient numerically computed by backpropagation.\n\n• Sequential IG: This method is based on the IG approach, but calculates the importance of each word in a sentence by creating an ad hoc baseline x 0 for that word, where every other word is held fixed and the reference word is replaced by a MASK token embedding  [22] . Due to its iterative nature, it adds complexity to the standard IG approach and also loses the completeness property.\n\n• Discretized IG: This approach uses a more effective attribution along nonlinear interpolation paths, based on the rationale that \"straight-line interpolated points are not representative of text data due to the inherent discreteness of the word embedding space\"  [23] . Although it retains the completeness property, it is computationally expensive and requires searching for close words in the embedding space. Moreover, it does not provide any consistent improvement over IG when run on a RoBERTa model  [23] , and for this reason, it will not be considered further in this paper.\n\n• DeepLIFT: This method extends the IG concept by backpropagating activation differences, in such a way as to permit the information to propagate even when the gradient is zero, allowing us to identify dependencies missed by other methods  [24] .\n\n• GradientSHAP: This technique exploits Shapley values, a concept from game theory, to attribute an importance score to each part of the input  [25] ,  [26] ,  [31] . It has been applied to different approaches ranging from IG (GradientSHAP) to DeepLIFT (DeepSHAP). In this paper, we consider the SHAP implemetation enhancing IG.\n\nAll algorithms are tested in Python using the open source PyTorch CAPTUM library 3 and run on GPU resources.\n\nAs previously discussed, IG based approaches are dependent on two main parameters, the number of steps N and the baseline input x 0 . We therefore test the algorithms for optimal performance by varying these parameters according to the following approach:\n\n• Number of steps: the integration step is known to have an impact on the quality of IG attributions, with the correct value largely dependent on the specific application  [32] ; a reference range N ∈ [20, 1000] is available for applications of the Transformer architecture, and we therefore take it as our reference for testing purposes.\n\n• Baseline input: The choice of the baseline input should ensure that F (x 0 ) is as close as possible to the zero value, to allow the sum of the association values to correspond to the target output F (x). For this reason, the baseline embedding x 0 is built to retain the CLS, SEP, and PAD token embeddings (so that their association values remain zero) while setting the remaining embeddings to a reference value chosen among the following inspired by the literature (e.g., see  [33] ):\n\n3. https://captum.ai -zero: the baseline embedding is filled with zero values. -mask: the baseline embedding is filled with MASK token embeddings. -padding: the baseline embedding is filled with PAD token embeddings. -mean: the baseline embedding is filled with the mean value calculated on the whole set of RoBERTa input embeddings.\n\nWe underline that the baseline choice is known to have an impact on the performance, and only an appropriate baseline choice is able to generate reliable attributions.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Quality Measures",
      "text": "For comparison purposes between different algorithms and different settings, we selected two faithfulness measures from  [34] , namely comprehensiveness and sufficiency, as well as an approximation error that evaluates the deviation from the output of the ideal model  [32] . Faithfulness metrics evaluate whether the important features identified by the algorithms are genuinely important (comprehensiveness) and sufficient (sufficiency) to make predictions. These metrics are assessed by masking features in the order of their importance scores and analyzing how the model predictions change  [35] . Specifically, we define:\n\n•",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Comprehensiveness:",
      "text": "The output is tested against x and a counterpart x c f where a fraction f of words is removed. The words removed correspond to the top scoring attribution values (in absolute value)  [36] . We calculate\n\nComprehensiveness naturally increases with f , and a higher comprehensiveness indicates better algorithm performance, as the best scores contribute more significantly to the prediction.\n\n• Sufficiency: The output is tested against x and a counterpart x s f , which is the complement of x c f . In x s f , the fraction f of the top-scoring attribution values (in absolute value) is retained, and the remaining words are removed  [36] . We calculate\n\nSufficiency naturally decreases with f , and lower sufficiency values indicate better algorithm performance.\n\n• Approximation error: This is a normalized measure  [32]\n\nIt measures the deviation of the actual computed value from the theoretical value. This metric equals zero in the case of ideal integration and captures the deviation from ideality based on the choice of the number of steps N .\n\nAll measures were implemented using Python.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Datasets",
      "text": "In order to test different algorithmic approaches, we selected a few datasets covering distinct content, as well as distinct sentence ranges. Specifically, we have:\n\n• #covid19 a dataset of covid19 Twitter posts collected during the period from February 11 to April 11, 2020, using the hashtag #covid19 in the search; 1000 tweets per week were selected among the most influential, i.e. those that received the most reactions, replies, likes and quotes; the dataset is taken from  [37] .\n\n• IMDB a set of 50K reviews of highly popular movies, allowing no more than 30 reviews per movie, typically used for binary sentiment classification  [38] ; the dataset was collected in 2011, and contains an even number of positive and negative reviews; it is available from HuggingFace. 4   • slurs a set of 336 real or fictitious stories written by female participants in a 2022 questionnaire, describing a situation in which they experienced verbal aggression; the data is a subset including the two experimental conditions described in  [39] .\n\n• snippets a collection of very short Twitter posts of a maximum of 5 words taken from the TweetEval dataset; specifically, we use \"SemEval 2018 Task 1: Affect in Tweets\" dataset, which focuses on detecting emotional content in social media posts  [40] .\n\nTo ensure correct input to our classifiers, the datasets \"IMDB\" and \"slurs\", which contain very long texts, were split into sentences to control the text length. A superficial cleaning was also applied to all datasets in order to remove mentions, html links, special characters, and double spaces, where present. The text length distribution (number of tokens distribution) of the datasets is reported in Fig.  1 . Note how \"IMDB\" and \"slurs\" show an equivalent distribution (at the sentence level) mostly active in the range from 5 to 40, while the distribution of the \"#covid19\" dataset, where we kept the original tweets since they have a strict length limit, is active in a higher range, from 30 to 70. For the \"snippets\" database, the distribution is active in the lowest range of 0 to 40.\n\n4. https://huggingface.co/datasets/stanfordnlp/imdb\n\nTo further control the computational burden of the test campaign, we randomly selected a subset of text samples from each dataset to capture the entire range of active text lengths. Specifically, 1600 tweets equally distributed in the length range  [25, 64]  were selected from the #covid19 dataset (40 samples per text length), 1500 sentences equally distributed in the length range  [1, 49]  from the IMDB dataset (30 samples per text length), 1335 sentences equally distributed in the length range  [5, 40]  from the slurs dataset (approximately 40 samples per text length), and, finally, 300 tweets equally distributed in the length range  [2, 14]  from the snippets dataset (approximately 20 samples per text length). In such a way, the snippets dataset is targeted to short text samples, while the other datasets cover a wider range.\n\nAn additional dataset was used to verify the potential of the explainability approach, namely:\n\n• highlights a collection of 802 short texts (100-125 words) written by native English speakers (authors) on a socially relevant topic they deemed personally important. Authors were asked to \"review the list of socially relevant issues below 5 and select the one that resonates most with you and you believe it requires mobilizing others to take action in order to address it.\" After completing the writing task, authors highlighted the text fragments they considered most effective in mobilizing others. An identical highlight task was assigned to 2,347 independent participants (readers), with at least two readers evaluating each text (M= 2.4, SD= 0.76)  [41] . The data data used in the present paper were collected before December 3 rd 2025.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Word-Level Agency Prediction",
      "text": "",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Agency And Bertagent",
      "text": "In this application, relevant to the availability of large labeled datasets on which a robust classifier/regressor is trained, we concentrate on a specific sociopsychological marker called agency. Agency is defined as the capacity for goal orientation and the ability to plan and execute goal achievement  [42] -  [46] . This motivation is at the center of the functioning of individuals and since early childhood drives goal-oriented behavior  [47] ,  [48] . The achievement of goals is fundamental for individuals  [49] ,  [50]  and is related to outcomes such as social status, career success, and wellbeing  [51] -  [53] . However, goal achievement rarely occurs in isolation, as individuals often depend on others to facilitate or hinder their progress. This interdependence explains why humans are highly attuned to agency-related cues, such as biological motion  [54]  or causality, intentionality  [55] , which help navigate social dynamics and optimize cooperation or competition. Beyond these individual and interpersonal factors, agency is deeply embedded within a sociocultural framework that supports or limits one's ability to act and 5. List of socially relevant issues: raise awareness of mental health, prevent climate change and protect environment, increase voting turnout in elections, reduce economic inequality, increase volunteering, advocate for free speech, protect human rights, ensure food security and sustainable agriculture, and advocate for digital privacy and security.  achieve goals  [56] . By linking individual capacities, social interdependence, and cultural influences, agency serves as a unifying construct to understand collective dynamics. Consequently, agency plays a crucial role in fostering collective action, as it underpins the belief of individuals in their ability to make a meaningful impact toward shared goals  [30] . Psychological research highlights that people are more likely to participate in collective action when they believe that their efforts can lead to tangible results, reflecting a sense of achievable goals and personal influence  [57] -  [60] . We will rely on the link between agency and collective action in the validation study presented below.\n\nAgency can recently be automatically measured from text samples using BERTAgent, 6 a NLP model based on RoBERTa  [5] , trained on a large labeled dataset of samples generated from existing agency dictionaries available from the literature, and properly verified by a panel of experts  [11] . BERTAgent has been shown to outperform existing approaches for automated identification of agency level in text, and is therefore taken as our reference pre-trained NLP model to test IG capabilities. It comes as a ready-to-use Python package. It has recently been used to predict political participation in elections  [61] , call-to-action behavior before and after a significant event  [37] , and depression states through its negative connotation  [62] .",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "Parameters Selection In Ig",
      "text": "The performance of IG is illustrated in Fig.  2  and Fig.  4  with respect to the measures of comprehensiveness and sufficiency, in Fig.  3  with respect to the value of the baseline output and in Fig.  5  with respect to the approximation error. We comment on them in detail in the following. Fig.  2  shows comprehensiveness and sufficiency of the different datasets for the four different baseline choices.\n\nHere, the number of steps is fixed to N = 300, to guarantee a reliable outcome, as we will investigate later. As is evident from Fig.  2 , the performance dependency on the baseline choice is weak, since all behave very similarly. However, some interesting conclusions can be drawn. First, the mask baseline (in blue in the figure) consistently shows the worst behavior in both comprehensiveness (lower curve) and sufficiency (higher curve, at least in the lower range of f ). An analysis of the error regions (not shown in the figure for the sake of readability) further shows that the difference is statistically significant, that is, the mask baseline regularly provides the worst performance. zero, mean, and padding instead provide the best performance and essentially show equivalent behavior.\n\nTo further investigate the choice of the baseline, Fig.  3  shows the value of the baseline output F (x 0 ) as a function of the length of the text (number of tokens k). In this case, the lower the baseline output value F (x 0 ), the better the approach, since the deviation of the sum of attributions with respect to the true value F (x) is controlled (see also  (2) ). Above in Fig.  3  we display the true value of the baseline output, which is then normalized by the text length k below in the figure in order to capture the average contribution on each single token, that is, its real impact. From the figure, we clearly see that the mask baseline (in blue) shows pretty constant behavior that, however, is constantly outperformed by the zero baseline (in yellow). Padding baseline (in red) and mean baseline (in green) exhibit a similar behavior, with a peak at low k, and a high saturation value at large k, with mean providing the highest values. They are also outperformed by the zero baseline, except for a very small region in the interval k ∈  [10, 20]  where, however, we observe the lowest values of F (x 0 ). For this reason, the zero baseline is the preferred choice, as it exhibits the best or the highest performance throughout k.\n\nSome further insights are provided in Fig.  4  and Fig.  5  regarding the choice of the number of steps N . In general, as we can appreciate from Fig.  4 , the role of the parameter N is not captured by comprehensiveness and sufficiency measures, at least for N in a reasonable range N ≥ 50. In fact, the curves in Fig.  4  almost perfectly superpose. We observe that, although in Fig.  4  we show a result for the Snippets dataset with zero baseline only, this behavior was found to be consistent over the different datasets and the different baseline choices, although we do not show this explicitly, as it carries little information.\n\nThe role of the number of steps N is better captured by the approximation error statistics displayed in Fig.  5  for N that spans in 50, 100, 300, 700, and 1000, and for different choices of the baseline. We separately report the statistic for the aggregated datasets (above) and the Snippets dataset only (below). The box plot reports the 25%, 50%, and 75% quartiles (colored box) and outliers. From the plot above in Fig.  5  we clearly see that the best performance is achieved with zero and baselines, a small loss is experienced by the padding baseline, while the mean baseline provides the worst performance. Note how the performance tends to saturate for a number of steps greater than or equal to N = 300, especially for zero and mask. This saturation effect, which we verified to be associated with the performance for short sentences, is evidenced by the plot below in Fig.  5 , practically setting N = 300 as a reliable choice. In conclusion, the most reliable choice for IG is identified in the zero baseline, as it consistently provides among the best performance in comprehensiveness and sufficiency (see Fig.  2 ), the most reliable baseline output values (see Fig.  3 ) and among the best performance in approximation error (Fig.  5 ). The number of steps is set to N = 300, this choice being able to provide a highly reliable outcome, especially for short sentences (see Fig.  5 , below).",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Algorithm Choice",
      "text": "The comparison of IG with alternative approaches is reported in Fig.  6  and Fig.  7  for SequentialIG (sig in figure), DeepLIFT, and GradientSHAP (shap in figure). In the figures, IG is implemented with a zero baseline and N = 300, SequentialIG with a zero baseline and N = 300 for the snippets dataset and N = 50 for the other datasets due to its high computational complexity, while DeepLIFT and GradientSHAP are run with their reference implementation. In general, the processing burden of DeepLIFT and Gradi-entSHAP is about 10% of that of IG (they are very fast algorithms), while SequentialIG runs at least 10 times longer than IG due to its iterative nature.\n\nIn the comparison given in Fig.  6 , we can clearly observe how DeepLIFT and GradientSHAP consistently provide the worst performance in terms of both comprehensiveness and sufficiency, in the four data sets, which is consistent with the findings of  [23] . In the comparison between IG and SequentialIG, instead, the expected improvement of the sequential approach does not occur, with the exception of comprehensiveness in the \"snippets\" dataset. A further inspection of the result as a function of the number of tokens, available in Fig.  7 , confirms this trend: an improvement is available only for comprehensiveness when considering very short text snippets of length of up to 10 tokens. Evidently, this outcome does not justify the computational burden of SequentialIG, and identifies IG as the preferred choice.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Rendering The Ig Output To A Readable Form",
      "text": "Having assessed IG with zero baseline and N = 300 steps as our reference approach, some additional steps are needed to build a proper tool. Specifically, the raw IG output should be processed for readability, and we propose to graphically render it as follows:\n\n• The RoBERTa tokenizer often splits words into a number of tokens, for example These people are lazy and unm ot ivated ,  (7)  where darker highlights correspond to a stronger association value and where in this case it is the word \"unmotivated\" to be split into three tokens; to prevent this effect, we exploit the more readable token structure provided by SpaCy, and align the RoBERTa tokens to it by taking advantage of the offset information; specifically, every time a word is split into many tokens the corresponding attributions are added to provide a unique value, to get SpaCy associations of the form These people are lazy and unmotivated .\n\n(8)\n\n• Negations often carry most of the association meaning although, conceptually, the association should be also linked to the word that is negated; for example, for the negative agency sentence These people are not lazy at all ! (9) the word \"not\" is carrying most of the association value while, in practice, we would like the couple \"not lazy\" to carry the positive agentic meaning; in this case we again exploit SpaCy to identify such couples and provide a more readable result where the two words are linked and are charged with the sum of their agencies, that is These people are not lazy at all !  (10)  the underlying rationale being that of associating a negation with the word or the verb it refers to, and, in case of an auxiliary verb, to further add the adjectival complement (acomp, e.g., \"not be lazy\"), or the passive auxiliary (auxpass, e.g., \"never been unmotivated\") parts, in order to select the full meaning.\n\nThe phrasal verb particle (prt, e.g. \"shut down\") is also included.\n\n• Some of the associations might have a sign which is not coherent with the overall agency value; for example, in a sentence that carries, overall, a positive agency, namely\n\nThis person is far from being lazy !  (11)  the words \"person\" and \"lazy\" carry negative association values, but this might be confusing; for this reason, in the visual representation of agency at the word-level, we set to zero association all those values that carry a weight which is not coherent with the overall agency, to have This person is far from being lazy ! (12)\n\n• Finally, in order to facilitate the interpretation of the outcome, the maximum association value is normalized to the actual agency value F (x), in such a way that lower agency is rendered by a weaker colour; for example Join our next #fridays4future strike !  (13)  which, in the comparison with  (12) , is rendered in a weaker green colour since it carries a lower agency level.\n\nIn general, the above preprocessing steps can hide the more technical aspects of IG, while keeping its core message. They allow a reliable visual interpretation of the association values and are, for this reason, adequate for a proper interpretation of the quality of the IG approach.\n\nThe reference code implementing these features is available at https://github.com/ali-abbi/agency-ig.",
      "page_start": 7,
      "page_end": 8
    },
    {
      "section_name": "Evaluation Of Plausability",
      "text": "In order to further prove the effectiveness and plausibility of the chosen IG approach, we exploit the highlights dataset, namely a collection of 802 texts written by English native speakers on a specific subject (see above for dataset description) with the intention of motivating the reader to action, that is, naturally carrying a high level of agency. For each text, the author and two or three additional expert readers were asked to highlight which portions of the text carry the most relevant part of the call-to-action. We would therefore expect that the highlight captures the highest agency levels (at the word level).\n\nTo our aim, the texts were divided into sentences and only those sentences that were (partially or totally) highlighted were retained. For each sentence, the following measures were identified:\n\n• the overall agency level, a;\n\n• the highlight fraction f h , namely what fraction of words were highlighted, ranging from 0 to 1;\n\n• the amount of agency contained in the highlight, a h , evaluated via the IG attribution output; for the sake of readability of the result, the attribution output was preliminarily polished according to the rendering procedure described in Section 3.4, were, in particular, in a positive (negative) agentic text all negative (positive) attributions were set to zero and the resulting values were rescaled in order for their sum to provide the true agency level a;\n\n• the maximum agency level a max for the considered highlight, that is, the sum of the strongest agency levels up to the highlight length, with a polishing procedure equivalent to the one applied for a h ;\n\n• the agency level captured in case as many words as in the highlight are selected, but these are selected at random in such a way to capture the overall noise level.\n\nObserve that we have a h ≤ a max ≤ a for a positive agentic text and reverse ordering for a negative agentic text.\n\nThe values of the highlight agency a h and the maximum agency a max are shown versus the overall agency a on the left of Fig.  8  for two different ranges of the highlight fraction f h . Note that in all the considered cases the behavior is naturally captured by a linear fitting (slope only), the slope being obviously higher for the maximum agency a max as it captures all the best choices. A more detailed overview of this idea is shown in the graph of Fig.  8.(c)  where slope values of the linear fitting of a h and a max versus a consider a highlight fraction range of the form f h ∈ ( k 10 , k+1 10 ]. The plot also shows, in green, the ratio between the slopes of a h and a max , revealing that the highlight captures a consistent fraction of the most agentic words in the text, which is higher than 40% even for very low values of the highlight fraction f h . Moreover, the fact that a h is clearly separate from the noise level (with noise accounting for about 40% of a h at low f h ) certifies that the highlights naturally evidence the agentic portion of the text. We note incidentally that the highlight process, especially at low values of f h , naturally implies a selection of the part of text that is both more agentic and more meaningful, and therefore it is natural not to necessarily capture the entire value a max . As a clarifying example, for the sentence If we all work together , we can make a difference !  (14)  where the highlight (underlined text) is the final part, the expert reader is evidently selecting the agentic part of the text that is more meaningful to them. In this respect, an agreement with a max greater than 40% is a strong certification that the highlight process is invaluably linked to high agency in the text (as we expect), as well as that the IG approach is fully capable of correctly capturing it.\n\nThis finding is significant for sociopsychological research. It demonstrates that individuals, when considering collective mobilization, spontaneously highlight agency as a critical factor in creating an effective mobilization message. This observation is consistent with questionnairebased studies  [60]  showing that the efficacy (agency) consistently predicts collective action intentions (r = .34; it accounts for 11.56% of the variance in collective action intentions). In this study, we are further emphasizing its role in motivating collective action. Recent evidence  [63]  also underscores the importance of agentic language in mobilization strategies, linking it to the effectiveness of such messages. The prevalence of mobilizing speech acts fosters a shared understanding between communicators and audiences, consistent with the persuasion knowledge model  [64] . This shared knowledge enhances the use and recognition of linguistic features that characterize persuasive attempts, thereby contributing to their effectiveness. The presented method provides insight into the specific elements that drive this effectiveness, elucidating how communication fosters collective action, engagement, and compliance.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Word-Level Saliency In (Small) Labeled",
      "text": "",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Datasets",
      "text": "As we have largely discussed so far, the IG approach is able to correctly highlight the keywords that drive the output values in a classification or regression NLP task. We proved it in detail with agency and the BERTAgent regressor, but the idea is evidently applicable over a wide range (for example, for sentiment or any other sociopsychological marker of interest). However, the drawback of what we have considered so far is the availability of a large labeled dataset for training our NLP algorithm. In many applications, this large dataset is not available and we are instead constrained by a small dataset that can be easily labeled in practice.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Rationale For Small Labeled Datasets",
      "text": "In this latter scenario of small labeled datasets, the IG technique can be exploited to reveal the keywords related to the different classes identified by the labels, or, in case the label is a continuous value, to reveal the keywords that concur in building different levels of such value. We therefore set ourselves a task of explainability, which can be formalized as follows.\n\n• First, we train a NLP model to detect labels (or values in case we build a regressor),\n\n• then we exploit IG to identify the keywords related to each label (or regressor level), to obtain a thorough description of the classes and, more importantly, capturing those keywords that differentiate one class from the others. However, in order for this approach to work correctly, we need to address the training process in a rather unusual way. Unlike what we have learned from the machine learning (ML) literature, here we not only allow, but drastically encourage overfitting, up to a point where the trained NLP model exhibits full precision (accuracy of 1). In this context, there is also no need to differentiate between a train and a test set, as the intention is that of overfitting; hence, all the available data can be used as a train set. In this way, we are confident that the model we are training fully captures the statistics that are peculiar to each class and specific to the dataset. Specifically, the NLP classification task here is performed by a \"RobertaForSequenceClassification\" model in PyTorch, 7 trained to accuracy 1 (in about 20 epochs) with GPU processing resources. The NLP classifier is fed the raw text. IG is then run on the trained model to extract wordlevel associations that carry a description of each class.\n\nIn the following, we demonstrate that this peculiar solution works effectively using a standard application to a dataset labeled for relevant sociopsychological features.",
      "page_start": 9,
      "page_end": 10
    },
    {
      "section_name": "Sociopsychological Labels",
      "text": "The idea is here applied to the \"slurs\" dataset which, as explained, contains a collection of 336 real or fictitious stories describing a situation of verbal aggression and harassment suffered by a female subject. The dataset was labeled by social psychology experts for relevant aspects, namely the gender of the aggressor (male, female, both) and the relationship between the victim and the aggressor (acquaintance, friend, partner/family, unknown). Furthermore, it includes participants' ratings (in levels from 1 to 7) concerning the emotions they experienced during the event (e.g., shame and fear), as well as the extent to which they felt treated as a sexual object. Sexual objectification is a phenomenon by which people are reduced to their body, sexual body parts, or sexual functions  [65] . Women are frequent targets of sexual objectification, with estimates suggesting that they are treated as sexual objects as frequently as 1.3 times per day  [66] , with important consequences on their life outcomes and self-perceptions: for one, repeated exposures to sexual objectification can lead to the internalization of this external perspective on the self (i.e., self-objectification). Both objectification and self-objectification have severe consequences on women's wellbeing  [67] , including a higher risk of health issues such as depression and eating disorders  [68] .\n\nThe application of the proposed method to the above labels is illustrated in Table  1 , where only the top 20 scoring words are shown for each class, with a darker color indicating a stronger association value. Several unlabeled texts are also present and have been included in the classification process, although their IG values are not shown in the tables because they carry little meaning.\n\n7. https://huggingface.co/transformers/v2.9.1/model doc/roberta. html For the first label, gender of the aggressor, we appreciate from the top of Table  1  that the proposed technique works correctly, being able to efficiently identify all keywords that are markers of gender. As such, for aggressions conducted by a male perpetrator, male-related keywords such as male, boy, brother, boyfriend, man, etc. are identified. In the woman class, female-related keywords are also correctly associated with verbs such as obsess and charge, which are needed to distinguish female keywords referring to victims (always women) from keywords referring to the perpetrator. The second label, relationship between the victim and the aggressor, further corroborates the accuracy of the tool. We see in Table  1  that the partner/family class correctly identifies daughter, partner, boyfriend, husband, dad, sister, etc., in the keyword list. Also, a correct distinction is available between the acquaintance class, including figures related to the subject such as employer, boss, mate, advisor, supervisor, and the unknown person class which instead includes more generic words like saleperson, customer, gentleman, etc.\n\nIn the realm of sexual objectification, shame and fear are two key emotional outcomes  [69] . In line with this previous literature, we see in Table  1  that the high-level classes correctly identify words related to shame (e.g., mortify, insecurity) and fear (e.g., scare, afraid), both of which are not present in the low-level classes. This is important because it attests to the sensitivity of IG to emotion gradients. Accordingly, high levels of fear are denoted by references to aggression (e.g., violence, unprovoked, abusive). The objectification label, at the bottom of Table  1 , also provides compelling information. In particular, high levels of objectification are featured by sexual content (e.g., blowjob, cock, slut) and clothing (skirt), in line with the fact that sexual objectification is characterized by the reduction of a person to their sexual body parts or functions  [70] , which translates to a focus on physical appearance above one's personhood.\n\nOverall, not only does the proposed technique display the criteria that one would expect to guide human evaluations, and is thus proven to be a valuable tool, but it also provides insights about the most relevant keywords in classifications of complex phenomena, such as objectification. Although the classification of male vs. female characters in a story could also be achieved with a natural language processing tool, and emotions can be detected through dictionaries, a complex sociopsychological phenomenon such as self-objectification entails a more nuanced appraisal of the relevant keywords. In particular, within the objectification process, the observer's perspective on one's body is blended with the exploitation of the dehumanized person as a sexual toolkit. This technique could therefore also be applied to build or expand new dictionaries, including words that would possibly not emerge as synonyms of the initial keywords but semantically related as specific clues of the construct under investigation.",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Conclusion",
      "text": "In this paper we approached the problem of explainability at the word-level for relevant sociopsychological semantic markers, that include but are not limited to the common sentiment analysis. By a thorough comparison of the algorithm performance and an accurate choice of the parameters, we identified integrated gradient (IG) as the most reliable choice, and developed an IG-based tool for the word-level identification of agency, a fundamental marker identifying collective dynamics that is particularly relevant, e.g., in social and political discourses. We further applied the IG machinery to a more focused dataset scenario, where labels can be manually identified, and the IG explainability can be applied to identify words that semantically characterize each class. Although, in general, the quality of the output strongly depends on the specific label and the availability of strong (and statistically coherent) semantic content that can be captured by the NLP training procedure, the technique is relevant in at least two ways. First, for all those classification tasks lacking a strong and mature theoretical ground (e.g., the objectification task discussed in the paper, but also fake news detection, vaccine hesitancy behavior and causes, polarization mechanics in online social networks, etc.) can benefit in understanding which semantic content characterizes the classes, in such a way as to be able to extend existing dictionaries and strengthen or widen the theoretical ground. Second, more pragmatically, the semantic content highlighted by IG can be used to extend, by similarity, a dataset in a recursive fashion until coherent detection is achieved. But these aspects are left to our future work.",
      "page_start": 10,
      "page_end": 12
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Number of tweets/sentences as a function of their length, in the",
      "page": 4
    },
    {
      "caption": "Figure 2: Comprehensiveness and sufficiency in IG (with N = 300 steps) as a function of the fraction f in the four datasets, and for different baseline",
      "page": 5
    },
    {
      "caption": "Figure 3: Baseline output F(x0) (above) and normalized baseline output",
      "page": 5
    },
    {
      "caption": "Figure 4: Comprehensiveness and sufficiency in IG (with N = 300 steps)",
      "page": 5
    },
    {
      "caption": "Figure 2: and Fig. 4",
      "page": 5
    },
    {
      "caption": "Figure 3: with respect to the value of the baseline",
      "page": 5
    },
    {
      "caption": "Figure 5: with respect to the approximation error.",
      "page": 5
    },
    {
      "caption": "Figure 5: Approximation error statistics in IG (with N = 300 steps) as a function of the number of steps N in the four datasets, and for different baseline",
      "page": 6
    },
    {
      "caption": "Figure 2: shows comprehensiveness and sufficiency of the",
      "page": 6
    },
    {
      "caption": "Figure 2: , the performance dependency on the baseline",
      "page": 6
    },
    {
      "caption": "Figure 3: shows the value of the baseline output F(x0) as a function",
      "page": 6
    },
    {
      "caption": "Figure 3: we display the true value of the baseline",
      "page": 6
    },
    {
      "caption": "Figure 4: and Fig. 5",
      "page": 6
    },
    {
      "caption": "Figure 4: , the role of the parameter",
      "page": 6
    },
    {
      "caption": "Figure 4: almost perfectly superpose. We",
      "page": 6
    },
    {
      "caption": "Figure 4: we show a result for the",
      "page": 6
    },
    {
      "caption": "Figure 5: for N that spans in 50, 100, 300, 700, and 1000, and for",
      "page": 6
    },
    {
      "caption": "Figure 5: we clearly see that the best performance is",
      "page": 6
    },
    {
      "caption": "Figure 6: Comprehensiveness and sufficiency in different approaches as a function of the fraction f in the four datasets.",
      "page": 7
    },
    {
      "caption": "Figure 2: ), the most reliable baseline output values (see Fig. 3)",
      "page": 7
    },
    {
      "caption": "Figure 5: ). The number of steps is set to N = 300, this choice",
      "page": 7
    },
    {
      "caption": "Figure 6: and Fig. 7 for SequentialIG (sig in figure),",
      "page": 7
    },
    {
      "caption": "Figure 6: , we can clearly observe",
      "page": 7
    },
    {
      "caption": "Figure 7: , confirms this trend: an improvement",
      "page": 7
    },
    {
      "caption": "Figure 7: Comprehensiveness and sufficiency for f = 20% in different",
      "page": 7
    },
    {
      "caption": "Figure 8: for two different ranges of the highlight fraction",
      "page": 8
    },
    {
      "caption": "Figure 8: (c) where slope",
      "page": 8
    },
    {
      "caption": "Figure 8: Highlights data: (a-b) highlight agency ah versus agency in text a for fh ∈(0, .3] and fh ∈(.3, .6]; (c) linear fitting (slopes) for highlight",
      "page": 9
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "",
          "Column_2": "",
          "together": "",
          "Column_4": "",
          "Column_5": ",",
          "Column_6": ""
        },
        {
          "Column_1": "make",
          "Column_2": "a",
          "together": "",
          "Column_4": "difference",
          "Column_5": "",
          "Column_6": "!"
        }
      ],
      "page": 9
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "class": "GENDER(oftheaggressor)-classifier4classes",
          "#docs": "",
          "keywords": ""
        },
        {
          "class": "both\nman\nwoman\nNA",
          "#docs": "5\n189\n92\n50",
          "keywords": "couplehusbandwalkdogpeopleblockaggressivewomanfrontaskvoice\npersonthinkpartnerhatehousecomeyellfriendstand\nmaleboybrotherboyfriendmanladguygentlemanhusbanddadnotice\ntargetaccordannoyingmisogynisticbosssuddensupervisorentirelykid\nobsess secretary waitress sister girl girlfriend nurse mother woman\nchargesupermarketstaffgranddaughterbedroomrestaurantownerin-\ntervenetreatsame"
        },
        {
          "class": "RELATIONSHIP(betweenthevictimandtheaggressor)-classifier5classes",
          "#docs": "",
          "keywords": ""
        },
        {
          "class": "acquaintance\nfriend\npartner/family\nunknownperson\nNA",
          "#docs": "62\n26\n62\n166\n20",
          "keywords": "employerbossmateadvisorthesissupervisorroommatemasterneigh-\nbourneighborcolleagueuniversityclassmatesingleuseclientcatechism\nexercisefactoryguy\nfriendfriendshipboyfriendclassmateuniversitycollegegoodclassroom\nmutualbackbelieveimpulsivelymtalktakecallstillduetellyear\ndaughterengagepartnerdateboyfriendhusbanddadsisterexbrother\ngirlfriendmotherobsessguyspendthenconversationpregnantmum\nforumsalespersoncheckoutstorecustomercountergentlemanmotorist\naged overtook pizza winning service catch vaxxer exchange colleague\ncitizenbarnearby"
        },
        {
          "class": "SHAME(levelofshameevaluatedbyauthors)-classifier7classes",
          "#docs": "",
          "keywords": ""
        },
        {
          "class": "low(1-2)\nmedium(3-5)\nhigh(6-7)",
          "#docs": "124\n112\n100",
          "keywords": "confrontational incense overtook unprovoked excuse chap offer prosti-\ntutescooterchauvinistmutualmphjunkderisivebanbutcherannoying\npoliteimpatienthonk\ncleavage pushy desk oppose sketchy embarrasment embarrsse hurtful\nreach reschedule division effort bitchy pizza report particularly tipsy\noffensivetonightwickedness\nassignheartbrokeninfatuationmortifyspeechlessnormalinsecurityinat-\ntentivedaduniversitybehaviourgirlfriendcompulsivesyllabushumili-\nateheavilybreatheterriblesalespersonfear"
        },
        {
          "class": "FEAR(leveloffearevaluatedbyauthors)-classifier7classes",
          "#docs": "",
          "keywords": ""
        },
        {
          "class": "low(1-2)\nmedium(3-5)\nhigh(6-7)",
          "#docs": "108\n138\n90",
          "keywords": "topicreportrudeassignemployerjoincheatamusinginattentiveblowjob\noratorydivisionitemoffensesellteamskirtawkwardjestrandom\nheartbroken temper unqualified dickhead spend bully exactly loose\nbias overtook reckless threaten witness misogynistic useless nightclub\ninsecureentitleoutfitspace\nbouncer violence violent unprovoked scare scary afraid pizza chase\nnervousness abusive avoid ground youngish aggressive horn terrify\ndemeanourmemorablenightclub"
        },
        {
          "class": "OBJECTIFICATION(levelofobjectificationevaluatedbyexperts)-classifier7classes",
          "#docs": "",
          "keywords": ""
        },
        {
          "class": "low(1-2)\nmedium(3-5)\nhigh(6-7)",
          "#docs": "124\n92\n120",
          "keywords": "foolishgrumpyincompetentexcuseattributeslackerintelligentungrate-\nful error log handicapped slur retard misunderstand housekeep cock-\nroachsuitcasedisgustingomissionmanoeuvre\nbuggyconfrontationalmuzzleroundaboutreprimandtelepasscocksucke\nwhore fight slut savage spineless huff foul agitate ex threaten sexism\nwoundidiotic\nblowjobcock cuntinfatuationpushyslutskirtmoronwhorecheatwet\nslaghumiliationnightclubsweatshirtpizzarealheartdickjealous"
        },
        {
          "class": "SELFOBJECTIFICATION(levelofselfobjectificationevaluatedbyexperts)-classifier9classes",
          "#docs": "",
          "keywords": ""
        },
        {
          "class": "low(-6,-2)\nmedium(-2,2)\nhigh(2,6)",
          "#docs": "96\n147\n93",
          "keywords": "handicapped arm mood offer attribute overtook infant health drunk\nwalkermentalsheepstaffintervenesiblinglandlordcriticizeyesterday\nbarrefuse\ncook dick elevator shit thick pizza compulsive macho forum employer\ntender system unprovoked ride challenge deny seat loose wheelchair\nkey\nblowjobcocksmallhirepregnanttipsysalespersonsinglebedclienthurl\ncleavagecockroachstrengthovertakesuperiordogsleepshoeskirt"
        }
      ],
      "page": 11
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Beneath the tip of the iceberg: Current challenges and new directions in sentiment analysis research",
      "authors": [
        "Soujanya Poria",
        "Devamanyu Hazarika",
        "Navonil Majumder",
        "Rada Mihalcea"
      ],
      "year": "2023",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "2",
      "title": "Comparative study of deep learning-based sentiment classification",
      "authors": [
        "Seungwan Seo",
        "Czangyeob Kim",
        "Haedong Kim",
        "Kyounghyun Mo",
        "Pilsung Kang"
      ],
      "year": "2020",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "3",
      "title": "Attention is all you need",
      "authors": [
        "Ashish Vaswani",
        "Noam Shazeer",
        "Niki Parmar",
        "Jakob Uszkoreit",
        "Llion Jones",
        "Aidan Gomez",
        "Łukasz Kaiser",
        "Illia Polosukhin"
      ],
      "year": "2017",
      "venue": "Advances in neural information processing systems"
    },
    {
      "citation_id": "4",
      "title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "authors": [
        "Jacob Devlin",
        "Ming-Wei Chang",
        "Kenton Lee",
        "Kristina Toutanova"
      ],
      "year": "2018",
      "venue": "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "arxiv": "arXiv:1810.04805"
    },
    {
      "citation_id": "5",
      "title": "Roberta: A robustly optimized bert pretraining approach",
      "authors": [
        "Yinhan Liu"
      ],
      "year": "2019",
      "venue": "Roberta: A robustly optimized bert pretraining approach",
      "arxiv": "arXiv:1907.11692"
    },
    {
      "citation_id": "6",
      "title": "Improving language understanding by generative pre-training",
      "authors": [
        "Alec Radford"
      ],
      "year": "2018",
      "venue": "Improving language understanding by generative pre-training"
    },
    {
      "citation_id": "7",
      "title": "Language models are unsupervised multitask learners",
      "authors": [
        "Alec Radford",
        "Jeffrey Wu",
        "Rewon Child",
        "David Luan",
        "Dario Amodei",
        "Ilya Sutskever"
      ],
      "year": "2019",
      "venue": "OpenAI blog"
    },
    {
      "citation_id": "8",
      "title": "Language models are few-shot learners",
      "authors": [
        "Tom B Brown"
      ],
      "year": "2020",
      "venue": "Language models are few-shot learners",
      "arxiv": "arXiv:2005.14165"
    },
    {
      "citation_id": "9",
      "title": "Bert: A sentiment analysis odyssey",
      "authors": [
        "Shivaji Alaparthi",
        "Manit Mishra"
      ],
      "year": "2021",
      "venue": "Journal of Marketing Analytics"
    },
    {
      "citation_id": "10",
      "title": "Linguistic inquiry and word count: Liwc 2001",
      "authors": [
        "James Pennebaker"
      ],
      "year": "2001",
      "venue": "Linguistic inquiry and word count: Liwc 2001"
    },
    {
      "citation_id": "11",
      "title": "Bertagent: The development of a novel tool to quantify agency in textual data",
      "authors": [
        "Jan Nikadon",
        "Caterina Suitner",
        "Tomaso Erseghe",
        "Lejla Dzanko",
        "Magdalena Formanowicz"
      ],
      "year": "2025",
      "venue": "Journal of Experimental Psychology: General"
    },
    {
      "citation_id": "12",
      "title": "A survey on deep learning for textual emotion analysis in social networks",
      "authors": [
        "Sancheng Peng",
        "Lihong Cao",
        "Yongmei Zhou",
        "Zhouhao Ouyang",
        "Aimin Yang",
        "Xinguang Li",
        "Weijia Jia",
        "Shui Yu"
      ],
      "year": "2022",
      "venue": "Digital Communications and Networks"
    },
    {
      "citation_id": "13",
      "title": "A survey of textual emotion recognition and its challenges",
      "authors": [
        "Jiawen Deng",
        "Fuji Ren"
      ],
      "year": "2023",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "14",
      "title": "Deep learning in sentiment analysis: Recent architectures",
      "authors": [
        "Tariq Abdullah",
        "Ahmed Ahmet"
      ],
      "year": "2022",
      "venue": "ACM Computing Surveys"
    },
    {
      "citation_id": "15",
      "title": "Pars-off: A benchmark for offensive language detection on farsi social media",
      "authors": [
        "Taha Shangipour Ataei",
        "Kamyar Darvishi",
        "Soroush Javdan",
        "Amin Pourdabiri",
        "Behrouz Minaei-Bidgoli",
        "Mohammad Taher"
      ],
      "year": "2023",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "16",
      "title": "Sentiment analysis meets explainable artificial intelligence: A survey on explainable sentiment analysis",
      "authors": [
        "Arwa Diwali",
        "Kawther Saeedi",
        "Kia Dashtipour",
        "Mandar Gogate",
        "Erik Cambria",
        "Amir Hussain"
      ],
      "year": "2024",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "17",
      "title": "Explainable ai: A review of machine learning interpretability methods",
      "authors": [
        "Pantelis Linardatos",
        "Vasilis Papastefanopoulos",
        "Sotiris Kotsiantis"
      ],
      "year": "2020",
      "venue": "Entropy"
    },
    {
      "citation_id": "18",
      "title": "Evaluating attribution methods for explainable nlp with transformers",
      "authors": [
        "Vojtěch Bartička",
        "Ondřej Pražák",
        "Miloslav Konopík",
        "Jakub Sido"
      ],
      "year": "2022",
      "venue": "International Conference on Text, Speech, and Dialogue"
    },
    {
      "citation_id": "19",
      "title": "Text augmentation based on integrated gradients attribute score for aspect-based sentiment analysis",
      "authors": [
        "Noviyanti Santoso",
        "Israel Mendonc",
        "Masayoshi Aritsugi"
      ],
      "year": "2023",
      "venue": "2023 IEEE International Conference on Big Data and Smart Computing (BigComp)"
    },
    {
      "citation_id": "20",
      "title": "Discovering relevant sub-spaces of bert, wav2vec 2.0, electra and vit embeddings for humor and mimicked emotion recognition with integrated gradients",
      "authors": [
        "Anja Tamás Gr Ósz",
        "Dejan Virkkunen",
        "Mikko Porjazovski",
        "Kurimo"
      ],
      "year": "2023",
      "venue": "Proceedings of the 4th on Multimodal Sentiment Analysis Challenge and Workshop: Mimicked Emotions, Humour and Personalisation"
    },
    {
      "citation_id": "21",
      "title": "A dataset for explainable sentiment analysis in the german automotive industry",
      "authors": [
        "Andrea Zielinski",
        "Calvin Spolwind",
        "Henning Kroll",
        "Anna Grimm"
      ],
      "year": "2023",
      "venue": "Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, & Social Media Analysis"
    },
    {
      "citation_id": "22",
      "title": "Sequential integrated gradients: a simple but effective method for explaining language models",
      "authors": [
        "Joseph Enguehard"
      ],
      "year": "2023",
      "venue": "Sequential integrated gradients: a simple but effective method for explaining language models"
    },
    {
      "citation_id": "23",
      "title": "Discretized integrated gradients for explaining language models",
      "authors": [
        "Soumya Sanyal",
        "Xiang Ren"
      ],
      "year": "2021",
      "venue": "Discretized integrated gradients for explaining language models",
      "arxiv": "arXiv:2108.13654"
    },
    {
      "citation_id": "24",
      "title": "Learning important features through propagating activation differences",
      "authors": [
        "Avanti Shrikumar",
        "Peyton Greenside",
        "Anshul Kundaje"
      ],
      "year": "2017",
      "venue": "International conference on machine learning"
    },
    {
      "citation_id": "25",
      "title": "Shap-based explanation methods: a review for nlp interpretability",
      "authors": [
        "Edoardo Mosca",
        "Ferenc Szigeti",
        "Stella Tragianni",
        "Daniel Gallagher",
        "Georg Groh"
      ],
      "year": "2022",
      "venue": "Proceedings of the 29th international conference on computational linguistics"
    },
    {
      "citation_id": "26",
      "title": "A unified approach to interpreting model predictions",
      "authors": [
        "Lee Scott",
        "Su-In"
      ],
      "year": "2017",
      "venue": "Advances in neural information processing systems"
    },
    {
      "citation_id": "27",
      "title": "Axiomatic attribution for deep networks",
      "authors": [
        "Mukund Sundararajan",
        "Ankur Taly",
        "Qiqi Yan"
      ],
      "year": "2017",
      "venue": "International conference on machine learning"
    },
    {
      "citation_id": "28",
      "title": "The biases of pre-trained language models: An empirical study on prompt-based sentiment analysis and emotion detection",
      "authors": [
        "Rui Mao",
        "Qian Liu",
        "Kai He",
        "Wei Li",
        "Erik Cambria"
      ],
      "year": "2023",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "29",
      "title": "A fine-grained interpretability evaluation benchmark for neural nlp",
      "authors": [
        "Lijie Wang",
        "Yaozong Shen",
        "Shuyuan Peng",
        "Shuai Zhang",
        "Xinyan Xiao",
        "Hao Liu",
        "Hongxuan Tang",
        "Ying Chen",
        "Hua Wu",
        "Haifeng Wang"
      ],
      "year": "2022",
      "venue": "A fine-grained interpretability evaluation benchmark for neural nlp",
      "arxiv": "arXiv:2205.11097"
    },
    {
      "citation_id": "30",
      "title": "Building a tower of babel? integrating core motivations and features of social structure into the political psychology of political action",
      "authors": [
        "Martijn Van Zomeren"
      ],
      "year": "2016",
      "venue": "Political Psychology"
    },
    {
      "citation_id": "31",
      "title": "Interpreting stress detection models using shap and attention for muse-stress 2022",
      "authors": [
        "Ganghyun Ho-Min Park",
        "Jinsung Kim",
        "Arnout Oh",
        "Wesley Van Messem",
        "Neve De"
      ],
      "year": "2024",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "32",
      "title": "The impact of integration step on integrated gradients",
      "authors": [
        "Masahiro Makino",
        "Yuya Asazuma",
        "Shota Sasaki",
        "Jun Suzuki"
      ],
      "year": "2024",
      "venue": "Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics: Student Research Workshop"
    },
    {
      "citation_id": "33",
      "title": "will you find these shortcuts?\" a protocol for evaluating the faithfulness of input salience methods for text classification",
      "authors": [
        "Jasmijn Bastings",
        "Sebastian Ebert",
        "Polina Zablotskaia",
        "Anders Sandholm",
        "Katja Filippova"
      ],
      "year": "2021",
      "venue": "will you find these shortcuts?\" a protocol for evaluating the faithfulness of input salience methods for text classification",
      "arxiv": "arXiv:2111.07367"
    },
    {
      "citation_id": "34",
      "title": "Eraser: A benchmark to evaluate rationalized nlp models",
      "authors": [
        "Jay Deyoung",
        "Sarthak Jain",
        "Nazneen Fatema Rajani",
        "Eric Lehman",
        "Caiming Xiong",
        "Richard Socher",
        "Byron Wallace"
      ],
      "year": "2020",
      "venue": "Eraser: A benchmark to evaluate rationalized nlp models"
    },
    {
      "citation_id": "35",
      "title": "Beexai: Benchmark to¬ †evaluate explainable ai",
      "authors": [
        "Samuel Sithakoul",
        "Sara Meftah",
        "Clément Feutry"
      ],
      "year": "2024",
      "venue": "Beexai: Benchmark to¬ †evaluate explainable ai"
    },
    {
      "citation_id": "36",
      "title": "On the sensitivity and stability of model interpretations in nlp",
      "authors": [
        "Fan Yin",
        "Zhouxing Shi",
        "Cho-Jui Hsieh",
        "Kai-Wei Chang"
      ],
      "year": "2022",
      "venue": "On the sensitivity and stability of model interpretations in nlp"
    },
    {
      "citation_id": "37",
      "title": "Projection of socio-linguistic markers in a semantic context and its application to online social networks",
      "authors": [
        "Tomaso Erseghe",
        "Leonardo Badia",
        "Lejla Džanko",
        "Magdalena Formanowicz",
        "Jan Nikadon",
        "Caterina Suitner"
      ],
      "year": "2023",
      "venue": "Online Social Networks and Media"
    },
    {
      "citation_id": "38",
      "title": "Learning word vectors for sentiment analysis",
      "authors": [
        "Andrew Maas",
        "Raymond Daly",
        "Peter Pham",
        "Dan Huang",
        "Andrew Ng",
        "Christopher Potts"
      ],
      "year": "2011",
      "venue": "Proceedings of the 49th annual meeting of the association for computational linguistics: Human language technologies"
    },
    {
      "citation_id": "39",
      "title": "The words of (non-) humanity: Sexist slurs elicit self-dehumanization in women",
      "authors": [
        "Carmen Cervone",
        "Alice Lucarini",
        "Bruno G Salvador",
        "Silvia Casara",
        "Andrea Filippi",
        "Maria Scatolon",
        "Bettinsoli"
      ],
      "year": "2025",
      "venue": "Journal of Language and Social Psychology"
    },
    {
      "citation_id": "40",
      "title": "Semeval-2018 task 1: Affect in tweets",
      "authors": [
        "Saif Mohammad",
        "Felipe Bravo-Marquez",
        "Mohammad Salameh",
        "Svetlana Kiritchenko"
      ],
      "year": "2018",
      "venue": "Proceedings of the 12th international workshop on semantic evaluation"
    },
    {
      "citation_id": "41",
      "title": "Uncovering the linguistic drivers of mobilization: A theory-and data-driven computational approach",
      "authors": [
        "Jan Nikadon",
        "B Bylicka",
        "Caterina Suitner",
        "Lejla Dzanko",
        "Marta Beneda",
        "Magdalena Formanowicz"
      ],
      "year": "2025",
      "venue": "Uncovering the linguistic drivers of mobilization: A theory-and data-driven computational approach"
    },
    {
      "citation_id": "42",
      "title": "The Duality of Human Existence: An Essay on Psychology and Religion, Beacon paperback",
      "authors": [
        "D Bakan"
      ],
      "year": "1966",
      "venue": "The Duality of Human Existence: An Essay on Psychology and Religion, Beacon paperback"
    },
    {
      "citation_id": "43",
      "title": "Social cognitive theory: An agentic perspective",
      "authors": [
        "Albert Bandura"
      ],
      "year": "2001",
      "venue": "Annual review of psychology"
    },
    {
      "citation_id": "44",
      "title": "Adaptivity: From metabolism to behavior",
      "authors": [
        "Xabier Barandiaran",
        "Alvaro Moreno"
      ],
      "year": "2008",
      "venue": "Adaptive Behavior"
    },
    {
      "citation_id": "45",
      "title": "On minimal autonomous agency: natural and artificial",
      "authors": [
        "Alvaro Moreno"
      ],
      "year": "2018",
      "venue": "Complex Systems"
    },
    {
      "citation_id": "46",
      "title": "The computational boundary of a \"self\": developmental bioelectricity drives multicellularity and scale-free cognition",
      "authors": [
        "Michael Levin"
      ],
      "year": "2019",
      "venue": "Frontiers in psychology"
    },
    {
      "citation_id": "47",
      "title": "Goal attribution to inanimate agents by 6.5month-old infants",
      "authors": [
        "Gergely Csibra"
      ],
      "year": "2008",
      "venue": "Cognition"
    },
    {
      "citation_id": "48",
      "title": "Pulling out the intentional structure of action: the relation between action processing and action production in infancy",
      "authors": [
        "Jessica Sommerville",
        "Amanda Woodward"
      ],
      "year": "2005",
      "venue": "Cognition"
    },
    {
      "citation_id": "49",
      "title": "Agency and communion from the perspective of self versus others",
      "authors": [
        "Andrea Abele",
        "Bogdan Wojciszke"
      ],
      "year": "2007",
      "venue": "Journal of personality and social psychology"
    },
    {
      "citation_id": "50",
      "title": "Communal and agentic content in social cognition: A dual perspective model",
      "authors": [
        "Andrea Abele",
        "Bogdan Wojciszke"
      ],
      "year": "2014",
      "venue": "Advances in experimental social psychology"
    },
    {
      "citation_id": "51",
      "title": "The\" what\" and\" why\" of goal pursuits: Human needs and the self-determination of behavior",
      "authors": [
        "L Edward",
        "Richard Deci",
        "Ryan"
      ],
      "year": "2000",
      "venue": "Psychological inquiry"
    },
    {
      "citation_id": "52",
      "title": "Self-efficacy and workrelated performance: A meta-analysis",
      "authors": [
        "D Alexander",
        "Fred Stajkovic",
        "Luthans"
      ],
      "year": "1998",
      "venue": "Psychological bulletin"
    },
    {
      "citation_id": "53",
      "title": "Agency-communion and self-esteem relations are moderated by culture, religiosity, age, and sex: Evidence for the \"self-centrality breeds self-enhancement\" principle",
      "authors": [
        "Jenny Jochen E Gebauer",
        "Constantine Wagner",
        "Wiebke Sedikides",
        "Neberich"
      ],
      "year": "2013",
      "venue": "Journal of Personality"
    },
    {
      "citation_id": "54",
      "title": "A predisposition for biological motion in the newborn baby",
      "authors": [
        "Francesca Simion",
        "Lucia Regolin",
        "Hermann Bulf"
      ],
      "year": "2008",
      "venue": "Proceedings of the National Academy of Sciences"
    },
    {
      "citation_id": "55",
      "title": "The social brain: allowing humans to boldly go where no other species has been",
      "authors": [
        "Uta Frith",
        "Chris Frith"
      ],
      "year": "2010",
      "venue": "Philosophical Transactions of the Royal Society B: Biological Sciences"
    },
    {
      "citation_id": "56",
      "title": "Language and agency",
      "authors": [
        "Laura M Ahearn"
      ],
      "year": "2001",
      "venue": "Annual review of anthropology"
    },
    {
      "citation_id": "57",
      "title": "Collective psychological empowerment as a model of social change: Researching crowds and power",
      "authors": [
        "John Drury",
        "Steve Reicher"
      ],
      "year": "2009",
      "venue": "Journal of Social Issues"
    },
    {
      "citation_id": "58",
      "title": "Aligning identities, emotions, and beliefs to create commitment to sustainable social and political action",
      "authors": [
        "Emma F Thomas",
        "Craig Mcgarty",
        "Kenneth Mavor"
      ],
      "year": "2009",
      "venue": "Personality and social psychology review"
    },
    {
      "citation_id": "59",
      "title": "Community detection and stochastic block models: recent developments",
      "authors": [
        "Emmanuel Abbe"
      ],
      "year": "2018",
      "venue": "Journal of Machine Learning Research"
    },
    {
      "citation_id": "60",
      "title": "Toward an integrative social identity model of collective action: A quantitative research synthesis of three socio-psychological perspectives",
      "authors": [
        "M Van Zomeren",
        "T Postmes",
        "R Spears"
      ],
      "year": "2008",
      "venue": "Psych. Bull"
    },
    {
      "citation_id": "61",
      "title": "The role of linguistic agency in mobilizing election candidate support",
      "authors": [
        "Jan Nikadon",
        "Caterina Suitner",
        "Tomaso Erseghe",
        "Lejla Dzanko",
        "Michal Olech",
        "Pawell Jurek",
        "Magdalena Formanowicz"
      ],
      "year": "2024",
      "venue": "Journal of Language and Social Psychology"
    },
    {
      "citation_id": "62",
      "title": "Diminished agency as a linguistic marker of depressive synthoms on social networks",
      "authors": [
        "M Witkowska",
        "M Beneda",
        "M Formanowicz",
        "M Leszko",
        "S Arslan",
        "J Nikadon",
        "J Kowalski",
        "T Erseghe",
        "C Suitner"
      ],
      "year": "2025",
      "venue": "Diminished agency as a linguistic marker of depressive synthoms on social networks"
    },
    {
      "citation_id": "63",
      "title": "Mobilize is a verb: The use of verbs and concrete language is associated with authors' and readers' perceptions of a text's action orientation and persuasiveness",
      "authors": [
        "Magdalena Formanowicz",
        "Marta Beneda",
        "Marta Witkowska",
        "Jan Nikadon",
        "Caterina Suitner"
      ],
      "year": "2023",
      "venue": "Personality and Social Psychology Bulletin"
    },
    {
      "citation_id": "64",
      "title": "The persuasion knowledge model: How people cope with persuasion attempts",
      "authors": [
        "Marian Friestad",
        "Peter Wright"
      ],
      "year": "1994",
      "venue": "Journal of consumer research"
    },
    {
      "citation_id": "65",
      "title": "Objectification theory: Toward understanding women's lived experiences and mental health risks",
      "authors": [
        "B Fredrickson",
        "T.-A Roberts"
      ],
      "year": "1997",
      "venue": "Psychology of Women Quarterly"
    },
    {
      "citation_id": "66",
      "title": "Sexual objectification in women's daily lives: A smartphone ecological momentary assessment study",
      "authors": [
        "Elise Holland",
        "Peter Koval",
        "Michelle Stratemeyer",
        "Fiona Thomson",
        "Nick Haslam"
      ],
      "year": "2017",
      "venue": "British Journal of Social Psychology"
    },
    {
      "citation_id": "67",
      "title": "How does it feel to be treated like an object? direct and indirect effects of exposure to sexual objectification on women's emotions in daily life",
      "authors": [
        "Peter Koval",
        "Holland Elise",
        "Zyphur Michael",
        "Stratemeyer Michelle",
        "Makovec Knight Jennifer",
        "Bailen Natasha",
        "Thompson Renee",
        "Roberts Tomi-Ann",
        "Haslam Nick"
      ],
      "year": "2019",
      "venue": "ournal of Personality and Social Psychology"
    },
    {
      "citation_id": "68",
      "title": "Objectification theory: Continuing contributions to feminist psychology",
      "authors": [
        "Tomi-Ann Roberts",
        "Rachel Calogero",
        "Sarah Gervais"
      ],
      "year": "2018",
      "venue": "APA handbook of the psychology of women: History, theory, and battlegrounds"
    },
    {
      "citation_id": "69",
      "title": "Interpersonal sexual objectification, fear of rape, and us college women's depression",
      "authors": [
        "Dawn Szymanski",
        "Charlotte Strauss Swanson",
        "Rachel Carretta"
      ],
      "year": "2021",
      "venue": "Sex roles"
    },
    {
      "citation_id": "70",
      "title": "Seeing women as objects: The sexual body part recognition bias",
      "authors": [
        "Sarah Gervais",
        "Theresa Vescio",
        "Jens Örster",
        "Anne Maass",
        "Caterina Suitner"
      ],
      "year": "2012",
      "venue": "European Journal of Social Psychology"
    }
  ]
}