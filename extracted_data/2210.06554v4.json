{
  "paper_id": "2210.06554v4",
  "title": "Toward The Application Of Xai Methods In Eeg-Based Systems",
  "published": "2022-10-12T19:47:34Z",
  "authors": [
    "Andrea Apicella",
    "Francesco Isgrò",
    "Andrea Pollastro",
    "Roberto Prevete"
  ],
  "keywords": [
    "BCI",
    "XAI",
    "EEG",
    "Dataset",
    "Shift cross-session"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "1 An interesting case of the well-known Dataset Shift Problem is the classification of Electroencephalogram (EEG) signals in the context of Brain-Computer Interface (BCI). The non-stationarity of EEG signals can lead to poor generalisation performance in BCI classification systems used in different sessions, also from the same subject. In this paper, we start from the hypothesis that the Dataset Shift problem can be alleviated by exploiting suitable eXplainable Artificial Intelligence (XAI) methods to locate and transform the relevant characteristics of the input for the goal of classification. In particular, we focus on an experimental analysis of explanations produced by several XAI methods on an ML system trained on a typical EEG dataset for emotion recognition. Results show that many relevant components found by XAI methods are shared across the sessions and can be used to build a system able to generalise better. However, relevant components of the input signal also appear to be highly dependent on the input itself.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Related Works",
      "text": "In general, Modern ML approaches, as Deep learning, are characterised by a lack of transparency of their internal mechanisms, making it not easy for the AI scientist to understand the real reasons behind the inner behaviours. In this case, the relationships of the classified emotion with the EEG input are often challenging to understand. In the EEG-based applications, works based on simple features selection strategies to choose the best EEG features are widely proposed in the literature, such as  [32, 35] . These studies, however, are based on standard feature selection methods, without exploiting information given by XAI methods. XAI is a branch of AI concerned to \"explain\" ML behaviours. This is made providing methods for generating possible explanations of the model's outputs. XAI methods are gaining prominence in explaining several classification systems based on several inputs, such as images  [22, 3] , natural language processing  [19] , clinical decision support systems  [24] , and so on. To the best of our knowledge, however, the number of research works which attempt to improve the performance of ML models on the basis of XAI's methods is enough limited, especially in the context of bio-signal classification problems. For example, in  [14, 25]  feature selection procedures are carried out on biomedical data leveraging on Correlation-based Feature Selection and Chaotic Spider Monkey Optimization methods. In  [11]  the authors propose to use an occlusion sensitivity analysis strategy  [33]  to locate the most relevant cortical areas in a motor imagery task. In  [21]  the use of XAI methods to interpret the answer of Epilepsy Detection systems is discussed.",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "Methods",
      "text": "Taking in mind that we want to use the XAI method to alleviate the dataset shift problem in the BCI context, we conducted a series of experiments having the following goals: 1) testing the capability of the selected XAI methods to find relevant components for this specific signal; 2) verifying how much relevant components are dependent on the single sample of the dataset where the relevance are computed; 3) how much relevant components can be considered shared among samples of the same session, and finally 4) how much relevant components can be considered shared between samples of two different sessions, where the data shift problem is typically present.\n\nIn the remaining of this section, a brief description of the tested XAI methods is reported, followed by the used data and model descriptions. Finally experimental assessment and the evaluation strategy adopted are reported.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Investigated Xai Methods",
      "text": "In this work, we analyse XAI methods proposing explanations in terms of relevance of the input components on the output returned by a given classifier. More in detail, the following XAI methods are investigated: Saliency  [27] , Guided Backpropagation  [29] , Layer-wise Relevance Propagation (LRP)  [9] , Integrated Gradients  [31] , and DeepLIFT  [26] .",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Saliency",
      "text": "Saliency method is one the of the simplest and more intuitive method to build an explanation of a ML system. Proposed in  [27] , Saliency method is based on the gradient of the output function of the ML system respect to its input. In a nutshell, an explanation of the output C(x) of a ML system fed with an input x ∈ R d is built generating a saliency map leveraging on the gradient ∂C ∂x of C with respect to its input computed through backpropagation. The magnitude of the gradient indicates how much the features need to be changed to affect the class score.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Guided Backpropagation",
      "text": "Guided BackPropagation (Guided BP)  [29]  can be viewed as a slighlty variation of Saliency method proposed in  [27] . The main difference is in the value used as gradient in case of rectified activation functions (ReLU): in Saliency method, the real gradient is used in computing the features relevance. Instead, Guided BP starts from the hypothesis that the user is not interested if a feature \"decreases\" (i.e., negative value) a neuron activation, but only in the most relevant ones. Therefore, instead of the true gradient, in guided BP a gradient transformation is used to prevent backward flow of negative values, avoiding to decrease the neuron activations and highlighting the most relevant features. Obviously, Guided BP can fail to highlight inputs that contribute negatively to the output due to \"zero-ing\" the negative values.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Layer-Wise Relevance Propagation",
      "text": "Layer-wise Relevance Propagation (LRP) associates a relevance value to each input element (pixels in case of images) to build explanations for the ML model answer. In a nutshell, the output C(x) of a ML system on an input x ∈ R d is decomposed as a sum of relevances on the single features composing x, i.e.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "C(X)",
      "text": "R i where R i is a score of the local contribution of the i-th feature on the produced output. In particular, positive values denote positive contributions, while negative values negative contributions. Applied to ANN, this principle can be generalised across each pair of consecutive layers l and l + 1 of a network composed of L layers such that\n\ni where q and q ′ are the features of the layers l + 1 and l respectively. Since the final network output C(x) of an ANN is the output of the L-th layer, it results that\n\nR i . This rule can be interpreted as a conservation rule, and leveraging on that different methods to compute the relevance have been proposed, depending on the type of features involved. In case of densely connected layers, the most known rule is the z -rule  [9] , which takes care of the neuron activations of each layer to compute the final relevance of each layer.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Integrated Gradients",
      "text": "One of the main drawbacks of simple gradient-based method is that the gradient respect to the input should be small in the neighbourhood of the input features also for relevant ones. Instead of using only the gradient respect to the original input,  [31]  proposed to average all the gradients between the original input x and a baseline input x ref (that is, an input s.t. C(x ref ) results in a neutral prediction). In this way, if features of inputs closer to the baseline have higher gradient magnitudes, they are taken into account thanks to the average operator. More formally, the importance of each feature x i computed by Integrated Gradient (IG) is defined as:\n\nIn other words, IG aggregates the gradients along the intermediate inputs on the straight-line between the baseline and the input, selected as α ∈ [0, 1] changes.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Deeplift",
      "text": "In  [26]  a method consisting in assigning feature relevance scores according to the difference between the neurons activation and a reference activation (such as the baseline for Integrated Gradient method) is proposed. The authors proposed to compute for each feature a multiplier entity similar to a partial derivative, but leveraging over finite differences instead of infinitesimal ones. Each multiplier can be defined as m ∆x∆t = R∆x∆t ∆x and represents the ratio between i) the contribution R ∆x∆t of the difference ∆x = x -x ref from the reference x ref of each feature x to the difference ∆t = t -t ref between the output t and the reference output t ref , and ii) the difference ∆x. Therefore, the authors proposed a set of rules to compute the features relevance based on the proposed multipliers exploiting a Back Propagation-based approach.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Data",
      "text": "The SEED dataset consists of EEG signals recorded from 15 subjects stimulated by 15 film clips carefully chosen to induce negative, neutral and positive emotions. Each film clip has a duration of approximately 4 minutes. Three sessions of 15 trials were collected for each subject. EEG signals were recorded in 62 channels using the ESI Neuroscan System 2  . During our experiments, we considered the pre-computed differential entropy (DE) features smoothed by linear dynamic systems (LDS) for each second, in each channel, over the following five bands: delta (1-3 Hz); theta (4-7 Hz); alpha (8-13 Hz); beta (14-30 Hz); gamma  (31) (32) (33) (34) (35) (36) (37) (38) (39) (40) (41) (42) (43) (44) (45) (46) (47) (48) (49) (50) .\n\nIn this work, the relevant components of an EEG signal can be considered taking into account three different aspects of the signal: i) considering each single feature composing the input, ii) considering each single band composing the EEG signal, that are alpha, beta, theta, and delta, and iii) considering each single channel/electrode from which the input EEG signal was acquired. Cases ii) and iii) can be viewed as different aggregations of fixed features of the EEG signals. In the following of this work, we refer generically with the term \"components\" where it is not necessary to specify if we are talking about features, bands or channels.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Experimental Assessment",
      "text": "To achieve the goals defined at the beginning of this section, the following experiments are made: firstly, to evaluate the capability of the selected XAI methods to find relevant components, we analysed the explanations of model responses on data coming from the same session where the training data was extracted; then, to evaluate how much relevant components can be considered shared among samples of the same session, we analysed the explanations of the model responses on data belonging to a session different from the training one. Finally, to evaluate if relevant components can be considered shared between samples of two different sessions and how much relevant components are dependent on the single data sample where the relevance are computed, the components' average relevance of data coming from the training session are used as sorting score and select the components belonging to another session.\n\nSummarising, the following cases are considered: i) intra-session case: given a model C trained on data coming from a session s tr , explanations of the responses on input data belonging to the same session s tr are built. ii) inter-session case: given a model C trained on data coming from a session s tr , explanation of responses on inputs belonging to a sessions s te different from s tr are built. Each of these cases can be in turn evaluated considering two different relevance: a) real relevance: we assume that it is possible to compute the relevance of the input, since the classification output is known; b) presumed relevance: we assume that the relevance of the input is not available, since we are outside the training stage. In this case, we use the average of the same component relevance obtained on training data as component relevance.",
      "page_start": 8,
      "page_end": 9
    },
    {
      "section_name": "Evaluation",
      "text": "For each case, we investigated the explanations returned by XAI method in order to analyse if the explanations built can correctly identify the impact that i) each input feature, ii) each electrode, and iii) each frequency band has on the classification performances. To this aim, we consider as relevance for each feature the relevance score returned by the XAI method, for each electrode the mean relevance score of all the feature belonging to the electrode, and for each frequency bands the mean average score of all the features belonging to the frequency band. Therefore, the following evaluation strategies are then adopted and repeated considering features, electrodes, and frequency bands as EEG components in turn: a) analysis of the MoRF (Most Relevant First) curve, Figure  2 : MoRF (first column), AOPC (second column), LeRF (third column), and ABPC (fourth column) curves using the tested XAI methods are reported for both intra-session (solid line) and inter-session (dotted lines) considering features as signal components. Results scoring the input components using effective relevance (blue lines) and averaged relevance computed on training data (orange lines) are reported for each case and compared with a random component scoring (green lines). On the x axis and y axis are reported the iteration step in the curve generation and the accuracy level reached, respectively.\n\nFigure  3 : MoRF (first column), AOPC (second column), LeRF (third column), and ABPC (fourth column) curves using the tested XAI methods are reported for both intra-session (solid line) and inter-session (dotted lines) considering delta, theta, alpha, beta, gamma EEG bands as signal components. Results scoring the input components using effective relevance (blue lines) and averaged relevance computed on training data (orange lines) are reported for each case and compared with a random component scoring (green lines). On the x axis and y axis are reported the iteration step in the curve generation and the accuracy level reached, respectively.\n\nFigure  4 : MoRF (first column), AOPC (second column), LeRF (third column), and ABPC (fourth column) curves using the tested XAI methods are reported for both intra-session (solid line) and inter-session (dotted lines) considering the acquisition electrodes as signal components. Results scoring the input components using effective relevance (blue lines) and averaged relevance computed on training data (orange lines) are reported for each case and compared with a random component scoring (green lines). On the x axis and y axis are reported the iteration step in the curve generation and the accuracy level reached, respectively.\n\nFigure  5 : A first analysis of the discriminative power of the components alone. Signals composed of only one component following the relevance order given by the Explainer are fed to the ML system in an iterative manner. Results are reported for both intra-session (solid line) and inter-session (dotted lines) considering features (first column), bands (second column), and electrodes (third column) as signal components. Results scoring the input components using effective relevance (blue lines) and averaged relevance computed on training data (orange lines) are reported for each case and compared with a random component scoring (green lines).\n\nproposed in  [9, 23] . In case of evaluating the components relevance returned by the explanation method, the MoRF curve can be computed as follows: given a classifier, an input EEG signal x and the respective classification output C(x), the EEG components are iteratively replaced by zeros, following the descending order with respect to the relevance values returned by the explanation method. In other words, performances were analysed by removing (i.e. setting to zero) components in a decreasing order of impact on the predictions supplied by the explanation. In this way, the expected curve is such that more relevant the identified components are for the classification output, steepest is the curve. Furthermore, the change in the AOPC (Area Over Perturbation Curve) value is reported for each MoRF iteration. AOPC is computed as\n\nwhere K is the total number of iterations, x (0) is the original input, x (k) is the input at the iteration k, and ⟨•⟩ is the average operator over a set of inputs. MoRFs and AOPCs are reported also considering channels and bands as characteristics to analyse. b) the analysis of the LeRF (Least Relevant First) curve, proposed in  [23] . Differently from the MoRF curve, in this case the EEG components are iteratively removed following the ascending order with respect to the relevance values returned by the explanation method. In the resulting curve, we expect that the classification output should be very close to the original value when the less relevant components are removed (corresponding to the first iterations), dropping quickly to zero as the process goes toward the remotion of relevant elements. While the MoRFs report how much the classifier output is destroyed removing highly relevant components, LeRFs report how much the least relevant components leave the output intact. These indications can be combined in the ABPC (Area Between Perturbation Curves,  [23] ) quantity, defined as:\n\nLeRF are the values of the MoRF and LeRF values obtained at the k-th iteration step. ABPC is an indicator of how good the XAI method is. The larger the ABPC value, the better the XAI method. LeRFs and ABPCs are reported also for channels and bands analysis.\n\nc) an analysis of the discriminative power of each component alone is made. Signals composed of only one component following the relevance order given by the XAI method are fed to the ML system in an iterative manner, and the relative performance curves are plotted.\n\nAll the experiments were carried out only on correctly classified samples.",
      "page_start": 8,
      "page_end": 13
    },
    {
      "section_name": "Classification Model",
      "text": "The XAI methods are evaluated on a feed-forward fully connected multi layered neural networks. Hyperparameters were tuned through bayesian optimisation  [28] : the number of layers was constrained to a maximum of 3; for each layer, the number of nodes was searched in the space {2 n |n ∈ {4, 5, ..., 10}} having the ReLU as activation function. Each experiment was run having early stopping as convergence criterion with 20 epochs of patience. The 10 % of the training set was extracted using stratified sampling  [18]  on class labels and considered as validation set. Network optimisation was performed using Adam optimiser  [13] , whose learning rate that was searched in the space {0.1, 0.01, ..., 0.0001}. As a result from the model selection stage, the best setting consisted in ANN having 3 layers with 128, 256 and 128 neurons respectively. The learning rate was set to 0.01, and reduced to its 10 % whenever the loss on validation set plateaus for 10 consecutive epochs.",
      "page_start": 14,
      "page_end": 14
    },
    {
      "section_name": "Results & Discussions",
      "text": "Since the behaviour of the explored XAI methods resulted in being similar across all the subjects, we report only the results obtained on just one subject. In Fig.  2 , 3, and 4 MoRF and LeRF curves using the tested XAI methods are reported for both intra-session and inter-session cases, considering as components to remove at each step features (Fig.  2 ), bands (Fig.  3 ), and channels (Fig.  4 ), respectively. Results related to the intra-session cases are reported with solid lines, while those regarding the inter-session case are marked with dotted lines. On the x axis and y axis are reported the iteration step in the curve generation and the accuracy level reached, respectively. With blue lines, results scoring the input components using effective relevance are reported; with orange lines, results scoring the components using averaged relevance computed on training data are reported; with green lines, results related to random choice.\n\nAll the curves were compared with the random curve obtained by removing the components in random order. Several interesting points can be highlighted:\n\n1) In all the cases, LRP, IG and Deep LIFT resulted in being more reliable XAI methods with respect to Saliency and Guided BP. Indeed, MoRF curves of LRP, IG and Deep LIFT have high slopes, however similar to each other, differently from Saliency and Guided BP. In particular, the latter is the only method among those tested whose explanations do not always seem to capture the relevant components, especially in the case of intra-session. These considerations seem consistent with what is reported in LeRF, AOPC, and ABPC.\n\n2) counterintuitively, in almost all the cases, explanations built in intersession cases seem to be more reliable with respect to intra-session cases. This behaviour can be explained by a more significant \"robustness\" of the trained classifier toward data from the same training session. Instead, data coming from different sessions leads the classifier toward more borderline class scores, and minimum perturbation of the input data can lead to different classes, influencing the final performance.\n\n3) Although the best XAI methods can locate relevant features/channels/bands for each input data sample, they don't seem able to locate a set of relevant components for all the samples. In other words, the examined XAI methods fail to \"generalise\" to a set of general features/channels/bands relevant to the most significant part of the possible inputs. Indeed, removing the components following the average relevance (obtained in the training stage) in reverse order (MoRF orange curves) does not lead to a steep drop in performance, as in the other case (MORF blue curves). Even in some cases, such as using bands as a component to assign the relevance (Fig.  3 ), the obtained curves overlap with the random ones, highlighting that removing bands in random order is almost the same that following the relevance assigned by the XAI method. This is confirmed by the other evaluation metrics adopted, i.e. MeRF, AOPC and ABPC curves.\n\nIn Fig.  5  a first analysis of the discriminative power of the components alone is made. Signals composed of only one component following the relevance order given by the XAI method are iteratively fed to the ML system. We limit the analysis only to the best XAI methods identified in the previous step: DeepLIFT, IG and LRP. From the obtained results, it is interesting to notice that the components considered most relevant for each sample fed to the classifier are enough to reach high performances. However, considering the average relevance detected during the training stage, the best components do not seem to lead toward similar performance, although they are still better than a random choice.",
      "page_start": 14,
      "page_end": 14
    },
    {
      "section_name": "Conclusions",
      "text": "In this work, the performances of several XAI methods proposed in the literature in the context of Brain-Computer Interface (BCI) problems using EEG inputbased Machine Learning (ML) algorithms are experimentally evaluated. The focus was on how much the relevant components selected by XAI methods be shared between different samples of the same dataset (in this case, same session) or samples of different datasets (in this case, different sessions). The final results show that the components considered most relevant for each sample fed to the classifier are enough to achieve high performances. However, the components detected considering the best average relevance during the training stage do not seem to lead toward performance returned by components scored according to their effective relevance returned by the XAI method.\n\nThis work is the first step toward developing a BCI system able to exploit XAI methods to alleviate the dataset shift problem. However, in this work, only data belonging to different sessions but acquired from the same subjects are taken into account. In future work, we plan to analyse the behaviour of XAI methods with inter-subject classifiers. Several benefits can be obtained in the EEG-based BCI applications by the proposed project. For example, a BCI system can work across different subjects without retraining the model on each new unseen subject (subject-independent model). Furthermore, a better understanding of the relationships between the system inputs and outputs provided by XAI explanations can lead to the developing and producing more effective EEG acquisition devices.",
      "page_start": 15,
      "page_end": 16
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: A general functional scheme of a Machine Learning (ML) architecture",
      "page": 3
    },
    {
      "caption": "Figure 1: ). Notice that several current XAI",
      "page": 4
    },
    {
      "caption": "Figure 2: MoRF (first column), AOPC (second column), LeRF (third column),",
      "page": 9
    },
    {
      "caption": "Figure 3: MoRF (first column), AOPC (second column), LeRF (third column),",
      "page": 10
    },
    {
      "caption": "Figure 4: MoRF (first column), AOPC (second column), LeRF (third column),",
      "page": 11
    },
    {
      "caption": "Figure 5: A first analysis of the discriminative power of the components alone.",
      "page": 12
    },
    {
      "caption": "Figure 2: , 3, and 4 MoRF and LeRF curves using the tested XAI methods are reported",
      "page": 14
    },
    {
      "caption": "Figure 2: ), bands (Fig. 3), and channels (Fig. 4),",
      "page": 14
    },
    {
      "caption": "Figure 3: ), the obtained",
      "page": 15
    },
    {
      "caption": "Figure 5: a first analysis of the discriminative power of the components",
      "page": 15
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "ML system": ""
        }
      ],
      "page": 3
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Contrastive explanations to classification systems using sparse dictionaries",
      "authors": [
        "A Apicella",
        "F Isgrò",
        "R Prevete",
        "G Tamburrini"
      ],
      "year": "2019",
      "venue": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics"
    },
    {
      "citation_id": "2",
      "title": "Sparse dictionaries for the explanation of classification systems",
      "authors": [
        "Apicella",
        "R Isgro",
        "G Prevete",
        "Tamburrini",
        "Vietri"
      ],
      "year": "2015",
      "venue": "PIE"
    },
    {
      "citation_id": "3",
      "title": "Explaining classification systems using sparse dictionaries",
      "authors": [
        "A Apicella",
        "F Isgrò",
        "R Prevete",
        "A Sorrentino",
        "G Tamburrini"
      ],
      "year": "2019",
      "venue": "ESANN 2019 -Proceedings, 27th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning"
    },
    {
      "citation_id": "4",
      "title": "Eeg-based measurement system for monitoring student engagement in learning 4",
      "authors": [
        "Andrea Apicella",
        "Pasquale Arpaia",
        "Mirco Frosolone",
        "Giovanni Improta",
        "Nicola Moccaldi",
        "Andrea Pollastro"
      ],
      "year": "2022",
      "venue": "0. Scientific Reports"
    },
    {
      "citation_id": "5",
      "title": "High-wearable eeg-based distraction detection in motor rehabilitation",
      "authors": [
        "Andrea Apicella",
        "Pasquale Arpaia",
        "Mirco Frosolone",
        "Nicola Moccaldi"
      ],
      "year": "2021",
      "venue": "Scientific Reports"
    },
    {
      "citation_id": "6",
      "title": "Exploiting auto-encoders and segmentation methods for middle-level explanations of image classification systems",
      "authors": [
        "Andrea Apicella",
        "Salvatore Giugliano",
        "Francesco Isgrò",
        "Roberto Prevete"
      ],
      "year": "2022",
      "venue": "Knowledge-Based Systems"
    },
    {
      "citation_id": "7",
      "title": "Metrological characterization of a low-cost electroencephalograph for wearable neural interfaces in industry 4.0 applica-tions",
      "authors": [
        "Pasquale Arpaia",
        "Luca Callegaro",
        "Alessandro Cultrera",
        "Antonio Esposito",
        "Massimo Ortolano"
      ],
      "year": "2021",
      "venue": "2021 IEEE International Workshop on Metrology for Industry 4.0 & IoT"
    },
    {
      "citation_id": "8",
      "title": "A wearable ar-based bci for robot control in adhd treatment: Preliminary evaluation of adherence to therapy",
      "authors": [
        "Pasquale Arpaia",
        "Sabatina Criscuolo",
        "Egidio De Benedetto",
        "Nicola Donato",
        "Luigi Duraccio"
      ],
      "year": "2021",
      "venue": "2021 15th International Conference on Advanced Technologies, Systems and Services in Telecommunications (TELSIKS)"
    },
    {
      "citation_id": "9",
      "title": "On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation",
      "authors": [
        "Sebastian Bach",
        "Alexander Binder",
        "Grégoire Montavon",
        "Frederick Klauschen",
        "Klaus-Robert Müller",
        "Wojciech Samek"
      ],
      "year": "2015",
      "venue": "PloS one"
    },
    {
      "citation_id": "10",
      "title": "IEEE engineering in medicine and biology magazine",
      "authors": [
        "David Alexander J Casson",
        "Shelagh Jm Yates",
        "John Smith",
        "Esther Duncan",
        "Rodriguez-Villegas",
        "Wearable"
      ],
      "year": "2010",
      "venue": "IEEE engineering in medicine and biology magazine"
    },
    {
      "citation_id": "11",
      "title": "A novel explainable machine learning approach for eeg-based brain-computer interface systems",
      "authors": [
        "Cosimo Ieracitano",
        "Nadia Mammone",
        "Amir Hussain",
        "Francesco Morabito"
      ],
      "year": "2022",
      "venue": "Neural Computing and Applications"
    },
    {
      "citation_id": "12",
      "title": "Nonstationary nature of the brain activity as revealed by eeg/meg: methodological, practical and conceptual challenges",
      "authors": [
        "Alexander Ya Kaplan",
        "Andrew Fingelkurts",
        "Alexander Fingelkurts",
        "Sergei Borisov",
        "Boris Darkhovsky"
      ],
      "year": "2005",
      "venue": "Signal processing"
    },
    {
      "citation_id": "13",
      "title": "Adam: A method for stochastic optimization",
      "authors": [
        "P Diederik",
        "Jimmy Kingma",
        "Ba"
      ],
      "year": "2014",
      "venue": "Adam: A method for stochastic optimization",
      "arxiv": "arXiv:1412.6980"
    },
    {
      "citation_id": "14",
      "title": "Modeling of explainable artificial intelligence with correlation-based feature selection approach for biomedical data analysis",
      "authors": [
        "Lydia Laxmi",
        "Anupama",
        "Sharmili"
      ],
      "year": "2022",
      "venue": "Biomedical Data Analysis and Processing Using Explainable (XAI) and Responsive Artificial Intelligence (RAI)"
    },
    {
      "citation_id": "15",
      "title": "Games, gameplay, and bci: the state of the art",
      "authors": [
        "David Marshall",
        "Damien Coyle",
        "Shane Wilson",
        "Michael Callaghan"
      ],
      "year": "2013",
      "venue": "IEEE Transactions on Computational Intelligence and AI in Games"
    },
    {
      "citation_id": "16",
      "title": "Bci-based consumers' choice prediction from eeg signals: An intelligent neuromarketing framework",
      "authors": [
        "Rabbi Fazla",
        "Khandoker Mashrur",
        "Mohammad Mahmudur Rahman",
        "Tohidul Islam",
        "Ravi Miya",
        "Vaidyanathan",
        "Ferhat Syed",
        "Farhana Anwar",
        "Khondaker Sarker",
        "Mamun"
      ],
      "year": "2022",
      "venue": "Frontiers in Human Neuroscience"
    },
    {
      "citation_id": "17",
      "title": "Layer-wise relevance propagation: an overview. Explainable AI: interpreting, explaining and visualizing deep learning",
      "authors": [
        "Grégoire Montavon",
        "Alexander Binder",
        "Sebastian Lapuschkin",
        "Wojciech Samek",
        "Klaus-Robert Müller"
      ],
      "year": "2019",
      "venue": "Layer-wise relevance propagation: an overview. Explainable AI: interpreting, explaining and visualizing deep learning"
    },
    {
      "citation_id": "18",
      "title": "On the two different aspects of the representative method: the method of stratified sampling and the method of purposive selection",
      "authors": [
        "Jerzy Neyman"
      ],
      "year": "1992",
      "venue": "Breakthroughs in statistics"
    },
    {
      "citation_id": "19",
      "title": "Xnlp: A living survey for xai research in natural language processing",
      "authors": [
        "Marina Kun Qian",
        "Yannis Danilevsky",
        "Ban Katsis",
        "Erick Kawas",
        "Lucian Oduor",
        "Yunyao Popa",
        "Li"
      ],
      "year": "2021",
      "venue": "26th International Conference on Intelligent User Interfaces-Companion"
    },
    {
      "citation_id": "20",
      "title": "Dataset shift in machine learning",
      "authors": [
        "Joaquin Quinonero-Candela",
        "Masashi Sugiyama",
        "Anton Schwaighofer",
        "Neil Lawrence"
      ],
      "year": "2008",
      "venue": "Dataset shift in machine learning"
    },
    {
      "citation_id": "21",
      "title": "Review on epilepsy detection with explainable artificial intelligence",
      "authors": [
        "Prajakta Rathod",
        "Shefali Naik"
      ],
      "year": "2022",
      "venue": "2022 10th International Conference on Emerging Trends in Engineering and Technology-Signal and Information Processing"
    },
    {
      "citation_id": "22",
      "title": "explaining the predictions of any classifier",
      "authors": [
        "Marco Tulio Ribeiro",
        "Sameer Singh",
        "Carlos Guestrin"
      ],
      "year": "2016",
      "venue": "Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining"
    },
    {
      "citation_id": "23",
      "title": "Evaluating the visualization of what a deep neural network has learned",
      "authors": [
        "Wojciech Samek",
        "Alexander Binder",
        "Grégoire Montavon",
        "Sebastian Lapuschkin",
        "Klaus-Robert Müller"
      ],
      "year": "2016",
      "venue": "IEEE transactions on neural networks and learning systems"
    },
    {
      "citation_id": "24",
      "title": "Human-centered xai: Developing design patterns for explanations of clinical decision support systems",
      "authors": [
        "A Tjeerd",
        "Wiard Schoonderwoerd",
        "Mark Jorritsma",
        "Karel Neerincx",
        "Van Den",
        "Bosch"
      ],
      "year": "2021",
      "venue": "International Journal of Human-Computer Studies"
    },
    {
      "citation_id": "25",
      "title": "Explainable artificial intelligence with metaheuristic feature selection technique for biomedical data classification",
      "authors": [
        "Selvam Pandi",
        "Sheryl Oliver",
        "V Mohan",
        "Prakash",
        "Jayasankar"
      ],
      "year": "2022",
      "venue": "Biomedical Data Analysis and Processing Using Explainable (XAI) and Responsive Artificial Intelligence (RAI)"
    },
    {
      "citation_id": "26",
      "title": "Learning important features through propagating activation differences",
      "authors": [
        "Avanti Shrikumar",
        "Peyton Greenside",
        "Anshul Kundaje"
      ],
      "year": "2017",
      "venue": "International conference on machine learning"
    },
    {
      "citation_id": "27",
      "title": "Deep inside convolutional networks: Visualising image classification models and saliency maps",
      "authors": [
        "Karen Simonyan",
        "Andrea Vedaldi",
        "Andrew Zisserman"
      ],
      "year": "2013",
      "venue": "Deep inside convolutional networks: Visualising image classification models and saliency maps",
      "arxiv": "arXiv:1312.6034"
    },
    {
      "citation_id": "28",
      "title": "Practical bayesian optimization of machine learning algorithms",
      "authors": [
        "Jasper Snoek",
        "Hugo Larochelle",
        "Ryan Adams"
      ],
      "year": "2012",
      "venue": "Advances in neural information processing systems"
    },
    {
      "citation_id": "29",
      "title": "Striving for simplicity: The all convolutional net",
      "authors": [
        "Jost Tobias Springenberg",
        "Alexey Dosovitskiy",
        "Thomas Brox",
        "Martin Riedmiller"
      ],
      "year": "2014",
      "venue": "Striving for simplicity: The all convolutional net",
      "arxiv": "arXiv:1412.6806"
    },
    {
      "citation_id": "30",
      "title": "Eeg signal analysis: a survey",
      "authors": [
        "Paul Puthankattil Subha",
        "Rajendra Joseph",
        "U Acharya",
        "Min Choo",
        "Lim"
      ],
      "year": "2010",
      "venue": "Journal of medical systems"
    },
    {
      "citation_id": "31",
      "title": "Axiomatic attribution for deep networks",
      "authors": [
        "Mukund Sundararajan",
        "Ankur Taly",
        "Qiqi Yan"
      ],
      "year": "2017",
      "venue": "International conference on machine learning"
    },
    {
      "citation_id": "32",
      "title": "Hybrid method of automated eeg signals' selection using reversed correlation algorithm for improved classification of emotions",
      "authors": [
        "Agnieszka Wosiak",
        "Aleksandra Dura"
      ],
      "year": "2020",
      "venue": "Sensors"
    },
    {
      "citation_id": "33",
      "title": "Visualizing and understanding convolutional networks",
      "authors": [
        "D Matthew",
        "Rob Zeiler",
        "Fergus"
      ],
      "year": "2014",
      "venue": "European conference on computer vision"
    },
    {
      "citation_id": "34",
      "title": "Investigating critical frequency bands and channels for EEG-based emotion recognition with deep neural networks",
      "authors": [
        "Wei-Long Zheng",
        "Bao-Liang Lu"
      ],
      "year": "2015",
      "venue": "IEEE Transactions on Autonomous Mental Development"
    },
    {
      "citation_id": "35",
      "title": "A portable hci system-oriented eeg feature extraction and channel selection for emotion recognition",
      "authors": [
        "Xiangwei Zheng",
        "Xiaofeng Liu",
        "Yuang Zhang",
        "Lizhen Cui",
        "Xiaomei Yu"
      ],
      "year": "2021",
      "venue": "International Journal of Intelligent Systems"
    }
  ]
}