{
  "paper_id": "2402.12071v3",
  "title": "Emobench: Evaluating The Emotional Intelligence Of Large Language Models",
  "published": "2024-02-19T11:48:09Z",
  "authors": [
    "Sahand Sabour",
    "Siyang Liu",
    "Zheyuan Zhang",
    "June M. Liu",
    "Jinfeng Zhou",
    "Alvionna S. Sunaryo",
    "Juanzi Li",
    "Tatia M. C. Lee",
    "Rada Mihalcea",
    "Minlie Huang"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Recent advances in Large Language Models (LLMs) have highlighted the need for robust, comprehensive, and challenging benchmarks. Yet, research on evaluating their Emotional Intelligence (EI) is considerably limited. Existing benchmarks have two major shortcomings: first, they mainly focus on emotion recognition, neglecting essential EI capabilities such as emotion regulation and thought facilitation through emotion understanding; second, they are primarily constructed from existing datasets, which include frequent patterns, explicit information, and annotation errors, leading to unreliable evaluation. We propose EMOBENCH, a benchmark that draws upon established psychological theories and proposes a comprehensive definition for machine EI, including Emotional Understanding and Emotional Application. EMOBENCH includes a set of 400 hand-crafted questions in English and Chinese, which are meticulously designed to require thorough reasoning and understanding. Our findings reveal a considerable gap between the EI of existing LLMs and the average human, highlighting a promising direction for future research. Our code and data are publicly available at https://github. com/Sahandfer/EmoBench.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Emotional intelligence (EI) enables us to recognize, understand, and manage the thoughts and feelings of ourselves and others  (Salovey and Mayer, 1990) . It plays a pivotal role in shaping our interpersonal relationships, improving our decision-making, and impacting our overall well-being  (Schutte et al., 2001 (Schutte et al., , 2002;; Lopes et al., 2004) . Notably, emotionally intelligent systems share similar benefits  (Reeves and Nass, 1996) , as they are perceived as more understanding, trustworthy, and engaging expectations regarding their potential capabilities. However, despite their apparent proficiency in a variety of downstream tasks, such as question answering, and summarization  (Zhou et al., 2023a; Zhong et al., 2023) , research on evaluating EI capabilities for LLMs has been limited. The majority of current benchmarks  (Huang et al., 2023; Yang et al., 2023b; Amin et al., 2023)  assess EI through existing datasets for traditional tasks, mainly Emotion Label and Cause Recognition. Yet, these datasets were mainly designed as pattern recognition problems  (Picard, 2008) , encouraging models to rely on frequent patterns and explicit information  (Xu et al., 2023)  rather than implications and reasoning  (Ghosal et al., 2022) . Moreover, EI is not only limited to recognizing emotions and their causes, but also includes the ability to understand emotions and leverage this understanding for thought facilitation and emotion management  (MacCann and Roberts, 2008) . We believe the advancing capabilities of LLMs require the development of more comprehensive and challenging benchmarks for EI. These benchmarks should go beyond conventional tasks to fully evaluate LLMs' understanding, reasoning, and ability to navigate individuals' mental states, encompassing all of the core EI capabilities.\n\nAn example highlighting these issues is provided in Figure  1 . Traditional datasets typically contain samples that adhere to common patterns, such as associating 'losing' with 'sadness', and include explicit information guiding the model to extract the cause directly from the context. However, by simply adding an object's perceived value, the model would need to deduce the individual's mental state in the provided scenario to identify the corresponding emotion and infer its corresponding cause.\n\nTowards this end, we propose EMOBENCH, a theory-based comprehensive EI benchmark for LLM evaluation, consisting of a set of 400 handcrafted questions, available in English and Chinese. Our framework draws upon several established psychological theories for EI  (Salovey and Mayer, 1990; Goleman, 1996; Schuller and Schuller, 2018; O'Connor et al., 2019; Rivers et al., 2020)  and presents an extensive definition for machine EI, covering its essential capabilities: Emotional Understanding (EU) and Emotional Application (EA). We design emotionally sophisticated scenarios involving multiple individuals and multi-label annotations, encompassing diverse social situations, relationships, and emotional problems. In our eval-uation, we assess an LLM's ability to accurately understand the emotions of the individuals in the scenario and their causes (EU). We also evaluate whether they can appropriately apply this understanding (EA) to facilitate their thoughts and emotion management and identify the most effective solution within an emotional dilemma (e.g., a family member asking for money when you are facing financial problems yourself). Our experimental results highlight a considerable gap between the EI capabilities of existing LLMs and humans, with the best-performing LLM (GPT-4) falling short of the average human's performance.\n\nTo the best of our knowledge, EMOBENCH is the first benchmark to propose a comprehensive framework for EI, including assessments of emotional understanding and application. In line with our work,  Wang et al. (2023)  and Paech (2023) also curated similar assessments for EI. However, their evaluation is limited to Emotional Understanding and is also comparatively limited in scale. We will publicly release our code and data to facilitate future research on this topic.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Preliminaries",
      "text": "",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Definition Of Emotional Intelligence",
      "text": "The term Emotional Intelligence was coined and popularized by  Salovey and Mayer (1990)  as the ability to monitor feelings of our own and understand feelings of others, differentiate between them, and leverage this information to guide our thoughts and actions. Since then, the rapid progress in psychology research has expanded our understanding of EI, facilitating the rise of new perspectives on EI  (Bar-On, 1997; Goleman, 1996; Schuller and Schuller, 2018)  and improvements upon existing definitions  (Salovey and Mayer, 1990; Mayer et al., 1999; Rivers et al., 2020) . The differences in perspectives and definitions of EI make its assessment a non-trivial task  (Waterhouse, 2006) , as the experimental interpretations rely heavily on the adopted definitions and criteria. Hence, we must first identify commonalities of existing work and establish a comprehensive definition of machine EI.\n\nAt its core, EI is a unique set of abilities. Among the most notable definitions,  Mayer et al. (1999)  suggested EI is the ability to perceive, understand, regulate, and express emotions.  Goleman (1996)  and  (Bar-On, 1997)  believed competence in five aspects is indicative of high EI: knowing, recognizing, and managing emotions in self and others, motivat-",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Main Category",
      "text": "",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Secondary Category Example",
      "text": "",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Complex Emotions",
      "text": "Emotion Transition I was annoyed for burning my food, but felt joy after he enjoyed it.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Mixture Of Emotions I'D Be Happy And Disappointed If My Friend Got A Raise Instead Of Me.",
      "text": "",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Unexpected Outcome",
      "text": "Laughing hysterically after a tragic event shows devastation.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Personal Beliefs And Experiences",
      "text": "",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Cultural Value",
      "text": "A waiter getting tipped in Japan would likely not feel gratitude.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Sentimental Value",
      "text": "I would be unbothered by losing an item without sentimental value.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Persona",
      "text": "As an introvert, I would feel joy from having to spend a night alone.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Emotional Cues",
      "text": "Vocal cues A sigh after finishing a hard task shows relief, not disappointment.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Visual Cues",
      "text": "A white face usually indicates fear, unless it's from low blood sugar.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Perspective-Taking",
      "text": "",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Faux Pas",
      "text": "Henry criticized the painting on the wall, not knowing I drew it.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Strange Story",
      "text": "Getting an F, where it is the highest mark, leads to pride.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "False Belief",
      "text": "Seeing her cry, I thought she was sad, but she'd received great news.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Relationship Problem Example",
      "text": "",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Social",
      "text": "Self I work better than my coworkers and I feel my workload is higher because of it.\n\nOthers I missed a deadline because my coworker didn't tell me about it in time.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Personal Self",
      "text": "My best friend is going on a road trip with his other friends, leaving me behind.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Others",
      "text": "My younger brother is being bullied but he begged me not to tell our parents.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Emotional Understanding Taxonomy",
      "text": "Emotional Application Taxonomy ing oneself, and building relationships. In addition,  Schuller and Schuller (2018) 's interpretation of EI involved emotion recognition, adapting emotions to the situation, and leveraging emotional information to solve problems and accomplish goals. While there are subtle differences among these interpretations, the recurring theme suggests that a comprehensive view of EI revolves around the ability to accurately understand emotions, which includes perceiving, identifying, and monitoring emotions, and appropriately applying this understanding to accomplish a task (e.g., managing emotions and facilitating our thoughts and decisions). Hence, we designed our evaluation framework to encompass these two salient dimensions: Emotional Understanding (EU) and Emotional Application (EA).",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Measures Of Emotional Intelligence",
      "text": "In psychology, EI evaluation is mainly classified into trait and ability measures  (Ashkanasy and Daus, 2005) . Trait measures are commonly assessed through self-report questionnaires and designed to explore how individuals respond to scenarios that evoke emotions  (O'Connor et al., 2019) . However, self-report assessments are not suitable for evaluating LLMs. On the other hand, ability measures target individuals' emotional understanding and performance and provide a more theoretical view of EI, and they are more commonly employed for assessing EI  (Conte, 2005) . Among them, the Mayer-Salovey-Caruso Emotional Intelligence Test (MSCEIT)  (Mayer et al., 2007)  and MacCann and Roberts (2008)'s situational tests for emotion understanding and management (STEU and STEM), have become the most frequently adopted tools in the literature  (O'Connor et al., 2019) . These measures include sets of meticulously designed multiple-choice questions, with each set targeting a specific EI ability.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Emobench",
      "text": "We believe EI benchmarks should be comprehensive and transcend general patterns while necessitating deep reasoning and understanding. Therefore, based on our established definition for machine EI ( §2.1) and existing tools for EI assessment in psychology ( §2.2), our framework includes a multifaceted evaluation of LLMs' emotional understanding, while also exploring LLMs' emotional awareness and mentalizing capabilities by analyzing their response to emotional dilemmas and their application of emotional understanding.\n\nFigure  2  presents an overview of EMOBENCH. First, through synthesizing several established psychological theories for EI  (Salovey and Mayer, 1990; Goleman, 1996; Rivers et al., 2020) , we identified and taxonomized essential capabilities for the established dimensions: Emotional Understanding (EU) and Emotional Application (EA). Accord-ingly, based on these taxonomies, we crafted a series of emotionally sophisticated situations involving one to three individuals.\n\nCreating challenging scenarios that involve implications and do not rely on common patterns requires substantial creativity and diversity, which makes manual data collection a non-trivial task. Therefore, using the designed category descriptions, we initially prompted  GPT-4 (OpenAI, 2023)  to generate example scenarios. However, while GPT-4 produced the best results in our preliminary experiments among the adopted LLMs, the generated scenarios included explicit mentions of emotion labels and their causes and required minimum reasoning and understanding to reach the correct answer, lacking emotional depth and coverage. Therefore, we used the generated examples as inspiration to increase our topic diversity and manually crafted the scenarios in our dataset. Lastly, we annotated each scenario based on each dimension's design and requirements, which we will discuss in the following sections. For the remainder of this section, the authors who collected and annotated the data will be referred to as workers.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Emotional Understanding",
      "text": "Emotion Recognition has become a popular research direction in NLP over the past two decades as it is an essential skill for emotionally intelligent machines  (Picard et al., 2001) . There exist several datasets that are commonly used for this task, such as MELD  (Poria et al., 2019) , DailyDialog  (Li et al., 2017) , and GoEmotions  (Demszky et al., 2020) . These datasets mainly provide an emotionstimulating scenario and a corresponding emotion label for the person involved in the situation (e.g., I broke up with my girlfriend → Sad). Following this trend, an auxiliary task, namely Emotion Cause Recognition  (Poria et al., 2021) , was proposed to assess whether language models can learn to identify the causes of emotions in addition to their labels in given scenarios (e.g., I'm getting married soon → getting married → Excited).\n\nThere are two fundamental problems with the design of these traditional datasets. First, previous work considers emotion recognition as a pattern recognition problem  (Picard, 2008; Schuller and Schuller, 2018) , in which models predict the most likely emotion label for the situation based on the observed patterns in the training set. With this approach, no reasoning or understanding is involved or required to reach the desired output, a trait we believe is necessary for evaluating modern LLMs due to their emerging capabilities. Moreover, current datasets for cause recognition are designed as span extraction problems, requiring the cause to be explicitly stated and removing the need for understanding the individual's mental state and reasoning about implications.\n\nHowever, we believe combining these two tasks lays a solid foundation for assessing emotional understanding. Hence, while keeping the same format, we create more challenging scenarios in which merely relying on common patterns would not lead to the correct response, and understanding emotional implications and thorough reasoning is necessitated. Moreover, as many of our designed scenarios involve multiple individuals, our assessment targets understanding the various perspectives of the same situation, which leads to differences in the experienced emotions.\n\nData Collection and Annotation Our designed taxonomy for this dimension predominately assesses LLMs' comprehension of four essential categories that are indicative of emotional understanding: complex emotions, emotional cues, personal beliefs and experiences, and individual perspectives (perspective-taking). Each category consists of several sub-categories, targeting its various aspects. More descriptions and examples are provided in Appendix A.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Base Emotions",
      "text": "",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Intensity High Low",
      "text": "",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Mixed Emotions",
      "text": "",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "No Emotions",
      "text": "",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Oblivious",
      "text": "Unbothered Indifferent  Subsequently, in our framework, we need to annotate the labels and causes for the emotions of the people involved in the scenario. Due to its comprehensive and scalable design, we adopt Plutchik's wheel of emotions  (Plutchik, 1982)  as the foundation of our emotion taxonomy. At its core, Plutchik's design involves eight basic emotions with varying intensities, and other emotions are created and labeled as a mixture of these basic emotions. For instance, the basic emotion Disgust could turn into Boredom or Loathing with low and high intensities, respectively. It could also mix with Sadness to create the feeling of Remorse. This design facilitates the addition of new labels by mixing different emotions and seamless scaling of our taxonomy. In addition, we aggregate the emotion labels from previous work  (Ekman, 1984; Li et al., 2017; Rashkin et al., 2018; Demszky et al., 2020)  to augment our emotion categories, creating a unified and scalable taxonomy (Figure  3 ). Following the design of our taxonomies, each worker manually created emotionally challenging scenarios and annotated the emotion label and cause for the people involved. They also created additional labels for emotions and causes to form multiple-choice questions (MCQs). In our framework, a scenario involving three people would result in three separate MCQs for each individual's emotions and their causes, respectively. Subsequently, one worker was assigned to translate the MCQ (into English if the original was written in Chinese, and vice versa, based on the worker's language fluency) and, with the addition of two other workers, meticulously review its content to ensure data quality and overall agreement. In total, we created 121 scenarios involving 1-3 individuals, leading to 200 challenging MCQs. Figure  4  shows the corresponding category distributions (emotion distributions are provided in Appendix C).",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Melancholy",
      "text": "",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Emotional Application",
      "text": "Despite emotional understanding being a critical part of EI, it is also essential to analyze how LLMs use this knowledge to facilitate thoughts and manage emotions when faced with emotionally sophisticated problems  (Goleman, 1996) . Inspired by  Mac-Cann and Roberts (2008) , we propose a novel task for assessing LLM's EI: Emotional Application. In this task, we aim to evaluate LLMs' proficiency in leveraging their emotional understanding of the individuals' mental states in a given scenario and identifying the most effective course of action or response within an emotional dilemma.\n\nWe create our scenario based on different Relationships and Problems. Similar to  Zhou et al. (2023b) , we only consider two types of relationships in this work: personal (e.g., friends, family, romantic partners) and social (e.g., boss, teacher, coworkers), and leave more detailed categorizations to future work. Accordingly, a situation involving these relationships could contain problems that we (self ) or others are facing. Issues arising from interpersonal conflicts or arguments are also considered problems with others. Lastly, we would prompt the LLM to find the most effective solution to the presented dilemma, which is either an action (i.e., what to do?) or a response (i.e., what to say?).\n\nData Collection and Annotation Similar to Section 3.1, each worker was tasked with designing scenarios based on the generated examples and the assigned categories, and creating multiple plausible solutions to the presented dilemma. Workers were encouraged to make the MCQ more difficult by introducing implications in the scenario and making all of the choices plausible. Subsequently, a second worker revised and translated the scenario and choices (English → Chinese, and vice versa).\n\nGiven that this could be seen as a subjective task, we assigned the original two workers alongside two new workers to annotate each MCQ and determine its label. Inspired by  MacCann and Roberts (2008) , workers were asked to distribute four units of 0.25 based on their preference as scores for the available choices ( Scores = 1). For instance, for choices {a, b, c, d}, if a worker believes choices a and b are both plausible but prefers a over b, the annotated score would be {0.75, 0.25, 0, 0}. Then, we averaged the scores from all annotators to define the most effective answer for each dilemma. The inter-annotator agreement using Fleiss' Kappa  (Fleiss and Cohen, 1973)  was κ = 0.852), indicating excellent agreement and an objectively correct answer for the majority of the collected questions. Overall, we curated a set of 200 MCQs, with each relationship-problem-solution triplet (e.g., socialself-action) containing 25 items.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Task Formulation",
      "text": "Our tasks take the form of multiple-choice questions (MCQ). For each MCQ in the Emotional Understanding task, we first ask the LLM to identify the individual's emotion and, subsequently, choose the corresponding cause. In the Emotional Application task, we simply ask the LLM to choose the most effective response/action in the given scenario. We evaluate LLMs in two settings: zero-shot prompting with task instruction (Base) and with chain-of-thought reasoning (CoT). Our designed prompts are provided in Appendix B.\n\nFor our evaluation, we prompt each LLM five times (5-shot) for each MCQ and use majority voting (i.e., the most frequent choice) to determine the LLM's answer. Then, we leverage a series of heuristic rules to parse the generated outputs. Since LLMs have shown to have a bias towards choice ordering  (Zheng et al., 2023) , we randomly modify the choice ordering three times (4 permutations) and repeat the above process for each new permutation. Lastly, we calculate and report the average accuracy of the four runs.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Baselines",
      "text": "In our experiments, we adopt a range of recent widely-used LLMs with promising performance on existing benchmarks  (Zhang et al., 2023) . For close-sourced LLMs (accessible through APIs 1 ), we evaluate OpenAI's GPT 4 (gpt-4) and GPT 3.5 (gpt-3.5-turbo) (OpenAI, 2023), ChatGLM 3 (66B)  (Du et al., 2022; Zeng et al., 2022) , and Baichuan 2 (53B)  (Yang et al., 2023a) . For opensource LLMs, we experimented with Llama 2 (7B and 13B;  (Touvron et al., 2023) ), Baichuan 2 (7B and 13B), Qwen (7B and 14B;  (Bai et al., 2023) ), ChatGLM 3 (6B), and Yi (6B) 2 . Following Ismayilzada et al. (  2023 ), we also include Random choice and Majority (i.e., choosing the most frequent choice) as baselines.",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Implementation Details",
      "text": "For Llama-based LLMs, we used the default generation hyperparameters (top-p sampling with p = 0.9 and temperature = 0.6). For others, we directly employed their pre-defined interfaces, either through their online API or the CHAT function in 1 https://api.openai.com/v1/chat/completions 2 https://github.com/01-ai/Yi the Transformers library 3  . All of our experiments were run on single A100 80GB GPUs.",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Results And Findings",
      "text": "Our obtained results are provided in Tables  1  and 2 . Overall, GPT-4 significantly outperformed the other LLMs in both tasks. In general, all LLMs demonstrated better accuracy than random chance. However, in the EU task, several of the smaller models had worse performance than simply choosing the most frequent choice. An interesting finding in our experiments was that requiring LLMs to reason step-by-step generally had little to no improvements, even hindering the performance for smaller models (particularly <14B). We will further investigate this issue in section 7.\n\nNotably, the task's language did not have a significant impact on the performance, with all LLMs (excluding Yi and ChatGLM-6B) performing slightly better in English, which we believe could be due to data distributions in their training data. This could also explain why Chinese-based LLMs (e.g., Yi) outperform their English-based counterparts, such as LLama 2 (7B), in the Chinese subset of EMOBENCH despite having a similar size. However, as we do not have access to the LLMs' pertaining data, we cannot claim any correlations between their training data and performance on our benchmark. Moreover, the performance consistently improved with increased parameters, which is consistent with previous findings on LLM scaling  (Brown et al., 2020) .\n\nAll LLMs found emotional understanding considerably more challenging than its application. We believe this is due to several reasons. Contrary to the EA task, the EU samples require LLMs to correctly answer two questions (the emotion and its cause), which itself serves as a bigger challenge. This is also indicated by the results from the Random and Majority baselines. Moreover, evidenced by differences in their designs, the EU questions aimed to portray situations that included various implications and outcomes for frequent patterns. However, our design of EA samples was still prone to including such patterns as with this task, our main goal was to present a novel evaluation of LLMs' awareness and management when faced with emotional dilemmas. Hence, the difficulty of the EA task would naturally be much lower.\n\nAs shown in  categories with the EU task more challenging than the others. Mainly, all LLMs struggled with MCQs regarding Perspective Taking (PT), which has also been shown in relevant tasks (e.g., ToM  (Ullman, 2023) ) that require this mentalizing ability. Similarly, LLMs found it difficult to understand the nuances regarding personal traits, sentimental values, and cultural values. Within the EA task (Table  2 ), each LLM had varying performances in differ-ent types of relationships and problems. In general, LLMs perceived solving the self's social problems as more challenging among the studied dimensions.",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "Comparison With Human Performance",
      "text": "To obtain a baseline for human EI, we recruited participants through online surveys to complete our EI test. More information on our recruitment process, quality control, and participant demographics are provided in Appendix D. In total, we recruited 48 participants and allocated an equal number of participants to each language-task evaluation pair. Subsequently, for each group, we randomly sampled 30 MCQs from EMOBENCH that were not included in the initial screening process. As shown in Figure  5 , our human participants outperformed the LLMs on both tasks. Notably, although GPT-4, the top-performing LLM, came close to the average human performance, particularly in the EA task, it still fell short of surpassing individuals with higher emotional intelligence, highlighting a significant gap in current LLMs.",
      "page_start": 14,
      "page_end": 14
    },
    {
      "section_name": "Error Analysis",
      "text": "To provide a qualitative view of LLMs' performance on our benchmark, we analyzed LLMs' generated reasoning through CoT. We believe appropriate reasoning for our tasks would involve traversing the events within the provided scenario and following the transitions in the individual's emotions, demonstrating an understanding of their mental state and the situation's implications. However, our analysis showed that LLMs' reasoning mainly involved analyzing the provided choices and evaluating the validity of each choice. While this could be an effective strategy for filtering out the wrong responses, this form of reasoning may overlook the nuanced emotional awareness and considerations involved in human decision-making, which are pivotal parts of EI.\n\nWe observed that LLMs' step-by-step reasoning occasionally led to changes in the topic (e.g., turning to a detailed discussion on the necessity of being empathetic in modern society when faced with a scenario about supporting a loved one within an emotional dilemma) or refusal to answer (stating that none of the options are correct). Such errors were considerably less common in larger models (>50B), which is indicated by the smaller gaps between their performance with and without CoT (Tables  1  and 2 ). However, these results are expected as more reliable reasoning capabilities emerge when the parameters are scaled above certain thresholds  (Wei et al., 2022) .   by having misassumptions (e.g., a person walking in the door would not immediately know what is going on), and incorrect reasoning (e.g., having a phobia would not necessarily lead to fear or getting an F is not a failure when its the highest score). We believe these errors mainly occur due to LLMs' lack of emotional understanding, such as weak perspective taking (as shown in Table  1 ) and reliance on frequent patterns for reasoning. With EA questions, LLMs' answers mainly exhibited a preference for more general solutions, disregarding the relationship between individuals, which is an important factor in determining their emotions and subsequent responses. For instance, while the best course of action when facing criticism may be taking accountability, gentle humor would be a more suitable response to a friend's simple tease as it shows better emotional regulation and awareness.",
      "page_start": 15,
      "page_end": 15
    },
    {
      "section_name": "Moreover, We Present Several Examples Of Common Mistakes Made By Llms In",
      "text": "",
      "page_start": 15,
      "page_end": 15
    },
    {
      "section_name": "Conclusion And Future Work",
      "text": "In this paper, we introduced EMOBENCH, a theorybased, comprehensive, and challenging set of 400 hand-crafted MCQs, including emotionally sophisticated scenarios, for assessing Emotional Intelligence (EI) in Large Language Models through its two salient dimensions: Emotional Understanding and Emotional Application. Our results revealed that existing LLMs struggle with emotional intelligence (mainly understanding), and there is still a considerable gap between the best-performing LLM in our study and the average human. We hope that by facilitating EI evaluation, EMOBENCH can encourage research on emotionally intelligent LLMs, leading to LLMs that are more capable of understanding emotions and applying this understanding in many promising tasks, such as emotional and mental health support  (Sabour et al., 2022) . In addition, we plan to augment EMOBENCH with more data, exploring the more fine-grained features.",
      "page_start": 16,
      "page_end": 16
    },
    {
      "section_name": "Limitations",
      "text": "with EMOBENCH, we aimed to ensure high annotation quality and difficulty with our curated samples, which required intensive labor and manual supervision, and thus, compared to existing benchmarks for other tasks, our dataset is limited in scale. Given our resources, we were only able to collect data in English and Chinese. We believe translating our data to other languages could reveal more insights into their seemingly intelligent behavior.\n\nIn addition, our benchmark is limited to a single modality (text) as most of the recent prevalent LLMs are text-based. However, many psychological tests for emotional intelligence (e.g., MSCEIT; Mayer et al. (  2007 )), include assessments of various modalities, such as the individual's tone and facial features. Moreover, while we did not directly include samples from GPT-4, we leveraged its generated examples to inspire our MCQs, which might have introduced a bias in our benchmark. With future improvements in LLMs, we will continue exploring different dimensions of EI and augment our benchmark accordingly.\n\nIn our evaluation, we acknowledge that the choice of prompts could have significantly influenced the LLMs' performance. However, despite our emphasis on prompt design, we cannot claim our prompts were optimal, and thus, the experimental results are not indicative of LLMs' peak performance in EI. Moreover, we only experimented with chain-of-thought reasoning to augment the output, which future work could expand upon and propose new reasoning techniques that better apply to emotional scenarios.\n\nEmotional intelligence is still an abstract concept in psychology and our view on it may change with developing research. Similarly, emotions are not objective, and individual responses to the same situation could vary significantly. We strived to design our scenarios and choices in a manner that would only require a general and commonsensical understanding of emotions. The trade-off here, particularly for designing scenarios for emotional application, was that we could only include scenarios that all the annotators had experienced to ensure reliable annotation, limiting the scope of the topics and relationships covered. Furthermore, to address the issues with subjectivity, we designed our MCQs to have only one objectively correct answer. This is more straightforward for the EU questions, as a golden label can be directly defined for the emotions based on the taxonomy. In addition, four different workers checked and agreed upon these golden labels along with the designed causes, suggesting that all the workers found the labels for emotions and corresponding causes to be objectively the only correct choice among the provided choices. For EA, to reduce the effect of subjectivity, while we create choices that could all be plausible, we require one choice to be clearly more effective and applicable than others. In addition, in cases where two plausible choices are equally favorable, we modify one of the choices to be a viable action in general circumstances while being impractical in the given situation. As shown by our high human annotator agreement in this task (Fleiss' Kappa = 0.852), we can assume that the proposed evaluation is substantially objective since multiple annotators were able to agree on one correct answer.\n\nWe did not study the effect of more fine-grained personal traits (e.g., detailed experiences, characteristics, and language expression) on the experienced emotions, as we found it outside of our scope. For instance, during a conflict or confrontation, a person who deals with issues by making jokes may not experience the same level of anger as a serious individual. We believe future work could explore augmenting our benchmark with more cases and study the effects of these more fine-grained traits.",
      "page_start": 17,
      "page_end": 17
    },
    {
      "section_name": "Ethical Considerations",
      "text": "We emphasize that our evaluation is concerned with the perceived view of emotional intelligence, aiming to explore the limitations of existing LLMs through novel and challenging tasks. In this work, while our proposed definition includes the ability to understand emotions and apply this understanding to manage emotions, we do not claim nor believe that LLMs are capable of possessing or simulating emotions. With our experiments, we demonstrated that LLMs still rely on frequent patterns to indicate signs of understanding. In addition, despite not having emotions, we found that LLMs can capitalize on their seen patterns to show apparent signs of emotional sense and awareness, which is in line with previous research on LLMs' commonsense  (Sap et al., 2019)  and morality  (Jiang et al., 2021) .",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "A Scenario Taxonomy",
      "text": "",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "A.1 Complex Emotions",
      "text": "Understanding complex emotions is an essential part of emotion understanding  (Rivers et al., 2020) . In our framework, we include three categories that cover the essential aspects of complex emotions:\n\n• Emotion Transition: In response to different events, our emotions are subject to change.\n\nTo assess whether LLMs can reason about such transitions in one's emotions, we create scenarios in which the individual's emotion changes based on the turn of events.\n\nA mother who is annoyed about ruining the food, would be delighted when their child enjoys and compliments it.\n\n• Mixture of Emotions: while previous work mainly annotates each sample with a single emotion label  (Li et al., 2017; Rashkin et al., 2018) , many individuals tend to experience a combination of emotions in various situations. Such emotions could be of the same (e.g., happy and excited) or the opposite (e.g., sad yet relieved) polarities. Hence, we designed scenarios in which the individual feels a mixture of emotions.\n\nIf two friends, Annie and Mark, participate in the same competition and Annie gets first place, then Mark would be happy and proud for his friend's accomplishment while being disappointed for his loss.\n\n• Unexpected Outcome: Inspired by Dyck et al. (  2001 ), we create scenarios in which the conclusion contradicts explicit commonsense and expected reactions. We believe this is crucial in assessing whether LLMs are reliant on patterns to understand emotions, as these scenarios involve reactions that are uncommon for displaying the emotion in the corresponding scenarios.\n\nIf Jamie has had a bad day full of misfortune and bad luck, and finally starts laughing hysterically after dropping his ice cream, his laughter shows frustration, not amusement.",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "A.2 Personal Beliefs And Experiences",
      "text": "To have a deep understanding of one's emotions, we need to recognize how their beliefs and values among past experiences and appraisals could impact the emotions they experience  (Rivers et al., 2020) . To assess this, we designed three categories that aim to evaluate LLM's comprehension of how individual's Cultural Values, Sentimental Values, and personal experiences and traits (namely Persona) could affect their reaction to certain events.\n\n• Cultural Values: In these scenarios, we aim to assess whether LLMs are capable of understanding how an individual's reaction to the same event could vary based on their cultural values and background  (Rivers et al., 2020) . Consider the following situation. Anna is brought up in a culture where being late is considered rude. However, Jonah's culture does not put a great emphasis on punctuality.\n\nIf Anna is late to a meeting with Jonah, she would be embarrassed and apologetic, while Jonah would be unbothered.\n\n• Sentimental Value: Similarly, an important aspect of understanding a person's emotion is identifying the sentimental value that they assign to different memories and belongings.\n\nLosing a T-shirt we wanted to throw out (low sentimental value) is unlikely to lead to sadness, whereas it would be devastating if the T-shirt was a gift from a lost family member (high sentimental value).\n\n• Persona: we also wanted to analyze whether LLMs comprehend the reactions of people with pre-existing emotions. These could include phobias, appraisals (previous experiences), and personal traits (e.g., being antisocial or extroverted).\n\nIf a person with claustrophobia, who gets extremely uncomfortable in small or crowded spaces, is invited to a small space, they might experience fear, but not when going to a spacious garden space.\n\nA.3 Emotional Cues C EMOTION DISTRIBUTION",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "A.3 Emotional Cues",
      "text": "Emotional intelligence enables us to recognize and understand cues about emotions of ourselves and others  (Rivers et al., 2020) . While recent research has shown that LLMs are capable of understanding and responding to direct and explicit emotional stimuli and cues  (Li et al., 2023) , it is not explored how such models would react to implicit cues. To this end, we designed this category to assess LLM's comprehension of text-based vocal (e.g., vocal utterances, tone, and speech) and visual (e.g., facial/physical expressions) cues of emotions.\n\nA person's face turning red could be a visual cue for being angry or shy. A sigh could indicate relief or annoyance.",
      "page_start": 15,
      "page_end": 15
    },
    {
      "section_name": "A.4 Perspective Taking",
      "text": "Emotional understanding has significant correlations with affective theory-of-mind  (Mier et al., 2010; Kalbe et al., 2010; Ferguson and Austin, 2010) , mainly in that they both require the ability to view situations from the perspective of others and simulate their emotions given the circumstances, formally known as perspective-taking. Therefore, we adopt three of the prevalent tasks for assessing perspective-taking in theory-of-mind: False Belief, Faux Pas, Strange Story. However, contrary to the traditional implementation of these tests, our sole focus is on designing scenarios that trigger different emotions based on personal knowledge and views of the situation.\n\n• Affective False Belief: The Sally-Ann test  (Baron-Cohen et al., 1985)  is one of the de facto assessments for the theory of mind (ToM), i.e., the ability to infer the beliefs and mental states of others. Recently, it has also been widely adopted for evaluating ToM in LLMs  (He et al., 2023; Ma et al., 2023; Kim et al., 2023)  as it requires reasoning about each individual's knowledge and perspective on the situation to answer the corresponding questions. In our framework, we collected scenarios in which the individual's emotions could be implied through reasoning about their beliefs, which could be affected by trusting the word of others and/or being oblivious to certain events.\n\nI was the only one who saw my friend's grades and realized that he failed the exam. Therefore, if I tell him that he passed the exam with flying colors, he would be excited, not disappointed.\n\n• Faux Pas: Similarly, a more advanced assessment of ToM is conducted through the faux pas (i.e., tactless acts or remarks that cause unintentional negative consequences) detection test  (Baron-Cohen et al., 1999) . In this task, participants are presented with a social situation and are required to detect the presence and identify the faux pas. Inspired by this, we include a series of scenarios that include a faux pas and assess LLMs on identifying the emotions of the involved individuals. In these scenarios, in addition to understanding social cues associated with a faux pas, LLMs also have to reason about each individual's beliefs and their known information to understand their emotions.\n\nIf a person openly criticizes a painting without knowing it was drawn by their brother, then they may feel disgust towards the painting and not embarrassment due to their lack of information.\n\n• Strange Story: Inspired by Happé (1994), we also designed scenarios that establish hypothetical grounds and imaginary assumptions that would contradict the normal pattern of behavior. This further evaluates whether LLMs truly reason about the situation to infer the relevant emotions or base their judgments on learned patterns.\n\nWhile getting an F in a test would regularly lead to disappointment, getting an F in a class where the teacher only gives Fs to the highest mark leads to pride.",
      "page_start": 16,
      "page_end": 16
    },
    {
      "section_name": "B Experiment Prompts",
      "text": "Our designed prompts are demonstrated in Table  4 . For Chinese samples, we directly translated the provided prompts into Chinese.",
      "page_start": 17,
      "page_end": 17
    },
    {
      "section_name": "C Emotion Distribution",
      "text": "",
      "page_start": 17,
      "page_end": 17
    },
    {
      "section_name": "D Human Evaluation",
      "text": "During registration for our experiments, all candidates disclosed their demographics, language, and task preferences. As a part of our annotation quality control, we excluded individuals under the age of 21 as a means of ensuring emotional maturity (the ability to understand and manage emotions; Jobson (2020)). In addition, we required each candidate to correctly answer all of the questions (six MCQs) in a randomly sampled subset of our benchmark.",
      "page_start": 16,
      "page_end": 16
    },
    {
      "section_name": "D Human Evaluation",
      "text": "Emotional Understanding Guideline",
      "page_start": 18,
      "page_end": 18
    },
    {
      "section_name": "Background",
      "text": "In this test, (1) You will be presented with 30 emotional scenarios.\n\n(2) You will be asked to identify the emotions of the individual and their causes in this scenario. Your task is to :\n\n(1) Carefully read the design section and familiarize yourself with the emotion category.\n\n(2) Take the perspective of the people involved (think how you would feel in this situation).\n\n(3) Choose the appropriate answer from the given choices and enter in the provided Excel sheet.\n\nEmotion Taxonomy\n\n[BASIC EMOTIONS]: Our emotion category includes 8 basic emotions: Sadness, Anger, Joy, Fear, Anticipation, Trust, Disgust, and Surprise.\n\n[MIXED EMOTIONS]: By combining the above basic emotions, we can get 14 mixed emotions: Guilt (joy + fear), Pride (joy + anger), Excitement/Hopeful (Optimism) (joy + anticipation), Love/Caring/Gratitude (joy + + trust), Amusement/Delight (joy + surprise), Disapproval/ Disappointment (surprise + sadness), Sentimental(trust + sadness), Jealousy (sadness + anger), Pessimism (anticipation + sadness), Remorse (disgust + sadness), Hopeless (fear + sadness), Embarrassment (fear + disgust), Nervousness (fear + anticipation), Curiosity (trust + surprise).\n\n[NEUTRAL]: In case the individual in the situation is not experiencing any emotions, we would label them as 1) unbothered (indifferent) or 2) Oblivious, depending on the situation.",
      "page_start": 19,
      "page_end": 19
    },
    {
      "section_name": "Example",
      "text": "Scenario: James and I are coworkers. We've been best friends for over a decade. Our boss gives out an employee of the year award every year. This year, we both applied as candidates for this reward and worked hard to get it. The results were announced yesterday. James won the award.",
      "page_start": 18,
      "page_end": 18
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: An example of the shortcomings in previous",
      "page": 1
    },
    {
      "caption": "Figure 1: Traditional datasets typically contain",
      "page": 2
    },
    {
      "caption": "Figure 2: Overview of Our Benchmark (EMOBENCH).",
      "page": 3
    },
    {
      "caption": "Figure 2: presents an overview of EMOBENCH.",
      "page": 3
    },
    {
      "caption": "Figure 3: Emotion Taxonomy in EMOBENCH.",
      "page": 4
    },
    {
      "caption": "Figure 4: Category Distribution in EMOBENCH. The",
      "page": 5
    },
    {
      "caption": "Figure 5: Results on the EMOBENCH subset used in the human evaluation.",
      "page": 7
    },
    {
      "caption": "Figure 5: , our human participants",
      "page": 8
    },
    {
      "caption": "Figure 4: demonstrates the category distribution for",
      "page": 15
    },
    {
      "caption": "Figure 6: Emotion Distribution in EMOBENCH.",
      "page": 17
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Main Category": "Complex \nEmotions",
          "Secondary Category": "Emotion Transition",
          "Example": "I was annoyed for burning my food, but felt joy after he enjoyed it."
        },
        {
          "Main Category": "",
          "Secondary Category": "Mixture of Emotions",
          "Example": "I’d be happy and disappointed if my friend got a raise instead of me."
        },
        {
          "Main Category": "",
          "Secondary Category": "Unexpected Outcome",
          "Example": "Laughing hysterically after a tragic event shows devastation."
        },
        {
          "Main Category": "Personal Beliefs \nand Experiences",
          "Secondary Category": "Cultural Value",
          "Example": "A waiter getting tipped in Japan would likely not feel gratitude."
        },
        {
          "Main Category": "",
          "Secondary Category": "Sentimental Value",
          "Example": "I would be unbothered by losing an item without sentimental value."
        },
        {
          "Main Category": "",
          "Secondary Category": "Persona",
          "Example": "As an introvert, I would feel joy from having to spend a night alone."
        },
        {
          "Main Category": "Emotional Cues",
          "Secondary Category": "Vocal cues",
          "Example": "A sigh after finishing a hard task shows relief, not disappointment."
        },
        {
          "Main Category": "",
          "Secondary Category": "Visual cues",
          "Example": "A white face usually indicates fear, unless it’s from low blood sugar."
        },
        {
          "Main Category": "Perspective-taking",
          "Secondary Category": "Faux pas",
          "Example": "Henry criticized the painting on the wall, not knowing I drew it."
        },
        {
          "Main Category": "",
          "Secondary Category": "Strange story",
          "Example": "Getting an F, where it is the highest mark, leads to pride."
        },
        {
          "Main Category": "",
          "Secondary Category": "False belief",
          "Example": "Seeing her cry, I thought she was sad, but she’d received great news."
        }
      ],
      "page": 3
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Relationship": "Social",
          "Problem": "Self",
          "Example": "I work better than my coworkers and I feel my workload is higher because of it."
        },
        {
          "Relationship": "",
          "Problem": "Others",
          "Example": "I missed a deadline because my coworker didn’t tell me about it in time."
        },
        {
          "Relationship": "Personal",
          "Problem": "Self",
          "Example": "My best friend is going on a road trip with his other friends, leaving me behind."
        },
        {
          "Relationship": "",
          "Problem": "Others",
          "Example": "My younger brother is being bullied but he begged me not to tell our parents."
        }
      ],
      "page": 3
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "A wide evaluation of chatgpt on affective computing tasks",
      "authors": [
        "M Mostafa",
        "Rui Amin",
        "Erik Mao",
        "Björn Cambria",
        "Schuller"
      ],
      "year": "2023",
      "venue": "A wide evaluation of chatgpt on affective computing tasks"
    },
    {
      "citation_id": "2",
      "title": "Rumors of the death of emotional intelligence in organizational behavior are vastly exaggerated",
      "authors": [
        "M Neal",
        "Catherine Ashkanasy",
        "Daus"
      ],
      "year": "2005",
      "venue": "Journal of Organizational Behavior"
    },
    {
      "citation_id": "3",
      "title": "Qwen technical report",
      "authors": [
        "Jinze Bai",
        "Shuai Bai",
        "Yunfei Chu",
        "Zeyu Cui",
        "Kai Dang",
        "Xiaodong Deng",
        "Yang Fan",
        "Wenbin Ge",
        "Yu Han",
        "Fei Huang"
      ],
      "year": "2023",
      "venue": "Qwen technical report",
      "arxiv": "arXiv:2309.16609"
    },
    {
      "citation_id": "4",
      "title": "BarOn emotional quotient inventory",
      "authors": [
        "Reuven Bar-On"
      ],
      "year": "1997",
      "venue": "BarOn emotional quotient inventory"
    },
    {
      "citation_id": "5",
      "title": "Does the autistic child have a \"theory of mind",
      "authors": [
        "Simon Baron-Cohen",
        "Alan Leslie",
        "Uta Frith"
      ],
      "year": "1985",
      "venue": "Cognition"
    },
    {
      "citation_id": "6",
      "title": "Recognition of faux pas by normally developing children and children with asperger syndrome or high-functioning autism",
      "authors": [
        "Simon Baron-Cohen",
        "Michelle 'riordan",
        "Valerie Stone",
        "Rosie Jones",
        "Kate Plaisted"
      ],
      "year": "1999",
      "venue": "Journal of autism and developmental disorders"
    },
    {
      "citation_id": "7",
      "title": "",
      "authors": [
        "B Tom",
        "Benjamin Brown",
        "Nick Mann",
        "Melanie Ryder",
        "Jared Subbiah",
        "Prafulla Kaplan",
        "Arvind Dhariwal",
        "Pranav Neelakantan",
        "Girish Shyam",
        "Amanda Sastry",
        "Sandhini Askell",
        "Ariel Agarwal",
        "Gretchen Herbert-Voss",
        "Tom Krueger",
        "Rewon Henighan",
        "Aditya Child",
        "Daniel Ramesh",
        "Jeffrey Ziegler",
        "Clemens Wu",
        "Christopher Winter",
        "Mark Hesse",
        "Eric Chen",
        "Mateusz Sigler",
        "Scott Litwin",
        "Gray"
      ],
      "venue": ""
    },
    {
      "citation_id": "8",
      "title": "A review and critique of emotional intelligence measures",
      "authors": [
        "Jeffrey M Conte"
      ],
      "year": "2005",
      "venue": "Journal of organizational behavior"
    },
    {
      "citation_id": "9",
      "title": "Emotional artificial intelligence: detecting and managing customer emotions in automated customer service",
      "authors": [
        "Marzia Del"
      ],
      "year": "2021",
      "venue": "Emotional artificial intelligence: detecting and managing customer emotions in automated customer service"
    },
    {
      "citation_id": "10",
      "title": "Goemotions: A dataset of fine-grained emotions",
      "authors": [
        "Dorottya Demszky",
        "Dana Movshovitz-Attias",
        "Jeongwoo Ko",
        "Alan Cowen",
        "Gaurav Nemade",
        "Sujith Ravi"
      ],
      "year": "2020",
      "venue": "Goemotions: A dataset of fine-grained emotions",
      "arxiv": "arXiv:2005.00547"
    },
    {
      "citation_id": "11",
      "title": "Glm: General language model pretraining with autoregressive blank infilling",
      "authors": [
        "Zhengxiao Du",
        "Yujie Qian",
        "Xiao Liu",
        "Ming Ding",
        "Jiezhong Qiu",
        "Zhilin Yang",
        "Jie Tang"
      ],
      "year": "2022",
      "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "12",
      "title": "Do autism spectrum disorders differ from each other and from non-spectrum disorders on emotion recognition tests?",
      "authors": [
        "J Murray",
        "Kara Dyck",
        "Ian Ferguson",
        "Shochet"
      ],
      "year": "2001",
      "venue": "European child & adolescent psychiatry"
    },
    {
      "citation_id": "13",
      "title": "Expression and the nature of emotion",
      "authors": [
        "Paul Ekman"
      ],
      "year": "1984",
      "venue": "Approaches to emotion"
    },
    {
      "citation_id": "14",
      "title": "Do we need emotionally intelligent artificial agents? first results of human perceptions of emotional intelligence in humans compared to robots",
      "authors": [
        "Lisa Fan",
        "Matthias Scheutz",
        "Monika Lohani",
        "Marissa Mccoy",
        "Charlene Stokes"
      ],
      "year": "2017",
      "venue": "Intelligent Virtual Agents: 17th International Conference"
    },
    {
      "citation_id": "15",
      "title": "Associations of trait and ability emotional intelligence with performance on theory of mind tasks in an adult sample",
      "authors": [
        "J Fiona",
        "Elizabeth Ferguson",
        "Austin"
      ],
      "year": "2010",
      "venue": "Personality and individual differences"
    },
    {
      "citation_id": "16",
      "title": "The equivalence of weighted kappa and the intraclass correlation coefficient as measures of reliability",
      "authors": [
        "L Joseph",
        "Jacob Fleiss",
        "Cohen"
      ],
      "year": "1973",
      "venue": "Educational and psychological measurement"
    },
    {
      "citation_id": "17",
      "title": "CICERO: A dataset for contextualized commonsense inference in dialogues",
      "authors": [
        "Deepanway Ghosal",
        "Siqi Shen",
        "Navonil Majumder",
        "Rada Mihalcea",
        "Soujanya Poria"
      ],
      "year": "2022",
      "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/2022.acl-long.344"
    },
    {
      "citation_id": "18",
      "title": "Emotional intelligence. why it can matter more than iq",
      "authors": [
        "Daniel Goleman"
      ],
      "year": "1996",
      "venue": "Learning"
    },
    {
      "citation_id": "19",
      "title": "An advanced test of theory of mind: Understanding of story characters' thoughts and feelings by able autistic, mentally handicapped, and normal children and adults",
      "authors": [
        "G Francesca",
        "Happé"
      ],
      "year": "1994",
      "venue": "Journal of autism and Developmental disorders"
    },
    {
      "citation_id": "20",
      "title": "Hi-tom: A benchmark for evaluating higher-order theory of mind reasoning in large language models",
      "authors": [
        "Yinghui He",
        "Yufan Wu",
        "Yilin Jia",
        "Rada Mihalcea",
        "Yulong Chen",
        "Naihao Deng"
      ],
      "year": "2023",
      "venue": "Hi-tom: A benchmark for evaluating higher-order theory of mind reasoning in large language models",
      "arxiv": "arXiv:2310.16755"
    },
    {
      "citation_id": "21",
      "title": "Who is chatgpt? benchmarking llms' psychological portrayal using psychobench",
      "authors": [
        "Jen-Tse Huang",
        "Wenxuan Wang",
        "Eric Li",
        "Man Lam",
        "Shujie Ren",
        "Youliang Yuan",
        "Wenxiang Jiao",
        "Zhaopeng Tu",
        "Michael R Lyu"
      ],
      "year": "2023",
      "venue": "Who is chatgpt? benchmarking llms' psychological portrayal using psychobench",
      "arxiv": "arXiv:2310.01386"
    },
    {
      "citation_id": "22",
      "title": "CRoW: Benchmarking commonsense reasoning in real-world tasks",
      "authors": [
        "Mete Ismayilzada",
        "Debjit Paul",
        "Syrielle Montariol",
        "Mor Geva",
        "Antoine Bosselut"
      ],
      "year": "2023",
      "venue": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
      "doi": "10.18653/v1/2023.emnlp-main.607"
    },
    {
      "citation_id": "23",
      "title": "Emotional intelligence and agents: Survey and possible applications",
      "authors": [
        "Mirjana Ivanović",
        "Miloš Radovanović",
        "Zoran Budimac",
        "Dejan Mitrović",
        "Vladimir Kurbalija",
        "Weihui Dai",
        "Weidong Zhao"
      ],
      "year": "2014",
      "venue": "Proceedings of the 4th International Conference on Web Intelligence, Mining and Semantics"
    },
    {
      "citation_id": "24",
      "title": "Saadia Gabriel, et al. 2021. Can machines learn morality? the delphi experiment",
      "authors": [
        "Liwei Jiang",
        "Jena Hwang",
        "Chandra Bhagavatula",
        "Le Ronan",
        "Jenny Bras",
        "Jesse Liang",
        "Keisuke Dodge",
        "Maxwell Sakaguchi",
        "Jon Forbes",
        "Borchardt"
      ],
      "venue": "Saadia Gabriel, et al. 2021. Can machines learn morality? the delphi experiment",
      "arxiv": "arXiv:2110.07574"
    },
    {
      "citation_id": "25",
      "title": "Emotional maturity among adolescents and its importance",
      "authors": [
        "C Mridula",
        "Jobson"
      ],
      "year": "2020",
      "venue": "Indian Journal of Mental Health"
    },
    {
      "citation_id": "26",
      "title": "Dissociating cognitive from affective theory of mind: A tms study",
      "authors": [
        "Elke Kalbe",
        "Marius Schlegel",
        "Alexander Sack",
        "Dennis Nowak",
        "Manuel Dafotakis",
        "Christopher Bangard",
        "Matthias Brand",
        "Simone Shamay-Tsoory",
        "Oezguer Onur",
        "Josef Kessler"
      ],
      "year": "2010",
      "venue": "Cortex",
      "doi": "10.1016/j.cortex.2009.07.010"
    },
    {
      "citation_id": "27",
      "title": "FANToM: A benchmark for stress-testing machine theory of mind in interactions",
      "authors": [
        "Hyunwoo Kim",
        "Melanie Sclar",
        "Xuhui Zhou",
        "Ronan Bras",
        "Gunhee Kim",
        "Yejin Choi",
        "Maarten Sap"
      ],
      "year": "2023",
      "venue": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
      "doi": "10.18653/v1/2023.emnlp-main.890"
    },
    {
      "citation_id": "28",
      "title": "Large language models understand and can be enhanced by emotional stimuli",
      "authors": [
        "Cheng Li",
        "Jindong Wang",
        "Yixuan Zhang",
        "Kaijie Zhu",
        "Wenxin Hou",
        "Jianxun Lian",
        "Fang Luo",
        "Qiang Yang",
        "Xing Xie"
      ],
      "year": "2023",
      "venue": "Large language models understand and can be enhanced by emotional stimuli",
      "arxiv": "arXiv:2305.15068"
    },
    {
      "citation_id": "29",
      "title": "Dailydialog: A manually labelled multi-turn dialogue dataset",
      "authors": [
        "Yanran Li",
        "Hui Su",
        "Xiaoyu Shen",
        "Wenjie Li",
        "Ziqiang Cao",
        "Shuzi Niu"
      ],
      "year": "2017",
      "venue": "Dailydialog: A manually labelled multi-turn dialogue dataset",
      "arxiv": "arXiv:1710.03957"
    },
    {
      "citation_id": "30",
      "title": "Towards emotional support dialog systems",
      "authors": [
        "Siyang Liu",
        "Chujie Zheng",
        "Orianna Demasi",
        "Sahand Sabour",
        "Yu Li",
        "Zhou Yu",
        "Yong Jiang",
        "Minlie Huang"
      ],
      "year": "2021",
      "venue": "Towards emotional support dialog systems",
      "arxiv": "arXiv:2106.01144"
    },
    {
      "citation_id": "31",
      "title": "Emotional intelligence and social interaction",
      "authors": [
        "Paulo Lopes",
        "Marc Brackett",
        "John Nezlek",
        "Astrid Schütz",
        "Ina Sellin",
        "Peter Salovey"
      ],
      "year": "2004",
      "venue": "Personality and social psychology bulletin"
    },
    {
      "citation_id": "32",
      "title": "Tomchallenges: A principle-guided dataset and diverse evaluation tasks for exploring theory of mind",
      "authors": [
        "Xiaomeng Ma",
        "Lingyu Gao",
        "Qihui Xu"
      ],
      "year": "2023",
      "venue": "Tomchallenges: A principle-guided dataset and diverse evaluation tasks for exploring theory of mind",
      "arxiv": "arXiv:2305.15068"
    },
    {
      "citation_id": "33",
      "title": "New paradigms for assessing emotional intelligence: theory and data",
      "authors": [
        "Carolyn Maccann",
        "Richard Roberts"
      ],
      "year": "2008",
      "venue": "Emotion"
    },
    {
      "citation_id": "34",
      "title": "Emotional intelligence meets traditional standards for an intelligence",
      "authors": [
        "David John D Mayer",
        "Peter Caruso",
        "Salovey"
      ],
      "year": "1999",
      "venue": "Intelligence"
    },
    {
      "citation_id": "35",
      "title": "Mayer-salovey-caruso emotional intelligence test",
      "authors": [
        "Peter John D Mayer",
        "David Salovey",
        "Caruso"
      ],
      "year": "2007",
      "venue": "Mayer-salovey-caruso emotional intelligence test"
    },
    {
      "citation_id": "36",
      "title": "The involvement of emotion recognition in affective theory of mind",
      "authors": [
        "Daniela Mier",
        "Stefanie Lis",
        "Kerstin Neuthe",
        "Carina Sauer",
        "Christine Esslinger",
        "Bernd Gallhofer",
        "Peter Kirsch"
      ],
      "year": "2010",
      "venue": "Psychophysiology",
      "doi": "10.1111/j.1469-8986.2010.01031.x"
    },
    {
      "citation_id": "37",
      "title": "The measurement of emotional intelligence: A critical review of the literature and recommendations for researchers and practitioners",
      "authors": [
        "J O' Peter",
        "Andrew Connor",
        "Maria Hill",
        "Brett Kaya",
        "Martin"
      ],
      "year": "2019",
      "venue": "Frontiers in psychology"
    },
    {
      "citation_id": "38",
      "title": "Gpt-4 technical report",
      "authors": [
        "Openai"
      ],
      "year": "2023",
      "venue": "Gpt-4 technical report"
    },
    {
      "citation_id": "39",
      "title": "Eq-bench: An emotional intelligence benchmark for large language models",
      "authors": [
        "J Samuel",
        "Paech"
      ],
      "year": "2023",
      "venue": "Eq-bench: An emotional intelligence benchmark for large language models",
      "arxiv": "arXiv:2312.06281"
    },
    {
      "citation_id": "40",
      "title": "Toward machines with emotional intelligence",
      "authors": [
        "Rosalind Picard"
      ],
      "year": "2008",
      "venue": "Toward machines with emotional intelligence"
    },
    {
      "citation_id": "41",
      "title": "Toward machine emotional intelligence: Analysis of affective physiological state. IEEE transactions on pattern analysis and machine intelligence",
      "authors": [
        "Rosalind Picard",
        "Elias Vyzas",
        "Jennifer Healey"
      ],
      "year": "2001",
      "venue": "Toward machine emotional intelligence: Analysis of affective physiological state. IEEE transactions on pattern analysis and machine intelligence"
    },
    {
      "citation_id": "42",
      "title": "A psychoevolutionary theory of emotions",
      "authors": [
        "Robert Plutchik"
      ],
      "year": "1982",
      "venue": "A psychoevolutionary theory of emotions"
    },
    {
      "citation_id": "43",
      "title": "MELD: A multimodal multi-party dataset for emotion recognition in conversations",
      "authors": [
        "Soujanya Poria",
        "Devamanyu Hazarika",
        "Navonil Majumder",
        "Gautam Naik",
        "Erik Cambria",
        "Rada Mihalcea"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/P19-1050"
    },
    {
      "citation_id": "44",
      "title": "Recognizing emotion cause in conversations",
      "authors": [
        "Soujanya Poria",
        "Navonil Majumder",
        "Devamanyu Hazarika",
        "Deepanway Ghosal",
        "Rishabh Bhardwaj",
        "Samson Yu Bai Jian",
        "Pengfei Hong",
        "Romila Ghosh",
        "Abhinaba Roy",
        "Niyati Chhaya"
      ],
      "year": "2021",
      "venue": "Cognitive Computation"
    },
    {
      "citation_id": "45",
      "title": "Towards empathetic opendomain conversation models: A new benchmark and dataset",
      "authors": [
        "Eric Hannah Rashkin",
        "Margaret Smith",
        "Y-Lan Li",
        "Boureau"
      ],
      "year": "2018",
      "venue": "Towards empathetic opendomain conversation models: A new benchmark and dataset",
      "arxiv": "arXiv:1811.00207"
    },
    {
      "citation_id": "46",
      "title": "The media equation: How people treat computers, television, and new media like real people",
      "authors": [
        "Byron Reeves",
        "Clifford Nass"
      ],
      "year": "1996",
      "venue": "The media equation: How people treat computers, television, and new media like real people"
    },
    {
      "citation_id": "47",
      "title": "",
      "authors": [
        "Susan Rivers",
        "Isaac Handley-Miner",
        "John Mayer",
        "David Caruso"
      ],
      "year": "2020",
      "venue": ""
    },
    {
      "citation_id": "48",
      "title": "Chatbots for mental health support: Exploring the impact of emohaa on reducing mental distress in china",
      "authors": [
        "Sahand Sabour",
        "Wen Zhang",
        "Xiyao Xiao",
        "Yuwei Zhang",
        "Yinhe Zheng",
        "Jiaxin Wen",
        "Jialu Zhao",
        "Minlie Huang"
      ],
      "year": "2022",
      "venue": "Chatbots for mental health support: Exploring the impact of emohaa on reducing mental distress in china",
      "arxiv": "arXiv:2209.10183"
    },
    {
      "citation_id": "49",
      "title": "Emotional intelligence. Imagination, cognition and personality",
      "authors": [
        "Peter Salovey",
        "John Mayer"
      ],
      "year": "1990",
      "venue": "Emotional intelligence. Imagination, cognition and personality"
    },
    {
      "citation_id": "50",
      "title": "Atomic: An atlas of machine commonsense for ifthen reasoning",
      "authors": [
        "Maarten Sap",
        "Le Ronan",
        "Emily Bras",
        "Chandra Allaway",
        "Nicholas Bhagavatula",
        "Hannah Lourie",
        "Brendan Rashkin",
        "Noah Roof",
        "Yejin Smith",
        "Choi"
      ],
      "year": "2019",
      "venue": "Proceedings of the AAAI conference on artificial intelligence"
    },
    {
      "citation_id": "51",
      "title": "The age of artificial emotional intelligence",
      "authors": [
        "Dagmar Schuller",
        "Björn Schuller"
      ],
      "year": "2018",
      "venue": "Computer"
    },
    {
      "citation_id": "52",
      "title": "Emotional intelligence and interpersonal relations",
      "authors": [
        "Nicola Schutte",
        "John Malouff",
        "Chad Bobik",
        "Tracie Coston",
        "Cyndy Greeson",
        "Christina Jedlicka",
        "Emily Rhodes",
        "Greta Wendorf"
      ],
      "year": "2001",
      "venue": "Journal of social psychology"
    },
    {
      "citation_id": "53",
      "title": "Characteristic emotional intelligence and emotional wellbeing",
      "authors": [
        "Nicola Schutte",
        "John Malouff",
        "Maureen Simunek",
        "Jamie Mckenley",
        "Sharon Hollander"
      ],
      "year": "2002",
      "venue": "Cognition & Emotion"
    },
    {
      "citation_id": "54",
      "title": "Engagement, emotions, and relationships: on building intelligent agents",
      "authors": [
        "Candace Sidner"
      ],
      "year": "2016",
      "venue": "Emotions, Technology, Design, and Learning"
    },
    {
      "citation_id": "55",
      "title": "Open foundation and fine-tuned chat models",
      "authors": [
        "Hugo Touvron",
        "Louis Martin",
        "Kevin Stone",
        "Peter Albert",
        "Amjad Almahairi",
        "Yasmine Babaei",
        "Nikolay Bashlykov",
        "Soumya Batra",
        "Prajjwal Bhargava",
        "Shruti Bhosale"
      ],
      "year": "2023",
      "venue": "Open foundation and fine-tuned chat models",
      "arxiv": "arXiv:2307.09288"
    },
    {
      "citation_id": "56",
      "title": "Large language models fail on trivial alterations to theory-of-mind tasks",
      "authors": [
        "Tomer Ullman"
      ],
      "year": "2023",
      "venue": "Large language models fail on trivial alterations to theory-of-mind tasks",
      "arxiv": "arXiv:2302.08399"
    },
    {
      "citation_id": "57",
      "title": "Emotional intelligence of large language models",
      "authors": [
        "Xuena Wang",
        "Xueting Li",
        "Zi Yin",
        "Yue Wu",
        "Jia Liu"
      ],
      "year": "2023",
      "venue": "Journal of Pacific Rim Psychology",
      "doi": "10.1177/18344909231213958"
    },
    {
      "citation_id": "58",
      "title": "Multiple intelligences, the mozart effect, and emotional intelligence: A critical review",
      "authors": [
        "Lynn Waterhouse"
      ],
      "year": "2006",
      "venue": "Educational psychologist"
    },
    {
      "citation_id": "59",
      "title": "Chain-of-thought prompting elicits reasoning in large language models",
      "authors": [
        "Jason Wei",
        "Xuezhi Wang",
        "Dale Schuurmans",
        "Maarten Bosma",
        "Fei Xia",
        "Ed Chi",
        "V Quoc",
        "Denny Le",
        "Zhou"
      ],
      "year": "2022",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "60",
      "title": "Efficient cross-task prompt tuning for few-shot conversational emotion recognition",
      "authors": [
        "Yige Xu",
        "Zhiwei Zeng",
        "Zhiqi Shen"
      ],
      "year": "2023",
      "venue": "Findings of the Association for Computational Linguistics: EMNLP 2023"
    },
    {
      "citation_id": "61",
      "title": "Open large-scale language models",
      "authors": [
        "Aiyuan Yang",
        "Bin Xiao",
        "Bingning Wang",
        "Borong Zhang",
        "Ce Bian",
        "Chenxu Chao Yin",
        "Da Lv",
        "Dian Pan",
        "Dong Wang",
        "Yan"
      ],
      "year": "2023",
      "venue": "Open large-scale language models",
      "arxiv": "arXiv:2309.10305"
    },
    {
      "citation_id": "62",
      "title": "Qianqian Xie, and Sophia Ananiadou. 2023b. On the evaluations of chatgpt and emotion-enhanced prompting for mental health analysis",
      "authors": [
        "Kailai Yang",
        "Shaoxiong Ji",
        "Tianlin Zhang"
      ],
      "venue": "Qianqian Xie, and Sophia Ananiadou. 2023b. On the evaluations of chatgpt and emotion-enhanced prompting for mental health analysis",
      "arxiv": "arXiv:2304.03347"
    },
    {
      "citation_id": "63",
      "title": "Glm-130b: An open bilingual pre-trained model",
      "authors": [
        "Aohan Zeng",
        "Xiao Liu",
        "Zhengxiao Du",
        "Zihan Wang",
        "Hanyu Lai",
        "Ming Ding",
        "Zhuoyi Yang",
        "Yifan Xu",
        "Wendi Zheng",
        "Xiao Xia"
      ],
      "year": "2022",
      "venue": "Glm-130b: An open bilingual pre-trained model",
      "arxiv": "arXiv:2210.02414"
    },
    {
      "citation_id": "64",
      "title": "Safetybench: Evaluating the safety of large language models with multiple choice questions",
      "authors": [
        "Zhexin Zhang",
        "Leqi Lei",
        "Lindong Wu",
        "Rui Sun",
        "Yongkang Huang",
        "Chong Long",
        "Xiao Liu",
        "Xuanyu Lei",
        "Jie Tang",
        "Minlie Huang"
      ],
      "year": "2023",
      "venue": "Safetybench: Evaluating the safety of large language models with multiple choice questions",
      "arxiv": "arXiv:2309.07045"
    },
    {
      "citation_id": "65",
      "title": "Large language models are not robust multiple choice selectors",
      "authors": [
        "Chujie Zheng",
        "Hao Zhou",
        "Fandong Meng",
        "Jie Zhou",
        "Minlie Huang"
      ],
      "year": "2023",
      "venue": "Large language models are not robust multiple choice selectors"
    },
    {
      "citation_id": "66",
      "title": "Agieval: A human-centric benchmark for evaluating foundation models",
      "authors": [
        "Wanjun Zhong",
        "Ruixiang Cui",
        "Yiduo Guo",
        "Yaobo Liang",
        "Shuai Lu",
        "Yanlin Wang",
        "Amin Saied",
        "Weizhu Chen",
        "Nan Duan"
      ],
      "year": "2023",
      "venue": "Agieval: A human-centric benchmark for evaluating foundation models",
      "arxiv": "arXiv:2304.06364"
    },
    {
      "citation_id": "67",
      "title": "2023a. Solving challenging math word problems using gpt-4 code interpreter with code-based self-verification",
      "authors": [
        "Aojun Zhou",
        "Ke Wang",
        "Zimu Lu",
        "Weikang Shi",
        "Sichun Luo",
        "Zipeng Qin",
        "Shaoqing Lu",
        "Anya Jia",
        "Linqi Song",
        "Mingjie Zhan"
      ],
      "venue": "2023a. Solving challenging math word problems using gpt-4 code interpreter with code-based self-verification",
      "arxiv": "arXiv:2308.07921"
    },
    {
      "citation_id": "68",
      "title": "Graham Neubig, et al. 2023b. Sotopia: Interactive evaluation for social intelligence in language agents",
      "authors": [
        "Xuhui Zhou",
        "Hao Zhu",
        "Leena Mathur",
        "Ruohong Zhang",
        "Haofei Yu",
        "Zhengyang Qi",
        "Louis-Philippe Morency",
        "Yonatan Bisk",
        "Daniel Fried"
      ],
      "venue": "Graham Neubig, et al. 2023b. Sotopia: Interactive evaluation for social intelligence in language agents",
      "arxiv": "arXiv:2310.11667"
    }
  ]
}