{
  "paper_id": "2209.13999v1",
  "title": "Cefer: A Four Facets Framework Based On Context And Emotion Embedded Features For Implicit And Explicit Emotion Recognition",
  "published": "2022-09-28T11:16:32Z",
  "authors": [
    "Fereshteh Khoshnam",
    "Ahmad Baraani-Dastjerdi",
    "M. J. Liaghatdar"
  ],
  "keywords": [
    "Transformer",
    "Emotional embedding",
    "Explicit/Implicit Recognition",
    "Word/ Sentence Feature Vector",
    "Hierarchical and Categorical Emotional Models",
    "Lexicon"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "People's conduct and reactions are driven by their emotions. Online social media is becoming a great instrument for expressing emotions in written form. Paying attention to the context and the entire sentence help us to detect emotion from texts. However, this perspective inhibits us from noticing some emotional words or phrases in the text, particularly when the words express an emotion implicitly rather than explicitly. On the other hand, focusing only on the words and ignoring the context results in a distorted understanding of the sentence meaning and feeling. In this paper, we propose a framework that analyses text at both the sentence and word levels. We name it CEFER (Context and Emotion embedded Framework for Emotion Recognition). Our four approach facets are to extracting data by considering the entire sentence and each individual word simultaneously, as well as implicit and explicit emotions. The knowledge gained from these data not only mitigates the impact of flaws in the preceding approaches but also it strengthens the feature vector. We evaluate several feature spaces using BERT family and design the CEFER based on them. CEFER combines the emotional vector of each word, including explicit and implicit emotions, with the feature vector of each word based on context. CEFER performs better than the BERT family. The experimental results demonstrate that identifying implicit emotions are more challenging than detecting explicit emotions. CEFER, improves the accuracy of implicit emotion recognition. According to the results, CEFER perform 5% better than the BERT family in recognizing explicit emotions and 3% in implicit.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Introduction",
      "text": "People's lifestyles are changing due to the use of the Internet and various social media platforms. These changes have had an impact on practically the entire world daily routines. People use the internet to work, learn, shop, and socialize. It has also influence on how individuals communicate their opinions, and emotions; they are continuously posting their thoughts, feelings, and emotions on social media.\n\nEmotions are the most important factor in human behavior. Emotion is a vital component of a person's reaction to both external and internal events. It causes him to reconsider his thoughts and perspectives  [1, 2] . Therefore, analysis of publicly available data on platforms, which is typically in the form of document collections -often short texts-appears to be vital and plays a significant role in giving reliable public opinion insights. Researches in this field are valuable. Major domains of researches in this field are: health monitoring  [3, 46, 47] , election forecasting  [4] , financial markets  [5] , student surveys  [6] , and software product design  [7, 50] .\n\nTo recognize emotions from textual data, emotion analysis systems use a number of learning approaches: including lexical-based  [8] , machine / deep learning  [9, 10] , a combination of lexical and machine learning  [11] , and concept-based learning approaches  [12, 13] .\n\nThe task of creating systems that can automatically analyze natural language in order to understand emotional content is challenging and fraught with difficulties. A general problem is modeling human emotional behavior and recognizing the boundaries between different emotions in automated text-based systems  [14] .\n\nAnother key challenge is determining the text emotions through proper analysis. Two levels of analyses exist: sentence-level and word-level. The sentence-level is concerned with how to evaluate the context and applies the sentence meaning  [4, 5, 6] . A word-level that necessitates concentrating on individual words which may or may not contain any emotions. These emotions may be expressed implicitly or explicitly. Writers may avoid using explicit emotional words in the text in favor of using words that express the senses implicitly  [15, 51] . Implicit emotions, according to researchers, influence the intensity and duration of emotional responses. In addition, the combination of implicit and explicit emotions allows complex emotional states to be deduced  [48, 49] . As a result, it appears that broadening the scope of research to identify implicit emotions is required  [51] .\n\nAll of the aforementioned factors emphasize the necessity of recognizing both implicit and explicit emotions, as well as accurate text analysis at both the sentence and word levels. The current research is focused on text-based emotion mining. We propose a framework which we name CEFER that all four aforementioned approach facets are considered. Some key contributions of CEFER are as follows:\n\n1-Constructing the feature vector of each word using the concept of the entire sentence and context. In this situation, the semantic of the entire sentence will be implicitly stored in the feature vector of each word.\n\n2-Constructing the emotional vector of words based on implicit and explicit emotions at the same time 3-Studying the results of integrating emotional knowledge with extracted feature vectors.  4 -Experimental results show that CEFER works well in both implicit and explicit emotion recognition.\n\n5-CEFER can identify emotions in short English texts and classify them into Plutchik eight primary categories (Joy, Trust, Fear, Surprise, Sadness, Disgust, Anger, and Anticipation). 6-The emotional vector and the extracted feature vector for each word are used to construct the meta-embedding.\n\nThe evaluation of the proposed framework on three valid datasets shows that CEFER performs better than many previous works in detecting explicit and implicit emotions. CEFER, on the other hand, can simultaneously identify both types of emotion that none of the previous works have. Of course, except for DuFER, which is the previous work of the authors of the article. In addition, compared to the results obtained from transformers, CEFER shows a detection improvement of between 3% and 5%.\n\nThe organization of this article is as follows: First, we will review the related works. Subsequently, Section 3 provides more details on CEFER architecture. Experimental and evaluation results will be discussed in Section 4. Conclusion is presented in Section 5.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Related Work",
      "text": "Emotions have been explored by psychologists in terms of definition and classification. Ekman  [17] , who recognized six primary emotions, and Plutchik  [18] , who classified emotions into eight broad groups, are two prominent and well-known definitions in this topic. Moreover, emotions are divided into two main types, explicit and implicit  [36] . Many studies on textbased emotion recognition focus on explicit emotions. Some studies focus on implicit emotions, while only a few about both types of emotions. These studies used a variety of deep learning and machine learning methodologies.\n\nMachine learning approaches have generally recognized explicit emotions  [16, 19, 21, 22, 57] , while a small number of research methods have identified implicit emotions. The two methods which identified implicit emotions are presented in the IEST competition, which came in 15th and 19th place among the 30 teams  [20] . Finally, a few studies have been done, such as DuFER  [15] , to identify both implicit and explicit emotions at the same time.\n\nIn this study, the deep learning approach is applied. Therefore, studies that have employed deep learning methods are reviewed. Levels of text processing (sentence and word levels) and types of emotions (explicit and implicit) are explored.\n\nPark et al.  [23]  concentrated on modeling emotional representations within the text at the sentence and word level. Neural network models were used as feature extractors. They used these representations for classic machine learning methods like support vector regression and logistic regression to transfer emotional knowledge. The emoticons and hashtags in their labeled corpuses were used. The problem is that their model only predicts emoji clusters with a maximum accuracy of 61.0 percent. As a result, the emotionally gathered knowledge is also less accurate only four of Plutchik eight main emotions (happy, sad, fear, and anger) are recognized. Furthermore, the work was focused on the expressive feelings of the characters. The explicit emotions of text are only considered. Chatterjee et al.  [24]  suggested a deep learning approach for recognizing three emotions in textual dialogue: happy, sad, and angry. The sad emotion is the one that is most accurate (80.79 percent). This study is focused on recognizing explicit emotions. Implicit emotions are not considered. The method combines semantic and sentiment representations of words to better recognize explicit emotions. However, the limitation of model is that the context of conversation and the sentence features are not considered.\n\nEmoDet2  [25]  can recognize and classify the explicit emotions in English text conversation into four groups (happy, sad, angry, etc.). GloVe word embedding, BERT embedding, and a set of psycholinguistic features make up the main input of system. The suggested system combines the BiLSTM neural network with a fully connected neural network architecture. EmoDet2's results demonstrate that it has improved significantly (F1=0.748) over the base model submitted by the Semeval-2019 organizers (F1 = 0.58). However, semantic features are extracted by transforming the entire text into a single vector. EmoDet2 does not really involve the specific features of words and sentences. Furthermore, this approach has not recognized or even paid attention to the implicit emotions in order to find the explicit emotions.\n\nIllendula and Sheth  [26]  studied the effect of emojis and images on the accuracy of categorizing explicit emotions in social media posts. They used the BiLSTM model with the attention mechanism. They fed it with extracted features from the images, FastText embedding and EmojiNet. They were able to reach a 72 percent accuracy rate. The explicit emotions (Anger, Fear, Joy, Love, Sad, Surprise, and Thankful) were recognized according to the features of the words. The number of words that caused the best accuracy was investigated but the sentence and context features were not taken into account. In addition, the implicit emotions of texts were not considered.\n\nA classification approach based on deep neural networks, Bi-LSTM, CNN, and self-attention was proposed in  [27] . For word encoding, three pre-trained word embeddings (GoogleEmb, GloVeEmb, and FastTextEmb) were employed and compared. The outcomes of different word embedding were compared. The four explicit emotions (anger, fear, joy, and sadness) were recognized with a maximum accuracy of 84 percent which were focused on the features of words. Context and sentence-level features were not taken into account in this study. It is also important to pay attention to implicit emotions. Low accuracy has resulted from a lack of attention to these factors.\n\nFour types of sequence-based convolutional neural network models were proposed by Zahiri and Choi  [28] . The sequence information encapsulated in conversation was used by these attentive networks. They also proposed detailed SCNN models that contained existing sequence information. The presented CNN is sequence-based and extracted features from the current speech are combined with previous ones. Sequence information was used to improve the classification of the seven emotions. This study attempted to maintain the sequence of conversation, however, this did not help paying attention to the concept at the sentence level. This leads not to pay attention to the implicit emotions in the text, resulting in a 54 percent accuracy rate.\n\nBNet is a technique presented by Jabreel and Moreno  [29]  to turn the problem of emotion recognition into a binary classification problem. It has a 59 percent accuracy rate. Three embedding models and an attention function were used in this method. A set of key-value pairs was mapped to an output by the embedding module. BNet extracts features at the word level but sentence-level feature and the impact of implicit concepts throughout the sentence are not considered. The system recognizes eight emotions that it has aggressively encountered in relation to four of them. This means that the system has linked a small number of instances to these labels.\n\nThe application of natural language comprehension to emotion recognition tasks is investigated in  [30] . Different transformers are fine-tuned by the writers (BERT, DistilBERT, RoBERTa, XLNet). They use a fine-grained emotion dataset for this purpose. They then assess each the performance of transformer appropriately. The major goal of this research is to look into the behavior of different transformer language models when it comes to recognize emotions. The authors have simply paid attention to the context in accordance with the purpose. The study ignores implicit emotions and concepts as well as word-level features. The findings demonstrate that these transformers perform similarly in the emotion recognition task while RoBERTa had the highest F1-score. Schmidt et al.  [31]  examine the performance of different methods for classifying emotional texts in the context of German historical plays around 1800. Lexicon-based machine learning, FastText as static word embedding and various transformer models based on the BERT or ELECTRA architecture are among these methods. The recognition of 13 sub-emotions from six primary emotional categories is taken into account, resulting in a 66 percent accuracy rate.\n\nThe entire text serves as the foundation for identifying emotion. Because many texts are relatively long, they contain a variety of emotions. So, the main reason of misdiagnosis in this study is mapping the entire text to only one emotion. As a result, shorter textual units such as sentences, phrases, and words must be prioritized. Furthermore, the writers' attention on the overall context has caused them to overlook the implicit emotions as well as the word-level and sentence-level analysis.\n\nKrommyda et al.  [52]  identifies eight Plutchik emotions in short texts using emoji, keyword, and semantic analysis. The authors produce a dataset and use it to train classification models. They use an empirical investigation to determine the influential features and then created a model for recognizing emotions in social media posts. The authors' rationale for employing emotional and lexical dictionaries to extract word-level properties and semantic correlations are correct, resulting in a 91.9 percent accuracy. The sentence-level features and context, on the other hand, have received no attention.\n\nThe goal of  [53]  is to use deep learning and natural language processing to identify, examine, and understand the emotions expressed globally in the early months of the Covid. Model analysis and text-based emotional data analysis are both used in this research. The accuracy of model in recognizing emotions in Twitter texts is 80.33 percent. This categorization is based on 13 different emotions (anger, boredom, empty, enthusiasm, fun, happiness, hate, love, neutral, relief, sadness, surprise and worry). The lack of a distinct emotional model has resulted in the categorization of emotions into numerous groupings, lowering accuracy. Some of these emotions might be combined. Another issue is not paying attention to the implicit concepts, especially due to the limitations of the collected hashtags. The authors were able to discover emotions more accurately by addressing this issue. The essential point is that they may get better results if they focus on both word-level and sentence-level characteristics at the same time.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Methodology",
      "text": "Emotion recognition is modeled as a text classification problem that can assign one or more emotional labels to a sentence. In CEFER, the general idea for recognition emotions from short English texts is to use the meaning of the entire sentence and context as well as to pay attention to each word in particular. Thus, a proper and accurate label can be assigned to the text by simultaneously considering the implicit and explicit emotions in the text.\n\nWe used transformer-based word embedding in this study with considering four aspects: extracting data from the entire sentence and each individual word simultaneously as well as implicit and explicit emotions. The extraction of contextual information is required for the discovery of implicit emotions as well as the meaning of the sentence. Hence, transformer is a suitable technique to handle this issue  [51] . Since transformers employ learning algorithms to increase classification accuracy, they also aid with more accurate classification of words and explicit emotions in the text  [55] . The CEFER framework which is designed to recognize emotions in short texts, is explained in the following sections.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Overview Of The Framework",
      "text": "The main purpose of this study is to create a framework for inferring emotions from text and classifying texts based on their emotional content. The framework CEFER can recognize the",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Emotional Reasoning Module",
      "text": "1024d for each Token + 8d emotional vector for each token correct label, even if there are no clear emotional words in the text. Figure  1  shows all part of the proposed framework CEFER: preprocessing tweets, extracting word features, inferring emotions using an emotional dictionary, building implicit or explicit emotion vectors of words, constructing meta-embedding, and recognizing the emotions of tweets. Detail of each parts is explained in the following.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Preprocessing Module",
      "text": "Presence of hyperlinks and emojis in tweets are increase their meaning and mention. Also, they are used for questions and referring specific people. However, they are not necessary for recognizing emotions and they should be removed from texts of dataset. In order to do this, preprocessing of tweets is done. To begin preprocessing, any tokens beyond the main part of the tweet are deleted and then the tweets are normalized.\n\nAnother problem is character repetition in a word as well as misspelling words. To address this problem, each tweet is tokenized and the correctness of each token is checked against a dictionary. If a token is recognized invalid character repetition elimination and hashtag checking are done. For character repetition elimination, the Ekphrasis tool  [54]  is used. Characters that appear more than once are gradually eliminated to have a correct token. Hashtag checking are explained in Section 3.4.2 due to the use of several interconnected tokens and their specific writing form.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Feature Extraction Module",
      "text": "As said before, the goal of this study is to use word and sentence features and contextual concepts at the same time in order to obtain appropriate features for emotion recognition. In order to reach this goal, Feature Extraction module has three phases: transformer, feature extraction in sentences, and feature extraction in words. Each phase is explained in the following subsections.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Transformer",
      "text": "To extract word and sentence features, we use transformer in the CEFER because BERT  [32]  is the most explored transformer-based model for recognizing text-based emotions and a number of variants of that are proposed  [27, 55] . Therefore, in experimental, we use BERT  [32]  and RoBERTa  [33]  transformers in both base and large modes in the CEFER. Both transformers have 12 hidden layers with 768 dimensions in base mode and 24 hidden layers with 1024 dimensions in large mode. The maximum input text length is considered to be 512.\n\nRoBERTa and BERT learn different semantic information in different layers. In general, the shallower layers are learned more semantic information at the word level. The deeper layers are learned more generalized semantic information  [34] . The BERT encoder produces a sequence of hidden states. For classification tasks, this sequence ultimately needs to be reduced to a single vector. To make this pooling scheme work, BERT prepends a [CLS] token (short for \"classification\") to the start of each sentence. It represents sentence-level features. The [CLS] token in the last layer is commonly assumed to contain semantic information to classify the entire sentence, ignoring a lot of information about the sentence. In CEFER, feature extraction is done in two methods: Sentence feature extraction using  [CLS]  and Word feature extraction.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Feature Extraction In Sentences",
      "text": "Both base and large models of BERT and RoBERTa transformers are used the entire sentence as input. The [CLS] output is used as a feature vector the sentence. This process is carried out in two steps.\n\n In the first step, data are sent into the transformer, and the [CLS] of the last layer is used as the feature vector of each tweet.  In the second step, the [CLS] from the upper layers of transformer are received. These values are then combined in different ways in order to produce the best feasible combination feature vector.\n\nThe main goal of this phase is to feed the full sentence into the transformer as input, then analyze the features that the transformer returns for the entire sentence. The effectiveness of this method is then compared to that of other feature extraction methods. The accuracy of these feature vectors is shown in Section 4.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Feature Extraction In Words",
      "text": "The feature vector extraction of all the words in the text is performed at this phase in order to pay more attention to the words. By extracting the features of each word according to the sentence, it is feasible to have both context knowledge and semantic information about the words in the extracted features at the same time. This task is done in two steps.\n\n In the first step, the feature vector of each word is obtained from last layer of the transformer. Then, the entire sentence vector is created by combining word vectors.  In the second step, the feature vectors of each word are obtained from the last four upper layers of the transformer which is similar to Section 3.3.2. After extracting all the feature vectors for each word, they are merged.\n\nThe task of recognizing emotions is then completed. Tables  3  and 4  in Section 4 demonstrate the results of emotion recognition accuracy using these feature vectors.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Emotional Reasoning Module",
      "text": "The usage of BERT variations demonstrates that language knowledge is acquired rapidly and consistently across most domains although facts are more domain-specific. Reasoning abilities are also not gained in a consistent manner. Many abilities are not learnt through RoBERTa's pre-training  [35] . To extract the implicit emotions from the text, reasoning is required  [36] .\n\nInference can be added to the embedding methods since they need to be reinforced in reasoning.\n\nAs a result, in the CEFER, identifying words with implicit emotions at different levels has helped in reaching this inference. To do so, we use EmoSyn Emotional Dictionary which is explained in the following subsections.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Emosyn Emotional Dictionary",
      "text": "The EmoSyn is created as an emotional dictionary with the aim of extracting implicit and explicit emotions from words. It is made from three emotional dictionaries: WordNet (hierarchical model), NRC Emotion Lexicon (based on Plutchik, which is a categorical model) and NRC Hashtag Emotion Lexicon  [15] . EmoSyn, actually combines hierarchical and categorical emotional models.\n\nBased on the Plutchik model, this dictionary has eight categories of words and emotional phrases (Anger, Fear, Joy, Sadness, Anticipation, Trust, Surprise, and Disgust). Each category contains words and phrases that can convey a feeling either implicitly or explicitly. EmoSyn is made up of emotional words that represent each of the eight categories of Plutchik. Synonyms for these words are taken from three mentioned dictionaries at three levels, and added to each category. The reason for exploring up to three levels is that even if words do not represent an emotion explicitly, they can convey it implicitly. That is, they may have emotional synonyms in the first, second, or third level, so words can implicitly express an emotion.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Creating Emotion Vector Using Emosyn",
      "text": "In the following, We show how an emotional vector is provided for each word. The structure of emotion vector for each token or word is shown in Figure  2 . The emotional vector of each token has eight elements because the Plutchik emotional model which contains eight basic emotions using in this study.\n\nIf x is an inferred word, the emotional vector of the word x is provided as follow. First, word x will be searched throughout all EmoSyn categories. If x belongs to two categories y and z, it means that x has two emotions y and z. Then only for the values associated to these two emotions, y and z, '1' is added in the emotional vector while the rest of the values of the emotional vector becomes '0'. If the token x is a hashtag, this is exactly the way which we use to provide its emotional vector. Since in EmoSyn for this form of emotional data, the NRC Hashtag Emotion Lexicon vocabulary is used. For example, if we have Example 1 and we use EmoSyn to generate an emotional vector for each token in Example1. The emotional vectors will look like what are shown in Figure  3 .\n\nExample1: I don't want to sit here any longer.  fear, disgust, sadness, and surprise-are gained for token \"want\". These vectors are then employed as emotional token vectors to assist in sentence recognition.\n\nThe emotions in Example 1 are anger and disgust according to  [36] . However, the sentence is mistakenly labeled as neutral using the proposed approach for recognizing implicit emotions in  [36] . While CEFER predicts the anger emotion for Example 1 which is correct.",
      "page_start": 10,
      "page_end": 11
    },
    {
      "section_name": "…",
      "text": "Sentence 1 1 0 1 1 0 0 1 1 1 1 1 0 0 0 0 …",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Meta-Embedding Module",
      "text": "Meta-embedding integrates different word embeddings and successfully improves system performance over equivalent models that use only one type of embedding  [37] . Multiple embedding can improve performance in three ways:\n\n1. Expands the model and the capacity of network.\n\n2. Increases vocabulary size. That is, instead of using the initial randomization, the model utilizes a better beginning point.\n\n3. The second embedding presents a different perspective on the word. The model is able to take use of diverse features based on differences in how each word is shown.\n\nSeveral approaches for creating meta-embedding have been presented in  [37, 38, and 39] . Despite the variety of methods that have been presented for meta-embedding, concatenation remains a very powerful method for meta-embedding  [37] . It keeps the entire structure of the primary embeddings. Also, many new features make the concatenation results desirable. However, the dimensions are increased linearly where it can sometimes be problematic.\n\nAs stated in Section 3.4.2, in providing an emotional vector, an 8-dimensional vector, W Emotional , is generated for each word that expresses the emotions encoded in that word. The emotional 8-digit vector WEmotional is concatenated to the feature vector acquired from RoBERTa, WRoBERTa , to create the feature vector of the proposed approach (Equation  1 ). This gives CEFER a particular emotional meta-embedding.\n\nMeta (W) = Embedding (W RoBERTa) + Embedding (W Emotional) Equation  (1)  This vector is used to improve the recognition of emotions in short texts.",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Experimental Results",
      "text": "The three standard datasets for evaluation of the framework, CEFER, are introduced in Section 4.1. Emotional tweets in the first and second datasets contain words that express the writer's feelings explicitly. The final dataset contains tweets that have been stripped of explicit emotional words. The tweets in this dataset, according to its creators, implicitly express the author's feelings.",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Datasets",
      "text": "Three different datasets are used to evaluate the proposed framework.\n\n1. The Emotion Intensity Dataset [40] categorizes its tweets into four emotional classes (joy, sadness, fear, and anger). Each tweet contains an emotional label and a numerical value that represents the intensity of the emotion (Table  1 ). 2. Hasan collected the EmoTex dataset  [16]  from Twitter. Tweets were automatically categorized based on the Circumplex emotional model depending on the emotions of their writers. Table  2  displays the dataset's attributes.\n\n3. The third dataset has been developed in preparation for the WASSA 2018 IEST [41] (Table  3 ). For the first time, the proposed task requires systems to predict emotions of tweets without explicit access to words expressing emotions. The Implicit Emotion Shared Task (IEST) is named after this purpose since the systems must infer the emotion mostly from the Every tweet contains an explicit emotive word that has been masked. The training data for this competition is only accessible to participants who have usernames and passwords. In this study, we only use its test data for both training and testing, which included 28757 labelled tweets.",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Results",
      "text": "The results of experiments which are done with the CEFER are presented in the following.",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "Results Of Feature Extraction In Sentences",
      "text": "As mentioned in Section 3.3.1, the data are first sent into the transformer, and the [CLS] output of the final layer is used as the feature vector of each tweet. In the second case, the [CLS] output from several layers are then combined with various methods to obtain the best possible feature to improve the recognition result at this stage. This procedure is carried out in both base and large modes with RoBERTa and BERT. Tables  4  and 5  show the of these experiments.\n\nThe results from Tables  4  and 5  reveal that the RoBERTa outperforms BERT in extracting sentence features. It has resulted in more accurate emotion recognition. In each tables, the best performances are shown in bold. The analysis demonstrates that when it comes to extracting the features of the entire sentence, the best option is to \"Concatenate the 24 layers\", and with a very small distance, the \"Sum of the last 4 layers\", which do not differ much in performance.",
      "page_start": 13,
      "page_end": 14
    },
    {
      "section_name": "Results Of Feature Extraction In Words",
      "text": "In Section 3.3.2, all words' feature vectors are extracted with the purpose of paying more attention to words. The feature vector for each word is initially extracted from the last layer of transformer. The sentence feature vector is then created by merging these vectors. In the second step, the vectors of each word are extracted from several transformer layers and combined in various ways. Each word's vector is created by using these combinations. After the vectors of all words are merged, then the emotion recognition task is completed. The accuracy of emotion recognition is demonstrated in Tables  6  and 7 .\n\nThe comparison of Tables 4 with 6 and 5 with 7 reveals that integrating all words' feature vectors improved recognition accuracy when compared to using [CLS] as the sentence's feature vector. The \"summing the last 4 layers\" method has the advantage of being flexible enough to reduce the dimensions without losing much more information as well as it is easy to use. It also takes less time to execute. The results of Tables  4 5 6 7 show that RoBERTa outperforms BERT. Therefore, in CEFER, we use the RoBERTa transformer and the summing of the last four layers method for features extraction in words and feature and sentence feature vectors are constructed by merging word vectors.",
      "page_start": 14,
      "page_end": 14
    },
    {
      "section_name": "Results Of Cefer Using Meta-Embedding Vectors",
      "text": "According to meta-embedding proposed in Section 3.5, the final feature vector for each tweet is created. Then tweets are classified and assigned an emotional label. The results are shown in Table  8 .\n\nTable  8  shows that the CEFER (the last column of the table) outperforms the RoBERTa and BERT. These findings support the need to reinforce the inference which mentioned in Section 3.4.",
      "page_start": 15,
      "page_end": 15
    },
    {
      "section_name": "Comparing With Other Works",
      "text": "In this section, the results of comparison of CEFER with other similar studies are presented. The comparison is done from two perspectives: recognition of implicit emotions and recognition of explicit emotions which are presented in Section 4.3.1 and 4.3.2 respectively.",
      "page_start": 16,
      "page_end": 16
    },
    {
      "section_name": "Implicit Emotion Recognition",
      "text": "WASSA2018IEST [41], as explained in Section 4.1, is designed by masking all explicit emotional words in the text to detect the emotion of the sentence with the help of other words that express emotion implicitly. CEFER is evaluated on this dataset and compared to some similar studies. Results are shown in Table  9 .\n\nThirty teams competed in the WASSA2018 competition, the majority of which used deep learning methods  [20] . One of the greatest results was related to IIIDYT  [42] , which employed the Elmo and the BiLSTM network for classification and had F1-score of 71.05. HUMIR  [44]  introduced a deep neural network model that used two BiLSTM networks to display the target word's left and right context in the same competition. The outputs were referred to as text-sensitive features. The authors also included vocabulary and emotion-based features into the BiLSTM model. With F1-score of 68.8, this model was ranked sixth among the 30 teams that competed. SINAI  [56] , which ranked 22nd out of 30 teams in the WASSA competition with a F1-score of 58.3  [20] , provided four deep learning algorithms based on a sequence encoding layer. Systems that used external emotional knowledge had a higher generalization capacity according to their findings.\n\nThe fourth line of Table  9  shows DuFER  [15] , which the prior framework established by the authors of this study. DuFER used emotional dictionaries as well as a feature selection and special feature weighting method. It has 68.93 F1-score. Based on the accuracy of other models in WASSA competition  [20] , DuFER is in sixth place. The F1-score of CEFER is 70.57, placing it third.",
      "page_start": 16,
      "page_end": 17
    },
    {
      "section_name": "Explicit Emotion Recognition",
      "text": "Two datasets, EmoTex and Emotion Intensity are considered when examining CEFER outcomes on datasets with explicit emotions.",
      "page_start": 17,
      "page_end": 17
    },
    {
      "section_name": "4.3.2.1-Evaluation Results Of Cefer On Emotex-Dataset",
      "text": "A point should be mentioned before the results are presented. The Plutchik emotional model is used to classify emotions in CEFER. Happiness vs. sadness, anger vs. fear, trust vs. disgust, and surprise vs. expectation are among the eight bipolar emotions in this model. The Circumplex emotional model is used by the Emotex-method which considers four main classes: happy-active, happy-inactive, unhappy-active, and unhappy-inactive. The equivalence of these emotional classes are reported in Table  10  which is used to compare the results of the proposed framework and the Emotex-method on the EmoTex dataset. In this dataset, three frameworks are tested, as shown in Table  11 .\n\n1. To determine emotional classes, the Emotex-method employs four features. According to the results of classification based on these features in  [16] , the use of three features other than unigram has little influence on improving the results by 0.3 percent. 2. DuFER  [15]  recognizes emotions in tweets using a machine learning algorithm. By applying modified TF-IDF weights to words and maximum probability for expressions, it employs language models and computational linguistics. Finally, a combination classification method is used to determine the emotion of each tweet. 3. In CEFER, RoBERTa Large is used to extract the feature vector of each word. The emotional vector of the words is then retrieved and added to their feature vector using EmoSyn  [15] . The acquired feature vectors are used to recognize the sentence emotion.\n\nResults are shown in the first to third rows of Table  11 .",
      "page_start": 17,
      "page_end": 18
    },
    {
      "section_name": "4.3.2.2-Evaluation Results On The Emotion Intensity Dataset (Eid)",
      "text": "A tweet, its emotional label, and a value associated with the intensity of emotion are all included in the EID dataset  [40] . There are four different emotions in this dataset. The purpose of this work is to discover the emotional label for each tweet without using emotional intensity values. As a result, CEFER only uses tweets and emotional labels that are related to them. The 4 th till 6 th rows of Table  11  illustrate the outcomes of the CEFER framework and two other methods. The findings obtained from this dataset are superior to the results obtained from other datasets due to the repetition of different emotional terms in a tweet and the existence of more emotional words in the dataset. In  [45] , a model based on LSTM and CNN are proposed which using the level of attention. The achievement of 94% accuracy for the model shows the effectiveness of the approach although the model has high complexity. In DuFER  [15] , the accuracy 95.27 for explicit emotions is achieved and the result for CEFER is 95.16.",
      "page_start": 17,
      "page_end": 18
    },
    {
      "section_name": "Discussion",
      "text": "According to the results are shown in Tables  9  and 11 , the proposed framework CEFER scored better on implicit recognition than explicit since in constructing the feature vector of each word, the transformer dynamically uses the words around it and also the meaning of the whole sentence. Therefore, the vector of each word implicitly contains the entire sentence's meaning. On the other hand, the use of the MASK feature in the transformer corresponds to the masking nature of some words (words that explicitly express emotion) in the IEST database. Each text in this dataset implicitly expresses an emotion. Hence, it can be said that in CEFER, the appropriateness of the method for extracting feature vectors is the most important reason for improving the recognition accuracy in the IEST dataset. In fact, it can be seen that CEFER is able to use and deduce the text well even without any explicit emotional words.\n\nHowever, despite the high accuracy achieved by CEFER, it performs worse in explicit emotions than DuFER, the authors' earlier study. We return to the structure of the two methods in order to figure out what is causing this issue. The use of the modified TF-IDF in DuFER, which is based on the BOW technique, causes all emotional words related to one emotion to fall into the same class. As a result, the weight of that emotion increases. CEFER employs a transformer that encodes each word according to its context. So, the entire sentence contributes to the creation of the word feature vector. As a result, the feature vector of a specific emotive term does not remain consistent across the dataset and changes from sentence to sentence. The chances that the term will fall into the appropriate emotional category is low. Third column of Table  8  before employing the emotional vector demonstrates this. The usage of EmoSyn in creating an emotional vector and then adding it to the feature vector of words improved the accuracy of emotion recognition in each tweet in the proposed framework. The authors believe that concentrating on the classification module will aid future studies in improving recognition accuracy. Tables  12  and 13  show the characteristics of the reviewed papers as well as the proposed framework. Table  12  examines the quality of articles in terms of key parameters and Table  13  studies information sources employed by different papers.",
      "page_start": 19,
      "page_end": 19
    },
    {
      "section_name": "Conclusions",
      "text": "In this Paper, we provide a four facets framework for recognizing emotions in short texts. We developed and evaluated a supervised deep learning framework called CEFER, based on four important aspects of text processing and emotion recognition. CEFER automatically classifies short texts with implicit and / or explicit emotions. Our experiments show that CEFER correctly classifies emotions in nearly 95% of text messages with explicit emotions. It also achieves 70.57% in classifying texts with implicit emotions, which is a very good result compared to the methods proposed in the IEST competition and it is in third place (Table  9 ). CEFER focuses on text processing at both word and sentence levels. It acquires textual properties using context properties by Roberta. Then, according to the emotional features of each word, it builds an emotional vector using an emotional embedding. Combining these features in meta embedding deals with the emotional recognition of tweets. We show that using words and sentence features simultaneously has a higher performance than using them individually and improves recognition results compared to transformers. We also show that paying attention to implicit emotions also improves the power of recognizing explicit emotions. Our future plan is concentrating on the classification module to improve recognition accuracy.",
      "page_start": 21,
      "page_end": 22
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Proposed Framework (CEFER)",
      "page": 7
    },
    {
      "caption": "Figure 1: shows all part of",
      "page": 8
    },
    {
      "caption": "Figure 2: The emotional vector of each",
      "page": 10
    },
    {
      "caption": "Figure 3: Example1: I don’t want to sit here any longer.",
      "page": 10
    },
    {
      "caption": "Figure 3: depicts two samples of emotional vectors of tokens of the Example 1. Four emotions-",
      "page": 10
    },
    {
      "caption": "Figure 2: Emotional Vector",
      "page": 10
    },
    {
      "caption": "Figure 3: An example of extracting the emotional vector of tokens",
      "page": 11
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Feature Extracting \n \nModule": "Create Features \n \nExtract features per\nToken/Sentence \n \nTransformer"
        }
      ],
      "page": 7
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Meta-Embedding \n \nModule": "Context Features\n1024d for each Token \n+ 8d emotional vector \n+ \n for each token \nWord/Emotional \n \nFeatures"
        }
      ],
      "page": 7
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Meta-Embedding \n \nModule": "Context Features\n1024d for each Token \n+ 8d emotional vector \n+ \n for each token \nWord/Emotional \n \nFeatures"
        }
      ],
      "page": 7
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Preprocessing Module": "Spell correction\n \nNormalize\n \nTokenize\nEmotional \n \ntweets"
        }
      ],
      "page": 7
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Emotional Reasoning \nModule": "Word Implicit| Explicit \n \nemotion detection\n \nEmoSyn Lexicon"
        }
      ],
      "page": 7
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Want": "Anger",
          "Any": "Anger",
          "…": "…"
        },
        {
          "Want": "1",
          "Any": "1",
          "…": "…"
        }
      ],
      "page": 11
    },
    {
      "caption": "Table 4: Accuracy of emotion recognition using different combinations of [CLS] output layers of RoBERTa",
      "data": [
        {
          "Table 4: Accuracy of emotion recognition using different combinations of [CLS] output layers of RoBERTa \ntransformer (selecting appropriate features based on the whole sentence)": "Dataset\n \nTransformer"
        },
        {
          "Table 4: Accuracy of emotion recognition using different combinations of [CLS] output layers of RoBERTa \ntransformer (selecting appropriate features based on the whole sentence)": "base\nRoBERTa"
        },
        {
          "Table 4: Accuracy of emotion recognition using different combinations of [CLS] output layers of RoBERTa \ntransformer (selecting appropriate features based on the whole sentence)": "large\nRoBERTa"
        },
        {
          "Table 4: Accuracy of emotion recognition using different combinations of [CLS] output layers of RoBERTa \ntransformer (selecting appropriate features based on the whole sentence)": "RoBERTa large \n24 layers"
        },
        {
          "Table 4: Accuracy of emotion recognition using different combinations of [CLS] output layers of RoBERTa \ntransformer (selecting appropriate features based on the whole sentence)": ""
        },
        {
          "Table 4: Accuracy of emotion recognition using different combinations of [CLS] output layers of RoBERTa \ntransformer (selecting appropriate features based on the whole sentence)": ""
        },
        {
          "Table 4: Accuracy of emotion recognition using different combinations of [CLS] output layers of RoBERTa \ntransformer (selecting appropriate features based on the whole sentence)": "RoBERTa large \n4 last layers"
        },
        {
          "Table 4: Accuracy of emotion recognition using different combinations of [CLS] output layers of RoBERTa \ntransformer (selecting appropriate features based on the whole sentence)": ""
        },
        {
          "Table 4: Accuracy of emotion recognition using different combinations of [CLS] output layers of RoBERTa \ntransformer (selecting appropriate features based on the whole sentence)": ""
        },
        {
          "Table 4: Accuracy of emotion recognition using different combinations of [CLS] output layers of RoBERTa \ntransformer (selecting appropriate features based on the whole sentence)": "RoBERTa large \n2 last layers"
        },
        {
          "Table 4: Accuracy of emotion recognition using different combinations of [CLS] output layers of RoBERTa \ntransformer (selecting appropriate features based on the whole sentence)": ""
        },
        {
          "Table 4: Accuracy of emotion recognition using different combinations of [CLS] output layers of RoBERTa \ntransformer (selecting appropriate features based on the whole sentence)": ""
        }
      ],
      "page": 13
    },
    {
      "caption": "Table 4: Accuracy of emotion recognition using different combinations of [CLS] output layers of RoBERTa",
      "data": [
        {
          "Table 5: Accuracy of emotion recognition using different combinations of [CLS] output layers of BERT \ntransformer (selecting appropriate features based on the whole sentence)": "Dataset\n \nTransforme\nr"
        },
        {
          "Table 5: Accuracy of emotion recognition using different combinations of [CLS] output layers of BERT \ntransformer (selecting appropriate features based on the whole sentence)": "Bert \nbase"
        },
        {
          "Table 5: Accuracy of emotion recognition using different combinations of [CLS] output layers of BERT \ntransformer (selecting appropriate features based on the whole sentence)": "Bert \nlarge"
        },
        {
          "Table 5: Accuracy of emotion recognition using different combinations of [CLS] output layers of BERT \ntransformer (selecting appropriate features based on the whole sentence)": "Bert large 24 \nlayers"
        },
        {
          "Table 5: Accuracy of emotion recognition using different combinations of [CLS] output layers of BERT \ntransformer (selecting appropriate features based on the whole sentence)": ""
        },
        {
          "Table 5: Accuracy of emotion recognition using different combinations of [CLS] output layers of BERT \ntransformer (selecting appropriate features based on the whole sentence)": ""
        },
        {
          "Table 5: Accuracy of emotion recognition using different combinations of [CLS] output layers of BERT \ntransformer (selecting appropriate features based on the whole sentence)": "Bert large 4 last \nlayers"
        },
        {
          "Table 5: Accuracy of emotion recognition using different combinations of [CLS] output layers of BERT \ntransformer (selecting appropriate features based on the whole sentence)": ""
        },
        {
          "Table 5: Accuracy of emotion recognition using different combinations of [CLS] output layers of BERT \ntransformer (selecting appropriate features based on the whole sentence)": ""
        },
        {
          "Table 5: Accuracy of emotion recognition using different combinations of [CLS] output layers of BERT \ntransformer (selecting appropriate features based on the whole sentence)": "Bert large 2 last \nlayers"
        },
        {
          "Table 5: Accuracy of emotion recognition using different combinations of [CLS] output layers of BERT \ntransformer (selecting appropriate features based on the whole sentence)": ""
        },
        {
          "Table 5: Accuracy of emotion recognition using different combinations of [CLS] output layers of BERT \ntransformer (selecting appropriate features based on the whole sentence)": ""
        }
      ],
      "page": 13
    },
    {
      "caption": "Table 6: Accuracy of emotion recognition using different combinations of RoBERTa transformer layers",
      "data": [
        {
          "Table 6: Accuracy of emotion recognition using different combinations of RoBERTa transformer layers \n(selecting the appropriate combination of word feature vectors)": "Dataset\n \n \nTransformer"
        },
        {
          "Table 6: Accuracy of emotion recognition using different combinations of RoBERTa transformer layers \n(selecting the appropriate combination of word feature vectors)": "RoBERTa base"
        },
        {
          "Table 6: Accuracy of emotion recognition using different combinations of RoBERTa transformer layers \n(selecting the appropriate combination of word feature vectors)": "RoBERTa large"
        },
        {
          "Table 6: Accuracy of emotion recognition using different combinations of RoBERTa transformer layers \n(selecting the appropriate combination of word feature vectors)": "RoBERTa large \n24 layers"
        },
        {
          "Table 6: Accuracy of emotion recognition using different combinations of RoBERTa transformer layers \n(selecting the appropriate combination of word feature vectors)": ""
        },
        {
          "Table 6: Accuracy of emotion recognition using different combinations of RoBERTa transformer layers \n(selecting the appropriate combination of word feature vectors)": ""
        },
        {
          "Table 6: Accuracy of emotion recognition using different combinations of RoBERTa transformer layers \n(selecting the appropriate combination of word feature vectors)": "RoBERTa large \n4 last layers"
        },
        {
          "Table 6: Accuracy of emotion recognition using different combinations of RoBERTa transformer layers \n(selecting the appropriate combination of word feature vectors)": ""
        },
        {
          "Table 6: Accuracy of emotion recognition using different combinations of RoBERTa transformer layers \n(selecting the appropriate combination of word feature vectors)": ""
        },
        {
          "Table 6: Accuracy of emotion recognition using different combinations of RoBERTa transformer layers \n(selecting the appropriate combination of word feature vectors)": "RoBERTa large \n2 last layers"
        },
        {
          "Table 6: Accuracy of emotion recognition using different combinations of RoBERTa transformer layers \n(selecting the appropriate combination of word feature vectors)": ""
        },
        {
          "Table 6: Accuracy of emotion recognition using different combinations of RoBERTa transformer layers \n(selecting the appropriate combination of word feature vectors)": ""
        }
      ],
      "page": 14
    },
    {
      "caption": "Table 7: Accuracy of emotion recognition using different combinations of BERT transformer layers (selecting",
      "data": [
        {
          "Table 7: Accuracy of emotion recognition using different combinations of BERT transformer layers (selecting \nthe appropriate combination of word feature vectors)": "Transformer"
        },
        {
          "Table 7: Accuracy of emotion recognition using different combinations of BERT transformer layers (selecting \nthe appropriate combination of word feature vectors)": "Bert base"
        },
        {
          "Table 7: Accuracy of emotion recognition using different combinations of BERT transformer layers (selecting \nthe appropriate combination of word feature vectors)": "Bert large"
        },
        {
          "Table 7: Accuracy of emotion recognition using different combinations of BERT transformer layers (selecting \nthe appropriate combination of word feature vectors)": "Bert large 24 \nlayers"
        },
        {
          "Table 7: Accuracy of emotion recognition using different combinations of BERT transformer layers (selecting \nthe appropriate combination of word feature vectors)": ""
        },
        {
          "Table 7: Accuracy of emotion recognition using different combinations of BERT transformer layers (selecting \nthe appropriate combination of word feature vectors)": ""
        },
        {
          "Table 7: Accuracy of emotion recognition using different combinations of BERT transformer layers (selecting \nthe appropriate combination of word feature vectors)": "Bert large 4 last \nlayers"
        },
        {
          "Table 7: Accuracy of emotion recognition using different combinations of BERT transformer layers (selecting \nthe appropriate combination of word feature vectors)": ""
        },
        {
          "Table 7: Accuracy of emotion recognition using different combinations of BERT transformer layers (selecting \nthe appropriate combination of word feature vectors)": ""
        },
        {
          "Table 7: Accuracy of emotion recognition using different combinations of BERT transformer layers (selecting \nthe appropriate combination of word feature vectors)": "Bert large 2 last \nlayers"
        },
        {
          "Table 7: Accuracy of emotion recognition using different combinations of BERT transformer layers (selecting \nthe appropriate combination of word feature vectors)": ""
        },
        {
          "Table 7: Accuracy of emotion recognition using different combinations of BERT transformer layers (selecting \nthe appropriate combination of word feature vectors)": ""
        }
      ],
      "page": 15
    },
    {
      "caption": "Table 7: Accuracy of emotion recognition using different combinations of BERT transformer layers (selecting",
      "data": [
        {
          "Table 8: Improving the accuracy of emotion recognition using the proposed Meta-embedding": "Dataset"
        },
        {
          "Table 8: Improving the accuracy of emotion recognition using the proposed Meta-embedding": "Emotion \nIntensity(EI)[40]"
        },
        {
          "Table 8: Improving the accuracy of emotion recognition using the proposed Meta-embedding": "Implicit Emotion \nShared Task \n(IEST)[41]"
        },
        {
          "Table 8: Improving the accuracy of emotion recognition using the proposed Meta-embedding": "EmoTex[16]"
        }
      ],
      "page": 15
    },
    {
      "caption": "Table 9: Thirty teams competed in the WASSA2018 competition, the majority of which used deep",
      "data": [
        {
          "Table 9: Comparison of CEFER results with other methods of recognizing implicit emotions": "Proposed Work"
        },
        {
          "Table 9: Comparison of CEFER results with other methods of recognizing implicit emotions": "IIIDYT [42]"
        },
        {
          "Table 9: Comparison of CEFER results with other methods of recognizing implicit emotions": "NTUA-SLP [43]"
        },
        {
          "Table 9: Comparison of CEFER results with other methods of recognizing implicit emotions": "CEFER"
        },
        {
          "Table 9: Comparison of CEFER results with other methods of recognizing implicit emotions": "DuFER [15]"
        },
        {
          "Table 9: Comparison of CEFER results with other methods of recognizing implicit emotions": "HUMIR [44]"
        },
        {
          "Table 9: Comparison of CEFER results with other methods of recognizing implicit emotions": "SINAI[56]"
        }
      ],
      "page": 16
    },
    {
      "caption": "Table 10: which is used to compare the results of the proposed",
      "data": [
        {
          "Table 10: Equalizing emotional classes in Circumplex model and Emotional Classes \n[15]": "EmoTex Emotional Classes"
        },
        {
          "Table 10: Equalizing emotional classes in Circumplex model and Emotional Classes \n[15]": "Unhappy Active"
        },
        {
          "Table 10: Equalizing emotional classes in Circumplex model and Emotional Classes \n[15]": "Unhappy Inactive"
        },
        {
          "Table 10: Equalizing emotional classes in Circumplex model and Emotional Classes \n[15]": "Happy Active"
        },
        {
          "Table 10: Equalizing emotional classes in Circumplex model and Emotional Classes \n[15]": "Happy Inactive"
        }
      ],
      "page": 17
    },
    {
      "caption": "Table 11: Comparison of CEFER with other explicit emotion recognition methods",
      "data": [
        {
          "Table 11: Comparison of CEFER with other explicit emotion recognition methods": "Best \nDataset \nContribution \nProposed Work \nprediction"
        },
        {
          "Table 11: Comparison of CEFER with other explicit emotion recognition methods": "Emotex-method [16]"
        },
        {
          "Table 11: Comparison of CEFER with other explicit emotion recognition methods": "CEFER"
        },
        {
          "Table 11: Comparison of CEFER with other explicit emotion recognition methods": "DuFER[15]"
        },
        {
          "Table 11: Comparison of CEFER with other explicit emotion recognition methods": "Method in [45]"
        },
        {
          "Table 11: Comparison of CEFER with other explicit emotion recognition methods": "CEFER"
        },
        {
          "Table 11: Comparison of CEFER with other explicit emotion recognition methods": "DuFER[15]"
        }
      ],
      "page": 18
    },
    {
      "caption": "Table 8: before employing the",
      "data": [
        {
          "Table12: Qualitative analysis of the relevant literature according to key parameters. I and E indicate implicit and explicit \nrespectively": "Paper"
        },
        {
          "Table12: Qualitative analysis of the relevant literature according to key parameters. I and E indicate implicit and explicit \nrespectively": "15 \nKhoshnam \n2022"
        },
        {
          "Table12: Qualitative analysis of the relevant literature according to key parameters. I and E indicate implicit and explicit \nrespectively": ""
        },
        {
          "Table12: Qualitative analysis of the relevant literature according to key parameters. I and E indicate implicit and explicit \nrespectively": "23 \nPark  \n2019"
        },
        {
          "Table12: Qualitative analysis of the relevant literature according to key parameters. I and E indicate implicit and explicit \nrespectively": "24 \nChatterjee \n2019"
        },
        {
          "Table12: Qualitative analysis of the relevant literature according to key parameters. I and E indicate implicit and explicit \nrespectively": "25 \nAl-Omari \n2020"
        },
        {
          "Table12: Qualitative analysis of the relevant literature according to key parameters. I and E indicate implicit and explicit \nrespectively": "26 \nIllendula \n2019"
        },
        {
          "Table12: Qualitative analysis of the relevant literature according to key parameters. I and E indicate implicit and explicit \nrespectively": "27 \nPolignano \n2019"
        },
        {
          "Table12: Qualitative analysis of the relevant literature according to key parameters. I and E indicate implicit and explicit \nrespectively": "28 \nZahiri \n2018"
        },
        {
          "Table12: Qualitative analysis of the relevant literature according to key parameters. I and E indicate implicit and explicit \nrespectively": "29 \nJabreel \n2019"
        }
      ],
      "page": 19
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "70.1 \n(F1)": "74.2 \n(ACC) \n49 \n(F1)"
        },
        {
          "70.1 \n(F1)": "66 \n(ACC) \n90 \n(ACC)"
        },
        {
          "70.1 \n(F1)": "71 \n(F1)"
        },
        {
          "70.1 \n(F1)": "70.3 \n(F1)"
        },
        {
          "70.1 \n(F1)": "68.6 \n(F1)"
        },
        {
          "70.1 \n(F1)": "91.9 \n(ACC)"
        },
        {
          "70.1 \n(F1)": "80.33 \n(ACC) \n \n75.25 \n(F1)"
        },
        {
          "70.1 \n(F1)": "58.3 \n(F1)"
        },
        {
          "70.1 \n(F1)": "95.16 \n(ACC)"
        },
        {
          "70.1 \n(F1)": "70.57 \n(F1)"
        }
      ],
      "page": 20
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Table13: Overview of information sources employed by different papers": "Paper"
        },
        {
          "Table13: Overview of information sources employed by different papers": "15 \nKhoshnam(2022)"
        },
        {
          "Table13: Overview of information sources employed by different papers": "23 \nPark(2019)"
        },
        {
          "Table13: Overview of information sources employed by different papers": "24 \nChatterjee(2019)"
        },
        {
          "Table13: Overview of information sources employed by different papers": "25 \nAl-Omari(2020)"
        },
        {
          "Table13: Overview of information sources employed by different papers": "26 \nIllendula(2019)"
        },
        {
          "Table13: Overview of information sources employed by different papers": "27 \nPolignano(2019)"
        },
        {
          "Table13: Overview of information sources employed by different papers": "28 \nZahiri(2018)"
        },
        {
          "Table13: Overview of information sources employed by different papers": "29 \nJabreel(2019)"
        },
        {
          "Table13: Overview of information sources employed by different papers": "30 \nCortiz(2021)"
        },
        {
          "Table13: Overview of information sources employed by different papers": "31 \nSchmidt(2021)"
        },
        {
          "Table13: Overview of information sources employed by different papers": "42 \nBalazs(2018)"
        },
        {
          "Table13: Overview of information sources employed by different papers": "43 \nChronopoulou(2018)"
        },
        {
          "Table13: Overview of information sources employed by different papers": "44 \nNaderalvojoud(2018)"
        },
        {
          "Table13: Overview of information sources employed by different papers": "52 \nKrommyda(2021)"
        },
        {
          "Table13: Overview of information sources employed by different papers": "53 \nChoudrie(2021)"
        },
        {
          "Table13: Overview of information sources employed by different papers": "56 \nPlaza-del-Arco(2018)"
        },
        {
          "Table13: Overview of information sources employed by different papers": "CEFER \n(2022)"
        }
      ],
      "page": 21
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Cognitive science: an introduction to the study of mind",
      "authors": [
        "J Friedenberg",
        "G Silverman",
        "M Spivey"
      ],
      "year": "2021",
      "venue": "Cognitive science: an introduction to the study of mind"
    },
    {
      "citation_id": "2",
      "title": "Handbook of emotions",
      "authors": [
        "M Lewis",
        "J Haviland-Jones",
        "L Barrett"
      ],
      "year": "2016",
      "venue": "Handbook of emotions"
    },
    {
      "citation_id": "3",
      "title": "A deep learning sentiment analyser for social media comments in low-resource languages",
      "authors": [
        "Z Kastrati",
        "L Ahmedi",
        "A Kurti",
        "F Kadriu",
        "D Murtezaj",
        "F Gashi"
      ],
      "year": "2021",
      "venue": "Electronics"
    },
    {
      "citation_id": "4",
      "title": "The emergence of social media data and sentiment analysis in election prediction",
      "authors": [
        "P Chauhan",
        "N Sharma",
        "G Sikka"
      ],
      "year": "2021",
      "venue": "Journal of Ambient Intelligence and Humanized Computing"
    },
    {
      "citation_id": "5",
      "title": "Analyzing the Brazilian financial market through Portuguese sentiment analysis in social media",
      "authors": [
        "A Carosia",
        "G Coelho",
        "A Silva"
      ],
      "year": "2020",
      "venue": "Applied Artificial Intelligence"
    },
    {
      "citation_id": "6",
      "title": "Weakly supervised framework for aspect-based sentiment analysis on students' reviews of MOOCs",
      "authors": [
        "Z Kastrati",
        "A Imran",
        "A Kurti"
      ],
      "year": "2020",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "7",
      "title": "Emotion recognition and its application in software engineering. 2013 6th International Conference on Human System Interactions (HSI)",
      "authors": [
        "A Kołakowska",
        "A Landowska",
        "M Szwoch",
        "W Szwoch",
        "M Wróbel"
      ],
      "year": "2013",
      "venue": "Emotion recognition and its application in software engineering. 2013 6th International Conference on Human System Interactions (HSI)"
    },
    {
      "citation_id": "8",
      "title": "Lexicon-based sentiment analysis of teachers' evaluation. Applied computational intelligence and soft computing",
      "authors": [
        "Q Rajput",
        "S Haider",
        "S Ghani"
      ],
      "year": "2016",
      "venue": "Lexicon-based sentiment analysis of teachers' evaluation. Applied computational intelligence and soft computing"
    },
    {
      "citation_id": "9",
      "title": "Sentiment Analysis of COVID-19 tweets by Deep Learning Classifiers-A study to show how popularity is affecting accuracy in social media",
      "authors": [
        "K Chakraborty",
        "S Bhatia",
        "S Bhattacharyya",
        "J Platos",
        "R Bag",
        "A Hassanien"
      ],
      "year": "2020",
      "venue": "Applied Soft Computing"
    },
    {
      "citation_id": "10",
      "title": "Cross-cultural polarity and emotion detection using sentiment analysis and deep learning on COVID-19 related tweets",
      "authors": [
        "A Imran",
        "S Daudpota",
        "Z Kastrati",
        "R Batra"
      ],
      "year": "2020",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "11",
      "title": "Aspect-based sentiment analysis of students' feedback to improve teaching-learning process. Information and communication technology for intelligent systems",
      "authors": [
        "G Chauhan",
        "P Agrawal",
        "Y Meena"
      ],
      "year": "2019",
      "venue": "Aspect-based sentiment analysis of students' feedback to improve teaching-learning process. Information and communication technology for intelligent systems"
    },
    {
      "citation_id": "12",
      "title": "BabelSenticNet: a commonsense reasoning framework for multilingual sentiment analysis",
      "authors": [
        "D Vilares",
        "H Peng",
        "R Satapathy",
        "E Cambria"
      ],
      "year": "2018",
      "venue": "IEEE symposium series on computational intelligence (SSCI"
    },
    {
      "citation_id": "13",
      "title": "Sentiment analysis and topic recognition in video transcriptions",
      "authors": [
        "L Stappen",
        "A Baird",
        "E Cambria",
        "B Schuller"
      ],
      "year": "2021",
      "venue": "IEEE Intelligent Systems"
    },
    {
      "citation_id": "14",
      "title": "Emotion representation analysis and synthesis in continuous space: A survey",
      "authors": [
        "H Gunes",
        "B Schuller",
        "M Pantic",
        "R Cowie"
      ],
      "year": "2011",
      "venue": "IEEE International Conference on Automatic Face & Gesture Recognition and Workshops",
      "doi": "10.1109/FG.2011.5771357"
    },
    {
      "citation_id": "15",
      "title": "A Dual Framework for Implicit and Explicit Emotion Recognition: An Ensemble of Language Models and Computational Linguistics. Be appeared in Expert System with Aplications",
      "authors": [
        "F Khoshnam",
        "A Baraani"
      ],
      "year": "2022",
      "venue": "A Dual Framework for Implicit and Explicit Emotion Recognition: An Ensemble of Language Models and Computational Linguistics. Be appeared in Expert System with Aplications",
      "doi": "10.1016/j.eswa.2022.116686"
    },
    {
      "citation_id": "16",
      "title": "Automatic emotion detection in text streams by analyzing twitter data",
      "authors": [
        "M Hasan",
        "E Rundensteiner",
        "E Agu"
      ],
      "year": "2019",
      "venue": "International Journal of Data Science and Analytics"
    },
    {
      "citation_id": "17",
      "title": "Basic emotions. Handbook of Cognition and Emotion",
      "authors": [
        "P Ekman"
      ],
      "year": "1999",
      "venue": "Basic emotions. Handbook of Cognition and Emotion"
    },
    {
      "citation_id": "18",
      "title": "A general psychoevolutionary theory of emotion",
      "authors": [
        "R Plutchik"
      ],
      "year": "1980",
      "venue": "Theories of Emotion"
    },
    {
      "citation_id": "19",
      "title": "SemEval-2017 task 4: Sentiment analysis in Twitter",
      "authors": [
        "S Rosenthal",
        "N Farra",
        "P Nakov"
      ],
      "year": "2019",
      "venue": "SemEval-2017 task 4: Sentiment analysis in Twitter"
    },
    {
      "citation_id": "20",
      "title": "WASSA-2018 Implicit Emotions Shared Task",
      "authors": [
        "A Balahur",
        "Mohammad Hoste",
        "V Klinger",
        "R Iest"
      ],
      "year": "2018",
      "venue": "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity",
      "doi": "10.18653/v1/W18-6201"
    },
    {
      "citation_id": "21",
      "title": "Enhancement of text based emotion recognition performances using word clusters",
      "authors": [
        "S Adarsh"
      ],
      "year": "2019",
      "venue": "International Journal of Research-Granthaalayah"
    },
    {
      "citation_id": "22",
      "title": "Improved emotion recognition in Spanish social media through incorporation of lexical knowledge",
      "authors": [
        "F Plaza-Del-Arco",
        "Martín Valdivia",
        "M Ureña-López",
        "L Mitkov"
      ],
      "year": "2020",
      "venue": "Future Generation Computer Systems"
    },
    {
      "citation_id": "23",
      "title": "Plusemo2vec at semeval-2018 task 1",
      "authors": [
        "J Park",
        "P Xu",
        "P Fung"
      ],
      "venue": "Exploiting emotion knowledge from emoji and# hashtags"
    },
    {
      "citation_id": "24",
      "title": "Understanding emotions in text using deep learning and big data",
      "authors": [
        "A Chatterjee",
        "U Gupta",
        "M Chinnakotla",
        "R Srikanth",
        "M Galley",
        "P Agrawal"
      ],
      "year": "2019",
      "venue": "Computers in Human Behavior"
    },
    {
      "citation_id": "25",
      "title": "Emodet2: Emotion detection in english textual dialogue using bert and bilstm models",
      "authors": [
        "H Al-Omari",
        "M Abdullah",
        "S Shaikh"
      ],
      "year": "2020",
      "venue": "11th International Conference on Information and Communication Systems (ICICS)"
    },
    {
      "citation_id": "26",
      "title": "Multimodal emotion classification",
      "authors": [
        "A Illendula",
        "A Sheth"
      ],
      "year": "2019",
      "venue": "Companion Proceedings of The 2019 World Wide Web Conference"
    },
    {
      "citation_id": "27",
      "title": "A comparison of wordembeddings in emotion detection from text using bilstm, cnn and self-attention",
      "authors": [
        "M Polignano",
        "P Basile",
        "M De Gemmis",
        "G Semeraro"
      ],
      "year": "2019",
      "venue": "Adjunct Publication of the 27th Conference on User Modeling, Adaptation and Personalization"
    },
    {
      "citation_id": "28",
      "title": "Emotion detection on tv show transcripts with sequencebased convolutional neural networks",
      "authors": [
        "S Zahiri",
        "J Choi"
      ],
      "year": "2018",
      "venue": "Workshops at the thirty-second aaai conference on artificial intelligence"
    },
    {
      "citation_id": "29",
      "title": "A deep learning-based approach for multi-label emotion classification in tweets",
      "authors": [
        "M Jabreel",
        "A Moreno"
      ],
      "year": "2019",
      "venue": "Applied Sciences"
    },
    {
      "citation_id": "30",
      "title": "Exploring transformers in emotion recognition: a comparison of bert, distillbert, roberta, xlnet and electra",
      "authors": [
        "D Cortiz"
      ],
      "venue": "Exploring transformers in emotion recognition: a comparison of bert, distillbert, roberta, xlnet and electra"
    },
    {
      "citation_id": "31",
      "title": "Emotion Classification in German Plays with Transformer-based Language Models Pretrained on Historical and Contemporary Language",
      "authors": [
        "T Schmidt",
        "K Dennerlein",
        "C Wolff"
      ],
      "year": "2021",
      "venue": "Proceedings of the 5th Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage"
    },
    {
      "citation_id": "32",
      "title": "Pre-training of deep bidirectional transformers for language understanding",
      "authors": [
        "J Devlin",
        "M-W Chang",
        "Lee Toutanova",
        "K Bert"
      ],
      "venue": "Pre-training of deep bidirectional transformers for language understanding"
    },
    {
      "citation_id": "33",
      "title": "A robustly optimized bert pretraining approach",
      "authors": [
        "Y Liu",
        "M Ott",
        "N Goyal",
        "J Du",
        "M Joshi",
        "D Chen"
      ],
      "year": "2019",
      "venue": "A robustly optimized bert pretraining approach"
    },
    {
      "citation_id": "34",
      "title": "HASOC2020: Fine-tune XML-RoBERTa for Hate Speech Identification. FIRE (Working Notes)",
      "authors": [
        "L Xu",
        "J Xeng",
        "S Chen"
      ],
      "year": "2020",
      "venue": "HASOC2020: Fine-tune XML-RoBERTa for Hate Speech Identification. FIRE (Working Notes)"
    },
    {
      "citation_id": "35",
      "title": "Probing Across Time: What Does RoBERTa Know and When? arXiv preprint",
      "authors": [
        "L Liu",
        "Y Wang",
        "J Kasai",
        "H Hajishirzi",
        "N Smith"
      ],
      "venue": "Probing Across Time: What Does RoBERTa Know and When? arXiv preprint"
    },
    {
      "citation_id": "36",
      "title": "Implicit emotion detection in text",
      "authors": [
        "U Orizu"
      ],
      "year": "2018",
      "venue": "Implicit emotion detection in text"
    },
    {
      "citation_id": "37",
      "title": "Learning efficient task-specific metaembeddings with word prisms",
      "authors": [
        "J He",
        "K Tsiolis",
        "K Kenyon-Dean",
        "Jck Cheung"
      ],
      "venue": "Learning efficient task-specific metaembeddings with word prisms"
    },
    {
      "citation_id": "38",
      "title": "Multiple Word Embeddings for Increased Diversity of Representation",
      "authors": [
        "B Lester",
        "D Pressel",
        "A Hemmeter",
        "S Choudhury",
        "S Bangalore"
      ],
      "venue": "Multiple Word Embeddings for Increased Diversity of Representation"
    },
    {
      "citation_id": "39",
      "title": "Task-oriented domain-specific metaembedding for text classification",
      "authors": [
        "X Wu",
        "Y Cai",
        "Y Kai",
        "T Wang",
        "Q Li"
      ],
      "year": "2020",
      "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "40",
      "title": "Emotion Intensities in Tweets for four emotions: joy, sadness, fear, and anger",
      "authors": [
        "Mohammad Bravo-Marquez"
      ],
      "year": "2017",
      "venue": "Proceedings of the 6th joint conference on lexical and computational semantics(*Sem)",
      "doi": "10.18653/v1/S17-1"
    },
    {
      "citation_id": "41",
      "title": "The data consists of the emotion class of the word which has been removed in the text",
      "authors": [
        "A Balahur",
        "Mohammad Hoste",
        "V Klinger"
      ],
      "venue": "The data consists of the emotion class of the word which has been removed in the text"
    },
    {
      "citation_id": "42",
      "title": "Iiidyt at iest 2018 :Implicit emotion classification with deep contextualized word representations",
      "authors": [
        "J Balazs",
        "E Marrese-Taylor",
        "Y Matsuo"
      ],
      "venue": "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
      "doi": "10.18653/v1/P17"
    },
    {
      "citation_id": "43",
      "title": "NTUA-SLP at IEST 2018: Ensemble of neural transfer methods for implicit emotion classification",
      "authors": [
        "A Chronopoulou",
        "A Margatina",
        "C Baziotis",
        "A Potamianos"
      ],
      "venue": "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
      "doi": "10.18653/v1/P17"
    },
    {
      "citation_id": "44",
      "title": "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
      "authors": [
        "B Naderalvojoud",
        "A Ucan",
        "Akcapinar Sezer"
      ],
      "venue": "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
      "doi": "10.18653/v1/P17"
    },
    {
      "citation_id": "45",
      "title": "A comparison of Word-Embeddings in Emotion Detection from Text using BiLSTM, CNN and Self-Attention, UMAP'19 Adjunct: Adjunct Publication of the 27th Conference on User Modeling, Adaptation and Personalization",
      "authors": [
        "M Polignano",
        "P Basile",
        "M Gemmis",
        "G Semeraro"
      ],
      "venue": "A comparison of Word-Embeddings in Emotion Detection from Text using BiLSTM, CNN and Self-Attention, UMAP'19 Adjunct: Adjunct Publication of the 27th Conference on User Modeling, Adaptation and Personalization",
      "doi": "10.1145/3314183.3324983"
    },
    {
      "citation_id": "46",
      "title": "Application of EEG-based Machine Learning in Emotion Recognition: A Review",
      "authors": [
        "J Cai",
        "R Xiao",
        "W Cui",
        "S Zhang",
        "G Liu"
      ],
      "year": "2021",
      "venue": "Frontiers in Systems Neuroscience"
    },
    {
      "citation_id": "47",
      "title": "Emotion Recognition for Healthcare Surveillance Systems Using Neural Networks: A Survey. 2021 International Wireless Communications and Mobile Computing (IWCMC)",
      "authors": [
        "M Dhuheir",
        "A Albaseer",
        "E Baccour",
        "A Erbad",
        "M Abdallah",
        "M Hamdi"
      ],
      "venue": "Emotion Recognition for Healthcare Surveillance Systems Using Neural Networks: A Survey. 2021 International Wireless Communications and Mobile Computing (IWCMC)"
    },
    {
      "citation_id": "48",
      "title": "Implicit vs. explicit emotion processing in autism spectrum disorders: An opinion on the role of the cerebellum",
      "authors": [
        "L Siciliano",
        "S Clausi"
      ],
      "year": "2020",
      "venue": "Frontiers in psychology",
      "doi": "10.3389/fpsyg.2020.00096"
    },
    {
      "citation_id": "49",
      "title": "The psychology of implicit emotion regulation",
      "authors": [
        "S Koole",
        "K Rothermund"
      ],
      "year": "2011",
      "venue": "The psychology of implicit emotion regulation"
    },
    {
      "citation_id": "50",
      "title": "A Novel Paradigm to Design Personalized Derived Images of Art Paintings Using an Intelligent Emotional Analysis Model",
      "authors": [
        "Y Duan",
        "J Zhang",
        "X Gu"
      ],
      "year": "2021",
      "venue": "Frontiers in psychology"
    },
    {
      "citation_id": "51",
      "title": "AI Based Emotion Detection for Textual Big Data: Techniques and Contribution. Big Data and Cognitive Computing",
      "authors": [
        "S Kusal",
        "S Patil",
        "K Kotecha",
        "R Aluvalu",
        "V Varadarajan"
      ],
      "year": "2021",
      "venue": "AI Based Emotion Detection for Textual Big Data: Techniques and Contribution. Big Data and Cognitive Computing"
    },
    {
      "citation_id": "52",
      "title": "An experimental analysis of data annotation methodologies for emotion detection in short text posted on social media",
      "authors": [
        "M Krommyda",
        "A Rigos",
        "K Bouklas",
        "A Amditis"
      ],
      "venue": "Informatics"
    },
    {
      "citation_id": "53",
      "title": "Applying and understanding an advanced, novel deep learning approach: A Covid 19, text based, emotions analysis study",
      "authors": [
        "J Choudrie",
        "S Patil",
        "K Kotecha",
        "N Matta",
        "I Pappas"
      ],
      "year": "2021",
      "venue": "Information Systems Frontiers"
    },
    {
      "citation_id": "54",
      "title": "",
      "authors": [
        "Tweet Preprocessor"
      ],
      "year": "2020",
      "venue": ""
    },
    {
      "citation_id": "55",
      "title": "Transformer models for text-based emotion detection: a review of BERT-based approaches",
      "authors": [
        "F Acheampong",
        "H Nunoo-Mensah"
      ],
      "year": "2021",
      "venue": "Artificial Intelligence Review"
    },
    {
      "citation_id": "56",
      "title": "SINAI at IEST 2018: Neural Encoding of Emotional External Knowledge for Emotion Classification. Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
      "authors": [
        "F Plaza-Del-Arco",
        "E Martínez-Cámara",
        "Martín Valdivia",
        "M Lopez"
      ],
      "year": "2018",
      "venue": "SINAI at IEST 2018: Neural Encoding of Emotional External Knowledge for Emotion Classification. Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis"
    }
  ]
}