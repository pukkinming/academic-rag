{
  "paper_id": "2408.01728v2",
  "title": "Survey On Emotion Recognition Through Posture Detection And The Possibility Of Its Application In Virtual Reality",
  "published": "2024-08-03T10:01:29Z",
  "authors": [
    "Leina Elansary",
    "Zaki Taha",
    "Walaa Gad"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "A survey is presented focused on using pose estimation techniques in Emotional recognition using various technologies normal cameras, and depth cameras for real-time, and the potential use of VR and inputs including images, videos, and 3-dimensional poses described in vector space. We discussed 19 research papers collected from selected journals and databases highlighting their methodology, classification algorithm, and the used datasets that relate to emotion recognition and pose estimation. A benchmark has been made according to their accuracy as it was the most common performance measurement metric used. We concluded that the multimodal Approaches overall made the best accuracy and then we mentioned futuristic concerns that can improve the development of this research topic.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Emotion recognition is one of the main vital tasks essential for having an intelligent system or application. Dealing with humans requires understanding their own emotions so that the human feels comfortable and the communication becomes more spontaneous which reflects on the efficiency of the service provided by the system/application. Emotions can be measured from multiple modalities like reading facial expressions, gesture detection, static posture, movement behavior, vocal tones, and text. When interacting with another human, you might know his current emotions from only seeing his face and sometimes the eyes can do the trick, or from his vocal tone, his posture -the way he is standing-or from the pattern of his movements, the gestures he is making or the context of his words whether those words are said or written -you can read an article and still visualize the emotions the writer has been through-or you can combine two or more modalities together which increases the efficiency of the human's predictions. Computer models are being trained to recognize the above models far above is the physical measurement which may include using sensors and actuators to measure physiological patterns that are hard for the computer to measure like measuring the heart rate, body temperature, and skin sensitivity  (Picard, R.W. and Vyzas, E. and Healey, J., n.d.) . Those extra modalities shall prepare the computer to be able to measure emotions accurately even more than humans, which is not currently reached. We will discuss the challenges being faced in this field and how some papers overcome those challenges. Some modalities can provide reliable measurements on their own or they may be used only to enhance the recognition of another modality and may not produce accurate results once used by themselves. In this paper, Our main focus will be on using the Pose estimation modality or posture recognition to measure the emotions of the human interacting with affective systems. The body posture or the pose can be detected from static images taken by a camera, image sequences (captured from videos) whether they are previously captured or provided in real-time, using a depth camera like Kinect which is usually used in providing real-time data, or finally using the Virtual reality technology which is usually real-time also. The images provide 2D coordinate system data unless a 2D to 3D conversion algorithm is implemented and that provides us with 3D coordinate system data or by using simply the depth camera or a VR device and sometimes it shall be equipped with external sensors to provide a full body detection including the lower body.\n\nResearch Question: What techniques and methodologies are used in literature to detect emotions through posture recognition?\n\nObjectives:\n\n• Observe how frequently each technology is Used.\n\n• List the measurement metric of each methodology.\n\n• explore the possibility of using Virtual Reality in the task of emotion recognition through posture detection.\n\nThose keywords were chosen while doing the systematic review to be used in the academic databases and journals: Emotion Recognition/Detection AND Posture/Pose. The Virtual Reality keyword shall be used later in the paper classification step. The review shall be held from year 2019 to 2023. After the systematic review, we noticed the absence of Virtual reality usage and one of the main objectives of this survey paper was to explore the possibility of using Virtual reality technology in Pose detection so we added the Virtual Reality journal to the above, when those queries were used \"Pose in Virtual Reality\", \"Pose estimation in Virtual Reality\", \"Pose detection in Virtual Reality\" no results were found till 5/2024 but by combining the Pose and Virtual reality keywords we reached 184 research article which was refined for relevance according to their title and abstract.",
      "page_start": 1,
      "page_end": 2
    }
  ],
  "figures": [],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Survey on Emotion Recognition through Posture Detection": "and the possibility of its application in Virtual Reality"
        },
        {
          "Survey on Emotion Recognition through Posture Detection": "leina.saad@cis.asu.edu.eg"
        },
        {
          "Survey on Emotion Recognition through Posture Detection": "Leina Elansary"
        },
        {
          "Survey on Emotion Recognition through Posture Detection": "Master's student,Faculty of Computer and Information"
        },
        {
          "Survey on Emotion Recognition through Posture Detection": "Sciences, Ain Shams University, Egypt."
        },
        {
          "Survey on Emotion Recognition through Posture Detection": "zaki.taha@cis.asu.edu.eg"
        },
        {
          "Survey on Emotion Recognition through Posture Detection": "Zaki Taha"
        },
        {
          "Survey on Emotion Recognition through Posture Detection": "Professor of Computer Science, Faculty of Computer and"
        },
        {
          "Survey on Emotion Recognition through Posture Detection": "Information Sciences, Ain Shams University, Egypt."
        },
        {
          "Survey on Emotion Recognition through Posture Detection": "walaagad@cis.asu.edu.eg"
        },
        {
          "Survey on Emotion Recognition through Posture Detection": "Walaa Gad"
        },
        {
          "Survey on Emotion Recognition through Posture Detection": "Professor of InformationSystems, Faculty of Computer"
        },
        {
          "Survey on Emotion Recognition through Posture Detection": "and Information Sciences, Ain Shams University, Egypt"
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Professor of InformationSystems, Faculty of Computer": "and Information Sciences, Ain Shams University, Egypt"
        },
        {
          "Professor of InformationSystems, Faculty of Computer": "Abstract"
        },
        {
          "Professor of InformationSystems, Faculty of Computer": "A survey is presented focused on using pose estimation techniques in Emotional recognition using"
        },
        {
          "Professor of InformationSystems, Faculty of Computer": "various technologies normal cameras, and depth cameras for real-time, and the potential use of VR"
        },
        {
          "Professor of InformationSystems, Faculty of Computer": "and inputs\nincluding images, videos,\nand 3-dimensional poses described in vector\nspace. We"
        },
        {
          "Professor of InformationSystems, Faculty of Computer": "discussed 19 research papers\ncollected from selected journals and databases highlighting their"
        },
        {
          "Professor of InformationSystems, Faculty of Computer": "methodology, classification algorithm, and the used datasets that relate to emotion recognition and"
        },
        {
          "Professor of InformationSystems, Faculty of Computer": "pose\nestimation. A benchmark has been made\naccording to their accuracy as\nit was\nthe most"
        },
        {
          "Professor of InformationSystems, Faculty of Computer": "common performance measurement metric used. We concluded that\nthe multimodal Approaches"
        },
        {
          "Professor of InformationSystems, Faculty of Computer": "overall made the best accuracy and then we mentioned futuristic concerns that can improve the"
        },
        {
          "Professor of InformationSystems, Faculty of Computer": "development of this research topic."
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "common performance measurement metric used. We concluded that\nthe multimodal Approaches": "overall made the best accuracy and then we mentioned futuristic concerns that can improve the"
        },
        {
          "common performance measurement metric used. We concluded that\nthe multimodal Approaches": "development of this research topic."
        },
        {
          "common performance measurement metric used. We concluded that\nthe multimodal Approaches": "Introduction"
        },
        {
          "common performance measurement metric used. We concluded that\nthe multimodal Approaches": "Emotion recognition is one of\nthe main vital\ntasks essential for having an intelligent system or"
        },
        {
          "common performance measurement metric used. We concluded that\nthe multimodal Approaches": "application. Dealing with humans requires understanding their own emotions so that\nthe human"
        },
        {
          "common performance measurement metric used. We concluded that\nthe multimodal Approaches": "feels\ncomfortable\nand\nthe\ncommunication\nbecomes more\nspontaneous which reflects on the"
        },
        {
          "common performance measurement metric used. We concluded that\nthe multimodal Approaches": "efficiency of\nthe\nservice provided by the system/application. Emotions can be measured from"
        },
        {
          "common performance measurement metric used. We concluded that\nthe multimodal Approaches": "multiple modalities like reading facial expressions, gesture detection, static posture, movement"
        },
        {
          "common performance measurement metric used. We concluded that\nthe multimodal Approaches": "behavior,\nvocal\ntones,\nand\ntext. When interacting with another human, you might know his"
        },
        {
          "common performance measurement metric used. We concluded that\nthe multimodal Approaches": "current emotions from only seeing his face and sometimes the eyes can do the trick, or from his"
        },
        {
          "common performance measurement metric used. We concluded that\nthe multimodal Approaches": "vocal\ntone, his posture\n-\nthe way he\nis\nstanding- or\nfrom the pattern of his movements,\nthe"
        },
        {
          "common performance measurement metric used. We concluded that\nthe multimodal Approaches": "gestures he is making or the context of his words whether those words are said or written - you"
        },
        {
          "common performance measurement metric used. We concluded that\nthe multimodal Approaches": "can\nread an article\nand still visualize\nthe\nemotions\nthe writer has been through- or you can"
        },
        {
          "common performance measurement metric used. We concluded that\nthe multimodal Approaches": "combine\ntwo\nor more modalities\ntogether which\nincreases\nthe\nefficiency\nof\nthe\nhuman’s"
        },
        {
          "common performance measurement metric used. We concluded that\nthe multimodal Approaches": "predictions. Computer models are being trained to recognize the above models far above is the"
        },
        {
          "common performance measurement metric used. We concluded that\nthe multimodal Approaches": "physical measurement which may include using sensors and actuators to measure physiological"
        },
        {
          "common performance measurement metric used. We concluded that\nthe multimodal Approaches": "patterns\nthat\nare\nhard\nfor\nthe\ncomputer\nto measure\nlike measuring\nthe\nheart\nrate,\nbody"
        },
        {
          "common performance measurement metric used. We concluded that\nthe multimodal Approaches": "temperature, and skin sensitivity(Picard, R.W. and Vyzas, E. and Healey, J., n.d.). Those extra"
        },
        {
          "common performance measurement metric used. We concluded that\nthe multimodal Approaches": "modalities shall prepare the computer to be able to measure emotions accurately even more than"
        },
        {
          "common performance measurement metric used. We concluded that\nthe multimodal Approaches": "humans, which is not currently reached. We will discuss the challenges being faced in this field"
        },
        {
          "common performance measurement metric used. We concluded that\nthe multimodal Approaches": "and\nhow some\npapers\novercome\nthose\nchallenges.\nSome modalities\ncan\nprovide\nreliable"
        },
        {
          "common performance measurement metric used. We concluded that\nthe multimodal Approaches": "measurements on their own or\nthey may be used only to enhance the recognition of another"
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585\nSubmitted _/2024; published _/2024": "modality and may not produce accurate results once used by themselves. In this paper, Our main"
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585\nSubmitted _/2024; published _/2024": "focus will\nbe\non\nusing\nthe Pose\nestimation modality or posture\nrecognition to measure\nthe"
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585\nSubmitted _/2024; published _/2024": "emotions of\nthe human interacting with affective systems. The body posture or the pose can be"
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585\nSubmitted _/2024; published _/2024": "detected from static images taken by a camera, image sequences\n(captured from videos) whether"
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585\nSubmitted _/2024; published _/2024": "they are previously captured or provided in real-time, using a depth camera like Kinect which is"
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585\nSubmitted _/2024; published _/2024": "usually used in providing real-time data, or finally using the Virtual reality technology which is"
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585\nSubmitted _/2024; published _/2024": "usually\nreal-time\nalso. The\nimages\nprovide\n2D coordinate\nsystem data\nunless\na\n2D to\n3D"
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585\nSubmitted _/2024; published _/2024": "conversion algorithm is implemented and that provides us with 3D coordinate system data or by"
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585\nSubmitted _/2024; published _/2024": "using simply the depth camera or a VR device and sometimes it shall be equipped with external"
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585\nSubmitted _/2024; published _/2024": "sensors to provide a full body detection including the lower body."
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585\nSubmitted _/2024; published _/2024": "Research Question: What techniques and methodologies are used in literature to detect emotions"
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585\nSubmitted _/2024; published _/2024": "through posture recognition?"
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585\nSubmitted _/2024; published _/2024": "Objectives:"
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "BRED Dataset. (n.d.). [Dataset]. https://zenodo.org/records/3233060",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Celeghin A, Diano M, Bagnis A, Viola M and Tamietto M. (2017). Basic Emotions in Human",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Neuroscience: Neuroimaging and Beyond. Rontiers in Psychology.",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2017.01432/full",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Crenn, A., Meyer, A., Konik, H., Khan, R. A., & Bouakaz, S. (2020). Generic Body Expression",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Recognition Based on Synthesis of Realistic Neutral Motion. IEEE Access, 8, 207758–207767.",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "IEEE Access. https://doi.org/10.1109/ACCESS.2020.3038473",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "CUI, M., FANG, J., & ZHAO, Y. (2020). Emotion recognition of human body’s posture in open",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "environment. 2020 Chinese Control And Decision Conference (CCDC), 3294–3299.",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "https://doi.org/10.1109/CCDC49329.2020.9164551",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Dr Wanqing Li (UOW)—MSR Action3D. (n.d.). Retrieved May 26, 2024, from",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "https://sites.google.com/view/wanqingli/data-sets/msr-action3d",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Ekaterina Volkova ,Stephan de la Rosa,Heinrich H. Bülthoff ,Betty Mohler. (2014). The MPI",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "body expressions database [Dataset].",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "https://figshare.com/articles/dataset/MPI_EMBM_Database_Mocap_Files/1220428",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Ekman Paul. (1992). An argument for basic emotions. Cognitive and Emotion.",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "https://www.tandfonline.com/doi/abs/10.1080/02699939208411068",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "EWalk dataset. (n.d.). [Dataset].",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "https://drive.google.com/drive/folders/1wWL0Yc7Oa7AMm2QqQ4lbtTIRYvMW0L2h",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Expressive Hands and Faces (EHF)—V7 Open Datasets. (n.d.). Retrieved May 26, 2024, from",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "https://www.v7labs.com/open-datasets/expressive-hands-and-faces-ehf",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Face Tracking for Movement SDK for Unity: Unity | Oculus Developers. (n.d.). Retrieved May",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "26, 2024, from https://developer.oculus.com/documentation/unity/move-face-tracking/",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Filntisis, P. P., Efthymiou, N., Koutras, P., Potamianos, G., & Maragos, P. (2019). Fusing Body",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "",
          "Submitted _/2024; published _/2024": "Posture With Facial Expressions for Joint Recognition of Affect in Child–Robot Interaction. IEEE"
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Robotics and Automation Letters, 4(4), 4011–4018. IEEE Robotics and Automation Letters.",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "https://doi.org/10.1109/LRA.2019.2930434",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Gemep. (n.d.). [Dataset]. https://www.unige.ch/cisa/gemep/",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "GroupWalk dataset. (n.d.). [Dataset].",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "https://drive.google.com/drive/folders/1tVoqBaQWa8bsoXr2brxNObaZ3g-FQ5QM",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Gunes, H., & M. Piccardi. (2006). FABO [Dataset]. https://www.cl.cam.ac.uk/~hg410/fabo.html",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "IEMOCAP. (n.d.). [Dataset]. https://sail.usc.edu/iemocap/",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Kalampokas, T., Krinidis, S., Chatzis, V., & Papakostas, G. A. (2023). Performance benchmark of",
          "Submitted _/2024; published _/2024": ""
        }
      ],
      "page": 3
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "deep learning human pose estimation for UAVs. Machine Vision and Applications, 34(6), 97.",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "https://doi.org/10.1007/s00138-023-01448-5",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Keshari, T., & Palaniswamy, S. (2019). Emotion Recognition Using Feature-level Fusion of",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Facial Expressions and Body Gestures. 2019 International Conference on Communication and",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Electronics Systems (ICCES), 1184–1189. https://doi.org/10.1109/ICCES45898.2019.9002175",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Kosti, Ronak and Alvarez, Jose M and Recasens, Adria and Lapedriza, Agata. (2019). EMOTIC",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "[Dataset]. https://opendatalab.com/OpenDataLab/EMOTIC",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Kumar, L., & Singh, D. K. (2023). Pose image generation for video content creation using",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "controlled human pose image generation GAN. Multimedia Tools and Applications.",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "https://doi.org/10.1007/s11042-023-17856-8",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Li, H., Yao, H., & Hou, Y. (2024). Hierarchical pose net: Spatial hierarchical body tree driven",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "multi-person pose estimation. Multimedia Tools and Applications, 83(2), 6373–6392.",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "https://doi.org/10.1007/s11042-023-15320-1",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Liakopoulos, L., Stagakis, N., Zacharaki, E. I., & Moustakas, K. (2021). CNN-based stress and",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "emotion recognition in ambulatory settings. 2021 12th International Conference on Information,",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Intelligence, Systems & Applications (IISA), 1–8.",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "https://doi.org/10.1109/IISA52424.2021.9555508",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Malek–Podjaski, M., & Deligianni, F. (2021). Towards Explainable, Privacy-Preserved",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Human-Motion Affect Recognition. 2021 IEEE Symposium Series on Computational Intelligence",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "(SSCI), 01–09. https://doi.org/10.1109/SSCI50451.2021.9660129",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Mittal, T., Bera, A., & Manocha, D. (2021). Multimodal and Context-Aware Emotion Perception",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Model With Multiplicative Fusion. IEEE MultiMedia, 28(2), 67–75. IEEE MultiMedia.",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "https://doi.org/10.1109/MMUL.2021.3068387",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "MoCap. (n.d.). [Dataset]. https://paperswithcode.com/dataset/mocap",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Nesrine Fourati, Catherine Pelachaud. (2014). Emilya: Emotional body expression in daily",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "actions database [Dataset]. European Language Resources Association (ELRA).",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "http://www.lrec-conf.org/proceedings/lrec2014/pdf/334_Paper.pdf",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Papers with Code—AVA Dataset. (n.d.). Retrieved May 26, 2024, from",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "https://paperswithcode.com/dataset/ava",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Papers with Code—MSRC-12 Dataset. (n.d.). Retrieved May 26, 2024, from",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "https://paperswithcode.com/dataset/msrc-12",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Pavlakos, G., Choutas, V., Ghorbani, N., Bolkart, T., Osman, A. A., Tzionas, D., & Black, M. J.",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "(2019). Expressive Body Capture: 3D Hands, Face, and Body From a Single Image. 2019",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 10967–10977.",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "https://doi.org/10.1109/CVPR.2019.01123",
          "Submitted _/2024; published _/2024": ""
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Picard, R. (n.d.). Affective Computing. MIT Press.",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "https://mitpress.mit.edu/9780262661157/affective-computing/",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Picard, R.W. and Vyzas, E. and Healey, J. (n.d.). Toward machine emotional intelligence:",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Analysis of affective physiological state. IEEE.",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "https://ieeexplore.ieee.org/abstract/document/954607",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Plutchik. (2017). Psychoevolutionary Theory of Emotion.",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "https://link.springer.com/referenceworkentry/10.1007/978-3-319-28099-8_547-1",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Prakash, V. G., Kohli, M., Kohli, S., Prathosh, A. P., Wadhera, T., Das, D., Panigrahi, D., &",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Kommu, J. V. S. (2023). Computer Vision-Based Assessment of Autistic Children: Analyzing",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Interactions, Emotions, Human Pose, and Life Skills. IEEE Access, 11, 47907–47929. IEEE",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Access. https://doi.org/10.1109/ACCESS.2023.3269027",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Randhavane, T., Bhattacharya, U., Kapsaskis, K., Gray, K., Bera, A., & Manocha, D. (2019).",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Learning Perceived Emotion Using Affective and Deep Features for Mental Health Applications.",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct),",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "395–399. https://doi.org/10.1109/ISMAR-Adjunct.2019.000-2",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Razzaq, M. A., Bang, J., Kang, S. S., & Lee, S. (2020). UnSkEm: Unobtrusive Skeletal-based",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Emotion Recognition for User Experience. 2020 International Conference on Information",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Networking (ICOIN), 92–96. https://doi.org/10.1109/ICOIN48656.2020.9016601",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Russell, J. (1980). A Complex Model of Affect.",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "https://www.researchgate.net/publication/235361517_A_Circumplex_Model_of_Affect",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Santhoshkumar, R., & Geetha, M. K. (2019). Deep Learning Approach for Emotion Recognition",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "from Human Body Movements with Feedforward Deep Convolution Neural Networks. Procedia",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Computer Science, 152, 158–165. https://doi.org/10.1016/j.procs.2019.05.038",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Spencer, M. (2022). EMOTIONS VS. FEELINGS VS. MOODS.",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "https://dakotafamilyservices.org/resources/blog/archive/moods-feelings-emotions/#:~:text=While",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "%20emotions%20start%20as%20sensations,both%20physical%20and%20emotional%20states.",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "SWELL-KW. (n.d.). [Dataset]. http://cs.ru.nl/~skoldijk/SWELL-KW/Dataset.html",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "The Difference Between Feelings and Emotions. (n.d.). Wake Forest University. Retrieved",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "January 2, 2023, from https://counseling.online.wfu.edu/blog/difference-feelings-emotions/",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "The difference between Joy and happiness. (n.d.). Retrieved May 16, 2024, from",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "https://www.embarkbh.com/blog/mental-health/joy-vs-happiness/#:~:text=Happiness%20is%20ty",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "pically%20a%20more,and%20satisfaction%20with%20life%20overall.",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "The motion capture library. (n.d.). [Dataset]. https://themotioncapturelibrary.co.uk/",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "The Ten Postulates of Plutchik’s (1980) psychoevolutionary theory of basic emotions. (n.d.).",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "https://is.muni.cz/el/1421/jaro2011/PSA_033/um/plutchik.pdf",
          "Submitted _/2024; published _/2024": ""
        }
      ],
      "page": 5
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "UCLIC Affective Body Posture and Motion Database. (n.d.). [Dataset].",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "http://web4.cs.ucl.ac.uk/uclic/people/n.berthouze/AffectivePostures/",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "UTKinect-Action3D Dataset. (n.d.). Retrieved May 26, 2024, from",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "https://cvrc.ece.utexas.edu/KinectDatasets/HOJ3D.html",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "WESAD. (n.d.). [Dataset].",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "http://archive.ics.uci.edu/dataset/465/wesad+wearable+stress+and+affect+detection",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Wu, J., Zhang, Y., & Ning, L. (2019). The Fusion Knowledge of Face, Body and Context for",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Emotion Recognition. 2019 IEEE International Conference on Multimedia & Expo Workshops",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "(ICMEW), 108–113. https://doi.org/10.1109/ICMEW.2019.0-102",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Xing, Y., Hu, Z., Huang, Z., Lv, C., Cao, D., & Velenis, E. (2020). Multi-Scale Driver Behaviors",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Reasoning System for Intelligent Vehicles Based on a Joint Deep Learning Framework. 2020",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "IEEE International Conference on Systems, Man, and Cybernetics (SMC), 4410–4415.",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "https://doi.org/10.1109/SMC42975.2020.9283004",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "YINGLIANG MA, HELENA M. PATERSON, and FRANK E. POLLICK. (2006). A motion",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "capture library for the study of identity, gender, and emotion perception from biological motion",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "[Dataset]. https://link.springer.com/article/10.3758/BF03192758",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Zacharatos, H., Gatzoulis, C., Charalambous, P., & Chrysanthou, Y. (2021). Emotion Recognition",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "from 3D Motion Capture Data using Deep CNNs. 2021 IEEE Conference on Games (CoG), 1–5.",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "https://doi.org/10.1109/CoG52621.2021.9619065",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Zaghbani, S., & Bouhlel, M. S. (2022). Multi-task CNN for multi-cue affects recognition using",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "upper-body gestures and facial expressions. International Journal of Information Technology,",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "14(1), 531–538. https://doi.org/10.1007/s41870-021-00820-w",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Zhang, X., Qi, G., Fu, X., & Zhang, N. (2023). Robust Emotion Recognition Across Diverse",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "Scenes: A Deep Neural Network Approach Integrating Contextual Cues. IEEE Access, 11,",
          "Submitted _/2024; published _/2024": ""
        },
        {
          "Journal of Artificial Intelligence Research 23 (2005) 533-585": "73959–73970. IEEE Access. https://doi.org/10.1109/ACCESS.2023.3296316",
          "Submitted _/2024; published _/2024": ""
        }
      ],
      "page": 6
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Human motions and emotions recognition inspired by LMA qualities",
      "authors": [
        "I Ajili",
        "M Mallem",
        "J.-Y Didier"
      ],
      "year": "2019",
      "venue": "The Visual Computer",
      "doi": "10.1007/s00371-018-01619-w"
    },
    {
      "citation_id": "2",
      "title": "Emotion Recognition for Affective Human Digital Twin by Means of Virtual Reality Enabling Technologies",
      "authors": [
        "K Amara",
        "O Kerdjidj",
        "N Ramzan"
      ],
      "year": "2023",
      "venue": "IEEE Access",
      "doi": "10.1109/ACCESS.2023.3285398"
    },
    {
      "citation_id": "3",
      "title": "Annotations in the EMOTIC dataset",
      "venue": "Annotations in the EMOTIC dataset"
    },
    {
      "citation_id": "4",
      "title": "On Mobile Pose Estimation and Action Recognition Design and Implementation",
      "authors": [
        "M Aslanyan"
      ],
      "year": "2024",
      "venue": "Pattern Recognition and Image Analysis",
      "doi": "10.1134/S1054661824010036"
    },
    {
      "citation_id": "6",
      "title": "Basic Emotions in Human Neuroscience: Neuroimaging and Beyond. Rontiers in Psychology",
      "authors": [
        "A Celeghin",
        "M Diano",
        "A Bagnis",
        "Viola Tamietto"
      ],
      "year": "2017",
      "venue": "Basic Emotions in Human Neuroscience: Neuroimaging and Beyond. Rontiers in Psychology",
      "doi": "10.3389/fpsyg.2017.01432/full"
    },
    {
      "citation_id": "7",
      "title": "Generic Body Expression Recognition Based on Synthesis of Realistic Neutral Motion",
      "authors": [
        "A Crenn",
        "A Meyer",
        "H Konik",
        "R Khan",
        "S Bouakaz"
      ],
      "year": "2020",
      "venue": "IEEE Access",
      "doi": "10.1109/ACCESS.2020.3038473"
    },
    {
      "citation_id": "8",
      "title": "Emotion recognition of human body's posture in open environment",
      "authors": [
        "M Cui",
        "J Fang",
        "Y Zhao"
      ],
      "year": "2020",
      "venue": "Chinese Control And Decision Conference (CCDC)",
      "doi": "10.1109/CCDC49329.2020.9164551"
    },
    {
      "citation_id": "9",
      "title": "MSR Action3D",
      "authors": [
        "Dr Wanqing"
      ],
      "year": "2024",
      "venue": "MSR Action3D"
    },
    {
      "citation_id": "10",
      "title": "The MPI body expressions database",
      "authors": [
        "Ekaterina Volkova",
        "Stephan De La Rosa",
        "Heinrich Bülthoff",
        "Betty Mohler"
      ],
      "year": "2014",
      "venue": "The MPI body expressions database"
    },
    {
      "citation_id": "11",
      "title": "An argument for basic emotions",
      "authors": [
        "Ekman Paul"
      ],
      "year": "1992",
      "venue": "Cognitive and Emotion",
      "doi": "10.1080/02699939208411068"
    },
    {
      "citation_id": "12",
      "title": "EWalk dataset",
      "venue": "EWalk dataset"
    },
    {
      "citation_id": "13",
      "title": "Face Tracking for Movement SDK for Unity: Unity | Oculus Developers",
      "year": "2024",
      "venue": "Face Tracking for Movement SDK for Unity: Unity | Oculus Developers"
    },
    {
      "citation_id": "14",
      "title": "Fusing Body Posture With Facial Expressions for Joint Recognition of Affect in Child-Robot Interaction",
      "authors": [
        "P Filntisis",
        "N Efthymiou",
        "P Koutras",
        "G Potamianos",
        "P Maragos"
      ],
      "year": "2019",
      "venue": "IEEE Robotics and Automation Letters",
      "doi": "10.1109/LRA.2019.2930434"
    },
    {
      "citation_id": "15",
      "title": "",
      "authors": [
        "Gemep"
      ],
      "venue": ""
    },
    {
      "citation_id": "16",
      "title": "FABO",
      "authors": [
        "H Gunes",
        "M Piccardi"
      ],
      "year": "2006",
      "venue": "FABO"
    },
    {
      "citation_id": "17",
      "title": "Performance benchmark of deep learning human pose estimation for UAVs. Machine Vision and Applications",
      "authors": [
        "T Kalampokas",
        "S Krinidis",
        "V Chatzis",
        "G Papakostas"
      ],
      "year": "2023",
      "venue": "Performance benchmark of deep learning human pose estimation for UAVs. Machine Vision and Applications",
      "doi": "10.1007/s00138-023-01448-5"
    },
    {
      "citation_id": "18",
      "title": "Emotion Recognition Using Feature-level Fusion of Facial Expressions and Body Gestures",
      "authors": [
        "T Keshari",
        "S Palaniswamy"
      ],
      "year": "2019",
      "venue": "International Conference on Communication and Electronics Systems (ICCES)",
      "doi": "10.1109/ICCES45898.2019.9002175"
    },
    {
      "citation_id": "19",
      "title": "EMOTIC",
      "authors": [
        "Ronak Kosti",
        "Jose Alvarez",
        "Adria Recasens",
        "Agata Lapedriza"
      ],
      "year": "2019",
      "venue": "EMOTIC"
    },
    {
      "citation_id": "20",
      "title": "Pose image generation for video content creation using controlled human pose image generation GAN",
      "authors": [
        "L Kumar",
        "D Singh"
      ],
      "year": "2023",
      "venue": "Multimedia Tools and Applications",
      "doi": "10.1007/s11042-023-17856-8"
    },
    {
      "citation_id": "21",
      "title": "Hierarchical pose net: Spatial hierarchical body tree driven multi-person pose estimation",
      "authors": [
        "H Li",
        "H Yao",
        "Y Hou"
      ],
      "year": "2024",
      "venue": "Multimedia Tools and Applications",
      "doi": "10.1007/s11042-023-15320-1"
    },
    {
      "citation_id": "22",
      "title": "CNN-based stress and emotion recognition in ambulatory settings",
      "authors": [
        "L Liakopoulos",
        "N Stagakis",
        "E Zacharaki",
        "K Moustakas"
      ],
      "year": "2021",
      "venue": "12th International Conference on Information, Intelligence, Systems & Applications (IISA)",
      "doi": "10.1109/IISA52424.2021.9555508"
    },
    {
      "citation_id": "23",
      "title": "Towards Explainable, Privacy-Preserved Human-Motion Affect Recognition",
      "authors": [
        "M Malek-Podjaski",
        "F Deligianni"
      ],
      "year": "2021",
      "venue": "IEEE Symposium Series on Computational Intelligence (SSCI)",
      "doi": "10.1109/SSCI50451.2021.9660129"
    },
    {
      "citation_id": "24",
      "title": "Multimodal and Context-Aware Emotion Perception Model With Multiplicative Fusion",
      "authors": [
        "T Mittal",
        "A Bera",
        "D Manocha"
      ],
      "year": "2021",
      "venue": "IEEE MultiMedia",
      "doi": "10.1109/MMUL.2021.3068387"
    },
    {
      "citation_id": "25",
      "title": "",
      "authors": [
        "Mocap"
      ],
      "venue": ""
    },
    {
      "citation_id": "26",
      "title": "Emilya: Emotional body expression in daily actions database",
      "authors": [
        "Nesrine Fourati",
        "Catherine Pelachaud"
      ],
      "year": "2014",
      "venue": "Emilya: Emotional body expression in daily actions database"
    },
    {
      "citation_id": "27",
      "title": "Papers with Code-AVA Dataset",
      "year": "2024",
      "venue": "Papers with Code-AVA Dataset"
    },
    {
      "citation_id": "28",
      "title": "Expressive Body Capture: 3D Hands, Face, and Body From a Single Image",
      "authors": [
        "G Pavlakos",
        "V Choutas",
        "N Ghorbani",
        "T Bolkart",
        "A Osman",
        "D Tzionas",
        "M Black"
      ],
      "year": "2019",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
      "doi": "10.1109/CVPR.2019.01123"
    },
    {
      "citation_id": "29",
      "title": "Affective Computing",
      "authors": [
        "R Picard"
      ],
      "venue": "Affective Computing"
    },
    {
      "citation_id": "30",
      "title": "Toward machine emotional intelligence: Analysis of affective physiological state",
      "authors": [
        "R Picard",
        "E Vyzas",
        "J Healey"
      ],
      "venue": "IEEE"
    },
    {
      "citation_id": "31",
      "title": "Psychoevolutionary Theory of Emotion",
      "authors": [
        "Plutchik"
      ],
      "year": "2017",
      "venue": "Psychoevolutionary Theory of Emotion",
      "doi": "10.1007/978-3-319-28099-8_547-1"
    },
    {
      "citation_id": "32",
      "title": "Computer Vision-Based Assessment of Autistic Children: Analyzing Interactions, Emotions, Human Pose, and Life Skills",
      "authors": [
        "V Prakash",
        "M Kohli",
        "S Kohli",
        "A Prathosh",
        "T Wadhera",
        "D Das",
        "D Panigrahi",
        "J Kommu"
      ],
      "year": "2023",
      "venue": "Computer Vision-Based Assessment of Autistic Children: Analyzing Interactions, Emotions, Human Pose, and Life Skills",
      "doi": "10.1109/ACCESS.2023.3269027"
    },
    {
      "citation_id": "33",
      "title": "Learning Perceived Emotion Using Affective and Deep Features for Mental Health Applications",
      "authors": [
        "T Randhavane",
        "U Bhattacharya",
        "K Kapsaskis",
        "K Gray",
        "A Bera",
        "D Manocha"
      ],
      "year": "2019",
      "venue": "IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)",
      "doi": "10.1109/ISMAR-Adjunct.2019.000-2"
    },
    {
      "citation_id": "34",
      "title": "UnSkEm: Unobtrusive Skeletal-based Emotion Recognition for User Experience",
      "authors": [
        "M Razzaq",
        "J Bang",
        "S Kang",
        "S Lee"
      ],
      "year": "2020",
      "venue": "International Conference on Information Networking (ICOIN)",
      "doi": "10.1109/ICOIN48656.2020.9016601"
    },
    {
      "citation_id": "35",
      "title": "A Complex Model of Affect",
      "authors": [
        "J Russell"
      ],
      "year": "1980",
      "venue": "A Complex Model of Affect"
    },
    {
      "citation_id": "36",
      "title": "Deep Learning Approach for Emotion Recognition from Human Body Movements with Feedforward Deep Convolution Neural Networks",
      "authors": [
        "R Santhoshkumar",
        "M Geetha"
      ],
      "year": "2019",
      "venue": "Procedia Computer Science",
      "doi": "10.1016/j.procs.2019.05.038"
    },
    {
      "citation_id": "37",
      "title": "The Ten Postulates of Plutchik's (1980) psychoevolutionary theory of basic emotions",
      "authors": [
        "M Spencer"
      ],
      "year": "2022",
      "venue": "#:~:text=Happiness%20is%20ty pically%20a%20more,and%20satisfaction%20with%20life%20overall. The motion capture library"
    },
    {
      "citation_id": "38",
      "title": "The Fusion Knowledge of Face, Body and Context for Emotion Recognition",
      "authors": [
        "J Wu",
        "Y Zhang",
        "L Ning"
      ],
      "year": "2019",
      "venue": "IEEE International Conference on Multimedia & Expo Workshops (ICMEW)",
      "doi": "10.1109/ICMEW.2019.0-102"
    },
    {
      "citation_id": "39",
      "title": "Multi-Scale Driver Behaviors Reasoning System for Intelligent Vehicles Based on a Joint Deep Learning Framework",
      "authors": [
        "Y Xing",
        "Z Hu",
        "Z Huang",
        "C Lv",
        "D Cao",
        "E Velenis"
      ],
      "year": "2020",
      "venue": "IEEE International Conference on Systems, Man, and Cybernetics",
      "doi": "10.1109/SMC42975.2020.9283004"
    },
    {
      "citation_id": "40",
      "title": "A motion capture library for the study of identity, gender, and emotion perception from biological motion",
      "authors": [
        "Yingliang Ma",
        "Helena Paterson",
        "Frank Pollick"
      ],
      "year": "2006",
      "venue": "A motion capture library for the study of identity, gender, and emotion perception from biological motion",
      "doi": "10.3758/BF03192758"
    },
    {
      "citation_id": "41",
      "title": "Emotion Recognition from 3D Motion Capture Data using Deep CNNs",
      "authors": [
        "H Zacharatos",
        "C Gatzoulis",
        "P Charalambous",
        "Y Chrysanthou"
      ],
      "year": "2021",
      "venue": "2021 IEEE Conference on Games (CoG)",
      "doi": "10.1109/CoG52621.2021.9619065"
    },
    {
      "citation_id": "42",
      "title": "Robust Emotion Recognition Across Diverse Scenes: A Deep Neural Network Approach Integrating Contextual Cues",
      "authors": [
        "S Zaghbani",
        "M Bouhlel",
        "X Qi",
        "G Fu",
        "X Zhang"
      ],
      "year": "2022",
      "venue": "International Journal of Information Technology",
      "doi": "10.1007/s41870-021-00820-wZhang"
    }
  ]
}