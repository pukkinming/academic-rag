{
  "paper_id": "2406.05063v1",
  "title": "Are Large Language Models More Empathetic Than Humans?",
  "published": "2024-06-07T16:33:43Z",
  "authors": [
    "Anuradha Welivita",
    "Pearl Pu"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "With the emergence of large language models (LLMs), investigating if they can surpass humans in areas such as emotion recognition and empathetic responding has become a focal point of research. This paper presents a comprehensive study exploring the empathetic responding capabilities of four state-of-the-art LLMs: GPT-4, LLaMA-2-70B-Chat, Gemini-1.0-Pro, and Mixtral-8x7B-Instruct in comparison to a human baseline. We engaged 1,000 participants in a between-subjects user study, assessing the empathetic quality of responses generated by humans and the four LLMs to 2,000 emotional dialogue prompts meticulously selected to cover a broad spectrum of 32 distinct positive and negative emotions. Our findings reveal a statistically significant superiority of the empathetic responding capability of LLMs over humans. GPT-4 emerged as the most empathetic, marking ≈31% increase in responses rated as Good compared to the human benchmark. It was followed by LLaMA-2, Mixtral-8x7B, and Gemini-Pro, which showed increases of approximately 24%, 21%, and 10% in Good ratings, respectively. We further analyzed the response ratings at a finer granularity and discovered that some LLMs are significantly better at responding to specific emotions compared to others. The suggested evaluation framework offers a scalable and adaptable approach for assessing the empathy of new LLMs, avoiding the need to replicate this study's findings in future research.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "This era is marked by massive developments in artificial intelligence (AI), especially large language models (LLMs). They have exhibited performance exceeding humans across a variety of traditional language processing tasks such as question answering, text summarization, and commonsense reasoning  (Laskar et al., 2023; Ziyu et al., 2023) . While there are public benchmarks and evaluation frameworks to evaluate LLMs' performance on these tasks, there is a lack of such resources to evaluate LLMs' ability to generate empathetic responses. Empathetic response generation requires generating replies that are not only contextually relevant and coherent but also demonstrate understanding, compassion, and emotional support towards the user's situation and feelings  (Rashkin et al., 2019) . This is particularly challenging as empathy, being a deeply nuanced human experience, requires not only linguistic proficiency but also a deep understanding of human psychology, emotions, and social context  (Ioannidou and Konstantikaki, 2008) .\n\nEmpathy is a multifaceted construct, encompassing cognitive, affective, and compassionate counterparts  (Ekman, 2004; Decety et al., 2006; Powell and Roberts, 2017) . Each component plays a crucial role in holistic empathetic engagement. Cognitive empathy is understanding and accurately identifying others' feelings. Affective empathy is sharing the other person's emotions. Compassionate empathy is taking action to help the other person deal with their emotions. Empathy is a key component in making artificial conversational agents human-like, which fosters trust and rapport with the user  (Liu-Thompkins et al., 2022)  and helps to increase people's adoption of this technology  (Goetz et al., 2003; Stroessner and Benitez, 2019; Svikhnushina and Pu, 2022) . So, evaluating the empathetic capabilities of LLMs that power artificial conversational agents plays a big role in deciding people's willingness to use this technology.\n\nExisting studies that evaluate the empathetic capabilities of LLMs encompass major limitations. Most of them use automatic evaluation metrics that do not necessarily correlate with human perceptions of empathy  (Belkhir and Sadat, 2023; Loh and Raamkumar, 2023) . Most evaluations are focused on the healthcare domain involving a lot of negative emotions  (Chen et al., 2023; Ayers et al., 2023;   Figure  1 : Between-subjects experiment design to evaluate the level of empathy demonstrated by LLMs compared to a human baseline when responding to emotional situations.  Liu et al., 2023) . But empathy plays an important role in responding to both positive and negative emotions encountered in daily conversations. Also, most studies investigate LLMs' ability to respond in general to emotions (which are mostly coarsegrained) as a whole, without analyzing them at a finer level  (Lee et al., 2024; Zhao et al., 2023; Qian et al., 2023; Lee et al., 2022; Fu et al., 2023; Loh and Raamkumar, 2023) . This makes it impossible to observe any variability in LLMs' performance when responding to diverse emotions. Last, but most importantly, all studies we came across used within-subjects study designs where the same participant evaluated responses generated by different models  (Lee et al., 2024 (Lee et al., , 2022;; Ayers et al., 2023; Fu et al., 2023; Zhao et al., 2023; Qian et al., 2023) . In addition to introducing evaluation biases caused due to over-exposure to different model outputs and the order they are shown to the participants, this type of study design makes the evaluation approach not scalable to incorporate new and updated LLMs.\n\nAddressing the above limitations, we designed a between-subjects user study, recruiting 1,000 people from the crowdsourcing platform Prolific (www. prolific.com), in which 200 participants each were assigned to rate responses generated by humans and four state-of-the-art LLMs: GPT-4 (Ope-nAI, 2023), LLaMA-2-70B-Chat  (Touvron et al., 2023) , Gemini-1.0-Pro  (Pichai, 2023) , and Mixtral-8x7B-Instruct (MistralAI, 2024) (see Figure  1 ). We use 2,000 emotional dialogue prompts from the state-of-the-art EmpatheticDialogues dataset  (Rashkin et al., 2019) , which contains chit-chat oriented human-human conversations, to form the human baseline required for our study as well as to initiate responses from the LLMs. We carefully selected the dialogue prompts to be equally distributed over a broad spectrum of 32 positive and negative emotions so that we can analyze whether there are any significant differences between humans and LLMs when responding to such distinct emotions. We prompt the four LLMs to generate a response to a given dialogue prompt, with instructions defining empathy in terms of its cognitive, affective, and compassionate counterparts. We adopt a simple and straightforward evaluation scale to gauge the empathy level in these responses. We perform rigorous statistical analysis to identify whether there are any statistically significant differences between the empathy ratings of humans and the four LLMs when responding to positive and negative emotional situations. We further delve into each finer emotion category and observe whether there are any significant differences in the way humans and LLMs respond to these individual emotions. Due to the careful and thorough design, this evaluation framework provides a robust and extensible solution to evaluate the empathetic quality of emerging LLMs without having to replicate the current study 1  .\n\nDifferent studies use different approaches to evaluate empathy in LLMs, most of which encompass automatic evaluation criteria. For example, Loh and Raamkumar (2023) investigated the capability of five state-of-the-art LLMs including GPT-3.5, GPT-4, PaLM-2-the predecessor of Gemini, and Vicuna-based on LLaMA-1 to generate empathetic responses using ≈2,550 dialogue prompts from the EmpatheticDialogues dataset. They utilized three automatic empathy-related evaluation metrics: 1) Emotional Reactions (indicative of affective empathy); 2) Interpretations (indicative of cognitive empathy); and 3) Explorations (indicative of cognitive empathy)  (Sharma et al., 2020a)  and discovered that LLMs' responses scored higher across the three metrics compared to those generated by traditional dialogue systems and humans. However, their evaluation is purely based on automatic evaluation, which does not necessarily correlate with how human users perceive the responses generated by the LLMs. A user-based evaluation could either validate the above observations or bring forth vastly different results.  Belkhir and Sadat (2023)  analyzed GPT-3.5's ability to produce empathetic responses, using precision, accuracy, and recall related to the emotion conveyed in the responses. However, empathetic communication does not always have to be emotional; it can sometimes be more neutral, focusing on specific intentions, as noted by  Welivita and Pu (2020) . This raises questions about the appropriateness of such metrics for evaluating empathetic responses.\n\nSome studies have utilized questionnaires and psychological scales that are primarily designed to measure the empathy levels of humans on LLMs without considering their applicability.  Schaaff et al. (2023)  used standardized questionnaires from psychology such as Interpersonal Reactivity  Index (Davis, 1980) , Empathy Quotient  (Lawrence et al., 2004) , and Toronto Empathy Questionnaire  (Spreng et al., 2009)  to assess the level of empathy exhibited by  GPT-3.5 compared to humans. Elyoseph et al. (2023)  utilized the Levels of Emotional Awareness Scale (LEAS)  (Lane et al., 1990)  to evaluate GPT-3.5's ability to identify and describe emotions compared to the general population. But the applicability of this type of scales designed to evaluate humans' emotion understanding and empathy levels on LLMs is debatable.\n\nResearch evaluating the empathetic responding ability of LLMs using human evaluators employ within-subjects designs, where the same participant evaluates different model outputs  (Lee et al., 2024 (Lee et al., , 2022;; Ayers et al., 2023; Fu et al., 2023; Zhao et al., 2023; Qian et al., 2023) . For instance,  Lee et al. (2024)",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "The Dataset",
      "text": "To conduct the study, we used dialogues from the state-of-the-art EmpatheticDialogues dataset  (Rashkin et al., 2019) , which consists of ≈25K dialogues spanning 32 fine-grained positive and negative emotions, selected from multiple annotation schemes, ranging from basic emotions derived from biological responses  (Ekman, 1992; Plutchik, 1984)  to larger sets of subtle emotions derived from contextual situations  (Skerry and Saxe, 2015) . The dialogues in this dataset are curated by recruiting crowd workers from Amazon Mechanical Turk (AMT) 2  . The workers were paired together and were asked to role-play a dialogue, one person acting as the speaker and the other as the listener. The speaker was asked to pick an emotion, come up with a situation based on the chosen emotion, and start a conversation. The listener who is unaware of the emotion or the situation was asked to respond to You are engaging in a conversation with a human. Respond in an empathetic manner to the following using on average 28 words and a maximum of 97 words.\n\nTable  1 : The set of instructions used to prompt the large language models to generate empathetic responses.\n\nthe speaker. Based on the sample size predicted by power analysis (in Section 4.5), we used randomly sampled 2,000 dialogues from this dataset, which are more or less equally distributed across the 32 emotions for our study (see Appendix A). Though the dialogues spanned up to a maximum of 8 turns, for simplicity, we selected only the first two dialogue turns along with the emotion the dialogues were based on and the situation description. This formed the human baseline for our study.\n\nIn one of our previous studies, we used two different prompts to instruct the LLM GPT-4 to generate responses given the 1 st turn of the dialogues. The first one was a very basic prompt that did not define the concept of empathy nor explicitly asked the model to generate an empathetic response. The second prompt defined the concept of empathy concerning its cognitive, affective, and compassionate counterparts and explicitly asked the model to respond in an empathetic manner to the given dialogue utterance. We observed that the one that utilized the second prompt outperformed the one that utilized the basic prompt as well as the human baseline with respect to the empathy ratings allocated by the study participants. Thus, we utilized the same empathy-defining instructions to prompt the LLMs compared in this study to generate responses. Table  1  denotes this set of instructions.\n\nFor comparison with the human baseline, we use responses generated by four state-of-the-art LLMs: GPT-4 (OpenAI, 2023); LLaMA-2-70B-Chat  (Touvron et al., 2023) ; Gemini-1.0-Pro  (Pichai, 2023); and Mixtral-8x7B-Instruct (MistralAI, 2024) . Details regarding the four LLMs are in Appendix B. We first manually inspected a random set of responses generated by a large group of LLMs that included other LLMs such as PaLM-2  (Anil et al., 2023) , ChatGLM-3  (Zeng et al., 2022) , Vicuna-180B  (Chiang et al., 2023) , and Falcon-40B-Instruct  (Almazrouei et al., 2023)  and selected the LLMs that seemingly generated the highest quality responses to evaluate against the human baseline. Appendix C denotes the statistics of all the prompt-response pairs evaluated in the study.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Experiment Design",
      "text": "",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Between-Subjects Vs Within-Subjects",
      "text": "In our experiment design, which was structured as a between-subjects study, participants were divided into five groups. The first group assessed the empathetic quality of responses from humans to both positive and negative emotional scenarios. Each of the other four groups were assigned to evaluate empathy in responses generated by one of the four LLMs to the same emotional dialogue scenarios. This type of study design offers distinct advantages over a within-subjects approach. In within-subjects studies, as one person evaluates two or more model outputs, the evaluator's perception of empathy could be distorted by overexposure to model outputs resulting in a bias in their evaluations-commonly known as the carry-over effect. For example, an averagely empathetic response may be judged more harshly by the evaluator if they have already seen an extremely empathetic response given by another model. This could also lead to order effects, as the sequence in which model outputs are presented to the workers may influence how they assess the responses.  (Shaughnessy et al., 2000; Charness et al., 2012; Montoya, 2023) . Within-subjects studies also cannot accommodate seamless integration of outputs from newly developed language models. Such a study design necessitates starting from scratch every time a new model is introduced, making prior results obsolete. Conversely, a between-subjects study design, which employs different participants for assessing each model, offers the adaptability needed to evaluate emerging language models. This method facilitates an ongoing evaluation of language models' evolving empathy capabilities, making it a desirable option for such assessments.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Selection Of The Rating Scale",
      "text": "When choosing a rating scale to evaluate the empathetic quality of responses, we faced a decision between a simpler 3-point scale with options Bad, Okay, Good and a more detailed 5-point scale with options Bad, Fair, Okay, Good, and Excellent. To determine the better option, we conducted a pilot study with 100 participants from Prolific. Each participant rated 10 responses using both scales. Half of the participants rated on a 3-point scale first and then on a 5-point scale (Group A) and the other half vice versa (Group B). We measured the agreement between raters in the above two groups using weighted Cohen's kappa  (Cohen, 1968) . The results showed that the 3-point scale achieved a kappa score of 0.2817, indicating fair agreement, whereas the 5-point scale scored 0.1813, indicating poor agreement. Additionally, we assessed how well the ratings from each scale correlated with scores from EPITOME  (Sharma et al., 2020b) , an automatic empathy evaluation tool. The 3-point scale ratings showed a low but better correlation of 0.1731 with EPITOME's emotional reaction scores, compared to a negligible correlation of 0.0811 for the 5-point scale. These findings indicate that although individual preferences for different scale types may vary subjectively, the 3-point scale more successfully maintains the accuracy of objective empathy measurements, resulting in evaluations that are both more reliable and consistent compared to those using the 5-point scale. This makes the 3-point scale a preferable choice for assessing empathy in responses, enhancing consistency among human raters, and alignment with automated tools.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Task Design",
      "text": "The five groups of participants for the study were recruited through the Prolific crowdsourcing platform (www.prolific.com). Past research has indicated that Prolific outperforms other crowdsourcing platforms like AMT, CloudResearch (www.cloudresearch.com), Dynata (www.dynata.com), and Qualtrics (www. qualtrics.com) in aspects such as worker attentiveness, integrity, understanding, and dependability  (Peer et al., 2022; Douglas et al., 2023) . Participants in the five groups were balanced across demographic criteria: gender (male and female); and age group  (young adulthood [19 -25 years] ; middle adulthood  [26 -45 years] ; late adulthood [46 -64 years]; and older adulthood [65 years and above]). Additionally, a survey based on the Toronto Empathy Questionnaire (TEQ)  (Spreng et al., 2009)  measured the empathy propensity of each participant, i.e., their natural predisposition to empathize with others. Subsequent analysis indicated that the inclination towards empathy was comparably distributed among the five groups, suggesting that participant conditions were uniformly matched across the board (see Appendix K). Each participant evaluated randomly chosen 10 dialogue responses generated by the same model. The source of the responses, whether from a human or an LLM, was unknown to the participants. They were tasked with rating the empathy of the responses as either Bad, Okay, or Good, relative to how they would have responded in similar situations. Furthermore, participants were introduced to the concept of empathy through a tutorial that covered its cognitive, affective, and compassionate dimensions. This tutorial was identical to the one used to prompt the LLMs and included exemplary dialogues from the Em-patheticDialogues dataset. These examples were chosen based on high ratings of empathy, relevance, and fluency by the human participants involved in the dataset's creation.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Quality Control",
      "text": "To ensure a high standard of data quality, our study selectively recruited participants who were proficient in English and had a track record of at least 100 prior submissions with an approval rate exceeding 95%. Following the selection criteria, the Toronto Empathy Questionnaire (TEQ), which was used to measure the workers' propensity to empathize, contained 8 reserve scale questions. These questions were used to gauge the quality of the workers and their attentiveness to the task.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Statistical Test And Sample Size",
      "text": "To analyze the results from the study we use the chi-square test of independence  (McHugh, 2013)  that tests whether there is any statistically significant difference between the proportion of Bad, Okay, and Good ratings of the five response groups.\n\nWhen analyzing categorical ratings, particularly if the data involves ratings from different groups (like humans vs LLMs), the chi-Square test of independence is often a strong choice due to its robustness and the straightforward interpretability of the results  (Field, 2013) . The null and the alternate hypotheses of this statistical test are as below.\n\nχ 2 test of independence:\n\n• Null hypothesis: There is no difference between the proportion of Bad, Okay, and Good ratings of the five groups of responses.\n\n• Alternative hypothesis: There is a difference between the proportion of Bad, Okay, and Good ratings of at least one out of the five groups of responses.\n\nWe used the G-Power software  (Faul et al., 2009 ) to compute the minimal sample size required to detect a significant difference between the ratings of the five response groups. For the chi-square test of independence with a medium effect size (0.3), a significance level (α) of 0.05, and a power (1 -β) of 0.95, the minimal total sample size required is 253 (i.e. at least 51 participants per group). When statistically analyzing the differences in empathy ratings when responding to positive and negative emotions separately, the minimal sample size required becomes twice the sample size suggested above (i.e. at least 102 participants per group). From a prior study, we had already engaged 200 participants to evaluate responses generated by humans and GPT-4. To ensure compatibility, we additionally recruited 600 participants from Prolific to rate responses generated by the LLMs: LLaMA-2; Gemini-Pro; and Mixtral-8x7B. That is 200 participants per group, which is sufficiently above the minimal sample size. One participant was asked to rate 10 responses. Altogether our study compares empathy ratings received for 10, 000 responses (2, 000 responses per group).",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Results",
      "text": "Figure  2  visualizes the number of Good, Okay, and Bad ratings received by the responses generated by humans, and the four LLMs for dialogue prompts spanning across all emotions as a whole. The χ 2 and the p-values obtained by applying the chi-square test of independence to the number of Good, Okay, and Bad ratings collectively and for each category independently indicated that there is a statistically significant difference between the proportion of Good, Okay, and Bad ratings of at least one out of the five response groups. We com-puted the percentage gains of the ratings received by each LLM compared to the human baseline under each rating category. GPT-4 was observed to generate the most empathetic responses with ≈ 31%(χ 2 = 96.77, p < .001) gain in the number of Good ratings compared to the humans. LLaMA-2, Mixtral-8x7B, and Gemini-Pro were observed to follow GPT-4 with ≈ 24%(χ 2 = 54.40, p < .001), ≈ 21%(χ 2 = 42.36, p < .001), and ≈ 10%(χ 2 = 8.85, p < .01) gain in the number of Good ratings, respectively, compared to the human baseline. Note that when calculating the χ 2 values here, we considered Good ratings as one category and combined Bad and Okay ratings as another category.\n\nFigure  3  visualizes the number of Good, Okay, and Bad ratings received by the responses generated by humans and the four LLMs for positive and negative emotional dialogue prompts, separately. All four LLMs outperformed the human baseline across both positive and negative emotions in the number of Good ratings received. Here too, GPT-4 ranked the top in the number of Good ratings, obtaining percentage gains of ≈ 36%(χ 2 = 64.10, p < .001) and ≈ 27%(χ 2 = 36.78, p < .001), respectively across positive and negative emotions, compared to the human baseline. LLaMA-2 and Mixtral-8x7B followed GPT-4 when responding to positive emotions obtaining ≈ 28%(χ 2 = 38.40, p < .001), and ≈ 25%(χ 2 = 29.21, p < .001) gain in the number of Good ratings, respectively, compared to the human baseline. However, the percentage gain in the number of Good ratings obtained by Gemini-Pro across positive emotions was observed to be statistically insignificant compared to those received by the human responses (↑= 5.95%, χ 2 = 1.54, p > .05). LLaMA-2, Mixtral-8x7B, and Gemini-Pro followed GPT-4 when responding to negative emotions obtaining ≈ 20%(χ 2 = 19.0, p < .001), ≈ 17%(χ 2 = 15.15, p < .001), and ≈ 13%(χ 2 = 8.02, p < .01) gain in the number of Good ratings, respectively, compared to the human baseline.\n\nFurther, we computed the percentage gains of the categorical ratings received by each LLM compared to the human baseline when responding to each of the 32 positive and negative emotions (See Table  9  in Appendix H). This finer analysis allowed us to observe that some LLMs are significantly better than humans when responding to specific emotions compared to others. It could be observed that GPT-4 obtains statistically significant percentage gains in the number of Good ratings over the human baseline across most positive emotion categories such as Impressed (↑= 56%, χ 2 = 10.62, p < .01), Surprised (↑= 79%, χ 2 = 10.33, p < .01), Grateful (↑= 65%, χ 2 = 8.36, p < .01), Proud (↑= 50%, χ 2 = 7.7, p < .01), Confident (↑= 44%, χ 2 = 6.86, p < .01), Joyful (↑= 42%, χ 2 = 6.34, p < .05), and Excited (↑= 47%, χ 2 = 5.41, p < .05); LLaMA-2 across emotions Grateful (↑= 65%, χ 2 = 8.36, p < .01), Surprised (↑= 71%, χ 2 = 8.14, p < .01), Proud (↑= 44%, χ 2 = 5.69, p < .05), Excited (↑= 44%, χ 2 = 4.59, p < .05), Hopeful (↑= 39%, χ 2 = 4.27, p < .05), and Prepared (↑= 39%, χ 2 = 4.06, p < .05); and Mixtral-8x7B across emotions Proud (↑= 59%, χ 2 = 11.44, p < .001), Grateful (↑= 58%, χ 2 = 6.36, p < .05), and Excited (↑= 47%, χ 2 = 5.41, p < .05).\n\nCompared to the positive emotions, we could only observe the four LLMs obtaining significant gains in the number of Good ratings over humans only across a few negative emotions such as Afraid (LLaMA: ↑= 50%, χ 2 = 4.66, p < .05; GPT: ↑= 46%, χ 2 = 3.91, p < .05), Apprehensive (GPT: ↑= 104%, χ 2 = 20.72, p < .001; Gemini: ↑= 60%, χ 2 = 6.23, p < .05; LLaMA: ↑= 52%, χ 2 = 4.57, p < .05), Anxious (GPT: ↑= 75%, χ 2 = 9.2, p < .01; LLaMA: ↑= 63%, χ 2 = 6.22, p < .05; Gemini: ↑= 63%, χ 2 = 6.22, p < .05; Mixtral: ↑= 50%, χ 2 = 3.85, p < .05), and Annoyed (GPT: ↑= 59%, χ 2 = 6.62, p < .05); Mixtral: ↑= 52%, χ 2 = 4.97, p < .05)). This implies that there is more room for these LLMs to improve their performance across other important negative emotion categories that commonly occur in day-to-day conversations.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Case Study",
      "text": "Table  2  shows an example, in which the response generated by the human was rated Bad whereas the responses generated by the four LLMs were rated Good by the participants. It could be noted that in the human response, the human responder speaks about themselves rather than focussing on the emotion of the speaker. On the other hand, all the four LLMs seem to recognize the emotion of the speaker and the love the speaker's grandmother has towards them and validate it using phrases such as That's so sweet, That's so thoughtful, That's so heartwarming to hear!, and Your grandmother's thoughtfulness warms my heart. What follows in the LLMs' responses are more complex reflections of what the speaker has said, which not only demonstrates understanding but also adds depth to the conversation, potentially leading to a more profound continuation of the dialogue. More such examples are denoted in Appendix I.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Discussion",
      "text": "The responses generated by all four LLMs surpassed the human responses in terms of empathetic quality by a statistically significant margin across all emotions as a whole, and across positive (except Gemini-pro) and negative emotions separately. Even though Gemini-Pro reported a significant gain (≈ 13%) compared to the human baseline across negative emotions, it failed to report statistically significant gains compared to the human baseline  across positive emotions, which leaves more room for Gemini-Pro to improve its performance when responding to positive emotions. It was seen that LLMs GPT-4, LLaMA-2, and Mixtral-8x7B perform significantly better than humans when responding to most positive emotion categories such as Grateful, Proud, and Excited. However, compared to positive emotions, the four LLMs could only perform significantly better than humans when responding to a few negative emotions such as Apprehensive and Anxious. This implies that the LLMs, while advanced in their empathetic understanding and response generation, have differential performance based on the valence of the emotions they are responding to. This could be due to a variety of factors such as the data the models are trained on, which may contain richer or more nuanced examples of responses to specific emotions, allowing the LLMs to learn more effective response strategies for these emotions.\n\nThe disparity in performance between positive and negative emotions also suggests that future iterations of these LLMs could benefit from targeted improvements in understanding and responding to more negative emotions. This could involve incor-porating more diverse and nuanced examples of negative emotional responses into the training data or refining the models' algorithms to better capture the subtleties of negative emotional expressions.\n\nFurthermore, the fact that LLMs outperform humans in empathetic response quality, especially in certain emotions, underscores the potential of these models in applications requiring emotional intelligence, such as mental health support, customer service, and social interactions. However, the variability in performance across different types of emotions also highlights the importance of ongoing research and development to enhance the models' emotional intelligence across the full spectrum of human emotions.\n\nOverall, this study contributed knowledge on how empathy is conveyed in responses generated by different LLMs to diverse positive and negative emotional stimuli, compared to a human baseline. Due to the between-groups study design and the release of the dataset, the evaluation framework that we introduce could be extended to evaluate the empathetic responding capabilities of newer and updated versions of LLMs as they emerge.\n\nThe choice of using a 3-point scale rather than a 5 or 7-point scale can raise questions regarding the granularity of the evaluation. As described in section 4.2, given that the study involves a large and diverse pool of participants, we believe that the advantages of using a simple, straightforward, and a human-centric rating scale, outweigh the concerns regarding granularity. As is evident from our results, the 3-point scale, while offering less granularity than a 5 or 7-point scale, still provides sufficient variability to perform robust statistical analyses. This scale was adequate to reveal significant differences in human and LLM-generated empathetic responses, confirming its effectiveness in the context of our research objectives. This establishes a foundational benchmark for evaluating the empathetic quality of responses, serving as a stepping stone for more detailed future studies.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Ethical Considerations",
      "text": "Data usage: The study utilized dialogue promptresponse pairs from the state-of-the-art Empathet-icDialogues dataset  (Rashkin et al., 2019) , which contains ethically sourced dialogues and is available publicly under the CC BY-NC 4.0 license. The dataset itself is anonymized to protect the privacy of individuals who contributed to its creation. We plan to publicly release the new artifacts generated in this study, including the responses from the four LLMs and the participants' empathy ratings, under the CC BY-NC 4.0 license. This licensing allows other researchers to modify, enhance, and further build upon our work for non-commercial purposes. By doing so, we aim to facilitate ongoing comparisons with newer and updated versions of LLMs, eliminating the need to replicate the entire study from the beginning.\n\nHuman experiment: The human participants recruited from the crowdsourcing platform Prolific (www.prolific.com) were paid C2.25 for rating 10 responses that took on average 11 minutes and 23 seconds to complete. This was ≈1.3 times above the wage recommended as Good (C9 per hour) by the Prolific crowdsourcing platform. All participants were informed about the purpose of the study and the nature of the tasks they would perform. The ratings were collected at the end of the task after the participants decided to submit their work. Intermediate annotations were not recorded. The participants were allowed to leave the task at any time without submitting their ratings. Random subsets of dialogue prompt-response pairs used in the study were manually inspected to ensure that the tasks assigned to the crowd workers were not psychologically distressing or offensive. In addition, efforts were made to recruit a diverse group of participants considering factors of gender and the age group that represent the broader population to avoid bias in the results.\n\nTransparency and reproducibility of the study: The dialogue prompt-response pairs that were subjected to evaluation along with the participants' evaluations of these responses will be released publicly to ensure the transparency and reproducibility of our study.\n\nEthical concerns surrounding empathetic LLMs: Given the black-box nature of LLMs and their limited controllability and interpretability, one should take caution when using them, particularly in sensitive application domains such as mental health and crisis support. The opaque nature of these models can lead to outputs that are unpredictable or misaligned with human expectations, which can raise significant ethical concerns. Also, LLM-generated responses can represent societal biases and discriminations that are inherently present in the training data, which can lead to discriminatory or unethical outputs. Thus, an ethical approach to deploying such LLMs in sensitive domains should involve rigorous checking for biases and continuously monitoring their performance across underrepresented social groups. Some research studies point out that over-reliance on AI for empathetic interactions could affect human empathy skills and alter traditional social interactions  (Chen et al., 2024) . There is also a concern regarding the sincerity of the LLM-generated empathetic responses since LLMs cannot feel the users' emotions  (Bove, 2019) . Hence, it is important to be transparent about the nature of the LLM-generated responses to avoid over-reliance or emotional attachment to these agents over time.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "A Distribution Of Emotions",
      "text": "Figure  4  shows the distribution of the dialogue prompt-response pairs sampled from the Empathet-icDialogues dataset across the 32 positive and negative emotions. Table  3  shows the counts and the percentages of dialogue prompt-response pairs in the dataset corresponding to each emotion. It can be noted that the prompt-response pairs are more or less equally distributed across the 32 emotions.",
      "page_start": 11,
      "page_end": 12
    },
    {
      "section_name": "B Large Language Models",
      "text": "The study evaluated four state-of-the-art LLMs: GPT-4; LLaMA-2-Chat-70B; Gemini-1.0-Pro; and Mixtral-8x7B-Instruct. The details of the four LLMs are as follows.\n\nGPT-4 (OpenAI, 2023) developed by OpenAI (openai.com) is the latest model in their GPT series with an estimated 1.76 trillion parameters. GPT-4 is claimed to be more reliable, creative, and able to handle much more nuanced instructions than its predecessor GPT-3.5. The model considerably outperforms existing LLMs, alongside most state-of-the-art models which include benchmarkspecific crafting or additional training protocols.\n\nLLaMA-2-Chat-70B  (Touvron et al., 2023)    developed by Meta AI (ai.meta.com) , is an opensource LLM pre-trained on publicly available online data sources and fine-tuned on publicly available instruction tuning data  (Chung et al., 2022)   aligning the LLM towards dialogue-style instructions. We used the largest variant of LLaMA-2 with 70 billion parameters for this study.\n\nGemini-1.0-Pro  (Pichai, 2023)",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "C Statistics Of The Dialogue Prompts And Responses",
      "text": "",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "D Toronto Empathy Questionnaire",
      "text": "Table  5  shows the questions in the Toronto Empathy Questionnaire (TEQ)  (Spreng et al., 2009)  that were asked from the participants. Responses to the questions are scored according to the following 3 https://www.nltk.org/api/nltk.tokenize.html scale for positively worded questions: Never = 0; Rarely = 1; Sometimes = 2; Often = 3; Always = 4. The negatively worded questions indicated are reverse-scored. Scores are summed to derive one's propensity to empathize.",
      "page_start": 14,
      "page_end": 14
    },
    {
      "section_name": "E Task Interfaces",
      "text": "Figures 5, 6, 7 and 8 show the task interfaces corresponding to the description of the task, the tutorial presented to the crowd workers, the Toronto Empathy Questionnaire, and the response rating task, respectively.",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "F Determing The Effect Size",
      "text": "Jacob Cohen, a renowned psychologist and statistician, introduced standards for evaluating the magnitude of effect sizes in statistical analyses such as chi-square tests and analysis of variance (ANOVA), as detailed in his work on quantitative methods  (Cohen, 1992) . These standards provide a foundational guide for assessing the substantive importance of observed effects within these statistical tests. For Chi-square tests, Cohen's W is utilized to measure the association strength between categories, with Cohen establishing benchmarks for small (0.10), medium (0.30), and large (0.50) effects.\n\nWe chose the medium effect size to compute the required minimum sample size because a medium effect size can sensitively detect differences in empathy levels between humans' and LLMs' responses, whose differences can be significant, yet not overwhelmingly so. Furthermore, employing a medium effect size enables the identification of nu-  anced yet significant differences without the need for an overly large sample, ensuring that the differences detected by the study are practically meaningful.",
      "page_start": 14,
      "page_end": 14
    },
    {
      "section_name": "G Chi-Squared Test Of Independence -Results",
      "text": "The statistical chi-square test of independence results corresponding to the proportions of the Bad, Okay, and Good empathy ratings received by the responses generated by the humans and the four LLMs are denoted in Table  6 .",
      "page_start": 15,
      "page_end": 15
    },
    {
      "section_name": "H Finer Analysis Of Empathy Ratings",
      "text": "Tables 9 denote the percentage gains obtained by the four LLMs' response ratings compared to the human baseline when responding to dialogue prompts containing positive and negative emotions.\n\nWe conducted pairwise statistical chi-square tests of independence for the proportions of each of Bad, Okay, and Good response ratings between the humans and each of the four LLMs. The percentage gains for which statistical significance was indicated by the chi-square test of independence are highlighted in bold.",
      "page_start": 16,
      "page_end": 16
    },
    {
      "section_name": "I Example Dialogue Responses",
      "text": "Table  10  denotes some example dialogue situations and responses generated by humans and LLMs and the corresponding ratings given by the human raters.",
      "page_start": 17,
      "page_end": 17
    },
    {
      "section_name": "J Participants' Demographics",
      "text": "Figures 9 and 10 respectively show the distributions of the countries of residence and the ethnicities of the participants who rated the five groups of responses. It could be observed that though there are imbalances across the countries and the ethnicities represented in the participants' pool, these demographics are similar across the five groups of participants. This allows control for factors other than the independent variable influencing the results of the study and fair comparison of response ratings across the five groups.  Table  7 : Statistical χ 2 test results corresponding to the proportions of Bad, Okay, and Good empathy ratings of the humans' and each of the LLMs' responses. In this case, we compare two by two. The critical value of the χ 2 distribution in this case is 5.991 (computed at a significance level of 0.05 and 2 degrees of freedom), which means if the χ 2 statistic is greater than 5.991 the null hypothesis can be rejected at 5% significance level, which means there is a statistically significant difference in the proportions of the Bad, Okay, and Good empathy ratings between the two groups of responses being compared.",
      "page_start": 15,
      "page_end": 15
    },
    {
      "section_name": "K Distribution Of Empathy Propensity Of Participants",
      "text": "Figure  11  shows the distributions of the participants' propensities to empathize across the five groups. It could be observed that they are more or less equally distributed across the three groups avoiding any biases in the results that might be caused by any inequal distribution of empathy propensities across the five groups.",
      "page_start": 16,
      "page_end": 16
    },
    {
      "section_name": "L Quality Analysis",
      "text": "Figure  12  shows the number of reverse scale questions in the TEQ that were marked incorrect by the participants rating the three response groups. It was observed that 60% of all participants did not get any reverse scale questions wrong and only 2.3% of all participants got more than half of the reverse scale questions wrong. These statistics validate the quality of the workers recruited for the study.\n\nFurther, Figure  13  shows the histogram of times (in minutes) taken to complete the study. On average it took 11 minutes and 23 seconds to complete rating 10 responses, which was close to the average completion time of 15 minutes that we estimated before conducting the study. Only 4.53% of all participants were observed to take less than 5 minutes to complete the study, which indicates that most of the participants took time to carefully read the instructions and respond to the questions attentively.",
      "page_start": 17,
      "page_end": 17
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Between-subjects experiment design to evaluate the level of empathy demonstrated by LLMs compared to",
      "page": 2
    },
    {
      "caption": "Figure 2: visualizes the number of Good, Okay,",
      "page": 6
    },
    {
      "caption": "Figure 3: visualizes the number of Good, Okay,",
      "page": 6
    },
    {
      "caption": "Figure 2: The Good, Okay, and Bad rating counts corresponding to the responses generated by humans, GPT-4,",
      "page": 7
    },
    {
      "caption": "Figure 3: The Good, Okay, and Bad rating counts corresponding to the responses generated by humans, GPT-4,",
      "page": 8
    },
    {
      "caption": "Figure 4: shows the distribution of the dialogue",
      "page": 12
    },
    {
      "caption": "Figure 4: Distribution of the dialogue prompt-response pairs sampled from the EmpatheticDialogues dataset across",
      "page": 13
    },
    {
      "caption": "Figure 5: The description of the task.",
      "page": 14
    },
    {
      "caption": "Figure 6: The tutorial.",
      "page": 14
    },
    {
      "caption": "Figure 7: The Toronto Empathy Questionnaire.",
      "page": 15
    },
    {
      "caption": "Figure 8: The task interface for rating responses in terms",
      "page": 15
    },
    {
      "caption": "Figure 11: shows the distributions of the partici-",
      "page": 16
    },
    {
      "caption": "Figure 12: shows the number of reverse scale ques-",
      "page": 16
    },
    {
      "caption": "Figure 13: shows the histogram of times",
      "page": 16
    },
    {
      "caption": "Figure 9: Distribution of the countries of residence of the participants across the five groups.",
      "page": 17
    },
    {
      "caption": "Figure 12: The number of reverse scale questions in the",
      "page": 17
    },
    {
      "caption": "Figure 10: Distribution of the ethnicities of the participants across the five groups.",
      "page": 18
    },
    {
      "caption": "Figure 11: The distributions of the participants’ propensities to empathize across the five groups.",
      "page": 18
    }
  ],
  "tables": [
    {
      "caption": "Table 1: The set of instructions used to prompt the large language models to generate empathetic responses.",
      "page": 4
    },
    {
      "caption": "Table 1: denotes this set of instructions.",
      "page": 4
    },
    {
      "caption": "Table 9: in Appendix H). This finer analysis allowed",
      "page": 6
    },
    {
      "caption": "Table 2: shows an example, in which the response",
      "page": 7
    },
    {
      "caption": "Table 2: An example where the response generated by the human was rated Bad whereas the responses generated by",
      "page": 8
    },
    {
      "caption": "Table 3: shows the counts and the",
      "page": 12
    },
    {
      "caption": "Table 3: The counts and percentages of dialogue prompt-",
      "page": 12
    },
    {
      "caption": "Table 4: Statistics of the dialogue prompts and responses",
      "page": 13
    },
    {
      "caption": "Table 5: shows the questions in the Toronto Empa-",
      "page": 13
    },
    {
      "caption": "Table 5: The Toronto Empathy Questionnaire (Spreng et al., 2009). *Negatively worded reverse scale questions.",
      "page": 14
    },
    {
      "caption": "Table 6: Table 8 denotes the",
      "page": 15
    },
    {
      "caption": "Table 10: denotes some example dialogue situations",
      "page": 15
    },
    {
      "caption": "Table 6: Statistical Chi-square test results corresponding to the proportions of Bad, Okay, and Good empathy ratings",
      "page": 16
    },
    {
      "caption": "Table 7: Statistical χ2 test results corresponding to the proportions of Bad, Okay, and Good empathy ratings of",
      "page": 16
    },
    {
      "caption": "Table 8: The percentage gains obtained by the LLMs in each rating category compared to the human baseline. The",
      "page": 17
    },
    {
      "caption": "Table 9: Percentage gains obtained by the four LLMs’",
      "page": 20
    },
    {
      "caption": "Table 10: Some example dialogue situations and responses generated by humans and LLMs and the corresponding",
      "page": 21
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Ángel Alexander Cabrera, Krish Dholakia, Chenyan Xiong, and Graham Neubig. 2023. An in-depth look at gemini's language abilities",
      "authors": [
        "Zichun Syeda Nahida Akter",
        "Aashiq Yu",
        "Tianyue Muhamed",
        "Alex Ou",
        "Bäuerle"
      ],
      "venue": "Ángel Alexander Cabrera, Krish Dholakia, Chenyan Xiong, and Graham Neubig. 2023. An in-depth look at gemini's language abilities",
      "arxiv": "arXiv:2312.11444"
    },
    {
      "citation_id": "2",
      "title": "Falcon-40B: an open large language model",
      "authors": [
        "Ebtesam Almazrouei",
        "Hamza Alobeidli",
        "Abdulaziz Alshamsi",
        "Alessandro Cappelli",
        "Ruxandra Cojocaru",
        "Merouane Debbah",
        "Etienne Goffinet",
        "Daniel Heslow",
        "Julien Launay",
        "Quentin Malartic",
        "Badreddine Noune",
        "Baptiste Pannier",
        "Guilherme Penedo"
      ],
      "year": "2023",
      "venue": "Falcon-40B: an open large language model"
    },
    {
      "citation_id": "3",
      "title": "Palm 2 technical report",
      "authors": [
        "Rohan Anil",
        "Andrew Dai",
        "Orhan Firat",
        "Melvin Johnson",
        "Dmitry Lepikhin",
        "Alexandre Passos",
        "Siamak Shakeri",
        "Emanuel Taropa",
        "Paige Bailey",
        "Zhifeng Chen"
      ],
      "year": "2023",
      "venue": "Palm 2 technical report",
      "arxiv": "arXiv:2305.10403"
    },
    {
      "citation_id": "4",
      "title": "Comparing physician and artificial intelligence chatbot responses to patient questions posted to a public social media forum",
      "authors": [
        "John Ayers",
        "Adam Poliak",
        "Mark Dredze",
        "Eric Leas",
        "Zechariah Zhu",
        "Jessica Kelley",
        "Dennis Faix",
        "Aaron Goodman",
        "Christopher Longhurst",
        "Michael Hogarth"
      ],
      "year": "2023",
      "venue": "JAMA internal medicine"
    },
    {
      "citation_id": "5",
      "title": "Beyond information: Is chatgpt empathetic enough?",
      "authors": [
        "Ahmed Belkhir",
        "Fatiha Sadat"
      ],
      "year": "2023",
      "venue": "Proceedings of the 14th International Conference on Recent Advances in Natural Language Processing"
    },
    {
      "citation_id": "6",
      "title": "Empathy for service: benefits, unintended consequences, and future research agenda",
      "authors": [
        "Liliana Bove"
      ],
      "year": "2019",
      "venue": "Journal of Services Marketing"
    },
    {
      "citation_id": "7",
      "title": "Experimental methods: Between-subject and withinsubject design",
      "authors": [
        "Gary Charness",
        "Uri Gneezy",
        "Michael Kuhn"
      ],
      "year": "2012",
      "venue": "Journal of economic behavior & organization"
    },
    {
      "citation_id": "8",
      "title": "Feels like empathy: How \"emotional\" ai challenges human essence",
      "authors": [
        "Angelina Chen",
        "Oliver Hannon",
        "Sarah Koegel",
        "Raffaele Ciriello"
      ],
      "year": "2024",
      "venue": "Australasian Conference on Information Systems"
    },
    {
      "citation_id": "9",
      "title": "Llmempowered chatbots for psychiatrist and patient simulation: Application and evaluation",
      "authors": [
        "Siyuan Chen",
        "Mengyue Wu",
        "Kenny Zhu",
        "Kunyao Lan",
        "Zhiling Zhang",
        "Lyuchun Cui"
      ],
      "year": "2023",
      "venue": "Llmempowered chatbots for psychiatrist and patient simulation: Application and evaluation",
      "arxiv": "arXiv:2305.13614"
    },
    {
      "citation_id": "10",
      "title": "Vicuna: An opensource chatbot impressing gpt-4 with 90%* chatgpt quality",
      "authors": [
        "Wei-Lin Chiang",
        "Zhuohan Li",
        "Zi Lin",
        "Ying Sheng",
        "Zhanghao Wu",
        "Hao Zhang",
        "Lianmin Zheng",
        "Siyuan Zhuang",
        "Yonghao Zhuang",
        "Joseph Gonzalez",
        "Ion Stoica",
        "Eric Xing",
        "Le Hou",
        "Shayne Longpre",
        "Barret Zoph",
        "Yi Tay",
        "William Fedus",
        "Yunxuan Li",
        "Xuezhi Wang",
        "Mostafa Dehghani"
      ],
      "year": "2023",
      "venue": "Siddhartha Brahma, et al. 2022. Scaling instruction-finetuned language models",
      "arxiv": "arXiv:2210.11416"
    },
    {
      "citation_id": "11",
      "title": "Weighted kappa: Nominal scale agreement provision for scaled disagreement or partial credit",
      "authors": [
        "Jacob Cohen"
      ],
      "year": "1968",
      "venue": "Psychological bulletin"
    },
    {
      "citation_id": "12",
      "title": "Quantitative methods in psychology: A power primer",
      "authors": [
        "Jacob Cohen"
      ],
      "year": "1980",
      "venue": "Psychol. Bull"
    },
    {
      "citation_id": "13",
      "title": "Human empathy through the lens of social neuroscience",
      "authors": [
        "Jean Decety",
        "Claus Lamm"
      ],
      "year": "2006",
      "venue": "The scientific World journal"
    },
    {
      "citation_id": "14",
      "title": "Data quality in online humansubjects research: Comparisons between mturk, prolific, cloudresearch, qualtrics, and sona",
      "authors": [
        "Patrick Benjamin D Douglas",
        "Markus Ewell",
        "Brauer"
      ],
      "year": "2023",
      "venue": "Plos one"
    },
    {
      "citation_id": "15",
      "title": "An argument for basic emotions",
      "authors": [
        "Paul Ekman"
      ],
      "year": "1992",
      "venue": "Cognition & emotion"
    },
    {
      "citation_id": "16",
      "title": "Chatgpt outperforms humans in emotional awareness evaluations",
      "authors": [
        "Paul Ekman"
      ],
      "year": "2004",
      "venue": "Emotions revealed"
    },
    {
      "citation_id": "17",
      "title": "Statistical power analyses using g* power 3.1: Tests for correlation and regression analyses",
      "authors": [
        "Franz Faul",
        "Edgar Erdfelder",
        "Axel Buchner",
        "Albert-Georg Lang"
      ],
      "year": "2009",
      "venue": "Behavior research methods"
    },
    {
      "citation_id": "18",
      "title": "Discovering statistics using IBM SPSS statistics",
      "authors": [
        "Andy Field"
      ],
      "year": "2013",
      "venue": "Discovering statistics using IBM SPSS statistics"
    },
    {
      "citation_id": "19",
      "title": "Reasoning before responding: Integrating commonsense-based causality explanation for empathetic response generation",
      "authors": [
        "Yahui Fu",
        "Koji Inoue",
        "Chenhui Chu",
        "Tatsuya Kawahara"
      ],
      "year": "2023",
      "venue": "Reasoning before responding: Integrating commonsense-based causality explanation for empathetic response generation",
      "arxiv": "arXiv:2308.00085"
    },
    {
      "citation_id": "20",
      "title": "Matching robot appearance and behavior to tasks to improve human-robot cooperation",
      "authors": [
        "Jennifer Goetz",
        "Sara Kiesler",
        "Aaron Powers"
      ],
      "year": "2003",
      "venue": "The 12th IEEE International Workshop on Robot and Human Interactive Communication"
    },
    {
      "citation_id": "21",
      "title": "Empathy and emotional intelligence: What is it really about?",
      "authors": [
        "Flora Ioannidou",
        "Vaya Konstantikaki"
      ],
      "year": "2008",
      "venue": "International Journal of caring sciences"
    },
    {
      "citation_id": "22",
      "title": "The levels of emotional awareness scale: A cognitivedevelopmental measure of emotion",
      "authors": [
        "Donald Richard D Lane",
        "Gary Quinlan",
        "Pamela Schwartz",
        "Sharon Walker",
        "Zeitlin"
      ],
      "year": "1990",
      "venue": "Journal of personality assessment"
    },
    {
      "citation_id": "23",
      "title": "A systematic study and comprehensive evaluation of ChatGPT on benchmark datasets",
      "authors": [
        "Md Tahmid Rahman Laskar",
        "M Saiful Bari",
        "Mizanur Rahman",
        "Md Amran Hossen Bhuiyan",
        "Shafiq Joty",
        "Jimmy Huang"
      ],
      "year": "2023",
      "venue": "Findings of the Association for Computational Linguistics: ACL 2023"
    },
    {
      "citation_id": "24",
      "title": "Measuring empathy: reliability and validity of the empathy quotient",
      "authors": [
        "Emma J Lawrence",
        "Philip Shaw",
        "Dawn Baker",
        "Simon Baron-Cohen",
        "Anthony David"
      ],
      "year": "2004",
      "venue": "Psychological medicine"
    },
    {
      "citation_id": "25",
      "title": "Large language models produce responses perceived to be empathic",
      "authors": [
        "Kyung Yoon",
        "Jina Lee",
        "Hongli Suh",
        "Junyi Zhan",
        "Jessy Li",
        "Desmond Ong"
      ],
      "year": "2024",
      "venue": "Large language models produce responses perceived to be empathic",
      "arxiv": "arXiv:2403.18148"
    },
    {
      "citation_id": "26",
      "title": "Does gpt-3 generate empathetic dialogues? a novel in-context example selection method and automatic evaluation metric for empathetic dialogue generation",
      "authors": [
        "Young-Jun Lee",
        "Chae-Gyun Lim",
        "Ho-Jin Choi",
        "Siru Liu",
        "Allison Mccoy",
        "Aileen Wright",
        "Babatunde Carew",
        "Julian Genkins",
        "Sean Huang",
        "Josh Peterson",
        "Bryan Steitz",
        "Adam Wright"
      ],
      "year": "2022",
      "venue": "Proceedings of the 29th International Conference on Computational Linguistics"
    },
    {
      "citation_id": "27",
      "title": "Artificial empathy in marketing interactions: Bridging the human-ai gap in affective and social customer experience",
      "authors": [
        "Yuping Liu-Thompkins",
        "Shintaro Okazaki",
        "Hairong Li"
      ],
      "year": "2022",
      "venue": "Journal of the Academy of Marketing Science"
    },
    {
      "citation_id": "28",
      "title": "Harnessing large language models' empathetic response generation capabilities for online mental health counselling support",
      "authors": [
        "Brandon Siyuan",
        "Aravind Loh",
        "Sesagiri"
      ],
      "year": "2023",
      "venue": "Harnessing large language models' empathetic response generation capabilities for online mental health counselling support",
      "arxiv": "arXiv:2310.08017"
    },
    {
      "citation_id": "29",
      "title": "The chi-square test of independence",
      "authors": [
        "Mary Mchugh"
      ],
      "year": "2013",
      "venue": "Biochemia medica"
    },
    {
      "citation_id": "30",
      "title": "Mixtral of experts",
      "authors": [
        "Mistralai"
      ],
      "year": "2024",
      "venue": "Mixtral of experts"
    },
    {
      "citation_id": "31",
      "title": "Selecting a within-or between-subject design for mediation: Validity, causality, and statistical power",
      "authors": [
        "Amanda Montoya"
      ],
      "year": "2023",
      "venue": "Multivariate Behavioral Research"
    },
    {
      "citation_id": "32",
      "title": "",
      "authors": [
        "Openai"
      ],
      "year": "2023",
      "venue": ""
    },
    {
      "citation_id": "33",
      "title": "Zak Evernden, and Ekaterina Damer. 2022. Data quality of platforms and panels for online behavioral research",
      "authors": [
        "Eyal Peer",
        "David Rothschild",
        "Andrew Gordon"
      ],
      "venue": "Behavior Research Methods"
    },
    {
      "citation_id": "34",
      "title": "Introducing gemini: Our largest and most capable ai model",
      "authors": [
        "Sundar Pichai"
      ],
      "year": "2023",
      "venue": "Introducing gemini: Our largest and most capable ai model"
    },
    {
      "citation_id": "35",
      "title": "Emotions: A general psychoevolutionary theory. Approaches to emotion",
      "authors": [
        "Robert Plutchik"
      ],
      "year": "1984",
      "venue": "Emotions: A general psychoevolutionary theory. Approaches to emotion"
    },
    {
      "citation_id": "36",
      "title": "Situational determinants of cognitive, affective, and compassionate empathy in naturalistic digital interactions",
      "authors": [
        "A Philip",
        "Jennifer Powell",
        "Roberts"
      ],
      "year": "2017",
      "venue": "Computers in Human Behavior"
    },
    {
      "citation_id": "37",
      "title": "Harnessing the power of large language models for empathetic response generation: Empirical investigations and improvements",
      "authors": [
        "Yushan Qian",
        "Wei-Nan Zhang",
        "Ting Liu"
      ],
      "year": "2023",
      "venue": "Harnessing the power of large language models for empathetic response generation: Empirical investigations and improvements",
      "arxiv": "arXiv:2310.05140"
    },
    {
      "citation_id": "38",
      "title": "Towards empathetic opendomain conversation models: A new benchmark and dataset",
      "authors": [
        "Eric Hannah Rashkin",
        "Margaret Smith",
        "Y-Lan Li",
        "Boureau"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "39",
      "title": "Exploring chatgpt's empathic abilities",
      "authors": [
        "Kristina Schaaff",
        "Caroline Reinig",
        "Tim Schlippe"
      ],
      "year": "2023",
      "venue": "Exploring chatgpt's empathic abilities",
      "arxiv": "arXiv:2308.03527"
    },
    {
      "citation_id": "40",
      "title": "A computational approach to understanding empathy expressed in text-based mental health support",
      "authors": [
        "Ashish Sharma",
        "Adam Miner",
        "David Atkins",
        "Tim Althoff"
      ],
      "year": "2020",
      "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
      "doi": "10.18653/v1/2020.emnlp-main.425"
    },
    {
      "citation_id": "41",
      "title": "A computational approach to understanding empathy expressed in text-based mental health support",
      "authors": [
        "Ashish Sharma",
        "Adam Miner",
        "David Atkins",
        "Tim Althoff"
      ],
      "year": "2020",
      "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
      "doi": "10.18653/v1/2020.emnlp-main.425"
    },
    {
      "citation_id": "42",
      "title": "Research methods in psychology",
      "authors": [
        "John J Shaughnessy",
        "Eugene Zechmeister",
        "Jeanne Zechmeister"
      ],
      "year": "2000",
      "venue": "Research methods in psychology"
    },
    {
      "citation_id": "43",
      "title": "Neural representations of emotion are organized around abstract event features",
      "authors": [
        "Amy Skerry",
        "Rebecca Saxe"
      ],
      "year": "2015",
      "venue": "Current biology"
    },
    {
      "citation_id": "44",
      "title": "The toronto empathy questionnaire: Scale development and initial validation of a factor-analytic solution to multiple empathy measures",
      "authors": [
        "Nathan Spreng",
        "Margaret Mckinnon",
        "Raymond Mar",
        "Brian Levine"
      ],
      "year": "2009",
      "venue": "Journal of personality assessment"
    },
    {
      "citation_id": "45",
      "title": "The social perception of humanoid and non-humanoid robots: Effects of gendered and machinelike features",
      "authors": [
        "J Steven",
        "Jonathan Stroessner",
        "Benitez"
      ],
      "year": "2019",
      "venue": "ACM Transactions on Interactive Intelligent Systems"
    },
    {
      "citation_id": "46",
      "title": "Open foundation and fine-tuned chat models",
      "authors": [
        "Hugo Touvron",
        "Louis Martin",
        "Kevin Stone",
        "Peter Albert",
        "Amjad Almahairi",
        "Yasmine Babaei",
        "Nikolay Bashlykov",
        "Soumya Batra",
        "Prajjwal Bhargava",
        "Shruti Bhosale"
      ],
      "year": "2023",
      "venue": "Open foundation and fine-tuned chat models",
      "arxiv": "arXiv:2307.09288"
    },
    {
      "citation_id": "47",
      "title": "A taxonomy of empathetic response intents in human social conversations",
      "authors": [
        "Anuradha Welivita",
        "Pearl Pu"
      ],
      "year": "2020",
      "venue": "Proceedings of the 28th International Conference on Computational Linguistics"
    },
    {
      "citation_id": "48",
      "title": "Glm-130b: An open bilingual pre-trained model",
      "authors": [
        "Aohan Zeng",
        "Xiao Liu",
        "Zhengxiao Du",
        "Zihan Wang",
        "Hanyu Lai",
        "Ming Ding",
        "Zhuoyi Yang",
        "Yifan Xu",
        "Wendi Zheng",
        "Xiao Xia"
      ],
      "year": "2022",
      "venue": "Glm-130b: An open bilingual pre-trained model",
      "arxiv": "arXiv:2210.02414"
    },
    {
      "citation_id": "49",
      "title": "Is chatgpt equipped with emotional dialogue capabilities? arXiv preprint",
      "authors": [
        "Weixiang Zhao",
        "Yanyan Zhao",
        "Xin Lu",
        "Shilong Wang",
        "Yanpeng Tong",
        "Bing Qin"
      ],
      "year": "2023",
      "venue": "Is chatgpt equipped with emotional dialogue capabilities? arXiv preprint",
      "arxiv": "arXiv:2304.09582"
    },
    {
      "citation_id": "50",
      "title": "Through the lens of core competency: Survey on evaluation of large language models",
      "authors": [
        "Zhuang Ziyu",
        "Chen Qiguang",
        "Ma Longxuan",
        "Li Mingda",
        "Han Yi",
        "Qian Yushan",
        "Bai Haopeng",
        "Zhang Weinan",
        "Ting Liu"
      ],
      "year": "2023",
      "venue": "Proceedings of the 22nd Chinese National Conference on Computational Linguistics"
    },
    {
      "citation_id": "51",
      "title": "I enjoy making other people feel better",
      "venue": "I enjoy making other people feel better"
    },
    {
      "citation_id": "52",
      "title": "I have tender, concerned feelings for people less fortunate than me 7. When a friend starts to talk about his or her problems, I try to steer the conversation towards something else *",
      "venue": "I have tender, concerned feelings for people less fortunate than me 7. When a friend starts to talk about his or her problems, I try to steer the conversation towards something else *"
    },
    {
      "citation_id": "53",
      "title": "I find that I am \"in tune",
      "venue": "I find that I am \"in tune"
    },
    {
      "citation_id": "54",
      "title": "I do not feel sympathy for people who cause their own serious illnesses * 11. I become irritated when someone cries *",
      "venue": "I do not feel sympathy for people who cause their own serious illnesses * 11. I become irritated when someone cries *"
    },
    {
      "citation_id": "55",
      "title": "When I see someone being taken advantage of, I feel kind of protective towards him or her Table 5: The Toronto Empathy Questionnaire",
      "authors": [
        "Spreng"
      ],
      "year": "2009",
      "venue": "When I see someone being taken advantage of, I feel kind of protective towards him or her Table 5: The Toronto Empathy Questionnaire"
    },
    {
      "citation_id": "56",
      "title": "Prompt These days I feel like I got it all. I'm not rich by any means but I am enriched by a loving wife, children and a dog",
      "venue": "Prompt These days I feel like I got it all. I'm not rich by any means but I am enriched by a loving wife, children and a dog"
    },
    {
      "citation_id": "57",
      "title": "Human I think I have a problem with jealousy because it's starting all over again. What sort of dog do you have? (Bad) GPT That sounds wonderful! It's heartwarming to hear how much you value your family and your life. Love and happiness truly are the richest treasures",
      "venue": "Human I think I have a problem with jealousy because it's starting all over again. What sort of dog do you have? (Bad) GPT That sounds wonderful! It's heartwarming to hear how much you value your family and your life. Love and happiness truly are the richest treasures"
    },
    {
      "citation_id": "58",
      "title": "LLaMA It sounds like you have a beautiful family and a fulfilling life. It's great to hear that you have found such joy and love in your life",
      "venue": "LLaMA It sounds like you have a beautiful family and a fulfilling life. It's great to hear that you have found such joy and love in your life"
    },
    {
      "citation_id": "59",
      "title": "Gemini I can understand why you feel so fulfilled. Having a loving family and a pet can bring immense joy and contentment. It sounds like you have a strong support system that makes you feel loved and appreciated",
      "venue": "Gemini I can understand why you feel so fulfilled. Having a loving family and a pet can bring immense joy and contentment. It sounds like you have a strong support system that makes you feel loved and appreciated"
    },
    {
      "citation_id": "60",
      "title": "Mixtral That's wonderful to hear that you feel enriched by your loving family! Cherish these moments, as they bring joy and fulfillment to life. I'm here if you ever need to talk about anything else",
      "venue": "Mixtral That's wonderful to hear that you feel enriched by your loving family! Cherish these moments, as they bring joy and fulfillment to life. I'm here if you ever need to talk about anything else"
    },
    {
      "citation_id": "61",
      "title": "that sounds like a hectic week! It's great that you're taking time to relax and enjoy the comfort of your home. I bet your dogs are loving the extra attention too",
      "authors": [
        "Gpt Wow"
      ],
      "venue": "that sounds like a hectic week! It's great that you're taking time to relax and enjoy the comfort of your home. I bet your dogs are loving the extra attention too"
    },
    {
      "citation_id": "62",
      "title": "LLaMA Wow, that sounds like a whirlwind week! It's great that you're taking some time to unwind and enjoy the AC with your furry friends",
      "venue": "LLaMA Wow, that sounds like a whirlwind week! It's great that you're taking some time to unwind and enjoy the AC with your furry friends"
    },
    {
      "citation_id": "63",
      "title": "Gemini I can understand why you're feeling relieved and content after a hectic week. It's wonderful that you can now unwind at home in the comfort of the air conditioning, and it's heartwarming to know that your dogs are also enjoying the relaxation",
      "venue": "Gemini I can understand why you're feeling relieved and content after a hectic week. It's wonderful that you can now unwind at home in the comfort of the air conditioning, and it's heartwarming to know that your dogs are also enjoying the relaxation"
    },
    {
      "citation_id": "64",
      "title": "Mixtral I'm glad to hear that you're finally getting some well-deserved rest after a hectic week. It sounds like those four events were quite demanding, and it's completely understandable that you're thrilled to be at home now. Your dogs must be delighted to be relaxing with you in the cool air conditioning! Take all the time you need to recharge and enjoy this precious downtime",
      "venue": "Mixtral I'm glad to hear that you're finally getting some well-deserved rest after a hectic week. It sounds like those four events were quite demanding, and it's completely understandable that you're thrilled to be at home now. Your dogs must be delighted to be relaxing with you in the cool air conditioning! Take all the time you need to recharge and enjoy this precious downtime"
    },
    {
      "citation_id": "65",
      "title": "Prompt I had a difficult job interview this week. (Apprehensive) Responses: Human Don't think about it, what is done is done, just anticipate that they will call you back, the universe have it's way of helping if we believe",
      "venue": "Prompt I had a difficult job interview this week. (Apprehensive) Responses: Human Don't think about it, what is done is done, just anticipate that they will call you back, the universe have it's way of helping if we believe"
    },
    {
      "citation_id": "66",
      "title": "m really sorry to hear that you had a tough time with your job interview. It's completely normal to feel this way. Remember, each interview is a learning experience. Don't be too hard on yourself. (Good) LLaMA Sorry to hear that. It can be really tough when job interviews don't go as planned. It's understandable to feel frustrated and disappointed",
      "authors": [
        "Gpt I'"
      ],
      "venue": "m really sorry to hear that you had a tough time with your job interview. It's completely normal to feel this way. Remember, each interview is a learning experience. Don't be too hard on yourself. (Good) LLaMA Sorry to hear that. It can be really tough when job interviews don't go as planned. It's understandable to feel frustrated and disappointed"
    },
    {
      "citation_id": "67",
      "title": "Gemini I understand that job interviews can be stressful and challenging. It's important to remember that you are not alone in this experience and that many people feel anxious during interviews. I'm here to listen if you",
      "venue": "Gemini I understand that job interviews can be stressful and challenging. It's important to remember that you are not alone in this experience and that many people feel anxious during interviews. I'm here to listen if you"
    },
    {
      "citation_id": "68",
      "title": "Mixtral I'm really sorry to hear that you had a tough job interview this week. It's completely normal to feel anxious or disappointed after an important event like that. Just know that you have the skills and experience necessary to succeed, and that every interview is a valuable learning experience. I'm here for you if you need to talk or want to practice for next time",
      "venue": "Mixtral I'm really sorry to hear that you had a tough job interview this week. It's completely normal to feel anxious or disappointed after an important event like that. Just know that you have the skills and experience necessary to succeed, and that every interview is a valuable learning experience. I'm here for you if you need to talk or want to practice for next time"
    }
  ]
}