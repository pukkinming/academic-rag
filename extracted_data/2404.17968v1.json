{
  "paper_id": "2404.17968v1",
  "title": "Usefulness Of Emotional Prosody In Neural Machine Translation",
  "published": "2024-04-27T18:04:28Z",
  "authors": [
    "Charles Brazier",
    "Jean-Luc Rouas"
  ],
  "keywords": [
    "Neural Machine Translation",
    "Speech Emotion Recognition",
    "Neural Networks"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Neural Machine Translation (NMT) is the task of translating a text from one language to another with the use of a trained neural network. Several existing works aim at incorporating external information into NMT models to improve or control predicted translations (e.g. sentiment, politeness, gender). In this work, we propose to improve translation quality by adding another external source of information: the automatically recognized emotion in the voice. This work is motivated by the assumption that each emotion is associated with a specific lexicon that can overlap between emotions. Our proposed method follows a two-stage procedure. At first, we select a state-of-theart Speech Emotion Recognition (SER) model to predict dimensional emotion values from all input audio in the dataset. Then, we use these predicted emotions as source tokens added at the beginning of input texts to train our NMT model. We show that integrating emotion information, especially arousal, into NMT systems leads to better translations.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Machine Translation (MT) is the task of translating a text from one language to another. Existing methods are originally based on rule-based or statistical approaches. More recently, end-toend neural networks have demonstrated their efficiency in the task  [1, 2] , outperforming earlier methods  [3] , and leading to the emergence of the Neural Machine Translation (NMT) task.\n\nTransformer-based architectures  [4]  are widely used in NMT, leading to state-of-the-art performances for several language pairs. Transformers are sequence-to-sequence models composed of an encoder that reads the input sequence and generates a representation of it, a decoder that generates the output sequence based on the input representation, and self-attention mechanisms that enable the use of the entire input sequence for each output prediction.\n\nSeveral works in the domain focused on the control of the translation given by existing NMT models. In fact, most NMT models aim to generate a single correct translation of a given sentence. However, the translation can be dependent on specific information that may be missing in the input sentence. For example, translations are dependent on the speaker's gender that may not be specified in the source language, or even some words can be translated differently depending on the context. For this purpose, several models propose solutions to improve translation quality by controlling sentiment  [5] , politeness  [6] , gender  [7, 8] , style of translators  [9] , or output language in the case of a multilingual setup  [10] .\n\nIn this work, we propose to improve translation quality by adding another external source of information: the automatically recognized emotion in the voice. This work is motivated by the assumption that each emotion is associated with a specific lexicon that can overlap between emotions. One possible approach to estimate the emotion of a specific sentence is to use affective word lists that classify individual words into emotion categories  [11]  or rate them on emotion dimension scales for arousal, dominance, and valence  [12] . However, the emotion of words is dependent on the entire sentence context  [13] . Additionally, word lists are not exhaustive and are specific to particular languages. In the following, we focus on the prosody of the pronounced sentences present in audio recordings to estimate emotion.\n\nTo this end, we first select a state-of-the-art Speech Emotion Recognition (SER) model to predict dimensional emotion values from audio recordings. Then, we use these predicted emotions as source tokens added at the beginning of input texts to train our NMT model. We show that integrating emotion information, especially arousal, into NMT systems leads to better translations.\n\nIn this paper, existing works adding external information to NMT models will be presented in Section 2. The selected stateof-the-art SER model and our proposed emotion-aware NMT pipeline will be described in Section 3. Experiments and results will be presented and discussed in Section 4. Section 5 will conclude the work.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Related Works",
      "text": "Existing works aiming at incorporating external information into NMT models to improve or control translation quality are numerous. They generally involve a two-stage procedure. At first, the external information is translated into a special token with the help of manual or automatic annotations. Then, the special token is added into the NMT model to control translation.\n\nIn the case of sentiment, Si et al.  [5]  use a trained sentiment classifier to label ambiguous words with positive or negative tags. Then, the authors incorporate the sentiment information into the source sentence either at the beginning or directly before the ambiguous word. They also try to use two different embedding vectors for each ambiguous word and select the correct embedding depending on the desired sentiment.\n\nIn the case of politeness, Sennrich et al.  [6]  automatically annotate politeness (informal/polite) using linguistic rules and add the special token at the end of the source sentence.\n\nIn the case of gender, Vanmassenhove et al.  [7]  extract gender information (male/female) from meta data present in their dataset and use it as additional token added at the beginning of the source sentence.\n\nIn the case of translation style, Wang et al.  [9]  use the data translated by 10 translators and incorporate the translator token at the beginning of input sentences, or add the embedded translator token to every token in the encoder. They also try to add the translator information directly into the decoder but this solution seems ineffective.\n\nIn the case of a multilingual scenario, Johnson et al.  [10]  add an artificial token at the beginning of input sentences to arXiv:2404.17968v1 [cs.CL] 27 Apr 2024 specify the desired target language.\n\nOur approach aims at enhancing translation quality by adding emotion information into text sentences. Emotion is automatically extracted from audio data (recordings or synthesized text) with the help of a trained SER model and added to source sentences at the beginning as an additional emotion token.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Emotion Aware Neural Machine Translation",
      "text": "In this work, we propose to combine SER classifier and NMT models to improve translation quality.\n\nTo the best of our knowledge, the only work that combines an emotion classifier with an NMT model is presented by Troiano et al.  [14] . The authors introduce a method to preserve emotion during automatic translation by re-ranking the best translations generated by an NMT model, according to a trained emotion classifier. Due to the lack of comparable emotion classifiers for different languages, they adopt a backtranslation setup that re-translates the best translation hypotheses and re-rank them to preserve the same emotion between the input sentence and its translated translations. The re-ranking is performed as a post-processing step and not as a fine-tuning procedure for the NMT model.\n\nIn contrast to  [14] , we aim at improving translation quality by using the output of a pre-trained emotion classifier in the NMT training step.\n\nOur proposed method follows a two-stage procedure. At first, a trained Speech Emotion Recognition (SER) model predicts dimensional emotion values from all input audio in the dataset. Then, these predicted values are converted into discrete tokens and added at the beginning of input texts. Finally, we train various NMT models by varying the utilized emotion token and extraction method (whether it is predicted from original or synthesized recordings).",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Speech Emotion Recognition",
      "text": "Automatic Speech Emotion Recognition (SER) is the task of predicting emotion from speech recordings. SER models can predict discrete categories such as happy, sad, etc., or continuous emotional dimensions like arousal, valence, and dominance. The three emotional dimensions are described as follows:\n\n• Arousal refers to the level of stimulation or activation associated with an emotion. It ranges from low arousal (calm, relaxed) to high arousal (excited, agitated). Emotions like excitement, anxiety, and surprise typically have higher arousal levels, while calmness and relaxation have lower arousal levels.\n\n• Valence represents the positive or negative nature of an emotion. Emotions can be categorized on a scale from positive (happy, joyful) to negative (sad, angry). Valence indicates whether an emotion is pleasant or unpleasant, with positive valence indicating positive emotions and negative valence indicating negative emotions.\n\n• Dominance refers to the level of control or power associated with an emotion. It measures whether an emotion makes an individual feel dominant or submissive in a particular situation. Emotions with high dominance might include feelings of confidence, assertiveness, or control, while low dominance emotions might involve feelings of submission or helplessness.\n\nThese dimensions are often used in psychology and neuroscience to help understand and categorize emotions, providing a more nuanced view of the complex nature of human feelings and experiences.\n\nFor our experiments, we select a state-of-the-art transformer-based SER model proposed by Wagner et al.  [15] . This model is based on the wav2vec2.0  [16]  model which learns powerful speech representations from unlabelled speech data. Wav2vec2.0 is composed of 7 Convolutional Neural Networks (CNN) layers of feature encoder and 12 transformer layers of encoder including multi-head self-attention modules and fully-connected layers. Wagner et al. add one average pooling layer, one hidden layer, and one output layer of length 3 at the end of the network to classify each raw waveform into three emotion dimensions corresponding to arousal, dominance, and valence. The three output values range from 0 to 1.\n\nDuring training, the authors freeze the CNN layers and only fine-tune transformer layers with the added layers on top of the model. The fine-tuning step is performed on the MSP-Podcast  [17]  dataset (train split) for training, and tested on MSP-Podcast (test-1 split), IEMOCAP  [18] , and MOSI  [19] . All three corpora contain audio recordings with corresponding dimensional emotion values that are normalized between 0 and 1. Model performances are evaluated with the Concordance Correlation Coefficient (CCC)  [20] . The authors report a CCC of .744 for arousal, .655 for dominance, and .638 for valence, on the MSP-Podcast dataset.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Neural Machine Translation",
      "text": "Neural Machine Translation (NMT) is the task of translating a text from one language to another. As model for our experiments, we selected a transformer-based encoder-decoder architecture developed with the ESPnet toolkit  [21] . The model is composed of an encoder of 6 transformer layers, a decoder of 6 transformer layers, and 4 attention heads in each self-attention layers. The model is end-to-end meaning that it receives text as input and outputs text. All textual sentences are tokenized into sub-word sequences using a byte-pair encoding algorithm with 1000 units.\n\nThe model is trained on the Libri-trans  [22]  dataset, a dataset that contains speech recordings and corresponding transcripts in English and French. The dataset is divided into train, dev, and test sets whose durations are respectively 230, 2, and 3.5 hours. In this work, we focus on text-to-text translation from English to French.\n\nThe model is evaluated with BiLingual Evaluation Understudy (BLEU) score, a metric that measures the similarity between generated translations and corresponding groundtruth. Its calculation includes a brevity penalty, penalizing generated translations shorter than their references, and a n-gram precision factor that considers various n-grams (including unigrams, bigrams, etc.) and counts the number of n-grams from the generated translation that also appear in the reference translation. The BLEU score is a value between 0 (poor translation) and 100 (perfect translation). Note that a translation with a BLEU score higher than 40 is generally considered as a high-quality translation. We report BLEU using SacreBLEU  [23] .",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Emotion Aware Neural Machine Translation",
      "text": "To improve the translation quality of our NMT model, we propose to incorporate the emotion information extracted from input recordings into their corresponding input text sequences.\n\nThe emotion information is represented as an additional token representing the polarity over a specific emotion dimension. We use the tokens <AroNeg> and <AroPos> for recordings that have an arousal score lower or higher than 0.5 respectively, as well as <DomNeg> and <DomPos> for dominance, and <ValNeg> and <ValPos> for valence.\n\nFor example, consider the following pair of English and French sentences:\n\nI am quite foolish → Je suis toute sotte In the case of valence, the pair will be modified to: <ValNeg> I am quite foolish → Je suis toute sotte\n\nThe proposed method offers several advantages. Firstly, it does not necessitate any changes in the model architecture nor in the set of translated sequences. Model performances with and without the additional token can be directly compared. Furthermore, the approach is simple yet effective, showcasing progress in various domains  [5, 6, 7, 9, 10] . It only involves the addition of an extra token at the beginning of each input sentence. Lastly, the method does not require any additional manual annotation, as the emotion is automatically extracted from the SER model.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Experiments And Results",
      "text": "In this section, we conduct a set of experiments to compare NMT performances under different configurations. Firstly, we analyze the statistical distribution of values provided by the SER model on the Libri-trans dataset for the three emotion dimensions. Secondly, we train four different NMT models that are a baseline model, and three different models that use the arousal, dominance, and valence information respectively.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Emotion Recognition On Libri-Trans",
      "text": "Our proposed method starts with the computation of emotional dimensions for each English sentence in the Libri-trans dataset. These values will be later used for the English-to-French textto-text translation task.\n\nDue to the modality mismatch between the text-to-text task and the required raw audio waveform as input for our SER model, we propose two different ways to compute emotion values. The first method involves using audio recordings that are already present in the Libri-trans dataset to evaluate emotion values. This represents the most accurate method to estimate emotion; however, it implies the use of additional data in the translation pipeline. Statistical distributions of emotion values on original audio recordings from the Libri-trans dataset are illustrated in Figure  1 . We showcase statistical distributions for each train, dev, and test subset of the Libri-trans dataset. We remark that, for the three emotional dimensions and each subset, statistical distributions are balanced, medians are around 0.5 and values range from 0.1 to 0.9. Due to the acceptable balance of dimensional emotion scores provided by our selected SER, we consider the initial train, dev, and test splits as good candidates for the translation task conditioned with emotion information.\n\nThe second method involves synthesizing each English text with the help of the Google Text-to-Speech API 1 . This method has the advantage of using only text data; however, the original emotion can be altered with a neutral rendering. Statistical distributions of emotion values on synthesized audio of all English text are illustrated in Figure  2 . We observe that arousal values are concentrated around 0.5, indicating that synthesizing audio files produces neutral arousal. Also, we remark that almost all 1 https://gtts.readthedocs.io/en/latest/ dominance values are above 0.5. Thus, using synthesized audio to estimate dominance is inefficient. However, valence values are more distributed, reflecting the fact that valence is captured in the vocabulary used in each English sentence. As an additional observation, the medians of arousal and valence values across all Libri-trans subsets are close to 0.5, enabling an automatically balanced dataset for training.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Neural Machine Translation On Libri-Trans",
      "text": "The computation of emotion values on English data from Libritrans enables the assignment of a specific dimension polarity for each input sentence. This is reflected by the addition of an extra token at the beginning of each input text.\n\nIn the following experiments, we compare four different NMT models. The first model, baseline, is trained without the use of an emotion token and serves as a reference to improve its translation score. The second, third, and fourth models, namely arousal, dominance, and valence, are NMT models trained with the addition of a special token at the beginning of each English sentence representing the polarity (positive or negative) of their corresponding emotion dimension.\n\nWe also conduct two sets of experiments, one using tokens extracted from original audio recordings and the other using those extracted from synthesized audio.\n\nAll models have the exact same structure. They are trained with a label-smoothing loss, a Noam optimizer, a dropout rate of 0.1, an inverse square root scheduler with 8000 warm-up steps, and a batch size of 96. Each transformer model is trained during 250 epochs and the 5 best MT models are averaged to create the best model. Each training session takes approximately 15 hours on a single NVIDIA A100 GPU.\n\nTable  1  showcases the results of our different experiments. In this table, we report BLEU scores of 8 different experiments. It gathers the evaluation of our four proposed models, evaluated on the development and test sets of Libri-trans, with the emotion token computed either from the synthesized text or the audio recordings directly.  Regarding the baseline model, we emphasize that it does not include any additional token, and thus, BLEU scores are insensitive to the type of modality used to extract the emotion token and are respectively 20.1 and 18.2 on the dev and test sets.\n\nIn comparison with the baseline performances, we observe that the addition of the emotion token computed from real speech leads to a noticeable improvement for arousal, with a BLEU score of 18.6 on the test set of Libri-trans, and there is no degradation in BLEU score for dominance and valence, with BLEU scores of 18.3 and 18.2 respectively. These results show that the arousal information seems to be a promising factor to enhance translation quality. The best performances are achieved when using the arousal information, which has been automatically estimated from real speech, resulting in a 0.4-point improvement in the BLEU score.\n\nWhen the emotion token is computed from synthesized text, we observe a slight improvement in the BLEU score for arousal. However, for dominance, we notice a slight degradation in the BLEU score. As mentioned earlier, dominance value estimations on synthesized audio almost always provide a value higher than 0.5. Thus, we anticipated a BLEU score lower or equal to the baseline, as no additional information is introduced to the NMT model. Finally, the highest deterioration in BLEU score is observed for valence.\n\nUsing emotion tokens extracted from real speech always leads to better BLEU scores than when using tokens from synthesized speech. We observed that, with synthesized audio, emotion value estimations become neutral in the case of arousal and dominance, and translation quality is degraded. Therefore, it appears crucial to use real audio recordings to estimate emotion and improve translation quality.\n\nIn addition, we note that all BLEU scores presented in Table 1 are consistently low, indicating poor translation quality for all proposed models, including the baseline. This is due to the nature of the data within the Libri-trans dataset, which comprises English utterances extracted from books. Audios are recorded from readers, and the vocabulary in the texts differs significantly from the language commonly spoken in real-world interactions.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Conclusion",
      "text": "We proposed an innovative method that combines SER with NMT models to improve translation quality. Our method is fully automatic and does not require any manual annotation. The proposed method is simple, effective, and enables the direct comparison between models. The best performances were achieved by adding the arousal token extracted from real speech at the start of each input sentence.\n\nThis study only presents the first experiment on combining SER and NMT models to improve translation. Additional experiments can be conducted, such as using the three emotional dimensions to condition each source sentence, switching languages (translating from French to English), testing the method on other multilingual datasets including MuST-C, or visualizing the embedding of the NMT model to get a better understanding on how vocabulary related to a specific emotion is clustered. Moreover, different methods to include the emotion information can be tested, such as adding the embedding of the emotion token to all token embeddings.\n\nIn this work, we incorporate real speech recordings as an additional modality to estimate emotion. Introducing the audio modality into the translation task also enables to perform speech-to-text translation, known as Speech Translation. Consequently, exploring the conditioning of Speech Translation models with emotion as additional information would be valuable.",
      "page_start": 4,
      "page_end": 4
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: We showcase statistical distributions for",
      "page": 3
    },
    {
      "caption": "Figure 2: We observe that arousal values",
      "page": 3
    },
    {
      "caption": "Figure 1: Statistical distribution of emotion values on original",
      "page": 3
    },
    {
      "caption": "Figure 2: Statistical distribution of emotion values on synthe-",
      "page": 4
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "charles.brazier@u-bordeaux.fr"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "Abstract"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "Neural Machine Translation (NMT)\nis\nthe task of\ntranslating"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "a text\nfrom one language to another with the use of a trained"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "neural network.\nSeveral existing works aim at\nincorporating"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "external\ninformation into NMT models to improve or control"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "predicted translations (e.g.\nsentiment, politeness, gender).\nIn"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "this work, we propose to improve translation quality by adding"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "another external source of information:\nthe automatically rec-"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "ognized emotion in the voice.\nThis work is motivated by the"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "assumption that each emotion is associated with a specific lex-"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "icon that can overlap between emotions. Our proposed method"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "follows a two-stage procedure. At first, we select a state-of-the-"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "art Speech Emotion Recognition (SER) model to predict dimen-"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "sional emotion values from all input audio in the dataset. Then,"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "we use these predicted emotions as source tokens added at\nthe"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "beginning of input texts to train our NMT model. We show that"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "integrating emotion information, especially arousal,\ninto NMT"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "systems leads to better translations."
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "Index Terms: Neural Machine Translation, Speech Emotion"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "Recognition, Neural Networks."
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": ""
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": ""
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "1.\nIntroduction"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "Machine Translation (MT) is the task of translating a text from"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": ""
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "one language to another. Existing methods are originally based"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "on rule-based or statistical approaches. More recently, end-to-"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "end neural networks have demonstrated their efficiency in the"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "task [1, 2], outperforming earlier methods [3], and leading to"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "the emergence of the Neural Machine Translation (NMT) task."
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "Transformer-based\narchitectures\n[4]\nare widely\nused\nin"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "NMT,\nleading to state-of-the-art performances for several\nlan-"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "guage pairs.\nTransformers are sequence-to-sequence models"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "composed of an encoder that reads the input sequence and gen-"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "erates a representation of it, a decoder that generates the output"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "sequence based on the input\nrepresentation, and self-attention"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "mechanisms that enable the use of the entire input sequence for"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "each output prediction."
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "Several works in the domain focused on the control of the"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "translation given by existing NMT models.\nIn fact, most NMT"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "models aim to generate a single correct\ntranslation of a given"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "sentence. However,\nthe translation can be dependent on spe-"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "cific information that may be missing in the input\nsentence."
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "For example, translations are dependent on the speaker’s gender"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "that may not be specified in the source language, or even some"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "words can be translated differently depending on the context."
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "For this purpose, several models propose solutions to improve"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "translation quality by controlling sentiment [5], politeness [6],"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "gender [7, 8], style of translators [9], or output\nlanguage in the"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "case of a multilingual setup [10]."
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "In this work, we propose to improve translation quality by"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "adding another external source of\ninformation:\nthe automati-"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "cally recognized emotion in the voice. This work is motivated"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "by the assumption that each emotion is associated with a spe-"
        },
        {
          "Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France": "cific lexicon that can overlap between emotions. One possible"
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "specify the desired target language.": "Our\napproach\naims\nat\nenhancing\ntranslation\nquality\nby",
          "These dimensions are often used in psychology and neuro-": "science to help understand and categorize emotions, providing"
        },
        {
          "specify the desired target language.": "adding emotion information into text\nsentences.\nEmotion is",
          "These dimensions are often used in psychology and neuro-": "a more nuanced view of the complex nature of human feelings"
        },
        {
          "specify the desired target language.": "automatically extracted from audio data (recordings or synthe-",
          "These dimensions are often used in psychology and neuro-": "and experiences."
        },
        {
          "specify the desired target language.": "sized text) with the help of a trained SER model and added to",
          "These dimensions are often used in psychology and neuro-": "For\nour\nexperiments,\nwe\nselect\na\nstate-of-the-art"
        },
        {
          "specify the desired target language.": "source sentences at\nthe beginning as an additional emotion to-",
          "These dimensions are often used in psychology and neuro-": "transformer-based\nSER model\nproposed\nby Wagner\net\nal."
        },
        {
          "specify the desired target language.": "ken.",
          "These dimensions are often used in psychology and neuro-": "[15]. This model is based on the wav2vec2.0 [16] model which"
        },
        {
          "specify the desired target language.": "",
          "These dimensions are often used in psychology and neuro-": "learns powerful speech representations from unlabelled speech"
        },
        {
          "specify the desired target language.": "",
          "These dimensions are often used in psychology and neuro-": "data.\nWav2vec2.0 is\ncomposed of 7 Convolutional Neural"
        },
        {
          "specify the desired target language.": "3. Emotion Aware Neural Machine",
          "These dimensions are often used in psychology and neuro-": ""
        },
        {
          "specify the desired target language.": "",
          "These dimensions are often used in psychology and neuro-": "Networks (CNN) layers of feature encoder and 12 transformer"
        },
        {
          "specify the desired target language.": "Translation",
          "These dimensions are often used in psychology and neuro-": ""
        },
        {
          "specify the desired target language.": "",
          "These dimensions are often used in psychology and neuro-": "layers of encoder\nincluding multi-head self-attention modules"
        },
        {
          "specify the desired target language.": "In this work, we propose to combine SER classifier and NMT",
          "These dimensions are often used in psychology and neuro-": "and fully-connected layers. Wagner et al.\nadd one average"
        },
        {
          "specify the desired target language.": "models to improve translation quality.",
          "These dimensions are often used in psychology and neuro-": "pooling layer, one hidden layer, and one output\nlayer of length"
        },
        {
          "specify the desired target language.": "To the best of our knowledge,\nthe only work that com-",
          "These dimensions are often used in psychology and neuro-": "3 at\nthe\nend of\nthe network to classify each raw waveform"
        },
        {
          "specify the desired target language.": "bines an emotion classifier with an NMT model\nis presented",
          "These dimensions are often used in psychology and neuro-": "into\nthree\nemotion\ndimensions\ncorresponding\nto\narousal,"
        },
        {
          "specify the desired target language.": "by Troiano et al.\n[14]. The authors introduce a method to pre-",
          "These dimensions are often used in psychology and neuro-": "dominance, and valence. The three output values range from 0"
        },
        {
          "specify the desired target language.": "serve emotion during automatic translation by re-ranking the",
          "These dimensions are often used in psychology and neuro-": "to 1."
        },
        {
          "specify the desired target language.": "best\ntranslations generated by an NMT model,\naccording to",
          "These dimensions are often used in psychology and neuro-": "During training, the authors freeze the CNN layers and only"
        },
        {
          "specify the desired target language.": "a trained emotion classifier.\nDue to the lack of comparable",
          "These dimensions are often used in psychology and neuro-": "fine-tune transformer layers with the added layers on top of the"
        },
        {
          "specify the desired target language.": "emotion classifiers for different\nlanguages,\nthey adopt a back-",
          "These dimensions are often used in psychology and neuro-": "model. The fine-tuning step is performed on the MSP-Podcast"
        },
        {
          "specify the desired target language.": "translation setup that re-translates the best\ntranslation hypothe-",
          "These dimensions are often used in psychology and neuro-": "[17] dataset (train split) for training, and tested on MSP-Podcast"
        },
        {
          "specify the desired target language.": "ses and re-rank them to preserve the same emotion between the",
          "These dimensions are often used in psychology and neuro-": "(test-1 split),\nIEMOCAP [18], and MOSI\n[19]. All\nthree cor-"
        },
        {
          "specify the desired target language.": "input sentence and its translated translations.\nThe re-ranking",
          "These dimensions are often used in psychology and neuro-": "pora contain audio recordings with corresponding dimensional"
        },
        {
          "specify the desired target language.": "is performed as a post-processing step and not as a fine-tuning",
          "These dimensions are often used in psychology and neuro-": "emotion values that are normalized between 0 and 1. Model"
        },
        {
          "specify the desired target language.": "procedure for the NMT model.",
          "These dimensions are often used in psychology and neuro-": "performances are evaluated with the Concordance Correlation"
        },
        {
          "specify the desired target language.": "In contrast to [14], we aim at improving translation quality",
          "These dimensions are often used in psychology and neuro-": "Coefficient (CCC) [20]. The authors report a CCC of .744 for"
        },
        {
          "specify the desired target language.": "by using the output of a pre-trained emotion classifier\nin the",
          "These dimensions are often used in psychology and neuro-": "arousal, .655 for dominance, and .638 for valence, on the MSP-"
        },
        {
          "specify the desired target language.": "NMT training step.",
          "These dimensions are often used in psychology and neuro-": "Podcast dataset."
        },
        {
          "specify the desired target language.": "Our proposed method follows a two-stage procedure. At",
          "These dimensions are often used in psychology and neuro-": ""
        },
        {
          "specify the desired target language.": "first, a trained Speech Emotion Recognition (SER) model pre-",
          "These dimensions are often used in psychology and neuro-": "3.2. Neural Machine Translation"
        },
        {
          "specify the desired target language.": "dicts dimensional emotion values from all\ninput audio in the",
          "These dimensions are often used in psychology and neuro-": ""
        },
        {
          "specify the desired target language.": "",
          "These dimensions are often used in psychology and neuro-": "Neural Machine Translation (NMT) is the task of translating a"
        },
        {
          "specify the desired target language.": "dataset. Then, these predicted values are converted into discrete",
          "These dimensions are often used in psychology and neuro-": ""
        },
        {
          "specify the desired target language.": "",
          "These dimensions are often used in psychology and neuro-": "text\nfrom one language to another. As model\nfor our experi-"
        },
        {
          "specify the desired target language.": "tokens and added at\nthe beginning of\ninput\ntexts.\nFinally, we",
          "These dimensions are often used in psychology and neuro-": ""
        },
        {
          "specify the desired target language.": "",
          "These dimensions are often used in psychology and neuro-": "ments, we selected a transformer-based encoder-decoder archi-"
        },
        {
          "specify the desired target language.": "train various NMT models by varying the utilized emotion to-",
          "These dimensions are often used in psychology and neuro-": ""
        },
        {
          "specify the desired target language.": "",
          "These dimensions are often used in psychology and neuro-": "tecture developed with the ESPnet\ntoolkit\n[21]. The model\nis"
        },
        {
          "specify the desired target language.": "ken and extraction method (whether it is predicted from original",
          "These dimensions are often used in psychology and neuro-": ""
        },
        {
          "specify the desired target language.": "",
          "These dimensions are often used in psychology and neuro-": "composed of an encoder of 6 transformer layers, a decoder of 6"
        },
        {
          "specify the desired target language.": "or synthesized recordings).",
          "These dimensions are often used in psychology and neuro-": ""
        },
        {
          "specify the desired target language.": "",
          "These dimensions are often used in psychology and neuro-": "transformer layers, and 4 attention heads in each self-attention"
        },
        {
          "specify the desired target language.": "",
          "These dimensions are often used in psychology and neuro-": "layers. The model is end-to-end meaning that it receives text as"
        },
        {
          "specify the desired target language.": "3.1.\nSpeech Emotion Recognition",
          "These dimensions are often used in psychology and neuro-": ""
        },
        {
          "specify the desired target language.": "",
          "These dimensions are often used in psychology and neuro-": "input and outputs text. All\ntextual sentences are tokenized into"
        },
        {
          "specify the desired target language.": "",
          "These dimensions are often used in psychology and neuro-": "sub-word sequences using a byte-pair encoding algorithm with"
        },
        {
          "specify the desired target language.": "Automatic Speech Emotion Recognition (SER)\nis the task of",
          "These dimensions are often used in psychology and neuro-": ""
        },
        {
          "specify the desired target language.": "",
          "These dimensions are often used in psychology and neuro-": "1000 units."
        },
        {
          "specify the desired target language.": "predicting emotion from speech recordings.\nSER models can",
          "These dimensions are often used in psychology and neuro-": ""
        },
        {
          "specify the desired target language.": "",
          "These dimensions are often used in psychology and neuro-": "The model\nis\ntrained on the Libri-trans\n[22] dataset,\na"
        },
        {
          "specify the desired target language.": "predict discrete categories such as happy, sad, etc., or continu-",
          "These dimensions are often used in psychology and neuro-": ""
        },
        {
          "specify the desired target language.": "",
          "These dimensions are often used in psychology and neuro-": "dataset that contains speech recordings and corresponding tran-"
        },
        {
          "specify the desired target language.": "ous emotional dimensions like arousal, valence, and dominance.",
          "These dimensions are often used in psychology and neuro-": ""
        },
        {
          "specify the desired target language.": "",
          "These dimensions are often used in psychology and neuro-": "scripts in English and French. The dataset is divided into train,"
        },
        {
          "specify the desired target language.": "The three emotional dimensions are described as follows:",
          "These dimensions are often used in psychology and neuro-": ""
        },
        {
          "specify the desired target language.": "",
          "These dimensions are often used in psychology and neuro-": "dev, and test sets whose durations are respectively 230, 2, and"
        },
        {
          "specify the desired target language.": "• Arousal\nrefers to the level of\nstimulation or activation",
          "These dimensions are often used in psychology and neuro-": ""
        },
        {
          "specify the desired target language.": "",
          "These dimensions are often used in psychology and neuro-": "3.5 hours. In this work, we focus on text-to-text translation from"
        },
        {
          "specify the desired target language.": "associated with an emotion.\nIt ranges from low arousal",
          "These dimensions are often used in psychology and neuro-": ""
        },
        {
          "specify the desired target language.": "",
          "These dimensions are often used in psychology and neuro-": "English to French."
        },
        {
          "specify the desired target language.": "(calm, relaxed) to high arousal (excited, agitated). Emo-",
          "These dimensions are often used in psychology and neuro-": ""
        },
        {
          "specify the desired target language.": "",
          "These dimensions are often used in psychology and neuro-": "The model\nis evaluated with BiLingual Evaluation Under-"
        },
        {
          "specify the desired target language.": "tions like excitement, anxiety, and surprise typically have",
          "These dimensions are often used in psychology and neuro-": ""
        },
        {
          "specify the desired target language.": "",
          "These dimensions are often used in psychology and neuro-": "study (BLEU) score, a metric that measures the similarity be-"
        },
        {
          "specify the desired target language.": "higher arousal levels, while calmness and relaxation have",
          "These dimensions are often used in psychology and neuro-": ""
        },
        {
          "specify the desired target language.": "",
          "These dimensions are often used in psychology and neuro-": "tween generated translations\nand corresponding groundtruth."
        },
        {
          "specify the desired target language.": "lower arousal levels.",
          "These dimensions are often used in psychology and neuro-": ""
        },
        {
          "specify the desired target language.": "",
          "These dimensions are often used in psychology and neuro-": "Its calculation includes a brevity penalty, penalizing generated"
        },
        {
          "specify the desired target language.": "• Valence represents the positive or negative nature of an",
          "These dimensions are often used in psychology and neuro-": "translations shorter\nthan their\nreferences, and a n-gram preci-"
        },
        {
          "specify the desired target language.": "emotion. Emotions can be categorized on a scale from",
          "These dimensions are often used in psychology and neuro-": "sion factor that considers various n-grams (including unigrams,"
        },
        {
          "specify the desired target language.": "positive (happy, joyful) to negative (sad, angry). Valence",
          "These dimensions are often used in psychology and neuro-": "bigrams, etc.) and counts the number of n-grams from the gen-"
        },
        {
          "specify the desired target language.": "indicates whether an emotion is pleasant or unpleasant,",
          "These dimensions are often used in psychology and neuro-": "erated translation that also appear in the reference translation."
        },
        {
          "specify the desired target language.": "with positive valence indicating positive emotions and",
          "These dimensions are often used in psychology and neuro-": "The BLEU score is a value between 0 (poor\ntranslation) and"
        },
        {
          "specify the desired target language.": "negative valence indicating negative emotions.",
          "These dimensions are often used in psychology and neuro-": "100 (perfect\ntranslation). Note that a translation with a BLEU"
        },
        {
          "specify the desired target language.": "",
          "These dimensions are often used in psychology and neuro-": "score higher\nthan 40 is generally considered as a high-quality"
        },
        {
          "specify the desired target language.": "• Dominance refers to the level of control or power asso-",
          "These dimensions are often used in psychology and neuro-": ""
        },
        {
          "specify the desired target language.": "",
          "These dimensions are often used in psychology and neuro-": "translation. We report BLEU using SacreBLEU [23]."
        },
        {
          "specify the desired target language.": "ciated with an emotion.\nIt measures whether an emo-",
          "These dimensions are often used in psychology and neuro-": ""
        },
        {
          "specify the desired target language.": "tion makes an individual feel dominant or submissive in",
          "These dimensions are often used in psychology and neuro-": ""
        },
        {
          "specify the desired target language.": "",
          "These dimensions are often used in psychology and neuro-": "3.3. Emotion Aware Neural Machine Translation"
        },
        {
          "specify the desired target language.": "a particular\nsituation.\nEmotions with high dominance",
          "These dimensions are often used in psychology and neuro-": ""
        },
        {
          "specify the desired target language.": "might\ninclude feelings of confidence, assertiveness, or",
          "These dimensions are often used in psychology and neuro-": "To improve the translation quality of our NMT model, we pro-"
        },
        {
          "specify the desired target language.": "control, while low dominance emotions might\ninvolve",
          "These dimensions are often used in psychology and neuro-": "pose to incorporate the emotion information extracted from in-"
        },
        {
          "specify the desired target language.": "feelings of submission or helplessness.",
          "These dimensions are often used in psychology and neuro-": "put\nrecordings\ninto their corresponding input\ntext\nsequences."
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "The emotion information is represented as an additional\ntoken": "representing the polarity over a specific emotion dimension. We"
        },
        {
          "The emotion information is represented as an additional\ntoken": "use the tokens <AroNeg> and <AroPos> for recordings that"
        },
        {
          "The emotion information is represented as an additional\ntoken": "have an arousal\nscore lower or higher\nthan 0.5 respectively,"
        },
        {
          "The emotion information is represented as an additional\ntoken": "as well as <DomNeg> and <DomPos> for dominance, and"
        },
        {
          "The emotion information is represented as an additional\ntoken": "<ValNeg> and <ValPos> for valence."
        },
        {
          "The emotion information is represented as an additional\ntoken": "For example, consider\nthe following pair of English and"
        },
        {
          "The emotion information is represented as an additional\ntoken": "French sentences:"
        },
        {
          "The emotion information is represented as an additional\ntoken": "I\nam\nquite\nsuis\ntoute\nsotte\nfoolish → Je"
        },
        {
          "The emotion information is represented as an additional\ntoken": "In the case of valence, the pair will be modified to:"
        },
        {
          "The emotion information is represented as an additional\ntoken": "am\nquite\nsuis\ntoute\nsotte\n<ValNeg> I\nfoolish → Je"
        },
        {
          "The emotion information is represented as an additional\ntoken": "The proposed method offers several advantages. Firstly,\nit"
        },
        {
          "The emotion information is represented as an additional\ntoken": "does not necessitate any changes in the model architecture nor"
        },
        {
          "The emotion information is represented as an additional\ntoken": "in the set of translated sequences. Model performances with and"
        },
        {
          "The emotion information is represented as an additional\ntoken": "without the additional token can be directly compared. Further-"
        },
        {
          "The emotion information is represented as an additional\ntoken": "more, the approach is simple yet effective, showcasing progress"
        },
        {
          "The emotion information is represented as an additional\ntoken": "in various domains [5, 6, 7, 9, 10]. It only involves the addition"
        },
        {
          "The emotion information is represented as an additional\ntoken": "of an extra token at the beginning of each input sentence. Lastly,"
        },
        {
          "The emotion information is represented as an additional\ntoken": "the method does not require any additional manual annotation,"
        },
        {
          "The emotion information is represented as an additional\ntoken": "as the emotion is automatically extracted from the SER model."
        },
        {
          "The emotion information is represented as an additional\ntoken": "4. Experiments and results"
        },
        {
          "The emotion information is represented as an additional\ntoken": ""
        },
        {
          "The emotion information is represented as an additional\ntoken": "In this\nsection, we conduct a set of experiments\nto compare"
        },
        {
          "The emotion information is represented as an additional\ntoken": ""
        },
        {
          "The emotion information is represented as an additional\ntoken": "NMT performances under different configurations. Firstly, we"
        },
        {
          "The emotion information is represented as an additional\ntoken": "analyze the statistical distribution of values provided by the"
        },
        {
          "The emotion information is represented as an additional\ntoken": "SER model on the Libri-trans dataset for the three emotion di-"
        },
        {
          "The emotion information is represented as an additional\ntoken": ""
        },
        {
          "The emotion information is represented as an additional\ntoken": "mensions. Secondly, we train four different NMT models that"
        },
        {
          "The emotion information is represented as an additional\ntoken": ""
        },
        {
          "The emotion information is represented as an additional\ntoken": "are a baseline model, and three different models that use the"
        },
        {
          "The emotion information is represented as an additional\ntoken": ""
        },
        {
          "The emotion information is represented as an additional\ntoken": "arousal, dominance, and valence information respectively."
        },
        {
          "The emotion information is represented as an additional\ntoken": ""
        },
        {
          "The emotion information is represented as an additional\ntoken": ""
        },
        {
          "The emotion information is represented as an additional\ntoken": "4.1. Emotion recognition on Libri-trans"
        },
        {
          "The emotion information is represented as an additional\ntoken": ""
        },
        {
          "The emotion information is represented as an additional\ntoken": "Our proposed method starts with the computation of emotional"
        },
        {
          "The emotion information is represented as an additional\ntoken": "dimensions for each English sentence in the Libri-trans dataset."
        },
        {
          "The emotion information is represented as an additional\ntoken": "These values will be later used for the English-to-French text-"
        },
        {
          "The emotion information is represented as an additional\ntoken": "to-text translation task."
        },
        {
          "The emotion information is represented as an additional\ntoken": ""
        },
        {
          "The emotion information is represented as an additional\ntoken": "Due to the modality mismatch between the text-to-text task"
        },
        {
          "The emotion information is represented as an additional\ntoken": ""
        },
        {
          "The emotion information is represented as an additional\ntoken": "and the required raw audio waveform as\ninput\nfor our SER"
        },
        {
          "The emotion information is represented as an additional\ntoken": ""
        },
        {
          "The emotion information is represented as an additional\ntoken": "model, we propose two different ways to compute emotion val-"
        },
        {
          "The emotion information is represented as an additional\ntoken": ""
        },
        {
          "The emotion information is represented as an additional\ntoken": "ues. The first method involves using audio recordings that are"
        },
        {
          "The emotion information is represented as an additional\ntoken": ""
        },
        {
          "The emotion information is represented as an additional\ntoken": "already present\nin the Libri-trans dataset\nto evaluate emotion"
        },
        {
          "The emotion information is represented as an additional\ntoken": ""
        },
        {
          "The emotion information is represented as an additional\ntoken": "values.\nThis represents the most accurate method to estimate"
        },
        {
          "The emotion information is represented as an additional\ntoken": ""
        },
        {
          "The emotion information is represented as an additional\ntoken": "emotion; however,\nit\nimplies the use of additional data in the"
        },
        {
          "The emotion information is represented as an additional\ntoken": ""
        },
        {
          "The emotion information is represented as an additional\ntoken": "translation pipeline. Statistical distributions of emotion values"
        },
        {
          "The emotion information is represented as an additional\ntoken": ""
        },
        {
          "The emotion information is represented as an additional\ntoken": "on original audio recordings from the Libri-trans dataset are il-"
        },
        {
          "The emotion information is represented as an additional\ntoken": ""
        },
        {
          "The emotion information is represented as an additional\ntoken": "lustrated in Figure 1. We showcase statistical distributions for"
        },
        {
          "The emotion information is represented as an additional\ntoken": ""
        },
        {
          "The emotion information is represented as an additional\ntoken": "each train, dev, and test subset of\nthe Libri-trans dataset. We"
        },
        {
          "The emotion information is represented as an additional\ntoken": ""
        },
        {
          "The emotion information is represented as an additional\ntoken": "remark that, for the three emotional dimensions and each sub-"
        },
        {
          "The emotion information is represented as an additional\ntoken": ""
        },
        {
          "The emotion information is represented as an additional\ntoken": "set,\nstatistical distributions are balanced, medians are around"
        },
        {
          "The emotion information is represented as an additional\ntoken": ""
        },
        {
          "The emotion information is represented as an additional\ntoken": "0.5 and values range from 0.1 to 0.9. Due to the acceptable bal-"
        },
        {
          "The emotion information is represented as an additional\ntoken": ""
        },
        {
          "The emotion information is represented as an additional\ntoken": "ance of dimensional emotion scores provided by our selected"
        },
        {
          "The emotion information is represented as an additional\ntoken": ""
        },
        {
          "The emotion information is represented as an additional\ntoken": "SER, we consider the initial\ntrain, dev, and test splits as good"
        },
        {
          "The emotion information is represented as an additional\ntoken": ""
        },
        {
          "The emotion information is represented as an additional\ntoken": "candidates for the translation task conditioned with emotion in-"
        },
        {
          "The emotion information is represented as an additional\ntoken": ""
        },
        {
          "The emotion information is represented as an additional\ntoken": "formation."
        },
        {
          "The emotion information is represented as an additional\ntoken": ""
        },
        {
          "The emotion information is represented as an additional\ntoken": "The second method involves synthesizing each English text"
        },
        {
          "The emotion information is represented as an additional\ntoken": ""
        },
        {
          "The emotion information is represented as an additional\ntoken": "with the help of the Google Text-to-Speech API1. This method"
        },
        {
          "The emotion information is represented as an additional\ntoken": ""
        },
        {
          "The emotion information is represented as an additional\ntoken": "has the advantage of using only text data; however, the original"
        },
        {
          "The emotion information is represented as an additional\ntoken": ""
        },
        {
          "The emotion information is represented as an additional\ntoken": "emotion can be altered with a neutral rendering. Statistical dis-"
        },
        {
          "The emotion information is represented as an additional\ntoken": ""
        },
        {
          "The emotion information is represented as an additional\ntoken": "tributions of emotion values on synthesized audio of all English"
        },
        {
          "The emotion information is represented as an additional\ntoken": ""
        },
        {
          "The emotion information is represented as an additional\ntoken": "text are illustrated in Figure 2. We observe that arousal values"
        },
        {
          "The emotion information is represented as an additional\ntoken": ""
        },
        {
          "The emotion information is represented as an additional\ntoken": "are concentrated around 0.5,\nindicating that synthesizing audio"
        },
        {
          "The emotion information is represented as an additional\ntoken": ""
        },
        {
          "The emotion information is represented as an additional\ntoken": "files produces neutral arousal. Also, we remark that almost all"
        },
        {
          "The emotion information is represented as an additional\ntoken": ""
        },
        {
          "The emotion information is represented as an additional\ntoken": "1https://gtts.readthedocs.io/en/latest/"
        }
      ],
      "page": 3
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "periments can be conducted, such as using the three emotional": ""
        },
        {
          "periments can be conducted, such as using the three emotional": "dimensions to condition each source sentence,\nswitching lan-"
        },
        {
          "periments can be conducted, such as using the three emotional": ""
        },
        {
          "periments can be conducted, such as using the three emotional": "guages (translating from French to English), testing the method"
        },
        {
          "periments can be conducted, such as using the three emotional": ""
        },
        {
          "periments can be conducted, such as using the three emotional": "on other multilingual datasets including MuST-C, or visualizing"
        },
        {
          "periments can be conducted, such as using the three emotional": "the embedding of the NMT model to get a better understanding"
        },
        {
          "periments can be conducted, such as using the three emotional": "on how vocabulary related to a specific emotion is clustered."
        },
        {
          "periments can be conducted, such as using the three emotional": "Moreover, different methods to include the emotion informa-"
        },
        {
          "periments can be conducted, such as using the three emotional": ""
        },
        {
          "periments can be conducted, such as using the three emotional": "tion can be tested, such as adding the embedding of the emotion"
        },
        {
          "periments can be conducted, such as using the three emotional": ""
        },
        {
          "periments can be conducted, such as using the three emotional": "token to all token embeddings."
        },
        {
          "periments can be conducted, such as using the three emotional": ""
        },
        {
          "periments can be conducted, such as using the three emotional": "In this work, we incorporate real speech recordings as an"
        },
        {
          "periments can be conducted, such as using the three emotional": ""
        },
        {
          "periments can be conducted, such as using the three emotional": "additional modality to estimate emotion.\nIntroducing the au-"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "leads to better BLEU scores than when using tokens from syn-": "thesized speech. We observed that, with synthesized audio,"
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "emotion value estimations become neutral in the case of arousal"
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "and dominance, and translation quality is degraded. Therefore,"
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "it appears crucial to use real audio recordings to estimate emo-"
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "tion and improve translation quality."
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "In addition, we note that all BLEU scores presented in Ta-"
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "ble 1 are consistently low,\nindicating poor\ntranslation quality"
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "for all proposed models,\nincluding the baseline.\nThis\nis due"
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "to the nature of\nthe data within the Libri-trans dataset, which"
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "comprises English utterances extracted from books. Audios are"
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "recorded from readers, and the vocabulary in the texts differs"
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "significantly from the language commonly spoken in real-world"
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "interactions."
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "5. Conclusion"
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "We proposed an innovative method that combines SER with"
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "NMT models\nto improve translation quality.\nOur method is"
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "fully automatic and does not\nrequire any manual annotation."
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "The proposed method is simple, effective, and enables the di-"
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "rect comparison between models. The best performances were"
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "achieved by adding the arousal token extracted from real speech"
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": ""
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "at the start of each input sentence."
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": ""
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "This study only presents the first experiment on combining"
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "SER and NMT models to improve translation. Additional ex-"
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": ""
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "periments can be conducted, such as using the three emotional"
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": ""
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "dimensions to condition each source sentence,\nswitching lan-"
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": ""
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "guages (translating from French to English), testing the method"
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": ""
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "on other multilingual datasets including MuST-C, or visualizing"
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "the embedding of the NMT model to get a better understanding"
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "on how vocabulary related to a specific emotion is clustered."
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "Moreover, different methods to include the emotion informa-"
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": ""
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "tion can be tested, such as adding the embedding of the emotion"
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": ""
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "token to all token embeddings."
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": ""
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "In this work, we incorporate real speech recordings as an"
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": ""
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "additional modality to estimate emotion.\nIntroducing the au-"
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "dio modality into the translation task also enables to perform"
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "speech-to-text\ntranslation, known as Speech Translation. Con-"
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "sequently,\nexploring the\nconditioning of Speech Translation"
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "models with emotion as additional\ninformation would be valu-"
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "able."
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": ""
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "6. Acknowledgements"
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": ""
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "The research presented in this paper is conducted as part of the"
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": ""
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "project FVLLMONTI, which has received funding from the Eu-"
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": ""
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "ropean Union’s Horizon 2020 Research and Innovation action"
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": ""
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": "under grant agreement No 101016776."
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": ""
        },
        {
          "leads to better BLEU scores than when using tokens from syn-": ""
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "ropean Union’s Horizon 2020 Research and Innovation action": ""
        },
        {
          "ropean Union’s Horizon 2020 Research and Innovation action": "under grant agreement No 101016776."
        },
        {
          "ropean Union’s Horizon 2020 Research and Innovation action": ""
        },
        {
          "ropean Union’s Horizon 2020 Research and Innovation action": ""
        },
        {
          "ropean Union’s Horizon 2020 Research and Innovation action": "7. References"
        },
        {
          "ropean Union’s Horizon 2020 Research and Innovation action": ""
        },
        {
          "ropean Union’s Horizon 2020 Research and Innovation action": "[1]\nI. Sutskever, O. Vinyals, and Q. V. Le, “Sequence to Sequence"
        },
        {
          "ropean Union’s Horizon 2020 Research and Innovation action": "the Annual Con-\nLearning with Neural Networks,”\nin Proc. of"
        },
        {
          "ropean Union’s Horizon 2020 Research and Innovation action": "ference on Neural Information Processing Systems (NIPS), Mon-"
        },
        {
          "ropean Union’s Horizon 2020 Research and Innovation action": "treal, Canada, 2014, pp. 3104–3112."
        },
        {
          "ropean Union’s Horizon 2020 Research and Innovation action": "[2] D. Bahdanau, K. Cho, and Y. Bengio, “Neural Machine Trans-"
        },
        {
          "ropean Union’s Horizon 2020 Research and Innovation action": "lation by Jointly Learning to Align and Translate,” in Proc. of"
        },
        {
          "ropean Union’s Horizon 2020 Research and Innovation action": "the International Conference on Learning Representation (ICLR),"
        },
        {
          "ropean Union’s Horizon 2020 Research and Innovation action": ""
        },
        {
          "ropean Union’s Horizon 2020 Research and Innovation action": "San Diego, USA, 2015."
        },
        {
          "ropean Union’s Horizon 2020 Research and Innovation action": ""
        },
        {
          "ropean Union’s Horizon 2020 Research and Innovation action": "[3]\nT. Kocmi, E. Avramidis, R. Bawden, O. Bojar, A. Dvorkovich,"
        },
        {
          "ropean Union’s Horizon 2020 Research and Innovation action": ""
        },
        {
          "ropean Union’s Horizon 2020 Research and Innovation action": "C. Federmann, M. Fishel, M. Freitag, T. Gowda, R. Grund-"
        },
        {
          "ropean Union’s Horizon 2020 Research and Innovation action": ""
        },
        {
          "ropean Union’s Horizon 2020 Research and Innovation action": "kiewicz, B. Haddow, P. Koehn, B. Marie, C. Monz, M. Morishita,"
        },
        {
          "ropean Union’s Horizon 2020 Research and Innovation action": ""
        },
        {
          "ropean Union’s Horizon 2020 Research and Innovation action": "K. Murray, M. Nagata, T. Nakazawa, M. Popel, M. Popovic,"
        },
        {
          "ropean Union’s Horizon 2020 Research and Innovation action": ""
        },
        {
          "ropean Union’s Horizon 2020 Research and Innovation action": "and M. Shmatova, “Findings of the 2023 Conference on Machine"
        },
        {
          "ropean Union’s Horizon 2020 Research and Innovation action": "Translation (WMT23): LLMs Are Here But Not Quite There Yet,”"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": "the Conference of the North American Chapter of the Association"
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": "for Computational Linguistics: Human Language Technologies"
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": "(NAACL-HLT), Online, 2021, pp. 1193–1199."
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": ""
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": "N. Thorat, F. Vi´egas, M. Wattenberg, G. Corrado, M. Hughes, and"
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": "J. Dean, “Google’s Multilingual Neural Machine Translation Sys-"
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": "tem: Enabling Zero-shot Translation,” Transactions of the Associ-"
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": "ation for Computational Linguistics, vol. 5, pp. 339–351, 2017."
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": "J. Pennebaker, M. Francis, and R. Booth, “Linguistic Inquiry and"
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": "Word Count: LIWC 2001,” Mahway: Lawrence Erlbaum Asso-"
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": "ciates, vol. 71, 2001."
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": ""
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": "Arousal, and Dominance for 13,915 English Lemmas,” Behavior"
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": "Research Methods, vol. 45, no. 4, pp. 1191–1207, 2013."
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": ""
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": "the Company They Keep:\nStudying the Accuracy of Affective"
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": "Word Lists\nin Determining Sentence\nand Word Valence\nin\na"
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": "Domain-Specific Corpus,” IEEE transactions on Affective Com-"
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": "puting, vol. 13, no. 3, pp. 1440–1451, 2020."
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": "E. Troiano, R. Klinger, and S. Pad´o, “Lost\nin Back-translation:"
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": "Emotion Preservation in Neural Machine Translation,” in Proc."
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": "of\nthe\nInternational Conference on Computational Linguistics"
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": "(COLING), Barcelona, Spain (Online), 2020, pp. 4340–4354."
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": "J. Wagner, A. Triantafyllopoulos, H. Wierstorf, M. Schmitt,"
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": "F. Burkhardt, F. Eyben, and B. W. Schuller, “Dawn of the Trans-"
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": "former Era in Speech Emotion Recognition: Closing the Valence"
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": "Gap,” IEEE Transactions on Pattern Analysis and Machine Intel-"
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": "ligence, vol. 45, pp. 10 745–10 759, 2023."
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": ""
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": "Framework for Self-supervised Learning of Speech Representa-"
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": "the Annual Conference on Neural Information\ntions,” in Proc. of"
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": "Processing Systems (NeurIPS), Online, 2020, pp. 12 449–12 460."
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": ""
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": "anced Speech Corpus by Retrieving Emotional Speech from Ex-"
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": "isting Podcast Recordings,” IEEE Transactions on Affective Com-"
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": "puting, vol. 10, no. 4, pp. 471–483, 2017."
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": ""
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": "S. Kim, J. N. Chang, S. Lee, and S. S. Narayanan, “IEMOCAP:"
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": "Interactive Emotional dyadic MOtion CAPture database,” Lan-"
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": "guage Resources and Evaluation, vol. 42, pp. 335–359, 2008."
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": ""
        },
        {
          "Style of Translators in Neural Machine Translation,” in Proc. of": "Sentiment Intensity Analysis in Videos: Facial Gestures and Ver-"
        }
      ],
      "page": 5
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "gapore, 2023, pp. 1–42.",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": "based Loss Functions for Multitask Learning Dimensional Speech"
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": "Emotion Recognition,”\nJournal of Physics: Conference Series,"
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "[4] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N.",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": "vol. 1896, 2021."
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "Gomez, Ł. Kaiser, and I. Polosukhin, “Attention is All you Need,”",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "in Proc. of the Annual Conference on Neural Information Process-",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": "S. Watanabe, T. Hori, S. Karita, T. Hayashi, J. Nishitoba, Y. Unno,"
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "ing Systems (NIPS), Long Beach, USA, 2017, pp. 5998–6008.",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": "N. E. Y. Soplin, J. Heymann, M. Wiesner, N. Chen et al., “ESPnet:"
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": "the Annual\nEnd-to-end Speech Processing Toolkit,” in Proc. of"
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "[5] C. Si, K. Wu, A. Aw, and M.-Y. Kan, “Sentiment Aware Neural",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": "Conference of the International Speech Communication Associa-"
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "the Workshop on Asian Trans-\nMachine Translation,” in Proc. of",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": "tion (Interspeech), Hyderabad, India, 2018, pp. 2207–2211."
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "lation (WAT), Hong Kong, China, 2019, pp. 200–206.",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": "[22] A. C. Kocabiyikoglu, L. Besacier,\nand O. Kraif,\n“Augmenting"
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "[6] R. Sennrich, B. Haddow, and A. Birch, “Controlling Politeness",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": "Librispeech with French Translations:\nA Multimodal Corpus"
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "in Neural Machine Translation via Side Constraints,” in Proc. of",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": "the\nIn-\nfor Direct Speech Translation Evaluation,”\nin Proc. of"
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "the Conference of the North American Chapter of the Association",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": "ternational Conference on Language Resources and Evaluation"
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "for Computational Linguistics: Human Language Technologies",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": "(LREC), Miyazaki, Japan, 2018."
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "(NAACL-HLT), San Diego, USA, 2019, pp. 35–40.",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "E. Vanmassenhove, C. Hardmeier,\nand A. Way,\n“Getting Gen-",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": "“A Call\nfor Clarity in Reporting BLEU Scores,”\nin"
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "the Con-\nder Right\nin Neural Machine Translation,” in Proc. of",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": "Proc. of\nthe Conference on Machine Translation: Research Pa-"
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "ference on Empirical Methods in Natural Language Processing",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": "pers (WMT), Brussels, Belgium, 2018, pp. 186–191."
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "(CEMNLP), Brussels, Belgium, 2018, pp. 3003–3008.",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "[8] M. Gaido, D. Fucci, M. Negri, and L. Bentivogli, “How to Build",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "Competitive Multi-gender Speech Translation Models\nfor Con-",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "trolling Speaker Gender Translation,” in Proc. of the Italian Con-",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "ference on Computational Linguistics (CLiC-it), 2023.",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "[9] Y. Wang, C. Hoang, and M. Federico, “Towards Modeling the",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "Style of Translators in Neural Machine Translation,” in Proc. of",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "the Conference of the North American Chapter of the Association",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "for Computational Linguistics: Human Language Technologies",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "(NAACL-HLT), Online, 2021, pp. 1193–1199.",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "N. Thorat, F. Vi´egas, M. Wattenberg, G. Corrado, M. Hughes, and",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "J. Dean, “Google’s Multilingual Neural Machine Translation Sys-",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "tem: Enabling Zero-shot Translation,” Transactions of the Associ-",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "ation for Computational Linguistics, vol. 5, pp. 339–351, 2017.",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "J. Pennebaker, M. Francis, and R. Booth, “Linguistic Inquiry and",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "Word Count: LIWC 2001,” Mahway: Lawrence Erlbaum Asso-",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "ciates, vol. 71, 2001.",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "Arousal, and Dominance for 13,915 English Lemmas,” Behavior",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "Research Methods, vol. 45, no. 4, pp. 1191–1207, 2013.",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "the Company They Keep:\nStudying the Accuracy of Affective",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "Word Lists\nin Determining Sentence\nand Word Valence\nin\na",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "Domain-Specific Corpus,” IEEE transactions on Affective Com-",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "puting, vol. 13, no. 3, pp. 1440–1451, 2020.",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "E. Troiano, R. Klinger, and S. Pad´o, “Lost\nin Back-translation:",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "Emotion Preservation in Neural Machine Translation,” in Proc.",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "of\nthe\nInternational Conference on Computational Linguistics",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "(COLING), Barcelona, Spain (Online), 2020, pp. 4340–4354.",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "J. Wagner, A. Triantafyllopoulos, H. Wierstorf, M. Schmitt,",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "F. Burkhardt, F. Eyben, and B. W. Schuller, “Dawn of the Trans-",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "former Era in Speech Emotion Recognition: Closing the Valence",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "Gap,” IEEE Transactions on Pattern Analysis and Machine Intel-",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "ligence, vol. 45, pp. 10 745–10 759, 2023.",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "Framework for Self-supervised Learning of Speech Representa-",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "the Annual Conference on Neural Information\ntions,” in Proc. of",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "Processing Systems (NeurIPS), Online, 2020, pp. 12 449–12 460.",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "anced Speech Corpus by Retrieving Emotional Speech from Ex-",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "isting Podcast Recordings,” IEEE Transactions on Affective Com-",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "puting, vol. 10, no. 4, pp. 471–483, 2017.",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "S. Kim, J. N. Chang, S. Lee, and S. S. Narayanan, “IEMOCAP:",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "Interactive Emotional dyadic MOtion CAPture database,” Lan-",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "guage Resources and Evaluation, vol. 42, pp. 335–359, 2008.",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "Sentiment Intensity Analysis in Videos: Facial Gestures and Ver-",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "bal Messages,” IEEE Intelligent Systems, vol. 31, no. 6, pp. 82–88,",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        },
        {
          "in Proc. of\nthe Conference on Machine Translation (WMT), Sin-": "2016.",
          "[20] B. T. Atmaja and M. Akagi, “Evaluation of Error-and Correlation-": ""
        }
      ],
      "page": 5
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "",
      "authors": [
        "References"
      ],
      "venue": ""
    },
    {
      "citation_id": "2",
      "title": "Sequence to Sequence Learning with Neural Networks",
      "authors": [
        "I Sutskever",
        "O Vinyals",
        "Q Le"
      ],
      "year": "2014",
      "venue": "Proc. of the Annual Conference on Neural Information Processing Systems (NIPS), Montreal"
    },
    {
      "citation_id": "3",
      "title": "Neural Machine Translation by Jointly Learning to Align and Translate",
      "authors": [
        "D Bahdanau",
        "K Cho",
        "Y Bengio"
      ],
      "year": "2015",
      "venue": "Proc. of the International Conference on Learning Representation (ICLR)"
    },
    {
      "citation_id": "4",
      "title": "23): LLMs Are Here But Not Quite There Yet",
      "authors": [
        "T Kocmi",
        "E Avramidis",
        "R Bawden",
        "O Bojar",
        "A Dvorkovich",
        "C Federmann",
        "M Fishel",
        "M Freitag",
        "T Gowda",
        "R Grundkiewicz",
        "B Haddow",
        "P Koehn",
        "B Marie",
        "C Monz",
        "M Morishita",
        "K Murray",
        "M Nagata",
        "T Nakazawa",
        "M Popel",
        "M Popovic",
        "M Shmatova"
      ],
      "year": "2023",
      "venue": "Proc. of the Conference on Machine Translation (WMT), Singapore"
    },
    {
      "citation_id": "5",
      "title": "Attention is All you Need",
      "authors": [
        "A Vaswani",
        "N Shazeer",
        "N Parmar",
        "J Uszkoreit",
        "L Jones",
        "A Gomez",
        "Ł Kaiser",
        "I Polosukhin"
      ],
      "year": "2017",
      "venue": "Proc. of the Annual Conference on Neural Information Processing Systems (NIPS)"
    },
    {
      "citation_id": "6",
      "title": "Sentiment Aware Neural Machine Translation",
      "authors": [
        "C Si",
        "K Wu",
        "A Aw",
        "M.-Y Kan"
      ],
      "year": "2019",
      "venue": "Proc. of the Workshop on Asian Translation (WAT)"
    },
    {
      "citation_id": "7",
      "title": "Controlling Politeness in Neural Machine Translation via Side Constraints",
      "authors": [
        "R Sennrich",
        "B Haddow",
        "A Birch"
      ],
      "year": "2019",
      "venue": "Proc. of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)"
    },
    {
      "citation_id": "8",
      "title": "Getting Gender Right in Neural Machine Translation",
      "authors": [
        "E Vanmassenhove",
        "C Hardmeier",
        "A Way"
      ],
      "year": "2018",
      "venue": "Proc. of the Conference on Empirical Methods in Natural Language Processing (CEMNLP)"
    },
    {
      "citation_id": "9",
      "title": "How to Build Competitive Multi-gender Speech Translation Models for Controlling Speaker Gender Translation",
      "authors": [
        "M Gaido",
        "D Fucci",
        "M Negri",
        "L Bentivogli"
      ],
      "venue": "Proc. of the Italian Conference on Computational Linguistics (CLiC-it)"
    },
    {
      "citation_id": "10",
      "title": "Towards Modeling the Style of Translators in Neural Machine Translation",
      "authors": [
        "Y Wang",
        "C Hoang",
        "M Federico"
      ],
      "year": "2021",
      "venue": "Proc. of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)"
    },
    {
      "citation_id": "11",
      "title": "Google's Multilingual Neural Machine Translation System: Enabling Zero-shot Translation",
      "authors": [
        "M Johnson",
        "M Schuster",
        "Q Le",
        "M Krikun",
        "Y Wu",
        "Z Chen",
        "N Thorat",
        "F Viégas",
        "M Wattenberg",
        "G Corrado",
        "M Hughes",
        "J Dean"
      ],
      "year": "2017",
      "venue": "Transactions of the Association for Computational Linguistics"
    },
    {
      "citation_id": "12",
      "title": "Linguistic Inquiry and Word Count: LIWC 2001",
      "authors": [
        "J Pennebaker",
        "M Francis",
        "R Booth"
      ],
      "year": "2001",
      "venue": "Mahway: Lawrence Erlbaum Associates"
    },
    {
      "citation_id": "13",
      "title": "Norms of Valence, Arousal, and Dominance for 13,915 English Lemmas",
      "authors": [
        "A Warriner",
        "V Kuperman",
        "M Brysbaert"
      ],
      "year": "2013",
      "venue": "Behavior Research Methods"
    },
    {
      "citation_id": "14",
      "title": "Affective Words and the Company They Keep: Studying the Accuracy of Affective Word Lists in Determining Sentence and Word Valence in a Domain-Specific Corpus",
      "authors": [
        "N Braun",
        "M Goudbeek",
        "E Krahmer"
      ],
      "year": "2020",
      "venue": "IEEE transactions on Affective Computing"
    },
    {
      "citation_id": "15",
      "title": "Lost in Back-translation: Emotion Preservation in Neural Machine Translation",
      "authors": [
        "E Troiano",
        "R Klinger",
        "S Padó"
      ],
      "year": "2020",
      "venue": "Proc. of the International Conference on Computational Linguistics (COLING)"
    },
    {
      "citation_id": "16",
      "title": "Dawn of the Transformer Era in Speech Emotion Recognition: Closing the Valence Gap",
      "authors": [
        "J Wagner",
        "A Triantafyllopoulos",
        "H Wierstorf",
        "M Schmitt",
        "F Burkhardt",
        "F Eyben",
        "B Schuller"
      ],
      "year": "2023",
      "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
    },
    {
      "citation_id": "17",
      "title": "wav2vec2.0: A Framework for Self-supervised Learning of Speech Representations",
      "authors": [
        "A Baevski",
        "Y Zhou",
        "A Mohamed",
        "M Auli"
      ],
      "year": "2020",
      "venue": "Proc. of the Annual Conference on Neural Information Processing Systems (NeurIPS)"
    },
    {
      "citation_id": "18",
      "title": "Building Naturalistic Emotionally Balanced Speech Corpus by Retrieving Emotional Speech from Existing Podcast Recordings",
      "authors": [
        "R Lotfian",
        "C Busso"
      ],
      "year": "2017",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "19",
      "title": "IEMOCAP: Interactive Emotional dyadic MOtion CAPture database",
      "authors": [
        "C Busso",
        "M Bulut",
        "C.-C Lee",
        "A Kazemzadeh",
        "E Mower",
        "S Kim",
        "J Chang",
        "S Lee",
        "S Narayanan"
      ],
      "year": "2008",
      "venue": "Language Resources and Evaluation"
    },
    {
      "citation_id": "20",
      "title": "Multimodal Sentiment Intensity Analysis in Videos: Facial Gestures and Verbal Messages",
      "authors": [
        "A Zadeh",
        "R Zellers",
        "E Pincus",
        "L.-P Morency"
      ],
      "year": "2016",
      "venue": "IEEE Intelligent Systems"
    },
    {
      "citation_id": "21",
      "title": "Evaluation of Error-and Correlationbased Loss Functions for Multitask Learning Dimensional Speech Emotion Recognition",
      "authors": [
        "B Atmaja",
        "M Akagi"
      ],
      "year": "2021",
      "venue": "Journal of Physics: Conference Series"
    },
    {
      "citation_id": "22",
      "title": "Proc. of the Annual Conference of the International Speech Communication Association (Interspeech)",
      "authors": [
        "S Watanabe",
        "T Hori",
        "S Karita",
        "T Hayashi",
        "J Nishitoba",
        "Y Unno",
        "N Soplin",
        "J Heymann",
        "M Wiesner",
        "N Chen"
      ],
      "year": "2018",
      "venue": "Proc. of the Annual Conference of the International Speech Communication Association (Interspeech)"
    },
    {
      "citation_id": "23",
      "title": "Augmenting Librispeech with French Translations: A Multimodal Corpus for Direct Speech Translation Evaluation",
      "authors": [
        "A Kocabiyikoglu",
        "L Besacier",
        "O Kraif"
      ],
      "year": "2018",
      "venue": "Proc. of the International Conference on Language Resources and Evaluation (LREC)"
    },
    {
      "citation_id": "24",
      "title": "A Call for Clarity in Reporting BLEU Scores",
      "authors": [
        "M Post"
      ],
      "year": "2018",
      "venue": "Proc. of the Conference on Machine Translation: Research Papers (WMT)"
    }
  ]
}