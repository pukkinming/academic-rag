{
  "paper_id": "2508.05474v1",
  "title": "Can Large Language Models Generate Effective Datasets For Emotion Recognition In Conversations?",
  "published": "2025-08-07T15:13:55Z",
  "authors": [
    "Burak Can Kaplan",
    "Hugo Cesar De Castro Carneiro",
    "Stefan Wermter"
  ],
  "keywords": [
    "large language models",
    "machine learning",
    "data generation",
    "affective computing"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Emotion recognition in conversations (ERC) focuses on identifying emotion shifts within interactions, representing a significant step toward advancing machine intelligence. However, ERC data remains scarce, and existing datasets face numerous challenges due to their highly biased sources and the inherent subjectivity of soft labels. Even though Large Language Models (LLMs) have demonstrated their quality in many affective tasks, they are typically expensive to train, and their application to ERC tasks-particularly in data generation-remains limited. To address these challenges, we employ a small, resource-efficient, and general-purpose LLM to synthesize ERC datasets with diverse properties, supplementing the three most widely used ERC benchmarks. We generate six novel datasets, with two tailored to enhance each benchmark. We evaluate the utility of these datasets to (1) supplement existing datasets for ERC classification, and (  2 ) analyze the effects of label imbalance in ERC. Our experimental results indicate that ERC classifier models trained on the generated datasets exhibit strong robustness and consistently achieve statistically significant performance improvements on existing ERC benchmarks.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "I. Introduction",
      "text": "Emotion recognition in conversations (ERC) is a relatively new field of study that focuses on identifying and understanding human emotions expressed during interactions  [1] . Its primary goal is to detect emotion shifts within dialogues, a capability that has become increasingly important with the rise of social robotics and applications requiring emotionally intelligent systems  [2] . Large Language Models (LLMs) have demonstrated substantial improvements in various natural language processing (NLP) tasks, including affective computing  [3] , and hold potential as effective tools for generating ERC data. Despite their success, most evaluations of LLMs in affective tasks have been conducted with API-based models, which are expensive, or top-performing local models requiring significant computational resources  [4] ,  [5] . Exploring the capabilities of small and general-purpose LLMs in ERC tasks thus emerges as a promising and cost-efficient alternative.\n\nA critical challenge in ERC lies in the scarcity of highquality, diverse datasets. Most existing datasets are derived from biased sources such as scripted TV shows or social media, which often feature imbalanced label distributions  [6] ,  [7] . Moreover, crafting such datasets is costly and time-consuming due to participant recruitment, ethical concerns, unbiased dialogue construction, and the difficulty of accurate and consistent labeling. Annotating emotional data often involves subjective interpretations, with annotators frequently providing English CPED  [11]  TV Multiple 13 Chinese EC  [12]  Twitter 3 4 English KDEmor  [13]  TV Multiple 3 Korean inconsistent labels for the same utterance. Typically, a majority vote is used to select a label when there is disagreement, but this process is limited by the small number of annotators (usually 3-5), leading to reliability issues  [7] ,  [8] . Additionally, as highlighted in Tab. I, existing ERC datasets vary significantly in their emotion label sets, speaker numbers, and languages, making it difficult to combine them effectively for transfer learning. Furthermore, the inconsistencies in emotion categories across datasets limit their interoperability, leading some studies to rely on mappings based on psychological studies to align these different label sets  [5] . However, such mappings are often rough approximations, raising concerns about their accuracy and applicability. Rooted in the concept that only the entity expressing a particular affective state can fully recognize it  [9] , we hypothesize that by having the LLM generate both utterances and their corresponding emotion labels simultaneously, we can address these issues and significantly improve dataset consistency. Tab. I highlights the characteristics of popular ERC datasets and underscores their limitations.\n\nTo tackle these limitations, we propose leveraging a small, general-purpose LLM to synthesize new ERC datasets. By generating both dialogue lines and their corresponding emotion labels in a single step, we aim to improve the consistency and reliability of ERC data while avoiding the costs and complexities associated with traditional data collection and annotation methods. To ensure comparability with existing benchmarks, we generate six new datasets, with two corresponding datasets for each of the three widely used ERC benchmarks. This alignment allows us to systematically evaluate the potential of LLM-generated datasets to supplement existing resources, mitigate label imbalance, and enhance ERC model performance. Fig.  1  shows an example of a dialogue generated by our LLM.\n\nOur contributions are as follows: Firstly, we demonstrate the capability of a small LLM to generate consistent, multi-party ERC datasets suitable for training ERC models. Secondly, we propose a methodology to evaluate the quality and validity of The remainder of the paper is organized as follows: Section II reviews existing ERC datasets and related research on LLMs for affective computing, dataset enhancement, and synthetic data generation. Section III details the LLM setup, the dataset synthesis process, prompt engineering, and all parameters used, providing all necessary information for transparency. Section IV presents experimental evaluations of the generated datasets, and Section V concludes with insights and directions for future research.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Ii. Related Work A. Existing Datasets",
      "text": "In this study, we focus on the three most popular ERC datasets in Papers With Code 1 : MELD  [6] , EmoryNLP  [7] , and IEMOCAP  [8] . These datasets are chosen to assess the performance of ERC models on our generated datasets, as well as on these existing datasets.\n\nMELD is a dataset constructed by extracting lines from the \"Friends\" TV series. It encompasses 7 emotions: Neutral, Disgust, Anger, Sadness, Fear, Joy, and Surprise. There is a high imbalance among its labels, with Neutral being the most common. On the other hand, Disgust and Fear are notably rare. In some studies, authors perform classification task without either one or both of these labels. According to Papers With Code, weighted F1 classification results for MELD usually lie within the range from 60% to 70%.\n\nThe EmoryNLP dataset is also constructed from the lines of \"Friends\" TV series, but it employs different emotion labels than MELD, which are: Sad, Mad, Scared, Powerful, Peaceful, 1 https://paperswithcode.com/task/emotion-recognition-in-conversation Joyful, and Neutral. For the annotation process, 4 annotators participated, and only 6.17% of the annotations correspond to labels in which there was an unanimous agreement among the annotators. In 9.39% of the annotations, each annotator labeled the same data with different label. Majority voting was used to select the annotation in most cases. The weighted F1 results for EmoryNLP, as reported on Papers With Code, are around 35%, which is significantly lower compared to other datasets, characterizing EmoryNLP as a challenging dataset.\n\nIEMOCAP is a scripted dyadic dataset which also provides multimodal information. It encompasses 10 labels: Neutral, Happiness, Sadness, Anger, Excited, Frustration, Fear, Surprise, Disgust, and Other (Uninformative). Disgust does not show up in any record in the conversations of the validation split. Classification tasks on IEMOCAP involve the utilization of specific subsets of its available classes. Those that do not include Disgust and Other are denoted 8-way. Fear and Surprise are very rare throughout the dataset, so papers often do not include them. This classification task is denoted 6-way. Finally, although with more observations, Excited and Frustration appear considerably less than Neutral, Happiness, Sadness, and Anger. A classification using solely these 4 labels is denoted 4-way. Results aggregated on Papers With Code reveal that weighted F1 scores for IEMOCAP are slightly higher than those for MELD regardless of the number of classes used. This paper adopts the 6-way classification, as it is the most commonly employed approach in the literature.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "B. Llm Usage",
      "text": "MELD, IEMOCAP, and EmoryNLP are multimodal datasets, but they are often exclusively benchmarked in the textual modality  [5] ,  [14]  due to the inherent noise in their audio and visual components, which poses challenges to ERC model training. Even though some approaches aim to enhance audiovisual data quality through preprocessing  [15] ,  [16]  or modifying the modality fusing approach  [17] -  [19] , opportunities for improvement in this field still persist. Language models are frequently leveraged to increase the quality of existing datasets as well. For instance, pretrained language models can provide additional information at the utterance and conversation levels, thus increasing the context of an existing ERC dataset  [20] . Additionally, LLMs are also used in annotation process of affective speech data to enhance its quality  [4] ,  [21] .\n\nEmpathetic intelligence also requires measuring the capabilities of an LLM in various affective tasks. Existing literature indicates that LLMs exhibit considerable empathetic intelligence. Zhu et al.  [22]  demonstrate that transformerbased architectures are capable of distinguishing emotions in dialogues, and Deng et al.  [23]  use transformer architectures to generate dialogue responses. Amin et al  [4]  assess ChatGPT in affective computing, revealing that even a generalized model can achieve decent results. ChatGPT's knowledge has been also measured in solving affective computing problems, namely sentiment analysis, personality assessment, and suicide tendency detection  [3] . LLMs are also evaluated in tasks like affective support, multi-party conversations and ERC  [24] ,  [25]. Tu et al.  [26]  extract detailed additional knowledge from ERC data using ChatGPT and measures its impact on ERC models. Feng et al.  [27]  show that LLMs can serve as effective classifiers for affect recognition in conversation tasks. Additionally, LLM-based models have achieved high classification scores on widely used ERC datasets  [5] , further supporting the suitability of LLMs for ERC data generation.\n\nThere are approaches to enhance the LLMs' data generation capabilities. Eldan et al.  [28]  employ GPT-3.5 and GPT-4 to generate child-level language to train small language models. Josifoski et al.  [29]  present a synthetic data generation pipeline that involves prompting LLMs to generate text from coherent triplets extracted from a knowledge graph. Conversely, Chung et al.  [30]  attempt to increase the diversity of LLM data, acknowledging potential trade-offs with lower output accuracy. Veselovsky et al.  [31]  use LLM synthetic data to train classifiers, evaluating them on real data with various strategies. In summary, the existing literature underscores LLMs' effectiveness in diverse affective tasks. However, despite the significant limitations and noise present in existing ERC datasets, research on leveraging LLMs specifically for ERC data generation remains scarce, leaving an open opportunity for further exploration in this direction.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Iii. Dataset Generation",
      "text": "In the LLM selection phase, we ran small dialogue generation experiments, and observed that 7 billion-sized models proved incapable of generating creative and diverse dialogues while keeping sufficient output consistency for use as a dataset, often exhibiting repetitions of words or sentences. Regarding the larger models, we decided not to use ChatGPT despite yielding the most favorable results, due to our emphasis on ensuring the reproducibility of our approach. Although 33 billion-sized models yielded decent results, dialogues from the 13 billion-sized model appeared natural and required roughly 25 GB VRAM. Thus, we opted for using a small model with a reasonable GPU to offer an affordable and computationefficient solution for ERC dataset generation, with Vicuna 1.5 2  being the 13 billion-sized model to provide the best and most consistent results, and one of the most popular open sourced LLMs.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "A. Natural And Balanced Data",
      "text": "To assess our local LLMs' capabilities in generating multiparty affective conversations across various aspects, we generated two types of dataset with the same set of labels and dialogue structure of the three mentioned datasets in Sec. II-A, providing a total of 6 new datasets. These dataset types are named \"Natural\" and \"Balanced\". Each dataset was intentionally over-generated to safeguard against data limitations and to facilitate comparison with their corresponding original datasets. Fig.  2  displays total utterances, label amounts and label distributions of each dataset.\n\nNatural datasets comprise dialogues created freely by an LLM without any predetermined bias in its generation process. These datasets show the broad potential of LLMs in creating dialogues, with the distribution of the emotion labels within them being closer to reality. For example, emotions like happiness, sadness, or even the absence of emotions being far more common than emotions like fear and surprise. The generation of natural data is particularly useful for the development of affective interactive systems, e.g., more realistic and natural social robots to be used in real-life applications. With natural datasets, we aim to assess how naturally LLMs generate dialogues without emotional pre-conditioning.\n\nBalanced datasets, conversely, comprise dialogues with more evenly distributed emotions and they are designed to address class imbalance in existing ERC datasets while maintaining natural dialogue flow. To preserve the naturalness of the dialogues, we instruct the LLM to generate conversations that include at least one utterance with a specific given emotion. However, the content and placement of these within the dialogue, as well as the emotions of the remaining utterances, are left for the LLM to decide. This procedure does not yield a dataset where all emotions are uniformly distributed; rather, it ensures that a particular emotion appears in a significant number of dialogues. Fig  2  shows that the balanced datasets have the most balanced label distributions among all datasets. Due to the intentional bias introduced in its generation process, balanced datasets are not well suited for generative and affective usage, since rare emotions may appear more often than they do in real-life conversations. Nevertheless, these datasets are better fitting in the development of more accurate classifiers.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "B. Prompt Engineering",
      "text": "Prompting is a critical aspect of this research, directly biasing the LLM towards the goal. In the generation of natural data, four tasks were needed to achieve a proper output which are providing speaker names, utterances, consistent emotion labels and structure. Due to the varying nature of the speakers in the target datasets, distinct prompts tailored to each dataset were employed. Specifically, IEMOCAP involves dyadic interactions with unnamed male and female participants, while EmoryNLP and MELD are derived from conversations in the \"Friends\" TV show.\n\nThe most challenging aspect of the prompting process was obtaining accurate emotion labels from the LLM, given that these models tend to hallucinate and often forget prompt details when faced with complex tasks, leading to inconsistencies. To restrict the LLM to generate emotion labels from a specific label group, we assign each emotion label with a number as symbols and ask the LLM to provide one of them for each utterance. In the literature, the same logic is used in LLM Logic Reasoning  [32] -  [34] , and it is a proven technique that improves the LLM performance. In our case, this method ensures the generation of consistent labels across datasets. The last task involved employing a prompt to generate structured outputs to facilitate the retrieval of the necessary data. To ensure the parseability of that structure, we instructed the LLM to prepend speaker, utterance, and number (representing emotion) to the corresponding data. Fig.  3  provides the prompts used to generate the dialogues with this structure. At the generation, all sentences are concatenated and submitted to the LLM as a single prompt. Fig.  1  displays an example of ERC dialogue generated by the LLM.\n\nFor the generation of balanced data, the prompt is kept the same, except for the last part of the first sentence, where we instruct the LLM to ensure the dialogue contains at least one utterance expressing a specific emotion. Fig.  3  offers an example of prompt used to ensure the existence of at least one utterance expressing fear. To preserve the naturalness of the dialogue, we restrain from specifying the number associated with that label. This prompt iterates through all labels within the target dataset, ensuring an equal number of dialogues containing utterances expressing some particular emotion.\n\nWe tested these prompts with the LLM several times with the parameters provided in Tab. II. It was observed that the LLM consistently produced the same outputs, ensuring reproducibility. Specific words drive each LLM to produce different outputs based on their weights, and the prompts here offered were tailored for Vicuna 1.5(13b).",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "C. Llm Parameters",
      "text": "For the utilization of the local LLM, we employed Textgen-WebUI Chat API  3  with Langchain 4  , which provides access to all LLM parameters. For reproducibility, the seed is randomized for diversity but fixed to maintain consistent random numbers for each LLM run. Tab. II shows all parameters used in our data generation process.\n\nTemperature is not crucial in our case due to the fixed seed, so we opted to keep it at its default value. We kept top p, top k, and typical p very high, to enhance context diversity and provide more options in the dialogues. Furthermore, we minimized repetition penalty to avoid limiting the LLM based on the tokens it produced.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Iv. Experiments And Analyses",
      "text": "As outlined in Section III-A, two datasets-natural and balanced-were generated for each of the datasets discussed in Section III-B. These datasets share the same speakers, structure, and emotion label set as their corresponding datasets for the purpose of comparison. To assess the utility of the generated datasets, we employed three popular ERC classifier architectures: CoMPM  [35] , EmoOne-RoBERTa  [36] , and TODKAT  [22] . These models were chosen based on their available implementations and competitive performance scores on all three datasets: MELD, EmoryNLP, and IEMOCAP. These architectures were preferred over some state-of-the-art models due to factors such as the lack of implementations for certain datasets or high VRAM requirements such as 4x80G nVidia A100  [5] . This decision aligns with our aim of delivering a reproducible and affordable solution. Furthermore, the primary focus of this research is not achieving the highest scores but demonstrating whether the datasets generated through our approach boost the ERC classification process. To further validate our findings, we conducted statistical tests on the experiment results from the three classifier architectures, ensuring the significance of our conclusions. The entire pipeline used for evaluation is illustrated in Fig.  4 .",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "A. Assessing Synthetic Dataset Properties",
      "text": "To evaluate the utility of the generated datasets for ERC and the methodology proposed in this paper, we need to assess whether these datasets possess desirable properties relevant to the task. These properties include: 1. having all their splits sampled from the same distribution; 2. being able to train models to be robust to unseen data; and 3. having the potential to pretrain models for better performance when fine-tuned with benchmark datasets. The first property is guaranteed by our methodology since dialogues are independently generated by the LLM using the same prompt and parameters. As dialogues are independently generated and the dataset is only split afterward, all generated datasets have splits sampled from the same distribution. The second property requires training ERC architectures on the generated datasets and subjecting them to unseen data. The third property involves training the same architectures on the generated datasets and further finetuning them on the corresponding reference dataset to evaluate whether it results in significant improvements in the recognition capability.\n\nTo evaluate both robustness and fine-tuning potential, we split each generated dataset into training, validation, and test sets, ensuring that a portion of the data remained unseen for evaluation at later stages. Additionally, models were tested on unseen data by evaluating them on the original test splits of MELD, IEMOCAP, and EmoryNLP. In the literature, this evaluation strategy-train on synthetic, test on real (TSTR)-is commonly used to assess the effectiveness of synthetic data in downstream tasks and represents the most suitable evaluation scheme for our study  [37] ,  [38] .\n\nAfter splitting the datasets, we trained the CoMPM, EmoOne-RoBERTa, and TODKAT architectures separately using the training splits of the generated datasets. Once training was completed, we fine-tuned all models on the training splits of MELD, IEMOCAP, and EmoryNLP for domain adaptation. Finally, we evaluated the fine-tuned models on the test splits of MELD, IEMOCAP, and EmoryNLP to assess: 1. whether they function as robust ERC classifiers, and 2. whether models trained on synthetic data exhibit improved performance compared to their original versions. The results of this experiment can be seen in Tab. III An initial review of Table  III  shows that models trained on LLM-generated datasets exhibit strong robustness and generalization capabilities, producing ERC models that perform comparably to or better than those trained on original datasets. Most importantly, across all classifier architectures, models trained on generated datasets (highlighted in gray backgrounds) consistently outperform their original counterparts across all three benchmarks. This demonstrates that even small LLMgenerated datasets can enhance ERC classifier performance through transfer learning, thereby achieving the primary objective of this study.",
      "page_start": 5,
      "page_end": 6
    },
    {
      "section_name": "B. Assessment Of The Effects Of Different Label Distributions",
      "text": "In this subsection, we compare model performances across different synthetic label distributions, as presented in Table  III . Surprisingly, our experiments reveal that not all benchmarks behave similarly when evaluating models trained on datasets with different label distributions. Balanced datasets yielded the highest scores on the MELD dataset across all classifiers, highlight that this dataset needs much more balanced labels to be",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "C. Further Validation On Findings",
      "text": "To further validate our findings, we conducted an additional experiment, where we subjected the models used in Section IV-A to unseen test data split from the generated datasets additionally. The models were then ranked across all test sets and architectures to enable a comparative analysis.\n\nWe performed a Friedman rank sum test  [39] , which is a non-parametric statistical test that has been established as a scientifically valid way to evaluate the significant improvement of a classifier in comparison to several others over various datasets  [40] . Due to the relatively small number of classifiers  (9)  and datasets (9), we could not resort to chi-squared approximations and calculated the exact p-values using the formula introduced by Eisinga et al.  [41] .\n\nThe Friedman test is non-parametric, as the dataset does not follow a normal distribution. Consequently, ranking-based analysis is applied instead of using raw W-F1 scores. Each trained model instance-whether trained solely on the original dataset or pretrained on synthetic data and subsequently finetuned on the original dataset-was assigned a rank from 1 (highest W-F1 score) to 9 (lowest W-F1 score). This ranking procedure was repeated for each test set, corresponding to each row in Table  IV .\n\nAfter ranking, the rank sums for each model across all test sets were calculated. A lower rank sum indicates consistently strong performance, while a higher rank sum suggests weaker performance across the test sets. The rank sum of models pretrained on synthetic datasets (and fine-tuned on the original dataset) was then subtracted from the rank sum of models trained solely on the original dataset. If the rank sum of a model pretrained on synthetic data was lower than that of a model trained solely on the original dataset, this indicated that the pretrained model exhibited stronger overall performance. Conversely, if the rank sum was higher, the original model outperformed the pretrained one. Significant differences in rank sums suggested consistent performance disparities, which could indicate statistical significance.\n\nBonferroni-corrected p-values were calculated to provide a quantitative measure of statistical significance  [42] . Table  IV  presents each model's rank (in parentheses), rank sums, and absolute differences. The bottom row of the table provides the corresponding Bonferroni-corrected p-values.\n\nThe low p-values obtained through the Friedman rank sum test suggest that it is highly unlikely that the performance improvements of models pretrained on synthetic data are due to random chance. This effect is especially evident in CoMPM and EmoOne-RoBERTa, which demonstrated the strongest performance across benchmarks. However, no statistical significance was observed for TODKAT, likely due to inherent limitations of this model. These results further reinforce the potential of LLMgenerated datasets in enhancing ERC classifier performance while highlighting variations in model-specific responses to synthetic pretraining.",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "V. Conclusion",
      "text": "This study introduces a reproducible, affordable, and computationally efficient approach for generating ERC datasets using a small, resource-efficient LLM with structured prompt engineering. By addressing key challenges such as soft labels, dataset incompatibilities, and class imbalance, our method enables scalable dataset creation without relying on expensive or black-box models. Our experimental results demonstrate that models trained on LLM-generated datasets exhibit enhanced recognition capabilities and improved performance on ERC benchmarks. We proposed a systematic approach to assessing the quality of these datasets, and confirmed their potential for fine-tuning ERC models. Statistical tests further solidify these findings, providing robust support for the impact of our approach. Additionally, we assessed the effects of having different label distributions in ERC, and our results highlight the need of having more balanced data for some particular benchmarks.\n\nLooking ahead, fine-tuning existing LLMs (e.g., Llama 3) could enable the generation of even larger and more diverse affective datasets, further improving dataset adaptability. Additionally, given that scalability is one of the biggest advantages of LLM synthetic data, the research on its effects in ERC is also can be an interesting direction. Moreover, our methodology provides a foundation for generating customizable datasets not only for ERC but also for other NLP tasks. By releasing our parameters, code, and prompts, we aim TABLE IV: Extended version of results(W-F1), in which the test results of test splits of generated datasets and Friedman test calculations included. The W-F1 scores are ranked row-wise (1 for the highest, 9 for the lowest), with the highest in bold. The \"Rank\" part shows the sum of ranks and the absolute difference between rank sums compared to the original dataset-trained counterpart. The \"p\" row provides the p-values from the Friedman rank sum test.  (6) 65.52 (4) 66.16 (3)  65.46 (5) 66.50 (2) 67.27 (1)  63.47 (9) 64.20 (8) 64.27 (7)   Nat 48.07 (7) 50.96 (1) 50.29 (3)  49.18 (6) 50.95 (2) 49.24 (5)  46.52 (9) 49.37 (4) 47.86 (8)   Bal 58.66 (8) 60.77 (6) 65.99 (2)  61.17 (5) 61.20 (4) 66.10 (1)  57.34 (9) 60.46 (7) 62.30 (3)   EMORY-NLP Org 37.25 (6) 39.50 (1) 38.93 (3)  35.93 (8) 38.79 (4) 39.05 (2)  35.38 (9) 36.77 (7) 37.40 (5)   Nat 31.66 (6) 35.89 (2) 34.00 (5)  28.85 (8) 34.06 (4) 34.73 (3)  28.37 (9) 37.14 (1) 31.12 (7)   Bal 47.67 (7) 53.39 (4) 60.86 (2)  46.91 (8) 50.51 (5) 60.92 (1)  38.15 (9) 49.71 (6) 56.95 (3)   IEMOCAP Org 65.21 (6) 68.06 (2) 67.87 (3)  67.19 (5) 69.28 (1) 67.81 (4)  54.63 (8) 55.96 (7) 53.39 (9)   Nat 16.76 (9) 37.58 (1) 27.08 (6)  19.84 (8) 35.85 (2) 27.89 (5)  26.02 (7) 30.86 (3) 30.27 (4)   Bal 34.05 (8) 53.89 (3) 59.62 (2)  33.20 (9) 50.26 (4) 60.35 (1)  40.23 (7) 41.94 (6) 47.64 (5)   Rank",
      "page_start": 6,
      "page_end": 7
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: shows an example of a dialogue generated by our LLM.",
      "page": 1
    },
    {
      "caption": "Figure 1: Example of a generated dialogue, featuring multiple",
      "page": 2
    },
    {
      "caption": "Figure 2: Label distribution of reference and generated datasets. The horizontal axis represents the number of utterances within",
      "page": 3
    },
    {
      "caption": "Figure 2: displays total utterances, label amounts",
      "page": 3
    },
    {
      "caption": "Figure 3: Prompt examples for each generated dataset. Each",
      "page": 4
    },
    {
      "caption": "Figure 2: shows that the balanced datasets",
      "page": 4
    },
    {
      "caption": "Figure 3: provides the prompts",
      "page": 4
    },
    {
      "caption": "Figure 1: displays an example of ERC",
      "page": 4
    },
    {
      "caption": "Figure 3: offers an",
      "page": 4
    },
    {
      "caption": "Figure 4: Diagram of our pipeline.",
      "page": 5
    },
    {
      "caption": "Figure 4: A. Assessing Synthetic Dataset Properties",
      "page": 5
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "∗Department of\nInformatics, University of Hamburg, Hamburg 22527, Germany"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "TABLE I: ERC datasets"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "Abstract—Emotion recognition in conversations (ERC)\nfocuses"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "on identifying emotion shifts within interactions, representing a"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "Dataset\nSource\nSpeaker\nEmotions\nLanguage"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "significant step toward advancing machine intelligence. However,"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "ERC data remains scarce, and existing datasets face numerous\nMELD [6]\nTV\nMultiple\n7\nEnglish"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "IEMOCAP [8]\nScripted\n2\n6\nEnglish\nchallenges due to their highly biased sources and the inherent"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "EmoryNLP [7]\nTV\n6\n7\nEnglish\nsubjectivity of soft\nlabels. Even though Large Language Models"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "DailyDialog [10]\nScripted\n2\n7\nEnglish"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "(LLMs) have demonstrated their quality in many affective tasks,"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "CPED [11]\nTV\nMultiple\n13\nChinese"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "they are\ntypically expensive\nto train, and their application to"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "EC [12]\nTwitter\n3\n4\nEnglish"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "ERC tasks—particularly in data generation—remains limited. To"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "KDEmor [13]\nTV\nMultiple\n3\nKorean"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "address these challenges, we employ a small, resource-efficient,"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "and\ngeneral-purpose LLM to\nsynthesize ERC datasets with"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "diverse properties, supplementing the three most widely used ERC"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "benchmarks. We generate six novel datasets, with two tailored\ninconsistent\nlabels for the same utterance. Typically, a majority"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "to enhance\neach benchmark. We\nevaluate\nthe utility of\nthese"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "vote is used to select a label when there is disagreement, but this"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "datasets to (1) supplement existing datasets for ERC classification,"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "process is limited by the small number of annotators (usually"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "and (2)\nanalyze\nthe\neffects\nof\nlabel\nimbalance\nin ERC. Our"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "3–5),\nleading to reliability issues\n[7],\n[8]. Additionally,\nas"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "experimental results indicate that ERC classifier models trained on"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "highlighted in Tab.\nI, existing ERC datasets vary significantly\nthe generated datasets exhibit strong robustness and consistently"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "achieve\nstatistically significant performance\nimprovements on\nin their emotion label sets, speaker numbers, and languages,"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "existing ERC benchmarks."
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "making it difficult\nto combine them effectively for\ntransfer"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "Index Terms—large language models, machine learning, data"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "learning. Furthermore, the inconsistencies in emotion categories"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "generation, affective computing"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "across datasets limit\ntheir interoperability,\nleading some studies"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "to rely on mappings based on psychological studies to align"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "I.\nINTRODUCTION"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "these different\nlabel\nsets\n[5]. However,\nsuch mappings\nare"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "Emotion recognition in conversations (ERC)\nis a relatively\noften\nrough\napproximations,\nraising\nconcerns\nabout\ntheir"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "new field of study that focuses on identifying and understanding\naccuracy and applicability. Rooted in the concept\nthat only"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "human emotions expressed during interactions [1].\nIts primary\nthe\nentity\nexpressing\na\nparticular\naffective\nstate\ncan\nfully"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "goal\nis to detect emotion shifts within dialogues, a capability\nrecognize\nit\n[9], we hypothesize\nthat by having the LLM"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "that has become increasingly important with the rise of social\ngenerate both utterances and their corresponding emotion labels"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "robotics\nand\napplications\nrequiring\nemotionally\nintelligent\nsimultaneously, we can address these issues and significantly"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "systems\n[2]. Large Language Models\n(LLMs) have demon-\nimprove dataset consistency. Tab. I highlights the characteristics"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "strated substantial\nimprovements in various natural\nlanguage\nof popular ERC datasets and underscores their\nlimitations."
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "processing (NLP)\ntasks,\nincluding affective\ncomputing [3],\nTo tackle these limitations, we propose leveraging a small,"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "and hold potential as effective tools for generating ERC data.\ngeneral-purpose LLM to synthesize new ERC datasets. By"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "Despite their success, most evaluations of LLMs in affective\ngenerating both dialogue lines and their corresponding emotion"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "tasks have been conducted with API-based models, which are\nlabels in a single step, we aim to improve the consistency and"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "expensive, or top-performing local models requiring significant\nreliability of ERC data while avoiding the costs and complexi-"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "computational\nresources [4],\n[5]. Exploring the capabilities of\nties associated with traditional data collection and annotation"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "small and general-purpose LLMs in ERC tasks thus emerges\nmethods. To ensure comparability with existing benchmarks,"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "as a promising and cost-efficient alternative.\nwe generate six new datasets, with two corresponding datasets"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "A critical challenge in ERC lies\nin the scarcity of high-\nfor\neach of\nthe\nthree widely used ERC benchmarks. This"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "quality, diverse datasets. Most existing datasets are derived\nalignment allows us\nto systematically evaluate the potential"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "from biased sources such as scripted TV shows or social media,\nof LLM-generated datasets to supplement existing resources,"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "which often feature\nimbalanced label distributions\n[6],\n[7].\nmitigate label imbalance, and enhance ERC model performance."
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "Moreover, crafting such datasets is costly and time-consuming\nFig. 1 shows an example of a dialogue generated by our LLM."
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "due\nto\nparticipant\nrecruitment,\nethical\nconcerns,\nunbiased\nOur contributions are as follows: Firstly, we demonstrate the"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "dialogue\nconstruction,\nand\nthe\ndifficulty\nof\naccurate\nand\ncapability of a small LLM to generate consistent, multi-party"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "consistent\nlabeling. Annotating emotional data often involves\nERC datasets suitable for\ntraining ERC models. Secondly, we"
        },
        {
          "Burak Can Kaplan∗, Hugo Cesar De Castro Carneiro∗, and Stefan Wermter∗": "subjective interpretations, with annotators frequently providing\npropose a methodology to evaluate the quality and validity of"
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "participated, and only 6.17% of\nthe annotations correspond to"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "labels in which there was an unanimous agreement among the"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "annotators. In 9.39% of the annotations, each annotator labeled"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "the same data with different\nlabel. Majority voting was used"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "to select\nthe annotation in most cases. The weighted F1 results"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "for EmoryNLP, as reported on Papers With Code, are around"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "35%, which is significantly lower compared to other datasets,"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "characterizing EmoryNLP as a challenging dataset."
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "IEMOCAP is a scripted dyadic dataset which also provides"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "multimodal\ninformation.\nIt encompasses 10 labels: Neutral,"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "Happiness, Sadness, Anger, Excited, Frustration, Fear, Surprise,"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "Disgust, and Other\n(Uninformative). Disgust does not show"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": ""
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "up in any record in the conversations of\nthe validation split."
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": ""
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "Classification tasks on IEMOCAP involve the utilization of"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "specific\nsubsets of\nits\navailable\nclasses. Those\nthat do not"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "include Disgust and Other are denoted 8-way. Fear and Surprise"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": ""
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "are very rare throughout\nthe dataset, so papers often do not"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": ""
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "include them. This classification task is denoted 6-way. Finally,"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": ""
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "although with more\nobservations, Excited\nand Frustration"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": ""
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "appear considerably less than Neutral, Happiness, Sadness, and"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": ""
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "Anger. A classification using solely these 4 labels is denoted"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": ""
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "4-way. Results aggregated on Papers With Code reveal\nthat"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": ""
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "weighted F1 scores\nfor\nIEMOCAP are slightly higher\nthan"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": ""
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "those for MELD regardless of\nthe number of classes used."
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": ""
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "This paper adopts the 6-way classification, as it\nis the most"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": ""
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "commonly employed approach in the literature."
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": ""
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": ""
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "B. LLM Usage"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": ""
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "MELD, IEMOCAP, and EmoryNLP are multimodal datasets,"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": ""
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "but\nthey are often exclusively benchmarked in the\ntextual"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": ""
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "modality [5],\n[14] due to the inherent noise in their audio"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": ""
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "and visual components, which poses challenges to ERC model"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": ""
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "training. Even though some approaches aim to enhance audio-"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": ""
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "visual data quality through preprocessing [15],\n[16] or modify-"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "ing the modality fusing approach [17]–[19], opportunities for"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "improvement\nin this field still persist. Language models are"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "frequently leveraged to increase the quality of existing datasets"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": ""
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "as well. For\ninstance, pretrained language models can provide"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": ""
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "additional\ninformation at\nthe utterance and conversation levels,"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": ""
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "thus increasing the context of an existing ERC dataset\n[20]."
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": ""
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "Additionally, LLMs are also used in annotation process of"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": ""
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "affective speech data to enhance its quality [4],\n[21]."
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": ""
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "Empathetic\nintelligence\nalso\nrequires measuring\nthe\nca-"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": ""
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "pabilities\nof\nan LLM in\nvarious\naffective\ntasks. Existing"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": ""
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "literature indicates that LLMs exhibit considerable empathetic"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": ""
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "intelligence. Zhu\net\nal.\n[22]\ndemonstrate\nthat\ntransformer-"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": ""
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "based architectures\nare\ncapable of distinguishing emotions"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": ""
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "in dialogues, and Deng et al. [23] use transformer architectures"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": ""
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "to generate dialogue responses. Amin et al [4] assess ChatGPT"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": ""
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "in\naffective\ncomputing,\nrevealing\nthat\neven\na\ngeneralized"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": ""
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "model can achieve decent\nresults. ChatGPT’s knowledge has"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": ""
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "been also measured in solving affective computing problems,"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": ""
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "namely sentiment analysis, personality assessment, and suicide"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": ""
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "tendency detection [3]. LLMs are also evaluated in tasks like"
        },
        {
          "Joyful, and Neutral. For\nthe annotation process, 4 annotators": "affective\nsupport, multi-party conversations\nand ERC [24],"
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Neutral": "Sadness",
          "Joy": "Disgust",
          "Sadness": "Surprise",
          "Joyful": "Scared",
          "Sad": "Peaceful",
          "Happiness": "Anger"
        },
        {
          "Neutral": "Frustration",
          "Joy": "",
          "Sadness": "",
          "Joyful": "",
          "Sad": "",
          "Happiness": "Excitement"
        },
        {
          "Neutral": "",
          "Joy": "",
          "Sadness": "",
          "Joyful": "",
          "Sad": "",
          "Happiness": ""
        },
        {
          "Neutral": "",
          "Joy": "",
          "Sadness": "",
          "Joyful": "",
          "Sad": "",
          "Happiness": ""
        },
        {
          "Neutral": "",
          "Joy": "",
          "Sadness": "",
          "Joyful": "",
          "Sad": "",
          "Happiness": ""
        },
        {
          "Neutral": "",
          "Joy": "",
          "Sadness": "",
          "Joyful": "",
          "Sad": "",
          "Happiness": ""
        },
        {
          "Neutral": "",
          "Joy": "",
          "Sadness": "",
          "Joyful": "",
          "Sad": "",
          "Happiness": ""
        },
        {
          "Neutral": "",
          "Joy": "",
          "Sadness": "",
          "Joyful": "",
          "Sad": "",
          "Happiness": ""
        },
        {
          "Neutral": "",
          "Joy": "",
          "Sadness": "",
          "Joyful": "",
          "Sad": "",
          "Happiness": ""
        },
        {
          "Neutral": "",
          "Joy": "",
          "Sadness": "",
          "Joyful": "",
          "Sad": "",
          "Happiness": ""
        },
        {
          "Neutral": "",
          "Joy": "",
          "Sadness": "",
          "Joyful": "",
          "Sad": "",
          "Happiness": ""
        },
        {
          "Neutral": "1,500",
          "Joy": "3,000",
          "Sadness": "12,000",
          "Joyful": "3,500",
          "Sad": "7,000 14,000",
          "Happiness": "3,000"
        }
      ],
      "page": 3
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Test\nTest\nTest": "3,000\n6,000\n12,000\n1,500\n3,000\n6,000\n3,500\n7,000 14,000"
        },
        {
          "Test\nTest\nTest": "(a) MELD\n(b) EmoryNLP\n(c)\nIEMOCAP"
        },
        {
          "Test\nTest\nTest": "Fig. 2: Label distribution of\nreference and generated datasets. The horizontal axis represents the number of utterances within"
        },
        {
          "Test\nTest\nTest": "each dataset, and is shown in a logarithmic scale to enhance the visualization of\nrare labels."
        },
        {
          "Test\nTest\nTest": "[25]. Tu\net\nal.\n[26]\nextract\ndetailed\nadditional\nknowledge\n13 billion-sized model appeared natural and required roughly"
        },
        {
          "Test\nTest\nTest": "from ERC data using ChatGPT and measures its impact on\n25 GB VRAM. Thus, we opted for using a small model with"
        },
        {
          "Test\nTest\nTest": "ERC models. Feng et\nal.\n[27]\nshow that LLMs\ncan serve\na\nreasonable GPU to offer\nan affordable\nand computation-"
        },
        {
          "Test\nTest\nTest": "as effective classifiers for affect\nrecognition in conversation\nefficient solution for ERC dataset generation, with Vicuna 1.52"
        },
        {
          "Test\nTest\nTest": "tasks. Additionally, LLM-based models have achieved high\nbeing the 13 billion-sized model\nto provide the best and most"
        },
        {
          "Test\nTest\nTest": "classification scores on widely used ERC datasets [5],\nfurther\nconsistent\nresults, and one of\nthe most popular open sourced"
        },
        {
          "Test\nTest\nTest": "supporting the suitability of LLMs for ERC data generation.\nLLMs."
        },
        {
          "Test\nTest\nTest": "There are approaches to enhance the LLMs’ data generation"
        },
        {
          "Test\nTest\nTest": "A. Natural and Balanced Data"
        },
        {
          "Test\nTest\nTest": "capabilities. Eldan\net\nal.\n[28]\nemploy GPT-3.5\nand GPT-"
        },
        {
          "Test\nTest\nTest": "To assess our\nlocal LLMs’ capabilities in generating multi-"
        },
        {
          "Test\nTest\nTest": "4 to generate\nchild-level\nlanguage\nto train small\nlanguage"
        },
        {
          "Test\nTest\nTest": "party affective conversations across various aspects, we gen-"
        },
        {
          "Test\nTest\nTest": "models. Josifoski et al. [29] present a synthetic data generation"
        },
        {
          "Test\nTest\nTest": "erated\ntwo\ntypes\nof\ndataset with\nthe\nsame\nset\nof\nlabels"
        },
        {
          "Test\nTest\nTest": "pipeline that\ninvolves prompting LLMs to generate text\nfrom"
        },
        {
          "Test\nTest\nTest": "and\ndialogue\nstructure\nof\nthe\nthree mentioned\ndatasets\nin"
        },
        {
          "Test\nTest\nTest": "coherent\ntriplets extracted from a knowledge graph. Conversely,"
        },
        {
          "Test\nTest\nTest": "Sec.\nII-A, providing a total of 6 new datasets. These dataset"
        },
        {
          "Test\nTest\nTest": "Chung et al.\n[30] attempt\nto increase the diversity of LLM"
        },
        {
          "Test\nTest\nTest": "types\nare\nnamed\n“Natural”\nand\n“Balanced”. Each\ndataset"
        },
        {
          "Test\nTest\nTest": "data,\nacknowledging potential\ntrade-offs with lower output"
        },
        {
          "Test\nTest\nTest": "was\nintentionally\nover-generated\nto\nsafeguard\nagainst\ndata"
        },
        {
          "Test\nTest\nTest": "accuracy. Veselovsky et al.\n[31] use LLM synthetic data to"
        },
        {
          "Test\nTest\nTest": "limitations and to facilitate comparison with their corresponding"
        },
        {
          "Test\nTest\nTest": "train classifiers,\nevaluating them on real data with various"
        },
        {
          "Test\nTest\nTest": "original datasets. Fig. 2 displays total utterances,\nlabel amounts"
        },
        {
          "Test\nTest\nTest": "strategies.\nIn\nsummary,\nthe\nexisting\nliterature\nunderscores"
        },
        {
          "Test\nTest\nTest": "and label distributions of each dataset."
        },
        {
          "Test\nTest\nTest": "LLMs’ effectiveness in diverse affective tasks. However, despite"
        },
        {
          "Test\nTest\nTest": "Natural datasets comprise dialogues created freely by an"
        },
        {
          "Test\nTest\nTest": "the significant\nlimitations and noise present\nin existing ERC"
        },
        {
          "Test\nTest\nTest": "LLM without any predetermined bias in its generation process."
        },
        {
          "Test\nTest\nTest": "datasets,\nresearch on leveraging LLMs specifically for ERC"
        },
        {
          "Test\nTest\nTest": "These datasets show the broad potential of LLMs in creating"
        },
        {
          "Test\nTest\nTest": "data generation remains scarce,\nleaving an open opportunity"
        },
        {
          "Test\nTest\nTest": "dialogues, with the distribution of\nthe emotion labels within"
        },
        {
          "Test\nTest\nTest": "for\nfurther exploration in this direction."
        },
        {
          "Test\nTest\nTest": "them being\ncloser\nto\nreality. For\nexample,\nemotions\nlike"
        },
        {
          "Test\nTest\nTest": "happiness,\nsadness, or even the absence of emotions being\nIII. DATASET GENERATION"
        },
        {
          "Test\nTest\nTest": "far more\ncommon\nthan\nemotions\nlike\nfear\nand\nsurprise."
        },
        {
          "Test\nTest\nTest": "In the LLM selection phase, we ran small dialogue generation"
        },
        {
          "Test\nTest\nTest": "The generation of natural data is particularly useful\nfor\nthe"
        },
        {
          "Test\nTest\nTest": "experiments, and observed that 7 billion-sized models proved"
        },
        {
          "Test\nTest\nTest": "development of affective interactive systems, e.g., more realistic"
        },
        {
          "Test\nTest\nTest": "incapable of generating creative and diverse dialogues while"
        },
        {
          "Test\nTest\nTest": "and natural social\nrobots to be used in real-life applications."
        },
        {
          "Test\nTest\nTest": "keeping sufficient output\nconsistency for use\nas\na dataset,"
        },
        {
          "Test\nTest\nTest": "With natural datasets, we aim to assess how naturally LLMs"
        },
        {
          "Test\nTest\nTest": "often exhibiting repetitions of words or sentences. Regarding"
        },
        {
          "Test\nTest\nTest": "generate dialogues without emotional pre-conditioning."
        },
        {
          "Test\nTest\nTest": "the larger models, we decided not\nto use ChatGPT despite"
        },
        {
          "Test\nTest\nTest": "Balanced datasets, conversely, comprise dialogues with more"
        },
        {
          "Test\nTest\nTest": "yielding the most\nfavorable results, due to our emphasis on"
        },
        {
          "Test\nTest\nTest": "evenly distributed emotions and they are designed to address"
        },
        {
          "Test\nTest\nTest": "ensuring the\nreproducibility of our\napproach. Although 33"
        }
      ],
      "page": 3
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "0.7\n1\n10000\n1\n0.995"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "symbols and ask the LLM to provide one of\nthem for each"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "utterance. In the literature, the same logic is used in LLM Logic"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "Reasoning [32]–[34], and it is a proven technique that improves"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "the LLM performance.\nIn our case,\nthis method ensures the"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "generation of consistent\nlabels across datasets."
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "The\nlast\ntask involved employing a prompt\nto generate"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "structured outputs to facilitate the retrieval of the necessary data."
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "To ensure the parseability of\nthat structure, we instructed the"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "LLM to prepend speaker, utterance, and number\n(representing"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "emotion) to the corresponding data. Fig. 3 provides the prompts"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "used to generate\nthe dialogues with this\nstructure. At\nthe"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": ""
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "generation, all sentences are concatenated and submitted to the"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": ""
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "LLM as a single prompt. Fig. 1 displays an example of ERC"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": ""
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "dialogue generated by the LLM."
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": ""
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "For\nthe generation of balanced data,\nthe prompt\nis kept"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": ""
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "the same, except\nfor\nthe last part of\nthe first sentence, where"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "we instruct\nthe LLM to ensure the dialogue contains at\nleast"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "one utterance expressing a specific emotion. Fig. 3 offers an"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "example of prompt used to ensure the existence of at\nleast one"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "utterance expressing fear. To preserve the naturalness of\nthe"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "dialogue, we restrain from specifying the number associated"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "with that label. This prompt iterates through all labels within the"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "target dataset, ensuring an equal number of dialogues containing"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "utterances expressing some particular emotion."
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "We tested these prompts with the LLM several\ntimes with"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "the\nparameters\nprovided\nin Tab.\nII.\nIt was\nobserved\nthat"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "the LLM consistently produced the same outputs, ensuring"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "reproducibility. Specific words drive each LLM to produce"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "different outputs based on their weights, and the prompts here"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "offered were tailored for Vicuna 1.5(13b)."
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": ""
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "C. LLM Parameters"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": ""
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "For\nthe utilization of\nthe local LLM, we employed Textgen-"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "WebUI Chat API3 with Langchain4, which provides access to"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": ""
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "all LLM parameters. For reproducibility, the seed is randomized"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": ""
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "for diversity but fixed to maintain consistent\nrandom numbers"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": ""
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "for each LLM run. Tab.\nII shows all parameters used in our"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": ""
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "data generation process."
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": ""
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "Temperature is not crucial\nin our case due to the fixed seed,"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": ""
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "so we opted to keep it at\nits default value. We kept\ntop p,"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": ""
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "top k, and typical p very high,\nto enhance context diversity"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": ""
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "and provide more options in the dialogues. Furthermore, we"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": ""
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "minimized repetition penalty to avoid limiting the LLM based"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": ""
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "on the tokens it produced."
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": ""
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "IV. EXPERIMENTS AND ANALYSES"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": ""
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "As outlined in Section III-A,\ntwo datasets—natural\nand"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": ""
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "balanced—were generated for each of\nthe datasets discussed"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": ""
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "3https://github.com/oobabooga/text-generation-webui"
        },
        {
          "Temperature\nTop p\nTop k\nRP\nTyp. p": "4https://www.langchain.com/"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Fig. 4: Diagram of our pipeline.": "in Section\nIII-B. These\ndatasets\nshare\nthe\nsame\nspeakers,"
        },
        {
          "Fig. 4: Diagram of our pipeline.": "structure, and emotion label set as their corresponding datasets"
        },
        {
          "Fig. 4: Diagram of our pipeline.": "for\nthe purpose of comparison. To assess\nthe utility of\nthe"
        },
        {
          "Fig. 4: Diagram of our pipeline.": "generated datasets, we employed three popular ERC classifier"
        },
        {
          "Fig. 4: Diagram of our pipeline.": "architectures: CoMPM [35], EmoOne-RoBERTa\n[36],\nand"
        },
        {
          "Fig. 4: Diagram of our pipeline.": "TODKAT [22]. These models were\nchosen based on their"
        },
        {
          "Fig. 4: Diagram of our pipeline.": "available implementations and competitive performance scores"
        },
        {
          "Fig. 4: Diagram of our pipeline.": "on all three datasets: MELD, EmoryNLP, and IEMOCAP. These"
        },
        {
          "Fig. 4: Diagram of our pipeline.": "architectures were preferred over some state-of-the-art models"
        },
        {
          "Fig. 4: Diagram of our pipeline.": "due to factors such as the lack of\nimplementations for certain"
        },
        {
          "Fig. 4: Diagram of our pipeline.": "datasets or high VRAM requirements such as 4x80G nVidia"
        },
        {
          "Fig. 4: Diagram of our pipeline.": "A100 [5]. This decision aligns with our aim of delivering a"
        },
        {
          "Fig. 4: Diagram of our pipeline.": "reproducible and affordable solution. Furthermore,\nthe primary"
        },
        {
          "Fig. 4: Diagram of our pipeline.": "focus of\nthis research is not achieving the highest scores but"
        },
        {
          "Fig. 4: Diagram of our pipeline.": "demonstrating whether\nthe\ndatasets\ngenerated\nthrough\nour"
        },
        {
          "Fig. 4: Diagram of our pipeline.": "approach boost\nthe ERC classification\nprocess. To\nfurther"
        },
        {
          "Fig. 4: Diagram of our pipeline.": "validate our findings, we\nconducted statistical\ntests on the"
        },
        {
          "Fig. 4: Diagram of our pipeline.": "experiment\nresults\nfrom the\nthree\nclassifier\narchitectures,"
        },
        {
          "Fig. 4: Diagram of our pipeline.": "ensuring the significance of our conclusions. The entire pipeline"
        },
        {
          "Fig. 4: Diagram of our pipeline.": "used for evaluation is illustrated in Fig. 4."
        },
        {
          "Fig. 4: Diagram of our pipeline.": ""
        },
        {
          "Fig. 4: Diagram of our pipeline.": "A. Assessing Synthetic Dataset Properties"
        },
        {
          "Fig. 4: Diagram of our pipeline.": ""
        },
        {
          "Fig. 4: Diagram of our pipeline.": "To evaluate the utility of\nthe generated datasets\nfor ERC"
        },
        {
          "Fig. 4: Diagram of our pipeline.": "and the methodology proposed in this paper, we need to assess"
        },
        {
          "Fig. 4: Diagram of our pipeline.": "whether\nthese datasets possess desirable properties relevant\nto"
        },
        {
          "Fig. 4: Diagram of our pipeline.": "the task. These properties\ninclude: 1. having all\ntheir\nsplits"
        },
        {
          "Fig. 4: Diagram of our pipeline.": "sampled from the\nsame distribution; 2. being able\nto train"
        },
        {
          "Fig. 4: Diagram of our pipeline.": "models to be robust\nto unseen data; and 3. having the potential"
        },
        {
          "Fig. 4: Diagram of our pipeline.": "to pretrain models for better performance when fine-tuned with"
        },
        {
          "Fig. 4: Diagram of our pipeline.": "benchmark datasets. The first property is guaranteed by our"
        },
        {
          "Fig. 4: Diagram of our pipeline.": "methodology since dialogues are independently generated by"
        },
        {
          "Fig. 4: Diagram of our pipeline.": "the LLM using the same prompt and parameters. As dialogues"
        },
        {
          "Fig. 4: Diagram of our pipeline.": "are\nindependently\ngenerated\nand\nthe\ndataset\nis\nonly\nsplit"
        },
        {
          "Fig. 4: Diagram of our pipeline.": ""
        },
        {
          "Fig. 4: Diagram of our pipeline.": "afterward,\nall generated datasets have\nsplits\nsampled from"
        },
        {
          "Fig. 4: Diagram of our pipeline.": "the same distribution. The second property requires training"
        },
        {
          "Fig. 4: Diagram of our pipeline.": "ERC architectures on the generated datasets and subjecting"
        },
        {
          "Fig. 4: Diagram of our pipeline.": "them to unseen data. The third property involves training the"
        },
        {
          "Fig. 4: Diagram of our pipeline.": "same architectures on the generated datasets and further fine-"
        },
        {
          "Fig. 4: Diagram of our pipeline.": "tuning them on the corresponding reference dataset\nto evaluate"
        },
        {
          "Fig. 4: Diagram of our pipeline.": "whether it results in significant improvements in the recognition"
        },
        {
          "Fig. 4: Diagram of our pipeline.": "capability."
        }
      ],
      "page": 5
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "distinction. The highest scores for each benchmark is marked": ""
        },
        {
          "distinction. The highest scores for each benchmark is marked": "in bold."
        },
        {
          "distinction. The highest scores for each benchmark is marked": ""
        },
        {
          "distinction. The highest scores for each benchmark is marked": ""
        },
        {
          "distinction. The highest scores for each benchmark is marked": ""
        },
        {
          "distinction. The highest scores for each benchmark is marked": ""
        },
        {
          "distinction. The highest scores for each benchmark is marked": ""
        },
        {
          "distinction. The highest scores for each benchmark is marked": ""
        },
        {
          "distinction. The highest scores for each benchmark is marked": "MELD"
        },
        {
          "distinction. The highest scores for each benchmark is marked": ""
        },
        {
          "distinction. The highest scores for each benchmark is marked": ""
        },
        {
          "distinction. The highest scores for each benchmark is marked": ""
        },
        {
          "distinction. The highest scores for each benchmark is marked": "EMORYNLP"
        },
        {
          "distinction. The highest scores for each benchmark is marked": ""
        },
        {
          "distinction. The highest scores for each benchmark is marked": ""
        },
        {
          "distinction. The highest scores for each benchmark is marked": ""
        },
        {
          "distinction. The highest scores for each benchmark is marked": ""
        },
        {
          "distinction. The highest scores for each benchmark is marked": "IEMOCAP"
        },
        {
          "distinction. The highest scores for each benchmark is marked": ""
        },
        {
          "distinction. The highest scores for each benchmark is marked": ""
        },
        {
          "distinction. The highest scores for each benchmark is marked": ""
        }
      ],
      "page": 6
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": ""
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": "across all\nthree benchmarks (wf1). Org denotes scores from"
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": ""
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": "the original dataset, while generated dataset scores (Nat and"
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": ""
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": "Bal) are highlighted with a colored background for clearer"
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": ""
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": "distinction. The highest scores for each benchmark is marked"
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": ""
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": "in bold."
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": ""
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": ""
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": "Test Set\nComPM\nEmoOne\nTODKAT"
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": ""
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": "Org\n65.43\n65.46\n63.47"
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": ""
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": "MELD\nNat\n65.52\n66.50\n64.20"
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": "66.16\n67.27\n64.27\nBal"
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": ""
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": "Org\n37.25\n35.93\n35.38"
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": "EMORYNLP\n39.50\nNat\n38.79\n36.77"
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": "39.05\n37.40\nBal\n38.93"
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": ""
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": "Org\n65.21\n67.19\n54.63"
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": ""
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": "IEMOCAP\n68.06\n69.28\n55.96\nNat"
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": ""
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": "Bal\n67.87\n67.81\n53.39"
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": ""
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": ""
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": "more effective for ERC.\nIn contrast, models trained on natural"
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": "datasets performed best on IEMOCAP, suggesting that class"
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": "imbalance is less critical\nfor\nthis benchmark and that\ntraining"
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": "should prioritize data that\nreflects real-world distributions. For"
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": "EmoryNLP, classification scores were consistently lower\nthan"
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": "in the other\ntwo benchmarks,\nindicating its greater complexity."
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": "Moreover, no clear advantage was observed between training"
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": "on balanced versus natural datasets\nfor\nthis dataset. These"
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": "findings suggest\nthat\nthe impact of label distributions on model"
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": "performance is dataset-dependent, highlighting the importance"
        },
        {
          "TABLE III: Performance\nresults\nof\nthree ERC classifiers": "of\ntailoring\nsynthetic\ndataset\ngeneration\nstrategies\nto\nthe"
        }
      ],
      "page": 6
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "counterpart. The “p” row provides the p-values from the Friedman rank sum test.": ""
        },
        {
          "counterpart. The “p” row provides the p-values from the Friedman rank sum test.": ""
        },
        {
          "counterpart. The “p” row provides the p-values from the Friedman rank sum test.": ""
        },
        {
          "counterpart. The “p” row provides the p-values from the Friedman rank sum test.": ""
        },
        {
          "counterpart. The “p” row provides the p-values from the Friedman rank sum test.": "MELD"
        },
        {
          "counterpart. The “p” row provides the p-values from the Friedman rank sum test.": ""
        },
        {
          "counterpart. The “p” row provides the p-values from the Friedman rank sum test.": ""
        },
        {
          "counterpart. The “p” row provides the p-values from the Friedman rank sum test.": "EMORY-NLP"
        },
        {
          "counterpart. The “p” row provides the p-values from the Friedman rank sum test.": ""
        },
        {
          "counterpart. The “p” row provides the p-values from the Friedman rank sum test.": ""
        },
        {
          "counterpart. The “p” row provides the p-values from the Friedman rank sum test.": "IEMOCAP"
        },
        {
          "counterpart. The “p” row provides the p-values from the Friedman rank sum test.": ""
        },
        {
          "counterpart. The “p” row provides the p-values from the Friedman rank sum test.": "Rank"
        },
        {
          "counterpart. The “p” row provides the p-values from the Friedman rank sum test.": ""
        },
        {
          "counterpart. The “p” row provides the p-values from the Friedman rank sum test.": ""
        },
        {
          "counterpart. The “p” row provides the p-values from the Friedman rank sum test.": ""
        }
      ],
      "page": 7
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "p\n0.0034\n0.0186\n-": "to facilitate further\nresearch in synthetic data generation for",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "[12] A. Chatterjee, K. N. Narahari, M. Joshi, and P. Agrawal, “SemEval-2019"
        },
        {
          "p\n0.0034\n0.0186\n-": "",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "Task 3: EmoContext contextual emotion detection in text,” in Proceedings"
        },
        {
          "p\n0.0034\n0.0186\n-": "affective computing and beyond.",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": ""
        },
        {
          "p\n0.0034\n0.0186\n-": "",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "of the 13th International Workshop on Semantic Evaluation, (Minneapolis,"
        },
        {
          "p\n0.0034\n0.0186\n-": "",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "Minnesota, USA), pp. 39–48, Association for Computational Linguistics,"
        },
        {
          "p\n0.0034\n0.0186\n-": "",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "2019."
        },
        {
          "p\n0.0034\n0.0186\n-": "REFERENCES",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": ""
        },
        {
          "p\n0.0034\n0.0186\n-": "",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "[13]\nS. Pant, E. Lim, H.-J. Yang, G.-S. Lee, S.-H. Kim, Y.-S. Kang, and"
        },
        {
          "p\n0.0034\n0.0186\n-": "",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "H. Jang, “Korean drama scene transcript dataset\nfor emotion recognition"
        },
        {
          "p\n0.0034\n0.0186\n-": "S. Poria, N. Majumder, R. Mihalcea, and E. Hovy, “Emotion recognition\n[1]",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "in conversations,” IEEE Access, vol. 10, pp. 119221–119231, 2022."
        },
        {
          "p\n0.0034\n0.0186\n-": "in conversation: Research challenges, datasets, and recent advances,”",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "[14] X. Song, L. Huang, H. Xue, and S. Hu, “Supervised prototypical con-"
        },
        {
          "p\n0.0034\n0.0186\n-": "IEEE Access, vol. 7, pp. 100943–100953, 2019.",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "trastive learning for emotion recognition in conversation,” in Proceedings"
        },
        {
          "p\n0.0034\n0.0186\n-": "[2] H. Mahdi, S. A. Akgun, S. Saleh, and K. Dautenhahn, “A survey on",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "of\nthe 2022 Conference on Empirical Methods\nin Natural Language"
        },
        {
          "p\n0.0034\n0.0186\n-": "the design and evolution of social\nrobots — Past, present and future,”",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "Processing (Y. Goldberg, Z. Kozareva, and Y. Zhang, eds.),\n(Abu Dhabi,"
        },
        {
          "p\n0.0034\n0.0186\n-": "Robotics and Autonomous Systems, vol. 156, p. 104193, Oct. 2022.",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "United Arab Emirates), pp. 5197–5206, Association for Computational"
        },
        {
          "p\n0.0034\n0.0186\n-": "[3] M. M. Amin, E. Cambria, and B. W. Schuller, “Can ChatGPT’s responses",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "Linguistics, Dec. 2022."
        },
        {
          "p\n0.0034\n0.0186\n-": "boost\ntraditional natural\nlanguage processing?,” IEEE Intelligent Systems,",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "[15]\nJ. Pohjalainen, F. Fabien Ringeval, Z. Zhang, and B. Schuller, “Spectral"
        },
        {
          "p\n0.0034\n0.0186\n-": "vol. 38, no. 5, pp. 5–11, 2023.",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "and\ncepstral\naudio\nnoise\nreduction\ntechniques\nin\nspeech\nemotion"
        },
        {
          "p\n0.0034\n0.0186\n-": "[4] M. M. Amin, E. Cambria, and B. W. Schuller, “Will affective computing",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "the 24th ACM International Conference\nrecognition,” in Proceedings of"
        },
        {
          "p\n0.0034\n0.0186\n-": "emerge from foundation models and general AI? A first evaluation on",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "on Multimedia,\n(Amsterdam, The Netherlands), pp. 670–674, ACM, Oct."
        },
        {
          "p\n0.0034\n0.0186\n-": "ChatGPT,” 2023.\narXiv:2303.03186 [cs].",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "2016."
        },
        {
          "p\n0.0034\n0.0186\n-": "S. Lei, G. Dong, X. Wang, K. Wang,\nand S. Wang,\n“InstructERC:\n[5]",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "[16] H. Carneiro, C. Weber,\nand S. Wermter,\n“Whose\nemotion matters?"
        },
        {
          "p\n0.0034\n0.0186\n-": "Reforming emotion recognition in conversation with a retrieval multi-",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "Speaking activity localisation without prior knowledge,” Neurocomputing,"
        },
        {
          "p\n0.0034\n0.0186\n-": "task LLMs framework,” Nov. 2023.\narXiv:2309.11911 [cs].",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "vol. 545, p. 126271, Aug. 2023."
        },
        {
          "p\n0.0034\n0.0186\n-": "S.\nPoria, D. Hazarika, N. Majumder, G. Naik,\nE. Cambria,\nand\n[6]",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "[17] D. Hu, X. Hou, L. Wei, L. Jiang, and Y. Mo, “MM-DFN: Multimodal"
        },
        {
          "p\n0.0034\n0.0186\n-": "R. Mihalcea, “MELD: A multimodal multi-party dataset\nfor emotion",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "dynamic fusion network for emotion recognition in conversations,” in"
        },
        {
          "p\n0.0034\n0.0186\n-": "the 57th Annual Meeting\nrecognition in conversations,” in Proceedings of",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech"
        },
        {
          "p\n0.0034\n0.0186\n-": "of\nthe Association\nfor Computational Linguistics,\n(Florence,\nItaly),",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "and Signal Processing (ICASSP), (Singapore, Singapore), pp. 7037–7041,"
        },
        {
          "p\n0.0034\n0.0186\n-": "pp. 527–536, Association for Computational Linguistics, July 2019.",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "IEEE, May 2022."
        },
        {
          "p\n0.0034\n0.0186\n-": "[7]\nS. M. Zahiri and J. D. Choi, “Emotion detection on TV show transcripts",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "[18] X. Zhang and Y. Li, “A cross-modality context\nfusion and semantic"
        },
        {
          "p\n0.0034\n0.0186\n-": "with sequence-based convolutional neural networks,” in Workshops of",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "refinement network for emotion recognition in conversation,” in Proceed-"
        },
        {
          "p\n0.0034\n0.0186\n-": "the Thirty-Second AAAI Conference on Artificial\nIntelligence, pp. 44–51,",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "ings of\nthe 61st Annual Meeting of\nthe Association for Computational"
        },
        {
          "p\n0.0034\n0.0186\n-": "2018.",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "Linguistics (Volume 1: Long Papers)\n(A. Rogers, J. Boyd-Graber, and"
        },
        {
          "p\n0.0034\n0.0186\n-": "[8] C. Busso, M. Bulut, C.-C. Lee, A. Kazemzadeh, E. Mower, S. Kim, J. N.",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "N. Okazaki, eds.),\n(Toronto, Canada), pp. 13099–13110, Association for"
        },
        {
          "p\n0.0034\n0.0186\n-": "Chang, S. Lee, and S. S. Narayanan, “IEMOCAP:\nInteractive emotional",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "Computational Linguistics, July 2023."
        },
        {
          "p\n0.0034\n0.0186\n-": "dyadic motion capture database,” Language Resources and Evaluation,",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "[19]\nL. Maoheng, “Enhanced emotion recognition through multimodal\nfusion"
        },
        {
          "p\n0.0034\n0.0186\n-": "vol. 42, pp. 335–359, Dec. 2008.",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "using trimodal\nfusion graph convolutional networks,” in 2024 Interna-"
        },
        {
          "p\n0.0034\n0.0186\n-": "[9] R. W. Picard, Affective computing. MIT press, 2000.",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "tional Joint Conference on Neural Networks (IJCNN), pp. 1–9, 2024."
        },
        {
          "p\n0.0034\n0.0186\n-": "[10] Y. Li, H. Su, X. Shen, W. Li, Z. Cao, and S. Niu, “DailyDialog: A",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "[20]\nJ. Kim, H. Ko, S. Song, S. Jang, and J. Hong, “Contextual augmentation"
        },
        {
          "p\n0.0034\n0.0186\n-": "the\nmanually labelled multi-turn dialogue dataset,” in Proceedings of",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "of pretrained language models for emotion recognition in conversations,”"
        },
        {
          "p\n0.0034\n0.0186\n-": "Eighth International Joint Conference on Natural Language Processing",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "the Third Workshop on Computational Modeling\nin Proceedings of"
        },
        {
          "p\n0.0034\n0.0186\n-": "(Volume 1: Long Papers)\n(G. Kondrak and T. Watanabe, eds.),\n(Taipei,",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "of People’s Opinions, Personality,\nand Emotion’s\nin\nSocial Media,"
        },
        {
          "p\n0.0034\n0.0186\n-": "Taiwan), pp. 986–995, Asian Federation of Natural Language Processing,",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "(Barcelona, Spain (Online)), pp. 64–73, Association for Computational"
        },
        {
          "p\n0.0034\n0.0186\n-": "Nov. 2017.",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "Linguistics, Dec. 2020."
        },
        {
          "p\n0.0034\n0.0186\n-": "[11] Y. Chen, W. Fan, X. Xing, J. Pang, M. Huang, W. Han, Q. Tie, and X. Xu,",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "[21]\nS. Latif, M. Usama, M.\nI. Malik,\nand B. W. Schuller,\n“Can\nlarge"
        },
        {
          "p\n0.0034\n0.0186\n-": "“CPED: A large-scale Chinese personalized and emotional dialogue",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "language models aid in annotating speech emotional data? Uncovering"
        },
        {
          "p\n0.0034\n0.0186\n-": "dataset\nfor conversational AI,” May 2022.\narXiv:2205.14727 [cs].",
          "0.0186\n0.0034\n-\n-\n0.1273\n0.2025": "new frontiers,” July 2023.\narXiv:2307.06090 [cs, eess]."
        }
      ],
      "page": 7
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "and\nknowledge-aware\ntransformer\nfor\ndialogue\nemotion\ndetection,”",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": "for pairwise comparison of Friedman rank sums, with application to"
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "of\nthe\n59th Annual Meeting\nof\nthe Association\nfor\nin Proceedings",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": "comparing classifiers,” BMC Bioinformatics, vol. 18, p. 68, Dec. 2017."
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "Computational Linguistics and the 11th International Joint Conference",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": "J. Dunn,"
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "on Natural Language Processing (Volume 1: Long Papers),\n(Online),",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": "American Statistical Association, vol. 56, pp. 52–64, Mar. 1961."
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "pp. 1571–1582, Association for Computational Linguistics, Aug. 2021.",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "[23] Q. Deng, L. Wu, K. Su, W. Wu, Z. Li, and W. Duan, “Hierarchical",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "fusion framework for multimodal dialogue response generation,” in 2024",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "International Joint Conference on Neural Networks (IJCNN), pp. 1–8,",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "2024.",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "[24] W.\nZhao, Y.\nZhao, X.\nLu,\nS. Wang, Y.\nTong,\nand B. Qin,\n“Is",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "ChatGPT equipped with emotional dialogue capabilities?,” Apr. 2023.",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "arXiv:2304.09582 [cs].",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "[25] C.-H. Tan, J.-C. Gu, and Z.-H. Ling, “Is ChatGPT a good multi-party",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "the Association for Computational\nconversation solver?,” in Findings of",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "Linguistics: EMNLP 2023 (H. Bouamor,\nJ. Pino, and K. Bali, eds.),",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "(Singapore, Singapore), pp. 4905–4915, Association for Computational",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "Linguistics, Dec. 2023.",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "[26] G. Tu, B. Liang, B. Qin, K.-F. Wong,\nand R. Xu,\n“An\nempirical",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "study on multiple knowledge from ChatGPT for emotion recognition",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "the Association for Computational\nin conversations,”\nin Findings of",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "Linguistics: EMNLP 2023,\n(Singapore), pp. 12160–12173, Association",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "for Computational Linguistics, 2023.",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "[27]\nS. Feng, G. Sun, N. Lubis, C. Zhang, and M. Gaˇsi´c, “Affect\nrecog-",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "nition\nin\nconversations\nusing\nlarge\nlanguage models,”\nSept.\n2023.",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "arXiv:2309.12881 [cs].",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "[28] R. Eldan and Y. Li, “TinyStories: How small can language models be",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "and still speak coherent English?,” May 2023.\narXiv:2305.07759 [cs].",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "[29] M. Josifoski, M. Sakota, M. Peyrard, and R. West, “Exploiting asymmetry",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "for synthetic training data generation: SynthIE and the case of information",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "extraction,” in Proceedings of the 2023 Conference on Empirical Methods",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "in Natural Language Processing (H. Bouamor, J. Pino, and K. Bali, eds.),",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "(Singapore), pp. 1555–1574, Association for Computational Linguistics,",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "Dec. 2023.",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "[30]\nJ. J. Y. Chung, E. Kamar, and S. Amershi, “Increasing diversity while",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "maintaining accuracy: Text data generation with large language models",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "the 61st Annual Meeting of\nand human interventions,” in Proceedings of",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "the Association for Computational Linguistics Volume 1: Long Papers,",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "pp. 575–593, Association for Computational Linguistics, July 2023.",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "[31] V. Veselovsky, M. H. Ribeiro, A. Arora, M.\nJosifoski, A. Anderson,",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "and R. West, “Generating faithful\nsynthetic data with large language",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "models: A case\nstudy\nin\ncomputational\nsocial\nscience,” May\n2023.",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "arXiv:2305.15041 [cs].",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "[32] H. Zhang, L. H. Li, T. Meng, K.-W. Chang, and G. Van Den Broeck,",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "the\n“On the paradox of\nlearning to reason from data,” in Proceedings of",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "Thirty-Second International Joint Conference on Artificial\nIntelligence,",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "IJCAI\n’23, 2023.",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "[33] A. Creswell and M. Shanahan, “Faithful\nreasoning using large language",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "models,” Aug. 2022.\narXiv:2208.14271 [cs].",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "[34]\nS. Qiao, Y. Ou, N. Zhang, X. Chen, Y. Yao, S. Deng, C. Tan, F. Huang,",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "and H. Chen, “Reasoning with language model prompting: A survey,”",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "of\nthe\n61st Annual Meeting\nof\nthe Association\nfor\nin Proceedings",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "Computational Linguistics (Volume 1: Long Papers) (A. Rogers, J. Boyd-",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "Graber,\nand N. Okazaki,\neds.),\n(Toronto, Canada),\npp.\n5368–5393,",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "Association for Computational Linguistics, July 2023.",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "[35]\nJ. Lee and W. Lee, “CoMPM: Context modeling with speaker’s pre-",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "trained memory tracking for emotion recognition in conversation,” in",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "Proceedings of\nthe 2022 Conference of\nthe North American Chapter",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "of\nthe Association for Computational Linguistics: Human Language",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "Technologies,\n(Seattle, United States), pp. 5669–5679, Association for",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "Computational Linguistics, July 2022.",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "[36]\nJ. Lee, “The emotion is not one-hot encoding: Learning with grayscale",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "label\nfor\nemotion recognition in conversation,”\nin Interspeech 2022,",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "pp. 141–145,\nISCA, Sept. 2022.",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "[37]\nS. L. Hyland, C. Esteban, and G. R¨atsch, “Real-valued (medical)\ntime",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "series generation with recurrent conditional gans,” stat, vol. 1050, p. 8,",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "2017.",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "[38] Y. Yuan, Y. Liu, and L. Cheng, “A multi-faceted evaluation framework",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "for assessing synthetic data generated by large language models,” 2024.",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "[39] M. Friedman, “The use of\nranks to avoid the assumption of normality",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "the American Statistical\nimplicit\nin the analysis of variance,” Journal of",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "Association, vol. 32, pp. 675–701, Dec. 1937.",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "J. Demˇsar, “Statistical comparisons of classifiers over multiple data sets,”\n[40]",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        },
        {
          "[22]\nL. Zhu, G.\nPergola, L. Gui, D. Zhou,\nand Y. He,\n“Topic-driven": "Journal of Machine Learning Research, vol. 7, pp. 1–30, Dec. 2006.",
          "[41] R. Eisinga, T. Heskes, B. Pelzer, and M. Te Grotenhuis, “Exact p-values": ""
        }
      ],
      "page": 8
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Emotion recognition in conversation: Research challenges, datasets, and recent advances",
      "authors": [
        "S Poria",
        "N Majumder",
        "R Mihalcea",
        "E Hovy"
      ],
      "year": "2019",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "2",
      "title": "A survey on the design and evolution of social robots -Past, present and future",
      "authors": [
        "H Mahdi",
        "S Akgun",
        "S Saleh",
        "K Dautenhahn"
      ],
      "year": "2022",
      "venue": "Robotics and Autonomous Systems"
    },
    {
      "citation_id": "3",
      "title": "Can ChatGPT's responses boost traditional natural language processing?",
      "authors": [
        "M Amin",
        "E Cambria",
        "B Schuller"
      ],
      "year": "2023",
      "venue": "IEEE Intelligent Systems"
    },
    {
      "citation_id": "4",
      "title": "Will affective computing emerge from foundation models and general AI? A first evaluation on ChatGPT",
      "authors": [
        "M Amin",
        "E Cambria",
        "B Schuller"
      ],
      "year": "2023",
      "venue": "Will affective computing emerge from foundation models and general AI? A first evaluation on ChatGPT",
      "arxiv": "arXiv:2303.03186"
    },
    {
      "citation_id": "5",
      "title": "InstructERC: Reforming emotion recognition in conversation with a retrieval multitask LLMs framework",
      "authors": [
        "S Lei",
        "G Dong",
        "X Wang",
        "K Wang",
        "S Wang"
      ],
      "year": "2023",
      "venue": "InstructERC: Reforming emotion recognition in conversation with a retrieval multitask LLMs framework",
      "arxiv": "arXiv:2309.11911"
    },
    {
      "citation_id": "6",
      "title": "MELD: A multimodal multi-party dataset for emotion recognition in conversations",
      "authors": [
        "S Poria",
        "D Hazarika",
        "N Majumder",
        "G Naik",
        "E Cambria",
        "R Mihalcea"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "7",
      "title": "Emotion detection on TV show transcripts with sequence-based convolutional neural networks",
      "authors": [
        "S Zahiri",
        "J Choi"
      ],
      "year": "2018",
      "venue": "Workshops of the Thirty-Second AAAI Conference on Artificial Intelligence"
    },
    {
      "citation_id": "8",
      "title": "IEMOCAP: Interactive emotional dyadic motion capture database",
      "authors": [
        "C Busso",
        "M Bulut",
        "C.-C Lee",
        "A Kazemzadeh",
        "E Mower",
        "S Kim",
        "J Chang",
        "S Lee",
        "S Narayanan"
      ],
      "year": "2008",
      "venue": "Language Resources and Evaluation"
    },
    {
      "citation_id": "9",
      "title": "Affective computing",
      "authors": [
        "R Picard"
      ],
      "year": "2000",
      "venue": "Affective computing"
    },
    {
      "citation_id": "10",
      "title": "DailyDialog: A manually labelled multi-turn dialogue dataset",
      "authors": [
        "Y Li",
        "H Su",
        "X Shen",
        "W Li",
        "Z Cao",
        "S Niu"
      ],
      "year": "2017",
      "venue": "Proceedings of the Eighth International Joint Conference on Natural Language Processing"
    },
    {
      "citation_id": "11",
      "title": "CPED: A large-scale Chinese personalized and emotional dialogue dataset for conversational AI",
      "authors": [
        "Y Chen",
        "W Fan",
        "X Xing",
        "J Pang",
        "M Huang",
        "W Han",
        "Q Tie",
        "X Xu"
      ],
      "year": "2022",
      "venue": "CPED: A large-scale Chinese personalized and emotional dialogue dataset for conversational AI",
      "arxiv": "arXiv:2205.14727"
    },
    {
      "citation_id": "12",
      "title": "SemEval-2019 Task 3: EmoContext contextual emotion detection in text",
      "authors": [
        "A Chatterjee",
        "K Narahari",
        "M Joshi"
      ],
      "year": "2019",
      "venue": "Proceedings of the 13th International Workshop on Semantic Evaluation"
    },
    {
      "citation_id": "13",
      "title": "Korean drama scene transcript dataset for emotion recognition in conversations",
      "authors": [
        "S Pant",
        "E Lim",
        "H.-J Yang",
        "G.-S Lee",
        "S.-H Kim",
        "Y.-S Kang",
        "H Jang"
      ],
      "year": "2022",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "14",
      "title": "Supervised prototypical contrastive learning for emotion recognition in conversation",
      "authors": [
        "X Song",
        "L Huang",
        "H Xue",
        "S Hu"
      ],
      "year": "2022",
      "venue": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "15",
      "title": "Spectral and cepstral audio noise reduction techniques in speech emotion recognition",
      "authors": [
        "J Pohjalainen",
        "F Fabien Ringeval",
        "Z Zhang",
        "B Schuller"
      ],
      "year": "2016",
      "venue": "Proceedings of the 24th ACM International Conference on Multimedia"
    },
    {
      "citation_id": "16",
      "title": "Whose emotion matters? Speaking activity localisation without prior knowledge",
      "authors": [
        "H Carneiro",
        "C Weber",
        "S Wermter"
      ],
      "year": "2023",
      "venue": "Neurocomputing"
    },
    {
      "citation_id": "17",
      "title": "MM-DFN: Multimodal dynamic fusion network for emotion recognition in conversations",
      "authors": [
        "D Hu",
        "X Hou",
        "L Wei",
        "L Jiang",
        "Y Mo"
      ],
      "year": "2022",
      "venue": "ICASSP 2022 -2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
    },
    {
      "citation_id": "18",
      "title": "A cross-modality context fusion and semantic refinement network for emotion recognition in conversation",
      "authors": [
        "X Zhang",
        "Y Li"
      ],
      "year": "2023",
      "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "19",
      "title": "Enhanced emotion recognition through multimodal fusion using trimodal fusion graph convolutional networks",
      "authors": [
        "L Maoheng"
      ],
      "year": "2024",
      "venue": "2024 International Joint Conference on Neural Networks (IJCNN)"
    },
    {
      "citation_id": "20",
      "title": "Contextual augmentation of pretrained language models for emotion recognition in conversations",
      "authors": [
        "J Kim",
        "H Ko",
        "S Song",
        "S Jang",
        "J Hong"
      ],
      "year": "2020",
      "venue": "Proceedings of the Third Workshop on Computational Modeling of People's Opinions, Personality, and Emotion's in Social Media"
    },
    {
      "citation_id": "21",
      "title": "Can large language models aid in annotating speech emotional data? Uncovering new frontiers",
      "authors": [
        "S Latif",
        "M Usama",
        "M Malik",
        "B Schuller"
      ],
      "year": "2023",
      "venue": "Can large language models aid in annotating speech emotional data? Uncovering new frontiers",
      "arxiv": "arXiv:2307.06090"
    },
    {
      "citation_id": "22",
      "title": "Topic-driven and knowledge-aware transformer for dialogue emotion detection",
      "authors": [
        "L Zhu",
        "G Pergola",
        "L Gui",
        "D Zhou",
        "Y He"
      ],
      "year": "2021",
      "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing"
    },
    {
      "citation_id": "23",
      "title": "Hierarchical fusion framework for multimodal dialogue response generation",
      "authors": [
        "Q Deng",
        "L Wu",
        "K Su",
        "W Wu",
        "Z Li",
        "W Duan"
      ],
      "year": "2024",
      "venue": "2024 International Joint Conference on Neural Networks (IJCNN)"
    },
    {
      "citation_id": "24",
      "title": "Is ChatGPT equipped with emotional dialogue capabilities?",
      "authors": [
        "W Zhao",
        "Y Zhao",
        "X Lu",
        "S Wang",
        "Y Tong",
        "B Qin"
      ],
      "year": "2023",
      "venue": "Is ChatGPT equipped with emotional dialogue capabilities?",
      "arxiv": "arXiv:2304.09582"
    },
    {
      "citation_id": "25",
      "title": "Is ChatGPT a good multi-party conversation solver?",
      "authors": [
        "C.-H Tan",
        "J.-C Gu",
        "Z.-H Ling"
      ],
      "year": "2023",
      "venue": "Findings of the Association for Computational Linguistics: EMNLP 2023"
    },
    {
      "citation_id": "26",
      "title": "An empirical study on multiple knowledge from ChatGPT for emotion recognition in conversations",
      "authors": [
        "G Tu",
        "B Liang",
        "B Qin",
        "K.-F Wong",
        "R Xu"
      ],
      "year": "2023",
      "venue": "Findings of the Association for Computational Linguistics: EMNLP 2023"
    },
    {
      "citation_id": "27",
      "title": "Affect recognition in conversations using large language models",
      "authors": [
        "S Feng",
        "G Sun",
        "N Lubis",
        "C Zhang",
        "M Gašić"
      ],
      "venue": "Affect recognition in conversations using large language models",
      "arxiv": "arXiv:2309.12881"
    },
    {
      "citation_id": "28",
      "title": "TinyStories: How small can language models be and still speak coherent English?",
      "authors": [
        "R Eldan",
        "Y Li"
      ],
      "year": "2023",
      "venue": "TinyStories: How small can language models be and still speak coherent English?",
      "arxiv": "arXiv:2305.07759"
    },
    {
      "citation_id": "29",
      "title": "Exploiting asymmetry for synthetic training data generation: SynthIE and the case of information extraction",
      "authors": [
        "M Josifoski",
        "M Sakota",
        "M Peyrard",
        "R West"
      ],
      "year": "2023",
      "venue": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "30",
      "title": "Increasing diversity while maintaining accuracy: Text data generation with large language models and human interventions",
      "authors": [
        "J Chung",
        "E Kamar",
        "S Amershi"
      ],
      "year": "2023",
      "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "31",
      "title": "Generating faithful synthetic data with large language models: A case study in computational social science",
      "authors": [
        "V Veselovsky",
        "M Ribeiro",
        "A Arora",
        "M Josifoski",
        "A Anderson",
        "R West"
      ],
      "year": "2023",
      "venue": "Generating faithful synthetic data with large language models: A case study in computational social science",
      "arxiv": "arXiv:2305.15041"
    },
    {
      "citation_id": "32",
      "title": "On the paradox of learning to reason from data",
      "authors": [
        "H Zhang",
        "L Li",
        "T Meng",
        "K.-W Chang",
        "G Van Den",
        "Broeck"
      ],
      "year": "2023",
      "venue": "Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence, IJCAI '23"
    },
    {
      "citation_id": "33",
      "title": "Faithful reasoning using large language models",
      "authors": [
        "A Creswell",
        "M Shanahan"
      ],
      "year": "2022",
      "venue": "Faithful reasoning using large language models",
      "arxiv": "arXiv:2208.14271"
    },
    {
      "citation_id": "34",
      "title": "Reasoning with language model prompting: A survey",
      "authors": [
        "S Qiao",
        "Y Ou",
        "N Zhang",
        "X Chen",
        "Y Yao",
        "S Deng",
        "C Tan",
        "F Huang",
        "H Chen"
      ],
      "year": "2023",
      "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "35",
      "title": "CoMPM: Context modeling with speaker's pretrained memory tracking for emotion recognition in conversation",
      "authors": [
        "J Lee",
        "W Lee"
      ],
      "year": "2022",
      "venue": "Proceedings of the 2022 Conference of the North American Chapter"
    },
    {
      "citation_id": "36",
      "title": "The emotion is not one-hot encoding: Learning with grayscale label for emotion recognition in conversation",
      "authors": [
        "J Lee"
      ],
      "year": "2022",
      "venue": "Interspeech 2022"
    },
    {
      "citation_id": "37",
      "title": "Real-valued (medical) time series generation with recurrent conditional gans",
      "authors": [
        "S Hyland",
        "C Esteban",
        "G Rätsch"
      ],
      "year": "2017",
      "venue": "stat"
    },
    {
      "citation_id": "38",
      "title": "A multi-faceted evaluation framework for assessing synthetic data generated by large language models",
      "authors": [
        "Y Yuan",
        "Y Liu",
        "L Cheng"
      ],
      "year": "2024",
      "venue": "A multi-faceted evaluation framework for assessing synthetic data generated by large language models"
    },
    {
      "citation_id": "39",
      "title": "The use of ranks to avoid the assumption of normality implicit in the analysis of variance",
      "authors": [
        "M Friedman"
      ],
      "year": "1937",
      "venue": "Journal of the American Statistical Association"
    },
    {
      "citation_id": "40",
      "title": "Statistical comparisons of classifiers over multiple data sets",
      "authors": [
        "J Demšar"
      ],
      "year": "2006",
      "venue": "Journal of Machine Learning Research"
    },
    {
      "citation_id": "41",
      "title": "Exact p-values for pairwise comparison of Friedman rank sums, with application to comparing classifiers",
      "authors": [
        "R Eisinga",
        "T Heskes",
        "B Pelzer",
        "M Grotenhuis"
      ],
      "year": "2017",
      "venue": "BMC Bioinformatics"
    },
    {
      "citation_id": "42",
      "title": "Multiple comparisons among means",
      "authors": [
        "O Dunn"
      ],
      "year": "1961",
      "venue": "Journal of the American Statistical Association"
    }
  ]
}