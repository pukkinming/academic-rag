{
  "paper_id": "2407.14576v1",
  "title": "A Comparative Study Of Transfer Learning For Emotion Recognition Using Cnn And Modified Vgg16 Models",
  "published": "2024-07-19T17:41:46Z",
  "authors": [
    "Samay Nathani"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Emotion recognition is a critical aspect of human interaction. This topic garnered significant attention in the field of artificial intelligence. In this study, we investigate the performance of convolutional neural network (CNN) and Modified VGG16 models for emotion recognition tasks across two datasets: FER2013 and AffectNet. Our aim is to measure the effectiveness of these models in identifying emotions and their ability to generalize to different and broader datasets. Our findings reveal that both models achieve reasonable performance on the FER2013 dataset, with the Modified VGG16 model demonstrating slightly increased accuracy. When evaluated on the Affect-Net dataset, performance declines for both models, with the Modified VGG16 model continuing to outperform the CNN. Our study emphasizes the importance of dataset diversity in emotion recognition and discusses open problems and future research directions, including the exploration of multimodal approaches and the development of more comprehensive datasets.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Human emotion recognition based on facial expression plays an integral role in various applications within computing, such as human-computer interaction  [1]  and affective computing  [3] , and outside of computing like mental health assessments  [6] . However, accurate emotion recognition remains a challenging computer vision problem due to the complexity and variability of facial expressions, and also emotion classes are at the cusp of subjective and objective. Transfer learning is a strong candidate to address this challenge by using pre-trained deep learning models on larger and more diverse datasets to improve performance on target tasks with limited data. While previous research has explored transfer learning for emotion recognition using deep learning architectures like VGG16  [5] , there re-main gaps in generalization for emotion recognition outside of a controlled setting. In this study, we aim to fill this gap by conducting a comprehensive analysis of transfer learning using a CNN based on the original VGG16 model and a modified VGG16 models for emotion recognition. We will investigate how these models perform when transferred from a source dataset (FER2013) to a target dataset (Affect-Net), analyze their strengths and limitations, and identify strategies to improve their performance. By discussing the strengths and weaknesses of different transfer learning approaches, our project aims to provide useful information for improving emotion recognition and understanding the underlying structures of these models.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Methodology",
      "text": "In this study, our hypothesis is that transfer learning using deep learning architectures can improve the accuracy of emotion recognition on target datasets with limited training data. To investigate this hypothesis, we utilize two widely used datasets: the Facial Expression Recognition 2013 (FER2013) dataset  [2]  as the source dataset and Af-fectNet  [4]  as the target dataset. The FER2013 dataset consists of grayscale images of facial expressions categorized into seven emotion classes: angry, disgust, fear, happy, sad, surprise, and neutral. On the other hand, modified version of AffectNet dataset provides more diverse examples for facial expressions, along with mixed backgrounds, angles, and people, making it a suitable target dataset for evaluating transfer learning approaches. We preprocess the image data by resizing them to 48x48 pixels and normalizing pixel values to the range [0, 1]. For our experiments, we select two deep learning architectures: Convolutional Neural Network (CNN) and a modified VGG16.\n\nThe modified VGG16 model presented here is a modified version of the original VGG16 architecture, with several key differences aimed at enhancing its capacity and performance.\n\nThe original VGG16 architecture comprises 13 convolu-tional and 3 fully connected layers. In contrast, the modified VGG16 model incorporates an additional convolutional layer in each convolutional block, resulting in a total of 16 convolutional layers. This increased depth allows the model to learn more intricate hierarchical representations of the input data, potentially capturing finer details and patterns. The modified VGG16 model introduces an extra fully connected layer with 2048 neurons between the existing fully connected layers. This additional layer provides the model with more capacity to capture complex relationships in the learned features, potentially improving its discriminative power.\n\nThe fully connected layers in the modified VGG16 model contains a larger number of neurons compared to the original VGG16 architecture. Specifically, the first two fully connected layers have 4096 neurons each, while the additional layer has 2048 neurons. This increased number of neurons in the fully connected layers enables the model to learn more diverse and expressive representations from the convolutional feature maps.\n\nA dropout rate of 0.25 is employed after each fully connected layer in the modified VGG16 model. Dropout regularization helps prevent overfitting by randomly dropping a fraction of the neurons during training, encouraging the network to learn more generalizable features. In the original VGG16 model, dropout values are 0.5 after each fully connected layer. Rather than remove it, its inclusion in the modified architecture reinforces the model's capacity to generalize effectively.\n\nThe modified VGG16 model incorporates a learning rate scheduler using the ReduceLROnPlateau callback. This dynamic adjustment of the learning rate during training helps fine-tune the optimization process, potentially leading to improved convergence and performance.\n\nIn summary, the modified VGG16 model distinguishes itself from the original VGG16 architecture through its increased depth, additional fully connected layer, larger number of neurons, dropout regularization, and learning rate scheduler. These modifications are designed to augment the model's capacity to learn intricate representations of the input data and enhance its performance in emotion recognition tasks. While the efficacy of these enhancements may vary depending on the specific dataset and task, we believe that they collectively contribute to the model's superiority over the original VGG16 architecture in capturing and discriminating emotional cues.\n\nThese models are pretrained on the FER2013 dataset and fine-tuned on the modified AffectNet dataset using transfer learning techniques. We evaluate the performance of each model based on standard metrics such as accuracy, precision, recall, and F1-score, which are commonly used in classification tasks to assess the model's ability to correctly classify emotions. We also incorporate predictive entropy as a performance metric. Predictive entropy measures uncertainty of the model's predictions, and is calculated using probability distribution of the predicted class probabilities. Entropy is directly correlated with uncertainty, and this metric is useful in gauging the model's ability to predict and perform in ambiguous situations. Ultimately, this metric highlights not just the performance of the model, but rather its reliability and robustness.\n\nAccess the notebook with the models and training data here.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Experimental Results & Discussion",
      "text": "The performance metrics of the CNN and Modified VGG16 models are compared across two different datasets: FER2013 and AffectNet.\n\nOn the FER2013 Dataset, the CNN achieved an accuracy of 66.20%, with precision, recall, and F1-score all hovering around the same range of approximately 66%. The predictive entropy was measured at 0.3977. The modified VGG16 outperformed the CNN model slightly, with an accuracy of 67.43% and similar precision, recall, and F1-score metrics. The predictive entropy increased to 0.5588, indicating slightly higher uncertainty in the model's predictions compared to the CNN. The slight improvement in performance metrics, particularly accuracy, suggests that the modified VGG16 model may have learned more complex features and patterns from the FER2013 dataset compared to the CNN model. However, it is also possible that the increase in accuracy may be the result of overfitting.\n\nOn the AffectNet Dataset, the CNN experienced a decrease in accuracy to 41.43%. Precision, recall and F1-score decreased significantly. The Modified VGG16 showed similar trends to the CNN model, with an accuracy of 42.86% and a decrease in recall and F1-score compared to the FER2013 evaluation. The decline in performance metrics when transitioning from the FER2013 to the AffectNet dataset suggests that both models may struggle to generalize well to different datasets with varying characteristics and distributions of emotional expressions. However, the accuracy, precision, and recall scores were all greater with the modified VGG16 model, suggesting the more complex architecture played a role its higher performance on the target dataset.\n\nWhile the Modified VGG16 model demonstrated slightly superior performance compared to the CNN model on the FER2013 dataset, both models experienced a notable decrease in performance when evaluated on the AffectNet dataset. This highlights the importance of dataset diversity and the challenges of generalization in emotion recognition tasks. Further improvements in model architectures and training methodologies may be necessary to enhance performance across diverse datasets.\n\nThe CNN, known for its simplicity and computational efficiency, emerged as a baseline in our comparative analysis. Its architecture, characterized by alternating convolutional and pooling layers, demonstrated success in extracting spatial features from input images. As a result, the CNN exhibited modest yet robust performance in capturing the subtle nuances of emotional cues, achieving competitive accuracy and precision scores across multiple emotion classes well above random.\n\nIn contrast, the modified VGG16 model has a slightly deeper and more complex architecture. The modified VGG16 model showcased slightly superior performance compared to the CNN, achieving greater accuracy, precision, and recall scores across a range of emotion classes.\n\nHowever, the heightened performance of the modified VGG16 model came at the expense of increased computational complexity and resource requirements. Its more complex architecture, comprising multiple convolutional and fully connected layers, required longer training times, higher memory consumption, and overall more compute resources. As a result, the practical usage of the modified VGG16 model may be hindered by its computational demands, particularly in resource-constrained environments, all for marginally better performance when compared to the CNN.\n\nFurthermore, our analysis revealed insights into the tradeoffs between model complexity and generalization. While the modified VGG16 model demonstrated notable proficiency with the training data, concerns regarding overfitting were observed, particularly when trained on smaller datasets. This highlights the importance of regularization techniques and data augmentation strategies to mitigate the risk of overfitting.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Conclusion",
      "text": "This study investigated the performance of CNN and Modified VGG16 models for emotion recognition tasks across two datasets, FER2013 and AffectNet. We aimed to assess the effectiveness of these models in recognizing emotion and their ability to generalize to more diverse datasets.\n\nOur findings revealed that both models achieved reasonable performance on the FER2013 dataset, with the Modified VGG16 model exhibiting slightly superior accuracy compared to the CNN model, which was based on the original VGG16 model. However, when evaluated on the Af-fectNet dataset, both models experienced a decrease in performance, which speaks to the challenges of generalization to new data.\n\nA highlight from this study is the importance of dataset diversity in training and evaluating. The performance disparities observed between the FER2013 and AffectNet datasets emphasize the need for more comprehensive and representative datasets to improve the robustness and generalization capabilities of these models.\n\nDespite the preliminary results achieved on the FER2013 dataset, this study calls out open problems and areas for future research. One such area is the exploration of multimodal approaches to emotion recognition, which integrate information from facial images, text, and audio to enhance model performance.\n\nAdditionally, addressing the limitations of existing datasets and developing improved methods for data collection and annotation could further improve accuracy and reliability. Furthermore, investigating the influence cultural differences and situational contexts could provide valuable insights into the complexities of human emotion recognition.\n\nTo conclude, our study contributes to the ongoing research in emotion recognition by highlighting strengths and limitations of CNN and Modified VGG16 models and by calling out the importance of dataset diversity and future research directions. By addressing these challenges and exploring new avenues for research, we can advance the field of emotion recognition and its applications in affective computing and human-computer interaction.",
      "page_start": 3,
      "page_end": 4
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: CNN Accuracy on the FER2013 dataset",
      "page": 3
    },
    {
      "caption": "Figure 2: CNN Loss on the FER2013 dataset",
      "page": 4
    },
    {
      "caption": "Figure 3: Modified VGG16 Loss on the FER2013 dataset",
      "page": 4
    },
    {
      "caption": "Figure 4: Modified VGG16 Accuracy on the FER2013 dataset",
      "page": 4
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "sn3062@columbia.edu": "Abstract"
        },
        {
          "sn3062@columbia.edu": ""
        },
        {
          "sn3062@columbia.edu": "Emotion recognition is a critical aspect of human in-"
        },
        {
          "sn3062@columbia.edu": "teraction.\nThis topic garnered significant attention in the"
        },
        {
          "sn3062@columbia.edu": "field of artificial\nintelligence.\nIn this study, we investigate"
        },
        {
          "sn3062@columbia.edu": "the performance of convolutional neural network (CNN)"
        },
        {
          "sn3062@columbia.edu": "and Modified VGG16 models for emotion recognition tasks"
        },
        {
          "sn3062@columbia.edu": "across\ntwo datasets:\nFER2013 and AffectNet.\nOur aim"
        },
        {
          "sn3062@columbia.edu": "is\nto measure\nthe\neffectiveness of\nthese models\nin iden-"
        },
        {
          "sn3062@columbia.edu": "tifying emotions and their ability to generalize to differ-"
        },
        {
          "sn3062@columbia.edu": "ent and broader datasets.\nOur findings\nreveal\nthat both"
        },
        {
          "sn3062@columbia.edu": "models achieve reasonable performance on the FER2013"
        },
        {
          "sn3062@columbia.edu": "dataset, with the Modified VGG16 model demonstrating"
        },
        {
          "sn3062@columbia.edu": "slightly increased accuracy. When evaluated on the Affect-"
        },
        {
          "sn3062@columbia.edu": "Net dataset, performance declines for both models, with the"
        },
        {
          "sn3062@columbia.edu": ""
        },
        {
          "sn3062@columbia.edu": "Modified VGG16 model continuing to outperform the CNN."
        },
        {
          "sn3062@columbia.edu": "Our study emphasizes the importance of dataset diversity in"
        },
        {
          "sn3062@columbia.edu": "emotion recognition and discusses open problems and fu-"
        },
        {
          "sn3062@columbia.edu": "ture research directions, including the exploration of multi-"
        },
        {
          "sn3062@columbia.edu": "modal approaches and the development of more compre-"
        },
        {
          "sn3062@columbia.edu": "hensive datasets."
        },
        {
          "sn3062@columbia.edu": ""
        },
        {
          "sn3062@columbia.edu": ""
        },
        {
          "sn3062@columbia.edu": ""
        },
        {
          "sn3062@columbia.edu": "1. Introduction"
        },
        {
          "sn3062@columbia.edu": ""
        },
        {
          "sn3062@columbia.edu": ""
        },
        {
          "sn3062@columbia.edu": "Human emotion recognition based on facial expression"
        },
        {
          "sn3062@columbia.edu": ""
        },
        {
          "sn3062@columbia.edu": "plays an integral\nrole in various applications within com-"
        },
        {
          "sn3062@columbia.edu": ""
        },
        {
          "sn3062@columbia.edu": "puting, such as human-computer interaction [1] and affec-"
        },
        {
          "sn3062@columbia.edu": ""
        },
        {
          "sn3062@columbia.edu": "tive computing [3], and outside of computing like mental"
        },
        {
          "sn3062@columbia.edu": ""
        },
        {
          "sn3062@columbia.edu": "health assessments [6]. However, accurate emotion recog-"
        },
        {
          "sn3062@columbia.edu": ""
        },
        {
          "sn3062@columbia.edu": "nition remains a challenging computer vision problem due"
        },
        {
          "sn3062@columbia.edu": ""
        },
        {
          "sn3062@columbia.edu": "to the complexity and variability of facial expressions, and"
        },
        {
          "sn3062@columbia.edu": ""
        },
        {
          "sn3062@columbia.edu": "also emotion classes are at\nthe cusp of subjective and ob-"
        },
        {
          "sn3062@columbia.edu": ""
        },
        {
          "sn3062@columbia.edu": "jective. Transfer\nlearning is a strong candidate to address"
        },
        {
          "sn3062@columbia.edu": "this challenge by using pre-trained deep learning models on"
        },
        {
          "sn3062@columbia.edu": "larger and more diverse datasets\nto improve performance"
        },
        {
          "sn3062@columbia.edu": "on target\ntasks with limited data. While previous research"
        },
        {
          "sn3062@columbia.edu": "has explored transfer\nlearning for emotion recognition us-"
        },
        {
          "sn3062@columbia.edu": "ing deep learning architectures like VGG16 [5],\nthere re-"
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "fied VGG16 model incorporates an additional convolutional",
          "as a performance metric. Predictive entropy measures un-": "certainty of\nthe model’s predictions, and is calculated us-"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "layer in each convolutional block, resulting in a total of 16",
          "as a performance metric. Predictive entropy measures un-": "ing\nprobability distribution of the predicted class probabil-"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "convolutional layers. This increased depth allows the model",
          "as a performance metric. Predictive entropy measures un-": "ities.\nEntropy is directly correlated with uncertainty, and"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "to learn more intricate hierarchical representations of the in-",
          "as a performance metric. Predictive entropy measures un-": "this metric is useful\nin gauging the model’s ability to pre-"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "put data, potentially capturing finer details and patterns.",
          "as a performance metric. Predictive entropy measures un-": "dict and perform in ambiguous situations. Ultimately,\nthis"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "The modified VGG16 model\nintroduces an extra fully",
          "as a performance metric. Predictive entropy measures un-": "metric highlights not just the performance of the model, but"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "connected layer with 2048 neurons between the existing",
          "as a performance metric. Predictive entropy measures un-": "rather its reliability and robustness."
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "fully connected layers. This additional\nlayer provides the",
          "as a performance metric. Predictive entropy measures un-": "Access the notebook with the models and training data"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "model with more capacity to capture complex relationships",
          "as a performance metric. Predictive entropy measures un-": "here."
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "in the learned features, potentially improving its discrimi-",
          "as a performance metric. Predictive entropy measures un-": ""
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "native power.",
          "as a performance metric. Predictive entropy measures un-": "3. Experimental Results & Discussion"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "The\nfully\nconnected\nlayers\nin\nthe modified VGG16",
          "as a performance metric. Predictive entropy measures un-": ""
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "",
          "as a performance metric. Predictive entropy measures un-": "The\nperformance metrics\nof\nthe CNN and Modified"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "model contains a larger number of neurons compared to",
          "as a performance metric. Predictive entropy measures un-": ""
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "",
          "as a performance metric. Predictive entropy measures un-": "VGG16 models are compared across two different datasets:"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "the original VGG16 architecture. Specifically,\nthe first\ntwo",
          "as a performance metric. Predictive entropy measures un-": ""
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "",
          "as a performance metric. Predictive entropy measures un-": "FER2013 and AffectNet."
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "fully connected layers have 4096 neurons each, while the",
          "as a performance metric. Predictive entropy measures un-": ""
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "",
          "as a performance metric. Predictive entropy measures un-": "On the FER2013 Dataset,\nthe CNN achieved an accu-"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "additional\nlayer has 2048 neurons. This increased number",
          "as a performance metric. Predictive entropy measures un-": ""
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "",
          "as a performance metric. Predictive entropy measures un-": "racy of 66.20%, with precision, recall, and F1-score all hov-"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "of neurons in the fully connected layers enables the model",
          "as a performance metric. Predictive entropy measures un-": ""
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "",
          "as a performance metric. Predictive entropy measures un-": "ering around the same range of approximately 66%.\nThe"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "to learn more diverse and expressive representations from",
          "as a performance metric. Predictive entropy measures un-": ""
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "",
          "as a performance metric. Predictive entropy measures un-": "predictive entropy was measured at 0.3977. The modified"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "the convolutional feature maps.",
          "as a performance metric. Predictive entropy measures un-": ""
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "",
          "as a performance metric. Predictive entropy measures un-": "VGG16 outperformed the CNN model slightly, with an ac-"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "A dropout rate of 0.25 is employed after each fully con-",
          "as a performance metric. Predictive entropy measures un-": ""
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "",
          "as a performance metric. Predictive entropy measures un-": "curacy of 67.43% and similar precision, recall, and F1-score"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "nected layer in the modified VGG16 model. Dropout regu-",
          "as a performance metric. Predictive entropy measures un-": ""
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "",
          "as a performance metric. Predictive entropy measures un-": "metrics.\nThe predictive entropy increased to 0.5588,\nin-"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "larization helps prevent overfitting by randomly dropping a",
          "as a performance metric. Predictive entropy measures un-": ""
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "",
          "as a performance metric. Predictive entropy measures un-": "dicating slightly higher uncertainty in the model’s predic-"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "fraction of the neurons during training, encouraging the net-",
          "as a performance metric. Predictive entropy measures un-": ""
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "",
          "as a performance metric. Predictive entropy measures un-": "tions compared to the CNN. The slight improvement in per-"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "work to learn more generalizable features.\nIn the original",
          "as a performance metric. Predictive entropy measures un-": ""
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "",
          "as a performance metric. Predictive entropy measures un-": "formance metrics, particularly accuracy,\nsuggests that\nthe"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "VGG16 model, dropout values are 0.5 after each fully con-",
          "as a performance metric. Predictive entropy measures un-": ""
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "",
          "as a performance metric. Predictive entropy measures un-": "modified VGG16 model may have learned more complex"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "nected layer. Rather than remove it, its inclusion in the mod-",
          "as a performance metric. Predictive entropy measures un-": ""
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "",
          "as a performance metric. Predictive entropy measures un-": "features and patterns from the FER2013 dataset compared"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "ified architecture reinforces the model’s capacity to gener-",
          "as a performance metric. Predictive entropy measures un-": ""
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "",
          "as a performance metric. Predictive entropy measures un-": "to the CNN model. However,\nit\nis also possible that\nthe"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "alize effectively.",
          "as a performance metric. Predictive entropy measures un-": ""
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "",
          "as a performance metric. Predictive entropy measures un-": "increase in accuracy may be the result of overfitting."
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "The modified VGG16 model incorporates a learning rate",
          "as a performance metric. Predictive entropy measures un-": ""
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "",
          "as a performance metric. Predictive entropy measures un-": "On the AffectNet Dataset,\nthe CNN experienced a de-"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "scheduler using the ReduceLROnPlateau callback. This dy-",
          "as a performance metric. Predictive entropy measures un-": ""
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "",
          "as a performance metric. Predictive entropy measures un-": "crease in accuracy to 41.43%. Precision, recall and F1-score"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "namic adjustment of the learning rate during training helps",
          "as a performance metric. Predictive entropy measures un-": ""
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "",
          "as a performance metric. Predictive entropy measures un-": "decreased significantly. The Modified VGG16 showed sim-"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "fine-tune the optimization process, potentially leading to",
          "as a performance metric. Predictive entropy measures un-": ""
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "",
          "as a performance metric. Predictive entropy measures un-": "ilar trends to the CNN model, with an accuracy of 42.86%"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "improved convergence and performance.",
          "as a performance metric. Predictive entropy measures un-": ""
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "",
          "as a performance metric. Predictive entropy measures un-": "and\na\ndecrease\nin recall\nand F1-score\ncompared\nto the"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "In summary,\nthe modified VGG16 model distinguishes",
          "as a performance metric. Predictive entropy measures un-": "FER2013 evaluation.\nThe decline\nin performance met-"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "itself from the original VGG16 architecture through its in-",
          "as a performance metric. Predictive entropy measures un-": "rics when transitioning from the FER2013 to the AffectNet"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "creased depth, additional fully connected layer, larger num-",
          "as a performance metric. Predictive entropy measures un-": "dataset\nsuggests\nthat both models may struggle to gener-"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "ber of neurons, dropout\nregularization,\nand learning rate",
          "as a performance metric. Predictive entropy measures un-": "alize well\nto different datasets with varying characteristics"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "scheduler. These modifications are designed to augment the",
          "as a performance metric. Predictive entropy measures un-": "and distributions of emotional expressions. However,\nthe"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "model’s capacity to learn intricate representations of the in-",
          "as a performance metric. Predictive entropy measures un-": "accuracy, precision, and recall scores were all greater with"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "put data and enhance its performance in emotion recogni-",
          "as a performance metric. Predictive entropy measures un-": "the modified VGG16 model, suggesting the more complex"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "tion tasks. While the efficacy of these enhancements may",
          "as a performance metric. Predictive entropy measures un-": "architecture played a role its higher performance on the tar-"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "vary depending on the specific dataset and task, we believe",
          "as a performance metric. Predictive entropy measures un-": "get dataset."
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "that\nthey collectively contribute to the model’s superiority",
          "as a performance metric. Predictive entropy measures un-": "While the Modified VGG16 model demonstrated slightly"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "over the original VGG16 architecture in capturing and dis-",
          "as a performance metric. Predictive entropy measures un-": "superior performance compared to the CNN model on the"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "criminating emotional cues.",
          "as a performance metric. Predictive entropy measures un-": "FER2013 dataset, both models experienced a notable de-"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "These models are pretrained on the FER2013 dataset and",
          "as a performance metric. Predictive entropy measures un-": "crease\nin performance when evaluated on the AffectNet"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "fine-tuned on the modified AffectNet dataset using transfer",
          "as a performance metric. Predictive entropy measures un-": "dataset.\nThis highlights\nthe importance of dataset diver-"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "learning techniques. We evaluate the performance of each",
          "as a performance metric. Predictive entropy measures un-": "sity and the challenges of generalization in emotion recog-"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "model based on standard metrics such as accuracy, preci-",
          "as a performance metric. Predictive entropy measures un-": "nition tasks. Further improvements in model architectures"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "sion,\nrecall,\nand F1-score, which are commonly used in",
          "as a performance metric. Predictive entropy measures un-": "and training methodologies may be necessary to enhance"
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "classification tasks to assess the model’s ability to correctly",
          "as a performance metric. Predictive entropy measures un-": "performance across diverse datasets."
        },
        {
          "tional and 3 fully connected layers.\nIn contrast,\nthe modi-": "classify emotions. We also incorporate predictive entropy",
          "as a performance metric. Predictive entropy measures un-": "The CNN, known for\nits simplicity and computational"
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "efficiency, emerged as a baseline in our comparative anal-": "ysis.\nIts architecture, characterized by alternating convolu-",
          "Despite the preliminary results achieved on the FER2013": "dataset,\nthis\nstudy calls out open problems and areas\nfor"
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "tional and pooling layers, demonstrated success in extract-",
          "Despite the preliminary results achieved on the FER2013": "future research. One such area is the exploration of multi-"
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "ing spatial features from input images. As a result, the CNN",
          "Despite the preliminary results achieved on the FER2013": "modal approaches to emotion recognition, which integrate"
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "exhibited modest yet\nrobust performance in capturing the",
          "Despite the preliminary results achieved on the FER2013": "information from facial\nimages,\ntext, and audio to enhance"
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "subtle nuances of emotional cues, achieving competitive ac-",
          "Despite the preliminary results achieved on the FER2013": "model performance."
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "curacy and precision scores across multiple emotion classes",
          "Despite the preliminary results achieved on the FER2013": "Additionally,\naddressing\nthe\nlimitations\nof\nexisting"
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "well above random.",
          "Despite the preliminary results achieved on the FER2013": "datasets and developing improved methods for data collec-"
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "In contrast,\nthe modified VGG16 model has a slightly",
          "Despite the preliminary results achieved on the FER2013": "tion and annotation could further improve accuracy and re-"
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "deeper\nand more\ncomplex\narchitecture.\nThe modified",
          "Despite the preliminary results achieved on the FER2013": "liability.\nFurthermore,\ninvestigating the influence cultural"
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "VGG16 model\nshowcased slightly superior performance",
          "Despite the preliminary results achieved on the FER2013": "differences and situational contexts could provide valuable"
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "compared to the CNN, achieving greater accuracy, preci-",
          "Despite the preliminary results achieved on the FER2013": "insights into the complexities of human emotion recogni-"
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "sion, and recall scores across a range of emotion classes.",
          "Despite the preliminary results achieved on the FER2013": "tion."
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "However,\nthe heightened performance of\nthe modified",
          "Despite the preliminary results achieved on the FER2013": "To conclude, our\nstudy contributes\nto the ongoing re-"
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "VGG16 model came at\nthe expense of\nincreased compu-",
          "Despite the preliminary results achieved on the FER2013": "search in emotion recognition by highlighting strengths and"
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "tational complexity and resource requirements.\nIts more",
          "Despite the preliminary results achieved on the FER2013": "limitations of CNN and Modified VGG16 models and by"
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "complex architecture,\ncomprising multiple\nconvolutional",
          "Despite the preliminary results achieved on the FER2013": "calling out\nthe importance of dataset diversity and future"
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "and fully connected layers,\nrequired longer training times,",
          "Despite the preliminary results achieved on the FER2013": "research directions. By addressing these challenges and ex-"
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "higher memory consumption, and overall more compute re-",
          "Despite the preliminary results achieved on the FER2013": "ploring new avenues for research, we can advance the field"
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "sources.\nAs a result,\nthe practical usage of\nthe modified",
          "Despite the preliminary results achieved on the FER2013": "of emotion recognition and its applications in affective com-"
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "VGG16 model may be hindered by its computational de-",
          "Despite the preliminary results achieved on the FER2013": "puting and human-computer interaction."
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "mands, particularly in resource-constrained environments,",
          "Despite the preliminary results achieved on the FER2013": ""
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "all for marginally better performance when compared to the",
          "Despite the preliminary results achieved on the FER2013": ""
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "CNN.",
          "Despite the preliminary results achieved on the FER2013": ""
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "Furthermore,\nour\nanalysis\nrevealed\ninsights\ninto\nthe",
          "Despite the preliminary results achieved on the FER2013": ""
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "tradeoffs\nbetween model\ncomplexity\nand\ngeneralization.",
          "Despite the preliminary results achieved on the FER2013": ""
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "While the modified VGG16 model demonstrated notable",
          "Despite the preliminary results achieved on the FER2013": ""
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "proficiency with the training data, concerns regarding over-",
          "Despite the preliminary results achieved on the FER2013": ""
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "fitting were observed, particularly when trained on smaller",
          "Despite the preliminary results achieved on the FER2013": ""
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "datasets.\nThis highlights the importance of\nregularization",
          "Despite the preliminary results achieved on the FER2013": ""
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "techniques and data augmentation strategies to mitigate the",
          "Despite the preliminary results achieved on the FER2013": ""
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "risk of overfitting.",
          "Despite the preliminary results achieved on the FER2013": ""
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "4. Conclusion",
          "Despite the preliminary results achieved on the FER2013": ""
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "This\nstudy investigated the performance of CNN and",
          "Despite the preliminary results achieved on the FER2013": ""
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "Modified VGG16 models\nfor\nemotion\nrecognition\ntasks",
          "Despite the preliminary results achieved on the FER2013": ""
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "across two datasets, FER2013 and AffectNet. We aimed to",
          "Despite the preliminary results achieved on the FER2013": ""
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "assess the effectiveness of these models in recognizing emo-",
          "Despite the preliminary results achieved on the FER2013": "Figure 1. CNN Accuracy on the FER2013 dataset"
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "tion and their ability to generalize to more diverse datasets.",
          "Despite the preliminary results achieved on the FER2013": ""
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "Our findings revealed that both models achieved reason-",
          "Despite the preliminary results achieved on the FER2013": ""
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "able performance on the FER2013 dataset, with the Mod-",
          "Despite the preliminary results achieved on the FER2013": ""
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "ified VGG16 model exhibiting slightly superior accuracy",
          "Despite the preliminary results achieved on the FER2013": ""
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "compared to the CNN model, which was based on the orig-",
          "Despite the preliminary results achieved on the FER2013": ""
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "inal VGG16 model. However, when evaluated on the Af-",
          "Despite the preliminary results achieved on the FER2013": ""
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "fectNet dataset, both models experienced a decrease in per-",
          "Despite the preliminary results achieved on the FER2013": ""
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "formance, which speaks to the challenges of generalization",
          "Despite the preliminary results achieved on the FER2013": ""
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "to new data.",
          "Despite the preliminary results achieved on the FER2013": ""
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "A highlight from this study is the importance of dataset",
          "Despite the preliminary results achieved on the FER2013": ""
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "diversity\nin\ntraining\nand\nevaluating.\nThe\nperformance",
          "Despite the preliminary results achieved on the FER2013": ""
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "disparities observed between the FER2013 and AffectNet",
          "Despite the preliminary results achieved on the FER2013": ""
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "datasets emphasize the need for more comprehensive and",
          "Despite the preliminary results achieved on the FER2013": ""
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "representative datasets to improve the robustness and gen-",
          "Despite the preliminary results achieved on the FER2013": ""
        },
        {
          "efficiency, emerged as a baseline in our comparative anal-": "eralization capabilities of these models.",
          "Despite the preliminary results achieved on the FER2013": ""
        }
      ],
      "page": 3
    },
    {
      "caption": "Table 1: Accuracy and precision of CNN and Modified VGG16",
      "data": [
        {
          "Model": "CNN",
          "Accuracy (%)": "66.20",
          "Precision (%)": "66.27"
        },
        {
          "Model": "Modified VGG16",
          "Accuracy (%)": "67.43",
          "Precision (%)": "67.60"
        },
        {
          "Model": "Table 1. Accuracy and precision of CNN and Modified VGG16",
          "Accuracy (%)": "",
          "Precision (%)": ""
        },
        {
          "Model": "models with the FER2013 Dataset.",
          "Accuracy (%)": "",
          "Precision (%)": ""
        },
        {
          "Model": "Model",
          "Accuracy (%)": "Recall (%)",
          "Precision (%)": "F1-Score (%)"
        },
        {
          "Model": "CNN",
          "Accuracy (%)": "66.20",
          "Precision (%)": "66.08"
        },
        {
          "Model": "Modified VGG16",
          "Accuracy (%)": "67.43",
          "Precision (%)": "67.35"
        },
        {
          "Model": "Table 2. Recall and F-1 score of CNN and Modified VGG16 mod-",
          "Accuracy (%)": "",
          "Precision (%)": ""
        },
        {
          "Model": "els with the FER2013 Dataset.",
          "Accuracy (%)": "",
          "Precision (%)": ""
        },
        {
          "Model": "",
          "Accuracy (%)": "",
          "Precision (%)": ""
        },
        {
          "Model": "Model",
          "Accuracy (%)": "Predictive Entropy",
          "Precision (%)": ""
        },
        {
          "Model": "CNN",
          "Accuracy (%)": "",
          "Precision (%)": "0.3977"
        },
        {
          "Model": "Modified VGG16",
          "Accuracy (%)": "",
          "Precision (%)": "0.5588"
        },
        {
          "Model": "Table 3. Predictive Entropy of CNN and Modified VGG16 models",
          "Accuracy (%)": "",
          "Precision (%)": ""
        },
        {
          "Model": "with the FER2013 Dataset.",
          "Accuracy (%)": "",
          "Precision (%)": ""
        },
        {
          "Model": "Model",
          "Accuracy (%)": "Accuracy (%)",
          "Precision (%)": "Precision (%)"
        },
        {
          "Model": "CNN",
          "Accuracy (%)": "41.43",
          "Precision (%)": "51.34"
        },
        {
          "Model": "Modified VGG16",
          "Accuracy (%)": "42.86",
          "Precision (%)": "56.70"
        },
        {
          "Model": "Table\n4.\nAccuracy",
          "Accuracy (%)": "and Precision\nof",
          "Precision (%)": "the CNN and Modified"
        },
        {
          "Model": "VGG16 models on the AffectNet Dataset.",
          "Accuracy (%)": "",
          "Precision (%)": ""
        },
        {
          "Model": "",
          "Accuracy (%)": "",
          "Precision (%)": ""
        },
        {
          "Model": "Model",
          "Accuracy (%)": "Recall (%)",
          "Precision (%)": "F1-Score (%)"
        },
        {
          "Model": "CNN",
          "Accuracy (%)": "41.43",
          "Precision (%)": "38.97"
        },
        {
          "Model": "Modified VGG16",
          "Accuracy (%)": "42.86",
          "Precision (%)": "38.81"
        },
        {
          "Model": "Table 5. Recall and F-1 Score of the CNN and Modified VGG16",
          "Accuracy (%)": "",
          "Precision (%)": ""
        },
        {
          "Model": "models on the AffectNet Dataset.",
          "Accuracy (%)": "",
          "Precision (%)": ""
        },
        {
          "Model": "",
          "Accuracy (%)": "",
          "Precision (%)": ""
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "References": "[1] R. Cowie, E. Douglas-Cowie, N. Tsapatsoulis, G. Vot-"
        },
        {
          "References": "sis, S. Kollias, W. Fellenz, and J.G. Taylor.\nEmotion"
        },
        {
          "References": "IEEE Sig-\nrecognition in human-computer interaction."
        },
        {
          "References": "nal Processing Magazine, 18(1):32–80, 2001. 1"
        },
        {
          "References": "[2]\nIan J. Goodfellow, Dumitru Erhan, Pierre Luc Car-"
        },
        {
          "References": "rier, Aaron Courville, Mehdi Mirza, Ben Hamner,"
        },
        {
          "References": "Will Cukierski, Yichuan Tang, David Thaler, Dong-"
        },
        {
          "References": "Hyun Lee, Yingbo Zhou, Chetan Ramaiah, Fangxiang"
        },
        {
          "References": "Feng, Ruifan Li, Xiaojie Wang, Dimitris Athanasakis,"
        },
        {
          "References": "John Shawe-Taylor, Maxim Milakov, John Park, Radu"
        },
        {
          "References": "Ionescu, Marius\nPopescu,\nCristian Grozea,\nJames"
        },
        {
          "References": "Bergstra,\nJingjing Xie, Lukasz Romaszko, Bing Xu,"
        },
        {
          "References": "Zhang Chuang, and Yoshua Bengio. Challenges in rep-"
        },
        {
          "References": "resentation learning: A report on three machine learn-"
        },
        {
          "References": "ing contests, 2013. 1"
        },
        {
          "References": "[3]\nJ. Mar´ın-Morales,\nJ. L. Higuera-Trujillo, A. Greco,"
        },
        {
          "References": "et al. Affective computing in virtual\nreality:\nemotion"
        },
        {
          "References": "recognition from brain and heartbeat dynamics using"
        },
        {
          "References": "wearable sensors. Sci Rep, 8:13657, 2018. 1"
        },
        {
          "References": "[4] Ali Mollahosseini, Behzad Hasani, and Mohammad H."
        },
        {
          "References": "Mahoor.\nAffectnet:\nA new database\nfor\nfacial\nex-"
        },
        {
          "References": "pression, valence, and arousal computation in the wild."
        },
        {
          "References": "IEEE Transactions on Affective Computing, 2017. 1"
        },
        {
          "References": "[5] Karen Simonyan and Andrew Zisserman.\nVery deep"
        },
        {
          "References": "convolutional networks for\nlarge-scale image recogni-"
        },
        {
          "References": "tion. arXiv preprint arXiv:1409.1556, 2014. 1"
        },
        {
          "References": "[6] D. Turcian and V. Stoicu-Tivadar.\nReal-time detec-"
        },
        {
          "References": "tion of emotions based on facial expression for mental"
        },
        {
          "References": "health. Stud Health Technol Inform, 309:272–276, Oct"
        },
        {
          "References": "2023. 1"
        }
      ],
      "page": 5
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Emotion recognition in human-computer interaction",
      "authors": [
        "R Cowie",
        "E Douglas-Cowie",
        "N Tsapatsoulis",
        "G Votsis",
        "S Kollias",
        "W Fellenz",
        "J Taylor"
      ],
      "year": "2001",
      "venue": "IEEE Signal Processing Magazine"
    },
    {
      "citation_id": "2",
      "title": "",
      "authors": [
        "Ian Goodfellow",
        "Dumitru Erhan",
        "Pierre Carrier",
        "Aaron Courville",
        "Mehdi Mirza",
        "Ben Hamner",
        "Will Cukierski",
        "Yichuan Tang",
        "David Thaler",
        "Dong-Hyun Lee",
        "Yingbo Zhou",
        "Chetan Ramaiah",
        "Fangxiang Feng",
        "Ruifan Li",
        "Xiaojie Wang",
        "Dimitris Athanasakis",
        "John Shawe-Taylor",
        "Maxim Milakov",
        "John Park",
        "Radu Ionescu",
        "Marius Popescu",
        "Cristian Grozea",
        "James Bergstra",
        "Jingjing Xie",
        "Lukasz Romaszko",
        "Bing Xu",
        "Zhang Chuang",
        "Yoshua Bengio"
      ],
      "year": "2013",
      "venue": ""
    },
    {
      "citation_id": "3",
      "title": "Affective computing in virtual reality: emotion recognition from brain and heartbeat dynamics using wearable sensors",
      "authors": [
        "J Marín-Morales",
        "J Higuera-Trujillo",
        "A Greco"
      ],
      "year": "2018",
      "venue": "Sci Rep"
    },
    {
      "citation_id": "4",
      "title": "Affectnet: A new database for facial expression, valence, and arousal computation in the wild",
      "authors": [
        "Ali Mollahosseini",
        "Behzad Hasani",
        "Mohammad Mahoor"
      ],
      "year": "2017",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "5",
      "title": "Very deep convolutional networks for large-scale image recognition",
      "authors": [
        "Karen Simonyan",
        "Andrew Zisserman"
      ],
      "year": "2014",
      "venue": "Very deep convolutional networks for large-scale image recognition",
      "arxiv": "arXiv:1409.1556"
    },
    {
      "citation_id": "6",
      "title": "Real-time detection of emotions based on facial expression for mental health",
      "authors": [
        "D Turcian",
        "V Stoicu-Tivadar"
      ],
      "year": "2001",
      "venue": "Stud Health Technol Inform"
    }
  ]
}