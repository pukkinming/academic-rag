{
  "paper_id": "2409.05770v1",
  "title": "Consensus-Based Distributed Quantum Kernel Learning For Speech Recognition",
  "published": "2024-09-09T16:33:00Z",
  "authors": [
    "Kuan-Cheng Chen",
    "Wenxuan Ma",
    "Xiaotian Xu"
  ],
  "keywords": [
    "Quantum Computing",
    "Distributed Quantum Computing",
    "Quantum Machine Learning",
    "Speech Recognition"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "This paper presents a Consensus-based Distributed Quantum Kernel Learning (CDQKL) framework aimed at improving speech recognition through distributed quantum computing.CDQKL addresses the challenges of scalability and data privacy in centralized quantum kernel learning. It does this by distributing computational tasks across quantum terminals, which are connected through classical channels. This approach enables the exchange of model parameters without sharing local training data, thereby maintaining data privacy and enhancing computational efficiency. Experimental evaluations on benchmark speech emotion recognition datasets demonstrate that CDQKL achieves competitive classification accuracy and scalability compared to centralized and local quantum kernel learning models. The distributed nature of CDQKL offers advantages in privacy preservation and computational efficiency, making it suitable for data-sensitive fields such as telecommunications, automotive, and finance. The findings suggest that CDQKL can effectively leverage distributed quantum computing for largescale machine-learning tasks.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "I. Introduction",
      "text": "Quantum computing harnesses the principles of quantum mechanics, such as entanglement and superposition, to tackle complex computational problems, often achieving exponential speedups that classical algorithms cannot match  [1] . For example, variational quantum algorithms (VQAs)  [2] ,  [3] , which integrate quantum computing with optimization and machine learning, have become a leading approach for demonstrating quantum advantage. As classical machine learning models struggle with the growing complexity and scale of data, quantum computing presents a promising pathway to address these challenges  [4] . The formal distinction between classical and quantum learnability underscores the transformative potential of quantum computing paradigms in revolutionizing machine learning and computational sciences  [5] .\n\nKernel learning, although not at the forefront of contemporary machine learning research, remains a valuable framework for addressing nonlinear problems by transforming data into higher-dimensional spaces  [6] . Quantum Kernel Learning (QKL) extends this classical approach into the quantum domain, leveraging the unique properties of quantum mechanics to enhance computational speed and representational power by *The first two authors contributed equally to this work. mapping features into the quantum state Hilbert space  [7] ,  [8] . The effectiveness of quantum support vector machines with a large number of qubits has been demonstrated using tensor network-based quantum circuit simulations (cuTN-QSVM)  [9] . Recent studies have further highlighted the potential of QKL in tackling high-dimensional, large-scale machine learning tasks through practical applications and demonstrations  [10] ,  [11] . Despite these potential advantages in computational efficiency and expressiveness, QKL faces significant scalability challenges due to the high computational costs associated with constructing large quantum kernel matrices, which become increasingly prohibitive as dataset sizes grow. Moreover, centralized quantum kernel learning struggles with managing sensitive data, such as medical, personal, and financial information, raising critical concerns about data privacy and security.\n\nTo address these challenges, this paper introduces to apply a novel consensus-based distributed quantum kernel learning (termed CDQKL  [12] ) approach to the senario of speech recognition. This approach tailored to enhance scalability and preserve data privacy in speech recognition. CDQKL draws inspiration from federated learning and distributed quantum computing by enabling model parameter exchange between adjacent nodes without sharing local training data, thus maintaining data privacy and security  [12] . As shown in Fig.  1 , this distributed architecture involves a network of quantum terminals connected through classical channels, allowing for large-scale machine learning tasks without direct data aggregation. As quantum devices are increasingly deployed in cloud services and localized environments, CDQKL aligns with this evolving landscape, offering a compelling solution that leverages distributed data processing to improve training efficiency and scalability in complex machine learning tasks, particularly when handling sensitive data.\n\nThe distributed nature of CDQKL offers significant advantages for privacy preservation, making it particularly impactful in industries that handle sensitive information, such as telecommunications, automotive, finance, and healthcare. Applications include speech and facial recognition, autonomous driving systems, and financial analytics, where data security and scalability are critical. Unlike previous research in distributed quantum computing  [13] ,  [14] , the proposed algorithm processes sensitive data locally at each quantum terminal, exchanging only model parameters between nodes. This approach enhances training efficiency while mitigating the privacy risks associated with centralized data processing. This paper pioneers the application of CDQKL to speech signal processing, demonstrating its effectiveness through extensive experiments in terms of accuracy, convergence speed, and scalability compared to centralized and local QKL approaches, as well as traditional kernel classifiers. The algorithm's robust performance underscores its potential to transform data-driven applications in sectors that demand high computational efficiency and stringent privacy standards.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Ii. Methodology",
      "text": "",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "A. Classical Kernel Learning And Quantum Kernel Learning",
      "text": "SVMs effectively handle high-dimensional, non-linear classification problems by identifying an optimal hyperplane in an N -dimensional space with feature vectors x i ∈ R N and labels y i . The goal is to maximize the margin between classes, enhancing generalization to new data. The optimization problem is expressed as:\n\nwhere w k , b k , and ζ ik represent hyperplane parameters and slack variables. Kernel methods extend SVMs to non-linear spaces using the kernel function:\n\nwhere ϕ maps data into a higher-dimensional space, capturing complex relationships.\n\nQuantum SVMs (QSVMs) extend classical SVMs into the quantum domain by mapping data into quantum states within the Hilbert space  [8] ,  [15] . The mapping function ϕ(x) encodes classical data into quantum states |Φ(x)⟩. Rotational entanglement operations, defined as:\n\nfacilitate the encoding process. The quantum kernel function between two points is calculated as:\n\nleveraging quantum parallelism for computational speedups by O(log(n)) for computing the kernel function for n 2 pairs of data points over classical methods  [16] ,  [17] .",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "B. Consensus-Based Distributed Quantum Kernel Learning",
      "text": "In this paper, we utilize a consensus-based distributed quantum kernel learning (CDQKL) framework  [12]  designed for large-scale speech recognition task. Our model consists of N quantum computing units interconnected through classical communication channels, forming a network represented by a graph G(V, E), where V = {1, . . . , N } represents the quantum units, and E ⊆ V × V indicates the communication links. For each link (i, j) ∈ E, unit j is considered a neighbor of unit i, and the neighborhood set of unit i is\n\nThe communication between nodes is governed by a consensus matrix W = [w ij ] N ×N , where w ij > 0 if (i, j) ∈ E and w ij = 0 otherwise.\n\nWe consider G as a connected graph with a doubly stochastic matrix W that satisfies W 1 N = 1 N and 1 T N W = 1 T N , where 1 N is an N -dimensional vector of ones. The properties of doubly stochastic matrices, such as having a spectral radius of 1, provide stability and convergence benefits critical for distributed optimization algorithms.\n\nEach quantum unit i possesses a local dataset D i . The objective is to minimize the global loss function defined over the entire network:\n\nHere, D represents the entire dataset. V i and K i (θ) are alignment values and the quantum kernel associated with the i-th quantum unit, respectively. This formulation enables distributed quantum kernel learning, where each unit minimizes its local loss function L i (D i , θ), contributing to the global optimization task.\n\nTo achieve consensus across the network, we employ a gradient-based distributed optimization algorithm. At each iteration k, the quantum unit i updates an auxiliary variable λ k i and its parameter vector θ k i as follows:\n\nwhere η i is the step size, and λ k i aggregates gradient information from neighboring nodes, facilitating the consensus mechanism. The gradient of the local loss function ∇ θ L i (D i , λ k i ) is estimated using m i data points s p i from the local dataset:\n\nTo further enhance computational efficiency, a stochastic gradient descent approach is employed, wherein the gradient is approximated using a random subset of q i samples:\n\nThus, each quantum unit i updates its parameters using the consensus-based stochastic gradient algorithm:\n\nThis iterative procedure ensures that the units reach a consensus on the model parameters without the need to share sensitive local data, offering both computational efficiency and data security. The proposed CDQKL framework (shown in Fig.  2 ) demonstrates significant potential for enhancing the scalability and privacy of distributed quantum kernel learning, making it a promising approach for applications in automotive, finance, and other data-sensitive domains.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Iii. Experiments And Result Analysis",
      "text": "",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "A. Experimental Setup",
      "text": "The Speech Emotion Recognition (SER) dataset utilized in this study consists of four publicly available benchmarks: the Crowd-sourced Emotional Multimodal Actors Dataset (CREMA-D)  [18] , the Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS)  [19] , the Surrey Audio-Visual Expressed Emotion (SAVEE)  [20] , and the Toronto Emotional Speech Set (TESS)  [21] . These datasets provide a diverse set of speech samples with annotated emotional states, including emotions such as Happy, Fear, Angry, Disgust, Surprise, Sad, and Neutral. For this study, we specifically focused on the \"Surprise\" and \"Sad\" emotions due to their contrasting emotional valence and the complexity they add to classification tasks (shown in Fig.  3 ). The comprehensive nature of these datasets allows for robust training and evaluation of SER classifiers, enabling the detection of emotions from vocal characteristics such as tone and pitch. This capability is critical in various applications, from customer service analysis in call centers to enhancing driver safety in automotive systems, where understanding emotional context can significantly impact performance and user experience.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "B. Data Pre-Processing",
      "text": "In this study, the audio data from the aforementioned datasets was preprocessed to enhance the performance of the SER classifier. Key features were extracted, including Zero Crossing Rate (ZCR), Root Mean Square Energy (RMS), and Mel Frequency Cepstral Coefficients (MFCC), which are instrumental in capturing the emotional nuances in speech  [22] . To further improve model robustness, data augmentation techniques such as noise injection, stretching, shifting, and pitching were employed to increase the variability of the training data. Each audio sample was trimmed to 2.5 seconds with a 0.6-second offset to exclude initial silent segments and focus on the relevant emotional content. The processed data was divided into training and testing sets to ensure a fair comparison. This methodological approach supports a comprehensive assessment of speech emotion detection, leveraging advanced feature extraction and augmentation techniques to enhance recognition accuracy across diverse emotional speech data.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "C. Classification Result And Analysis",
      "text": "First, we conducted a preliminary study comparing QSVM with traditional kernel-based SVM models for speech emotion recognition of \"Surprise\" and \"Sad\" emotions, as shown in Table  I . The Linear SVM, serving as a baseline, showed the lowest performance with training and testing accuracies of 55.62% and 53.76%, respectively, highlighting its limitations in capturing complex data patterns. Incorporating a Gaussian kernel with C = 1, the SVM improved significantly, achieving 76.88% training and 73.75% testing accuracy. Further optimization with C = 1000 balanced the training and testing accuracy at 84.00%, demonstrating the impact of regularization tuning. The Central QSVM models outperformed these SVMs, with the QSVM (C = 1) achieving 81.00% training and 76.25% testing accuracy. The best performance was observed with the optimized QSVM (C = 1000), which reached 86.33% on training and 84.33% on testing, showcasing QSVM's superior ability to model complex data structures and outperform classical SVMs. Table  II  presents the performance of our proposed CDQKL algorithm on the speech recognition task, demonstrating its effectiveness in enhancing classification accuracy across distributed nodes through consensus-based training. Initially, the nodes exhibited varied performance, with accuracies ranging from 62.50% to 87.50%. After CDQKL implementation, notable improvements were seen, particularly in local and whole test metrics. For example, Node 1's local test accuracy increased from 62.50% to 67.50%, and whole test accuracy improved from 71.88% to 79.38%. Node 4 showed the most significant gains, with local and whole test accuracies rising to 80.00% and 78.75%, respectively. These results illustrate CDQKL's ability to leverage global data insights without direct data sharing, thus preserving data privacy while achieving robust performance. Compared to centralized methods, CDQKL offers similar or superior accuracy with the added advantages of distributed learning, parallel processing, and faster convergence. This aligns with prior findings on artificial and real-world datasets, positioning CDQKL as a scalable, privacy-preserving solution for distributed speech recognition tasks in quantum kernel-based machine learning. In this work, we proposed the CDQKL approach, which enhances classification accuracy and discriminative performance across distributed nodes by exchanging model parameters between adjacent nodes without sharing local training data. Our experiments on speech recognition tasks and comparisons on artificial and real-world datasets demonstrate that CDQKL achieves comparable or superior accuracy to centralized methods while preserving data privacy, scalability, and parallel processing benefits. Despite current challenges such as device noise in quantum machine learning, our results indicate that CDQKL effectively leverages consensus-based training to incorporate global data insights, offering a promising solution for future distributed quantum computing scenarios. Future work will focus on integrating noise-aware vulnerability detection protocols, such as noise-aware detectable Byzantine agreement  [23]  and error mitigation strategy  [24] , to enhance the robustness of CDQKL on real quantum hardware and exploring its potential within federated quantum machine learning frameworks  [25] . Additionally, we aim to expand the application of CDQKL, further validating its deployment in practical quantum HPC and distributed quantum computing.",
      "page_start": 4,
      "page_end": 4
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Conceptual Framework of CDQKL for Speech Recognition in a",
      "page": 1
    },
    {
      "caption": "Figure 2: Schematic of the CDQKL framework showing distributed quantum",
      "page": 2
    },
    {
      "caption": "Figure 2: ) demonstrates significant potential for enhancing the",
      "page": 3
    },
    {
      "caption": "Figure 3: 2D projection of training and testing data points for speech emotion",
      "page": 3
    },
    {
      "caption": "Figure 3: ). The compre-",
      "page": 3
    },
    {
      "caption": "Figure 4: (a) Waveform of the audio signal showing amplitude over time,",
      "page": 3
    }
  ],
  "tables": [],
  "citations": [
    {
      "citation_id": "1",
      "title": "Learning with optimized random features: Exponential speedup by quantum machine learning without sparsity and low-rank assumptions",
      "authors": [
        "H Yamasaki",
        "S Subramanian",
        "S Sonoda",
        "M Koashi"
      ],
      "year": "2020",
      "venue": "Advances in neural information processing systems"
    },
    {
      "citation_id": "2",
      "title": "Variational quantum algorithms",
      "authors": [
        "M Cerezo",
        "A Arrasmith",
        "R Babbush",
        "S Benjamin",
        "S Endo",
        "K Fujii",
        "J Mcclean",
        "K Mitarai",
        "X Yuan",
        "L Cincio"
      ],
      "year": "2021",
      "venue": "Nature Reviews Physics"
    },
    {
      "citation_id": "3",
      "title": "Learning quantum phase estimation by variational quantum circuits",
      "authors": [
        "C.-Y Liu",
        "C.-H Lin",
        "K.-C Chen"
      ],
      "year": "2023",
      "venue": "Learning quantum phase estimation by variational quantum circuits",
      "arxiv": "arXiv:2311.04690"
    },
    {
      "citation_id": "4",
      "title": "Power of data in quantum machine learning",
      "authors": [
        "H.-Y Huang",
        "M Broughton",
        "M Mohseni",
        "R Babbush",
        "S Boixo",
        "H Neven",
        "J Mcclean"
      ],
      "year": "2021",
      "venue": "Nature communications"
    },
    {
      "citation_id": "5",
      "title": "Shadows of quantum machine learning",
      "authors": [
        "S Jerbi",
        "C Gyurik",
        "S Marshall",
        "R Molteni",
        "V Dunjko"
      ],
      "year": "2024",
      "venue": "Nature Communications"
    },
    {
      "citation_id": "6",
      "title": "A comprehensive survey on support vector machine classification: Applications, challenges and trends",
      "authors": [
        "J Cervantes",
        "F Garcia-Lamont",
        "L Rodríguez-Mazahua",
        "A Lopez"
      ],
      "year": "2020",
      "venue": "Neurocomputing"
    },
    {
      "citation_id": "7",
      "title": "Quantum machine learning in feature hilbert spaces",
      "authors": [
        "M Schuld",
        "N Killoran"
      ],
      "year": "2019",
      "venue": "Physical review letters"
    },
    {
      "citation_id": "8",
      "title": "Quantum support vector machine for big data classification",
      "authors": [
        "P Rebentrost",
        "M Mohseni",
        "S Lloyd"
      ],
      "year": "2014",
      "venue": "Physical review letters"
    },
    {
      "citation_id": "9",
      "title": "cutn-qsvm: cutensornet-accelerated quantum support vector machine with cuquantum sdk",
      "authors": [
        "K.-C Chen",
        "T.-Y Li",
        "Y.-Y Wang",
        "S See",
        "C.-C Wang",
        "R Willie",
        "N.-Y Chen",
        "A.-C Yang",
        "C.-Y Lin"
      ],
      "year": "2024",
      "venue": "cutn-qsvm: cutensornet-accelerated quantum support vector machine with cuquantum sdk",
      "arxiv": "arXiv:2405.02630"
    },
    {
      "citation_id": "10",
      "title": "Quantum-enhanced support vector machine for large-scale multi-class stellar classification",
      "authors": [
        "K.-C Chen",
        "X Xu",
        "H Makhanov",
        "H.-H Chung",
        "C.-Y Liu"
      ],
      "year": "2024",
      "venue": "International Conference on Intelligent Computing"
    },
    {
      "citation_id": "11",
      "title": "Quantum computing for climate resilience and sustainability challenges",
      "authors": [
        "K Ho",
        "K.-C Chen",
        "L Lee",
        "F Burt",
        "S Yu"
      ],
      "year": "2024",
      "venue": "Quantum computing for climate resilience and sustainability challenges",
      "arxiv": "arXiv:2407.16296"
    },
    {
      "citation_id": "12",
      "title": "Cdqkl: Consensus-based distributed quantum kernel learning",
      "authors": [
        "W Ma",
        "M Liu",
        "R Deng"
      ],
      "year": "2024",
      "venue": "2024 International Conference on Quantum Communications, Networking, and Computing (QCNC)"
    },
    {
      "citation_id": "13",
      "title": "Generalised circuit partitioning for distributed quantum computing",
      "authors": [
        "F Burt",
        "K.-C Chen",
        "K Leung"
      ],
      "year": "2024",
      "venue": "Generalised circuit partitioning for distributed quantum computing",
      "arxiv": "arXiv:2408.01424"
    },
    {
      "citation_id": "14",
      "title": "Noise-aware distributed quantum approximate optimization algorithm on near-term quantum hardware",
      "authors": [
        "K.-C Chen",
        "X Xu",
        "F Burt",
        "C.-Y Liu"
      ],
      "year": "2024",
      "venue": "Noise-aware distributed quantum approximate optimization algorithm on near-term quantum hardware",
      "arxiv": "arXiv:2407.17325"
    },
    {
      "citation_id": "15",
      "title": "Experimental realization of a quantum support vector machine",
      "authors": [
        "Z Li",
        "X Liu",
        "N Xu",
        "J Du"
      ],
      "year": "2015",
      "venue": "Physical review letters"
    },
    {
      "citation_id": "16",
      "title": "The complexity of quantum support vector machines",
      "authors": [
        "G Gentinetta",
        "A Thomsen",
        "D Sutter",
        "S Woerner"
      ],
      "year": "2024",
      "venue": "Quantum"
    },
    {
      "citation_id": "17",
      "title": "Quantum support vector machine without iteration",
      "authors": [
        "R Zhang",
        "J Wang",
        "N Jiang",
        "Z Wang"
      ],
      "year": "2023",
      "venue": "Information Sciences"
    },
    {
      "citation_id": "18",
      "title": "Crema-d: Crowd-sourced emotional multimodal actors dataset",
      "authors": [
        "H Cao",
        "D Cooper",
        "M Keutmann",
        "R Gur",
        "A Nenkova",
        "R Verma"
      ],
      "year": "2014",
      "venue": "IEEE transactions on affective computing"
    },
    {
      "citation_id": "19",
      "title": "The ryerson audio-visual database of emotional speech and song (ravdess): A dynamic, multimodal set of facial and vocal expressions in north american english",
      "authors": [
        "S Livingstone",
        "F Russo"
      ],
      "year": "2018",
      "venue": "PloS one"
    },
    {
      "citation_id": "20",
      "title": "Surrey audio-visual expressed emotion (savee) database",
      "authors": [
        "P Jackson",
        "S Haq"
      ],
      "year": "2014",
      "venue": "Surrey audio-visual expressed emotion (savee) database"
    },
    {
      "citation_id": "21",
      "title": "Toronto emotional speech set (tess)",
      "authors": [
        "M Pichora-Fuller",
        "K Dupuis"
      ],
      "year": "2020",
      "venue": "Toronto emotional speech set (tess)"
    },
    {
      "citation_id": "22",
      "title": "A comprehensive review of speech emotion recognition systems",
      "authors": [
        "T Wani",
        "T Gunawan",
        "S Qadri",
        "M Kartiwi",
        "E Ambikairajah"
      ],
      "year": "2021",
      "venue": "IEEE access"
    },
    {
      "citation_id": "23",
      "title": "Quantum-error-mitigated detectable byzantine agreement with dynamical decoupling for distributed quantum computing",
      "authors": [
        "M Prest",
        "K.-C Chen"
      ],
      "year": "2023",
      "venue": "Quantum-error-mitigated detectable byzantine agreement with dynamical decoupling for distributed quantum computing",
      "arxiv": "arXiv:2311.03097"
    },
    {
      "citation_id": "24",
      "title": "Short-depth circuits and error mitigation for large-scale ghz-state preparation, and benchmarking on ibm's 127-qubit system",
      "authors": [
        "K.-C Chen"
      ],
      "year": "2023",
      "venue": "2023 IEEE International Conference on Quantum Computing and Engineering (QCE)"
    },
    {
      "citation_id": "25",
      "title": "Federated quantum machine learning",
      "authors": [
        "C Chen",
        "S Yoo"
      ],
      "year": "2021",
      "venue": "Entropy"
    }
  ]
}