{
  "paper_id": "2302.13170v2",
  "title": "Partial Label Learning For Emotion Recognition From Eeg",
  "published": "2023-02-25T21:36:39Z",
  "authors": [
    "Guangyi Zhang",
    "Ali Etemad"
  ],
  "keywords": [
    "Partial label learning",
    "deep learning",
    "electroencephalography",
    "emotion recognition"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Fully supervised learning has recently achieved promising performance in various electroencephalography (EEG) learning tasks by training on large datasets with ground truth labels. However, labeling EEG data for affective experiments is challenging, as it can be difficult for participants to accurately distinguish between similar emotions, resulting in ambiguous labeling (reporting multiple emotions for one EEG instance). This notion could cause model performance degradation, as the ground truth is hidden within multiple candidate labels. To address this issue, Partial Label Learning (PLL) has been proposed to identify the ground truth from candidate labels during the training phase, and has shown good performance in the computer vision domain. However, PLL methods have not yet been adopted for EEG representation learning or implemented for emotion recognition tasks. In this paper, we adapt and re-implement six state-of-the-art PLL approaches for emotion recognition from EEG on two large emotion datasets (SEED-IV and SEED-V). These datasets contain four and five categories of emotions, respectively. We evaluate the performance of all methods in classical, circumplex-based and real-world experiments. The results show that PLL methods can achieve strong results in affective computing from EEG and achieve comparable performance to fully supervised learning. We also investigate the effect of label disambiguation, a key step in many PLL methods. The results show that in most cases, label disambiguation would benefit the model when the candidate labels are generated based on their similarities to the ground truth rather than obeying a uniform distribution. This finding suggests the potential of using label disambiguation-based PLL methods for circumplex-based and real-world affective tasks.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Introduction",
      "text": "Emotion has been widely recognized as a mental state and a psycho-physiological process that can be associated with various brain or physical activities  [1] -  [3] . It can be expressed through various modalities, such as facial expression, hand gestures, body movement, and voice, with various levels of intensity  [4] . Emotion plays an important role in our daily life by affecting decisionmaking and interactions  [5] ; it is thus vital to enable computers to identify, understand, and respond to human emotions  [6]  for better human-computer interaction and user experience. In recent decades, among non-invasive physiological measurements such as electrocardiography  [7] , electromyography  [8] , and electrodermal activity  [9] , Electroencephalography (EEG) has been widely used for human emotion recognition due to its direct reflection of brain activities  [2] ,  [10] -  [12]  One of the critical challenges in EEG labeling is the lack of reliability in self-assessment of emotions  [13] . For example, while participants may easily distinguish between dissimilar emotions or feelings such as 'happy' vs. 'fear', they often struggle to distinguish similar ones, for instance, 'disgust' vs. 'fear'. This difficulty in accurately identifying emotions may result in unreliable selfassessment reports  [13] . Since accurate labeling of emotions is difficult and expensive, participants should ideally be allowed to report multiple possible emotions for a single EEG instance. However, fully supervised learning models, which rely on precise, singular labels, are not designed to handle this ambiguity  [14] .\n\nRecently, self-and semi-supervised learning approaches have been explored for emotion recognition using EEG to address the scarcity of labeled EEG data  [3] ,  [15] -  [21] . While such approaches can improve model performance when faced with limited labels, they do not address the challenge of 'ambiguous' labeling. Self-supervised and semi-supervised learning assume that existing labels are accurate and reliable, which is not always the case in emotion self-assessment, particularly when emotions are similar or closely positioned on the arousal and valence dimensions, as described by Russell's circumplex model  [22] .\n\nTo tackle the above-stated problems, we propose a framework to allow participants to report multiple possible emotions if they are uncertain about their affective state during the self-assessment stage. This notion, referred to as Partial Label Learning (PLL), has shown effectiveness in handling label ambiguity in domains such as computer vision, yet it remains unexplored in EEG-based emotion recognition. In contrast to self-supervised and semisupervised learning methods that typically rely on reliable and accurate labels, the proposed PLL approach is specifically designed to tackle label ambiguity by incorporating multiple candidate labels and applying a label disambiguation mechanism during training. However, ambiguous labeling often causes performance degradation in deep learning algorithms as the ground truth is hidden within the candidate labels during the training phase  [23] , making PLL a challenging area. In this paper, we explore several state-of-the-art PLL techniques  [23] -  [28]  originally proposed in the field of computer vision. For the first time, we adapt these methods for EEG-based emotion recognition, demonstrating their potential in a novel application area. We also adapt two largescale emotion EEG datasets, SEED-IV  [29]  and SEED-V  [12]  by substituting the original labels (ground truth) with 'candidate' label sets, allowing the evaluation of PLL techniques for EEGbased emotion recognition. This work comprehensively compares and analyzes these techniques to understand the viability of using PLL for EEG-based emotion recognition. An overview of the core concept behind PLL is provided in Figure  1 .\n\nOur contributions in this paper are as follows.\n\n(1) For the first time, we introduce PLL to address the challenge of ambiguous EEG labeling in emotion recognition tasks, offering a novel approach to manage uncertainty in self-assessed emotions.  (2)  We re-implement and adapt six recent state-of-the-art PLL algorithms on two large EEG datasets, providing a comprehensive comparison of these methods for emotion recognition.  (3)  We explore different strategies for generating candidate labels, including simulation of circumplex-based and real-world emotional ambiguity. By introducing various levels of label uncertainty, we systematically evaluate the impact of these strategies on the performance of the six PLL methods, providing insights into their robustness and practical effectiveness in learning from EEG data with ambiguous emotional labels.\n\nThe rest of this paper is organized as follows. In the next section, a literature survey on EEG learning for affective computing is provided followed by a summary of PLL methods proposed in the literature. In Section 3, the problem statement and the details of the PLL techniques adopted for EEG are provided . The datasets used in this work are then presented in Section 4, along with implementation details and experiment setup. In Section 5, the detailed results and analysis are provided. And finally Section 6 presents the concluding remarks.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Background",
      "text": "In this section, a literature review of works in the area of deep EEG learning is first provided, followed by a review of recent works in the area of PLL, which have been originally proposed for computer vision applications.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Deep Eeg Representation Learning",
      "text": "Deep learning techniques, such as deep belief networks  [30] , fully connected neural networks  [10] , Convolutional Neural Networks (CNNs)  [31] , capsule networks  [11] ,  [32] , Recurrent Neural Networks (RNNs)  [33] , long short-term memory networks  [34] , and graph neural networks  [35] -  [37]  have been widely used for EEGbased fully-supervised tasks, such as motor imagery or movement classification and emotion recognition  [38] ,  [39] . These deep learning techniques outperformed classical statistical algorithms and conventional machine learning methods in most tasks, as they are able to learn non-linear and more complex patterns and focus on task-relevant features  [10] ,  [32] ,  [34] . CNNs are the most popular deep learning backbones for EEG learning  [31] ,  [38] ,  [39] . Lately, transformers with various pre-training strategies have achieved state-of-the-art results in emotion recognition tasks across multiple EEG datasets  [40] -  [42] .\n\nDeep EEG representation learning frameworks have also shown good performance in semi-supervised tasks, where only a few EEG annotations are available during training  [3] ,  [15] . An attention-based recurrent autoencoder was proposed for semisupervised EEG learning  [3] . Furthermore, state-of-the-art semisupervised techniques originally developed for computer vision tasks, such as MixMatch  [43] , FixMatch  [43]  and AdaMatch  [44] , have been adapted for EEG learning and obtained promising results in emotion recognition tasks. A novel pairwise EEG representation alignment method (PARSE), based on a lightweight CNN backbone, was lately proposed and achieved state-of-theart results in semi-supervised tasks on multiple publicly available large-scale affective datasets  [16] . More importantly, PARSE achieved similar performance to fully-supervised models trained on large-scale labeled datasets with substantially fewer labeled samples, demonstrating the superiority of deep semi-supervised EEG learning in the face of a scarcity of labeled data  [16] . More recently, to address the issue of label scarcity, DS-AGC employed multi-domain adaptation and graph contrastive learning to extract EEG representations in a semi-supervised manner, achieving strong results in cross-subject emotion recognition experiments  [45] .",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Partial Label Learning",
      "text": "PLL algorithms have been lately used to tackle the challenges of label ambiguity and achieved promising performance in a variety of image classification tasks with ambiguous labels. For instance, in  [24] , a deep naive partial label learning model was proposed based on the assumption that the distribution of candidate labels should be uniform since ground truth is unknown  [46] . In addition to this naive approach, a number of other frameworks have been lately developed to rely on a process called 'label disambiguation', which refines the distribution of candidate labels by updating it in each training iteration. This process of combining label disambiguation and model classification works as an Expectation-Maximization (EM) algorithm as shown in  [46] . Specifically, the candidate labels' distribution is initially assumed to be uniform. In the first iteration, a model is trained on the uniformly distributed candidate labels. Then, the candidate labels are disambiguated based on the trained model's predictions. In the next iteration, the model is trained on the disambiguated candidate labels, and the process repeats during the training phase  [25] ,  [46] .\n\nIn  [26] , a method was proposed for label disambiguation that utilized the importance of each output class, rather than relying solely on the model's predictions. To mitigate the possible negative effect of training on false positive labels, in  [27] ,  [28] , a method was proposed to leverage both candidate and non- candidate labels with the label disambiguation process. Furthermore, in  [23] , a prototype-based label disambiguation method was proposed, which was used in combination with supervised contrastive learning  [47] , a technique that relies on contrastive loss to train a Siamese-style network. Specifically, prototype-based label disambiguation is first used to guess the ground truth and generate accurate positive pairs for contrastive learning. Then, the contrastively learned embeddings, in turn, could better guide the label disambiguation process. Thus, these two components are mutually beneficial during the iterative training, leading the PLL framework to achieve state-of-the-art results in multiple vision tasks  [23] .",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Pll Methods",
      "text": "In this section, we first provide a clear description of the problem setup, followed by the details of the PLL methods used for EEGbased emotion recognition in this study. While we build upon existing PLL techniques, we introduce several key modifications and adaptations to enhance performance specifically in the EEG domain.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Problem Setup",
      "text": "Let In classical PLL literature, candidate labels are assumed to be generated independently, uniformly, and randomly. Thus, for the distribution of each candidate label set, P(Y i | x i , y i , q) = s̸ =yi q, ∀s ∈  [1, k] , where P(Y i | x i , y i , q) represents the label ambiguity and q < 1 represents the degree of label ambiguity. The goal of PLL is to construct a robust multi-class classifier by minimizing the divergence between model output and candidate labels. In this study, we aim to evaluate the effectiveness of various PLL algorithms for EEG representation learning when emotion labels with different levels of ambiguity are provided.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Method Overview",
      "text": "A general PLL framework for emotion recognition is illustrated in Figure  2 . In a typical EEG-based emotion recognition experiment setup, EEG recordings are collected from a participant's brain scalp while they are watching an emotion-related video clip. Then, candidate labels are generated based on the participant's self-assessment. These candidate labels are then used to train a model with the features extracted from EEG recordings. In the context of partial label learning, 'label disambiguation' is an additional mechanism beyond the softmax operation used by the learner or backbone itself. This mechanism is often based on uniformly distributed candidate labels ( Ŷ ) or the disambiguated labels obtained from the last training iteration ( ⃗ Y ) and model predictions (p m (x)). The disambiguated labels ( ⃗ Y ) are updated in each training iteration, and the model is trained by minimizing the divergence between the model predictions and the disambiguated labels. When label disambiguation is not used, the divergence will consistently be minimized between model predictions and the candidate labels (with uniform distribution) during the entire training phase. Training is performed by batches, where x b denotes input samples of each batch.\n\nWe identify six state-of-the-art PLL techniques from the literature, which we re-implement and adapt for emotion recognition from EEG. These methods are Deep Naive Partial Label (DNPL) learning  [24] , PROgressive iDENtification (PRODEN) true Labels for PLL  [25] , Class Activation Value Learning (CAVL) for PLL,  [26] , Leveraged Weighted (LW) loss for PLL  [27] , revisiting Consistency Regularization (CR)  [28]  for deep PLL, and Partial label learning with COntrastive label disambiguation (PiCO)  [23] , which are described in the following sub-sections.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Dnpl",
      "text": "In DNPL  [24] , since the ground truth is unknown  [46] , the candidate labels are assumed to have uniform distribution as follows:\n\nwhere Ŷs = 1, ∀s ∈ Y . The DNPL model is simply trained by minimizing the divergence between the model's predictions and the uniformly distributed candidate labels, as:\n\nwhere ϕ(.) denotes the softmax operation, and ν is the clamp operator which limits the output in the range of [0, 1].",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Proden",
      "text": "PRODEN was proposed to refine candidate labels through a label disambiguation process  [25] . Specifically, the process obtains disambiguated labels by multiplying model predictions with candidate labels, as: ⃗ Y = p m (x) Ŷ . Following, the model is trained by minimizing cross-entropy between the model's predictions and the disambiguated labels, as:\n\nHere, when the label disambiguation process is not used, ⃗ Y will be replaced by Ŷ .",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Cavl",
      "text": "In  [26] , CAVL was proposed to disambiguate candidate labels by focusing on the importance score of each label in the model's predictions. Specifically, inspired by  [48] , CAVL uses gradient flow (v s ) of the network output's log probability as a measurement of the importance of each label, which is shown as:\n\nAs suggested in  [26] , ϕ(p m (x)) is replaced by p m (x) since p m (x) contains more information. Consequently, vs = p s m (x i )-1 p s m (x i ) and disambiguated label ⃗ Y = arg max(v s Ŷ ). The same cross-entropy loss in (Eq. 3) is used for model training. When label disambiguation is not used, same as in PRODEN, ⃗ Y will be replaced by Ŷ .",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Lw",
      "text": "Most existing PLL algorithms only focus on learning from candidate labels while ignoring non-candidate ones  [23] -  [26] . However, a model could be misled by the false positive labels if it only relies on the candidate label set  [28] . To mitigate this possible negative effect, in  [27] , both candidate and non-candidate labels have been used for model training using an LW loss. To do so, first, the sigmoid loss s / ∈Y φ(p m (x)) (φ(.) representing sigmoid operation) or negative log-likelihood losss / ∈Y log(1 -ϕ(p m (x))) is applied on non-candidate labels, in order to discourage the model predictions to be among the non-candidate labels. Next, the modified sigmoid loss s∈Y φ(-p m (x)) or negative loglikelihood loss -s∈Y log(ϕ(p m (x))) is employed for model training on candidate labels. Finally, the model is trained on both candidate and non-candidate labels. The total loss function using the sigmoid function and cross-entropy loss (negative loglikelihood) are shown in Eq. 5 and Eq. 6, respectively.\n\nA trade-off parameter β = 0, 1, 2 is applied as suggested in  [27] . The weights w s are the normalized model predictions, as\n\nThe weights (w s ) are updated chronologically and used to assign more weights to learn the candidate labels which are more likely to be the ground truth and the more confusing non-candidate labels. Note that w s = 1 when label disambiguation is not used.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Cr",
      "text": "In  [28] , both candidate and non-candidate labels are leveraged in a similar manner to the LW method  [27] , where modified negative log-likelihood loss is applied on non-candidate labels, as\n\n. In  [28] , instead of using cross-entropy loss, a consistency regularization method has been proposed for learning candidate labels. Consistency regularization encourages a model to have consistent predictions on the original data or its perturbed versions  [16] ,  [43] ,  [49] . As suggested in  [28] , consistency regularization is applied by minimizing the divergence between each augmentation of an instance and its refined label. To do so, the refined label is first obtained based on the network predictions of the original data and its different augmentations, as:\n\nwhere A i presents the original, weakly, and strongly augmented data, as x, A w , A s when i = 1, 2, 3. Additive Gaussian noise has been commonly used as an effective data augmentation method in recent EEG studies  [15] ,  [16] ,  [50] ,  [51] . Therefore, the augmented data are produced as\n\nwhere N represents a Gaussian distribution. As suggested in  [16] ,  [32] , a mean value (µ) of 0.5 is chosen, along with standard deviation values (σ) of 0.8 and 0.2 for strong (A s ) and weak (A w ) augmentations respectively. Following, the divergence between different augmentations of an instance and its refined label is minimized,\n\nwhere D KL denotes Kullback-Leibler (KL) divergence and ⃗ Y ′ denotes the normalized disambiguated labels, as ⃗ Y ′ = ⃗ Y / s∈Y ⃗ Y . Finally, the total loss consists of a supervised loss applied on noncandidate labels and a consistency regularization term applied on candidate labels,\n\nwhere η = t/T is the warm-up function. t and T represent the current epoch and the total training epochs, respectively. Moreover, η is set to 0 when label disambiguation is not used.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Pico",
      "text": "PiCO was proposed to incorporate contrastive learning and a prototype-based label disambiguation method for effective partial label learning  [23] . PiCO employs a similar framework with MoCo  [52] , which includes a query network p m and a key network p ′ m sharing the same encoder architecture, where p ′ m uses a momentum update with p m  [52] . Following, the details of contrastive learning and the prototype-based label disambiguation technique are described. Contrastive Learning. Contrastive learning has achieved promising performance in both supervised and unsupervised learning tasks by maximizing the similarity between learned representations of a positive pair  [47] ,  [52] -  [54] . In supervised contrastive learning, a positive pair includes samples from the same class, while a negative pair contains examples belonging to different classes. In unsupervised contrastive learning, a positive pair often consists of a sample and its augmentation, while a negative pair consists of a sample and a randomly chosen instance.\n\nSince the ground truth is unknown in partial label learning tasks, contrastive learning could be performed in an unsupervised manner. To do so, a positive pair is first constructed using an instance (x i ) and its weak augmentation (A w (x i )). Then, a pair of L2 normalized embeddings is obtained from the query and key networks, as\n\nwhere p emb and p ′ emb denotes the embeddings obtained from encoders p m and p ′ m , respectively. N emb = 64 denotes the dimension of the embeddings. Following, the negative sample pool is initialized as queue ∈ R [Nq×k] , where queue i,j ∼ N (0, 1), ∀i ∈ [1, N q ], ∀j ∈ [1, N emb ], as suggested in  [52] . The length of the pool, N q , is set to N q = 1000, according to the total number of EEG training samples. Next, the unsupervised contrastive loss is calculated as:\n\nwhere bmm denotes the batch matrix multiplication operator such that bmm ,1] . The temperature hyper-parameter τ is set to 0.07, as suggested in  [23] .\n\nUnsupervised contrastive learning remains challenging since the false negative samples in the negative samples pool may cause performance degradation  [47] ,  [55] . To tackle this challenge, one solution is to construct a positive pair consisting of two samples whose guessed labels are the same. To do so, the pseudo-label is first estimated as ⃗ Y i = ϕ(p m (x i )) Ŷi . The contrastive representation pool is then constructed as queue + = cat(K, queue), where cat(.) denotes a concatenation operation. The corresponding pseudo-label pool is denoted as Y queue + = cat( Ŷ , Y queue ), where Y queue ∼ N (0, 1). Next, the set of instances with the same guessed label is constructed as\n\nwhere N q+ repre-sents the length of queue +. Following, the supervised contrastive loss is employed as:\n\nBoth the negative samples pool and the corresponding pseudolabel pool, are randomly initialized with Gaussian distributions. queue is replaced by the embeddings K obtained in the previous training batch, and Y queue is replaced by the uniformly distributed candidate labels Ŷ , chronologically.\n\nPrototype-based Label Disambiguation. Prototype is defined as a representative embedding of instances with the same label  [23] ,  [56] . The prototype is denoted as proto ∈ R k×N emb , where the instances belonging to each class have their unique embedding vector. From an EM perspective, the E-step uses clustering to estimate the distribution of the prototype, and the M-step is to update the query network parameters through contrastive learning  [23] ,  [56] . The prototype is zero-initialized and smoothly updated by the embedding Q as:\n\nwhere λ = 0.99 is the coefficient used in a moving average strategy. Following, the pseudo-label after prototype-based disambiguation is denoted as:\n\nFinally, the total loss consists of the cross-entropy loss and the supervised contrastive loss using prototype-disambiguated labels, as\n\nwhere ⃗ Y refers to Y proto . ξ = 0.5 is adopted as the contrastive loss weight, as suggested in  [23] . When the label disambiguation process is not used, the contrastive loss L ct s will be replaced by L ct u , and ⃗ Y will be replaced by Ŷ in Eq. 3. Note that when contrastive learning is not used, ξ = 0.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Experiment Setup",
      "text": "This section provides the details of the datasets used, followed by the descriptions of feature extraction, evaluation protocols, and model specifics, including the backbone, hyper-parameters, and training.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Dataset",
      "text": "We use the SEED-IV 1  [29]  and SEED-V 2  [12]  datasets to evaluate and compare the different techniques described earlier. In SEED-IV, 72 video clips with four emotions ('happy', 'neutral', 'sad', and 'fear') served as stimuli. The study involved 15 participants, comprised of 8 females and 7 males. Each subject repeated the experiment three times, each time with different stimuli. The experiment includes 24 trials for each session, with 6 trials per emotion. Each trial consists of three stages: 5 seconds of start cue, a 2-minute video clip, followed by a 45-second period for self-assessment. A total of 62 EEG recordings were collected at a sampling rate of 1000Hz. In SEED-V, 45 short films with five emotions ('happy', 'neutral', 'sad', 'fear', and 'disgust') were used as stimuli. 16 participants including 10 females and 6 males participated in the study. All participants repeated the experiment three times, with completely new stimuli each time. Each experiment contains 3 trials for each emotion, yielding 15 trials in total. Each trial includes three stages: 15 seconds for initial stimuli prior to starting, 2 -4 minutes of watching film clips, and 15 or 30 seconds of self-assessment on the induction effect of the stimuli. EEG recordings were collected with 62 channels at a sampling frequency of 1000Hz.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Candidate Label Generation",
      "text": "",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Classical Pll Setup",
      "text": "In the standard approach to EEG representation learning, one ground truth label is provided for each particular signal. However, in order to employ a PLL framework (classical), we can assume that the ground truth emotion label provided with the dataset is invariably part of the candidate label set. For each sample, every emotion label that does not match the ground truth is given an equal chance, determined by the predefined probability q < 1, to be considered as a candidate label. This procedure is detailed in the problem setup section (Section 3.1).",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Circumplex Pll Setup",
      "text": "Most existing PLL methods employ independent sampling for candidate label generation, where each class except for the ground truth has the same probability of q to become the candidate label, as mentioned in the classical PLL setup above. However, independent sampling may not be suitable for emotion recognition tasks since in Russell's circumplex model  [22] , it is more likely to confuse emotions that are more closely related (e.g., 'sad' and 'fear'), while it is less likely to confuse dissimilar emotions (e.g., 'sad' and 'happy'). To address this, we design additional experiments to generate the candidate labels based on the similarity between two emotions. To do so, we first estimate the location of each emotion on Russell's circumplex model  [22] ,  [57] . As shown in Figure  3 , the wheel of emotions is a circumplex that represents the relationships between different emotions on two orthogonal axes, arousal and valence. This was first proposed by Russell  [22]  and further developed in studies such as  [57] . In this model, emotions are arranged in a circular layout, with certain emotions being considered more closely related to one another based on their proximity on the wheel. To perform more realistic experiments on label generation, we estimate the polar coordinates of each emotion in the format of (radius, angle degrees). According to  [57] , we assume that emotions (with the exception of 'disgust' and 'fear') are uniformly distributed in each quarter of the wheel, with each adjacent angle representing a difference of 18 • . 'Disgust' is positioned between 'upset' and 'nervous', and 'fear' is positioned between 'stressed' and 'tense'. Moreover, the 'neutral' emotion is always placed at the center of the wheel, at the coordinate of (0, 0 • ). Based on this distribution, we can determine the polar coordinates of each emotion, with the radius of the wheel being set to 1. Following, we calculate the distance between two emotions (i and j), as dist(i, j) = r 2 i + r 2 j -2r i r j cos (θ i -θ j ), where r and θ denote the radius and angle radians, respectively. Next, we obtain the normalized similarity score between two emotions, as\n\nThe normalized similarity scores among the five emotions are shown in Figure  4 . Finally, for candidate label generation, we use the normalized similarity score instead of a predefined constant (q) as the probability, such that\n\nTherefore, emotions that are more related to the ground truth have higher a probability of becoming the candidate labels and vice-versa.",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "Real-World Pll Setup",
      "text": "Sections 4.2.1 and 4.2.2 describe the classical PLL setup with predefined and uniform label ambiguity levels as well as the circumplex PLL setup with non-uniform label ambiguity levels, respectively. Revisiting Russell's circumplex model  [22] ,  [57] , we observe that the distances between emotions are predefined, offering a structured guide to emotional relationships. However, real-world emotional relationships are often more fluid, with emotions perceived in ways that may introduce greater ambiguity, potentially exceeding the model's structural limitations. To address this, we introduce δ scaling, a simple method to dynamically adjust the sensitivity of the circumplex model to emotional distances. We apply δ scaling to the normalized similarity score in Eq. 15 as:\n\n) Here, Eq. 15 represents the special case of δ = 1. Applying δ > 1 compresses most emotional distances, bringing them closer to one another. It should be noted that the similarity scores between identical emotions and very dissimilar emotions (e.g., 'happy' vs. 'sad') remain unchanged, as δ scaling does not affect the cases where normalized distances are 0 or 1. Therefore, with moderate δ values, δ scaling increases overall ambiguity by bringing similar emotions closer, while preserving the circumplex model's overall structure. Figure  5  shows the normalized similarity scores (γ δ ) of emotion pairs with δ ∈ {1, 2, 3, 4, 5}. Among the 10 emotion pairs, curves for 'non-neutral'-'neutral' pairs (e.g., 'sad'-'neutral', 'fear'-'neutral') are identical. Generally, γ δ increases as δ increases, except in the case of 'happy'-'sad'.\n\nWe apply δ ∈ {1, 2, 3, 4, 5} in the real-world PLL setup to evaluate the performance of all PLL methods and assess the impact of disambiguation as average ambiguity increases. Furthermore, to enable fair performance comparison between classical and real-world PLL setups, we align the ambiguity level (q) in the classical PLL setup with the average ambiguity level calculated using similarity scores from the real-world setup, as follows:",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "Feature Space",
      "text": "EEG recordings in each experiment were split into continuous and non-overlapping 4-second segments. We use the Differential Entropy (DE) features provided by the datasets  [12] ,  [29] . DE features were extracted from 5 EEG bands (delta, theta, alpha, beta, and gamma) and all 62 EEG channels for each segment, yielding s = 310 features in total. Figure  6  presents a thermogram of DE feature extracted from a single experiment in the SEED-V dataset  [12] . Each row corresponds to a specific EEG frequency band, concatenated across EEG channels, yielding a 1-dimensional feature vector with 310 features per 4-second segment. The horizontal axis represents time in seconds, while the vertical axis shows the feature values across all bands and channels. Emotion codes are shown along the top of the figure, indicating the emotion label associated with each segment ('0': Disgust, '1': Fear, '2': Sad, '3': Neutral, '4': Happy). Additionally, Figure  7  illustrates the spatial distribution of DE features across different emotion categories and frequency bands. These DE features are averaged over all EEG segments within the same single SEED-V experiment (as shown in Figure  6 ). We observe that DE values are consistently higher in the frontal and temporal lobes, particularly in higher-frequency bands such as beta and gamma. In contrast, regions such as the central, fronto-central, and centro-parietal lobes generally shows lower DE values across emotions. These patterns are consistent with findings in affective neuroscience where the frontal lobe, especially the prefrontal cortex, is critically involved in emotional regulation  [58] , while the temporal lobe, plays a key role in emotional memory and reaction  [59] . We normalize the feature vector of each segment (x i ∼ [0, 1] 310 ) to be used as input for training the models.",
      "page_start": 7,
      "page_end": 8
    },
    {
      "section_name": "Evaluation Protocols",
      "text": "In SEED-IV dataset, we follow the evaluation protocol defined in  [29] , where the first 16 trials are used for training and the remaining 8 are used for testing. In SEED-V dataset, we apply the same evaluation protocol that was originally used in  [12] . Specifically, EEG recordings of each subject have been formed",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Backbone Model",
      "text": "We employ the same lightweight CNN used in very recent EEGbased affective computing studies  [15] ,  [16]  as our backbone model due to its demonstrated effectiveness. The lightweight nature of this CNN makes it particularly well-suited for handling EEG data, balancing model efficiency with the ability to capture important spatial and temporal features. This structure is wellsuited for EEG signals, as they are high-dimensional but lack the large labeled datasets found in other domains such as computer vision and natural language processing, allowing for faster training and inference without the need for a deeper network. As shown in Table  1 , the encoder consists of two 1-dimensional (1-D) convolutional blocks. Each block has a 1-D convolutional layer followed by a 1-D batch normalization layer and a LeakyReLU activation function. The encoder is used to transform the DE features extracted from EEG recordings into a compact representation. The learned embedding is then fed to the classifier which includes two fully connected layers with a dropout rate of 0.5 for emotion recognition. In the table, s and k denote the total number of EEG features, and the number of emotion categories, respectively.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Implementation Details",
      "text": "In all the experiments, we ran T = 30 training epochs with a batch size of |x b | = 8. We set the learning rate to 0.01 and used SGD as the optimizer with a default momentum of 0.9 and a weight decay of 0.0001. The learning rate scheduler was  not used for the naive method  [24]  and the fully supervised method as it hurt the performance in these cases. All the PLL methods have been evaluated five times, each time with different random seeds used for candidate label generation. Our experiments were carried out on two NVIDIA GeForce RTX 2080 Ti GPUs using PyTorch  [60] . For the sake of reproducibility, we made the source code of this work publicly available at: https://github.com/guangyizhangbci/PLL-Emotion-EEG.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Results And Discussions",
      "text": "This section presents the performance of the PLL methods for EEG-based emotion recognition in classical and circumplex PLL setups, as well as in the real-world scenario designed based on the proximity of certain emotion classes. This section also discusses the impact of ground truth reliability.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Performance In The Classical Pll Setup",
      "text": "We evaluate the performance of each PLL method in all 6 scenarios with different levels of ambiguity (q ∈ {0.2, 0.4, 0.6, 0.8, 0.9, 0.95}) and present the results in Table  2  for SEED-IV and Table  3  for SEED-V. We observe that when candidate labels with low ambiguity (q ∈ {0.2, 0.4}) are provided, LW  [27]  and PiCO  [23]  obtain the best results in SEED-IV and SEED-V, respectively (shown in bold). DNPL  [24]  obtains the second-best performance (shown with an underline) with less ambiguous labels (q = 0.4 in SEED-IV and q = 0.2 in SEED-V) while achieving the best performance with more ambiguous labels (q ∈ {0.8, 0.9, 0.95}) in both the datasets. When the label ambiguity is moderate, DNPL  [24]  and LW  [27]  behave similarly. Specifically, when q = 0.6, DNPL ranks first in SEED-IV and second in SEED-V, while LW performs the best in SEED-V and second best in SEED-IV. Overall, across all the scenarios, DNPL  [24]  maintains a very stable performance on both datasets, while others suffer from major performance drops when candidate labels are provided with very high ambiguity (q > 0.8).\n\nAll PLL methods use label disambiguation methods except for DNPL  [24] . To analyze the effect of label disambiguation in each PLL method, we evaluate them both with and without label disambiguation. As shown in Tables  2  and 3 , among these five PLL methods, label disambiguation methods, denoted by LD in the tables, play different roles. Specifically, label disambiguation consistently improves the model performance in PRODEN  [25]  and PiCO  [23]  (only except when q = 0.95 is used in SEED-V), while causing performance decline in CR  [28] , across all the ambiguously labeled scenarios, on both datasets. In SEED-IV, for The accuracy (in %) of Comparison PLL Methods (SEED-IV). The average accuracy across 15 subjects and 3 repeated sessions is presented, with standard deviations shown in parentheses.",
      "page_start": 9,
      "page_end": 10
    },
    {
      "section_name": "Method",
      "text": "Venue LD q = 0.2 q = 0.4 q = 0.6 q = 0.8 q = 0.9 q = 0.95\n\nThe accuracy (in %) of Comparison PLL Methods (SEED-V). The average accuracy across 16 subjects and 3 repeated sessions is presented, with standard deviations shown in parentheses.",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Method",
      "text": "Venue LD q = 0.2 q = 0.4 q = 0.6 q = 0.8 q = 0.9 q = 0.95",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Table 4",
      "text": "The accuracy (in %) of LW  [27]  with different settings (SEED-IV). The average accuracy across 15 subjects and 3 repeated sessions is presented, with standard deviations shown in parentheses.",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "Method",
      "text": "β LD q = 0.2 q = 0.4 q = 0.6 q = 0.8 q = 0.9 q = 0.95 the CAVL method  [26] , label disambiguation improves the model performance when candidate labels with lower ambiguity are provided (q ∈ {0.4, 0.6, 0.8}). However, when candidate labels are provided with very high ambiguity (q ∈ {0.9, 0.95}), label disambiguation results in performance degradation. In SEED-V, the LW method  [27]  exhibits a similar impact for label disambiguation on performance as seen with the CAVL method in SEED-IV. Notably, label disambiguation causes a consistent performance drop for CAVL in SEED-V while consistently increasing performance for LW in SEED-IV dataset.",
      "page_start": 14,
      "page_end": 14
    },
    {
      "section_name": "Lw-",
      "text": "",
      "page_start": 14,
      "page_end": 14
    },
    {
      "section_name": "Table 5",
      "text": "The accuracy (in %) of LW  [27]  with different settings (SEED-V). The average accuracy across 16 subjects and 3 repeated sessions is presented, with standard deviations shown in parentheses.",
      "page_start": 15,
      "page_end": 15
    },
    {
      "section_name": "Method",
      "text": "β LD q = 0.2 q = 0.4 q = 0.6 q = 0.8 q = 0.9 q = 0.95 The accuracy (in %) of PiCO  [23]  with different settings (SEED-IV). The average accuracy across 15 subjects and 3 repeated sessions is presented, with standard deviations shown in parentheses.",
      "page_start": 15,
      "page_end": 15
    },
    {
      "section_name": "Lw-",
      "text": "CL LD q = 0.2 q = 0.4 q = 0.6 q = 0.8 q = 0.9 q = 0.95 The accuracy (in %) of PiCO  [23]  with different settings (SEED-V). The average accuracy across 16 subjects and 3 repeated sessions is presented, with standard deviations shown in parentheses.\n\nCL LD q = 0.2 q = 0.4 q = 0.6 q = 0.8 q = 0.9 q = 0.95 Furthermore, we compare the average performance across q ∈ {0.2, 0.4, 0.6, 0.8, 0.9, 0.95} for all the PLL methods. As illustrated in Figures  8  and 9 , in both the datasets, DNPL shows w/o LD w/ LD Fig.  9 . SEED-V: Average performance of the PLL methods across 6 ambiguously labeled scenarios with classical PLL setup (q ∈ {0.2, 0.4, 0.6, 0.8, 0.9, 0.95}).\n\nthe best performance, followed by LW, when label disambiguation is not used. With label disambiguation, LW outperforms the rest, followed by PRODEN. We also observe that label disambiguation methods do not improve the model performance in CAVL  [26]  and CR  [28] . In SEED-IV, label disambiguation enhances performance for the LW method  [27] , whereas, in SEED-V, it has a negligible impact on the average performance.\n\nIn LW  [27] , we further evaluate the method using both sigmoid and cross-entropy losses with three suggested values for the loss leveraging parameter (β = 0, 1, 2) (discussed in section 3.6). This experiment is performed as these parameters are deemed important in the original LW paper  [27] . As shown in Tables  4  and 5 , across both datasets, LW with cross-entropy loss consistently outperforms LW with sigmoid loss in all the β and label disambiguation settings, across all the ambiguously labeled scenarios. LW with cross-entropy loss achieves the best results when more weights are assigned for learning non-candidate labels (β = 2).\n\nIn PiCO  [23] , we evaluate the impact of two major components, namely Contrastive Learning (CL) and label disambiguation (discussed in section 3.8). As shown in Table  6 , in SEED-IV, PiCO performs the best using label disambiguation but without CL, across the majority of scenarios (q ∈ {0.2, 0.6, 0.8, 0.9, 0.95}) and ranks the second best when q = 0.2. As indicated in Table  7 , in SEED-V, we find that CL and label disambiguation are beneficial in cases where the candidate labels are less ambiguous (q ∈ {0.2, 0.4, 0.6}). PiCO performs the best without CL when label ambiguity increases (q ∈ {0.8, 0.9}), and obtains the top performance without both components when label ambiguity is very high (q = 0.95).",
      "page_start": 15,
      "page_end": 15
    },
    {
      "section_name": "Performance In The Circumplex Pll Setup",
      "text": "We evaluate the performance of the existing PLL methods with the candidate labels generated based on the similarity scores between two emotions. As demonstrated in Figures  10  and 11 , in both the datasets, in contrast to the role of label disambiguation in PLL methods under classical setup (uniform distribution of candidate labels), label disambiguation improves model performance for the majority of methods under circumplex-based setup. In particular, the LW method with label disambiguation closely approaches the best result. The only exception is in CR method  [28] , where label disambiguation has a negative impact on model performance. We believe that compared to the classical experiments, label disambiguation is less likely to be misled by false positive labels and allows the model to focus on the candidate labels which are closer to the ground truth in circumplex-based experiments. Therefore, the label disambiguation process is helpful in identifying the ground truth from candidate labels, thus improving model performance. Furthermore, we discover that DNPL  [24]  and LW  [27]  with the label disambiguation process are able to approach the performance of the fully supervised learning method (62.11% in SEED-IV and 63.08% in SEED-V), addressing the challenge of ambiguous EEG labels in circumplex-based affective computing. We also observe that DNPL  [24]  performs the best in both classical and circumplexbased experiments, demonstrating its effectiveness in handling candidate labels with various ambiguity levels.",
      "page_start": 11,
      "page_end": 12
    },
    {
      "section_name": "Performance In The Real-World Pll Setup",
      "text": "We evaluate the performance of all PLL methods in the realworld setup with δ ∈ {1, 2, 3, 4, 5}. Furthermore, to enable a fair comparison between classical and real-world setups, as described in Section 4.2.3, we apply q ∈ {0.35, 0.54, 0.65, 0.72, 0.76} for the SEED-IV dataset  [29] , and q ∈ {0.40, 0.59, 0.69, 0.75, 0.78} for SEED-V  [12] , respectively. As illustrated in Figures  12  and 13 , PLL methods generally perform better in the classical PLL setup than in the real-world PLL setup, particularly at higher ambiguity levels. For example, the performance of DNPL  [24]  drops sharply when δ > 3 in the real-world PLL setup, while it remains consistently high in the classical PLL setup. This is likely due to the exceptionally high similarity scores among closely related emotions in the real-world setup at higher ambiguity levels (q). Specifically, when δ > 3, the real-world setup presents an increased challenge due to significantly greater ambiguity among similar emotions compared to the overall average ambiguity. For instance, as shown in Figure  5 , at δ = 4, ambiguity levels (γ δ ) exceed 0.95 for the 'fear'-'disgust' and 'sad'-'disgust' pairs, while the average ambiguity levels (q) are 0.72 and 0.75 in SEED and SEED-IV, respectively. These extremely high ambiguity levels among closely related emotions pose a substantial challenge for PLL methods. In contrast, the classical PLL setup is less challenging due to both the lower ambiguity level (q) and the uniform distribution of ambiguity.\n\nIn the real-world PLL setup, we observe that as δ increases, the positive effects of the label disambiguation process weaken in some cases. For example, in both the LW  [27]  and PRODEN  [25]  methods, the benefits of label disambiguation diminish when δ ≥ 3. This is primarily due to the increased difficulty of distinguishing closely related emotions when their similarity scores are extremely high (e.g., γ δ > 0.9), which can even lead to negative effects at Fig.  12 . SEED-IV: Performance comparison of all PLL methods in both classical and real-world setups. In the real-world PLL setup, we applied δ scaling on distances between emotions with δ ∈ {1, 2, 3, 4, 5} to gradually increase similarity scores, therefore increasing the averaged label ambiguity levels q. For a fair comparison, we applied the same ambiguity level with q ∈ {0.35, 0.54, 0.65, 0.72, 0.76} in the classical PLL setup. In the real-world PLL setup, we applied δ scaling on distances between emotions with δ ∈ {1, 2, 3, 4, 5} to gradually increase similarity scores, therefore increasing the averaged label ambiguity levels q. For a fair comparison, we applied the same ambiguity levels with q ∈ {0.40, 0.59, 0.69, 0.75, 0.78} in the classical PLL setup.\n\nhigher δ values, as seen in the performance of the PRODEN  [25] , CAVL  [26]  and LW  [27]  on the SEED-V dataset. Interestingly, PiCO  [23]  maintains the positive effect of label disambiguation as δ increases, possibly due to the impact of contrastive learning. Furthermore, we assess the impact of the label disambiguation process across datasets. Compared to SEED-IV, SEED-V includes an additional emotion class, 'disgust', yielding two extra emotion pairs ('fear'-'disgust' and 'sad'-'disgust') with the highest γ δ values among the 10 emotion pairs, particularly when δ ≥ 3 (Figure  5 ). This increased challenge is evident in the performance of the PRODEN, CAVL, and LW methods, as shown in Figures 12 and 13. Specifically, in SEED-IV, PRODEN with label disambiguation consistently outperforms its counterpart without label disambiguation, whereas in SEED-V, PRODEN with label disambiguation performs worse when δ > 3. Similarly, LW with label disambiguation consistently performs better in SEED-IV, but in SEED-V, it performs worse when δ = 5. For CAVL, label disambiguation leads to worse performance in SEED-IV when δ > 2, while in SEED-V, this effect appears when δ > 1. Overall, DNPL  [24]  consistently performs the best among PLL methods in both classical and real-world setups across datasets.",
      "page_start": 11,
      "page_end": 13
    },
    {
      "section_name": "Impact Of Ground Truth Reliability",
      "text": "The SEED-IV and SEED-V datasets used in this study benefit from rigorous data collection protocols including the careful selection of stimuli to evoke specific emotions and the use of facial expressions and physiological signals to reduce dependence on self-reported labels. However, emotion annotation remains inherently subjective, which can lead to inconsistencies in ground truth labels. To address this challenge, our study employs PLL to incorporate multiple candidate labels during training to reduce reliance on any single, potentially unreliable label, thus enhancing the robustness of the methods against noisy annotations. We acknowledge that obtaining perfect ground truth labels for emotion recognition would require additional sensing modalities, such as functional MRI  [61]  or biochemical analysis (e.g., cortisol measurements)  [62] , to further minimize subjectivity. However, these techniques are limited in practical applications due to their high cost, restricted accessibility, and invasive nature.",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "Conclusion",
      "text": "In this study, we tackle the challenge of ambiguous EEG labeling in emotion recognition tasks by adapting and implementing state-of-the-art partial label learning methods. These methods were originally developed for computer vision applications. We conduct extensive experiments with six PLL frameworks across 6 scenarios with different label ambiguities (across q ∈ {0.2, 0.4, 0.6, 0.8, 0.9, 0.95}). We also design circumplexbased and real-world scenarios where candidate labels are generated based on similarities among emotions instead of a uniform distribution assumption. We evaluate the performance of all the PLL methods and investigate the importance of the label disambiguation process in classical, circumplex-based and real-world experiments on two large publicly available datasets, SEED-IV and SEED-V with 4 and 5 emotion categories, respectively. The results show that, in the majority of cases, the label disambiguation process improves the model performance in circumplex-based experiments while causing performance degradation in the classical experiments. We believe the false positive labels generated with a uniform distribution would mislead the label disambiguation process, while the label disambiguation process is provided with better guidance when the candidate labels are generated based on the similarities with the ground truth. These results indicate the potential of using label disambiguation-based PLL frameworks for circumplex-based emotion recognition experiments. Furthermore, we revisited Russell's circumplex model and introduced δ scaling to control label ambiguity by adjusting the similarity scores for emotion pairs (e.g., 'happy'-'fear'), enabling a PLL performance comparison between the classical and real-world PLL setups. The results shows that, when δ ≤ 5, corresponding to an average ambiguity level of q < 0.8, PLL methods generally perform better in a classical PLL setup, which is less challenging due to its uniform distribution of ambiguity. In contrast, the real-world setup poses a more realistic challenge, characterized by high ambiguity levels among closely related emotions. Our analysis indicates that δ > 3 leads to impractical scenarios where emotions become overly similar, compromising the model's ability to reflect realworld emotional relationships described by Russell's circumplex model. This threshold highlights the limitations of PLL methods and the reduced effectiveness of the label disambiguation process when similarity scores between emotions become excessively high, as demonstrated by the degraded performance of these methods. Therefore, we chose not to explore scenarios with δ > 5, as they would not reflect realistic relationships among emotions. Overall, DNPL achieves the best performance and approaches fully supervised learning in all the classical, circumplex-based and real-world experiments, addressing the challenge of ambiguous EEG labeling in emotion classification tasks. Limitations and Future Work: Our work targets scenarios where emotion labels are categorized (e.g., 'happy', 'sad', 'neutral'), which corresponds to discrete models of affect. However, continuous models of affect, which represent emotions along continuous dimensions (as used in datasets such as DEAP  [2] , MAHNOB-HCI  [63] , DREAMER  [64] , and AMIGOS  [13] ) are not suitable for our current evaluations. Adapting PLL to continuous models would require substantial modifications, particularly in the label disambiguation process, which would need to predict continuous outputs instead of discrete labels. For future work, this adaptation can be explored by modifying the loss functions and disambiguation processes to handle continuous values rather than categorical labels. More advanced architectures can also be explored to investigate the impact of different architectural choices in this context.",
      "page_start": 13,
      "page_end": 13
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: A description of full-supervised learning, semi-supervised learn-",
      "page": 2
    },
    {
      "caption": "Figure 1: Our contributions in this paper are as follows. (1) For the first",
      "page": 2
    },
    {
      "caption": "Figure 2: A general EEG-based PLL framework for emotion recognition is presented.",
      "page": 3
    },
    {
      "caption": "Figure 2: In a typical EEG-based emotion recognition experiment",
      "page": 3
    },
    {
      "caption": "Figure 3: , the wheel of emotions is a circumplex that represents the",
      "page": 6
    },
    {
      "caption": "Figure 3: Wheel of emotions reproduced from [22], [57].",
      "page": 6
    },
    {
      "caption": "Figure 4: Normalized similarity score between two emotions as label am-",
      "page": 6
    },
    {
      "caption": "Figure 4: Finally, for candidate label generation, we use",
      "page": 6
    },
    {
      "caption": "Figure 5: Normalized similarity score (γδ) between two emotions as label",
      "page": 7
    },
    {
      "caption": "Figure 5: shows the normalized similarity scores",
      "page": 7
    },
    {
      "caption": "Figure 6: presents a ther-",
      "page": 7
    },
    {
      "caption": "Figure 7: illustrates the spatial distribution of DE features across",
      "page": 7
    },
    {
      "caption": "Figure 6: ). We observe",
      "page": 7
    },
    {
      "caption": "Figure 6: DE feature maps from a single experiment of the SEED-V",
      "page": 7
    },
    {
      "caption": "Figure 7: Topographical maps of DE features from a single experiment",
      "page": 8
    },
    {
      "caption": "Figure 8: SEED-IV: Average performance of the PLL methods across",
      "page": 10
    },
    {
      "caption": "Figure 9: SEED-V: Average performance of the PLL methods across",
      "page": 10
    },
    {
      "caption": "Figure 10: SEED-IV: Performance of the PLL methods in the experiments",
      "page": 11
    },
    {
      "caption": "Figure 11: SEED-V: Performance of the PLL methods in the experiments",
      "page": 11
    },
    {
      "caption": "Figure 5: , at δ = 4, ambiguity levels (γδ)",
      "page": 11
    },
    {
      "caption": "Figure 12: SEED-IV: Performance comparison of all PLL methods in both classical and real-world setups. In the real-world PLL setup, we applied",
      "page": 12
    },
    {
      "caption": "Figure 13: SEED-V: Performance comparison of all PLL methods in both classical and real-world setups. In the real-world PLL setup, we applied",
      "page": 12
    },
    {
      "caption": "Figure 5: ). This increased challenge is evident in the performance",
      "page": 13
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "1\n0.69\n0.69\n1": "0.35\n0.62\n1\n0.5",
          "0.35\n0.5\n0.62\n0.5": ""
        }
      ],
      "page": 6
    },
    {
      "caption": "Table 2: We employ the same lightweight CNN used in very recent EEG-",
      "data": [
        {
          "Module": "Input",
          "Layer details": "-",
          "Output shape": "(1, s)"
        },
        {
          "Module": "Encoder",
          "Layer details": " \n \nConv1D, kernel(3), output channels(5)\nBatchNorm1D, output channels(5)\nLeakyReLU, slope(0.3)",
          "Output shape": "(5, s − 2)"
        },
        {
          "Module": "",
          "Layer details": " \n \nConv1D, kernel(3), output channels(10)\nBatchNorm1D, output channels(10)\nLeakyReLU, slope(0.3)",
          "Output shape": "(10, s − 4)"
        },
        {
          "Module": "Embedding",
          "Layer details": "Flatten",
          "Output shape": "10 × (s − 4)"
        },
        {
          "Module": "Classifier",
          "Layer details": " \n \nLinear, 64\nReLU, −\nDropout, 0.5\nLinear, k",
          "Output shape": "(k)"
        }
      ],
      "page": 8
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "The emotional brain",
      "authors": [
        "Tim Dalgleish"
      ],
      "year": "2004",
      "venue": "Nature Reviews Neuroscience"
    },
    {
      "citation_id": "2",
      "title": "Deap: A database for emotion analysis; using physiological signals",
      "authors": [
        "Sander Koelstra",
        "Christian Muhl",
        "Mohammad Soleymani",
        "Jong-Seok Lee",
        "Ashkan Yazdani",
        "Touradj Ebrahimi",
        "Anton Thierry Pun",
        "Ioannis Nijholt",
        "Patras"
      ],
      "year": "2011",
      "venue": "IEEE transactions on affective computing"
    },
    {
      "citation_id": "3",
      "title": "Deep recurrent semi-supervised EEG representation learning for emotion recognition",
      "authors": [
        "Guangyi Zhang",
        "Ali Etemad"
      ],
      "year": "2021",
      "venue": "9th International Conference on Affective Computing and Intelligent Interaction (ACII)"
    },
    {
      "citation_id": "4",
      "title": "Supramodal representations of perceived emotions in the human brain",
      "authors": [
        "Anthony Marius V Peelen",
        "Patrik Atkinson",
        "Vuilleumier"
      ],
      "year": "2010",
      "venue": "Journal of Neuroscience"
    },
    {
      "citation_id": "5",
      "title": "Sociological theories of human emotions",
      "authors": [
        "H Jonathan",
        "Jan Turner",
        "Stets"
      ],
      "year": "2006",
      "venue": "Annual Review of Sociology"
    },
    {
      "citation_id": "6",
      "title": "",
      "authors": [
        "Rosalind Picard"
      ],
      "year": "2000",
      "venue": ""
    },
    {
      "citation_id": "7",
      "title": "self-supervised ECG representation learning for emotion recognition",
      "authors": [
        "Pritam Sarkar",
        "Ali Etemad"
      ],
      "year": "2020",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "8",
      "title": "Physiological signals based human emotion recognition: a review",
      "authors": [
        "M Jerritta",
        "R Murugappan",
        "Khairunizam Nagarajan",
        "Wan"
      ],
      "year": "2011",
      "venue": "th International Colloquium on Signal Processing and its Applications"
    },
    {
      "citation_id": "9",
      "title": "Attentive cross-modal connections for deep multimodal wearable-based emotion recognition",
      "authors": [
        "Anubhav Bhatti",
        "Behnam Behinaein",
        "Dirk Rodenburg",
        "Paul Hungler",
        "Ali Etemad"
      ],
      "year": "2021",
      "venue": "9th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos"
    },
    {
      "citation_id": "10",
      "title": "RFNet: Riemannian fusion network for EEG-based brain-computer interfaces",
      "authors": [
        "Guangyi Zhang",
        "Ali Etemad"
      ],
      "year": "2020",
      "venue": "RFNet: Riemannian fusion network for EEG-based brain-computer interfaces",
      "arxiv": "arXiv:2008.08633"
    },
    {
      "citation_id": "11",
      "title": "Distilling EEG representations via capsules for affective computing",
      "authors": [
        "Guangyi Zhang",
        "Ali Etemad"
      ],
      "year": "2021",
      "venue": "Distilling EEG representations via capsules for affective computing",
      "arxiv": "arXiv:2105.00104"
    },
    {
      "citation_id": "12",
      "title": "Comparing recognition performance and robustness of multimodal deep learning models for multimodal emotion recognition",
      "authors": [
        "Wei Liu",
        "Jie-Lin Qiu",
        "Wei-Long Zheng",
        "Bao-Liang Lu"
      ],
      "year": "2021",
      "venue": "IEEE Transactions on Cognitive and Developmental Systems"
    },
    {
      "citation_id": "13",
      "title": "Amigos: A dataset for affect, personality and mood research on individuals and groups",
      "authors": [
        "Juan Abdon",
        "Miranda Correa",
        "Mojtaba Khomami Abadi",
        "Niculae Sebe",
        "Ioannis Patras"
      ],
      "year": "2018",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "14",
      "title": "Towards effective visual representations for partial-label learning",
      "authors": [
        "Shiyu Xia",
        "Jiaqi Lv",
        "Ning Xu",
        "Gang Niu",
        "Xin Geng"
      ],
      "year": "2023",
      "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition"
    },
    {
      "citation_id": "15",
      "title": "Holistic semi-supervised approaches for EEG representation learning",
      "authors": [
        "Guangyi Zhang",
        "Ali Etemad"
      ],
      "year": "2022",
      "venue": "International Conference on Acoustics, Speech and Signal Processing"
    },
    {
      "citation_id": "16",
      "title": "Parse: Pairwise alignment of representations in semi-supervised EEG learning for emotion recognition",
      "authors": [
        "Guangyi Zhang",
        "Vandad Davoodnia",
        "Ali Etemad"
      ],
      "year": "2008",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "17",
      "title": "Self-supervised eeg emotion recognition models based on cnn",
      "authors": [
        "Xingyi Wang",
        "Yuliang Ma",
        "Jared Cammon",
        "Feng Fang",
        "Yunyuan Gao",
        "Yingchun Zhang"
      ],
      "year": "2023",
      "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering"
    },
    {
      "citation_id": "18",
      "title": "Self-supervised eeg representation learning for robust emotion recognition",
      "authors": [
        "Huan Liu",
        "Yuzhe Zhang",
        "Xuxu Chen",
        "Dalin Zhang",
        "Rui Li",
        "Tao Qin"
      ],
      "year": "2024",
      "venue": "ACM Transactions on Sensor Networks"
    },
    {
      "citation_id": "19",
      "title": "Gmaeeg: A self-supervised graph masked autoencoder for eeg representation learning",
      "authors": [
        "Zanhao Fu",
        "Huaiyu Zhu",
        "Yisheng Zhao",
        "Ruohong Huan",
        "Yi Zhang",
        "Shuohui Chen",
        "Yun Pan"
      ],
      "year": "2024",
      "venue": "IEEE Journal of Biomedical and Health Informatics"
    },
    {
      "citation_id": "20",
      "title": "Neu-roLM: A universal multi-task foundation model for bridging the gap between language and EEG signals",
      "authors": [
        "Weibang Jiang",
        "Yansen Wang",
        "Bao Liang Lu",
        "Dongsheng Li"
      ],
      "year": "2025",
      "venue": "The Thirteenth International Conference on Learning Representations"
    },
    {
      "citation_id": "21",
      "title": "CBramod: A criss-cross brain foundation model for EEG decoding",
      "authors": [
        "Jiquan Wang",
        "Sha Zhao",
        "Zhiling Luo",
        "Yangxuan Zhou",
        "Haiteng Jiang",
        "Shijian Li",
        "Tao Li",
        "Gang Pan"
      ],
      "year": "2025",
      "venue": "The Thirteenth International Conference on Learning Representations"
    },
    {
      "citation_id": "22",
      "title": "A circumplex model of affect",
      "authors": [
        "Russell James"
      ],
      "year": "1980",
      "venue": "Journal of Personality and Social Psychology"
    },
    {
      "citation_id": "23",
      "title": "PiCO: Contrastive label disambiguation for partial label learning",
      "authors": [
        "Haobo Wang",
        "Ruixuan Xiao",
        "Yixuan Li",
        "Lei Feng",
        "Gang Niu",
        "Gang Chen",
        "Junbo Zhao"
      ],
      "year": "2022",
      "venue": "International Conference on Learning Representations (ICLR)"
    },
    {
      "citation_id": "24",
      "title": "On the power of deep but naive partial label learning",
      "authors": [
        "Junghoon Seo",
        "Joon Suk"
      ],
      "year": "2009",
      "venue": "International Conference on Acoustics, Speech and Signal Processing"
    },
    {
      "citation_id": "25",
      "title": "Progressive identification of true labels for partial-label learning",
      "authors": [
        "Jiaqi Lv",
        "Miao Xu",
        "Lei Feng",
        "Gang Niu",
        "Xin Geng",
        "Masashi Sugiyama"
      ],
      "year": "2009",
      "venue": "International Conference on Machine Learning (ICML)"
    },
    {
      "citation_id": "26",
      "title": "Exploiting class activation value for partial-label learning",
      "authors": [
        "Fei Zhang",
        "Lei Feng",
        "Bo Han",
        "Tongliang Liu",
        "Gang Niu",
        "Tao Qin",
        "Masashi Sugiyama"
      ],
      "year": "2022",
      "venue": "International Conference on Learning Representations (ICLR)"
    },
    {
      "citation_id": "27",
      "title": "Leveraged weighted loss for partial label learning",
      "authors": [
        "Hongwei Wen",
        "Jingyi Cui",
        "Hanyuan Hang",
        "Jiabin Liu",
        "Yisen Wang",
        "Zhouchen Lin"
      ],
      "year": "2021",
      "venue": "International Conference on Machine Learning (ICML)"
    },
    {
      "citation_id": "28",
      "title": "Revisiting consistency regularization for deep partial label learning",
      "authors": [
        "Dong-Dong Wu",
        "Deng-Bao Wang",
        "Min-Ling Zhang"
      ],
      "year": "2022",
      "venue": "International Conference on Machine Learning (ICML)"
    },
    {
      "citation_id": "29",
      "title": "Emotionmeter: A multimodal framework for recognizing human emotions",
      "authors": [
        "Wei-Long Zheng",
        "Wei Liu",
        "Yifei Lu",
        "Bao-Liang Lu",
        "Andrzej Cichocki"
      ],
      "year": "2018",
      "venue": "IEEE Transactions on Cybernetics"
    },
    {
      "citation_id": "30",
      "title": "Investigating critical frequency bands and channels for EEG-based emotion recognition with deep neural networks",
      "authors": [
        "Wei-Long Zheng",
        "Bao-Liang Lu"
      ],
      "year": "2015",
      "venue": "IEEE Transactions on Autonomous Mental Development"
    },
    {
      "citation_id": "31",
      "title": "EEGNet: a compact convolutional neural network for EEG-based brain-computer interfaces",
      "authors": [
        "Amelia Vernon J Lawhern",
        "Nicholas Solon",
        "Waytowich",
        "Stephen M Gordon",
        "P Chou",
        "Brent Hung",
        "Lance"
      ],
      "year": "2018",
      "venue": "Journal of Neural Engineering"
    },
    {
      "citation_id": "32",
      "title": "Capsule attention for multimodal EEG-EOG representation learning with application to driver vigilance estimation",
      "authors": [
        "Guangyi Zhang",
        "Ali Etemad"
      ],
      "year": "2021",
      "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering"
    },
    {
      "citation_id": "33",
      "title": "Chrononet: a deep recurrent neural network for abnormal EEG identification",
      "authors": [
        "Subhrajit Roy",
        "Isabell Kiral-Kornek",
        "Stefan Harrer"
      ],
      "year": "2019",
      "venue": "17th Conference on Artificial Intelligence in Medicine"
    },
    {
      "citation_id": "34",
      "title": "Classification of hand movements from EEG using a deep attention-based LSTM network",
      "authors": [
        "Guangyi Zhang",
        "Vandad Davoodnia",
        "Alireza Sepas-Moghaddam",
        "Yaoxue Zhang",
        "Ali Etemad"
      ],
      "year": "2019",
      "venue": "IEEE Sensors Journal"
    },
    {
      "citation_id": "35",
      "title": "EEG emotion recognition using dynamical graph convolutional neural networks",
      "authors": [
        "Tengfei Song",
        "Wenming Zheng",
        "Peng Song",
        "Zhen Cui"
      ],
      "year": "2018",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "36",
      "title": "EEG-based emotion recognition using regularized graph neural networks",
      "authors": [
        "Peixiang Zhong",
        "Di Wang",
        "Chunyan Miao"
      ],
      "year": "2020",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "37",
      "title": "Residual gcb-net: Residual graph convolutional broad network on emotion recognition",
      "authors": [
        "Qilin Li",
        "Tong Zhang",
        "Ke Cl Philip Chen",
        "Long Yi",
        "Chen"
      ],
      "year": "2022",
      "venue": "IEEE Transactions on Cognitive and Developmental Systems"
    },
    {
      "citation_id": "38",
      "title": "Deep learning for electroencephalogram (EEG) classification tasks: a review",
      "authors": [
        "Alexander Craik",
        "Yongtian He",
        "Jose L Contreras- Vidal"
      ],
      "year": "2019",
      "venue": "Journal of Neural Engineering"
    },
    {
      "citation_id": "39",
      "title": "Deep learning-based electroencephalography analysis: a systematic review",
      "authors": [
        "Yannick Roy",
        "Hubert Banville",
        "Isabela Albuquerque",
        "; Tiago",
        "H Falk",
        "Jocelyn Faubert"
      ],
      "year": "2019",
      "venue": "Journal of Neural Engineering"
    },
    {
      "citation_id": "40",
      "title": "Learning topologyagnostic eeg representations with geometry-aware modeling",
      "authors": [
        "Ke Yi",
        "Yansen Wang",
        "Kan Ren",
        "Dongsheng Li"
      ],
      "year": "2024",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "41",
      "title": "Large brain model for learning generic representations with tremendous eeg data in bci",
      "authors": [
        "Weibang Jiang",
        "Liming Zhao",
        "Bao-Liang Lu"
      ],
      "year": "2024",
      "venue": "The Twelfth International Conference on Learning Representations"
    },
    {
      "citation_id": "42",
      "title": "Neurolm: A universal multi-task foundation model for bridging the gap between language and eeg signals",
      "authors": [
        "Wei-Bang Jiang",
        "Yansen Wang",
        "Bao-Liang Lu",
        "Dongsheng Li"
      ],
      "year": "2024",
      "venue": "Neurolm: A universal multi-task foundation model for bridging the gap between language and eeg signals",
      "arxiv": "arXiv:2409.00101"
    },
    {
      "citation_id": "43",
      "title": "Mixmatch: A holistic approach to semi-supervised learning",
      "authors": [
        "David Berthelot",
        "Nicholas Carlini",
        "Ian Goodfellow",
        "Nicolas Papernot",
        "Avital Oliver",
        "Colin Raffel"
      ],
      "year": "2019",
      "venue": "Advances in Neural Information Processing Systems (NeurIPS)"
    },
    {
      "citation_id": "44",
      "title": "Adamatch: A unified approach to semi-supervised learning and domain adaptation",
      "authors": [
        "David Berthelot",
        "Rebecca Roelofs",
        "Kihyuk Sohn",
        "Nicholas Carlini",
        "Alex Kurakin"
      ],
      "year": "2021",
      "venue": "Adamatch: A unified approach to semi-supervised learning and domain adaptation",
      "arxiv": "arXiv:2106.04732"
    },
    {
      "citation_id": "45",
      "title": "Semi-supervised dual-stream self-attentive adversarial graph contrastive learning for cross-subject eegbased emotion recognition",
      "authors": [
        "Weishan Ye",
        "Zhiguo Zhang",
        "Fei Teng",
        "Min Zhang",
        "Jianhong Wang",
        "Dong Ni",
        "Fali Li",
        "Peng Xu",
        "Zhen Liang"
      ],
      "year": "2024",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "46",
      "title": "Learning with multiple labels",
      "authors": [
        "Rong Jin",
        "Zoubin Ghahramani"
      ],
      "year": "2002",
      "venue": "Advances in Neural Information Processing Systems (NeurIPS)"
    },
    {
      "citation_id": "47",
      "title": "Supervised contrastive learning",
      "authors": [
        "Prannay Khosla",
        "Piotr Teterwak",
        "Chen Wang",
        "Aaron Sarna",
        "Yonglong Tian",
        "Phillip Isola",
        "Aaron Maschinot",
        "Ce Liu",
        "Dilip Krishnan"
      ],
      "year": "2020",
      "venue": "Advances in Neural Information Processing Systems (NeurIPS)"
    },
    {
      "citation_id": "48",
      "title": "Grad-cam: Visual explanations from deep networks via gradient-based localization",
      "authors": [
        "Michael Ramprasaath R Selvaraju",
        "Abhishek Cogswell",
        "Ramakrishna Das",
        "Devi Vedantam",
        "Dhruv Parikh",
        "Batra"
      ],
      "year": "2017",
      "venue": "Proceedings of conference on International Conference on Computer Vision (ICCV"
    },
    {
      "citation_id": "49",
      "title": "Temporal ensembling for semi-supervised learning",
      "authors": [
        "Laine Samuli",
        "Aila Timo"
      ],
      "year": "2017",
      "venue": "International Conference on Learning Representations (ICLR)"
    },
    {
      "citation_id": "50",
      "title": "A channel-projection mixed-scale convolutional neural network for motor imagery EEG decoding",
      "authors": [
        "Yang Li",
        "Xian-Rui Zhang",
        "Bin Zhang",
        "Meng-Ying Lei",
        "Wei-Gang Cui",
        "Yu-Zhu Guo"
      ],
      "year": "2019",
      "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering"
    },
    {
      "citation_id": "51",
      "title": "Data augmentation for enhancing EEG-based emotion recognition with deep generative models",
      "authors": [
        "Yun Luo",
        "Li-Zhen Zhu",
        "Zi-Yu Wan",
        "Bao-Liang Lu"
      ],
      "year": "2020",
      "venue": "Journal of Neural Engineering"
    },
    {
      "citation_id": "52",
      "title": "Momentum contrast for unsupervised visual representation learning",
      "authors": [
        "Kaiming He",
        "Haoqi Fan",
        "Yuxin Wu",
        "Saining Xie",
        "Ross Girshick"
      ],
      "year": "2020",
      "venue": "Proceedings of conference on Computer Vision and Pattern Recognition (CVPR)"
    },
    {
      "citation_id": "53",
      "title": "A simple framework for contrastive learning of visual representations",
      "authors": [
        "Ting Chen",
        "Simon Kornblith",
        "Mohammad Norouzi",
        "Geoffrey Hinton"
      ],
      "year": "2020",
      "venue": "International Conference on Machine Learning (ICML)"
    },
    {
      "citation_id": "54",
      "title": "BrainUICL: An unsupervised individual continual learning framework for EEG applications",
      "authors": [
        "Yangxuan Zhou",
        "Sha Zhao",
        "Jiquan Wang",
        "Haiteng Jiang",
        "Shijian Li",
        "Tao Li",
        "Gang Pan"
      ],
      "year": "2025",
      "venue": "The Thirteenth International Conference on Learning Representations"
    },
    {
      "citation_id": "55",
      "title": "Incremental false negative detection for contrastive learning",
      "authors": [
        "Wei-Chih Tsai-Shien Chen",
        "Hung-Yu Hung",
        "Shao-Yi Tseng",
        "Ming-Hsuan Chien",
        "Yang"
      ],
      "year": "2022",
      "venue": "International Conference on Learning Representations (ICLR)"
    },
    {
      "citation_id": "56",
      "title": "Prototypical contrastive learning of unsupervised representations",
      "authors": [
        "Junnan Li",
        "Pan Zhou",
        "Caiming Xiong",
        "Steven Hoi"
      ],
      "venue": "International Conference on Learning Representations (ICLR)"
    },
    {
      "citation_id": "57",
      "title": "A study of emotional communication of emoticon based on russell's circumplex model of affect",
      "authors": [
        "Ke Zhong",
        "Tianwei Qiao",
        "Liqun Zhang"
      ],
      "year": "2019",
      "venue": "International Conference on Human-Computer Interaction"
    },
    {
      "citation_id": "58",
      "title": "The cognitive control of emotion",
      "authors": [
        "N Kevin",
        "James Ochsner",
        "Gross"
      ],
      "year": "2005",
      "venue": "Trends in cognitive sciences"
    },
    {
      "citation_id": "59",
      "title": "Emotion circuits in the brain",
      "authors": [
        "Joseph Ledoux"
      ],
      "year": "2013",
      "venue": "Fear and anxiety"
    },
    {
      "citation_id": "60",
      "title": "Pytorch: An imperative style, high-performance deep learning library",
      "authors": [
        "Adam Paszke",
        "Sam Gross",
        "Francisco Massa",
        "Adam Lerer",
        "James Bradbury",
        "Gregory Chanan",
        "Trevor Killeen",
        "Zeming Lin",
        "Natalia Gimelshein",
        "Luca Antiga"
      ],
      "year": "2019",
      "venue": "Advances in Neural Information Processing Systems (NeurIPS)"
    },
    {
      "citation_id": "61",
      "title": "Probing neurodynamics of experienced emotions-a hitchhiker's guide to film fmri",
      "authors": [
        "Elenor Morgenroth",
        "Laura Vilaclara",
        "Michal Muszynski",
        "Julian Gaviria",
        "Patrik Vuilleumier",
        "Dimitri Van De",
        "Ville"
      ],
      "year": "2023",
      "venue": "Social Cognitive and Affective Neuroscience"
    },
    {
      "citation_id": "62",
      "title": "Neural circuitry of emotion regulation: Effects of appraisal, attention, and cortisol administration",
      "authors": [
        "Sean T Ma",
        "Go James L Abelson",
        "Stephan Okada",
        "Israel Taylor",
        "Liberzon"
      ],
      "year": "2017",
      "venue": "Cognitive, Affective, & Behavioral Neuroscience"
    },
    {
      "citation_id": "63",
      "title": "A multimodal database for affect recognition and implicit tagging",
      "authors": [
        "Mohammad Soleymani",
        "Jeroen Lichtenauer",
        "Maja Thierry Pun",
        "Pantic"
      ],
      "year": "2011",
      "venue": "IEEE transactions on affective computing"
    },
    {
      "citation_id": "64",
      "title": "Dreamer: A database for emotion recognition through eeg and ecg signals from wireless lowcost off-the-shelf devices",
      "authors": [
        "Stamos Katsigiannis",
        "Naeem Ramzan"
      ],
      "year": "2017",
      "venue": "IEEE journal of biomedical and health informatics"
    }
  ]
}