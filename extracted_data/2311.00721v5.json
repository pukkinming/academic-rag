{
  "paper_id": "2311.00721v5",
  "title": "This Article Has Been Accepted For Publication In Ieee Transactions On Affective Computing. This Is The Author'S Version Which Has Not Been Fully Edited And Content May Change Prior To Final Publication. Citation Information",
  "published": "2023-10-30T08:34:12Z",
  "authors": [
    "Md Rakibul Hasan",
    "Md Zakir Hossain",
    "Shreya Ghosh",
    "Aneesh Krishna",
    "Tom Gedeon"
  ],
  "keywords": [
    "Empathy",
    "Empathy Computing",
    "Deep Learning",
    "Machine Learning",
    "Pattern Recognition",
    "Systematic Review"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Empathy indicates an individual's ability to understand others. Over the past few years, empathy has drawn attention from various disciplines, including but not limited to Affective Computing, Cognitive Science, and Psychology. Detecting empathy has potential applications in society, healthcare and education. Despite being a broad and overlapping topic, the avenue of empathy detection leveraging Machine Learning remains underexplored from a systematic literature review perspective. We collected 849 papers from 10 well-known academic databases, systematically screened them and analysed the final 82 papers. Our analyses reveal several prominent task formulations -including empathy on localised utterances or overall expressions, unidirectional or parallel empathy, and emotional contagion -in monadic, dyadic and group interactions. Empathy detection methods are summarised based on four input modalities -text, audiovisual, audio and physiological signals -thereby presenting modality-specific network architecture design protocols. We discuss challenges, research gaps and potential applications in the Affective Computing-based empathy domain, which can facilitate new avenues of exploration. We further enlist the public availability of datasets and codes. This paper, therefore, provides a structured overview of recent advancements and remaining challenges towards developing a robust empathy detection system that could meaningfully contribute to enhancing human well-being.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "E MPATHY, an involuntary and vicarious reaction to emo- tional signals from another individual or their circumstances  [1] , is essential for effective communication in many aspects of human life, including social dynamics  [2] , healthcare  [3]  and education  [4] . Empathy towards other individuals is essential for the survival of our species and contributes significantly to enhancing the quality of life and the depth of social interactions  [5] ,  [6] . Research on empathy has been a major topic across various disciplines, including Social Science, Psychology, Neuroscience, Health and, most recently, Computer Science  [7] ,  [8] . Although contexts of empathy research vary across disciplines, all agree on its crucial role in human well-being  [7] . In Computer Science, a significant body of literature deals with operationalising empathy using Machine Learning (ML) tools.\n\nML-based empathy computing remains underexplored compared to more established domains in Affective Computing, such as emotion and facial expression recognition  [9] ,  [10] . Existing reviews on empathy recognition  [8] ,  [11] -  [15]  are fragmented and largely limited to specific contexts. For instance, Paiva et al.  [8]  and Yalcin and DiPaola  [11]  Fig.  1 . Hierarchy of empathy detection task formulations and representative datasets.   1 3 2 0 1 4 2 0 1 5 2 0 1 6 2 0 1 7 2 0 1 8 2 0 1 9 2 0 2 0 2 0 2 1 2 0 2 2 2 0 2 3 2 0 2   focused on artificial agents (published in 2017 and 2018, respectively). In 2022, Park and Whang  [12]  reviewed empathy in social robots, and Raamkumar and Yang  [13]  concentrated on empathic response generation in conversational systems. The more recent reviews -Lahnala et al.  [14]  in 2022 and Shetty et al.  [15]  in 2023 -restricted their scope to Natural Language Processing (NLP)-based approaches. In contrast, our work presents the first comprehensive systematic literature review of empathy detection across four modalities (text, audio, video and physiological signals) and various interaction contexts (e.g., social robots, healthcare and education). We capture studies up to May 2025, and unlike prior reviews, we screen all published works instead of cherry-picking.\n\nOur method adopts relevant aspects of the PRISMA 2020 guidelines  [16] , which are applicable to typical systematic reviews in Affective Computing. Refer to Appendix C for a mapping of how each relevant guideline has been considered in our study. We first devised search keywords and examined ten databases, including Scopus, Web of Science and IEEE Xplore. We screened the resulting 849 records against seven inclusion and exclusion criteria. Through rigorous title-and-abstract and full-text screenings, the final 82 papers are thoroughly reviewed in this paper. As shown in Figure  2 , the distribution of papers reveals a predominant focus on text-based empathy detection (n = 57), followed by audiovisual (n = 15), audio (n = 7), and physiological signals (n = 3). Refer to Appendix A for the details of our paper selection strategy.\n\nWe categorise datasets based on various task formulations found in the literature (Figure  1 ) and analyse ML methods across four input modalities: text, audiovisual, audio and physiological signals. The overarching objective of this study is to systematically review all ML-based empathy detection works published between 2013 and May 2025. Our main contributions are as follows:\n\ni. Systematic categorisation of task formulations in empathy computing. ii. Comparative analysis of 45 existing datasets, including their composition and accessibility.\n\niii. Survey of modelling approaches, highlighting commonly used ML models and code availability. iv. Identification of high-performing methods frequently applied to benchmark datasets. v. Synthesis of application domains where empathy detection can be deployed. vi. Discussion of key challenges and open opportunities across task types and modelling strategies. The paper is organised as follows. Section 2 defines empathy and empathy detection based on several seminal works in Psychology. Section 3 introduces various task formulations with a comprehensive overview of representative datasets. Our dataset analysis includes their statistics, annotation protocol and public availability of the whole annotated dataset. Section 4 presents ML models specific to four input modalities -text sequences, audiovisual content, audio signals and physiological signals -where we discuss studies involving the datasets introduced in Section 3. In presenting empathy detection works, we report public availability of the software code, best-performing models and their performance. Both Section 3 and Section 4 end with a consolidating discussion on findings, challenges and opportunities. We present some applications of empathy detection in Section 5 and conclude the paper in Section 6.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Preliminaries",
      "text": "",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Empathy And Related Concepts",
      "text": "With broad usage across various disciplines, the definition of empathy varies. Cuff et al.  [17]  reviewed 43 discrete definitions of empathy and identified eight themes related to its nature. Themes include distinguishing empathy from similar concepts and determining whether it is cognitive or affective. The term 'empathy', as defined by Hoffman  [1] , is predominantly an involuntary and vicarious reaction to emotional signals from another individual or their circumstances. In another work, Hoffman  [5]  defines empathy as 'an affective response more appropriate to another's situation than one's own'. Empathy is a multifaceted concept that involves perceiving, understanding and sharing the emotional thoughts of others  [18] . It can also be defined as a multidimensional concept, such as four-dimensional empathy (perspective taking, fantasy, empathic concern and personal distress)  [19] , and two-dimensional empathy (empathic concern and personal distress)  [20] .\n\nNumerous endeavours have been made to disentangle empathy from other similar concepts  [17] . Some scholars (e.g.,  [20] ,  [21] ) conceptualise empathy as a comprehensive category including emotional contagion, sympathy and compassion. Empathy is defined as comprehending another's emotions through adopting their perspective; other related psychological states include compathy (feelings shared due to shared circumstances), mimpathy (copying another's emotions without personally experiencing them), sympathy (intentionally responding emotionally), transpathy (emotional contagion, where one becomes 'infected' by another's emotions) and unipathy (an elevated form of emotional contagion)  [22] ,  [23] . Despite the inherent ambiguity in defining empathy, scholars such as Ickes  [22]  and Blair  [24]  advocated separating these terms. The two most related terms are empathy and sympathy, which can be described as 'feeling as' versus 'feeling for', respectively  [25] . Neuroscientific evidence supports the distinction between empathy and sympathy as they have distinct neural processes  [26] .\n\nWhile distinctions in empathy are well-recognised in Psychology, empathy computing literature often overlooks these nuances during dataset collection and labelling. This is likely because the primary focus has been on detecting the presence of empathy in any form, typically categorised into levels such as 'not empathic', 'somewhat empathic', and 'very empathic'  [27]  or as binary classifications like 'empathic' and 'not empathic'. Binary labelling, in particular, is the most prevalent approach in the literature  [28] -  [31] . Given that empathy computing literature does not always adopt a formal definition of empathy, we chose not to exclude any studies based on their operational definitions of the concept.\n\nWithin the domain of empathy, perhaps the two most common forms are cognitive empathy and emotional (also known as affective) empathy  [32] . Understanding someone's thoughts and perspective is known as cognitive empathy, whereas vicarious sharing of emotion is known as emotional empathy  [32] . Cognitive empathy is closely related to the theory of mind, that is, understanding another person's mental state, such as wants, beliefs and intentions  [24] . In other words, cognitive empathy is 'I understand what you feel', whereas emotional empathy is 'I feel what you feel'  [33] . Although most empathy computing studies treat empathy as a single, consolidated construct, Dey and Girju  [34]  explicitly distinguishes between cognitive and affective empathy in a patient-doctor interaction setup.\n\nEmpathy detection differs from emotion detection, although both involve analysing human responses. Emotion detection focuses on recognising an individual's emotional state, such as happiness or sadness  [35] . In contrast, empathy detection goes into a deeper analysis of the interactions between multiple individuals. It considers the initial emotion expressed by one person and the emotional response of the other, whose empathy is being measured. For example, if someone expresses sadness, empathy detection would analyse how the listener emotionally supports the speaker in response  [36] .",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Empathy Measurement",
      "text": "In Psychology, questionnaires are widely employed to measure self-reported empathy levels  [19] . These instruments typically present participants with statements or scenarios, prompting them to indicate their level of agreement or emotional response. Examples of widely used empathy questionnaires include the Interpersonal Reactivity Index (IRI)  [37] , the Empathy Quotient  [38] , Batson's Empathy Scale  [20]  and the Toronto Empathy Questionnaire  [39] .\n\nEmpathic accuracy is another method of operationalising empathy in Psychology, which assesses how accurately an individual can infer another person's thoughts and emotions. Experimentally, it is often determined by comparing one person's reported thoughts and emotions with their partner's in a dyadic interaction  [40] .\n\nIn Affective Computing, computational methods are developed to objectively measure empathy levels from verbal and non-verbal cues, such as facial expressions, tone of voice and body language. To achieve this, self-reported empathy levels through psychological questionnaires often provide necessary ground truths for training ML algorithms. Studies that use such self-reported annotations typically align with a specific definition of empathy as defined by the chosen questionnaire. For instance, Batson et al.  [20] 's definition has been employed for measuring empathy in written essays  [30] ,  [41] ,  [42] , while the IRI questionnaire  [19] ,  [37]  has been used in studies such as  [43] . However, not all studies explicitly adhere to a specific definition of empathy. For example, datasets like RolePlayMI  [44]  and PEC adopt heuristic labelling approaches based on the origin of the data rather than examining each sample.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Task Formulations In Detecting Empathy",
      "text": "Let X be the input content on which empathy y will be measured. The content can be multimodal, i.e., X ∈ {X s , X a , X v }, where X s , X a , X v refer to text, audio, and video sequences, respectively. The empathy label y can be formulated as different levels of empathy, as in a classification problem, or a degree of empathy, as in a regression problem. The content X can consist of N segments X i , where i ∈ [1, N ]. Accordingly, measuring empathy on some segments of the content\n\nwhere 0 ≤ m < N , can be interpreted as localised measurement, whereas measuring empathy on the whole content X can be interpreted as global measurement.\n\nA range of experimental setups have been proposed in the literature to define and structure the specific goals for detecting empathy. Firstly, in Monadic Response, the focus is on measuring empathy on self-contained, individual responses of a person. Secondly, in Dyadic Interaction, empathy is measured from the interactions between two individuals. Expanding beyond dyads, in Group Interaction, empathy is measured on multiple individuals engaging in an interaction. Task formulations in each of these setups and corresponding datasets are summarised in the following subsections.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Monadic Response",
      "text": "Several studies explored monadic response-based empathy computing in either the localised or global manner (Table  1 ).",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Localised Measurement",
      "text": "In detecting empathy at a localised level of monadic responses, Shi et al.  [28]  proposed MedicalCare dataset, which consists of 774 narrative essays of simulated patientdoctor interactions written by pre-med students. Sentences of the essays were labelled as either 'empathic' or 'nonempathic' by six trained undergraduate students, followed by two meta-annotators. Samples were considered 'empathic' if they displayed cognitive or affective empathy. As an extension of this task formulation, Dey and Girju  [34]  selected 440 essays from the pool of 774 MedicalCare essays and re-annotated them into four labels: cognitive empathy, affective empathy, prosocial behaviour and nonempathy, hereinafter referred to as the MedicalCare v2 dataset. Dey and Girju  [34] 's task formulation, therefore, aims to measure different types of empathy rather than different levels of generalised empathy like Shi et al.  [28] . As a further extension of the MedicalCare v2 dataset, Dey and Girju  [29]  formulated an empathy versus non-empathy classification problem by collapsing cognitive, affective and prosocial labels into a single 'empathic' class, hereinafter referred to as the MedicalCare v3 dataset. In this updated dataset, the authors also identified four themes that a healthcare provider might express during the interactions: (1) empathic language, (2) medical procedural information, (3) both empathy and information and (4) neither empathy nor information. Such a thematic approach can help healthcare providers communicate effectively, given that they need to empathise as well as deliver procedural information.\n\nLeadEmpathy is another dataset modelling localised measurement, which consists of emails from participants acting as leaders in a business organisation  [45] . In the first phase of data collection, each participant wrote an email to their subordinate employees regarding a hypothetical concern that resulted in losing a customer. In the second phase of the experiment, the participants were asked to rewrite their earlier emails to increase empathy. Both emails were considered for empathy detection, and exploratory data analysis supports increased empathy in the second email. The annotation protocol considers empathy success and failure in both cognitive and affective empathy. Segments of emails are annotated into discrete empathy scores ranging from -4 to +7, which facilitates modelling it either as a classification task or a regression task. In addition, scores of 1 and below can be mapped to 'low' empathy and scores of 2 and higher to 'high' empathy in a binary classification setup  [45] .",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Global Measurement",
      "text": "In predicting empathy on the whole content level, the NewsEssay dataset consists of essays written by Amazon Mechanical Turk participants about news articles involving harm to individuals, groups or nature. In addition to the essays, the dataset consists of participants' demographic information, such as age, gender, income and education level. This dataset has gone through a series of enhancements, serving empathy detection challenges in a conference workshop named Workshop on Computational Approaches to Subjectivity, Sentiment & Social Media Analysis (WASSA) 1 . The WASSA 2021 and 2022 challenges use the same NewsEssay v2 dataset  [41] , whereas the WASSA 2023 challenge release the updated NewsEssay v3 dataset  [42] , both of which extend from the inaugural NewsEssay dataset  [30]  by involving new participants in the data collection experiment. The NewsEssay v4 dataset, used in WASSA 2024 challenge, includes samples from the NewsEssay v3 dataset and further extends it with additional data. Empathy labels in these datasets came from the essay writers themselves as they filled in Batson's empathy and distress scale  [20] . This scale includes questions related to six empathy-related emotions (sympathetic, compassionate, tender, etc.) and eight personal distress-related emotions (alarmed, upset, worried, etc.). The responses were collected on a 7-point Likert scale, where a value of one and seven means the participant is not feeling the emotion at all and is feeling the emotion extremely, respectively. After averaging the scores across questions, this dataset's ground truth degree of empathy ranges from 1 to 7 for each written essay.\n\nPeople often leave reviews on products or services through online forums, including for hospitals. A. Rahim et al.  [31]  collected people's reviews on the official Facebook pages of 48 public hospitals. Two hospital quality managers labelled the reviews of this FacebookReview dataset into 'yes' or 'no' empathy. This task formulation aimed to analyse the service quality of the hospitals in addition to other characteristics such as assurance, responsiveness and reliability.\n\nApart from individuals' expressed contents like written essays, empathy can be measured from physiological signals since these indicate individuals' internal emotional states  [48] . The fMRI dataset  [43]  consists of resting-state functional Magnetic Resonance Imaging (fMRI) data from 24 cocaine-addicted subjects. The subjects filled in the wellknown IRI questionnaire  [19] ,  [37] , which provides continuous empathy scores for empathy assessment.",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "Dyadic Interaction",
      "text": "Similar to monadic response-based empathy computing, dyadic interactions are explored both in localised and global measurements. Table  2  and Table  3  categorise datasets derived from such interactions into subcategories based on their task formulations.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Localised Unidirectional Empathy",
      "text": "Localised measurement of unidirectional empathy (i.e., empathy flowing in one direction) has been studied across various contexts Table  2 , such as social media, healthcare and general conversations.\n\n3.2.1.1 Social Media: In empathising by one person towards another, several studies leverage dyadic interaction from online forums. For example, the iEmpathize dataset  [36]  consists of discussion threads from a website named Cancer Survivors Network 2 . Collected from the same website, the LungBreastCSN dataset  [49]  focuses on lung and breast cancer data. While the iEmpathize dataset aims to detect empathy direction (seeking, providing or none), the LungBreastCSN dataset aims to detect the presence of empathy (empathic and non-empathic sentences).\n\nThe RolePlayMI dataset  [44]  consists of counselling conversations from video-sharing platforms, such as YouTube and Vimeo, which were originally collected in a separate study on counselling quality analysis  [50] . Wu et al.  [44]  later annotated this dataset into utterance-level empathic and non-empathic categories.\n\nBeing a versatile platform, Reddit is often used for analysing data across different topics of interest. The PEC dataset  [44] ,  [51]  consists of general conversations 2. https://csn.cancer.org/ from three subreddits (forums dedicated to specific topics in Reddit), which are labelled heuristically. Utterances from the 'Happy' and 'OffMyChest' subreddits and the EmpathicDialogues corpus (dyadic conversations regarding any personal situation)  [52]  are considered empathic labels, whereas samples from the 'CasualConversation' subreddit are considered non-empathic labels.",
      "page_start": 5,
      "page_end": 6
    },
    {
      "section_name": "Patient-Doctor Interaction:",
      "text": "The MultimodalMI dataset  [53] ,  [54]  consists of two realworld motivational interviewing sessions: (Dataset 1) students assigned to MI sessions due to alcohol-related matters, and (Dataset 2) volunteering heavy drinkers aged 17-20 years. The therapists' empathy (through a sequence of texts) is annotated primarily through a Likert scale, which is also converted to binary labels (low vs high empathy). This dataset, therefore, allows empathy detection as either a classification problem  [54]  or as a regression problem  [53] . Annotation protocols utilise Motivational Interviewing Skill Code (MISC) 2.5 guidelines  [60]  for Dataset 1 and Motivational Interviewing Treatment Integrity (MITI) 3.1 code  [61]  for Dataset 2. The dataset consists of speech transcripts and audio, enabling it to model a multimodal empathy detection problem.\n\nAnother multimodal dataset is the MEDIC dataset  [55] , which consists of video, audio and text sequences of counselling case videos. It evaluates counsellors' empathy through three mechanisms: expression of experience, emotional reaction and cognitive reaction. The 'expression of experience' mechanism aims to measure a client's expression to trigger empathy from a counsellor. In contrast, the 'emotional reaction' and 'cognitive reaction' mechanisms aim to measure the empathy of counsellors. Five trained students annotated the speech turns into none, weak and strong expressions for each mechanism.\n\nLastly, mental health helpline counsellors' empathy is being measured from telephone conversations in a suicide helpline service named On The Line, Australia (OTLA)  [56] . Segments of the audio conversations are annotated by two expert mental health practitioners using the Carkhuff and Truax Empathy scale  [62] , which is later converted to binary labels (low vs high empathy) for empathy detection.\n\n3.2.1.3 Interaction with Non-Human Entity: The DAIC-WOZ dataset comprises semi-structured interviews between human participants and a virtual agent, which aims to measure the empathy of the virtual agent towards the human participants. The conversations are segmented into small time windows and annotated by third-party annotators into three classes: negative empathy, positive empathy and no empathy  [57] ,  [58] . Responses such as 'That sounds really hard' are considered 'negative empathy', whereas no responses, expressed fillers or responses without sentiment are considered 'no empathy'.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Localised Parallel Empathy",
      "text": "In one study covering localised empathy measurements, both persons provide empathy to someone else (parallel empathy), such as two persons conversing and empathising with some disadvantaged people. This NewsConvT dataset  [42]  consists of dyadic conversations regarding newspaper articles featuring harm to individuals, entities or nature. Speech turns of the conversations are annotated by independent annotators on a scale of 0 to 5. It is worthwhile to note that the same news articles were used in the NewsEssay v3 dataset, which aims to measure the empathy of individual study participants towards others through written essays.\n\nIn contrast, the NewsConvT dataset aims to measure the empathy of two persons in the conversations.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Global Unidirectional Empathy",
      "text": "Similar to the localised measurement of unidirectional empathy, global measurement has been explored in various contexts (Table  3 ), including social media and healthcare. 3.2.3.1 Social Media: Several studies assess empathy globally from social media data -primarily Twitter, Reddit and Facebook -which are annotated by trained annotators. For example, the Brand-Customer dataset  [63]  consists of Twitter threads about customer service-related queries and corresponding brand responses. The authors  [63]  aimed to estimate engagement between brands and customers into three categories of empathy: none, weak and strong empathy (of brand agents).\n\nThe TwittEmp dataset  [64]  consists of cancer-related tweets labelled into three categories: seeking, providing and no empathy. In a binary classification setting, the 'seeking' and 'providing' samples are considered positive, and the no empathy samples are considered negative.\n\nApart from these, various online forums facilitate consultations and mental health support. Sharma et al.  [65]  proposed a widely-recognised empathy detection framework, named EPITOME, which consists of three communication mechanisms: emotional reactions, interpretations and explorations. Mental health-related help-seeking posts were collected from Reddit and TalkLife (a dedicated mental health support network) and annotated into three categories -none, weak and strong -for each of the three mechanisms. EPITOME was relabelled by Hosseini and Caragea  [66]  into two classes: weak and strong communication as the positive samples, and no communication as the negative samples, hereinafter referred to as the EPITOME v2 dataset.\n\nThe AcnEmpathize dataset consists of discussions from an online acne-related forum  3  . Adopting the annotation principle of EPITOME  [65] , three annotators labelled each of the discussion components (posts, replies and quotes) as either 'empathic' or 'not empathic'. A discussion component is labelled as empathic if any part exhibits any of the three communication mechanisms (emotional reactions, interpretations and explorations) of the EPITOME framework.\n\n3.2.3.2 Patient-Doctor Interaction: Global measurement has been formulated in several datasets of counselling sessions between therapists and patients. For example, the motivational interviewing dataset, named MI   [68] , comprises interview sessions from clinical interviews with patients of drug or alcohol use from six clinical studies. Another similar dataset (MI v2)  [69]  also evaluates session-level empathy in motivational interviewing. The CTT dataset  [70] ,  [71]  includes 200 sessions between therapists and patients of drug and alcohol abuse. The annotation includes a continuous degree of empathy between 1 and 7 to model a regression problem and a low or high empathy level to model a classification problem. The COPE dataset  [72] ,  [73]  consists of 425 oncology encounters between cancer patients and healthcare providers. The task of this dataset is to detect empathic interactions and filter out non-empathic ones. Two trained annotators labelled this dataset into binary labels, where empathic interaction refers to when a patient expressed negative emotions and the oncologists responded empathically.\n\n3.2.3.3 General Conversation: Apart from specialised peer support communities and patient-doctor interactions, some studies aim to measure empathy in general conversations. For example, the EmpathicDialogues dataset -consisting of conversations regarding any personal situation and earlier used in localised measurement  [44] ,  [52]  -was relabelled into five levels of empathy (EmpathicDialogues v2) and used for global measurement  [27] .\n\nThe quality of support provided by call centre staff can be measured by measuring their empathy. Alam et al.  [74]  proposed CallCentre dataset consisting of human-to-human call-centre conversation, where conversations are labelled either empathic if the session contains at least one empathic segment or non-empathic otherwise.\n\n3.2.3.4 Interaction with Non-Human Entity: Several global empathy detection datasets include interactions between humans and non-human entities, such as avatars and robots. The Human-Robot data collection includes a robot telling scripted stories to human participants  [75] . Stories were told in either first-person or third-person point of view. To measure the participants' empathy towards the robot or story content, the participants answered a custom questionnaire of eight questions on a 5-point Likert scale. Thresholding based on median statistics is used to binarise the empathy scores into two labels ('empathic' and 'less empathic').\n\nThe Human-Avatar dataset aims to assess the empathy of human participants interacting with an avatar expressing six types of emotion  [76] . Rather than self-reported annotation or third-party annotation, each interaction is labelled as empathic for normotypical participants and nonempathic for participants having social communication disorders such as Down syndrome and intellectual disability. Such a labelling approach was formulated to diagnose social communication disorders through empathy assessment.\n\nIn Human-VirtualAgent dataset  [77] , human participants watched a virtual character expressing sadness in a virtual reality environment. Participants fill in two questionnaires, including the Toronto empathy questionnaire  [39] , to reflect how much empathy they feel towards the agents. The questionnaire responses are leveraged as self-assessed ground truth empathy scores on a scale of 0 to 20.\n\nLastly, the EmpathicStories++ dataset features human participants telling personal stories to a ChatGPTbased AI agent and reading stories shared by the agent  [78] . Collected over a month-long in-the-wild deployment, the dataset includes multimodal recordings (video, audio, and text) and several state and trait surveys from 41 participants. The empathy labels are based on participants' self-reported ratings of their empathy toward each story on a sliding scale from 1 to 5.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Global Parallel Empathy",
      "text": "Building on the turn-level empathy annotations in the NewsConvT dataset  [42] , Giorgi et al.  [47]  released NewsConvD, which provides dialogue-level annotations of perceived empathy. While both datasets feature conversations between two participants discussing newspaper articles, this new annotation specifically captures each participant's perception of their partner's empathy towards the articles.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Global Bidirectional Empathy",
      "text": "Bidirectional empathy can be defined as two individuals empathising with each other. Shen et al.  [79]  introduced EmpathicStories, which features bidirectional empathy in personal stories. Pairs of personal stories are labelled in terms of how two persons empathise with each other's experiences. The authors operationalise empathic similarity in terms of three key aspects: main event, emotion and moral of the story  [79] .",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Localised Emotional Contagion",
      "text": "Emotional contagion -the process by which one person's emotions and behaviours trigger similar emotions and behaviours in others -is an element of empathy  [20] ,  [21] . Some studies exclusively aim to measure emotional contagion, and, as such, they are discussed in this separate category of task formulation.\n\nOne such dataset, named OMG-Empathy  [80] , consists of audiovisual conversations with semi-scripted stories in a speaker-listener setup. Following the conversations, the listeners answered how the story impacted their emotional state in terms of a valence score between -1 to +1. Using this dataset, an empathy detection challenge  4  was organised, and accordingly, several empathy detection models are proposed for this dataset. This dataset offers two detection protocols: a personalised protocol, which detects the valence score of each listener across all conversations, and a generalised protocol, which detects the valence score towards each story by all listeners.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Global Emotional Contagion",
      "text": "Three datasets aim to measure emotional contagion at the global level. These datasets are collected through passive dyadic interaction, where the subjects often look at some stimuli, for example, still images, video or text sequences (Table  4 ).\n\nSome studies use subjects' physiological signals during a passive interaction. For example, the EEG dataset  [81]  contains Electroencephalogram (EEG) signals from 52 participants watching an emotional video (a young girl being abused as a domestic enslaved person) in virtual reality. The EEG signals were collected from the frontal, central and occipital regions of the brain before, during and after watching the video. Before the experiment, the participants filled in the Toronto empathy questionnaire  [39] . Although the questionnaire allows empathy annotations to range from 0 to 96, participants' responses fell within a narrower range of 49 to 86, indicating a moderate to high level of empathy reported by the participants. Using a median split, samples are also grouped into high and low classes. Both regression and classification tasks in this dataset offer empathy detection at all three times when the EEG was collected: before, during and after.\n\nThe PainEmp dataset  [82]  comprises Electrocardiogram (ECG) and skin conductance data from 36 participants with different levels of autistic traits. After viewing pictures of individuals with different pain levels, the participants filled in a questionnaire regarding cognitive and affective empathy. Although it may sound a little frightening, the painful pictures (24 in total) were, in fact, collected from eight individuals going through different levels of electrical stimulation on the back of their hands. This dataset's task is to classify cognitive and affective empathy into high or low levels.\n\nFinally, the PathogenicEmp dataset aims to measure emotional contagion from Facebook posts. Abdul-Mageed et al.  [83]  defines 'pathogenic empathy' as the automatic contagion of negative emotions from others, which may lead to stress and burnout. The authors argued that this negative side of empathy is risky for the health and well-being of empathic people. In their data collection, participants answered a questionnaire, which consisted of eight questions on a Likert scale, with 'not at all like me' on one end and 'very much like me' on the other end of the scale. The average of the responses is considered the ground truth pathogenic empathy score.",
      "page_start": 8,
      "page_end": 9
    },
    {
      "section_name": "Group Interaction",
      "text": "There is only one dataset where empathy is measured from more than two persons as a group (Table  4 ). This dataset, hereinafter referred to as the Teacher-Student dataset, consists of 63 online audiovisual lectures in a one-to-many teaching setup  [84] . Expert annotators label each lecture session on a scale of 0 to 10 (regression task), which is then thresholded to binarise into 'Excellent' and 'Good' categories (classification task). The broader aim of Pan et al.  [84] 's work is to evaluate teaching quality through five characteristics of a good lecture: empathy, clarity, interaction, technical management and time management.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Discussion: Findings, Challenges And Research Gaps",
      "text": "The varieties in task formulations and trends across all datasets result in several key findings and opportunities, which are discussed in the following subsections.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Prospective Task Formulations",
      "text": "Although unidirectional empathy is well studied in localised and global measurements (Figure  1 ), there is a notable gap in exploring parallel empathy. We found only one study on parallel empathy in localised measurement and another in global measurement. Parallel empathy is particularly relevant in understanding collective emotional dynamics, such as in team collaborations or group therapy sessions. Investigating these scenarios could reveal insights into how empathy propagates in multi-person interactions.\n\nSimilarly, studies are scarce in group interactions, with only one study addressing the global measurement of unidirectional empathy. Group settings capture naturalistic social environments, and therefore, empathy computing in group scenarios could advance effective collaboration and social cohesion. Overall, investigating these new task formulations could significantly enrich our understanding of the evolution and change in empathy during complex social interactions.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Empathy From Observer'S Physiological Signals",
      "text": "Physiological signals contain essential affective cues in detecting internal states of people, which are often difficult to detect in other ways, such as classifying posed smiles  [85]  and pretended anger  [86]  from their real counterparts. Hossain et al.  [85] 's observer-based smile veracity detection shows that it is possible to objectively measure subjective reactions. Considering the subjective nature of empathy, accurately assessing someone's actual (ground truth) empathy level can be challenging, making physiological signals potentially valuable.\n\nOut of all the task formulations we review in this paper, three studies measured empathy from subjects' physiological signals, including ECG, EEG, fMRI and skin conductance. Firstly, other types of physiological signals that showed effectiveness in Affective Computing, such as pupillary response  [86]  and blood volume pulse  [85] , may be experimented with for empathy detection. Secondly, instead of physiological signals from one person, we could leverage signals from all parties involved, for example, both people in a dyadic interaction. Thirdly, detecting empathy from an observer's physiological signal could be an interesting avenue of exploration. This way, physiological signals can be collected from an observer observing the interaction in which we want to measure empathy. Then, we could investigate if the signals correlate with participants' empathy. Studying observer-based physiological signals could uncover how empathy is perceived and processed by third parties, a perspective that has implications for training empathy in professionals such as counsellors, educators and healthcare workers.",
      "page_start": 9,
      "page_end": 10
    },
    {
      "section_name": "Annotation Protocol",
      "text": "The performance of supervised ML models is inherently tied to the quality of the labelled data. Empathy detection datasets are annotated primarily in two ways: selfannotation and third-party annotation. Self-rated annotation is a popular way to get the data labelled for Affective Computing tasks  [87] . In empathy computing, it refers to study participants filling in empathy-related questionnaires such as the IRI  [19] ,  [37]  and the Toronto  [39]  questionnaires. In contrast, third-party annotation refers to annotations by third-party trained annotators instead of the study participants from whom the data is collected.\n\nThe choice between self-annotation and third-party annotators remains a debated topic in the literature. Of all the datasets we examine in this paper, 13 used self-annotation, and 30 used third-party annotation. Buechel et al.  [30]  argued that self-annotation provides a more appropriate measure of empathy than third-party annotators. Shi et al.  [28]  used MedicalCare dataset, annotated by trained third-party annotators, and NewsEssay dataset, annotated by study participants themselves. One interesting conclusion of their study is that third-party annotation could be more robust than self-rated annotation  [28] . Using ensemble methods to combine the results of multiple third-party annotators is likely to be the most robust, which should be investigated thoroughly.\n\nThe NewsEssay v3 and NewsConvT datasets use the same participants but differ in annotation protocols, with self-assessment for essays and third-party annotation for conversations, respectively. As shown in Table  5 , studies have achieved higher empathy detection performance in the NewsConvT dataset than in the NewsEssay v3 dataset, potentially suggesting that third-party annotation provides greater consistency.\n\nJudgment varies across individuals; for example, a certain empathic interaction can be felt as 'high' by someone, whereas the same can be felt as 'medium' by someone else. In this case, employing multiple third-party annotators to label many of the samples separately and subsequently testing their inter-rater reliability to reach a consensus for confounding samples should be preferred. However, a study has found that third-party annotators' conscious labelling of subjective reactions is worse than their non-conscious judgement  [85] . Therefore, it can be argued that a third-party annotator may be unable to accurately assess the perceived empathy of the subject because empathy is subjective. To come to a conclusion, both self-annotation and third-party annotation, while fixing the other aspects (such as dataset and model), would be a prospective research domain to understand more about annotation and simultaneously find an appropriate annotation scheme.",
      "page_start": 10,
      "page_end": 11
    },
    {
      "section_name": "Public Availability Of Datasets",
      "text": "Data availability facilitates reproducibility, comparative studies and benchmarking research. Among the 45 empathy detection datasets reviewed, 25 are publicly available. Challenges associated with making data public include privacy and ethical considerations. Ensuring the anonymisation of sensitive information and obtaining proper consent from participants are crucial steps, supposedly for which patient data such as MI, CTT, and COPE are unavailable. Additionally, there may be legal and institutional restrictions that prevent sharing of certain datasets. Addressing these challenges is essential during the early stage of planning to ensure data availability. We urge the authors of the 20 nonpublic datasets to take active steps towards making them public.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Modality-Specific Empathy Detection Methods",
      "text": "Design protocols for empathy detection methods, including the choice of preprocessing techniques and specific ML models, are primarily influenced by the input data modality. This section outlines methods based on four input modalities -text sequences, audiovisual contents, audio signals and physiological signals -observed across different task formulations.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Text Sequence",
      "text": "In NLP research, empathy is detected from various textual content, such as essays, conversations and social media discussions. Such text-based datasets are predominantly employed with transformer-based Deep Learning (DL) algorithms and, to a lesser extent, with classical ML algorithms. Figure  3  illustrates the usage of algorithms in text-based empathy detection studies. With the recent successes of finetuning pre-trained language models in a variety of NLP tasks  [88] , it comes as no surprise that pre-trained language models dominate the landscape of text-based empathy detection studies. Among different variants of pre-trained language models, the Bidirectional Encoder Representations from Transformers (BERT)-based Robustly Optimised BERT Pretraining Approach (RoBERTa) is mostly used, followed by the BERT base model itself.\n\nBoth a continuous degree of empathy (regression) and a distinct level of empathy (classification) detection tasks are described in the literature, which are discussed in the following subsections.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Regression Task (Degree Of Empathy)",
      "text": "Table  5  summarises regression studies on common benchmark textual datasets and highlights the best-performing models in each benchmark. Refer to Appendix Table  B2  for studies on datasets used in a single published work. Most works used NewsEssay and its variants to detect empathy as a continuous value. The average performance in detecting empathy in essays from the v4 and v3 datasets is relatively lower than that observed in the v1 and v2 datasets, which may be attributed to the smaller size of the v3 and the v4 datasets.\n\nOut of 30 studies on NewsEssay datasets, 28 of them leverage pre-trained word-embedding or language models. Buechel et al.  [30]  leveraged fastText  [119] , a pre-trained word-embedding model, for text embeddings, followed by a Convolutional Neural Network (CNN) regression model, achieving a Pearson correlation coefficient of 0.404 in the NewsEssay dataset. Vettigli and Sorgente  [91]  employed Linear Regression (LR) classical ML method on the v2 dataset and reported a Pearson correlation coefficient of\n\nFig.  3 . Usage of ML algorithms in text-based empathy detection studies, demonstrating a substantial use of pre-trained language models. 0.516. This performance is competitive with studies utilising transformer-based language models such as BERT and RoBERTa, where the Pearson correlation coefficient ranges from 0.470 to 0.558  [93] ,  [94] . This exceptional performance using classical ML can be attributed to incorporating handcrafted features, such as lexicon-based, n-gram and demographic-based features  [91] . Handcrafted features combined with additional raw data could be experimented with transformer architectures, as this might yield even better performance. Instead of traditional ML and DL models, some recent studies  [89] ,  [107] ,  [109] -  [111]  leverage Large Language Model (LLM). For example, Hasan et al.  [89]  introduces a system called LLM-Guided Empathy (LLM-GEm) that leverages Generative Pre-trained Transformer (GPT)-3.5 LLM for three distinct purposes: converting numerical demographic numbers into semantically meaningful text, augmenting text sequences and rectifying label noises. Experiments on NewsEssay v1, v2 and v3 datasets demonstrate that LLM-GEm achieves state-of-the-art performance on the v1 and v3 datasets using a RoBERTa-based pretrained language model as the prediction model. On the v2 dataset where LLM-GEm underperformed, Mundra et al.  [93]  reported the best result (Pearson correlation coefficient: 0.558) using an ensemble of ELECTRA and RoBERTa models. Such a higher performance can be attributed to the ensemble of two language models (ELECTRA and RoBERTa). Overall, RoBERTa appears to be the best method in detecting empathy within the NewsEssay datasets.\n\nPerformance on the NewsConvT dataset is higher than NewsEssay datasets, with 0.708 as the highest Pearson correlation coefficient using a Decoding-Enhanced BERT with Disentangled Attention (DeBERTa) model  [102] . Plausible reasons could be the annotation protocols (as discussed RoBERTa-MLP 0.193 × Note: Studies using common datasets are sorted year-wise chronologically, followed by performance, where best results and methods are bolded. a U -Unofficially available on the Internet but not provided with the paper b PCC -Pearson correlation coefficient earlier, NewsConvT uses third-party annotation, which is likely to be more consistent and reduce the noise in the labels) and the size of the datasets (12,601 samples in the NewsConvT dataset compared to 1,100-2,655 samples in the NewsEssay datasets).",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Classification Task (Level Of Empathy)",
      "text": "In the case of modelling empathy as a classification task, four benchmark datasets are used in multiple studies to allow comparative analysis (  [65]'s models on the EPITOME dataset. However, one important insight from Lee et al.  [120] 's study is that the current empathy detection models probably consider surface-level information rather than the whole conversation context. In detecting empathy on the iEmpathize dataset, Hosseini and Caragea  [36] ,  [122]  leveraged BERT and RoBERTa models, respectively. Despite being the same dataset, their reported classification performances are on different evaluation metrics: a maximum F1 score of 85.9% is reported in  [36] , and a classification accuracy of 81.1% is reported in  [122] . The key contribution of Hosseini and Caragea  [122] 's work is a data-agnostic technique for prompt-based fewshot learning to improve the performance of pre-trained language models on empathy and emotion classification tasks, especially when training data is limited and noisy.",
      "page_start": 11,
      "page_end": 12
    },
    {
      "section_name": "Audiovisual Content",
      "text": "Empathy detection from audiovisual contents is designed mostly as a multimodal system combining computer vision and NLP techniques, with inputs such as facial expressions, hand gestures and audio conversations. This section, therefore, includes some multimodal approaches, which utilise audio, video and sometimes text sequences.  Note: Studies using common datasets are sorted year-wise chronologically, followed by performance, where best results and methods are bolded. a Performance refers to test-set performance unless otherwise stated. P -Personalised protocol; G -Generalised protocol; CCC -Concordance Correlation Coefficient b U -Unofficially available on the Internet but not provided with the paper Support Vector Machine (SVM) enjoys a higher level of usage.\n\nTable  7  summarises empathy detection studies on the only common benchmark audiovisual dataset, named OMG-Empathy. Refer to Appendix Table  B4  for studies on audiovisual datasets used in a single published work.",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Regression Task (Degree Of Empathy)",
      "text": "The baseline model in the OMG-Empathy challenge  [80]  used VGG16 architecture to process facial expression and Long Short-Term Memory (LSTM) to process spatialtemporal features. The outputs of these two networks were then concatenated and fed to an SVM for empathy detection, which resulted in 0.17 and 0.23 correlation coefficients in the personalised and generalised empathy protocols, respectively. Challenge participants  [125] -  [129]  did not surpass these baseline results. Among them, Barbieri et al.  [129]  performed the best, achieving a 0.17 correlation coefficient for both protocols. They used separate models for each modality -Gated Recurrent Unit (GRU) on audio signals, LSTM on audio transcripts (text) and CNN on vision (face and body images) -followed by Multi Layer Perceptrons (MLPs). To integrate the predictions across different modal-ities, they used a weighted average proportional to the validation score on each modality, followed by a Butterworth low-pass filter.\n\nTan et al.  [128]  extracted multimodal features using VGG-Face  [131]  on faces, openSMILE  [132]  on audio and GloVe embedding  [133]  on texts. Using a multimodal LSTM model, they reported a correlation coefficient of 0.14 on both personalised and generalised protocols. Mallol-Ragolta et al.  [127]  reported correlation coefficients of 0.11 and 0.06 in personalised and generalised protocols, respectively, using openSMILE for extracting audio features and Open-Face  [134]  for extracting video features, followed by a Bidirectional LSTM (BiLSTM) network.\n\nIn addition to verbal and non-verbal features from audio, image and text, Azari et al.  [126]  experimented with a different type of feature: mutual or contagious laughter as a measure of synchrony between the speaker and listener during the interaction. Hinduja et al.  [125]  used facial landmarks and spectrogram as hand-crafted features and CNN output as deep features in a Random Forest (RF) model. Lastly, Lusquino Filho et al.  [130]  leveraged a different type of model -Weightless Artificial Neural Network (WANN)and reported a correlation coefficient of 0.25 on the validation set of the OMG-Empathy dataset.\n\nOther works in empathy detection as regression tasks primarily utilised classical ML models (Appendix Table  B4 ). Kroes et al.  [77]  leveraged a LR model on the Human-VirtualAgent dataset. With the Teacher-Student dataset, Pan et al.  [84]  comprehensively experimented with a wide range of features from audio and video in an AdaBoost model. Their extracted features include mid-level behavioural features -such as facial expression, head pose and eye gaze -and high-level interpretable features, such as video length, frequency of speaker switch and total number of words. Such feature extraction often yields good results but may require substantial computational resources and careful tuning to optimise the model.",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "Classification Task (Level Of Empathy)",
      "text": "In classifying empathy levels, no studies used any common benchmark dataset (Appendix Table  B4 ). On the DAIC-WOZ dataset, Tavabi et al.  [57]  leveraged pre-trained BERT to calculate text embedding and pre-trained Residual Network (ResNet) to calculate visual features in addition to action units and head pose features from OpenFace. As audio features, they extracted the extended Geneva minimalistic acoustic parameter set and Mel-Frequency Cepstral Coefficients (MFCC)  [135]  using OpenSMILE. With these features, they experimented with GRU and MLP in different fusion techniques, where GRU-based fusion of temporal audio and video sequences appeared to be the best fusion strategy in their setting, resulting an F1 score of 71%. Their ablation experiment shows that text modality is more effective than video and audio modalities: text alone resulted in an F1 score of 64%, whereas the video and audio individually provided F1 scores of 46% and 38%, respectively.\n\nOn the MEDIC dataset  [55] , the best result is achieved using SWAFN, a multimodal LSTM network proposed by Chen and Li  [136] . The network uses three individual LSTMs to encode video, audio and textual modalities, followed by a novel aggregation strategy using a multi-task learning framework. Among the three mechanisms of the MEDIC dataset, the client's expression of experience was better classified than the counsellor's empathy  [55] , which supports the difficult nature of empathy detection compared to expression (i.e., emotion) recognition.",
      "page_start": 13,
      "page_end": 14
    },
    {
      "section_name": "Audio Signals",
      "text": "Audio-based empathy detection works include audio from conversations in various contexts, such as healthcare and call centres. By audio-based empathy detection studies, we refer to studies that exclusively leverage audio and sometimes transcripts, which differ from multimodal audiovisual studies presented earlier.\n\nProcessing audio includes two primary approaches: directly utilising audio as a signal or converting it into text and employing text-based methods. As shown in Appendix Table  B5 , none of the audio datasets are used across multiple studies to allow comparative analysis on model performance.\n\nGiven that audio-based datasets involve conversations between two persons, the works of Chen et al.  [72]  and Xiao et al.  [70]  include voice activity detection ('speech' or 'no speech') and speaker diarisation (i.e., speaker separation) in their empathy detection workflow. Xiao et al.  [70] , Chen et al.  [72] , and Alam et al.  [74]  converted the audio into text sequences, followed by extracting features from the text sequences. Chen et al.  [72]  and Alam et al.  [74]  extracted several lexical features, such as text embedding, from the audio transcripts and several acoustic features, such as MFCC, from the audio signal. Chen et al.  [72]  reported better performance of lexical features than acoustic features. Lastly, Xiao et al.  [70] 's empathy detection model on audio-based CTT dataset is entirely text-based -leveraging uni-gram, bigram and tri-gram language models -without audio-based features.\n\nOn the recent MultimodalMI dataset, Tavabi et al.  [53]  used a distilled RoBERTa pre-trained language model, a bidirectional GRU layer followed by a two-head selfattention layer to predict a continuous empathy score between 0 and 1 (regression task). Using the same dataset, Tran et al.  [54]  proposes a multimodal empathy classification system utilising both audio and text transcripts to predict high vs low empathy. Features from the audio and texts are extracted using Hidden-Unit BERT (HuBERT)  [137]  and distilled RoBERTa pre-trained models, respectively. The features are then passed through a bidirectional GRU model, followed by modality fusion. They experimented with early and late fusion through MLP layers. A wide range of experiments supports the effectiveness of late fusion in most experimental conditions, early fusion in some cases and text-only prediction in very few cases.",
      "page_start": 13,
      "page_end": 14
    },
    {
      "section_name": "Physiological Signals",
      "text": "Research in physiological signal-based empathy detection typically adopts feature extraction, followed by ML algorithms. Appendix Table  B6  reports the studies and methods of physiological signal-based empathy detection. No datasets are used across multiple studies.\n\nWith the PainEmp dataset, Golbabaei et al.  [82]  extracted ten features and leveraged an SVM with radial basis function kernel to detect cognitive and affective empathy. Lastly, Kuijt and Alimardani  [81]  extracted 15 features from the EEG data and leveraged multiple LR in the regression task and LR, SVM and Decision Tree (DT) in the classification task. In the classification task, they only used five bestperforming features. In both regression and classification settings, the participants' empathy before the experiment is better detected than 'after' and 'during' the experiment.",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "Discussion: Findings, Challenges And Research Gaps",
      "text": "",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "Lack Of Benchmarking",
      "text": "Benchmarking and comparative analysis of empathy detection models are hindered by a lack of common benchmark dataset usage, particularly in the domains of audio and physiological signals. Code availability further impacts benchmarking and the broader adoption of methodologies, as minute details of proposed algorithms are often not fully captured in the papers. Among 77 text-based empathy detection models (treating each dataset-specific implementation as a separate model), only 29 have shared their code. Similarly, for audiovisual, audio signal, and physiological signal-based models, the proportion of publicly accessible code is even lower, with only 7 out of 17, 2 out of 7, and none out of 4 releasing their implementations. Mandating the publication of code alongside research findings can ensure transparency and facilitate progress in the field.\n\nA variety of evaluation metrics have been employed in the literature for empathy detection. For regression tasks predicting a continuous degree of empathy, metrics such as Pearson's correlation, Spearman's correlation, concordance, mean squared error, and R 2 are commonly used. In classification tasks predicting discrete empathy levels, metrics include accuracy, F1 score, Area Under the receiver operating characteristics Curve (AUC), average precision, unweighted average recall, and the Matthews correlation coefficient. However, inconsistent use of these metrics across studies can complicate cross-study comparisons. For instance, despite both using the iEmpathize dataset, the metrics reported in  [36]  and  [122]  differ. While it is unreasonable to expect universal adoption of a single metric, efforts toward greater standardisation in evaluation frameworks and metric reporting would enhance comparability.",
      "page_start": 14,
      "page_end": 15
    },
    {
      "section_name": "Multimodal Empathy Detection",
      "text": "The growth of empathy detection modalities, as illustrated in Figure  2 , shows a dominant rising trend in text-based empathy detection since 2020. However, the current body of research lacks equivalent development in audiovisual, audio, and physiological signals. Empathy detection systems based on these modalities can be particularly effective in scenarios where such signals are available and potentially provide a more comprehensive measure of empathy. While spoken information from video and audio can be converted to text for text-based empathy detection, video and audio contain additional information such as facial expressions and pitch. These elements can significantly enhance the accuracy and quality of empathy detection, which necessitates dedicated research in these areas.\n\nA multimodal empathy detection system can effectively integrate these different types of data. Additionally, analysing the contributions of different modalities provides insights into the most important factors for an effective empathy detection system. Few studies  [46] ,  [54] ,  [55] ,  [57] ,  [84]  have shown proof of concept towards multimodal empathy detection. Overall, the multimodal approach holds promise for creating a robust empathy detection system by leveraging the strengths of various input modalities.",
      "page_start": 14,
      "page_end": 14
    },
    {
      "section_name": "Llm In Empathy Detection",
      "text": "The recent success of LLMs presents an opportunity to utilise them in empathy detection tasks. LLMs can serve as the primary prediction model or as a supportive tool to enhance predictions made by conventional models. While LLMs may excel in empathy detection due to their extensive language understanding capabilities, their training and deployment often require substantial resources, which may be impractical for low-resource settings. Smaller optimised models like BERT and RoBERTa can offer reasonable performance with better resource efficiency and may be better suited for certain applications, such as remote areas with limited healthcare access, community counselling centres, education settings in low-income schools, and humanitarian aid and crisis response.\n\nEven when not utilised as the primary prediction model, LLMs can contribute to empathy prediction tasks, particularly in data preprocessing tasks such as text rephrasing  [102]  and empathy annotation  [89] . A recent study  [138]  has shown that LLMs achieve human-level performance in theory of mind tasks. Drawing on the close relationship between cognitive empathy and theory of mind  [24] , this indicates that LLMs possess (or can mimic) empathic skills that could potentially assist in empathy detection.\n\nMultimodal LLMs hold promise for empathy detection in real-life audiovisual interactions, as suggested by Hasan et al.  [139] . This approach capitalises on LLMs' advanced language understanding and multimodal abilities to interpret the nuances of natural conversations across audio, visual and text modalities. The emergence of multimodal LLMs -such as OpenAI's GPT-4o (omni), GPT-4V (vision) and Google's Gemini -enables both zero-shot (i.e., no finetuning) and few-shot (i.e., fine-tuning with a few examples) applications in empathy detection. A recent study on GPT-4V  [140]  assessed its performance on 21 emotion recognition datasets across six tasks, including sentiment analysis, facial emotion recognition and multimodal emotion recognition, all in zero-shot settings. Although GPT-4V demonstrated strong visual processing capabilities, it struggled with micro-expression recognition. Since GPT-4V is designed primarily for general domains, future studies could focus on fine-tuning it in few-shot settings. Nonetheless, this proof of concept for multimodal LLMs in general emotion recognition indicates potential for empathy detection. With the rapid advancement of multimodal LLMs, they are likely to become a stronger candidate for empathy detection in the days to come.",
      "page_start": 14,
      "page_end": 15
    },
    {
      "section_name": "Applications Of Empathy Detection",
      "text": "Empathy detection has the potential to bring transformative changes across various domains, such as healthcare, education and social media, Focusing on a few key domains, this section discusses potential benefits, associated challenges and ethical considerations.",
      "page_start": 14,
      "page_end": 14
    },
    {
      "section_name": "Assessment Of Communication Quality",
      "text": "Empathy detection can be used to evaluate the quality of interpersonal communication, which can be used as feedback to improve interactions. Consider healthcare as an example. A study on patient-doctor interaction found that 85% of 563 patients either changed or were considering changing their doctors due to a lack of effective communication related to empathy being one of the main reasons  [141] ,  [142] . Empathic doctors would be better equipped to communicate medical information in a fashion that the patient will attend to  [3] . Therefore, the service quality of healthcare providers could be assessed in terms of empathy if we could detect empathy in the first place. Assessment of healthcare providers can be in various contexts -such as counselling sessions  [44] ,  [68] -  [70] , oncology encounters  [72] , and other general patient-doctor interactions  [28] ,  [34]  -either through telehealth or in-person. Measurement of empathy can also facilitate effective empathy training programs for healthcare professionals. In the same vein, empathy detection can be applied in educational interactions in teaching, customer service in businesses, and even in human-robot interactions.\n\nEmpathy detection can also improve communication quality in long-distance communication, such as that between international students and their families or during online interviews for jobs or university admissions. Video conferencing applications like Zoom and Microsoft Teams could incorporate live empathy feedback, similar to live transcripts, which is common nowadays. This way, people can see how their words and expressions are perceived in real-time, which may help people adjust their communication to be more empathic and responsive.",
      "page_start": 15,
      "page_end": 16
    },
    {
      "section_name": "Disease Diagnosis",
      "text": "Empathy detection systems can help diagnose diseases and cognitive disorders where a lack of empathy is a symptom, such as autism, psychopathy and alexithymia  [143] . Several studies have shown proof of concepts in this regard, such as diagnosing social communication disorders (Down syndrome, intellectual disability) [76] and autism spectrum disorders  [82] .",
      "page_start": 15,
      "page_end": 15
    },
    {
      "section_name": "Social Media Moderation",
      "text": "People often seek mental support through social media platforms. Accordingly, several works have detected empathy in various social media interactions, such as Reddit  [65] , Twitter  [64] , and cancer survivors networks  [36] ,  [49] ,  [122] . We can envision a peer support platform where nonempathic responses are filtered out through an empathy detection system. This way, social media platforms can foster empathic responses while discouraging non-empathic ones.",
      "page_start": 15,
      "page_end": 15
    },
    {
      "section_name": "Ethical Considerations And Challenges",
      "text": "Visibility of empathy scores might encourage individuals to feign empathy, similar to how fake facial expressions are a concern in emotion detection  [85] . Developing robust methods to differentiate genuine empathy from feigned responses will be crucial to ensure the reliability and effectiveness of empathy detection systems. Continuous feedback on empathic behaviour may also inadvertently create undue pressure on individuals, which may affect their mental health or authenticity in interactions. Safeguards should be in place to mitigate such unintended consequences.\n\nWhat is considered a normal conversation and what is perceived as harsh can vary greatly across cultures. Ensuring fairness, therefore, becomes a significant challenge. Systems may inherit biases from training data that predominantly represent a specific demographic, resulting in unfair or inaccurate assessments towards other demographic or cultural groups. Addressing these biases is essential to ensure fairness and inclusivity. Before deploying an empathy detection system, it is imperative to rigorously evaluate the generalisability of the system across diverse populations. Apart from these, other ethical considerations and challenges, such as data privacy and consent, commonly associated with general Affective Computing tasks, must also be carefully addressed to ensure the responsible and ethical deployment of empathy detection systems.",
      "page_start": 15,
      "page_end": 15
    },
    {
      "section_name": "Conclusion",
      "text": "Empathy, an involuntary and vicarious reaction to emotional signals from another individual or their circumstances  [1] , has emerged as a promising research area across several disciplines. Empathy detection in Computer Science, particularly through ML methodologies, has grown substantially in recent years. This paper presents a rigorous, systematic literature review following relevant Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) guidelines for reproducibility. Starting with an extensive search across ten scholarly databases, we select 82 papers after a thorough screening process, including abstract and full-text screening based on exclusion criteria. We discuss and group similar papers based on task formulations and ML methodologies. We present a task formulation hierarchy with representative datasets and their details, such as data collection, experiment details, statistics, annotation protocol and public availability. To describe ML methodologies, we group our findings based on four input modalities: text sequences, audiovisual data, audio signals and physiological signals. In each modality, we enumerate the algorithms used, their performance and code availability.\n\nThis review uncovers several new insights into the computational empathy domain and identifies critical avenues for future research and development. Exploring novel task formulations such as parallel and bidirectional empathy, particularly in group settings and global-level measurements, can advance our understanding of empathy in complex social interactions. Further research comparing selfannotation and third-party annotation under controlled conditions is necessary to determine the most appropriate annotation scheme for empathy detection. The limited public availability of datasets and codes poses significant challenges for reproducibility and benchmarking in the field. At the same time, the diversity and lack of standardisation in evaluation metrics complicate consistent model comparison. Physiological signals offer promising avenues for more accurate empathy detection. Finally, the potential of LLMs and multimodal approaches to enhance empathy detection systems presents exciting opportunities for future research.\n\nStudies we review in this paper operationalise the term 'empathy' in varying ways. For example, some define empathy purely in cognitive dimension, such as understanding another's perspective or capacity to comprehend  [30] , and some further integrate behavioural or prosocial dimensions, such as offering emotional support  [34] . Future reviews may adopt a more critical lens to distinguish studies according to how they operationalise empathy.",
      "page_start": 15,
      "page_end": 16
    },
    {
      "section_name": "Acknowledgement",
      "text": "We thank A/Professor Susannah Soon at Curtin University for her comments on the initial version of this paper.",
      "page_start": 16,
      "page_end": 16
    },
    {
      "section_name": "List Of Acronyms",
      "text": "",
      "page_start": 16,
      "page_end": 16
    },
    {
      "section_name": "Appendix A Paper Selection",
      "text": "The systematic nature of this review ensures reproducibility and transparency in the selection and analysis of relevant papers. We adhered to the relevant recommendations from the PRISMA 2020 guidelines  [16]  as well as published systematic reviews in Affective Computing  [144] -  [149] . For example, our paper selection process considered the following inclusion and exclusion criteria. We included papers from 2013 onward to capture the period when ML, and particularly DL, became widely feasible. Key developments, such as the first modern CNN (AlexNet) in 2012  [150]  and optimisation algorithms like Adam  [151]  in 2014-2015, led DL's success on a variety of tasks  [152] ,  [153] . Our systematic search validated this time frame, as we found no relevant empathy detection studies published in 2013 or 2014.",
      "page_start": 16,
      "page_end": 16
    },
    {
      "section_name": "A.1 Paper Search",
      "text": "We formulate a search string using logical operators (AND and OR) among synonymous terms of empathy, detection and artificial intelligence: empath* AND (detect* OR recog*) AND (\"deep learning\" OR \"machine learning\" OR \"artificial intelligence\" OR AI). The asterisk (*) is a wildcard character that facilitates the inclusion of any number of characters in place of the asterisk.\n\nWith the search string, one researcher (MRH) searched for relevant records across ten databases (see Table  8  for more details) on 24 February 2023. Among the search engines, ACL Anthology does not support logical search. We, therefore, built a program 5 to search in the ACL database using the available bibliography document. Several search engines, such as Scopus and Web of Science, support filtering based on publication year (IC!3) and paper type (EC1 and EC3), so we automatically filtered out the search results. Table  8  presents the number of search results, search condition (e.g., title, abstract, full-paper, etc.), automaticfiltering results and corresponding filtering criteria.",
      "page_start": 16,
      "page_end": 16
    },
    {
      "section_name": "A.2 Paper Screening",
      "text": "Figure  5  illustrates our step-by-step paper screening strategy. We initially gathered 801 records from the databases. After removing duplicated and retracted records, one researcher (MRH) screened the remaining 434 records by reading titles and abstracts using the Covidence systematic review management software  [154] . At this stage, records were excluded only if they clearly met one or more Exclusion Criteria (EC). Records that could not be conclusively evaluated based on the title and abstract proceeded to the full-text screening stage. At this stage, three researchers (MRH, MZH and SG) screened the 86 remaining records. Some records were deemed ambiguous for inclusion or exclusion, and these were discussed among all researchers in regular weekly meetings during the full-text screening period until a consensus was reached. For instance, while Hossain and Rahman  [155]  and Hinduja  [156]  initially appeared to meet the inclusion criteria, further examination revealed that Hossain and Rahman  [155]  perform sentiment analysis on how people react toward online reviews, and Hinduja  [156]  analyses potential biases in empathy detection without detecting any types of empathy. We screened another 27 recent papers, which we received through notifications and 'snowballing'. Several Overall, the selection and analysis of papers were systematic and transparent, involving automated searches across multiple databases, clearly defined inclusion and exclusion criteria, and collaborative decision-making. This definitive and collaborative approach minimised the likelihood of individual bias. However, potential biases may still arise from limitations in the selected databases, which might not capture all relevant studies, as well as from the interpretation of ambiguous records by the researchers.",
      "page_start": 17,
      "page_end": 17
    },
    {
      "section_name": "Appendix B Modality-Specific Empathy Detection Meth-",
      "text": "",
      "page_start": 17,
      "page_end": 17
    },
    {
      "section_name": "Ods",
      "text": "This section lists studies based on datasets that have each been used in only one published work to date.",
      "page_start": 17,
      "page_end": 17
    },
    {
      "section_name": "B.1 Text Sequence",
      "text": "",
      "page_start": 17,
      "page_end": 17
    },
    {
      "section_name": "B.1.1 Regression Task (Degree Of Empathy)",
      "text": "On continuous degrees of empathy detection on text datasets (Table  9 ), works include therapists' empathy detection on MI dataset  [68]  and pathogenic empathy detection on social media  [83] . Both of them leveraged classical ML methods: LR and Ridge Regression (RR). Classical MLs",
      "page_start": 18,
      "page_end": 18
    },
    {
      "section_name": "Methods",
      "text": "",
      "page_start": 18,
      "page_end": 18
    },
    {
      "section_name": "Eligibility Criteria 5",
      "text": "Specify the inclusion and exclusion criteria for the review and how studies were grouped for the syntheses.\n\nAppendices & Section 3\n\nInformation sources 6 Specify all databases, registers, websites, organisations, reference lists and other sources searched or consulted to identify studies. Specify the date when each source was last searched or consulted.",
      "page_start": 19,
      "page_end": 19
    },
    {
      "section_name": "Appendices",
      "text": "Search strategy 7 Present the full search strategies for all databases, registers and websites, including any filters and limits used.",
      "page_start": 20,
      "page_end": 20
    },
    {
      "section_name": "Appendices",
      "text": "Selection process 8 Specify the methods used to decide whether a study met the inclusion criteria of the review, including how many reviewers screened each record and each report retrieved, whether they worked independently, and if applicable, details of automation tools used in the process.",
      "page_start": 21,
      "page_end": 21
    },
    {
      "section_name": "Appendices",
      "text": "Data collection process 9 Specify the methods used to collect data from reports, including how many reviewers collected data from each report, whether they worked independently, any processes for obtaining or confirming data from study investigators, and if applicable, details of automation tools used in the process.",
      "page_start": 22,
      "page_end": 22
    },
    {
      "section_name": "Appendices 10A",
      "text": "List and define all outcomes for which data were sought. Specify whether all results that were compatible with each outcome domain in each study were sought (e.g. for all measures, time points, analyses), and if not, the methods used to decide which results to collect.",
      "page_start": 19,
      "page_end": 19
    },
    {
      "section_name": "Sections 3 & 4",
      "text": "",
      "page_start": 19,
      "page_end": 19
    },
    {
      "section_name": "Data Items 10B",
      "text": "List and define all other variables for which data were sought (e.g. participant and intervention characteristics, funding sources). Describe any assumptions made about any missing or unclear information.",
      "page_start": 19,
      "page_end": 19
    },
    {
      "section_name": "Sections 3",
      "text": "Study risk of bias assessment 11 Specify the methods used to assess risk of bias in the included studies, including details of the tool(s) used, how many reviewers assessed each study and whether they worked independently, and if applicable, details of automation tools used in the process.",
      "page_start": 20,
      "page_end": 20
    },
    {
      "section_name": "Appendices",
      "text": "Effect measures 12 Specify for each outcome the effect measure(s) (e.g. risk ratio, mean difference) used in the synthesis or presentation of results.",
      "page_start": 21,
      "page_end": 21
    },
    {
      "section_name": "Sections 3 & 4 13A",
      "text": "Describe the processes used to decide which studies were eligible for each synthesis (e.g. tabulating the study intervention characteristics and comparing against the planned groups for each synthesis (item #5)).",
      "page_start": 19,
      "page_end": 19
    },
    {
      "section_name": "Appendices 13B",
      "text": "Describe any methods required to prepare the data for presentation or synthesis, such as handling of missing summary statistics, or data conversions.",
      "page_start": 19,
      "page_end": 19
    },
    {
      "section_name": "Sections 3 & 4 13C",
      "text": "Describe any methods used to tabulate or visually display results of individual studies and syntheses.",
      "page_start": 19,
      "page_end": 19
    },
    {
      "section_name": "Sections 3 & 4 13D",
      "text": "Describe any methods used to synthesize results and provide a rationale for the choice(s). If meta-analysis was performed, describe the model(s), method(s) to identify the presence and extent of statistical heterogeneity, and software package(s) used.",
      "page_start": 19,
      "page_end": 19
    },
    {
      "section_name": "Sections 3 & 4 13E",
      "text": "Describe any methods used to explore possible causes of heterogeneity among study results (e.g. subgroup analysis, meta-regression).",
      "page_start": 19,
      "page_end": 19
    },
    {
      "section_name": "Sections 3 & 4",
      "text": "Synthesis methods 13f Describe any sensitivity analyses conducted to assess robustness of the synthesized results.",
      "page_start": 20,
      "page_end": 20
    },
    {
      "section_name": "Not Applicable",
      "text": "Reporting bias assessment 14 Describe any methods used to assess risk of bias due to missing results in a synthesis (arising from reporting biases).",
      "page_start": 21,
      "page_end": 21
    },
    {
      "section_name": "Appendices",
      "text": "Certainty assessment 15 Describe any methods used to assess certainty (or confidence) in the body of evidence for an outcome.",
      "page_start": 22,
      "page_end": 22
    },
    {
      "section_name": "Sections 3 & 4",
      "text": "",
      "page_start": 22,
      "page_end": 22
    },
    {
      "section_name": "Results",
      "text": "16a Describe the results of the search and selection process, from the number of records identified in the search to the number of studies included in the review, ideally using a flow diagram.",
      "page_start": 23,
      "page_end": 23
    },
    {
      "section_name": "Appendices",
      "text": "",
      "page_start": 23,
      "page_end": 23
    },
    {
      "section_name": "Study Selection 16B",
      "text": "Cite studies that might appear to meet the inclusion criteria, but which were excluded, and explain why they were excluded.",
      "page_start": 19,
      "page_end": 19
    },
    {
      "section_name": "Appendices Study Characteristics 17",
      "text": "Cite each included study and present its characteristics.",
      "page_start": 19,
      "page_end": 19
    },
    {
      "section_name": "Sections 3 & 4",
      "text": "Risk of bias in studies 18 Present assessments of risk of bias for each included study.",
      "page_start": 20,
      "page_end": 20
    },
    {
      "section_name": "Not Applicable",
      "text": "",
      "page_start": 20,
      "page_end": 20
    },
    {
      "section_name": "Results Of Individual Studies 19",
      "text": "For all outcomes, present, for each study: (a) summary statistics for each group (where appropriate) and (b) an effect estimate and its precision (e.g. confidence/credible interval), ideally using structured tables or plots.",
      "page_start": 19,
      "page_end": 19
    },
    {
      "section_name": "Sections 3 & 4 20A",
      "text": "For each synthesis, briefly summarise the characteristics and risk of bias among contributing studies.",
      "page_start": 19,
      "page_end": 19
    },
    {
      "section_name": "Sections 3 & 4 20B",
      "text": "Present results of all statistical syntheses conducted. If meta-analysis was done, present for each the summary estimate and its precision (e.g. confidence/credible interval) and measures of statistical heterogeneity. If comparing groups, describe the direction of the effect.",
      "page_start": 19,
      "page_end": 19
    },
    {
      "section_name": "Other Information 24A",
      "text": "Provide registration information for the review, including register name and registration number, or state that the review was not registered.",
      "page_start": 19,
      "page_end": 19
    },
    {
      "section_name": "Not Applicable 24B",
      "text": "Indicate where the review protocol can be accessed, or state that a protocol was not prepared.",
      "page_start": 19,
      "page_end": 19
    },
    {
      "section_name": "Not Applicable",
      "text": "Registration and protocol 24c Describe and explain any amendments to information provided at registration or in the protocol.\n\nNot applicable Support 25 Describe sources of financial or non-financial support for the review, and the role of the funders or sponsors in the review.",
      "page_start": 20,
      "page_end": 20
    },
    {
      "section_name": "Article Submission System",
      "text": "Competing interests 26 Declare any competing interests of review authors.",
      "page_start": 21,
      "page_end": 21
    },
    {
      "section_name": "Article Submission System",
      "text": "Availability of data, code and other materials 27 Report which of the following are publicly available and where they can be found: template data collection forms; data extracted from included studies; data used for all analyses; analytic code; any other materials used in the review.",
      "page_start": 22,
      "page_end": 22
    },
    {
      "section_name": "Appendices",
      "text": "From:\n\nNaïve Bayes (NB) on MedicalCare dataset, yielding an F1 score of 78.4%. In MedicalCare v2 dataset, Dey Girju  [34]  experimented with BERT, RoBERTa, SVM, NB, Logistic Regression (LogR), LSTM and BiLSTM models and reported an F1 score of 85%. Similar experiments are also conducted with the MedicalCare v3 dataset  [29] . Both experiments reveal the superior performance of BERT-based models. Incorporation of FrameNet pre-trained model  [159]  boosted the baseline performance in the v2 dataset  [34] . In the v3 dataset  [29] , various linguistic constructions -such as active or passive voice, static or energetic tone -enhanced binary empathy classification performance compared to the baseline BERT model. Lee and Parde  [67]  experimented with two classical ML algorithms (NB and LogR) and four pre-trained language model (including BERT, RoBERTa and Distilled BERT (DistilBERT)) on the AcnEmpathize dataset. Among these, DistilBERT resulted in the best overall accuracy of 89.3%, while the accuracy of BERT and RoBERTa was also close: 89.1% and 88.5%, respectively. Due to the unbalanced nature of the dataset, the authors also reported class-wise precision, recall and F1 scores. Although NB provided better precision in the empathy class and better recall in the noempathy class, it underperforms the BERT-based models in the precision and F1 scores. The best F1 scores of 77.4% in the empathy class and 93.1% in the no empathy class are achieved by RoBERTa and DistilBERT, respectively.\n\nOn the LeadEmpathy dataset, Sedefoglu et al.  [45]  employed SVM for binary classification and BERT for a 10-class classification task. The 10-class F1 score was notably lower at 45.7%, reflecting the challenge of fine-grained empathy classification compared to the more straightforward binary classification, which achieved a higher F1 score of 81.7%.\n\nInstead of language models, several studies leveraged traditional DL models like LSTM and CNN. Gibson et al.  [68]  reported NB as the optimal model in MI dataset. In a later study, Gibson et al.  [69]  reported that a combination of MLP and LSTM are the optimal model in the closely related MI v2 dataset, yielding a higher unweighted average recall from 75.3% to 79.6%. Khanpour et al.  [49]  used a combination of CNN and LSTM on the LungBreastCSN dataset. Other than commonly known models, Montiel-Vázquez et al.  [27]  reported Pattern-Based Classifier for Class Imbalance Problems (PBC4cip) -exclusively designed for imbalanced datasets -as the most effective classifier compared to several classical ML baselines on EmpathicDialogues v2 dataset.\n\nHosseini and Caragea  [64] ,  [66]  used knowledge distillation, which refers to the process of transferring knowledge from a large, complex model (teacher) to a smaller, simpler model (student) to improve the latter's performance while maintaining efficiency. Hosseini and Caragea  [66]  used EPITOME v2 as an in-domain dataset and NewsEssay as an out-of-domain dataset to transfer knowledge from a RoBERTa teacher model to a RoBERTa student model. Their knowledge distillation framework boosted the performance compared to BERT and RoBERTa baselines. In their study, the NewsEssay dataset was used in a binary classification setting instead of the dataset's default usage as a regression task. Such a binary classification setup is also utilised by Shi et al.  [28]  and Hosseini and Caragea  [64]  using SVM and BERT-MLP models, respectively.",
      "page_start": 23,
      "page_end": 23
    },
    {
      "section_name": "B.2 Audiovisual Content",
      "text": "As presented in Table  11 , most studies leveraged a variety of classical ML algorithms. For example, Mathur et al.  [75]  experimented with eight classical ML and two DL models and reported XGBoost as the best model on the Human-Robot dataset.",
      "page_start": 24,
      "page_end": 24
    },
    {
      "section_name": "B.3 Audio Signals",
      "text": "Most of the studies on audio datasets (Table  12 ) reported classical ML algorithms as the best in corresponding experiments: SVM in empathy classification on the CTT  [70] , COPE  [72]  and CallCentre  [74]  datasets and LR in the regression study on the CTT dataset by Xiao et al.  [70] .",
      "page_start": 25,
      "page_end": 25
    },
    {
      "section_name": "B.4 Physiological Signals",
      "text": "All empathy detection studies on physiological signals (Table 13) leveraged classical ML algorithms: LR and SVM, each in two studies.",
      "page_start": 20,
      "page_end": 20
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Hierarchy of empathy detection task formulations and represen-",
      "page": 1
    },
    {
      "caption": "Figure 2: Growth of ML-based empathy detection literature from 2013 to",
      "page": 2
    },
    {
      "caption": "Figure 2: , the distribution of papers reveals a predominant",
      "page": 2
    },
    {
      "caption": "Figure 1: ) and analyse ML",
      "page": 2
    },
    {
      "caption": "Figure 1: ), there is a",
      "page": 9
    },
    {
      "caption": "Figure 3: illustrates the usage of algorithms in text-based",
      "page": 10
    },
    {
      "caption": "Figure 3: Usage of ML algorithms in text-based empathy detection studies,",
      "page": 11
    },
    {
      "caption": "Figure 4: illustrates the application of algorithms in audiovisual-",
      "page": 12
    },
    {
      "caption": "Figure 4: Usage of ML algorithms in audiovisual dataset-based empathy",
      "page": 12
    },
    {
      "caption": "Figure 2: , shows a dominant rising trend in text-based",
      "page": 14
    },
    {
      "caption": "Figure 5: Number of records at different stages in our screening process.",
      "page": 17
    },
    {
      "caption": "Figure 5: illustrates our step-by-step paper screening strat-",
      "page": 17
    },
    {
      "caption": "Figure 5: presents the completed PRISMA 2020 checklist [16].",
      "page": 20
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Global Measurement": "",
          "Column_2": "Social Media",
          "Column_3": ""
        },
        {
          "Global Measurement": "",
          "Column_2": "Patient-Doctor",
          "Column_3": ""
        },
        {
          "Global Measurement": "",
          "Column_2": "General\nConversation",
          "Column_3": ""
        },
        {
          "Global Measurement": "",
          "Column_2": "Interaction with\nNon-Human Entity",
          "Column_3": ""
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "NewsEssay, FacebookReview, fMRI": "iEmpathize, LungBreastCSN,\nRolePlayMI, PEC, EmpathicDialogues"
        },
        {
          "NewsEssay, FacebookReview, fMRI": "MultimodalMI, MEDIC, OTLA"
        },
        {
          "NewsEssay, FacebookReview, fMRI": "EmpathicExchanges"
        },
        {
          "NewsEssay, FacebookReview, fMRI": "DAIC-WOZ"
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Patient-Doctor\nInteraction": "General\nConversation"
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "MI, CTT, COPE": "EmpathicDialogues v2, CallCentre"
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Global Bidirectional Empathy": "Global Parallel Empathy"
        },
        {
          "Global Bidirectional Empathy": "Localised Emotional\nContagion"
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "EmpathicStories": "NewsConvD"
        },
        {
          "EmpathicStories": "OMG-Empathy"
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Text\nAudiovisual\n2\nAudio\nPhysiologicalSignals 1 2\n2\n1\n1\n12\n10\n9\n7 1\n1 1\n1 1 1\n2\n1 1 1 1": "",
          "1": "1",
          "1\n4": ""
        },
        {
          "Text\nAudiovisual\n2\nAudio\nPhysiologicalSignals 1 2\n2\n1\n1\n12\n10\n9\n7 1\n1 1\n1 1 1\n2\n1 1 1 1": "",
          "1": "16",
          "1\n4": ""
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "2": "2"
        },
        {
          "2": "12"
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "1": "2"
        },
        {
          "1": "10"
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "1": "1"
        },
        {
          "1": "9"
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "1": "4"
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "1": "1"
        },
        {
          "1": "1"
        },
        {
          "1": "1"
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "1": "1"
        },
        {
          "1": "1"
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "1": "1"
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "erehwnoitacoL detropersimeti": "metitsilkcehC",
          "Column_2": "ELTIT"
        },
        {
          "erehwnoitacoL detropersimeti": "metI\n#",
          "Column_2": ""
        },
        {
          "erehwnoitacoL detropersimeti": "cipoTdnanoitceS",
          "Column_2": ""
        }
      ],
      "page": 19
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "TCARTSBA"
        }
      ],
      "page": 19
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "NOITCUDORTNI"
        }
      ],
      "page": 19
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "SDOHTEM"
        }
      ],
      "page": 19
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "STLUSER"
        }
      ],
      "page": 19
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "NOISSUCSID"
        }
      ],
      "page": 19
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "NOITAMROFNIREHTO"
        }
      ],
      "page": 19
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Toward a theory of empathic arousal and development",
      "authors": [
        "M Hoffman"
      ],
      "year": "1978",
      "venue": "The Development of Affect",
      "doi": "10.1007/978-1-4684-2616-8_9"
    },
    {
      "citation_id": "2",
      "title": "The role of cognitive and affective empathy in spouses' support interactions: An observational study",
      "authors": [
        "L Verhofstadt",
        "I Devoldre",
        "A Buysse"
      ],
      "year": "2016",
      "venue": "PloS one",
      "doi": "10.1371/journal.pone.0149944"
    },
    {
      "citation_id": "3",
      "title": "The role of empathy in therapy and the physician-patient relationship",
      "authors": [
        "B Jani",
        "D Blane",
        "S Mercer"
      ],
      "year": "2012",
      "venue": "Complementary Medicine Research",
      "doi": "10.1159/000342998"
    },
    {
      "citation_id": "4",
      "title": "Is empathy the key to effective teaching? a systematic review of its association with teacher-student interactions and student outcomes",
      "authors": [
        "K Aldrup",
        "B Carstensen",
        "U Klusmann"
      ],
      "year": "2022",
      "venue": "Educational Psychology Review",
      "doi": "10.1007/s10648-021-09649-y"
    },
    {
      "citation_id": "5",
      "title": "Empathy and Moral Development: Implications for Caring and Justice",
      "authors": [
        "M Hoffman"
      ],
      "year": "2000",
      "venue": "Empathy and Moral Development: Implications for Caring and Justice",
      "doi": "10.1017/CBO9780511805851"
    },
    {
      "citation_id": "6",
      "title": "The origins and social significance of empathy-related responding. a review of empathy and moral development: Implications for caring and justice by",
      "authors": [
        "N Eisenberg",
        "A Morris",
        "M Hoffman"
      ],
      "year": "2001",
      "venue": "Social Justice Research",
      "doi": "10.1023/A:1012579805721"
    },
    {
      "citation_id": "7",
      "title": "Empathy present and future",
      "authors": [
        "J Hall",
        "R Schwartz"
      ],
      "year": "2019",
      "venue": "The Journal of social psychology",
      "doi": "10.1080/00224545.2018.1477442"
    },
    {
      "citation_id": "8",
      "title": "Empathy in virtual agents and robots: A survey",
      "authors": [
        "A Paiva",
        "I Leite",
        "H Boukricha",
        "I Wachsmuth"
      ],
      "year": "2017",
      "venue": "ACM Transactions on Interactive Intelligent Systems (TiiS)",
      "doi": "10.1145/2912150"
    },
    {
      "citation_id": "9",
      "title": "Automatic analysis of facial affect: A survey of registration, representation, and recognition",
      "authors": [
        "E Sariyanidi",
        "H Gunes",
        "A Cavallaro"
      ],
      "year": "2015",
      "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
      "doi": "10.1109/TPAMI.2014.2366127"
    },
    {
      "citation_id": "10",
      "title": "Automatic emotion recognition for groups: A review",
      "authors": [
        "E Veltmeijer",
        "C Gerritsen",
        "K Hindriks"
      ],
      "year": "2023",
      "venue": "IEEE Transactions on Affective Computing",
      "doi": "10.1109/TAFFC.2021.3065726"
    },
    {
      "citation_id": "11",
      "title": "A computational model of empathy interactive agents",
      "authors": [
        "Ö Yalcin",
        "S Dipaola"
      ],
      "year": "2018",
      "venue": "Biologically inspired cognitive architectures",
      "doi": "10.1016/j.bica.2018.07.010"
    },
    {
      "citation_id": "12",
      "title": "Empathy in human-robot interaction: Designing for social robots",
      "authors": [
        "S Park",
        "M Whang"
      ],
      "year": "2022",
      "venue": "International journal of environmental research and public health",
      "doi": "10.3390/ijerph19031889"
    },
    {
      "citation_id": "13",
      "title": "Empathetic conversational systems: A review of current advances, gaps, and opportunities",
      "authors": [
        "A Raamkumar",
        "Y Yang"
      ],
      "year": "2022",
      "venue": "IEEE Transactions on Affective Computing",
      "doi": "10.1109/TAFFC.2022.3226693"
    },
    {
      "citation_id": "14",
      "title": "A critical reflection and forward perspective on empathy and natural language processing",
      "authors": [
        "A Lahnala",
        "C Welch",
        "D Jurgens",
        "L Flek"
      ],
      "year": "2022",
      "venue": "Findings of the Association for Computational Linguistics: EMNLP 2022",
      "doi": "10.18653/v1/2022.findings-emnlp.157"
    },
    {
      "citation_id": "15",
      "title": "A scoping review of empathy recognition in text using natural language processing",
      "authors": [
        "V Shetty",
        "S Durbin",
        "M Weyrich",
        "A Martínez",
        "J Qian",
        "D Chin"
      ],
      "year": "2023",
      "venue": "Journal of the American Medical Informatics Association",
      "doi": "10.1093/jamia/ocad229"
    },
    {
      "citation_id": "16",
      "title": "The PRISMA 2020 statement: An updated guideline for reporting systematic reviews",
      "authors": [
        "M Page",
        "J Mckenzie",
        "P Bossuyt"
      ],
      "year": "2021",
      "venue": "BMJ",
      "doi": "10.1136/bmj.n71"
    },
    {
      "citation_id": "17",
      "title": "Empathy: A review of the concept",
      "authors": [
        "B Cuff",
        "S Brown",
        "L Taylor",
        "D Howat"
      ],
      "year": "2016",
      "venue": "Emotion Review",
      "doi": "10.1177/1754073914558466"
    },
    {
      "citation_id": "18",
      "title": "Emotional intelligence",
      "authors": [
        "D Goleman"
      ],
      "year": "2020",
      "venue": "Emotional intelligence"
    },
    {
      "citation_id": "19",
      "title": "A multidimensional approach to individual differences in empathy",
      "authors": [
        "M Davis"
      ],
      "year": "1980",
      "venue": "JSAS Catalog of Selected Documents in Psychology"
    },
    {
      "citation_id": "20",
      "title": "Distress and empathy: Two qualitatively distinct vicarious emotions with different motivational consequences",
      "authors": [
        "C Batson",
        "J Fultz",
        "P Schoenrade"
      ],
      "year": "1987",
      "venue": "Journal of Personality",
      "doi": "10.1111/j.1467-6494.1987.tb00426.x"
    },
    {
      "citation_id": "21",
      "title": "Empathy: Its ultimate and proximate bases",
      "authors": [
        "S Preston",
        "F De Waal"
      ],
      "year": "2002",
      "venue": "Behavioral and Brain Sciences",
      "doi": "10.1017/S0140525X02000018"
    },
    {
      "citation_id": "22",
      "title": "Everyday mind reading: Understanding what other people think and feel",
      "authors": [
        "W Ickes"
      ],
      "year": "2003",
      "venue": "Everyday mind reading: Understanding what other people think and feel"
    },
    {
      "citation_id": "23",
      "title": "Some forms of sympathy: A phenomenological analysis",
      "authors": [
        "H Becker"
      ],
      "year": "1931",
      "venue": "The Journal of Abnormal and Social Psychology",
      "doi": "10.1037/h0072609"
    },
    {
      "citation_id": "24",
      "title": "Responding to the emotions of others: Dissociating forms of empathy through the study of typical and psychiatric populations",
      "authors": [
        "R Blair"
      ],
      "year": "2005",
      "venue": "Consciousness and cognition",
      "doi": "10.1016/j.concog.2005.06.004"
    },
    {
      "citation_id": "25",
      "title": "I feel how you feel but not always: The empathic brain and its modulation",
      "authors": [
        "G Hein",
        "T Singer"
      ],
      "year": "2008",
      "venue": "Current Opinion in Neurobiology",
      "doi": "10.1016/j.conb.2008.07.012"
    },
    {
      "citation_id": "26",
      "title": "Neurodevelopmental changes in the circuits underlying empathy and sympathy from childhood to adulthood",
      "authors": [
        "J Decety",
        "K Michalska"
      ],
      "year": "2010",
      "venue": "Developmental Science",
      "doi": "10.1111/j.1467-7687.2009.00940.x"
    },
    {
      "citation_id": "27",
      "title": "An explainable artificial intelligence approach for detecting empathy in textual communication",
      "authors": [
        "E Montiel-Vázquez",
        "J Ramírez Uresti",
        "O Loyola-González"
      ],
      "year": "2022",
      "venue": "Applied Sciences",
      "doi": "10.3390/app12199407"
    },
    {
      "citation_id": "28",
      "title": "Modeling clinical empathy in narrative essays",
      "authors": [
        "S Shi",
        "Y Sun",
        "J Zavala",
        "J Moore",
        "R Girju"
      ],
      "year": "2021",
      "venue": "2021 IEEE 15th International Conference on Semantic Computing (ICSC)",
      "doi": "10.1109/ICSC50631.2021.00046"
    },
    {
      "citation_id": "29",
      "title": "Investigating stylistic profiles for the task of empathy classification in medical narrative essays",
      "authors": [
        "P Dey",
        "R Girju ; Cxgs+nlp"
      ],
      "year": "2023",
      "venue": "Proceedings of the First International Workshop on Construction Grammars and NLP"
    },
    {
      "citation_id": "30",
      "title": "Modeling empathy and distress in reaction to news stories",
      "authors": [
        "S Buechel",
        "A Buffone",
        "B Slaff",
        "L Ungar",
        "J Sedoc"
      ],
      "year": "2018",
      "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
      "doi": "10.18653/v1/D18-1507"
    },
    {
      "citation_id": "31",
      "title": "Assessing patient-perceived hospital service quality and sentiment in malaysian public hospitals using machine learning and facebook reviews",
      "authors": [
        "A Rahim",
        "M Ibrahim",
        "K Musa",
        "S.-L Chua",
        "N Yaacob"
      ],
      "year": "2021",
      "venue": "International Journal of Environmental Research and Public Health",
      "doi": "10.3390/ijerph18189912"
    },
    {
      "citation_id": "32",
      "title": "Cognitive empathy and emotional empathy in human behavior and evolution",
      "authors": [
        "A Smith"
      ],
      "year": "2006",
      "venue": "The Psychological Record",
      "doi": "10.1007/BF03395534"
    },
    {
      "citation_id": "33",
      "title": "Cognitive and affective perspective-taking: Evidence for shared and dissociable anatomical substrates",
      "authors": [
        "M Healey",
        "M Grossman"
      ],
      "year": "2018",
      "venue": "Frontiers in neurology",
      "doi": "10.3389/fneur.2018.00491"
    },
    {
      "citation_id": "34",
      "title": "Enriching deep learning with frame semantics for empathy classification in medical narrative essays",
      "authors": [
        "P Dey",
        "R Girju"
      ],
      "year": "2022",
      "venue": "Proceedings of the 13th International Workshop on Health Text Mining and Information Analysis (LOUHI)"
    },
    {
      "citation_id": "35",
      "title": "",
      "authors": [
        "R Picard",
        "Affective Computing"
      ],
      "year": "2000",
      "venue": ""
    },
    {
      "citation_id": "36",
      "title": "It takes two to empathize: One to seek and one to provide",
      "authors": [
        "M Hosseini",
        "C Caragea"
      ],
      "year": "2021",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence",
      "doi": "10.1609/aaai.v35i14.17539"
    },
    {
      "citation_id": "37",
      "title": "Measuring individual differences in empathy: Evidence for a multidimensional approach",
      "authors": [
        "M Davis"
      ],
      "year": "1983",
      "venue": "Journal of personality and social psychology",
      "doi": "10.1037/0022-3514.44.1.113"
    },
    {
      "citation_id": "38",
      "title": "The empathy quotient: An investigation of adults with asperger syndrome or high functioning autism, and normal sex differences",
      "authors": [
        "S Baron-Cohen",
        "S Wheelwright"
      ],
      "year": "2004",
      "venue": "Journal of autism and developmental disorders",
      "doi": "10.1023/B:JADD.0000022607.19833.00"
    },
    {
      "citation_id": "39",
      "title": "The toronto empathy questionnaire: Scale development and initial validation of a factor-analytic solution to multiple empathy measures",
      "authors": [
        "R Spreng",
        "M Mckinnon",
        "R Mar",
        "B Levine"
      ],
      "year": "2009",
      "venue": "Journal of personality assessment",
      "doi": "10.1080/00223890802484381"
    },
    {
      "citation_id": "40",
      "title": "Sources of accuracy in the empathic accuracy paradigm",
      "authors": [
        "J Hall",
        "M Mast"
      ],
      "year": "2007",
      "venue": "Emotion",
      "doi": "10.1037/1528-3542.7.2.438"
    },
    {
      "citation_id": "41",
      "title": "WASSA 2021 shared task: Predicting empathy and emotion in reaction to news stories",
      "authors": [
        "S Tafreshi",
        "O De Clercq",
        "V Barriere",
        "S Buechel",
        "J Sedoc",
        "A Balahur"
      ],
      "year": "2021",
      "venue": "Proceedings of the Eleventh Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis"
    },
    {
      "citation_id": "42",
      "title": "Findings of WASSA 2023 shared task on empathy, emotion and personality detection in conversation and reactions to news articles",
      "authors": [
        "V Barriere",
        "J Sedoc",
        "S Tafreshi",
        "S Giorgi"
      ],
      "year": "2023",
      "venue": "Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, & Social Media Analysis",
      "doi": "10.18653/v1/2023.wassa-1.44"
    },
    {
      "citation_id": "43",
      "title": "Effective connectivity predicts cognitive empathy in cocaine addiction: A spectral dynamic causal modeling study",
      "authors": [
        "L Wei",
        "G.-R Wu",
        "M Bi",
        "C Baeken"
      ],
      "year": "2021",
      "venue": "Brain Imaging and Behavior",
      "doi": "10.1007/s11682-020-00354-y"
    },
    {
      "citation_id": "44",
      "title": "Towards low-resource real-time assessment of empathy in counselling",
      "authors": [
        "Z Wu",
        "R Helaoui",
        "D Recupero",
        "D Riboni"
      ],
      "year": "2021",
      "venue": "Proceedings of the Seventh Workshop on Computational Linguistics and Clinical Psychology: Improving Access",
      "doi": "10.18653/v1/2021.clpsych-1.22"
    },
    {
      "citation_id": "45",
      "title": "LeadEmpathy: An expert annotated German dataset of empathy in written leadership communication",
      "authors": [
        "D Sedefoglu",
        "A Lahnala",
        "J Wagner",
        "L Flek",
        "S Ohly"
      ],
      "year": "2024",
      "venue": "Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024"
    },
    {
      "citation_id": "46",
      "title": "Detecting empathy in speech",
      "authors": [
        "R Chen",
        "H Chen",
        "A Kulkarni"
      ],
      "venue": "Proc. Interspeech 2024",
      "doi": "10.21437/Interspeech.2024-347"
    },
    {
      "citation_id": "47",
      "title": "Findings of WASSA 2024 shared task on empathy and personality detection in interactions",
      "authors": [
        "S Giorgi",
        "J Sedoc",
        "V Barriere",
        "S Tafreshi"
      ],
      "year": "2024",
      "venue": "Proceedings of the 14th Workshop on Computational Approaches to Subjectivity, Sentiment, & Social Media Analysis",
      "doi": "10.18653/v1/2024.wassa-1.30"
    },
    {
      "citation_id": "48",
      "title": "Socially assistive robots: The link between personality, empathy, physiological signals, and task performance",
      "authors": [
        "A Tapus",
        "M Mataric"
      ],
      "year": "2008",
      "venue": "AAAI spring symposium: emotion, personality, and social behavior"
    },
    {
      "citation_id": "49",
      "title": "Identifying empathetic messages in online health communities",
      "authors": [
        "H Khanpour",
        "C Caragea",
        "P Biyani"
      ],
      "year": "2017",
      "venue": "Proceedings of the Eighth International Joint Conference on Natural Language Processing"
    },
    {
      "citation_id": "50",
      "title": "What makes a good counselor? learning to distinguish between highquality and low-quality counseling conversations",
      "authors": [
        "V Pérez-Rosas",
        "X Wu",
        "K Resnicow",
        "R Mihalcea"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/P19-1088"
    },
    {
      "citation_id": "51",
      "title": "Towards persona-based empathetic conversational models",
      "authors": [
        "P Zhong",
        "C Zhang",
        "H Wang",
        "Y Liu",
        "C Miao"
      ],
      "year": "2020",
      "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
      "doi": "10.18653/v1/2020.emnlp-main.531"
    },
    {
      "citation_id": "52",
      "title": "Towards empathetic open-domain conversation models: A new benchmark and dataset",
      "authors": [
        "H Rashkin",
        "E Smith",
        "M Li",
        "Y.-L Boureau"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/P19-1534"
    },
    {
      "citation_id": "53",
      "title": "Therapist empathy assessment in motivational interviews",
      "authors": [
        "L Tavabi",
        "T Tran",
        "B Borsari"
      ],
      "year": "2023",
      "venue": "2023 11th International Conference on Affective Computing and Intelligent Interaction (ACII)",
      "doi": "10.1109/ACII59096.2023.10388176"
    },
    {
      "citation_id": "54",
      "title": "Multimodal analysis and assessment of therapist empathy in motivational interviews",
      "authors": [
        "T Tran",
        "Y Yin",
        "L Tavabi"
      ],
      "year": "2023",
      "venue": "Proceedings of the 25th International Conference on Multimodal Interaction, ser. ICMI '23",
      "doi": "10.1145/3577190.3614105"
    },
    {
      "citation_id": "55",
      "title": "MEDIC: A multimodal empathy dataset in counseling",
      "authors": [
        "Z Zhu",
        "C Li",
        "J Pan"
      ],
      "year": "2023",
      "venue": "Proceedings of the 31st ACM International Conference on Multimedia",
      "doi": "10.1145/3581783.3612346"
    },
    {
      "citation_id": "56",
      "title": "Machine learning approach to identifying empathy using the vocals of mental health helpline counselors: Algorithm development and validation",
      "authors": [
        "R Sanjeewa",
        "R Iyer",
        "P Apputhurai",
        "N Wickramasinghe",
        "D Meyer"
      ],
      "year": "2025",
      "venue": "JMIR Form Res",
      "doi": "10.2196/67835"
    },
    {
      "citation_id": "57",
      "title": "Multimodal learning for identifying opportunities for empathetic responses",
      "authors": [
        "L Tavabi",
        "K Stefanov",
        "S Nasihati",
        "D Gilani",
        "M Traum",
        "Soleymani"
      ],
      "year": "2019",
      "venue": "2019 International Conference on Multimodal Interaction",
      "doi": "10.1145/3340555.3353750"
    },
    {
      "citation_id": "58",
      "title": "The distress analysis interview corpus of human and computer interviews",
      "authors": [
        "J Gratch",
        "R Artstein",
        "G Lucas"
      ],
      "year": "2014",
      "venue": "Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC'14)"
    },
    {
      "citation_id": "59",
      "title": "Empatheticexchanges: Toward understanding the cues for empathy in dyadic conversations",
      "authors": [
        "E Montiel-Vázquez",
        "C Cruz",
        "J Uresti",
        "R Gomez"
      ],
      "year": "2024",
      "venue": "IEEE Access",
      "doi": "10.1109/ACCESS.2024.3520000"
    },
    {
      "citation_id": "60",
      "title": "Manual for the motivational interviewing skill code (misc)",
      "authors": [
        "W Miller",
        "T Moyers",
        "D Ernst",
        "P Amrhein"
      ],
      "year": "2003",
      "venue": "Manual for the motivational interviewing skill code (misc)"
    },
    {
      "citation_id": "61",
      "title": "Revised global scales: Motivational interviewing treatment integrity 3.1. 1 (miti 3.1. 1)",
      "authors": [
        "T Moyers",
        "T Martin",
        "J Manuel",
        "W Miller",
        "D Ernst"
      ],
      "year": "2010",
      "venue": "Revised global scales: Motivational interviewing treatment integrity 3.1. 1 (miti 3.1. 1)"
    },
    {
      "citation_id": "62",
      "title": "Differential expression of empathy in a counseling analogue",
      "authors": [
        "E Heck",
        "C Davis"
      ],
      "year": "1973",
      "venue": "Journal of Counseling Psychology",
      "doi": "10.1037/h0034171"
    },
    {
      "citation_id": "63",
      "title": "Linguistic elements of engaging customer service discourse on social media",
      "authors": [
        "S Singh",
        "A Rios"
      ],
      "year": "2022",
      "venue": "Proceedings of the Fifth Workshop on Natural Language Processing and Computational Social Science (NLP+CSS)"
    },
    {
      "citation_id": "64",
      "title": "Distilling knowledge for empathy detection",
      "authors": [
        "M Hosseini",
        "C Caragea"
      ],
      "year": "2021",
      "venue": "Findings of the Association for Computational Linguistics: EMNLP 2021",
      "doi": "10.18653/v1/2021.findings-emnlp.314"
    },
    {
      "citation_id": "65",
      "title": "A computational approach to understanding empathy expressed in text-based mental health support",
      "authors": [
        "A Sharma",
        "A Miner",
        "D Atkins",
        "T Althoff"
      ],
      "year": "2020",
      "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
      "doi": "10.18653/v1/2020.emnlp-main.425"
    },
    {
      "citation_id": "66",
      "title": "Calibrating student models for emotion-related tasks",
      "authors": [
        "M Hosseini",
        "C Caragea"
      ],
      "year": "2022",
      "venue": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "67",
      "title": "AcnEmpathize: A dataset for understanding empathy in dermatology conversations",
      "authors": [
        "G Lee",
        "N Parde"
      ],
      "year": "2024",
      "venue": "Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024"
    },
    {
      "citation_id": "68",
      "title": "Predicting therapist empathy in motivational interviews using language features inspired by psycholinguistic norms",
      "authors": [
        "J Gibson",
        "N Malandrakis",
        "F Romero",
        "D Atkins",
        "S Narayanan"
      ],
      "year": "2015",
      "venue": "Sixteenth annual conference of the international speech communication association"
    },
    {
      "citation_id": "69",
      "title": "A deep learning approach to modeling empathy in addiction counseling",
      "authors": [
        "J Gibson",
        "D Can",
        "B Xiao"
      ],
      "year": "2016",
      "venue": "Commitment",
      "doi": "10.21437/Interspeech.2016-554"
    },
    {
      "citation_id": "70",
      "title": "Rate my therapist\": Automated detection of empathy in drug and alcohol counseling via speech and language processing",
      "authors": [
        "B Xiao",
        "Z Imel",
        "P Georgiou",
        "D Atkins",
        "S Narayanan"
      ],
      "year": "2015",
      "venue": "PloS One",
      "doi": "10.1371/journal.pone.0143055"
    },
    {
      "citation_id": "71",
      "title": "Agency context and tailored training in technology transfer: A pilot evaluation of motivational interviewing training for community counselors",
      "authors": [
        "J Baer",
        "E Wells",
        "D Rosengren",
        "B Hartzler",
        "B Beadnell",
        "C Dunn"
      ],
      "year": "2009",
      "venue": "Journal of substance abuse treatment",
      "doi": "10.1016/j.jsat.2009.01.003"
    },
    {
      "citation_id": "72",
      "title": "Automated empathy detection for oncology encounters",
      "authors": [
        "Z Chen",
        "J Gibson",
        "M.-C Chiu"
      ],
      "year": "2020",
      "venue": "2020 IEEE International Conference on Healthcare Informatics (ICHI)",
      "doi": "10.1109/ICHI48887.2020.9374402"
    },
    {
      "citation_id": "73",
      "title": "Enhancing communication between oncologists and patients with a computer-based training program: A randomized trial",
      "authors": [
        "J Tulsky",
        "R Arnold",
        "S Alexander"
      ],
      "year": "2011",
      "venue": "Annals of internal medicine",
      "doi": "10.7326/0003-4819-155-9-201111010-00007"
    },
    {
      "citation_id": "74",
      "title": "Can we detect speakers' empathy?: A real-life case study",
      "authors": [
        "F Alam",
        "M Danieli",
        "G Riccardi"
      ],
      "year": "2016",
      "venue": "th IEEE International Conference on Cognitive Infocommunications (CogInfoCom)",
      "doi": "10.1109/CogInfoCom.2016.7804525"
    },
    {
      "citation_id": "75",
      "title": "Modeling user empathy elicited by a robot storyteller",
      "authors": [
        "L Mathur",
        "M Spitale",
        "H Xi",
        "J Li",
        "M Matarić"
      ],
      "year": "2021",
      "venue": "2021 9th International Conference on Affective Computing and Intelligent Interaction (ACII)",
      "doi": "10.1109/ACII52823.2021.9597416"
    },
    {
      "citation_id": "76",
      "title": "A learning system to support social and empathy disorders diagnosis through affective avatars",
      "authors": [
        "R Hervás",
        "E Johnson",
        "C De La Franca",
        "J Bravo",
        "T Mondéjar"
      ],
      "year": "2016",
      "venue": "2016 15th International Conference on Ubiquitous Computing and Communications and 2016 International Symposium on Cyberspace and Security",
      "doi": "10.1109/IUCC-CSS.2016.021"
    },
    {
      "citation_id": "77",
      "title": "Empathizing with virtual agents: The effect of personification and general empathic tendencies",
      "authors": [
        "K Kroes",
        "I Saccardi",
        "J Masthoff"
      ],
      "year": "2022",
      "venue": "2022 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)",
      "doi": "10.1109/AIVR56993.2022.00017"
    },
    {
      "citation_id": "78",
      "title": "EmpathicStories++: A multimodal dataset for empathy towards personal experiences",
      "authors": [
        "J Shen",
        "Y Kim",
        "M Hulse"
      ],
      "year": "2024",
      "venue": "Findings of the Association for Computational Linguistics: ACL 2024",
      "doi": "10.18653/v1/2024.findings-acl.268"
    },
    {
      "citation_id": "79",
      "title": "Modeling empathic similarity in personal narratives",
      "authors": [
        "J Shen",
        "M Sap",
        "P Colon-Hernandez",
        "H Park",
        "C Breazeal"
      ],
      "year": "2023",
      "venue": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
      "doi": "10.18653/v1/2023.emnlp-main.383"
    },
    {
      "citation_id": "80",
      "title": "The omgempathy dataset: Evaluating the impact of affective behavior in storytelling",
      "authors": [
        "P Barros",
        "N Churamani",
        "A Lim",
        "S Wermter"
      ],
      "year": "2019",
      "venue": "2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII)",
      "doi": "10.1109/ACII.2019.8925530"
    },
    {
      "citation_id": "81",
      "title": "Prediction of human empathy based on eeg cortical asymmetry",
      "authors": [
        "A Kuijt",
        "M Alimardani"
      ],
      "year": "2020",
      "venue": "2020 IEEE International Conference on Human-Machine Systems (ICHMS)",
      "doi": "10.1109/ICHMS49158.2020.9209561"
    },
    {
      "citation_id": "82",
      "title": "Physiological indicators of the relation between autistic traits and empathy: Evidence from electrocardiogram and skin conductance signals",
      "authors": [
        "S Golbabaei",
        "N Sammaknejad",
        "K Borhani"
      ],
      "year": "2022",
      "venue": "2022 29th National and 7th International Iranian Conference on Biomedical Engineering (ICBME)",
      "doi": "10.1109/ICBME57741.2022.10053068"
    },
    {
      "citation_id": "83",
      "title": "Recognizing pathogenic empathy in social media",
      "authors": [
        "M Abdul-Mageed",
        "A Buffone",
        "H Peng",
        "J Eichstaedt",
        "L Ungar"
      ],
      "year": "2017",
      "venue": "Proceedings of the International AAAI Conference on Web and Social Media",
      "doi": "10.1609/icwsm.v11i1.14942"
    },
    {
      "citation_id": "84",
      "title": "A multimodal framework for automated teaching quality assessment of one-to-many online instruction videos",
      "authors": [
        "Y Pan",
        "J Wu",
        "R Ju"
      ],
      "year": "2022",
      "venue": "2022 26th International Conference on Pattern Recognition (ICPR)",
      "doi": "10.1109/icpr56361.2022.9956185"
    },
    {
      "citation_id": "85",
      "title": "Using temporal features of observers' physiological measures to distinguish between genuine and fake smiles",
      "authors": [
        "M Hossain",
        "T Gedeon",
        "R Sankaranarayana"
      ],
      "year": "2020",
      "venue": "IEEE Transactions on Affective Computing",
      "doi": "10.1109/TAFFC.2018.2878029"
    },
    {
      "citation_id": "86",
      "title": "Are you really angry? detecting emotion veracity as a proposed tool for interaction",
      "authors": [
        "L Chen",
        "T Gedeon",
        "M Hossain",
        "S Caldwell"
      ],
      "year": "2017",
      "venue": "Proceedings of the 29th Australian Conference on Computer-Human Interaction",
      "doi": "10.1145/3152771.3156147"
    },
    {
      "citation_id": "87",
      "title": "in New Perspectives on Affect and Learning Technologies",
      "authors": [
        "S Afzal",
        "P Robinson"
      ],
      "year": "2011",
      "venue": "in New Perspectives on Affect and Learning Technologies",
      "doi": "10.1007/978-1-4419-9625-1_5"
    },
    {
      "citation_id": "88",
      "title": "From word embeddings to pre-trained language models: A state-of-the-art walkthrough",
      "authors": [
        "M Mars"
      ],
      "year": "2022",
      "venue": "Applied Sciences",
      "doi": "/10.3390/app12178805"
    },
    {
      "citation_id": "89",
      "title": "LLM-GEm: Large language model-guided prediction of people's empathy levels towards newspaper article",
      "authors": [
        "M Hasan",
        "M Hossain",
        "T Gedeon",
        "S Rahman"
      ],
      "year": "2024",
      "venue": "Findings of the Association for Computational Linguistics: EACL 2024"
    },
    {
      "citation_id": "90",
      "title": "Team Phoenix at WASSA 2021: Emotion analysis on news stories with pre-trained language models",
      "authors": [
        "Y Butala",
        "K Singh",
        "A Kumar",
        "S Shrivastava"
      ],
      "year": "2021",
      "venue": "Proceedings of the Eleventh Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis"
    },
    {
      "citation_id": "91",
      "title": "EmpNa at WASSA 2021: A lightweight model for the prediction of empathy, distress and emotions from reactions to news stories",
      "authors": [
        "G Vettigli",
        "A Sorgente"
      ],
      "year": "2021",
      "venue": "Proceedings of the Eleventh Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis"
    },
    {
      "citation_id": "92",
      "title": "PVG at WASSA 2021: A multi-input, multi-task, transformer-based architecture for empathy and distress prediction",
      "authors": [
        "A Kulkarni",
        "S Somwase",
        "S Rajput",
        "M Marathe"
      ],
      "year": "2021",
      "venue": "Proceedings of the Eleventh Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis"
    },
    {
      "citation_id": "93",
      "title": "WASSA@IITK at WASSA 2021: Multi-task learning and transformer finetuning for emotion classification and empathy prediction",
      "authors": [
        "J Mundra",
        "R Gupta",
        "S Mukherjee"
      ],
      "year": "2021",
      "venue": "Proceedings of the Eleventh Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis"
    },
    {
      "citation_id": "94",
      "title": "Transformerbased architecture for empathy prediction and emotion classification",
      "authors": [
        "H Vasava",
        "P Uikey",
        "G Wasnik",
        "R Sharma"
      ],
      "year": "2022",
      "venue": "Proceedings of the 12th Workshop on Computational Approaches to Subjectivity, Sentiment & Social Media Analysis",
      "doi": "10.18653/v1/2022.wassa-1.27"
    },
    {
      "citation_id": "95",
      "title": "Team IITP-AINLPML at WASSA 2022: Empathy detection, emotion classification and personality detection",
      "authors": [
        "S Ghosh",
        "D Maurya",
        "A Ekbal",
        "P Bhattacharyya"
      ],
      "year": "2022",
      "venue": "Proceedings of the 12th Workshop on Computational Approaches to Subjectivity, Sentiment & Social Media Analysis",
      "doi": "10.18653/v1/2022.wassa-1.26"
    },
    {
      "citation_id": "96",
      "title": "SURREY-CTS-NLP at WASSA2022: An experiment of discourse and sentiment analysis for the prediction of empathy, distress and emotion",
      "authors": [
        "S Qian",
        "C Orašan",
        "D Kanojia",
        "H Saadany",
        "F Carmo"
      ],
      "year": "2022",
      "venue": "Proceedings of the 12th Workshop on Computational Approaches to Subjectivity, Sentiment & Social Media Analysis",
      "doi": "10.18653/v1/2022.wassa-1.29"
    },
    {
      "citation_id": "97",
      "title": "CAISA at WASSA 2022: Adapter-tuning for empathy prediction",
      "authors": [
        "A Lahnala",
        "C Welch",
        "L Flek"
      ],
      "year": "2022",
      "venue": "Proceedings of the 12th Workshop on Computational Approaches to Subjectivity, Sentiment & Social Media Analysis",
      "doi": "10.18653/v1/2022.wassa-1.31"
    },
    {
      "citation_id": "98",
      "title": "IUCL at WASSA 2022 shared task: A text-only approach to empathy and emotion detection",
      "authors": [
        "Y Chen",
        "Y Ju",
        "S Übler"
      ],
      "year": "2022",
      "venue": "Proceedings of the 12th Workshop on Computational Approaches to Subjectivity, Sentiment & Social Media Analysis",
      "doi": "10.18653/v1/2022.wassa-1.21"
    },
    {
      "citation_id": "99",
      "title": "Empathy and distress prediction using transformer multi-output regression and emotion analysis with an ensemble of supervised and zero-shot learning models",
      "authors": [
        "F Plaza-Del-Arco",
        "J Collado-Monta Ñez",
        "L Ure",
        "M.-T Martín-Valdivia"
      ],
      "year": "2022",
      "venue": "Proceedings of the 12th Workshop on Computational Approaches to Subjectivity, Sentiment & Social Media Analysis",
      "doi": "10.18653/v1/2022.wassa-1.23"
    },
    {
      "citation_id": "100",
      "title": "Curtin OCAI at WASSA 2023 empathy, emotion and personality shared task: Demographic-aware prediction using multiple transformers",
      "authors": [
        "M Hasan",
        "M Hossain",
        "T Gedeon",
        "S Soon",
        "S Rahman"
      ],
      "year": "2023",
      "venue": "Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, & Social Media Analysis",
      "doi": "10.18653/v1/2023.wassa-1.47"
    },
    {
      "citation_id": "101",
      "title": "Team Hawk at WASSA 2023 empathy, emotion, and personality shared task: Multitasking multi-encoder based transformers for empathy and emotion prediction in conversations",
      "authors": [
        "A Srinivas",
        "N Barua",
        "S Pal"
      ],
      "year": "2023",
      "venue": "Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, & Social Media Analysis",
      "doi": "10.18653/v1/2023.wassa-1.48"
    },
    {
      "citation_id": "102",
      "title": "HIT-SCIR at WASSA 2023: Empathy and emotion analysis at the utterancelevel and the essay-level",
      "authors": [
        "X Lu",
        "Z Li",
        "Y Zhao",
        "B Qin"
      ],
      "year": "2023",
      "venue": "Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, & Social Media Analysis",
      "doi": "10.18653/v1/2023.wassa-1.54"
    },
    {
      "citation_id": "103",
      "title": "YNU-HPCC at WASSA-2023 shared task 1: Large-scale language model with LoRA finetuning for empathy detection and emotion classification",
      "authors": [
        "Y Wang",
        "J Wang",
        "X Zhang"
      ],
      "year": "2023",
      "venue": "Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, & Social Media Analysis",
      "doi": "10.18653/v1/2023.wassa-1.45"
    },
    {
      "citation_id": "104",
      "title": "Caisa at wassa 2023 shared task: Domain transfer for empathy, distress, and personality prediction",
      "authors": [
        "F Gruschka",
        "A Lahnala",
        "C Welch",
        "L Flek"
      ],
      "year": "2023",
      "venue": "Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, & Social Media Analysis",
      "doi": "10.18653/v1/2023.wassa-1.50"
    },
    {
      "citation_id": "105",
      "title": "PICT-CLRL at WASSA 2023 empathy, emotion and personality shared task: Empathy and distress detection using ensembles of transformer models",
      "authors": [
        "T Chavan",
        "K Deshpande",
        "S Sonawane"
      ],
      "year": "2023",
      "venue": "Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, & Social Media Analysis",
      "doi": "10.18653/v1/2023.wassa-1.52"
    },
    {
      "citation_id": "106",
      "title": "NCUEE-NLP at WASSA 2023 shared task 1: Empathy and emotion prediction using sentiment-enhanced RoBERTa transformers",
      "authors": [
        "T.-M Lin",
        "J.-Y Chang",
        "L.-H Lee"
      ],
      "year": "2023",
      "venue": "Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, & Social Media Analysis",
      "doi": "10.18653/v1/2023.wassa-1.49"
    },
    {
      "citation_id": "107",
      "title": "Empathify at WASSA 2024 empathy and personality shared task: Contextualizing empathy with a BERT-based context-aware approach for empathy detection",
      "authors": [
        "A Numano Glu",
        "S Ates",
        "N Cicekli"
      ],
      "year": "2024",
      "venue": "Proceedings of the 14th Workshop on Computational Approaches to Subjectivity, Sentiment, & Social Media Analysis",
      "doi": "10.18653/v1/2024.wassa-1.33"
    },
    {
      "citation_id": "108",
      "title": "Daisy at WASSA 2024 empathy and personality shared task: A quick exploration on emotional pattern of empathy and distress",
      "authors": [
        "R Chevi",
        "A Aji"
      ],
      "year": "2024",
      "venue": "Proceedings of the 14th Workshop on Computational Approaches to Subjectivity, Sentiment, & Social Media Analysis",
      "doi": "10.18653/v1/2024.wassa-1.37"
    },
    {
      "citation_id": "109",
      "title": "Fraunhofer SIT at WASSA 2024 empathy and personality shared task: Use of sentiment transformers and data augmentation with fuzzy labels to predict emotional reactions in conversations and essays",
      "authors": [
        "R Frick",
        "M Steinebach"
      ],
      "year": "2024",
      "venue": "Proceedings of the 14th Workshop on Computational Approaches to Subjectivity, Sentiment, & Social Media Analysis",
      "doi": "10.18653/v1/2024.wassa-1.40"
    },
    {
      "citation_id": "110",
      "title": "Chinchunmei at WASSA 2024 empathy and personality shared task: Boosting LLM's prediction with role-play augmentation and contrastive reasoning calibration",
      "authors": [
        "T Li",
        "N Rusnachenko",
        "H Liang"
      ],
      "year": "2024",
      "venue": "Proceedings of the 14th Workshop on Computational Approaches to Subjectivity, Sentiment, & Social Media Analysis",
      "doi": "10.18653/v1/2024.wassa-1.32"
    },
    {
      "citation_id": "111",
      "title": "RU at WASSA 2024 shared task: Task-aligned prompt for predicting empathy and distress",
      "authors": [
        "H Kong",
        "S Moon"
      ],
      "year": "2024",
      "venue": "Proceedings of the 14th Workshop on Computational Approaches to Subjectivity, Sentiment, & Social Media Analysis",
      "doi": "10.18653/v1/2024.wassa-1.31"
    },
    {
      "citation_id": "112",
      "title": "Labels generated by large language model helps measuring people's empathy in vitro",
      "authors": [
        "M Hasan",
        "Y Yao",
        "M Hossain"
      ],
      "year": "2025",
      "venue": "Labels generated by large language model helps measuring people's empathy in vitro",
      "arxiv": "arXiv:2501.00691[cs.CL]"
    },
    {
      "citation_id": "113",
      "title": "Last-min-submission at WASSA 2024 empathy and personality shared task: Enhancing emotional intelligence with prompts",
      "authors": [
        "S Churina",
        "P Verma",
        "S Tripathy"
      ],
      "year": "2024",
      "venue": "Proceedings of the 14th Workshop on Computational Approaches to Subjectivity, Sentiment, & Social Media Analysis",
      "doi": "10.18653/v1/2024.wassa-1.38"
    },
    {
      "citation_id": "114",
      "title": "Empaths at WASSA 2024 empathy and personality shared task: Turn-level empathy prediction using psychological indicators",
      "authors": [
        "S Furniturewala",
        "K Jaidka"
      ],
      "year": "2024",
      "venue": "Proceedings of the 14th Workshop on Computational Approaches to Subjectivity, Sentiment, & Social Media Analysis",
      "doi": "10.18653/v1/2024.wassa-1.35"
    },
    {
      "citation_id": "115",
      "title": "Hyy33 at WASSA 2024 empathy and personality shared task: Using the CombinedLoss and FGM for enhancing BERT-based models in emotion and empathy prediction from conversation turns",
      "authors": [
        "H Yang",
        "L Huang",
        "T Li",
        "N Rusnachenko",
        "H Liang"
      ],
      "year": "2024",
      "venue": "Proceedings of the 14th Workshop on Computational Approaches to Subjectivity, Sentiment, & Social Media Analysis",
      "doi": "10.18653/v1/2024.wassa-1.39"
    },
    {
      "citation_id": "116",
      "title": "EmpatheticFIG at WASSA 2024 empathy and personality shared task: Predicting empathy and emotion in conversations with figurative language",
      "authors": [
        "G Lee",
        "Z Wang",
        "S Ravi",
        "N Parde"
      ],
      "year": "2024",
      "venue": "Proceedings of the 14th Workshop on Computational Approaches to Subjectivity, Sentiment, & Social Media Analysis",
      "doi": "10.18653/v1/2024.wassa-1.41"
    },
    {
      "citation_id": "117",
      "title": "Zhenmei at WASSA-2024 empathy and personality shared track 2 incorporating Pearson correlation coefficient as a regularization term for enhanced empathy and emotion prediction in conversational turns",
      "authors": [
        "L Huang",
        "H Liang"
      ],
      "year": "2024",
      "venue": "Proceedings of the 14th Workshop on Computational Approaches to Subjectivity, Sentiment, & Social Media Analysis",
      "doi": "10.18653/v1/2024.wassa-1.34"
    },
    {
      "citation_id": "118",
      "title": "ConText at WASSA 2024 empathy and personality shared task: History-dependent embedding utterance representations for empathy and emotion prediction in conversations",
      "authors": [
        "P Pereira",
        "H Moniz",
        "J Carvalho"
      ],
      "year": "2024",
      "venue": "Proceedings of the 14th Workshop on Computational Approaches to Subjectivity, Sentiment, & Social Media Analysis",
      "doi": "10.18653/v1/2024.wassa-1.42"
    },
    {
      "citation_id": "119",
      "title": "Enriching word vectors with subword information",
      "authors": [
        "P Bojanowski",
        "E Grave",
        "A Joulin",
        "T Mikolov"
      ],
      "year": "2017",
      "venue": "Transactions of the Association for Computational Linguistics",
      "doi": "10.1162/tacl_a_00051"
    },
    {
      "citation_id": "120",
      "title": "Empathy identification systems are not accurately accounting for context",
      "authors": [
        "A Lee",
        "J Kummerfeld",
        "L An",
        "R Mihalcea"
      ],
      "year": "2023",
      "venue": "Proceedings of the 17th Conference of the European Chapter",
      "doi": "10.18653/v1/2023.eacl-main.123"
    },
    {
      "citation_id": "121",
      "title": "Utterance as a bridge: Few-shot joint learning of empathy detection and empathy intent classification",
      "authors": [
        "L Jiang",
        "D Wu",
        "Z Li",
        "S Song",
        "Y Li",
        "H Huang"
      ],
      "year": "2025",
      "venue": "ICASSP 2025 -2025 IEEE International Conference on Acoustics, Speech and Signal Processing",
      "doi": "10.1109/ICASSP49660.2025.10890614"
    },
    {
      "citation_id": "122",
      "title": "Feature normalization and cartography-based demonstrations for prompt-based fineon emotion-related tasks",
      "authors": [
        "M Hosseini",
        "C Caragea"
      ],
      "year": "2023",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence",
      "doi": "10.1609/aaai.v37i11.26514"
    },
    {
      "citation_id": "123",
      "title": "Empathetic robots using empathy classifiers in hri settings",
      "authors": [
        "C Cruz",
        "E Montiel-Vázquez",
        "C Maeda",
        "D Lam",
        "R Gomez"
      ],
      "year": "2025",
      "venue": "Proceedings of the 2025 ACM/IEEE International Conference on Human-Robot Interaction, ser. HRI '25"
    },
    {
      "citation_id": "124",
      "title": "Micromodels for efficient, explainable, and reusable systems: A case study on mental health",
      "authors": [
        "A Lee",
        "J Kummerfeld",
        "L An",
        "R Mihalcea"
      ],
      "year": "2021",
      "venue": "Findings of the Association for Computational Linguistics: EMNLP 2021",
      "doi": "10.18653/v1/2021.findings-emnlp.360"
    },
    {
      "citation_id": "125",
      "title": "Fusion of hand-crafted and deep features for empathy prediction",
      "authors": [
        "S Hinduja",
        "M Uddin",
        "S Jannat",
        "A Sharma",
        "S Canavan"
      ],
      "year": "2019",
      "venue": "2019 14th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2019)",
      "doi": "10.1109/FG.2019.8756522"
    },
    {
      "citation_id": "126",
      "title": "Towards an emocog model for multimodal empathy prediction",
      "authors": [
        "B Azari",
        "Z Zhang",
        "A Lim"
      ],
      "year": "2019",
      "venue": "Gesture Recognition (FG 2019)",
      "doi": "10.1109/FG.2019.8756612"
    },
    {
      "citation_id": "127",
      "title": "Performance analysis of unimodal and multimodal models in valence-based empathy recognition",
      "authors": [
        "A Mallol-Ragolta",
        "M Schmitt",
        "A Baird",
        "N Cummins",
        "B Schuller"
      ],
      "year": "2019",
      "venue": "2019 14th IEEE International Conference on Automatic Face & Gesture Recognition",
      "doi": "10.1109/FG.2019.8756517"
    },
    {
      "citation_id": "128",
      "title": "A multimodal lstm for predicting listener empathic responses over time",
      "authors": [
        "Z.-X Tan",
        "A Goel",
        "T.-S Nguyen",
        "D Ong"
      ],
      "year": "2019",
      "venue": "2019 14th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2019)",
      "doi": "10.1109/FG.2019.8756577"
    },
    {
      "citation_id": "129",
      "title": "Towards a multimodal time-based empathy prediction system",
      "authors": [
        "F Barbieri",
        "E Guizzo",
        "F Lucchesi",
        "G Maffei",
        "F Del Prado Martín",
        "T Weyde"
      ],
      "year": "2019",
      "venue": "Gesture Recognition",
      "doi": "10.1109/FG.2019.8756532"
    },
    {
      "citation_id": "130",
      "title": "A weightless regression system for predicting multi-modal empathy",
      "authors": [
        "L Lusquino Filho",
        "L Oliveira",
        "H Carneiro"
      ],
      "year": "2020",
      "venue": "2020 15th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2020",
      "doi": "10.1109/FG47880.2020.00086"
    },
    {
      "citation_id": "131",
      "title": "Deep face recognition",
      "authors": [
        "O Parkhi",
        "A Vedaldi",
        "A Zisserman"
      ],
      "year": "2015",
      "venue": "Proceedings of the British Machine Vision Conference",
      "doi": "10.5244/C.29.41"
    },
    {
      "citation_id": "132",
      "title": "Recent developments in openSMILE, the munich open-source multimedia feature extractor",
      "authors": [
        "F Eyben",
        "F Weninger",
        "F Gross",
        "B Schuller"
      ],
      "year": "2013",
      "venue": "Proceedings of the 21st ACM international conference on Multimedia",
      "doi": "10.1145/2502081.2502224"
    },
    {
      "citation_id": "133",
      "title": "GloVe: Global vectors for word representation",
      "authors": [
        "J Pennington",
        "R Socher",
        "C Manning"
      ],
      "year": "2014",
      "venue": "Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)",
      "doi": "10.3115/v1/D14-1162"
    },
    {
      "citation_id": "134",
      "title": "OpenFace: A general-purpose face recognition library with mobile applications",
      "authors": [
        "B Amos",
        "B Ludwiczuk",
        "M Satyanarayanan"
      ],
      "year": "2016",
      "venue": "CMU School of Computer Science"
    },
    {
      "citation_id": "135",
      "title": "How many Mel-frequency cepstral coefficients to be utilized in speech recognition? a study with the Bengali language",
      "authors": [
        "M Hasan",
        "M Hasan",
        "M Hossain"
      ],
      "year": "2021",
      "venue": "The Journal of Engineering",
      "doi": "10.1049/tje2.12082"
    },
    {
      "citation_id": "136",
      "title": "SWAFN: Sentimental words aware fusion network for multimodal sentiment analysis",
      "authors": [
        "M Chen",
        "X Li"
      ],
      "year": "2020",
      "venue": "Proceedings of the 28th International Conference on Computational Linguistics",
      "doi": "10.18653/v1/2020.coling-main.93"
    },
    {
      "citation_id": "137",
      "title": "Hubert: Self-supervised speech representation learning by masked prediction of hidden units",
      "authors": [
        "W.-N Hsu",
        "B Bolte",
        "Y.-H Tsai",
        "K Lakhotia",
        "R Salakhutdinov",
        "A Mohamed"
      ],
      "year": "2021",
      "venue": "IEEE/ACM Transactions on Audio, Speech, and Language Processing",
      "doi": "10.1109/TASLP.2021.3122291"
    },
    {
      "citation_id": "138",
      "title": "Llms achieve adult human performance on higher-order theory of mind tasks",
      "authors": [
        "W Street",
        "J Siy",
        "G Keeling"
      ],
      "year": "2024",
      "venue": "Llms achieve adult human performance on higher-order theory of mind tasks",
      "doi": "10.48550/arXiv.2405.18870",
      "arxiv": "arXiv:2405.18870[cs.AI"
    },
    {
      "citation_id": "139",
      "title": "Thesis proposal: Detecting empathy using multimodal language model",
      "authors": [
        "M Hasan",
        "M Hossain",
        "A Krishna",
        "S Rahman",
        "T Gedeon"
      ],
      "year": "2024",
      "venue": "Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics: Student Research Workshop"
    },
    {
      "citation_id": "140",
      "title": "Gpt-4v with emotion: A zero-shot benchmark for generalized emotion recognition",
      "authors": [
        "Z Lian",
        "L Sun",
        "H Sun"
      ],
      "year": "2024",
      "venue": "Information Fusion",
      "doi": "10.1016/j.inffus.2024.102367"
    },
    {
      "citation_id": "141",
      "title": "How patients appraise physicians",
      "authors": [
        "N Cousins"
      ],
      "year": "1985",
      "venue": "New England Journal of Medicine"
    },
    {
      "citation_id": "142",
      "title": "The importance of empathy as an interviewing skill in medicine",
      "authors": [
        "P Bellet",
        "M Maloney"
      ],
      "year": "1991",
      "venue": "JAMA",
      "doi": "10.1001/jama.1991.03470130111039"
    },
    {
      "citation_id": "143",
      "title": "From shared to distinct self-other representations in empathy: Evidence from neurotypical function and socio-cognitive disorders",
      "authors": [
        "C Lamm",
        "H Bukowski",
        "G Silani"
      ],
      "year": "2016",
      "venue": "Philosophical Transactions of the Royal Society B: Biological Sciences",
      "doi": "10.1098/rstb.2015.0083"
    },
    {
      "citation_id": "144",
      "title": "Automatic assessment of depression based on visual cues: A systematic review",
      "authors": [
        "A Pampouchidou",
        "P Simos",
        "K Marias"
      ],
      "year": "2019",
      "venue": "IEEE Transactions on Affective Computing",
      "doi": "10.1109/TAFFC.2017.2724035"
    },
    {
      "citation_id": "145",
      "title": "Adapting software with affective computing: A systematic review",
      "authors": [
        "R Aranha",
        "C Corrêa",
        "F Nunes"
      ],
      "year": "2021",
      "venue": "IEEE Transactions on Affective Computing",
      "doi": "10.1109/TAFFC.2019.2902379"
    },
    {
      "citation_id": "146",
      "title": "A review of affective computing research based on function-component-representation framework",
      "authors": [
        "H Ma",
        "S Yarosh"
      ],
      "year": "2023",
      "venue": "IEEE Transactions on Affective Computing",
      "doi": "10.1109/TAFFC.2021.3104512"
    },
    {
      "citation_id": "147",
      "title": "Automatic emotion recognition in clinical scenario: A systematic review of methods",
      "authors": [
        "L Pepa",
        "L Spalazzi",
        "M Capecci",
        "M Ceravolo"
      ],
      "year": "2023",
      "venue": "IEEE Transactions on Affective Computing",
      "doi": "10.1109/TAFFC.2021.3128787"
    },
    {
      "citation_id": "148",
      "title": "Emotion recognition for everyday life using physiological signals from wearables: A systematic literature review",
      "authors": [
        "S Saganowski",
        "B Perz",
        "A Polak",
        "P Kazienko"
      ],
      "year": "2023",
      "venue": "IEEE Transactions on Affective Computing",
      "doi": "10.1109/TAFFC.2022.3176135"
    },
    {
      "citation_id": "149",
      "title": "Threat perception captured by emotion, motor and empathetic system responses: A systematic review",
      "authors": [
        "E Jacobs",
        "F Deligianni",
        "F Pollick"
      ],
      "year": "2024",
      "venue": "IEEE Transactions on Affective Computing",
      "doi": "10.1109/TAFFC.2023.3323043"
    },
    {
      "citation_id": "150",
      "title": "Imagenet classification with deep convolutional neural networks",
      "authors": [
        "A Krizhevsky",
        "I Sutskever",
        "G Hinton"
      ],
      "year": "2012",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "151",
      "title": "Adam: A method for stochastic optimization",
      "authors": [
        "D Kingma",
        "J Ba"
      ],
      "year": "2015",
      "venue": "3rd International Conference on Learning Representations, ICLR 2015"
    },
    {
      "citation_id": "152",
      "title": "Dive into Deep Learning",
      "authors": [
        "A Zhang",
        "Z Lipton",
        "M Li",
        "A Smola"
      ],
      "year": "2023",
      "venue": "Dive into Deep Learning"
    },
    {
      "citation_id": "153",
      "title": "Deep learning",
      "authors": [
        "Y Lecun",
        "Y Bengio",
        "G Hinton"
      ],
      "year": "2015",
      "venue": "nature",
      "doi": "10.1038/nature14539"
    },
    {
      "citation_id": "154",
      "title": "Covidence systematic review software",
      "venue": "Covidence systematic review software"
    },
    {
      "citation_id": "155",
      "title": "Detection of potential customers' empathy behavior towards customers' reviews",
      "authors": [
        "M Hossain",
        "M Rahman"
      ],
      "year": "2022",
      "venue": "Journal of retailing and consumer services",
      "doi": "10.1016/j.jretconser.2021.102881"
    },
    {
      "citation_id": "156",
      "title": "Mitigating the bias in empathy detection",
      "authors": [
        "S Hinduja"
      ],
      "year": "2019",
      "venue": "2019 8th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW)",
      "doi": "10.1109/ACIIW.2019.8925035"
    },
    {
      "citation_id": "157",
      "title": "Evaluation of LLMs-based hidden states as author representations for psychological human-centered NLP tasks",
      "authors": [
        "N Soni",
        "P Chitale",
        "N Singh",
        "H Balasubramanian",
        "Schwartz"
      ],
      "year": "2025",
      "venue": "Findings of the Association for Computational Linguistics: NAACL 2025"
    },
    {
      "citation_id": "158",
      "title": "Prediction of emotional empathy in intelligent agents to facilitate precise social interaction",
      "authors": [
        "S Alanazi",
        "M Shabbir",
        "N Alshammari",
        "M Alruwaili",
        "I Hussain",
        "F Ahmad"
      ],
      "year": "2023",
      "venue": "Applied Sciences",
      "doi": "10.3390/app13021163"
    },
    {
      "citation_id": "159",
      "title": "The Berkeley FrameNet project",
      "authors": [
        "C Baker",
        "C Fillmore",
        "J Lowe"
      ],
      "year": "1998",
      "venue": "36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics",
      "doi": "10.3115/980845.980860"
    }
  ]
}