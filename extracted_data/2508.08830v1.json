{
  "paper_id": "2508.08830v1",
  "title": "Silicon Minds Versus Human Hearts: The Wisdom Of Crowds Beats The Wisdom Of Ai In Emotion Recognition",
  "published": "2025-08-12T10:37:37Z",
  "authors": [
    "Mustafa Akben",
    "Vinayaka Gude",
    "Haya Ajjan"
  ],
  "keywords": [
    "Large Language Models",
    "Human-AI Collaboration",
    "Emotion Recognition",
    "Wisdom of the Crowd"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "The ability to discern subtle emotional cues is fundamental to human social intelligence. As artificial intelligence (AI) becomes increasingly common, AI's ability to recognize and respond to human emotions is crucial for effective human-AI interactions. In particular, whether such systems can match or surpass human experts remains to be seen. However, the emotional intelligence of AI, particularly multimodal large language models (MLLMs), remains largely unexplored. This study evaluates the emotion recognition abilities of MLLMs using the Reading the Mind in the Eyes Test (RMET) and its multiracial counterpart (MRMET), and compares their performance against human participants. Results show that, on average, MLLMs outperform humans in accurately identifying emotions across both tests. This trend persists even when comparing performance across low, medium, and expert-level performing groups. Yet when we aggregate independent human decisions to simulate collective intelligence, human groups significantly surpass the performance of aggregated MLLM predictions, highlighting the wisdom of the crowd. Moreover, a collaborative approach (augmented intelligence) that combines human and MLLM predictions achieves greater accuracy than either humans or MLLMs alone. These results suggest that while MLLMs exhibit strong emotion recognition at the individual level, the collective intelligence of humans and the synergistic potential of human-AI collaboration offer the most promising path toward effective emotional AI. We discuss the implications of these findings for the development of emotionally intelligent AI systems and future research directions.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Emotion recognition, which refers to the ability to discern and interpret others' emotional states, influences how individuals perceive, think, and navigate their social environments  (Salovey and Mayer, 1990) . People adept at recognizing emotions forge deep connections with others, resolve conflicts, and sustain social cohesion  (Lopes et al., 2004; Vellante et al., 2013) , whereas deficits present difficulties ranging from neuropsychiatric disorders to socio-cognitive challenges  (Paiva-Silva et al., 2016; Vellante et al., 2013) .\n\nThis same capacity has become a sine qua non for artificial intelligence (AI) systems as they become increasingly ubiquitous in daily life  (Picard, 2010) . AI systems are currently entrusted with high-stakes emotion recognition tasks that require near-perfection, from identifying depression in psychiatric clinics to detecting deception at border security  (Garcia-Ceja et al., 2018; SÃ¡nchez-Monedero and Dencik, 2022) . In such conditions, emotion recognition is not an optional feature but a fundamental requirement to inspire trust, encourage cooperation, and ultimately deliver success. Against this backdrop, researchers have accelerated progress on emotion-aware AI systems, yielding substantial advances  (Monedero and Dencik, 2022) .\n\nLeading this progress, large language models (LLMs) have advanced rapidly. Over the past few years, LLMs have now performed at average human levels or better on widely accepted text-based emotion detection tests, as documented in recent studies  (Elyoseph et al., 2023; Wang et al., 2023) . More recently, multimodal LLMs (MLLMs) capable of processing both language and images have outperformed average individuals on image-based tests  (Strachan, Pansardi, et al., 2024) . GPT-4o from OpenAI, consistently ranked highest among multimodal models in benchmarks and emotion recognition tests  (Hurst et al., 2024) , exemplifies current state-of-the-art performance. Accordingly, GPT-4o serves as an ideal test case for evaluating current AI capabilities in emotion recognition. However, prevailing assessment methods may not capture the model's full range of abilities.\n\nSpecifically, conventional methodologies tend to rely on central tendency metrics (e.g., group means) to compare AI model performance to the average human level. Illustratively,  Strachan et al. (2024)  found that GPT-4o exceeded average human performance, but their analysis relied solely on group mean differences, thereby failing to test whether AI could match the performance of expert-level humans. Such approaches overlook the wide variation in human emotion recognition abilities and the exceptional performers whose skills are critical in high-stakes fields like clinical psychology and medical practice  (Ickes, 2009) . Validating GPT-4o only against average performance thus risks deploying suboptimal systems in high-stakes settings and mistaking AI mediocrity for human excellence. To address this gap, we pose our first research question (RQ1): How does GPT-4o's emotion recognition performance compare across low, medium, and top-performing human groups, rather than only against the average?\n\nOur second research question (RQ2) extends the first by examining whether GPT-4o can outperform collective human intelligence, or the \"wisdom of crowds.\" This comparison is critical because society's important decisions often emerge from groups rather than individuals  (Centola, 2018; Surowiecki, 2005) , with collective judgment canceling individual biases to achieve better accuracy  (Hong & Page, 2004) . Whether AI can match this collective intelligence thus provides a litmus test of its true capabilities, especially given claims of human-level or better emotional skills  (Elyoseph et al., 2023; MittelstÃ¤dt et al., 2024; Refoua, Meinlschmidt, and Elyoseph, 2024) .\n\nTo test RQ2, we implemented a plurality voting procedure for both human and GPT-4o conditions. This plurality voting involved creating groups of varying sizes (from n = 5 to n = 90) by randomly sampling participants from the human pool and independent GPT-4o instances from our multiple runs. We then examined each selected participant's or instance's independent response to determine the group's collective decision through plurality voting. Specifically, within each group, the emotion category that received the most votes became the collective decision of that group. For example, if 7 out of 10 respondents in a group (whether human or GPT-4o) selected \"jealous\" for a particular item, \"jealous\" was designated as that group's response. We repeated this process multiple times using random sampling, generating human and AI group decisions with different group sizes (see the Methods section for details). This aggregation procedure enables a direct comparison of human and AI crowds, revealing whether GPT-4o can reproduce the statistical processes that underpin the wisdom of the crowd.\n\nFinally, we investigate augmented intelligence by asking (RQ3) whether combining human and GPT-4o collective judgments yields superior performance to either crowd alone. This approach tests whether the complementary strengths of AI's computational abilities and human cognitive diversity can synergize to improve emotion recognition accuracy  (Dellermann et al., 2019) , moving beyond simple comparisons to explore genuine human-AI collaboration.\n\nAlthough valuable in some settings, direct human-machine interactions can suffer from human biases, such as algorithm aversion or overreliance on AI inputs, which may reduce rather than enhance collaborative performance  (Bansal et al., 2021; Prahl and Van Swol, 2017) . To circumvent these interaction biases, we aggregate independent human and AI predictions rather than having them interact directly, allowing each to contribute strengths without interference. We used a similar majority voting system as described previously. This independent aggregation design, particularly the use of plurality voting to create augmented intelligence, represents a novel approach to emotion recognition tasks that remains largely unexplored.\n\nTaken together, our study investigates three questions about GPT-4o's emotion recognition capabilities. (RQ1) Does GPT-4o consistently outperform humans at all skill levels, or only at specific points in the performance distribution? (RQ2) When both human and GPT-4o predictions are aggregated through plurality voting, which collective intelligence performs better? (RQ3) Can we achieve superior emotion recognition by combining human and GPT-4o crowd predictions into a unified augmented intelligence system?\n\nTo answer these questions, we follow prior work  (Strachan, Pansardi, et al., 2024)  that evaluates the emotion recognition skill of humans and LLMs with the Reading the Mind in the Eyes Test (RMET)  (Baron-Cohen et al., 2001)  and the Multiracial Reading the Mind in the Eyes Test (MRMET)  (Kim et al., 2024) .\n\nFor our analysis, we used publicly available human performance data from  Kim et al. (2024)  (N = 17,680 for RMET and N = 9,295 for MRMET) and generated GPT-4o responses via the API. We evaluated accuracy using mixed-effects logistic regression, shift function analyses, and stochastic dominance analyses, thereby capturing performance across the full range of abilities. To test augmented intelligence, we aggregated GPT-4o and human judgments via plurality voting and assessed whether the combined approach outperformed either source alone. Our research thus provides a test of GPT-4o's true emotion-recognition capabilities and the viability of AI-assisted collaboration.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Methods",
      "text": "",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Participants And Procedures",
      "text": "In this study, we used publicly available data from  Kim et al. (2024) , who collected 17,680 and 9,295 responses for the RMET and MRMET, respectively, and described original demographic information, recruitment methods, and consent information. For our study, we ran GPT-4o in February 2025 for 50 trials per condition (N = 50 for zero-shot; N = 50 for 10shot) with default settings. Following machine learning evaluation practices  (Brown et al., 2020) , we assessed the model under two prompting conditions: (a) zero-shot, to evaluate its baseline performance without examples, and (b) 10-shot, to test its optimal performance with them.\n\nIn the zero-shot condition, the model analyzed each image from the RMET and MRMET datasets. Each image included the instruction: \"Please pick the best possible answer that describes the emotion or mental state the person is experiencing from the following options.\" This zero-shot condition provided no examples or demonstrations, testing the model's baseline ability to infer emotion from pre-trained knowledge and generalization.\n\nIn contrast, the 10-shot condition evaluated the model's capacity for few-shot contextual learning. The model received ten examples of randomly selected images from the dataset, and each was paired with its corresponding ground-truth answer. This 10-shot approach investigated the model's ability to learn from a limited number of examples. We used 10-shot examples based on prior research showing that performance gains in few-shot settings often plateau after a small number of examples  (Brown et al., 2020; Wei et al., 2022) , and that too many examples can adversely affect the model's performance  (Min et al., 2022) .\n\nAs detailed in the Findings section, we later found no significant differences between the zero-shot and 10-shot conditions, so we combined these conditions in subsequent analyses. This pooling decision simplified interpretation and provided a comprehensive estimate of GPT-4o's performance, capturing the model's abilities from baseline to enhanced performance.\n\nWe ran the model with its default settings: a temperature of 1 and top-p (nucleus) sampling of 1. Sample size differences between human participants (17,680 for RMET and 9,295 for MRMET) and GPT-4o runs (50 for zero-shot and 50 for 10-shot) were addressed through statistical approaches. LLMs like GPT-4o have low variance between runs, showing consistency even with high temperature and top-p sampling  (Chang et al., 2023) , especially with multiple-choice options. Previous work  (Chen et al., 2024)  shows statistical performance gains for LLMs diminish sharply after a few runs, making large samples unnecessary. To account for the uneven sample sizes, we used mixed-effects models that adjust through partial pooling, allowing flexible group-size handling  (Pinheiro and Bates, 2000) . Thus, these sample size differences between conditions do not threaten our findings' validity or reliability.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Materials",
      "text": "To assess emotion recognition abilities, we employed two widely used and validated instruments. The Reading the Mind in the Eyes Test (RMET) is a validated test for inferring mental states and emotions  (Baron-Cohen et al., 2001) . It uses 36 black-and-white photographs of the eye region. Participants select from four options the label best describing the person's mental state. Applied across diverse populations, the RMET demonstrates adequate psychometric properties.\n\nThe Multiracial Reading the Mind in the Eyes Test (MRMET), a recently validated test  (Kim et al., 2024) , addresses RMET weaknesses, such as a lack of racial diversity and inaccessible vocabulary. It uses 37 high-resolution, color photographs with diverse participants. The MRMET demonstrates sufficient psychometric properties for emotion recognition tasks. For the validation studies, please refer to  Kim et al., 2024.  Finally, all statistical analyses were conducted using R version 4.3.2. GPT-4o data collection used Python 3.9 via the OpenAI API. Code and data are available upon request.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Analytical Strategy",
      "text": "",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Logistic Mixed-Effects Models.",
      "text": "To analyze these data and address our research questions, we employed four complementary statistical approaches. First, we used generalized linear mixed-effects models (GLMMs) with a logit link, as outcomes were binary (correct = 1 and incorrect = 0)  (Snijders and Bosker, 2012) . Our data had a nested structure. Test items were nested within participants, who were themselves nested within groups. GLMMs suit this structure, accounting for random effects at item and group levels. These models handle unbalanced designs, especially with 30+ observations per group  (Meteyard and Davies, 2020) .\n\nWe used random intercepts to model test items and participants, and fixed effects for group conditions (e.g., human, GPT-4o zero-shot, GPT-4o 10-shot). We used the human condition as the reference group. Given dataset size and potential convergence problems, we implemented maximum likelihood estimation with adaptive Gauss-Hermite quadrature. Models were fitted using the lme4 package with diagnostics for overdispersion and convergence. Model fit used likelihood ratio tests with ORs and 95% confidence intervals. Odds ratios were derived using the emmeans package. Odds ratios greater than 1 indicated higher accuracy than the reference human group. p-values were adjusted using Bonferroni corrections.\n\nBootstrap Shift-Function Test for Quantile Performance. Beyond mean comparisons, to analyze performance across quantiles, we used a bootstrap shift-function analysis with the \"rogme\" R package  (Rousselet, 2019) . This shift function shows differences between two distributions by comparing them at multiple quantiles, examining how one distribution shifts and changes across the other. We compared human and GPT-4o performance across quantiles ranging from 0.03 to 0.97, excluding extremes (0.01 and 0.99), where accuracy saturates at 0 or 1 due to ceiling effects. Given our finding of no significant differences between the zero-and 10-shot conditions through our GLMMs, we combined them to create a single GPT-4o condition. This pooling efficiently assesses the model's full range, from baseline performance to enhanced contextual learning.\n\nPerformance scores were calculated by averaging item accuracy per participant for humans and per trial for GPT-4o. For example, if someone predicts 35 of 36 RMET items correctly, accuracy equals 35/36 = 0.972. We used the Harrell-Davis quantile estimator. To assess between-group differences across distributions, we computed uncertainty intervals for each quantile comparison using percentile bootstrap techniques. This approach determined whether performance differences between humans and GPT-4o varied across performance segments, providing uncertainty estimates without parametric assumptions  (Wilcox, 2011) . We used Bonferroni corrections for multiple comparisons. Results were plotted as shift functions for each comparison, showing distributional differences across quantiles. Analyses were carried out independently for RMET and MRMET tasks.\n\nFirst and Second-Order Stochastic Dominance Tests. In addition to shift-function analysis, we conducted first-and second-order stochastic dominance analyses to assess distributions. These analyses compare entire performance spectra to determine whether one group systematically outperforms another at every accuracy threshold. Stochastic dominance analyses involve comparisons of entire distributions rather than sample characteristics like means or quantiles  (Davidson and Duclos 2000) ; for comprehensive reviews, see  (Whang 2019) . We used aggregated performance scores per participant and compared group conditions (human versus GPT-4o) as before.\n\nMore specifically, first-order stochastic dominance (FSD) exists when one distribution consistently offers higher probabilities of achieving values greater than or equal to any given level compared to another distribution. Formally, for cumulative distribution functions ð¹ ð´ (ð‘¥) and ð¹ ðµ (ð‘¥) of distributions ð´ and ðµ, ð´ exhibits FSD over ðµ if ð¹ ð´ (ð‘¥) â‰¤ ð¹ ðµ (ð‘¥) for all x, with strict inequality for at least one x. This implies that, at any performance threshold, the dominant distribution has a higher probability of surpassing that threshold. Second-order stochastic dominance (SSD) compares the overall shapes of two distributions, considering both their central tendencies and their spread (i.e., risk or variability). It extends FSD. Unlike FSD, which requires one cumulative distribution function, or CDF, to lie entirely below the other, SSD allows the CDFs to cross once or twice if the area under one remains smaller overall. Distribution A exhibits SSD over ðµ if\n\nfor all x, with strict inequality for at least one x. If ð´ shows SSD, it suggests more consistent and stable performance across various test items.\n\nWe used bootstrap with 2,000 replicates to calculate CDFs for both groups across all accuracy levels  (Wilcox 2011) . We tested dominance in both directions (AI over humans and humans over AI) where the null hypothesis posits that dominance exists. Critically, this reverses typical statistical interpretation: p-values > 0.05 support dominance by failing to reject the null, while p-values < 0.05 indicate dominance violations. Readers should note this inverted interpretation when evaluating our results. If AI demonstrated both FSD and SSD over the human condition, this indicates consistent AI superiority. Conversely, partial overlap or absent stochastic dominance suggests advantages only at specific segments, revealing performance consistency between conditions. Analyses were carried out for the RMET and MRMET tasks.\n\nPlurality Voting: Artificial, Collective, and Augmented Intelligence. Finally, to address our questions about collective and augmented intelligence, we analyzed accuracy at the group level for human groups, GPT-4o groups, and combined human-AI groups using a plurality voting procedure. This procedure creates \"crowds\" by aggregating individual responses at the group level, where the emotion category receiving the most votes becomes the collective decision. For human crowds, we randomly sampled participants from the total pool to form groups of varying sizes. We created groups containing 5 to 90 participants, with replacement across groups. For each test item, we counted how many individuals in the sampled group selected each emotion option, and the option with the most votes became that crowd's answer. For GPT-4o crowds, we applied the identical plurality voting method, collecting the model's responses from multiple independent runs and forming groups of the same size as the human condition. This parallel approach ensures that both human and AI crowds are formed through the same aggregation process.\n\nTo create the augmented intelligence (human + AI) crowds, we combined human and GPT-4o responses using the same plurality voting procedure. Given the larger human sample size, we used a stratified approach, sampling humans and GPT-4o responses at a 10:1 ratio to form mixed crowds with 90% human and 10% AI participants. For each test item, we counted votes from both human and AI participants together, and the emotion receiving the most votes became the augmented crowd's answer. In the case of a tie, we randomly selected one of the tied choices.\n\nTo compare group performance, we used GLMMs with a logit link as described above. These models included random intercepts for both test items and iteration, and fixed effects for group condition (human, GPT-4o, human + GPT-4o) and log-transformed group size. Log transformation accounted for diminishing returns in collective decisions  (Navajas et al., 2018; Peeters et al., 2021) . Separate analyses were performed for RMET and MRMET datasets, testing main effects and interactions. Marginal slopes used the emtrends function in emmeans, with interactions visualized via the interactions R package.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Results",
      "text": "",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Ai Outperformed Average Human Performance On Emotion Recognition Tasks",
      "text": "To address our first research question about performance across ability levels, we begin by examining overall performance differences between humans and GPT-4o. We evaluated human and GPT-4o performance differences using RMET and MRMET tasks. Descriptive statistics and average scores are presented in Table  1 . On the RMET, GPT-4o achieved 0.90 (SD = 0.03) (pooled across zero-shot and 10-shot conditions), outperforming the human average of 0.71 (SD = 0.14): 0.89 (zero-shot) and 0.91 (10-shot). On the MRMET, GPT-4o attained 0.83 (SD = 0.03) (pooled), surpassing the human average of 0.62 (SD = 0.13): 0.81 (zero-shot) and 0.85 (10-shot). While GPT-4o improved slightly with examples (10shot condition), these differences were not statistically significant (see Supplementary Table  S1-S2 ). Therefore, we combined zero-shot and 10-shot conditions in subsequent analyses, simplifying interpretation without losing significant information. for human participants represents individual participants, while for GPT-4o conditions, it represents the number of independent model iterations. Human participants completed all items in each test. GPT-4o models were tested in both zero-shot (no examples 6 provided) and 10-shot (10 examples provided) conditions. GPT-4o (Pooled) combines both zero-shot and 10-shot iterations (n = 100 total). Human data remains the same whether analyzed separately or pooled, as all participants completed the same task.\n\nWith the combined pooled results, we ran the rest of the analysis. Results from generalized linear mixedeffects models (GLMMs) show the observed differences were significant. Overall, GPT-4o achieved higher accuracy than humans on both RMET and MRMET, consistent with prior findings. Table  2  shows the results for the pooled GPT-4o analysis. On the RMET, GPT-4o showed significantly higher logodds than humans (Î² = 1.27, SE = 0.08, p < 0.001). On the MRMET, GPT-4o showed significantly higher log-odds than humans (Î² = 1.11, SE = 0.07, p < 0.001).\n\nFor separate zero-shot and 10-shot results, see Supplementary Table  S3 .\n\nAs such, the results show that, on average, GPT-4o was much more accurate than average human beings in both RMET and MRMET tests. However, average scores can obscure important differences in performance distributions across skill levels and are less likely to reveal whether GPT-4o can outperform the best-performing human groups. In our second analysis, we explore these questions. Notes. RMET = Reading the Mind in the Eyes Test; MRMET = Multiracial Reading the Mind in the Eyes Test. Both models were fit as generalized linear mixed models (GLMM) using the lme4 package in R, with a logit link function. Models were fit by maximum likelihood using adaptive Gauss-Hermite quadrature (nAGQ = 0) with crossed random intercepts for participant and item. Fixed effects estimates are presented on the log-odds scale; exponentiating these values yields odds ratios. SE refers to standard error. P-values were calculated using Satterthwaite's method for denominator degrees of freedom approximation through the lmerTest package, with Î± = 0.05. Human performance serves as the reference group for all comparisons (Intercept). The GPT-4o (Pooled) parameter represents the pooled effect of both zero-shot and 10-shot conditions, which was statistically justified through model comparison (see Table  6 ). Random effects are reported as variances and their standard deviations, representing the unexplained variation at the participant and item levels. AIC (Akaike Information Criterion) and BIC (Bayesian Information Criterion) provide measures of model fit, with smaller values indicating better fit. Log Likelihood represents the logarithm of the model's likelihood function at convergence. Both models showed successful convergence with no warnings or errors",
      "page_start": 6,
      "page_end": 10
    },
    {
      "section_name": "Ai Outperform Human Performance Across Low-, Medium-, And High-Performing Group Levels",
      "text": "Moving beyond averages to address our first research question more fully, we examined performance differences across ability levels. We conducted a shift-function analysis with bootstrap resampling, comparing AI and human performance distributions across quantiles. Figure  1  shows these differences across the quantiles.\n\nTable  3  presents quantile-specific comparisons between GPT-4o and humans, employing the Harrell-Davis quantile estimator and percentile bootstrap. Reported differences represent Î” GPT-4o -Human quantile estimates, where positive values indicate higher accuracy for GPT-4o. The analysis revealed that GPT-4o showed higher accuracy than humans across the entire performance spectrum. Notably, the magnitude of this advantage varied systematically across ability levels. This table presents the shift function results comparing the GPT-4o condition to the Human condition across multiple quantiles in the RMET dataset. The shift function was generated using the Harrell-Davis quantile estimator and a percentile bootstrap approach (bootstrapped 100 times), which provides confidence intervals derived from the bootstrapped quantiles rather than from the standard errors of the difference. The Difference column reflects GPT-4o minus Human quantile estimates; positive values indicate that the GPT-4o distribution is shifted toward higher values compared to Human. Quantiles range from 0.03 to 0.97. All p-values were computed via percentile bootstrap and corrected for multiple comparisons using the Bonferroni method. Human serves as the reference group. The mean difference across all quantiles is 0.19.\n\nOn the RMET, accuracy differences were most pronounced at lower quantiles (Î” GPT-4o -Human = 0.40 at the 0.03 quantile), indicating that GPT-4o performs substantially better than humans with lower emotion recognition abilities (Table  3 ). While the difference decreases at higher quantiles, GPT-4o maintains significantly higher accuracy even at the 0.97 quantile (Î” GPT-4o -Human = 0.04, p < 0.001). This pattern suggests GPT-4o consistently outperforms humans across all levels, with the largest gap among lower-performing individuals, gradually diminishing toward higher-performing ones. The mean Î” GPT-4o -Human across all quantiles was 0.19. This pattern held for the MRMET, where GPT-4o again showed the largest differences at lower quantiles (Î” GPT-4o -Human = 0.38 at the 0.03 quantile) (Table  3 ). As with the RMET, these differences decreased at higher quantiles but remained significant throughout (p < 0.001 for all quantiles), including at the 0.97 quantile (Î” GPT-4o -Human = 0.05, p < 0.001). This consistent pattern reinforces that GPT-4o's advantage is most notable among lowerperforming individuals, with differences narrowing among high-performing participants. The mean Î” GPT-4o -Human across all quantiles was 0.20.\n\nFigure  1  presents three complementary visualizations for both RMET and MRMET. Panels A and D show box plots of accuracy distributions for humans and GPT-4o, with quantile-based sampling applied to accommodate large sample sizes. Panels B and E display violin plots illustrating density estimates of accuracy, with vertical lines marking quantiles from 0.03 to 0.97 (thicker lines indicate medians). Panels C and F present shift-function plots comparing GPT-4o and human accuracy differences (Î” GPT-4o -Human) across quantiles, with 95% bootstrap confidence intervals shown as vertical lines. These visualizations confirm that GPT-4o's advantage is most pronounced among lower-performing individuals and gradually diminishes, though remains significant, at higher performance levels. To further establish this performance advantage across entire distributions, we next employed stochastic dominance tests. The vertical axes show the mean differences in accuracy for each quantile, with 95% bootstrap confidence intervals displayed as vertical lines. Confidence intervals that do not include zero indicate statistically significant differences. For both datasets, AI consistently outperforms Humans across all quantiles, but the effect size diminishes as quantiles increase. This pattern suggests a larger performance gap between lower-performing Humans and AI, while the gap between top-performing Humans and AI narrows.",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Ai Exhibits Stochastic Dominance Over Humans In Emotion Recognition",
      "text": "To further test whether GPT-4o's advantage holds across the entire performance spectrum, we conducted first-order stochastic dominance (FSD) and secondorder stochastic dominance (SSD) tests comparing the distributions of GPT-4o and humans on both RMET and MRMET. Importantly, in both FSD and SSD tests, the null hypothesis states that one distribution dominates the other; thus, rejecting the null hypothesis indicates no evidence of dominance, while failing to reject it supports dominance. This interpretation reverses the typical statistical logic. In other words, to find evidence that one distribution stochastically dominates another, we seek p-values larger than 0.05 (i.e., we fail to reject the null), not smaller. Figure  2  visualizes these dominance results for both datasets.\n\nFor the RMET, the FSD test compared cumulative distribution functions (CDFs) of GPT-4o and humans. Testing whether humans dominated GPT-4o yielded Tobs = 10.29 (p < 0.001), rejecting human stochastic dominance. Testing whether GPT-4o dominated humans yielded Tobs = 0.01 (p = 0.89), implying GPT-4o's stochastic dominance (Supplementary Table  S4 ). These results confirm GPT-4o demonstrated firstorder stochastic dominance. In practical terms, at any accuracy level, GPT-4o has a higher probability of achieving that level or above than humans.\n\nThe SSD test further confirmed this pattern, rejecting human dominance over GPT-4o (Tobs = 184.77, p < 0.001) while implying GPT-4o dominance over humans (Tobs = 0.00, p = 0.91) (Supplementary Table  S4 ). This finding indicates GPT-4o achieved higher overall accuracy while maintaining greater consistency across different test items.\n\nThe MRMET results paralleled those of the RMET, demonstrating performance differences favoring GPT-4o. The FSD test rejected human dominance (Tobs = 7.93, p < 0.001) while failing to reject GPT-4o dominance (Tobs = 0.01, p = 0.86) (Supplementary Table  S4 ). The SSD test similarly rejected human dominance (Tobs = 69.94, p < 0.001) while failing to reject GPT-4o dominance (Tobs = 0.00, p = 0.88) (Supplementary Table  S4 ). Thus, GPT-4o's better performance on the MRMET also spans the entire distribution.\n\nThese results collectively demonstrate that GPT-4o achieved both first-and second-order stochastic dominance on both RMET and MRMET. For any accuracy threshold, GPT-4o consistently has a higher probability of achieving that threshold or higher than humans. Second-order dominance further reveals both higher accuracy and greater stability across test items. Having established GPT-4o's individual superiority across the full performance spectrum, we now turn to our second research question: how does collective intelligence change these dynamics?",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Figure 2. First And Second-Order Stochastic Dominance",
      "text": "Notes. We examined whether the AI accuracy distribution first-order (Panels A and C) and second-order (Panels B and D) stochastically dominates the Human accuracy distribution in both the RMET and MRET datasets. In all cases, the AI group combines zero-shot and n-shot trials due to the absence of significant differences between them. Panel A and C show the firstorder dominance test results. We tested the null hypothesis that the AI accuracy distribution first-order dominates the Human accuracy distribution. This was done by comparing the empirical cumulative distribution functions (CDFs) of accuracy scores for AI (blue) and Humans (red). For the RMET dataset (Panel A), the test yielded a T-statistic of 0.014 and a p-value of 0.995, while for the MRET dataset (Panel C), the T-statistic was 0.013 and the p-value was 0.995. In both cases, we failed to reject the null hypothesis, indicating that no statistically significant evidence was found to suggest that AI violates first-order dominance. These findings suggest that the data are consistent with AI outperforming Humans under the first-order dominance criterion. Panels B and D show the second-order dominance test results. We tested whether the AI accuracy distribution second-order dominates the Human accuracy distribution by evaluating cumulative differences in the CDFs (AI minus Human) across accuracy thresholds. For the RMET dataset (Panel B), the test yielded a T-statistic of -0.001 and a p-value of 0.923, while for the MRET (Panel D), the T-statistic was -0.002 and the p-value was 0.907. Again, we failed to reject the null hypothesis in both datasets, indicating that no statistically significant evidence was found to suggest that AI violates second-order dominance. As with the first-order results, these findings imply that AI performance is consistent with outperforming Humans under the second-order dominance criterion.",
      "page_start": 9,
      "page_end": 10
    },
    {
      "section_name": "Collective Intelligence: Aggregated Human Decisions Outperform Gpt-4O In Emotion Recognition",
      "text": "To address our second research question, we examined whether GPT-4o can match or surpass the \"wisdom of crowds\" in humans when aggregating judgments through plurality voting. We formed GPT-4o crowds by aggregating responses from multiple independent runs and formed human crowds by randomly sampling participants, creating groups ranging from 5 to 90 members. Accuracy was assessed via generalized linear mixed-effects models (GLMMs), with fixed effects for condition (human as reference, GPT-4o, human + GPT-4o) and logtransformed group size, including their interaction. Random intercepts accounted for test items and iterations. Separate models were fitted for RMET and MRMET datasets. Note. RMET = Reading the Mind in the Eyes Test; MRMET = Multiracial Reading the Mind in the Eyes Test. Both models were fit as generalized linear mixed models (GLMM) using the lme4 package in R, with a logit link function and binomial family distribution. Models were fit by maximum likelihood using adaptive Gauss-Hermite quadrature (nAGQ = 0) with crossed random intercepts for participant and item. Fixed-effects estimates are presented on the log-odds scale. SE refers to standard error. Human performance serves as the reference group for all comparisons (Intercept). The Logâ‚â‚€ Group Size variable represents the base-10 logarithm of aggregation size in plurality voting. Interaction terms (Ã—) indicate how the effect of group size differs across conditions. Random effects are reported as variances and their standard deviations. AIC = Akaike Information Criterion; BIC = Bayesian Information Criterion. Both models showed successful convergence with no warnings or errors.\n\nTable  4  presents the GLMM fixed effects for both tasks. On the RMET, the intercept (human baseline) was significant (Î² = 0.87, SE = 0.20, p < 0.001), with GPT-4o showing higher baseline log-odds (Î² = 1.92, SE = 0.07, p < 0.001) but a strongly negative interaction with log-group size (Î² = -3.73, SE = 0.07, p < 0.001), indicating minimal scaling benefits for AI crowds. The main effect of log-group size was positive and substantial for humans (Î² = 3.99, SE = 0.06, p < 0.001). Estimates are derived from generalized linear mixed models. For Marginal Probabilities, estimates represent the predicted probability of correct responses for each condition, where SE = Standard Error and CI = Confidence Interval. All probabilities and confidence intervals are back-transformed from the logit scale. For Contrasts, odds ratios compare relative performance between conditions, where values greater than 1 indicate higher odds of correct responses for the first group in the contrast. All contrasts were significant at p < 0.001 (Bonferroni-adjusted for multiple comparisons). The Human + GPT-4o condition showed the highest predicted accuracy in both datasets, with more pronounced differences in the RMET dataset compared to MRMET.\n\nTable  5  shows the marginal probabilities and odds ratio analysis. It revealed near-ceiling accuracy for human crowds (0.998, 95% CI [0.998, 0.999]) but lower for GPT-4o crowds (0.959, 95% CI [0.940, 0.971]). Odds ratios confirmed humans outperformed GPT-4o (OR = 26.01, p < 0.001). Slope analysis (Supplementary Table  S7 ) underscored this pattern, showing that human crowds improved steeply with size (slope = 3.99, 95%  CI [3.87, 4 .10]), while GPT-4o showed limited gains (slope = 0.25, 95%  CI [0.19, 0.32] ).\n\nOn the MRMET, patterns were similar but with attenuated effects. The human baseline was significant (Î² = 1.20, SE = 0.30, p < 0.001), with GPT-4o again showing higher initial log-odds (Î² = 1.36, SE = 0.05, p < 0.001) but a negative interaction (Î² = -1.47, SE = 0.04, p < 0.001). Log-group size benefited humans (Î² = 1.42, SE = 0.03, p < 0.001; Table  4 ). Table  5  shows that marginal probabilities indicated human accuracy at 0.960 (95% CI [0.930, 0.977]), and GPT-4o at 0.924  (95% CI [0.872, 0.956] ). Human crowds outperformed GPT-4o crowds (OR = 1.95, p < 0.001). Slope analysis (Supplementary Table  S7 ) revealed human gains  (1.42, 95% CI [1.37, 1.47] ) but near-zero or slightly negative slopes for GPT-4o (-0.04, 95% CI [-0.09, 0.01]), suggesting aggregation may even reinforce errors in GPT-4o's predictions.\n\nFigure  3  visualizes marginal trends by condition and group size for both tasks, illustrating how human crowds scale effectively while GPT-4o crowds plateau or decline slightly. These findings indicate that, despite GPT-4o's performance, its collective intelligence does not match human crowds, particularly as group size increases. The limited diversity in AI instances likely constrains the errorcanceling benefits of aggregation, unlike the varied perspectives in human groups.",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Augmented Intelligence: Combining Human And Ai Leads To Optimal Performance In Emotion Recognition",
      "text": "Our third research question investigated whether augmented crowds, formed by combining independent human and GPT-4o votes at a 10:1 ratio, outperform human-only or GPT-4o-only crowds. Using the same plurality voting and generalized linear mixed-effects model (GLMM) framework, we included the human + GPT-4o condition in the models.\n\nAs shown in Table  4 , on the RMET, the augmented intelligence (human + GPT-4o) condition had a non-significant baseline (Î² = 0.04, SE = 0.06, p = 0.511) but a positive interaction with log-group size (Î² = 0.25, SE = 0.08, p = 0.002), enhancing scaling beyond humans alone. In Table  5 , marginal probabilities analysis confirmed the highest accuracy for augmented crowds (0.999, 95% CI [0.998, 0.999]), surpassing humans (OR = 1.47, p < 0.001, inverse of 0.68) and GPT-4o (OR = 38.17, p < 0.001, inverse of 0.03). Supplementary Table  S7  shows the trend slope was steepest for augmented groups  (4.23, 95% CI [4.13, 4.34] ), compared to humans (3.99) and .\n\nFor the MRMET, augmented intelligence showed a positive baseline (Î² = 0.11, SE = 0.05, p = 0.030) and interaction (Î² = 0.17, SE = 0.03, p < 0.001) in Table  4 . In Table  5 , marginal probabilities yielded an accuracy of 0.971 (95% CI [0.949, 0.984]), outperforming humans (OR = 1.41, p < 0.001, inverse of 0.71) and GPT-4o (OR = 2.76, p < 0.001, inverse of 0.36). Supplementary Table  S7  shows that trend slopes were highest for augmented (1.59, 95% CI [1.55, 1.64]), versus humans (1.42) and GPT-4o (-0.04).\n\nFigure  3  further depicts these interactions, showing augmented crowds consistently achieving the greatest improvements with scale on both tasks. These results affirm RQ3, showing that augmented intelligence synergistically leverages human diversity and AI consistency, yielding superior emotion recognition without direct interaction.",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Discussion",
      "text": "Our findings addressing the three research questions yield critical insights for understanding AI emotion recognition capabilities and limitations. First, GPT-4o exceeded human performance at all levels on RMET and MRMET, surpassing every performance group from the 3rd to 97th percentiles with first-and second-order stochastic dominance, confirming prior findings  (Strachan, Albergo, et al., 2024; Tamkin et al., 2021) . Second, aggregating judgments via plurality voting revealed a striking reversal: human crowds achieved dramatic accuracy improvements while GPT-4o crowds showed minimal gains. Third, augmented intelligence, which combines human cognitive diversity with GPT-4o's computational consistency, produced the highest accuracy, supporting ensemble-learning theory that uncorrelated classifiers surpass either alone  (Domingos, 2000) . These findings illuminate both AI capabilities and enduring human advantages. We discuss each finding's implications and limitations below.\n\nThe first finding of GPT-4o's individual superiority warrants careful interpretation. While one might interpret GPT-4o's performance advantage as demonstrating AI's superior emotion recognition, we believe it reveals as much about these standardized tests' limitations as it does about what AI can do. One such limitation is dataset contamination: GPT-4o might have been trained on these test items. Although GPT-4o's training corpus is proprietary, widely distributed RMET items likely appeared in pretraining data. The newer MRMET (released after GPT-4o's 2024 cut-off) had limited distribution, making contamination unlikely and suggesting genuine performance rather than memorization.\n\nFurthermore, the magnitude of GPT-4o's advantage reveals important nuances. Accuracy differences between GPT-4o and humans varied systematically across ability levels. GPT-4o had large advantages over lower performers but modest advantages over higher performers. The advantage was 24% at the 10 th percentile and 6% at the 97 th for RMET; 27% and 5% for MRMET. This narrowing does not mean AI and human experts are equally skilled. Instead, it reflects a ceiling effect: when both score near 100%, tests cannot measure remaining differences. Expert humans may still possess finer abilities these tests cannot detect. Thus, our results speak to performance on standardized, static images, not naturalistic emotion recognition tasks where GPT-4o and human experts likely diverge significantly in their ability. These performance patterns have direct practical implications.\n\nThese nuanced performance differences provide preliminary guidance on the specific conditions under which GPT-4o can add incremental value alongside human judgment. In applied contexts, organizations and users might leverage AI for standardized, highthroughput screening in low-stakes conditions, reserving human expertise for ambiguous, contextdependent judgments that demand broader social understanding. However, this individual-level guidance changes dramatically when considering collective intelligence.\n\nOur second finding addresses Research Question 2 about collective intelligence, revealing a striking reversal. When aggregating judgments via plurality voting, human crowds improved dramatically from 0.70 to perfect accuracy as groups grew, while GPT-4o crowds stagnated at 90-93%. The improvement rates, specifically 3.98 for humans versus 0.27 for GPT-4o, demonstrate clear collective human advantage. This reversal from individual AI superiority to collective human advantage demands explanation.\n\nThis collective advantage stems from a fundamental difference in how diversity emerges. Human crowds embody cognitive diversity from varied backgrounds and perspectives. Aggregating diverse perspectives cancels individual errors, creating stronger collective judgments. In contrast, GPT-4o showed no aggregation benefit. While temperature adjustments or alternative prompting could add diversity, these degrade real-world performance through reduced coherence  (Peeperkorn et al., 2024) . Remarkably, across all test items, the model's choices remained consistent regardless of sampling frequency. Each API call processes information through the same architecture and weights, yielding identical error patterns. Whereas humans generate varied predictions, GPT-4o produces uniform responses. Simply stated, repeated GPT-4o sampling resembles asking one person repeatedly, not polling a crowd. Consequently, aggregating GPT-4o responses reinforces rather than eliminates errors. Therefore, the wisdom of one AI differs fundamentally from the wisdom of many humans. This fundamental difference has critical implications for deployment decisions.\n\nThe wisdom-of-crowds advantage has critical practical implications for high-stakes applications. Human crowds remain indispensable for high-stakes emotion recognition tasks, despite requiring more resources and coordination. While it's efficient to deploy GPT-4o for large-scale emotion screening in low-stakes conditions, our results indicate we must prioritize human collective judgment when accuracy is vital, such as in clinical diagnoses, security screenings, or conflict mediations. The gap between human and AI collective judgments shows GPT-4o would misinterpret about 7% of emotional expressions. In these contexts, one misstep from AI could cause wrong diagnoses, miss security threats, or escalate conflicts. A single error could be costly. When deciding between humans or AI, organizations must consider whether they can accept any avoidable error. Given these constraints, a natural question emerges: can we achieve better performance by combining AI efficiency with human understanding?\n\nThis question leads to our third finding about augmented intelligence, which provides an affirmative answer. Augmented intelligence, created by combining human and AI judgments, achieved nearperfect accuracy (100% for RMET and 95% for MRMET). Its improvement rate as groups grew surpassed both human and AI conditions. While human-only crowds improved from 70% to 100% as group size increased, and GPT-4o crowds stagnated at 90-93%, augmented intelligence reached perfect accuracy using smaller group sizes. This superior performance emerges from complementary strengths.\n\nThis synergy emerges from a crucial complementarity between human and AI capabilities. Humans provide cognitive diversity, reducing unsystematic and uncorrelated errors. AI provides a consistent base level that corrects a group's typical mean accuracy. Keeping humans and GPT-4o independent in this process prevented humans from introducing errors and biases in the selection process and GPT-4o from causing overreliance. These two forms of intelligence, each bringing unique strengths and limitations, create through their augmentation emergent capabilities beyond what any single system can achieve. This aligns with distributed cognition theories  (Hutchins, 1995) , suggesting optimal emotion recognition requires collaboration between AI and human intelligence, distributed and combined independently. These findings point toward practical applications.\n\nThese findings point toward a new paradigm for intelligent systems development, one that favors augmentation and collaboration rather than replacement. Instead of developing fully autonomous AI that replaces human expertise, the target could be teams where AI is a critical member. Research shows that when humans and AI interact directly, performance degrades due to biases or cognitive shortcuts: cognitive offloading from over-relying on AI recommendations or algorithmic aversion bias from rejecting AI input. These established challenges in human-AI collaboration appear in medical diagnoses  (Goh et al., 2024) , education  (Kim, 2024) , and workplaces  (Meng et al., 2025) . Our research proposes an alternative approach: collecting independent judgments from human and AI and aggregating them through plurality voting proves more effective. Researchers might explore alternative ways to blend human and AI intelligence, including dynamic weighting schemes, hybrid committees with multiple AI models, and other strategies for augmented intelligence. This paradigm shift fundamentally reframes our approach to emotional AI.\n\nTaken together, our three findings reveal a critical distinction in the current state of emotion recognition with AI. While GPT-4o's accuracy on standardized tests surpasses that of any individual, it cannot match the collective wisdom that emerges from diverse human crowds. The most promising path forward, however, is not a choice between human intuition and machine logic. Our findings conclusively show that an augmented intelligence strategy, which synergistically combines human and AI judgments, achieves a level of accuracy that neither can reach alone. This synergy capitalizes on both AI's consistent analytical rigor and humanity's collective emotional diversity. This understanding points to a clear directive for the future of affective computing. The objective should not be to build autonomous systems that supplant human insight, but to architect collaborative tools that amplify it. Ultimately, the development of truly effective and trustworthy emotional AI hinges on a paradigm shift, away from creating silicon minds that compete with us, and toward designing systems that enhance our collective human heart.",
      "page_start": 13,
      "page_end": 13
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: shows these",
      "page": 6
    },
    {
      "caption": "Figure 1: Performance and Distributional Difference between AI and Human in Emotional",
      "page": 8
    },
    {
      "caption": "Figure 2: visualizes these dominance results for both datasets.",
      "page": 9
    },
    {
      "caption": "Figure 2: First and Second-Order Stochastic Dominance",
      "page": 9
    },
    {
      "caption": "Figure 3: visualizes marginal trends by condition",
      "page": 11
    },
    {
      "caption": "Figure 3: further depicts these interactions,",
      "page": 12
    },
    {
      "caption": "Figure 3: Artificial, Collective, Augmented Intelligence",
      "page": 12
    },
    {
      "caption": "Figure 3: illustrates how accuracy improves with larger group sizes (on a logâ‚â‚€ scale) across three conditionsâ€”",
      "page": 12
    }
  ],
  "tables": [
    {
      "caption": "Table 1: On the RMET, GPT-",
      "data": [
        {
          "Dataset": "RMET",
          "Model": "Human",
          "Mean Accuracy": "0.71",
          "Standard Deviation": "0.14",
          "Max Accuracy": "1.00",
          "Min Accuracy": "0.11",
          "Sample Size (n)": "17,680"
        },
        {
          "Dataset": "",
          "Model": "GPT-4o (Pooled)",
          "Mean Accuracy": "0.90",
          "Standard Deviation": "0.03",
          "Max Accuracy": "0.97",
          "Min Accuracy": "0.84",
          "Sample Size (n)": "100"
        },
        {
          "Dataset": "",
          "Model": "GPT-4o (Zero-shot)",
          "Mean Accuracy": "0.89",
          "Standard Deviation": "0.03",
          "Max Accuracy": "0.95",
          "Min Accuracy": "0.84",
          "Sample Size (n)": "50"
        },
        {
          "Dataset": "",
          "Model": "GPT-4o (10-shot)",
          "Mean Accuracy": "0.91",
          "Standard Deviation": "0.03",
          "Max Accuracy": "0.97",
          "Min Accuracy": "0.86",
          "Sample Size (n)": "50"
        },
        {
          "Dataset": "MRMET",
          "Model": "Human",
          "Mean Accuracy": "0.62",
          "Standard Deviation": "0.13",
          "Max Accuracy": "0.97",
          "Min Accuracy": "0.03",
          "Sample Size (n)": "9,295"
        },
        {
          "Dataset": "",
          "Model": "GPT-4o (Pooled)",
          "Mean Accuracy": "0.83",
          "Standard Deviation": "0.03",
          "Max Accuracy": "0.92",
          "Min Accuracy": "0.74",
          "Sample Size (n)": "100"
        },
        {
          "Dataset": "",
          "Model": "GPT-4o (Zero-shot)",
          "Mean Accuracy": "0.81",
          "Standard Deviation": "0.02",
          "Max Accuracy": "0.84",
          "Min Accuracy": "0.76",
          "Sample Size (n)": "50"
        },
        {
          "Dataset": "",
          "Model": "GPT-4o (10-shot)",
          "Mean Accuracy": "0.85",
          "Standard Deviation": "0.03",
          "Max Accuracy": "0.92",
          "Min Accuracy": "0.74",
          "Sample Size (n)": "50"
        }
      ],
      "page": 5
    },
    {
      "caption": "Table 2: average scores can obscure important differences in",
      "data": [
        {
          "Parameter": "",
          "RMET": "Estimate",
          "MRMET": "Estimate"
        },
        {
          "Parameter": "Fixed Effects",
          "RMET": "",
          "MRMET": ""
        },
        {
          "Parameter": "(Intercept)",
          "RMET": "0.96",
          "MRMET": "0.69"
        },
        {
          "Parameter": "GPT-4o",
          "RMET": "1.27",
          "MRMET": "1.11"
        },
        {
          "Parameter": "Random Effects",
          "RMET": "",
          "MRMET": ""
        },
        {
          "Parameter": "Participant Variance",
          "RMET": "0.39",
          "MRMET": "0.34"
        },
        {
          "Parameter": "Participant Std Dev",
          "RMET": "0.62",
          "MRMET": "0.59"
        },
        {
          "Parameter": "Item Variance",
          "RMET": "0.21",
          "MRMET": "0.88"
        },
        {
          "Parameter": "Item Std Dev",
          "RMET": "0.46",
          "MRMET": "0.94"
        },
        {
          "Parameter": "Model Information",
          "RMET": "",
          "MRMET": ""
        },
        {
          "Parameter": "Observations",
          "RMET": "640,080",
          "MRMET": "347,615"
        },
        {
          "Parameter": "Number of Participants",
          "RMET": "17,780",
          "MRMET": "9,395"
        },
        {
          "Parameter": "Number of Items",
          "RMET": "36",
          "MRMET": "37"
        },
        {
          "Parameter": "AIC",
          "RMET": "729,232.50",
          "MRMET": "395,826.00"
        },
        {
          "Parameter": "BIC",
          "RMET": "729,277.90",
          "MRMET": "395,869.00"
        },
        {
          "Parameter": "Log Likelihood",
          "RMET": "-364,612.20",
          "MRMET": "-197,909.00"
        }
      ],
      "page": 6
    },
    {
      "caption": "Table 3: Quantile Comparison of Results with Shift Function",
      "data": [
        {
          "Dataset": "RMET",
          "Quantile": "0.03",
          "GPT-4o": "0.77",
          "Human": "0.38",
          "Difference": "0.40",
          "95% CI Lower": "0.38",
          "95% CI Upper": "0.41",
          "p": "p < 0.001",
          "Adjusted p": "p < 0.001"
        },
        {
          "Dataset": "",
          "Quantile": "0.05",
          "GPT-4o": "0.78",
          "Human": "0.42",
          "Difference": "0.37",
          "95% CI Lower": "0.35",
          "95% CI Upper": "0.38",
          "p": "p < 0.001",
          "Adjusted p": "p < 0.001"
        },
        {
          "Dataset": "",
          "Quantile": "0.10",
          "GPT-4o": "0.80",
          "Human": "0.49",
          "Difference": "0.31",
          "95% CI Lower": "0.30",
          "95% CI Upper": "0.32",
          "p": "p < 0.001",
          "Adjusted p": "p < 0.001"
        },
        {
          "Dataset": "",
          "Quantile": "0.25",
          "GPT-4o": "0.82",
          "Human": "0.59",
          "Difference": "0.22",
          "95% CI Lower": "0.22",
          "95% CI Upper": "0.24",
          "p": "p < 0.001",
          "Adjusted p": "p < 0.001"
        },
        {
          "Dataset": "",
          "Quantile": "0.50",
          "GPT-4o": "0.86",
          "Human": "0.69",
          "Difference": "0.17",
          "95% CI Lower": "0.15",
          "95% CI Upper": "0.17",
          "p": "p < 0.001",
          "Adjusted p": "p < 0.001"
        },
        {
          "Dataset": "",
          "Quantile": "0.75",
          "GPT-4o": "0.89",
          "Human": "0.78",
          "Difference": "0.11",
          "95% CI Lower": "0.11",
          "95% CI Upper": "0.13",
          "p": "p < 0.001",
          "Adjusted p": "p < 0.001"
        },
        {
          "Dataset": "",
          "Quantile": "0.90",
          "GPT-4o": "0.92",
          "Human": "0.86",
          "Difference": "0.06",
          "95% CI Lower": "0.06",
          "95% CI Upper": "0.07",
          "p": "p < 0.001",
          "Adjusted p": "p < 0.001"
        },
        {
          "Dataset": "",
          "Quantile": "0.95",
          "GPT-4o": "0.93",
          "Human": "0.89",
          "Difference": "0.04",
          "95% CI Lower": "0.03",
          "95% CI Upper": "0.06",
          "p": "p < 0.001",
          "Adjusted p": "p < 0.001"
        },
        {
          "Dataset": "",
          "Quantile": "0.97",
          "GPT-4o": "0.94",
          "Human": "0.91",
          "Difference": "0.04",
          "95% CI Lower": "0.01",
          "95% CI Upper": "0.06",
          "p": "p < 0.001",
          "Adjusted p": "p < 0.001"
        },
        {
          "Dataset": "Dataset",
          "Quantile": "Quantile",
          "GPT-4o": "GPT-4o",
          "Human": "Human",
          "Difference": "Difference",
          "95% CI Lower": "95% CI Lower",
          "95% CI Upper": "95% CI Upper",
          "p": "p",
          "Adjusted p": "Adjusted p"
        },
        {
          "Dataset": "MRET",
          "Quantile": "0.03",
          "GPT-4o": "0.76",
          "Human": "0.38",
          "Difference": "0.38",
          "95% CI Lower": "0.36",
          "95% CI Upper": "0.41",
          "p": "p < 0.001",
          "Adjusted p": "p < 0.001"
        },
        {
          "Dataset": "",
          "Quantile": "0.05",
          "GPT-4o": "0.77",
          "Human": "0.41",
          "Difference": "0.36",
          "95% CI Lower": "0.35",
          "95% CI Upper": "0.38",
          "p": "p < 0.001",
          "Adjusted p": "p < 0.001"
        },
        {
          "Dataset": "",
          "Quantile": "0.10",
          "GPT-4o": "0.78",
          "Human": "0.46",
          "Difference": "0.32",
          "95% CI Lower": "0.31",
          "95% CI Upper": "0.33",
          "p": "p < 0.001",
          "Adjusted p": "p < 0.001"
        },
        {
          "Dataset": "",
          "Quantile": "0.25",
          "GPT-4o": "0.81",
          "Human": "0.54",
          "Difference": "0.27",
          "95% CI Lower": "0.25",
          "95% CI Upper": "0.27",
          "p": "p < 0.001",
          "Adjusted p": "p < 0.001"
        },
        {
          "Dataset": "",
          "Quantile": "0.50",
          "GPT-4o": "0.82",
          "Human": "0.65",
          "Difference": "0.17",
          "95% CI Lower": "0.16",
          "95% CI Upper": "0.19",
          "p": "p < 0.001",
          "Adjusted p": "p < 0.001"
        },
        {
          "Dataset": "",
          "Quantile": "0.75",
          "GPT-4o": "0.84",
          "Human": "0.73",
          "Difference": "0.11",
          "95% CI Lower": "0.11",
          "95% CI Upper": "0.13",
          "p": "p < 0.001",
          "Adjusted p": "p < 0.001"
        },
        {
          "Dataset": "",
          "Quantile": "0.90",
          "GPT-4o": "0.87",
          "Human": "0.80",
          "Difference": "0.07",
          "95% CI Lower": "0.04",
          "95% CI Upper": "0.09",
          "p": "p < 0.001",
          "Adjusted p": "p < 0.001"
        },
        {
          "Dataset": "",
          "Quantile": "0.95",
          "GPT-4o": "0.88",
          "Human": "0.84",
          "Difference": "0.04",
          "95% CI Lower": "0.03",
          "95% CI Upper": "0.07",
          "p": "p < 0.001",
          "Adjusted p": "p < 0.001"
        },
        {
          "Dataset": "",
          "Quantile": "0.97",
          "GPT-4o": "0.90",
          "Human": "0.85",
          "Difference": "0.05",
          "95% CI Lower": "0.01",
          "95% CI Upper": "0.07",
          "p": "p < 0.001",
          "Adjusted p": "p < 0.001"
        }
      ],
      "page": 7
    },
    {
      "caption": "Table 4: Mixed-Effects Logistic Regression Results for Collective and Augmented Intelligence",
      "data": [
        {
          "Model Information": "Fixed Effects",
          "RMET": "Estimate",
          "MRMET": "Estimate"
        },
        {
          "Model Information": "(Intercept-Human Crowd)",
          "RMET": "0.87",
          "MRMET": "1.20"
        },
        {
          "Model Information": "GPT-4o Crowd",
          "RMET": "1.92",
          "MRMET": "1.36"
        },
        {
          "Model Information": "Augmented Intelligence",
          "RMET": "0.04",
          "MRMET": "0.11"
        },
        {
          "Model Information": "Logâ‚â‚€ Group Size",
          "RMET": "3.99",
          "MRMET": "1.42"
        },
        {
          "Model Information": "GPT-4o Crowd Ã— Logâ‚â‚€ Group Size",
          "RMET": "-3.73",
          "MRMET": "-1.47"
        },
        {
          "Model Information": "Augmented Intelligence Ã— Logâ‚â‚€ Group Size",
          "RMET": "0.25",
          "MRMET": "0.17"
        },
        {
          "Model Information": "Random Effects",
          "RMET": "",
          "MRMET": ""
        },
        {
          "Model Information": "Participant Variance",
          "RMET": "0.26",
          "MRMET": "0.19"
        },
        {
          "Model Information": "Participant SD",
          "RMET": "0.51",
          "MRMET": "0.44"
        },
        {
          "Model Information": "Item Variance",
          "RMET": "1.37",
          "MRMET": "3.27"
        },
        {
          "Model Information": "Item SD",
          "RMET": "1.17",
          "MRMET": "1.81"
        },
        {
          "Model Information": "Model Information",
          "RMET": "",
          "MRMET": ""
        },
        {
          "Model Information": "Observations",
          "RMET": "316,800",
          "MRMET": "325,600"
        },
        {
          "Model Information": "Number of Participants",
          "RMET": "6,600",
          "MRMET": "6,600"
        },
        {
          "Model Information": "Number of Items",
          "RMET": "36",
          "MRMET": "37"
        },
        {
          "Model Information": "AIC",
          "RMET": "64,491.600",
          "MRMET": "158,731.800"
        },
        {
          "Model Information": "BIC",
          "RMET": "64,576.900",
          "MRMET": "158,817.400"
        },
        {
          "Model Information": "Log Likelihood",
          "RMET": "-32,237.900",
          "MRMET": "-79,357.900"
        }
      ],
      "page": 10
    },
    {
      "caption": "Table 4: presents the GLMM fixed effects for both interaction with log-group size (Î² = -3.73, SE = 0.07,",
      "data": [
        {
          "Dataset": "RMET",
          "Condition/Contrast": "",
          "Estimate": "",
          "SE": "",
          "95% CI Lower": "",
          "95% CI Upper": ""
        },
        {
          "Dataset": "",
          "Condition/Contrast": "Marginal Probabilities",
          "Estimate": "",
          "SE": "",
          "95% CI Lower": "",
          "95% CI Upper": ""
        },
        {
          "Dataset": "",
          "Condition/Contrast": "Collective Intelligence-Human",
          "Estimate": "0.998",
          "SE": "0.000",
          "95% CI Lower": "0.998",
          "95% CI Upper": "0.999"
        },
        {
          "Dataset": "",
          "Condition/Contrast": "Collective Intelligence-GPT-4o",
          "Estimate": "0.959",
          "SE": "0.008",
          "95% CI Lower": "0.940",
          "95% CI Upper": "0.971"
        },
        {
          "Dataset": "",
          "Condition/Contrast": "Augmented intelligence",
          "Estimate": "0.999",
          "SE": "0.000",
          "95% CI Lower": "0.998",
          "95% CI Upper": "0.999"
        },
        {
          "Dataset": "",
          "Condition/Contrast": "Contrasts (Odds Ratios)",
          "Estimate": "",
          "SE": "",
          "95% CI Lower": "",
          "95% CI Upper": ""
        },
        {
          "Dataset": "",
          "Condition/Contrast": "Human vs. GPT-4o",
          "Estimate": "26.015",
          "SE": "1.710",
          "95% CI Lower": "-",
          "95% CI Upper": "-"
        },
        {
          "Dataset": "",
          "Condition/Contrast": "Human vs. Augmented",
          "Estimate": "0.681",
          "SE": "0.055",
          "95% CI Lower": "-",
          "95% CI Upper": "-"
        },
        {
          "Dataset": "",
          "Condition/Contrast": "GPT-4o vs. Augmented",
          "Estimate": "0.026",
          "SE": "0.002",
          "95% CI Lower": "-",
          "95% CI Upper": "-"
        },
        {
          "Dataset": "MRMET",
          "Condition/Contrast": "",
          "Estimate": "",
          "SE": "",
          "95% CI Lower": "",
          "95% CI Upper": ""
        },
        {
          "Dataset": "",
          "Condition/Contrast": "Marginal Probabilities",
          "Estimate": "",
          "SE": "",
          "95% CI Lower": "",
          "95% CI Upper": ""
        },
        {
          "Dataset": "",
          "Condition/Contrast": "Collective Intelligence-Human",
          "Estimate": "0.960",
          "SE": "0.012",
          "95% CI Lower": "0.930",
          "95% CI Upper": "0.977"
        },
        {
          "Dataset": "",
          "Condition/Contrast": "Collective Intelligence-GPT-4o",
          "Estimate": "0.924",
          "SE": "0.021",
          "95% CI Lower": "0.872",
          "95% CI Upper": "0.956"
        },
        {
          "Dataset": "",
          "Condition/Contrast": "Augmented intelligence",
          "Estimate": "0.971",
          "SE": "0.008",
          "95% CI Lower": "0.949",
          "95% CI Upper": "0.984"
        },
        {
          "Dataset": "",
          "Condition/Contrast": "Contrasts (Odds Ratios)",
          "Estimate": "",
          "SE": "",
          "95% CI Lower": "",
          "95% CI Upper": ""
        },
        {
          "Dataset": "",
          "Condition/Contrast": "Human vs. GPT-4o",
          "Estimate": "1.954",
          "SE": "0.043",
          "95% CI Lower": "-",
          "95% CI Upper": "-"
        },
        {
          "Dataset": "",
          "Condition/Contrast": "Human vs. Augmented",
          "Estimate": "0.710",
          "SE": "0.015",
          "95% CI Lower": "-",
          "95% CI Upper": "-"
        },
        {
          "Dataset": "",
          "Condition/Contrast": "GPT-4o vs. Augmented",
          "Estimate": "0.363",
          "SE": "0.007",
          "95% CI Lower": "-",
          "95% CI Upper": "-"
        }
      ],
      "page": 11
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Does the Whole Exceed Its Parts? The Effect of AI Explanations on Complementary Team Performance",
      "authors": [
        "References Bansal",
        "Tongshuang Gagan",
        "Joyce Wu",
        "Raymond Zhou",
        "Besmira Fok",
        "Ece Nushi",
        "Marco Kamar",
        "Daniel Tulio Ribeiro",
        "Weld"
      ],
      "year": "2021",
      "venue": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems"
    },
    {
      "citation_id": "2",
      "title": "The 'Reading the Mind in the Eyes' Test Revised Version: A Study with Normal Adults, and Adults with Asperger Syndrome or High-Functioning Autism",
      "authors": [
        "S Baron-Cohen",
        "S Wheelwright",
        "J Hill",
        "Y Raste",
        "I Plumb"
      ],
      "year": "2001",
      "venue": "Journal of Child Psychology and Psychiatry, and Allied Disciplines"
    },
    {
      "citation_id": "3",
      "title": "",
      "authors": [
        "Tom Brown",
        "Benjamin Mann",
        "Nick Ryder",
        "Melanie Subbiah",
        "Jared Kaplan",
        "Prafulla Dhariwal",
        "Arvind Neelakantan"
      ],
      "venue": ""
    },
    {
      "citation_id": "4",
      "title": "Language Models Are Few-Shot Learners",
      "authors": [
        "Amanda Sastry",
        "Sandhini Askell",
        "Ariel Agarwal",
        "Gretchen Herbert-Voss",
        "Tom Krueger",
        "Rewon Henighan",
        "Aditya Child",
        "Daniel Ramesh",
        "Jeffrey Ziegler",
        "Clemens Wu",
        "Chris Winter",
        "Mark Hesse",
        "Eric Chen",
        "Mateusz Sigler",
        "Scott Litwin",
        "Benjamin Gray",
        "Jack Chess",
        "Christopher Clark",
        "Sam Berner",
        "Alec Mccandlish",
        "Ilya Radford",
        "Dario Sutskever",
        "Amodei"
      ],
      "year": "2020",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "5",
      "title": "How Behavior Spreads: The Science of Complex Contagions",
      "authors": [
        "Damon Centola"
      ],
      "year": "2018",
      "venue": "How Behavior Spreads: The Science of Complex Contagions"
    },
    {
      "citation_id": "6",
      "title": "KL-Divergence Guided Temperature Sampling",
      "authors": [
        "Chung Chang",
        "David Ching",
        "Renat Reitter",
        "Yun-Hsuan Aksitov",
        "Sung"
      ],
      "year": "2023",
      "venue": "KL-Divergence Guided Temperature Sampling"
    },
    {
      "citation_id": "7",
      "title": "Are More LLM Calls All You Need? Towards Scaling Laws of Compound Inference Systems",
      "authors": [
        "Lingjiao Chen",
        "Jared Davis",
        "Boris Hanin",
        "Peter Bailis",
        "Ion Stoica",
        "Matei Zaharia",
        "James Zou"
      ],
      "year": "2024",
      "venue": "Are More LLM Calls All You Need? Towards Scaling Laws of Compound Inference Systems"
    },
    {
      "citation_id": "8",
      "title": "Statistical Inference for Stochastic Dominance and for the Measurement of Poverty and Inequality",
      "authors": [
        "Russell Davidson",
        "Jean-Yves Duclos"
      ],
      "year": "2000",
      "venue": "Econometrica"
    },
    {
      "citation_id": "9",
      "title": "Hybrid Intelligence",
      "authors": [
        "Dominik Dellermann",
        "Philipp Ebel",
        "Matthias SÃ¶llner",
        "Jan Leimeister"
      ],
      "year": "2019",
      "venue": "Business & Information Systems Engineering"
    },
    {
      "citation_id": "10",
      "title": "Bayesian Averaging of Classifiers and the Overfitting Problem",
      "authors": [
        "Pedro Domingos"
      ],
      "year": "2000",
      "venue": "Bayesian Averaging of Classifiers and the Overfitting Problem"
    },
    {
      "citation_id": "11",
      "title": "ChatGPT Outperforms Humans in Emotional Awareness Evaluations",
      "authors": [
        "Zohar Elyoseph",
        "Dorit Hadar-Shoval",
        "Kfir Asraf",
        "Maya Lvovsky"
      ],
      "year": "2023",
      "venue": "Frontiers in Psychology",
      "doi": "10.3389/fpsyg.2023.1199058"
    },
    {
      "citation_id": "12",
      "title": "Mental Health Monitoring with Multimodal Sensing and Machine Learning: A Survey",
      "authors": [
        "Enrique Garcia-Ceja",
        "Michael Riegler",
        "Tine Nordgreen",
        "Petter Jakobsen",
        "J Ketil",
        "Jim Oedegaard",
        "TÃ¸rresen"
      ],
      "year": "2018",
      "venue": "Pervasive and Mobile Computing"
    },
    {
      "citation_id": "13",
      "title": "Large Language Model Influence on Diagnostic Reasoning: A Randomized Clinical Trial",
      "authors": [
        "Ethan Goh",
        "Robert Gallo",
        "Jason Hom",
        "Eric Strong",
        "Yingjie Weng",
        "Hannah Kerman",
        "JosÃ©phine Cool",
        "Zahir Kanjee",
        "Andrew Parsons",
        "Neera Ahuja",
        "Eric Horvitz",
        "Daniel Yang",
        "Arnold Milstein",
        "P Andrew",
        "Adam Olson",
        "Jonathan Rodman",
        "Chen"
      ],
      "year": "2024",
      "venue": "JAMA Network Open",
      "doi": "10.1001/jamanetworkopen.2024.40969"
    },
    {
      "citation_id": "14",
      "title": "Groups of Diverse Problem Solvers Can Outperform Groups of High-Ability Problem Solvers",
      "authors": [
        "Lu Hong",
        "Scott Page"
      ],
      "year": "2004",
      "venue": "Proceedings of the National Academy of Sciences"
    },
    {
      "citation_id": "15",
      "title": "Gpt-4o System Card",
      "authors": [
        "Aaron Hurst",
        "Adam Lerer",
        "Adam Goucher",
        "Adam Perelman",
        "Aditya Ramesh",
        "Aidan Clark",
        "A Ostrow",
        "Akila Welihinda",
        "Alan Hayes",
        "Alec Radford"
      ],
      "year": "2024",
      "venue": "Gpt-4o System Card",
      "arxiv": "arXiv:2410.21276"
    },
    {
      "citation_id": "16",
      "title": "How a Cockpit Remembers Its Speeds",
      "authors": [
        "Edwin Hutchins"
      ],
      "year": "1995",
      "venue": "Cognitive Science",
      "doi": "10.1207/s15516709cog1903_1"
    },
    {
      "citation_id": "17",
      "title": "Empathic Accuracy: Its Links to Clinical, Cognitive, Developmental, Social, and Physiological Psychology",
      "authors": [
        "William Ickes"
      ],
      "year": "2009",
      "venue": "Empathic Accuracy: Its Links to Clinical, Cognitive, Developmental, Social, and Physiological Psychology"
    },
    {
      "citation_id": "18",
      "title": "Multiracial Reading the Mind in the Eyes Test (MRMET): An Inclusive Version of an Influential Measure",
      "authors": [
        "Heesu Kim",
        "Jasmine Ally",
        "Roger Kaduthodil",
        "Laura Strong",
        "Sarah Germine",
        "Jeremy Cohan",
        "Wilmer"
      ],
      "year": "2024",
      "venue": "Behavior Research Methods",
      "doi": "10.3758/s13428-023-02323-x"
    },
    {
      "citation_id": "19",
      "title": "Types of Teacher-AI Collaboration in K-12 Classroom Instruction: Chinese Teachers' Perspective",
      "authors": [
        "Jinhee Kim"
      ],
      "year": "2024",
      "venue": "Education and Information Technologies",
      "doi": "10.1007/s10639-024-12523-3"
    },
    {
      "citation_id": "20",
      "title": "Emotional Intelligence and Social Interaction",
      "authors": [
        "Paulo Lopes",
        "A Marc",
        "John Brackett",
        "Astrid Nezlek",
        "Ina SchÃ¼tz",
        "Peter Sellin",
        "Salovey"
      ],
      "year": "2004",
      "venue": "Personality and Social Psychology Bulletin"
    },
    {
      "citation_id": "21",
      "title": "Effects of Employee-Artificial Intelligence (AI) Collaboration on Counterproductive Work Behaviors (CWBs): Leader Emotional Support as a Moderator",
      "authors": [
        "Qingqi Meng",
        "Tung-Ju Wu",
        "Wenyan Duan",
        "Shijia Li"
      ],
      "year": "2025",
      "venue": "Behavioral Sciences",
      "doi": "10.3390/bs15050696"
    },
    {
      "citation_id": "22",
      "title": "Best Practice Guidance for Linear Mixed-Effects Models in Psychological Science",
      "authors": [
        "Lotte Meteyard",
        "A Robert",
        "Davies"
      ],
      "year": "2020",
      "venue": "Journal of Memory and Language"
    },
    {
      "citation_id": "23",
      "title": "MetaICL: Learning to Learn In Context",
      "authors": [
        "Sewon Min",
        "Mike Lewis",
        "Luke Zettlemoyer",
        "Hannaneh Hajishirzi"
      ],
      "year": "2022",
      "venue": "MetaICL: Learning to Learn In Context"
    },
    {
      "citation_id": "24",
      "title": "Large Language Models Can Outperform Humans in Social Situational Judgments",
      "authors": [
        "Justin MittelstÃ¤dt",
        "Julia Maier",
        "Panja Goerke",
        "Frank Zinn",
        "Michael Hermes"
      ],
      "year": "2024",
      "venue": "Scientific Reports",
      "doi": "10.1038/s41598-024-79048-0"
    },
    {
      "citation_id": "25",
      "title": "Aggregated Knowledge from a Small Number of Debates Outperforms the Wisdom of Large Crowds",
      "authors": [
        "Joaquin Navajas",
        "Tamara Niella",
        "Gerry Garbulsky",
        "Bahador Bahrami",
        "Mariano Sigman"
      ],
      "year": "2018",
      "venue": "Nature Human Behaviour",
      "doi": "10.1038/s41562-017-0273-4"
    },
    {
      "citation_id": "26",
      "title": "How Do We Evaluate Facial Emotion Recognition?",
      "authors": [
        "Ana Paiva-Silva",
        "Marta Idalina De",
        "Juliana Kerr Pontes",
        "WÃ¢nia Cristina De Silva Rocha Aguiar",
        "Souza"
      ],
      "year": "2016",
      "venue": "Psychology & Neuroscience",
      "doi": "10.1037/pne0000047"
    },
    {
      "citation_id": "27",
      "title": "Is Temperature the Creativity Parameter of Large Language Models",
      "authors": [
        "Max Peeperkorn",
        "Tom Kouwenhoven",
        "Dan Brown",
        "Anna Jordanous",
        "; Peeters",
        "M Marieke",
        "Jurriaan Van Diggelen",
        "Karel Van Den",
        "Bosch"
      ],
      "year": "2021",
      "venue": "AI & SOCIETY",
      "doi": "10.1007/s00146-020-01005-y"
    },
    {
      "citation_id": "28",
      "title": "Emotion Research by the People, for the People",
      "authors": [
        "Rosalind Picard"
      ],
      "year": "2010",
      "venue": "Emotion Review"
    },
    {
      "citation_id": "29",
      "title": "Fitting Nonlinear Mixed-Effects Models",
      "authors": [
        "JosÃ© Pinheiro",
        "Douglas Bates"
      ],
      "year": "2000",
      "venue": "in Mixed-Effects Models in S and S-PLUS"
    },
    {
      "citation_id": "30",
      "title": "Understanding Algorithm Aversion: When Is Advice from Automation Discounted?",
      "authors": [
        "Andrew Prahl",
        "Lyn Van Swol"
      ],
      "year": "2017",
      "venue": "Journal of Forecasting",
      "doi": "10.1002/for.2464"
    },
    {
      "citation_id": "31",
      "title": "Generative Artificial Intelligence Demonstrates Excellent Emotion Recognition Abilities Across Ethnical Boundaries",
      "authors": [
        "Elad Refoua",
        "Gunther Meinlschmidt",
        "Zohar Elyoseph ; Rousselet"
      ],
      "year": "2019",
      "venue": "Generative Artificial Intelligence Demonstrates Excellent Emotion Recognition Abilities Across Ethnical Boundaries"
    },
    {
      "citation_id": "32",
      "title": "Emotional Intelligence",
      "authors": [
        "Peter Salovey",
        "John Mayer"
      ],
      "year": "1990",
      "venue": "Imagination, Cognition and Personality"
    },
    {
      "citation_id": "33",
      "title": "The Politics of Deceptive Borders:'Biomarkers of Deceit'and the Case of iBorderCtrl",
      "authors": [
        "Javier SÃ¡nchez-Monedero",
        "Lina Dencik"
      ],
      "year": "2022",
      "venue": "Information, Communication & Society"
    },
    {
      "citation_id": "34",
      "title": "Multilevel Analysis: An Introduction to Basic and Advanced Multilevel Modeling",
      "authors": [
        "T Snijders",
        "R Bosker"
      ],
      "year": "2012",
      "venue": "Multilevel Analysis: An Introduction to Basic and Advanced Multilevel Modeling"
    },
    {
      "citation_id": "35",
      "title": "Testing Theory of Mind in Large Language Models and Humans",
      "authors": [
        "James Strachan",
        "Dalila Albergo",
        "Giulia Borghini",
        "Oriana Pansardi",
        "Eugenio Scaliti",
        "Saurabh Gupta",
        "Krati Saxena",
        "Alessandro Rufo",
        "Stefano Panzeri",
        "Guido Manzi",
        "S Michael",
        "Cristina Graziano",
        "Becchio"
      ],
      "year": "2024",
      "venue": "Nature Human Behaviour",
      "doi": "10.1038/s41562-024-01882-z"
    },
    {
      "citation_id": "36",
      "title": "",
      "authors": [
        "James Strachan",
        "Oriana Pansardi",
        "Eugenio Scaliti",
        "Marco Celotto",
        "Krati Saxena",
        "Chunzhi Yi",
        "Fabio Manzi",
        "Alessandro Rufo",
        "Guido Manzi",
        "S Michael",
        "Stefano Graziano",
        "Cristina Panzeri",
        "Becchio"
      ],
      "year": "2024",
      "venue": ""
    },
    {
      "citation_id": "37",
      "title": "The Wisdom of Crowds. Vintage",
      "authors": [
        "James Surowiecki"
      ],
      "year": "2005",
      "venue": "The Wisdom of Crowds. Vintage"
    },
    {
      "citation_id": "38",
      "title": "Understanding the Capabilities, Limitations, and Societal Impact of Large Language Models",
      "authors": [
        "Alex Tamkin",
        "Miles Brundage",
        "Jack Clark",
        "Deep Ganguli"
      ],
      "year": "2021",
      "venue": "Understanding the Capabilities, Limitations, and Societal Impact of Large Language Models",
      "arxiv": "arXiv:2102.02503"
    },
    {
      "citation_id": "39",
      "title": "The 'Reading the Mind in the Eyes' Test: Systematic Review of Psychometric Properties and a Validation Study in Italy",
      "authors": [
        "Marcello Vellante",
        "Simon Baron-Cohen",
        "Mariangela Melis",
        "Matteo Marrone",
        "Rita Donatella",
        "Carmelo Petretto",
        "Antonio Masala",
        "Preti"
      ],
      "year": "2013",
      "venue": "Cognitive Neuropsychiatry",
      "doi": "10.1080/13546805.2012.721728"
    },
    {
      "citation_id": "40",
      "title": "Emotional Intelligence of Large Language Models",
      "authors": [
        "Xuena Wang",
        "Xueting Li",
        "Zi Yin",
        "Yue Wu",
        "Jia Liu"
      ],
      "year": "2023",
      "venue": "Journal of Pacific Rim Psychology",
      "doi": "10.1177/18344909231213958"
    },
    {
      "citation_id": "41",
      "title": "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models",
      "authors": [
        "Jason Wei",
        "Xuezhi Wang",
        "Dale Schuurmans",
        "Maarten Bosma",
        "Fei Xia",
        "Ed Chi",
        "Quoc Le",
        "Denny Zhou"
      ],
      "year": "2022",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "42",
      "title": "Econometric Analysis of Stochastic Dominance: Concepts, Methods, Tools, and Applications",
      "authors": [
        "Yoon-Jae Whang"
      ],
      "year": "2019",
      "venue": "Econometric Analysis of Stochastic Dominance: Concepts, Methods, Tools, and Applications"
    },
    {
      "citation_id": "43",
      "title": "Introduction to Robust Estimation and Hypothesis Testing",
      "authors": [
        "Rand Wilcox"
      ],
      "year": "2011",
      "venue": "Introduction to Robust Estimation and Hypothesis Testing"
    }
  ]
}