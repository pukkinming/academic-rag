{
  "paper_id": "2504.08281v1",
  "title": "Elsa: A Style-Aligned Dataset For Emotionally Intelligent Language Generation",
  "published": "2025-04-11T06:30:16Z",
  "authors": [
    "Vishal Gandhi",
    "Sagar Gandhi"
  ],
  "keywords": [
    "emotion-aware language modeling",
    "fine-grained emotion recognition",
    "stylistic variation",
    "emotionconditioned text generation",
    "large language models (LLMs)",
    "text augmentation",
    "emotion and style transfer",
    "affective text generation",
    "emotion-centric NLP",
    "multistyle text synthesis",
    "Natural Language Generation (NLG)"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Advancements in emotion-aware language processing increasingly shape vital NLP applications ranging from conversational AI and affective computing to computational psychology and creative content generation. Existing emotion datasets either lack emotional granularity or fail to capture necessary stylistic diversity, limiting the advancement of effective emotion-conditioned text generation systems. Seeking to bridge this crucial gap between granularity and style diversity, this paper introduces a novel systematically constructed dataset named ELSA (Emotion and Language Style Alignment Dataset) 1 leveraging fine-grained emotion taxonomies adapted from existing sources (dair-ai/emotion dataset and GoEmotions taxonomy). This dataset comprises multiple emotionally nuanced variations of original sentences regenerated across distinct contextual styles (conversational, formal, poetic, and narrative) using advanced Large Language Models (LLMs). Rigorous computational evaluation using metrics such as perplexity, embedding variance, readability, lexical diversity, and semantic coherence measures validates the dataset's emotional authenticity, linguistic fluency, and textual diversity. Comprehensive metric analyses affirm its potential to support deeper explorations into emotion-conditioned style-adaptive text generation. By enabling precision-tuned emotionally nuanced language modeling, our dataset creates fertile ground for research on finegrained emotional control, prompt-driven explanation, interpretability, and style-adaptive expressive language generation with LLMs.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Introduction",
      "text": "Emotion-aware language processing is a cornerstone of human-computer interactions, shaping applications from affective computing and conversational AI to computational psychology and literary analysis  [1, 2] . With the rapid advancement of Large Language Models (LLMs), recent research has significantly expanded the capabilities of automated emotional expression generation, providing unprecedented levels of expressive and affective control in generated text  [3, 4] . However, effectively leveraging these advances still fundamentally depends on having access to high-quality datasets with sufficiently nuanced emotion annotations and economically diverse language expressions  [5, 6] .\n\nCurrently, popular datasets such as the dair-ai/emotion collection cover broadly defined emotional categories including sadness, anger, love, surprise, fear, and joy  [6] . While useful and widely embraced by the emotion recognition community, these emotion labels lack granularity, failing to represent wide variations in emotional intensity and complexity frequently encountered in realistic human language scenarios  [3] . Conversely, although fine-grained datasets, such as Google's GoEmotions  [5] , encompass a richer and more nuanced taxonomy of 27 emotions, they focus primarily on short and informal conversational texts. Consequently, utilizing these datasets to train and evaluate LLM-based controlled emotion generation systems proves challenging, as direct transfer of nuanced conversational emotional annotations to diverse linguistic contexts (e.g., professional writing, poetry, storytelling) often results in unsuitable or unnatural outputs  [8] .\n\nMoreover, emotions are inherently expressed differently across contexts and styles: the same emotional intent may translate with radically different lexical, syntactic, and semantic choices across poetic, conversational, formal, or narrative settings  [9] . Prior work underscores that ignoring these contextual variations significantly limits the expressiveness and authenticity of computationally generated emotion-laden sentences  [10] . Thus, a central research challenge emerges: existing emotion datasets either lack granularity or overlook stylistic contextual diversity, thereby restricting LLMs' potential to produce genuinely nuanced, contextually accurate emotional content.\n\nAddressing this notable research gap, this paper introduces a systematically constructed ELSA dataset explicitly designed to enrich emotion-controlled text generation frameworks. Our proposed ELSA dataset effectively bridges the granularity of GoEmotion's fine-grained emotional taxonomy with the wide stylistic contextual diversity needed for realistic text generation. By employing mapping strategies linking dair-ai's coarse emotional categories  [6]  with GoEmotion's fine-grained categories  [5] , and through targeted prompt-based augmentation using advanced LLMs, we systematically generate multiple emotionally nuanced rewrites of textual samples across distinct stylistic expressions such as conversational, poetic, formal, and narrative.\n\nRecognizing the importance of rigorous validation, we evaluate our ELSA dataset across established computational metrics, including perplexity for fluency, emotional distinctiveness through embedding variance, lexical diversity (distinct-n and self-BLEU), and style coherence measures  [11] . This careful methodological process guarantees that generated texts exhibit emotional authenticity while preserving stylistic diversity. Thus, our ELSA dataset provides a robust foundation for future NLP research aimed at deeper exploration into emotion-conditioned text generation and style-adaptive affective language modeling. In summary, the contributions of this paper include:  (1)  proposing an integrative ELSA dataset bridging existing coarse-grained emotion taxonomies with richer fine-grained emotional labels, (2) introducing nuanced stylistic contextual variation essential for realistic human textual emotion expressions, and (3) providing systematic empirical quality assessments designed to standardize future research benchmarks. Through enhancing emotional and stylistic complexity, the presented dataset promises to significantly advance the capacity of models to accurately replicate human emotional expression across varied communicative situations, thereby setting a valuable precedent for future research in affective computing and computational linguistics.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Related Work",
      "text": "Emotion recognition and generation in natural language processing (NLP) have undergone significant advancements, primarily driven by the development of annotated emotional datasets and the evolution of generative models capable of producing emotionally nuanced text.\n\nEarly approaches to emotion recognition relied heavily on lexicon-based tools such as the Linguistic Inquiry and Word Count (LIWC) and WordNet-Affect, which extended the WordNet database to include affective concepts, facilitating emotion analysis in textual data  [12] . While foundational, these lexicon-based methods were limited by manual creation constraints and often struggled to capture the nuanced, context-dependent expressions of emotion.\n\nTo address scalability challenges, researchers employed distant supervision techniques, leveraging social media platforms like Twitter to collect large-scale emotion-labeled data. For instance, Wang et al.  [13]  automatically created a dataset of approximately 2.5 million tweets by harnessing emotion-related hashtags, enabling broader emotion identification studies. However, these methods introduced substantial labeling noise and often focused on coarse emotional categories, such as those defined by Ekman's six basic emotions such as anger, disgust, fear, happiness, sadness, and surprise  [17]  or Plutchik's eight primary emotions.\n\nRecent efforts have aimed to enhance the granularity of emotion taxonomies. Notably, Demszky et al. introduced GoEmotions, a dataset comprising 58,000 Reddit comments annotated with 27 distinct emotion categories  [5] . This dataset provides a more nuanced understanding of emotional expression in text. However, its domain specificity, primarily encompassing informal, conversational-style text from Reddit, may limit its applicability across diverse writing genres.\n\nIn parallel, the field of text generation has seen significant progress in controlling stylistic and emotional attributes. Techniques such as controlled text generation have been employed to modulate the emotional tone of generated content. For example, Singh et al. proposed adapting language models to generate affect-driven and topic-focused sentences by incorporating emotion as a prior, allowing control over both the category and intensity of emotion in the generated text  [25] . Similarly, Liu et al. introduced a method for modulating language models with emotions using a technique inspired by computer vision, enabling the generation of context-aware language that embodies diverse emotions  [20] . Recent advances in LLM-based augmentation and emotion-controlled generation have opened new avenues for affectaware text generation  [27, 16] . Additionally, models have been developed to condition output on stylistic or emotional goals, bridging the gap between emotion recognition and controlled generation  [29] .\n\nContemporary models like EmoLLMs and others have begun integrating emotion representations more directly into language modeling  [20] . Other studies focus on augmenting low-resource or complex affective phenomena, such as irony, through LLM-powered augmentation  [21] . More broadly, text augmentation remains a core method to increase emotional data diversity and robustness  [25] . Studies have also attempted to benchmark the emotional expressivity and comprehension of various LLMs  [24] .\n\nDespite these advancements, a notable gap remains in datasets that simultaneously offer fine-grained emotion labels and encompass a broad range of stylistic contexts. Existing resources often lack the stylistic diversity necessary to train models capable of generating emotionally expressive text across various genres, such as formal writing, poetry, storytelling, and conversational language. Addressing this gap is crucial for developing models that can understand and generate text with appropriate emotional and stylistic nuances. Beyond text, emotion conditioning is also extending into other modalities like image generation, enabling broader multimodal affect-aware applications  [22] .\n\nThe present study seeks to bridge this gap by introducing ELSA (Emotion and Language Style Alignment) dataset that combines fine-grained emotion annotations with diverse stylistic contexts. By leveraging recent advances in large language model-based text augmentation techniques, we aim to enrich stylized emotional expression for diverse NLP applications, facilitating the development of models capable of generating emotionally and stylistically nuanced text across various domains.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Elsa Dataset Creation Methodology",
      "text": "To generate a nuanced dataset, an iterative pipeline leveraging advanced LLM-based augmentation was designed:",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Initial Dataset Preparation",
      "text": "The initial data is derived from dair-ai/emotion dataset, containing 10,434 annotated text samples across six emotional classes (sadness, anger, love, surprise, fear, joy). First, each dair-ai emotion was mapped systematically to fine-grained GoEmotions subcategories-yielding higher granularity:   1 : Primary emotions and their mapped emotions.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Emotion-Conditioned Stylistic Augmentation",
      "text": "Each original textual instance was expanded through automated LLM-generated augmentation. The original text was fed into an OpenAI GPT o-1 conditioned explicitly with the mapped GoEmotions subcategories to create multiple emotionally varied, yet semantically genuine rewrites. For each emotionally labeled instance, the dataset includes systematically generated stylistic variations: formal, conversational, poetic, and narrative.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Quality Control And Validation",
      "text": "Generated texts were automatically evaluated with off-the-shelf classification models (e.g., GoEmotions classification model) to verify emotional and categorical accuracy. Text embeddings (Sentence-BERT embeddings) were utilized to ensure adequate semantic distance, ensuring novelty and diversity from original sources.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Dataset Metrics And Analysis",
      "text": "In this section, we present a comprehensive quantitative analysis of our ELSA dataset. To systematically evaluate the quality, emotional distinctiveness, semantic coherence, linguistic diversity, and readability of the generated texts, we employ multiple established metrics. Below, we formally define each metric, summarize their empirical statistics ( Table  2 ), and discuss our results in detail thereafter.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Metric Definitions",
      "text": "Embedding Variance: Given sentence embedding vectors s 1 , s 2 , . . . , s n corresponding to n generated samples derived from a common base sentence, the embedding variance is defined as:\n\nwhere s is the mean embedding vector:\n\nAverage Emotion Distance: For a given emotion embedding representation e orig of the original text and generated emotion embeddings e i , the average emotion distance is computed as the mean cosine distance:\n\nAverage Readability: The readability score is calculated using the Flesch-Kincaid readability test: Distinct-n: Distinct-n measures lexical diversity as the proportion of unique n-grams over all n-grams in a corpus. For bigrams (n = 2), it is computed as:\n\nSelf-BLEU: Self-BLEU measures textual similarity within a set by calculating the average BLEU score of each sentence against all remaining generated sentences. A lower Self-BLEU implies greater textual diversity:\n\nAverage Perplexity: Given a probabilistic language model with probabilities p(w t | w <t ) for tokens w t in a sentence of length T , the perplexity is defined as:\n\nCosine Similarity: To assess semantic consistency between the original embeddings s orig and the generated embeddings s i , we calculate their cosine similarity, averaged over all generated sentences:",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Discussion And Analysis",
      "text": "The computed metrics reveal several important insights regarding the ELSA dataset's emotional and stylistic complexity, diversity, readability, and semantic coherence.\n\nEmbedding Variance (mean=0.000867, std=0.000247): The low variance observed in sentence embeddings indicates highly stable semantic embedding vectors across stylistically diverse text versions derived from the same input base sentences. This stability aligns with expectations, as generated texts differ stylistically and emotionally while maintaining semantic coherence.\n\nAverage Emotion Distance (mean=0.525, std=0.146): The moderate mean emotional distance suggests that generated variations indeed shift significantly in emotion from the original samples. Thus, our generated ELSA dataset successfully exhibits moderate emotional diversity. However, the presence of high extreme values (max=0.89) implies occasional pronounced emotional shifts, warranting caution when very strict emotional stylistic retention is necessary.\n\nAverage Readability (mean=57.67, std=10.6): Overall readability scores provide evidence of good linguistic accessibility (Flesch-Kincaid readability scale). Nonetheless, the relatively high standard deviation and wide range of readability scores (minimum 13.86, maximum 92.63) reflect stylistic differences-for instance, markedly complex sentences common in poetic or formal narrative generation may reduce readability, suggesting a potential trade-off between stylistic richness and accessibility.\n\nDistinct-2 (mean=0.9308, std=0.052): A mean Distinct-2 score approaching one underscores a high degree of lexical richness across the generated samples. Strong lexical diversity assures minimal repetitiveness, supporting the dataset's effectiveness for diverse generation applications that demand linguistic creativity and richness.\n\nSelf-BLEU (mean=0.036, std=0.067): The very low Self-BLEU values indicate notable textual novelty and minimal overlap among generated outputs. These low values are particularly advantageous for tasks that value output variety and originality, highlighting dataset quality in ensuring robust diversity.\n\nAverage Perplexity (mean=67.52, std=31.57): Moderate perplexity levels suggest the generated sentences generally maintain fluency and grammatical structures. However, the significant variations and the presence of high maximum values reflect complexities introduced by stylistic types. Particularly, poetic and highly expressive genres may lead to occasional lower predictability, an issue future research might address to optimize coherence and fluency further.\n\nCosine Similarity (mean=0.525, std=0.146): This value closely mirrors the average emotion distance metric, emphasizing moderate semantic retention relative to original texts while allowing ample room for stylistic and emotional variations.\n\nIn summary, these metrics collectively underscore our ELSA dataset's potential, showcasing distinctive emotional and stylistic variations, acceptable readability, high lexical richness and textual diversity, and stable semantic coherence. Such balanced metrics indicate its suitability for various nuanced NLP applications, ranging from emotion modeling and controlled generation to stylistic text generation tasks.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Potential Research Use-Cases",
      "text": "The proposed ELSA dataset opens several valuable avenues for downstream research in affective NLP, LLM finetuning, and emotion-conditioned generation. Below, we outline key areas where the ELSA dataset can significantly contribute:\n\n1. Fine-tuning for Emotionally Nuanced Stylistic Transfer. Large language models currently excel in generic text generation but struggle with reliably transferring nuanced emotional semantics across diverse stylistic contexts. By fine-tuning these models with the proposed emotionally labeled dataset-containing carefully mapped stylistic variations between conversational, poetic, formal, and narrative texts-researchers can systematically train LLMs to precisely control emotional intensity, subtlety, and semantic appropriateness simultaneously with effective style transfer. This would significantly advance capacities currently limited in state-of-the-art LLM-driven style-adaptive generation systems.\n\n2. Precision-guided Prompt Engineering and Emotional Steering. Controlling generated emotional outputs of large-scale generative models currently depends primarily on ad-hoc prompt engineering, leading to imprecise emotional or stylistic outcomes. With a comprehensive emotion-stylistic mapping, this dataset facilitates precise fine-tuning that supports systematic prompt-based control of emotional outputs. Consequently, it enables researchers and developers to create structured prompt methodologies-moving beyond empirical trial-and-error prompt crafting-to rigorously guide emotional and style aspects of generated responses, thus substantially advancing controllability and consistency levels currently unachievable through traditional prompting techniques alone  [18] . Despite these contributions, careful attention needs to be paid regarding inherent biases within source datasets and possible semantic overlaps or unintended misclassifications during text generation processes. Therefore, we encourage continued research aimed at mitigating such limitations through explicit detection, evaluation, and controlled remediation strategies within downstream applications.",
      "page_start": 5,
      "page_end": 7
    },
    {
      "section_name": "Conclusion",
      "text": "This study presents a rigorously constructed emotion-conditioned ELSA dataset, explicitly designed to address existing limitations in granular emotional modeling and contextual stylistic variations within NLP. By methodically integrating coarse-grained emotional categories with fine-grained emotional subcategories derived from established datasets (dair-ai and GoEmotions), we generate stylistically diversified emotional expressions via advanced LLM-driven augmentations. Comprehensive computational evaluation demonstrates promising levels of semantic stability, moderate emotional divergence, high linguistic diversity, readability, and fluency, highlighting the ELSA dataset's practical utility and scientific rigor.\n\nThe proposed ELSA dataset opens numerous research pathways conducive to fine-tuning LLMs for emotionally expressive, stylistic text generation tasks previously unattainable, such as nuanced stylistic transfer, controlled emotional prompting, context-driven explainability, and accurate emotional grounding within complex textual contexts. Given these clear benefits, we encourage the NLP community to leverage this resource for advancing emotional control and interpretability with large language models. Future research should focus on addressing inherent biases from source datasets and optimizing generations further for fluency and emotion-stylistic coherence, thereby continuously enhancing the robustness and applicability of emotion-aware NLP solutions.\n\nhttp://arxiv.org/ps/2504.08281v1",
      "page_start": 7,
      "page_end": 8
    }
  ],
  "figures": [],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Primary Emotion": "Sadness",
          "Mapped Emotions": "Sadness, Grief, Remorse"
        },
        {
          "Primary Emotion": "Anger",
          "Mapped Emotions": "Anger, Annoyance, Disapproval, Embarrassment"
        },
        {
          "Primary Emotion": "Love",
          "Mapped Emotions": "Love, Admiration, Caring"
        },
        {
          "Primary Emotion": "Surprise",
          "Mapped Emotions": "Surprise, Realization"
        },
        {
          "Primary Emotion": "Fear",
          "Mapped Emotions": "Fear, Nervousness"
        },
        {
          "Primary Emotion": "Joy",
          "Mapped Emotions": "Joy, Excitement, Pride, Gratitude, Amusement"
        }
      ],
      "page": 3
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Mean": "0.000867",
          "Median": "0.000869",
          "Std": "0.000247",
          "Min": "0.000179",
          "Max": "0.001715"
        },
        {
          "Mean": "0.525050",
          "Median": "0.527698",
          "Std": "0.146301",
          "Min": "0.029889",
          "Max": "0.890717"
        },
        {
          "Mean": "57.671280",
          "Median": "58.027500",
          "Std": "10.606247",
          "Min": "13.865000",
          "Max": "92.630000"
        },
        {
          "Mean": "0.930821",
          "Median": "0.940594",
          "Std": "0.052273",
          "Min": "0.601563",
          "Max": "1.000000"
        },
        {
          "Mean": "0.036381",
          "Median": "1.369605e-78",
          "Std": "0.066719",
          "Min": "8.548274e-232",
          "Max": "0.525877"
        },
        {
          "Mean": "67.522142",
          "Median": "60.261040",
          "Std": "31.579396",
          "Min": "17.430520",
          "Max": "400.349832"
        },
        {
          "Mean": "0.525050",
          "Median": "0.527698",
          "Std": "0.146301",
          "Min": "0.029889",
          "Max": "0.890717"
        }
      ],
      "page": 5
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Affective Computing: Challenges",
      "authors": [
        "R Picard"
      ],
      "year": "2003",
      "venue": "International Journal of Human-Computer Studies"
    },
    {
      "citation_id": "2",
      "title": "Ethics Sheet for Automatic Emotion Recognition and Sentiment Analysis",
      "authors": [
        "S Mohammad"
      ],
      "year": "2022",
      "venue": "Computational Linguistics"
    },
    {
      "citation_id": "3",
      "title": "ECCRG: A Emotion-and Content-Controllable Response Generation Model",
      "authors": [
        "H Chen",
        "B Wang",
        "K Yang",
        "Y Song"
      ],
      "year": "2023",
      "venue": "Proceedings of the International Conference on Collaborative Computing"
    },
    {
      "citation_id": "4",
      "title": "Recent Advancement of Emotion Cognition in Large Language Models",
      "authors": [
        "Y Chen"
      ],
      "year": "2024",
      "venue": "Recent Advancement of Emotion Cognition in Large Language Models",
      "arxiv": "arXiv:2409.13354"
    },
    {
      "citation_id": "5",
      "title": "A Dataset of Fine-Grained Emotions",
      "authors": [
        "D Demszky",
        "D Movshovitz-Attias",
        "J Ko",
        "A Cowen",
        "G Nemade",
        "S Ravi",
        "Goemotions"
      ],
      "year": "2020",
      "venue": "A Dataset of Fine-Grained Emotions",
      "arxiv": "arXiv:2005.00547"
    },
    {
      "citation_id": "6",
      "title": "Contextualized Affect Representations for Emotion Recognition",
      "authors": [
        "E Saravia",
        "H.-C Liu",
        "Y.-H Huang",
        "J Wu",
        "Y.-S Chen",
        "Carer"
      ],
      "year": "2018",
      "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "7",
      "title": "Decoupled Variational Autoencoder with Interactive Attention for Affective Text Generation",
      "authors": [
        "R Chen",
        "J Wang",
        "L.-C Yu",
        "X Zhang"
      ],
      "year": "2023",
      "venue": "Engineering Applications of Artificial Intelligence"
    },
    {
      "citation_id": "8",
      "title": "Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, and Social Media Analysis",
      "authors": [
        "J Barnes",
        "O De Clercq",
        "R Klinger"
      ],
      "year": "2023",
      "venue": "Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, and Social Media Analysis"
    },
    {
      "citation_id": "9",
      "title": "Lexicons for Sentiment, Affect, and Connotation. Speech and Language Processing: An Introduction to NLP, Computational Linguistics, and Speech Recognition",
      "authors": [
        "D Jurafsky",
        "J Martin"
      ],
      "year": "2000",
      "venue": "Lexicons for Sentiment, Affect, and Connotation. Speech and Language Processing: An Introduction to NLP, Computational Linguistics, and Speech Recognition"
    },
    {
      "citation_id": "10",
      "title": "Representation Learning for Non-Parallel Text Style Transfer",
      "authors": [
        "V John",
        "L Mou",
        "H Bahuleyan",
        "Vechtomova"
      ],
      "year": "2018",
      "venue": "Representation Learning for Non-Parallel Text Style Transfer",
      "arxiv": "arXiv:1808.04339"
    },
    {
      "citation_id": "11",
      "title": "Correlations and Potential Cross-Linguistic Indicators of Writing Style",
      "authors": [
        "P Juola",
        "G Mikros",
        "S Vinsick"
      ],
      "year": "2019",
      "venue": "Journal of Quantitative Linguistics"
    },
    {
      "citation_id": "12",
      "title": "WordNet Affect: An Affective Extension of WordNet",
      "authors": [
        "C Strapparava",
        "A Valitutti"
      ],
      "year": "2004",
      "venue": "Proceedings of LREC"
    },
    {
      "citation_id": "13",
      "title": "Harnessing Twitter \"Big Data\" for Automatic Emotion Identification",
      "authors": [
        "W Wang",
        "L Chen",
        "K Thirunarayan",
        "A Sheth"
      ],
      "year": "2012",
      "venue": "Proceedings of the 2012 International Conference on Privacy, Security, Risk and Trust, and the 2012 International Conference on Social Computing"
    },
    {
      "citation_id": "14",
      "title": "Mapping the Passions: Toward a High-Dimensional Taxonomy of Emotional Experience and Expression",
      "authors": [
        "A Cowen",
        "D Sauter",
        "J Tracy",
        "D Keltner"
      ],
      "year": "2019",
      "venue": "Psychological Science in the Public Interest"
    },
    {
      "citation_id": "15",
      "title": "Self-Report Captures 27 Distinct Categories of Emotion Bridged by Continuous Gradients",
      "authors": [
        "A Cowen",
        "D Keltner"
      ],
      "year": "2017",
      "venue": "Proceedings of the National Academy of Sciences"
    },
    {
      "citation_id": "16",
      "title": "Prompt Sentiment: The Catalyst for LLM Change",
      "authors": [
        "V Gandhi",
        "S Gandhi"
      ],
      "year": "2025",
      "venue": "Prompt Sentiment: The Catalyst for LLM Change",
      "arxiv": "arXiv:2503.13510"
    },
    {
      "citation_id": "17",
      "title": "An Argument for Basic Emotions",
      "authors": [
        "P Ekman"
      ],
      "year": "1992",
      "venue": "Cognition and Emotion"
    },
    {
      "citation_id": "18",
      "title": "Steering Large Language Models via Directional Stimuli",
      "authors": [
        "R Turner",
        "J Thorp",
        "J He",
        "G Neubig"
      ],
      "year": "2023",
      "venue": "Steering Large Language Models via Directional Stimuli",
      "arxiv": "arXiv:2305.14855"
    },
    {
      "citation_id": "19",
      "title": "Cause-and-Effect Prompting for Emotion-Cause Pair Extraction in Conversations",
      "authors": [
        "C Chen",
        "J Wang",
        "Z Feng",
        "Z Liu",
        "S Li"
      ],
      "year": "2024",
      "venue": "Cause-and-Effect Prompting for Emotion-Cause Pair Extraction in Conversations",
      "arxiv": "arXiv:2401.10835"
    },
    {
      "citation_id": "20",
      "title": "A Series of Emotional Large Language Models and Annotation Tools for Comprehensive Affective Analysis. Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining",
      "authors": [
        "Z Liu",
        "K Yang",
        "Q Xie",
        "T Zhang",
        "S Ananiadou",
        "Emollms"
      ],
      "year": "2024",
      "venue": "A Series of Emotional Large Language Models and Annotation Tools for Comprehensive Affective Analysis. Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining"
    },
    {
      "citation_id": "21",
      "title": "Augmenting Emotion Features in Irony Detection with Large Language Modeling",
      "authors": [
        "Y Lin",
        "Y Xia",
        "Y Long"
      ],
      "year": "2024",
      "venue": "Workshop on Chinese Lexical Semantics"
    },
    {
      "citation_id": "22",
      "title": "Evoking Emotions Through Image Diffusion Models",
      "authors": [
        "Q Lin",
        "J Zhang",
        "Y Ong",
        "M Zhang",
        "Me Make",
        "Happier"
      ],
      "year": "2024",
      "venue": "Evoking Emotions Through Image Diffusion Models",
      "arxiv": "arXiv:2403.08255"
    },
    {
      "citation_id": "23",
      "title": "Large Language Models on Fine-grained Emotion Detection Dataset with Data Augmentation and Transfer Learning",
      "authors": [
        "K Wang",
        "Z Jing",
        "Y Su",
        "Y Han"
      ],
      "year": "2024",
      "venue": "Large Language Models on Fine-grained Emotion Detection Dataset with Data Augmentation and Transfer Learning",
      "arxiv": "arXiv:2403.06108"
    },
    {
      "citation_id": "24",
      "title": "The Comparative Emotional Capabilities of Five Popular Large Language Models. Critical Debates in Humanities",
      "authors": [
        "N Klapach"
      ],
      "venue": "Science and Global Justice"
    },
    {
      "citation_id": "25",
      "title": "Augmenting Interpretable Models with Large Language Models During Training",
      "authors": [
        "C Singh",
        "A Askari",
        "R Caruana",
        "J Gao"
      ],
      "year": "2023",
      "venue": "Nature Communications"
    },
    {
      "citation_id": "26",
      "title": "Text Augmentation-Based Model for Emotion Recognition Using Transformers",
      "authors": [
        "F Mohammad",
        "M Khan",
        "S Marwat",
        "N Jan",
        "N Gohar",
        "M Bilal",
        "A Al-Rasheed"
      ],
      "year": "2023",
      "venue": "Computers, Materials & Continua"
    },
    {
      "citation_id": "27",
      "title": "",
      "authors": [
        "Y Resendiz",
        "R Klinger"
      ],
      "year": "2023",
      "venue": "",
      "arxiv": "arXiv:2308.04857"
    },
    {
      "citation_id": "28",
      "title": "Large Language Models Understand and Can Be Enhanced by Emotional Stimuli",
      "authors": [
        "C Li",
        "J Wang",
        "Y Zhang",
        "K Zhu",
        "W Hou",
        "J Lian",
        "F Luo",
        "Q Yang",
        "X Xie"
      ],
      "year": "2023",
      "venue": "Large Language Models Understand and Can Be Enhanced by Emotional Stimuli",
      "arxiv": "arXiv:2307.11760"
    },
    {
      "citation_id": "29",
      "title": "Dialogue Augmentation with Large Language Models for Emotional Support Conversation",
      "authors": [
        "C Zheng",
        "S Sabour",
        "J Wen",
        "Z Zhang",
        "M Huang",
        "Augesc"
      ],
      "year": "2022",
      "venue": "Dialogue Augmentation with Large Language Models for Emotional Support Conversation",
      "arxiv": "arXiv:2202.13047"
    },
    {
      "citation_id": "30",
      "title": "Response Generation by Jointly Modeling Personalized Linguistic Styles and Emotions",
      "authors": [
        "T Sun",
        "C Wang",
        "X Song",
        "F Feng",
        "L Nie"
      ],
      "year": "2022",
      "venue": "ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM)"
    }
  ]
}