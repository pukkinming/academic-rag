{
  "paper_id": "2311.02647v1",
  "title": "New Approach For An Affective Computing-Driven Quality Of Experience (Qoe) Prediction",
  "published": "2023-11-05T13:21:07Z",
  "authors": [
    "Joshua Bègue",
    "Mohamed Aymen Labiod",
    "Abdelhamid Melloulk"
  ],
  "keywords": [
    "Machine Learning (ML)",
    "Deep Learning (DL)",
    "electroencephalogram (EEG)",
    "Signal processing",
    "Quality of Experience (QoE)"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "In human interactions, emotion recognition is crucial. For this reason, the topic of computer-vision approaches for automatic emotion recognition is currently being extensively researched. Processing multi-channel electroencephalogram (EEG) information is one of the most researched methods for automatic emotion recognition. This paper presents a new model for an affective computing-driven Quality of Experience (QoE) prediction. In order to validate the proposed model, a publicly available dataset is used. The dataset contains EEG, ECG, and respiratory data and is focused on a multimedia QoE assessment context. The EEG data are retained on which the differential entropy and the power spectral density are calculated with an observation window of three seconds. These two features were extracted to train several deep-learning models to investigate the possibility of predicting QoE with five different factors. The performance of these models is compared, and the best model is optimized to improve the results. The best results were obtained with an LSTM-based model, presenting an F1-score from 68% to 78%. An analysis of the model and its features shows that the Delta frequency band is the least necessary, that two electrodes have a higher importance, and that two other electrodes have a very low impact on the model's performances.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Humans' responses to interactions in daily life are known as emotions. They may show themselves through a variety of human expression techniques, including psychophysiology, gesture, or biological responses. Analyzing emotions using computer vision and affective computing is seen as a fundamental challenge  [1] . However, in order to analyze emotions, it is necessary to detect the appropriate signals beforehand. Numerous methods exist to achieve this, including using nonphysiological cues such as speech, body posture, or facial expressions. Physiological markers like heart rate, breathing, or brain signals like functional magnetic resonance imaging (fMRI) or electroencephalography (EEG) are also investigated to detect them  [2] .\n\nOn the other hand, in the network field, techniques and concepts are evolving rapidly, toward better performance, and lower latency, to keep up with the rapid increase in internet traffic. Among these, the emergence of the quality of experience (QoE) concept did not go unnoticed. It had This paper was produced by the IEEE Publication Technology Group. They are in Piscataway, NJ.\n\nManuscript received December 01, 2022.\n\nan impact on almost every aspect of network environments, regardless of the application or context involving a network  [3] . The procedure to implement such QoE-aware network solution is already really well developed and can include many parts of the network equipment  [4] , creating a control loop whose goal is to maximize QoE.\n\nThe QoE concept has truly changed how networks are designed. Indeed, before the use of QoE as the metric to measure the performance of any network application, Quality of Service (QoS) was at the center of most approaches with a QoS maximization control loop, which is always relevant and used, but QoE makes it possible to go further. The QoS is traditionally measured through the technical characteristics of the said application in the different fields concerned, such as the network and the video domains. It comes from the belief that better values upon these characteristics enable a better quality for the proposed service which is true in general. However, the opposite is not necessarily true; in fact, moderate impairments have been shown to have very little impact on users' perceived quality. This is what the QoE is about; \"How bad can the QoS become without having an impact on the user experience?\" is a great way to summarize the idea of a QoE-driven approach to quality assessment. This is a significant change since maintaining a high QoS can be difficult and expensive. Therefore, QoE can help to reduce end-to-end service complexity and the time used to develop a service for a similar product at the end (from the user's point of view).\n\nUltimately, knowing the user's feedback realistically will help to meet his expectations, making him more likely to pay for this service  [3] . From there, being able to do an accurate QoE estimation is very important. Nevertheless, the QoE estimation oriented towards affective computing is still under-explored, with the use of physiological signals, such as EEG.\n\nBecause brain signals are the ideal place to investigate several cognitive mechanisms, the affective computing sector has taken off thanks to recent advancements in EEG systems. Since its advent, the domain has been expanding, with more and more work falling under its banner. Part of the QoE prediction area focuses on trying to achieve a good prediction using psychophysiological signals such as an electrocardiograms and an electroencephalograms to obtain good prediction, rather than focusing on QoS factors. It is now arXiv:2311.02647v1 [cs.CV] 5 Nov 2023 well known that the QoE is influenced by other factors such as age, preferences in content, mood, and more. The QoE assessment is then a cognitive mechanism by itself, and its estimation is actually a part of affective computing.\n\nIn this article, we investigate a deep learning-based affective computing-driven approach to quality of experience assessment in a multimedia context. A processing pipeline presented here allows the extraction from raw EEG signals of the Differential Entropy (DE) and the Power Spectral Density (PSD) with an observation window of three seconds. The two features are calculated from five different frequency bands, permitting QoE estimation. Our estimation is performed through an LSTM-based deep learning model that has been chosen based on a comparison with two other models. After optimization, the selected model is achieving up to 78% in F1-score, standing in state-of-the-art on this dataset. The contributions of this work are as follows:\n\n• We present a pipeline to process EEG data and extract features with which QoE estimation can be performed. • Three Deep Learning-based architectures are proposed for QoE prediction on which a comparison took place to determine the most efficient model for this topic. • An evaluation of the importance of features and electrodes is performed, the results of which simplify and improve the procedure and the estimation.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Background And Related Work",
      "text": "The QoE estimation field is now very large, with studies about the impact on QoE of network hardware, architectures, or even algorithms. In the literature, QoS-based QoE prediction is widely used, and the research field is still active. In  [5] , Duanmu et al. propose a publicly available dataset containing network and video features, generated by several algorithms used in streaming applications named adaptive bitrate (ABR), and propose an analysis of the said algorithms to enhance their QoE optimization. The solutions take into account the bandwidth available to exploit it at the maximum. Their findings indicate axes of enhancement, such as through a better understanding of the human visual system and psychological behaviors. In  [6] , the authors proposed an objective Bayesian model to estimate a function representing the QoE based on knowledge of the human visual system, which they named the \"Bayesian streaming model index\" (BSMI). The proposed modeling has been optimized on existing datasets and tested on publicly available databases. The results presented are Pearson and Spearman correlations between the model prediction and the real mean opinion score (MOS). Among the existing objective models, the BSMI proposes the best results, with a correlation of 79.3% on average over four datasets, compared to 76.4% for the best overall model (on these same datasets). Other works propose some modifications to the traditional estimation method. For example, Tiotsop et al.  [7]  propose to estimate the QoE in intervals instead of the simple MOS value returned by the participant to give more room to the model while still maintaining the prediction relevance. In fact, the traditional approach is to try to predict the value directly given by the participant. Using well-known video quality metrics, their proposal gives an encouraging result, opening the way to that new type of prediction. In the same way, the work investigating new features for their correlation with QoE is nonetheless important. In  [8] , a new method for conducting QoE assessment experiments is presented, allowing for the management of acceptability and annoyance factors in a single step, thereby reducing the time required for these time-consuming QoE assessments. The proposed method is shown to lead to similar results as the traditional method while being way more convenient for the subjects. They show that users expectations can be modified by the instructions given to the subjects, and we know that these can have an impact on QoE, as psychological factors.\n\nBecause of the cognitive nature of QoE in general, the affective computing domain and its development have inspired many domains, including QoE estimation. In  [9] , Kitao et al. used affective computing factors and electroencephalographic data to estimate the QoE in a video streaming context. This work proposes a way to select EEG features using a generative algorithm (GA). Over 400 features were used, and they showed that the number of features necessary to predict QoE from EEG does not need to be very large. Using an SVM, they improved its performance up to 6% in accuracy with their feature selection method, compared to a random feature selection. The affective computing domain is filled with studies using electroencephalogram (EEG) data and associated analysis. For instance, in  [10] , Rudakov et al. worked on the use of emotion estimation using EEG signals. Exploiting a famous publicly available dataset, the DEAP (Dataset for Emotion Analysis using Physiological signals) dataset, they propose a multi-task model, which is a very interesting approach as a single model is trained on several tasks, reducing the training time necessary. They achieved an accuracy of 96,28% on valence and 96,62% on arousal by training this model on PSD heatmaps of each frequency band of the EEG and differential entropy heatmaps. The success of such work has already shown the potential of the EEG sensor, and many have since tried it in several domains. QoE and EEG have since been correlated, for instance in  [11] , where Kroupi et al. investigated the EEG signals for patterns associated with QoE. Among their findings, they found an asymmetry in the alpha band of the frontal electrodes, which appeared during low-quality perception. Among the various works listed, some points proposed in this work have not yet been investigated, such as the EEG characteristics used here (in particular differential entropy) and their importance in the evaluation of QoE in a multimedia context. This is also valid for different deep learning models, which currently show the best results for the EEG data classification, especially those based on an LSTM model. These further investigations deserve greater attention to obtain better results and possibly simplify the process.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Proposal",
      "text": "In this paper, we are using a publicly available dataset, named SoPMD, which is made for the QoE estimation using",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Dataset",
      "text": "The used SoPMD dataset has been introduced in  [12] , where Perrin et al. created the dataset for QoE estimation from physiological activity. The experiment during which the data were collected was organized as the following. Before the experiments, subjects were required to wear an EEG headset, an ECG, and two respiratory bands. The acquisition consists of three sessions, interspersed with breaks, in which subjects would watch nine 60-second long videos (each preceded by a 10-second baseline) and assess their experience by answering five questions measuring the QoE factors being: \"immersive level\" (IL), \"perceived video quality\" (VQ), \"surrounding awareness\" (SA), \"interest in video content\" (VC), and \"interest in audio content\" (AC) on a nine-point scale each. Subjects were not limited in time during the rating phase. The chosen videos are from nine sequences, each being declined in terms of compression level (high and low QP, with x264 encoding), resolution (SD, HD, UHD), and audio sound system (mono, stereo, 5.1). As required in  [13] , participants used a 56-inch Sony Trimaster SRM-L560 monitor to present stimuli and were seated at a distance of 1.6 times the height of the screen. Audio stimuli were played on an Altec Lansing 5.1 THX speaker system. The environment was quiet, and the ambient light were unobtrusive in both dark and bright scenes. A total of 20 participants were involved to create the dataset. The authors proposed a solution to estimate the immersion level. However, they have exploited all the signals: EEG, ECG, and respiratory, to extract characteristics to train an SVM model. A functional connectivity analysis was used to extract the EEG features. The model was able to achieve an average accuracy of 55.33% on a three classes classification problem. Vijayakumar et al.  [14]  proposed also BiLSTM architecture to achieve the same prediction based on this dataset. In their proposal, they used 19 features from physiological data only (ECG and respiration signals), forming a total of 57 features to feed the model. With the help of a SMOTE data augmentation, their approach achieved an f1 score ranging from 58% to 67% depending on the evaluated QoE factor.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Psychophysiological Data Extraction",
      "text": "Data preprocessing: As previously mentioned, this dataset provides EEG, ECG, and respiration recordings from the subjects during their participation in the experiment. This paper presents a work using only the collected EEG data during this experiment, which is summarized in Fig.  1 . The EEG headset used for the experiment uses 256 electrodes to record brain activity at a frequency of 250Hz. We selected eight well-known electrodes for their ability to show the activity of each external brain region, to keep the spacial information. The electrodes used are as follows : Fp1 ; Fp2 ; T3 ; T4 ; P3 ; P4 ; O1 ; O2. The raw signals cannot be used directly, EEG signals being very sensitive to noise and artifacts. To get rid of the noise, a bandpass filter with cut-off frequencies of 1 Hz and 47 Hz. The frequencies below 1 Hz are not important to us, and the high cut-off frequency was chosen to eliminate the 50 or 60 Hz perturbation due to electrical surroundings. Artifacts have not been removed as they are not very present.\n\nFeature extraction: In EEG analysis, the most used approach is the frequency analysis, to regroup the frequency energies or power in five bands, for their simultaneous appearance during several tasks or states (Delta band activity appearing during unconscious states, for instance) :\n\n• δ (delta) : 1 to 4 Hz\n\n• θ (theta) : 4 to 8 Hz • α (alpha) : 8 to 13 Hz • β (beta) : 13 to 30 Hz • γ (gamma) : 30 to 60 Hz Numerous features can be calculated from such spectral analysis, and among these, the most used and known is the power spectral density (PSD) from the five frequency bands introduced above. It was also important to include the other well-known type of feature, from the family of entropy-based features : the one selected is the differential entropy (DE) one. The DE is a feature that has emerged in affective computing papers (but not only), as it was introduced by Shi et al.  [15]  for the context of vigilance estimation. This feature is the measure the complexity of a continuous random variable, and the article from  Shi et al.  shows the relationship between their novel feature and the logarithm energy spectrum, widely used in EEG signal analysis. The article is presenting how it can be computed, following the equation :\n\nWhere σ is the signal variance of the frequency band i. It has been used in various contexts since.\n\nTo extract these features, it was chosen to use three seconds long segment as the window to perform the welch transform, with 50% of overlap between windows, creating one data point for every 1.5 seconds. This gives us 40 points for each of the 10 features per acquisition, leaving a data shape of (40,80) as input for our model.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Qoe Classification Method",
      "text": "In affective computing, the most used tool for this part are DL classification models, and the results proposed are generally presenting outstanding results, if the models are well constructed regarding the addressed problem. Inspired by literature, the results proposed by studies are significant enough for this approach to be an answer to the problem investigated here. More precisely, some models architectures have been selected for their potential in this context, each having already proved itself. Moreover, in EEG data processing and classification domain, most DL models are handling this data type very well and can outperform every other classification or regression technique known, in some issues. The selected models architecture are the following :\n\n• LSTM-based models : The LSTM architecture is based on LSTM cells, standing for 'Long-Short Term Memory'. These models are a type of recurrent neural network (RNN) for their feedback connections, and the name is a reference its both 'short-term' and 'long-term' memory.\n\nThe architecture we fancy with these is the possibility to use it in a bidirectional way, where data will go through two LSTM layers, with opposite direction of information (forward and backward). This type of model is often encountered in the classification or prediction of time-series data, as their 'memory' is an asset when using such data.\n\n• Transformer-based models : The Transformer architecture has been introduced in 2017 with the goal of replacing LSTM architectures in natural language processing. For this model, the most important part is their self-attention mechanism, allowing them to gather information about a data point relative to its position (that can be named context) in a sequence. This is critical to know as, unlike RNN models, these process the entire input at once. These models are from the Encoder family.\n\n• Convolutional LSTM-based model : This is also a type of model taking advantage of the LSTM cells strength, but also of Convolutional neural network (CNN) models.\n\nThat allows these to collect local spatio-temporal information about the input data pretty well. An implementation of each model has been done to produce preliminary results on the perceived video quality QoE factor, but only the one giving the best results at this time is going to be optimized at maximum for each factor. The one that was withheld after this selection was the BiLSTM-based, which was able to perform way better than the two other models tested, and was less subject to overfit (detailed below).",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Model Optimization",
      "text": "For the models we selected, each layer can be adjusted by numerous parameters, named hyperparameters. For each different setting of each, we have a slightly different model, that can give various results. In DL problems, this part is called model tuning, and is necessary if we want to have the model as optimized for our subject as possible. To address this issue, several methods exist and among which 'Gridsearch' is from. Its name come from the way the algorithm work, which is simple although resourceintensive: given a list of values for each hyperparameter and the model, the algorithm will simply train the model with every possible combination and keep track of the results for each training, viewable as a grid of values. At the end, the algorithm returns the parameters giving the best results, with the obtained results. Applying such an algorithm has the advantage to result in the best model possible given a list of hyperparameters. The major method drawback is the time-consuming aspect since each value added to the list of parameters is adding exponentially more training. Given that model training can already be lengthy, depending on the complexity of the model and the data used with it, this technique exponentially increase the time required for the model hyperparameters adjustment.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Results And Discussion",
      "text": "",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Classification Results",
      "text": "In this part, it is presented the results obtained with each model at the end of their training and after the processing of the entire pipeline mentioned before. • Dropout layers, optimized for each factor with the Grid-Search. • L2 regularisation, also optimized for each factor with the GridSearch.  As said in the classification part, the BiLSTM was the most efficient model, presenting results of 68% to 79% of accuracy for the five QoE factors, with the classes being low, middle, and high (for the concerned factor), as it is discussed below.\n\nThe model is constructed as follows:\n\n• Two bidirectional LSTM layers (with a tanh activation function, and an L2 kernel regularisation optimized with GridSearch), each followed by a BatchNormalisation and a Dropout layer (optimized with GridSearch). In Table  II , we present a part of the result which are the one for the perceived video quality for the three models, where the selected model was finally the best. In the table, we can see that the model was offering various results, placing overall the LSTM-based first with an accuracy of 79% and an F1score of 78%, followed by the Transformer-based with 70% of accuracy and an F1-score of 67%, leaving the last place to the ConvLSTM-based with 61% and 59% for the accuracy and F1-score respectively.\n\nIn the Fig.  2  are the four relevant performances indicators of the selected model for each factor, as a bar graph with: VC as interest in video content; VQ as perceived video quality; AC as interest in audio content; IL as immersive level; and SA as surrounding awareness. It can be noticed that the model is presenting better results on the VQ and AC (78% and 79% of F1-score), and similar results on the VC, IL, and SA (with 69%, 69%, and 68% of F1score). As a reminder that the presented prediction accuracies are compared to the subjects' answers gathered during the   In Fig.  3 , a zoom on the results obtained for the perceived video quality is proposed, with the confusion matrix of the test part after the training phase. The prediction on the classes 'Low' (0) and 'High' (2) are the best with 94% and 85% of accuracy respectively, which are near-perfect results. As expected, the class 'Middle' (1) is the hardest to classify for the model, since the boundary in the features from this class are not really defined, and even, 52% of the examples from that class have been classified right.",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "Feature Importance",
      "text": "The knowledge of which feature, namely frequency band and electrode, has the most impact on the model is an important piece of information to us, for the future model optimization. In order to have an idea of this, it was decided to simply train the model while removing a frequency band, to see the impact it would have on the model prediction. The same method is used for the electrodes, and these results are presented in Fig.  4 . For these two figures, the QoE factor on which the model is trained is the 'Interest in the video content (VC)', but any could have been selected.\n\nFirst, for the frequency band importance, we see on the left of the Fig.  4  that each frequency band has at least some necessary information for the estimator prediction, as removing any frequency band has an impact on the estimator results. If we look at this graph, it is obvious that removing the Delta band has less impact on the results, taking away 8% from the original F1-score. This indicates that the Delta band contains the least information. It can be noticed that the other bands removal has a bigger impact than Delta, with Alpha, Theta, Gamma et Beta respectively taking away 13%, 14%, 15%, and 17% from the F1-score. From these results, we can classify their importance (from the more important to the less important) as: Beta, Gamma, Theta, Alpha, and Delta. Secondly, the electrode importance can be seen on the right of Fig.  4  and is presenting more differences. Two main things can be noticed :\n\n1) P3 and P4 electrode removal have almost no impact on the results the model produce with 4% and 6% less on the F1-score. This shows that the parietal lobes are poor in information for the QoE estimation with the proposed model. 2) At the opposite, the removal of the O1 or O2 electrodes have the strongest impact on the results, with 21% and 16% lower F1-score. From the two importance analysis, it is clear that it could be possible to reduce the complexity of a real implementation while minimizing the impact on the results by removing the Delta frequency band from the feature extraction and the P3 and P4 electrodes. The entire results presented in the article are encouraging for the possibility to read a user's QoE directly in the signals from his brain, to assess the quality of a multimedia application in a simpler and more efficient way, with state-of-the-art results.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Conclusion And Future Work",
      "text": "This paper presents an affective computing inspired approach for QoE estimation in multimedia applications. Using a publicly available dataset, features calculated from EEG and a BiLSTM-based deep learning model proposed an underexplored way to predict QoE, presenting results up to 79% on accuracy and 78% on F1-score. We analyze the resulting model to show the importance of each EEG frequency band and electrode used. This will also contributes to future improvements and simplifications, for easier integration into existing systems. These results could make it possible to improve the QoE evaluation of multimedia services by making it simpler and more efficient, particularly in virtual and augmented reality fields. In fact, these emerging next-generation multimedia technologies are currently only possible with the obligation to wear a dedicated helmet; this simplifies the addition of EEG electrodes in the helmet and would simplify the implementation of the proposed solution. Moreover, with a simplification of the needed data for the prediction, and improvement in the EEG field (in particular on the dry electrodes) an improvement of the results is strongly possible.\n\nAs future work, we are investigating the use of all available data which should improve the current results. But the presented model needs to be adapted to be able to handle this, as it does not improve using all data for now. Overall, the results obtained in this article reveal the potential of affective computing techniques in the field of QoE prediction and it could still be improved with a complete description of the user's psychophysiological data. On the other hand, integrating this affective computing-based Quality of Experience (QoE) assessment into a QoE-maximizing control loop will be a big step forward. The real-time aspect of such a system must also be considered because the correction must be applied rapidly.",
      "page_start": 6,
      "page_end": 7
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Data processing pipeline",
      "page": 3
    },
    {
      "caption": "Figure 1: The EEG headset used for the experiment uses 256 electrodes",
      "page": 3
    },
    {
      "caption": "Figure 2: Results of the BiLSTM for each QoE factor",
      "page": 5
    },
    {
      "caption": "Figure 3: Confusion matrix of the test part for the perceived",
      "page": 5
    },
    {
      "caption": "Figure 2: are the four relevant performances indicators",
      "page": 5
    },
    {
      "caption": "Figure 4: Results of the BiLSTM on the first QoE factor removing one frequency band (left) and removing one electrode (right)",
      "page": 6
    },
    {
      "caption": "Figure 3: , a zoom on the results obtained for the perceived",
      "page": 6
    },
    {
      "caption": "Figure 4: For these two figures, the QoE factor on",
      "page": 6
    },
    {
      "caption": "Figure 4: that each frequency band has at least",
      "page": 6
    },
    {
      "caption": "Figure 4: and is presenting more differences. Two main things",
      "page": 6
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "BidirectionalLSTMunitslayer1",
          "VC": "16",
          "VQ": "128",
          "AC": "64",
          "IL": "32",
          "SA": "64"
        },
        {
          "Column_1": "BidirectionalLSTMunitslayer2",
          "VC": "128",
          "VQ": "16",
          "AC": "128",
          "IL": "64",
          "SA": "128"
        },
        {
          "Column_1": "Dropout",
          "VC": "0,7",
          "VQ": "0,2",
          "AC": "0,7",
          "IL": "0,4",
          "SA": "0,2"
        },
        {
          "Column_1": "L2regulation",
          "VC": "0,2",
          "VQ": "0,6",
          "AC": "0,4",
          "IL": "0,6",
          "SA": "0,2"
        }
      ],
      "page": 5
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Model": "BiLSTM",
          "Accuracy": "79,00%",
          "F1-score": "78,00%",
          "Precision": "80,00%",
          "Recall": "79,00%"
        },
        {
          "Model": "Transformer",
          "Accuracy": "70,00%",
          "F1-score": "67,00%",
          "Precision": "70,00%",
          "Recall": "70,00%"
        },
        {
          "Model": "ConvLSTM",
          "Accuracy": "61,00%",
          "F1-score": "59,00%",
          "Precision": "59,00%",
          "Recall": "61,00%"
        }
      ],
      "page": 6
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Automated emotion recognition: Current trends and future perspectives",
      "authors": [
        "M Maithri",
        "U Raghavendra",
        "A Gudigar",
        "J Samanth",
        "P Barua",
        "M Murugappan",
        "Y Chakole",
        "U Acharya"
      ],
      "year": "2022",
      "venue": "Computer Methods and Programs in Biomedicine"
    },
    {
      "citation_id": "2",
      "title": "OVPD: Odor-Video Elicited Physiological Signal Database for Emotion Recognition",
      "authors": [
        "J Xue",
        "J Wang",
        "S Hu",
        "N Bi",
        "Z Lv"
      ],
      "year": "2022",
      "venue": "IEEE Transactions on Instrumentation and Measurement"
    },
    {
      "citation_id": "3",
      "title": "Quality of Experience for Multimedia: Application to Content Delivery Network Architecture",
      "authors": [
        "Abdelhamid Mellouk",
        "Anh Tran",
        "Said Hoceini"
      ],
      "year": "2013",
      "venue": "Quality of Experience for Multimedia: Application to Content Delivery Network Architecture"
    },
    {
      "citation_id": "4",
      "title": "Supervised-Learning-Based QoE Prediction of Video Streaming in Future Networks: A Tutorial with Comparative Study",
      "authors": [
        "A Ahmad",
        "A Mansoor",
        "A Barakabitze",
        "A Hines",
        "L Atzori",
        "R Walshe"
      ],
      "year": "2021",
      "venue": "IEEE Communications Magazine"
    },
    {
      "citation_id": "5",
      "title": "Assessing the Quality-of-Experience of Adaptive Bitrate Video Streaming, 2nd ed",
      "authors": [
        "Z Duanmu",
        "W Liu",
        "Z Li",
        "D Chen",
        "Z Wang",
        "Y Wang",
        "W Gao"
      ],
      "year": "2004",
      "venue": "Assessing the Quality-of-Experience of Adaptive Bitrate Video Streaming, 2nd ed"
    },
    {
      "citation_id": "6",
      "title": "Experience Model for Adaptive Streaming Videos",
      "authors": [
        "Z Duanmu",
        "W Liu",
        "D Chen",
        "Z Li",
        "Z Wang",
        "Y Wang",
        "W Gao",
        "Bayesian"
      ],
      "year": "2022",
      "venue": "Experience Model for Adaptive Streaming Videos"
    },
    {
      "citation_id": "7",
      "title": "Computing Quality-of-Experience Ranges for Video Quality Estimation",
      "authors": [
        "L Tiotsop",
        "E Masala",
        "A Aldahdooh",
        "G Wallendael",
        "M Barkowsky"
      ],
      "year": "2019",
      "venue": "Eleventh International Conference on Quality of Multimedia Experience (QoMEX)"
    },
    {
      "citation_id": "8",
      "title": "AccAnn: A New Subjective Assessment Methodology for Measuring Acceptability and Annoyance of Quality of Experience",
      "authors": [
        "J Li",
        "L Krasula",
        "Y Baveye",
        "Z Li",
        "P Callet"
      ],
      "year": "2019",
      "venue": "IEEE Transactions on Multimedia"
    },
    {
      "citation_id": "9",
      "title": "GA-based feature selection for QoE estimation using EEG during video viewing",
      "authors": [
        "K Kitao",
        "D Kominami",
        "M Murata"
      ],
      "year": "2020",
      "venue": "International Conference on Emerging Technologies for Communications (ICETC)"
    },
    {
      "citation_id": "10",
      "title": "Multi-Task CNN model for emotion recognition from EEG Brain maps",
      "authors": [
        "E Rudakov",
        "L Laurent",
        "V Cousin",
        "A Roshdi",
        "R Fournier",
        "A Nait-Ali",
        "T Beyrouthy",
        "S Kork"
      ],
      "venue": "th International Conference on Bio-Engineering for Smart Technologies (BioSMART)"
    },
    {
      "citation_id": "11",
      "title": "EEG CORRELATES DURING VIDEO QUALITY PERCEPTION. 22nd European Signal Processing Conference",
      "authors": [
        "E Kroupi",
        "P Hanhart",
        "J Lee",
        "M Rerabek",
        "T Ebrahimi"
      ],
      "year": "2014",
      "venue": "EEG CORRELATES DURING VIDEO QUALITY PERCEPTION. 22nd European Signal Processing Conference"
    },
    {
      "citation_id": "12",
      "title": "Multimodal Dataset for Assessment of Quality of Experience in Immersive Multimedia. MM '15: Proceedings of the 23rd ACM international conference on Multimedia",
      "authors": [
        "A Perrin",
        "H Xu",
        "E Kroupi",
        "M Rerabek",
        "T Ebrahimi"
      ],
      "year": "2015",
      "venue": "Multimodal Dataset for Assessment of Quality of Experience in Immersive Multimedia. MM '15: Proceedings of the 23rd ACM international conference on Multimedia"
    },
    {
      "citation_id": "13",
      "title": "Subjective test methodology for assessing impact of initial loading delay on quality of experience",
      "year": "2019",
      "venue": "Subjective test methodology for assessing impact of initial loading delay on quality of experience"
    },
    {
      "citation_id": "14",
      "title": "BiLSTM-based Quality of Experience Prediction using Physiological Signals",
      "authors": [
        "S Vijayakumar",
        "R Flynn",
        "P Corcoran",
        "N Murray"
      ],
      "venue": "14th International Conference on Quality of Multimedia Experience (QoMEX)"
    },
    {
      "citation_id": "15",
      "title": "Differential Entropy Feature for EEGbased Vigilance Estimation. 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)",
      "authors": [
        "L Shi",
        "Y Jiao",
        "B Lu"
      ],
      "year": "2013",
      "venue": "Differential Entropy Feature for EEGbased Vigilance Estimation. 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)"
    }
  ]
}