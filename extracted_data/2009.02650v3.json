{
  "paper_id": "2009.02650v3",
  "title": "A Genetic Feature Selection Based Two-Stream Neural Network For Anger Veracity Recognition",
  "published": "2020-09-06T05:52:41Z",
  "authors": [
    "Chaoxing Huang",
    "Xuanying Zhu",
    "Tom Gedeon"
  ],
  "keywords": [
    "Anger veracity",
    "Two-stream architecture",
    "Neural network",
    "Genetic algorithm"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "People can manipulate emotion expressions when interacting with others. For example, acted anger can be expressed when the stimulus is not genuinely angry with an aim to manipulate the observer. In this paper, we aim to examine if the veracity of anger can be recognized from observers pupillary data with computational approaches. We use Genetic-based Feature Selection (GFS) methods to select timeseries pupillary features of observers who see acted and genuine anger as video stimuli. We then use the selected features to train a simple fully connected neural network and a two-stream neural network. Our results show that the two-stream architecture is able to achieve a promising recognition result with an accuracy of 93.6% when the pupillary responses from both eyes are available. It also shows that genetic algorithm based feature selection method can effectively improve the classification accuracy by 3.1%. We hope our work could help current research such as human machine interaction and psychology studies that require emotion recognition.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "The veracity of emotions plays an essential role in human interaction. It influences people's view towards others after the observer observes a certain emotion  [1] . In reality, human beings are sometimes very poor at telling whether a person's emotion is genuine or posed, especially in the scenario that humans are usually asked to use verbal information to make the prediction  [17] . This kind of mistake may negatively affect some current research like psychological studies which includes emotion observation  [18] . Thus, it is worth looking into the problem of using computational algorithms to take the physiological responses of humans to aid the recognition. Also, in human-machine interaction, it is important to let the machine know whether a human's emotion is disguised or genuine if the interaction involves emotion  [3] . There has been work using physiological signals of observers who are exposed to emotional stimuli to interpret the emotion of the stimuli. In  [2]  and  [3] , a classifier is trained to identify if a person's smile or anger is genuine or posed. Meanwhile, a human thermal data based algorithm is proposed to analyse human's stress in  [4] .\n\nNeural Networks (NNs) are able to learn their parameters automatically via back-propagation and can be used to map physiological data to emotion veracity. However, since human beings interact with the environment, it is likely that physiological data being collected by sensors are noisy. Noisy features can dampen the learning process of the NN on the data-set, since the model needs to learn the underlying pattern of the noise. On the other hand, the model can overfit the dataset when the training time has to be escalated. Therefore, it is crucial to look into the problem of selecting useful features from the physiological data-set. Anomaly detection has a profound studied history. One of the most classic methods is the generative model learning approach  [10] . However, this method requires a cumbersome learning process and relies heavily on distribution assumptions. Other works have also been done to detect noisy and fraud features  [6, 7] , and genetic algorithm is used in  [5]  to select features without much human intervention. Since the noise in physiological data is usually not obvious to non-expert humans and has long temporal sequences, the evolutionary based genetic algorithm becomes a reasonable way for avoiding intractable manual selection. In the original work of  [3] , it is shown that using pupillary data, the model can recognise anger veracity with an accuracy of 95%, which is a significant improvement over verbal data. However, the collected data may contain environment-affected noise and the sensors occasionally fail to collect physiological data at some time stages. When we take the time-series information into consideration, not all the recorded data from the sensor plays essential roles in classification due to this noisiness and redundancy, which thus requires feature selection, and the genetic algorithm provides a way to achieve this. Therefore, we study the effect of genetic-based feature selection (GFS)  [13]  on anger veracity recognition in this paper.\n\nThe contribution of this paper is two-fold:\n\n-We adopt a two-stream neural-network to effectively use the physiological data (pupil diameters) from the two eyes of humans to predict the anger veracity of the emotion stimuli. -We adopt the genetic-based feature selection method to select useful features from the noisy temporal data due to environment noise and occasional sensor failures (e.g. eye-blinks) and thus to enhance the recognition performance.\n\nIn this paper, we first tune a baseline NN with one hidden layer by taking the pupillary data from one eye as input. Then we apply GFS to the time-series data and verify our proposed two-stream model can handle the binocular pupillary information. The rest of this paper is organised as follows: Section 2 introduces the NN architecture, and the GFS pipeline. Section 3 is about the experiments and results. Discussions are also provided in this section. Section 4 includes future work and concludes this paper.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Method",
      "text": "",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Dataset",
      "text": "We use Chen et al's anger dataset  [3] . The dataset was collected by displaying 20 video segments to 22 different persons (observers). The observers watched the presenters' anger expression in the video and the pupillary response of the observers were collected by an eye-tracking sensor. A sample in the dataset means the pupillary data of a person which was collected when the person watched a video, and each of them is labelled with \"Genuine\" or \"Posed\", meaning a genuine anger expression or a posed anger expression is observed. The videos have various lengths and the recorded data sequence length of each samples varies from 60 time-steps to 186 time-steps. The sensor recording rate for each of the samples is 60Hz. The dataset contains the pupillary response from each observer's two eyes at each time-step as well as the mean statistics.",
      "page_start": 1,
      "page_end": 3
    },
    {
      "section_name": "Network Architecture",
      "text": "Baseline Architecture In the baseline model, we adopt a simple fully-connected neural network architecture with one hidden layer with n hidden neurons. There are three potential choices of activation function in our NN, which are Sigmoid, Tanh and ReLU. We will investigate the effect of different choices of n and activation function type in the experiment part. Since this is a binary classification, we choose cross-entropy loss as the loss function.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Two-Stream Architecture",
      "text": "Inspired by the two-stream architecture in video recognition  [11, 12] , we adopt a two-stream fully connected architecture in our classification task, which is shown in Figure  1 . For every stream, the sub-stream network is the baseline model and the feature vector from the two streams are fused together to a one-layer fully connected layer for final prediction. There are two potential kinds of input to the network. The first scenario is, the first stream takes the pupillary temporal data from the left eye and the second stream takes the pupillary data from the right eye. The second scenario is, the first stream takes the pupillary temporal data from the left (right) eye and the second stream takes the pupillary diameter differences at each time step from the left (right) eye. The pupillary difference for each time step is the data at the current time step minus the data at the previous step.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Data Pre-Processing And Feature Selection",
      "text": "Data pre-processing The data in the dataset is temporal, with values from both eyes at each time time-step. We regard every sequence of time-series data of each sample as an input vector to the neural network. To deal with the length varying issue, we use zero padding to pad every feature vector to the same length (186 × 1). Genetic-based feature selection The feature selection mask is indicated by a binary vector with the length of the feature-vector (0 for omitting a feature and 1 for keeping a feature). In a genetic algorithm, the selection mask is regarded as the chromosome. We first initialize the population size as n + 1, and we adopt a neural network to compute the validation classification accuracy as the fitness value. Note that for different chromosomes, the input size of the neural network is different, and thus we are not only doing a feature selection but also conducting a network architecture selection. We adopt a tournament-based reproduction  [14] , in which we create n 2 sets of tournament-group, and we randomly choose a fix size of members from the current generation to form the tournament-groups as the population pool for generating off-spring. Note that we actually repeat n 2 times of tournament group creation, which means one chromosome can appear in different tournament groups. In each tournament-group, two parents are selected by using the selection probability which is obtained by its normalized fitness value in the population (proportional selection). The crossover generates two off-springs by a one-point crossing. Therefore, the tournament-reproduction can generates n off-springs, while the selected one is the chromosome with the highest fitness value in the current generation. Every generated off-spring goes through a mutation process to increase the gene diversity. To sum up, the population of each generation retains at n + 1 while the parents' selection in every generation's reproduction need to go through a fierce tournament competition. The pipeline is shown in Figure  2 .",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Experiments And Discussions",
      "text": "",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Experiment Settings",
      "text": "We first shuffle the data-set and randomly split out 80% of the data as training patterns. The rest of the data are for testing. We use Python3. 1.0  [9]  to implement the experiment and the environment is Windows 10. Since the training set is small, we only use an i7-8750H CPU for computation and we adopt batch gradient descent an Adam  [8]  optimizer. For the optimizer, the hyper-parameters are: β 1 = 0.9 and β 2 = 0.999. The learning rate is set to be 1e-4 and a weight-decay of 1e-5 is used to prevent over-fitting. The iteration number of training is set to be 1000 epochs. The random seed numbers are set as 1000, 2000, 3000, 4000 and 5000. We will denote them as sets 1 to 5 respectively in this context. All the results are reported based on five-fold cross-validation by using set 1 to set 5.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Baseline Model",
      "text": "We train the model under different settings of hidden neuron number n and different activation function types. We take the left eye pupillary data as input.\n\nThe results, which are the average accuracy of the 5 runs, are shown in Table  1 . As is clearly shown, the performance of using ReLU activation function with 60 neurons shows significant advantage over those of Tanh and Sigmoid since it avoids the problem of gradient diminishing and overfitting. In the rest of the experiments, we will use the model using ReLU with 60 hidden units as the baseline. We also present the precision, recall and F1 score of the baseline model after five runs in Table  2 .",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Experiments On Gfs And Two-Stream Architecture",
      "text": "Classification without feature-selection We first conduct experiments on training the fully-connected classifier without applying GFS on the temporal features. We compare the 5-set averaged results of different input settings of both single-stream and two-stream models, and the results are shown in Table  3 . The hidden layer number is still 60. We also present the precision, recall as well as the F1 score of the best model here. The results are shown in Table  4 . We can also notice that using information from two eyes achieves a better performance than only using information from either single eye, and this is aligned with our human intuition. It should also be noted that taking the diameter differences into consideration does not provide an improvement, this may be due to the fact that the diameter change in every time-step is very small and does not provide much significant temporal information.\n\nEffectiveness of GFS We study the effect of applying Genetic feature selection to the model. During the feature selection stage, 80% of the training data is used for training while 20% of the training data is used for validation to compute the fitness value. After selecting the best chromosome, we train our model on the entire training set. For every tournament group, the member number is set to be 9. The generation number is set to be 10. The population number is set to be 21 and the mutation rate is 0.001. In the two-stream case, both the streams use the same feature selection mask. We conduct the GFS experiment on the double-eye two stream model as well as the left-eye single stream model. The results are shown in Table  5 . As we can see from Table  3  and 5, by using the GFS method, the single-stream model with left eye input can achieve a better performance by applying feature selection, the single-stream model using feature selection can even surpass the performance of the double-eye two stream model that does not have feature selection. Moreover, the double-eye two stream model with feature-selection achieves the best performance among all. The result reveals an underlying drawback, that using zero padding to fill up the length of those \"short\" vector create feature redundancy, and feature-selection can improve the recognition performance.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Discussion",
      "text": "Why does the GFS improve the recognition performance? Perhaps the most plausible explanation is that the GFS helps to eliminate some of the noisy pupillary data during collection. In the original paper using the dataset, it is mentioned that the eye-blinks of the humans exist, and which is prone to affect some of the collected pupillary diameter values. In fact, we have found that many of the feature selection masks have many zero entries before the zero padding stage, which means those actual collected data are removed.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Conclusion And Future Work",
      "text": "This paper examines applying two-stream neural networks with genetic-based feature selection on anger veracity recognition, to tackle the problem of noisy data collection and sensor failure during physiological data collection. From the experimental results, it can be concluded that the two-stream architecture can effectively handle the data from both eyes of humans and it is crucial to take these binocular physiological reactions into consideration when doing anger veracity recognition. It can also be concluded that applying genetic-based feature selection can effectively improve the model performance and remove redundant or noisy features.\n\nIn our work, we use the same feature mask for selecting features from both eyes. One might question that the data behaviour from two eyes may be different and applying an identical mask overlooks this possibility to a certain extent. Indeed, the asymmetric reaction of both eyes can affect the data collection of the sensor differently, and it is worth looking into the problems of finding two feature selection masks that can reflect the linkage and difference between the two eyes.\n\nAs for the model that uses time-series data, our fully-connected model requires zero padding to deal with varying length data, which creates redundancy and reduces flexibility. Therefore, it is worth looking into the method of applying RNN/LSTM  [15]  or Transformer models  [16]  in the future.",
      "page_start": 8,
      "page_end": 8
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: For every stream, the sub-stream network is the baseline model and",
      "page": 3
    },
    {
      "caption": "Figure 1: Two-stream network architecture",
      "page": 4
    },
    {
      "caption": "Figure 2: Genetic-algorithm pipeline",
      "page": 5
    }
  ],
  "tables": [
    {
      "caption": "Table 2: Table 1. Test accuracy of the baseline model (%)",
      "data": [
        {
          "30\n90.26\n91.03\n91.03": "40\n91.54\n91.79\n92.05"
        },
        {
          "30\n90.26\n91.03\n91.03": "50\n91.54\n90.30\n92.05"
        },
        {
          "30\n90.26\n91.03\n91.03": "60\n93.08\n91.54\n91.80"
        },
        {
          "30\n90.26\n91.03\n91.03": "70\n90.52\n91.27\n91.80"
        },
        {
          "30\n90.26\n91.03\n91.03": "80\n91.54\n91.28\n92.05"
        }
      ],
      "page": 6
    },
    {
      "caption": "Table 3: Test accuracy of different model (%)",
      "data": [
        {
          "Double-eyes (two-stream)\n93.58": "Left-eye (single-stream)\n93.08"
        },
        {
          "Double-eyes (two-stream)\n93.58": "Right-eye (single-stream)\n92.31"
        },
        {
          "Double-eyes (two-stream)\n93.58": "Left-eye+Left-diﬀerences (two-stream)\n91.03"
        },
        {
          "Double-eyes (two-stream)\n93.58": "Right-eye+Right-diﬀerences (two-stream)\n91.03"
        }
      ],
      "page": 7
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Facial expressions of emotion influence interpersonal trait inferences",
      "authors": [
        "B Knutson"
      ],
      "year": "1996",
      "venue": "journal of Nonverbal Behavior"
    },
    {
      "citation_id": "2",
      "title": "Classifying posed and real smiles from observers' peripheral physiology",
      "authors": [
        "M Hossain",
        "T Gedeon"
      ],
      "year": "2017",
      "venue": "Proceedings of the 11th EAI International Conference on Pervasive Computing Technologies for Healthcare"
    },
    {
      "citation_id": "3",
      "title": "Are you really angry? detecting emotion veracity as a proposed tool for interaction",
      "authors": [
        "L Chen",
        "T Gedeon",
        "M Hossain",
        "S Caldwell"
      ],
      "year": "2017",
      "venue": "Proceedings of the 29th Australian Conference on Computer-Human Interaction"
    },
    {
      "citation_id": "4",
      "title": "Thermal superpixels for bimodal stress recognition",
      "authors": [
        "R Irani",
        "K Nasrollahi",
        "A Dhall",
        "T Moeslund",
        "T Gedeon"
      ],
      "year": "2016",
      "venue": "Sixth International Conference on Image Processing Theory, Tools and Applications (IPTA)"
    },
    {
      "citation_id": "5",
      "title": "A genetic algorithm-based method for feature subset selection",
      "authors": [
        "F Tan",
        "X Fu",
        "Y Zhang",
        "A Bourgeois"
      ],
      "year": "2008",
      "venue": "Soft Computing"
    },
    {
      "citation_id": "6",
      "title": "Outlier detection using replicator neural networks",
      "authors": [
        "S Hawkins",
        "H He",
        "G Williams",
        "R Baxter"
      ],
      "year": "2002",
      "venue": "International Conference on Data Warehousing and Knowledge Discovery"
    },
    {
      "citation_id": "7",
      "title": "Balancing bias and variance: Network topology and pattern set reduction techniques",
      "authors": [
        "T Gedeon",
        "P Wong",
        "D Harris"
      ],
      "year": "1995",
      "venue": "International Workshop on Artificial Neural Networks"
    },
    {
      "citation_id": "8",
      "title": "Adam: A method for stochastic optimization",
      "authors": [
        "D Kingma",
        "J Ba"
      ],
      "year": "2014",
      "venue": "Adam: A method for stochastic optimization",
      "arxiv": "arXiv:1412.6980"
    },
    {
      "citation_id": "9",
      "title": "Pytorch: An imperative style, highperformance deep learning library",
      "authors": [
        "A Paszke",
        "S Gross",
        "F Massa",
        "A Lerer",
        "J Bradbury",
        "G Chanan",
        "T Killeen",
        "Z Lin",
        "N Gimelshein",
        "L Antiga"
      ],
      "year": "2019",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "10",
      "title": "Pattern recognition and machine learning",
      "authors": [
        "M Svensen",
        "C Bishop"
      ],
      "year": "2007",
      "venue": "Pattern recognition and machine learning"
    },
    {
      "citation_id": "11",
      "title": "Convolutional two-stream network fusion for video actionrecognition",
      "authors": [
        "C Feichtenhofer",
        "A Pinz",
        "A Zisserman"
      ],
      "year": "2016",
      "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition"
    },
    {
      "citation_id": "12",
      "title": "Two-stream convolutional networks for action recognition in videos",
      "authors": [
        "K Simonyan",
        "A Zisserman"
      ],
      "year": "2014",
      "venue": "Advances in neural information processing systems"
    },
    {
      "citation_id": "13",
      "title": "Genetic algorithms as a tool for feature selection in machine learning",
      "authors": [
        "H Vafaie",
        "De",
        "K Jong"
      ],
      "year": "1992",
      "venue": "Genetic algorithms as a tool for feature selection in machine learning"
    },
    {
      "citation_id": "14",
      "title": "Structural optimization by genetic algorithms with tournament selection",
      "authors": [
        "J Yang",
        "C Soh"
      ],
      "year": "1997",
      "venue": "Journal of Computing in Civil Engineering"
    },
    {
      "citation_id": "15",
      "title": "Learning to forget: Continual prediction with lstm",
      "authors": [
        "F Gers",
        "J Schmidhuber",
        "F Cummins"
      ],
      "year": "1999",
      "venue": "Learning to forget: Continual prediction with lstm"
    },
    {
      "citation_id": "16",
      "title": "Attention is all you need",
      "authors": [
        "A Vaswani",
        "N Shazeer",
        "N Parmar",
        "J Uszkoreit",
        "L Jones",
        "A Gomez",
        "L Kaiser",
        "I Polosukhin"
      ],
      "year": "2017",
      "venue": "Advances in neural information processing systems"
    },
    {
      "citation_id": "17",
      "title": "Neural networks assist crowd predictions in discerning the veracity of emotional expressions",
      "authors": [
        "Z Qin",
        "T Gedeon",
        "S Caldwell"
      ],
      "year": "2018",
      "venue": "International Conference on Neural Information Processing"
    },
    {
      "citation_id": "18",
      "title": "The psychology of emotion: Theories of emotion in perspective",
      "authors": [
        "K Strongman"
      ],
      "year": "1996",
      "venue": "The psychology of emotion: Theories of emotion in perspective"
    }
  ]
}