{
  "paper_id": "2506.20204v1",
  "title": "Affective Priming Score: A Data-Driven Method To Detect Priming In Sequential Datasets",
  "published": "2025-06-25T07:48:22Z",
  "authors": [
    "Eduardo Gutierrez Maestro",
    "Hadi Banaee",
    "Amy Loutfi"
  ],
  "keywords": [
    "Affective priming",
    "ambiguity",
    "data-driven"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Affective priming exemplifies the challenge of ambiguity in affective computing. While the community has largely addressed this issue from a label-based perspective, identifying data points in the sequence affected by the priming effect, the impact of priming on data itself, particularly in physiological signals, remains underexplored. Data affected by priming can lead to misclassifications when used in learning models. This study proposes the Affective Priming Score (APS), a data-driven method to detect data points influenced by the priming effect. The APS assigns a score to each data point, quantifying the extent to which it is affected by priming. To validate this method, we apply it to the SEED and SEED-VII datasets, which contain sufficient transitions between emotional events to exhibit priming effects. We train models with the same configuration using both the original data and priming-free sequences. The misclassification rate is significantly reduced when using priming-free sequences compared to the original data. This work contributes to the broader challenge of ambiguity by identifying and mitigating priming effects at the data level, enhancing model robustness, and offering valuable insights for the design and collection of affective computing datasets.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "I. Introduction",
      "text": "Ambiguity is an increasingly important research challenge in affective computing. Researchers from multiple disciplines tackle this issue from different perspectives. In psychology, ambiguity arises in various contexts, such as designing stimuli that effectively engage participants or defining and labeling emotional concepts consistently. In computer science, ambiguity becomes a challenge in machine learning when labels are subjective and do not precisely represent the underlying data, as is often the case when labeling data with emotions.\n\nAffective priming is a concrete case of ambiguity in affective computing, where the order of emotional events influences how subjects perceive and react to subsequent stimuli  [1] . Prior studies have examined this effect primarily from a labeling perspective. For instance, authors demonstrated in  [2]  that previously seen images biased annotators' judgmentsneutral facial expressions were more likely to be labeled as sad if preceded by a sequence of sad expressions. Similarly, in  [3] , authors analyzed how inter-annotator disagreement led Fig.  1 : Affective priming can be observed in sequential datasets where a set of emotional categories is induced (happy: green, neutral: blue, sad: red). Models trained on data points affected by the priming effect (highlighted in red in the top sequence) tend to misclassify emotions.\n\nto labels influenced by priming, ultimately affecting model performance.\n\nAlthough the community has explored the effects of priming mainly from the label perspective, i.e., how priming manifests in labeled data, this effect also alters the underlying data itself. Some data modalities, like physiological signals, are highly susceptible to the priming effect. For example, in  [4] , researchers observed statistically significant differences in model performance when trained on datasets in which a stressful task was induced before an amusement task, suggesting that priming is present in the data. However, their analysis was limited to data sequences containing only a single transition between emotional states, which is insufficient to generalize the presence of priming. Thus, the study of data-centric priming remains fairly unexplored.\n\nOur work addresses this gap by introducing the Affective Priming Score (APS), a method designed to identify data points affected by priming in sequential datasets. The APS assigns a score to each data point, quantifying the extent to which it has been influenced by the emotional event preceding it. We hypothesize that data points affected by priming are more prone to misclassification, particularly into the class of the preceding event. Figure  1  illustrates such a hypothesis. To validate this hypothesis, we introduce the Priming Error (PE) metric, which measures the proportion of data points misclassified as the previous event's class. Since priming labels are not explicitly available in datasets, PE serves as an indirect validation tool.\n\nOur experimental results show that training models on datasets where high-APS data points have been removed leads to a significant reduction in the PE metric, confirming the effectiveness of APS in detecting priming-affected data points. Additionally, APS provides a practical tool for dataset design, allowing researchers to visualize the extent to which data points might be influenced by the sequentiality of induced stimuli.\n\nThis study contributes to the broader challenge of ambiguity in affective computing by addressing the data-driven impact of affective priming. By identifying and mitigating priming effects at the data level, our approach enhances model robustness and provides insights for the design and collection of affective computing datasets.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Ii. Related Work",
      "text": "",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "A. Priming In Affective Computing",
      "text": "In affective computing, the priming effect has been explicitly explored in several works. In  [2] , the authors studied how priming affects biases in labeling facial expression images when presented in a sequence. They investigated the impact of sequence order on labeling facial expressions and found a positive correlation: Participants were more likely to label a neutral image with the emotion corresponding to the preceding positive or negative images in the sequence. The authors in  [3]  followed a similar path by proposing a metric to quantify the affective priming present in the annotation of the data in the speech data. Additionally, the authors used this metric to create subsets of different levels of priming and found better performance of models trained on less biased annotations. In machine learning, affective priming is associated with data samples being labeled with noisy or ambiguous information, which can hinder the performance of the model  [3] .\n\nThe sequential order of events can also influence the data that is generated. For example, the physiological reaction to a stressful event may have so called lingering effects that influence the data collected during subsequent events. In  [4] , Maestro et al. investigated this impact and found significant statistical differences in model performance between two groups. In the first group, amusement stimuli appeared first in the sequence, whereas in the second group, stressful stimuli came first. Performance in the second group dropped significantly compared to the first, supporting the hypothesis that the order of stimuli influences the data-i.e., affective priming occurs from a data perspective as well. However, the data sequences used in  [4]  were short and contained only one transition between different emotional states, making it difficult to generalize the extent of the priming effect.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "B. Sequential Models In Affective Computing",
      "text": "The physiological response to an emotional stimulus generates data that contains temporal information. Sequential models are designed to capture temporal relationships between data points in a sequence and extract meaningful patterns from time-series data. In the literature, Long Short-Term Memory (LSTM)  [5]  networks and transformer  [6]  models are the most widely used architectures for learning tasks involving timedependent data, with the latter representing the state-of-the-art approach.\n\nIn affective computing, these models are used to improve the prediction accuracy in different benchmarks. However, in the literature, there are studies that make use of such model architectures, where the temporality between samples in the sequence is not correctly considered. For example, in  [7] , the authors proposed an efficient LSTM network where the number of channels was used to define the temporality in the model's input data. Similar input data is proposed in  [8] . In this case, the LSTM architecture was fed at each time step by one of the 20 features in each data point.\n\nThere are other studies in the field where the model is fed by sequences of data, being able to learn patterns in the transitions between emotional states. However, the validation method chosen to evaluate the trained model may hide the difficulties present in affective sequential datasets. The stationary property of a signal is normally not the same throughout the transitions from one emotional state to another. In  [9]  and  [10] , an LSTM and Transformer architecture was trained, respectively, where the input data was configured to capture temporal information in the sequence. However, the data were split randomly, making the learning task less challenging as the model would see data points for the same class where the stationarity was different. Similarly, it happens in  [11]    [12] , where the authors used the K-fold validation method.\n\nCompared with related work, this study studies the priming effect from a data-driven perspective, i.e., how priming impacts the data quality in sequential way. Additionally, importance is given to the validation method chosen, as the impact of the priming effect may be eluded when validation methods chosen that do not keep the temporality between the train and test sets.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Iii. Datasets",
      "text": "This study employs the family of SEED  [13]  datasets to validate the proposed method. Specifically, we focus on SEED  [13]  and SEED-VII  [14] . These datasets consist of sequences of audio-visual emotional stimuli, where the subjects' reactions to each stimulus are recorded. We select these benchmarks because they contain multiple transitions between emotional states. In contrast, other datasets in the field, such as DEAP  [15]  and DREAMER  [16] , have insufficient emotional state transitions. For example, in the DREAMER  [16]  dataset, nine emotions were induced, with each emotion elicited only twice in the sequence. The low number of transitions between emotional trials makes these datasets unsuitable for this study.\n\nSEED. The authors selected three emotional states to elicit in the subjects: happy (H), neutral (N), and sad (S). The data collection protocol involves exposing each subject to a sequence of videos, with each video chosen to induce one\n\nFig.  2 : Sequence of emotional trials in SEED (H: Happy, N: Neutral, S: Sad). of the three emotions. In each video, an Electroencephalogram (EEG) signal is recorded. Each video exposure is referred to as a trial, and the full sequence consists of 15 trials. The whole sequence of trials is defined as a session. This dataset encompasses a total of 15 subjects. Each subject participated in three sessions, which were recorded on different days. Fig.  2  illustrates the sequence of emotional trials across the three sessions. The variety of transitions between the three emotional states makes this dataset particularly suitable for studying the effects of priming from a data-driven perspective.\n\nSEED-VII. To further validate the proposed method, we select an additional benchmark: SEED-VII  [14] , an extension of the SEED dataset. The key differences between these benchmarks lie in the total number of targeted emotions and the number of trials per session. SEED-VII includes seven emotions: happy (H), surprise (U), neutral (N), disgust (D), fear (F), sad (S), and anger (A). These emotions are elicited across four sessions, with each session consisting of 20 trials-that is, each subject is exposed to 20 emotional video clips per session. This dataset in total encompasses 20 subjects. To prevent abrupt shifts in emotional valence, the authors designed the sequence of video clips to ensure a smoother transition between emotional states  [14] . Fig.  3  illustrates the sequence of video clips in each session of the benchmark. According to the authors, the order of the clips was carefully designed to minimize abrupt emotional shifts, making this benchmark particularly challenging for validating the proposed method.\n\nFor both benchmarks, we use the Differential Entropy (DE) features provided by the authors. A sliding window technique is used to extract features from each EEG segment at five frequencies bands (delta: 1 Hz to 3 Hz, theta: 4 Hz to 7 Hz, alpha: 8 Hz to 13 Hz, beta: 14 Hz to 30 Hz, gamma: 31 Hz to 50 Hz). These frequency bands have been reported to perform well for emotion classification  [13] ,  [14] . Hence, each sliding window yields a feature matrix in R 62×5 , where 62 is the number of EEG channels and 5 corresponds to the DE values computed per channel across the five frequency bands. We use the vector obtained by flattening this matrix as input to the proposed method.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Iv. Methodology",
      "text": "",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "A. Problem Formulation",
      "text": "Consider a dataset that consists of a sequence of trials {T 1 , T 2 , . . . , T N }, where each trial is the exposure to an emotional stimulus, and N is the total number of trials in the sequence. The set C ∈ {c 1 , c 2 , . . . , c K } represents all possible emotions induced across trials. Let y i,k denote the emotion induced at trial T i in the sequence, corresponding to emotion c k . Additionally, each trial T i is composed of a set of data points T i ∈ {x i,1 , x i,2 , . . . , x i,M }, being M the total number of data points in the trial. Each data point is a feature vector representing the subject's response to the emotional stimulus and is labeled with the emotion associated with that trial, y i,k .\n\nGiven the description above, suppose a dataset consists of N trials. Let this data be used to train a machine learning model to detect three different emotions: {happy, neutral, sad}. Let {P happy (x), P neutral (x), P sad (x)} be the posterior probability functions learned by the model for each of the targeted emotions.\n\nDue to the lingering nature of emotions, the order of the induced stimuli can impact the perception and reactions of subjects, a phenomenon known as affective priming. In machine learning, this translates to data points being projected closer to a posterior probability function that does not correspond to their actual label as learned by the model. This problem is illustrated in Fig.  4 . For example, in the trials of the test sequence, the neutral trial appears twice: first following a happy trial and later following a sad trial. In the former case, data points in the neutral trial suffer from low priming, whereas in the latter, data points in the neutral trial are strongly affected by the priming effect. As a result, the model is more likely to project priming-affected data points closer to the priming class posterior probability function, i.e., P sad (x) in this case, ultimately leading to incorrect predictions. This study investigates how the sequential order of emotional trials influences data generation within a dataset.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "B. Affective Priming Score",
      "text": "To address the problem of affective priming presented in section IV-A, we introduce the Affective Priming Score (APS), a method that uses a data-driven approach to score data points affected by the priming effect in sequential datasets. Based on the formulation presented in section IV-A, this method evaluates the impact of priming in each data point by measuring the distance to data points in past trials. A closer distance to data points in the preceding trial in the sequence than to data points of the same class in previous trials indicates an influence of the priming effect. The APS is calculated for Fig.  4 : The data generated in response to an emotional trial may be influenced by the order in which these trials are presented. For example, a subject's reaction to a neutral trial may be less affected when preceded by a happy trial than when preceded by a sad trial. Consequently, data points affected by the priming effect (highlighted in red) tend to be closer to the posterior probability function of the trial that caused the priming, leading models to make erroneous predictions. each data point (x i ) within each trial T i using the following function:\n\nEq. 1 sequentially computes the APS values. Specifically, for each trial in the sequence, the APS value is calculated for all data points within that trial. To achieve this, the following terms are needed: {d(x i , g class ), d(x i , g prev ), d(x i , g other )}. These terms are computed using a distance function d; in this case, we use the Euclidean distance to a set of centroids. As mentioned, APS values are calculated for each trial T i . Using the set {T 0 , . . . , T i-1 }, we compute the centroids {g class , g prev , g other }. The centroid g class is computed using data points corresponding to the same class as x i ; g prev is computed using data points from the class of the previous trial to x i ; finally, g other is computed using data points from the other classes in past trials in the sequence. Eq. 1 applies the softmax function, aiming to output higher scores when the distances of the data points in the assessed trial are closer to the centroid of the class in the previous trial. In Eq. 1, τ is a temperature parameter used to soften the softmax output. In this study, it is set to 0.1.\n\nAdditionally, this method makes the following assumptions: 1) The APS for the first K trials is 0, where K is the total number of induced emotions. This assumption is based on the fact that priming requires prior emotional exposure, which is absent at the beginning of the sequence. 2) If two consecutive trials induce the same emotional class, the APS values for the second trial are 0, as a trial of the same class cannot provoke priming by definition.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "V. Experimental Results",
      "text": "This section presents the results and benefits of applying the proposed method to data sequences affected by the priming effect. It is divided into two parts.\n\nThe first part examines the output of the APS method, presenting the averaged APS values computed across sequences. The second part validates the efficiency of the proposed method by comparing the performance of models trained on the original sequences with those trained on their priming-free versions.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "A. Affective Priming Score In Sequential Datasets",
      "text": "We compute the affective priming score for each data point in the sequence using the method described in Section IV-B. The presented method assumes the data points of the initial trials to have zero APS value, thus, they are excluded from the illustrations presented in this section. In SEED and SEED-VII, the first three and five trials are excluded, respectively.\n\nAffective priming has a different impact depending on the sequential order of emotional stimuli. For this reason, we visualize the average APS value for sequences that follow the same order of emotional stimuli. We applied the APS method to all sequences in the dataset and then averaged the obtained values across sequences. For example, assuming a sequence has 3000 data points, we calculate the corresponding APS values for each data point and then average these values across the other sequences in the dataset.\n\nIn SEED, the sequence of emotions remains consistent across the three recorded sessions. Therefore, we compute the average affective priming scores across all sessions and  participants. The results are presented in Fig.  5 . In SEED-VII, the sequential order of induced emotions varies across sessions. Therefore, the results for this benchmark are reported separately for each session. As done with SEED, we averaged the computed affective priming score across all participants in each session. The results are illustrated in Fig.  6 . We highlight the variability in trial duration within the sequence, represented by the width between the dashed horizontal lines in Fig.  5  and Fig.  6 . In the SEED dataset, this width remains mostly constant, indicating that approximately the same number of data points is available for each trial in the sequence. In contrast, in SEED-VII, the width between trials is more irregular, with some trials having fewer data points. This difference arises from the varying duration of the stimuli used in each dataset. In SEED, each stimulus lasts approximately four minutes on average, whereas in SEED-VII, the durations range from two to four minutes. This variability is reflected in the results presented in the next section.",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "B. Training Models On Priming-Free Data Sequences",
      "text": "The second part evaluates the effectiveness of the proposed method in detecting data points affected by affective priming. To do so, we train models on the original sequences and compare their performance with the same sequences after filtering out data points whose APS values exceed a predefined threshold. A core contribution of this work is the introduction of a metric to quantify the priming effect. This metric, named Priming Error (PE), is defined as follows:\n\nThe objective of Eq. 2 is to count the number of misclassifications in which the predicted label of a trial incorrectly matches the class of the previous trial in the sequence. For\n\n...",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "(D) Session 4",
      "text": "Fig.  6 : Averaged priming score for SEED-VII dataset. The priming score for each session is calculated independently as they do not follow the same sequence of emotions.\n\nexample, if a test data point labeled as neutral is misclassified as sadness, the class corresponding to the previous trial, this data point contributes to the PE metric. This metric serves as an indicator that the proposed data-driven method can effectively produce priming-free data sequences. Intuitively, lower PE values on the test set suggest that the model was trained on data less affected by the priming effect, thereby validating the proposed method.\n\nTo ensure the robustness of our method to identify primingaffected data points, we train two different sequential models. Specifically, we employ two well-known architectures: LSTM and Transformer (see Table  I ). Given the limited number of available data points per sequence, we adjust the model configurations accordingly. We use the precomputed DE features provided in the benchmarks to construct sequences as model inputs (see section III). Each input sample is formed by concatenating consecutive DE feature vectors, enabling the model to capture temporal patterns and transitions between trials within a sequence. The models are trained with an initial learning rate of 1e-4 and a weight decay of 1e-5 for regularization. The batch size is set to 8. For our experiments, we train a model for each subject-session combination, with each combination trained 5 times using different random initializations (seeds) to ensure statistical robustness. To promote reproducibility, we will make our code publicly available.\n\nBased on findings in the literature  [17] , physiological signals vary across days and subjects. To prevent such variability from affecting the interpretation of the results, we train an independent model for each sequence in the dataset. In each dataset, a sequence is defined as the recording of a subject during one session (see Section III).\n\nEach model is trained on the first 9 trials in SEED and the first 15 trials in SEED-VII. For each trained model, the priming error (PE) is evaluated on the test set, i.e., the remaining trials in the sequence. In SEED, results are aggregated across all sessions, as all recorded sessions follow the same sequence of emotional trials. In SEED-VII, results are reported separately for each session since each follows a distinct sequence of emotional trials.\n\nAs previously mentioned, we compare model performance on the original sequences and their priming-free counterparts. To remove data points affected by the priming effect, we apply a threshold of 0.7 on the APS values. This threshold balances the trade-off between retaining enough data to train the model and filtering out the most strongly affected data points. The SEED dataset provides approximately 3300 data points per sequence, whereas the SEED-VII dataset contains around 900 data points per sequence. When applying this threshold, the average removed percentage of data points is 9% and 10% for the SEED and SEED-VII dataset, respectively.\n\nIn Table  II , we present the priming error (PE) for the test trials in the SEED dataset. The columns Original and Priming-  free report the average PE across the test trials, where the model was trained using either the original or the primingfree data sequence, respectively. We report similar results for the SEED-VII dataset in tables III-IV. Since in the SEED-VII dataset, sessions follow different emotional orders for the induced stimuli, we report results for each session independently. Additionally, we provide the corresponding average accuracy for each case.\n\nThe results reported in both datasets show a consistent reduction of the priming error when models are trained on priming-free sequences. Thus, these results confirm the efficiency of the APS method to detect data points affected by the priming effect.\n\nWe further investigate the effect of removing primingaffected data points by disaggregating the previously reported results. In this analysis, we aim to illustrate the distribution of the PE metric across individual trials in the test sequence. To achieve this, we compute the PE value for each trial in every trained model. The resulting distributions are visualized using box plots, as shown in Fig.  7  for the SEED dataset and Fig.  8  for SEED-VII. The variation in PE values is notably heterogeneous, as each sequence in the dataset, i.e., each  subject in each recorded session, is affected by priming to a different extent. Interestingly, the trials with higher average PE values correspond to those where the proposed method also reports higher average APS values in the sequence. For example, in the SEED dataset, trial 12 shows higher PE values compared to other trials in the test sequence, and Fig.  5  shows a higher APS value for trial 12 as well. A similar pattern is observed in the SEED-VII dataset, specifically in trial 17 of session 1 and trial 20 of session 3. These results highlight the effectiveness of the proposed method in identifying primingaffected data points in sequential datasets.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Vi. Discussion",
      "text": "Data-centric affective priming quantification. To the best of our knowledge, no previous work has addressed the challenge of affective priming from a data-centric perspective. This work highlights its importance and proposes a method that not only prevents performance degradation in models but also enables visualization of the priming effect in data sequences. This visualization can serve as a tool to enhance the design of dataset collection protocols.\n\nSystem limitations. Although the results show a decrease in Priming Error (PE) across all models for both the SEED and SEED-VII datasets, the difference in accuracy between these databases is noteworthy. In SEED, both metrics (PE and accuracy) improve, while in SEED-VII, some sessions (e.g., sessions 1 and 4) show worse accuracy on priming-free sequences. We attribute this to differences in the number of available data points per sequence in each dataset. Consequently, the effectiveness of the proposed method is limited by the amount of available data.\n\nFuture work. To address ambiguity in systems of this kind, it is essential to incorporate all relevant information during the modeling phase. While this study introduces a method to quantify the priming effect in the data, incorporating such information during model training would be necessary to address the issue. Future work will explore strategies to effectively integrate such information.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Vii. Conclusion",
      "text": "This study explored the problem of affective priming from a data-centric perspective and introduced a method to detect data points influenced by this effect in sequential datasets. We propose the Affective Priming Score (APS), a data-driven method to identify data points that are more likely to be impacted by priming. To evaluate the effectiveness of APS in detecting priming in data points, we train models using two data types: the original sequence and its priming-free version. Given the absence of ground truth for affective priming, we introduce the priming effect metric, which quantifies the proportion of misclassified data points that are incorrectly predicted as the emotion from the preceding trial in the sequence. Experimental results demonstrate the effectiveness of APS, as it significantly reduces this metric.\n\nBeyond its application in cleaning data sequences, this tool has the potential to improve the design of data collection protocols. By analyzing how different sequences of emotional stimuli influence collected data, researchers can optimize experimental setups to minimize priming effects.\n\nAddressing label ambiguity remains a critical challenge in affective computing. This work contributes to ongoing efforts in the field by providing a systematic method for detecting and mitigating affective priming at the data level, thereby improving the reliability of emotion recognition models and the overall quality of affective computing datasets.",
      "page_start": 7,
      "page_end": 8
    },
    {
      "section_name": "Ethical Impact Statement",
      "text": "The data used in this work originate from two publicly available benchmark datasets found online. These datasets contain EEG recordings, which do not allow for the identification of individual subjects. The authors have also considered the potential for negative societal impact. While the proposed solution does not pose any immediate risk, it could potentially be misused in ways that compromise the privacy of monitored individuals. Additionally, the datasets may contain cultural biases, which could affect the generalizability of the developed models. Nonetheless, the focus of this study was limited to subject-dependent modeling.",
      "page_start": 8,
      "page_end": 8
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Affective priming can be observed in sequential",
      "page": 1
    },
    {
      "caption": "Figure 1: illustrates such a hypothesis.",
      "page": 1
    },
    {
      "caption": "Figure 2: Sequence of emotional trials in SEED (H: Happy,",
      "page": 3
    },
    {
      "caption": "Figure 3: Sequence of emotional trials in SEED-VII in each",
      "page": 3
    },
    {
      "caption": "Figure 2: illustrates the sequence of emotional trials across the",
      "page": 3
    },
    {
      "caption": "Figure 3: illustrates the",
      "page": 3
    },
    {
      "caption": "Figure 4: For example, in the trials of the test",
      "page": 3
    },
    {
      "caption": "Figure 4: The data generated in response to an emotional trial may be influenced by the order in which these trials are presented.",
      "page": 4
    },
    {
      "caption": "Figure 5: Averaged priming score for SEED dataset. Note that",
      "page": 5
    },
    {
      "caption": "Figure 5: . In SEED-",
      "page": 5
    },
    {
      "caption": "Figure 6: We highlight the variability in trial duration within the",
      "page": 5
    },
    {
      "caption": "Figure 5: and Fig. 6. In the SEED dataset, this",
      "page": 5
    },
    {
      "caption": "Figure 6: Averaged priming score for SEED-VII dataset. The",
      "page": 5
    },
    {
      "caption": "Figure 7: for the SEED dataset and",
      "page": 6
    },
    {
      "caption": "Figure 8: for SEED-VII. The variation in PE values is notably",
      "page": 6
    },
    {
      "caption": "Figure 7: Distribution of the priming error (PE) for each trial in",
      "page": 6
    },
    {
      "caption": "Figure 8: Distribution of the priming error (PE) for each trial in the test sequence in the SEED-VII dataset.",
      "page": 7
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "xx\nNo priming sample\nNeutral\nSad\nPriming sample": ""
        }
      ],
      "page": 4
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "The mind in the middle",
      "authors": [
        "J Bargh",
        "T Chartrand"
      ],
      "year": "2000",
      "venue": "Handbook of research methods in social and personality psychology"
    },
    {
      "citation_id": "2",
      "title": "Unintentional affective priming during labeling may bias labels",
      "authors": [
        "J Shen",
        "A Lapedriza",
        "R Picard"
      ],
      "year": "2019",
      "venue": "2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII)"
    },
    {
      "citation_id": "3",
      "title": "Analyzing the effect of affective priming on emotional annotations",
      "authors": [
        "L Martinez-Lucas",
        "A Salman",
        "S.-G Leem",
        "S Upadhyay",
        "C.-C Lee",
        "C Busso"
      ],
      "year": "2023",
      "venue": "2023 11th International Conference on Affective Computing and Intelligent Interaction (ACII)"
    },
    {
      "citation_id": "4",
      "title": "Stress lingers: Recognizing the impact of task order on design of stress and emotion detection systems",
      "authors": [
        "E Maestro",
        "H Banaee",
        "A Loutfi"
      ],
      "year": "2023",
      "venue": "2023 IEEE EMBS Special Topic Conference on Data Science and Engineering in Healthcare"
    },
    {
      "citation_id": "5",
      "title": "Lstm can solve hard long time lag problems",
      "authors": [
        "S Hochreiter",
        "J Schmidhuber"
      ],
      "year": "1996",
      "venue": "Advances in neural information processing systems"
    },
    {
      "citation_id": "6",
      "title": "Attention is all you need",
      "authors": [
        "A Vaswani",
        "N Shazeer",
        "N Parmar",
        "J Uszkoreit",
        "L Jones",
        "A Gomez",
        "Ł Kaiser",
        "I Polosukhin"
      ],
      "year": "2017",
      "venue": "Advances in neural information processing systems"
    },
    {
      "citation_id": "7",
      "title": "An efficient lstm network for emotion recognition from multichannel eeg signals",
      "authors": [
        "X Du",
        "C Ma",
        "G Zhang",
        "J Li",
        "Y.-K Lai",
        "G Zhao",
        "X Deng",
        "Y.-J Liu",
        "H Wang"
      ],
      "year": "2020",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "8",
      "title": "A lstm based deep learning network for recognizing emotions using wireless brainwave driven system",
      "authors": [
        "A Sakalle",
        "P Tomar",
        "H Bhardwaj",
        "D Acharya",
        "A Bhardwaj"
      ],
      "year": "2021",
      "venue": "Expert Systems with Applications"
    },
    {
      "citation_id": "9",
      "title": "Eeg-based emotion recognition with cascaded convolutional recurrent neural networks",
      "authors": [
        "M Meng",
        "Y Zhang",
        "Y Ma",
        "Y Gao",
        "W Kong"
      ],
      "year": "2023",
      "venue": "Pattern Analysis and Applications"
    },
    {
      "citation_id": "10",
      "title": "Daeegvit: A domain adaptive vision transformer framework for eeg cognitive state identification",
      "authors": [
        "Y Ouyang",
        "Y Liu",
        "L Shan",
        "Z Jia",
        "D Qian",
        "T Zeng",
        "H Zeng"
      ],
      "year": "2025",
      "venue": "Biomedical Signal Processing and Control"
    },
    {
      "citation_id": "11",
      "title": "A transformer convolutional network with the method of image segmentation for eeg-based emotion recognition",
      "authors": [
        "X Zhang",
        "X Cheng"
      ],
      "year": "2024",
      "venue": "IEEE Signal Processing Letters"
    },
    {
      "citation_id": "12",
      "title": "Eeg conformer: Convolutional transformer for eeg decoding and visualization",
      "authors": [
        "Y Song",
        "Q Zheng",
        "B Liu",
        "X Gao"
      ],
      "year": "2023",
      "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering"
    },
    {
      "citation_id": "13",
      "title": "Investigating critical frequency bands and channels for eeg-based emotion recognition with deep neural networks",
      "authors": [
        "W.-L Zheng",
        "B.-L Lu"
      ],
      "year": "2015",
      "venue": "IEEE Transactions on autonomous mental development"
    },
    {
      "citation_id": "14",
      "title": "Seed-vii: A multimodal dataset of six basic emotions with continuous labels for emotion recognition",
      "authors": [
        "W.-B Jiang",
        "X.-H Liu",
        "W.-L Zheng",
        "B.-L Lu"
      ],
      "year": "2024",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "15",
      "title": "Deap: A database for emotion analysis; using physiological signals",
      "authors": [
        "S Koelstra",
        "C Muhl",
        "M Soleymani",
        "J.-S Lee",
        "A Yazdani",
        "T Ebrahimi",
        "T Pun",
        "A Nijholt",
        "I Patras"
      ],
      "year": "2011",
      "venue": "IEEE transactions on affective computing"
    },
    {
      "citation_id": "16",
      "title": "Dreamer: A database for emotion recognition through eeg and ecg signals from wireless low-cost offthe-shelf devices",
      "authors": [
        "S Katsigiannis",
        "N Ramzan"
      ],
      "year": "2017",
      "venue": "IEEE journal of biomedical and health informatics"
    },
    {
      "citation_id": "17",
      "title": "Toward machine emotional intelligence: Analysis of affective physiological state",
      "authors": [
        "R Picard",
        "E Vyzas",
        "J Healey"
      ],
      "year": "2001",
      "venue": "IEEE transactions on pattern analysis and machine intelligence"
    }
  ]
}