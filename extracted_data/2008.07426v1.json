{
  "paper_id": "2008.07426v1",
  "title": "Hey Human, If Your Facial Emotions Are Uncertain, You Should Use Bayesian Neural Networks!",
  "published": "2020-08-17T15:50:40Z",
  "authors": [
    "Maryam Matin",
    "Matias Valdenegro-Toro"
  ],
  "keywords": [
    "Facial Emotion Recognition",
    "Uncertainty Quantification",
    "Bayesian Deep Learning"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Facial emotion recognition is the task to classify human emotions in face images. It is a difficult task due to high aleatoric uncertainty and visual ambiguity. A large part of the literature aims to show progress by increasing accuracy on this task, but this ignores the inherent uncertainty and ambiguity in the task. In this paper we show that Bayesian Neural Networks, as approximated using MC-Dropout, MC-DropConnect, or an Ensemble, are able to model the aleatoric uncertainty in facial emotion recognition, and produce output probabilities that are closer to what a human expects. We also show that calibration metrics show strange behaviors for this task, due to the multiple classes that can be considered correct, which motivates future work. We believe our work will motivate other researchers to move away from Classical and into Bayesian Neural Networks.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Emotion recognition in facial images is the task of classifying the face of a person into a set of emotions. One important characteristic of this task is its high degree of aleatoric uncertainty  [2] , which presents itself as ambiguity in defining what is the correct emotion class given an image  [22]    [11] . Most state of the art neural networks used for this task do not model any kind of uncertainty, which makes them ill-posed for emotion recognition.\n\nIn this paper we evaluate three scalable methods for uncertainty quantification in neural networks, namely Monte Carlo Dropout/DropConnect, and Deep Ensembles, on the FER+ dataset  [2]  using three different neural network architectures. This dataset is a variation of the FER dataset  [6]  where each image is labeled with a crowd-sourced distribution of emotion classes, instead of a single class annotation per image. Our results show that Bayesian neural networks are better able to model this kind of problem, even as only one label is used during training.\n\nWe believe that our results show that metrics for this task need to be rethought, and that only methods able to model at least aleatoric uncertainty should be used for emotion recognition. It makes little sense to obtain high accuracy on this task, given the visual ambiguity and the multiple correct answers that are possible.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Related Work",
      "text": "There is a rich literature on emotion recognition from facial images  [11] . The FER+ dataset  [2]  is one dataset used to evaluate progress in this task. Two defining characteristics of this dataset are being grayscale images at 64 × 64 resolution, and labels might indicate multiple emotions, as defined by a crowdsourced probability distribution. Classes are 'neutral', 'happiness', 'surprise', 'sadness','anger', 'disgust', 'fear', and 'contempt'. The baseline reported in  [2]  is 84.7% accuracy with a custom VGG13 network and a standard cross-entropy loss and data augmentation from  [23] .\n\nGeorgescu et al.  [5]  use CNNs with bag of visual words to obtain 87.7% accuracy. Other baselines presented in this paper are 84.4% accuracy with VGGface  [16] , a Bag of Visual Words alone obtaining 79.6%, and a large ensemble achieving 88% accuracy. Arriaga et al.  [1]  reports 78% and 81% accuracy with a reduced VGG and a mini-Xception network.\n\nOverall most methods for facial emotion recognition use classical neural networks, and Bayesian neural networks are not commonly used, even more recent work that uses ensembles like Siqueira et al.  [19]  or Surace et al.  [20]  do not consider the possibility of modeling output uncertainty, despite Lakshminarayanan et al.  [13]  showing that ensembles are able to produce state of the art uncertainty quantification.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Experimental Methodology",
      "text": "For our experiments we use three of the most common CNN model architectures which have shown outstanding performance in image classification competition on ImageNet, namely AlexNet  [12] , VGG16  [18]  and DenseNet121  [8]  with some minor modifications. To simplify the models, we reduce the number of neurons in fully connected layers to 256 instead of 4096. For AlexNet, we add batch normalization  [9]  after each layer. DenseNet-121 is modified to integrate dropout layers into the architecture.\n\nWe use the dropout/drop rate of 0.5 for AlexNet and 0.2 for the other two models as suggested by their original implementations. The batch size is set to 32 and we use categorical cross-entropy loss and accuracy metric with Adam optimizer  [10] . Note that most implementations of the cross-entropy loss use only a single label per class, even as more labels might be available, so in this work we do not explore the use of soft labels  [17] . We decided to only tune the learning rate in range 10 -1 to 10 -4 . For VGG16 models we used Stochastic Gradient Descent instead of Adam. For SGD optimizer we tuned the learning rate decay in range 10 -1 to 10 -6 . The actual training after hyper-parameter tuning is done over 80 epochs. We do not perform any kind of data augmentation. Since full inference in a Bayesian neural network is intractable, we use approximate methods. Due to their scalability and simplicity, we use Monte Carlo Dropout  [4] , Monte Carlo DropConnect  [14] , and Deep Ensembles  [13] . These methods all have a hyper-parameter in common, the number of stochastic forward passes T for Monte Carlo methods, and the number of ensembles N for Deep Ensembles. Note that while MC Dropout/DropConnect are approximations to a BNN, Deep Ensembles is a non-Bayesian method but it outperforms other methods in uncertainty quantification and out of distribution detection  [15] .\n\nWe evaluate three metrics on the FER+ dataset  [2] . We compute classification error, Negative Log Likelihood (NLL), and expected calibration error (ECE)  [7] , all as a function of number of stochastic forward samples/ensembles, which are varied between 1 to 15. NLL determines whether the network is assigning high confidence to correct classes, and calibration determines if its confidence estimates are compatible with the true likelihood of the data.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Experimental Results And Analysis",
      "text": "Our main results are presented in Figure  1  for classification error, Figure  2  for the negative log-likelihood, and Figure  3  for expected calibration error  [7] .\n\nThe effect on task performance (accuracy/error) is as expected, with overall decreasing error for all uncertainty methods, but this is more pronounced with an ensemble of DenseNets, which is also confirmed with the plots of negative log-likelihood. There are large variations in performance across different models, and MC-Dropout and MC-DropConnect seem to be less stable than ensembles.\n\nCalibration error shown in Fig.  3  shows an unusual pattern for all models and uncertainty methods, as the calibration error increases with more samples or ensemble members, instead of decreasing as it does with other datasets (like CIFAR10 and SVHN, as shown by Valdenegro-Toro  [21] ). We interpret these results as that the model's probabilities are closer to represent the true label distribution than the classical network (which can also be seen in Fig.  4 ).\n\nWe believe that our Bayesian neural network models are overall underconfident, which might be undesirable, but this is due to the large aleatoric uncer-  tainty in the labels and input images (which can be validated by looking at the label entropy), not because the models are producing incorrect predictions. The calibration error considers both the correct class and the prediction confidence of that class, but this considers only one correct class per sample, there are no calibration metrics that consider cases of high aleatoric uncertainty, where some classes are visually similar and should be allowed for the model to be confused. We visualize the top five most uncertain images as computed using entropy of the output probabilities for the DenseNet model using a Deep Ensemble. This is shown in Figure  4 . These results show the uncertainty and visual ambiguity between the classes. An ensemble with a single model is equivalent to a classical neural network, and overall it produces a correct but overconfident result. A Deep Ensemble produces probabilities that are more spread across classes, which make more sense for face images with visual ambiguity in terms of which emotion is actually conveyed.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Conclusions And Future Work",
      "text": "Overall we see multiple benefits from using BNNs over a classical neural network for facial emotion recognition in the FER+ dataset. A BNN is able to model aleatoric and epistemic uncertainty, while providing small improvements in accuracy (in the order of 2-4%) compared to a classical network, and providing more realistic probability estimates, specially when considering overconfident point predictions made by classical networks  [7] . We also find that usual calibration metrics behave strangely in the presence of high aleatoric uncertainty, with calibration error increasing along with number of samples or ensembles, while in other datasets it generally decreases producing a more calibrated model.\n\nFor future work, we wish to evaluate the potential of out of distribution detection based on probability entropy, as a way to detect biases in the model, and prevent wrong predictions to be made in out of distribution settings, which is certainly a concern for skin shades that are far away from the training set  [3] .\n\nFinally, we wish to explore ways to disentangle aleatoric and epistemic uncertainty, and to train BNNs using other losses that are able to fully utilize the soft labels  [17]  in the FER+ dataset.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "A Additional Results On Calibration",
      "text": "This section presents calibration plots for each model and uncertainty method combination, as they did not fit in the main paper.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "B Additional Results On Most Uncertain Images",
      "text": "This section presents additional probability plots for Deep Ensembles across models. One important conclusion that can be drawn from these plots is that the number of ensembles has a big influence on the output probabilities, and for task with high uncertainty such as facial emotion recognition, this can lead to very different class predictions as computed by taking the maximum probability.",
      "page_start": 9,
      "page_end": 9
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Classiﬁcation error as a function of # of samples/ensembles for all meth-",
      "page": 3
    },
    {
      "caption": "Figure 1: for classiﬁcation error, Figure 2 for",
      "page": 3
    },
    {
      "caption": "Figure 3: for expected calibration error [7].",
      "page": 3
    },
    {
      "caption": "Figure 3: shows an unusual pattern for all models",
      "page": 3
    },
    {
      "caption": "Figure 2: NLL as a function of # of samples/ensembles for all methods in diﬀerent",
      "page": 4
    },
    {
      "caption": "Figure 3: Calibration error as a function of # of samples/ensembles for all methods",
      "page": 4
    },
    {
      "caption": "Figure 4: These results show the uncertainty and visual ambiguity",
      "page": 4
    },
    {
      "caption": "Figure 4: Five most uncertain images based on DenseNet model and Deep Ensem-",
      "page": 5
    },
    {
      "caption": "Figure 5: Calibration curve for all methods in diﬀerent models on FERPlus dataset",
      "page": 8
    },
    {
      "caption": "Figure 6: Five most uncertain images based on VGG model and Deep Ensembles",
      "page": 9
    },
    {
      "caption": "Figure 7: Five most uncertain images based on AlexNet model and Deep Ensem-",
      "page": 10
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Hey Human, If your Facial Emotions are": "Uncertain, You Should Use Bayesian Neural"
        },
        {
          "Hey Human, If your Facial Emotions are": "Networks!"
        },
        {
          "Hey Human, If your Facial Emotions are": "Maryam Matin1 and Matias Valdenegro-Toro2"
        },
        {
          "Hey Human, If your Facial Emotions are": "1 Hochschule Bonn-Rhein-Sieg, 53757 Sankt Augustin, Germany"
        },
        {
          "Hey Human, If your Facial Emotions are": "maryam.matin.1987@gmail.com"
        },
        {
          "Hey Human, If your Facial Emotions are": ""
        },
        {
          "Hey Human, If your Facial Emotions are": "matias.valdenegro@dfki.de"
        },
        {
          "Hey Human, If your Facial Emotions are": "Abstract. Facial emotion recognition is the task to classify human emo-"
        },
        {
          "Hey Human, If your Facial Emotions are": "is a diﬃcult"
        },
        {
          "Hey Human, If your Facial Emotions are": "tainty and visual ambiguity. A large part of the literature aims to show"
        },
        {
          "Hey Human, If your Facial Emotions are": ""
        },
        {
          "Hey Human, If your Facial Emotions are": "herent uncertainty and ambiguity in the"
        },
        {
          "Hey Human, If your Facial Emotions are": "that Bayesian Neural Networks, as approximated using MC-Dropout,"
        },
        {
          "Hey Human, If your Facial Emotions are": "MC-DropConnect, or an Ensemble, are able to model the aleatoric un-"
        },
        {
          "Hey Human, If your Facial Emotions are": "certainty in facial emotion recognition, and produce output probabilities"
        },
        {
          "Hey Human, If your Facial Emotions are": "that are closer to what a human expects. We also show that calibration"
        },
        {
          "Hey Human, If your Facial Emotions are": "metrics show strange behaviors for this task, due to the multiple classes"
        },
        {
          "Hey Human, If your Facial Emotions are": "that can be considered correct, which motivates future work. We believe"
        },
        {
          "Hey Human, If your Facial Emotions are": "researchers"
        },
        {
          "Hey Human, If your Facial Emotions are": ""
        },
        {
          "Hey Human, If your Facial Emotions are": "Keywords: Facial Emotion Recognition, Uncertainty Quantiﬁcation,"
        },
        {
          "Hey Human, If your Facial Emotions are": ""
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "2\nMatin et al.": "We believe\nthat\nour\nresults\nshow that metrics\nfor\nthis\ntask need to be"
        },
        {
          "2\nMatin et al.": "rethought, and that only methods able to model at\nleast aleatoric uncertainty"
        },
        {
          "2\nMatin et al.": "should be used for emotion recognition. It makes little sense to obtain high ac-"
        },
        {
          "2\nMatin et al.": "curacy on this task, given the visual ambiguity and the multiple correct answers"
        },
        {
          "2\nMatin et al.": "that are possible."
        },
        {
          "2\nMatin et al.": "2\nRelated Work"
        },
        {
          "2\nMatin et al.": "There is a rich literature on emotion recognition from facial\nimages\n[11]. The"
        },
        {
          "2\nMatin et al.": "FER+ dataset\n[2]\nis one dataset used to evaluate progress\nin this\ntask. Two"
        },
        {
          "2\nMatin et al.": "deﬁning characteristics of\nthis dataset are being grayscale\nimages at 64 × 64"
        },
        {
          "2\nMatin et al.": "resolution, and labels might indicate multiple emotions, as deﬁned by a crowd-"
        },
        {
          "2\nMatin et al.": "sourced probability distribution. Classes\nare\n’neutral’,\n’happiness’,\n’surprise’,"
        },
        {
          "2\nMatin et al.": "’sadness’,’anger’,\n’disgust’,\n’fear’, and ’contempt’. The baseline reported in [2]"
        },
        {
          "2\nMatin et al.": "is 84.7% accuracy with a custom VGG13 network and a standard cross-entropy"
        },
        {
          "2\nMatin et al.": "loss and data augmentation from [23]."
        },
        {
          "2\nMatin et al.": "Georgescu et al.\n[5] use CNNs with bag of visual words\nto obtain 87.7%"
        },
        {
          "2\nMatin et al.": "accuracy. Other baselines presented in this paper are 84.4% accuracy with VGG-"
        },
        {
          "2\nMatin et al.": "face [16], a Bag of Visual Words alone obtaining 79.6%, and a large ensemble"
        },
        {
          "2\nMatin et al.": "achieving 88% accuracy. Arriaga et al.[1] reports 78% and 81% accuracy with a"
        },
        {
          "2\nMatin et al.": "reduced VGG and a mini-Xception network."
        },
        {
          "2\nMatin et al.": "Overall most methods for facial emotion recognition use classical neural net-"
        },
        {
          "2\nMatin et al.": "works, and Bayesian neural networks are not commonly used, even more recent"
        },
        {
          "2\nMatin et al.": "work that uses ensembles like Siqueira et al.\n[19] or Surace et al.\n[20] do not con-"
        },
        {
          "2\nMatin et al.": "sider the possibility of modeling output uncertainty, despite Lakshminarayanan"
        },
        {
          "2\nMatin et al.": "et al. [13] showing that ensembles are able to produce state of the art uncertainty"
        },
        {
          "2\nMatin et al.": "quantiﬁcation."
        },
        {
          "2\nMatin et al.": "3\nExperimental Methodology"
        },
        {
          "2\nMatin et al.": "For our experiments we use three of the most common CNN model architectures"
        },
        {
          "2\nMatin et al.": "which have shown outstanding performance in image classiﬁcation competition"
        },
        {
          "2\nMatin et al.": "on ImageNet, namely AlexNet [12], VGG16 [18] and DenseNet121 [8] with some"
        },
        {
          "2\nMatin et al.": "minor modiﬁcations. To simplify the models, we reduce the number of neurons"
        },
        {
          "2\nMatin et al.": "in fully connected layers\nto 256 instead of 4096. For AlexNet, we add batch"
        },
        {
          "2\nMatin et al.": "normalization [9] after each layer. DenseNet-121 is modiﬁed to integrate dropout"
        },
        {
          "2\nMatin et al.": "layers into the architecture."
        },
        {
          "2\nMatin et al.": "We use the dropout/drop rate of 0.5 for AlexNet and 0.2 for the other two"
        },
        {
          "2\nMatin et al.": "models as\nsuggested by their original\nimplementations. The batch size\nis\nset"
        },
        {
          "2\nMatin et al.": "to 32 and we use categorical cross-entropy loss and accuracy metric with Adam"
        },
        {
          "2\nMatin et al.": "optimizer [10]. Note that most implementations of the cross-entropy loss use only"
        },
        {
          "2\nMatin et al.": "a single label per class, even as more labels might be available, so in this work we"
        },
        {
          "2\nMatin et al.": "do not explore the use of soft labels [17]. We decided to only tune the learning"
        },
        {
          "2\nMatin et al.": "rate in range 10−1\nto 10−4. For VGG16 models we used Stochastic Gradient"
        },
        {
          "2\nMatin et al.": "Descent instead of Adam. For SGD optimizer we tuned the learning rate decay"
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Hey Human, If your Facial Emotions are Uncertain, You Should Use BNNs!": ""
        },
        {
          "Hey Human, If your Facial Emotions are Uncertain, You Should Use BNNs!": ""
        },
        {
          "Hey Human, If your Facial Emotions are Uncertain, You Should Use BNNs!": ""
        },
        {
          "Hey Human, If your Facial Emotions are Uncertain, You Should Use BNNs!": "22.5"
        },
        {
          "Hey Human, If your Facial Emotions are Uncertain, You Should Use BNNs!": ""
        },
        {
          "Hey Human, If your Facial Emotions are Uncertain, You Should Use BNNs!": "22.0"
        },
        {
          "Hey Human, If your Facial Emotions are Uncertain, You Should Use BNNs!": ""
        },
        {
          "Hey Human, If your Facial Emotions are Uncertain, You Should Use BNNs!": ""
        },
        {
          "Hey Human, If your Facial Emotions are Uncertain, You Should Use BNNs!": "Error (%)\n21.5"
        },
        {
          "Hey Human, If your Facial Emotions are Uncertain, You Should Use BNNs!": ""
        },
        {
          "Hey Human, If your Facial Emotions are Uncertain, You Should Use BNNs!": "21.0"
        },
        {
          "Hey Human, If your Facial Emotions are Uncertain, You Should Use BNNs!": ""
        },
        {
          "Hey Human, If your Facial Emotions are Uncertain, You Should Use BNNs!": "20.5"
        },
        {
          "Hey Human, If your Facial Emotions are Uncertain, You Should Use BNNs!": ""
        },
        {
          "Hey Human, If your Facial Emotions are Uncertain, You Should Use BNNs!": ""
        },
        {
          "Hey Human, If your Facial Emotions are Uncertain, You Should Use BNNs!": ""
        }
      ],
      "page": 3
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14": "# of Samples\n# of Samples\n# of Ensembles"
        },
        {
          "2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14": "(a) MC-D\n(b) MC-DC\n(c) DE"
        },
        {
          "2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14": "Fig. 1: Classiﬁcation error as a function of # of samples/ensembles for all meth-"
        },
        {
          "2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14": "ods in diﬀerent models on FERPlus dataset."
        },
        {
          "2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14": "in range 10−1 to 10−6. The actual training after hyper-parameter tuning is done"
        },
        {
          "2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14": "over 80 epochs. We do not perform any kind of data augmentation."
        },
        {
          "2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14": "Since full\ninference in a Bayesian neural network is intractable, we use ap-"
        },
        {
          "2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14": "proximate methods. Due to their scalability and simplicity, we use Monte Carlo"
        },
        {
          "2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14": "Dropout\n[4], Monte Carlo DropConnect\n[14], and Deep Ensembles\n[13]. These"
        },
        {
          "2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14": "methods all have a hyper-parameter in common, the number of stochastic for-"
        },
        {
          "2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14": "ward passes T for Monte Carlo methods, and the number of ensembles N for"
        },
        {
          "2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14": "Deep Ensembles. Note that while MC Dropout/DropConnect are approxima-"
        },
        {
          "2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14": "tions to a BNN, Deep Ensembles is a non-Bayesian method but it outperforms"
        },
        {
          "2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14": "other methods\nin uncertainty quantiﬁcation and out of distribution detection"
        },
        {
          "2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14": "[15]."
        },
        {
          "2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14": "We evaluate three metrics on the FER+ dataset [2]. We compute classiﬁca-"
        },
        {
          "2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14": "tion error, Negative Log Likelihood (NLL), and expected calibration error (ECE)"
        },
        {
          "2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14": "[7], all as a function of number of stochastic forward samples/ensembles, which"
        },
        {
          "2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14": "are varied between 1 to 15. NLL determines whether\nthe network is assigning"
        },
        {
          "2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14": "high conﬁdence to correct classes, and calibration determines\nif\nits conﬁdence"
        },
        {
          "2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14\n2\n4\n6\n8\n10\n12\n14": "estimates are compatible with the true likelihood of the data."
        }
      ],
      "page": 3
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "NLL vs # of Samples, MC-D, FERPlus": "",
          "NLL vs # of Samples, MC-DC, FERPlus": ""
        },
        {
          "NLL vs # of Samples, MC-D, FERPlus": "",
          "NLL vs # of Samples, MC-DC, FERPlus": ""
        },
        {
          "NLL vs # of Samples, MC-D, FERPlus": "",
          "NLL vs # of Samples, MC-DC, FERPlus": ""
        },
        {
          "NLL vs # of Samples, MC-D, FERPlus": "",
          "NLL vs # of Samples, MC-DC, FERPlus": ""
        },
        {
          "NLL vs # of Samples, MC-D, FERPlus": "",
          "NLL vs # of Samples, MC-DC, FERPlus": ""
        },
        {
          "NLL vs # of Samples, MC-D, FERPlus": "",
          "NLL vs # of Samples, MC-DC, FERPlus": ""
        },
        {
          "NLL vs # of Samples, MC-D, FERPlus": "",
          "NLL vs # of Samples, MC-DC, FERPlus": ""
        },
        {
          "NLL vs # of Samples, MC-D, FERPlus": "",
          "NLL vs # of Samples, MC-DC, FERPlus": ""
        },
        {
          "NLL vs # of Samples, MC-D, FERPlus": "",
          "NLL vs # of Samples, MC-DC, FERPlus": ""
        },
        {
          "NLL vs # of Samples, MC-D, FERPlus": "",
          "NLL vs # of Samples, MC-DC, FERPlus": ""
        },
        {
          "NLL vs # of Samples, MC-D, FERPlus": "",
          "NLL vs # of Samples, MC-DC, FERPlus": ""
        },
        {
          "NLL vs # of Samples, MC-D, FERPlus": "",
          "NLL vs # of Samples, MC-DC, FERPlus": ""
        },
        {
          "NLL vs # of Samples, MC-D, FERPlus": "",
          "NLL vs # of Samples, MC-DC, FERPlus": ""
        },
        {
          "NLL vs # of Samples, MC-D, FERPlus": "",
          "NLL vs # of Samples, MC-DC, FERPlus": ""
        },
        {
          "NLL vs # of Samples, MC-D, FERPlus": "6\n8\n10",
          "NLL vs # of Samples, MC-DC, FERPlus": "6\n8\n10"
        },
        {
          "NLL vs # of Samples, MC-D, FERPlus": "# of Samples",
          "NLL vs # of Samples, MC-DC, FERPlus": "# of Samples"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Calibration error vs # of Samples, MC-D, FERplus": "",
          "Calibration error vs # of Samples, MC-DC, FERplus": ""
        },
        {
          "Calibration error vs # of Samples, MC-D, FERplus": "",
          "Calibration error vs # of Samples, MC-DC, FERplus": ""
        },
        {
          "Calibration error vs # of Samples, MC-D, FERplus": "",
          "Calibration error vs # of Samples, MC-DC, FERplus": ""
        },
        {
          "Calibration error vs # of Samples, MC-D, FERplus": "",
          "Calibration error vs # of Samples, MC-DC, FERplus": ""
        },
        {
          "Calibration error vs # of Samples, MC-D, FERplus": "",
          "Calibration error vs # of Samples, MC-DC, FERplus": ""
        },
        {
          "Calibration error vs # of Samples, MC-D, FERplus": "",
          "Calibration error vs # of Samples, MC-DC, FERplus": ""
        },
        {
          "Calibration error vs # of Samples, MC-D, FERplus": "",
          "Calibration error vs # of Samples, MC-DC, FERplus": ""
        },
        {
          "Calibration error vs # of Samples, MC-D, FERplus": "",
          "Calibration error vs # of Samples, MC-DC, FERplus": ""
        },
        {
          "Calibration error vs # of Samples, MC-D, FERplus": "",
          "Calibration error vs # of Samples, MC-DC, FERplus": ""
        },
        {
          "Calibration error vs # of Samples, MC-D, FERplus": "",
          "Calibration error vs # of Samples, MC-DC, FERplus": ""
        },
        {
          "Calibration error vs # of Samples, MC-D, FERplus": "",
          "Calibration error vs # of Samples, MC-DC, FERplus": ""
        },
        {
          "Calibration error vs # of Samples, MC-D, FERplus": "",
          "Calibration error vs # of Samples, MC-DC, FERplus": ""
        },
        {
          "Calibration error vs # of Samples, MC-D, FERplus": "4\n6\n8\n10\n12",
          "Calibration error vs # of Samples, MC-DC, FERplus": "4\n6\n8\n10\n12"
        },
        {
          "Calibration error vs # of Samples, MC-D, FERplus": "# of Samples",
          "Calibration error vs # of Samples, MC-DC, FERplus": "# of Samples"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "1.0": "0.8",
          "Label Probability": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": ""
        },
        {
          "1.0": "Probability\n0.6",
          "Label Probability": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": ""
        },
        {
          "1.0": "0.4",
          "Label Probability": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": ""
        },
        {
          "1.0": "0.2",
          "Label Probability": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": ""
        },
        {
          "1.0": "0.0",
          "Label Probability": "s",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "s\ns\ne",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "s\ns\ne",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "s\ns\ne",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": "s\ns\ne"
        },
        {
          "1.0": "",
          "Label Probability": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "n\ni\np\np\na\nh",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "n\ni\np\np\na\nh",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "n\ni\np\np\na\nh",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": "n\ni\np\np\na\nh"
        },
        {
          "1.0": "",
          "Label Probability": "Class",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": ""
        },
        {
          "1.0": "",
          "Label Probability": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": ""
        },
        {
          "1.0": "1.0",
          "Label Probability": "Label Probability",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "Class probability, DE, FERPlus, DenseNet, Entropy : 1.62",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "Class probability, DE, FERPlus, DenseNet, Entropy : 1.86",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": "Class probability, DE, FERPlus, DenseNet, Entropy : 1.86"
        },
        {
          "1.0": "0.8",
          "Label Probability": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": ""
        },
        {
          "1.0": "Probability\n0.6",
          "Label Probability": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": ""
        },
        {
          "1.0": "0.4",
          "Label Probability": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": ""
        },
        {
          "1.0": "0.2",
          "Label Probability": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": ""
        },
        {
          "1.0": "0.0",
          "Label Probability": "s",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "s\ns\ne",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "s\ns\ne",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "s\ns\ne",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": "s\ns\ne"
        },
        {
          "1.0": "",
          "Label Probability": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "n\ni\np\np\na\nh",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "n\ni\np\np\na\nh",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "n\ni\np\np\na\nh",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": "n\ni\np\np\na\nh"
        },
        {
          "1.0": "",
          "Label Probability": "Class",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": ""
        },
        {
          "1.0": "",
          "Label Probability": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "Neutral",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": ""
        },
        {
          "1.0": "1.0",
          "Label Probability": "Label Probability",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "Class probability, DE, FERPlus, DenseNet, Entropy : 1.67",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "Class probability, DE, FERPlus, DenseNet, Entropy : 1.83",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "Class probability, DE, FERPlus, DenseNet, Entropy : 1.86",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": "Class probability, DE, FERPlus, DenseNet, Entropy : 1.91"
        },
        {
          "1.0": "0.8",
          "Label Probability": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": ""
        },
        {
          "1.0": "Probability\n0.6",
          "Label Probability": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": ""
        },
        {
          "1.0": "0.4",
          "Label Probability": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": ""
        },
        {
          "1.0": "0.2",
          "Label Probability": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": ""
        },
        {
          "1.0": "0.0",
          "Label Probability": "s",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "s\ns\ne",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "s\ns\ne",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "s\ns\ne",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": "s\ns\ne"
        },
        {
          "1.0": "",
          "Label Probability": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "n\ni\np\np\na\nh",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "n\ni\np\np\na\nh",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "n\ni\np\np\na\nh",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": "n\ni\np\np\na\nh"
        },
        {
          "1.0": "",
          "Label Probability": "Class",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": ""
        },
        {
          "1.0": "",
          "Label Probability": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "Happiness",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "Happiness",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "Happiness",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": "Happiness"
        },
        {
          "1.0": "1.0",
          "Label Probability": "Label Probability",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "Class probability, DE, FERPlus, DenseNet, Entropy : 1.79",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "Class probability, DE, FERPlus, DenseNet, Entropy : 1.92",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "Class probability, DE, FERPlus, DenseNet, Entropy : 1.94",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": "Class probability, DE, FERPlus, DenseNet, Entropy : 1.91"
        },
        {
          "1.0": "0.8",
          "Label Probability": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": ""
        },
        {
          "1.0": "Probability\n0.6",
          "Label Probability": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": ""
        },
        {
          "1.0": "0.4",
          "Label Probability": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": ""
        },
        {
          "1.0": "0.2",
          "Label Probability": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": ""
        },
        {
          "1.0": "0.0",
          "Label Probability": "s",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "s\ns\ne",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "s\ns\ne",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "s\ns\ne",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": "s\ns\ne"
        },
        {
          "1.0": "",
          "Label Probability": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "n\ni\np\np\na\nh",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "n\ni\np\np\na\nh",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "n\ni\np\np\na\nh",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": "n\ni\np\np\na\nh"
        },
        {
          "1.0": "",
          "Label Probability": "Class",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": ""
        },
        {
          "1.0": "",
          "Label Probability": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": ""
        },
        {
          "1.0": "1.0",
          "Label Probability": "Label Probability",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "Class probability, DE, FERPlus, DenseNet, Entropy : 1.75",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "Class probability, DE, FERPlus, DenseNet, Entropy : 1.99",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": "Class probability, DE, FERPlus, DenseNet, Entropy : 1.94"
        },
        {
          "1.0": "0.8",
          "Label Probability": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": ""
        },
        {
          "1.0": "Probability\n0.6",
          "Label Probability": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": ""
        },
        {
          "1.0": "0.4",
          "Label Probability": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": ""
        },
        {
          "1.0": "0.2",
          "Label Probability": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": ""
        },
        {
          "1.0": "0.0",
          "Label Probability": "s",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "s\ns\ne",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "s\ns\ne",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "s\ns\ne",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": "s\ns\ne"
        },
        {
          "1.0": "",
          "Label Probability": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "n\ni\np\np\na\nh",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "n\ni\np\np\na\nh",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "n\ni\np\np\na\nh",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": "n\ni\np\np\na\nh"
        },
        {
          "1.0": "",
          "Label Probability": "Class",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.93": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.88": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.84": "",
          "Class probability, DE, FERPlus, DenseNet, Entropy : 1.85": ""
        }
      ],
      "page": 5
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Fig. 4: Five most uncertain images based on DenseNet model and Deep Ensem-": "bles with # of ensembles and a plot of predictive probabilities using 1, 5, 10"
        },
        {
          "Fig. 4: Five most uncertain images based on DenseNet model and Deep Ensem-": "and 15 ensembles. The ﬁrst column represents"
        },
        {
          "Fig. 4: Five most uncertain images based on DenseNet model and Deep Ensem-": "ground truth label distribution. Under each probability plot, the predicted class"
        },
        {
          "Fig. 4: Five most uncertain images based on DenseNet model and Deep Ensem-": "is presented."
        },
        {
          "Fig. 4: Five most uncertain images based on DenseNet model and Deep Ensem-": ""
        },
        {
          "Fig. 4: Five most uncertain images based on DenseNet model and Deep Ensem-": "of high aleatoric uncertainty, with calibration error increasing along with number"
        },
        {
          "Fig. 4: Five most uncertain images based on DenseNet model and Deep Ensem-": "of samples or ensembles, while in other datasets it generally decreases producing"
        },
        {
          "Fig. 4: Five most uncertain images based on DenseNet model and Deep Ensem-": "a more calibrated model."
        },
        {
          "Fig. 4: Five most uncertain images based on DenseNet model and Deep Ensem-": "For\nfuture work, we wish to evaluate"
        },
        {
          "Fig. 4: Five most uncertain images based on DenseNet model and Deep Ensem-": "detection based on probability entropy, as a way to detect biases in the model,"
        },
        {
          "Fig. 4: Five most uncertain images based on DenseNet model and Deep Ensem-": "and prevent wrong predictions to be made in out of distribution settings, which"
        },
        {
          "Fig. 4: Five most uncertain images based on DenseNet model and Deep Ensem-": "is certainly a concern for skin shades that are far away from the training set [3]."
        },
        {
          "Fig. 4: Five most uncertain images based on DenseNet model and Deep Ensem-": ""
        },
        {
          "Fig. 4: Five most uncertain images based on DenseNet model and Deep Ensem-": "certainty, and to train BNNs using other losses that are able to fully utilize the"
        },
        {
          "Fig. 4: Five most uncertain images based on DenseNet model and Deep Ensem-": "soft labels [17]\nin the FER+ dataset."
        }
      ],
      "page": 5
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "6\nMatin et al.": "References"
        },
        {
          "6\nMatin et al.": "1. Arriaga, O., Valdenegro-Toro, M., Pl¨oger, P.G.: Real-time convolutional neural net-"
        },
        {
          "6\nMatin et al.": "works for emotion and gender classiﬁcation. In: European Symposium on Artiﬁcial"
        },
        {
          "6\nMatin et al.": "Neural Networks (2019)"
        },
        {
          "6\nMatin et al.": "2. Barsoum, E., Zhang, C., Ferrer, C.C., Zhang, Z.: Training deep networks for facial"
        },
        {
          "6\nMatin et al.": "expression recognition with crowd-sourced label distribution.\nIn: Proceedings of"
        },
        {
          "6\nMatin et al.": "the 18th ACM International Conference on Multimodal Interaction. ACM (2016)"
        },
        {
          "6\nMatin et al.": "3. Buolamwini, J., Gebru, T.: Gender\nshades:\nIntersectional accuracy disparities\nin"
        },
        {
          "6\nMatin et al.": "commercial gender\nclassiﬁcation.\nIn: Conference on fairness, accountability and"
        },
        {
          "6\nMatin et al.": "transparency. pp. 77–91 (2018)"
        },
        {
          "6\nMatin et al.": "4. Gal, Y., Ghahramani, Z.: Dropout\nas\na bayesian approximation: Representing"
        },
        {
          "6\nMatin et al.": "model uncertainty in deep learning. In:\ninternational conference on machine learn-"
        },
        {
          "6\nMatin et al.": "ing. pp. 1050–1059 (2016)"
        },
        {
          "6\nMatin et al.": "5. Georgescu, M.I., Ionescu, R.T., Popescu, M.: Local\nlearning with deep and hand-"
        },
        {
          "6\nMatin et al.": "crafted features for facial expression recognition. arXiv preprint arXiv:1804.10892"
        },
        {
          "6\nMatin et al.": "(2018)"
        },
        {
          "6\nMatin et al.": "6. Goodfellow,\nI.J., Erhan, D., Carrier, P.L., Courville, A., Mirza, M., Hamner, B.,"
        },
        {
          "6\nMatin et al.": "Cukierski, W., Tang, Y., Thaler, D., Lee, D.H., et al.: Challenges in representation"
        },
        {
          "6\nMatin et al.": "learning: A report on three machine learning contests. In: International Conference"
        },
        {
          "6\nMatin et al.": "on Neural Information Processing. Springer (2013)"
        },
        {
          "6\nMatin et al.": "7. Guo, C., Pleiss, G., Sun, Y., Weinberger, K.Q.: On calibration of modern neu-"
        },
        {
          "6\nMatin et al.": "ral networks.\nIn: Proceedings of\nthe 34th International Conference on Machine"
        },
        {
          "6\nMatin et al.": "Learning-Volume 70. pp. 1321–1330. JMLR. org (2017)"
        },
        {
          "6\nMatin et al.": "8. Huang, G., Liu, Z., Van Der Maaten, L., Weinberger, K.Q.: Densely connected"
        },
        {
          "6\nMatin et al.": "convolutional networks. In: Proceedings of the IEEE conference on computer vision"
        },
        {
          "6\nMatin et al.": "and pattern recognition. pp. 4700–4708 (2017)"
        },
        {
          "6\nMatin et al.": "9.\nIoﬀe, S., Szegedy, C.: Batch normalization: Accelerating deep network training by"
        },
        {
          "6\nMatin et al.": "reducing internal covariate shift. In: International Conference on Machine Learning"
        },
        {
          "6\nMatin et al.": "(2015)"
        },
        {
          "6\nMatin et al.": "10. Kingma, D., Ba, J.: Adam: A method for stochastic optimization. arXiv preprint"
        },
        {
          "6\nMatin et al.": "arXiv:1412.6980 (2014)"
        },
        {
          "6\nMatin et al.": "11. Ko, B.C.: A brief review of facial emotion recognition based on visual\ninformation."
        },
        {
          "6\nMatin et al.": "sensors 18(2),\n401 (2018)"
        },
        {
          "6\nMatin et al.": "12. Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classiﬁcation with deep con-"
        },
        {
          "6\nMatin et al.": "volutional neural networks. In: Advances in neural information processing systems."
        },
        {
          "6\nMatin et al.": "pp. 1097–1105 (2012)"
        },
        {
          "6\nMatin et al.": "13. Lakshminarayanan, B., Pritzel, A., Blundell, C.: Simple and scalable predictive"
        },
        {
          "6\nMatin et al.": "uncertainty estimation using deep ensembles. In: Advances in Neural Information"
        },
        {
          "6\nMatin et al.": "Processing Systems. pp. 6402–6413 (2017)"
        },
        {
          "6\nMatin et al.": "14. Mobiny, A., Nguyen, H.V., Moulik,\nS., Garg, N., Wu, C.C.: Dropconnect\nis"
        },
        {
          "6\nMatin et al.": "eﬀective\nin modeling\nuncertainty\nof\nbayesian\ndeep\nnetworks.\narXiv\npreprint"
        },
        {
          "6\nMatin et al.": "arXiv:1906.04569 (2019)"
        },
        {
          "6\nMatin et al.": "15. Ovadia, Y., Fertig, E., Ren, J., Nado, Z., Sculley, D., Nowozin, S., Dillon, J., Lak-"
        },
        {
          "6\nMatin et al.": "shminarayanan, B., Snoek, J.: Can you trust your model’s uncertainty? evaluating"
        },
        {
          "6\nMatin et al.": "predictive uncertainty under dataset\nshift.\nIn: Advances\nin Neural\nInformation"
        },
        {
          "6\nMatin et al.": "Processing Systems. pp. 13991–14002 (2019)"
        },
        {
          "6\nMatin et al.": "16. Parkhi, O.M., Vedaldi, A., Zisserman, A.: Deep face recognition.\nIn: British Ma-"
        },
        {
          "6\nMatin et al.": "chine Vision Conference (2015)"
        }
      ],
      "page": 6
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Hey Human, If your Facial Emotions are Uncertain, You Should Use BNNs!\n7": "17. Peterson, J.C., Battleday, R.M., Griﬃths, T.L., Russakovsky, O.: Human uncer-"
        },
        {
          "Hey Human, If your Facial Emotions are Uncertain, You Should Use BNNs!\n7": "tainty makes classiﬁcation more robust. In: Proceedings of the IEEE International"
        },
        {
          "Hey Human, If your Facial Emotions are Uncertain, You Should Use BNNs!\n7": "Conference on Computer Vision. pp. 9617–9626 (2019)"
        },
        {
          "Hey Human, If your Facial Emotions are Uncertain, You Should Use BNNs!\n7": "18. Simonyan, K., Zisserman, A.: Very deep convolutional networks\nfor\nlarge-scale"
        },
        {
          "Hey Human, If your Facial Emotions are Uncertain, You Should Use BNNs!\n7": "image recognition. arXiv preprint arXiv:1409.1556 (2014)"
        },
        {
          "Hey Human, If your Facial Emotions are Uncertain, You Should Use BNNs!\n7": "19. Siqueira, H., Magg, S., Wermter, S.: Eﬃcient\nfacial\nfeature\nlearning with wide"
        },
        {
          "Hey Human, If your Facial Emotions are Uncertain, You Should Use BNNs!\n7": "ensemble-based convolutional neural networks. arXiv preprint arXiv:2001.06338"
        },
        {
          "Hey Human, If your Facial Emotions are Uncertain, You Should Use BNNs!\n7": "(2020)"
        },
        {
          "Hey Human, If your Facial Emotions are Uncertain, You Should Use BNNs!\n7": "20. Surace, L., Patacchiola, M., Battini S¨onmez, E., Spataro, W., Cangelosi, A.: Emo-"
        },
        {
          "Hey Human, If your Facial Emotions are Uncertain, You Should Use BNNs!\n7": "tion recognition in the wild using deep neural networks and bayesian classiﬁers. In:"
        },
        {
          "Hey Human, If your Facial Emotions are Uncertain, You Should Use BNNs!\n7": "Proceedings of the 19th ACM International Conference on Multimodal Interaction."
        },
        {
          "Hey Human, If your Facial Emotions are Uncertain, You Should Use BNNs!\n7": "pp. 593–597 (2017)"
        },
        {
          "Hey Human, If your Facial Emotions are Uncertain, You Should Use BNNs!\n7": "21. Valdenegro-Toro, M.: Deep Sub-ensembles for Fast Uncertainty Estimation in Im-"
        },
        {
          "Hey Human, If your Facial Emotions are Uncertain, You Should Use BNNs!\n7": "age Classiﬁcation. In: NeurIPS Workshop on Bayesian Deep Learning (2019)"
        },
        {
          "Hey Human, If your Facial Emotions are Uncertain, You Should Use BNNs!\n7": "22. Wang, K., Peng, X., Yang, J., Lu, S., Qiao, Y.: Suppressing uncertainties for large-"
        },
        {
          "Hey Human, If your Facial Emotions are Uncertain, You Should Use BNNs!\n7": "scale facial expression recognition.\nIn: Proceedings of the IEEE/CVF Conference"
        },
        {
          "Hey Human, If your Facial Emotions are Uncertain, You Should Use BNNs!\n7": "on Computer Vision and Pattern Recognition. pp. 6897–6906 (2020)"
        },
        {
          "Hey Human, If your Facial Emotions are Uncertain, You Should Use BNNs!\n7": "23. Yu, Z., Zhang, C.:\nImage based static facial expression recognition with multiple"
        },
        {
          "Hey Human, If your Facial Emotions are Uncertain, You Should Use BNNs!\n7": "deep network learning. In: Proceedings of the 2015 ACM on international confer-"
        },
        {
          "Hey Human, If your Facial Emotions are Uncertain, You Should Use BNNs!\n7": "ence on multimodal\ninteraction. pp. 435–442 (2015)"
        }
      ],
      "page": 7
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Calibration curve using # of samples resulting in best accuracies, MC-D, FERPlus": "VGG16 - 2 MC-D Samples",
          "Calibration curve using # of samples resulting in least calibration error, MC-D, FERPlus": "VGG16 - 3 MC-D Samples\n1.0"
        },
        {
          "Calibration curve using # of samples resulting in best accuracies, MC-D, FERPlus": "AlexNet - 11 MC-D Samples",
          "Calibration curve using # of samples resulting in least calibration error, MC-D, FERPlus": "AlexNet - 1 MC-D Samples"
        },
        {
          "Calibration curve using # of samples resulting in best accuracies, MC-D, FERPlus": "DenseNet - 8 MC-D Samples",
          "Calibration curve using # of samples resulting in least calibration error, MC-D, FERPlus": "DenseNet - 3 MC-D Samples"
        },
        {
          "Calibration curve using # of samples resulting in best accuracies, MC-D, FERPlus": "",
          "Calibration curve using # of samples resulting in least calibration error, MC-D, FERPlus": "0.8"
        },
        {
          "Calibration curve using # of samples resulting in best accuracies, MC-D, FERPlus": "",
          "Calibration curve using # of samples resulting in least calibration error, MC-D, FERPlus": "0.6"
        },
        {
          "Calibration curve using # of samples resulting in best accuracies, MC-D, FERPlus": "",
          "Calibration curve using # of samples resulting in least calibration error, MC-D, FERPlus": "0.4"
        },
        {
          "Calibration curve using # of samples resulting in best accuracies, MC-D, FERPlus": "",
          "Calibration curve using # of samples resulting in least calibration error, MC-D, FERPlus": "0.2"
        },
        {
          "Calibration curve using # of samples resulting in best accuracies, MC-D, FERPlus": "",
          "Calibration curve using # of samples resulting in least calibration error, MC-D, FERPlus": "0.0"
        },
        {
          "Calibration curve using # of samples resulting in best accuracies, MC-D, FERPlus": "0.0\n0.2\n0.4\n0.6\n0.8\n1.0",
          "Calibration curve using # of samples resulting in least calibration error, MC-D, FERPlus": "0.0\n0.2\n0.4"
        },
        {
          "Calibration curve using # of samples resulting in best accuracies, MC-D, FERPlus": "Confidence",
          "Calibration curve using # of samples resulting in least calibration error, MC-D, FERPlus": "Confidence"
        }
      ],
      "page": 8
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "1.0": "0.8",
          "Label Probability": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": ""
        },
        {
          "1.0": "Probability\n0.6",
          "Label Probability": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": ""
        },
        {
          "1.0": "0.4",
          "Label Probability": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": ""
        },
        {
          "1.0": "0.2",
          "Label Probability": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": ""
        },
        {
          "1.0": "0.0",
          "Label Probability": "s",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "e\ns\ni\nr",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "e\ns\ni\nr",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "e\ns\ni\nr",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": "e\ns\ni\nr"
        },
        {
          "1.0": "",
          "Label Probability": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "p\nr\nu\ns",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "p\nr\nu\ns",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "p\nr\nu\ns",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": "p\nr\nu\ns"
        },
        {
          "1.0": "",
          "Label Probability": "Class",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": ""
        },
        {
          "1.0": "",
          "Label Probability": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": ""
        },
        {
          "1.0": "1.0",
          "Label Probability": "Label Probability",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "Class probability, DE, FERPlus, VGG16, Entropy : 1.76",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "Class probability, DE, FERPlus, VGG16, Entropy : 1.98",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "Class probability, DE, FERPlus, VGG16, Entropy : 1.88",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": "Class probability, DE, FERPlus, VGG16, Entropy : 1.85"
        },
        {
          "1.0": "0.8",
          "Label Probability": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": ""
        },
        {
          "1.0": "Probability\n0.6",
          "Label Probability": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": ""
        },
        {
          "1.0": "0.4",
          "Label Probability": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": ""
        },
        {
          "1.0": "0.2",
          "Label Probability": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": ""
        },
        {
          "1.0": "0.0",
          "Label Probability": "s",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "e\ns\ni\nr",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "e\ns\ni\nr",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "e\ns\ni\nr",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": "e\ns\ni\nr"
        },
        {
          "1.0": "",
          "Label Probability": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "p\nr\nu\ns",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "p\nr\nu\ns",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "p\nr\nu\ns",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": "p\nr\nu\ns"
        },
        {
          "1.0": "",
          "Label Probability": "Class",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": ""
        },
        {
          "1.0": "",
          "Label Probability": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": ""
        },
        {
          "1.0": "1.0",
          "Label Probability": "Label Probability",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "Class probability, DE, FERPlus, VGG16, Entropy : 1.46",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "Class probability, DE, FERPlus, VGG16, Entropy : 1.84",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "Class probability, DE, FERPlus, VGG16, Entropy : 1.89",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": "Class probability, DE, FERPlus, VGG16, Entropy : 1.89"
        },
        {
          "1.0": "0.8",
          "Label Probability": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": ""
        },
        {
          "1.0": "Probability\n0.6",
          "Label Probability": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": ""
        },
        {
          "1.0": "0.4",
          "Label Probability": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": ""
        },
        {
          "1.0": "0.2",
          "Label Probability": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": ""
        },
        {
          "1.0": "0.0",
          "Label Probability": "s",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "e\ns\ni\nr",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "e\ns\ni\nr",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "e\ns\ni\nr",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": "e\ns\ni\nr"
        },
        {
          "1.0": "",
          "Label Probability": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "p\nr\nu\ns",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "p\nr\nu\ns",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "p\nr\nu\ns",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": "p\nr\nu\ns"
        },
        {
          "1.0": "",
          "Label Probability": "Class",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": ""
        },
        {
          "1.0": "",
          "Label Probability": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": ""
        },
        {
          "1.0": "1.0",
          "Label Probability": "Label Probability",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "Class probability, DE, FERPlus, VGG16, Entropy : 1.82",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "Class probability, DE, FERPlus, VGG16, Entropy : 1.86",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "Class probability, DE, FERPlus, VGG16, Entropy : 1.90",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": "Class probability, DE, FERPlus, VGG16, Entropy : 1.89"
        },
        {
          "1.0": "0.8",
          "Label Probability": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": ""
        },
        {
          "1.0": "Probability\n0.6",
          "Label Probability": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": ""
        },
        {
          "1.0": "0.4",
          "Label Probability": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": ""
        },
        {
          "1.0": "0.2",
          "Label Probability": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": ""
        },
        {
          "1.0": "0.0",
          "Label Probability": "s",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "e\ns\ni\nr",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "e\ns\ni\nr",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "e\ns\ni\nr",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": "e\ns\ni\nr"
        },
        {
          "1.0": "",
          "Label Probability": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "p\nr\nu\ns",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "p\nr\nu\ns",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "p\nr\nu\ns",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": "p\nr\nu\ns"
        },
        {
          "1.0": "",
          "Label Probability": "Class",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": ""
        },
        {
          "1.0": "",
          "Label Probability": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "Anger",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": ""
        },
        {
          "1.0": "1.0",
          "Label Probability": "Label Probability",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "Class probability, DE, FERPlus, VGG16, Entropy : 1.92",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "Class probability, DE, FERPlus, VGG16, Entropy : 1.90",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "Class probability, DE, FERPlus, VGG16, Entropy : 1.89",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": "Class probability, DE, FERPlus, VGG16, Entropy : 1.88"
        },
        {
          "1.0": "0.8",
          "Label Probability": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": ""
        },
        {
          "1.0": "Probability\n0.6",
          "Label Probability": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": ""
        },
        {
          "1.0": "0.4",
          "Label Probability": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": ""
        },
        {
          "1.0": "0.2",
          "Label Probability": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": ""
        },
        {
          "1.0": "0.0",
          "Label Probability": "s",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "e\ns\ni\nr",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "e\ns\ni\nr",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "e\ns\ni\nr",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": "e\ns\ni\nr"
        },
        {
          "1.0": "",
          "Label Probability": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "p\nr\nu\ns",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "p\nr\nu\ns",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "p\nr\nu\ns",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": "p\nr\nu\ns"
        },
        {
          "1.0": "",
          "Label Probability": "Class",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.68": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.86": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.85": "",
          "Class probability, DE, FERPlus, VGG16, Entropy : 1.87": ""
        }
      ],
      "page": 9
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "1.0": "0.8",
          "Label Probability": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": ""
        },
        {
          "1.0": "Probability\n0.6",
          "Label Probability": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": ""
        },
        {
          "1.0": "0.4",
          "Label Probability": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": ""
        },
        {
          "1.0": "0.2",
          "Label Probability": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": ""
        },
        {
          "1.0": "0.0",
          "Label Probability": "s",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "e\ns\ni\nr",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "e\ns\ni\nr",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": "e\ns\ni\nr"
        },
        {
          "1.0": "",
          "Label Probability": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "p\nr\nu\ns",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "p\nr\nu\ns",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": "p\nr\nu\ns"
        },
        {
          "1.0": "",
          "Label Probability": "Class",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": ""
        },
        {
          "1.0": "",
          "Label Probability": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": ""
        },
        {
          "1.0": "1.0",
          "Label Probability": "Label Probability",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "Class probability, DE, FERPlus, AlexNet, Entropy : 1.51",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": "Class probability, DE, FERPlus, AlexNet, Entropy : 1.84"
        },
        {
          "1.0": "0.8",
          "Label Probability": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": ""
        },
        {
          "1.0": "Probability\n0.6",
          "Label Probability": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": ""
        },
        {
          "1.0": "0.4",
          "Label Probability": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": ""
        },
        {
          "1.0": "0.2",
          "Label Probability": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": ""
        },
        {
          "1.0": "0.0",
          "Label Probability": "s",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "e\ns\ni\nr",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "e\ns\ni\nr",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": "e\ns\ni\nr"
        },
        {
          "1.0": "",
          "Label Probability": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "p\nr\nu\ns",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "p\nr\nu\ns",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": "p\nr\nu\ns"
        },
        {
          "1.0": "",
          "Label Probability": "Class",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": ""
        },
        {
          "1.0": "",
          "Label Probability": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": ""
        },
        {
          "1.0": "1.0",
          "Label Probability": "Label Probability",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "Class probability, DE, FERPlus, AlexNet, Entropy : 1.84",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "Class probability, DE, FERPlus, AlexNet, Entropy : 1.85",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": "Class probability, DE, FERPlus, AlexNet, Entropy : 1.86"
        },
        {
          "1.0": "0.8",
          "Label Probability": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": ""
        },
        {
          "1.0": "Probability\n0.6",
          "Label Probability": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": ""
        },
        {
          "1.0": "0.4",
          "Label Probability": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": ""
        },
        {
          "1.0": "0.2",
          "Label Probability": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": ""
        },
        {
          "1.0": "0.0",
          "Label Probability": "s",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "e\ns\ni\nr",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "e\ns\ni\nr",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": "e\ns\ni\nr"
        },
        {
          "1.0": "",
          "Label Probability": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "p\nr\nu\ns",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "p\nr\nu\ns",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": "p\nr\nu\ns"
        },
        {
          "1.0": "",
          "Label Probability": "Class",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": ""
        },
        {
          "1.0": "",
          "Label Probability": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": ""
        },
        {
          "1.0": "1.0",
          "Label Probability": "Label Probability",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "Class probability, DE, FERPlus, AlexNet, Entropy : 1.64",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "Class probability, DE, FERPlus, AlexNet, Entropy : 1.88",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": "Class probability, DE, FERPlus, AlexNet, Entropy : 1.87"
        },
        {
          "1.0": "0.8",
          "Label Probability": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": ""
        },
        {
          "1.0": "Probability\n0.6",
          "Label Probability": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": ""
        },
        {
          "1.0": "0.4",
          "Label Probability": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": ""
        },
        {
          "1.0": "0.2",
          "Label Probability": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": ""
        },
        {
          "1.0": "0.0",
          "Label Probability": "s",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "e\ns\ni\nr",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "e\ns\ni\nr",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": "e\ns\ni\nr"
        },
        {
          "1.0": "",
          "Label Probability": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "p\nr\nu\ns",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "p\nr\nu\ns",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": "p\nr\nu\ns"
        },
        {
          "1.0": "",
          "Label Probability": "Class",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": ""
        },
        {
          "1.0": "",
          "Label Probability": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": ""
        },
        {
          "1.0": "1.0",
          "Label Probability": "Label Probability",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "Class probability, DE, FERPlus, AlexNet, Entropy : 1.75",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "Class probability, DE, FERPlus, AlexNet, Entropy : 1.89",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": "Class probability, DE, FERPlus, AlexNet, Entropy : 1.89"
        },
        {
          "1.0": "0.8",
          "Label Probability": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": ""
        },
        {
          "1.0": "Probability\n0.6",
          "Label Probability": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": ""
        },
        {
          "1.0": "0.4",
          "Label Probability": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": ""
        },
        {
          "1.0": "0.2",
          "Label Probability": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": ""
        },
        {
          "1.0": "0.0",
          "Label Probability": "s",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "e\ns\ni\nr",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "e\ns\ni\nr",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": "e\ns\ni\nr"
        },
        {
          "1.0": "",
          "Label Probability": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "p\nr\nu\ns",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "p\nr\nu\ns",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": "p\nr\nu\ns"
        },
        {
          "1.0": "",
          "Label Probability": "Class",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.90": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.80": "",
          "Class probability, DE, FERPlus, AlexNet, Entropy : 1.82": ""
        }
      ],
      "page": 10
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Real-time convolutional neural networks for emotion and gender classification",
      "authors": [
        "O Arriaga",
        "M Valdenegro-Toro",
        "P Plöger"
      ],
      "year": "2019",
      "venue": "European Symposium on Artificial Neural Networks"
    },
    {
      "citation_id": "2",
      "title": "Training deep networks for facial expression recognition with crowd-sourced label distribution",
      "authors": [
        "E Barsoum",
        "C Zhang",
        "C Ferrer",
        "Z Zhang"
      ],
      "year": "2016",
      "venue": "Proceedings of the 18th ACM International Conference on Multimodal Interaction"
    },
    {
      "citation_id": "3",
      "title": "Gender shades: Intersectional accuracy disparities in commercial gender classification",
      "authors": [
        "J Buolamwini",
        "T Gebru"
      ],
      "year": "2018",
      "venue": "Conference on fairness, accountability and transparency"
    },
    {
      "citation_id": "4",
      "title": "Dropout as a bayesian approximation: Representing model uncertainty in deep learning",
      "authors": [
        "Y Gal",
        "Z Ghahramani"
      ],
      "year": "2016",
      "venue": "international conference on machine learning"
    },
    {
      "citation_id": "5",
      "title": "Local learning with deep and handcrafted features for facial expression recognition",
      "authors": [
        "M Georgescu",
        "R Ionescu",
        "M Popescu"
      ],
      "year": "2018",
      "venue": "Local learning with deep and handcrafted features for facial expression recognition",
      "arxiv": "arXiv:1804.10892"
    },
    {
      "citation_id": "6",
      "title": "Challenges in representation learning: A report on three machine learning contests",
      "authors": [
        "I Goodfellow",
        "D Erhan",
        "P Carrier",
        "A Courville",
        "M Mirza",
        "B Hamner",
        "W Cukierski",
        "Y Tang",
        "D Thaler",
        "D Lee"
      ],
      "year": "2013",
      "venue": "International Conference on Neural Information Processing"
    },
    {
      "citation_id": "7",
      "title": "On calibration of modern neural networks",
      "authors": [
        "C Guo",
        "G Pleiss",
        "Y Sun",
        "K Weinberger"
      ],
      "year": "2017",
      "venue": "Proceedings of the 34th International Conference on Machine Learning"
    },
    {
      "citation_id": "8",
      "title": "Densely connected convolutional networks",
      "authors": [
        "G Huang",
        "Z Liu",
        "L Van Der Maaten",
        "K Weinberger"
      ],
      "year": "2017",
      "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition"
    },
    {
      "citation_id": "9",
      "title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift",
      "authors": [
        "S Ioffe",
        "C Szegedy"
      ],
      "year": "2015",
      "venue": "International Conference on Machine Learning"
    },
    {
      "citation_id": "10",
      "title": "Adam: A method for stochastic optimization",
      "authors": [
        "D Kingma",
        "J Ba"
      ],
      "year": "2014",
      "venue": "Adam: A method for stochastic optimization",
      "arxiv": "arXiv:1412.6980"
    },
    {
      "citation_id": "11",
      "title": "A brief review of facial emotion recognition based on visual information",
      "authors": [
        "B Ko"
      ],
      "year": "2018",
      "venue": "sensors"
    },
    {
      "citation_id": "12",
      "title": "Imagenet classification with deep convolutional neural networks",
      "authors": [
        "A Krizhevsky",
        "I Sutskever",
        "G Hinton"
      ],
      "year": "2012",
      "venue": "Advances in neural information processing systems"
    },
    {
      "citation_id": "13",
      "title": "Simple and scalable predictive uncertainty estimation using deep ensembles",
      "authors": [
        "B Lakshminarayanan",
        "A Pritzel",
        "C Blundell"
      ],
      "year": "2017",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "14",
      "title": "Dropconnect is effective in modeling uncertainty of bayesian deep networks",
      "authors": [
        "A Mobiny",
        "H Nguyen",
        "S Moulik",
        "N Garg",
        "C Wu"
      ],
      "year": "2019",
      "venue": "Dropconnect is effective in modeling uncertainty of bayesian deep networks",
      "arxiv": "arXiv:1906.04569"
    },
    {
      "citation_id": "15",
      "title": "Can you trust your model's uncertainty? evaluating predictive uncertainty under dataset shift",
      "authors": [
        "Y Ovadia",
        "E Fertig",
        "J Ren",
        "Z Nado",
        "D Sculley",
        "S Nowozin",
        "J Dillon",
        "B Lakshminarayanan",
        "J Snoek"
      ],
      "year": "2019",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "16",
      "title": "Deep face recognition",
      "authors": [
        "O Parkhi",
        "A Vedaldi",
        "A Zisserman"
      ],
      "year": "2015",
      "venue": "British Machine Vision Conference"
    },
    {
      "citation_id": "17",
      "title": "Human uncertainty makes classification more robust",
      "authors": [
        "J Peterson",
        "R Battleday",
        "T Griffiths",
        "O Russakovsky"
      ],
      "year": "2019",
      "venue": "Proceedings of the IEEE International Conference on Computer Vision"
    },
    {
      "citation_id": "18",
      "title": "Very deep convolutional networks for large-scale image recognition",
      "authors": [
        "K Simonyan",
        "A Zisserman"
      ],
      "year": "2014",
      "venue": "Very deep convolutional networks for large-scale image recognition",
      "arxiv": "arXiv:1409.1556"
    },
    {
      "citation_id": "19",
      "title": "Efficient facial feature learning with wide ensemble-based convolutional neural networks",
      "authors": [
        "H Siqueira",
        "S Magg",
        "S Wermter"
      ],
      "year": "2020",
      "venue": "Efficient facial feature learning with wide ensemble-based convolutional neural networks",
      "arxiv": "arXiv:2001.06338"
    },
    {
      "citation_id": "20",
      "title": "Emotion recognition in the wild using deep neural networks and bayesian classifiers",
      "authors": [
        "L Surace",
        "M Patacchiola",
        "E Battini Sönmez",
        "W Spataro",
        "A Cangelosi"
      ],
      "year": "2017",
      "venue": "Proceedings of the 19th ACM International Conference on Multimodal Interaction"
    },
    {
      "citation_id": "21",
      "title": "Deep Sub-ensembles for Fast Uncertainty Estimation in Image Classification",
      "authors": [
        "M Valdenegro-Toro"
      ],
      "year": "2019",
      "venue": "NeurIPS Workshop on Bayesian Deep Learning"
    },
    {
      "citation_id": "22",
      "title": "Suppressing uncertainties for largescale facial expression recognition",
      "authors": [
        "K Wang",
        "X Peng",
        "J Yang",
        "S Lu",
        "Y Qiao"
      ],
      "year": "2020",
      "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition"
    },
    {
      "citation_id": "23",
      "title": "Image based static facial expression recognition with multiple deep network learning",
      "authors": [
        "Z Yu",
        "C Zhang"
      ],
      "year": "2015",
      "venue": "Proceedings of the 2015 ACM on international conference on multimodal interaction"
    }
  ]
}