{
  "paper_id": "2210.11715v3",
  "title": "Empathetic Dialogue Generation Via Sensitive Emotion Recognition And Sensible Knowledge Selection",
  "published": "2022-10-21T03:51:18Z",
  "authors": [
    "Lanrui Wang",
    "Jiangnan Li",
    "Zheng Lin",
    "Fandong Meng",
    "Chenxu Yang",
    "Weiping Wang",
    "Jie Zhou"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Empathy, which is widely used in psychological counselling, is a key trait of everyday human conversations. Equipped with commonsense knowledge, current approaches to empathetic response generation focus on capturing implicit emotion within dialogue context, where the emotions are treated as a static variable throughout the conversations. However, emotions change dynamically between utterances, which makes previous works difficult to perceive the emotion flow and predict the correct emotion of the target response, leading to inappropriate response. Furthermore, simply importing commonsense knowledge without harmonization may trigger the conflicts between knowledge and emotion, which confuse the model to choose incorrect information to guide the generation process. To address the above problems, we propose a Serial Encoding and Emotion-Knowledge interaction (SEEK) method for empathetic dialogue generation. We use a fine-grained encoding strategy which is more sensitive to the emotion dynamics (emotion flow) in the conversations to predict the emotion-intent characteristic of response. Besides, we design a novel framework to model the interaction between knowledge and emotion to generate more sensible response. Extensive experiments on EMPATHET-ICDIALOGUES demonstrate that SEEK outperforms the strong baselines in both automatic and manual evaluations. 1",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Enriching dialogue systems with human characteristics and capabilities is a hotspot in the humanlike dialogue system research area. Empathy, which is used extensively in psychological counselling  (Sharma et al., 2021; Liu et al., 2021; Sharma et al., 2020) , is a key trait of everyday human conversations. In contrast to generating responses with controlled emotions  (Zhou et al., 2018; Zheng et al., 2021) , the key to the empathetic dialogue system is to understand the user's emotions and generate appropriate responses. Several works concentrate on improving the empathetic models' ability to capture contextual emotions by emotion mimicry  (Majumder et al., 2020) , feedback-based adversarial generating  (Li et al., 2019) , or the mixture of experts  (Lin et al., 2019) . On the other hand,  Sabour et al. (2021) ;  Li et al. (2020)  introduce commonsense knowledge into empathetic models so as to better perceive implicit semantic information and generate more informative and empathetic response.\n\nHowever, the existing works are all about the dialogue-level emotional perception  (Lin et al., 2019; Majumder et al., 2020; Li et al., 2019; Sabour et al., 2021; Li et al., 2020) . Since emotions change dynamically throughout conversations, the coarse modeling method at the dialogue level (recognizing the emotion of the whole conversation context) cannot capture the process of emotional dynamics and makes it difficult to predict response emotions.  Welivita and Pu (2020)  have studied the shifting pattern of the utterances and drawn two graphs to show the most common emotion-intent flow patterns (with a frequency ≥ 5) throughout the first four dialogue turns and the global exchanging trends of emotion-intent between speakers and listeners in the EMPATHETICDIALOGUES dataset. For instance, in the first case illustrated in Fig.  1 , the speaker's emotion shifts from afraid at the beginning of the conversation to an embarrassed selfdeprecation about previous experience of fearing heights (sharing such a funny story). Accordingly, it is much better that the dialogue agent should express the same self-deprecating sentiment like the gold response. Nevertheless, the baseline models have difficulty capturing subtle changes in the speaker's emotions and can only provide response according to the fear detected. Moreover, merely introducing knowledge without making emotionally logical choices may lead to logical conflicts between knowledge and emotion in the generated responses. As illustrated in the second case illustrated in Fig.  1 , the CEM  (Sabour et al., 2021)  model chooses the wrong knowledge and is unable to correctly give empathetic responses with nostalgic overtones, which makes knowledge and emotion come into conflict.\n\nTo this end, we propose a Serial Encoding and Emotion-Knowledge interaction (SEEK) method for empathetic dialogue generation. To achieve a more fine-grained perception of emotional dynamics, we use an utterance-level encoding strategy which is more sensitive to the emotion flow in the conversations and able to predict the emotion characteristic of the response. We further introduce two new emotion-intent identification tasks to understand contextual emotion and predict the emotional and intentional trait of responses. For the problem of conflicts between knowledge and emotions, we also design a framework modeling the process of bi-directional interaction between them. Extensive experimental results on the utterance-level annotated EMPATHETICDIALOGUES (ED) dataset (Welivita and Pu, 2020) demonstrate that SEEK outper-forms the strong baseline with both automatic and manual evaluation metrics. Our contributions are summarized as follows:\n\n• To the best of our knowledge, our work is the first to model the emotion flow that involves the process of emotional dynamics in the task of empathetic dialogue generation. In addition to the coarse emotion at the dialogue level, we introduce fine-grained emotions at the utterance level.\n\n• By modelling the bi-directional interactive selection process between commonsense knowledge and emotions, we have improved not only the ability to recognize contextual emotions, but also the ability to filter out unreasonable external knowledge, allowing the model to generate more sensible empathetic responses.\n\n• The automatic and manual evaluation on annotated-ED dataset shows that our proposed model is superior to the strong baselines and capable of generating more diverse and sensible empathetic responses.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Related Work",
      "text": "In order to control the emotion of the generated response, which is one of the fundamental characteristics of daily conversation, plenty of approaches  (Zhou et al., 2018; Zheng et al., 2021; Zhong et al., 2019; Shen and Feng, 2020; Liang et al., 2021)  view the target emotion as a guiding information of the models' generator. Contrary to controlling the emotion of the target response, the task of empathetic dialogue generation requires that the models learn a proper emotion to express empathy. Numerous researchers have attempted to improve the dialogue models' ability to respond empathetically.  Rashkin et al. (2019)  proposed a benchmark and dataset to build and evaluate empathetic dialogue generation models.  Lin et al. (2019)  learned a precise emotion distribution of the response based on mixture of experts.  Majumder et al. (2020)  split the emotions into two classes and designed a framework to mimic the target emotion in a certain class.  Li et al. (2019)  utilized user feedback to build a multi-resolution adversarial training framework. In addition,  Kim et al. (2021)  and  Kim et al. (2022)  focused on the keywords and emotion cause of dialogue history to better understand the context-level emotion and recognize feature transitions between utterances. As well, several datasets  (Liu et al., 2021; Welivita et al., 2021)  of empathetic dialogue generation have been published for further research. However, most of the current approaches do not pay enough attention to the emotion flow of the conversations.\n\nCommonsense knowledge is widely used to build dialogue systems.  Zhong et al. (2021a)  utilize Commonsense knowledge graph to gain candidate words for generation.  Sabour et al. (2021)  adopt COMET  (Bosselut et al., 2019) , a pre-trained language model to generate commonsense inference for retrieving implicit information of dialogue context. In addition,  Li et al. (2020)  construct a graphbased framework to encode the context-knowledge graph retrieved on commonsense knowledge base. The knowledge introduced into these models might become a trigger of logical conflicts due to the absence of harmony selection.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Methodology",
      "text": "",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Task Formulation",
      "text": "The task of empathetic dialogue generation is to generate empathetic responses based on the historical context. Given a dialogue D, where the context and the target response are denoted as C = [C 1 , ..., C N -1 ] and Y respectively, with a emotion label of the whole context e c . Additionally, a given sequence of emotion-intent labels EI = [ei 1 , ..., ei N -1 , ei Y ] of the corresponding utterances in D, which includes the 32 emotion categories, and 9 common intent classes. Our goal is to generate the next utterance Y , which is fluent and coherent to the context, and express empathy to the speaker's situation and feelings.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Utterance And Knowledge Encoder",
      "text": "Utterance Encoding: To get a precise representation of each utterance, we firstly encode the context at the utterance level to extract the contextual information. We employ Transformer  (Vaswani et al., 2017)  to encode the utterance. The embedding of the input is the sum of the word embedding, positional embedding, and dialogue state embedding. Following previous work, we prepend the utterance u i with [CLS] token to obtain the utterance input\n\nThe embedding is then fed into the Transformer, and we obtain the representation:\n\nwhere H U i ∈ R Ln×d , L n is the length of the utterance, and d is the hidden size of the encoder. We take the representation of [CLS] to represent the utterance:\n\nKnowledge Encoding: In order to generate high-quality commonsense inferences for the corresponding context, we utilize COMET  (Bosselut et al., 2019) , which is a pre-trained GPT  (Radford et al., 2018)  language model and fine-tuned on ATOMIC  (Sap et al., 2019) , to generate five types of commonsense knowledge: the effect of the person (xEffect), the reaction of the person speaking the corresponding sentence (xReact), the intent before the person speaking  (xIntent) , what the person needs  (xNeed) , and what the person wants after speaking the sentence (xWant). Appending these five special relation tokens after the utterance and feeding them into COMET, we get 5 commonsense inferences texts for each relation of input utterance and then concatenate them to K i . Similarly, we encode the knowledge text using the same Transformer Encoder, and average the encoded hidden state via mean pooling  (Zhong et al., 2021b) :\n\n(3)",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Emotion Flow Perceiver",
      "text": "Regarding the task of emotional understanding of each utterance as a tagging task, we use a Bi-LSTM to model the emotion dynamics and the interactions between different utterances for the contextual understanding process.\n\nThe input of Bi-LSTM is the concatenation of the encoded utterances and knowledge:\n\nwhere W a ∈ R 2d×d is a trainable weight, and Û i ∈ R 2d represents the processed utterance representation.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Fine-Grained Emotion Recognition",
      "text": "For better understanding of the conversation, we pass Û i through a tagging classifier to produce a fine-grained emotion-intent tagging distribution P tag ∈ R t :",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Dialogue Emotion Recognition",
      "text": "Response  where t is the number of emotion-intent categories.\n\nWe train the tagging module with the crossentropy loss between the predicted distribution and the ground truth label for a conversation context:\n\n(6)",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Response Emotion-Intent Prediction",
      "text": "The shift in emotion and intent in empathetic dialogue conforms to an intuitive pattern. We use the attention mechanism to learn the shift pattern of emotion and intent between utterances. ĥpre = attention([ Û 1 , Û 2 , ..., Û N -1 ]),\n\nwhere ĥpre ∈ R 2d is the representation of the predicted emotion-intent characteristic of response, and W p ∈ R 2d×t is the weight vector for the linear layer. P pre denotes the predicted distribution of the emotion-intent of the target response, t is the number of emotion and intent categories.\n\nDuring training, we then minimize the crossentropy loss between the emotion-intent distribution of the predicted response P pre and the ground truth label ei N of the target response :\n\n(8)",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Dialogue Emotion Recognition",
      "text": "The sequence of utterances representation not only has the contextual information of utterances themselves but also indicates the emotional trait of the whole dialogue. Similarly, we employ the attention mechanism to summarize the holistic emotion label, based on the sequence\n\nwhere h dia ∈ R 2d , and W d ∈ R 2d×q is the weight vector for the linear layer. The P dia is the distribution of the dialogue emotion, q is the number of available emotion categories.\n\nThe ground truth label of the dialogue emotion is denoted as e * . The cross-entropy loss utilized to optimize the process of summarizing the conversational emotion is calculated by: L dia = -log(P dia (e * )).\n\n(10)",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Knowledge Selecting Decoder",
      "text": "Merely introducing commonsense knowledge into empathetic models without making an emotionally logical selection to is not ideal.  Sabour et al. (2021)  select commonsense inferences with an implicit procedure. On the contrary, our method models the process of bi-directional interactions between emotion and knowledge of the corresponding utterance in the conversations. We adopt s layers of Cross-Attention Transformer to perform the harmony of emotion and knowledge. Since the utterance representation sequence [ Û 1 , Û 2 , ..., Û N -1 ] passed through the three tasks of emotion, it contains emotional characteristics of the corresponding utterances. The inputs of Cross-Attention Knowledge Selector are composed of the utterance representation sequence acting as the query vector, the key and value vector which are both the knowledge text generated from the COMET model K = [K 1 , ...K N -1 ]. The hidden representation of selected knowledge is as follows:\n\nwhere S ∈ R Ls×d , L s is the maximum length of the knowledge text, and d is the hidden size of the model. Afterward,we average the harmonized knowledge via mean pooling  (Zhong et al., 2021b) :\n\nWe take the Transformer Decoder as the backbone of the Decoder. We perform a concatenation operation between the averaged harmonized knowledge S and the prediction of response representation ĥpre to get a mixture of these two types of information to represent the [SOS] token:\n\nwhere W k ∈ R 2d×d is the weight vector for the linear layer. (14)",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Training Objectives",
      "text": "During the training process, we need to minimize three classification losses and a response generation loss. The classification losses are weighted equally:\n\nIn order to improve the diversity of the generated response, we adopt Frequency-Aware Cross-Entropy (FACE)  (Jiang et al., 2019)  as an additional loss to penalize high-frequency tokens, similar to  Sabour et al. (2021) :\n\nwhere w i is a frequency weight value of the i-th token in the vocabulary V , c i represents a candidate token in the vocabulary and δ t (c i ) is a function indicate whether c i equals to the ground truth token y t .\n\nLastly, all the parameters for our proposed model are jointly trained and optimized by minimizing the weighted sum of the three mentioned losses:\n\nwhere α, β, and γ are hyper-parameters used to balance three losses. In our experiments, we set α= 1, β= 1, and γ= 1.5.\n\n4 Experimental Setup",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Dataset",
      "text": "Our experiments are conducted on the utterancelevel annotated EMPATHETICDIALOGUES (ED)  (Rashkin et al., 2019; Welivita and Pu, 2020) . ED is a large-scale multi-turn dialogue dataset that contains 25k empathetic conversations between a speaker and a listener. ED provides 32 evenly distributed emotion labels which are common in daily chats. However, the emotion labels of ED dataset are on the context level, there are no explicit signals for utterance-level emotions. Welivita and Pu (2020) annotated ED dataset with 41 new categories of utterance-level emotional and intentional labels, which provide fine-grained information about the empathetic dialogues in ED dataset.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Baselines",
      "text": "We select several strong baseline models for com-",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Implementation Details",
      "text": "We implement our model using Pytorch  (Paszke et al., 2019) , and utilize Adam  (Kingma and Ba, 2015)  optimizer to optimize the model. We use 300-dimensional pre-trained GloVE vectors  (Pennington et al., 2014)  to initialize the word embeddings, which are shared between the encoder and the decoder. During the training stage, the learning rate is initialed as 0.0001 and we vary the learning rate following  Vaswani et al. (2017) . Our model is trained on one NVIDIA Geforce RTX 3090 GPU using a batch size of 32 and the early stopping strategy. For other settings, such as dropout rate, maximum decoding steps, and so forth, we keep the same as  Sabour et al. (2021) . The training time of SEEK is about 3 hours for around 27000 iterations.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Automatic Evaluation",
      "text": "Since  Liu et al. (2016)  had proved that some automatic metrics based on word overlapping might be improper to evaluate the dialogue systems, such as BLEU  (Papineni et al., 2002)  and ROUGE  (Lin, 2004) , we adopt Perplexity (PPL) and Distinct-n (Dist-n)  (Li et al., 2016)  as the main automatic metrics of generation quality. For the conversational emotion recognition and our newly introduced two tasks including fine-grained emotion-intent tagging and response emotion-intent prediction, we employ dialogue emotion accuracy (DE Acc.), utterance emotion-intent accuracy (UEI Acc.) and response emotion-intent accuracy (REI Acc.).\n\nTo examine whether SEEK can generate more sensible response with fine-grained emotion recognition, we compare the performance of our model with the strong baselines. As shown in Table  1 , the diversity scores (Dist-1 and Dist-2) of SEEK outperform all of the baselines, which indicates our models can generate more informative response based on the external knowledge. We attribute this improvement to the knowledge selector and the predicted emotion of the target responses, with which the cross-attention mechanism helps to select the related knowledge based on the contextual information of utterances, and the predicted vector provides  additional information of the generating process.\n\nTo prove if SEEK has better understanding of the dialogue emotion, we list the accuracy of the baselines and our proposed model. Remarkably, SEEK surpasses all of the baselines by a large margin, we attribute the increase of performance to the two fine-grained tasks we introduced. The better comprehension of the utterances in dialogue, the more accuracy it takes. In terms of the two new accuracy scores, UEI Accuracy and REI Accuracy, SEEK reaches satisfying performances, as the number of the categories of these two tasks are 41.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Human Evaluation",
      "text": "Following previous works, we conduct a human evaluation based on three aspects: coherence (Coh.): How much does the response relevant to the context? empathy (Emp.): How much does the model know about the speaker's situation and emotion characteristic? Does the model respond empathetically enough or give suggestions? fluency (Flu.): How much the generated response obey the grammar? We randomly choose 100 dialogues and assign the responses generated by the models to three crowd-sourced workers for the evaluation. Each aspect is on a scale of 1 to 5. Moreover, considering the variation between different individuals, we conduct another human A/B test to directly compare our method with other baselines. Three professional annotators score the questionnaire of the response pairs to choose one of the responses in random order or select \"Tie\" when the quality of provided sentence is difficult to distinguish. As the results of the human rating and A/B test are shown in Table  3  and table 4 , SEEK outperforms the baselines in all the three aspects.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Ablation Studies",
      "text": "To study the effect of tasks and modules employed in our model, we remove the newly introduced tasks and the interaction process between emotion and knowledge. Additionally, we replace the knowledge type and encoding strategy respectively. The results are demonstrated in Table  2 .\n\nRemoving the task of fine-grained Utterance Emotion-Intent tagging and Response Emotion-Intent prediction (w/o Utter, w/o Res, and w/o Utter & Res) causes the drop of accuracy of dialogue emotion recognition and generative quality, as these variants lose the fine-grained understanding of the dialogue and the ability to predict the emotion-intent characteristics of the target response.\n\nThe margin between the variant (w/o Emo) without emotional harmonization of the knowledge and SEEK proves the importance of the interaction between knowledge and emotion-intent from the Knowledge Selection module of our model. The variant without knowledge (w/o Know) indicates the importance of external knowledge for the diversity of responses the model generated.\n\nMoreover, the decreased performance by replacing the type of knowledge + Others Know and the encoding strategy + Context Enc shows the superiority of our method. Using Others type of knowledge in our model rather than PersonX results in a considerable decrease in all performance, which indicates that the PersonX type of commonsense helps the model to understand the utterances more effectively. The encoding strategy employed",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Cem",
      "text": "That is so sad.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Seek",
      "text": "That is pretty scary! I am glad that you were able to get in out! (Sympathizing)",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Golden",
      "text": "Why did you feel guilty? People really shouldn't drive drunk. (Questioning)\n\nTable  5 : Two cases of generated responses by SEEK and the baselines. We annotated each turn with the emotional or intentional labels at the end of the utterances. The words relevant to the predicted labels in SEEK's response are highlighted in red.\n\nby baselines (as the variant + Context Enc used) emphasizes on overall understanding of the whole conversation, ignoring an accurate grasp of utterances, which leads to a decline of performance.\n\nRemarkably, the UEI Accuracy of w/o Utter and REI Accuracy of w/o Res are higher than SEEK. This is possibly due to the noise of the utterance label of annotated ED dataset and the subtle differences between intent categories (e.g. agreeing and acknowledging, counselling and questioning), which means the classification supervision signal of utterances or the response will make the input vector of attention module harder and lose some information of other classes. The loss of information about the hidden states may confuse another classifier and leads to a decrease in accuracy. In any case, although there exists a trade-off between these two tasks, they can simultaneously improve the ability of the model to generate more sensible empathetic responses by modeling the emotion flow.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Case Study",
      "text": "The first case of figure 1 illustrates how emotion shifts during a multi-turn conversation. For better compares generated responses of our model and the baselines, we show two of the generated result of our model and baselines in Table  5 . In the first case, the baselines failed to give responses with nostalgic overtones, similar to the commonsense knowledge demonstrated in figure  1 , where CEM choose the wrong knowledge to generate response with a happy emotion and the intent to have fun. On the contrary, SEEK successfully gives a response with more sensitive and accurate emotional perception. Similarly, in the second case, all of the baselines generate responses based on the explicit emotion guilty, without fine-grained understanding which is more accurate. Unlike the baselines, SEEK respond sensitively with sympathizing intent.\n\nWe further draw a heat map to illustrate the crossattention weights of commonsense knowledge in a certain case. The detailed information of that case and analysis will be shown in Appendix A.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Conclusion",
      "text": "In this paper, we study the task of empathetic dialogue generation. The strong baselines ignore emo-tion flow of the conversations. We therefore proposed a Serial Encoding and Emotion-Knowledge interaction (SEEK) method for empathetic dialogue generation, to predict the correct emotion of the target response by perceiving the emotion flow of the context and harmonizing commonsense knowledge with fine-grained emotions to avoid conflicts. Experiments on the utterance-level annotated EM-PATHETICDIALOGUES show that our model outperforms the baselines, and the ablation studies indicate that all the components of our model, the encoding strategy, and the commonsense knowledge work.\n\nIn the future, we will focus on further usage (e.g. providing online-emotion aid) of empathetic systems and try to improve normalization capabilities of our model on other datasets.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Limitations",
      "text": "The limitation of our work mainly comes from the shortage of datasets in the task of empathetic dialogue generation. Although there are several newly released large-scale datasets  (Liu et al., 2021; Welivita et al., 2021) , most of the research can only be carried out on the English corpus EMPATHET-ICDIALOGUES. Another limitation is the problem of evaluation metrics. As mentioned in  Liu et al. (2016) , the scores of standard automatic evaluation metrics are not consistent with human evaluation results. The lack of task-specifically automatic metrics makes it troublesome for evaluating empathetic dialogue generation.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Ethical Considerations",
      "text": "The data  (Rashkin et al., 2019; Welivita and Pu, 2020)  used in our work is all drawn from opensource datasets. The conversations of the dataset are around given emotions and carried out by employed crowd-sourced workers, with no personal privacy issues involved.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "A More Cases",
      "text": "To show the process of knowledge selection of our proposed model, we clearly show the attention weights on the commonsense knowledge in Table  6 . We firstly get the weights matrix from Cross-Attention outputs and search the words in the knowledge text by the index of high-value elements. To directly show the selecting process, we mark the knowledge words based on the color in the heat map we drew: the higher weight the knowledge words have the darker blue marks them in the table.\n\nIn this case, the context of the case is mainly about a couple of parents asking for the gender of the baby in a hospital and the COMET totally model generates 25 commonsense inferences based on it. The speaker reacts excitedly to knowing the gender of their baby which infers something to celebrate, and SEEK chooses the correct knowledge and expresses congratulation.",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Context",
      "text": "We asked the doc to put the ultrasound in an envelope so we could record our reaction to the gender reveal. I was very happy when I finally saw it! (Excited) SEEK Congratulations!",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Gold",
      "text": "Congrats! what gender did your child end up being?\n\nTable  6 : The visualization of the cross-attention weights of selecting knowledge in SEEK.",
      "page_start": 12,
      "page_end": 12
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Two cases of multi-turn Empathetic Di-",
      "page": 1
    },
    {
      "caption": "Figure 1: , the CEM (Sabour et al., 2021)",
      "page": 2
    },
    {
      "caption": "Figure 2: An overall architecture of our proposed model.",
      "page": 4
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Type\nx_intent": "to see the\nbaby\nto know the gender\nKnowledge\nto know the sex\nto be informed\nnone",
          "x_need": "to have an ultrasound\nto see the ultrasound\nto have the ultrasound\nto have a\nbaby\nto get the ultrasound",
          "x_want": "to see what the\nbaby\nis\nto show it to their friends\nto show it to everyone\nto show it to others\nto see the\nbaby",
          "x_effect": "to see the\nbaby\nto see the\ngender\nto see the ultrasound\nto be happy\nwe get excited",
          "x_react": "happy\nexcited\nsurprised\njoyful\nrelieved"
        }
      ],
      "page": 12
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "COMET: commonsense transformers for automatic knowledge graph construction",
      "authors": [
        "Antoine Bosselut",
        "Hannah Rashkin",
        "Maarten Sap",
        "Chaitanya Malaviya",
        "Asli Celikyilmaz",
        "Yejin Choi"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019",
      "doi": "10.18653/v1/p19-1470"
    },
    {
      "citation_id": "2",
      "title": "Improving neural response diversity with frequency-aware cross-entropy loss",
      "authors": [
        "Shaojie Jiang",
        "Pengjie Ren",
        "Christof Monz",
        "Maarten De Rijke"
      ],
      "year": "2019",
      "venue": "The World Wide Web Conference",
      "doi": "10.1145/3308558.3313415"
    },
    {
      "citation_id": "3",
      "title": "Perspective-taking and pragmatics for generating empathetic responses focused on emotion causes",
      "authors": [
        "Hyunwoo Kim",
        "Byeongchang Kim",
        "Gunhee Kim"
      ],
      "year": "2021",
      "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana",
      "doi": "10.18653/v1/2021.emnlp-main.170"
    },
    {
      "citation_id": "4",
      "title": "Emp-rft: Empathetic response generation via recognizing feature transitions between utterances",
      "authors": [
        "Wongyu Kim",
        "Youbin Ahn",
        "Donghyun Kim",
        "Kyong-Ho Lee"
      ],
      "year": "2022",
      "venue": "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2022",
      "doi": "10.18653/v1/2022.naacl-main.303"
    },
    {
      "citation_id": "5",
      "title": "Adam: A method for stochastic optimization",
      "authors": [
        "P Diederik",
        "Jimmy Kingma",
        "Ba"
      ],
      "year": "2015",
      "venue": "3rd International Conference on Learning Representations, ICLR 2015"
    },
    {
      "citation_id": "6",
      "title": "A diversity-promoting objective function for neural conversation models",
      "authors": [
        "Jiwei Li",
        "Michel Galley",
        "Chris Brockett",
        "Jianfeng Gao",
        "Bill Dolan"
      ],
      "year": "2016",
      "venue": "The 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
      "doi": "10.18653/v1/n16-1014"
    },
    {
      "citation_id": "7",
      "title": "Empgan: Multi-resolution interactive empathetic dialogue generation",
      "authors": [
        "Qintong Li",
        "Hongshen Chen",
        "Zhaochun Ren",
        "Zhumin Chen",
        "Zhaopeng Tu",
        "Jun Ma"
      ],
      "year": "2019",
      "venue": "Empgan: Multi-resolution interactive empathetic dialogue generation"
    },
    {
      "citation_id": "8",
      "title": "Empathetic dialogue generation via knowledge enhancing and emotion dependency modeling",
      "authors": [
        "Qintong Li",
        "Piji Li",
        "Zhumin Chen",
        "Zhaochun Ren"
      ],
      "year": "2020",
      "venue": "Empathetic dialogue generation via knowledge enhancing and emotion dependency modeling"
    },
    {
      "citation_id": "9",
      "title": "Infusing multisource knowledge with heterogeneous graph neural network for emotional conversation generation",
      "authors": [
        "Yunlong Liang",
        "Fandong Meng",
        "Ying Zhang",
        "Yufeng Chen",
        "Jinan Xu",
        "Jie Zhou"
      ],
      "year": "2021",
      "venue": "Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021, Virtual Event"
    },
    {
      "citation_id": "10",
      "title": "Rouge: A package for automatic evaluation of summaries",
      "authors": [
        "Chin-Yew Lin"
      ],
      "year": "2004",
      "venue": "Text summarization branches out"
    },
    {
      "citation_id": "11",
      "title": "MoEL: Mixture of empathetic listeners",
      "authors": [
        "Zhaojiang Lin",
        "Andrea Madotto",
        "Jamin Shin",
        "Peng Xu",
        "Pascale Fung"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
      "doi": "10.18653/v1/D19-1012"
    },
    {
      "citation_id": "12",
      "title": "How NOT to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation",
      "authors": [
        "Chia-Wei Liu",
        "Ryan Lowe",
        "Iulian Serban",
        "Michael Noseworthy",
        "Laurent Charlin",
        "Joelle Pineau"
      ],
      "year": "2016",
      "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing",
      "doi": "10.18653/v1/d16-1230"
    },
    {
      "citation_id": "13",
      "title": "Towards emotional support dialog systems",
      "authors": [
        "Siyang Liu",
        "Chujie Zheng",
        "Orianna Demasi",
        "Sahand Sabour",
        "Yu Li",
        "Zhou Yu",
        "Yong Jiang",
        "Minlie Huang"
      ],
      "year": "2021",
      "venue": "Towards emotional support dialog systems"
    },
    {
      "citation_id": "14",
      "title": "MIME: MIMicking emotions for empathetic response generation",
      "authors": [
        "Navonil Majumder",
        "Pengfei Hong",
        "Shanshan Peng",
        "Jiankun Lu",
        "Deepanway Ghosal"
      ],
      "year": "2020",
      "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
      "doi": "10.18653/v1/2020.emnlp-main.721"
    },
    {
      "citation_id": "15",
      "title": "Bleu: a method for automatic evaluation of machine translation",
      "authors": [
        "Kishore Papineni",
        "Salim Roukos",
        "Todd Ward",
        "Wei-Jing Zhu"
      ],
      "year": "2002",
      "venue": "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.3115/1073083.1073135"
    },
    {
      "citation_id": "16",
      "title": "Pytorch: An imperative style, high-performance deep learning library",
      "authors": [
        "Adam Paszke",
        "Sam Gross",
        "Francisco Massa",
        "Adam Lerer",
        "James Bradbury",
        "Gregory Chanan",
        "Trevor Killeen",
        "Zeming Lin",
        "Natalia Gimelshein",
        "Luca Antiga",
        "Alban Desmaison",
        "Andreas Köpf",
        "Edward Yang",
        "Zach Devito",
        "Martin Raison",
        "Alykhan Tejani",
        "Sasank Chilamkurthy",
        "Benoit Steiner",
        "Lu Fang",
        "Junjie Bai",
        "Soumith Chintala"
      ],
      "year": "2019",
      "venue": "Pytorch: An imperative style, high-performance deep learning library"
    },
    {
      "citation_id": "17",
      "title": "Glove: Global vectors for word representation",
      "authors": [
        "Jeffrey Pennington",
        "Richard Socher",
        "Christopher Manning"
      ],
      "year": "2014",
      "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing",
      "doi": "10.3115/v1/d14-1162"
    },
    {
      "citation_id": "18",
      "title": "Improving language understanding by generative pre-training",
      "authors": [
        "Alec Radford",
        "Karthik Narasimhan"
      ],
      "year": "2018",
      "venue": "Improving language understanding by generative pre-training"
    },
    {
      "citation_id": "19",
      "title": "Towards empathetic opendomain conversation models: A new benchmark and dataset",
      "authors": [
        "Eric Hannah Rashkin",
        "Margaret Smith",
        "Y-Lan Li",
        "Boureau"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019",
      "doi": "10.18653/v1/p19-1534"
    },
    {
      "citation_id": "20",
      "title": "CEM: commonsense-aware empathetic response generation",
      "authors": [
        "Sahand Sabour",
        "Chujie Zheng",
        "Minlie Huang"
      ],
      "year": "2021",
      "venue": "CEM: commonsense-aware empathetic response generation"
    },
    {
      "citation_id": "21",
      "title": "ATOMIC: an atlas of machine commonsense for if-then reasoning",
      "authors": [
        "Maarten Sap",
        "Le Ronan",
        "Emily Bras",
        "Chandra Allaway",
        "Nicholas Bhagavatula",
        "Hannah Lourie",
        "Brendan Rashkin",
        "Noah Roof",
        "Yejin Smith",
        "Choi"
      ],
      "year": "2019",
      "venue": "The Thirty-Third AAAI Conference on Artificial Intelligence, AAAI 2019, The Thirty-First Innovative Applications of Artificial Intelligence Conference, IAAI 2019, The Ninth AAAI Symposium on Educational Advances in Artificial Intelligence",
      "doi": "10.1609/aaai.v33i01.33013027"
    },
    {
      "citation_id": "22",
      "title": "Towards facilitating empathic conversations in online mental health support: A reinforcement learning approach",
      "authors": [
        "Ashish Sharma",
        "Inna Lin",
        "Adam Miner",
        "David Atkins",
        "Tim Althoff"
      ],
      "year": "2021",
      "venue": "Towards facilitating empathic conversations in online mental health support: A reinforcement learning approach"
    },
    {
      "citation_id": "23",
      "title": "A computational approach to understanding empathy expressed in text-based mental health support",
      "authors": [
        "Ashish Sharma",
        "Adam Miner",
        "David Atkins",
        "Tim Althoff"
      ],
      "year": "2020",
      "venue": "A computational approach to understanding empathy expressed in text-based mental health support"
    },
    {
      "citation_id": "24",
      "title": "CDL: curriculum dual learning for emotion-controllable response generation",
      "authors": [
        "Lei Shen",
        "Yang Feng"
      ],
      "year": "2020",
      "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020",
      "doi": "10.18653/v1/2020.acl-main.52"
    },
    {
      "citation_id": "25",
      "title": "Attention is all you need",
      "authors": [
        "Ashish Vaswani",
        "Noam Shazeer",
        "Niki Parmar",
        "Jakob Uszkoreit",
        "Llion Jones",
        "Aidan Gomez",
        "Lukasz Kaiser",
        "Illia Polosukhin"
      ],
      "year": "2017",
      "venue": "Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems"
    },
    {
      "citation_id": "26",
      "title": "A taxonomy of empathetic response intents in human social conversations",
      "authors": [
        "Anuradha Welivita",
        "Pearl Pu"
      ],
      "year": "2020",
      "venue": "Proceedings of the 28th International Conference on Computational Linguistics, COLING 2020",
      "doi": "10.18653/v1/2020.coling-main.429"
    },
    {
      "citation_id": "27",
      "title": "A large-scale dataset for empathetic response generation",
      "authors": [
        "Anuradha Welivita",
        "Yubo Xie",
        "Pearl Pu"
      ],
      "year": "2021",
      "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana",
      "doi": "10.18653/v1/2021.emnlp-main.96"
    },
    {
      "citation_id": "28",
      "title": "Comae: A multi-factor hierarchical framework for empathetic response generation",
      "authors": [
        "Chujie Zheng",
        "Yong Liu",
        "Wei Chen",
        "Yongcai Leng",
        "Minlie Huang"
      ],
      "year": "2021",
      "venue": "Findings of the Association for Computational Linguistics: ACL/IJCNLP 2021",
      "doi": "10.18653/v1/2021.findings-acl.72"
    },
    {
      "citation_id": "29",
      "title": "2021a. CARE: commonsense-aware emotional response generation with latent concepts",
      "authors": [
        "Peixiang Zhong",
        "Di Wang",
        "Pengfei Li",
        "Chen Zhang",
        "Hao Wang",
        "Chunyan Miao"
      ],
      "year": "2021",
      "venue": "Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021, Virtual Event"
    },
    {
      "citation_id": "30",
      "title": "2021b. CARE: commonsense-aware emotional response generation with latent concepts",
      "authors": [
        "Peixiang Zhong",
        "Di Wang",
        "Pengfei Li",
        "Chen Zhang",
        "Hao Wang",
        "Chunyan Miao"
      ],
      "year": "2021",
      "venue": "Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021, Virtual Event"
    },
    {
      "citation_id": "31",
      "title": "An affect-rich neural conversational model with biased attention and weighted cross-entropy loss",
      "authors": [
        "Peixiang Zhong",
        "Di Wang",
        "Chunyan Miao"
      ],
      "year": "2019",
      "venue": "The Thirty-Third AAAI Conference on Artificial Intelligence, AAAI 2019, The Thirty-First Innovative Applications of Artificial Intelligence Conference, IAAI 2019, The Ninth AAAI Symposium on Educational Advances in Artificial Intelligence",
      "doi": "10.1609/aaai.v33i01.33017492"
    },
    {
      "citation_id": "32",
      "title": "Emotional chatting machine: Emotional conversation generation with internal and external memory",
      "authors": [
        "Hao Zhou",
        "Minlie Huang",
        "Tianyang Zhang",
        "Xiaoyan Zhu",
        "Bing Liu"
      ],
      "year": "2018",
      "venue": "Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18)"
    }
  ]
}