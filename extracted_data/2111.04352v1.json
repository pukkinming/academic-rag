{
  "paper_id": "2111.04352v1",
  "title": "Grassmannian Learning Mutual Subspace Method For Image Set Recognition",
  "published": "2021-11-08T09:16:36Z",
  "authors": [
    "Lincon S. Souza",
    "Naoya Sogi",
    "Bernardo B. Gatto",
    "Takumi Kobayashi",
    "Kazuhiro Fukui"
  ],
  "keywords": [
    "Grassmannian learning mutual subspace method",
    "learning subspace methods",
    "subspace learning",
    "image recognition",
    "deep neural networks",
    "manifold optimization"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "This paper addresses the problem of object recognition given a set of images as input (e.g., multiple camera sources and video frames). Convolutional neural network (CNN)-based frameworks do not exploit these sets effectively, processing a pattern as observed, not capturing the underlying feature distribution as it does not consider the variance of images in the set. To address this issue, we propose the Grassmannian learning mutual subspace method (G-LMSM), a NN layer embedded on top of CNNs as a classifier, that can process image sets more effectively and can be trained in an end-to-end manner. The image set is represented by a low-dimensional input subspace; and this input subspace is matched with reference subspaces by a similarity of their canonical angles, an interpretable and easy to compute metric. The key idea of G-LMSM is that the reference subspaces are learned as points on the Grassmann manifold, optimized with Riemannian stochastic gradient descent. This learning is stable, efficient and theoretically well-grounded. We demonstrate the effectiveness of our proposed method on hand shape recognition, face identification, and facial emotion recognition.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "M ULTIPLE images of an object are useful for boosting performance of object classification  [1] ,  [2] . In surveillance and industrial systems, distributed cameras and sensors capture data in a continuous stream to provide multiple images pointing to a target object. The task of object recognition based on a set of images, called image set recognition, is formulated to classify an image set through comparing the input set to reference image sets (dictionary) of class objects.\n\nThe image set that we consider in this paper refers to a collection of image samples captured from the same object or event, thereby freeing images in a set from any order, such as temporal ordering. For example, image sets of our interest include multi-view images from multiple camera sources and video frames. As in the other image classification tasks, each image in the set could be represented by a naive image vector  [3] ,  [4] ,  [5]  or by the more sophisticated feature vector via CNNs  [6] ,  [7] , to provide us with a set of feature vectors for set classification. Therefore, the primal issue to be addressed in the set recognition is how to represent the set which is composed of variable number of feature vectors.\n\nSubspace-based methods  [8] ,  [9] ,  [10]  have been one of the leading solutions for image set recognition, and a central research topic for object recognition in computer vision. In the subspace methods, a set of images is effectively modeled by a lowdimensional subspace in a high-dimensional vector space  [1] ,  [2] ,  [4] ,  [11] . Such subspaces are typically generated by applying either singular value decomposition (SVD) or Gram-Schmidt orthogonalization to feature vectors in a set. The subspace-based set representation is effective in the following points. (1) A subspace exploits the geometrical structure of the probability distribution underlying an image set.  (2)  The subspaces are also statistically robust to input noises, e.g., occlusion in an image.  (3)  In addition, a subspace is a compact representation of a set; we can describe a set by fixed and low dimensional subspace no matter how many image frames are included in a set.\n\nIn the subspace-based methods, for classifying sets into class categories, an input subspace is compared to reference subspaces by using a structural similarity based on canonical angles  [12] ,  [13]  between subspaces. For example, suppose we have image sets of 3D objects, and it can be observed that under some assumptions, the structural similarity is related to 3D shape similarity  [2] ,  [3] ,  [4] , which enables us to implicitly compare object shapes by means of subspaces. Therefore, to further improve performance of subspace-based set classification, there are two directions regarding optimization of feature space on which the structural similarity is measured and that of reference subspace to describe dictionary samples.\n\nFor improving the feature space, some methods are proposed in the subspace literature, such as constrained mutual subspace method (CMSM)  [14] ,  [15]  and orthogonal MSM  [16] , by exploring linear projection from the original feature space to the space that is contributive to discriminatively measuring the structural similarities. Though the linear projection is extended to non-linear one via kernel tricks  [17] ,  [18] ,  [19] , the space that those methods produce is highly dependent on the input feature space in which image frames are originally represented. As to optimization of reference subspaces, the seminal work is performed by Kohonen and Oja  [10] ,  [20]  to formulate the learning subspace methods (LSM). In the LSM  [20] , a class reference subspace is iteratively improved by means of rotation based on the statistical decision-theoretic rule, beyond the simple SVD which computes reference subspace in a generative way. LSM is extended to averaged LSM (ALSM)  [21]  toward learning stability by considering iterative updating based on mini-batch. These two research directions are made in the subspace literature rather separately, while they could complement each other. Both proposed methods match an input subspace χ (blue) to a reference subspace υ j (t) (green) by using a similarity s j (red) based on their canonical angles. In the learning step, LMSM updates the reference subspaces to υ j (t + 1) (yellow) using a gradient vector; LMSM uses a gradient on the Euclidean matrix space, and G-LMSM uses the gradient ∇L(υ j ) (black) on the Grassmannian G.\n\nIn this paper, we formulate a new set-classification framework (Fig.  1 ) to learn both the reference subspaces and the feature space (representation) in which the set subspaces are extracted. It contains a key module which we propose to learn reference subspaces and is conceptualized in Fig.  2 . As in previous mutual subspace method, an input subspace is classified based on matching to class reference subspace by using canonical angle, a structural similarity. It should be noted that the reference subspaces are learned by means of the gradient descent and thereby it is possible to embed the learning subspace functionality into an end-to-end learning scheme to simultaneously learn image feature representation beyond the naive linear projection of off-the-shelf features  [14] ,  [19] .\n\nFrom the viewpoint of learning subspace, the proposed method is connected to Oja's LSM. There, however, are several key differences between those two methods. The LSM improves a reference subspace in an instance-based manner by considering vector-to-subspace classification, while our method learns subspace based on subspace-to-subspace comparison for set classification. Besides, in contrast to the heuristic updating rule in LSM, we apply gradient-based update to optimize the reference subspaces in a theoretical way.\n\nVector-to-subspace comparison in LSM is simply defined in Euclidean feature space. On the other hand, subspace-to-subspace relationships are naturally formulated in Grassmann manifold  [22] ,  [23] ,  [24] , a non-linear Riemannian manifold beyond the Euclidean space, thereby imposing difficulty on the gradient-based updating.\n\nWhile the gradient-based optimization has been usually applied in Euclidean parameter space such as by SGD, we establish the subspace updating formula by applying Riemannian stochastic gradient descent (RSGD)  [25] ,  [26]  to naturally optimize a subspace along a geodesic path towards (local) minima. It endows the learning subspace with an elegant geometrical structure of subspace as well as a clear and strong theoretical background and effective optimization; our method directly updates subspace representation without ad-hoc post-processing such as SVD to ensure orthonormality of the subspace basis which is time-consuming and degrades optimality of the updating.\n\nThe proposed method to learn subspaces can thus be plugged into an end-to-end learning framework which optimizes neural networks through back-propagation, as shown in Fig.  1 . As a result, the method contributes to learn both reference subspaces and feature representation in which the subspaces are extracted. The proposed set classification is formulated in such a general form that (1) it can cope with pre-designed (off-the-shelf) features to only learn reference subspaces and (2) can be embedded in an intermediate layer to represent an input set by a fixed-dimensional vector as set representation learning; from that viewpoint, the above-mentioned set classification (Fig.  1 ) is regarded as a set-based classification layer whose counterpart in a standard CNN is implemented in fully-connected (FC) layer.\n\nOur contributions are summarized as follows.\n\n•\n\nWe propose two new subspace-based methods named learn-ing mutual subspace method (LMSM) and Grassmannian learning mutual subspace method (G-LMSM). They match subspaces and learns reference subspaces: LMSM learns on the Euclidean space, whereas G-LMSM learns on the Grassmannian.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "•",
      "text": "We combine LMSM and G-LMSM with CNNs, by employing CNN as backbones and our methods as a classifier, yielding a straightforward yet powerful model for image set recognition. We showcase this combination by training models in an end-to-end manner and applying them to the problems of hand shape, face recognition, and face expression recognition from video data.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "•",
      "text": "We also propose variations of the : (1) the repulsion loss to maximize the G-LMSM representativity; (2) the square root as an activation function to reprimand overconfidence; (3) fully-connected layer after a G-LMSM layer to represent more abstract objects and (4) temperature softmax to control model confidence and unbound the logit similarity values.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Related Works",
      "text": "In this section, we briefly review the recent literature of image set recognition and subspace-based learning.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Image Set Recognition",
      "text": "The task of image set recognition aims to recognize an object from an image set, classifying the set in one of a finite amount of defined categories. It has attracted extensive attention of research community  [27] ,  [28] ,  [28] ,  [29] ,  [30] , and various applications have found success in this paradigm, such as face recognition  [31] ,  [32] ,  [33]  and object recognition  [34] ,  [35] ,  [36] . Zhao et al.  [37]  categorized the methods that approach image set recognition into parametric and non-parametric models. Parametric models, e.g. manifold density divergence  [38] , model sets and compare them by probability distributions and their divergences. Non-parametric models, however, do not assume a specific distribution and instead model the sets by a geometric object. The nonparametric models can be divided into: (1) linear subspace methods, such as the mutual subspace method (MSM)  [39] , discriminant correlation analysis (DCC)  [40] , constrained MSM (CMSM)  [14] .\n\n(2) nonlinear manifold methods, such as the manifold-manifold distance (MMD)  [41]  and manifold discriminant analysis (MDA)  [42] ; and (3) affine subspace methods, e.g. affine hull based image set distance (AHISD)  [43]  and sparse approximated nearest point (SANP)  [44] ,  [45] .",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Subspace-Based Learning",
      "text": "As seen in the previous section, linear subspaces can be employed as models for image sets. Although subspace-based learning intersects with the area of image set recognition, it also intersects a wide range of other fields, as many problems involve some kind of subspace structure, orthogonality or low-rank constraints, or subspace distances (e.g., canonical angles or projection norms). In most cases, the problems mathematical characteristics are expressed naturally using the Grassmann manifold. In the last few years, there have been growing interest in studying the Grassmann manifold to tackle new learning problems in computer vision, natural language processing, wireless communications, and statistical learning. Some of the recent approaches of Grassmannian learning involve metric learning, Grassmann kernels, dictionary learning and capsules. We introduce some of these works below.\n\nDictionary learning: Harandi et al.  [46]  proposes an approach based on sparse dictionary learning to learn linear subspaces, exploiting the Grassmann geometry to update the dictionary and handle non-linearity. Experiments on various classification tasks such as face recognition, action recognition, dynamic texture classification display advantages in discrimination accuracy compared to related methods.\n\nAnother method for face recognition based on dictionary learning and subspace learning (DLSL) is introduced in  [47] . This new approach efficiently handles corrupted data, including noise or face variations (e.g., occlusion and significant pose variation). The DLSL uses a new subspace learning algorithm with sparse and low-rank constraints. Results obtained through experiments on FRGC, LFW, CVL, Yale B, and AR face databases reveal that DLSL achieves better performance than many state-of-the-art algorithms.\n\nGrassmannian kernels: Encouraged by the advantages of linear subspace representation, a discriminant learning framework has been proposed by Hamm et al.  [18] ,  [48] . In this method, Various Grassmann kernel functions are developed that can map a subspace to a vector in a kernel space isometric to the Grassmannian. The subspaces are handled as a point in this kernel space through the use of a kernel trick, allowing feature extraction and classification. In the paper, kernel discriminant analysis is applied to the subspaces, a method called Grassmann discriminant analysis (GDA). In addition, experimental results on diverse datasets confirm that the proposed method provides competitive performance compared with state-ofthe-art solutions.\n\nIn  [49] , a Grassmannian kernel based on the canonical correlation between subspaces is proposed, improving the discrimination accuracy by estimating the local structure of the learning sets. More precisely, within-class and between-class similarity graphs are generated to describe intra-class compactness and inter-class separability. Experimental results obtained on PIE, BANCA, MoBo, and ETH-80 datasets confirm that the discriminant approach improves the accuracy compared to current methods.\n\nAnother kernel-based method  [50]  argues that Grassmann discriminant analysis (GDA) has a decrease in its discriminant ability when there are large overlaps between the subspaces. The enhanced GDA is proposed to resolve this issue, where class subspaces are projected onto a generalized difference subspace (GDS) before mapping them onto the manifold. In general terms, GDS removes the overlapping between the class subspaces, assisting the feature extraction and image set classification conducted by GDA. Hand shape and CMU face databases are employed to show the advantages of the proposed eGDA in terms of classification accuracy.\n\nMetric learning: Zhu et al.  [51]  employs nonlinear Riemannian manifolds for representing data as points, a practice widely adopted in the computer vision community. This work proposes a generalized and efficient Riemannian manifold metric learning (RMML), a general metric learning technique that can be applied to a large class of nonlinear manifolds. The RMML optimization process minimizes the geodesic distance of similar points and maximizes the geodesic distance of dissimilar ones on nonlinear manifolds. As a result, this procedure produces a closedform solution and high efficiency. Experiments were performed using several computer vision tasks. Experimental results The experimental results show that RMML outperforms related methods in terms of accuracy.\n\nSogi et al.  [52]  propose a metric learning approach for image set recognition. The main task is to provide a reliable metric for subspace representation. The objective of the proposed metric learning approach is to learn a general scalar product space that provides improved canonical angles to estimate the similarity between subspaces. In addition, they present a formulation for dimensionality reduction by imposing a low-rank constraint. Experimental results are provided using video-based face recognition, multi-view object recognition, and action recognition datasets.\n\nLuo et al.  [53]  addresses the problem that current metric learning solutions employ the L2-norm to estimate the similarity between data points. The authors argue that although practical, this approach may fail when handling noisy data. Then, they introduce a robust formulation of metric learning to solve this problem, where a low-dimensional space is utilized for producing a suitable error estimation. In addition to a robust framework, the authors present generalization guarantees by developing the generalization bounds employing the U-statistics. The proposed framework is evaluated using six benchmark datasets, obtaining high discrimination accuracy compared to related methods.\n\nCapsules: Capsule projection (CapPro), proposed recently by  [54] , is a neural network layer constructed by subspace capsules. In CapPro subspaces have been incorporated in neural networks, concretely as parameters of capsules. The general idea of capsule was first proposed by  [55] ,  [56] , and since then, much effort has been made to seek more effective capsule structures as the base for the next generation of deep network architectures. Capsules are groups of neurons that can learn an object's variations, such as deformations and poses effectively. CapPro obtains an output vector by performing an orthogonal projection of feature vectors x onto the capsule subspace. The intuition behind CapPro is that it learns a set of such capsule subspaces, each representing a class. Note that CapPro cannot handle a set in a natural manner, and it does not perform subspace matching. Our proposed models can be seen as extensions of CapPro, in the sense that their forward map correspond to CapPro in the case the input consists of a single vector x ∈ R d .",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "A Review Of Learning Subspaces",
      "text": "In this section, we review the theory and algorithms of classic learning subspace methods.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Problem Formulation",
      "text": "The learning subspace methods are Bayesian classifiers. The task they solve is defined as follows: Let {x i , y i } N i=1 be a set of N reference image feature vectors with d variables x i , paired with respective labels y i ∈ {1, • • • , C}. We want to learn a set of class subspaces, each represented by orthogonal basis matrices {V c } C c=1 , that correctly predicts the class of a novel vector x ∈ R d .",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Subspace Method",
      "text": "The subspace method (SM)  [57] ,  [58]  is a generative method that represents classes by subspaces. Let {V c } C c=1 be the bases of mdimensional class subspaces. In SM, the bases are obtained from principal component analysis (PCA) without centering of each class reference data, i.e., each class subspace is computed independently by an eigenvalue decomposition of the class auto-correlation matrix A:\n\nSince A is symmetric positive semidefinite, it has eigenvectors u 1 , . . . , u r , and corresponding real eigenvalues λ 1 , . . . , λ r , where r = rank A and m ≤ r. Without loss of generality we can assume\n\nis the matrix of eigenvectors and Λ ∈ R r×r is a diagonal matrix where each k-th diagonal entry is an eigenvalue λ k . U 1:m represents the first m eigenvectors of A. The subspace dimension m is selected as a hyperparameter.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Learning Subspace Method",
      "text": "The learning subspace method (LSM), proposed by Kohonen  [20]  introduces concepts of learning to SM by learning the class subspaces with an iterative algorithm. To initialize, the subspaces are computed as in SM. Then, the reference samples are classified iteratively. For a training sample x of class y, let the LSM classifier prediction be written as q ∈ {1, • • • , C}. The prediction q is obtained as:\n\nWhen a training sample is correctly classified, i.e., q = y, the subspace representation is reinforced by rotating the class subspace V y slightly towards the sample vector. Let t denote the current iteration and α a learning rate, then:\n\nWhen a sample is misclassified as being of some other class, i.e., q = y, the misclassified class subspace V q is punished by rotating it away from the sample vector, while the class subspace V y is rotated towards the sample vector so that it is correctly classified. Let β, γ be learning rates, then:\n\nV q (t + 1) = (I -γxx )V q (t).",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Average Learning Subspace Method",
      "text": "This subspace updating procedure is simple, yet theoretically sound and clearly superior to a priori methods such as SM and the Bayes classifier with normality assumptions up to a certain size  [10] . Yet, LSM is sensitive to the order of samples in iterations; the representation induced by the first samples tends to be canceled by subsequent samples, making the subspace wander around instead of steadily move towards local optima. To obtain smoother behavior and faster convergence, the averaged learning subspace method (ALSM) has been proposed, which considers the update based on the expectation of samples rather than each sample individually. The ALSM update, also referred in this paper as Oja's update, assumes that the sampling order of the training data is statistically independent. For a class subspace c, let the three potential statistical outcomes be denoted as follows. H CC stands for the event of a correct classification into class c i.e. c = q = y. Then, there are two cases of misclassification (q = y): H FN denotes a false negative (c = y), and H FP denotes a false positive (c = q). Then, the ALSM update is given for a class subspace c as follows:\n\nThat is, the expected updated subspace V c (t + 1) given the previous subspace V c (t) is a rotation of V c (t). This rotation is a weighted average of three cases: (1) the rotation to reinforce the correctly classified cases (c = q); (2) to punish false negatives (c = q a sample of class c misclassified as q); (3) to punish false positives (q = c a sample of class q misclassified as c). Note that V c (t + 1) will not necessarily be an orthogonal basis matrix, requiring Gram-Schmidt orthogonalization. We omit this from notation, being implicitly necessary for all Oja's updates.",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "Proposed Methods",
      "text": "In this section, we describe the algorithm of the proposed LMSM and G-LMSM.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Basic Idea",
      "text": "The ALSM has two major shortcomings that makes it unfit for image set recognition: (1) their input can only be a single vector, rather than a set of vectors, and (2) they update the reference subspaces with the Euclidean gradient. Therefore, in the following we propose two methods to address these problems by: (1) matching subspace to subspace and (2) performing updates with the Grassmannian gradient.\n\nIn this section, we generalize Oja's learning subspace framework to an image set setting, where now one sample represents one image set. Concretely, we replace a sample vector x ∈ R d by a subspace spanning an image set X ∈ R d×m with m basis vectors, in the same manner as realized by MSM. We call this algorithm the learning mutual subspace method (LMSM). The \"mutual\" word refers to the introduction of a matching between two subspaces based on their canonical angles. Such a method would be a natural extension of the learning subspace methods, but to the best of our knowledge, has not been proposed, most likely because finding appropriate ALSM's parameters α, β, and γ would become increasingly exhaustive under a heuristic subspace matching paradigm. Instead, we rewrite Oja's rule as a gradient update so that LMSM can exploit the backpropagation algorithm to enjoy learning stability similar to neural networks.\n\nThe main differences between ALSM and LMSM are: (1) LMSM performs subspace matching, whereas ALSM performs vector matching; And (2) ALSM learns its reference subspaces by performing heuristic parameter updates, while the LMSM performs explicit gradient updates.\n\nThen we propose the Grassmann learning subspace method (G-LMSM), further generalizing ALSM and LMSM. Unlike them, G-LMSM updates the gradient through the Riemannian SGD, which smoothly enforces the subspace constraint by correcting the Euclidean gradient to a Grassmannian gradient, keeping the reference subspace bases orthogonal. In contrast, the previous methods recompute the bases based on the Gram-Schmidt orthogonalization, which can lead to unstable convergence.",
      "page_start": 5,
      "page_end": 6
    },
    {
      "section_name": "Oja'S Rule Reformulation",
      "text": "Before describing the proposed methods, we reformulate Oja's rule as a gradient update. Now we turn our attention to Oja's update (equation 7). In our formulation, we assume that all learning rates are equal; as a result, equation 7 can be condensed as follows:\n\nwhere ι(c, q, y) is the indicator function for ALSM: for false negatives and correct classification it outputs +1 and for false positives it indicates -1, otherwise it indicates 0. Without loss of generality, assume a sample of size 1:\n\nLet the indicator function of the Oja's update be the gradient of a loss function L, i.e., dL dsc = ι(c, q, y). From the definition of ι, it is possible to determine that L corresponds to the common cross-entropy loss function plus an extra term. Throughout this paper, we use L to be the cross-entropy.\n\nWe prove that the remaining term xx V c (t) is the derivative of the squared vector projection onto the subspace V c (up to scaling), the similarity used by ALSM to match subspace and vector on the learning subspaces classification (eq. 3).\n\nBy using this result and inverting the signal of α, we rewrite Oja's rule as an usual gradient update:\n\nThis gradient form of the Oja's rule is the basis to develop LMSM and G-LMSM learning methods. The reasoning behind this reformulation is that many modern learning algorithms used for pattern recognition, especially neural networks, are trained with gradient descent methods. By using a gradient update, the methods we will develop in the next subsections can be flexibly employed within modern neural network frameworks in a plugin manner, without the need for reconfiguring the learning strategy.",
      "page_start": 5,
      "page_end": 6
    },
    {
      "section_name": "Problem Formulation",
      "text": "Our learning problem is defined as follows: let H = {I l } n l=1 denote a set of n images I l of size w × h × c, where w is width, h is height and c denotes the number of channels. Given training sets {H i , y i } N i=1 , paired with respective labels y i , we want to learn a model that correctly predicts the class of a novel set H. Note that the number of images n in a set does not need be the same among all sets. In this section, we consider the processing of a single instance H to keep the notation simple.\n\nIn our framework, we model a set H by means of a subspace χ ∈ G(d, m), where G(d, m) denotes the Grassmann manifold (or Grassmannian) of m-dimensional linear subspaces in R d . The Grassmannian is an m(d -m)-dimensional manifold, where a point corresponds to a m-dimensional subspace. χ is spanned by the orthogonal basis matrix X ∈ S(d, m), where S(d, m) denotes the set of orthonormal matrices of shape R d×m , called the compact Stiefel manifold. To compute X, we utilize noncentered PCA on the vectorized images or their CNN features, more being explained on Section 5.1, where all framework parts are put together.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Proposed Learning Methods",
      "text": "In this subsection, we explain the matching framework of the LMSM and G-LMSM. Our subspace matching is defined as the map s υ : G(d, m) → R from the Grassmann manifold to the reals. s υ is parameterized by the reference subspace υ ∈ G(d, p) spanned by a matrix V ∈ S(d, p). Given an input subspace χ ∈ G(d, m), spanned by an orthogonal basis matrix X ∈ S(d, m), s υ (χ) is defined as the sum of the squared cosines of the canonical angles θ i between χ and υ:\n\nwhere r = min(p, m). The canonical angles\n\n} between χ and υ are recursively defined as follows  [12] ,  [13] .\n\nwhere u i and w i are the canonical vectors forming the i-th smallest canonical angle θ i between χ and υ. The j-th canonical angle θ j is the smallest angle in the direction orthogonal to the canonical angles {θ k } j-1 k=1 . This optimization problem can be solved from the orthogonal basis matrices of subspaces χ and υ, i.e., cos 2 θ i can be obtained as the i-th largest singular value of X V  [59] . From this approach, our output s υ can be obtained as the sum of the squared singular values of X V , written as r i=1 δ 2 i (X V ). We utilize the spectral definition of the Frobenius norm to simplify our operation, redefining the subspace matching as:\n\nAs such, in our framework, we compute the matching with this matrix trace. Note that we omit the subscript from s υ , as it is clear it is parameterized by υ. We follow this to simplify notation. This definition of the LMSM similarity is a natural extension of ALSM similarity (eq. 3) that works for subspaces. In the special case of set recognition in which the input is a single vector x instead of a subspace, we obtain s = x V 2  2 . LMSM has a set of learnable parameters composed of K reference subspaces as matrices {V j ∈ S(d, p)} K j=1 . It is a function G(d, m) → R K from the Grassmann manifold to a latent space of dimension K.\n\nMatching: Given an input subspace basis X, its matching to the reference subspaces is defined as:\n\nwhich we write as s j = tr V j XX V j for compactness. Each reference subspace represents a class, so that each value s j represents the match of the input subspace to the patterns in a reference subspace.\n\nGradient: The gradient of parameters and input can be obtained by differentiating  (19)  and applying the chain rule, given the gradient ṡj with respect to a loss L. We obtain the following parameter update:\n\nThe input gradient is then:",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "Learning Mutual Subspace Method",
      "text": "Both LMSM and G-LMSM perform matching using the similarity presented above. They differ in their learning update, on how they consider the geometrical structure. LMSM uses Euclidean updates whereas G-LMSM uses updates on the Grassmannian. LMSM employs conventional stochastic gradient descent (SGD). For that, we set the reference subspaces V j to be unconstrained parameters (not orthogonal bases), which can be updated by SGD. Then, when matching subspaces (eq.  19)  we rewrite our similarity to an equivalent form as follows:\n\nI is a very small-valued multiplier of the identity matrix to regularize possible computational instabilities. We utilize the pseudoinverse of V j to ensure that the similarity reflects the defined function of canonical angles, and is not affected by other quantities embedded in the correlation matrices of nonorthogonal bases, such as norms of vectors and their correlation. Note that the input subspace basis X is normally is computed by PCA as a orthogonal basis.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Grassmann Learning Subspace Method",
      "text": "G-LMSM performs its learning on the Grassmannian instead of the Euclidean space, updating the reference subspaces by the Riemannian stochastic gradient descent (RSGD)  [26] ,  [60] . This manifold aware update allows the method to keep the reference subspace bases consistently orthogonal while maintaining a stable and efficient learning, without the need of tricks such as the pseudoinverse. From a geometry perspective, the method enforces the iterates V j (t) to always be a member of the Grassmann manifold, i.e., avoiding the parameter search line to leave the manifold. The RSGD update consists of two steps: (1) transforming the Euclidean gradient Vj to a Riemannian gradient π( Vj ) tangent to the Grassmannian, that is, the closest vector to Vj that is also tangent to G at V j . That can be obtained by the orthogonal projection of Vj to the horizontal space at V j as:\n\nThe next step is (2) updating the reference subspace by the Grassmannian exponential map:\n\n) Here, J ΘQ = π( V ) is the compact singular value decomposition (SVD) of the gradient, and λ is a learning rate. This update can be regarded as a geodesic walk towards the opposite direction to the Riemannian gradient (direction of descent), landing on a more optimal point V .",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Loss Functions",
      "text": "In their basic form, both LMSM and G-LMSM are trained using the cross-entropy (CE) as an objective: First, the similarities are mapped by softmax (similarities are used as logits):\n\nThen, the CE loss can be defined as follows. Let Ω : {1, . . . , C} → {0, 1} C be a function such that Ω(p) 1 = 1. This function maps an integer p to a one-hot vector, i.e., a vector of zeroes where only the entry p-th entry is set to one. With that function we can define two vectors: the one-hot prediction vector q = Ω(q) and the label vector y = Ω(y). Then the CE loss follows:\n\nHowever, the cross-entropy does not handle one possibility in the learning subspace methods. Their capacity for representation and discrimination can be impaired if the reference subspaces are highly overlapped, as most multiple activation values will tend to full activation r. This is more likely to happen when the class spread is very large, or the dimension r is large, and d is small. To tackle this possibility, we propose a repulsion loss to use in G-LMSM architectures. Let L CE (H) be the cross-entropy loss given the set H. The total loss is then given by L(H) = L CE (H) + γL RP ({V j }), where γ is a control parameter and:\n\nHere, δ ij is the Dirac delta. The idea of the repulsion loss is to guide the learning to mutually repel the reference subspaces, so that the class representations are unique and well separated.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Nonlinear Activation",
      "text": "A possible scenario when training a G-LMSM is that, as the value s j approaches zero, the reference subspaces may offer little contribution to the model. This situation can impair some subspaces from ever contributing, or in the softmax, can lead to sparse, confident predictions that result in misclassification of borderline samples. To avoid this possibility, we can extend the G-LMSM with an elementwise nonlinear activation φ as follows:\n\nThere are numerous choices of φ for G-LMSMs. In this paper, we choose to use the square root, that is, s = X V F . The main reason is that it is a more natural extension of ALSM. Another reason is that it is straightforward nonlinearity that has been used to regularize neural networks  [61] . Concretely, the square root will decrease the value of very high activations with high intensity, while not decreasing as much lower activations.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Softmax With Temperature",
      "text": "Another approach to handling overconfidence is to use softmax with temperature T , used by  [62] ,  [63] ,  [64] . In our framework, we utilize the inverse-temperature hyperparameter τ = 1/T to scale the logits before applying softmax. This learned scaling has the potential to free the bounded logits (0 ≤ s j ≤ √ r), allowing them to achieve proper classification margin. We can use it with our G-LMSM simply as exp(τ s j )/ C j =1 exp(τ s j ) . Agarwala et al.  [65]  offers a detailed analysis of the underpinning learning mechanisms of softmax with temperature.\n\nThe intuition of this idea is that by scaling the values of the activation we can control the level of confidence of our model when it makes predictions. When the temperature is τ = 1, we compute the unscaled softmax, leading to the basic G-LMSM with softmax. When the temperature is greater than 1 the input of softmax is a larger value. Performing softmax on larger values makes the model more confident, i.e., a smaller activation is needed to yield a high posterior probability. However, it also makes the model more conservative when looking at data, that is, it is less likely to sample from unlikely candidates. Using a temperature less than 1 produces a less confident probability distribution over the classes, where the probabilities are more distributed over categories. The model is less conservative on data, resulting in more diverse representation. However, if overdone the model is also more prone to mistakes.\n\nSince the temperature depends largely on the task, in our framework, we allow the temperature to be learned automatically as a network parameter.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Experiments",
      "text": "",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Network Architectures",
      "text": "In the following experiments, we use network architectures containing the proposed methods as a layer to approach image set recognition. The architectures are different in two separate design choices: (1) choice of set features, for example, raw images or CNN features; and (2) function of G-LMSM in the pipeline as a classifier or as a feature extractor. From these options, we can obtain the following architectures, shown on Figure  3 .\n\nG-LMSM+softmax: This is the simplest architecture, consisting of a G-LMSM layer and a softmax applied to the activation s. In this setting, the input set is preprocessed into a subspace as follows: Let the matrix H ∈ R d×n contain the set images as its columns, where d = w * h * c. Then, we compute a subspace from the set using noncentered PCA, i.e., HH = U ΣU T . The subspace basis X ∈ R d×m consists of the m leftmost columns of U , that is, the columns with the highest corresponding eigenvalues. The subspace basis X is input in the G-LMSM layer, obtaining the activation s ∈ R C . Each reference subspace V j represents one class, and the softmax of s j corresponds to the probability of that class given the samples. This model corresponds to CapPro in the case the input consists of a single vector x ∈ R d .\n\nG-LMSM+FC: This variation extends G-LMSM to act as a feature extractor rather than simply as a classifier, by processing s further through a fully-connected layer before applying softmax. The number of reference subspaces K becomes a free parameter, and the FC weights are W ∈ R K×C and b ∈ R C .   CNN backbone G-LMSM+softmax: Given the set H as input, we process each image I l through a convolutional neural network backbone f , obtaining features h l = f (I l ). Then, we can create H ∈ R d×n with normalized h l as columns. From here we either (1) perform noncentered PCA to obtain X or (2) approximate the subspace projection matrix by the autocorrelation matrix (AC) HH . PCA is exact, but requires an SVD decomposition, which although can be processed in an end-to-end manner by utilizing the SVD gradient updates proposed by  [Townsend] , can be unstable and lead to exploding gradients. The AC is not exact, as it does not yield a subspace projection matrix, but it is a reasonable approximation here since it quite fast and stable in end-to-end processing.\n\nIn this paper, we utilize two backbones: VGG4 and ResNet18 without the last stage of FC layers. These backbones act as feature extractors, while PCA combines the features into a subspace and a G-LMSM in the last layer acts as a classifier.\n\nCNN backbone G-LMSM+FC: This corresponds to extracting CNN features from the set images, and then apply G-LMSM+FC, where G-LMSM here functions as a feature extractor.",
      "page_start": 7,
      "page_end": 8
    },
    {
      "section_name": "Ablation Study On Hand Shape Recognition",
      "text": "We conducted an ablation study experiment of Hand shape recognition with the Tsukuba hand shape dataset. The objective is twofold:  (1)  show that the proposed methods can classify objects by achieving a meaningful result, and (2) understand the effects of subspace dimensions and G-LMSM's function as a classifier and as a feature extractor.\n\nDataset: This dataset contains 30 hand classes × 100 subjects, each of which contains 210 hand shape images, consisting of 30 frames × 7 different viewpoints. Example images can be seen in Fig.  4 . For each subject, we randomly created 6 sets with 5 frames from each viewpoint, so that each subject has 6 image sets of 35 images. In summary, there are a total of 18000 image sets in this dataset, each set containing image information from 7 camera viewpoints. In the experiments, all the images were resized to 24 × 24 pixels.\n\nSettings: We evaluated the performance of the proposed G-LMSM in the classification problem of 30 types of hand shapes. We used the image sets of 70 subjects as training sets, holding a subset of 15 subjects for validation. The remaining 15 subjects were used as testing sets.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Effect Of Optimization Algorithm",
      "text": "First we compare LMSM and G-LMSM to evaluate the choice of optimization algorithm, conventional SGD or Riemannian SGD. As a baseline for comparison, we also evaluate a variation of LMSM where for the input set representation X we use the normalized features themselves as a basis, i.e., H = X, yielding the method dubbed \"nonorth. matching\". Note that in this case, the similarity might not correspond to the canonical angles between span(H) and span(V ).\n\nTable  1  shows the results. For now, we focus only on comparing the proposed G-LMSM with the LMSM when equipped with a VGG4 backbone learned from random initialization. As shown, LMSM can outperform nonorth. matching, indicating that the PCA input subspace representation is effective in this task. Next, \"PCA+G-LMSM+softmax\" can outperform the LMSM, indicating that the learning on the Grassmannian yields better accuracy than learning on Euclidean space. The results are evidence that both the orthogonality constraint and the manifold optimization seem to play an important role in learning a subspace.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Performance Across Parameter Settings",
      "text": "Figure  5  shows the accuracies of G-LMSM+softmax when we vary the dimensions of subspaces, which are hyperparameters in our model. Both the dimension of reference subspaces p and the dimension of input subspace m are separately varied from 1 to 10. It can be inferred from the figure that G-LMSM+softmax has a lower performance from 1 to around 3 in both parameters because such low dimension subspaces are not enough to model the complexity of entities such as hand shapes, containing multiple poses, sizes, deformations and each subject's individual hand characteristics. When the dimension is 1, the G-LMSM+softmax can be regarded as a CapPro, which as seen on the figure, yields a  poor performance. Increasing the dimension of the input subspace improves the performance until about m = 8 and p = 7. It can be expected that a high value of p contributes to overfitting. However, overall, it appears that the performance is not so sensitive to the value of hyperparameters if they are selected in a reasonable range, such as 5 to 10.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Comparison Against Multiple Baselines",
      "text": "We compare G-LMSM to multiple baselines that do not contain its key features to evaluate its effectiveness.\n\nBaselines: There are five baselines in this experiment: (1) the mutual subspace method (MSM)  [14] , a fundamental method of classifying subspaces with canonical angles. (2) \"set average\", a very simple idea to test the effectiveness of the backbone network. The set images are processed through the backbone VGG4, yielding a matrix of output features H ∈ R 512×35 , where the backbone features are of size 512 and the number of images is 35. Then the set images are averaged, which can be regarded as a setwise global average pooling, resulting in a single 512 vector h, which is then processed through a FC layer and softmax. (3) Softmax average, which processes each image through a FC layer and softmax and then averages the output probabilities. (4) Bilinear  [66] , which uses the features correlation matrix HH as a single integrated feature, and classifies it through an FC layer. And (5) CapPro average, where the average vector h is used as input to a CapPro layer.\n\nResults and discussion: Table  1  shows the results. The first results, with no backbone convolutional layers, suggest two points: G-LMSM-based models can classify hand shapes more accurately than MSM, even when it is used on its own, i.e., just the G-LMSM layer as a standalone classifier; and the G-LMSM acting as a feature extractor followed by an FC classifier offers a much better performance. Neither the square root activation nor the repulsion loss seems to offer a gain of accuracy in this case.\n\nThe second part of Table  1  shows methods that perform end-toend learning with a VGG4 backbone. These results demonstrate two points: (1) the average feature vector of a set is a naive approach to treating image sets and that more information can be modeled from the features distribution; and (2) interestingly, the G-LMSM in a deep backbone network seems to perform better as a classifier than as a feature extractor. The reason might be that either the FC layer followed G-LMSM is prone to overfitting or that, in this kind of architecture, subspaces are better at representing classes directly rather than more abstract entities. We conducted an experiment on the task of emotion recognition to demonstrate the effectiveness of the proposed G-LMSM against various manifold and subspace-based methods that have been used in this task.",
      "page_start": 9,
      "page_end": 10
    },
    {
      "section_name": "Experiments On Emotion Recognition",
      "text": "Dataset: We utilize the Acted Facial Expression in Wild (AFEW)  [67]  dataset. The dataset contains 1, 345 sequences of 7 types of facial expressions acted by 330 actors in close to realworld settings.\n\nSettings: We follow the experiment protocol established by  [68] ,  [69]  to present the results on the validation set. The training videos are split into 1747 small subvideos augmenting the numbers of sets, as established by  [70] . For the evaluation, each facial frame is normalized to an image of size 20 × 20. For representation, following various works  [68] ,  [71] ,  [72] , we represent the sequences of facial expressions with linear subspaces of dimension 10, which exist on a Grassmann manifold G(400, 10).\n\nBaselines: As the G-LMSM is a network layer that learns subspaces based on iterative Riemannian optimization, we compare it against the following methods: (1) a regular CNN that can handle image sets, namely the Deep Second-order Pooling (DeepO2P)  [73] .\n\n(2) Methods based on subspace without Riemannian optimization: DCC  [5] , Grassmann Discriminant Analysis (GDA  [18]  and Grassmannian Graph-Embedding Discriminant Analysis (GGDA)  [19] . And (3) methods based on Riemannian optimization: Projection Metric Learning (PML)  [74] , Expressionlets on Spatio-Temporal Manifold (STMExpLet)  [68] , Riemannian Sparse Representation combining with Manifold Learning on the manifold of SPD matrices (RSR-SPDML)  [75] , Network on SPD manifolds (SPDNet)  [69]  and Grassmann net (GrNet)  [72] . Especially, GrNet proposes a block of manifold layers for subspace data. GrNet-1 denotes the architecture with 1 block and GrNet-2 with 2 blocks.\n\nResults and discussion: The results can be seen in Table  2 . The proposed method achieved quite competitive results compared to the manifold-based methods, by mapping the subspace into a vector and then uses simple Euclidean operations such as fullyconnected layers and cross-entropy loss, in contrast to several methods that use complex approaches requiring multiple matrix decompositions. First, G-LMSM+softmax outperforms popular methods such as GDA and GGDA, which have a similar purpose of mapping Grassmann manifold data into a vector representation. The reason is perhaps that G-LMSM learns both the representation and discrimination in an end-to-end manner, while GDA uses a kernel function to represent subspaces and learns the discriminant independently. Methods such as SPDNet and GrNet are composed of many complex layers involving SVD, QR decompositions, and Gram-Schmidt orthogonalization and its derivatives are utilized as well. They increase in complexity as the number of layers increases by repeating these operations, which are not easily scalable to use in GPUs. On the other hand, the proposed method provides competitive results with fewer layers and no decompositions, making it naturally parallelizable and scalable.",
      "page_start": 9,
      "page_end": 10
    },
    {
      "section_name": "Experiment On Face Identification",
      "text": "We conducted an experiment of face identification with the YouTube Celebrities (YTC) dataset. Dataset: The YTC dataset  [76]  contains 1910 videos of 47 identities. Similarly to  [77] , as an image set, we used a set of face images extracted from a video by the Incremental Learning Tracker  [78] . All the extracted face images were scaled to 30 × 30 pixels and converted to grayscale.\n\nSettings: Three videos per each person were randomly selected as training data, and six videos per each person were randomly selected as test data. We repeated the above procedure five times and measured the average accuracy.\n\nBaselines: (1) Classic image set-based methods: Discriminative Canonical Correlations (DCC)  [5] , manifold-manifold distance (MMD)  [79] , Convex Hull-based Image Set Distance (CHISD)  [43] , Pairwise linear regression classification (PLRC)  [30] . (2) Deep learning methods: deep reconstruction model (DRM)  [80] ; Resnet vote  [81]  is a baseline consisting of a Resnet50  [81]  fine-tuned to this dataset with the cross-entropy loss in a single image setting. For the fine-tuning, we added two fully connected (FC) layers after the last global average pooling layer in the network. The first FC layer outputs a 1024 dimension vector through the ReLU  [82]  function, and the second layer outputs a 47 (the number of classes) dimension vector through the softmax function. Hyperparameters of the optimizer were used as suggested by the original paper. For classification, each image of a set is classified independently and a majority voting strategy of all predictions is used to select a single class prediction for the whole set. The model called Resnet18 set average is the same as used in the hand shape experiment. The Resnet18 bilinear model uses the correlation matrix of the backbone features of the image set, generating a 512 × 512 matrix. The vectorized matrix is processed through an FC layer and softmax for classification.\n\nResults and discussion: Table  3  shows the results. G-LMSM outperforms not only the classical manifold methods, but also various deep methods. Although G-LMSM uses the same backbone as some methods, it still can achieve better results. In the case of Resnet50 vote and the G-LMSM+FC, the key difference is that voting is a simple heuristic approach to image set recognition, as the model is not aware of the set as a whole. This leads to unstable and diverging predictions on a set's class, as it does not take into account the underlying set distribution. The voting method is not differentiable by nature, so it is not trivial to extend this idea to an end-to-end approach. Then, set average seems again to be a naive approach to treating image sets and that more information can be modeled from the features distribution. The bilinear model could in theory capture the underlying set information from the correlations, but the high dimensionality of the correlation matrix makes it almost impossible to learn a FC classifier without overfitting.\n\nThese results confirm the advantage of G-LMSM over these methods using the same backbone: mutual subspaces provide a low-dimensional, differentiable approach to modeling the set distribution, ultimately leading to a straightforward integration of the deep convolutional networks and the problem of image sets.\n\nFurthermore, the AC+G-LMSM+softmax seems to yield the same result as PCA+G-LMSM+softmax, evidence that it is a good approximation for processing the input data. Then, the proposed variations of G-LMSM, namely, repulsion loss, the square root activation and the temperature softmax (temp-softmax) appear to provide an advantage over the base G-LMSM. \"",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Conclusion",
      "text": "In this paper, we addressed the problem of image set recognition. We proposed two subspace-based methods, named learning mutual subspace method (LMSM) and Grassmannian learning mutual subspace method (G-LMSM), that can recognize image sets with DNN as feature extractors in an end-to-end fashion. The proposed methods generalize the classic average learning subspace method (ALSM), in that LMSM and G-LMSM can handle an image set as input and perform subspace matching. The key idea of G-LMSM is to learn the subspaces with Riemannian stochastic gradient descent on the Grassmann manifold, ensuring each parameter is always an orthogonal basis of a subspace.\n\nExtensive experiments on hand shape recognition, face identification, and facial emotion recognition showed that LMSM and G-LMSM have a high discriminant ability in image set recognition. It can be used easily as a standalone method or within larger DNN frameworks. The experiments also reveal that Riemannian optimization is effective in learning G-LMSM within neural networks.",
      "page_start": 11,
      "page_end": 11
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Diagram of the proposed method embedded as a layer in an end-to-end learning framework.",
      "page": 2
    },
    {
      "caption": "Figure 2: Conceptualized depiction of the proposed LMSM and G-LMSM key idea. Both proposed methods match an input subspace χ",
      "page": 2
    },
    {
      "caption": "Figure 1: ) to learn both the reference subspaces and the feature space",
      "page": 2
    },
    {
      "caption": "Figure 2: As in previous mutual subspace",
      "page": 2
    },
    {
      "caption": "Figure 1: As a result,",
      "page": 2
    },
    {
      "caption": "Figure 1: ) is regarded as a set-based classiﬁcation",
      "page": 2
    },
    {
      "caption": "Figure 3: G-LMSM+softmax: This is the simplest architecture, consist-",
      "page": 7
    },
    {
      "caption": "Figure 3: Conceptual diagrams of the proposed G-LMSM architectures.",
      "page": 8
    },
    {
      "caption": "Figure 4: Sample images from the Tsukuba hand shape dataset,",
      "page": 8
    },
    {
      "caption": "Figure 4: For each subject, we randomly created 6 sets with 5",
      "page": 8
    },
    {
      "caption": "Figure 5: shows the accuracies of G-LMSM+softmax when we",
      "page": 8
    },
    {
      "caption": "Figure 5: Performance of G-LMSM across parameter settings, varying",
      "page": 9
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Lincon S. Souza, Naoya Sogi, Bernardo B. Gatto, Takumi Kobayashi, and Kazuhiro Fukui": "images as input (e.g., multiple camera sources and\nAbstract—This paper addresses the problem of object recognition given a set of"
        },
        {
          "Lincon S. Souza, Naoya Sogi, Bernardo B. Gatto, Takumi Kobayashi, and Kazuhiro Fukui": "video frames). Convolutional neural network (CNN)-based frameworks do not exploit\nthese sets effectively, processing a pattern as"
        },
        {
          "Lincon S. Souza, Naoya Sogi, Bernardo B. Gatto, Takumi Kobayashi, and Kazuhiro Fukui": "observed, not capturing the underlying feature distribution as it does not consider the variance of\nimages in the set. To address this issue,"
        },
        {
          "Lincon S. Souza, Naoya Sogi, Bernardo B. Gatto, Takumi Kobayashi, and Kazuhiro Fukui": "we propose the Grassmannian learning mutual subspace method (G-LMSM), a NN layer embedded on top of CNNs as a classiﬁer,\nthat"
        },
        {
          "Lincon S. Souza, Naoya Sogi, Bernardo B. Gatto, Takumi Kobayashi, and Kazuhiro Fukui": "can process image sets more effectively and can be trained in an end-to-end manner. The image set\nis represented by a low-dimensional"
        },
        {
          "Lincon S. Souza, Naoya Sogi, Bernardo B. Gatto, Takumi Kobayashi, and Kazuhiro Fukui": "input subspace; and this input subspace is matched with reference subspaces by a similarity of\ntheir canonical angles, an interpretable"
        },
        {
          "Lincon S. Souza, Naoya Sogi, Bernardo B. Gatto, Takumi Kobayashi, and Kazuhiro Fukui": "and easy to compute metric. The key idea of G-LMSM is that\nthe reference subspaces are learned as points on the Grassmann manifold,"
        },
        {
          "Lincon S. Souza, Naoya Sogi, Bernardo B. Gatto, Takumi Kobayashi, and Kazuhiro Fukui": "optimized with Riemannian stochastic gradient descent. This learning is stable, efﬁcient and theoretically well-grounded. We demonstrate"
        },
        {
          "Lincon S. Souza, Naoya Sogi, Bernardo B. Gatto, Takumi Kobayashi, and Kazuhiro Fukui": "the effectiveness of our proposed method on hand shape recognition,\nface identiﬁcation, and facial emotion recognition."
        },
        {
          "Lincon S. Souza, Naoya Sogi, Bernardo B. Gatto, Takumi Kobayashi, and Kazuhiro Fukui": "learning subspace methods, subspace learning,\nimage recognition,\nIndex Terms—Grassmannian learning mutual subspace method,"
        },
        {
          "Lincon S. Souza, Naoya Sogi, Bernardo B. Gatto, Takumi Kobayashi, and Kazuhiro Fukui": "deep neural networks, manifold optimization."
        },
        {
          "Lincon S. Souza, Naoya Sogi, Bernardo B. Gatto, Takumi Kobayashi, and Kazuhiro Fukui": "(cid:70)"
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "orthogonalization to feature vectors in a set. The subspace-based set": "representation is effective in the following points. (1) A subspace",
          "[20]\nto formulate the learning subspace methods (LSM).\nIn the": "LSM [20], a class reference subspace is iteratively improved by"
        },
        {
          "orthogonalization to feature vectors in a set. The subspace-based set": "exploits the geometrical structure of\nthe probability distribution",
          "[20]\nto formulate the learning subspace methods (LSM).\nIn the": "means of rotation based on the statistical decision-theoretic rule,"
        },
        {
          "orthogonalization to feature vectors in a set. The subspace-based set": "",
          "[20]\nto formulate the learning subspace methods (LSM).\nIn the": "beyond the simple SVD which computes reference subspace in a"
        },
        {
          "orthogonalization to feature vectors in a set. The subspace-based set": "",
          "[20]\nto formulate the learning subspace methods (LSM).\nIn the": "generative way. LSM is extended to averaged LSM (ALSM) [21]"
        },
        {
          "orthogonalization to feature vectors in a set. The subspace-based set": "L.S. Souza, T. Kobayashi and B.B. Gatto are with the National Institute of\n•",
          "[20]\nto formulate the learning subspace methods (LSM).\nIn the": ""
        },
        {
          "orthogonalization to feature vectors in a set. The subspace-based set": "",
          "[20]\nto formulate the learning subspace methods (LSM).\nIn the": "toward learning stability by considering iterative updating based on"
        },
        {
          "orthogonalization to feature vectors in a set. The subspace-based set": "Advanced Industrial Science and Technology (AIST), Japan.",
          "[20]\nto formulate the learning subspace methods (LSM).\nIn the": ""
        },
        {
          "orthogonalization to feature vectors in a set. The subspace-based set": "K. Fukui and N. Sogi are with the Department of Computer Science,\n•",
          "[20]\nto formulate the learning subspace methods (LSM).\nIn the": "mini-batch. These two research directions are made in the subspace"
        },
        {
          "orthogonalization to feature vectors in a set. The subspace-based set": "Graduate School of Systems and Information Engineering, University of",
          "[20]\nto formulate the learning subspace methods (LSM).\nIn the": ""
        },
        {
          "orthogonalization to feature vectors in a set. The subspace-based set": "",
          "[20]\nto formulate the learning subspace methods (LSM).\nIn the": "literature rather\nseparately, while they could complement each"
        },
        {
          "orthogonalization to feature vectors in a set. The subspace-based set": "Tsukuba, Japan. (E-mail: lincon.souza@aist.go.jp)",
          "[20]\nto formulate the learning subspace methods (LSM).\nIn the": ""
        },
        {
          "orthogonalization to feature vectors in a set. The subspace-based set": "",
          "[20]\nto formulate the learning subspace methods (LSM).\nIn the": "other."
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "(cid:70)": "1\nINTRODUCTION"
        },
        {
          "(cid:70)": "images\nof\nan\nobject\nare\nuseful\nfor\nboosting"
        },
        {
          "(cid:70)": "performance of object classiﬁcation [1], [2]. In surveillance\nM ULTIPLE"
        },
        {
          "(cid:70)": "and industrial systems, distributed cameras and sensors capture"
        },
        {
          "(cid:70)": "data in a continuous stream to provide multiple images pointing"
        },
        {
          "(cid:70)": "to a target object. The task of object recognition based on a set of"
        },
        {
          "(cid:70)": "images, called image set recognition, is formulated to classify an"
        },
        {
          "(cid:70)": "image set\nthrough comparing the input set\nto reference image sets"
        },
        {
          "(cid:70)": "(dictionary) of class objects."
        },
        {
          "(cid:70)": "The\nimage\nset\nthat we\nconsider\nin this paper\nrefers\nto a"
        },
        {
          "(cid:70)": "collection of\nimage samples captured from the same object or"
        },
        {
          "(cid:70)": "event,\nthereby freeing images in a set\nfrom any order,\nsuch as"
        },
        {
          "(cid:70)": "temporal ordering. For example,\nimage sets of our interest\ninclude"
        },
        {
          "(cid:70)": "multi-view images from multiple camera sources and video frames."
        },
        {
          "(cid:70)": "As in the other image classiﬁcation tasks, each image in the set"
        },
        {
          "(cid:70)": "could be represented by a naive image vector [3], [4], [5] or by"
        },
        {
          "(cid:70)": "the more sophisticated feature vector via CNNs [6], [7],\nto provide"
        },
        {
          "(cid:70)": "us with a set of\nfeature vectors for set classiﬁcation. Therefore,"
        },
        {
          "(cid:70)": "the primal\nissue to be addressed in the set recognition is how to"
        },
        {
          "(cid:70)": "represent\nthe set which is composed of variable number of feature"
        },
        {
          "(cid:70)": "vectors."
        },
        {
          "(cid:70)": "Subspace-based methods\n[8],\n[9],\n[10]\nhave\nbeen\none\nof"
        },
        {
          "(cid:70)": "the\nleading solutions\nfor\nimage\nset\nrecognition,\nand a\ncentral"
        },
        {
          "(cid:70)": "research topic for object\nrecognition in computer vision.\nIn the"
        },
        {
          "(cid:70)": "subspace methods, a set of images is effectively modeled by a low-"
        },
        {
          "(cid:70)": "dimensional subspace in a high-dimensional vector space [1], [2],"
        },
        {
          "(cid:70)": "[4],\n[11]. Such subspaces\nare\ntypically generated by applying"
        },
        {
          "(cid:70)": "either\nsingular value decomposition (SVD) or Gram–Schmidt"
        },
        {
          "(cid:70)": "orthogonalization to feature vectors in a set. The subspace-based set"
        },
        {
          "(cid:70)": "representation is effective in the following points. (1) A subspace"
        },
        {
          "(cid:70)": "exploits the geometrical structure of\nthe probability distribution"
        },
        {
          "(cid:70)": ""
        },
        {
          "(cid:70)": ""
        },
        {
          "(cid:70)": "L.S. Souza, T. Kobayashi and B.B. Gatto are with the National Institute of\n•"
        },
        {
          "(cid:70)": ""
        },
        {
          "(cid:70)": "Advanced Industrial Science and Technology (AIST), Japan."
        },
        {
          "(cid:70)": "K. Fukui and N. Sogi are with the Department of Computer Science,\n•"
        },
        {
          "(cid:70)": "Graduate School of Systems and Information Engineering, University of"
        },
        {
          "(cid:70)": ""
        },
        {
          "(cid:70)": "Tsukuba, Japan. (E-mail: lincon.souza@aist.go.jp)"
        },
        {
          "(cid:70)": ""
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "values.": "",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "ear subspace representation, a discriminant learning framework has"
        },
        {
          "values.": "",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "been proposed by Hamm et al. [18], [48]. In this method, Various"
        },
        {
          "values.": "2\nRELATED WORKS",
          "Grassmannian kernels: Encouraged by the advantages of lin-": ""
        },
        {
          "values.": "",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "Grassmann kernel functions are developed that can map a subspace"
        },
        {
          "values.": "In this section, we brieﬂy review the recent\nliterature of image set",
          "Grassmannian kernels: Encouraged by the advantages of lin-": ""
        },
        {
          "values.": "",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "to a vector in a kernel space isometric to the Grassmannian. The"
        },
        {
          "values.": "recognition and subspace-based learning.",
          "Grassmannian kernels: Encouraged by the advantages of lin-": ""
        },
        {
          "values.": "",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "subspaces are handled as a point in this kernel space through the use"
        },
        {
          "values.": "",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "of a kernel\ntrick, allowing feature extraction and classiﬁcation. In"
        },
        {
          "values.": "2.1\nImage set recognition",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "the paper, kernel discriminant analysis is applied to the subspaces, a"
        },
        {
          "values.": "",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "method called Grassmann discriminant analysis (GDA). In addition,"
        },
        {
          "values.": "The task of\nimage set\nrecognition aims\nto recognize an object",
          "Grassmannian kernels: Encouraged by the advantages of lin-": ""
        },
        {
          "values.": "",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "experimental results on diverse datasets conﬁrm that\nthe proposed"
        },
        {
          "values.": "from an image set, classifying the set\nin one of a ﬁnite amount of",
          "Grassmannian kernels: Encouraged by the advantages of lin-": ""
        },
        {
          "values.": "",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "method provides competitive performance compared with state-of-"
        },
        {
          "values.": "deﬁned categories. It has attracted extensive attention of research",
          "Grassmannian kernels: Encouraged by the advantages of lin-": ""
        },
        {
          "values.": "",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "the-art solutions."
        },
        {
          "values.": "community [27],\n[28],\n[28],\n[29],\n[30], and various applications",
          "Grassmannian kernels: Encouraged by the advantages of lin-": ""
        },
        {
          "values.": "",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "In [49], a Grassmannian kernel based on the canonical correla-"
        },
        {
          "values.": "have found success in this paradigm, such as face recognition [31],",
          "Grassmannian kernels: Encouraged by the advantages of lin-": ""
        },
        {
          "values.": "",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "tion between subspaces is proposed,\nimproving the discrimination"
        },
        {
          "values.": "[32], [33] and object recognition [34], [35], [36].",
          "Grassmannian kernels: Encouraged by the advantages of lin-": ""
        },
        {
          "values.": "",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "accuracy by estimating the local\nstructure of\nthe learning sets."
        },
        {
          "values.": "Zhao et al. [37] categorized the methods that approach image set",
          "Grassmannian kernels: Encouraged by the advantages of lin-": ""
        },
        {
          "values.": "",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "More precisely, within-class and between-class similarity graphs"
        },
        {
          "values.": "recognition into parametric and non-parametric models. Parametric",
          "Grassmannian kernels: Encouraged by the advantages of lin-": ""
        },
        {
          "values.": "",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "are generated to describe intra-class compactness and inter-class"
        },
        {
          "values.": "models, e.g. manifold density divergence [38], model\nsets and",
          "Grassmannian kernels: Encouraged by the advantages of lin-": ""
        },
        {
          "values.": "",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "separability. Experimental results obtained on PIE, BANCA, MoBo,"
        },
        {
          "values.": "compare them by probability distributions and their divergences.",
          "Grassmannian kernels: Encouraged by the advantages of lin-": ""
        },
        {
          "values.": "",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "and ETH-80\ndatasets\nconﬁrm that\nthe\ndiscriminant\napproach"
        },
        {
          "values.": "Non-parametric models, however, do not assume a speciﬁc distri-",
          "Grassmannian kernels: Encouraged by the advantages of lin-": ""
        },
        {
          "values.": "",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "improves the accuracy compared to current methods."
        },
        {
          "values.": "bution and instead model\nthe sets by a geometric object. The non-",
          "Grassmannian kernels: Encouraged by the advantages of lin-": ""
        },
        {
          "values.": "",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "Another kernel-based method [50]\nargues\nthat Grassmann"
        },
        {
          "values.": "parametric models can be divided into: (1) linear subspace methods,",
          "Grassmannian kernels: Encouraged by the advantages of lin-": ""
        },
        {
          "values.": "",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "discriminant analysis (GDA) has a decrease in its discriminant"
        },
        {
          "values.": "such as the mutual subspace method (MSM)\n[39], discriminant",
          "Grassmannian kernels: Encouraged by the advantages of lin-": ""
        },
        {
          "values.": "",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "ability when there are large overlaps between the subspaces. The"
        },
        {
          "values.": "correlation analysis (DCC) [40], constrained MSM (CMSM) [14].",
          "Grassmannian kernels: Encouraged by the advantages of lin-": ""
        },
        {
          "values.": "",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "enhanced GDA is proposed to resolve this issue, where class sub-"
        },
        {
          "values.": "(2) nonlinear manifold methods, such as the manifold-manifold dis-",
          "Grassmannian kernels: Encouraged by the advantages of lin-": ""
        },
        {
          "values.": "",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "spaces are projected onto a generalized difference subspace (GDS)"
        },
        {
          "values.": "tance (MMD) [41] and manifold discriminant analysis (MDA) [42];",
          "Grassmannian kernels: Encouraged by the advantages of lin-": ""
        },
        {
          "values.": "",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "before mapping them onto the manifold. In general\nterms, GDS"
        },
        {
          "values.": "and (3) afﬁne subspace methods, e.g. afﬁne hull based image set",
          "Grassmannian kernels: Encouraged by the advantages of lin-": ""
        },
        {
          "values.": "",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "removes the overlapping between the class subspaces, assisting"
        },
        {
          "values.": "distance (AHISD)\n[43] and sparse approximated nearest point",
          "Grassmannian kernels: Encouraged by the advantages of lin-": ""
        },
        {
          "values.": "",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "the feature extraction and image set classiﬁcation conducted by"
        },
        {
          "values.": "(SANP) [44], [45].",
          "Grassmannian kernels: Encouraged by the advantages of lin-": ""
        },
        {
          "values.": "",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "GDA. Hand shape and CMU face databases are employed to show"
        },
        {
          "values.": "",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "the advantages of\nthe proposed eGDA in terms of classiﬁcation"
        },
        {
          "values.": "2.2\nSubspace-based learning",
          "Grassmannian kernels: Encouraged by the advantages of lin-": ""
        },
        {
          "values.": "",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "accuracy."
        },
        {
          "values.": "As seen in the previous section,\nlinear subspaces can be employed",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "Metric\nlearning:\nZhu et\nal.\n[51]\nemploys nonlinear Rie-"
        },
        {
          "values.": "as models\nfor\nimage\nsets. Although\nsubspace-based\nlearning",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "mannian manifolds\nfor\nrepresenting data\nas points,\na practice"
        },
        {
          "values.": "intersects with the area of image set recognition, it also intersects a",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "widely adopted in the computer vision community. This work"
        },
        {
          "values.": "wide range of other ﬁelds, as many problems involve some kind",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "proposes a generalized and efﬁcient Riemannian manifold metric"
        },
        {
          "values.": "of subspace structure, orthogonality or\nlow-rank constraints, or",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "learning (RMML), a general metric learning technique that can"
        },
        {
          "values.": "subspace distances (e.g., canonical angles or projection norms). In",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "be applied to a large class of nonlinear manifolds. The RMML"
        },
        {
          "values.": "most cases, the problems mathematical characteristics are expressed",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "optimization process minimizes the geodesic distance of similar"
        },
        {
          "values.": "naturally using the Grassmann manifold. In the last few years, there",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "points and maximizes the geodesic distance of dissimilar ones on"
        },
        {
          "values.": "have been growing interest\nin studying the Grassmann manifold to",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "nonlinear manifolds. As a result,\nthis procedure produces a closed-"
        },
        {
          "values.": "tackle new learning problems in computer vision, natural\nlanguage",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "form solution and high efﬁciency. Experiments were performed"
        },
        {
          "values.": "processing, wireless communications, and statistical learning. Some",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "using several computer vision tasks. Experimental\nresults The"
        },
        {
          "values.": "of the recent approaches of Grassmannian learning involve metric",
          "Grassmannian kernels: Encouraged by the advantages of lin-": "experimental results show that RMML outperforms related methods"
        }
      ],
      "page": 3
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "3": "learning, Grassmann kernels, dictionary learning and capsules. We"
        },
        {
          "3": "introduce some of these works below."
        },
        {
          "3": "Dictionary learning: Harandi et al. [46] proposes an approach"
        },
        {
          "3": "based on sparse dictionary learning to learn linear\nsubspaces,"
        },
        {
          "3": "exploiting the Grassmann geometry to update the dictionary and"
        },
        {
          "3": "handle non-linearity. Experiments on various classiﬁcation tasks"
        },
        {
          "3": "such as face recognition, action recognition, dynamic texture clas-"
        },
        {
          "3": "siﬁcation display advantages in discrimination accuracy compared"
        },
        {
          "3": "to related methods."
        },
        {
          "3": "Another method\nfor\nface\nrecognition\nbased\non\ndictionary"
        },
        {
          "3": "learning and subspace learning (DLSL) is introduced in [47]. This"
        },
        {
          "3": "new approach efﬁciently handles corrupted data,\nincluding noise"
        },
        {
          "3": "or face variations (e.g., occlusion and signiﬁcant pose variation)."
        },
        {
          "3": "The DLSL uses a new subspace learning algorithm with sparse"
        },
        {
          "3": "and low-rank constraints. Results obtained through experiments"
        },
        {
          "3": "on FRGC, LFW, CVL, Yale B, and AR face databases\nreveal"
        },
        {
          "3": "that DLSL achieves better performance than many state-of-the-art"
        },
        {
          "3": "algorithms."
        },
        {
          "3": "Grassmannian kernels: Encouraged by the advantages of lin-"
        },
        {
          "3": "ear subspace representation, a discriminant learning framework has"
        },
        {
          "3": "been proposed by Hamm et al. [18], [48]. In this method, Various"
        },
        {
          "3": ""
        },
        {
          "3": "Grassmann kernel functions are developed that can map a subspace"
        },
        {
          "3": ""
        },
        {
          "3": "to a vector in a kernel space isometric to the Grassmannian. The"
        },
        {
          "3": ""
        },
        {
          "3": "subspaces are handled as a point in this kernel space through the use"
        },
        {
          "3": "of a kernel\ntrick, allowing feature extraction and classiﬁcation. In"
        },
        {
          "3": "the paper, kernel discriminant analysis is applied to the subspaces, a"
        },
        {
          "3": "method called Grassmann discriminant analysis (GDA). In addition,"
        },
        {
          "3": ""
        },
        {
          "3": "experimental results on diverse datasets conﬁrm that\nthe proposed"
        },
        {
          "3": ""
        },
        {
          "3": "method provides competitive performance compared with state-of-"
        },
        {
          "3": ""
        },
        {
          "3": "the-art solutions."
        },
        {
          "3": ""
        },
        {
          "3": "In [49], a Grassmannian kernel based on the canonical correla-"
        },
        {
          "3": ""
        },
        {
          "3": "tion between subspaces is proposed,\nimproving the discrimination"
        },
        {
          "3": ""
        },
        {
          "3": "accuracy by estimating the local\nstructure of\nthe learning sets."
        },
        {
          "3": ""
        },
        {
          "3": "More precisely, within-class and between-class similarity graphs"
        },
        {
          "3": ""
        },
        {
          "3": "are generated to describe intra-class compactness and inter-class"
        },
        {
          "3": ""
        },
        {
          "3": "separability. Experimental results obtained on PIE, BANCA, MoBo,"
        },
        {
          "3": ""
        },
        {
          "3": "and ETH-80\ndatasets\nconﬁrm that\nthe\ndiscriminant\napproach"
        },
        {
          "3": ""
        },
        {
          "3": "improves the accuracy compared to current methods."
        },
        {
          "3": ""
        },
        {
          "3": "Another kernel-based method [50]\nargues\nthat Grassmann"
        },
        {
          "3": ""
        },
        {
          "3": "discriminant analysis (GDA) has a decrease in its discriminant"
        },
        {
          "3": ""
        },
        {
          "3": "ability when there are large overlaps between the subspaces. The"
        },
        {
          "3": ""
        },
        {
          "3": "enhanced GDA is proposed to resolve this issue, where class sub-"
        },
        {
          "3": ""
        },
        {
          "3": "spaces are projected onto a generalized difference subspace (GDS)"
        },
        {
          "3": ""
        },
        {
          "3": "before mapping them onto the manifold. In general\nterms, GDS"
        },
        {
          "3": ""
        },
        {
          "3": "removes the overlapping between the class subspaces, assisting"
        },
        {
          "3": ""
        },
        {
          "3": "the feature extraction and image set classiﬁcation conducted by"
        },
        {
          "3": ""
        },
        {
          "3": "GDA. Hand shape and CMU face databases are employed to show"
        },
        {
          "3": "the advantages of\nthe proposed eGDA in terms of classiﬁcation"
        },
        {
          "3": ""
        },
        {
          "3": "accuracy."
        },
        {
          "3": "Metric\nlearning:\nZhu et\nal.\n[51]\nemploys nonlinear Rie-"
        },
        {
          "3": "mannian manifolds\nfor\nrepresenting data\nas points,\na practice"
        },
        {
          "3": "widely adopted in the computer vision community. This work"
        },
        {
          "3": "proposes a generalized and efﬁcient Riemannian manifold metric"
        },
        {
          "3": "learning (RMML), a general metric learning technique that can"
        },
        {
          "3": "be applied to a large class of nonlinear manifolds. The RMML"
        },
        {
          "3": "optimization process minimizes the geodesic distance of similar"
        },
        {
          "3": "points and maximizes the geodesic distance of dissimilar ones on"
        },
        {
          "3": "nonlinear manifolds. As a result,\nthis procedure produces a closed-"
        },
        {
          "3": "form solution and high efﬁciency. Experiments were performed"
        },
        {
          "3": "using several computer vision tasks. Experimental\nresults The"
        },
        {
          "3": "experimental results show that RMML outperforms related methods"
        }
      ],
      "page": 3
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "4": "by an eigenvalue decomposition of the class auto-correlation matrix"
        },
        {
          "4": "A:"
        },
        {
          "4": ""
        },
        {
          "4": "(cid:62) = A = U ΛU (cid:62),\n(1)\nxixi"
        },
        {
          "4": "(cid:88) y"
        },
        {
          "4": "i∈c"
        },
        {
          "4": ""
        },
        {
          "4": "(2)\nVc = U1:m."
        },
        {
          "4": ""
        },
        {
          "4": "Since A is symmetric positive semideﬁnite,\nit has eigenvectors"
        },
        {
          "4": ""
        },
        {
          "4": "u1, . . . , ur, and corresponding real eigenvalues λ1, . . . , λr, where"
        },
        {
          "4": ""
        },
        {
          "4": "r = rank A and m ≤ r. Without loss of generality we can assume"
        },
        {
          "4": ""
        },
        {
          "4": "is the matrix\nλ1 ≥ λ2 · · · ≥ λr. Here, U = [u1, u2, · · ·\n, ur]"
        },
        {
          "4": ""
        },
        {
          "4": "of eigenvectors and Λ ∈ Rr×r\nis a diagonal matrix where each"
        },
        {
          "4": ""
        },
        {
          "4": "k-th diagonal entry is an eigenvalue λk. U1:m represents the ﬁrst"
        },
        {
          "4": ""
        },
        {
          "4": "m eigenvectors of A. The subspace dimension m is selected as a"
        },
        {
          "4": ""
        },
        {
          "4": "hyperparameter."
        },
        {
          "4": ""
        },
        {
          "4": ""
        },
        {
          "4": ""
        },
        {
          "4": "3.3\nLearning subspace method"
        },
        {
          "4": ""
        },
        {
          "4": "The learning subspace method (LSM), proposed by Kohonen [20]"
        },
        {
          "4": ""
        },
        {
          "4": "introduces\nconcepts\nof\nlearning\nto SM by\nlearning\nthe\nclass"
        },
        {
          "4": ""
        },
        {
          "4": "subspaces with an iterative algorithm. To initialize, the subspaces"
        },
        {
          "4": ""
        },
        {
          "4": "are computed as in SM. Then,\nthe reference samples are classiﬁed"
        },
        {
          "4": ""
        },
        {
          "4": "iteratively. For a training sample x of class y, let the LSM classiﬁer"
        },
        {
          "4": ""
        },
        {
          "4": "∈\n{1, · · ·\nprediction be written as q\n, C}. The prediction q is"
        },
        {
          "4": ""
        },
        {
          "4": "obtained as:"
        },
        {
          "4": ""
        },
        {
          "4": "(3)\nc x(cid:107).\nq = argmaxc(cid:107)V (cid:62)"
        },
        {
          "4": ""
        },
        {
          "4": "When a training sample is correctly classiﬁed,\ni.e., q = y,\nthe"
        },
        {
          "4": ""
        },
        {
          "4": "subspace representation is reinforced by rotating the class subspace"
        },
        {
          "4": ""
        },
        {
          "4": "slightly towards the sample vector. Let t denote the current\nVy"
        },
        {
          "4": ""
        },
        {
          "4": "iteration and α a learning rate,\nthen:"
        },
        {
          "4": ""
        },
        {
          "4": ""
        },
        {
          "4": "(4)\nVy(t + 1) = (I + αxx(cid:62))Vy(t)."
        },
        {
          "4": ""
        },
        {
          "4": ""
        },
        {
          "4": "When a sample is misclassiﬁed as being of some other class, i.e.,"
        },
        {
          "4": ""
        },
        {
          "4": "q (cid:54)= y,\nthe misclassiﬁed class subspace Vq is punished by rotating"
        },
        {
          "4": ""
        },
        {
          "4": "is\nit away from the sample vector, while the class subspace Vy"
        },
        {
          "4": ""
        },
        {
          "4": "rotated towards the sample vector so that it is correctly classiﬁed."
        },
        {
          "4": ""
        },
        {
          "4": "Let β, γ be learning rates,"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "5": "4.2\nOja’s rule reformulation"
        },
        {
          "5": ""
        },
        {
          "5": "Before describing the proposed methods, we reformulate Oja’s rule"
        },
        {
          "5": "as a gradient update."
        },
        {
          "5": ""
        },
        {
          "5": "Now we turn our attention to Oja’s update (equation 7). In our"
        },
        {
          "5": ""
        },
        {
          "5": ""
        },
        {
          "5": "formulation, we assume that all learning rates are equal; as a result,"
        },
        {
          "5": ""
        },
        {
          "5": "equation 7 can be condensed as follows:"
        },
        {
          "5": ""
        },
        {
          "5": ""
        },
        {
          "5": "N(cid:88) i\n(8)\nVc(t + 1) = (I + α\nι(c, qi, yi)xx(cid:62))Vc(t)"
        },
        {
          "5": "=1"
        },
        {
          "5": ""
        },
        {
          "5": ""
        },
        {
          "5": "N(cid:88) i\n(9)\n= Vc(t) + α\nι(c, qi, yi)xx(cid:62)Vc(t),"
        },
        {
          "5": ""
        },
        {
          "5": "=1"
        },
        {
          "5": ""
        },
        {
          "5": "where ι(c, q, y)\nis\nthe indicator\nfunction for ALSM:\nfor\nfalse"
        },
        {
          "5": ""
        },
        {
          "5": "negatives and correct classiﬁcation it outputs +1 and for\nfalse"
        },
        {
          "5": ""
        },
        {
          "5": "positives it\nindicates −1, otherwise it\nindicates 0."
        },
        {
          "5": ""
        },
        {
          "5": "Without\nloss of generality, assume a sample of size 1:"
        },
        {
          "5": ""
        },
        {
          "5": ""
        },
        {
          "5": "(10)\nVc(t + 1) = Vc(t) + αι(c, q, y)xx(cid:62)Vc(t)."
        },
        {
          "5": "Let\nthe indicator function of the Oja’s update be the gradient of"
        },
        {
          "5": "dL\na loss function L,\ni.e.,\n= ι(c, q, y). From the deﬁnition of"
        },
        {
          "5": "dsc"
        },
        {
          "5": "ι,\nit\nis possible to determine that L corresponds to the common"
        },
        {
          "5": ""
        },
        {
          "5": "cross-entropy loss function plus an extra term. Throughout\nthis"
        },
        {
          "5": ""
        },
        {
          "5": "paper, we use L to be the cross-entropy."
        },
        {
          "5": "We prove that the remaining term xx(cid:62)Vc(t) is the derivative of"
        },
        {
          "5": ""
        },
        {
          "5": "the squared vector projection onto the subspace Vc (up to scaling),"
        },
        {
          "5": "the similarity used by ALSM to match subspace and vector on the"
        },
        {
          "5": "learning subspaces classiﬁcation (eq. 3)."
        }
      ],
      "page": 5
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "6": "Matching: Given an input subspace basis X, its matching to"
        },
        {
          "6": "the reference subspaces is deﬁned as:"
        },
        {
          "6": ""
        },
        {
          "6": "tr V1\n(cid:62)XX (cid:62)V1"
        },
        {
          "6": ""
        },
        {
          "6": " \n \n."
        },
        {
          "6": ".\ns =\n∈ RK,"
        },
        {
          "6": "(19)\n."
        },
        {
          "6": ""
        },
        {
          "6": "tr VK\n(cid:62)XX (cid:62)VK"
        },
        {
          "6": ""
        },
        {
          "6": "for compactness. Each\nwhich we write as sj = tr Vj\n(cid:62)XX (cid:62)Vj"
        },
        {
          "6": "reference\nsubspace\nrepresents\na\nclass,\nso\nthat\neach\nvalue\nsj"
        },
        {
          "6": "represents the match of\nthe input subspace to the patterns in a"
        },
        {
          "6": "reference subspace."
        },
        {
          "6": "Gradient: The\ngradient\nof\nparameters\nand\ninput\ncan\nbe"
        },
        {
          "6": "obtained by differentiating (19) and applying the chain rule, given"
        },
        {
          "6": "the gradient\nto a loss L. We obtain the following\nsj with respect"
        },
        {
          "6": "parameter update:"
        },
        {
          "6": "˙"
        },
        {
          "6": "(20)\nVj = (2 ˙sjVj\n(cid:62)XX (cid:62))(cid:62) = 2 ˙sjXX (cid:62)Vj."
        },
        {
          "6": ""
        },
        {
          "6": "The input gradient\nis then:"
        },
        {
          "6": ""
        },
        {
          "6": ""
        },
        {
          "6": "(21)\nX = 2 ˙sjVjVjX (cid:62)."
        },
        {
          "6": ""
        },
        {
          "6": ""
        },
        {
          "6": "4.5\nLearning mutual subspace method"
        },
        {
          "6": ""
        },
        {
          "6": "Both LMSM and G-LMSM perform matching using the similarity"
        },
        {
          "6": "presented above. They differ in their learning update, on how they"
        },
        {
          "6": "consider the geometrical structure. LMSM uses Euclidean updates"
        },
        {
          "6": ""
        },
        {
          "6": "whereas G-LMSM uses updates on the Grassmannian."
        },
        {
          "6": ""
        },
        {
          "6": "LMSM employs\nconventional\nstochastic\ngradient\ndescent"
        },
        {
          "6": "(SGD). For that, we set\nto be uncon-\nthe reference subspaces Vj"
        },
        {
          "6": "strained parameters (not orthogonal bases), which can be updated"
        },
        {
          "6": "by SGD. Then, when matching subspaces (eq. 19) we rewrite our"
        },
        {
          "6": "similarity to an equivalent form as follows:"
        },
        {
          "6": ""
        },
        {
          "6": "s = tr X (cid:62)V (V (cid:62)V + (cid:15)I)−1V (cid:62)X.\n(22)"
        },
        {
          "6": "(cid:15)I\nis\na very small-valued multiplier of\nthe\nidentity matrix to"
        },
        {
          "6": ""
        },
        {
          "6": "regularize\npossible\ncomputational\ninstabilities. We\nutilize\nthe"
        },
        {
          "6": ""
        },
        {
          "6": "pseudoinverse of Vj to ensure that the similarity reﬂects the deﬁned"
        },
        {
          "6": "function of canonical angles, and is not affected by other quantities"
        },
        {
          "6": "embedded in the correlation matrices of nonorthogonal bases, such"
        },
        {
          "6": ""
        },
        {
          "6": "as norms of vectors and their correlation. Note that\nthe input"
        },
        {
          "6": ""
        },
        {
          "6": "subspace basis X is normally is computed by PCA as a orthogonal"
        },
        {
          "6": ""
        },
        {
          "6": "basis."
        },
        {
          "6": ""
        }
      ],
      "page": 6
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "7": "reason is that it\nis straightforward nonlinearity that has been used"
        },
        {
          "7": "to regularize neural networks [61]. Concretely,\nthe square root will"
        },
        {
          "7": "decrease the value of very high activations with high intensity,"
        },
        {
          "7": "while not decreasing as much lower activations."
        },
        {
          "7": ""
        },
        {
          "7": ""
        },
        {
          "7": "4.9\nSoftmax with temperature"
        },
        {
          "7": ""
        },
        {
          "7": "Another approach to handling overconﬁdence is to use softmax"
        },
        {
          "7": ""
        },
        {
          "7": "with temperature T , used by [62], [63], [64]. In our framework,"
        },
        {
          "7": ""
        },
        {
          "7": "we utilize the inverse-temperature hyperparameter τ = 1/T to"
        },
        {
          "7": ""
        },
        {
          "7": "scale the logits before applying softmax. This learned scaling has"
        },
        {
          "7": "√"
        },
        {
          "7": "r), allowing\nthe potential to free the bounded logits (0 ≤ sj ≤"
        },
        {
          "7": "them to achieve proper classiﬁcation margin. We can use it with"
        },
        {
          "7": ""
        },
        {
          "7": "our G-LMSM simply as exp(τ sj)/ (cid:80)C\nj(cid:48)=1 exp(τ sj(cid:48)) . Agarwala"
        },
        {
          "7": ""
        },
        {
          "7": "et al. [65] offers a detailed analysis of the underpinning learning"
        },
        {
          "7": ""
        },
        {
          "7": "mechanisms of softmax with temperature."
        },
        {
          "7": ""
        },
        {
          "7": "The intuition of this idea is that by scaling the values of the"
        },
        {
          "7": "activation we can control the level of conﬁdence of our model when"
        },
        {
          "7": ""
        },
        {
          "7": ""
        },
        {
          "7": "it makes predictions. When the temperature is τ = 1, we compute"
        },
        {
          "7": ""
        },
        {
          "7": ""
        },
        {
          "7": "the unscaled softmax,\nleading to the basic G-LMSM with softmax."
        },
        {
          "7": "When the temperature is greater\nthan 1 the input of softmax is"
        },
        {
          "7": "a larger value. Performing softmax on larger values makes the"
        },
        {
          "7": "model more conﬁdent,\ni.e., a smaller activation is needed to yield a"
        },
        {
          "7": "high posterior probability. However,\nit also makes the model more"
        },
        {
          "7": "conservative when looking at data, that is, it is less likely to sample"
        },
        {
          "7": "from unlikely candidates. Using a temperature less than 1 produces"
        },
        {
          "7": "a less conﬁdent probability distribution over the classes, where the"
        },
        {
          "7": "probabilities are more distributed over categories. The model\nis"
        },
        {
          "7": "less conservative on data, resulting in more diverse representation."
        },
        {
          "7": ""
        },
        {
          "7": "However,\nif overdone the model\nis also more prone to mistakes."
        },
        {
          "7": "Since\nthe\ntemperature depends\nlargely on the\ntask,\nin our"
        },
        {
          "7": ""
        },
        {
          "7": "framework, we allow the temperature to be learned automatically"
        },
        {
          "7": ""
        },
        {
          "7": "as a network parameter."
        },
        {
          "7": ""
        },
        {
          "7": ""
        },
        {
          "7": "5\nEXPERIMENTS"
        },
        {
          "7": ""
        },
        {
          "7": "5.1\nNetwork Architectures"
        },
        {
          "7": ""
        },
        {
          "7": "In\nthe\nfollowing\nexperiments, we\nuse\nnetwork\narchitectures"
        },
        {
          "7": ""
        },
        {
          "7": "containing the proposed methods as a layer\nto approach image"
        },
        {
          "7": ""
        },
        {
          "7": "set\nrecognition. The architectures are different\nin two separate"
        },
        {
          "7": ""
        },
        {
          "7": "design choices: (1) choice of set features, for example, raw images"
        },
        {
          "7": "or CNN features; and (2) function of G-LMSM in the pipeline as"
        },
        {
          "7": "a classiﬁer or as a feature extractor. From these options, we can"
        },
        {
          "7": ""
        },
        {
          "7": "obtain the following architectures, shown on Figure 3."
        },
        {
          "7": "G-LMSM+softmax: This is the simplest architecture, consist-"
        },
        {
          "7": ""
        },
        {
          "7": "ing of a G-LMSM layer and a softmax applied to the activation"
        },
        {
          "7": ""
        },
        {
          "7": "s. In this setting, the input set is preprocessed into a subspace as"
        },
        {
          "7": ""
        },
        {
          "7": "follows: Let\nthe matrix H ∈ Rd×n contain the set\nimages as its"
        },
        {
          "7": "columns, where d = w ∗ h ∗ c. Then, we compute a subspace"
        },
        {
          "7": ""
        },
        {
          "7": "from the set using noncentered PCA,\ni.e., HH (cid:62) = U ΣU T . The"
        },
        {
          "7": "subspace basis X ∈ Rd×m consists of the m leftmost columns of"
        },
        {
          "7": "U , that is, the columns with the highest corresponding eigenvalues."
        },
        {
          "7": "The subspace basis X is input\nin the G-LMSM layer, obtaining"
        },
        {
          "7": ""
        },
        {
          "7": "represents one\nthe activation s ∈ RC . Each reference subspace Vj"
        },
        {
          "7": ""
        },
        {
          "7": "class, and the softmax of sj corresponds to the probability of that"
        },
        {
          "7": "class given the samples. This model corresponds to CapPro in the"
        },
        {
          "7": "case the input consists of a single vector x ∈ Rd."
        },
        {
          "7": "G-LMSM+FC: This variation extends G-LMSM to act as a"
        },
        {
          "7": ""
        },
        {
          "7": "feature extractor rather than simply as a classiﬁer, by processing s"
        },
        {
          "7": "further through a fully-connected layer before applying softmax."
        },
        {
          "7": "The number of reference subspaces K becomes a free parameter,"
        },
        {
          "7": "and the FC weights are W ∈ RK×C and b ∈ RC ."
        }
      ],
      "page": 7
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "SoftMax": ""
        },
        {
          "SoftMax": "frames\nfrom each viewpoint,\nso that each subject has 6 image"
        },
        {
          "SoftMax": "sets of 35 images. In summary,\nthere are a total of 18000 image"
        },
        {
          "SoftMax": "sets in this dataset, each set containing image information from 7"
        },
        {
          "SoftMax": "camera viewpoints. In the experiments, all\nthe images were resized"
        },
        {
          "SoftMax": "to 24 × 24 pixels."
        },
        {
          "SoftMax": "Settings: We evaluated the performance of\nthe proposed G-"
        },
        {
          "SoftMax": "LMSM in the classiﬁcation problem of 30 types of hand shapes."
        },
        {
          "SoftMax": "We used the image sets of 70 subjects as training sets, holding a"
        },
        {
          "SoftMax": ""
        },
        {
          "SoftMax": "subset of 15 subjects for validation. The remaining 15 subjects"
        },
        {
          "SoftMax": ""
        },
        {
          "SoftMax": "were used as testing sets."
        },
        {
          "SoftMax": "5.2.1\nEffect of Optimization algorithm"
        },
        {
          "SoftMax": ""
        },
        {
          "SoftMax": "First we compare LMSM and G-LMSM to evaluate the choice of"
        },
        {
          "SoftMax": ""
        },
        {
          "SoftMax": "optimization algorithm, conventional SGD or Riemannian SGD. As"
        },
        {
          "SoftMax": ""
        },
        {
          "SoftMax": "a baseline for comparison, we also evaluate a variation of LMSM"
        },
        {
          "SoftMax": "where for the input set representation X we use the normalized"
        },
        {
          "SoftMax": ""
        },
        {
          "SoftMax": "features themselves as a basis,\ni.e., H = X, yielding the method"
        },
        {
          "SoftMax": ""
        },
        {
          "SoftMax": "dubbed \"nonorth. matching\". Note that in this case, the similarity"
        },
        {
          "SoftMax": ""
        },
        {
          "SoftMax": "might not correspond to the canonical angles between span(H)"
        },
        {
          "SoftMax": ""
        },
        {
          "SoftMax": "and span(V )."
        },
        {
          "SoftMax": ""
        },
        {
          "SoftMax": "Table 1 shows the results. For now, we focus only on comparing"
        },
        {
          "SoftMax": ""
        },
        {
          "SoftMax": "the proposed G-LMSM with the LMSM when equipped with a"
        },
        {
          "SoftMax": ""
        },
        {
          "SoftMax": "VGG4 backbone learned from random initialization. As shown,"
        },
        {
          "SoftMax": ""
        },
        {
          "SoftMax": "LMSM can outperform nonorth. matching,\nindicating that\nthe"
        },
        {
          "SoftMax": ""
        },
        {
          "SoftMax": "PCA input subspace representation is effective in this task. Next,"
        },
        {
          "SoftMax": ""
        },
        {
          "SoftMax": "\"PCA+G-LMSM+softmax\" can outperform the LMSM,\nindicating"
        },
        {
          "SoftMax": ""
        },
        {
          "SoftMax": "that\nthe learning on the Grassmannian yields better accuracy than"
        },
        {
          "SoftMax": ""
        },
        {
          "SoftMax": "learning on Euclidean space. The results are evidence that both"
        },
        {
          "SoftMax": ""
        },
        {
          "SoftMax": "the orthogonality constraint and the manifold optimization seem to"
        },
        {
          "SoftMax": ""
        },
        {
          "SoftMax": "play an important role in learning a subspace."
        },
        {
          "SoftMax": ""
        },
        {
          "SoftMax": "5.2.2\nPerformance across parameter settings"
        },
        {
          "SoftMax": ""
        },
        {
          "SoftMax": "Figure 5 shows the accuracies of G-LMSM+softmax when we"
        },
        {
          "SoftMax": "vary the dimensions of subspaces, which are hyperparameters in"
        },
        {
          "SoftMax": "our model. Both the dimension of reference subspaces p and the"
        },
        {
          "SoftMax": "dimension of\ninput subspace m are separately varied from 1 to"
        },
        {
          "SoftMax": "10.\nIt can be inferred from the ﬁgure that G-LMSM+softmax"
        },
        {
          "SoftMax": "has a lower performance from 1 to around 3 in both parameters"
        },
        {
          "SoftMax": "because such low dimension subspaces are not enough to model"
        },
        {
          "SoftMax": "the complexity of entities such as hand shapes, containing multiple"
        },
        {
          "SoftMax": "poses,\nsizes, deformations\nand each subject’s\nindividual hand"
        },
        {
          "SoftMax": "characteristics. When the dimension is 1, the G-LMSM+softmax"
        },
        {
          "SoftMax": "can be regarded as a CapPro, which as seen on the ﬁgure, yields a"
        }
      ],
      "page": 8
    },
    {
      "caption": "Table 1: shows the results. The first ofsets,asestablishedby[70].Fortheevaluation,eachfacialframe",
      "data": [
        {
          "TABLE 1: Results of the experiment on the Tsukuba hand shape dataset.": "Feature"
        },
        {
          "TABLE 1: Results of the experiment on the Tsukuba hand shape dataset.": ""
        },
        {
          "TABLE 1: Results of the experiment on the Tsukuba hand shape dataset.": ""
        },
        {
          "TABLE 1: Results of the experiment on the Tsukuba hand shape dataset.": "No backbone"
        },
        {
          "TABLE 1: Results of the experiment on the Tsukuba hand shape dataset.": ""
        },
        {
          "TABLE 1: Results of the experiment on the Tsukuba hand shape dataset.": ""
        },
        {
          "TABLE 1: Results of the experiment on the Tsukuba hand shape dataset.": ""
        },
        {
          "TABLE 1: Results of the experiment on the Tsukuba hand shape dataset.": ""
        },
        {
          "TABLE 1: Results of the experiment on the Tsukuba hand shape dataset.": ""
        },
        {
          "TABLE 1: Results of the experiment on the Tsukuba hand shape dataset.": ""
        },
        {
          "TABLE 1: Results of the experiment on the Tsukuba hand shape dataset.": "With backbone (VGG4)"
        },
        {
          "TABLE 1: Results of the experiment on the Tsukuba hand shape dataset.": ""
        },
        {
          "TABLE 1: Results of the experiment on the Tsukuba hand shape dataset.": ""
        },
        {
          "TABLE 1: Results of the experiment on the Tsukuba hand shape dataset.": ""
        }
      ],
      "page": 9
    },
    {
      "caption": "Table 1: shows the results. The first ofsets,asestablishedby[70].Fortheevaluation,eachfacialframe",
      "data": [
        {
          "improves the performance until about m = 8 and p = 7. It can be": ""
        },
        {
          "improves the performance until about m = 8 and p = 7. It can be": "expected that a high value of p contributes to overﬁtting. However,"
        },
        {
          "improves the performance until about m = 8 and p = 7. It can be": "it appears that"
        },
        {
          "improves the performance until about m = 8 and p = 7. It can be": ""
        },
        {
          "improves the performance until about m = 8 and p = 7. It can be": "value of hyperparameters if they are selected in a reasonable range,"
        },
        {
          "improves the performance until about m = 8 and p = 7. It can be": ""
        },
        {
          "improves the performance until about m = 8 and p = 7. It can be": ""
        },
        {
          "improves the performance until about m = 8 and p = 7. It can be": "Comparison against multiple baselines"
        },
        {
          "improves the performance until about m = 8 and p = 7. It can be": ""
        },
        {
          "improves the performance until about m = 8 and p = 7. It can be": ""
        },
        {
          "improves the performance until about m = 8 and p = 7. It can be": ""
        },
        {
          "improves the performance until about m = 8 and p = 7. It can be": "key features to evaluate its effectiveness."
        },
        {
          "improves the performance until about m = 8 and p = 7. It can be": ""
        },
        {
          "improves the performance until about m = 8 and p = 7. It can be": "Baselines: There are ﬁve baselines in this experiment: (1) the"
        },
        {
          "improves the performance until about m = 8 and p = 7. It can be": ""
        },
        {
          "improves the performance until about m = 8 and p = 7. It can be": "mutual subspace method (MSM) [14], a fundamental method of"
        },
        {
          "improves the performance until about m = 8 and p = 7. It can be": ""
        },
        {
          "improves the performance until about m = 8 and p = 7. It can be": "classifying subspaces with canonical angles. (2) \"set average\", a"
        },
        {
          "improves the performance until about m = 8 and p = 7. It can be": "very simple idea to test"
        },
        {
          "improves the performance until about m = 8 and p = 7. It can be": "The set images are processed through the backbone VGG4, yielding"
        }
      ],
      "page": 9
    },
    {
      "caption": "Table 1: shows the results. The first ofsets,asestablishedby[70].Fortheevaluation,eachfacialframe",
      "data": [
        {
          "PCA+G-LMSM+softmax\n99.39": "PCA+G-LMSM+FC\n99.06"
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "than MSM, even when it\nis used on its own,\ni.e.,\njust\nthe G-LMSM"
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "layer as a standalone classiﬁer; and the G-LMSM acting as a"
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "feature extractor followed by an FC classiﬁer offers a much better"
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "performance. Neither the square root activation nor the repulsion"
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "loss seems to offer a gain of accuracy in this case."
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "The second part of Table 1 shows methods that perform end-to-"
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "end learning with a VGG4 backbone. These results demonstrate two"
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "points: (1) the average feature vector of a set is a naive approach"
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "to treating image sets and that more information can be modeled"
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "from the features distribution; and (2) interestingly,\nthe G-LMSM"
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "in a deep backbone network seems to perform better as a classiﬁer"
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "than as a feature extractor. The reason might be that either the FC"
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "layer followed G-LMSM is prone to overﬁtting or that,\nin this kind"
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "of architecture, subspaces are better at representing classes directly"
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "rather than more abstract entities."
        },
        {
          "PCA+G-LMSM+softmax\n99.39": ""
        },
        {
          "PCA+G-LMSM+softmax\n99.39": ""
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "5.3\nExperiments on Emotion Recognition"
        },
        {
          "PCA+G-LMSM+softmax\n99.39": ""
        },
        {
          "PCA+G-LMSM+softmax\n99.39": ""
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "TABLE 2: Results of the experiment on the AFEW dataset."
        },
        {
          "PCA+G-LMSM+softmax\n99.39": ""
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "Method\nAccuracy (%)"
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "STM-ExpLet\n31.73"
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "RSR-SPDML\n30.12"
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "DCC\n25.78"
        },
        {
          "PCA+G-LMSM+softmax\n99.39": ""
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "GDA\n29.11"
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "GGDA\n29.45"
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "PML\n28.98"
        },
        {
          "PCA+G-LMSM+softmax\n99.39": ""
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "DeepO2P\n28.54"
        },
        {
          "PCA+G-LMSM+softmax\n99.39": ""
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "SPDNet\n34.23"
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "GrNet\n34.23"
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "G-LMSM+FC\n38.27"
        },
        {
          "PCA+G-LMSM+softmax\n99.39": ""
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "We conducted an experiment on the task of emotion recognition"
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "to demonstrate the effectiveness of the proposed G-LMSM against"
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "various manifold and subspace-based methods that have been used"
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "in this task."
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "Dataset: We\nutilize\nthe Acted Facial Expression\nin Wild"
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "(AFEW)\n[67] dataset. The dataset contains 1, 345 sequences of"
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "7 types of facial expressions acted by 330 actors in close to real-"
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "world settings."
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "Settings: We\nfollow the\nexperiment\nprotocol\nestablished"
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "by [68], [69] to present the results on the validation set. The training"
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "videos are split into 1747 small subvideos augmenting the numbers"
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "of sets, as established by [70]. For the evaluation, each facial frame"
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "is normalized to an image of size 20 × 20. For\nrepresentation,"
        },
        {
          "PCA+G-LMSM+softmax\n99.39": "following various works [68], [71], [72], we represent the sequences"
        }
      ],
      "page": 9
    },
    {
      "caption": "Table 2: classification,eachimageofasetisclassifiedindependentlyanda",
      "data": [
        {
          "TABLE 3: Results of the experiment on the YouTube Celebrities dataset.": "Type"
        },
        {
          "TABLE 3: Results of the experiment on the YouTube Celebrities dataset.": ""
        },
        {
          "TABLE 3: Results of the experiment on the YouTube Celebrities dataset.": ""
        },
        {
          "TABLE 3: Results of the experiment on the YouTube Celebrities dataset.": "Classic"
        },
        {
          "TABLE 3: Results of the experiment on the YouTube Celebrities dataset.": ""
        },
        {
          "TABLE 3: Results of the experiment on the YouTube Celebrities dataset.": ""
        },
        {
          "TABLE 3: Results of the experiment on the YouTube Celebrities dataset.": ""
        },
        {
          "TABLE 3: Results of the experiment on the YouTube Celebrities dataset.": ""
        },
        {
          "TABLE 3: Results of the experiment on the YouTube Celebrities dataset.": ""
        },
        {
          "TABLE 3: Results of the experiment on the YouTube Celebrities dataset.": "Deep"
        },
        {
          "TABLE 3: Results of the experiment on the YouTube Celebrities dataset.": ""
        },
        {
          "TABLE 3: Results of the experiment on the YouTube Celebrities dataset.": ""
        },
        {
          "TABLE 3: Results of the experiment on the YouTube Celebrities dataset.": "Features (from ResNet50)"
        },
        {
          "TABLE 3: Results of the experiment on the YouTube Celebrities dataset.": ""
        },
        {
          "TABLE 3: Results of the experiment on the YouTube Celebrities dataset.": ""
        },
        {
          "TABLE 3: Results of the experiment on the YouTube Celebrities dataset.": ""
        },
        {
          "TABLE 3: Results of the experiment on the YouTube Celebrities dataset.": "End-to-end (backbone ResNet18)"
        },
        {
          "TABLE 3: Results of the experiment on the YouTube Celebrities dataset.": ""
        },
        {
          "TABLE 3: Results of the experiment on the YouTube Celebrities dataset.": ""
        }
      ],
      "page": 10
    },
    {
      "caption": "Table 2: classification,eachimageofasetisclassifiedindependentlyanda",
      "data": [
        {
          "End-to-end (backbone ResNet18)": "",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "AC+G-LMSM (repulsion)\n70.01 ± 2.87"
        },
        {
          "End-to-end (backbone ResNet18)": "",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "AC+G-LMSM+temp-softmax\n69.92 ± 3.79"
        },
        {
          "End-to-end (backbone ResNet18)": "of facial expressions with linear subspaces of dimension 10, which",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "Settings: Three videos per each person were randomly selected"
        },
        {
          "End-to-end (backbone ResNet18)": "exist on a Grassmann manifold G(400, 10).",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "as training data, and six videos per each person were randomly"
        },
        {
          "End-to-end (backbone ResNet18)": "Baselines: As\nthe G-LMSM is a network layer\nthat\nlearns",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "selected as test data. We repeated the above procedure ﬁve times"
        },
        {
          "End-to-end (backbone ResNet18)": "subspaces based on iterative Riemannian optimization, we compare",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "and measured the average accuracy."
        },
        {
          "End-to-end (backbone ResNet18)": "it against the following methods: (1) a regular CNN that can handle",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": ""
        },
        {
          "End-to-end (backbone ResNet18)": "",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "Baselines: (1) Classic image set-based methods: Discriminative"
        },
        {
          "End-to-end (backbone ResNet18)": "image sets, namely the Deep Second-order Pooling (DeepO2P) [73].",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": ""
        },
        {
          "End-to-end (backbone ResNet18)": "",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "Canonical Correlations\n(DCC)\n[5], manifold-manifold distance"
        },
        {
          "End-to-end (backbone ResNet18)": "(2) Methods based on subspace without Riemannian optimization:",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": ""
        },
        {
          "End-to-end (backbone ResNet18)": "",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "(MMD) [79], Convex Hull-based Image Set Distance (CHISD) [43],"
        },
        {
          "End-to-end (backbone ResNet18)": "DCC [5], Grassmann Discriminant Analysis (GDA [18] and Grass-",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": ""
        },
        {
          "End-to-end (backbone ResNet18)": "",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "Pairwise linear\nregression classiﬁcation (PLRC)\n[30].\n(2) Deep"
        },
        {
          "End-to-end (backbone ResNet18)": "mannian Graph-Embedding Discriminant Analysis (GGDA) [19].",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": ""
        },
        {
          "End-to-end (backbone ResNet18)": "",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "learning methods: deep reconstruction model (DRM) [80]; Resnet"
        },
        {
          "End-to-end (backbone ResNet18)": "And (3) methods based on Riemannian optimization: Projection",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": ""
        },
        {
          "End-to-end (backbone ResNet18)": "",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "vote [81] is a baseline consisting of a Resnet50 [81] ﬁne-tuned to"
        },
        {
          "End-to-end (backbone ResNet18)": "Metric Learning (PML) [74], Expressionlets on Spatio-Temporal",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": ""
        },
        {
          "End-to-end (backbone ResNet18)": "",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "this dataset with the cross-entropy loss in a single image setting."
        },
        {
          "End-to-end (backbone ResNet18)": "Manifold (STMExpLet) [68], Riemannian Sparse Representation",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": ""
        },
        {
          "End-to-end (backbone ResNet18)": "",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "For\nthe ﬁne-tuning, we added two fully connected (FC)\nlayers"
        },
        {
          "End-to-end (backbone ResNet18)": "combining with Manifold Learning on the manifold of SPD matri-",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": ""
        },
        {
          "End-to-end (backbone ResNet18)": "",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "after the last global average pooling layer in the network. The ﬁrst"
        },
        {
          "End-to-end (backbone ResNet18)": "ces (RSR-SPDML) [75], Network on SPD manifolds (SPDNet) [69]",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": ""
        },
        {
          "End-to-end (backbone ResNet18)": "",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "FC layer outputs a 1024 dimension vector through the ReLU [82]"
        },
        {
          "End-to-end (backbone ResNet18)": "and Grassmann net\n(GrNet)\n[72]. Especially, GrNet proposes a",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": ""
        },
        {
          "End-to-end (backbone ResNet18)": "",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "function, and the second layer outputs a 47 (the number of classes)"
        },
        {
          "End-to-end (backbone ResNet18)": "block of manifold layers for subspace data. GrNet-1 denotes the",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": ""
        },
        {
          "End-to-end (backbone ResNet18)": "",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "dimension vector through the softmax function. Hyperparameters"
        },
        {
          "End-to-end (backbone ResNet18)": "architecture with 1 block and GrNet-2 with 2 blocks.",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": ""
        },
        {
          "End-to-end (backbone ResNet18)": "",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "of the optimizer were used as suggested by the original paper. For"
        },
        {
          "End-to-end (backbone ResNet18)": "Results and discussion: The results can be seen in Table 2.",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": ""
        },
        {
          "End-to-end (backbone ResNet18)": "",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "classiﬁcation, each image of a set\nis classiﬁed independently and a"
        },
        {
          "End-to-end (backbone ResNet18)": "The proposed method achieved quite competitive results compared",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": ""
        },
        {
          "End-to-end (backbone ResNet18)": "",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "majority voting strategy of all predictions is used to select a single"
        },
        {
          "End-to-end (backbone ResNet18)": "to the manifold-based methods, by mapping the subspace into a",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": ""
        },
        {
          "End-to-end (backbone ResNet18)": "",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "class prediction for\nthe whole set. The model called Resnet18"
        },
        {
          "End-to-end (backbone ResNet18)": "vector and then uses simple Euclidean operations such as fully-",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": ""
        },
        {
          "End-to-end (backbone ResNet18)": "",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "set average is\nthe same as used in the hand shape experiment."
        },
        {
          "End-to-end (backbone ResNet18)": "connected layers and cross-entropy loss,\nin contrast\nto several",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": ""
        },
        {
          "End-to-end (backbone ResNet18)": "",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "The Resnet18 bilinear model uses the correlation matrix of\nthe"
        },
        {
          "End-to-end (backbone ResNet18)": "methods that use complex approaches requiring multiple matrix",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": ""
        },
        {
          "End-to-end (backbone ResNet18)": "",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "backbone features of the image set, generating a 512 × 512 matrix."
        },
        {
          "End-to-end (backbone ResNet18)": "decompositions. First, G-LMSM+softmax outperforms popular",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": ""
        },
        {
          "End-to-end (backbone ResNet18)": "",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "The vectorized matrix is processed through an FC layer and softmax"
        },
        {
          "End-to-end (backbone ResNet18)": "methods such as GDA and GGDA, which have a similar purpose",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": ""
        },
        {
          "End-to-end (backbone ResNet18)": "",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "for classiﬁcation."
        },
        {
          "End-to-end (backbone ResNet18)": "of mapping Grassmann manifold data into a vector representation.",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": ""
        },
        {
          "End-to-end (backbone ResNet18)": "",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "Results and discussion: Table 3 shows the results. G-LMSM"
        },
        {
          "End-to-end (backbone ResNet18)": "The reason is perhaps that G-LMSM learns both the representation",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": ""
        },
        {
          "End-to-end (backbone ResNet18)": "",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "outperforms not only the classical manifold methods, but also"
        },
        {
          "End-to-end (backbone ResNet18)": "and discrimination in an end-to-end manner, while GDA uses a",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": ""
        },
        {
          "End-to-end (backbone ResNet18)": "",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "various deep methods. Although G-LMSM uses the same backbone"
        },
        {
          "End-to-end (backbone ResNet18)": "kernel function to represent subspaces and learns the discriminant",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": ""
        },
        {
          "End-to-end (backbone ResNet18)": "",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "as some methods, it still can achieve better results. In the case of"
        },
        {
          "End-to-end (backbone ResNet18)": "independently. Methods such as SPDNet and GrNet are composed",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": ""
        },
        {
          "End-to-end (backbone ResNet18)": "",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "Resnet50 vote and the G-LMSM+FC,\nthe key difference is that"
        },
        {
          "End-to-end (backbone ResNet18)": "of many complex layers involving SVD, QR decompositions, and",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": ""
        },
        {
          "End-to-end (backbone ResNet18)": "",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "voting is a simple heuristic approach to image set recognition, as"
        },
        {
          "End-to-end (backbone ResNet18)": "Gram–Schmidt orthogonalization and its derivatives are utilized as",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": ""
        },
        {
          "End-to-end (backbone ResNet18)": "",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "the model\nis not aware of the set as a whole. This leads to unstable"
        },
        {
          "End-to-end (backbone ResNet18)": "well. They increase in complexity as the number of layers increases",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": ""
        },
        {
          "End-to-end (backbone ResNet18)": "",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "and diverging predictions on a set’s class, as it does not take into"
        },
        {
          "End-to-end (backbone ResNet18)": "by repeating these operations, which are not easily scalable to",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": ""
        },
        {
          "End-to-end (backbone ResNet18)": "",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "account the underlying set distribution. The voting method is not"
        },
        {
          "End-to-end (backbone ResNet18)": "use in GPUs. On the other hand,\nthe proposed method provides",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": ""
        },
        {
          "End-to-end (backbone ResNet18)": "",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "differentiable by nature, so it\nis not\ntrivial\nto extend this idea to an"
        },
        {
          "End-to-end (backbone ResNet18)": "competitive\nresults with fewer\nlayers\nand no decompositions,",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": ""
        },
        {
          "End-to-end (backbone ResNet18)": "",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "end-to-end approach. Then, set average seems again to be a naive"
        },
        {
          "End-to-end (backbone ResNet18)": "making it naturally parallelizable and scalable.",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": ""
        },
        {
          "End-to-end (backbone ResNet18)": "",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "approach to treating image sets and that more information can be"
        },
        {
          "End-to-end (backbone ResNet18)": "",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "modeled from the features distribution. The bilinear model could in"
        },
        {
          "End-to-end (backbone ResNet18)": "5.4\nExperiment on Face Identiﬁcation",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "theory capture the underlying set information from the correlations,"
        },
        {
          "End-to-end (backbone ResNet18)": "",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "but\nthe high dimensionality of\nthe correlation matrix makes\nit"
        },
        {
          "End-to-end (backbone ResNet18)": "We\nconducted\nan\nexperiment\nof\nface\nidentiﬁcation with\nthe",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": ""
        },
        {
          "End-to-end (backbone ResNet18)": "",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "almost\nimpossible to learn a FC classiﬁer without overﬁtting."
        },
        {
          "End-to-end (backbone ResNet18)": "YouTube Celebrities (YTC) dataset. Dataset: The YTC dataset [76]",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": ""
        },
        {
          "End-to-end (backbone ResNet18)": "contains 1910 videos of 47 identities. Similarly to [77], as an image",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "These results conﬁrm the advantage of G-LMSM over these"
        },
        {
          "End-to-end (backbone ResNet18)": "set, we used a set of face images extracted from a video by the",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "methods using the\nsame backbone: mutual\nsubspaces provide"
        },
        {
          "End-to-end (backbone ResNet18)": "Incremental Learning Tracker [78]. All the extracted face images",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "a low-dimensional, differentiable approach to modeling the set"
        },
        {
          "End-to-end (backbone ResNet18)": "were scaled to 30 × 30 pixels and converted to grayscale.",
          "AC+G-LMSM+sqrt\n71.09 ± 3.62": "distribution, ultimately leading to a straightforward integration of"
        }
      ],
      "page": 10
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "11": "S. N. Afriat, “Orthogonal and oblique projectors and the characteristics of\n[13]"
        },
        {
          "11": "pairs of vector spaces,” in Mathematical Proceedings of the Cambridge"
        },
        {
          "11": ""
        },
        {
          "11": "Philosophical Society, vol. 53, no. 4.\nCambridge University Press, 1957,"
        },
        {
          "11": ""
        },
        {
          "11": "pp. 800–816."
        },
        {
          "11": "[14] K. Fukui and A. Maki, “Difference subspace and its generalization for"
        },
        {
          "11": "subspace-based methods,” Pattern Analysis and Machine Intelligence,"
        },
        {
          "11": "IEEE Transactions on, vol. 37, no. 11, pp. 2164–2177, 2015."
        },
        {
          "11": ""
        },
        {
          "11": "[15] O. Yamaguchi and K. Fukui, “Smartface–a robust face recognition system"
        },
        {
          "11": ""
        },
        {
          "11": "under varying facial pose and expression,” 2003."
        },
        {
          "11": "[16] K. Fukui and O. Yamaguchi, “The kernel orthogonal mutual subspace"
        },
        {
          "11": "method and its application to 3d object recognition,” in Asian Conference"
        },
        {
          "11": "on Computer Vision."
        },
        {
          "11": "Springer, 2007, pp. 467–476."
        },
        {
          "11": "[17] H. Sakano\nand N. Mukawa,\n“Kernel mutual\nsubspace method\nfor"
        },
        {
          "11": "robust\nfacial\nimage\nrecognition,”\nin KES’2000. Fourth International"
        },
        {
          "11": "Conference on Knowledge-Based Intelligent Engineering Systems and"
        },
        {
          "11": ""
        },
        {
          "11": "Allied Technologies. Proceedings (Cat. No. 00TH8516), vol. 1.\nIEEE,"
        },
        {
          "11": ""
        },
        {
          "11": "2000, pp. 245–248."
        },
        {
          "11": "[18]\nJ. Hamm and D. D. Lee, “Grassmann discriminant analysis: a unifying"
        },
        {
          "11": "view on subspace-based learning,” in Proceedings of the 25th international"
        },
        {
          "11": "conference on Machine learning.\nACM, 2008, pp. 376–383."
        },
        {
          "11": ""
        },
        {
          "11": "[19] ——, “Extended grassmann kernels\nfor\nsubspace-based learning,” in"
        },
        {
          "11": ""
        },
        {
          "11": "Advances in neural\ninformation processing systems, 2009, pp. 601–608."
        },
        {
          "11": "[20] T. Kohonen, G. Németh, K.-J. Bry, M. Jalanko, and H. Riittinen, “Spectral"
        },
        {
          "11": "classiﬁcation of phonemes by learning subspaces,” in ICASSP’79. IEEE"
        },
        {
          "11": ""
        },
        {
          "11": "International Conference on Acoustics, Speech, and Signal Processing,"
        },
        {
          "11": ""
        },
        {
          "11": "vol. 4.\nIEEE, 1979, pp. 97–100."
        },
        {
          "11": "[21] E. Oja and M. Kuusela, “The ALSM algorithm — an improved subspace"
        },
        {
          "11": "method of classiﬁcation,” Pattern Recognition, vol. 16, no. 4, pp. 421–427,"
        },
        {
          "11": "1983."
        },
        {
          "11": ""
        },
        {
          "11": "[22]\nP.-A. Absil, R. Mahony, and R. Sepulchre, “Riemannian geometry of"
        },
        {
          "11": ""
        },
        {
          "11": "grassmann manifolds with a view on algorithmic computation,” Acta"
        },
        {
          "11": "Applicandae Mathematica, vol. 80, no. 2, pp. 199–220, 2004."
        },
        {
          "11": "[23] A. A. Borisenko and Y. A. Nikolaevskii, “Grassmann manifolds and"
        },
        {
          "11": "the grassmann image of submanifolds,” Russian mathematical surveys,"
        },
        {
          "11": ""
        },
        {
          "11": "vol. 46, no. 2, pp. 45–94, 1991."
        },
        {
          "11": ""
        },
        {
          "11": "[24] K. Fujii, “Introduction to grassmann manifolds and quantum computation,”"
        },
        {
          "11": "Journal of Applied Mathematics, vol. 2, no. 8, pp. 371–405, 2002."
        },
        {
          "11": "[25] O.-E. Ganea\nand G. Bécigneul,\n“Riemannian\nadaptive\noptimization"
        },
        {
          "11": "methods,” in 7th International Conference on Learning Representations"
        },
        {
          "11": ""
        },
        {
          "11": "(ICLR 2019), 2018."
        },
        {
          "11": "[26]\nS. Bonnabel, “Stochastic gradient descent on riemannian manifolds,” IEEE"
        },
        {
          "11": "Transactions on Automatic Control, vol. 58, no. 9, pp. 2217–2229, 2013."
        },
        {
          "11": "[27] L. Wang, H. Cheng,\nand\nZ.\nLiu,\n“A set-to-set\nnearest\nneighbor"
        },
        {
          "11": "approach\nfor\nrobust\nand\nefﬁcient\nface\nrecognition\nwith\nimage"
        },
        {
          "11": "Journal\nof Visual Communication\nand\nsets,”\nImage Representation,"
        },
        {
          "11": "vol.\n53,\npp.\n13–19,\nMay\n2018.\n[Online].\nAvailable:\nhttps:"
        },
        {
          "11": "//www.sciencedirect.com/science/article/pii/S1047320318300300"
        },
        {
          "11": "[28] W. Wang, R. Wang, S. Shan, and X. Chen, “Discriminative Covariance"
        },
        {
          "11": "Oriented Representation Learning for Face Recognition with Image Sets,”"
        },
        {
          "11": "in 2017 IEEE Conference on Computer Vision and Pattern Recognition"
        },
        {
          "11": "(CVPR).\nHonolulu, HI:\nIEEE,\nJul. 2017, pp. 5749–5758.\n[Online]."
        },
        {
          "11": "Available: http://ieeexplore.ieee.org/document/8100092/"
        },
        {
          "11": "[29]\nJ. Lu, G. Wang, W. Deng, P. Moulin, and J. Zhou, “Multi-manifold"
        },
        {
          "11": "deep metric learning for image set classiﬁcation,” in Proceedings of the"
        },
        {
          "11": "IEEE conference on computer vision and pattern recognition, 2015, pp."
        },
        {
          "11": "1137–1145."
        },
        {
          "11": "[30] Q. Feng, Y. Zhou, and R. Lan, “Pairwise Linear Regression Classiﬁcation"
        },
        {
          "11": "for Image Set Retrieval,” in 2016 IEEE Conference on Computer Vision"
        },
        {
          "11": "and Pattern Recognition (CVPR), Jun. 2016, pp. 4865–4872,\niSSN: 1063-"
        },
        {
          "11": "6919."
        },
        {
          "11": "[31]\nI. Naseem, R. Togneri,\nand M. Bennamoun,\n“Linear Regression for"
        },
        {
          "11": "Face Recognition,” IEEE Transactions on Pattern Analysis and Machine"
        },
        {
          "11": "Intelligence, vol. 32, no. 11, pp. 2106–2112, Nov. 2010, conference Name:"
        },
        {
          "11": "IEEE Transactions on Pattern Analysis and Machine Intelligence."
        },
        {
          "11": "[32]\nJ. Stallkamp, H. K. Ekenel, and R. Stiefelhagen, “Video-based Face"
        },
        {
          "11": "Recognition on Real-World Data,”\nin 2007 IEEE 11th International"
        },
        {
          "11": "Conference on Computer Vision, Oct. 2007, pp. 1–8,\niSSN: 2380-7504."
        },
        {
          "11": "[33]\nS. Zhou and R. Chellappa, “Probabilistic Human Recognition from Video,”"
        },
        {
          "11": "in Computer Vision — ECCV 2002,\nser. Lecture Notes\nin Computer"
        },
        {
          "11": "Science, A. Heyden, G. Sparr, M. Nielsen, and P. Johansen, Eds.\nBerlin,"
        },
        {
          "11": "Heidelberg: Springer, 2002, pp. 681–697."
        },
        {
          "11": "J. R. Uijlings, K. E. Van De Sande, T. Gevers, and A. W. Smeulders,\n[34]"
        },
        {
          "11": "“Selective search for object recognition,” International journal of computer"
        },
        {
          "11": "vision, vol. 104, no. 2, pp. 154–171, 2013."
        },
        {
          "11": "[35] X. Li, K. Fukui, and N. Zheng, “Boosting constrained mutual subspace"
        },
        {
          "11": "method for robust\nimage-set based object recognition,” in Twenty-First"
        },
        {
          "11": "International Joint Conference on Artiﬁcial Intelligence, 2009."
        }
      ],
      "page": 11
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "12": "[61] X. Yang, Y. Chen, and H. Liang, “Square root based activation function in"
        },
        {
          "12": "neural networks,” in 2018 International Conference on Audio, Language"
        },
        {
          "12": "and Image Processing (ICALIP).\nIEEE, 2018, pp. 84–89."
        },
        {
          "12": "[62] C. Guo, G. Pleiss, Y. Sun,\nand K. Q. Weinberger,\n“On calibration"
        },
        {
          "12": "of modern neural networks,” in International Conference on Machine"
        },
        {
          "12": "Learning.\nPMLR, 2017, pp. 1321–1330."
        },
        {
          "12": "[63] G. Hinton, O. Vinyals, and J. Dean, “Distilling the knowledge in a neural"
        },
        {
          "12": "network,” arXiv preprint arXiv:1503.02531, 2015."
        },
        {
          "12": "[64]\nS. Liang, Y. Li,\nand R. Srikant,\n“Enhancing\nthe\nreliability\nof\nout-"
        },
        {
          "12": "arXiv\npreprint\nof-distribution\nimage\ndetection\nin\nneural\nnetworks,”"
        },
        {
          "12": ""
        },
        {
          "12": "arXiv:1706.02690, 2017."
        },
        {
          "12": ""
        },
        {
          "12": "[65] A. Agarwala, J. Pennington, Y. Dauphin, and S. Schoenholz, “Temperature"
        },
        {
          "12": "check: theory and practice for training models with softmax-cross-entropy"
        },
        {
          "12": ""
        },
        {
          "12": "losses,” arXiv preprint arXiv:2010.07344, 2020."
        },
        {
          "12": ""
        },
        {
          "12": "[66] Y. Gao, O. Beijbom, N. Zhang, and T. Darrell, “Compact bilinear pooling,”"
        },
        {
          "12": ""
        },
        {
          "12": "the IEEE conference on computer vision and pattern\nin Proceedings of"
        },
        {
          "12": ""
        },
        {
          "12": "recognition, 2016, pp. 317–326."
        },
        {
          "12": ""
        },
        {
          "12": "[67] A. Dhall, R. Goecke,\nJ.\nJoshi, K. Sikka,\nand T. Gedeon,\n“Emotion"
        },
        {
          "12": ""
        },
        {
          "12": "recognition in the wild challenge 2014: Baseline, data and protocol,”"
        },
        {
          "12": ""
        },
        {
          "12": "of\nthe\n16th\ninternational\nconference\non multimodal\nin Proceedings"
        },
        {
          "12": ""
        },
        {
          "12": "interaction.\nACM, 2014, pp. 461–466."
        },
        {
          "12": ""
        },
        {
          "12": "[68] M. Liu, S. Shan, R. Wang, and X. Chen, “Learning expressionlets on"
        },
        {
          "12": ""
        },
        {
          "12": "spatio-temporal manifold for dynamic facial expression recognition,” in"
        },
        {
          "12": ""
        },
        {
          "12": "Proceedings of\nthe IEEE Conference on Computer Vision and Pattern"
        },
        {
          "12": ""
        },
        {
          "12": "Recognition, 2014, pp. 1749–1756."
        },
        {
          "12": ""
        },
        {
          "12": "[69] Z. Huang and L. Van Gool, “A riemannian network for spd matrix learning,”"
        },
        {
          "12": ""
        },
        {
          "12": "in Thirty-First AAAI Conference on Artiﬁcial Intelligence, 2017."
        },
        {
          "12": ""
        },
        {
          "12": "[70] Z. Huang, J. Wu, and L. V. Gool, “Building Deep Networks on Grassmann"
        },
        {
          "12": ""
        },
        {
          "12": "Manifolds,” arXiv, 2016."
        },
        {
          "12": ""
        },
        {
          "12": "[71] M. Liu, R. Wang, Z. Huang, S. Shan,\nand X. Chen,\n“Partial\nleast"
        },
        {
          "12": ""
        },
        {
          "12": "squares regression on grassmannian manifold for emotion recognition,” in"
        },
        {
          "12": ""
        },
        {
          "12": "Proceedings of\nthe 15th ACM on International conference on multimodal"
        },
        {
          "12": ""
        },
        {
          "12": "interaction.\nACM, 2013, pp. 525–530."
        },
        {
          "12": "[72] Z. Huang, J. Wu, and L. Van Gool, “Building deep networks on grassmann"
        },
        {
          "12": "manifolds,” in Thirty-Second AAAI Conference on Artiﬁcial Intelligence,"
        },
        {
          "12": "2018."
        },
        {
          "12": "[73] C. Ionescu, O. Vantzos, and C. Sminchisescu, “Training deep networks"
        },
        {
          "12": "arXiv\npreprint\nwith\nstructured\nlayers\nby matrix\nbackpropagation,”"
        },
        {
          "12": "arXiv:1509.07838, 2015."
        },
        {
          "12": "[74] Z. Huang, R. Wang, S. Shan, and X. Chen, “Projection metric learning"
        },
        {
          "12": "on grassmann manifold with application to video based face recognition,”"
        },
        {
          "12": "the IEEE conference on computer vision and pattern\nin Proceedings of"
        },
        {
          "12": "recognition, 2015, pp. 140–149."
        },
        {
          "12": "[75] M. T. Harandi, M. Salzmann, and R. Hartley, “From manifold to manifold:"
        },
        {
          "12": "Geometry-aware dimensionality reduction for spd matrices,” in European"
        },
        {
          "12": "conference on computer vision.\nSpringer, 2014, pp. 17–32."
        },
        {
          "12": "[76] M. Kim, S. Kumar, V. Pavlovic, and H. Rowley, “Face tracking and"
        },
        {
          "12": "recognition with visual constraints in real-world videos,” in Computer"
        },
        {
          "12": "Vision and Pattern Recognition.\nIEEE, 2008, pp. 1–8."
        },
        {
          "12": "[77]\nS. A. A. Shah, U. Nadeem, M. Bennamoun, F. A. Sohel, and R. Togneri,"
        },
        {
          "12": "“Efﬁcient\nimage set classiﬁcation using linear\nregression based image"
        },
        {
          "12": "reconstruction.” in Computer Vision and Pattern Recognition Workshops,"
        },
        {
          "12": ""
        },
        {
          "12": "2017, pp. 601–610."
        },
        {
          "12": ""
        },
        {
          "12": "[78] D. A. Ross, J. Lim, R.-S. Lin, and M.-H. Yang, “Incremental\nlearning for"
        },
        {
          "12": ""
        },
        {
          "12": "robust visual\ntracking,” International Journal of Computer Vision, vol. 77,"
        },
        {
          "12": ""
        },
        {
          "12": "no. 1-3, pp. 125–141, 2008."
        },
        {
          "12": ""
        },
        {
          "12": "[79] R. Wang, S. Shan, X. Chen, and W. Gao, “Manifold-manifold distance"
        },
        {
          "12": ""
        },
        {
          "12": "with application to face recognition based on image set,” in 2008 IEEE"
        },
        {
          "12": ""
        },
        {
          "12": "Conference on Computer Vision and Pattern Recognition.\nIEEE, 2008,"
        },
        {
          "12": ""
        },
        {
          "12": "pp. 1–8."
        },
        {
          "12": ""
        },
        {
          "12": "[80]\nS. A. Shah, U. Nadeem, M. Bennamoun, F. Sohel,\nand R. Togneri,"
        },
        {
          "12": ""
        },
        {
          "12": "“Efﬁcient\nimage set classiﬁcation using linear\nregression based image"
        },
        {
          "12": ""
        },
        {
          "12": "the IEEE Conference on Computer\nreconstruction,” in Proceedings of"
        },
        {
          "12": ""
        },
        {
          "12": "Vision and Pattern Recognition Workshops, 2017, pp. 99–108."
        },
        {
          "12": ""
        },
        {
          "12": "[81] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image"
        },
        {
          "12": ""
        },
        {
          "12": "recognition,” in The IEEE Conference on Computer Vision and Pattern"
        },
        {
          "12": ""
        },
        {
          "12": "Recognition, 2016."
        },
        {
          "12": ""
        },
        {
          "12": "[82] V. Nair and G. E. Hinton,\n“Rectiﬁed linear units\nimprove\nrestricted"
        },
        {
          "12": ""
        },
        {
          "12": "boltzmann machines,” in Proceedings of the 27th International Conference"
        },
        {
          "12": ""
        },
        {
          "12": "on Machine Learning, 2010, pp. 807–814."
        },
        {
          "12": ""
        },
        {
          "12": ""
        },
        {
          "12": ""
        },
        {
          "12": ""
        },
        {
          "12": ""
        },
        {
          "12": ""
        },
        {
          "12": ""
        },
        {
          "12": ""
        }
      ],
      "page": 12
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "On Photometric Issues in 3D Visual Recognition from a Single 2D Image",
      "authors": [
        "A Shashua"
      ],
      "year": "1997",
      "venue": "International Journal of Computer Vision",
      "doi": "10.1023/A:1007975506780"
    },
    {
      "citation_id": "2",
      "title": "What Is the Set of Images of an Object Under All Possible Illumination Conditions?",
      "authors": [
        "P Belhumeur",
        "D Kriegman"
      ],
      "year": "1998",
      "venue": "International Journal of Computer Vision",
      "doi": "10.1023/A:1008005721484"
    },
    {
      "citation_id": "3",
      "title": "Acquiring linear subspaces for face recognition under variable lighting",
      "authors": [
        "K.-C Lee",
        "J Ho",
        "D Kriegman"
      ],
      "year": "2005",
      "venue": "IEEE Transactions on pattern analysis and machine intelligence"
    },
    {
      "citation_id": "4",
      "title": "Lambertian reflectance and linear subspaces",
      "authors": [
        "R Basri",
        "D Jacobs"
      ],
      "year": "2003",
      "venue": "IEEE transactions on pattern analysis and machine intelligence"
    },
    {
      "citation_id": "5",
      "title": "Discriminative learning and recognition of image set classes using canonical correlations",
      "authors": [
        "T.-K Kim",
        "J Kittler",
        "R Cipolla"
      ],
      "year": "2007",
      "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
    },
    {
      "citation_id": "6",
      "title": "Constrained mutual convex cone method for image set based recognition",
      "authors": [
        "N Sogi",
        "R Zhu",
        "J.-H Xue",
        "K Fukui"
      ],
      "year": "2022",
      "venue": "Pattern Recognition"
    },
    {
      "citation_id": "7",
      "title": "Enhanced grassmann discriminant analysis with randomized time warping for motion recognition",
      "authors": [
        "L Souza",
        "B Gatto",
        "J.-H Xue",
        "K Fukui"
      ],
      "year": "2020",
      "venue": "Pattern Recognition"
    },
    {
      "citation_id": "8",
      "title": "Subspace method of pattern recognition",
      "authors": [
        "S Watanabe",
        "N Pakvasa"
      ],
      "year": "1973",
      "venue": "Proc. 1st. IJCPR"
    },
    {
      "citation_id": "9",
      "title": "A theory of character recognition by pattern matching method",
      "authors": [
        "T Iijima",
        "H Genchi",
        "K.-I Mori"
      ],
      "year": "1974",
      "venue": "Learning systems and intelligent robots"
    },
    {
      "citation_id": "10",
      "title": "Subspace methods of pattern recognition",
      "authors": [
        "E Oja"
      ],
      "year": "1983",
      "venue": "Subspace methods of pattern recognition"
    },
    {
      "citation_id": "11",
      "title": "From few to many: Illumination cone models for face recognition under variable lighting and pose",
      "authors": [
        "A Georghiades",
        "P Belhumeur",
        "D Kriegman"
      ],
      "year": "2001",
      "venue": "IEEE transactions on pattern analysis and machine intelligence"
    },
    {
      "citation_id": "12",
      "title": "Relations between two sets of variates",
      "authors": [
        "H Hotelling"
      ],
      "year": "1992",
      "venue": "Breakthroughs in statistics"
    },
    {
      "citation_id": "13",
      "title": "Orthogonal and oblique projectors and the characteristics of pairs of vector spaces",
      "authors": [
        "S Afriat"
      ],
      "year": "1957",
      "venue": "Mathematical Proceedings of the Cambridge Philosophical Society"
    },
    {
      "citation_id": "14",
      "title": "Difference subspace and its generalization for subspace-based methods",
      "authors": [
        "K Fukui",
        "A Maki"
      ],
      "year": "2015",
      "venue": "IEEE Transactions on"
    },
    {
      "citation_id": "15",
      "title": "Smartface-a robust face recognition system under varying facial pose and expression",
      "authors": [
        "O Yamaguchi",
        "K Fukui"
      ],
      "year": "2003",
      "venue": "Smartface-a robust face recognition system under varying facial pose and expression"
    },
    {
      "citation_id": "16",
      "title": "The kernel orthogonal mutual subspace method and its application to 3d object recognition",
      "authors": [
        "K Fukui",
        "O Yamaguchi"
      ],
      "year": "2007",
      "venue": "Asian Conference on Computer Vision"
    },
    {
      "citation_id": "17",
      "title": "Kernel mutual subspace method for robust facial image recognition",
      "authors": [
        "H Sakano",
        "N Mukawa"
      ],
      "year": "2000",
      "venue": "KES'2000. Fourth International Conference on Knowledge-Based Intelligent Engineering Systems and Allied Technologies. Proceedings (Cat. No. 00TH8516)"
    },
    {
      "citation_id": "18",
      "title": "Grassmann discriminant analysis: a unifying view on subspace-based learning",
      "authors": [
        "J Hamm",
        "D Lee"
      ],
      "year": "2008",
      "venue": "Proceedings of the 25th international conference on Machine learning"
    },
    {
      "citation_id": "19",
      "title": "Extended grassmann kernels for subspace-based learning",
      "year": "2009",
      "venue": "Advances in neural information processing systems"
    },
    {
      "citation_id": "20",
      "title": "Spectral classification of phonemes by learning subspaces",
      "authors": [
        "T Kohonen",
        "G Németh",
        "K.-J Bry",
        "M Jalanko",
        "H Riittinen"
      ],
      "year": "1979",
      "venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing"
    },
    {
      "citation_id": "21",
      "title": "The ALSM algorithm -an improved subspace method of classification",
      "authors": [
        "E Oja",
        "M Kuusela"
      ],
      "year": "1983",
      "venue": "Pattern Recognition"
    },
    {
      "citation_id": "22",
      "title": "Riemannian geometry of grassmann manifolds with a view on algorithmic computation",
      "authors": [
        "P.-A Absil",
        "R Mahony",
        "R Sepulchre"
      ],
      "year": "2004",
      "venue": "Acta Applicandae Mathematica"
    },
    {
      "citation_id": "23",
      "title": "Grassmann manifolds and the grassmann image of submanifolds",
      "authors": [
        "A Borisenko",
        "Y Nikolaevskii"
      ],
      "year": "1991",
      "venue": "Russian mathematical surveys"
    },
    {
      "citation_id": "24",
      "title": "Introduction to grassmann manifolds and quantum computation",
      "authors": [
        "K Fujii"
      ],
      "year": "2002",
      "venue": "Journal of Applied Mathematics"
    },
    {
      "citation_id": "25",
      "title": "Riemannian adaptive optimization methods",
      "authors": [
        "O.-E Ganea",
        "G Bécigneul"
      ],
      "year": "2018",
      "venue": "7th International Conference on Learning Representations"
    },
    {
      "citation_id": "26",
      "title": "Stochastic gradient descent on riemannian manifolds",
      "authors": [
        "S Bonnabel"
      ],
      "year": "2013",
      "venue": "IEEE Transactions on Automatic Control"
    },
    {
      "citation_id": "27",
      "title": "A set-to-set nearest neighbor approach for robust and efficient face recognition with image sets",
      "authors": [
        "L Wang",
        "H Cheng",
        "Z Liu"
      ],
      "year": "2018",
      "venue": "Journal of Visual Communication and Image Representation"
    },
    {
      "citation_id": "28",
      "title": "Discriminative Covariance Oriented Representation Learning for Face Recognition with Image Sets",
      "authors": [
        "W Wang",
        "R Wang",
        "S Shan",
        "X Chen"
      ],
      "year": "2017",
      "venue": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
    },
    {
      "citation_id": "29",
      "title": "Multi-manifold deep metric learning for image set classification",
      "authors": [
        "J Lu",
        "G Wang",
        "W Deng",
        "P Moulin",
        "J Zhou"
      ],
      "year": "2015",
      "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition"
    },
    {
      "citation_id": "30",
      "title": "Pairwise Linear Regression Classification for Image Set Retrieval",
      "authors": [
        "Q Feng",
        "Y Zhou",
        "R Lan"
      ],
      "year": "2016",
      "venue": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
    },
    {
      "citation_id": "31",
      "title": "Linear Regression for Face Recognition",
      "authors": [
        "I Naseem",
        "R Togneri",
        "M Bennamoun"
      ],
      "year": "2010",
      "venue": "conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence"
    },
    {
      "citation_id": "32",
      "title": "Video-based Face Recognition on Real-World Data",
      "authors": [
        "J Stallkamp",
        "H Ekenel",
        "R Stiefelhagen"
      ],
      "year": "2007",
      "venue": "2007 IEEE 11th International Conference on Computer Vision"
    },
    {
      "citation_id": "33",
      "title": "Probabilistic Human Recognition from Video",
      "authors": [
        "S Zhou",
        "R Chellappa"
      ],
      "year": "2002",
      "venue": "Computer Vision -ECCV 2002, ser. Lecture Notes in Computer"
    },
    {
      "citation_id": "34",
      "title": "Selective search for object recognition",
      "authors": [
        "J Uijlings",
        "K Van De Sande",
        "T Gevers",
        "A Smeulders"
      ],
      "year": "2013",
      "venue": "International journal of computer vision"
    },
    {
      "citation_id": "35",
      "title": "Boosting constrained mutual subspace method for robust image-set based object recognition",
      "authors": [
        "X Li",
        "K Fukui",
        "N Zheng"
      ],
      "year": "2009",
      "venue": "Twenty-First International Joint Conference on Artificial Intelligence"
    },
    {
      "citation_id": "36",
      "title": "What is the best multi-stage architecture for object recognition",
      "authors": [
        "K Jarrett",
        "K Kavukcuoglu",
        "M Ranzato",
        "Y Lecun"
      ],
      "year": "2009",
      "venue": "IEEE"
    },
    {
      "citation_id": "37",
      "title": "A review of image set classification",
      "authors": [
        "Z.-Q Zhao",
        "S.-T Xu",
        "D Liu",
        "W.-D Tian",
        "Z.-D Jiang"
      ],
      "year": "2019",
      "venue": "Neurocomputing"
    },
    {
      "citation_id": "38",
      "title": "Face recognition with image sets using manifold density divergence",
      "authors": [
        "O Arandjelovic",
        "G Shakhnarovich",
        "J Fisher",
        "R Cipolla",
        "T Darrell"
      ],
      "year": "2005",
      "venue": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
    },
    {
      "citation_id": "39",
      "title": "Towards 3-dimensional pattern recognition",
      "authors": [
        "K.-I Maeda",
        "O Yamaguchi",
        "K Fukui"
      ],
      "year": "2004",
      "venue": "Joint IAPR International Workshops on Statistical Techniques in Pattern Recognition (SPR) and Structural and Syntactic Pattern Recognition (SSPR)"
    },
    {
      "citation_id": "40",
      "title": "Canonical correlation analysis of video volume tensors for action categorization and detection",
      "authors": [
        "T.-K Kim",
        "R Cipolla"
      ],
      "year": "2009",
      "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
    },
    {
      "citation_id": "41",
      "title": "Manifold-manifold distance and its application to face recognition with image sets",
      "authors": [
        "R Wang",
        "S Shan",
        "X Chen",
        "Q Dai",
        "W Gao"
      ],
      "year": "2012",
      "venue": "IEEE Transactions on Image Processing"
    },
    {
      "citation_id": "42",
      "title": "Manifold discriminant analysis",
      "authors": [
        "R Wang",
        "X Chen"
      ],
      "year": "2009",
      "venue": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
    },
    {
      "citation_id": "43",
      "title": "Face recognition based on image sets",
      "authors": [
        "H Cevikalp",
        "B Triggs"
      ],
      "year": "2010",
      "venue": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
    },
    {
      "citation_id": "44",
      "title": "Face recognition using sparse approximated nearest points between image sets",
      "authors": [
        "Y Hu",
        "A Mian",
        "R Owens"
      ],
      "year": "2012",
      "venue": "IEEE transactions on pattern analysis and machine intelligence"
    },
    {
      "citation_id": "45",
      "title": "Sparse approximated nearest points for image set classification",
      "year": "2011",
      "venue": "CVPR 2011. IEEE"
    },
    {
      "citation_id": "46",
      "title": "Dictionary learning and sparse coding on grassmann manifolds: An extrinsic solution",
      "authors": [
        "M Harandi",
        "C Sanderson",
        "C Shen",
        "B Lovell"
      ],
      "year": "2013",
      "venue": "Proceedings of the IEEE international conference on computer vision"
    },
    {
      "citation_id": "47",
      "title": "Face recognition based on dictionary learning and subspace learning",
      "authors": [
        "M Liao",
        "X Gu"
      ],
      "year": "2019",
      "venue": "Digital Signal Processing"
    },
    {
      "citation_id": "48",
      "title": "Subspace-based learning with grassmann kernels",
      "authors": [
        "J Hamm"
      ],
      "year": "2008",
      "venue": "Subspace-based learning with grassmann kernels"
    },
    {
      "citation_id": "49",
      "title": "Graph embedding discriminant analysis on Grassmannian manifolds for improved image set matching",
      "authors": [
        "M Harandi",
        "C Sanderson",
        "S Shirazi",
        "B Lovell"
      ],
      "year": "2011",
      "venue": "Computer Vision and Pattern Recognition"
    },
    {
      "citation_id": "50",
      "title": "3d object recognition with enhanced grassmann discriminant analysis",
      "authors": [
        "L Souza",
        "H Hino",
        "K Fukui"
      ],
      "year": "2016",
      "venue": "ACCV 2016 Workshop"
    },
    {
      "citation_id": "51",
      "title": "Towards Generalized and Efficient Metric Learning on Riemannian Manifold",
      "authors": [
        "P Zhu",
        "H Cheng",
        "Q Hu",
        "Q Wang",
        "C Zhang"
      ],
      "year": "2018",
      "venue": "Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence"
    },
    {
      "citation_id": "52",
      "title": "Metric learning with a-based scalar product for image-set recognition",
      "authors": [
        "N Sogi",
        "L Souza",
        "B Gatto",
        "K Fukui"
      ],
      "year": "2020",
      "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops"
    },
    {
      "citation_id": "53",
      "title": "Robust Metric Learning on Grassmann Manifolds with Generalization Guarantees",
      "authors": [
        "L Luo",
        "J Xu",
        "C Deng",
        "H Huang"
      ],
      "year": "2019",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence"
    },
    {
      "citation_id": "54",
      "title": "Cappronet: Deep feature learning via orthogonal projections onto capsule subspaces",
      "authors": [
        "L Zhang",
        "M Edraki",
        "G.-J Qi"
      ],
      "year": "2018",
      "venue": "Advances in neural information processing systems"
    },
    {
      "citation_id": "55",
      "title": "Transforming autoencoders",
      "authors": [
        "G Hinton",
        "A Krizhevsky",
        "S Wang"
      ],
      "year": "2011",
      "venue": "International conference on artificial neural networks"
    },
    {
      "citation_id": "56",
      "title": "Dynamic routing between capsules",
      "authors": [
        "S Sabour",
        "N Frosst",
        "G Hinton"
      ],
      "year": "2017",
      "venue": "Dynamic routing between capsules",
      "arxiv": "arXiv:1710.09829"
    },
    {
      "citation_id": "57",
      "title": "Evaluation and selection of variables in pattern recognition",
      "authors": [
        "S Watanabe"
      ],
      "year": "1967",
      "venue": "Computer and Information Science"
    },
    {
      "citation_id": "58",
      "title": "A theoretical study of pattern recognition by matching method",
      "authors": [
        "T Iijima"
      ],
      "year": "1972",
      "venue": "Proc. of First USA-Japan Computer Conf"
    },
    {
      "citation_id": "59",
      "title": "The geometry of algorithms with orthogonality constraints",
      "authors": [
        "A Edelman",
        "T Arias",
        "S Smith"
      ],
      "year": "1998",
      "venue": "SIAM journal on Matrix Analysis and Applications"
    },
    {
      "citation_id": "60",
      "title": "Riemannian adaptive optimization methods",
      "authors": [
        "G Bécigneul",
        "O.-E Ganea"
      ],
      "year": "2018",
      "venue": "Riemannian adaptive optimization methods",
      "arxiv": "arXiv:1810.00760"
    },
    {
      "citation_id": "61",
      "title": "Square root based activation function in neural networks",
      "authors": [
        "X Yang",
        "Y Chen",
        "H Liang"
      ],
      "year": "2018",
      "venue": "2018 International Conference on Audio, Language and Image Processing"
    },
    {
      "citation_id": "62",
      "title": "On calibration of modern neural networks",
      "authors": [
        "C Guo",
        "G Pleiss",
        "Y Sun",
        "K Weinberger"
      ],
      "year": "2017",
      "venue": "International Conference on Machine Learning"
    },
    {
      "citation_id": "63",
      "title": "Distilling the knowledge in a neural network",
      "authors": [
        "G Hinton",
        "O Vinyals",
        "J Dean"
      ],
      "year": "2015",
      "venue": "Distilling the knowledge in a neural network",
      "arxiv": "arXiv:1503.02531"
    },
    {
      "citation_id": "64",
      "title": "Enhancing the reliability of outof-distribution image detection in neural networks",
      "authors": [
        "S Liang",
        "Y Li",
        "R Srikant"
      ],
      "year": "2017",
      "venue": "Enhancing the reliability of outof-distribution image detection in neural networks",
      "arxiv": "arXiv:1706.02690"
    },
    {
      "citation_id": "65",
      "title": "Temperature check: theory and practice for training models with softmax-cross-entropy losses",
      "authors": [
        "A Agarwala",
        "J Pennington",
        "Y Dauphin",
        "S Schoenholz"
      ],
      "year": "2020",
      "venue": "Temperature check: theory and practice for training models with softmax-cross-entropy losses",
      "arxiv": "arXiv:2010.07344"
    },
    {
      "citation_id": "66",
      "title": "Compact bilinear pooling",
      "authors": [
        "Y Gao",
        "O Beijbom",
        "N Zhang",
        "T Darrell"
      ],
      "year": "2016",
      "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition"
    },
    {
      "citation_id": "67",
      "title": "Emotion recognition in the wild challenge 2014: Baseline, data and protocol",
      "authors": [
        "A Dhall",
        "R Goecke",
        "J Joshi",
        "K Sikka",
        "T Gedeon"
      ],
      "year": "2014",
      "venue": "Proceedings of the 16th international conference on multimodal interaction"
    },
    {
      "citation_id": "68",
      "title": "Learning expressionlets on spatio-temporal manifold for dynamic facial expression recognition",
      "authors": [
        "M Liu",
        "S Shan",
        "R Wang",
        "X Chen"
      ],
      "year": "2014",
      "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition"
    },
    {
      "citation_id": "69",
      "title": "A riemannian network for spd matrix learning",
      "authors": [
        "Z Huang",
        "L Van Gool"
      ],
      "year": "2017",
      "venue": "Thirty-First AAAI Conference on Artificial Intelligence"
    },
    {
      "citation_id": "70",
      "title": "Building Deep Networks on Grassmann Manifolds",
      "authors": [
        "Z Huang",
        "J Wu",
        "L Gool"
      ],
      "year": "2016",
      "venue": "Building Deep Networks on Grassmann Manifolds"
    },
    {
      "citation_id": "71",
      "title": "Partial least squares regression on grassmannian manifold for emotion recognition",
      "authors": [
        "M Liu",
        "R Wang",
        "Z Huang",
        "S Shan",
        "X Chen"
      ],
      "year": "2013",
      "venue": "Proceedings of the 15th ACM on International conference on multimodal interaction"
    },
    {
      "citation_id": "72",
      "title": "Building deep networks on grassmann manifolds",
      "authors": [
        "Z Huang",
        "J Wu",
        "L Van Gool"
      ],
      "year": "2018",
      "venue": "Thirty-Second AAAI Conference on Artificial Intelligence"
    },
    {
      "citation_id": "73",
      "title": "Training deep networks with structured layers by matrix backpropagation",
      "authors": [
        "C Ionescu",
        "O Vantzos",
        "C Sminchisescu"
      ],
      "year": "2015",
      "venue": "Training deep networks with structured layers by matrix backpropagation",
      "arxiv": "arXiv:1509.07838"
    },
    {
      "citation_id": "74",
      "title": "Projection metric learning on grassmann manifold with application to video based face recognition",
      "authors": [
        "Z Huang",
        "R Wang",
        "S Shan",
        "X Chen"
      ],
      "year": "2015",
      "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition"
    },
    {
      "citation_id": "75",
      "title": "From manifold to manifold: Geometry-aware dimensionality reduction for spd matrices",
      "authors": [
        "M Harandi",
        "M Salzmann",
        "R Hartley"
      ],
      "year": "2014",
      "venue": "From manifold to manifold: Geometry-aware dimensionality reduction for spd matrices"
    },
    {
      "citation_id": "76",
      "title": "Face tracking and recognition with visual constraints in real-world videos",
      "authors": [
        "M Kim",
        "S Kumar",
        "V Pavlovic",
        "H Rowley"
      ],
      "year": "2008",
      "venue": "Computer Vision and Pattern Recognition"
    },
    {
      "citation_id": "77",
      "title": "Efficient image set classification using linear regression based image reconstruction",
      "authors": [
        "S Shah",
        "U Nadeem",
        "M Bennamoun",
        "F Sohel",
        "R Togneri"
      ],
      "year": "2017",
      "venue": "Computer Vision and Pattern Recognition Workshops"
    },
    {
      "citation_id": "78",
      "title": "Incremental learning for robust visual tracking",
      "authors": [
        "D Ross",
        "J Lim",
        "R.-S Lin",
        "M.-H Yang"
      ],
      "year": "2008",
      "venue": "International Journal of Computer Vision"
    },
    {
      "citation_id": "79",
      "title": "Manifold-manifold distance with application to face recognition based on image set",
      "authors": [
        "R Wang",
        "S Shan",
        "X Chen",
        "W Gao"
      ],
      "year": "2008",
      "venue": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
    },
    {
      "citation_id": "80",
      "title": "Efficient image set classification using linear regression based image reconstruction",
      "authors": [
        "S Shah",
        "U Nadeem",
        "M Bennamoun",
        "F Sohel",
        "R Togneri"
      ],
      "year": "2017",
      "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops"
    },
    {
      "citation_id": "81",
      "title": "Deep residual learning for image recognition",
      "authors": [
        "K He",
        "X Zhang",
        "S Ren",
        "J Sun"
      ],
      "year": "2016",
      "venue": "The IEEE Conference on Computer Vision and Pattern Recognition"
    },
    {
      "citation_id": "82",
      "title": "Rectified linear units improve restricted boltzmann machines",
      "authors": [
        "V Nair",
        "G Hinton"
      ],
      "year": "2010",
      "venue": "Proceedings of the 27th International Conference on Machine Learning"
    }
  ]
}