{
  "paper_id": "2509.09593v1",
  "title": "Fluent But Unfeeling: The Emotional Blind Spots Of Language Models",
  "published": "2025-09-11T16:31:13Z",
  "authors": [
    "Bangzhao Shu",
    "Isha Joshi",
    "Melissa Karnaze",
    "Anh C. Pham",
    "Ishita Kakkar",
    "Sindhu Kothe",
    "Arpine Hovasapian",
    "Mai ElSherief"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "The versatility of Large Language Models (LLMs) in natural language understanding has made them increasingly popular in mental health research. While many studies explore LLMs' capabilities in emotion recognition, a critical gap remains in evaluating whether LLMs align with human emotions at a finegrained level. Existing research typically focuses on classifying emotions into predefined, limited categories, overlooking more nuanced expressions. To address this gap, we introduce EXPRESS, a benchmark dataset curated from Reddit communities featuring 251 fine-grained, self-disclosed emotion labels. Our comprehensive evaluation framework examines predicted emotion terms and decomposes them into eight basic emotions using established emotion theories, enabling a finegrained comparison. Systematic testing of prevalent LLMs under various prompt settings reveals that accurately predicting emotions that align with human self-disclosed emotions remains challenging. Qualitative analysis further shows that while certain LLMs generate emotion terms consistent with established emotion theories and definitions, they sometimes fail to capture contextual cues as effectively as human selfdisclosures. These findings highlight the limitations of LLMs in fine-grained emotion alignment and offer insights for future research aimed at enhancing their contextual understanding.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "LLMs have been trained on vast amounts of written human language (e.g., from the internet), some of which contains descriptions of emotional experiences and emotional discourse  (Achiam et al. 2023; Brown et al. 2020) . LLMs have been designed to interface with users with some knowledge of human emotion  (Wang et al. 2023) . From an evolutionary standpoint, universal human emotions, like fear, joy, and disgust, developed to solve unique sets of challenges faced by ancestral humans, and LLMs can learn about emotions through training.\n\nSpecifically, LLMs can be assessed on competencies in emotional intelligence, a construct that encompasses how people can respond strategically to and leverage their emotional experiences in productive ways, regardless of how Figure  1 : An example of EXPRESS and our emotion recognition evaluation framework is presented. Language models are prompted to predict masked emotions in the text. Both the predicted and self-disclosed emotion words are then decomposed into eight basic emotion dimensions and two sentiment dimensions. The differences between the predictions and the self-disclosed emotions at the dimensional level indicate that GPT-4 Turbo fails to accurately capture the emotions conveyed in human self-disclosures.\n\nadaptive or ill-suited to a modern-day situation an emotional reaction might initially be  (Brackett, Rivers, and Salovey 2011; Salovey and Mayer 1990) . While LLMs cannot possess complete emotional intelligence, their stochastic outputs can be evaluated in two of the four domains of emotional intelligence as posited by  Salovey and Mayer:  accurately perceiving what emotion is being expressed by a human via their written expressions of emotional disclosures; and demonstrating accurate analysis of what a human is likely experiencing given contextual cues (such as a person's situation, appraisals of that situation, and/or corresponding bodily responses). The extent to which frontier foundation models can perform such tasks is an empirical question. As shown in Figure  1 , the LLM's predicted emotions fail to align with self-disclosed emotions when asked to provide completions to various human experience prompts.\n\nAccurate emotion recognition has the potential to substantially enhance a broad spectrum of natural language processing (NLP) tasks. By integrating fine-grained affective understanding, dialogue systems can become more emotionally aware, thereby improving their capacity to comprehend and generate human-like emotions  (Liu et al. 2021b ). Moreover, emotion recognition facilitates quantitative analyses of social dynamics, such as political discourse, customer service, and public opinion mining. Finally, it also enables critical NLP-driven applications, including automated depression screening (Jurafsky and Martin 2024).\n\nSubstantial research efforts have been made to study the emotion recognition capabilities of LLMs. These studies usually focus on constructing various emotion recognition benchmarks from different data sources, domains, and emotion theories  (Strapparava and Mihalcea 2007; Chatterjee et al. 2019 ). However, current benchmarks face three main limitations. First, little attention has been given to the selfdisclosure of emotional experiences, with existing research typically relying on crowdsourcing or expert annotations to label emotions in text, which might lead to unreliable evaluations  (Singh, Caragea, and Li 2024; Sabour et al. 2024 ). Second, these studies are often limited by a short, predefined list of emotions, restricting their ability to capture fine-grained nuances in emotional experiences  (Feng et al. 2022) . Third, current benchmarks primarily focus on short sentences, contexts, or dialogues, neglecting the self-disclosure of emotions in longer contexts  (Demszky et al. 2020 ).\n\nTo address this gap, we construct a new benchmark, EXPRESS (EXperiences and PRocessed Emotions in Selfdisclosure Stories), which consists of 33,679 human experiences and their associated self-disclosed emotions. The assessment framework is illustrated in Figure  1 . In this framework, we mask emotion words in human self-disclosure texts and prompt the LMs to predict the masked words. To move beyond predefined emotion classes and evaluate models' emotion recognition capabilities at a finer granularity, we decompose the emotions into 10 dimensions of basic emotions and sentiments based on Plutchik's Wheel  (Plutchik 1980; Mohammad and Turney 2013) . Using EXPRESS, we benchmark the emotion recognition performance of 14 language models.\n\nOur results reveal that the emotion recognition capabilities of LMs correlate with model size, model family, model architecture, and prompting strategies. While the accuracy of predicting emotions at the lexical level is low, some LMs demonstrate the ability to capture the basic emotions underlying compound emotions, even when the predicted emotion word does not exactly match the label. Furthermore, we find that LLMs are capable of in-context learning for emotion recognition when provided with examples. We also find that, under the best settings, LLMs are able to generate emotions consistent with theoretical definitions, but they are sometimes less contextually \"aware\" than the emotions self-disclosed by humans. These findings are particularly valuable for the de-velopment of emotion-aware AI systems, especially in future mental health applications  (Hua et al. 2025; Ji et al. 2022; Adhikary et al. 2024) .\n\nThis paper makes the following contributions:\n\n• We present EXPRESS, a novel benchmark designed for emotion recognition that serves as a resource for evaluating models' emotion recognition capabilities and facilitating potential emotion alignment. • We propose a multi-faceted emotion recognition evaluation framework that encompasses multiple metrics: lexical accuracy, decomposed emotion vector accuracy, and contextual accuracy.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Related Work Emotion Taxonomy",
      "text": "While emotion theorists have nuanced definitions of emotions that may differ in their descriptions of emotional features, most agree that emotions are functional in preparing us to respond to perceived or real environmental stimuli  (Gross and Feldman Barrett 2011) . Theories of emotion define discrete emotional experiences or reactions to events (real or imagined) as representations that may include correlated physiological responses, appraisal processes, subjective feelings, and action tendencies  (Schiller et al. 2024) .\n\nMany theories of emotion are studied in the field of affective science, but computational models of emotion in NLP have primarily been based on two families of theories. The first views emotions as fixed atomic units, often referred to as basic emotions, while the second conceptualizes emotion as existing within a multidimensional space (Jurafsky and Martin 2024). Within the family of fixed atomic unit theories, one prominent theory proposes six basic emotions: surprise, happiness, anger, fear, disgust, and sadness  (Ekman et al. 1999) . Another theory, known as the Plutchik Wheel of Emotion, posits that emotions consist of eight basic emotions in four opposing pairs: joy-sadness, anger-fear, trust-disgust, and anticipation-surprise  (Plutchik 1980) .\n\nRecent advances in psychology have introduced new conceptual and methodological approaches to capturing the more complex \"semantic space\" of emotion, which aligns with the second family of theories  (Cowen et al. 2019 ). These models typically use two dimensions-valence and arousal-to describe emotions  (Russell 1980) . Some models further include a third dimension, dominance, to provide additional nuance in describing emotions  (Fontaine et al. 2007) .",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Emotion Recognition Benchmarks",
      "text": "Substantial datasets for emotion recognition exist, each with varying emotion label domains.  of emotion labels, average context length, and annotation methods.\n\nEmotion label coverage is often limited. Most datasets include only a small set of predefined emotion categories. For example, Emotion-Stimulus  (Ghazi, Inkpen, and Szpakowicz 2015) , Tales Emotions  (Alm and Sproat 2005) , and SemEval Task 14  (Strapparava and Mihalcea 2007)  rely on Ekman's six basic emotions  (Ekman et al. 1999) , sometimes supplemented with a few additional labels. XED  (Öhman et al. 2018 ) and EmoTrigger  (Singh, Caragea, and Li 2024)   ISEAR  (Scherer and Wallbott 1994)  is an exception that uses self-reported emotion events, but its ecological validity is limited by its collection method: participants were asked to describe experiences for a fixed list of seven predefined emotions, constraining natural emotional expression and overlooking subtle or more complex feelings. In addition, relying on external annotations limits the granularity of emotion labels.\n\nPrior research provides a foundation for assessing the emotion recognition capabilities of LLMs, though it faces the limitations mentioned above. Our work addresses these issues by scaling up context length to an average of 259 words and the range of emotion labels to 251. We use self-disclosed emotions as ground truth labels without external annotation because they are considered ecologically valid. As naturally occurring disclosures, they allow individuals to freely and authentically share their internal experiences, including emotional reactions to past events, without being constrained by predefined categories or researcher-led methods  (Pennebaker and Beall 1986; Frattaroli 2006; Davitz 2013) . Moreover, selfreport remains a cornerstone of methods for empirically investigating subjectively felt emotional experiences  (Mauss and Robinson 2009) , further supporting the use of self-disclosed emotions as ground truth. Additionally, our framework allows models to generate context-based, non-predefined emotions, ensuring sufficient variation in emotional nuances. Together, these improvements establish our dataset as an ecologically valid and fine-grained benchmark for evaluating emotion recognition capabilities in language models.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Express: A Comprehensive Benchmark For Emotion Recognition",
      "text": "Selection of an Emotion Lexicon. used in this paper is provided in the Appendix.\n\nCollecting self-disclosed experiences and emotions. Our primary objective is to assess whether LMs can predict emotions based on real-life nuanced experiences. To achieve this, we created prompts that embed a self-disclosed emotion.\n\nTo ensure we evaluate LMs in scenarios that mirror actual language usage, we construct our prompts from natural contexts that we retrieve from Reddit, rather than crowdsourcing prompts.\n\nBecause of its pseudonymity, Reddit is a popular platform for discussing real-life experiences. Reddit served as the primary data source due to its support for longer posts (up to 40,000 characters) which enabled the collection of rich and nuanced human experiences and the corresponding evoked emotions. The Reddit API Praw (Boe 2021) 1  was utilized to collect posts from all subreddits containing at least one emotion from the Berkeley Well-Being list. Emotion Masking. To mask the self-disclosed emotions in the collected posts, we designed a comprehensive regular expression protocol, as not all emotion keywords in a post are self-disclosed by the author. For example, the author might use emotion keywords to describe external events or other people's feelings rather than their own. Our protocol includes three main patterns: 'I feel + emotion', 'I am + emotion', and 'no-pronoun + feeling + emotion'. To make the algorithm robust to variations in natural language phrasing, we designed a series of rules, with details provided in Appendix.\n\nWe included the pattern 'feel' because prior work indicates that humans use the word 'feeling' interchangeably with 'emotion', even though feelings and emotions are not the same  (Davis 2024) . Feelings encompass both emotional experiences (e.g., feeling sad) and physical sensations (e.g., feeling hungry). This distinction justifies our use of the following pattern-matching formats: (I + feel/am + emotion) and (no-pronoun + feeling + emotion).\n\nDue to the context window size limitations of some language models and the fact that some posts are extremely lengthy, we segmented the posts into chunks of 512 tokens. During the segmentation process, we ensured that the context surrounding the target masked emotions was maximized. If multiple masked emotions existed, they were grouped based on their relative positions in the text. Table  A .1 in Appendix outlines the algorithm used to perform post segmentation.\n\nThe resulting dataset (EXPRESS) comprises 33,697 posts with an average word count of 259 per post. EXPRESS posts originate from 6,930 unique subreddits and span the time pe-riod from June 2009 -April 2024. More details of the dataset are provided in the Appendix  (Table A.2, Table A.3, Table A.4 ). Across the dataset, a total of 52,632 emotion words were identified covering 251 (92.62%) out of 271 Berkeley Well-Being emotions. We create prompts from EXPRESS by replacing the original emotion with a <mask> token. Table  2  depicts examples from our dataset.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Evaluating Emotion Recognition Capabilities Of Llms",
      "text": "Using EXPRESS, we measured the emotion recognition capabilities of 14 prevalent language models including four masked language models, three Seq2Seq language models, and seven causal language models.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Model Details",
      "text": "Using our dataset, we evaluated several variants of opensource and closed-source language models widely used in current research. We included four prevalent masked language models, as they are specifically designed for masked language modeling tasks. These models are RoBERTa-base  (Liu et al. 2019) , Longformer (Beltagy, Peters, and Cohan 2020), Mental-RoBERTa  (Ji et al. 2022) , and Mental-Longformer  (Ji et al. 2023 ), the latter two of which have been further pretrained on mental health-related corpora. For Seq2Seq language models, we included three models from the Flan-T5 family (large, XL, and XXL)  (Chung et al. 2024) . For causal language models, we focused on instruction-tuned models of varying sizes, as they are fine-tuned to follow instructions. These include Llama3.1-Instruct (8B, 70B)  (Grattafiori et al. 2024 ), Gemma2-Instruct (2B, 9B, 27B)  (Team et al. 2024) ,  GPT-3.5-turbo, and GPT-4o (OpenAI et al. 2024 ). The temperature was set to 0.0 for all experiments to minimize the effects of randomness.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Experimental Setup",
      "text": "We evaluated the performance of the four masked language models by directly filling in the masked emotions. For the remaining 10 models, we prompted them to predict the masked emotions based on the context. We designed the experiments with four different settings: zero-shot, few-shot with 4 random examples, few-shot with 4 nearest examples, and Chainof-Thought (CoT) prompting  (Wei et al. 2022) .\n\nThe zero-shot setting served as the basic test of the emotion recognition ability of LLMs based on self-disclosed emotional experiences. Models were directly instructed to predict the <mask> word with an emotion based on the context. The prompt template used in this setting is detailed in Appendix (Table  A .9).\n\nTo investigate whether LLMs can enhance their emotion detection ability by learning from examples, we included two few-shot settings. In both settings, we used four examples, as prior work has shown that using a larger number of exemplars does not significantly improve model performance  (Min et al. 2022) . Additionally, we ensured that the number of <mask> tokens in the exemplars matched that of the target post to avoid confounding effects. The first few-shot setting used four examples randomly selected from EXPRESS, while the second used the Bert-base-uncased model  (Devlin et al. 2019)  to compute sentence embeddings and applied Euclidean distance to find the four nearest examples to the Reddit posts  (Liu et al. 2021a) . By comparing these two settings, we aimed to explore whether providing similar experiences in the examples could further enhance the models' ability.\n\nStudies have shown that CoT prompting improves performance across a range of arithmetic, commonsense, and symbolic reasoning tasks  (Wei et al. 2022) . However, some studies have also suggested that CoT prompting may not enhance performance in socially sensitive domains, such as addressing harmful questions  (Shaikh et al. 2023) . In this work, we included the CoT prompting setting to examine whether it could further improve the models' ability to predict emotions.",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "Measuring Accuracy Of Emotion Recognition",
      "text": "To evaluate LMs' emotion recognition capabilities on a fundamental level, beyond calculating lexicon accuracy, we adopted the approach of the NRC Emotion Lexicon (EmoLex)  (Mohammad and Turney 2013) . EmoLex is a widely used resource that analyzes 14,182 unigrams and associates these unigrams, through crowdsourcing, with eight basic emotions-anger, anticipation, disgust, fear, joy, sadness, surprise, and trust-as well as with positive and negative sentiment. The associations are represented as binary scores (0 or 1), indicating whether a word is linked to a particular emotion or sentiment. We leveraged EmoLex to construct vector representations for each predicted and actual emotion. These vectors, as shown in Figure  1 , are 10-dimensional: 8 dimensions correspond to the basic emotions, and 2 represent positive and negative sentiment. By converting all words into these 10-dimensional vectors, we evaluated the modelpredicted emotions against the self-disclosed emotions on a basic emotion and sentiment level.\n\nDuring this process, some model-generated emotions were not included in the NRC Emotion Lexicon. To address this, we replicated EmoLex's crowdsourcing task on Amazon Mechanical Turk (AMT) to generate vector representations for these additional emotions. Further details are provided in Appendix  (Figure A.2) .\n\nWe evaluated the results using three metrics: (1) Lexical Accuracy (Acc L ), defined as the percentage of exact lexical matches (N lm ) from all masks (N ):\n\n(2) Vector Accuracy (Acc V ), defined as the percentage of exact vector matches (N vm ) between the 10-dimensional basic emotion vectors for the predicted and actual emotions across all masks: Acc V = N vm /N ; and (3) Average Vector F-1 score (F 1 V ), which balances precision and recall to evaluate the model's ability to predict each dimension of the 10-dimensional emotion vector. More details on the F1-score calculation for vectors are provided in the Appendix section titled Evaluation Metrics.\n\nWe included Acc V as a metric because predicted and actual emotions may not align lexically due to the diversity of emotion vocabulary but could still match at the basic emotion level. For example, 'angry' and 'furious' share the same emotion vector but are two different labels lexically. A higher Acc V indicated greater alignment between the actual and predicted emotions. Similarly, F 1 V was included to assess how closely the predicted emotions approximated the selfdisclosed ones, even when there was no exact match across all dimensions.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Results",
      "text": "Here, we present our findings on the emotion recognition capabilities of LLMs evaluated on the EXPRESS dataset.\n\nFine-Grained Emotion Alignment is Challenging for LMs. Models demonstrated significant variability in their ability to predict emotions from emotional experiences in the zero-shot setting, as shown in Table  3 . Acc L ranged from 0.051 to 0.318, while Acc V , slightly higher, ranged from 0.097 to 0.388. F 1 V ranged from 0.434 to 0.711, compared to a baseline of randomly generated vectors at 0.322. Overall, the results show that it is challenging to predict human self-disclosed emotions from emotional experiences. The substantial number of emotion words, along with the similarity and overlapping nature of some emotion terms, may contribute to the low Acc L . However, Acc V , which evaluates the decomposed vectors of emotion terms, remains relatively low, increasing by only about 0.06 on average. This indicates that for most models, language models fail to align with human self-disclosed emotions on at least one basic emotion or sentiment dimension in the majority of predictions.\n\nSome models, such as Flan-T5-large, XL, and Gemma2-2B, have Acc V around 0.1, meaning they can only accurately predict around 10% of the emotions. Their F 1 V ranges from 0.4 to 0.5, which, although higher than randomly generated vectors, indicates their limited ability to correctly predict emotions. On the other hand, some models demonstrate relatively better emotion recognition ability, including the four masked language models, Llama-3.1-70B, Gemma-2-27B, and GPT-4o. These models achieve Acc V over 0.3 and F 1 V exceeding 0.6, indicating a certain degree of alignment with self-disclosed emotions or, at the very least, some aspects of them. Model Family and Size Matter. Although the tested language models do not achieve either Acc L or Acc V higher than 0.4 under zero-shot settings, the emotion recognition performance varies significantly between models, as shown in Figure  2 . Three factors appear to have the most significant impact on performance: Model Architecture, Model Family, and Model Size.\n\nThe four masked language models are all ranked among the top seven models in both accuracy metrics, despite having far fewer parameters (RoBERTa with 125M and Longformer",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "With 149M",
      "text": "). This may be due to their specialization in maskfilling tasks: they are specifically designed and trained to fill masks and do not need to interpret complex prompts as Seq2seq or causal language models do. In Seq2seq and causal language models, the model family plays a crucial role. For example, with similar model sizes, Flan-T5-xxl, Llama3.1-8B, and Gemma-2-9B exhibit vastly different Acc L , Acc V , and F 1 V scores. Flan-T5-xxl and Gemma2-9B have differences of 0.156, 0.174, and 0.135 in Acc L , Acc V , and F 1 V , respectively. GPT-3.5-turbo, despite having 175B parameters, performs worse than smaller models such as Llama-3.1-70B and Gemma-2-27B.\n\nAnother key factor influencing performance is model size. Within all model families-Flan-T5, Llama-3.1, Gemma-2, and GPTs-the ability to predict emotions improves consistently as the number of parameters increases, without exception. Interestingly, the best-performing causal language model, GPT-4o, with 1.75T parameters, performs similarly to the three masked language models. This highlights the significant gap in mask-filling ability between masked language models and causal language models in emotion recognition tasks. The Wilcoxon Signed-Rank tests were conducted, and the results are shown in Table  A .11. Chain of Thought Doesn't Help Models Predict Emotions. Studies show that CoT prompting enables models to reason step by step to arrive at the final answer and has been proven to improve performance on various NLP tasks  (Wei et al. 2022) . Given that most emotional experience texts in our dataset are long (259 words per post on average), leading models to reason step by step might be a potential way to achieve higher performance. To test this, we adapted CoT prompting by instructing models to \"Think step by step\"  (Kojima et al. 2022) . The prompts we used are shown in the Appendix (Table A.9).\n\nHowever, as Table  3  shows, for all seven tested models across three model families and various sizes, performance consistently worsened, with average decreases of 0.039, 0.037, and 0.026 for Acc L , Acc V , and F 1 V , respectively. The only models unaffected were GPT-4o and Llama-3.1-8B. Notably, for the three Gemma-2 models, regardless of size, the models' ability to respond in the correct format as instructed deteriorated significantly, dropping from an average of 99.9% to 76%. The Wilcoxon Signed-Rank tests were conducted and the results show that all models, except for these two, perform statistically significantly worse under CoT settings (p < 0.001). For smaller models, such as Gemma-2-9B, CoT prompting sometimes caused them to deviate from the original instruction and fail to respond with emotion words. For larger models, while CoT prompting did not reduce the rate of valid responses, overall performance declined. This aligns with prior findings  (Shaikh et al. 2023) , suggesting that CoT may underperform in socially situated tasks. It also echoes recent work  (Chochlakis et al. 2025) , which found that CoT fails to improve outcomes in complex, context-sensitive, and subjective tasks, particularly for larger models, which tend to rely heavily on their built-in prior knowledge, potentially leading them to overlook or disregard the specific context provided in the prompt. Error Analysis. To better understand the details of the prediction errors, we conducted an error analysis on the bestperforming causal language models: Llama-3.1-70B-Instruct, Gemma-2-27B-It, and GPT-4o. We observed a significant difference between the distribution of emotion words used in human self-disclosures and those predicted by the models. Humans tend to use emotion words such as happy, scared, sad, tired, and embarrassed, whereas the models frequently overused emotion words such as anxious, grateful, overwhelmed, ashamed, frustrated, and relieved, as shown in Figure  A .3 in the Appendix.\n\nAmong the most common mispredictions, errors frequently occur when the model predicts a similar but distinct emotion, or one with a different intensity. For example, models often predict grateful, a deeper and more enduring emotional expression, when the true label is thankful. They also tend to overuse words like frustrated and anxious to represent a wide range of emotional experiences, whereas humans express these emotions more diversely and subtly in these cases using words like disheartened, demoralized, irritated, annoyed, restless, panicked, agitated, and stressed. Additionally, models often reduce emotional intensity by predicting angry instead of furious, or afraid instead of terrified. Table  A .6 in the Appendix presents the normalized mispredictions commonly made by these three models.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Impact Of Dataset Segmentation On Model Performance",
      "text": "When constructing EXPRESS, we segmented long posts into segments of 512 tokens to ensure a fair and consistent evaluation across LLMs with different context length. However, this segmentation may limit the ability of LLMs with extended context windows, like GPT-4o to fully utilize their contextual reasoning capabilities, potentially underestimating their performance. To assess this trade-off, we conducted an additional analysis comparing model performance on segmented versus full posts. We randomly sampled 1,000 posts from the EXPRESS and evaluated GPT-4o, our best-performing model with a 128k-token context window, on both settings.\n\nAs Table  4  shows, despite a substantial increase in post length (approximately 1,000 additional words), performance remained effectively unchanged across all metrics. This suggests that a 512-token context window provides sufficient context for models to make comparable decisions on this task. Post segmentation not only ensures a fair and consistent evaluation across LLMs with different context lengths, but also does not disadvantage models with larger context capacities in this setting. Are Models Good Learners of Emotions?\n\nOur results in the previous section indicate that accurately predicting self-disclosed emotions based on emotional experiences remains a challenge for language models, both at the lexical level and the basic emotion vector level. Even the bestperforming models, including the four masked language models, Llama-3.1-70B-Instruct, Gemma-2-27B-Instruct, and GPT-4o, incorrectly predict at least one basic emotion dimension in the emotion vector for nearly 65% of instances. However, most language models are neither designed nor trained specifically for emotional intelligence tasks, such as emotion recognition. As a result, they may lack the implicit capacity to predict emotions in a human-like manner. Therefore, it is crucial to examine whether LLMs can learn and improve their emotion detection capabilities. Demonstrating this potential would highlight their utility in assisting mental health-related tasks, particularly when specifically designed and trained for such applications. To evaluate this, we established two few-shot experimental settings.\n\nThe two few-shot settings use different strategies to select examples. The first setting is designed to examine whether LLMs can learn from random examples of emotions, serving as a baseline. The second few-shot setting is designed to assess whether LLMs learn better when provided with examples of similar emotional experiences. To achieve this, we use the BERT-base-uncased model  (Devlin et al. 2019)  to compute sentence embeddings and apply cosine similarity to identify the four nearest examples to the test query as few-shot examples. Result As shown in Table  3  and Figure    3 , all tested LLMs demonstrate improved emotion recognition ability when exposed to random examples. The average improvements in Acc L , Acc V , and F 1 V are 0.032, 0.042, and 0.006, respectively. Similar to, but even better than, the first few-shot setting, the few-shot setting with the nearest distanced examples further boosts the models' performance on emotion recogni- tion. This setting outperforms the first setting for all models, with average improvements in Acc L , Acc V , and F 1 V of 0.045, 0.053, and 0.011, respectively, compared to the zeroshot setting. This indicates that models can learn better when exposed to examples with similar emotional experiences. The improved results of the two few-shot settings demonstrate the ability of models to learn from provided examples, indicating their potential to become more emotionally aware in future training and adapt to mental health applications.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Human Evaluation Of Predicted And Actual Emotions",
      "text": "To contextualize our empirical evaluation of LMs' emotion recognition capabilities across the previous experiments, we conducted a qualitative analysis of a subset of the predicted (by LLMs) and actual emotions. Our first research objective was to assess which emotion (predicted/actual) would be picked by a domain emotion expert as being more plausible, or consistent with academic theory and empirical research about emotion experience.\n\nOur second research question was: \"How might a domain expert in emotion research determine that a certain emotion fits the natural contexts in the posts (e.g., select an LLMgenerated vs. ground truth emotion as being accurate)?\" Essentially, we aim to compute a form of contextual accuracy to assess whether the predicted or ground truth emotion aligns with the local context of the text. Hence, we perform a qualitative analysis on a small subset of our dataset to compute this contextual accuracy, utilizing human evaluation by three emotion experts, whose backgrounds are detailed in the Human Evaluation section of the Appendix.\n\nWe framed this task as a Turing test  (Turing 2009) , aiming to see if an LLM can mimic human emotional intelligence by attempting to deceive the emotion experts into selecting the LLM's output over the self-disclosed emotion. To maximize the challenge, we utilize the best-performing model's outputs (GPT-4o with few-shot-nearest setting) for this task.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Setup",
      "text": "Our sample includes 213 EXPRESS posts, the associated selfdisclosed emotions, and the corresponding predictions from the best-performing model. We selected the posts where the emotions predicted by the LLM differ from the self-disclosed emotions at the vector level. We randomized the order of presenting predicted or actual emotions first, and asked the coders to read each post and select one of the following options without knowing which options were predicted or actual: (1) self-disclosed emotion (SD), (2) LLM-generated emotion (LLM), (3) both emotions equally fit (BOTH), and (4) neither emotion fits (NEITHER). For clarity, it is important to note that selecting one emotion does not necessarily imply that the other option is unsuitable; rather, it indicates that the chosen emotion is preferred by the coders.\n\nIn the next phase, one coder went through all samples and provided rationales for their selections. Open coding (Khandkar 2009) was then conducted on the rationales to understand what the common themes were to justify the selections made, as presented in Table  A .7 in Appendix. The codes were then presented to the other coders, who were also free to add additional codes; however, no additional codes were introduced.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Results",
      "text": "Two coders selected LLM over SD more frequently, while the third coder selected SD more often. We used a majority vote to aggregate the results from the three coders. Overall, SD was selected 89 times (40.0%), whereas LLM was selected 97 times (43.7%). The coders also considered BOTH emotions plausible 5 times (4.7%), and there were 22 instances (11.6%) where all three chose different options. However, given the subtle distinctions between emotions, agreement among the coders was relatively low, with only 36.2% of the samples receiving unanimous selection and a Fleiss' Kappa score of 0.21 (fair agreement).\n\nWe aggregated the codes from the three coders and reported the frequency of codes in Table  A .7 in the Appendix. The most common reason for coders selecting the SD emotions was that the selection better matched other terms providing context for the affective experience (Code 3, N=101). The second most common reason was that the selection was judged as better fitting the degree of specificity in the affective experience being described (Code 2, N=39). For the LLM emotions, the most common reasons were similar (Code 2, N=69; Code 3, N=58, and Code 5, N=57). However, when choosing SD, Code 3 was significantly more frequent (36.4%), indicating that coders believed SD emotions were more contextually appropriate in many cases. In contrast, when choosing LLM, Code 2 and Code 5 were significantly more frequent (23% and 19%), suggesting that coders preferred LLM-generated emotions due to their higher specificity in describing the affective experience and better alignment with emotion definitions and theories. Examples of code selections and the corresponding rationales are presented in Table  A .8.\n\nOur results unexpectedly show that experts slightly preferred the LLM's predicted emotions over the self-disclosed emotions. The low agreement between coders further reveals that both SD and LLM-generated emotions are plausible, differing primarily in nuanced ways. This finding highlights the inherent complexity and subtlety of our task, where human understanding and expression of emotions are highly subjective, shaped by an individual's unique experiences, personality, emotion granularity, and perspective. This pattern of findings, across the three coders, suggests that while our best-performing LLM is able to generate emotions consistent with theoretical definitions and convincing as being appropriate, there are also instances where LLM may miss important contextual cues in the excerpts that may seem intuitive to human coders. However, it is important to note that these findings are specific to the best-performing model under optimal settings, which may represent the upper bound of LLM performance. Further investigation is needed to explore whether, in such cases where a human coder can articulate how an important clue in an excerpt is \"missed\" by the LLM, the LLM is making \"errors\" (such as by not accounting for certain information) or registering the contextual information but making predictions based on different information within the excerpt, potentially relying on \"internal world modeling\" specific to the LLM.",
      "page_start": 8,
      "page_end": 9
    },
    {
      "section_name": "Conclusion",
      "text": "Higher emotional understanding and prediction abilities in LLMs are crucial for empathetic interactions  (Mayer and Geher 1996) , as users often prefer models that align with their beliefs  (Kirk et al. 2024) . Misjudging or failing to respond empathetically in dialogue can lead to user discomfort  (Ball and Breese 2001) . However, existing benchmarks are limited by unreliable labels, a narrow range of emotion categories, and short emotional contexts.\n\nTo address these gaps, we constructed EXPRESS, an emotion recognition dataset created by masking self-disclosed emotions in Reddit posts. Our systematic evaluation revealed that LLMs still face challenges in aligning with human emotional expressions. Performance varied across model architectures and families, with consistent improvements as model size increased. Notably, while model performance varied among model families, masked language models performed comparably to some larger causal language models, such as GPT-4o. Given their significantly smaller model sizes, they offer a cost-effective alternative with similar performance.\n\nWe also tested whether CoT prompting improves LLM performance. Our findings, consistent with prior work  (Shaikh et al. 2023; Chochlakis et al. 2025) , show that CoT degrades performance in subjective tasks, possibly due to models relying too heavily on prior knowledge instead of contextual cues. Few-shot prompting, however, showed promise, indicating that with targeted design and exposure, LLMs can improve their emotion recognition performance even without explicit emotion-task training.\n\nFor the qualitative analysis, future research could explore how the affective terms predicted by LLMs differ from selfdisclosed emotions and how expert observations might be used to fine-tune models for improved emotion recognition. The analysis also shows that LLM-generated emotions were preferred by experts half of the time, suggesting that GPT-4o, under the best settings, has the ability to generate reasonable emotions that fit the context. However, the error analysis and qualitative analysis reveal that while LLM emotions are sometimes more specific than SD emotions and consistent with emotion theories, they can also be overly general, frequently predicting common emotions such as 'anxious' or 'frustrated.' Moreover, LLMs are sometimes less effective at capturing contextual cues than SD emotions. These findings, along with the low alignment with SD emotions, highlight the importance of self-disclosed emotions in fine-grained emotion recognition tasks, which not only serve as a benchmark for evaluation but also provide valuable training material to improve model alignment.\n\nOur benchmark and evaluation framework offer a systematic way to assess LLMs' capacity to understand and predict fine-grained, self-disclosed emotions. While our setup is intentionally controlled, it provides foundational insights into how models handle nuanced emotional expressions, a prerequisite for deployment in sensitive, real-world applications such as mental health support tools or social media moderation. As these applications demand accurate emotion recognition, models that underperform in our benchmark may require further careful examination before being reliably applied in such contexts.",
      "page_start": 9,
      "page_end": 10
    },
    {
      "section_name": "Limitations",
      "text": "Diversity in emotion expression. While our research provides valuable insights into emotion recognition, it is primarily focused on neurotypical ways of expressing emotions. This limitation highlights the need for further research to explore and understand how emotional expressions may differ in neurodivergent populations, as differences in emotional expression are well-documented  (Trevisan et al. 2017) . Expanding the scope of future studies to include a more diverse range of emotional expressions will help create more inclusive models and improve the accuracy and applicability of emotion recognition systems across different populations  (Mazefsky, Pelphrey, and Dahl 2012) . Bias in User Demographics. Reddit's user base is not fully representative of the general population. Studies have shown that Reddit users are predominantly male, young adults, with a strong representation from North America and Europe  (Barthel et al. 2016; Singer et al. 2014) . This demographic bias may influence the types of emotions expressed and the language used on the platform. Thus, fine-tuning models on EXPRESS may not generalize well to other populations, leading to potential biases in the emotion recognition model when applied to more diverse or global datasets. Future work could broaden the demographic coverage by incorporating data from other platforms, such as Quora, or region-specific platforms like Zhihu (Chinese) in other languages. Future work can also oversample specific subreddits to target different demographic groups, such as r/askwomen for women and r/over60 for older adults. Limitations to Human Evaluation Approach. There are few, if any, real-world scenarios where a person would be tasked with predicting the emotion term that an emotionexperiencer would express via a written vignette. Rather, real-world scenarios involve some discussion and clarifying questions for an individual to learn about what a person might be feeling or have experienced in the past (e.g., emotional disclosure to a friend, or a therapist). A task similar to the one in this study is a subscale of an emotional intelligence measure in which participants determine what emotion a person is feeling based on a scenario described. However, this task uses standardized vignettes developed by researchers, rather than disclosed in colloquial terms by everyday people. As suggested by the instances where both the self-disclosed and LLM terms were considered by the expert as plausible colloquial descriptions of affect, there may be cases where a term cannot be predicted by a human (at least without more context provided). Furthermore, future work could include further refinement through iterative codebook development and discussions to improve agreement among coders.",
      "page_start": 9,
      "page_end": 10
    },
    {
      "section_name": "Ethics Statement",
      "text": "Emotion detection ability in LLMs could bring significant benefits to mental health applications. It would allow for the automation of mental health services, directing individuals to appropriate and personalized resources. This approach could enhance the accessibility of mental health support, particularly for vulnerable populations, such as ethnic minorities, where seeking help is often more stigmatized compared to majority groups  (Stade et al. 2024; Habicht et al. 2024) . However, there are potential risks as well. With increased emotional intelligence, large language models might become more persuasive, increasing the potential to manipulate vulnerable populations. Additionally, LLMs tend to be sycophantic  (Sharma et al. 2024) , and their emotional intelligence may lead them to better align with a human's opinions and sentiments. This personalization carries risks, as it can reinforce the user's existing beliefs  (Kirk et al. 2024 ). Consequently, LLMs may avoid suggesting mental health resources that fall outside the user's comfort zone, instead adhering to assumptions based on the user's prompts and selectively presenting information that reflects the user's biases and beliefs.\n\nThe annotations used to obtain the basic emotion vectors for Plutchik's eight basic emotions were crowd-sourced, with workers receiving $0.10 per assignment, ensuring that compensation complied with the minimum wage requirements in the authors' location. Each HIT allowed sufficient time of 3 minutes for completion, aligned with the number of questions included. To ensure quality, only workers with a HIT approval rate of 95% or higher, at least 5,000 approved HITs, and who passed a task-specific qualification test were allowed to perform the annotations. We also recruited one domain expert on Upwork for qualitative analysis, compensating the expert at $30 per hour, with the entire evaluation process taking 11 hours. To maintain data anonymity, we discarded post IDs and account names before feeding the posts into the LLMs. Our dataset is self-annotated, strictly extracting emotions explicitly expressed by the post author. as basic emotions. Plutchik's wheel of emotion  (Plutchik 1980 ) consists of 8 discrete emotions: joy, sadness, anger, fear, trust, disgust, anticipation, and surprise. Another similar theory is Ekman's basic emotions  (Ekman, Sorenson, and Friesen 1969) , consisting of 6 basic emotions: happiness, anger, fear, sadness, disgust, and surprise. On the other hand, some theories view emotions in a multi-dimensional space, such as Russel's Circumplex model of affect  (Russell 1980 ). The VAD model places emotions among dimensions of valence, arousal, and dominance. Valence, arousal, and dominance are dimensions used to describe emotions: valence indicates the positivity or negativity of emotion, arousal reflects the intensity of emotional activation, and dominance measures the degree of control or influence an emotion exerts over an individual  (Russell 1980) .\n\nMany works use these theories as a basis to create lexicons for emotion. Popular lexicons include the NRC Word-Emotion Association Lexicon, also known as EmoLex (Mohammad and Turney 2013), and the NRC Valence, Arousal, and Dominance lexicon  (Mohammad 2018) .",
      "page_start": 10,
      "page_end": 11
    },
    {
      "section_name": "Emotion Masking Algorithm",
      "text": "We included the pattern 'feel' because prior work indicated that humans use the word feeling' interchangeably with emotion, even though feelings and emotions are not the same  (Davis 2024) . Feelings encompass both emotional experiences (e.g., feeling sad) and physical sensations (e.g., feeling hungry). This distinction justifies our pattern-matching format (I + feel/am + emotion) or (no-pronoun + feeling + emotion). Up to three words can be added between 'I' and 'feel/am', and between 'feel/am' and the emotion, allowing the patterns to capture cases where extra words such as adverbs are present. For example, the word 'angry' in the phrase 'I have felt extremely angry' will be masked.\n\nIn addition to these basic patterns, several guidelines were introduced to ensure the accuracy of masking self-disclosed emotion words:\n\n1. We avoided masking the word if there is a pronoun, noun, or verb between 'feel' and the emotion word, to exclude phrases like 'I feel he was sad.' 2. We avoided masking the word if there is an interrogative word between 'feel' or 'am' and the emotion word, to exclude phrases like 'I feel how happy he is.'\n\n3. For the 'I am' pattern, we ensured that the emotion word is an adjective.\n\n4. Finally, we performed a manual review to filter out posts that did not satisfy the conditions but were not detected by the protocol.",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Post Segmentation",
      "text": "We segment the posts into chunks of 512 tokens using RoBERTa tokenizer due to input context length constraints of RoBERTa and Longformer. Table  A .1 outlines the algorithm used to perform post segmentation.",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "Evaluation Metrics",
      "text": "The F1-score for a vector v i is computed as:\n\nwhere:\n\nHere, TP i , FP i , and FN i represent the true positives, false positives, and false negatives for the prediction of the ten dimensions in vector v i , respectively.\n\nThe final F1-score across all vectors is obtained by averaging the vector-level F1-scores:\n\nwhere n is the total number of vectors.",
      "page_start": 14,
      "page_end": 14
    },
    {
      "section_name": "Topic Modeling",
      "text": "We use BERTopic to perform topic modeling on our dataset. BERTopic leverages document embeddings, reducing their dimensionality before clustering them  (Grootendorst 2022) .\n\nTo optimize our model's performance, we conducted hyperparameter tuning on the HDBSCAN algorithm.  2  The highest coherence score (C v ) achieved was 0.494, with a min_sample value of 3 and a min_cluster_size of 100, as illustrated in Figure  A .1. This configuration resulted in the identification of 49 distinct topics, which are detailed in Table  A .5, including the top four representative words and qualitative labels assigned to each topic.\n\nWe conducted similar topic modeling on other datasets if they did not report topic diversity and presented the results in Table  1 .",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "Human Evaluation",
      "text": "Coder Background. All three of our coders are domain experts with Ph.D. degrees in related fields: Step 4: Create segments around centroids For each centroid, create a segment by selecting tokens around this central position. Take n/2 tokens to the left and n/2 tokens to the right of the centroid to create a segment of n tokens in total (510 tokens).\n\nStep 5: Clip the segments Ensure that each segment makes sense contextually by clipping the segment to sentence boundaries. Clip the segment slightly to align with the nearest sentence-ending characters.\n\nStep 6: Return the segments Once all [MASK] token groups have been segmented and clipped, return the list of these segments as the output. The rest of the gallery erupted in cheers and applause as the judge handed down the death sentence and I too felt a wave of <mask> that this monster would face justice. I recognized the fairness of the court, but hounded by an agonizing regret I also wondered where I went wrong and longed bitterly for a do-over for the little boy my son had once been.\n\nrelief I feel so <mask> when there's no one beside me, as long as someone is there, a friend or a boyfriend nor a group of friends. I feel good and <mask>.\n\nThe minute am alone it starts to feel lonely, like I have no one in the world.",
      "page_start": 13,
      "page_end": 14
    },
    {
      "section_name": "Lonely, Cheerful",
      "text": "I just finished a two-year solo project and I feel <mask> and depressed at the same time. I'm playing with my app now ... it's alive! A ton of research, scrounging, all night coding around family life. Learned a ton, aged a lot but it was something I had to do after all those years of working on someone else's project. I'm so <mask> but I feel this weird sense of depression at the same time. A sort of loss. Since I'm a solo keyboard warrior, I guess you guys are the ones with whom I sharing this weird feeling(s).",
      "page_start": 14,
      "page_end": 14
    },
    {
      "section_name": "Elated, Happy",
      "text": "Lately I feel immense <mask> for my life and I wish I knew who to thank. Lately I feel overwhelmingly <mask> for the good things that have come into my life. I even feel <mask> for some of the bad things that have happened to me in the last couple years, because without those I wouldn't be a person ready to accept the good things that are happening lately. I don't believe in God but I quite often throughout my life feel that there is some energy looking out for me. Someone who has my best interest at heart and has the wisdom and ability to nudge me in the directions I need to go. Not always the directions I want to go, but always the ones I need. I wish I knew who that was, so I could thank them.\n\ngratitude, grateful, grateful",
      "page_start": 14,
      "page_end": 14
    },
    {
      "section_name": "Prompt Design",
      "text": "We manually tested multiple prompt variations, using accuracy score as a metric to assess performance improvements. Multiple prompt variations were tested, with accuracy score serving as the primary metric for evaluation. Our final prompt, which achieved the highest accuracy on our sample dataset, is detailed in Table A.9. A critical consideration in our design was the definition of  \"emotion\". We observed that providing an explicit definition of \"emotion\" often constrained the model's output, limiting it to a narrow set of predefined emotion terms. This conflicted with our objective of allowing the model to generate contextually appropriate emotion terms. To address this, we adopted a more flexible approach that avoids explicitly imposing a strict definition of emotions. This approach enables the model to capture nuanced emotional expressions without being restricted to predefined categories.",
      "page_start": 14,
      "page_end": 14
    },
    {
      "section_name": "Amazon Mechanical Turk Annotation",
      "text": "Figures A.2 include screenshots of the user interface created for workers to provide annotations for the 10 dimension emotion vector.",
      "page_start": 15,
      "page_end": 15
    },
    {
      "section_name": "Statistical Modeling",
      "text": "We conducted a Wilcoxon Signed-Rank Test to compare the LLMs' performance across the zero-shot, CoT, and two fewshot settings. This statistical test was applied to determine whether LLMs in the few-shot setting performed significantly better than those in the zero-shot setting, as well as whether the CoT setting performed significantly worse than the zeroshot setting. The LLMs, along with their corresponding pvalues and Cohen's d, are presented in Table  A .10. In most cases, the few-shot settings outperform the zeroshot setting, while CoT settings perform worse than zero-shot. Only two settings do not show a significant difference from zero-shot: Llama-3.1-8B-instruct under the CoT setting and Llama-3.1-70B-instruct under the few-shot (random) setting. Additionally, the few-shot (nearest) setting consistently yields higher Cohen's d scores across all conditions.\n\nTo compare of performance of different models under zeroshot setting, we also conducted Wilcoxon Signed-Rank Tests across models. The results are presented in My sister just suffered an ectopic pregnancy. I feel guilty for being thankful that it happened before her state banned abortion. Yesterday my pregnant sister was rushed to the ER with excruciating pain. She was 7 weeks pregnant. Once they realized she had an ectopic pregnancy, the doctors gave her the medicine to stop it. Luckily, my sister is fine, nothing ruptured. I am <mask> but also lividwhat if this happened four weeks later? What if the doctors didn't give her the proper care, so my sister had to endure the pain and potentially put her life at risk? What if it causes her to never have children again? All because of the Supreme Courts f*cked up decision to overturn Roe v Wade. label: sad, predicted: relieved Code 2 (N SD = 39, N LLM = 69): Terms have similar valence (positive/pleasant or negative/unpleasant) but the selection was judged as better fitting the degree of specificity in the affective experience being described (more general vs. more specific) Am I a bad friend for feeling <mask> that my friend is replacing me? for the longest time, ive been really close to one of my friends. we always gossip together, go everywhere together, and do so many things together. unfortunately shes struggled with making friends for a really long time but recently shes been doing really well and making new friends and ive felt really proud of her. a friend of mine was hanging out with the both of us and the friend of mine had brought another friend. the friend of the friend has instantly clicked with my close friend and they were almost inseparable afterwards. i feel like i shouldnt feel sad that shes getting closer to other people but she doesnt really talk to me when the other girl is there. label: upset, predicted: jealous",
      "page_start": 15,
      "page_end": 16
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: An example of EXPRESS and our emotion recogni-",
      "page": 1
    },
    {
      "caption": "Figure 1: , the LLM’s predicted emotions fail to align with",
      "page": 2
    },
    {
      "caption": "Figure 1: In this frame-",
      "page": 2
    },
    {
      "caption": "Figure 1: , are 10-dimensional: 8",
      "page": 5
    },
    {
      "caption": "Figure 2: Three factors appear to have the most signifi-",
      "page": 5
    },
    {
      "caption": "Figure 2: A comparison of model size, family, and emotion detection vector accuracy. The results show that model performance",
      "page": 7
    },
    {
      "caption": "Figure 3: , all tested LLMs",
      "page": 7
    },
    {
      "caption": "Figure 3: A comparison of zero-shot results and the other",
      "page": 8
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Post Segmentation Algorithm": "Step 1: Initialize grouping of [MASK] tokens\nStep 1.1: Traverse through the tokens of the post one by one.\nStep 1.2: Whenever a [MASK] token is encountered, start a new group if it’s the first one, or add it to the current group if it’s the first [MASK]\ntoken found."
        },
        {
          "Post Segmentation Algorithm": "Step 2: Group nearby [MASK] tokens\nStep 2.1: Check the distance between the current [MASK] token and the last [MASK] token in the current group.\nStep 2.2: If the distance is less than or equal to 235 tokens, add this [MASK] token to the current group.\nStep 2.3: Else, finalize the current group and start a new group with this [MASK] token."
        },
        {
          "Post Segmentation Algorithm": "Step 3: Compute centroid for each [MASK] group\nFor each group of [MASK] tokens, calculate the mean position by averaging the positions of all [MASK] tokens in that group."
        },
        {
          "Post Segmentation Algorithm": "Step 4: Create segments around centroids\nFor each centroid, create a segment by selecting tokens around this central position. Take n/2 tokens to the left and n/2 tokens to the right of the\ncentroid to create a segment of n tokens in total (510 tokens)."
        },
        {
          "Post Segmentation Algorithm": "Step 5: Clip the segments\nEnsure that each segment makes sense contextually by clipping the segment to sentence boundaries. Clip the segment slightly to align with the\nnearest sentence-ending characters."
        },
        {
          "Post Segmentation Algorithm": "Step 6: Return the segments\nOnce all [MASK] token groups have been segmented and clipped, return the list of these segments as the output."
        }
      ],
      "page": 14
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Category": "Applies\nto\nSD\nand\nLLM",
          "Qualitative Code Description": "Code 1 (NSD = 24, NLLM = 19): Valence (positive/-\npleasant or negative/unpleasant) matched the context of the\nsituation and/or the affective reaction described (N=18)",
          "Example": "My sister just suffered an ectopic pregnancy. I feel guilty for being thankful that it happened before\nher state banned abortion. Yesterday my pregnant sister was rushed to the ER with excruciating\npain. She was 7 weeks pregnant. Once they realized she had an ectopic pregnancy, the doctors gave\nher the medicine to stop it. Luckily, my sister is fine, nothing ruptured. I am <mask> but also livid -\nwhat if this happened four weeks later? What if the doctors didn’t give her the proper care, so my\nsister had to endure the pain and potentially put her life at risk? What if it causes her to never have\nchildren again? All because of the Supreme Courts f*cked up decision to overturn Roe v Wade.\nlabel: sad, predicted: relieved"
        },
        {
          "Category": "",
          "Qualitative Code Description": "Code 2 (NSD = 39, NLLM = 69): Terms have similar\nvalence (positive/pleasant or negative/unpleasant) but the selec-\ntion was judged as better fitting the degree of specificity in the\naffective experience being described (more general vs. more\nspecific)",
          "Example": "Am I a bad friend for feeling <mask> that my friend is replacing me? for the longest\ntime,\nive\nbeen really close to one of my friends. we always gossip together, go everywhere together, and do\nso many things together. unfortunately shes struggled with making friends for a really long time\nbut recently shes been doing really well and making new friends and ive felt really proud of her.\na friend of mine was hanging out with the both of us and the friend of mine had brought another\nfriend.\nthe friend of the friend has instantly clicked with my close friend and they were almost\ninseparable afterwards. i feel like i shouldnt feel sad that shes getting closer to other people but she\ndoesnt really talk to me when the other girl is there.\nlabel: upset, predicted: jealous"
        },
        {
          "Category": "",
          "Qualitative Code Description": "Code 3 (NSD = 101, NLLM = 58): Selection better\nmatches other term(s) providing context of the the affective\nexperience",
          "Example": "Feel hatred for family sometimes. Like, when I say I’m <mask> or depressed. They tell me \"then\nchange it\" like there’s some f*cking switch you can flip and it all gets better. I’m working my body\nand brain into dust just to make rent. It ain’t like the movies folks, the people closest to you cut the\ndeepest\nlabel: unhappy, predicted: frustrated"
        },
        {
          "Category": "",
          "Qualitative Code Description": "Code 4 (NSD = 20, NLLM = 37): Degree of intensity\n(greater or lesser) of the selection is better matched to or re-\nflective of typical responses to the scenario described",
          "Example": "I feel so <mask>. I need advice please. I was in school I I’ve gotten a weird feeling like I was about\nto throw up, well I did not but there was this loud sound of like choking or something (?) I just\nheard people giggle in the back what do i do now? Please give me some advice i feel horrible right\nnow\nlabel: humiliated, predicted: embarrassed"
        },
        {
          "Category": "",
          "Qualitative Code Description": "Code 5 (NSD = 25, NLLM = 57): Selection better fits a\ndefinition of the emotion described in the scenario, as proposed\nby a peer-reviewed published theory/definition of the emotion",
          "Example": "I feel riddled with <mask> about whether hrt will be illegal within the near future, how can I\ndeal with this? The far right has been launching an war on trans people and gender affirming care\nproviders and I’m afraid that within a few years or less than a year, it will no longer be legal for me\nto access hrt. If the right doesn’t ban hrt via legislature, they will at least try to intimidate doctors\naway from prescribing it via violent threats and intimidate pharmacies away from distributing it.\nAnd I don’t want to go back to the way I was before, hrt has done so much for my happiness and\nconfidence. But now it’s going to be taken away from me again. And it causes me a ton of anxiety\nand sadness not knowing if I’ll be forced to detransition someday soon.\nlabel: fear, predicted: anxiety"
        },
        {
          "Category": "",
          "Qualitative Code Description": "Code 6 (NSD = 16, NLLM = 16): Selection reflects\nwhether\nthe event/scenario described has already occurred\n(post-goal emotion, e.g., happiness/joy or down) or is likely to\noccur (pre-goal emotion, e.g., excitement or nervous)",
          "Example": "Feeling so <mask>. I (27F) posted in here a few weeks ago about\nthe proposal\nthat wasnt. Ive\nalready been clear with my (30M) boyfriend on my timeline and hes on board. I just feel so taken\nfor granted knowing that he has nothing planned for the foreseeable future. (Our weekends are all\npretty much booked and spoken for from now until the end of the holiday season). Trying to shake\nthis feeling of sadness and irritability whenever I see him.\nlabel: melancholy, predicted: disappointed"
        },
        {
          "Category": "",
          "Qualitative Code Description": "Code 7 (NSD = 9, NLLM = 11): Alternative does not fit\nas well with evidence-based normative descriptions of affective\nexperience in similar scenarios",
          "Example": "I feel <mask> to admit that i like the last of us part 2! i enjoyed the game and the story not at all\nbad! as youtubers and people made it seem. (according to me) and i enjoyed the gameplay and it\nfelt good. the only thing weird was the >!dual protaganist!< but i had no problems with it! and the\ngame looks so amazing im on a ps4 and its 60 fps too!i really enjoyed the game as much as i did\nthe first one.\nlabel: scared, predicted: embarrassed"
        },
        {
          "Category": "",
          "Qualitative Code Description": "Code 8 (NSD = 18, NLLM = 13): Alternative is not\nas consistent with colloquial descriptions of similar scenarios\n(according to the coder)",
          "Example": "My parents refuse me medical attention for my depression because they believe God will heal me\neven though i attempted suicide. Help me make sense of it all. hello all. Its not going good with me.\nMy religious parents refuse me medical treatment for my depression and instead pray and force\nme to fast once a week. I tried to commit suicide last year November because i am messed up in\nlife, in love with a black girl and they found out. My dad rambled racist stuff and i felt <mask> and\nlost. she is the only thing i have so i overdosed. I have had mental issues for a year now and things\ncompounded and i found my way in hospital. My parents promised to get me helo. They didn’t and\nchange the topic. I am really suffering and God evem left me. I am 15 and will become an atheist\nbecause of this. I already tore a Bible in anger. Why would God allow this to happen and harden\nmy parents heart and not even care. My girlfriends family are waay better to be around and they\nall non religious. They not bigotic and treat me well. all efforts to help me are shut down by my\nparents. they tell me God is testing me and i must be strong and not weak. help. I think i will leave\nreligion if rhis continues.\nlabel: hopeless, predicted: lost"
        },
        {
          "Category": "",
          "Qualitative Code Description": "Code 9 (NSD = 25, NLLM = 20): Alternative does not\nlogically follow as well as the alternative from the described\nsituation, based on coder’s lay theory of normative affective\nexperience in similar situations",
          "Example": "Feeling <mask> after quiting weed. So I quit smoking weed at night 2 and a half weeks ago. I feel\nbetter and I’m not having any problems right now. But I feel so bored. I have stuff to do clean and\ncook, bake etc. I’m a stay at home mom and my husband works alot. I really want to play the Sims\n3 on my laptop but I don’t play it anymore because I used to be addicted to playing it. I’m figured I\ncouldn’t control my usage because of episodes before I was unmedicated and not diagnosed, but\nI’m stable now and think I can regulate how much I play but I’ve tried playing GTA on my ps4 and\nI still feel so <mask> idk if games would do anything for me. I don’t feel like watching tv at all.\nI’m just here being bored all day. What do yall think what should I do? Has anyone been through\nthis after stopping smoking weed?\nlabel: bored, bored, predicted: anxious, disinterested"
        },
        {
          "Category": "Neither",
          "Qualitative Code Description": "Code 10 (N = 4): No information provided on the object/-\nsubject about which affect is being expressed (Unclear what\nthe person is feeling affect about)",
          "Example": "Feeling <mask>. You guys are gonna have to deal with my attempts as I try to figure out face paint\nlabel: melancholy, predicted: nervous"
        },
        {
          "Category": "Both",
          "Qualitative Code Description": "Code 11 (N = 57): Not enough information about the situ-\nation to determine whether on affect\nterm was a better fit\nto\nthe situation; rather, both terms could be applied such that the\nexpression of affect would be equally or similarly believable",
          "Example": "Just put my pc to sleep and felt very happy for some reason. Decided to take a picture. For absolutely\nno reason I felt very <mask> for having a computer like this. Its not the best out there but its mine.\nDoes that happen to anyone else?\nlabel: thankful, predicted: grateful"
        }
      ],
      "page": 17
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Code": "9",
          "Selection and Reasoning": "Selection of hopeless (SD) instead of confused (LLM): based\non the description of\nthe situation indicating that\nthe person\nappraises the situation as being bad, rather than unclear or con-\nfusing.",
          "Example": "I feel <mask> and don’t know what to do. To lay out a long story short. I have been in a relationship\nfor over six years. . . Within two months of my transferring, she cheated on me with another girl.\nShe continued to talk to this girl despite me not wanting her to. . . This continued and she got more\nabusive again."
        },
        {
          "Code": "9",
          "Selection and Reasoning": "Selection of frustrated (LLM) instead of numb (SD): based on\nthe coder’s lay theory that feeling the other emotions indicated in\nthe excerpt would not constitute “numbness”, or lack of ability\nto feel.",
          "Example": "I’m <mask> because I got tired of seeing my mom and dads disappointing faces in everything\nI tried so hard at, just to fail. My parents have paid for multiple classes so I could actually be\ngood at something but I never show any promise and It always ends up worse than when I started\ntrying. I have one friend and I feel like hes my opposite. . . I’m starting to hate everything I once\nenjoyed because the thought of him being better than me at everything creeps into my mind. At\nthis point I feel like there is no hope for me to be happy, just numb."
        },
        {
          "Code": "9",
          "Selection and Reasoning": "Selection of grateful (LLM) instead of happy (SD): based on the\nassumption that\nthe person is sharing an account of less-than-\nideal situation, rather than a situation to be happy for.",
          "Example": "Unfortunately I’m still low contact with them despite wanting to be no-contact (long story short, I\ngot caught packing up my stuff and it turned into this huge f****** ordeal to the point where my\nonline friend turned roommate who works a job involved with law enforcement had to drive 600\nmiles to rescue me and lowkey intimidated my family into letting me go), but GOD I will take the\nmental equivalent of weekly probation calls over the shit I was dealing with before. Hopefully I\ncan fully ditch their asses someday. I’m just so <mask> to be able to exist, indulge myself in my\nhobbies and go to places without immediately being interrogated about what I’m doing or where\nI’m going or being."
        },
        {
          "Code": "2",
          "Selection and Reasoning": "Selection of upset (SD) instead of jealous (LLM); based on lack\nof specificity of the alternative, that would be required to meet cri-\nteria for the definition of jealousy as a discrete emotion (Chung\nand Harris 2018).",
          "Example": "am i bad friend for feeling <mask> that my friend is replacing me?...i feel like i shouldnt feel sad\nthat shes getting closer to other people but she doesnt really talk to me when the other girl is there."
        },
        {
          "Code": "4",
          "Selection and Reasoning": "Selection of ashamed (LLM) instead of embarrassment (SD):\ngiven the use of the descriptor of feeling as being “so intense”,\nand based on findings that shame is relatively intense in terms\nof both negative valence, and physiological arousal, relative to\nembarrassment (Tangney et al. 1996).",
          "Example": ". . . After the break up the feeling I felt was so intense and awful. Id just cry myself to sleep in\nsilence because I knew no one understood how miserable I was and am. I never talk about\nit\nbecause Im <mask> I still care. . ."
        },
        {
          "Code": "5",
          "Selection and Reasoning": "Selection of angry (SD) instead of frustrated (LLM): based im-\nportant criteria met for the definition of anger as involving at-\ntribution of the other person as being at blame (rather than the\nself) for negative situation, in addition to goal blockage (Siemer,\nMauss, and Gross 2007).",
          "Example": ". . . I messaged her again yesterday, she responded playing the blame game, wouldnt call me,\nsaid my family and I publicly posting that she fled was embarrassing her, were messed up for\ntrying to hurt and embarrass her, etc. Basically blaming us for why she wouldnt reach out. I was\n<mask> and in tears. Classic behavior of someone struggling with addiction who wants to take no\nresponsibility. . . This has been going on for years. I lost my adoptive father to alcohol and drugs.\nI sat with him as he was dying. I cannot watch my sister die. I cannot do this again."
        },
        {
          "Code": "6",
          "Selection and Reasoning": "Selection of scared (SD) instead of guilty (LLM): based on the\ndescription of the goal (maintaining the status quo in family in\nthe context of the father’s death) as being in future, rather than\nbeing in the past (attained, or not attained) (Harmon-Jones, Price,\nand Gable 2012).",
          "Example": "I feel like I want to die (not really), sort of, because I wanted so bad to be there for my Dad, who\nI adored, and I just couldn’t do it. . . I loved him so much, and I came back to the hospital after\nhe passed, and held him forever, sobbing, telling him how much I missed him. He was so still,\nbut I wasn’t scared then for some reason.? I think I was more <mask> that I was braver than my\nsiblings, and wanted to stay, but didn’t’ want to upset the stupid family dynamic, when everyone\nwas like \"well I’m not staying, I can’t\ntake this, \" and I felt compelled to leave as well, some\nstupid, weak show of solidarity. I hate myself. . ."
        }
      ],
      "page": 18
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Model Name": "Llama-3.1-8B-instruct",
          "Setting": "Few-shot (random)\nFew-shot (nearest)\nCoT",
          "p-value": "7.08e-11\n7.32e-66\n1.0",
          "cohen’s D": "0.027\n0.077\n-0.013"
        },
        {
          "Model Name": "Llama-3.1-70B-instruct",
          "Setting": "Few-shot (random)\nFew-shot (nearest)\nCoT",
          "p-value": "1.0\n2.70e-06\n0.0",
          "cohen’s D": "-0.34\n0.015\n0.161"
        },
        {
          "Model Name": "Gemma-2-2B-it",
          "Setting": "Few-shot (random)\nFew-shot (nearest)\nCoT",
          "p-value": "1.39e-08\n2.12e-68\n1.86e-246",
          "cohen’s D": "0.026\n0.086\n0.120"
        },
        {
          "Model Name": "Gemma-2-9B-it",
          "Setting": "Few-shot (random)\nFew-shot (nearest)\nCoT",
          "p-value": "5.91e-54\n1.82e-89\n0.0",
          "cohen’s D": "0.061\n0.082\n0.204"
        },
        {
          "Model Name": "Gemma-2-27B-it",
          "Setting": "Few-shot (random)\nFew-shot (nearest)\nCoT",
          "p-value": "0.000125\n1.79e-13\n0.0",
          "cohen’s D": "0.014\n0.028\n0.314"
        },
        {
          "Model Name": "GPT-3.5-turbo",
          "Setting": "Few-shot (random)\nFew-shot (nearest)\nCoT",
          "p-value": "7.99e-22\n1.11e-37\n4.79e-234",
          "cohen’s D": "0.035\n0.048\n0.116"
        },
        {
          "Model Name": "GPT-4o",
          "Setting": "Few-shot (random)\nFew-shot (nearest)\nCoT",
          "p-value": "1.66e-53\n6.25e-111\n4.79e-234",
          "cohen’s D": "0.058\n0.086\n0.116"
        }
      ],
      "page": 20
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Model Name 1": "Flan-t5-xxl",
          "Model Name 2": "Llama-3.1-8B-instruct\nGemma-2-9B-it",
          "p-value": "2.33e-34\n2.32e-86",
          "cohen’s D": "0.084\n0.144"
        },
        {
          "Model Name 1": "GPT-3.5-turbo",
          "Model Name 2": "Llama-3.1-70B-instruct\nGemma-2-27B-it",
          "p-value": "6.17e-22\n1.37e-82",
          "cohen’s D": "0.043\n0.087"
        },
        {
          "Model Name 1": "Gemma-2-27B-it",
          "Model Name 2": "Gemma-2-2B-it\nGemma-2-9B-it",
          "p-value": "0.0\n2.31e-129",
          "cohen’s D": "0.468\n0.099"
        },
        {
          "Model Name 1": "Gemma-2-9B-it",
          "Model Name 2": "Gemma-2-2B-it",
          "p-value": "0.0",
          "cohen’s D": "0.367"
        },
        {
          "Model Name 1": "Llama-3.1-70B-instruct",
          "Model Name 2": "Llama-3.1-8B-instruct",
          "p-value": "0.0",
          "cohen’s D": "0.233"
        },
        {
          "Model Name 1": "GPT-4o",
          "Model Name 2": "GPT-3.5-turbo",
          "p-value": "2.173e-277",
          "cohen’s D": "0.160"
        }
      ],
      "page": 20
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Gpt-4 technical report",
      "authors": [
        "J Achiam",
        "S Adler",
        "S Agarwal",
        "F Aleman"
      ],
      "year": "2023",
      "venue": "Gpt-4 technical report",
      "arxiv": "arXiv:2303.08774"
    },
    {
      "citation_id": "2",
      "title": "Exploring the Efficacy of Large Language Models in Summarizing Mental Health Counseling Sessions: Benchmark Study",
      "authors": [
        "P Adhikary",
        "A Srivastava",
        "S Kumar",
        "S Singh",
        "P Manuja"
      ],
      "year": "2024",
      "venue": "JMIR Mental Health"
    },
    {
      "citation_id": "3",
      "title": "Perceptions of Emotions in Expressive Storytelling",
      "authors": [
        "C Alm",
        "R Sproat"
      ],
      "year": "2005",
      "venue": "In INTERSPEECH"
    },
    {
      "citation_id": "4",
      "title": "Emotion and personality in a conversational agent",
      "authors": [
        "G Ball",
        "J Breese"
      ],
      "year": "2001",
      "venue": "Emotion and personality in a conversational agent"
    },
    {
      "citation_id": "5",
      "title": "Reddit news users more likely to be male, young and digital in their news preferences",
      "authors": [
        "M Barthel",
        "G Stocking",
        "J Holcomb",
        "A Mitchell",
        "I Beltagy",
        "M Peters",
        "A Cohan"
      ],
      "year": "2016",
      "venue": "Longformer: The Long-Document Transformer",
      "arxiv": "arXiv:2004.05150"
    },
    {
      "citation_id": "6",
      "title": "Emotional intelligence: Implications for personal, social, academic, and workplace success. Social and personality psychology compass",
      "authors": [
        "M Brackett",
        "S Rivers",
        "P Salovey"
      ],
      "year": "2011",
      "venue": "Emotional intelligence: Implications for personal, social, academic, and workplace success. Social and personality psychology compass"
    },
    {
      "citation_id": "7",
      "title": "Language models are few-shot learners",
      "authors": [
        "T Brown",
        "B Mann",
        "P Ryder",
        "Nick Dhariwal"
      ],
      "year": "2020",
      "venue": "Advances in neural information processing systems"
    },
    {
      "citation_id": "8",
      "title": "EmoBank: Studying the Impact of Annotation Perspective and Representation Format on Dimensional Emotion Analysis",
      "authors": [
        "S Buechel",
        "U Hahn"
      ],
      "year": "2017",
      "venue": "Proceedings of the 15th Conference of the European Chapter"
    },
    {
      "citation_id": "9",
      "title": "SemEval-2019 task 3: EmoContext contextual emotion detection in text",
      "authors": [
        "A Chatterjee",
        "K Narahari",
        "M Joshi",
        "P Agrawal"
      ],
      "year": "2019",
      "venue": "Proceedings of the 13th international workshop on semantic evaluation"
    },
    {
      "citation_id": "10",
      "title": "Larger Language Models Don't Care How You Think: Why Chain-of-Thought Prompting Fails in Subjective Tasks",
      "authors": [
        "G Chochlakis",
        "N Pandiyan",
        "K Lerman",
        "S Narayanan",
        "H Chung",
        "L Hou",
        "J Longpre",
        "Shayne Wei"
      ],
      "year": "2024",
      "venue": "ICASSP 2025 -2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
    },
    {
      "citation_id": "11",
      "title": "Jealousy as a Specific Emotion: The Dynamic Functional Model",
      "authors": [
        "M Chung",
        "C Harris"
      ],
      "year": "2018",
      "venue": "Emotion Review"
    },
    {
      "citation_id": "12",
      "title": "Mapping the Passions: Toward a High-Dimensional Taxonomy of Emotional Experience and Expression",
      "authors": [
        "A Cowen",
        "D Sauter",
        "J Tracy",
        "D Keltner"
      ],
      "year": "2019",
      "venue": "Psychological Science in the Public Interest"
    },
    {
      "citation_id": "13",
      "title": "List of Emotions: 271 Emotion Words (+ PDF) -berkeleywellbeing",
      "authors": [
        "T Davis"
      ],
      "year": "2024",
      "venue": "List of Emotions: 271 Emotion Words (+ PDF) -berkeleywellbeing"
    },
    {
      "citation_id": "14",
      "title": "The Language of Emotion",
      "authors": [
        "J Davitz"
      ],
      "year": "2013",
      "venue": "The Language of Emotion"
    },
    {
      "citation_id": "15",
      "title": "GoEmotions: A Dataset of Fine-Grained Emotions",
      "authors": [
        "D Demszky",
        "D Movshovitz-Attias",
        "J Ko",
        "A Cowen",
        "G Nemade",
        "S Ravi"
      ],
      "year": "2020",
      "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "16",
      "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "authors": [
        "J Devlin",
        "M.-W Chang",
        "K Lee",
        "K Toutanova"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference of the North American Chapter"
    },
    {
      "citation_id": "17",
      "title": "Pancultural elements in facial displays of emotion",
      "authors": [
        "P Ekman",
        "E Sorenson",
        "W Friesen"
      ],
      "year": "1969",
      "venue": "Science"
    },
    {
      "citation_id": "18",
      "title": "Basic emotions. Handbook of cognition and emotion",
      "authors": [
        "P Ekman"
      ],
      "year": "1999",
      "venue": "Basic emotions. Handbook of cognition and emotion"
    },
    {
      "citation_id": "19",
      "title": "EmoWOZ: A Large-Scale Corpus and Labelling Scheme for Emotion Recognition in Task-Oriented Dialogue Systems",
      "authors": [
        "S Feng",
        "N Lubis",
        "C Geishauser",
        "H.-C Lin",
        "M Heck",
        "C Van Niekerk",
        "M Gasic"
      ],
      "year": "2022",
      "venue": "Proceedings of the Thirteenth Language Resources and Evaluation Conference"
    },
    {
      "citation_id": "20",
      "title": "The World of Emotions is not Two-Dimensional",
      "authors": [
        "J Fontaine",
        "K Scherer",
        "E Roesch",
        "P Ellsworth"
      ],
      "year": "2007",
      "venue": "Psychological Science"
    },
    {
      "citation_id": "21",
      "title": "Experimental Disclosure and Its Moderators: A Meta-Analysis",
      "authors": [
        "J Frattaroli"
      ],
      "year": "2006",
      "venue": "Psychological Bulletin"
    },
    {
      "citation_id": "22",
      "title": "Detecting emotion stimuli in emotion-bearing sentences",
      "authors": [
        "D Ghazi",
        "D Inkpen",
        "S Szpakowicz"
      ],
      "year": "2015",
      "venue": "Computational Linguistics and Intelligent Text Processing: 16th International Conference"
    },
    {
      "citation_id": "23",
      "title": "The Llama 3 Herd of Models",
      "authors": [
        "A Grattafiori",
        "A Dubey",
        "A Jauhri"
      ],
      "year": "2024",
      "venue": "The Llama 3 Herd of Models",
      "arxiv": "arXiv:2407.21783"
    },
    {
      "citation_id": "24",
      "title": "BERTopic: Neural topic modeling with a class-based TF-IDF procedure",
      "authors": [
        "M Grootendorst"
      ],
      "year": "2022",
      "venue": "BERTopic: Neural topic modeling with a class-based TF-IDF procedure",
      "arxiv": "arXiv:2203.05794"
    },
    {
      "citation_id": "25",
      "title": "Emotion generation and emotion regulation: One or two depends on your point of view",
      "authors": [
        "J Gross",
        "Feldman Barrett"
      ],
      "year": "2011",
      "venue": "Emotion review"
    },
    {
      "citation_id": "26",
      "title": "Closing the accessibility gap to mental health treatment with a personalized self-referral Chatbot",
      "authors": [
        "J Habicht",
        "S Viswanathan",
        "B Carrington",
        "T Hauser",
        "R Harper",
        "M Rollwage"
      ],
      "year": "2024",
      "venue": "Nature medicine"
    },
    {
      "citation_id": "27",
      "title": "The Influence of Affective States on Cognitive Broadening/Narrowing: Considering the Importance of Motivational Intensity",
      "authors": [
        "E Harmon-Jones",
        "T Price",
        "P Gable"
      ],
      "year": "2012",
      "venue": "Social and Personality Psychology Compass"
    },
    {
      "citation_id": "28",
      "title": "A scoping review of large language models for generative tasks in mental health care",
      "authors": [
        "Y Hua",
        "H Na",
        "Z Li",
        "F Liu",
        "X Fang",
        "D Clifton",
        "J Torous"
      ],
      "year": "2025",
      "venue": "Digital Medicine"
    },
    {
      "citation_id": "29",
      "title": "MentalBERT: Publicly Available Pretrained Language Models for Mental Healthcare",
      "authors": [
        "S Ji",
        "T Zhang",
        "L Ansari",
        "J Fu",
        "P Tiwari",
        "E Cambria"
      ],
      "year": "2022",
      "venue": "Proceedings of the Thirteenth Language Resources and Evaluation Conference"
    },
    {
      "citation_id": "30",
      "title": "Domain-specific Continued Pretraining of Language Models for Capturing Long Context in Mental Health",
      "authors": [
        "S Ji",
        "T Zhang",
        "K Yang",
        "S Ananiadou",
        "E Cambria",
        "J Tiedemann",
        "D Jurafsky",
        "J Martin"
      ],
      "year": "2023",
      "venue": "Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition with Language Models",
      "arxiv": "arXiv:2304.10447"
    },
    {
      "citation_id": "31",
      "title": "Open coding",
      "authors": [
        "S Khandkar"
      ],
      "year": "2009",
      "venue": "Open coding"
    },
    {
      "citation_id": "32",
      "title": "The benefits, risks and bounds of personalizing the alignment of large language models to individuals",
      "authors": [
        "H Kirk",
        "B Vidgen",
        "P Röttger",
        "S Hale"
      ],
      "year": "2024",
      "venue": "Nature Machine Intelligence"
    },
    {
      "citation_id": "33",
      "title": "Large language models are zero-shot reasoners",
      "authors": [
        "T Kojima",
        "S Gu",
        "M Reid",
        "Y Matsuo",
        "Y Iwasawa"
      ],
      "year": "2022",
      "venue": "Proceedings of the 36th International Conference on Neural Information Processing Systems, NIPS '22"
    },
    {
      "citation_id": "34",
      "title": "DailyDialog: A Manually Labelled Multi-turn Dialogue Dataset",
      "authors": [
        "Y Li",
        "H Su",
        "X Shen",
        "W Li",
        "Z Cao",
        "S Niu"
      ],
      "year": "2017",
      "venue": "Proceedings of the Eighth International Joint Conference on Natural Language Processing"
    },
    {
      "citation_id": "35",
      "title": "DENS: A Dataset for Multi-class Emotion Analysis",
      "authors": [
        "C Liu",
        "M Osama",
        "A De Andrade"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing"
    },
    {
      "citation_id": "36",
      "title": "What Makes Good In-Context Examples for GPT-3? arXiv preprint",
      "authors": [
        "J Liu",
        "D Shen",
        "Y Zhang",
        "B Dolan",
        "L Carin",
        "W Chen"
      ],
      "year": "2021",
      "venue": "What Makes Good In-Context Examples for GPT-3? arXiv preprint",
      "arxiv": "arXiv:2101.06804"
    },
    {
      "citation_id": "37",
      "title": "Towards Emotional Support Dialog Systems",
      "authors": [
        "S Liu",
        "C Zheng",
        "O Demasi",
        "S Sabour",
        "Y Li",
        "Z Yu",
        "Y Jiang",
        "M Huang"
      ],
      "year": "2021",
      "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing"
    },
    {
      "citation_id": "38",
      "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach",
      "authors": [
        "Y Liu",
        "M Ott",
        "N Goyal",
        "J Du",
        "M Joshi",
        "D Chen",
        "O Levy",
        "M Lewis",
        "L Zettlemoyer",
        "V Stoyanov"
      ],
      "year": "2019",
      "venue": "RoBERTa: A Robustly Optimized BERT Pretraining Approach",
      "arxiv": "arXiv:1907.11692"
    },
    {
      "citation_id": "39",
      "title": "Measures of Emotion: A Review",
      "authors": [
        "I Mauss",
        "M Robinson"
      ],
      "year": "2009",
      "venue": "Cognition and Emotion"
    },
    {
      "citation_id": "40",
      "title": "Emotional intelligence and the identification of emotion",
      "authors": [
        "J Mayer",
        "G Geher"
      ],
      "year": "1996",
      "venue": "Intelligence"
    },
    {
      "citation_id": "41",
      "title": "The need for a broader approach to emotion regulation research in autism",
      "authors": [
        "C Mazefsky",
        "K Pelphrey",
        "R Dahl"
      ],
      "year": "2012",
      "venue": "Child development perspectives"
    },
    {
      "citation_id": "42",
      "title": "Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?",
      "authors": [
        "S Min",
        "X Lyu",
        "A Holtzman",
        "M Artetxe",
        "M Lewis",
        "H Hajishirzi",
        "L Zettlemoyer"
      ],
      "year": "2022",
      "venue": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "43",
      "title": "Obtaining reliable human ratings of valence, arousal, and dominance for 20,000 English words",
      "authors": [
        "S Mohammad"
      ],
      "year": "2018",
      "venue": "Proceedings of the 56th annual meeting of the association for computational linguistics"
    },
    {
      "citation_id": "44",
      "title": "Emotion Intensities in Tweets",
      "authors": [
        "S Mohammad",
        "F Bravo-Marquez"
      ],
      "year": "2017",
      "venue": "Proceedings of the 6th Joint Conference on Lexical and Computational Semantics"
    },
    {
      "citation_id": "45",
      "title": "Crowdsourcing a word-emotion association lexicon",
      "authors": [
        "S Mohammad",
        "P Turney"
      ],
      "year": "2013",
      "venue": "Computational intelligence"
    },
    {
      "citation_id": "46",
      "title": "Creating a dataset for multilingual fine-grained emotiondetection using gamification-based annotation",
      "authors": [
        "E Öhman",
        "K Kajava",
        "J Tiedemann",
        "T Honkela"
      ],
      "year": "2018",
      "venue": "Proceedings of the 9th workshop on computational approaches to subjectivity, sentiment and social media analysis"
    },
    {
      "citation_id": "47",
      "title": "",
      "authors": [
        "J Openai; Achiam",
        "S Adler"
      ],
      "year": "2024",
      "venue": "",
      "arxiv": "arXiv:2303.08774"
    },
    {
      "citation_id": "48",
      "title": "Confronting a Traumatic Event: Toward an Understanding of Inhibition and Disease",
      "authors": [
        "J Pennebaker",
        "S Beall"
      ],
      "year": "1986",
      "venue": "Journal of Abnormal Psychology"
    },
    {
      "citation_id": "49",
      "title": "A general psychoevolutionary theory of emotion",
      "authors": [
        "R Plutchik"
      ],
      "year": "1980",
      "venue": "Theories of emotion"
    },
    {
      "citation_id": "50",
      "title": "A circumplex model of affect",
      "authors": [
        "J Russell"
      ],
      "year": "1980",
      "venue": "Journal of personality and social psychology"
    },
    {
      "citation_id": "51",
      "title": "EmoBench: Evaluating the Emotional Intelligence of Large Language Models",
      "authors": [
        "S Sabour",
        "S Liu",
        "Z Zhang",
        "J Liu",
        "J Zhou",
        "A Sunaryo",
        "T Lee",
        "R Mihalcea",
        "M Huang"
      ],
      "year": "2024",
      "venue": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "52",
      "title": "Emotional intelligence. Imagination, cognition and personality",
      "authors": [
        "P Salovey",
        "J Mayer"
      ],
      "year": "1990",
      "venue": "Emotional intelligence. Imagination, cognition and personality"
    },
    {
      "citation_id": "53",
      "title": "Evidence for universality and cultural variation of differential emotion response patterning",
      "authors": [
        "K Scherer",
        "H Wallbott"
      ],
      "year": "1994",
      "venue": "Journal of personality and social psychology"
    },
    {
      "citation_id": "54",
      "title": "The human affectome",
      "authors": [
        "D Schiller",
        "N Alessandra",
        "N Alia-Klein",
        "F Dolcos"
      ],
      "year": "2024",
      "venue": "The human affectome"
    },
    {
      "citation_id": "55",
      "title": "On Second Thought, Let's Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning",
      "authors": [
        "O Shaikh",
        "H Zhang",
        "W Held",
        "M Bernstein",
        "D Yang"
      ],
      "year": "2023",
      "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "56",
      "title": "Towards Understanding Sycophancy in Language Models",
      "authors": [
        "M Sharma",
        "M Tong",
        "S Bowman"
      ],
      "year": "2024",
      "venue": "The Twelfth International Conference on Learning Representations"
    },
    {
      "citation_id": "57",
      "title": "Same Situation-Different Emotions: How Appraisals Shape Our Emotions",
      "authors": [
        "M Siemer",
        "I Mauss",
        "J Gross"
      ],
      "year": "2007",
      "venue": "Emotion"
    },
    {
      "citation_id": "58",
      "title": "Evolution of reddit: from the front page of the internet to a self-referential community?",
      "authors": [
        "P Singer",
        "F Flöck",
        "C Meinhart",
        "E Zeitfogel",
        "M Strohmaier"
      ],
      "year": "2014",
      "venue": "Proceedings of the 23rd international conference on world wide web"
    },
    {
      "citation_id": "59",
      "title": "Language Models (Mostly) Do Not Consider Emotion Triggers When Predicting Emotion",
      "authors": [
        "S Singh",
        "C Caragea",
        "J Li"
      ],
      "year": "2024",
      "venue": "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies"
    },
    {
      "citation_id": "60",
      "title": "Large language models could change the future of behavioral healthcare: a proposal for responsible development and evaluation",
      "authors": [
        "E Stade",
        "S Stirman",
        "L Ungar",
        "C Boland",
        "H Schwartz",
        "D Yaden",
        "J Sedoc",
        "R Derubeis",
        "R Willer",
        "J Eichstaedt"
      ],
      "year": "2024",
      "venue": "NPJ Mental Health Research"
    },
    {
      "citation_id": "61",
      "title": "Semeval-2007 task 14: Affective text",
      "authors": [
        "C Strapparava",
        "R Mihalcea"
      ],
      "year": "2007",
      "venue": "Proceedings of the fourth international workshop on semantic evaluations (SemEval-2007)"
    },
    {
      "citation_id": "62",
      "title": "Are shame, guilt, and embarrassment distinct emotions?",
      "authors": [
        "J Tangney",
        "R Miller",
        "L Flicker",
        "D Barlow"
      ],
      "year": "1996",
      "venue": "Journal of Personality and Social Psychology"
    },
    {
      "citation_id": "63",
      "title": "Gemma 2: Improving Open Language Models at a Practical Size",
      "authors": [
        "G Team",
        "M Riviere",
        "S Pathak"
      ],
      "year": "2024",
      "venue": "Gemma 2: Improving Open Language Models at a Practical Size",
      "arxiv": "arXiv:2408.00118"
    },
    {
      "citation_id": "64",
      "title": "How do adults and teens with self-declared Autism Spectrum Disorder experience eye contact? A qualitative analysis of first-hand accounts",
      "authors": [
        "D Trevisan",
        "N Roberts",
        "C Lin",
        "E Birmingham"
      ],
      "year": "2017",
      "venue": "PloS one"
    },
    {
      "citation_id": "65",
      "title": "Designing a scalable crowdsourcing platform",
      "authors": [
        "A Turing",
        "Springer",
        "C Van Pelt",
        "A Sorokin"
      ],
      "year": "2009",
      "venue": "Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data"
    },
    {
      "citation_id": "66",
      "title": "Emotional intelligence of large language models",
      "authors": [
        "X Wang",
        "X Li",
        "Z Yin",
        "Y Wu",
        "J Liu"
      ],
      "year": "2023",
      "venue": "Journal of Pacific Rim Psychology"
    },
    {
      "citation_id": "67",
      "title": "Chain-of-thought prompting elicits reasoning in large language models",
      "authors": [
        "J Wei",
        "X Wang",
        "D Schuurmans",
        "D Zhou"
      ],
      "year": "2022",
      "venue": "Advances in neural information processing systems"
    }
  ]
}