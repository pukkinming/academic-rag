{
  "paper_id": "2003.07723v3",
  "title": "Po-Emo: Conceptualization, Annotation, And Modeling Of Aesthetic Emotions In German And English Poetry",
  "published": "2020-03-17T13:54:48Z",
  "authors": [
    "Thomas Haider",
    "Steffen Eger",
    "Evgeny Kim",
    "Roman Klinger",
    "Winfried Menninghaus"
  ],
  "keywords": [
    "Emotion",
    "Aesthetic Emotions",
    "Literature",
    "Poetry",
    "Annotation",
    "Corpora",
    "Emotion Recognition",
    "Multi-Label"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Most approaches to emotion analysis of social media, literature, news, and other domains focus exclusively on basic emotion categories as defined by Ekman or Plutchik. However, art (such as literature) enables engagement in a broader range of more complex and subtle emotions. These have been shown to also include mixed emotional responses. We consider emotions in poetry as they are elicited in the reader, rather than what is expressed in the text or intended by the author. Thus, we conceptualize a set of aesthetic emotions that are predictive of aesthetic appreciation in the reader, and allow the annotation of multiple labels per line to capture mixed emotions within their context. We evaluate this novel setting in an annotation experiment both with carefully trained experts and via crowdsourcing. Our annotation with experts leads to an acceptable agreement of κ = .70, resulting in a consistent dataset for future large scale analysis. Finally, we conduct first emotion classification experiments based on BERT, showing that identifying aesthetic emotions is challenging in our data, with up to .52 F1-micro on the German subset. Data and resources are available at https://github.com/tnhaider/poetry-emotion.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Emotions are central to human experience, creativity and behavior. Models of affect and emotion, both in psychology and natural language processing, commonly operate on predefined categories, designated either by continuous scales of, e.g., Valence, Arousal and Dominance  (Mohammad, 2016)  or discrete emotion labels (which can also vary in intensity). Discrete sets of emotions often have been motivated by theories of basic emotions, as proposed by  Ekman (1992) -Anger, Fear, Joy, Disgust, Surprise,  Sadness-and Plutchik (1991) , who added Trust and Anticipation. These categories are likely to have evolved as they motivate behavior that is directly relevant for survival. However, art reception typically presupposes a situation of safety and therefore offers special opportunities to engage in a broader range of more complex and subtle emotions. These differences between real-life and art contexts have not been considered in natural language processing work so far. To emotionally move readers is considered a prime goal of literature since Latin antiquity  (Johnson-Laird and Oatley, 2016; Menninghaus et al., 2019; Menninghaus et al., 2015) . Deeply moved readers shed tears or get chills and goosebumps even in lab settings  (Wassiliwizky et al., 2017) . In cases like these, the emotional response actually implies an aesthetic evaluation: narratives that have the capacity to move readers are evaluated as good and powerful texts for this very reason. Similarly, feelings of suspense experienced in narratives not only respond to the trajectory of the plot's content, but are also directly predictive of aesthetic liking (or disliking). Emotions that exhibit this dual capacity have been defined as \"aesthetic emotions\"  (Menninghaus et al., 2019) . Contrary to the negativity bias of classical emotion catalogues, emotion terms used for aesthetic evaluation purposes include far more positive than negative emotions. At the same time, many overall positive aesthetic emotions encompass negative or mixed emotional ingredients  (Menninghaus et al., 2019) , e.g., feelings of suspense include both hopeful and fearful anticipations. For these reasons, we argue that the analysis of literature (with a focus on poetry) should rely on specifically selected emotion items rather than on the narrow range of basic emotions only. Our selection is based on previous research on this issue in psychological studies on art reception and, specifically, on poetry. For instance,  Knoop et al. (2016)  found that Beauty is a major factor in poetry reception. We primarily adopt and adapt emotion terms that  Schindler et al. (2017)  have identified as aesthetic emotions in their study on how to measure and categorize such particular affective states. Further, we consider the aspect that, when selecting specific emotion labels, the perspective of annotators plays a major role. Whether emotions are elicited in the reader, expressed in the text, or intended by the author largely changes the permissible labels. For example, feelings of Disgust or Love might be intended or expressed in the text, but the text might still fail to elicit corresponding feelings as these concepts presume a strong reaction in the reader. Our focus here was on the actual emotional experience of the readers rather than on hypothetical intentions of authors. We opted for this reader perspective based on previous research in NLP  (Buechel and Hahn, 2017a; Buechel and Hahn, 2017b)  and work in empirical aesthetics  (Menninghaus et al., 2017) , that specifically measured the reception of poetry. Our final set of emotion labels consists of Beauty/Joy, Sadness, Uneasiness, Vitality/Energy, Suspense, Awe/Sublime, Humor, Annoyance, and Nostalgia. 1\n\nIn addition to selecting an adapted set of emotions, the annotation of poetry brings further challenges, one of which is the choice of the appropriate unit of annotation. Previous work considers words 2  (Mohammad and Turney, 2013; Strapparava and Valitutti, 2004) , sentences  (Alm et al., 2005; Aman and Szpakowicz, 2007) , utterances  (Cevher et al., 2019) , sentence triples  (Kim and Klinger, 2018) , or paragraphs  (Liu et al., 2019)  as the units of annotation. For poetry, reasonable units follow the logical document structure of poems, i.e., verse (line), stanza, and, owing to its relative shortness, the complete text. The more coarse-grained the unit, the more difficult the annotation is likely to be, but the more it may also enable the annotation of emotions in context. We find that annotating fine-grained units (lines) that are hierarchically ordered within a larger context (stanza, poem) caters to the specific structure of poems, where emotions are regularly mixed and are more interpretable within the whole poem. Consequently, we allow the mixing of emotions already at line level through multi-label annotation. The remainder of this paper includes (1) a report of the annotation process that takes these challenges into consideration, (2) a description of our annotated corpora, and (3) an implementation of baseline models for the novel task of aesthetic emotion annotation in poetry. In a first study, the annotators work on the annotations in a closely supervised fashion, carefully reading each verse, stanza, and poem. In a second study, the annotations are performed via crowdsourcing within relatively short time periods with annotators not seeing the entire poem while reading the stanza. Using these two settings, we aim at obtaining a better understanding of the advantages and disadvantages of an expert vs. crowdsourcing setting in this novel annotation task. Particularly, we are interested in estimating the potential of a crowdsourcing environment for the task of self-perceived emotion annotation in poetry, given time and cost overhead associated with in-house annotation process (that usually involve training and close supervision of the annotators). We provide the final datasets of German and English language poems annotated with reader emotions on verse level at https://github.com/tnhaider/ poetry-emotion.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Related Work",
      "text": "",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Poetry In Natural Language Processing",
      "text": "Natural language understanding research on poetry has investigated stylistic variation  (Kaplan and Blei, 2007; Kao and Jurafsky, 2015; Voigt and Jurafsky, 2013) , with a focus on broadly accepted formal features such as meter  (Greene et al., 2010; Agirrezabal et al., 2016; Estes and Hench, 2016)  and rhyme  (Reddy and Knight, 2011; Haider and Kuhn, 2018) , as well as enjambement  (Ruiz et al., 2017; Baumann et al., 2018)  and metaphor  (Kesarwani et al., 2017; Reinig and Rehbein, 2019) . Recent work has also explored the relationship of poetry and prose, mainly on a syntactic level feelings of Beauty and Sublime have therefore come to be subsumed under the rubrique of aesthetic emotions in recent psychological research  (Menninghaus et al., 2019) . For this reason, we refer to the whole set of category labels as emotions throughout this paper.\n\n2 to create emotion dictionaries  (Krishna et al., 2019; Gopidi and Alam, 2019) . Furthermore, poetry also lends itself well to semantic (change) analysis  (Haider, 2019; Haider and Eger, 2019) , as linguistic invention  (Underwood and Sellers, 2012; Herbelot, 2014)  and succinctness  (Roberts, 2000)  are at the core of poetic production.\n\nCorpus-based analysis of emotions in poetry has been considered, but there is no work on German, and little on English.  Kao and Jurafsky (2015)  analyze English poems with word associations from the Harvard Inquirer and LIWC, within the categories positive/negative outlook, positive/negative emotion and phys./psych. well-being.  Hou and Frank (2015)  examine the binary sentiment polarity of Chinese poems with a weighted personalized PageRank algorithm.  Barros et al. (2013)   In contrast to our work, these studies focus on basic emotions and binary sentiment polarity only, rather than addressing aesthetic emotions. Moreover, they annotate on the level of complete poems (instead of fine-grained verse and stanza-level).",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Emotion Annotation",
      "text": "Emotion corpora have been created for different tasks and with different annotation strategies, with different units of analysis and different foci of emotion perspective  (reader, writer, text) . Examples include the ISEAR dataset  (Scherer and Wallbott, 1994 ) (document-level); emotion annotation in children stories  (Alm et al., 2005)  and news headlines  (Strapparava and Mihalcea, 2007 ) (sentence-level); and finegrained emotion annotation in literature by  Kim and Klinger (2018) (phrase-and word-level) . We refer the interested reader to an overview paper on existing corpora  (Bostan and Klinger, 2018) .\n\nWe are only aware of a limited number of publications which look in more depth into the emotion perspective.  Buechel and Hahn (2017a)  report on an annotation study that focuses both on writer's and reader's emotions associated with English sentences. The results show that the reader perspective yields better inter-annotator agreement.  Yang et al. (2009)  also study the difference between writer and reader emotions, but not with a modeling perspective. The authors find that positive reader emotions tend to be linked to positive writer emotions in online blogs.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Emotion Classification",
      "text": "The task of emotion classification has been tackled before using rule-based and machine learning approaches. Rulebased emotion classification typically relies on lexical resources of emotionally charged words  (Strapparava and Valitutti, 2004; Esuli and Sebastiani, 2006; Mohammad and Turney, 2013)  and offers a straightforward and transparent way to detect emotions in text.\n\nIn contrast to rule-based approaches, current models for emotion classification are often based on neural networks and commonly use word embeddings as features.  Schuff et al. (2017)  applied models from the classes of CNN, Bi-LSTM, and LSTM and compare them to linear classifiers (SVM and MaxEnt), where the BiLSTM shows best results with the most balanced precision and recall. Abdul-Mageed and Ungar (2017) claim the highest F 1 with gated recurrent unit networks  (Chung et al., 2015)  for Plutchik's emotion model. More recently, shared tasks on emotion analysis  (Mohammad et al., 2018; Klinger et al., 2018)  triggered a set of more advanced deep learning approaches, including BERT  (Devlin et al., 2019)  and other transfer learning methods  (Dankers et al., 2019) .",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Data Collection",
      "text": "For our annotation and modeling studies, we build on top of two poetry corpora (in English and German), which we refer to as PO-EMO. This collection represents important contributions to the literary canon over the last 400 years.\n\nWe make this resource available in TEI P5 XML 3 and an easy-to-use tab separated format. Table  1  shows a size overview of these data sets. Figure  1  shows the distribution of our data over time via density plots. Note that both corpora show a relative underrepresentation before the onset of the romantic period (around 1750).\n\n3 https://tei-c.org/guidelines/p5/",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "German",
      "text": "The German corpus contains poems available from the website lyrik.antikoerperchen.de (ANTI-K), which provides a platform for students to upload essays about poems. The data was available in the Hypertext Markup Language, with clean line and stanza segmentation, which we transformed into TEI P5. ANTI-K also has extensive metadata, including author names, years of publication, numbers of sentences, poetic genres, and literary periods, that enable us to gauge the distribution of poems according to periods.\n\nThe 158 poems we consider (731 stanzas) are dispersed over 51 authors and the New High German timeline  (1575-1936 A.D.) . This data has been annotated, besides emotions, for meter, rhythm, and rhyme in other studies  (Haider and Kuhn, 2018; Haider et al., 2020) .",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "English",
      "text": "The English corpus contains 64 poems of popular English writers. It was partly collected from Project Gutenberg with the GutenTag tool, 4  and, in addition, includes a number of hand selected poems from the modern period and represents a cross section of popular English poets. We took care to include a number of female authors, who would have been underrepresented in a uniform sample. Time stamps in the corpus are organized by the birth year of the author, as assigned in Project Gutenberg.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Expert Annotation",
      "text": "In the following, we will explain how we compiled and annotated three data subsets, namely, (1) 48 German poems with gold annotation. These were originally annotated by three annotators. The labels were then aggregated with majority voting and based on discussions among the annotators. Finally, they were curated to only include one gold annotation.\n\n(2) The remaining 110 German poems that are used to compute the agreement in table 3 and (3) 64 English poems contain the raw annotation from two annotators. We report the genesis of our annotation guidelines including the emotion classes. With the intention to provide a language resource for the computational analysis of emotion in poetry, we aimed at maximizing the consistency of our annotation, while doing justice to the diversity of poetry. We iteratively improved the guidelines and the annotation workflow by annotating in batches, cleaning the class set, and the compilation of a gold standard. The final overall cost of producing this expert annotated dataset amounts to approximately A C3,500.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Workflow",
      "text": "The annotation process was initially conducted by three female university students majoring in linguistics and/or literary studies, which we refer to as our \"expert annotators\". We used the INCePTION platform for annotation 5    (Klie et al., 2018) . Starting with the German poems, we annotated in batches of about 16 (and later in some cases 32) poems.    (Schindler et al., 2017) .\n\nAfter each batch, we computed agreement statistics including heatmaps, and provided this feedback to the annotators.\n\nFor the first three batches, the three annotators produced a gold standard using a majority vote for each line. Where this was inconclusive, they developed an adjudicated annotation based on discussion. Where necessary, we encouraged the annotators to aim for more consistency, as most of the frequent switching of emotions within a stanza could not be reconstructed or justified.\n\nIn poems, emotions are regularly mixed (already on line level) and are more interpretable within the whole poem. We therefore annotate lines hierarchically within the larger context of stanzas and the whole poem. Hence, we instruct the annotators to read a complete stanza or full poem, and then annotate each line in the context of its stanza. To reflect on the emotional complexity of poetry, we allow a maximum of two labels per line while avoiding heavy label fluctuations by encouraging annotators to reflect on their feelings to avoid 'empty' annotations. Rather, they were advised to use fewer labels and more consistent annotation. This additional constraint is necessary to avoid \"wild\", nonreconstructable or non-justified annotations.\n\nAll subsequent batches (all except the first three) were only annotated by two out of the three initial annotators, coincidentally those two who had the lowest initial agreement with each other. We asked these two experts to use the generated gold standard (48 poems; majority votes of 3 annotators plus manual curation) as a reference (\"if in doubt, annotate according to the gold standard\"). This eliminated some systematic differences between them 6 and markedly improved the agreement levels, roughly from 0.3-0.5 Cohen's κ in the first three batches to around 0.6-0.8 κ for all subsequent batches. This annotation procedure relaxes the reader perspective, as we encourage annotators (if in doubt) to annotate how they think the other annotators would annotate. However, we found that this formulation improves the usability of the data and leads to a more consistent annotation.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Emotion Labels",
      "text": "We opt for measuring the reader perspective rather than the text surface or author's intent. To closer define and support conceptualizing our labels, we use particular 'items', as they are used in psychological self-evaluations. These items consist of adjectives, verbs or short phrases. We build on top of  Schindler et al. (2017)  who proposed 43 items that were then grouped by a factor analysis based on self-evaluations of participants. The resulting factors are shown in Table  2 .\n\nWe attempt to cover all identified factors and supplement with basic emotions  (Ekman, 1992; Plutchik, 1991) , where possible.\n\nWe started with a larger set of labels to then delete and substitute (tone down) labels during the initial annotation process to avoid infrequent classes and inconsistencies. Further, we conflate labels if they show considerable confusion with each other. These iterative improvements particularly affected Confusion, Boredom and Other that were very infrequently annotated and had little agreement among annotators (κ < .2). For German, we also removed Nostalgia (κ = .218) after gold standard creation, but after consideration, added it back for English, then achieving agreement.\n\nNostalgia is still available in the gold standard (then with a second label Beauty/Joy or Sadness to keep consistency). However, Confusion, Boredom and Other are not available in any sub-corpus.\n\nOur final set consists of nine classes, i.e., (in order of frequency) Beauty/Joy, Sadness, Uneasiness, Vitality/Energy, Suspense, Awe/Sublime, Humor, Annoyance, and Nostalgia.\n\nIn the following, we describe the labels and give further details on the aggregation process.\n\nAnnoyance (annoys me/angers me/felt frustrated): Annoyance implies feeling annoyed, frustrated or even angry while reading the line/stanza. We include the class Anger here, as this was found to be too strong in intensity.",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "Agreement",
      "text": "Table  3  shows the Cohen's κ agreement scores among our two expert annotators for each emotion category e as follows.\n\nWe assign each instance (a line in a poem) a binary label indicating whether or not the annotator has annotated the emotion category e in question. From this, we obtain vectors v e i , for annotators i = 0, 1, where each entry of v e i holds the binary value for the corresponding line. We then apply the κ statistics to the two binary vectors v e i . Additionally to averaged κ, we report micro-F1 values in Table  4  between the multi-label annotations of both expert annotators as well as the micro-F1 score of a random baseline as well as of the majority emotion baseline (which labels each line as Beauty/Joy). We find that Cohen κ agreement ranges from .84 for Uneasiness in the English data, .81 for Humor and Nostalgia, down to German Suspense (.65), Awe/Sublime (.61) and Vitality/Energy for both languages (.50 English, .63 German). Both annotators have a similar emotion frequency profile, where the ranking is almost identical, especially for German. However, for English, Annotator 2 annotates more Vitality/Energy than Uneasiness. Figure  2  shows the confusion matrices of labels between annotators as heatmaps. Notably, Beauty/Joy and Sadness are confused across annotators more often than other labels. This is topical for poetry, and therefore not surprising: One might argue that the beauty of beings and situations is only beautiful because it is not enduring and therefore not to divorce from the sadness of the vanishing of beauty  (Benjamin, 2016) . We also find considerable confusion of Sadness with Awe/Sublime and Vitality/Energy, while the latter is also regularly confused with Beauty/Joy. Furthermore, as shown in Figure  3 , we find that no single poem aggregates to more than six emotion labels, while no stanza aggregates to more than four emotion labels. However, most lines and stanzas prefer one or two labels. German poems seem more emotionally diverse where more poems have three labels than two labels, while the majority of English poems have only two labels. This is however attributable to the generally shorter English texts.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Crowdsourcing Annotation",
      "text": "After concluding the expert annotation, we performed a focused crowdsourcing experiment, based on the final label set and items as they are listed in Table  5  and Section 4.2. With this experiment, we aim to understand whether it is possible to collect reliable judgements for aesthetic perception of poetry from a crowdsourcing platform. A second goal is to see whether we can replicate the expensive expert annotations with less costly crowd annotations. We opted for a maximally simple annotation environment, where we asked participants to annotate English 4-line stanzas with self-perceived reader emotions. We choose English due to the higher availability of English language annotators on crowdsourcing platforms. Each annotator rates each stanza independently of surrounding context.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Data And Setup",
      "text": "For consistency and to simplify the task for the annotators, we opt for a trade-off between completeness and granularity of the annotation. Specifically, we subselect stanzas composed of four verses from the corpus of 64 hand selected English poems. The resulting selection of 59 stanzas is uploaded to Figure Eight 8 for annotation. The annotators are asked to answer the following questions for each instance. Question 1 (single-choice): Read the following stanza and decide for yourself which emotions it evokes. Question 2 (multiple-choice): Which additional emotions does the stanza evoke? The answers to both questions correspond to the emotion labels we defined to use in our annotation, as described in Section 4.2. We add an additional answer choice \"None\" to Question 2 to allow annotators to say that a stanza does not evoke any additional emotions. Each instance is annotated by ten people. We restrict the task geographically to the United Kingdom and Ireland and set the parameters on Figure Eight to only have the highest quality annotators join the task. We pay A C0.09 per instance. The final cost of the crowdsourcing experiment is A C74.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Results",
      "text": "In the following, we determine the best aggregation strategy regarding the 10 annotators with bootstrap resampling. For instance, one could assign the label of a specific emotion to an instance if just one annotators picks it, or one could assign the label only if all annotators agree on this emotion. To evaluate this, we repeatedly pick two sets of 5 annotators each out of the 10 annotators for each of the 59 stanzas, 1000 times overall (i.e., 1000×59 times, bootstrap resampling). For each of these repetitions, we compare the agreement of these two groups of 5 annotators. Each group gets assigned with an adjudicated emotion which is accepted if at least one annotator picks it, at least two annotators pick it, etc. up to all five pick it. We show the results in Table  5 . The κ scores show the average agreement between the two groups of five annotators, when the adjudicated class is picked based on the particular threshold of annotators with the same label choice. We see that some emotions tend to have higher agreement scores than others, namely Annoyance (.66), Sadness (up to .52), and Awe/Sublime, Beauty/Joy, Humor (all .46). The maximum agreement is reached mostly with a threshold of 2 (4 times) or 3 (3 times). We further show in the same table the average numbers of labels from each strategy. Obviously, a lower threshold leads to higher numbers (corresponding to a disjunction of annotations for each emotion). The drop in label counts is comparably drastic, with on average 18 labels per class. Overall, the best average κ agreement (.32) is less than half of what we saw for the expert annotators (roughly .70). Crowds especially disagree on many more intricate emotion labels (Uneasiness, Vitality/Energy, Nostalgia, Suspense). We visualize how often two emotions are used to label an instance in a confusion table in Figure  2 . Sadness is used most often to annotate a stanza, and it is often confused with Suspense, Uneasiness, and Nostalgia. Further, Beauty/Joy partially overlaps with Awe/Sublime, Nostalgia, and Sadness.\n\nOn average, each crowd annotator uses two emotion labels per stanza (56% of cases); only in 36% of the cases the annotators use one label, and in 6% and 1% of the cases three and four labels, respectively. This contrasts with the expert annotators, who use one label in about 70% of the cases and two labels in 30% of the cases for the same 59 four-liners.\n\nConcerning frequency distribution for emotion labels, both experts and crowds name Sadness and Beauty/Joy as the most frequent emotions (for the 'best' threshold of 3) and Nostalgia as one of the least frequent emotions. The Spearman rank correlation between experts and crowds is about 0.55 with respect to the label frequency distribution, indicating that crowds could replace experts to a moderate degree when it comes to extracting, e.g., emotion distributions for an author or time period. Now, we further compare crowds and experts in terms of whether crowds could replicate expert annotations also on a finer stanza level (rather than only on a distributional level).",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "Comparing Experts With Crowds",
      "text": "To gauge the quality of the crowd annotations in comparison with our experts, we calculate agreement on the emotions between experts and an increasing group size from the crowd.\n\nFor each stanza instance s, we pick N crowd workers, where N ∈ {4, 6, 8, 10}, then pick their majority emotion for s, and additionally pick their second ranked majority emotion if at least N 2 -1 workers have chosen it. 9  For the experts, we aggregate their emotion labels on stanza level, then perform the same strategy for selection of emotion labels. Thus, for s, both crowds and experts have 1 or 2 emotions. For each emotion, we then compute Cohen's κ as before. Note that, compared to our previous experiments in Section 5.2 with a threshold, each stanza now receives an emotion annotation (exactly one or two emotion labels), both by the experts and the crowd-workers. In Figure  4 , we plot agreement between experts and crowds on stanza level as we vary the number N of crowd workers involved. On average, there is roughly a steady linear increase in agreement as N grows, which may indicate that N = 20 or N = 30 would still lead to better agreement. Concerning individual emotions, Nostalgia is the emotion with the least agreement, as opposed to Sadness (in our sample of 59 four-liners): the agreement for this emotion grows from .47 κ with N = 4 to .65 κ with N = 10. Sadness is also the most frequent emotion, both according to experts and crowds. Other emotions for which a reasonable agreement is achieved are Annoyance, Awe/Sublime, Beauty/Joy, Humor (κ > 0.2). Emotions with little agreement are Vitality/Energy, Uneasiness, Suspense, Nostalgia (κ < 0.2). By and large, we note from Figure  2  that expert annotation is more restrictive, with experts agreeing more often on particular emotion labels (seen in the darker diagonal).\n\nThe results of the crowdsourcing experiment, on the other hand, are a mixed bag as evidenced by a much sparser distribution of emotion labels. However, we note that these differences can be caused by 1) the disparate training procedure for the experts and crowds, and 2) the lack of opportunities for close supervision and on-going training of the crowds, as opposed to the in-house expert annotators. In general, however, we find that substituting experts with crowds is possible to a certain degree. Even though the crowds' labels look inconsistent at first view, there appears to be a good signal in their aggregated annotations, helping to approximate expert annotations to a certain degree. The average κ agreement (with the experts) we get from N = 10 crowd workers (0.24) is still considerably below the agreement among the experts (0.70).",
      "page_start": 7,
      "page_end": 8
    },
    {
      "section_name": "Modeling",
      "text": "To estimate the difficulty of automatic classification of our data set, we perform multi-label 10  document classification (of stanzas) with BERT  (Devlin et al., 2019) . For this experiment we aggregate all labels for a stanza and sort them by frequency, both for the gold standard and the raw expert annotations. As can be seen in Figure  3 , stanza bears a minimum of one and a maximum of four emotions. Unfortunately, the label Nostalgia is only available 16 times in the German data (the gold standard) as a second label (as discussed in Section 4.2). None of our models was able to learn this label for German. Therefore we omit it, leaving us with eight proper labels. We use the code and the pre-trained BERT models of FARM, 11  provided by deepset.ai. We test the multilingual-uncased model (MULTILING), the germanbase-cased model (BASE), 12  the german-dbmdz-uncased model (DBMDZ),  13  and we tune the BASE model on 80k stanzas of the German Poetry Corpus DLK  (Haider and Eger, 2019)  for 2 epochs, both on token (masked words) and sequence (next line) prediction (BASE TUNED ). We split the randomized German dataset so that each label is at least 10 times in the validation set (63 instances, 113 labels), and at least 10 times in the test set (56 instances, 108 labels) and leave the rest for training (617 instances, 946 labels).  14  We train BERT for 10 epochs (with a batch size of 8), optimize with entropy loss, and report F1-micro on the test set. See Table  6  for the results. We find that the multilingual model cannot handle infrequent categories, i.e., Awe/Sublime, Suspense and Humor. However, increasing the dataset with English data improves the results, suggesting that the classification would largely benefit from more annotated data. The best model overall is DBMDZ (.520), showing a balanced response on both validation and test set. See Table  7     (30k) . We found that tuning on poetry does not show obvious improvements. Lastly, we find that models that were trained on lines (instead of stanzas) do not achieve the same F1 (~.42 for the German models).",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Concluding Remarks",
      "text": "In this paper, we presented a dataset of German and English poetry annotated with reader response to reading poetry. We argued that basic emotions as proposed by psychologists (such as  Ekman and Plutchik)  that are often used in emotion analysis from text are of little use for the annotation of poetry reception. We instead conceptualized aesthetic emotion labels and showed that a closely supervised annotation task results in substantial agreement-in terms of κ score-on the final dataset.\n\nThe task of collecting reader-perceived emotion response to poetry in a crowdsourcing setting is not straightforward. In contrast to expert annotators, who were closely supervised and reflected upon the task, the annotators on crowdsourcing platforms are difficult to control and may lack necessary background knowledge to perform the task at hand. However, using a larger number of crowd annotators may lead to finding an aggregation strategy with a better trade-off between quality and quantity of adjudicated labels. For future work, we thus propose to repeat the experiment with larger number of crowdworkers, and develop an improved training strategy that would suit the crowdsourcing environment.\n\nThe dataset presented in this paper can be of use for different application scenarios, including multi-label emotion classification, style-conditioned poetry generation, investigating the influence of rhythm/prosodic features on emotion, or analysis of authors, genres and diachronic variation (e.g., how emotions are represented differently in certain periods). Further, though our modeling experiments are still rudimentary, we propose that this data set can be used to investigate the intra-poem relations either through multi-task learning  (Schulz et al., 2018)  and/or with the help of hierarchical sequence classification approaches.",
      "page_start": 8,
      "page_end": 9
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Temporal distribution of poetry corpora (Kernel",
      "page": 3
    },
    {
      "caption": "Figure 1: shows the distribution",
      "page": 3
    },
    {
      "caption": "Figure 2: Emotion cooccurrence matrices for the German and English expert annotation experiments and the English",
      "page": 5
    },
    {
      "caption": "Figure 2: shows the con-",
      "page": 5
    },
    {
      "caption": "Figure 3: Distribution of number of distinct emotion labels per logical document level in the expert-based annotation. No",
      "page": 6
    },
    {
      "caption": "Figure 3: , we ﬁnd that no single",
      "page": 6
    },
    {
      "caption": "Figure 2: Sadness is used",
      "page": 7
    },
    {
      "caption": "Figure 4: Agreement between experts and crowds as a func-",
      "page": 7
    },
    {
      "caption": "Figure 4: , we plot agreement between experts and crowds",
      "page": 7
    },
    {
      "caption": "Figure 2: that expert annotation",
      "page": 7
    },
    {
      "caption": "Figure 3: , a stanza bears a",
      "page": 8
    }
  ],
  "tables": [
    {
      "caption": "Table 1: Statistics on our poetry corpora PO-EMO.",
      "page": 3
    },
    {
      "caption": "Table 1: shows a size",
      "page": 3
    },
    {
      "caption": "Table 3: and (3) 64 English poems",
      "page": 3
    },
    {
      "caption": "Table 2: Aesthetic Emotion Factors (Schindler et al., 2017).",
      "page": 4
    },
    {
      "caption": "Table 3: Cohen’s kappa agreement levels and normalized",
      "page": 4
    },
    {
      "caption": "Table 4: Top: averaged kappa scores and micro-F1 agree-",
      "page": 4
    },
    {
      "caption": "Table 2: We attempt to cover all identiﬁed factors and supplement",
      "page": 4
    },
    {
      "caption": "Table 3: shows the Cohen’s κ agreement scores among our",
      "page": 5
    },
    {
      "caption": "Table 5: and Section 4.2.",
      "page": 6
    },
    {
      "caption": "Table 5: The κ scores show the av-",
      "page": 6
    },
    {
      "caption": "Table 5: Results obtained via boostrapping for annotation aggregation. The row Threshold shows how many people within a",
      "page": 7
    },
    {
      "caption": "Table 6: for the results.",
      "page": 8
    },
    {
      "caption": "Table 7: for a breakdown of all",
      "page": 8
    },
    {
      "caption": "Table 6: BERT-based multi-label classiﬁcation on stanza-",
      "page": 8
    },
    {
      "caption": "Table 7: Recall and precision scores of the best model (db-",
      "page": 8
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "EmoNet: Finegrained emotion detection with gated recurrent neural networks",
      "authors": [
        "M Abdul-Mageed",
        "L Ungar"
      ],
      "year": "2017",
      "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "2",
      "title": "Machine learning for metrical analysis of English poetry",
      "authors": [
        "M Agirrezabal",
        "I Alegria",
        "M Hulden"
      ],
      "year": "2016",
      "venue": "Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers"
    },
    {
      "citation_id": "3",
      "title": "Emotions from text: Machine learning for text-based emotion prediction",
      "authors": [
        "C Alm",
        "D Roth",
        "R Sproat"
      ],
      "year": "2005",
      "venue": "Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "4",
      "title": "Emotion classification in arabic poetry using machine learning",
      "authors": [
        "O Alsharif",
        "D Alshamaa",
        "N Ghneim"
      ],
      "year": "2013",
      "venue": "International Journal of Computer Applications"
    },
    {
      "citation_id": "5",
      "title": "Identifying expressions of emotion in text",
      "authors": [
        "S Aman",
        "S Szpakowicz"
      ],
      "year": "2007",
      "venue": "Václav Matoušek et al., editors, Text, Speech and Dialogue"
    },
    {
      "citation_id": "6",
      "title": "Automatic classification of literature pieces by emotion detection: A study on quevedo's poetry",
      "authors": [
        "L Barros",
        "P Rodriguez",
        "A Ortigosa"
      ],
      "year": "2013",
      "venue": "2013 Humaine Association Conference on Affective Computing and Intelligent Interaction"
    },
    {
      "citation_id": "7",
      "title": "Style detection for free verse poetry from text and speech",
      "authors": [
        "T Baumann",
        "H Hussein",
        "B Meyer-Sickendiek"
      ],
      "year": "2018",
      "venue": "Proceedings of the 27th International Conference on Computational Linguistics"
    },
    {
      "citation_id": "8",
      "title": "Goethes Wahlverwandtschaften",
      "authors": [
        "W Benjamin"
      ],
      "year": "2016",
      "venue": "Goethes Wahlverwandtschaften"
    },
    {
      "citation_id": "9",
      "title": "An analysis of annotated corpora for emotion classification in text",
      "authors": [
        "L.-A.-M Bostan",
        "R Klinger"
      ],
      "year": "2018",
      "venue": "Proceedings of the 27th International Conference on Computational Linguistics"
    },
    {
      "citation_id": "10",
      "title": "EmoBank: Studying the impact of annotation perspective and representation format on dimensional emotion analysis",
      "authors": [
        "S Buechel",
        "U Hahn"
      ],
      "year": "2017",
      "venue": "Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics"
    },
    {
      "citation_id": "11",
      "title": "Readers vs. writers vs. texts: Coping with different perspectives of text understanding in emotion annotation",
      "authors": [
        "S Buechel",
        "U Hahn"
      ],
      "year": "2017",
      "venue": "Proceedings of the 11th Linguistic Annotation Workshop"
    },
    {
      "citation_id": "12",
      "title": "Towards multimodal emotion recognition in german speech events in cars using transfer learning",
      "authors": [
        "D Cevher",
        "S Zepf",
        "R Klinger"
      ],
      "year": "2019",
      "venue": "Conference on Natural Language Processing"
    },
    {
      "citation_id": "13",
      "title": "Gated feedback recurrent neural networks",
      "authors": [
        "J Chung",
        "C Gulcehre",
        "K Cho",
        "Y Bengio"
      ],
      "year": "2015",
      "venue": "Proceedings of the 32Nd International Conference on International Conference on Machine Learning"
    },
    {
      "citation_id": "14",
      "title": "Modelling the interplay of metaphor and emotion through multitask learning",
      "authors": [
        "V Dankers",
        "M Rei",
        "M Lewis",
        "E Shutova"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)"
    },
    {
      "citation_id": "15",
      "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "authors": [
        "J Devlin",
        "M.-W Chang",
        "K Lee",
        "K Toutanova"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference of the North American Chapter"
    },
    {
      "citation_id": "16",
      "title": "An argument for basic emotions",
      "authors": [
        "P Ekman"
      ],
      "year": "1992",
      "venue": "Cognition & emotion"
    },
    {
      "citation_id": "17",
      "title": "Supervised machine learning for hybrid meter",
      "authors": [
        "A Estes",
        "C Hench"
      ],
      "year": "2016",
      "venue": "Proceedings of the Fifth Workshop on Computational Linguistics for Literature"
    },
    {
      "citation_id": "18",
      "title": "Sentiwordnet: A publicly available lexical resource for opinion mining",
      "authors": [
        "A Esuli",
        "F Sebastiani"
      ],
      "year": "2006",
      "venue": "Proceedings of the 5th Conference on Language Resources and Evaluation (LREC'06"
    },
    {
      "citation_id": "19",
      "title": "Computational analysis of the historical changes in poetry and prose",
      "authors": [
        "A Gopidi",
        "A Alam"
      ],
      "year": "2019",
      "venue": "Proceedings of the 1st International Workshop on Computational Approaches to Historical Language Change"
    },
    {
      "citation_id": "20",
      "title": "Automatic analysis of rhythmic poetry with applications to generation and translation",
      "authors": [
        "E Greene",
        "T Bodrumlu",
        "K Knight"
      ],
      "year": "2010",
      "venue": "Proceedings of the 2010 conference on empirical methods in natural language processing"
    },
    {
      "citation_id": "21",
      "title": "Semantic change and emerging tropes in a large corpus of new high german poetry",
      "authors": [
        "T Haider",
        "S Eger"
      ],
      "year": "2019",
      "venue": "Proceedings of the 1st International Workshop on Computational Approaches to Historical Language Change"
    },
    {
      "citation_id": "22",
      "title": "Supervised rhyme detection with siamese recurrent networks",
      "authors": [
        "T Haider",
        "J Kuhn"
      ],
      "year": "2018",
      "venue": "Proceedings of the Second Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature at COLING 2018"
    },
    {
      "citation_id": "23",
      "title": "Speech rhythm and syntax in poetry and prose",
      "authors": [
        "T Haider",
        "D Trzeciak",
        "G Kentner"
      ],
      "year": "2020",
      "venue": "Speech rhythm and syntax in poetry and prose"
    },
    {
      "citation_id": "24",
      "title": "Diachronic topics in new high german poetry",
      "authors": [
        "T Haider"
      ],
      "year": "2019",
      "venue": "Proceedings of the International Digital Humanities Conference DH"
    },
    {
      "citation_id": "25",
      "title": "The semantics of poetry: a distributional reading",
      "authors": [
        "A Herbelot"
      ],
      "year": "2014",
      "venue": "Digital Scholarship in the Humanities"
    },
    {
      "citation_id": "26",
      "title": "Analyzing sentiment in classical Chinese poetry",
      "authors": [
        "Y Hou",
        "A Frank"
      ],
      "year": "2015",
      "venue": "Proceedings of the 9th SIGHUM Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities (LaTeCH)"
    },
    {
      "citation_id": "27",
      "title": "Emotion semantics show both cultural variation and universal structure",
      "authors": [
        "J Jackson",
        "J Watts",
        "T Henry",
        "J.-M List",
        "R Forkel",
        "P Mucha",
        "S Greenhill",
        "R Gray",
        "K Lindquist"
      ],
      "year": "2019",
      "venue": "Science"
    },
    {
      "citation_id": "28",
      "title": "Handbook of emotions, chapter Emotions in Music, Literature, and Film",
      "authors": [
        "P Johnson-Laird",
        "K Oatley"
      ],
      "year": "2016",
      "venue": "Handbook of emotions, chapter Emotions in Music, Literature, and Film"
    },
    {
      "citation_id": "29",
      "title": "Critique of the Power of Judgment",
      "authors": [
        "I Kant",
        "P Guyer",
        "E Matthews"
      ],
      "year": "1790",
      "venue": "Critique of the Power of Judgment"
    },
    {
      "citation_id": "30",
      "title": "A computational analy-sis of poetic style",
      "authors": [
        "J Kao",
        "D Jurafsky"
      ],
      "year": "2015",
      "venue": "LiLT (Linguistic Issues in Language Technology)"
    },
    {
      "citation_id": "31",
      "title": "A computational approach to style in american poetry",
      "authors": [
        "D Kaplan",
        "D Blei"
      ],
      "year": "2007",
      "venue": "Seventh IEEE International Conference on Data Mining (ICDM 2007)"
    },
    {
      "citation_id": "32",
      "title": "Metaphor detection in a poetry corpus",
      "authors": [
        "V Kesarwani",
        "D Inkpen",
        "S Szpakowicz",
        "C Tanasescu"
      ],
      "year": "2017",
      "venue": "Proceedings of the Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage"
    },
    {
      "citation_id": "33",
      "title": "Who feels what and why? annotation of a literature corpus with semantic roles of emotions",
      "authors": [
        "E Kim",
        "R Klinger"
      ],
      "year": "2018",
      "venue": "Proceedings of the 27th International Conference on Computational Linguistics"
    },
    {
      "citation_id": "34",
      "title": "The INCEpTION platform: Machine-assisted and knowledge-oriented interactive annotation",
      "authors": [
        "J.-C Klie",
        "M Bugert",
        "B Boullosa",
        "R De Castilho",
        "I Gurevych"
      ],
      "year": "2018",
      "venue": "Proceedings of the 27th International Conference on Computational Linguistics: System Demonstrations"
    },
    {
      "citation_id": "35",
      "title": "IEST: WASSA-2018 implicit emotions shared task",
      "authors": [
        "R Klinger",
        "O De Clercq",
        "S Mohammad",
        "A Balahur"
      ],
      "year": "2018",
      "venue": "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis"
    },
    {
      "citation_id": "36",
      "title": "Mapping the aesthetic space of literature \"from below",
      "authors": [
        "C Knoop",
        "V Wagner",
        "T Jacobsen",
        "W Menninghaus"
      ],
      "year": "2016",
      "venue": "Poetics"
    },
    {
      "citation_id": "37",
      "title": "Poetry to prose conversion in sanskrit as a linearisation task: A case for low-resource languages",
      "authors": [
        "A Krishna",
        "V Sharma",
        "B Santra",
        "A Chakraborty",
        "P Satuluri",
        "P Goyal"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "38",
      "title": "DENS: A dataset for multi-class emotion analysis",
      "authors": [
        "C Liu",
        "M Osama",
        "A De Andrade"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)"
    },
    {
      "citation_id": "39",
      "title": "Towards a psychological construct of being moved",
      "authors": [
        "W Menninghaus",
        "V Wagner",
        "J Hanich",
        "E Wassiliwizky",
        "M Kuehnast",
        "T Jacobsen"
      ],
      "year": "2015",
      "venue": "PloS one"
    },
    {
      "citation_id": "40",
      "title": "The emotional and aesthetic powers of parallelistic diction",
      "authors": [
        "W Menninghaus",
        "V Wagner",
        "E Wassiliwizky",
        "T Jacobsen",
        "C Knoop"
      ],
      "year": "2017",
      "venue": "Poetics"
    },
    {
      "citation_id": "41",
      "title": "What are aesthetic emotions?",
      "authors": [
        "W Menninghaus",
        "V Wagner",
        "E Wassiliwizky",
        "I Schindler",
        "J Hanich",
        "T Jacobsen",
        "S Koelsch"
      ],
      "year": "2019",
      "venue": "Psychological review"
    },
    {
      "citation_id": "42",
      "title": "Crowdsourcing a word-emotion association lexicon",
      "authors": [
        "S Mohammad",
        "P Turney"
      ],
      "year": "2013",
      "venue": "Computational Intelligence"
    },
    {
      "citation_id": "43",
      "title": "SemEval-2018 task 1: Affect in tweets",
      "authors": [
        "S Mohammad",
        "F Bravo-Marquez",
        "M Salameh",
        "S Kiritchenko"
      ],
      "year": "2018",
      "venue": "Proceedings of The 12th International Workshop on Semantic Evaluation"
    },
    {
      "citation_id": "44",
      "title": "Sentiment analysis: Detecting valence, emotions, and other affectual states from text",
      "authors": [
        "S Mohammad"
      ],
      "year": "2016",
      "venue": "Emotion measurement"
    },
    {
      "citation_id": "45",
      "title": "Kabithaa: An annotated corpus of odia poems with sentiment polarity information",
      "authors": [
        "G Mohanty",
        "P Mishra",
        "R Mamidi"
      ],
      "year": "2018",
      "venue": "Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)"
    },
    {
      "citation_id": "46",
      "title": "The Emotions",
      "authors": [
        "R Plutchik"
      ],
      "year": "1991",
      "venue": "The Emotions"
    },
    {
      "citation_id": "47",
      "title": "Unsupervised discovery of rhyme schemes",
      "authors": [
        "S Reddy",
        "K Knight"
      ],
      "year": "2011",
      "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies"
    },
    {
      "citation_id": "48",
      "title": "Metaphor detection for german poetry",
      "authors": [
        "I Reinig",
        "I Rehbein"
      ],
      "year": "2019",
      "venue": "Proceedings of the 15th Conference on Natural Language Processing"
    },
    {
      "citation_id": "49",
      "title": "How Poetry Works",
      "authors": [
        "P Roberts"
      ],
      "year": "2000",
      "venue": "How Poetry Works"
    },
    {
      "citation_id": "50",
      "title": "Enjambment detection in a large diachronic corpus of spanish sonnets",
      "authors": [
        "P Ruiz",
        "C Cantón",
        "T Poibeau",
        "E González-Blanco"
      ],
      "year": "2017",
      "venue": "Proceedings of the Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage"
    },
    {
      "citation_id": "51",
      "title": "Evidence for universality and cultural variation of differential emotion response patterning",
      "authors": [
        "K Scherer",
        "H Wallbott"
      ],
      "year": "1994",
      "venue": "Journal of personality and social psychology"
    },
    {
      "citation_id": "52",
      "title": "Measuring aesthetic emotions: A review of the literature and a new assessment tool",
      "authors": [
        "I Schindler",
        "G Hosoya",
        "W Menninghaus",
        "U Beermann",
        "V Wagner",
        "M Eid",
        "K Scherer"
      ],
      "year": "2017",
      "venue": "PloS one"
    },
    {
      "citation_id": "53",
      "title": "Annotation, modelling and analysis of finegrained emotions on a stance and sentiment detection corpus",
      "authors": [
        "H Schuff",
        "J Barnes",
        "J Mohme",
        "S Padó",
        "R Klinger"
      ],
      "year": "2017",
      "venue": "Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis"
    },
    {
      "citation_id": "54",
      "title": "Multi-task learning for argumentation mining in low-resource settings",
      "authors": [
        "C Schulz",
        "S Eger",
        "J Daxenberger",
        "T Kahse",
        "I Gurevych"
      ],
      "year": "2018",
      "venue": "Proceedings of the 2018 Conference of the North American Chapter"
    },
    {
      "citation_id": "55",
      "title": "Perc-an emotion recognition corpus for cognitive poems",
      "authors": [
        "S Sreeja",
        "G Mahalakshmi"
      ],
      "year": "2019",
      "venue": "2019 International Conference on Communication and Signal Processing (ICCSP)"
    },
    {
      "citation_id": "56",
      "title": "Semeval-2007 task 14: Affective text",
      "authors": [
        "C Strapparava",
        "R Mihalcea"
      ],
      "year": "2007",
      "venue": "Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007)"
    },
    {
      "citation_id": "57",
      "title": "WordNet affect: an affective extension of WordNet",
      "authors": [
        "C Strapparava",
        "A Valitutti"
      ],
      "year": "2004",
      "venue": "Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC'04)"
    },
    {
      "citation_id": "58",
      "title": "The emergence of literary diction",
      "authors": [
        "T Underwood",
        "J Sellers"
      ],
      "year": "2012",
      "venue": "The Journal of Digital Humanities"
    },
    {
      "citation_id": "59",
      "title": "Tradition and modernity in 20th century chinese poetry",
      "authors": [
        "R Voigt",
        "D Jurafsky"
      ],
      "year": "2013",
      "venue": "Proceedings of the Workshop on Computational Linguistics for Literature"
    },
    {
      "citation_id": "60",
      "title": "Tears falling on goosebumps: Co-occurrence of emotional lacrimation and emotional piloerection indicates a psychophysiological climax in emotional arousal",
      "authors": [
        "E Wassiliwizky",
        "T Jacobsen",
        "J Heinrich",
        "M Schneiderbauer",
        "W Menninghaus"
      ],
      "year": "2017",
      "venue": "Frontiers in Psychology"
    },
    {
      "citation_id": "61",
      "title": "Writer meets reader: Emotion analysis of social media from both the writer's and reader's perspectives",
      "authors": [
        "C Yang",
        "K Lin",
        "H Chen"
      ],
      "year": "2009",
      "venue": "2009 IEEE/WIC/ACM International Joint Conference on Web Intelligence and Intelligent Agent Technology"
    }
  ]
}