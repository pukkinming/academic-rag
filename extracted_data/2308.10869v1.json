{
  "paper_id": "2308.10869v1",
  "title": "A Novel Loss Function Utilizing Wasserstein Distance To Reduce Subject-Dependent Noise For Generalizable Models In Affective Computing",
  "published": "2023-08-17T01:15:26Z",
  "authors": [
    "Nibraas Khan",
    "Mahrukh Tauseef",
    "Ritam Ghosh",
    "Nilanjan Sarkar"
  ],
  "keywords": [
    "Machine Learning",
    "Affective Computing",
    "Optimal Transport Theory",
    "HCI",
    "Wasserstein Distance"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Emotions are an essential part of human behavior that can impact thinking, decision-making, and communication skills. Thus, the ability to accurately monitor and identify emotions can be useful in many human-centered applications such as behavioral training, tracking emotional well-being, and development of human-computer interfaces. The correlation between patterns in physiological data and affective states has allowed for the utilization of deep learning techniques which can accurately detect the affective states of a person. However, the generalisability of existing models is often limited by the subject-dependent noise in the physiological data due to variations in a subject's reactions to stimuli. Hence, we propose a novel cost function that employs Optimal Transport Theory, specifically Wasserstein Distance, to scale the importance of subject-dependent data such that higher importance is assigned to patterns in data that are common across all participants while decreasing the importance of patterns that result from subject-dependent noise. The performance of the proposed cost function is demonstrated through an autoencoder with a multi-class classifier attached to the latent space and trained simultaneously to detect different affective states. An autoencoder with a state-of-the-art loss function i.e., Mean Squared Error, is used as a baseline for comparison with our model across four different commonly used datasets. Centroid and minimum distance between different classes are used as a metrics to indicate the separation between different classes in the latent space. An average increase of 14.75% and 17.75% (from benchmark to proposed loss function) was found for minimum and centroid euclidean distance respectively over all datasets.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Affective state can be defined as the underlying experience of feeling, emotion, or mood  [1] . Its importance stems from the influence affective states have on a person's thinking skills, decision making, and communication skills as well as mental and physical well-being  [2] . Accurate monitoring and identification of affective states can lead to important applications in behavioral training, computer-based emotional analysis (e.g., stress detection), and human-computer interfaces that can cater to the emotional needs of an individual  [3, 4] .",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Arxiv:2308.10869V1 [Cs.Lg] 17 Aug 2023",
      "text": "Affective state can be measured and monitored in two ways: intrusively and non-intrusively. Intrusive methods measure the concentration of various hormones in the blood stream that can be used to detect an affective state. For instance, cortisol levels produced by the hypothalamic-pituitary-adrenocortical (HPA) axis can be collected through samples of blood, urine, hair or saliva and used to detect stress  [5] . One of the challenges with intrusive measurement is that it is invasive and cannot be used to monitor the affective state in real-time.\n\nNon-intrusive methods, on the other hand, include the analysis of behavioral or physiological data that can lead to non-invasive real-time detection of affective states. Behavioural actions such as blink rate, facial expression, gesture, speech, and body pose have been commonly used for affective state detection  [6] . However, all these actions can be masked and voluntarily controlled by a subject which reduces its reliability  [4, 6] . Alternatively, strong evidence suggests physiological signals to be more reliable for affective state detection due to its involuntary nature and a strong correlation of patterns in the data with different affective states  [5] .\n\nPhysiological signals are a response to the Autonomic Nervous System (ANS) utilizing both motor and sensory neurons to communicate and operate between the Central Nervous System (CNS) and the various organs or muscles. The ANS is composed of the Sympathetic (SNS) and Parasympathetic (PNS) nervous systems. The sympathetic nervous system prepares the body for emergency action, which results in the \"fight or flight\" response  [7] . The response leads to an increase in measurable physiological signals, such as heart rate, blood flow, and increased muscle activation which can be mapped to different affective states. Whereas, the parasympathetic nervous system helps sustain homeostasis during rest by decreasing physiological signals and maintaining them in moderate ranges  [8] . Since ANS is involuntarily stimulated, the response cannot be manipulated or masked by an individual. This has led to the popular field of affecting computing to focus on dynamically identifying different affective states using non-invasive wearable sensors that can monitor changes in physiological signals in response to a stimulus.\n\nThe ability to map patterns in physiological data with affective states has allowed for utilization of machine learning techniques for the detection of affective states. Research in psychophysiology has led to the compilation of a comprehensive list of physiological data that can be used to monitor affective state. This list includes heart activity (ECG), brain activity (EEG), skin response (EDA), blood pressure variation (PPG), respiratory response, and muscle activity (EMG)  [5] . Several datasets have been compiled by collecting physiological data while inducing an affective state. For instance, one of the state-of-the-art datasets, Wearable Stress and Affect Detection (WESAD)  [9] , induced amusement by making the subjects watch funny video clips and they induced stress through public speaking and mental arithmetic tasks. Meanwhile, their physiological data i.e., blood volume pulse, ECG, EDA, EMG, respiration, body temperature, and three-axis acceleration was collected and classified simultaneously. Other common datasets like Database for Emotional Analysis using Physiological Signals (DEAP)  [10] , Affect, Personality and Mood Research on Individuals and Groups (AMIGOS)  [11] , and Cognitive Load, Affect, and Stress Recognition (CLAS)  [12]  follow suit by using video clips or stress-inducing tasks to collect and classify physiological data for the induced affective states.\n\nNumerous machine learning techniques have been utilised to detect affective states from physiological data. These approaches include support vector machines (SVM), random forest (RF), k-nearest neighbors (KNN) and Linear Discriminant Analysis (LDA) that need handcrafted features from the pre-processed signal in order to remove noisy data  [6] . However, there is no consensus on the list of features extracted from physiological data that can be accurately mapped to affective states which results in reduced performance  [13] . Alternatively, with the advancement of deep learning, there has been an increasing interest in using deep learning techniques like long short-term memory (LSTM), autoencoders, and convolutional neural networks (CNN)  [3, 14] . These models allow for automatic feature extraction based on the model's ability to automatically comprehend patterns in data with respect to the labels.\n\nEven though deep learning techniques show promise, the lack of generalisability still exists and contributes to poor performance. This is because the subjects might not exhibit the same physiological response for a stimuli  [13] . Thus, subject dependent noise can lead to poor generalisability of the model. This issue can be resolved by using a loss function that filters out the features of data that are person specific and do not contribute much to affective state detection. In other words, if each subject's data is treated as a distribution, the loss function assigns higher importance to features that are closer in distance to the group distribution (distributions of all subjects) while assigning lower importance to features that are much further apart across from the group distribution. The distance between distributions can be calculated by using the Wasserstein distance  [15] .\n\nIn this paper, we introduce a novel loss function that accounts for subject dependent noise in the data in order to develop more generalizable models. This is accomplished by training an autoencoder model with a loss function that utilizes Wasserstein Distance to scale the importance of subject dependent patterns to obtain a latent space with reduced dimensions and less noisy subject independent features. The performance of the model is tested on four different datasets (WESAD, AMIGOS, CLAS, and DEAP) using the centroid and minimum distances between classes as metrics. This paper is structured as follows. Section 2 presents an overview of existing literature that informed the development of the proposed model. This is followed by the 3 section that discusses the mathematical and algorithmic details of the model. The results are shown and discussed in Section 4 followed by concluding remarks in Section 5.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Background",
      "text": "As mentioned before, machine learning techniques for affective state detection using physiological data has been a topic of immense interest in the past few years. Kolodyazhniy et al.  [16]  conducted a notable study in 2011 on the topic by compiling a dataset and training several machine learning models like LDA, Quaratic Discriminant Analyis (QDA), Multilayer Perceptron (MLP), Radial Basis Function (RBF), and KNN. They used a variety of features extracted from the physiological data to discover the features that are strongly correlated to affective state. They reported maximum accuracy of 81.9% using KNN with 7 features on subject-dependent classification, but they reported the accuracy to go down to 78.9% for subject independent classification. Ever since, several novel techniques have been implemented to improve the performance of subject independent classification. Bota et al.  [17]  conducted a review of existing machine learning and deep learning techniques for affective state detection from 2001 to 2019. They reported lower performance for subject independent classification as compared to subject dependent classification for most of the models.\n\nLi et. al  [18]  proposed a technique that assigned variable learnable weights to different physiological signals fed to an attention-based bidirectional LSTM model. They reported an accuracy of 81.1% for subject-independent classification using the AMIGOS dataset. However, the model's accuracy across other datasets is not known.\n\nReviews conducted by both Bota et al.  [17]  and Xin et al.  [19]  highlighted the lack of generalisation to be a consistent issue with the existing techniques for affective state detection. This has led to several works proposing novel techniques to increase generalisation of affective state detection models.\n\nLi et al.  [20]  used different automatic feature selection techniques such as Chi-Squared-Based Feature Selection, Mutual Information-Based Feature Selection, ANOVA F-Value-Based Feature Selection, Recursive Feature Elimination (RFE), and L1-Norm Penalty-Based Feature Selection. These techniques were used such that the most important features needed for affective state detection can be extracted and used to train an SVM. They reported an accuracy of 83.3% for subject independent classification using the SEED dataset and 59.06% using the DEAP dataset.\n\nIn addition, several domain adaptation techniques are being used in order to select features such that the difference between the distributions of each subject's physiological data is minimized. Chai et al.  [21]  proposed a Subspace Alignment Autoencoder to minimize the distribution mismatch of the physiological data of each subject by minimizing the maximum mean discrepancy of reproduced kernel Hilbert space (RKHS). This allowed the alignment of different distributions by mitigating the subject-specific noise from the data. They reported an accuracy 77.8% using the SEED dataset.\n\nBased on the literature survey, we identified the potential of decreasing the distance between each subject's distribution of physiological data and use the extracted features to train a more generalised model. However, this entails that a robust method needs to be chosen to calculate the distance between distribution. One such method, Wasserstein Distance, can be retrieved from Optimal Transport Theory (OTT)  [15] . Wasserstein Distance allows for the calculation of the distance between distributions while also considering the geometry of the distribution (symmetrical and triangular)  [22] . Kolouri et al.  [22]  demonstrated the potential of Wasserstein Distance to minimize the distance between an input and target distribution for generative modeling using autoencoders.\n\nHence, in this paper, we propose a novel loss function using Wasserstein Distance for automatic feature extraction by assigning more weight to features that are closer in distance to each other across all subjects. An autoencoder model is used to generate a latent space that excludes all the features that are influenced by subject-dependent nuances. The goal is to increase the separation between different affective states in the latent space such that a more generalised classification model can be trained.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Methods",
      "text": "The datasets are publicly available through their respective organizations, and the code used for the presented work is publicly provided (https://anonymous.4open.science/status/NeurIPS-F252).",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Optimal Transport Theory",
      "text": "Optimal Transport Theory was first formalized by the French mathematician, Gaspard Monge, in 1781, right before the French revolution  [15] . The motivation to study this was to come up with a transport plan to move a mass from one point to another with minimum cost. The outcome of this study formulated a method for measuring the distance between two probability distributions. In the formulation, consider two probability measures µ and v defined on spaces X and Y respectively. µ and v have density functions f and g where dµ = f (x)dx and dv = g(y)dy, where (x, y) ∈ XxY . A cost function is defined, c(x, y) which finds the distance between a point x and y. The initial choice by Monge was Euclidean distance. A transport plan T : X -→ Y allows for moving a mass, M, from X to Y such that the measure µ of the mass in space X is the same as the measure v of the mass in space Y after the mass is transported from X to Y:\n\nOnce a plan T has been found, the cost associated with it is:\n\nWhile there can be many solution to T, the aim is to minimize the overall cost\n\nwhere M is the set of all transport plans T that transfers f to g. In the formulation, the optimal cost of transporting x to y is also known as the Wasserstein Distance.\n\nwhere P p (X) is the set of probability measures with finite moments of order p  [23] . In this paper, we will focus on using the Wasserstein Distance to measure the distance between a subjects' individual distribution and the group's distribution.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Models",
      "text": "In this work, we focus on using an autoencoder architecture to reduce noise along with our novel cost function through dimensionality reduction. In addition to a reconstruction loss, a classifier is attached to the latent space to ensure it is discriminant. Figure  1  shows the architecture of our model, and both components (encoder and classifier) are trained simultaneously. The proposed cost function is not restricted to the autoencoder model and can be used with any suitable machine learning algorithm. The following section will address how the loss function can be integrated in the autoencoder architecture. We use a standard autoencoder model with Mean Squared Error (MSE) for a baseline to compare it with our novel cost function.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Autoencoder Error Decomposition",
      "text": "The group reconstruction error, r g , of the autoencoder for the subject-independent model is given as\n\nwhere N is the total number of samples across all subjects, L a is any loss function for reconstruction (Mean-Squared Error), and a is the encoder and decoder architecture of the network. The reconstruction error will be used in conjunction with the classifier loss. The classifier head, attached to the latent space, is used to calculate the group classifier error and subject specific classifier error. The group classifier uses all labeled samples available across all subjects.\n\nwhere L c is any classification loss function (Categorical Cross-Entropy) and λ g is a regularizer term used to scale the importance of the group classifier error during backpropagation. The definition of λ g is given in equation 11. Subject i's specific loss is computed using all labeled samples available S i and any loss function L c .\n\nλ s,i is used to scale the importance of a specific subject in the calculation of the overall loss for backpropogation. The overall classification loss is given as:\n\nwhere S is the number of subjects. Optimal Transport Theory, specifically, Wasserstein Distance, is used to calculate λ s,i by measuring the distance between the group distribution and subject distribution. Equations 9 and 10 denote the formulation for λ s,i .\n\nα s,i is normalized and subtracted from 1 to ensure that the further away a subject i is from the group, the smaller the scaling factor, λ s,i , is.\n\nFinally, λ g is determined by ensuring that the regularizer terms sum to 1.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Datasets",
      "text": "Experiments in this work were conducted on popular, public physiological datasets: WESAD, AMIGOS, CLAS, and DEAP.\n\nWESAD is a multimodal dataset for wearable stress and affect detection with data recorded using a wrist-worn device (sensors: PPG, accelerometer, electrodermal activity, and body temperature) and a chest-worn device (sensors: ECG, accelerometer, EMG, respiration, and body temperature). The dataset consists of 15 subjects (aged 24-35 years) with 100 min of data each. The dataset was recorded with the goal of detecting and distinguishing between three affective states: neutral, stress, amusement which were denoted using self-reports for subjective experience during the emotional stimulus along with the study protocol of inducing emotion  [9] .\n\nThe AMIGOS dataset consists of data from sensors (EEG, ECG and GSR), full-body videos, and depth videos from 40 volunteers. Data was collected while watching 16 short videos and 37 of the 40 volunteers watching 4 long-videos. Both self-assessment (valence-arousal, control, familiarity, like-dislike, and selection of basic emotions) and external assessment of participants' levels of valence were used to annotate the dataset. The participants were also asked to fill forms with Personality Traits and Positive and Negative Affect Schedule (PANAS) questionnaires  [11] .\n\nDEAP contains EEG, GSR, RESP, SKT, EMG, EOG, BVP data from 32 volunteers while they were watching 40 one minute-long music videos. Additionally, frontal face video was recorded for 22 of the participants. The dataset was self-annotated after each video with the following labels: arousal, valence, like-dislike, familiarity, and dominance by the volunteers  [10] .\n\nPPG, EEG and GSR data from 60 patients engaged in cognitively difficult tasks from was collected in the CLAS dataset.\n\nThe cognitively difficult tasks used in this dataset is: Stroop test, math test, logic problem test, and emotionally evoking stimuli  [24] . The dataset was labeled based on the study protocol (i.e., high cognitive load during logic and math problems and low cognitive load during neutral stimuli).",
      "page_start": 5,
      "page_end": 6
    },
    {
      "section_name": "Results",
      "text": "The results presented in this work use a standard 10-fold Leave-One-Subject-Out (LOSO) where the models were trained on all subjects excluding one and testing on the excluded subject.\n\nThe dimensionality of the latent space is too high to be visualized, so Principal Component Analysis (PCA) is used to condense the space into three components. Figure  2  compares the latent space using MSE with our cost function. Figure  2 (a) -2(d) shows a large overlap of classes which would lead to imprecise decision boundaries. Specifically consider Figure  2 (b) where all classes are highly interrelated. In contrast, the latent space in 2(f) shows a clear separation of classes by utilizing Wasserstein Distance. While the advantages of the novel cost function is distinct in three dimensions, the latent space has higher dimensionality, and the improvements are expressed using the euclidean distance between centroids of classes and the euclidean distance between closest points between different classes.\n\nFigure  3  highlights the percent increase between the centroids of classes in all datasets with the novel cost function for training and testing data. For all datasets, there is a significant increase in the distance over MSE. Additionally, Figure  4  shows the increase in the minimum distance between samples of classes.\n\nThe accuracy of our models is presented in Table  1  through a comparison of MSE with our novel cost function using LOSO. The table shows that the proposed cost function is able to achieve better performance on most datasets and performed the same as the MSE in the worst case scenario. The experiments presented in this work were conducted on a computer with a AMD Ryzen 9 5900HX, NVIDIA GeForce RTX 3070, and 32 GB of RAM with an approximate run time of 45 minutes per dataset.",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "Conclusion And Future Works",
      "text": "The lack of generalizability of affective state detection models has been a consistent issue. It is often due to a large variation in the distribution of physiological data for a set of individuals in reaction to the same stimuli. This leads to subject dependent noise that affects the performance of a model. Our approach employs autoencoders that can inherently reduce noise and extract relevant features through dimensionality reduction. In order to further reduce the subject-dependent noise, we introduce a novel cost function that uses Optimal Transport Theory to lower the   importance of uncommon patterns across individuals. This results in a latent space of affective state classes with increased separability.\n\nThe model was trained and tested on four different datasets and the performance of the proposed cost function was compared to the state-of-the-art MSE. From our study, we show the proposed cost function significantly increases the distance between classes in the latent space across all datasets. An average increase of 14.75% and 17.75% (from benchmark to proposed loss function) was found for minimum distance between classes and centroid euclidean distance respectively.\n\nAdditionally, our proposed cost function increases the robustness of affective computing models allowing for generalizability as the population increases. The larger the population, the more diverse the physiological responses to stimuli. This results in overlap between class clusters leaving no space to draw accurate decision boundaries. Since state-of-the-art models do not have a mechanism to accommodate this increased noise, their performance might decreases as the population size increase. Alternatively, our proposed loss function mitigates the affect of increased subject-dependent noise while increasing the performance by allowing the model to train on more data.\n\nHowever, commonly used public physiological datasets do not contain samples from a large population as the compilation of a large dataset is expensive. In our experiments, we used datasets with a smaller population size and were still able to show an increase in the distance between classes. Even though there was a significant increase in the separation between the classes, the accuracy of a multilayer perceptron trained on the latent space was nearly equivalent to that of the state-of-the-art models (see Table  1 ). We were not able to highlight the full extent of the cost function due to the lack of a large scale physiological dataset. Future works include implementation of more complex encoder and decoder models (for e.g., LSTMs and CNNs), exploration of different classifiers on the latent space in order to further increase the accuracy, and investigation of the cost function on a large scale dataset.",
      "page_start": 6,
      "page_end": 8
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Architecture of the Autoencoder model with a classifier attached to the latent space.",
      "page": 4
    },
    {
      "caption": "Figure 1: shows the architecture of our model, and both components (encoder and classifier) are",
      "page": 4
    },
    {
      "caption": "Figure 2: compares the latent space using MSE with our cost function. Figure",
      "page": 6
    },
    {
      "caption": "Figure 2: (b) where all classes are highly interrelated. In contrast, the latent space in 2(f) shows a clear separation of",
      "page": 6
    },
    {
      "caption": "Figure 3: highlights the percent increase between the centroids of classes in all datasets with the novel cost function for",
      "page": 6
    },
    {
      "caption": "Figure 4: shows the increase in the minimum distance between samples of classes.",
      "page": 6
    },
    {
      "caption": "Figure 2: Autoencoder latent space visualization using PCA",
      "page": 7
    },
    {
      "caption": "Figure 3: Distance increase when using the novel cost function over MSE expressed as a percentage for training and",
      "page": 7
    },
    {
      "caption": "Figure 4: Distance increase when using the novel cost function over MSE expressed as a percentage for training and",
      "page": 8
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Nibraas A. Khan": "Department of Computer Science",
          "Mahrukh Tauseef": "Department of Electrical Engineering"
        },
        {
          "Nibraas A. Khan": "Vanderbilt University",
          "Mahrukh Tauseef": "Vanderbilt University"
        },
        {
          "Nibraas A. Khan": "Nashville, TN 37235",
          "Mahrukh Tauseef": "Nashville, TN 37235"
        },
        {
          "Nibraas A. Khan": "nibraas.a.khan@vanderbilt.edu",
          "Mahrukh Tauseef": "mahrukh.tauseef@vanderbilt.edu"
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Vanderbilt University": "Nashville, TN 37235"
        },
        {
          "Vanderbilt University": "mahrukh.tauseef@vanderbilt.edu"
        },
        {
          "Vanderbilt University": "Nilanjan Sarkar"
        },
        {
          "Vanderbilt University": "Department of Mechanical Engineering"
        },
        {
          "Vanderbilt University": "Vanderbilt University"
        },
        {
          "Vanderbilt University": "Nashville, TN 37235"
        },
        {
          "Vanderbilt University": "nilanjan.sarkar@vanderbilt.edu"
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Khan et al.": "Affective state can be measured and monitored in two ways:\nintrusively and non-intrusively. Intrusive methods measure"
        },
        {
          "Khan et al.": "the concentration of various hormones in the blood stream that can be used to detect an affective state. For instance,"
        },
        {
          "Khan et al.": "cortisol levels produced by the hypothalamic-pituitary-adrenocortical (HPA) axis can be collected through samples of"
        },
        {
          "Khan et al.": "blood, urine, hair or saliva and used to detect stress [5]. One of the challenges with intrusive measurement is that it is"
        },
        {
          "Khan et al.": "invasive and cannot be used to monitor the affective state in real-time."
        },
        {
          "Khan et al.": "Non-intrusive methods, on the other hand,\ninclude the analysis of behavioral or physiological data that can lead to"
        },
        {
          "Khan et al.": "non-invasive real-time detection of affective states. Behavioural actions such as blink rate, facial expression, gesture,"
        },
        {
          "Khan et al.": "speech, and body pose have been commonly used for affective state detection [6]. However, all\nthese actions can"
        },
        {
          "Khan et al.": "be masked and voluntarily controlled by a subject which reduces its reliability [4, 6]. Alternatively, strong evidence"
        },
        {
          "Khan et al.": "suggests physiological signals to be more reliable for affective state detection due to its involuntary nature and a strong"
        },
        {
          "Khan et al.": "correlation of patterns in the data with different affective states [5]."
        },
        {
          "Khan et al.": "Physiological signals are a response to the Autonomic Nervous System (ANS) utilizing both motor and sensory neurons"
        },
        {
          "Khan et al.": "to communicate and operate between the Central Nervous System (CNS) and the various organs or muscles. The ANS"
        },
        {
          "Khan et al.": "is composed of the Sympathetic (SNS) and Parasympathetic (PNS) nervous systems. The sympathetic nervous system"
        },
        {
          "Khan et al.": "prepares the body for emergency action, which results in the “fight or flight” response [7]. The response leads to an"
        },
        {
          "Khan et al.": "increase in measurable physiological signals, such as heart rate, blood flow, and increased muscle activation which can"
        },
        {
          "Khan et al.": "be mapped to different affective states. Whereas, the parasympathetic nervous system helps sustain homeostasis during"
        },
        {
          "Khan et al.": "rest by decreasing physiological signals and maintaining them in moderate ranges [8]. Since ANS is involuntarily"
        },
        {
          "Khan et al.": "stimulated, the response cannot be manipulated or masked by an individual. This has led to the popular field of affecting"
        },
        {
          "Khan et al.": "computing to focus on dynamically identifying different affective states using non-invasive wearable sensors that can"
        },
        {
          "Khan et al.": "monitor changes in physiological signals in response to a stimulus."
        },
        {
          "Khan et al.": "The ability to map patterns in physiological data with affective states has allowed for utilization of machine learning"
        },
        {
          "Khan et al.": "techniques for the detection of affective states. Research in psychophysiology has led to the compilation of a compre-"
        },
        {
          "Khan et al.": "hensive list of physiological data that can be used to monitor affective state. This list includes heart activity (ECG),"
        },
        {
          "Khan et al.": "brain activity (EEG), skin response (EDA), blood pressure variation (PPG), respiratory response, and muscle activity"
        },
        {
          "Khan et al.": "(EMG) [5]. Several datasets have been compiled by collecting physiological data while inducing an affective state. For"
        },
        {
          "Khan et al.": "instance, one of the state-of-the-art datasets, Wearable Stress and Affect Detection (WESAD) [9], induced amusement"
        },
        {
          "Khan et al.": "by making the subjects watch funny video clips and they induced stress through public speaking and mental arithmetic"
        },
        {
          "Khan et al.": "tasks. Meanwhile, their physiological data i.e., blood volume pulse, ECG, EDA, EMG, respiration, body temperature,"
        },
        {
          "Khan et al.": "and three-axis acceleration was collected and classified simultaneously. Other common datasets like Database for"
        },
        {
          "Khan et al.": "Emotional Analysis using Physiological Signals (DEAP) [10], Affect, Personality and Mood Research on Individuals"
        },
        {
          "Khan et al.": "and Groups (AMIGOS) [11], and Cognitive Load, Affect, and Stress Recognition (CLAS) [12] follow suit by using"
        },
        {
          "Khan et al.": "video clips or stress-inducing tasks to collect and classify physiological data for the induced affective states."
        },
        {
          "Khan et al.": "Numerous machine learning techniques have been utilised to detect affective states from physiological data. These"
        },
        {
          "Khan et al.": "approaches include support vector machines (SVM),\nrandom forest (RF), k-nearest neighbors (KNN) and Linear"
        },
        {
          "Khan et al.": "Discriminant Analysis (LDA) that need handcrafted features from the pre-processed signal in order to remove noisy"
        },
        {
          "Khan et al.": "data [6]. However, there is no consensus on the list of features extracted from physiological data that can be accurately"
        },
        {
          "Khan et al.": "mapped to affective states which results in reduced performance [13]. Alternatively, with the advancement of deep"
        },
        {
          "Khan et al.": "learning, there has been an increasing interest in using deep learning techniques like long short-term memory (LSTM),"
        },
        {
          "Khan et al.": "autoencoders, and convolutional neural networks (CNN) [3, 14]. These models allow for automatic feature extraction"
        },
        {
          "Khan et al.": "based on the model’s ability to automatically comprehend patterns in data with respect to the labels."
        },
        {
          "Khan et al.": "Even though deep learning techniques show promise, the lack of generalisability still exists and contributes to poor"
        },
        {
          "Khan et al.": "performance. This is because the subjects might not exhibit the same physiological response for a stimuli [13]. Thus,"
        },
        {
          "Khan et al.": "subject dependent noise can lead to poor generalisability of the model. This issue can be resolved by using a loss"
        },
        {
          "Khan et al.": "function that filters out the features of data that are person specific and do not contribute much to affective state detection."
        },
        {
          "Khan et al.": "In other words, if each subject’s data is treated as a distribution, the loss function assigns higher importance to features"
        },
        {
          "Khan et al.": "that are closer in distance to the group distribution (distributions of all subjects) while assigning lower importance"
        },
        {
          "Khan et al.": "to features that are much further apart across from the group distribution. The distance between distributions can be"
        },
        {
          "Khan et al.": "calculated by using the Wasserstein distance [15]."
        },
        {
          "Khan et al.": "In this paper, we introduce a novel\nloss function that accounts for subject dependent noise in the data in order to"
        },
        {
          "Khan et al.": "develop more generalizable models. This is accomplished by training an autoencoder model with a loss function that"
        },
        {
          "Khan et al.": "utilizes Wasserstein Distance to scale the importance of subject dependent patterns to obtain a latent space with reduced"
        },
        {
          "Khan et al.": "dimensions and less noisy subject\nindependent features. The performance of the model\nis tested on four different"
        },
        {
          "Khan et al.": "datasets (WESAD, AMIGOS, CLAS, and DEAP) using the centroid and minimum distances between classes as metrics."
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Khan et al.": "This paper is structured as follows. Section 2 presents an overview of existing literature that informed the development"
        },
        {
          "Khan et al.": "of the proposed model. This is followed by the 3 section that discusses the mathematical and algorithmic details of the"
        },
        {
          "Khan et al.": "model. The results are shown and discussed in Section 4 followed by concluding remarks in Section 5."
        },
        {
          "Khan et al.": "2\nBackground"
        },
        {
          "Khan et al.": "As mentioned before, machine learning techniques for affective state detection using physiological data has been a"
        },
        {
          "Khan et al.": "topic of immense interest in the past few years. Kolodyazhniy et al. [16] conducted a notable study in 2011 on the topic"
        },
        {
          "Khan et al.": "by compiling a dataset and training several machine learning models like LDA, Quaratic Discriminant Analyis (QDA),"
        },
        {
          "Khan et al.": "Multilayer Perceptron (MLP), Radial Basis Function (RBF), and KNN. They used a variety of features extracted from"
        },
        {
          "Khan et al.": "the physiological data to discover the features that are strongly correlated to affective state. They reported maximum"
        },
        {
          "Khan et al.": "accuracy of 81.9% using KNN with 7 features on subject-dependent classification, but they reported the accuracy to go"
        },
        {
          "Khan et al.": "down to 78.9% for subject independent classification."
        },
        {
          "Khan et al.": "Ever since, several novel\ntechniques have been implemented to improve the performance of subject\nindependent"
        },
        {
          "Khan et al.": "classification. Bota et al.\n[17] conducted a review of existing machine learning and deep learning techniques for"
        },
        {
          "Khan et al.": "affective state detection from 2001 to 2019. They reported lower performance for subject independent classification as"
        },
        {
          "Khan et al.": "compared to subject dependent classification for most of the models."
        },
        {
          "Khan et al.": "Li et. al [18] proposed a technique that assigned variable learnable weights to different physiological signals fed to an"
        },
        {
          "Khan et al.": "attention-based bidirectional LSTM model. They reported an accuracy of 81.1% for subject-independent classification"
        },
        {
          "Khan et al.": "using the AMIGOS dataset. However, the model’s accuracy across other datasets is not known."
        },
        {
          "Khan et al.": "Reviews conducted by both Bota et al. [17] and Xin et al. [19] highlighted the lack of generalisation to be a consistent"
        },
        {
          "Khan et al.": "issue with the existing techniques for affective state detection. This has led to several works proposing novel techniques"
        },
        {
          "Khan et al.": "to increase generalisation of affective state detection models."
        },
        {
          "Khan et al.": "Li et al. [20] used different automatic feature selection techniques such as Chi-Squared-Based Feature Selection, Mutual"
        },
        {
          "Khan et al.": "Information-Based Feature Selection, ANOVA F-Value-Based Feature Selection, Recursive Feature Elimination (RFE),"
        },
        {
          "Khan et al.": "and L1-Norm Penalty-Based Feature Selection. These techniques were used such that\nthe most\nimportant features"
        },
        {
          "Khan et al.": "needed for affective state detection can be extracted and used to train an SVM. They reported an accuracy of 83.3% for"
        },
        {
          "Khan et al.": "subject independent classification using the SEED dataset and 59.06% using the DEAP dataset."
        },
        {
          "Khan et al.": "In addition, several domain adaptation techniques are being used in order to select features such that the difference"
        },
        {
          "Khan et al.": "between the distributions of each subject’s physiological data is minimized. Chai et al.\n[21] proposed a Subspace"
        },
        {
          "Khan et al.": "Alignment Autoencoder to minimize the distribution mismatch of the physiological data of each subject by minimizing"
        },
        {
          "Khan et al.": "the maximum mean discrepancy of reproduced kernel Hilbert space (RKHS). This allowed the alignment of different"
        },
        {
          "Khan et al.": "distributions by mitigating the subject-specific noise from the data. They reported an accuracy 77.8% using the SEED"
        },
        {
          "Khan et al.": "dataset."
        },
        {
          "Khan et al.": "Based on the literature survey, we identified the potential of decreasing the distance between each subject’s distribution"
        },
        {
          "Khan et al.": "of physiological data and use the extracted features to train a more generalised model. However, this entails that a robust"
        },
        {
          "Khan et al.": "method needs to be chosen to calculate the distance between distribution. One such method, Wasserstein Distance, can"
        },
        {
          "Khan et al.": "be retrieved from Optimal Transport Theory (OTT) [15]. Wasserstein Distance allows for the calculation of the distance"
        },
        {
          "Khan et al.": "between distributions while also considering the geometry of the distribution (symmetrical and triangular) [22]. Kolouri"
        },
        {
          "Khan et al.": "et al.\n[22] demonstrated the potential of Wasserstein Distance to minimize the distance between an input and target"
        },
        {
          "Khan et al.": "distribution for generative modeling using autoencoders."
        },
        {
          "Khan et al.": "Hence, in this paper, we propose a novel loss function using Wasserstein Distance for automatic feature extraction by"
        },
        {
          "Khan et al.": "assigning more weight to features that are closer in distance to each other across all subjects. An autoencoder model is"
        },
        {
          "Khan et al.": "used to generate a latent space that excludes all the features that are influenced by subject-dependent nuances. The"
        },
        {
          "Khan et al.": "goal\nis to increase the separation between different affective states in the latent space such that a more generalised"
        },
        {
          "Khan et al.": "classification model can be trained."
        },
        {
          "Khan et al.": "3\nMethods"
        },
        {
          "Khan et al.": "The datasets are publicly available through their respective organizations, and the code used for the presented work is"
        },
        {
          "Khan et al.": "publicly provided (https://anonymous.4open.science/status/NeurIPS-F252)."
        },
        {
          "Khan et al.": "3"
        }
      ],
      "page": 3
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Figure 1: Architecture of the Autoencoder model with a classifier attached to the latent space.": "3.1\nOptimal Transport Theory"
        },
        {
          "Figure 1: Architecture of the Autoencoder model with a classifier attached to the latent space.": "Optimal Transport Theory was first formalized by the French mathematician, Gaspard Monge, in 1781, right before the"
        },
        {
          "Figure 1: Architecture of the Autoencoder model with a classifier attached to the latent space.": "French revolution [15]. The motivation to study this was to come up with a transport plan to move a mass from one point"
        },
        {
          "Figure 1: Architecture of the Autoencoder model with a classifier attached to the latent space.": "to another with minimum cost. The outcome of this study formulated a method for measuring the distance between two"
        },
        {
          "Figure 1: Architecture of the Autoencoder model with a classifier attached to the latent space.": "probability distributions.\nIn the formulation, consider two probability measures µ and v defined on spaces X and Y"
        },
        {
          "Figure 1: Architecture of the Autoencoder model with a classifier attached to the latent space.": "respectively. µ and v have density functions f and g where dµ = f (x)dx and dv = g(y)dy, where (x, y) ∈ XxY . A"
        },
        {
          "Figure 1: Architecture of the Autoencoder model with a classifier attached to the latent space.": "cost function is defined, c(x, y) which finds the distance between a point x and y. The initial choice by Monge was"
        },
        {
          "Figure 1: Architecture of the Autoencoder model with a classifier attached to the latent space.": "Euclidean distance. A transport plan T : X −→ Y allows for moving a mass, M, from X to Y such that the measure µ"
        },
        {
          "Figure 1: Architecture of the Autoencoder model with a classifier attached to the latent space.": "of the mass in space X is the same as the measure v of the mass in space Y after the mass is transported from X to Y:"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Khan et al.": "3.3"
        },
        {
          "Khan et al.": "The group reconstruction error, rg, of the autoencoder for the subject-independent model is given as"
        },
        {
          "Khan et al.": ""
        },
        {
          "Khan et al.": ""
        },
        {
          "Khan et al.": ""
        },
        {
          "Khan et al.": ""
        },
        {
          "Khan et al.": ""
        },
        {
          "Khan et al.": "subject specific classifier error. The group classifier uses all labeled samples available across all subjects."
        },
        {
          "Khan et al.": ""
        },
        {
          "Khan et al.": ""
        },
        {
          "Khan et al.": ""
        },
        {
          "Khan et al.": ""
        },
        {
          "Khan et al.": "i’s specific loss is computed using all labeled samples available Si and any loss function Lc."
        },
        {
          "Khan et al.": ""
        },
        {
          "Khan et al.": ""
        },
        {
          "Khan et al.": ""
        },
        {
          "Khan et al.": ""
        },
        {
          "Khan et al.": "λs,i"
        },
        {
          "Khan et al.": "overall classification loss is given as:"
        },
        {
          "Khan et al.": ""
        },
        {
          "Khan et al.": ""
        },
        {
          "Khan et al.": ""
        },
        {
          "Khan et al.": ""
        },
        {
          "Khan et al.": "formulation for λs,i."
        },
        {
          "Khan et al.": ""
        },
        {
          "Khan et al.": ""
        },
        {
          "Khan et al.": "αs,i"
        },
        {
          "Khan et al.": "scaling factor, λs,i, is."
        },
        {
          "Khan et al.": ""
        },
        {
          "Khan et al.": ""
        },
        {
          "Khan et al.": ""
        },
        {
          "Khan et al.": ""
        },
        {
          "Khan et al.": "Finally, λg is determined by ensuring that the regularizer terms sum to 1."
        },
        {
          "Khan et al.": ""
        },
        {
          "Khan et al.": ""
        },
        {
          "Khan et al.": "3.4"
        },
        {
          "Khan et al.": ""
        },
        {
          "Khan et al.": "DEAP."
        },
        {
          "Khan et al.": "WESAD is a multimodal dataset for wearable stress and affect detection with data recorded using a wrist-worn device"
        },
        {
          "Khan et al.": ""
        },
        {
          "Khan et al.": ""
        }
      ],
      "page": 5
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Table 1: A comparison of the accuracy between using the standard MSE for reconstruction loss and the novel cost": ""
        },
        {
          "Table 1: A comparison of the accuracy between using the standard MSE for reconstruction loss and the novel cost": "WESAD"
        },
        {
          "Table 1: A comparison of the accuracy between using the standard MSE for reconstruction loss and the novel cost": "CLAS"
        },
        {
          "Table 1: A comparison of the accuracy between using the standard MSE for reconstruction loss and the novel cost": "AMIGOS"
        },
        {
          "Table 1: A comparison of the accuracy between using the standard MSE for reconstruction loss and the novel cost": "DEAP"
        }
      ],
      "page": 6
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Khan et al.": "(a) WESAD MSE"
        },
        {
          "Khan et al.": "(e) WESAD Custom"
        },
        {
          "Khan et al.": ""
        },
        {
          "Khan et al.": ""
        },
        {
          "Khan et al.": ""
        },
        {
          "Khan et al.": "Figure 3: Distance increase when using the novel cost function over MSE expressed as a percentage for training and"
        },
        {
          "Khan et al.": "testing data (LOSO) for class centroids."
        },
        {
          "Khan et al.": ""
        }
      ],
      "page": 7
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "(c) CLAS": "Figure 4: Distance increase when using the novel cost function over MSE expressed as a percentage for training and",
          "(d) AMIGOS": ""
        },
        {
          "(c) CLAS": "testing data (LOSO) for the minimum distance between classes.",
          "(d) AMIGOS": ""
        },
        {
          "(c) CLAS": "importance of uncommon patterns across individuals. This results in a latent space of affective state classes with",
          "(d) AMIGOS": ""
        },
        {
          "(c) CLAS": "increased separability.",
          "(d) AMIGOS": ""
        },
        {
          "(c) CLAS": "The model was trained and tested on four different datasets and the performance of the proposed cost function was",
          "(d) AMIGOS": ""
        },
        {
          "(c) CLAS": "compared to the state-of-the-art MSE. From our study, we show the proposed cost function significantly increases",
          "(d) AMIGOS": ""
        },
        {
          "(c) CLAS": "the distance between classes in the latent space across all datasets. An average increase of 14.75% and 17.75% (from",
          "(d) AMIGOS": ""
        },
        {
          "(c) CLAS": "benchmark to proposed loss function) was found for minimum distance between classes and centroid euclidean distance",
          "(d) AMIGOS": ""
        },
        {
          "(c) CLAS": "respectively.",
          "(d) AMIGOS": ""
        },
        {
          "(c) CLAS": "Additionally, our proposed cost function increases the robustness of affective computing models allowing for gen-",
          "(d) AMIGOS": ""
        },
        {
          "(c) CLAS": "eralizability as the population increases. The larger the population,",
          "(d) AMIGOS": "the more diverse the physiological responses"
        },
        {
          "(c) CLAS": "",
          "(d) AMIGOS": "to stimuli. This results in overlap between class clusters leaving no space to draw accurate decision boundaries."
        },
        {
          "(c) CLAS": "Since state-of-the-art models do not have a mechanism to accommodate this increased noise, their performance might",
          "(d) AMIGOS": ""
        },
        {
          "(c) CLAS": "decreases as the population size increase. Alternatively, our proposed loss function mitigates the affect of increased",
          "(d) AMIGOS": ""
        },
        {
          "(c) CLAS": "subject-dependent noise while increasing the performance by allowing the model to train on more data.",
          "(d) AMIGOS": ""
        },
        {
          "(c) CLAS": "",
          "(d) AMIGOS": "However, commonly used public physiological datasets do not contain samples from a large population as the compila-"
        },
        {
          "(c) CLAS": "tion of a large dataset is expensive. In our experiments, we used datasets with a smaller population size and were still",
          "(d) AMIGOS": ""
        },
        {
          "(c) CLAS": "able to show an increase in the distance between classes. Even though there was a significant increase in the separation",
          "(d) AMIGOS": ""
        },
        {
          "(c) CLAS": "between the classes, the accuracy of a multilayer perceptron trained on the latent space was nearly equivalent to that of",
          "(d) AMIGOS": ""
        },
        {
          "(c) CLAS": "the state-of-the-art models (see Table 1). We were not able to highlight the full extent of the cost function due to the",
          "(d) AMIGOS": ""
        },
        {
          "(c) CLAS": "lack of a large scale physiological dataset. Future works include implementation of more complex encoder and decoder",
          "(d) AMIGOS": ""
        },
        {
          "(c) CLAS": "models (for e.g., LSTMs and CNNs), exploration of different classifiers on the latent space in order to further increase",
          "(d) AMIGOS": ""
        },
        {
          "(c) CLAS": "the accuracy, and investigation of the cost function on a large scale dataset.",
          "(d) AMIGOS": ""
        }
      ],
      "page": 8
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Khan et al.": "[4] Muhammad Khateeb, Syed Muhammad Anwar, and Majdi Alnowami. Multi-domain feature fusion for emotion"
        },
        {
          "Khan et al.": "classification using deap dataset.\nIEEE Access, 9:12134–12142, 2021."
        },
        {
          "Khan et al.": "[5] Shalom Greene, Himanshu Thapliyal, and Allison Caban-Holt. A survey of affective computing for stress"
        },
        {
          "Khan et al.": "detection: Evaluating technologies in stress detection for better health.\nIEEE Consumer Electronics Magazine,"
        },
        {
          "Khan et al.": "5:44–56, 2016."
        },
        {
          "Khan et al.": "[6] Lin Shu, Jinyan Xie, Mingyue Yang, Ziyi Li, Zhenqi Li, Dan Liao, Xiangmin Xu, and Xinyi Yang. A review of"
        },
        {
          "Khan et al.": "emotion recognition using physiological signals. Sensors, 18(7):2074, 2018."
        },
        {
          "Khan et al.": "[7] Michael Richter and Rex A Wright. Sympathetic nervous system (sns). Encyclopedia of behavioral medicine,"
        },
        {
          "Khan et al.": "pages 1943–1944, 2013."
        },
        {
          "Khan et al.": "[8] Gerald Glick, Eugene Braunwald, and Robert M Lewis. Relative roles of the sympathetic and parasympathetic"
        },
        {
          "Khan et al.": "nervous systems in the reflex control of heart rate. Circulation research, 16:363–375, 1965."
        },
        {
          "Khan et al.": "[9] Philip Schmidt, Attila Reiss, Robert Duerichen, Claus Marberger, and Kristof Van Laerhoven.\nIntroducing wesad,"
        },
        {
          "Khan et al.": "the 20th ACM international\na multimodal dataset for wearable stress and affect detection.\nIn Proceedings of"
        },
        {
          "Khan et al.": "conference on multimodal interaction, pages 400–408, 2018."
        },
        {
          "Khan et al.": "[10] Sander Koelstra, Christian Muhl, Mohammad Soleymani, Jong-Seok Lee, Ashkan Yazdani, Touradj Ebrahimi,"
        },
        {
          "Khan et al.": "Thierry Pun, Anton Nijholt, and Ioannis Patras. Deap: A database for emotion analysis; using physiological"
        },
        {
          "Khan et al.": "signals.\nIEEE transactions on affective computing, 3(1):18–31, 2011."
        },
        {
          "Khan et al.": "[11]\nJuan Abdon Miranda-Correa, Mojtaba Khomami Abadi, Nicu Sebe, and Ioannis Patras. Amigos: A dataset for"
        },
        {
          "Khan et al.": "affect, personality and mood research on individuals and groups.\nIEEE Transactions on Affective Computing,"
        },
        {
          "Khan et al.": "12(2):479–493, 2018."
        },
        {
          "Khan et al.": "[12] Valentina Markova, Todor Ganchev, and Kalin Kalinkov. Clas: A database for cognitive load, affect and stress"
        },
        {
          "Khan et al.": "recognition.\nIn 2019 International Conference on Biomedical Innovations and Applications (BIA), pages 1–4,"
        },
        {
          "Khan et al.": "2019."
        },
        {
          "Khan et al.": "[13] Russell Li and Zhandong Liu.\nStress detection using deep neural networks. BMC Medical Informatics and"
        },
        {
          "Khan et al.": "Decision Making, 20(11):1–10, 2020."
        },
        {
          "Khan et al.": "[14] Ali Oskooei, Sophie Mai Chau, Jonas Weiss, Arvind Sridhar, María Rodríguez Martínez, and Bruno Michel."
        },
        {
          "Khan et al.": "Destress: deep learning for unsupervised identification of mental stress in firefighters from heart-rate variability"
        },
        {
          "Khan et al.": "(hrv) data.\nIn Explainable AI in Healthcare and Medicine, pages 93–105. Springer, 2021."
        },
        {
          "Khan et al.": "[15] Gaspard Monge. Memory on the theory of cuttings and embankments. History of the Royal Academy of Sciences"
        },
        {
          "Khan et al.": "of Paris, 1781."
        },
        {
          "Khan et al.": "[16] Vitaliy Kolodyazhniy, Sylvia D Kreibig, James J Gross, Walton T Roth, and Frank H Wilhelm. An affective"
        },
        {
          "Khan et al.": "computing approach to physiological emotion specificity: Toward subject-independent and stimulus-independent"
        },
        {
          "Khan et al.": "classification of film-induced emotions. Psychophysiology, 48(7):908–922, 2011."
        },
        {
          "Khan et al.": "[17] Patricia J. Bota, Chen Wang, Ana L.N. Fred, and Hugo Placido Da Silva. A review, current challenges, and"
        },
        {
          "Khan et al.": "future possibilities on emotion recognition using machine learning and physiological signals.\nIEEE Access,"
        },
        {
          "Khan et al.": "7:140990–141020, 2019."
        },
        {
          "Khan et al.": "[18] Chao Li, Zhongtian Bao, Linhao Li, and Ziping Zhao. Exploring temporal representations by leveraging attention-"
        },
        {
          "Khan et al.": "based bidirectional\nlstm-rnns for multi-modal emotion recognition.\nInformation Processing & Management,"
        },
        {
          "Khan et al.": "57(3):102185, 2020."
        },
        {
          "Khan et al.": "[19] Xin Hu, Jingjing Chen, Fei Wang, and Dan Zhang. Ten challenges for eeg-based affective computing. Brain"
        },
        {
          "Khan et al.": "Science Advances, 5(1):1–20, 2019."
        },
        {
          "Khan et al.": "Exploring eeg features in\n[20] Xiang Li, Dawei Song, Peng Zhang, Yazhou Zhang, Yuexian Hou, and Bin Hu."
        },
        {
          "Khan et al.": "cross-subject emotion recognition. Frontiers in neuroscience, 12:162, 2018."
        },
        {
          "Khan et al.": "[21] Xin Chai, Qisong Wang, Yongping Zhao, Xin Liu, Ou Bai, and Yongqiang Li. Unsupervised domain adaptation"
        },
        {
          "Khan et al.": "techniques based on auto-encoder for non-stationary eeg-based emotion recognition. Computers in biology and"
        },
        {
          "Khan et al.": "medicine, 79:205–214, 2016."
        },
        {
          "Khan et al.": "In\n[22] Soheil Kolouri, Phillip E Pope, Charles E Martin, and Gustavo K Rohde. Sliced wasserstein auto-encoders."
        },
        {
          "Khan et al.": "International Conference on Learning Representations, 2018."
        },
        {
          "Khan et al.": "[23] Yunan Yang, Björn Engquist, Junzhe Sun, and Brittany F Hamfeldt. Application of optimal transport and the"
        },
        {
          "Khan et al.": "quadratic wasserstein metric to full-waveform inversion. Geophysics, 83(1):R43–R62, 2018."
        },
        {
          "Khan et al.": "[24] Valentina Markova, Todor Ganchev, and Kalin Kalinkov. Clas: A database for cognitive load, affect and stress"
        },
        {
          "Khan et al.": "recognition.\nIn 2019 International Conference on Biomedical Innovations and Applications (BIA), pages 1–4."
        },
        {
          "Khan et al.": "IEEE, 2019."
        }
      ],
      "page": 9
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Social cognition and attitudes",
      "authors": [
        "A Michael",
        "Dominic Hogg",
        "Abrams"
      ],
      "year": "2007",
      "venue": "Psychology. Third Edition"
    },
    {
      "citation_id": "2",
      "title": "Nurul Fazmidar Binti Mohd Noor, Mohamad Nizam Bin Ayub, Hannyzzura Binti Affal, and Nornazlita Binti Hussin. Affective computing in education: A systematic review and future research",
      "authors": [
        "Elaheh Yadegaridehkordi"
      ],
      "year": "2019",
      "venue": "Computers & Education"
    },
    {
      "citation_id": "3",
      "title": "A survey of multidisciplinary domains contributing to affective computing",
      "authors": [
        "Resham Arya",
        "Jaiteg Singh",
        "Ashok Kumar"
      ],
      "year": "2021",
      "venue": "Computer Science Review"
    },
    {
      "citation_id": "4",
      "title": "Multi-domain feature fusion for emotion classification using deap dataset",
      "authors": [
        "Muhammad Khateeb",
        "Syed Muhammad Anwar",
        "Majdi Alnowami"
      ],
      "year": "2021",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "5",
      "title": "A survey of affective computing for stress detection: Evaluating technologies in stress detection for better health",
      "authors": [
        "Shalom Greene",
        "Himanshu Thapliyal",
        "Allison Caban-Holt"
      ],
      "year": "2016",
      "venue": "IEEE Consumer Electronics Magazine"
    },
    {
      "citation_id": "6",
      "title": "A review of emotion recognition using physiological signals",
      "authors": [
        "Lin Shu",
        "Jinyan Xie",
        "Mingyue Yang",
        "Ziyi Li",
        "Zhenqi Li",
        "Dan Liao",
        "Xiangmin Xu",
        "Xinyi Yang"
      ],
      "year": "2018",
      "venue": "Sensors"
    },
    {
      "citation_id": "7",
      "title": "Sympathetic nervous system (sns). Encyclopedia of behavioral medicine",
      "authors": [
        "Michael Richter",
        "Rex Wright"
      ],
      "year": "2013",
      "venue": "Sympathetic nervous system (sns). Encyclopedia of behavioral medicine"
    },
    {
      "citation_id": "8",
      "title": "Relative roles of the sympathetic and parasympathetic nervous systems in the reflex control of heart rate",
      "authors": [
        "Gerald Glick",
        "Eugene Braunwald",
        "Robert Lewis"
      ],
      "year": "1965",
      "venue": "Circulation research"
    },
    {
      "citation_id": "9",
      "title": "Introducing wesad, a multimodal dataset for wearable stress and affect detection",
      "authors": [
        "Philip Schmidt",
        "Attila Reiss",
        "Robert Duerichen",
        "Claus Marberger",
        "Kristof Van Laerhoven"
      ],
      "year": "2018",
      "venue": "Proceedings of the 20th ACM international conference on multimodal interaction"
    },
    {
      "citation_id": "10",
      "title": "Deap: A database for emotion analysis; using physiological signals",
      "authors": [
        "Sander Koelstra",
        "Christian Muhl",
        "Mohammad Soleymani",
        "Jong-Seok Lee",
        "Ashkan Yazdani",
        "Touradj Ebrahimi",
        "Anton Thierry Pun",
        "Ioannis Nijholt",
        "Patras"
      ],
      "year": "2011",
      "venue": "IEEE transactions on affective computing"
    },
    {
      "citation_id": "11",
      "title": "Amigos: A dataset for affect, personality and mood research on individuals and groups",
      "authors": [
        "Juan Abdon",
        "Mojtaba Khomami Abadi",
        "Nicu Sebe",
        "Ioannis Patras"
      ],
      "year": "2018",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "12",
      "title": "Clas: A database for cognitive load, affect and stress recognition",
      "authors": [
        "Valentina Markova",
        "Todor Ganchev",
        "Kalin Kalinkov"
      ],
      "year": "2019",
      "venue": "2019 International Conference on Biomedical Innovations and Applications (BIA)"
    },
    {
      "citation_id": "13",
      "title": "Stress detection using deep neural networks",
      "authors": [
        "Russell Li",
        "Zhandong Liu"
      ],
      "year": "2020",
      "venue": "BMC Medical Informatics and Decision Making"
    },
    {
      "citation_id": "14",
      "title": "Destress: deep learning for unsupervised identification of mental stress in firefighters from heart-rate variability (hrv) data",
      "authors": [
        "Ali Oskooei",
        "Sophie Chau",
        "Jonas Weiss",
        "Arvind Sridhar",
        "María Rodríguez Martínez",
        "Bruno Michel"
      ],
      "year": "2021",
      "venue": "Explainable AI in Healthcare and Medicine"
    },
    {
      "citation_id": "15",
      "title": "Memory on the theory of cuttings and embankments",
      "authors": [
        "Gaspard Monge"
      ],
      "venue": "History of the Royal Academy of Sciences"
    },
    {
      "citation_id": "16",
      "title": "An affective computing approach to physiological emotion specificity: Toward subject-independent and stimulus-independent classification of film-induced emotions",
      "authors": [
        "Vitaliy Kolodyazhniy",
        "Sylvia Kreibig",
        "James Gross",
        "Walton Roth",
        "Frank Wilhelm"
      ],
      "year": "2011",
      "venue": "Psychophysiology"
    },
    {
      "citation_id": "17",
      "title": "A review, current challenges, and future possibilities on emotion recognition using machine learning and physiological signals",
      "authors": [
        "Patricia Bota",
        "Chen Wang",
        "Ana Fred",
        "Hugo Placido",
        "Da Silva"
      ],
      "year": "2019",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "18",
      "title": "Exploring temporal representations by leveraging attentionbased bidirectional lstm-rnns for multi-modal emotion recognition",
      "authors": [
        "Chao Li",
        "Zhongtian Bao",
        "Linhao Li",
        "Ziping Zhao"
      ],
      "year": "2020",
      "venue": "Information Processing & Management"
    },
    {
      "citation_id": "19",
      "title": "Ten challenges for eeg-based affective computing",
      "authors": [
        "Xin Hu",
        "Jingjing Chen",
        "Fei Wang",
        "Dan Zhang"
      ],
      "year": "2019",
      "venue": "Brain Science Advances"
    },
    {
      "citation_id": "20",
      "title": "Exploring eeg features in cross-subject emotion recognition",
      "authors": [
        "Xiang Li",
        "Dawei Song",
        "Peng Zhang",
        "Yazhou Zhang",
        "Yuexian Hou",
        "Bin Hu"
      ],
      "year": "2018",
      "venue": "Frontiers in neuroscience"
    },
    {
      "citation_id": "21",
      "title": "Unsupervised domain adaptation techniques based on auto-encoder for non-stationary eeg-based emotion recognition",
      "authors": [
        "Xin Chai",
        "Qisong Wang",
        "Yongping Zhao",
        "Xin Liu",
        "Ou Bai",
        "Yongqiang Li"
      ],
      "year": "2016",
      "venue": "Computers in biology and medicine"
    },
    {
      "citation_id": "22",
      "title": "Sliced wasserstein auto-encoders",
      "authors": [
        "Soheil Kolouri",
        "Phillip Pope",
        "Charles Martin",
        "Gustavo Rohde"
      ],
      "year": "2018",
      "venue": "International Conference on Learning Representations"
    },
    {
      "citation_id": "23",
      "title": "Application of optimal transport and the quadratic wasserstein metric to full-waveform inversion",
      "authors": [
        "Yunan Yang",
        "Björn Engquist",
        "Junzhe Sun",
        "Brittany Hamfeldt"
      ],
      "year": "2018",
      "venue": "Geophysics"
    },
    {
      "citation_id": "24",
      "title": "Clas: A database for cognitive load, affect and stress recognition",
      "authors": [
        "Valentina Markova",
        "Todor Ganchev",
        "Kalin Kalinkov"
      ],
      "year": "2019",
      "venue": "2019 International Conference on Biomedical Innovations and Applications (BIA)"
    }
  ]
}