{
  "paper_id": "2510.06600v1",
  "title": "Fine-Grained Emotion Recognition Via In-Context Learning",
  "published": "2025-10-08T03:17:09Z",
  "authors": [
    "Zhaochun Ren",
    "Zhou Yang",
    "Chenglong Ye",
    "Haizhou Sun",
    "Chao Chen",
    "Xiaofei Zhu",
    "Xiangwen Liao"
  ],
  "keywords": [
    "Emotion Recognition",
    "In-Context Learning",
    "Large Language Models E1",
    "L1 E2",
    "L2 E3",
    "L3"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Fine-grained emotion recognition aims to identify the emotional type in queries through reasoning and decision-making processes, playing a crucial role in various systems. Recent methods use In-Context Learning (ICL), enhancing the representation of queries in the reasoning process through semantically similar examples, while further improving emotion recognition by explaining the reasoning mechanisms. However, these methods enhance the reasoning process but overlook the decision-making process. This paper investigates decision-making in fine-grained emotion recognition through prototype theory. We show that ICL relies on similarity matching between query representations and emotional prototypes within the model, where emotion-accurate representations are critical. However, semantically similar examples often introduce emotional discrepancies, hindering accurate representations and causing errors. To address this, we propose Emotion In-Context Learning (EICL) 1 , which introduces emotionally similar examples and uses a dynamic soft-label strategy to improve query representations in the emotion reasoning process. A two-stage exclusion strategy is then employed to assess similarity from multiple angles, further optimizing the decision-making process. Extensive experiments show that EICL significantly outperforms ICL on multiple datasets. \n CCS Concepts ‚Ä¢ Information systems ‚Üí Sentiment analysis.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Emotions  [1] [2] [3]  play a critical role in shaping how people seek, interpret, and respond to information. In applications such as search engines  [4, 5] , recommender systems  [6, 7] , and mental health support  [8, 9] , user queries often contain not only explicit information needs but also implicit emotional expressions. Accurately identifying these emotional cues can enhance search relevance  [10, 11]  and user satisfaction  [12, 13] . To this end, the task of fine-grained emotion recognition has emerged, aiming to classify the emotional categories in queries through reasoning and decision-making process  [14, 15] .\n\nEarly studies train small-scale models to adjust emotion reasoning and decision-making for specific datasets, achieving promising results  [16] [17] [18] [19] [20] . These methods are limited by model size and specific data, making them difficult to adapt to new data distributions and unseen emotions  [21] [22] [23] [24] . Recent studies employ In-Context Learning (ICL), which flexibly adjusts the reasoning and decisionmaking process of large language models (LLMs) using only semantically similar examples, thus enhancing the emotion recognition and generalization  [24, 25] . These methods rely on empirically constructed examples and lack an understanding of ICL's internal mechanisms, limiting improvements in emotion recognition. Meanwhile, other studies explore ICL's internal mechanisms, examining how it integrates example information into query representations from Bayesian  [26] [27] [28] [29] [30] , gradient  [31] [32] [33] [34] , algorithmic learning  [35] [36] [37] [38] , and information flow  [39]  perspectives to facilitate emotion reasoning, as shown in Figure  1 (a). However, emotion recognition involves both reasoning and decision-making processes, and these studies focus only on the reasoning process, i.e., how query representations form, neglecting the decision-making process, i.e., how query representations are transformed into final predictions.\n\nIn this paper, we investigate the decision-making mechanism in ICL for fine-grained emotion recognition. Inspired by neuroscience research on hidden representations in LLMs  [40] [41] [42] , we propose a prompt-pair detection method to reveal that LLMs represent emotion categories with specific hidden representations. In the ICL decision-making process, the more similar a query representation is to a category representation in LLMs, the more likely it is to predict the corresponding emotion, as shown in Figure  1(b) . Viewing category representations as emotional prototypes, this similarity matching phenomenon suggests that ICL's decision-making process aligns with prototype theory  [43] [44] [45] .\n\nFrom the perspective of prototype theory, we identify a flaw in ICL: During the reasoning process, semantically similar examples contribute little to building high-quality query representations in emotion recognition. For example, given the query \"I'm worried about the upcoming major meeting.\" the semantically similar example \"I'm anticipating the upcoming major meeting.\" shares only semantic content and contributes little to emotion reasoning. In contrast, the emotionally similar example \"The eve of a major event often causes anxiety.\" aligns with the query's emotional tone, supplying richer information for emotion reasoning and helping to foster a high-quality query representation. During the decision-making process, relying on similarity between query representations and emotion prototypes amplifies errors when those representations are inaccurate. Semantically similar examples offer little for emotion reasoning, making it hard to form emotionally precise query representations. Under the similarity matching mechanism, the model compares these flawed representations with the LLM's internal emotion prototypes to infer the query's emotion. Since the query representations lack emotional precision, the resulting similarity scores are unreliable, leading to incorrect judgments.\n\nTo address this issue, we propose a simple yet effective Emotion In-Context Learning method (abbreviated as EICL) for fine-grained emotion recognition. It introduces emotionally similar examples and uses a dynamic soft-label strategy to accurately depict their emotions, enhancing emotion reasoning and forming high-quality representations. Additionally, it use a two-stage exclusion strategy to assess similarity from multiple angles, optimizing the decisionmaking process. We perform experiments with five LLMs across four fine-grained emotion datasets: EDOS  [46] , Empathetic Dialogues  [47] , EmpatheticIntent  [48] , and GoEmotions  [49] . The results show that EICL significantly outperforms ICL in fine-grained emotion recognition.\n\nTo sum up, our contributions are as follows:\n\n(i) We introduce a prototype theory perspective to explain ICL's decision-making mechanism, highlighting its reliance on similarity matching between queries and emotional prototypes in LLMs, and addressing the gap in previous work that focused only on the reasoning process. (ii) We propose EICL, offering a comprehensive reasoning and decision-making approach by using emotionally similar examples and a dynamic soft-label strategy to improve emotion reasoning, while optimizing decision-making through a twostage exclusion strategy. (iii) Extensive experiments and analysis show that the proposed method outperforms ICL on multiple datasets.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Related Work",
      "text": "In this paper, we introduce a prompt-pair detection method inspired by neuroscience-based prompting to examine the decision-making process of in-context learning. Drawing on these insights, we refine our in-context learning approach for fine-grained emotion recognition.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Neuroscience-Based Prompting Methods",
      "text": "Driven by neuroscience advances, recent research  [40, 41]  treats LLM's internal parameters as neural nodes and probes their activations to understand or steer model behavior. Neuroscience-based Prompting Methods  [42, 50, 51] , valued for their simplicity and generality, have been applied across diverse tasks. Zou et al.,  [50]  use paired positive and negative prompts to extract concept vectors and steer outputs toward honesty, detoxification or ethical framing. Turner et al.,  [51]  apply contrastive prompting to derive steering vectors that modulate topic and sentiment through targeted interventions in hidden layers. Liu et al.,  [42]  leverage prompts to capture honesty and confidence signals and then use these signals to retrieve and generate trustworthy responses. Leong et al.,  [52]  control the toxification direction and manipulates information flow within attention layers to remove toxic content. These studies all use prompting to create stable concept representations, which are then leveraged to guide LLM behavior on specific tasks, yielding strong and versatile performance. Unlike prior methods that apply concept representations to task-specific control, we use the extracted representations to examine LLM decision behaviors and reveal their internal mechanisms.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "In-Context Learning Methods",
      "text": "Basic In-Context Learning. In-Context Learning (ICL) enhances LLMs' performance by learning from constructed examples, avoiding the time and computational costs of fine-tuning. One ICL approach improves LLMs by decomposing reasoning steps of examples into sub-steps, enabling the model to complete tasks by following these steps  [53] [54] [55] . This method has shown strong results in tasks like arithmetic  [56] , commonsense  [53] , and symbolic reasoning  [57] , but requires manual construction and is not always applicable to tasks that can't be easily decomposed. Another approach, retrieval-based ICL, addresses this by retrieving relevant examples from training datasets. It focuses on examples similar to the query in terms of words  [58] [59] [60] , semantics  [61] [62] [63] [64] , structures  [65] , or other relevant aspects  [66] [67] [68] . Most methods rely on the semantic similarity between the query and examples.\n\nIn-Context Learning on Emotion Recognition. ICL on finegrained emotion recognition can be categorized into heuristic-based ICL and exact-based ICL. Heuristic-based ICL enhances emotion recognition by adjusting the reasoning and decision-making processes of LLMs using semantically similar examples  [24, 25] . While heuristic-based ICL relies on empirically constructed examples, it lacks an understanding of ICL's internal mechanisms, limiting its effectiveness. In contrast, exact-based ICL analyzes the reasoning process from multiple perspectives, such as Bayesian  [26] [27] [28] [29] [30] , gradient descent  [31] [32] [33] [34] , algorithmic learning  [35] [36] [37] [38] , and information flow  [39] , to improve query representations and emotion reasoning. However, while these studies explore reasoning, few address the internal mechanisms of decision-making based on these representations. Unlike previous work on reasoning and mechanics, we explore ICL's decision-making, emphasizing similarity matching.\n\nWe then propose emotion in-context learning to enhance ICL's performance in fine-grained emotion recognition.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Investigating Decision-Making In Icl",
      "text": "Previous methods explore the internal reasoning mechanism of In-Context Learning (ICL), showing that semantically similar examples help form higher-quality query representations in the hidden layers of large language models (LLMs), promoting emotion reasoning  [26, 27, 31, 35, 36, 39] . However, how these query representations map to emotion categories remains unclear. Recently, the linear representation and superposition hypotheses  [40, 41]  suggest that specific hidden representations in LLMs represent distinct concepts, with LLMs moving closer to these representations when expressing them. This phenomenon offers a new perspective on the decision-making process in ICL. To this end, we propose a prompt-pair detection method to extract category-related representations from LLMs' hidden representations and investigate the relationship between query and category representations during decision-making.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Prompt-Pair Detection Method",
      "text": "The prompt-pair detection method aims to extract stable category representations. To achieve this, we collect representations of emotion categories in different semantic contexts and extract stable representations from them. Specifically, for an emotion category ùëê ùëñ , we select ùëÄ samples from a set ùëÜ that conveys the corresponding emotion. For each sample ùë† ùëó ‚àà ùëÜ, we construct a positive prompt ùëÉ + and a negative prompt ùëÉ -. The difference between the positive and negative prompts is that the positive prompt uses the target emotion category ùëê ùëñ , whereas the negative prompt randomly selects a category from the complete emotion category set ùê∂ in the datasets. The positive prompt is shown in Table  1 . Both prompts are then fed into LLMs to predict the emotion category of the sample. During category prediction, we adopt a curriculum learning strategy that guides the LLMs to generate the corresponding tokens step by step, as formalized below:\n\nwhere ùë¶ + ùë° and ùë¶ - ùë° represent the tokens generate by the LLM at timestep ùë°, respectively. ùë¶ + <ùë° and ùë¶ - <ùë° represent the tokens generated before time step ùë° using the positive and negative prompts, respectively.\n\nAs LLMs are required to produce grammatically, semantically, and emotionally coherent content, their hidden states encode both contextual information (e.g., syntax and semantics) and emotional information. To decouple emotion for category prediction, we construct prompt pairs that share all context but differ only in the emotion, then subtract the hidden state of the negative prompt from that of the positive prompt to remove shared contextual information and isolate the emotion. Concretely, at each time step ùë°, we extract the hidden representations ‚Ñé ùëô,+ ùë°,ùë† ùëó and ‚Ñé ùëô,-ùë°,ùë† ùëó for the positive and negative prompts, respectively, and compute their difference to obtain the category representation ‚Ñé ùëô ùë°,ùë† ùëó , following established methods  [42, 50, 51] . We have:\n\nwhere ‚Ñé ùëô ùë°,ùë† ùëó , ‚Ñé ùëô,+ ùë°, ùë† ùëó , and ‚Ñé ùëô,-ùë°, ùë† ùëó ‚àà R ùëë . ‚Ñé ùëô,+ ùë°, ùë† ùëó and ‚Ñé ùëô,-ùë°, ùë† ùëó denote the hidden representations at time step ùë° for token ùë† ùëó under the positive and negative prompts, respectively, and ‚Ñé ùëô ùë°,ùë† ùëó is the resulting category representation. ùëô indicates the ùëô-th layer of the LLM.\n\nWe then collect all category representations derived from each sample into the set ùëÜ ùëô ùëê ùëñ and apply principal component analysis (PCA) to extract their first principal component. Through this extraction, we obtain a common and stable representation ùêª ùëô ùëê ùëñ ‚àà ùëÖ ùëë of category ùëê ùëñ across different samples. We have:\n\n3.1.1 Category Representation Visualization. Representations produced by neuroscience-based prompting methods are stable and robust  [42, 50, 51] . As a neuroscience-based prompting method, our prompt-pair detection method inherits these advantages when constructing the category representation ùêª ùëô ùëê ùëñ . Nevertheless, we further validate them using Llama3.1 8ùëè on the ED dataset  [47] . We average ùêª ùëô ùëê ùëñ layer by layer to obtain ùêª ùëê ùëñ . Based on the representations ùêª ùëê ùëñ , we compute cosine similarities between category vectors and normalize the scores to [0, 1], as shown in Figure  2 . The results reveal that categories of similar emotions yield higher similarity scores, while dissimilar ones yield lower scores. Overall, these results confirm the validity of our category representations and lay a solid foundation for the following investigation.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Investigating Decision-Making With Prototype Theory",
      "text": "Based on these representations, we further explore whether ICL aligns with specific category representations during the decisionmaking process.\n\nPrevious research  [39]  suggests that ICL consolidates important information at the critical time step ùë° ùëò , where the hidden representation determines the prediction outcome. For instance, in the emotion recognition task, when the generated response is \"Emotion: sad,\" the hidden representation information at the time step of generating the \":\" determines the prediction as \"sad. \" Therefore, at this step, we compute the dot product between the query hidden representation ùêª ùëô and the category representation ùêª ùëô ùëê ùëó , we have:\n\nwhere ùëê ùëó and ùêø are an emotion category in the dataset and the number of LLM layers, respectively. We conduct experiments using Phi-3.5-mini, Mistral-Nemo, and Llama3.1 8ùëè on the EDOS  [46] , Empathetic-Dialogues (ED)  [47] and GoEmotions  [49]  datasets. Figure  3  shows the results, where the x-axis represents emotion categories sorted by dot product (similarity) in descending order, and the y-axis represents the probability of predicting each emotion. The results show that as the similarity decreases, the probability of predicting the emotion also decreases. From the perspective of prototype theory  [43] [44] [45] , treating category representations as prototypes, we find that the closer a query hidden representation is to the emotional prototype, the higher the probability of predicting the corresponding emotion. This suggests that ICL's decision-making process is driven by similarity matching, consistent with prototype theory.",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "Methodology 4.1 Preliminaries",
      "text": "Problem Formulation. We formalize the task as follows: Given a query ùëû ùëñ , the goal is to construct an effective prompt that guides the large language model (LLM) to accurately predict the emotion category ùëê ùëû ùëñ .\n\nOverview. The proposed EICL is an in-context learning method supported by an emotion auxiliary model. As shown in Figure  4 , EICL consists of two steps: (i) Emotion Reasoning (in Section 4.2): It retrieves emotionally similar samples to aid reasoning and applies a dynamic soft-label strategy to improve query representations in emotion reasoning process. (ii) Emotion Decision (in Section 4.3): It divides emotion categories into primary and secondary candidates, prompting the LLM to prioritize primary candidates during decision-making, while considering secondary candidates afterward. This reduces decision errors caused by relying solely on similarity. Note that this method method requires no training and relies on a pre-trained model RoBERTa ùëíùëöùëú with emotional capabilities to complete the task (for details, see Section 5).",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Dynamic Soft-Label Strategy",
      "text": "",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Emotion Reasoning",
      "text": "We retrieve emotionally similar examples and use a dynamic softlabel strategy to accurately depict the emotions they contain, thereby enhancing emotion reasoning in LLMs.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Emotion",
      "text": "where ùë£ ùëû ùëñ , ùë£ ùë† ùëö ùëñ ‚àà R ùëëùëíùëöùëú denote the emotion vectors of query ùëû ùëñ and sample ùë† ùëö ùëñ , respectively. Top ùëò 1 returns the top-ùëò 1 most similar samples, with ùëò 1 as a hyperparameter. ùëë ùëíùëöùëú is the hidden-layer dimension of the emotion auxiliary model ùëÖùëúùêµùê∏ùëÖùëá ùëé ùëíùëöùëú . ùëõ ùëë is the size of the training set.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Dynamic",
      "text": "Soft-Label Strategy. Emotions in linguistic expression are inherently complex and multifaceted  [72] [73] [74] . Existing ICL methods  [61, 62]  assign only a single, deterministic emotion label to each example, oversimplifying this nuance. Consequently, ICL fails to incorporate genuinely emotion-aligned examples into its reasoning, resulting in inaccurate query representations. To address this issue, we use a dynamic soft-label strategy to assign specific labels to examples, accurately depicting their emotions to aid emotion reasoning. Specifically, we first employ the emotion auxiliary model to predict the emotions ùëí ùë† ùëö ùëñ and their corresponding probabilities ùëù ùë† ùëö ùëñ for each sample ùë† ùëö ùëñ ; we then select the top ùëò 2 emotions with the highest probabilities. The formal definition is as follows:\n\nwhere\n\nùëÉ and ùê∂ represent the model's predicted probabilities and the set of emotion categories. Top ùëò 2 is a ranking function that selects the top ùëò 2 optimal emotions by their probabilities. ùëò 2 is a hyperparameter.\n\nSubsequently, we generate dynamic soft labels by combining predicted emotions with ground-truth labels, weighted by a hyperparameter ùõº, so we have:\n\nwhere ùëí * is the ground truth label. By combining emotions ùëí ùëñ with their corresponding probabilities pùëñ , we obtain the dynamic soft label ùëô ùëö ùëñ for the sample ùë† ùëö ùëñ . Incorporating the sample ùë† ùëö ùëñ and its dynamic soft labels ùëô ùëö ùëñ , we derive the example ùëë ùëö ùëñ . Then we concatenate the example ùëë ùëö ùëñ to obtain the examples ùëë ùëû ùëñ for query ùëû ùëñ .\n\nwhere ‚äï represents the concatenation operator.",
      "page_start": 5,
      "page_end": 6
    },
    {
      "section_name": "Emotion Decision",
      "text": "Based on our findings in Section 3.2, ICL decides by measuring the similarity between the query representation and the LLM's internal emotion prototypes. However, when the query representation is emotionally inaccurate, relying solely on similarity may lead to errors. To address this issue, we propose a two-stage exclusion strategy that prioritizes certain emotion categories in emotion prediction, followed by others. This strategy considers both high similarity and prioritized emotion categories, mitigating errors caused by relying solely on similarity.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Candidate Emotion Division.",
      "text": "Our strategy begins by dividing the emotion categories into primary and secondary emotion candidates. To achieve this, we apply the emotion auxiliary model to predict the query's emotions. We then select the top ùëò 3 emotions with the highest probabilities and consider them as primary emotion candidates, which we place in the primary emotion set ùëÜ ùëùùëíùë† . The remaining emotions are considered as secondary emotion candidates and are placed in the secondary emotion set ùëÜ ùë†ùëíùë† , so we have:\n\nwhere ùëí ùëö , ùëí ùëõ , ùëí ùëû ùëñ ‚àà ùê∂, ùëù ùëû ùëñ ‚àà ùëÉ. ùëí ùëû ùëñ and ùëù ùëû ùëñ are the emotion categories and probabilities predicted by the emotion auxiliary model for the query ùëû ùëñ , respectively. ùëí ùëö and ùëí ùëõ represent the primary and secondary emotions, respectively. ùëáùëúùëù ùëò 3 is a selection function that selects the ùëò 3 emotion categories with the highest probabilities.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Two-Stage Exclusion Strategy.",
      "text": "Based on the above, we predict fine-grained emotions using a two-stage exclusion strategy. Specifically, we prompt LLMs to process the query and examples, prioritizing emotions from the primary emotion set ùëÜ ùëùùëíùë† before considering others. This strategy considers both the primary emotion categories and their similarity to prototypes, increasing their prediction probability and reducing decision errors. The prediction process is defined as follows:\n\n5 Experiments\n\nEmotion Auxiliary Models and Datasets. To validate the proposed method, we conduct experiments using two emotion auxiliary models, RoBERTa ùëíùëñ and RoBERTa ùëîùëí , on four fine-grained emotion datasets: EDOS  [46] , Empathetic-Dialogues (ED)  [47] , EmpatheticIntent (EI)  [48] , and GoEmotions (GE)  [49] . For convenience, we refer to the emotion auxiliary models and datasets as RoBERTa ùëíùëöùëú and ùê∑ ùë° ùë¶ùëùùëí , where ùëíùëöùëú ‚àà ùê∏ùêº, ùê∫ùê∏ and ùë°ùë¶ùëùùëí ‚àà ùê∏ùêº, ùê∫ùê∏, ùê∏ùê∑, ùê∏ùê∑ùëÇùëÜ. Note that our goal is to verify the performance of EICL without fine-tuning, so the emotion auxiliary model used during reasoning should not have been fine-tuned on the respective dataset, i.e., ùëíùëöùëú ‚â† ùë°ùë¶ùëùùëí.\n\nSimultaneously, the emotion categories predicted by the emotion auxiliary model do not fully align with those of the datasets, rendering the exclusion strategy inapplicable. To address this issue, we adjust the datasets according to the emotion auxiliary model. For example, for the RoBERTa ùëíùëñ emotion auxiliary model  [48]  and the GoEmotions dataset, we first identify the emotion categories they share. Then, we select data from GE that falls within these common emotion categories for experimentation. Evaluation Metrics. We evaluate the methods using accuracy and macro-F1 (F1). Accuracy (Acc) measures the proportion of correctly predicted samples. F1 is the harmonic mean of precision and recall, considering both metrics. It accounts for each class's F1 score and is robust to class imbalance.\n\nBaselines. To validate EICL, we conduct experiments on several large language models, including Phi-3.5-mini, Mistral-Nemo, Llama3.1 8ùëè , Claude-Haiku, and ChatGPT-Turbo. For each model, we construct zero-shot learning (Z-shot) and in-context learning (ICL) as baselines.The zero-shot baseline considers only the query, while the in-context learning baseline includes examples semantically related to it. Implementation Details. In our experiments, we use two emotion auxiliary models, RoBERTa ùëíùëñ and RoBERTa ùëîùëí , both with a hiddenlayer dimension of ùëë ùëíùëöùëú =768. The former is applied to the GE, ED, and EDOS datasets, while the latter is used for EI, ED, and EDOS. During the construction of example-label pairs, we set the example number to ùëò 1 =5 and the weight for soft labels to ùõº=0.2. The values of ùëò 2 (the number of soft labels) and ùëò 3 (the number of primary emotion candidates) vary based on the data, emotion auxiliary models, and LLMs. A detailed analysis of these factors is provided in Section 6.2.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Results And Analysis 6.1 Main Results",
      "text": "Tables  2  and 3  show the results with RoBERTa ùëíùëñ and RoBERTa ùëîùëí as auxiliary models, respectively. The results demonstrate that ICL outperforms Z-shot across most metrics, indicating that semantically similar examples benefit emotional reasoning. Additionally, EICL outperforms both ICL and Z-shot on most metrics, primarily due to emotion-similar examples, dynamic soft-label strategies, and the two-stage exclusion strategy, all of which improve emotional reasoning and decision-making.\n\nHowever, some anomalies are observed: (i) In datasets like GE (in Table  2 ) and EDOS (in Table  3 ), ICL performs worse than Z-shot. This is due to the models' weaker emotional capabilities. For instance, Llama3.1 8ùëè struggles to interpret emotions accurately, even when beneficial examples are provided. (ii) EICL performs poorly on certain datasets. Llama3.1 8ùëè and Claude-Haiku, in particular, perform below baselines. This is primarily due to these models' difficulty in recognizing certain emotions, as their inherent limitations cannot be fully overcome, even with effective strategies and examples (detailed explanation, see Section 6.3). In contrast, models like Phi-3.5-mini and ChatGPT-Turbo, with stronger emotional perception, benefit more from the proposed methods. (iii) On the GE dataset, EICL on models like Mistral-Nemo and Llama3.1 8ùëè shows lower accuracy. This is primarily due to the dataset's bias, where the \"neutral\" category comprises 1606 samples out of 3442, accounting for 46.65% of the total data. In such a biased dataset, the F1 score is more reliable, and our method outperforms the baseline on this metric, demonstrating the effectiveness of the proposed method. The results show that removing all modules leads to a decline in model performance, demonstrating the effectiveness of the modules. For ChatGPT-Turbo, removing Emotion-Similar Retrieval (W/O EER), the Two-Stage Exclusion Prediction Strategy (W/O TE), and the Dynamic Soft-Label Strategy (W/O DSL) all result in significant performance drops. This indicates that all three methods contribute to enhancing EICL's emotional reasoning and decision-making abilities. For Claude-Haiku, removing Emotion-Similar Retrieval (W/O EER) and the Two-Stage Exclusion Strategy (W/O TE) leads to a significant decline in performance. However, removing the Dynamic Soft-Label Strategy (W/O DSL) causes only a minor decrease. This suggests that Claude-Haiku already benefits from sufficient emotional reasoning and decision-making capabilities through similar examples and the two-stage exclusion strategy, while the dynamic soft-label strategy also helps with query understanding to some extent.   Figure  8a  shows results with a strong emotion auxiliary model, while Figure  8b  shows results with a weaker one. Most results suggest that using a moderate number of emotions as candidates yields optimal performance, highlighting the effectiveness of the two-stage exclusion strategy. In some cases, using all emotions as candidates leads to more accurate predictions, particularly when the emotion auxiliary model's performance is much lower, such as being 15 points below the LLMs (see Section 6.2.5). In these cases, EICL tends to exclude accurate emotions, causing the strategy to fail.  Figure  9a  illustrates the performance of smaller LLMs, showing that Mistral-Nemo and Phi-3.5-mini perform notably well, while Llama3.1 8ùëè demonstrates weaker capabilities, excelling only in the emotions of \"ashamed, \" \"angry, \" and \"hopeful. \" Figure  9b  presents the performance of larger LLMs, indicating that ChatGPT-Turbo offers a more comprehensive and balanced emotional capacity, while Claude-Haiku shows advantages only in \"confident\" and \"caring\" emotions. Overall, for similar LLMs, Llama3.1 8ùëè and Claude-Haiku display relatively weak emotional perception abilities. For larger LLMs, ChatGPT-Turbo has more comprehensive emotional capability compared to Claude-Haiku.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Analytical Experiments",
      "text": "",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Acc",
      "text": "",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Impact Of Emotion Auxiliary Model Performance.",
      "text": "",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Emotional Capacity Analysis Of Eicl.",
      "text": "We analyze the emotional recognition accuracy of the Z-shot, ICL, and EICL methods, with the results shown in Figure  10 . Figure  10a  shows the results for Llama3.1 8ùëè , while Figure  10b  shows the results for ChatGPT-Turbo. According to the results, ICL shows a notable improvement over Z-shot. Compared to the first two methods, EICL demonstrates significant improvements in recognizing a wide range of emotions, highlighting the effectiveness of the method.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Conclusion",
      "text": "In this paper, we have examined the decision-making mechanism of in-context learning (ICL) in fine-grained emotion recognition from a prototype theory perspective. We have demonstrated that ICL's decision-making aligns with prototype theory and shown that semantically similar examples can cause errors in emotion reasoning and decision-making. Building on these insights, we have proposed a new perspective with emotion in-context learning, which enhances emotion reasoning with emotionally similar examples and dynamic soft-label strategies, and optimizes decision-making through a two-stage exclusion strategy. Experiments conducted on four datasets demonstrate that our method significantly outperforms traditional ICL methods. This work uses emotional prototypes within LLMs to explore the decision-making mechanism of ICL in emotion recognition. Research has shown that LLMs contain not only emotional prototypes but also broader knowledge prototypes, allowing the proposed method to be applied to other tasks  [40] [41] [42] . To further investigate ICL and LLMs' internal mechanisms, we will explore and validate them in more tasks in the future.",
      "page_start": 9,
      "page_end": 9
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: (a). However, emotion recognition",
      "page": 1
    },
    {
      "caption": "Figure 1: The reasoning and decision-making mechanism of",
      "page": 2
    },
    {
      "caption": "Figure 1: (b). Viewing",
      "page": 2
    },
    {
      "caption": "Figure 2: Heatmap of category representations.",
      "page": 4
    },
    {
      "caption": "Figure 2: The results reveal that categories of similar",
      "page": 4
    },
    {
      "caption": "Figure 3: Emotion probability as similarity decreases.",
      "page": 4
    },
    {
      "caption": "Figure 3: shows the results, where the",
      "page": 4
    },
    {
      "caption": "Figure 4: Overview of EICL. It retrieves emotionally similar examples and uses a dynamic soft-label strategy to accurately",
      "page": 5
    },
    {
      "caption": "Figure 5: presents ablation studies using the",
      "page": 7
    },
    {
      "caption": "Figure 5: Ablation Results for EICL on EDOS and ED Datasets.",
      "page": 7
    },
    {
      "caption": "Figure 6: a, when using a strong emotion auxiliary model, EICL is insensitive",
      "page": 7
    },
    {
      "caption": "Figure 6: Results across varying ùõºvalues on RoBERTaùëíùëñand",
      "page": 8
    },
    {
      "caption": "Figure 7: The experiments are divided into two groups:",
      "page": 8
    },
    {
      "caption": "Figure 7: a depicts results",
      "page": 8
    },
    {
      "caption": "Figure 7: Results based on differentùëò2, where ùëÅis the number",
      "page": 8
    },
    {
      "caption": "Figure 8: Results of EICL based on different ùëò3, where ùëÅis",
      "page": 8
    },
    {
      "caption": "Figure 8: a shows results with a strong emotion auxiliary model,",
      "page": 9
    },
    {
      "caption": "Figure 8: b shows results with a weaker one. Most results",
      "page": 9
    },
    {
      "caption": "Figure 9: Comparison of emotional capability between",
      "page": 9
    },
    {
      "caption": "Figure 9: a illustrates the performance of smaller LLMs, showing",
      "page": 9
    },
    {
      "caption": "Figure 9: b presents",
      "page": 9
    },
    {
      "caption": "Figure 10: Comparison of emotional accuracy between EICL",
      "page": 9
    },
    {
      "caption": "Figure 10: Figure 10a shows the results for",
      "page": 9
    },
    {
      "caption": "Figure 10: b shows the results for ChatGPT-Turbo.",
      "page": 9
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Dataset": "‚Äî\n‚Äî",
          "Phi-3.5-mini\nMistral-Nemo\nClaude-Haiku\nChatGPT-Turbo\nLlama3.18ùëè": "Z-shot\nICL\nEICL"
        },
        {
          "Dataset": "Acc\nEDOS\nF1",
          "Phi-3.5-mini\nMistral-Nemo\nClaude-Haiku\nChatGPT-Turbo\nLlama3.18ùëè": "52.36\n34.30\n40.14\n55.97\n40.81\n46.55"
        },
        {
          "Dataset": "Acc\nED\nF1",
          "Phi-3.5-mini\nMistral-Nemo\nClaude-Haiku\nChatGPT-Turbo\nLlama3.18ùëè": "42.81\n29.0\n37.33\n42.81\n28.27\n39.50"
        },
        {
          "Dataset": "Acc\nGE\nF1",
          "Phi-3.5-mini\nMistral-Nemo\nClaude-Haiku\nChatGPT-Turbo\nLlama3.18ùëè": "38.75\n27.86\n37.56\n31.22\n21.29\n27.04"
        }
      ],
      "page": 7
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Dataset": "‚Äî\n‚Äî",
          "Phi-3.5-mini\nMistral-Nemo\nClaude-Haiku\nChatGPT-Turbo\nLlama3.18ùëè": "Z-shot\nICL\nEICL"
        },
        {
          "Dataset": "Acc\nEDOS\nF1",
          "Phi-3.5-mini\nMistral-Nemo\nClaude-Haiku\nChatGPT-Turbo\nLlama3.18ùëè": "54.85\n52.20\n53.97\n54.81\n36.88\n32.33"
        },
        {
          "Dataset": "Acc\nED\nF1",
          "Phi-3.5-mini\nMistral-Nemo\nClaude-Haiku\nChatGPT-Turbo\nLlama3.18ùëè": "51.33\n49.33\n44.47\n68.89\n21.89\n29.94"
        },
        {
          "Dataset": "Acc\nEI\nF1",
          "Phi-3.5-mini\nMistral-Nemo\nClaude-Haiku\nChatGPT-Turbo\nLlama3.18ùëè": "60.62\n47.16\n58.69\n80.46\n48.15\n45.55"
        }
      ],
      "page": 7
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Claude Acc(EDOS)\nClaude F1(EDOS)": "Claude F1(EDOS)\nGPT Acc(ED)\nClaude Acc(EDOS)\nGPT F1(ED)"
        }
      ],
      "page": 8
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Claude Acc(EDOS)\nClaude F1(EDOS)": "Claude Acc(ED)\nClaude F1(ED)",
          "GPT Acc(EDOS)\nGPT F1(EDOS)": "GPT Acc(ED)\nGPT F1(ED)"
        }
      ],
      "page": 8
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Emotions as motivators for information seeking: A conceptual analysis",
      "authors": [
        "Reijo Savolainen"
      ],
      "year": "2014",
      "venue": "Library & Information Science Research"
    },
    {
      "citation_id": "2",
      "title": "Influences of mood on information seeking behavior",
      "authors": [
        "Mimi Zhang",
        "Bernard Jansen"
      ],
      "year": "2009",
      "venue": "CHI"
    },
    {
      "citation_id": "3",
      "title": "The influence of emotions on information processing and persuasion: A differential appraisals perspective",
      "authors": [
        "Maria Stavraki",
        "Grigorios Lamprinakos",
        "Pablo Bri√±ol",
        "Richard Petty",
        "Kalipso Karantinou",
        "Dar√≠o D√≠az"
      ],
      "year": "2021",
      "venue": "Journal of Experimental Social Psychology"
    },
    {
      "citation_id": "4",
      "title": "The emotion profile of web search",
      "authors": [
        "Gabriella Kazai",
        "Paul Thomas",
        "Nick Craswell"
      ],
      "year": "2019",
      "venue": "SIGIR"
    },
    {
      "citation_id": "5",
      "title": "Analyzing the emotional outcomes of the online search behavior with search engines",
      "authors": [
        "Carlos Flavi√°n-Blanco",
        "Raquel Gurrea-Sarasa",
        "Carlos Or√∫s-Sanclemente"
      ],
      "year": "2011",
      "venue": "Computers in Human Behavior"
    },
    {
      "citation_id": "6",
      "title": "Towards empathetic conversational recommender systems",
      "authors": [
        "Xiaoyu Zhang",
        "Ruobing Xie",
        "Yougang Lyu",
        "Xin Xin",
        "Pengjie Ren",
        "Mingfei Liang",
        "Bo Zhang",
        "Zhanhui Kang",
        "Maarten De Rijke",
        "Zhaochun Ren"
      ],
      "year": "2024",
      "venue": "RecSys"
    },
    {
      "citation_id": "7",
      "title": "Emotion-aware personalized music recommendation with a heterogeneity-aware deep bayesian network",
      "authors": [
        "Erkang Jing",
        "Yezheng Liu",
        "Yidong Chai",
        "Shuo Yu",
        "Longshun Liu",
        "Yuanchun Jiang",
        "Yang Wang"
      ],
      "year": "2025",
      "venue": "ACM Transactions on Information Systems"
    },
    {
      "citation_id": "8",
      "title": "MISC: A mixed strategy-aware model integrating COMET for emotional support conversation",
      "authors": [
        "Quan Tu",
        "Yanran Li",
        "Jianwei Cui",
        "Bin Wang",
        "Ji-Rong Wen",
        "Rui Yan"
      ],
      "year": "2022",
      "venue": "ACL"
    },
    {
      "citation_id": "9",
      "title": "Touch your heart: A tone-aware chatbot for customer care on social media",
      "authors": [
        "Tianran Hu",
        "Anbang Xu",
        "Zhe Liu",
        "Quanzeng You",
        "Yufan Guo",
        "Vibha Sinha",
        "Jiebo Luo",
        "Rama Akkiraju"
      ],
      "year": "2018",
      "venue": "CHI"
    },
    {
      "citation_id": "10",
      "title": "Affective feedback: an investigation into the role of emotions in the information seeking process",
      "authors": [
        "Ioannis Arapakis",
        "Joemon Jose",
        "Philip Gray"
      ],
      "year": "2008",
      "venue": "SIGIR"
    },
    {
      "citation_id": "11",
      "title": "Theories, methods and current research on emotions in library information science, information retrieval and humancomputer interaction",
      "authors": [
        "Irene Lopatovska",
        "Ioannis Arapakis"
      ],
      "year": "2011",
      "venue": "Information Processing & Management"
    },
    {
      "citation_id": "12",
      "title": "The error is the clue: Breakdown in human-machine interaction",
      "authors": [
        "Bilyana Martinovsky",
        "David Traum"
      ],
      "year": "2003",
      "venue": "ISCA Workshop on EH-SDS"
    },
    {
      "citation_id": "13",
      "title": "Clarifying the path to user satisfaction: An investigation into clarification usefulness",
      "authors": [
        "A Hossein",
        "Xi Rahmani",
        "Mohammad Wang",
        "Mohammadmehdi Aliannejadi",
        "Emine Naghiaei",
        "Yilmaz"
      ],
      "year": "2024",
      "venue": "Findings of EACL"
    },
    {
      "citation_id": "14",
      "title": "Exploring fine-grained emotion detection in tweets",
      "authors": [
        "Jasy Suet",
        "Yan Liew",
        "Howard Turtle"
      ],
      "year": "2016",
      "venue": "NAACL student research workshop"
    },
    {
      "citation_id": "15",
      "title": "EmoNet: Fine-grained emotion detection with gated recurrent neural networks",
      "authors": [
        "Muhammad Abdul",
        "Lyle Ungar"
      ],
      "year": "2017",
      "venue": "ACL"
    },
    {
      "citation_id": "16",
      "title": "Perspective-taking and pragmatics for generating empathetic responses focused on emotion causes",
      "authors": [
        "Hyunwoo Kim",
        "Byeongchang Kim",
        "Gunhee Kim"
      ],
      "year": "2021",
      "venue": "EMNLP"
    },
    {
      "citation_id": "17",
      "title": "Mime: Mimicking emotions for empathetic response generation",
      "authors": [
        "Navonil Majumder",
        "Pengfei Hong",
        "Shanshan Peng",
        "Jiankun Lu",
        "Deepanway Ghosal",
        "Alexander Gelbukh",
        "Rada Mihalcea",
        "Soujanya Poria"
      ],
      "year": "2020",
      "venue": "EMNLP"
    },
    {
      "citation_id": "18",
      "title": "A multi-turn emotionally engaging dialog model",
      "authors": [
        "Yubo Xie",
        "Ekaterina Svikhnushina",
        "Pearl Pu"
      ],
      "year": "2019",
      "venue": "A multi-turn emotionally engaging dialog model",
      "arxiv": "arXiv:1908.07816"
    },
    {
      "citation_id": "19",
      "title": "Dialoguernn: An attentive rnn for emotion detection in conversations",
      "authors": [
        "Navonil Majumder",
        "Soujanya Poria",
        "Devamanyu Hazarika",
        "Rada Mihalcea",
        "Alexander Gelbukh",
        "Erik Cambria"
      ],
      "year": "2019",
      "venue": "AAAI"
    },
    {
      "citation_id": "20",
      "title": "DialogueGCN: A graph convolutional neural network for emotion recognition in conversation",
      "authors": [
        "Deepanway Ghosal",
        "Navonil Majumder",
        "Soujanya Poria",
        "Niyati Chhaya",
        "Alexander Gelbukh"
      ],
      "year": "2019",
      "venue": "EMNLP-IJCNLP"
    },
    {
      "citation_id": "21",
      "title": "Is chatgpt equipped with emotional dialogue capabilities? arXiv preprint",
      "authors": [
        "Weixiang Zhao",
        "Yanyan Zhao",
        "Xin Lu",
        "Shilong Wang",
        "Yanpeng Tong",
        "Bing Qin"
      ],
      "year": "2023",
      "venue": "Is chatgpt equipped with emotional dialogue capabilities? arXiv preprint",
      "arxiv": "arXiv:2304.09582"
    },
    {
      "citation_id": "22",
      "title": "Exploring chatgpt's empathic abilities",
      "authors": [
        "Kristina Schaaff",
        "Caroline Reinig",
        "Tim Schlippe"
      ],
      "year": "2023",
      "venue": "Exploring chatgpt's empathic abilities"
    },
    {
      "citation_id": "23",
      "title": "Enhancing empathetic response generation by augmenting llms with small-scale empathetic models",
      "authors": [
        "Zhou Yang",
        "Zhaochun Ren",
        "Wang Yufeng",
        "Shizhong Peng",
        "Haizhou Sun",
        "Xiaofei Zhu",
        "Xiangwen Liao"
      ],
      "year": "2024",
      "venue": "Enhancing empathetic response generation by augmenting llms with small-scale empathetic models",
      "arxiv": "arXiv:2402.11801"
    },
    {
      "citation_id": "24",
      "title": "Harnessing the power of large language models for empathetic response generation: Empirical investigations and improvements",
      "authors": [
        "Yushan Qian",
        "Weinan Zhang",
        "Ting Liu"
      ],
      "year": "2023",
      "venue": "Findings of EMNLP"
    },
    {
      "citation_id": "25",
      "title": "Towards interpretable mental health analysis with large language models",
      "authors": [
        "Kailai Yang",
        "Shaoxiong Ji",
        "Tianlin Zhang",
        "Qianqian Xie",
        "Ziyan Kuang",
        "Sophia Ananiadou"
      ],
      "year": "2023",
      "venue": "EMNLP"
    },
    {
      "citation_id": "26",
      "title": "A latent space theory for emergent abilities in large language models",
      "authors": [
        "Hui Jiang"
      ],
      "year": "2023",
      "venue": "A latent space theory for emergent abilities in large language models",
      "arxiv": "arXiv:2304.09960"
    },
    {
      "citation_id": "27",
      "title": "An explanation of in-context learning as implicit bayesian inference",
      "authors": [
        "Sang Michael Xie",
        "Aditi Raghunathan",
        "Percy Liang",
        "Tengyu Ma"
      ],
      "year": "2021",
      "venue": "An explanation of in-context learning as implicit bayesian inference"
    },
    {
      "citation_id": "28",
      "title": "The learnability of in-context learning",
      "authors": [
        "Noam Wies",
        "Yoav Levine",
        "Amnon Shashua"
      ],
      "year": "2023",
      "venue": "NeurIPS"
    },
    {
      "citation_id": "29",
      "title": "-context learning through the bayesian prism",
      "authors": [
        "Madhur Panwar",
        "Kabir Ahuja",
        "Navin Goyal"
      ],
      "year": "2023",
      "venue": "-context learning through the bayesian prism",
      "arxiv": "arXiv:2306.04891"
    },
    {
      "citation_id": "30",
      "title": "Large language models are latent variable models: explaining and finding good demonstrations for in-context learning",
      "authors": [
        "Xinyi Wang",
        "Wanrong Zhu",
        "Michael Saxon",
        "Mark Steyvers",
        "William Yang"
      ],
      "year": "2023",
      "venue": "Large language models are latent variable models: explaining and finding good demonstrations for in-context learning"
    },
    {
      "citation_id": "31",
      "title": "Why can GPT learn in-context? language models secretly perform gradient descent as meta-optimizers",
      "authors": [
        "Damai Dai",
        "Yutao Sun",
        "Li Dong",
        "Yaru Hao",
        "Shuming Ma",
        "Zhifang Sui",
        "Furu Wei"
      ],
      "year": "2023",
      "venue": "Findings of ACL"
    },
    {
      "citation_id": "32",
      "title": "Transformers learn in-context by gradient descent",
      "authors": [
        "Johannes Von",
        "Eyvind Niklasson",
        "Ettore Randazzo",
        "Jo√£o Sacramento",
        "Alexander Mordvintsev",
        "Andrey Zhmoginov",
        "Max Vladymyrov"
      ],
      "year": "2023",
      "venue": "ICML"
    },
    {
      "citation_id": "33",
      "title": "Transformers learn to implement preconditioned gradient descent for in-context learning",
      "authors": [
        "Kwangjun Ahn",
        "Xiang Cheng",
        "Hadi Daneshmand",
        "Suvrit Sra"
      ],
      "year": "2023",
      "venue": "Transformers learn to implement preconditioned gradient descent for in-context learning"
    },
    {
      "citation_id": "34",
      "title": "One step of gradient descent is provably the optimal in-context learner with one layer of linear selfattention",
      "authors": [
        "Arvind Mahankali",
        "B Tatsunori",
        "Tengyu Hashimoto",
        "Ma"
      ],
      "year": "2023",
      "venue": "One step of gradient descent is provably the optimal in-context learner with one layer of linear selfattention",
      "arxiv": "arXiv:2307.03576"
    },
    {
      "citation_id": "35",
      "title": "What learning algorithm is in-context learning? investigations with linear models",
      "authors": [
        "Ekin Aky√ºrek",
        "Dale Schuurmans",
        "Jacob Andreas",
        "Tengyu Ma",
        "Denny Zhou"
      ],
      "year": "2022",
      "venue": "What learning algorithm is in-context learning? investigations with linear models"
    },
    {
      "citation_id": "36",
      "title": "What can transformers learn in-context? a case study of simple function classes",
      "authors": [
        "Shivam Garg",
        "Dimitris Tsipras",
        "Percy Liang",
        "Gregory Valiant"
      ],
      "year": "2022",
      "venue": "What can transformers learn in-context? a case study of simple function classes"
    },
    {
      "citation_id": "37",
      "title": "Transformers as algorithms: Generalization and stability in in-context learning",
      "authors": [
        "Yingcong Li",
        "Muhammed Emrullah Ildiz",
        "Dimitris Papailiopoulos",
        "Samet Oymak"
      ],
      "year": "2023",
      "venue": "ICML"
    },
    {
      "citation_id": "38",
      "title": "Transformers as statisticians: provable in-context learning with in-context algorithm selection",
      "authors": [
        "Yu Bai",
        "Fan Chen",
        "Huan Wang",
        "Caiming Xiong",
        "Song Mei"
      ],
      "year": "2023",
      "venue": "Transformers as statisticians: provable in-context learning with in-context algorithm selection"
    },
    {
      "citation_id": "39",
      "title": "Label words are anchors: An information flow perspective for understanding in-context learning",
      "authors": [
        "Lean Wang",
        "Lei Li",
        "Damai Dai",
        "Deli Chen",
        "Hao Zhou",
        "Fandong Meng",
        "Jie Zhou",
        "Xu Sun"
      ],
      "year": "2023",
      "venue": "EMNLP"
    },
    {
      "citation_id": "40",
      "title": "Distributed representations: Composition & superposition. Transformer Circuits Thread",
      "authors": [
        "Chris Olah"
      ],
      "year": "2023",
      "venue": "Distributed representations: Composition & superposition. Transformer Circuits Thread"
    },
    {
      "citation_id": "41",
      "title": "The linear representation hypothesis and the geometry of large language models",
      "authors": [
        "Kiho Park",
        "Yo Joong Choe",
        "Victor Veitch"
      ],
      "year": "2023",
      "venue": "The linear representation hypothesis and the geometry of large language models",
      "arxiv": "arXiv:2311.03658"
    },
    {
      "citation_id": "42",
      "title": "Ctrla: Adaptive retrieval-augmented generation via inherent control",
      "authors": [
        "Huanshuo Liu",
        "Hao Zhang",
        "Zhijiang Guo",
        "Jing Wang",
        "Kuicai Dong",
        "Xiangyang Li",
        "Yi Lee",
        "Cong Zhang",
        "Yong Liu"
      ],
      "year": "2024",
      "venue": "Ctrla: Adaptive retrieval-augmented generation via inherent control",
      "arxiv": "arXiv:2405.18727"
    },
    {
      "citation_id": "43",
      "title": "Principles of categorization",
      "authors": [
        "Eleanor Rosch"
      ],
      "year": "1978",
      "venue": "Cognition and categorization"
    },
    {
      "citation_id": "44",
      "title": "Prototype theory and compositionality",
      "authors": [
        "Hans Kamp",
        "Barbara Partee"
      ],
      "year": "1995",
      "venue": "Cognition"
    },
    {
      "citation_id": "45",
      "title": "Concepts as prototypes",
      "authors": [
        "James Hampton"
      ],
      "year": "2006",
      "venue": "Psychology of learning and motivation"
    },
    {
      "citation_id": "46",
      "title": "A large-scale dataset for empathetic response generation",
      "authors": [
        "Anuradha Welivita",
        "Yubo Xie",
        "Pearl Pu"
      ],
      "year": "2021",
      "venue": "EMNLP"
    },
    {
      "citation_id": "47",
      "title": "Towards empathetic open-domain conversation models: A new benchmark and dataset",
      "authors": [
        "Eric Hannah Rashkin",
        "Margaret Smith",
        "Y-Lan Li",
        "Boureau"
      ],
      "year": "2019",
      "venue": "ACL"
    },
    {
      "citation_id": "48",
      "title": "A taxonomy of empathetic response intents in human social conversations",
      "authors": [
        "Anuradha Welivita",
        "Pearl Pu"
      ],
      "year": "2020",
      "venue": "ACL"
    },
    {
      "citation_id": "49",
      "title": "GoEmotions: A dataset of fine-grained emotions",
      "authors": [
        "Dorottya Demszky",
        "Dana Movshovitz-Attias",
        "Jeongwoo Ko",
        "Alan Cowen",
        "Gaurav Nemade",
        "Sujith Ravi"
      ],
      "year": "2020",
      "venue": "ACL"
    },
    {
      "citation_id": "50",
      "title": "Representation engineering: A top-down approach to ai transparency",
      "authors": [
        "Andy Zou",
        "Long Phan",
        "Sarah Chen",
        "James Campbell",
        "Phillip Guo",
        "Richard Ren",
        "Alexander Pan",
        "Xuwang Yin",
        "Mantas Mazeika",
        "Ann-Kathrin Dombrowski"
      ],
      "year": "2023",
      "venue": "Representation engineering: A top-down approach to ai transparency",
      "arxiv": "arXiv:2310.01405"
    },
    {
      "citation_id": "51",
      "title": "Activation addition: Steering language models without optimization. arXiv e-prints",
      "authors": [
        "Matt Alexander",
        "Lisa Turner",
        "Gavin Thiergart",
        "David Leech",
        "Juan Udell",
        "Ulisse Vazquez",
        "Monte Mini",
        "Macdiarmid"
      ],
      "year": "2023",
      "venue": "Activation addition: Steering language models without optimization. arXiv e-prints"
    },
    {
      "citation_id": "52",
      "title": "Selfdetoxifying language models via toxification reversal",
      "authors": [
        "Chak Tou Leong",
        "Yi Cheng",
        "Jiashuo Wang",
        "Jian Wang",
        "Wenjie Li"
      ],
      "year": "2023",
      "venue": "EMNLP"
    },
    {
      "citation_id": "53",
      "title": "Chain-of-thought prompting elicits reasoning in large language models",
      "authors": [
        "Jason Wei",
        "Xuezhi Wang",
        "Dale Schuurmans",
        "Maarten Bosma",
        "Brian Ichter",
        "Fei Xia",
        "Ed Chi",
        "V Quoc",
        "Denny Le",
        "Zhou"
      ],
      "year": "2022",
      "venue": "Chain-of-thought prompting elicits reasoning in large language models"
    },
    {
      "citation_id": "54",
      "title": "Measuring mathematical problem solving with the math dataset",
      "authors": [
        "Dan Hendrycks",
        "Collin Burns",
        "Saurav Kadavath",
        "Akul Arora",
        "Steven Basart",
        "Eric Tang",
        "Dawn Song",
        "Jacob Steinhardt"
      ],
      "year": "2021",
      "venue": "Measuring mathematical problem solving with the math dataset",
      "arxiv": "arXiv:2103.03874"
    },
    {
      "citation_id": "55",
      "title": "LAMBADA: Backward chaining for automated reasoning in natural language",
      "authors": [
        "Mehran Kazemi",
        "Najoung Kim",
        "Deepti Bhatia",
        "Xin Xu",
        "Deepak Ramachandran"
      ],
      "year": "2023",
      "venue": "ACL"
    },
    {
      "citation_id": "56",
      "title": "Language models are few-shot learners",
      "authors": [
        "B Tom",
        "Benjamin Brown",
        "Nick Mann",
        "Melanie Ryder",
        "Jared Subbiah",
        "Prafulla Kaplan",
        "Arvind Dhariwal",
        "Pranav Neelakantan",
        "Girish Shyam",
        "Amanda Sastry",
        "Sandhini Askell",
        "Ariel Agarwal",
        "Gretchen Herbert-Voss",
        "Tom Krueger",
        "Rewon Henighan",
        "Aditya Child",
        "Daniel Ramesh",
        "Jeffrey Ziegler",
        "Clemens Wu",
        "Christopher Winter",
        "Mark Hesse",
        "Eric Chen",
        "Mateusz Sigler",
        "Scott Litwin",
        "Benjamin Gray",
        "Jack Chess",
        "Christopher Clark",
        "Sam Berner",
        "Alec Mccandlish",
        "Ilya Radford",
        "Dario Sutskever",
        "Amodei"
      ],
      "year": "2020",
      "venue": "NeurIPS"
    },
    {
      "citation_id": "57",
      "title": "Scaling language models: Methods, analysis & insights from training gopher",
      "authors": [
        "Sebastian Jack W Rae",
        "Trevor Borgeaud",
        "Katie Cai",
        "Jordan Millican",
        "Francis Hoffmann",
        "John Song",
        "Sarah Aslanides",
        "Roman Henderson",
        "Susannah Ring",
        "Young"
      ],
      "year": "2021",
      "venue": "Scaling language models: Methods, analysis & insights from training gopher",
      "arxiv": "arXiv:2112.11446"
    },
    {
      "citation_id": "58",
      "title": "Learning to retrieve prompts for in-context learning",
      "authors": [
        "Ohad Rubin",
        "Jonathan Herzig",
        "Jonathan Berant"
      ],
      "year": "2022",
      "venue": "NAACL-HLT"
    },
    {
      "citation_id": "59",
      "title": "In-context examples selection for machine translation",
      "authors": [
        "Sweta Agrawal",
        "Chunting Zhou",
        "Mike Lewis",
        "Luke Zettlemoyer",
        "Marjan Ghazvininejad"
      ],
      "year": "2023",
      "venue": "Findings of ACL"
    },
    {
      "citation_id": "60",
      "title": "Dr. icl: Demonstration-retrieved in-context learning",
      "authors": [
        "Man Luo",
        "Xin Xu",
        "Zhuyun Dai",
        "Panupong Pasupat",
        "Mehran Kazemi",
        "Chitta Baral",
        "Vaiva Imbrasaite",
        "Vincent Zhao"
      ],
      "year": "2023",
      "venue": "Dr. icl: Demonstration-retrieved in-context learning",
      "arxiv": "arXiv:2305.14128"
    },
    {
      "citation_id": "61",
      "title": "MoT: Memory-of-thought enables ChatGPT to self-improve",
      "authors": [
        "Xiaonan Li",
        "Xipeng Qiu"
      ],
      "year": "2023",
      "venue": "EMNLP"
    },
    {
      "citation_id": "62",
      "title": "What makes good in-context examples for GPT-3? In DeeLIO",
      "authors": [
        "Jiachang Liu",
        "Dinghan Shen",
        "Yizhe Zhang",
        "Bill Dolan",
        "Lawrence Carin",
        "Weizhu Chen"
      ],
      "year": "2022",
      "venue": "What makes good in-context examples for GPT-3? In DeeLIO"
    },
    {
      "citation_id": "63",
      "title": "Supervised knowledge makes large language models better in-context learners",
      "authors": [
        "Linyi Yang",
        "Shuibai Zhang",
        "Zhuohao Yu",
        "Guangsheng Bao",
        "Yidong Wang",
        "Jindong Wang",
        "Ruochen Xu",
        "Wei Ye",
        "Xing Xie",
        "Weizhu Chen"
      ],
      "year": "2023",
      "venue": "Supervised knowledge makes large language models better in-context learners",
      "arxiv": "arXiv:2312.15918"
    },
    {
      "citation_id": "64",
      "title": "Plug-and-play document modules for pre-trained models",
      "authors": [
        "Chaojun Xiao",
        "Zhengyan Zhang",
        "Xu Han",
        "Chi-Min Chan",
        "Yankai Lin",
        "Zhiyuan Liu",
        "Xiangyang Li",
        "Zhonghua Li",
        "Zhao Cao",
        "Maosong Sun"
      ],
      "year": "2023",
      "venue": "ACL"
    },
    {
      "citation_id": "65",
      "title": "Diverse demonstrations improve in-context compositional generalization",
      "authors": [
        "Itay Levy",
        "Ben Bogin",
        "Jonathan Berant"
      ],
      "year": "2023",
      "venue": "ACL"
    },
    {
      "citation_id": "66",
      "title": "Complexitybased prompting for multi-step reasoning",
      "authors": [
        "Yao Fu",
        "Hao Peng",
        "Ashish Sabharwal",
        "Peter Clark",
        "Tushar Khot"
      ],
      "year": "2022",
      "venue": "ICLR"
    },
    {
      "citation_id": "67",
      "title": "Demystifying prompts in language models via perplexity estimation",
      "authors": [
        "Srini Hila Gonen",
        "Terra Iyer",
        "Noah Blevins",
        "Luke Smith",
        "Zettlemoyer"
      ],
      "year": "2023",
      "venue": "Findings of EMNLP"
    },
    {
      "citation_id": "68",
      "title": "Compositional semantic parsing with large language models",
      "authors": [
        "Andrew Drozdov",
        "Nathanael Sch√§rli",
        "Ekin Aky√ºrek",
        "Nathan Scales",
        "Xinying Song",
        "Xinyun Chen",
        "Olivier Bousquet",
        "Denny Zhou"
      ],
      "year": "2022",
      "venue": "ICLR"
    },
    {
      "citation_id": "69",
      "title": "Family resemblances: Studies in the internal structure of categories",
      "authors": [
        "Eleanor Rosch",
        "Carolyn Mervis"
      ],
      "year": "1975",
      "venue": "Cognitive psychology"
    },
    {
      "citation_id": "70",
      "title": "Distinguishing prototype-based and exemplar-based processes in dot-pattern category learning",
      "authors": [
        "David Smith",
        "John Paul"
      ],
      "year": "2002",
      "venue": "Journal of Experimental Psychology: Learning, Memory, and Cognition"
    },
    {
      "citation_id": "71",
      "title": "Prototypes in category learning: the effects of category size, category structure, and stimulus complexity",
      "authors": [
        "John Paul",
        "J David"
      ],
      "year": "2001",
      "venue": "Journal of Experimental Psychology: Learning, Memory, and Cognition"
    },
    {
      "citation_id": "72",
      "title": "Further evidence for mixed emotions",
      "authors": [
        "T Jeff",
        "A Larsen",
        "Peter Mcgraw"
      ],
      "year": "2011",
      "venue": "Journal of personality and social psychology"
    },
    {
      "citation_id": "73",
      "title": "Inside-out: From basic emotions theory to the behavioral ecology view",
      "authors": [
        "Carlos Crivelli",
        "Alan Fridlund"
      ],
      "year": "2019",
      "venue": "Journal of Nonverbal Behavior"
    },
    {
      "citation_id": "74",
      "title": "Emotions in everyday life",
      "authors": [
        "Debra Trampe",
        "Jordi Quoidbach",
        "Maxime Taquet"
      ],
      "year": "2015",
      "venue": "PloS one"
    }
  ]
}