{
  "paper_id": "2103.16434v1",
  "title": "User Profile-Driven Large-Scale Multi-Agent Learning From Demonstration In Federated Human-Robot Collaborative Environments",
  "published": "2021-03-30T15:33:21Z",
  "authors": [
    "Georgios Th. Papadopoulos",
    "Asterios Leonidis",
    "Margherita Antona",
    "Constantine Stephanidis"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Learning from Demonstration (LfD) has been established as the dominant paradigm for efficiently transferring skills from human teachers to robots. In this context, the Federated Learning (FL) conceptualization has very recently been introduced for developing large-scale human-robot collaborative environments, targeting to robustly address, among others, the critical challenges of multi-agent learning and longterm autonomy. In the current work, the latter scheme is further extended and enhanced, by designing and integrating a novel user profile formulation for providing a fine-grained representation of the exhibited human behavior, adopting a Deep Learning (DL)-based formalism. In particular, a hierarchically organized set of key information sources is considered, including: a) User attributes (e.g. demographic, anthropomorphic, educational, etc.), b) User state (e.g. fatigue detection, stress detection, emotion recognition, etc.) and c) Psychophysiological measurements (e.g. gaze, electrodermal activity, heart rate, etc.) related data. Then, a combination of Long Short-Term Memory (LSTM) and stacked autoencoders, with appropriately defined neural network architectures, is employed for the modelling step. The overall designed scheme enables both short-and long-term analysis/interpretation of the human behavior (as observed during the feedback capturing sessions), so as to adaptively adjust the importance of the collected feedback samples when aggregating information originating from the same and different human teachers, respectively.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "I. Introduction",
      "text": "Learning from Demonstration (LfD) constitutes the most dominant paradigm for robot programming through direct interaction with humans  [1] . It relies on the fundamental principle of robots acquiring new skills by learning to imitate a (human) teacher  [2] . LfD has so far been successfully associated with multiple aspects of robotics technology, including human-robot interaction, machine learning, machine vision and motor control  [3]   [4] . The main advantageous characteristics that have led to the widespread adoption of LfD in multiple and diverse application cases are  [5]  With respect to the different types of human demonstration means considered, LfD approaches generally fall into three main categories  [2] :\n\n• Kinesthetic teaching, where the human teacher provides demonstrations by physically moving the robot through 1 Institute of Computer Science (ICS), Foundation for Research and Technology -Hellas (FORTH), GR-70013, Heraklion, Crete, Greece 2 Computer Science Department (CSD), University of Crete (UoC), GR-70013, Heraklion, Crete, Greece the desired motions  [6] ;\n\n• Teleoperation, where an external input (e.g. joystick, graphical user interface or other means) is used to guide the robot  [7] ; • Passive observation, where the robot passively observes the exhibited user behavior for learning  [8] . A critical factor for the success of any LfD scheme, while also in close relation with the particularities of the selected application case, concerns the adopted methodology for refining the robot learned policies. Different types of approaches have been introduced so far, including: a) Reinforcement learning, where a trial and error methodology is adopted to learn a policy to solve a given problem  [9] , b) Optimization, where the optimal solution is searched based on given criteria  [10] , c) Transfer learning, where knowledge of a task or a domain is used to enhance the learning procedure for another task  [11] , d) Apprenticeship learning, where the desired performance is modeled through the use of a set of demonstrated samples that serve as a template  [12] , e) Active learning, where the robot decides when to ask for an optimal response from a (human) expert to a given state and to use these active samples to improve its policy  [13]  and f) Structured predictions, where robotic actions are considered as a sequence of dependent predictions  [14] .\n\nAlthough extensive research efforts have been devoted in the LfD field over the past years, crucial research challenges, namely multi-agent learning  [15]  and long-term autonomy  [16] , still remain to be reliably addressed. Achieving the latter will act as a tremendous facilitator for enabling the wide-spread use of robots in large-scale, open and complex environments; this is the typical case when considering e.g. industrial manufacturing scenarios. The above need to be also investigated in conjunction with typical challenges in Human-Robot Interaction (HRI) schemes, like developing appropriate user interfaces, variance in human performance, variability in knowledge across human subjects, learning from noisy/imprecise human input, learning from very large or very sparse datasets, incremental learning, etc.\n\nThe current work adopts the Federated Learning (FL) conceptualization that has very recently been introduced for designing large-scale LfD human-robot collaborative environments  [17] , aiming at providing reliable solutions, among others, to the current critical challenges of multi-agent learning and long-term autonomy. In particular, the cognitive architecture of  [17]  is further elaborated and enhanced, by designing and integrating a novel user profile formulation for estimating a fine-grained representation of the exhibited human behavior. The introduced user model follows the Deep Learning (DL)-based formalism; hence, rendering the overall approach end-to-end learnable. Specifically, a set of key information sources that are hierarchically organized is considered, including: a) User attributes concerning each human teacher's background (e.g. demographic, anthropomorphic, educational, etc.), b) User state information that encodes particular human behavioral characteristics (e.g. fatigue detection, stress detection, emotion recognition, etc.) and c) Psychophysiological measurements that convey critical details about the user's mental state, personality and idiosyncrasy (e.g. gaze, electrodermal activity, heart rate, etc.). Then, a combination of Long Short-Term Memory (LSTM) and stacked autoencoders, with appropriately defined neural network architectures, is employed for the modelling step and for producing a concrete user profile representation. The overall designed scheme supports both short-and long-term analysis/interpretation of the human behavior (as observed during the feedback capturing sessions), so as to adaptively modulate the importance of the collected feedback samples when aggregating information originating from the same and different human teachers, respectively.\n\nThe remainder of the paper is organized as follows: Section II describes challenges and open issues currently present in the LfD learning field. Additionally, Section III outlines the already introduced cognitive architecture for FL-based multi-agent human-robot collaborative learning. Moreover, Section IV details the designed DL-based user profile modelling and knowledge aggregation approach. Finally, conclusions are drawn in Section V.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Ii. Open Issues In Lfd Learning",
      "text": "LfD has been shown to lead to significant advances in multiple and significantly diverse operational scenarios, involving the use of both manipulator  [18]   [19]  and mobile  [20] [21] robots. Regarding the targeted goal of the overall LfD procedure, this can be categorized to different levels of abstraction  [2] , including the learning of: a) Policies, i.e. the estimation of a function that generates the desired behavior, b) Cost and reward functions, where the ideal behavior is considered to stem out from the optimization of a hidden function, c) Plans, i.e. high level structured schemes, composed of several sub-tasks or primitive actions, and d) Multiple outcomes simultaneously, by jointly modeling complex behaviors at multiple levels of abstraction.\n\nAs already mentioned in Section I, despite the extensive research efforts devoted by the LfD community, key technological challenges and open issues still remain to be robustly addressed, including, among others, the following ones  [2] [15]  [5] [22]:\n\n• To involve in a more robust way a broad number of teachers with different styles of and possibly conflicting demonstrations; • To transfer skills across multiple agents, including multiple and diverse types of robots; • To simultaneously learn multiple complex tasks, while storing and reusing prior knowledge at large scale;\n\n• To robustly implement incremental learning schemes;\n\n• To reinforce the generalization ability;\n\n• To model compound tasks;\n\n• To implement multi-agent imitation learning schemes;\n\n• To operate in realistic, dynamic, time-varying and complex environments. Towards providing a reliable solution to the above aspects, a novel cognitive architecture for multi-agent LfD robotic learning has recently been introduced  [17] , targeting to enable the efficient deployment of open, scalable and expandable robotic systems in large-scale and complex environments. In particular, the designed architecture capitalizes on the recent advances in the Artificial Intelligence (AI) (and especially the DL field), by establishing a FL-based framework for incarnating a multi-human multi-robot collaborative learning environment (as will be discussed in Section III), going far beyond other literature approaches investigating relatively straight-forward implementations of FL schemes (without incorporating the human factor in the learning loop) in specific robotic tasks (e.g. autonomous navigation  [23] , motion planning  [24] , visual perception  [25] , etc.).\n\nHowever, the conventional FL mechanism, which is a purely data-driven scheme and typically employs a simple 'Federated Averaging' operator for knowledge aggregation  [26] , lacks theoretical guarantees for convergence under realistic settings  [27] , i.e. when non-independent-and-identicallydistributed (non-IID) data are available at the various network nodes. The latter assumption is highly likely to hold when considering human demonstration data (as required in the LfD scheme). In this context, the current work elaborates the multi-agent cognitive architecture conceptualization of  [17] , by introducing comprehensive DL-grounded user profile modelling and corresponding sophisticated knowledge aggregation strategies (explained in Section IV).",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Iii. Fl-Based Multi-Agent Human-Robot Collaborative Learning",
      "text": "",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "A. Fundamental Conceptualization",
      "text": "According to  [17] , a multi-agent cognitive architecture for LfD learning is introduced that is grounded on the fundamental mechanism of the FL paradigm, while a highlevel representation is provided in Fig.  1 . In particular, a global AI model W (that bears the targeted robot policy to be learned), which is aimed to be collaboratively trained and shared among a network of human-robot pairs, is initially constructed using proxy data (stored either offline or at a central node). Model W materializes a cognitive process  [28][29]  underpinning the robotic task of interest, e.g. sensing, navigation, manipulation, control, human-robot interaction, etc. Subsequently, the model is made available to the network and downloaded by each node (i.e. every employed robot). Every node encapsulates a local database that is used to estimate improved updates of the global model parameters (e.g. using conventional Stochastic Gradient Descent (SGD) for the case of Neural Network (NN)-based AI modules), without making the local (federated) data available to the",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "B. Constituent Entities",
      "text": "The considered cognitive AI architecture is composed of the following real-world reference entities: a) The robotic platform and b) The human. In order to enable the perception and the collection of critical information about the surrounding environment and the exhibited human behavior, two comprehensive sets of sensing devices are considered; one that can be attached to the robot (denoted S r ) and one to the human (denoted S h ). In particular, the set of potentially supported types of sensors for each case, which can be significantly broad and also depends on the particular application scenario, are defined as follows:\n\nRegarding the robotic platform, this refers to the actual mechatronic equipment to be deployed. Depending on the specific operational scenario and the targeted robotic task (that may cover a large set of possible perception, cognition, motor and interaction functionalities), multiple types of robots can be used, supporting different requirements for mobility, positioning, manipulation, communication, size, payload, etc. The set of available types of robots is denoted:\n\nTaking into account the above-mentioned formalisms, a robotic platform P l can be fully specified as follows:\n\nwhere L denotes the total number of robotic platforms present in the examined cognitive environment.\n\nWith respect to the human factor, although all types of LfD demonstration means methodologies (namely kinesthetic teaching, teleoperation and passive observation, as detailed in Section I) are supported by the cognitive AI architecture, the adoption of a teleoperation-based approach is considered to exhibit significant advantageous characteristics. In particular, an intuitive and sophisticated teleoperation scheme is foreseen that is based on the combined used of Augmented Reality (AR) visualization mechanisms and eXplainable AI (XAI) technologies. Regarding the former, AR tools are employed in order to allow the human user to perform a physical inspection of the robot exhibited behaviors (and hence to identify malfunctions, hazardous situations, deviations from desired policies, etc.), while at the same time being constantly provided with key detailed insights about the AI processes being applied (e.g. the AI modules being used, their estimated outputs, how specific decisions are reached, etc.). Concerning XAI methods, such techniques are adopted in order to provide precise explanations/insights to the human operator regarding the deviation of the robot behavior from the desired one, i.e. enabling an in depth inspection of the robot behavior. It needs to be mentioned that the set of human operators involved in the designed cognitive architecture is denoted",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "C. Collective Cognitive Ai Layer",
      "text": "A collective cognitive AI layer operates at the upper level of the designed architecture and its core functionality is based on the fundamental mechanism of the FL paradigm, as detailed in Section III-A. The main building blocks of the cognitive AI layer, their formalism and detailed explanation of their functionalities are provided in the followings: Network nodes: Every robotic platform P l corresponds to a network node of the defined architecture. Each P l stores locally the generated data, which largely contain information collected from the set of sensors S r l incorporated by P l . Global AI model: The goal of the overall framework is to collectively create a global AI model denoted W ← f 1 (S r , R), underpinning the implemented cognitive process present in the examined environment, where f 1 (.) implies a generalized function or process that defines the exact NN-based materialization of model W while considering S r and R as input parameters. However, each network node P l can maintain a local/customized version of W. Learning methodology: Regarding the specific methodology to be followed for refining the robot learned policies (i.e. for updating AI model W), different options can be investigated (e.g. reinforcement learning, transfer learning, active learning, etc.), as discussed in Section I. The most suitable selection depends on the particularities of the application domain and the examined W. Local parameter updates: Regardless of the particular learning methodology selected, each robotic platform P l can estimate updates for model W, using its locally stored data. More specifically, the following local parameter update mechanism is applied:\n\nwhere W l,m is the local/customized version of the global model W with respect to human teacher h m , lr l is the local learning rate, ∇ denotes the gradient of a function, L (.) represents the loss function defined for W and δ l is the locally stored dataset. Consequently, the local parameter updates, which are iteratively estimated, to be sent to the central node (aggregator) are computed as follows:\n\nUser profiling: For efficiently initially interpreting and subsequently incorporating human feedback, in parallel with the W l,m estimation process, an individual user profile Q l,m ← f 2 (δ l , S h m ) is constructed for every human subject h m at every node P l . The latter is estimated using the appropriate sensorial data S h m to model the observed human behavior and a generalized function f 2 (.) that defines the exact (NNbased) implementation of the user profile while considering S h m as input parameters. Under the current conceptualization, DL-based approaches are considered for generating Q l,m , as in  [30]  and  [31] , aiming at combining increased modelling capabilities and easier integration to the designed FL-based framework. Global model update: Having computed the local parameter updates ∆W l,m and the corresponding user profiles Q l,m (using locally generated and processed data δ l ), these are sent to the central node (aggregator) so as to periodically produce updated versions of global model W. According to the conventional FL mechanism, an updated version W of W is generated on a regular basis, by applying a simple averaging operator, as follows:\n\nwhere lr g denotes the global learning rate and Λ the total number of received ∆W l,m updates. For robustly confronting the observed variance in the behavior of the large number of involved human teachers h m , the designed cognitive architecture (apart from possible sensorial data S r l pre-processing for invariance incorporation) encompasses the estimated user profiles Q l,m in the global model update process, modifying  (8)  to the following general formalism:\n\nwhere Φ(.) denotes a generalized function that combines the available Q l,m and ∆W l,m , estimated at every network node P l . Depending on the particularities of the selected application domain (e.g. supported W, S r , S h , R, etc.), the following main and purely data-driven materializations of Φ(.), which are capable of being combined, are considered in  [17] : a) User weighting, where each human teacher h m is modulated by a different weight factor based on a similarity metric from the global user model, b) Parameter weighting, which assigns varying weights to the parameters of W, based on the degree of correlation among the parameters of W l,m and Q l,m , and c) User clustering, which considers the generation of multiple instances W η of the global model W, in order to better capture the heterogeneity of data distributions across the different users h m . In the remainder of this work the abovementioned 'User weighting' conceptualization is considered and the focus is put on thoroughly defining an efficient Q l,m formalism (Section IV), although 'Parameter weighting' and 'User clustering' (as well as any combination of the three alternatives) are equally applicable. In particular, the 'User weighting' approach adaptively adjusts the contribution of each human teacher h m by a different weight factor based on his/her exhibited behavior, as follows:\n\nwhere ε(Q l,m ) denotes the weight factor for each h m at every P l , Q g the corresponding global user model (e.g. estimated through the same FL-based mechanism used for constructing W) and . a dissimilarity score metric (e.g. Euclidean distance between the parameters of the involved user models).",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Iv. Dl-Based User Modelling And Knowledge",
      "text": "",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Aggregation",
      "text": "Incorporating human feedback constitutes a fundamental part of the LfD approach and, consequently, of the employed cognitive architecture. However, the latter poses additional challenges to the problem formulation that need to be efficiently addressed (e.g. variance in human performance, variability in knowledge across human subjects, learning from noisy/imprecise human input, possible conflicts in provided human feedback information, handling of individuals with different idiosyncrasies, learning from very large or very sparse datasets, incremental learning, etc.). On the other hand, the strength of the utilized FL-based mechanism (detailed in Section III) lies on incorporating a very large number Λ of samples and multiple iterative updates of W that will likely lead to the convergence to well-performing and robust W models, while the network nodes P l contributing in (8) may be sampled out of the available ones (usually in a random way). However, combining information (∆W l,m ) related to different human subjects h m (that presumably exhibit highly diverse and varying behavior) is in turn very likely to lead the FL process to be confined to a local maximum or even to a non-convergence of the FL procedure; hence, jeopardising the overall learning process. To this end, defining a detailed and robust user profile model Q l,m is of vital importance for enabling: a) The accurate assessment and interpretation of the demonstrated behavior of each human teacher h m and, subsequently, b) The appropriate adjustment of the importance of the provided human feedback from the same individual or across multiple ones, during the knowledge aggregation step.\n\nIn general, the purpose of defining user profile formalisms is to cover physical (e.g. human actions, physical capabilities, etc.), cognitive (e.g. intention, personality, etc.) and social (e.g. non-verbal cues, emotions, etc.) aspects, in order to model and efficiently interpret the exhibited human activity  [32] . So far, the problem has been investigated and assessed from different disciplines and scientific perspectives, while methodologies that rely on the use of Machine Learning (ML) techniques and the integration of the generated models in broader computational/cognitive systems continuously receives increasing attention. One of the most popular examples of the latter category of methods constitutes the so called recommender systems (that aim to predict the preferences of each individual human user)  [33] [34] and especially the so-called 'collaborative filtering' class  [35] . However, the introduced profiles so far model relatively simple types of human behavior aspects (e.g. correlations of individual users and different information items  [36] ).",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "A. Considered Information Sources",
      "text": "Under the proposed conceptualization, a fine-grained multi-level DL-based computational approach is introduced for modelling user profile Q l,m , grounded on the efficient processing and sophisticated combination of various heterogeneous and diverse information streams. The overall goal is to meet the demanding requirements of the LfD setting for modelling the exhibited user behavior, focusing on the following two main pillars: a) Accurately interpreting the captured human behavior both in the short-and the longterm cases and b) Effectively handling the variance of crosssubject (and often conflicting) information and its efficient merging. For that purpose, the following (hierarchically organized) types of information sources are considered for generating Q l,m (as also illustrated in Fig.  2 ):\n\n• User attributes: These include valuable and explicitly defined information concerning each human teacher's h m background, covering aspects like demographic (e.g. age, sex, race, origin, etc.), anthropomorphic (e.g. height, weight, possible disabilities, etc.), educational (e.g. level and types of education, etc.), work experience (e.g. duration, responsibilities/tasks, etc.), etc.; • User state: This corresponds to particular modules/pipelines that (automatically) detect specific human behavior characteristics, e.g. fatigue detection, stress detection, emotion recognition, intention prediction, etc.\n\nFor their extraction sensorial data types belonging to S r and S h are used; • Psychophysiological measurements: These comprise the actual raw sensorial data information streams captured (supporting data types of both S r and S h sets) and convey critical details about the user's mental state, personality and idiosyncrasy, e.g. heart rate, electroencephalogram (EEG), motion, facial expressions, gaze, accelerometer, gyroscope, electrodermal activity, etc. It needs to be highlighted that the specific information sources (belonging to each of the above mentioned categories) to be considered depends on the particularities of the selected application case.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "B. Processing Of Collected Data",
      "text": "According to the formalism of the cognitive architecture for LfD learning defined in Section III, each human teacher h m can provide, in relation to a given robotic platform P l , feedback information (denoted µ l,m ν ) regarding the robot exhibited behavior, where ν (ν ∈ [1, N], ν ∈ N, N ∈ N) indicates the index of the particular feedback session (denoted ξ l,m ν ) that consists of T ν time steps. The user attributes provided for human h m , after being appropriately numerically encoded, are concatenated to form static feature vector DE m . On the other hand, the outputs of the specific feature detectors (that summarize the user's state) for human h m at node P l during session ξ l,m ν , after also being appropriately numerically encoded (if needed), are similarly concatenated to produce static feature vector DS l,m ν . With respect to the corresponding psychophysiological measurements captured  during session ξ l,m ν , an individual multi-dimensional observation sequence OS l,m ν,ρ (of length T ν samples) is formed for every considered sensor type implied by index ρ. In order to estimate a static feature vector DR l,m ν,ρ (out of each OS l,m ν,ρ sequence), a DL-based unsupervised feature representation learning methodology is considered. Specifically, an individual LSTM autoencoder, similar to the one described in  [37]  and whose architecture is illustrated in Fig.  3 , is introduced for each OS l,m ν,ρ , since every OS l,m ν,ρ is in general related to a different sampling frequency and, hence, consists of a different number of samples. As can be seen in Fig.  3 , the autoencoder consists of two LSTM models, namely an encoder and a decoder one. The encoder receives as input a series of feature vectors (i.e. u 1 , u 2 , ... u T ) and updates at each time step its vectorial fixed-length internal state representation (i.e. h 1 , h 2 , ... h T ), which models/encodes the input sequence until that time step. During the decoding phase, the second LSTM is initialized with internal state h 1 ≡ h T and, through its fundamental sequential modelling mechanism, it recursively estimates new internal states (i.e. h 1 , h 2 , ... h T ) that correspondingly produce a respective series of prediction feature vectors (i.e. u 1 , u 2 , ... u T ). The overall goal of the autoencoder is to adjust its internal parameters so that sequences u 1 , u 2 , ... u T and u 1 , u 2 , ... u T to be as similar as possible. Vector h T that characterizes the overall input sequence u 1 , u 2 , ... u T is considered to coincide with DR l,m ν,ρ defined above.",
      "page_start": 5,
      "page_end": 6
    },
    {
      "section_name": "C. Modeling Of User Profile",
      "text": "The ultimate goal of designing a model of the human user profile Q l,m (Section III) is to provide a computational scheme that will simultaneously analyse, cross-correlate and eventually fuse the different heterogeneous information streams for producing a joint/compact representation that will efficiently encode/express the salient characteristics of each human teacher h m (e.g. mental state, idiosyncrasy, preferences, etc.) in an implicit way. The latter is of paramount importance for interpreting the human behavior during the knowledge aggregation step, as will be discussed in Section IV-D.\n\nFor creating a robust user profile, a DL-based hierarchical multi-stream unsupervised feature fusion approach is adopted. In particular, a multi-stream stacked autoencoder, similar to the one described in  [38]  and whose general architecture is illustrated in Fig.  4 , is introduced. Each of the 3 defined autoencoder streams is in direct accordance to the information sources definition of Section IV-A. In particular, a stacked autoencoder is a neural network consisting of several layers of sparse autoencoders, where the output of each hidden layer is connected to the input of the successive hidden layer. The designed autoencoder considers a multistream architecture, which aims at initially capturing the correlations among the features of the same stream (while also leveraging knowledge from the other streams) and subsequently modelling the inter-dependencies among the different streams, as can been seen in Fig.  4 . Similarly to the LSTM autoencoder (Section IV-B), the goal during the training process is for the input and output feature vectors to be as similar as possible. Moreover, the learned multimodal representation (feature vector) of the middle/internal encoding layer compactly summarizes the salient attributes of the input feature vectors.\n\nRegarding the actual user profile generation process, an individual stacked autoencoder is considered with respect to every Q l,m . The autoencoder receives as input (with respect to each associated feedback session ξ l,m ν ) the following feature vectors: a) User attributes vector DE m , b) User state vector DS l,m ν , and c) Concatenation of psychophysiological measurement vectors DR l,m ν,ρ . The estimated state representation of the encoding layer (denoted HS l,m ν ) comprises a static feature vector that summarizes the salient behavioral characteristics of human teacher h m at node P l during session ξ l,m ν . Moreover, the parameters of the learned stacked autoencoder (or practically only those of the encoder part) constitute the actual user profile model Q l,m introduced in the FL-based formalization of Section III.",
      "page_start": 6,
      "page_end": 7
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: In particular, a",
      "page": 2
    },
    {
      "caption": "Figure 1: High-level representation of the employed cognitive architecture",
      "page": 3
    },
    {
      "caption": "Figure 1: ) are asynchronously transmitted back to the central",
      "page": 3
    },
    {
      "caption": "Figure 2: Hierarchy of information sources for generating user proﬁle Ql,m.",
      "page": 5
    },
    {
      "caption": "Figure 3: Employed LSTM autoencoder for producing psychophysiological measurements representation DRl,m",
      "page": 6
    },
    {
      "caption": "Figure 4: , is introduced. Each of the",
      "page": 6
    },
    {
      "caption": "Figure 4: Similarly to",
      "page": 6
    },
    {
      "caption": "Figure 4: Designed stacked autoencoder for generating user proﬁle model Ql,m.",
      "page": 7
    }
  ],
  "tables": [],
  "citations": [
    {
      "citation_id": "1",
      "title": "A survey of robot learning from demonstration",
      "authors": [
        "B Argall",
        "S Chernova",
        "M Veloso",
        "B Browning"
      ],
      "year": "2009",
      "venue": "Robotics and autonomous systems"
    },
    {
      "citation_id": "2",
      "title": "Recent advances in robot learning from demonstration",
      "authors": [
        "H Ravichandar",
        "A Polydoros",
        "S Chernova",
        "A Billard"
      ],
      "year": "2020",
      "venue": "Robotics, and Autonomous Systems"
    },
    {
      "citation_id": "3",
      "title": "Motion planning with success judgement model based on learning from demonstration",
      "authors": [
        "D Furuta",
        "K Kutsuzawa",
        "S Sakaino",
        "T Tsuji"
      ],
      "year": "2020",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "4",
      "title": "Development and stability analysis of an imitation learning-based pose planning approach for multi-section continuum robot",
      "authors": [
        "I Seleem",
        "H El-Hussieny",
        "S Assal",
        "H Ishii"
      ],
      "year": "2020",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "5",
      "title": "Learning from humans",
      "authors": [
        "A Billard",
        "S Calinon",
        "R Dillmann"
      ],
      "year": "2016",
      "venue": "Springer handbook of robotics"
    },
    {
      "citation_id": "6",
      "title": "Kinesthetic teaching and attentional supervision of structured tasks in humanrobot interaction",
      "authors": [
        "R Caccavale",
        "M Saveriano",
        "A Finzi",
        "D Lee"
      ],
      "year": "2019",
      "venue": "Autonomous Robots"
    },
    {
      "citation_id": "7",
      "title": "Deep imitation learning for complex manipulation tasks from virtual reality teleoperation",
      "authors": [
        "T Zhang",
        "Z Mccarthy",
        "O Jow",
        "D Lee",
        "X Chen",
        "K Goldberg",
        "P Abbeel"
      ],
      "year": "2018",
      "venue": "2018 IEEE International Conference on Robotics and Automation (ICRA)"
    },
    {
      "citation_id": "8",
      "title": "Imitation from observation: Learning to imitate behaviors from raw video via context translation",
      "authors": [
        "Y Liu",
        "A Gupta",
        "P Abbeel",
        "S Levine"
      ],
      "year": "2018",
      "venue": "2018 IEEE International Conference on Robotics and Automation (ICRA)"
    },
    {
      "citation_id": "9",
      "title": "Learning deep neural network policies with continuous memory states",
      "authors": [
        "M Zhang",
        "Z Mccarthy",
        "C Finn",
        "S Levine",
        "P Abbeel"
      ],
      "year": "2016",
      "venue": "2016 IEEE International Conference on Robotics and Automation (ICRA"
    },
    {
      "citation_id": "10",
      "title": "A social learning particle swarm optimization algorithm for scalable optimization",
      "authors": [
        "R Cheng",
        "Y Jin"
      ],
      "year": "2015",
      "venue": "Information Sciences"
    },
    {
      "citation_id": "11",
      "title": "Policy transfer using reward shaping",
      "authors": [
        "T Brys",
        "A Harutyunyan",
        "M Taylor",
        "A Nowé"
      ],
      "year": "2015",
      "venue": "Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems"
    },
    {
      "citation_id": "12",
      "title": "Maximum entropy deep inverse reinforcement learning",
      "authors": [
        "M Wulfmeier",
        "P Ondruska",
        "I Posner"
      ],
      "year": "2015",
      "venue": "Maximum entropy deep inverse reinforcement learning",
      "arxiv": "arXiv:1507.04888"
    },
    {
      "citation_id": "13",
      "title": "Active imitation learning via reduction to iid active learning",
      "authors": [
        "K Judah",
        "A Fern",
        "T Dietterich"
      ],
      "year": "2012",
      "venue": "Active imitation learning via reduction to iid active learning",
      "arxiv": "arXiv:1210.4876"
    },
    {
      "citation_id": "14",
      "title": "Learning a repertoire of actions with deep neural networks",
      "authors": [
        "A Droniou",
        "S Ivaldi",
        "O Sigaud"
      ],
      "year": "2014",
      "venue": "4th International Conference on Development and Learning and on Epigenetic Robotics"
    },
    {
      "citation_id": "15",
      "title": "Imitation learning: A survey of learning methods",
      "authors": [
        "A Hussein",
        "M Gaber",
        "E Elyan",
        "C Jayne"
      ],
      "year": "2017",
      "venue": "ACM Computing Surveys (CSUR)"
    },
    {
      "citation_id": "16",
      "title": "Artificial intelligence for long-term robot autonomy: A survey",
      "authors": [
        "L Kunze",
        "N Hawes",
        "T Duckett",
        "M Hanheide",
        "T Krajník"
      ],
      "year": "2018",
      "venue": "IEEE Robotics and Automation Letters"
    },
    {
      "citation_id": "17",
      "title": "Towards open and expandable cognitive ai architectures for large-scale multi-agent human-robot collaborative learning",
      "authors": [
        "G Papadopoulos",
        "M Antona",
        "C Stephanidis"
      ],
      "year": "2020",
      "venue": "Towards open and expandable cognitive ai architectures for large-scale multi-agent human-robot collaborative learning",
      "arxiv": "arXiv:2012.08174"
    },
    {
      "citation_id": "18",
      "title": "A system for learning continuous human-robot interactions from human-human demonstrations",
      "authors": [
        "D Vogt",
        "S Stepputtis",
        "S Grehl",
        "B Jung",
        "H Amor"
      ],
      "year": "2017",
      "venue": "2017 IEEE International Conference on Robotics and Automation (ICRA)"
    },
    {
      "citation_id": "19",
      "title": "Towards robotic feeding: Role of haptics in fork-based food manipulation",
      "authors": [
        "T Bhattacharjee",
        "G Lee",
        "H Song",
        "S Srinivasa"
      ],
      "year": "2019",
      "venue": "IEEE Robotics and Automation Letters"
    },
    {
      "citation_id": "20",
      "title": "Agile autonomous driving using end-to-end deep imitation learning",
      "authors": [
        "Y Pan",
        "C.-A Cheng",
        "K Saigol",
        "K Lee",
        "X Yan",
        "E Theodorou",
        "B Boots"
      ],
      "year": "2017",
      "venue": "Agile autonomous driving using end-to-end deep imitation learning",
      "arxiv": "arXiv:1709.07174"
    },
    {
      "citation_id": "21",
      "title": "Dronet: Learning to fly by driving",
      "authors": [
        "A Loquercio",
        "A Maqueda",
        "C Del-Blanco",
        "D Scaramuzza"
      ],
      "year": "2018",
      "venue": "IEEE Robotics and Automation Letters"
    },
    {
      "citation_id": "22",
      "title": "Robot learning from demonstration in robotic assembly: A survey",
      "authors": [
        "Z Zhu",
        "H Hu"
      ],
      "year": "2018",
      "venue": "Robotics"
    },
    {
      "citation_id": "23",
      "title": "Lifelong federated reinforcement learning: a learning architecture for navigation in cloud robotic systems",
      "authors": [
        "B Liu",
        "L Wang",
        "M Liu"
      ],
      "year": "2019",
      "venue": "IEEE Robotics and Automation Letters"
    },
    {
      "citation_id": "24",
      "title": "Robot learning by collaborative network training: A self-supervised method using ranking",
      "authors": [
        "M Bretan",
        "S Oore",
        "S Sanan",
        "L Heck"
      ],
      "year": "2019",
      "venue": "Proceedings of the 18th International Conference on Autonomous Agents and MultiAgent Systems"
    },
    {
      "citation_id": "25",
      "title": "Real-time data processing architecture for multi-robots based on differential federated learning",
      "authors": [
        "W Zhou",
        "Y Li",
        "S Chen",
        "B Ding"
      ],
      "year": "2018",
      "venue": "IEEE SmartWorld Congress. IEEE"
    },
    {
      "citation_id": "26",
      "title": "Communication-efficient learning of deep networks from decentralized data",
      "authors": [
        "B Mcmahan",
        "E Moore",
        "D Ramage",
        "S Hampson",
        "B Arcas"
      ],
      "year": "2017",
      "venue": "Artificial Intelligence and Statistics. PMLR"
    },
    {
      "citation_id": "27",
      "title": "On the convergence of fedavg on non-iid data",
      "authors": [
        "X Li",
        "K Huang",
        "W Yang",
        "S Wang",
        "Z Zhang"
      ],
      "year": "2019",
      "venue": "On the convergence of fedavg on non-iid data",
      "arxiv": "arXiv:1907.02189"
    },
    {
      "citation_id": "28",
      "title": "Deep affordance-grounded sensorimotor object recognition",
      "authors": [
        "S Thermos",
        "G Papadopoulos",
        "P Daras",
        "G Potamianos"
      ],
      "year": "2017",
      "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition"
    },
    {
      "citation_id": "29",
      "title": "Human action recognition using 3d reconstruction data",
      "authors": [
        "G Papadopoulos",
        "P Daras"
      ],
      "year": "2016",
      "venue": "IEEE Transactions on Circuits and Systems for Video Technology"
    },
    {
      "citation_id": "30",
      "title": "User profiling through deep multimodal fusion",
      "authors": [
        "G Farnadi",
        "J Tang",
        "M Cock",
        "M.-F Moens"
      ],
      "year": "2018",
      "venue": "Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining"
    },
    {
      "citation_id": "31",
      "title": "Drprofiling: deep reinforcement user profiling for recommendations in heterogenous information networks",
      "authors": [
        "H Liang"
      ],
      "year": "2020",
      "venue": "IEEE Transactions on Knowledge and Data Engineering"
    },
    {
      "citation_id": "32",
      "title": "User profiling and behavioral adaptation for hri: a survey",
      "authors": [
        "S Rossi",
        "F Ferland",
        "A Tapus"
      ],
      "year": "2017",
      "venue": "Pattern Recognition Letters"
    },
    {
      "citation_id": "33",
      "title": "A survey of recommender systems based on deep learning",
      "authors": [
        "R Mu"
      ],
      "year": "2018",
      "venue": "Ieee Access"
    },
    {
      "citation_id": "34",
      "title": "Deep learning based recommender system: A survey and new perspectives",
      "authors": [
        "S Zhang",
        "L Yao",
        "A Sun",
        "Y Tay"
      ],
      "year": "2019",
      "venue": "ACM Computing Surveys (CSUR)"
    },
    {
      "citation_id": "35",
      "title": "Dual relations network for collaborative filtering",
      "authors": [
        "D Ji",
        "Z Xiang",
        "Y Li"
      ],
      "year": "2020",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "36",
      "title": "Neural collaborative filtering",
      "authors": [
        "X He",
        "L Liao",
        "H Zhang",
        "L Nie",
        "X Hu",
        "T.-S Chua"
      ],
      "year": "2017",
      "venue": "Proceedings of the 26th international conference on world wide web"
    },
    {
      "citation_id": "37",
      "title": "Unsupervised learning of video representations using lstms",
      "authors": [
        "N Srivastava",
        "E Mansimov",
        "R Salakhudinov"
      ],
      "year": "2015",
      "venue": "International conference on machine learning"
    },
    {
      "citation_id": "38",
      "title": "A survey on deep learning for multimodal data fusion",
      "authors": [
        "J Gao",
        "P Li",
        "Z Chen",
        "J Zhang"
      ],
      "year": "2020",
      "venue": "Neural Computation"
    }
  ]
}