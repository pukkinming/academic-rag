{
  "paper_id": "2307.05375v1",
  "title": "Emotion Analysis On Eeg Signal Using Machine Learning And Neural Network",
  "published": "2023-07-09T09:50:34Z",
  "authors": [
    "S. M. Masrur Ahmed",
    "Eshaan Tanzim Sabur"
  ],
  "keywords": [
    "emotion recognition",
    "EEG signal",
    "DEAP dataset",
    "fft",
    "Machine Learning",
    "SVM",
    "KNN",
    "DEAP",
    "RNN",
    "LSTM"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Emotion has a significant influence on how one thinks and interacts with others. It serves as a link between how a person feels and the actions one takes, or it could be said that it influences one's life decisions on occasion. Since the patterns of emotions and their reflections vary from person to person, their inquiry must be based on approaches that are effective over a wide range of population regions. To extract features and enhance accuracy, emotion recognition using brain waves or EEG signals requires the implementation of efficient signal processing techniques. Various approaches to human-machine interaction technologies have been ongoing for a long time, and in recent years, researchers have had great success in automatically understanding emotion using brain signals. In our research, several emotional states were classified and tested on EEG signals collected from a well-known publicly available dataset, the DEAP Dataset, using SVM (Support Vector Machine), KNN (K-Nearest Neighbor), and an advanced neural network model, RNN (Recurrent Neural Network), trained with LSTM (Long Short Term Memory). The main purpose of this study is to improve ways to improve emotion recognition performance using brain signals. Emotions, on the other hand, can change with time. As a result, the changes in emotion over time are also examined in our research.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "I. Introduction",
      "text": "Emotion is defined as a person's conscious or unconscious behavior that indicates our response to a situation. Emotion is interconnected with a person's personality, mood, thoughts, motivation, and a variety of other aspects. Fear, happiness, wrath, pride, anger, panic, despair, grief, joy, tenseness, surprise, confidence, enthusiasm are the common emotions are all experienced by humans  [1] . The experience can be both positive or negative. In the light of this, physiological indications such as heart rate, blood pressure, respiration signals, and Electroencephalogram (EEG) signals might be useful in properly recognizing emotions.Emotion recognition has always been a major necessity for humanity, not just for usage in fields like computer science, artificial intelligence, and life science, but also for assisting those who require emotional support. For a long time, experts couldn't figure out a reliable way to identify true human emotion. One method was to use words, facial expression, behavior, and image to recognize one's emotions  [2] -  [5] . Researchers found that subject answers are unreliable for gauging emotion; people are unable to reliably express the strength and impact of their feelings. Furthermore, it is simple to manipulate selfdeclared emotions, resulting in incorrect findings. As a result, researchers had to shift their focus to approaches that do not rely on subject reactions. The development of Brain-Computer Interface (BCI) and Electroencephalogram (EEG) signals demonstrated more accurate methods for detecting human emotions. It introduced an involuntary approach to get more accurate and reliable results. Involuntary signals are uncontrollable and detect people's true feelings. They have the ability to express genuine emotions. The advancement of a reliable human emotion recognition system using EEG signals could help people regulate their emotions and open up new possibilities in fields like education, entertainment, and security and might aid people suffering from Alexithymia or any other psychiatric disease. The goal of our paper is to use effective techniques on DEAP dataset to extract features from EEG signals using band waves and apply machine learning algorithms and neural network models to check the efficiency of the used algorithms on valence-arousal, EEG regions and band waves.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Ii. Literature Review",
      "text": "The EEG research community is expanding its reach into a number of different fields. In her research, Vanitha V. et al.  [6]  aims to connect stress and EEG, and how stress can have both beneficial and bad effects on a person's decisionmaking process. She also discusses how stress affects one's interpersonal, intrapersonal, and academic performance and argues that stress can cause insomnia, lowered immunity, migraines, and other physical problems. Jin et al.  [7]  while analyzing emotions reported promising results, claiming that combining FFT, PCA, and SVM yielded results that were about 90 percent accurate. As a result, rather than the complexity of the classification algorithm used, the feature extraction stage determines the accuracy of any model. As a result, categorization systems can offer consistent accuracy and recall. Liu et al.  [8]  proposed a fractal-based algorithm to identify and visualize emotions in real time. They found that gamma band could be used to classify emotion. For emotion recognition, the authors analyzed different kinds of EEG features to find the trajectory of changes in emotion. They then proposed a simple method to track the changes in emotion with time. In this paper, the authors built a bimodal deep auto encoder and a single deep auto encoder to produce shared representations of audios and images. They also explored the possibility of recognizing emotion in physiological signals. Two different fusion strategies were used to combine eye movement and EEG data. The authors tested the framework for cross modal learning tasks. The authors introduce a novel approach that combines deep learning and physiological signals. The DEAP Dataset was also utilized by the following writers to analyze emotion states. Xing et al.  [9]  developed a stacked autoencoder (SAE) to breakdown EEG data and classify them using an LSTM model. -The observed valence accuracy rate was 81.1 percent, while the observed arousal accuracy rate was 74.38 percent. Chao et al.  [10]  investigated a deep learning architecture, reaching an arousal rate of 75.92 percent. and 76.83 percent for valence states. Mohammadi et al.  [11]  classified arousal and valence using Entropy and energy of each frequency band and reached an accuracy of 84.05 percent for arousal and 86.75 percent for valence. Xian et al.  [12]  utilized MCF with statistical, frequency, and nonlinear dynamic characteristics to predict valence and arousal with 83.78 percent and 80.72 percent accuracy, respectively. Ang et al.  [13]  developed a wavelet transform and time-frequency characteristics with ANN classification method. For joyful feeling, the classification rate was 81.8 percent for mean and 72.7 percent for standard deviation y. The performance of frequency domain characteristics for sad emotions was 72.7 percent. Alhagry et al.  [14]  developed a deep learning technique for identifying emotions from raw EEG data that used long-short term memory (LSTM) neural networks to learn features from EEG signals and then classified these characteristics as low/high arousal, valence, and liking. The DEAP data set was used to evaluate the -e technique. -The method's average accuracy was 85.45 percent for arousal and 85.65 percent for valence.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Iii. Methodology A. Data Materials",
      "text": "For our research, we have chosen the DEAP  [15]  dataset. The DEAP dataset for emotion classification is freely available on the internet. A number of physiological signals found in the DEAP dataset can be utilized to determine emotions. It includes information on four main types of states: valence, arousal, dominance, and liking. Due to the use of various sample rates and different types of tests in data gathering, the DEAP Dataset is an amalgamation of many different data types. EEG data was gathered from 32 participants, comprising 16 males and 16 women, in 32 channels. The EEG signals were collected by playing 40 different music videos, each lasting 60 seconds, and recording the results. Following the viewing of each video, participants were asked to rate it on a scale of one to nine points. According to the total number of video ratings received, which was 1280, the number of videos (40) multiplied by the number of volunteers (40) yielded the result (i.e. 32). Following that, the signals from 512 Hz were downsampled to 128 Hz and denoised utilizing bandpass and lowpass frequency filters, as well as a lowpass frequency filter. 512 Hz EEG signals were acquired from the following 32 sensor positions (using the worldwide 10-20 positioning system): Fp1, AF3, F3, F7, FC5, FC1, C3, T7, CP5, CP1, P3, P7, PO3, O1, Oz, Pz, Fp2, AF4, Fz, F4, F8, FC6, FC2, Cz, T8, CP2, P4, P8, PO4, and O2. It was also possible to take a frontal face video of each of the 22 participants. Several signals, including EEG, electromyograms, breathing region, plethysmographs, temperature, and so on, were gathered as 40 channel data during each subject's 40 trials, with each channel representing a different signal. EEG data is stored in 32 of the 40 available channels. The rest of the channels record EOG, EMG, ECG, GSR, RSP, TEMP and PLET data.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "B. Data Visualization",
      "text": "We extracted valence and arousal ratings from the dataset. The combination of Valence and Arousal can be converted to emotional states: High Arousal Positive Valence (Excited, Happy), Low Arousal Positive Valence (Calm, Relaxed), High Arousal Negative Valence (Angry, Nervous) and Low Arousal Negative Valence (Sad, Bored). We have analyzed the changes in emotional state along with the number of trials for each group by following Russell's circumplex model. Russell's circumplex model helped classify the DEAP dataset. Russell's methodology for visualizing the scale with the real numbers, the DEAP dataset employs self-assessment manikins (SAMs)  [16] . 1-5 and 5-9 were chosen as the scales based on self-evaluation ratings  [17] -  [19] . The label was changed to \"positive\" if the rating was greater than or equal to 5, and to \"negative\" if it was less than 5. We utilized a different way to determine \"positive\" and \"negative\" values. The difference in valence and arousal was rated on a scale of 1 to 9 by the participants of DEAP. We believe that categorizing the dataset using a mean value is not a good approach because there may be no participants who rate between 1-2 and 4-6. As a result, using a mean value to derive the separation could lead to bias. On the other hand, all users may have given ratings ranging from 5 to 9. To avoid biased analysis, we wanted to utilize the value from the mid range to separate the positive and negative values. As a result, to distinguish between \"positive\" and \"negative\" numbers, we used median values. We looked for a positive or negative valence as well as a positive or negative arousal level in each experiment. Numbers greater than the median are considered \"positive\", while values less than the median are considered \"negative\". Four labels for our research have been created: high arousal low valence (HALV), low arousal high valence (LAHV), high arousal high valence (HAHV), and low arousal low valence (LALV).",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "C. Channel Selection",
      "text": "We used two types of studies for FFT analysis. For making an RNN model with LSTM with the help of FFT processing, Emotiv Epoch+ was fitted with a total of 14 channels, which were carefully selected. The number of channels is  [1, 2, 3, 4, 6, 11, 13, 17, 19, 20, 21, 25, 29, 31]  .The number of bands is 6. band =  [4, 8, 12, 16, 25, 45]  . We also discovered the relation between Time domain and Frequency domain with the help of FFT in another study.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "D. Fft",
      "text": "Fourier Transform (FFT) is a mathematical procedure that computes the discrete Fourier transform (DFT) of a sequence. It is used to solve a variety of different types of equations or graphically depict a range of frequency activity. Fourier analysis is a signal processing technique used to convert digital signals (x) of length (N) from the timedomain to the frequency domain (X) and vice versa. FFT is a technique that is widely utilized when estimating the Power Spectral Density of an EEG signal. PSD is an abbreviation for Power spectral distribution at a specific frequency and can be computed directly on the signal using FFT or indirectly by altering the estimated autocorrelation sequence.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "E. Rnn And Lstm",
      "text": "RNNs have risen to prominence as computing power has improved, data volumes have exploded, and long short-term memory (LSTM) technology became available in the 1990s. RNNs may be incredibly precise in forecasting what will happen next because of their internal memory, which allows them to retain key input details. The reason they're so popular is because they're good at handling sequential data kinds like time series and voice. Recurrent neural networks have the advantage over other algorithms in that they can gain a deeper understanding of a sequence and its context. A shortterm memory is common in RNNs. When linked with an LSTM, they have a long-term memory as well (more on that later). Due to the data sequence providing important information about what will happen next, an RNN may do jobs that other algorithms are unable to complete.  [23]  Long short-term memory networks (LSTMs) are a sort of recurrent neural network extension that expands memory effectively. As a result, it's well-suited to learning from big experiences separated by long periods of time. RNN extensions that increase memory capacity are known as long short-term memory (LSTM) networks. The layers of an RNN are built using LSTMs. RNNs can either assimilate new information, forget it, or give it enough importance to alter the result thanks to LSTMs, which assign \"weights\" to data. The layers of an RNN, which is sometimes referred to as an LSTM network, are built using the units of an LSTM. With the help of LSTMs, RNNs can remember inputs for a long time. Because LSTMs store data in a memory comparable to that of a computer, this is the case. The LSTM can read, write, and delete information from its memory. This memory can be thought of as a gated cell, with gated signifying that the cell decides whether to store or erase data (i.e., whether to open the gates) based on the value it assigns to the data. To allocate importance, weights are utilized, which the algorithm also learns. This basically means that it learns over time which data is critical and which is not.\n\nLong-Short-Term Memory Networks (LSTMs) are recurrent neural network subtypes (RNN).",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "F. Feature Extraction",
      "text": "Extracting features from EEG data can be done in a variety of methods. Periodogram and power spectral density calculations and combining band waves of various frequencies are required for feature extraction with the help of FFT. The Welch method is  [20]  a modified segmentation scheme for calculating the average periodogram. Generally the Welch method of the PSD can be described by the equations below, the power spectra density, P(f) equation is defined first. Then, for each interval, the Welch Power Spectrum, P welch (f ), is given as the mean average of the periodogram.\n\n(1)\n\nThe power spectral density (PSD) shows how a signal's power is distributed in the frequency domain. Among the PSD estimators, Welch's method and the multitaper approach have demonstrated the best results  [21] . The input  [22]  signal x\n\n[n], n = 0,1,2,. . . ,N-1 is divided into a number of overlapping segments. Let M be the length of each segment, using n=0,1, 2,. . . ,M-1, M.\n\nwhere n=0,. . . ,M-1,i=0,1,2,. . . ,N-1 Each segment is given a smooth window w(n). In most cases, we employ the Hamming window at a time. The Hamming window formula for each segment is as follows:\n\nHere,\n\ndenotes the mean power of the window w(n). So,\n\ndenotes the energy of the window function w(n) with length M. It is to be noted that, L denotes the number of data segment. For validation, \"Accuracy\" is the most popular metric. However, a model's performance cannot be judged based only by the accuracy. So, we have used other metrics, such as -precision, recall, and f-score. The metrics were calculated using the mean of metrics for all the folds through cross validation.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Iv. Results",
      "text": "In our research, we tried to come up with a relation among EEG channel, time domain and frequency domain using Welch's Periodogram with the help of band wave and FFT. The band waves identify the following emotions.    We attempted to experience the variations in electrical activities in the brain over time in the first study. To extract EEG signals, the 32 sensor sites were separated into globally recognizable zones. The position of the electrode are frontal, central, temporal, parietal, and occipital placements, respectively. The topographical maps are used to visualize spatial distribution of activity. This useful visualization method allows us to examine how data changes over one time point to another. The subject in this study was watching a video while we analyzed the changes in electrical activity from 0.153 to 0.273 seconds. We can see the changes of electrical activity in voltage based various frequencies as band waves are determined by the range of frequency and different band waves indicate different ranges of emotion. From this, it can be said that the subject can feel different emotions in a particular time point. For the second research, during the FFT processing, we employed meta data for the purpose of doing a meta vector analysis. Raw data was split over a time span of 2 seconds, with each slice having a 0.125-second interval between it.\n\nA two-second FFT of channel was carried out in different frequencies in a sequence. Emotiv Epoch+ was fitted with a total of 14 channels, which were carefully selected. The number of channels is  [1, 2, 3, 4, 6, 11, 13, 17, 19, 20, 21, 25, 29, 31]  .The number of bands is 6. band =  [4, 8, 12, 16, 25, 45]  . A band power of 2 seconds on average is used. The window size was 256 with a step size of 16, with each update occurring once every 0.125 seconds. The sampling rate was set to 128 hertz.\n\nThe FFT was then performed on all of the subjects using Fig.  6 . Topographical Map for Gamma band wave these settings in order to obtain the required output. Neural networks and other forms of artificial intelligence require a starting collection of data, referred to as a training dataset, that serves as a foundation for subsequent application and use. This dataset serves as the foundation for the program's developing information library. Before the model can interpret and learn from the training data, it must be appropriately labeled. The lowest value of the data is 200 and the greatest value is above 2000, which means that trying to plot it will result in a lot of irrelevant plots, which will make conducting the analysis tough. The objective of machine learning is to create a plot and then optimize it further in order to obtain a pattern. And if there are significant differences between the plotted points, it will be unable to optimize the data. As a result, in order to fix this issue, the values have been reduced to their bare minimum, commonly known as scaling. The values of the data will not be lost as a result of scaling; instead, the data will be optimized to the point where there is little difference between the plotted points. In order to achieve this, StandardScaler must transform your data into a distribution with a mean of zero and a standard deviation of one. When dealing with multivariate data, this is done feature-by-feature to ensure that the data is accurate (in other words independently for each column of the data). Because of the way the data is distributed, each value in the dataset will be deducted from the In our situation, dropout rates began at 30%, increased to 50%, then 30%, 30%, 30%, and eventually 20%. We worked with three-dimensional datasets; however, when we converted to a dense layer, we obtained a one-dimensional representation in order to make a prediction. RMSprop was used as the optimizer with a learning rate of 0.001, a rho value of 0.9, and an epsilon value of 1e-08. RMSprop calculates the gradient by dividing it by the root of the moving (discounted) average of the square of the gradients. This application of RMSprop makes use of conventional momentum rather than Nesterov momentum. Additionally, the centered version calculates the variance by calculating a moving average of the gradients.\n\nAs we can see, accuracy increases very gradually in this case, and learning rate plays a major part. If we increased the learning rate, accuracy would also increase rapidly, and when optimization is reached, the process would reverse, with accuracy decreasing at a faster rate. That is why the rate of learning has been reduced. When one zero is removed, the accuracy decreases significantly. As our loss function, we utilized the Mean Squared Error. The Mean Squared Error (MSE) loss function is the most basic and extensively used loss function, and it is typically taught in introductory Machine Learning programs. To calculate the MSE, take the difference between your model's predictions and the ground truth, square it, and then average it across the whole dataset. The MSE can never be negative since we are constantly squaring the errors.\n\nTo compute loss, we utilized mean squared error. Because of the squaring portion of the function, the MSE is excellent for guaranteeing that the trained model does not contain any outlier predictions with significant mistakes. Because of this, the MSE places greater emphasis on outlier predictions with large errors. We tried our best to reduce the percentage of value loss and increase the accuracy rate. We saved the model and kept track by every 50 epochs. In the first picture, we can see that for the first 50 epochs the training loss 0.",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "V. Conclusion",
      "text": "To summarize, in this research, we describe the EEGbased emotion recognition challenge, as well as existing and proposed solutions to this problem. Emotion detection by the use of EEG waves is a relatively new and exciting area of study and analysis. To identify and evaluate on numerous emotional states using EEG signals acquired from the DEAP Dataset, SVM (Support Vector Machine), KNN (K-Nearest Neighbor). According to the findings, the suggested method is a very promising option for emotion recognition, owing to its remarkable ability to learn features from raw data in a short period of time. When compared to typical feature extraction approaches, it produces higher average accuracy over a larger number of people.",
      "page_start": 5,
      "page_end": 5
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Time Domain of the EEG Signals",
      "page": 4
    },
    {
      "caption": "Figure 2: Power Spectral Density Across Channels",
      "page": 4
    },
    {
      "caption": "Figure 3: Topographical Map for Theta band wave",
      "page": 4
    },
    {
      "caption": "Figure 4: Topographical Map for Alpha band wave",
      "page": 4
    },
    {
      "caption": "Figure 5: Topographical Map for Beta band wave",
      "page": 4
    },
    {
      "caption": "Figure 6: Topographical Map for Gamma band wave",
      "page": 5
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Band Waves": "Theta",
          "Frequency (Hz)": "4 − 8",
          "Features or emotions": "Drowsiness,Mental Connection,\nCreativity"
        },
        {
          "Band Waves": "Alpha",
          "Frequency (Hz)": "8 − 16",
          "Features or emotions": "Reflection & Relaxation"
        },
        {
          "Band Waves": "Beta",
          "Frequency (Hz)": "16 − 32",
          "Features or emotions": "Concentration, Problem Solving"
        },
        {
          "Band Waves": "Gamma",
          "Frequency (Hz)": "32 − 64",
          "Features or emotions": "Learning, Perception, Multi-tasking"
        }
      ],
      "page": 4
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Emotion recognition based on eegusing deap dataset",
      "authors": [
        "S Rama Chaudhary",
        "Ram Jaswal"
      ],
      "year": "2021",
      "venue": "European Journal of Molecular amp"
    },
    {
      "citation_id": "2",
      "title": "A study on emotional feature analysisand recognition in speech signal",
      "authors": [
        "X Cheng",
        "C Ying",
        "L Zhao"
      ],
      "year": "2009",
      "venue": "Measuring Technology and MechatronicsAutomation, International Conference on",
      "doi": "10.1109/ICMTMA.2009.89"
    },
    {
      "citation_id": "3",
      "title": "Multimodal emotion recog-nition based on speech and ecg signals",
      "authors": [
        "C Huang",
        "Y Jin",
        "Q Wang",
        "L Zhao",
        "C Zou"
      ],
      "year": "2010",
      "venue": "Multimodal emotion recog-nition based on speech and ecg signals",
      "doi": "10.3969/j.issn.1001-0505.2010.05.003"
    },
    {
      "citation_id": "4",
      "title": "Research of emotion recognition based onspeech and facial expression",
      "authors": [
        "Y Wang",
        "X Yang",
        "J Zou"
      ],
      "year": "2013",
      "venue": "TELKOMNIKA Indonesian Journal of Electri-cal Engineering",
      "doi": "10.11591/telkom-nika.v11i1.1873"
    },
    {
      "citation_id": "5",
      "title": "A real time face emotion classificationand recognition using deep learning model",
      "authors": [
        "S Hussain",
        "A Balushi"
      ],
      "year": "2020",
      "venue": "Journal of Physics: ConferenceSeries",
      "doi": "10.1088/1742-6596/1432/1/012087"
    },
    {
      "citation_id": "6",
      "title": "Real time stress detection system based on eegsignals",
      "authors": [
        "V Vanitha",
        "P Krishnan"
      ],
      "year": "2016",
      "venue": "Real time stress detection system based on eegsignals"
    },
    {
      "citation_id": "7",
      "title": "Classification of direction perception eegbased on pca-svm",
      "authors": [
        "J Jin",
        "X Wang",
        "B Wang"
      ],
      "year": "2007",
      "venue": "inThird International Conference on Natural Computa-tion (ICNC 2007)",
      "doi": "10.1109/ICNC.2007.298"
    },
    {
      "citation_id": "8",
      "title": "Emotion recognition using multimodaldeep learning",
      "authors": [
        "W Liu",
        "W.-L Zheng",
        "B.-L Lu"
      ],
      "year": "2016",
      "venue": "Emotion recognition using multimodaldeep learning",
      "doi": "10.1007/978-3-319-46672-958"
    },
    {
      "citation_id": "9",
      "title": "Sae+lstm: A new framework for emotion recognition from multi-channel eeg",
      "authors": [
        "X Xing",
        "Z Li",
        "T Xu",
        "L Shu",
        "B Hu",
        "X Xu"
      ],
      "year": "2019",
      "venue": "Frontiers in Neurorobotics",
      "doi": "10.3389/fnbot.2019.00037"
    },
    {
      "citation_id": "10",
      "title": "Recognition of emotions using multi-channel eeg data and dbn-gc-based ensemble deep learning framework",
      "authors": [
        "H Chao",
        "H Zhi",
        "D Liang",
        "Y Liu"
      ],
      "year": "2018",
      "venue": "Computational Intelligence and Neuroscience",
      "doi": "10.1155/2018/9750904"
    },
    {
      "citation_id": "11",
      "title": "Wavelet-based emotion recognition system using eeg signal",
      "authors": [
        "Z Mohammadi",
        "J Frounchi",
        "M Amiri"
      ],
      "year": "2017",
      "venue": "Neural Computing and Applications",
      "doi": "10.1007/s00521-015-2149-8"
    },
    {
      "citation_id": "12",
      "title": "Channel division based multiple classifiersfusion for emotion recognition using eeg signals",
      "authors": [
        "X Li",
        "J.-Z Yan",
        "J.-H Chen"
      ],
      "year": "2017",
      "venue": "ITM Web of Conferences",
      "doi": "10.1051/itm-conf/20171107006"
    },
    {
      "citation_id": "13",
      "title": "Emotion classification from eeg signals using time-frequency-dwt features and ann",
      "authors": [
        "A Ang",
        "Y Yeong"
      ],
      "year": "2017",
      "venue": "Journal of Computer and Communications",
      "doi": "10.4236/jcc.2017.53009"
    },
    {
      "citation_id": "14",
      "title": "Emotion recognition based on eeg using lstm recurrent neural network",
      "authors": [
        "S Alhagry",
        "A Aly",
        "R El-Khoribi"
      ],
      "year": "2017",
      "venue": "International Journal of Advanced Computer Science and Applications",
      "doi": "10.14569/IJACSA.2017.081046"
    },
    {
      "citation_id": "15",
      "title": "DEAP: A Database for Emotion Analysis using Physiological Signals (PDF)",
      "authors": [
        "S Koelstra",
        "C Muehl",
        "M Soleymani",
        "J.-S Lee",
        "A Yazdani",
        "T Ebrahimi",
        "T Pun",
        "A Nijholt",
        "I Patras"
      ],
      "year": "2012",
      "venue": "EEE Transactions on Affective Computing"
    },
    {
      "citation_id": "16",
      "title": "Observations: Sam: The self-assessment manikin an efficient cross-cultural measurement of emotional response 1",
      "authors": [
        "J Morris"
      ],
      "year": "1995",
      "venue": "Journal of Advertising Research"
    },
    {
      "citation_id": "17",
      "title": "Modeling physiological data with deep belief net-works",
      "authors": [
        "D Wang",
        "Y Shang"
      ],
      "year": "2013",
      "venue": "International journal of information and education technology (IJIET)",
      "doi": "10.7763/IJIET.2013.V3.326"
    },
    {
      "citation_id": "18",
      "title": "Eeg based emotion identification using unsupervised deep feature learning",
      "authors": [
        "X Li",
        "P Zhang",
        "D Song",
        "G Yu",
        "Y Hou",
        "B Hu"
      ],
      "year": "2015",
      "venue": "Eeg based emotion identification using unsupervised deep feature learning"
    },
    {
      "citation_id": "19",
      "title": "Eeg-based multi-modal emotion recognition using bag of deep features: An optimal feature selection approach",
      "authors": [
        "M Asghar",
        "M Khan",
        "Y Fawad",
        "M Amin",
        "M Rizwan",
        "S Rahman",
        "S Bad-Nava",
        "S Mirjavadi",
        "Mirjavadi"
      ],
      "year": "2019",
      "venue": "Sensors",
      "doi": "10.3390/s19235218"
    },
    {
      "citation_id": "20",
      "title": "Psd based features extraction for eeg signal during typing task",
      "authors": [
        "W Ng",
        "A Saidatul",
        "Y Chong",
        "Z Ibrahim"
      ],
      "year": "2019",
      "venue": "IOP Conference Series: Materials Science and Engineering",
      "doi": "10.1088/1757-899X/557/1/012032"
    },
    {
      "citation_id": "21",
      "title": "Cross comparison of motor unit potential features used in emg signal decomposition",
      "authors": [
        "M Jahromi",
        "H Parsaei",
        "A Zamani",
        "D Stashuk"
      ],
      "year": "2018",
      "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering",
      "doi": "10.1109/TNSRE.2018.2817498"
    },
    {
      "citation_id": "22",
      "title": "A parallel algorithm framework for feature extraction of eeg signals on mpi",
      "authors": [
        "Q Xiong",
        "X Zhang",
        "W.-F Wang",
        "Y Gu"
      ],
      "year": "2020",
      "venue": "Computational and Mathematical Methods in Medicine",
      "doi": "10.1155/2020/9812019"
    },
    {
      "citation_id": "23",
      "title": "A guide to rnn: Understanding recurrent neural networksand lstm networks",
      "authors": [
        "N Donges"
      ],
      "year": "2021",
      "venue": "A guide to rnn: Understanding recurrent neural networksand lstm networks"
    }
  ]
}