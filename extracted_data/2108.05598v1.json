{
  "paper_id": "2108.05598v1",
  "title": "Affranknet+: Ranking Affect Using Privileged Information",
  "published": "2021-08-12T08:36:31Z",
  "authors": [
    "Konstantinos Makantasis"
  ],
  "keywords": [
    "Ranking affect",
    "preference function",
    "privileged information",
    "knowledge distillation",
    "RankNet"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Many of the affect modelling tasks present an asymmetric distribution of information between training and test time; additional information is given about the training data, which is not available at test time. Learning under this setting is called Learning Under Privileged Information (LUPI). At the same time, due to the ordinal nature of affect annotations, formulating affect modelling tasks as supervised learning ranking problems is gaining ground within the Affective Computing research community. Motivated by the two facts above, in this study, we introduce a ranking model that treats additional information about the training data as privileged information to accurately rank affect states. Our ranking model extends the wellknown RankNet model to the LUPI paradigm, hence its name Af-fRankNet+. To the best of our knowledge, it is the first time that a ranking model based on neural networks exploits privileged information. We evaluate the performance of the proposed model on the public available Afew-VA dataset and compare it against the RankNet model, which does not use privileged information. Experimental evaluation indicates that the AffRankNet+ model can yield significantly better performance.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "I. Introduction",
      "text": "One of the most popular ways for annotating affect is based on rating systems, such as simple Likert scales  [1] , self-assessment manikins  [2] , and rating scales of the discrete states in the Geneva emotion wheel  [3] . The common characteristic of all the above rating systems is that they provide ordinal and not nominal information about the affect states. In addition, several psychometric studies show that ratings of affect do not follow an absolute and consistent scale  [4] ,  [5] . Therefore, learning to predict nominal values of affect yields inconsistent models of questionable quality and use. On the contrary, treating ratings as ordinal values yields less biased datasets and, thus, more reliable models of affect  [6] . For the reasons above, formulating affect modelling tasks as supervised learning ranking problems is gaining ground within the Affective Computing research community.\n\nThe supervised learning problem of ranking consists of using labelled information to derive accurate ranking prediction functions. Most of the algorithms that try to address that problem are using information that comes solely from labelled This work has been supported by the European Union's Horizon 2020 research and innovation programme from the TAMED project (Grant Agreement No. 101003397). pairs of data points and transform the ranking problem into a classification one  [7] -  [9] . The label of a pair (x i , x i ) of data points is 1, -1, or 0 if x i is ranked higher than, lower than, or equal to x i , respectively. Hence, these algorithms can be used even when only the global ordering of data points is provided without the need for preference scores or other kinds of information.\n\nIn many real-world applications, however, there is an asymmetric distribution of information between training and test time; that is, additional information is given about the training data, which is not available at test time. Consider, for example, user ratings for different movies, self-assessment manikin scale for affect annotation, or the number of likes and dislikes associated with advertisements. Although this additional information, which can be implicitly seen as preference scores, is very valuable, it is disregarded by algorithms that use solely labelled pairs of data points.\n\nIn this study, we propose a supervised learning ranking model of affect. Besides the information that comes from labelled pairs of data points, our model also exploits additional information that directly or indirectly is associated with preference scores, that is ordinal values of affect states. Since this additional information can only be available during the training phase of the model and not at test time, we treat it as privileged information and follow the learning paradigm of Learning Under Privileged Information (LUPI) proposed by Vapnik and Vashist  [10] . Our model of affect is based on Neural Networks (NN) and extends the well-known RankNet  [11]  to the LUPI paradigm, hence its name AffRankNet+. To the best of our knowledge, this is the first time that privileged information is incorporated into NN for addressing supervised learning ranking problems and the first time that the LUPI paradigm is used for affect modelling. Experimental validation of AffRankNet+ on the large scale publicly available Afew-VA dataset  [12]  indicates that privileged information significantly improves the ranking performance of affect models.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Ii. Related Work",
      "text": "This section surveys literature on supervised learning ranking models, and affect modelling based on ranking/preference learning approaches.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "A. Supervised Learning Ranking Models",
      "text": "The supervised learning problem of ranking, based on labelled pairs of data points, has been widely studied. Below we present some landmark works focusing on this problem.\n\nRankSVM proposed in  [7]  was one of the first approaches focusing on this problem. The authors use Support Vector Machines (SVM) to compute a preference function. In  [13] ,  [14]  the authors reduce the number of RankSVM variables from quadratic to linear with respect to the number of training instances in order to significantly reduce the training time and make RankSVM suitable for large-scale problems.\n\nRankBoost  [8] ,  [15] ,  [16]  is another well-known ranking algorithm. RankBoost creates and aggregates a set of ranking functions in an iterative fashion to build an effective ranking procedure. Using solely information that comes from labelled pairs of data points, RankBoost estimates a preference function that can map single points to real-valued preference scores.\n\nThe authors in  [11]  approach the ranking problem by proposing a probabilistic cost function for training machine learning models. In their study, they utilize NN, and thus they call their approach RankNet. The idea, however, of employing a probabilistic cost function has equally well been applied to ranking algorithms that adopt different learning machines, such as Boosted Trees  [9] . Similarly to the approaches presented above, RankNet is trained on labelled pairs of data points. After training, it can evaluate single points and produce preference scores for each one of them. DeepRank  [17] , which targets information retrieval tasks, is also based on NN. However, it differs from RankNet, since it identifies and exploits local preference relations between the data points to induce the global ranking. In  [18]  the authors introduce l 1 regularization to a NN-based ranking model, to enforce sparsity and avoid overfitting. Since the above mentioned approaches are based on NN, they can straightforward exploit the recent advances in deep learning  [19] ,  [20]  and tensor-based learning  [21] -  [23] . However, none of these follows the LUPI paradigm to exploit additional/privileged information about the training data that might be available. In other words, they follow the typical supervised learning setting by transforming the ranking problem to a classification one.\n\nSelecting a preference function using the methods presented above is based solely on the order of the data points. Even if additional information is available, such as preference scores associated with the points, this information is entirely disregarded. In this study, we argue that exploiting additional information associated with preference scores can produce more accurate ranking algorithms. We assume that the additional information is available only during the training phase of the model and not at test time. This assumption is critical to impose no restrictions related to capturing additional information during the real-world deployment of the model. To enable the AffRankNet+ model to exploit additional information during training efficiently, we follow the LUPI paradigm  [10] ,  [24] , which is closely related to knowledge distillation proposed in  [25] . Theoretical results  [26] ,  [27]  show that following the LUPI paradigm reduces the sample complexity of the learning algorithm, which implies that LUPI models learn faster, and at the same time, they are very efficient for small sample setting problems, i.e. problems where the number of annotated samples is limited.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "B. Ranking-Based Affect Modelling",
      "text": "Based on psychological theories and evidence from multiple disciplines, such as neuroscience and artificial intelligence, Yannakakis et al.  [28]  draw the theoretical reasons to favour ordinal labels for representing and annotating affective states. They also suggest ranking/preference learning as the appropriate approach for building reliable and valid affect models. Due to the ordinal nature of emotions, several studies approach affect modelling using ranking or preference machine learning algorithms.\n\nIn  [29]  the authors represent the emotion elicited by a music song as a point into a two-dimensional Cartesian space with valence and arousal as dimensions. The coordinates of a song are determined relatively, using a modification of the ListNet  [30]  algorithm, with respect to other songs' emotions. The study in  [31]  also focuses on music emotion recognition. The authors first collect a dataset and annotate it using ordinal labels. Then, they propose a modification of RankSVM, called smoothed RankSVM, for deriving emotion recognition models.\n\nSimilarly, the study in  [32]  proposes a ranking algorithm to identify the emotions that are more intensely associated with a given text. By exploiting the ordinal nature of emotions, their proposed approach outperforms multi-label classification methods. The authors in  [33]  propose a multimodal ranking algorithm for emotion recognition. Their algorithm is based on the emotion intensity gradient; that is, the relative emotion intensity change between two or more different inputs. The authors in  [34]  exploit a ranking algorithm to predict spectators' felt emotions for a given movie scene. They use both physiology and audio-visual features to build and evaluate their models of affect. In  [35]  audio-visual information from gameplay videos is fed to a deep learning RankNet model to estimate the intensity of emotions felt by gamers while they were playing a game. Finally, due to the theoretical and experimental evidence that ordinal data processing yields more reliable, valid and general models of affect, the authors in  [36]  present the open-source Python Preference Learning Toolbox (PyPLT) to enable the extensive use of ordinal data processing and ranking algorithms.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "C. Our Contribution",
      "text": "The contribution of this study is four-fold. First, to the best of our knowledge, we propose for the first time an NN-based supervised learning algorithm that focuses on the problem of ranking and exploits privileged information associated with preference scores. Second, since our approach utilizes NN, it can take full advantage of the recent advances in deep learning and tensor-based NN, such as automatic feature extraction and information processing in high dimension spaces. The   5 ) (middle) for a pair of points (x, x ) when f (x, x ) = 1, g(z) = 8, g(z ) = 4, λ = 0.5 and τ = 1. The diagram on the right presents the error due to the terms that correspond to the privileged information in  (5) .\n\nabove implies that our model can be straightforwardly applied to data points that are represented as feature vectors, but also to data points that lie in tensor spaces such as images, videos, multi-model data (e.g. audiovisual signals) as well as to spatiotemporally evolving sensor network data  [37] . Third, by exploiting additional information only during the training phase, the potential applications of our model are not restricted by the requirement of capturing additional information at deployment time. Fourth, we evaluate the proposed model on a large scale publicly available affect dataset; the evaluation results indicate that exploitation of privileged information significantly improves ranking results.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Iii. Problem Formulation",
      "text": "In this section, we first present the ranking problem when information comes solely from labelled pairs of data points. Then, we present its extension to follow the LUPI paradigm assuming privileged information regarding preference scores is available only during the training phase of the model (and not during test time). For simplicity, we formulate the problem of ranking based on labelled pairs of data points as a binary classification problem. However, the formulation can be straightforwardly modified to treat this problem as a threeclass classification task to consider pairs of points that are non-comparable or equally preferred",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "A. The Ranking Problem",
      "text": "Let us denote by X the input space i.e. the feature space of data points, by f : X × X → {0, 1} a target labeling function, and by \" \" and \" \" preference relations; x i x j means x i is ranked higher than x j and thus f (x i , x j ) = 1. Similarly, x i x j means that x i is ranked lower than or equal to x j and thus f (x i , x j ) = 0. Given a set of labelled points\n\nwhere\n\nwhere RS (h) stands for the empirical error of the preference function h and can be quantified by the Binary Cross Entropy (BCE) loss function\n\nwhere\n\nis the sigmoid function.\n\nAt this point, we should mention that the class of functions H contains all the functions that a given machine learning model can compute. Consider, for example, a neural network with a given architecture. Then every function that the above neural network can compute for different values for its weights belongs to H.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "B. The Problem Of Ranking Using Privileged Information",
      "text": "LUPI is based on the availability of additional information, called privileged information, that can be used only during the training phase of a learning model. According to LUPI, exploitation of privileged information during training makes a learning model learn better and faster  [10] ,  [24] . This information, however, is not available at test time.\n\nLet us denote as Z the space of privileged information. Then, the set of labelled points in (1) is enhanced by the presence of privileged information as\n\nwhere z i , z i ∈ Z, and in general X = Z.\n\nConsidering especially the problem of ranking, z i 's should correspond to a representation of information that can be used to estimate preferences scores for x i 's (for example, the output of a learning model that has been trained on z i 's to predict preference scores), or to a direct representation of those preference scores. As far as the latter case is concerned, having available z i 's, which are a direct representation of preference scores, is prevalent for many real-world ranking applications; consider, for example, affect ratings from ordinal annotation tools be directly used as preference scores.\n\nIn the following, we unify the two cases of privileged information mentioned above by considering a function g : Z → R that transforms z i 's to preference scores. In the second case where z i 's are a direct representation of preference scores, g is the identity function, i.e. g(z i ) = z i . The function g in LUPI and knowledge distillation parlance is called \"teacher\".\n\nFor exploiting privileged information we modify the empirical error in (3)) as follows\n\nwhere function φ is the hyperbolic tangent function, i.e., φ(x) = tanh(x), that bounds the additional error terms to [0, 1), λ ∈ [0, 1] is balancing the error terms, and τ > 0 is a temperature parameter that quantifies the degree to which the values of the preference scores can be trusted. Fig.  1  presents the error surfaces normalized to [0, 1] for equations (  3 ) and (  5 ), when λ = 0.5 and τ = 1.0 and the preference scores for the two data points are 8 and 4, respectively. The same figure also presents the error added to the cost due to the two additional terms in (  5 ) which corresponds to the privileged information that comes in the form of preference scores. While the loss in (3) considers as best solution the one that maximizes the difference h(x) -h(x ), the loss in (  5 ) selects the preference function h that at the same time reduces the BCE loss and matches, as match as possible, the preference scores provided by the privileged information.\n\nBased on the discussion above, given a labelled set of training points in the form of equation (  4 ) and a set of preference functions H, the main objective of this study is to select a function h * ∈ H that minimizes the loss in  (5) .\n\nA natural question that arises is why not use a typical regression model for estimating the preference function h using as target the preference scores provided by the privileged information. Minimizing the sum of BCE and the last two terms of equation (  5 ) determines simultaneously the distance of a labelled pair of points from the classification decision boundary, and the degree to which the preference function h(•) matches the preference scores coming from privileged information. In ranking problems, the preference scores are usually subjectively biased; different users follow a different internal/personal preference function for providing their ratings. Parameters λ and τ in equation (5) determine the degree to which the learning model should trust the provided preference scores. Doing the same thing using a typical regression model is not possible. In addition, the loss in (  5 ) is not just balancing classification and regression losses; BCE and mean squared error. The employment of a general function g : Z → R that transforms privileged information to preference scores indicates that our model goes beyond the typical supervised learning setting to benefit from the properties (robust and fast training) of the LUPI paradigm.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Iv. The Affranknet+ Model",
      "text": "Our proposed model is based on and extends the RankNet model  [11] . Like RankNet, it is an NN-based learning model that is trained on labelled pairs of data points. At the same time, however, and unlike RankNet, it exploits privileged information related to preference scores during its training phase to learn faster and in a more robust way. Specifically, our proposed model is a two-stream neural network. The architectures of the neural networks corresponding to the two streams are identical, and their weights are tied. Therefore, the two streams produce the same outputs, given that their inputs are the same. Let us denote by ĥ(x) the output of each stream when x is given as input. The model receives as input a labelled pair of data points, that is (x i , x i , g(z i ), g(z i ), t i ). The first data point x i is fed as input to the first stream, which outputs ĥ(x i ). Similarly, the second point x i is fed as input to the second stream, which outputs ĥ(x i ). Having the outputs of the two streams, the model predicts a label ti for the sample (x i , x i ) as follows:\n\nwhere σ is the sigmoid function. The output ti replaces t in  (5)  and is used to estimate the missranking error. For computing the second and the third terms in equation (  5 ), we replace h(x i ) and h(x i ) with ĥ(x i ) and ĥ(x i ) respectively. Given that we have in our disposal a training set of labelled points in the form of equation (  4 ) and a function g : Z → R that transforms z i 's to preference scores, we can train the AffRankNet+ model by minimizing  (5)  with respect to the model parameters (NN weights). After training, the AffRankNet+ model computes a preference function ĥ * (x) that outputs the preference score for each data point x.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "V. Experimental Setting And Evaluation",
      "text": "In this section, we present the employed dataset including the training and test sets construction, the architecture of the AffRankNet+ model and the training details, and finally, the performance evaluation results.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "A. Dataset",
      "text": "For evaluating the proposed AffRankNet+ model, we use the Afew-VA public available dataset  [12] . That dataset consists of 600 videos from films that range from 10 to 120 frames. The collected videos display various facial expressions. Each of the videos is annotated per frame, in terms of valence and arousal level, in the integer range  [-10, 10] . In this study, which serves as a proof of concept, we consider only the arousal annotations. Therefore our objective is to rank the video frames based on the arousal level. Fig.  2  presents six indicative frames from the employed dataset along with their arousal annotation. We should note that the target variables for the Afew-VA dataset are subjectively defined and thus their estimation is better suited within a ranking setting  [6] ,  [28] .\n\nThe Afew-VA dataset, along with the frames, provides 68 facial landmark points. We use those landmark points to detect and crop the face. After cropping the face, we create a vector representation of the facial images using the features produced by the VGG-Face neural network  [39]  pre-trained for face recognition. Moreover, since the integer arousal annotation can be seen as preference scores, in our case the function g(•) in loss (  5 ) is the identity function.\n\nAfter defining the vector representation of frames and the form of privileged information, we have to construct the training and test sets in the form of (4) for training and evaluating the performance of our model. To do so, in the first place, we split the Afew-VA dataset into two sets following the group holdout scheme. This way, we can be sure that frames corresponding to the same video will be present either in the training set or the testing set, but not in both. Then, we compare the arousal annotation values of all pairs of points that belong to the same set and include in the training (test) set the pairs whose annotation difference is larger than a threshold. That threshold can be seen as a preference uncertainty bound which avoids resulting in a ranking model that its output is affected by trivial input differences. Such a threshold is commonly used when ranking algorithms are used for affect modelling (see for example  [35] ). In this study, we set the value for that threshold equal to 4 following a trial-and-error procedure. The value of the threshold above balances, on the one hand, the richness of the data, and on the other, the size of the dataset, which highly affects the computational cost for training the model.",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "B. Architecture Of Affranknet+ And Training Details",
      "text": "As mentioned before, the AffRankNet+ model is a twostream neural network. The two streams have exactly the same topology and tied weights. In this study, the AffRankNet+ model uses the pre-trained VGG Face as a backbone network for constructing features from the face images. The VGG Face network builds features with 4096 elements, which then are fed to a fully connected feedforward neural network with one hidden layer of 512 neurons. We keep fixed the weights of the VGG Face feature construction network during training and modify only the weights of the subsequent fully connected feedforward neural network. Fig.  3  visually presents the architecture of the proposed AffRankNet+ model. The green part corresponds to the VGG Face backbone network, while the blue to the trainable part of the AffRankNet+.\n\nWe conduct experiments with varying training sizes; that is, 5%, 10%, and 20% of the whole dataset are used for training and the rest for testing. 10% of the training set is used as the validation set to activate early stopping criteria; the training stops after 15 epochs without validation loss improvement. We choose to use a small percentage of the whole dataset for training since the exploitation of privileged information reduces the sample complexity of learning, enabling the efficient training of the model using a small number of labelled data. For each training set size, we run ten experiments following",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "C. Evaluation Results",
      "text": "Following the experimental setting described above, we evaluate the ranking performance of the proposed model. The evaluation takes place in terms of average Pearson's correlation coefficient (r) and average Kendall's tau (τ) since these metrics are widely used for evaluating ranking algorithms  [12] ,  [40] .\n\nFirst, we investigate the effect of λ parameter (see equation (  5 )) on the performance of the model by running experiments for different values of λ, namely λ = 0.3, 0, 5, 0.8. Second, we compare the performance of the AffRankNet+ model against the performance of the RankNet model, which does not exploit privileged information. To conduct a fair comparison, the two models have the same architecture and are trained and evaluated on the same sets of data points.\n\nTables I and II present the performance of AffRankNet+ model in terms of Pearson's correlation coefficient (r) and Kendall's tau (τ), respectively. We can see that for small-sized datasets, larger values of λ parameter yield better model's performance both in terms of Pearson's r and Kendall's τ. The obtained results agree with the formulation of loss in equation (  5 ) used by the AffRankNet+ model. The number of points in a dataset and the uncertainty about the preference scores are inversely proportional. As mentioned before, parameter λ quantifies the degree to which the model should trust the privileged information from the preference scores. Therefore, when the uncertainty is large, the model achieves better results by weighting more the first (preference relations) term in equation  (5) . On the contrary, when the size of the dataset is adequately large, the second term in (5), associated with preference scores, is more important and smaller values for parameter λ yield better ranking results.\n\nIn the next set of experiments, we compare the performance of the proposed AffRankNet+ model against the RankNet model, which does not exploit privilege information. As mentioned above, the two compared models have exactly the same architecture and are trained/validated on exactly the same data points. This way, any difference in the performance of the two models would be due to the exploitation of privileged information that comes from the preference scores. We should mention that for the AffRankNet+ model, we use the best value for the λ parameter based on our previous experiment, that is λ = 0.8 for dataset sizes 5% and 10% and λ = 0.3 for 20% dataset size.\n\nFig.  4  presents the results from the comparison above. No matter the size of the dataset, the AffRankNet+ model achieves better performance in terms of both metrics than the RankNet model. Moreover, we test whether the improvement in performance achieved by using privileged information is statistically significant or not. Since we run ten experiments for each dataset size following the group holdout cross-validation scheme, we collect each fold's models' performance. Then, we test the null hypothesis the performances of the two models come from the same distribution. To do so, we conduct paired t-tests. Based on the t-tests outcomes, for all dataset sizes, we can reject the null hypothesis at a significance level of 0.05. Therefore, we can safely conclude that the exploitation of privileged information can significantly boost the performance of a ranking model.\n\nAt this point, we should stress out that this study is not focusing on proposing a state-of-the-art ranking model for that specific dataset. Instead, it focuses on the importance of exploiting privileged information and on presenting a general methodology for ranking problems. Therefore the Afew-VA dataset is used as a proof-of-concept.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Vi. Conclusions",
      "text": "This study introduces the AffRankNet+ model for ranking affect states using privileged information associated with preference scores. To the best of our knowledge, this is the first time that a ranking model based on neural networks follows the LUPI paradigm. Although this study considers that preference scores are available, the formulation of the AffRankNet+ model is general to allow other types of information associated with preference scores to be used as privileged. For example, facial action units can be used as privileged information for learning to rank using the pixels' information solely from images of faces. We tested the ranking performance of AffRankNet+ on the public available Afew-VA dataset and compared it against the RankNet model. To conduct a fair comparison, both the AffRankNet+ and RankNet models have the same architecture and are trained/validated on the same data points. The experimental results emphasize the importance of privileged information by indicating that AffRankNet+, when appropriately parameterized, can perform significantly better than the RankNet model.",
      "page_start": 6,
      "page_end": 6
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Error surfaces normalized to [0,1] for the losses in (3) (left) and (5) (middle) for a pair of points (x, x′) when f(x, x′) = 1, g(z) = 8, g(z′) = 4,",
      "page": 3
    },
    {
      "caption": "Figure 2: Indicative frames from the Afew-VA dataset along with their",
      "page": 4
    },
    {
      "caption": "Figure 3: The architecture of AffRankNet+ model.",
      "page": 5
    },
    {
      "caption": "Figure 2: presents six",
      "page": 5
    },
    {
      "caption": "Figure 3: visually presents",
      "page": 5
    },
    {
      "caption": "Figure 4: The architecture of AffRankNet+ model.",
      "page": 7
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "1.0\n0.9\n0.8\n0.7\nrorrE\n0.6\n0.4\n0.3\n0.2\n0.1\n0.0\n10\n8\nh(x') 6 4\n2 0 0 2 4 h(x) 6\nFig.1. Errorsurfacesnormalizedto[0,1]\nλ=0.5andτ =1.Thediagramonther": "",
          "Column_2": "1.0\n0.9\n0.8\n0.7\nrorrE\n0.6\n0.4\n0.3\n0.2\n0.1\n0.0\n10\n8\nh(x') 6 4\n2 0 0 2 4 h(x) 6",
          "Column_3": "",
          "Column_4": "",
          "Column_5": "rorrE",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "",
          "Column_10": "rorrE",
          "Column_11": "",
          "Column_12": "",
          "4 2 0 0 2 4 h(x) 6 8 10\nhenf(x,x(cid:48))=1,g(z)=8,g(z(cid:48))=4,\nnformationin(5).": "4 2 0 0 2 4 h(x) 6 8 10"
        },
        {
          "1.0\n0.9\n0.8\n0.7\nrorrE\n0.6\n0.4\n0.3\n0.2\n0.1\n0.0\n10\n8\nh(x') 6 4\n2 0 0 2 4 h(x) 6\nFig.1. Errorsurfacesnormalizedto[0,1]\nλ=0.5andτ =1.Thediagramonther": "",
          "Column_2": "",
          "Column_3": "1.0\n0.9\n0.8\n0.7\nrorrE\n0.6\n0.4\n0.3\n0.2\n0.1\n0.0\n10\n8\nh(x') 6 4\n2 0 0 2 4 h(x) 6",
          "Column_4": "8 10",
          "Column_5": "",
          "Column_6": "rorrE",
          "Column_7": "1.0\n0.9\n0.8\n0.7\n0.6\n0.4\n0.3\n0.2\n0.1\n0.0\n10\n8\nh(x') 6",
          "Column_8": "4\n2 0 0 2 4 h(x) 6",
          "Column_9": "8 10",
          "Column_10": "",
          "Column_11": "rorrE",
          "Column_12": "1.0\n0.9\n0.8\n0.7\n0.6\n0.4\n0.3\n0.2\n0.1\n0.0\n10\n8\nh(x') 6",
          "4 2 0 0 2 4 h(x) 6 8 10\nhenf(x,x(cid:48))=1,g(z)=8,g(z(cid:48))=4,\nnformationin(5).": "4 2 0 0 2 4 h(x) 6 8 10"
        },
        {
          "1.0\n0.9\n0.8\n0.7\nrorrE\n0.6\n0.4\n0.3\n0.2\n0.1\n0.0\n10\n8\nh(x') 6 4\n2 0 0 2 4 h(x) 6\nFig.1. Errorsurfacesnormalizedto[0,1]\nλ=0.5andτ =1.Thediagramonther": "",
          "Column_2": "",
          "Column_3": "",
          "Column_4": "forthelossesin(3)(\nightpresentstheerror",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "left)and(5)(middle)forapa\nduetothetermsthatcorresp",
          "Column_9": "irofpoints(x,x(cid:48))w\nondtotheprivilegedi",
          "Column_10": "",
          "Column_11": "",
          "Column_12": "",
          "4 2 0 0 2 4 h(x) 6 8 10\nhenf(x,x(cid:48))=1,g(z)=8,g(z(cid:48))=4,\nnformationin(5).": ""
        }
      ],
      "page": 3
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "AffRankNet+(λ=0.3)",
          "Datasetsize\n5%": "0.262",
          "DatasetSize\n10%": "0.302",
          "Datasetsize\n20%": "0.293"
        },
        {
          "Column_1": "AffRankNet+(λ=0.5)",
          "Datasetsize\n5%": "0.258",
          "DatasetSize\n10%": "0.312",
          "Datasetsize\n20%": "0.289"
        },
        {
          "Column_1": "AffRankNet+(λ=0.8)",
          "Datasetsize\n5%": "0.263",
          "DatasetSize\n10%": "0.322",
          "Datasetsize\n20%": "0.284"
        }
      ],
      "page": 6
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "AffRankNet+(λ=0.3)",
          "Datasetsize\n5%": "0.172",
          "DatasetSize\n10%": "0.198",
          "Datasetsize\n20%": "0.210"
        },
        {
          "Column_1": "AffRankNet+(λ=0.5)",
          "Datasetsize\n5%": "0.168",
          "DatasetSize\n10%": "0.204",
          "Datasetsize\n20%": "0.206"
        },
        {
          "Column_1": "AffRankNet+(λ=0.8)",
          "Datasetsize\n5%": "0.179",
          "DatasetSize\n10%": "0.216",
          "Datasetsize\n20%": "0.191"
        }
      ],
      "page": 6
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Pearson's correlation coefficient (r)\n0.4\nAffRankNet+\nRankNet\n0.3 ecnamrofreP\n0.2\n0.1\n0.0\n5% 10% 20%\nDataset Size": "Kendall's tau coefficient ()\n0.30\nAffRankNet+\n0.25\nRankNet\necnamrofreP\n0.20\n0.15\n0.10\n0.05\n0.00\n5% 10% 20%\nDataset Size\nFig.4. ThearchitectureofAffRankNet+model."
        }
      ],
      "page": 7
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "AffR\nRan": "",
          "Column_2": "",
          "ankNet+\nkNet": "ankNet+\nkNet",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "",
          "Column_10": ""
        }
      ],
      "page": 7
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Column_1": "AffR",
          "Column_2": "",
          "ankNet+": "ankNet+",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "",
          "Column_10": ""
        },
        {
          "Column_1": "Ran",
          "Column_2": "",
          "ankNet+": "kNet",
          "Column_4": "",
          "Column_5": "",
          "Column_6": "",
          "Column_7": "",
          "Column_8": "",
          "Column_9": "",
          "Column_10": ""
        }
      ],
      "page": 7
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "A technique for the measurement of attitudes",
      "authors": [
        "Rensis Likert"
      ],
      "year": "1932",
      "venue": "Archives of psychology"
    },
    {
      "citation_id": "2",
      "title": "Observations: Sam: the self-assessment manikin; an efficient cross-cultural measurement of emotional response",
      "authors": [
        "Jon D Morris"
      ],
      "year": "1995",
      "venue": "Journal of advertising research"
    },
    {
      "citation_id": "3",
      "title": "What are emotions? and how can they be measured?",
      "authors": [
        "Klaus Scherer"
      ],
      "year": "2005",
      "venue": "Social science information"
    },
    {
      "citation_id": "4",
      "title": "Ratings and rankings: Reconsidering the structure of values and their measurement",
      "authors": [
        "Seth Ovadia"
      ],
      "year": "2004",
      "venue": "International Journal of Social Research Methodology"
    },
    {
      "citation_id": "5",
      "title": "Annotation and processing of continuous emotional attributes: Challenges and opportunities",
      "authors": [
        "Angeliki Metallinou",
        "Shrikanth Narayanan"
      ],
      "year": "2013",
      "venue": "2013 10th IEEE international conference and workshops on automatic face and gesture recognition (FG)"
    },
    {
      "citation_id": "6",
      "title": "Don't classify ratings of affect; rank them!",
      "authors": [
        "Georgios Hector P Martinez",
        "John Yannakakis",
        "Hallam"
      ],
      "year": "2014",
      "venue": "IEEE transactions on affective computing"
    },
    {
      "citation_id": "7",
      "title": "Optimizing search engines using clickthrough data",
      "authors": [
        "Thorsten Joachims"
      ],
      "year": "2002",
      "venue": "Proc. of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining"
    },
    {
      "citation_id": "8",
      "title": "An efficient boosting algorithm for combining preferences",
      "authors": [
        "Yoav Freund",
        "Raj Iyer",
        "Robert Schapire",
        "Yoram Singer"
      ],
      "year": "2003",
      "venue": "Journal of machine learning research"
    },
    {
      "citation_id": "9",
      "title": "From ranknet to lambdarank to lambdamart: An overview",
      "authors": [
        "Chris Burges"
      ],
      "year": "2010",
      "venue": "Learning"
    },
    {
      "citation_id": "10",
      "title": "A new learning paradigm: Learning using privileged information",
      "authors": [
        "Vladimir Vapnik",
        "Akshay Vashist"
      ],
      "year": "2009",
      "venue": "Neural networks"
    },
    {
      "citation_id": "11",
      "title": "Learning to rank using gradient descent",
      "authors": [
        "Chris Burges",
        "Tal Shaked",
        "Erin Renshaw",
        "Ari Lazier",
        "Matt Deeds",
        "Nicole Hamilton",
        "Greg Hullender"
      ],
      "year": "2005",
      "venue": "Proceedings of the 22nd international conference on Machine learning"
    },
    {
      "citation_id": "12",
      "title": "Afew-va database for valence and arousal estimation in-thewild",
      "authors": [
        "Jean Kossaifi",
        "Georgios Tzimiropoulos",
        "Sinisa Todorovic",
        "Maja Pantic"
      ],
      "year": "2017",
      "venue": "Image and Vision Computing"
    },
    {
      "citation_id": "13",
      "title": "Large-scale kernel ranksvm",
      "authors": [
        "Tzu-Ming Kuo",
        "Ching-Pei Lee",
        "Chih-Jen Lin"
      ],
      "year": "2014",
      "venue": "Proceedings of the 2014 SIAM international conference on data mining"
    },
    {
      "citation_id": "14",
      "title": "Large-scale linear ranksvm",
      "authors": [
        "Ching-Pei Lee",
        "Chih-Jen Lin"
      ],
      "year": "2014",
      "venue": "Neural computation"
    },
    {
      "citation_id": "15",
      "title": "Margin-based ranking and an equivalence between adaboost and rankboost",
      "authors": [
        "Cynthia Rudin",
        "Robert Schapire"
      ],
      "year": "2009",
      "venue": "Journal of Machine Learning Research"
    },
    {
      "citation_id": "16",
      "title": "Rank-boost++: an improvement to rankboost",
      "authors": [
        "Harold Connamacher",
        "Nikil Pancha",
        "Rui Liu",
        "Soumya Ray"
      ],
      "year": "2020",
      "venue": "Machine Learning"
    },
    {
      "citation_id": "17",
      "title": "Deeprank: A new deep architecture for relevance ranking in information retrieval",
      "authors": [
        "Liang Pang",
        "Yanyan Lan",
        "Jiafeng Guo",
        "Jun Xu",
        "Jingfang Xu",
        "Xueqi Cheng"
      ],
      "year": "2017",
      "venue": "Proceedings of the 2017 ACM on Conference on Information and Knowledge Management"
    },
    {
      "citation_id": "18",
      "title": "Deep neural network regularization for feature selection in learning-to-rank",
      "authors": [
        "Ashwini Rahangdale",
        "Shital Raut"
      ],
      "year": "2019",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "19",
      "title": "Adapting deep ranknet for personalized search",
      "authors": [
        "Yang Song",
        "Hongning Wang",
        "Xiaodong He"
      ],
      "year": "2014",
      "venue": "Proceedings of the 7th ACM international conference on Web search and data mining"
    },
    {
      "citation_id": "20",
      "title": "Ranking emotional attributes with deep neural networks",
      "authors": [
        "Srinivas Parthasarathy",
        "Reza Lotfian",
        "Carlos Busso"
      ],
      "year": "2017",
      "venue": "2017 IEEE international conference on acoustics, speech and signal processing (ICASSP)"
    },
    {
      "citation_id": "21",
      "title": "Tensor-based nonlinear classifier for high-order data analysis",
      "authors": [
        "Konstantinos Makantasis",
        "Anastasios Doulamis",
        "Nikolaos Doulamis"
      ],
      "year": "2018",
      "venue": "2018 IEEE International Conference on Acoustics, Speech and Signal Processing"
    },
    {
      "citation_id": "22",
      "title": "Common mode patterns for supervised tensor subspace learning",
      "authors": [
        "Konstantinos Makantasis",
        "Anastasios Doulamis",
        "Nikolaos Doulamis",
        "Athanasios Voulodimos"
      ],
      "year": "2019",
      "venue": "ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing"
    },
    {
      "citation_id": "23",
      "title": "Rank-r fnn: A tensor-based learning model for high-order data classification",
      "authors": [
        "Konstantinos Makantasis",
        "Alexandros Georgogiannis"
      ],
      "year": "2021",
      "venue": "Athanasios Voulodimos, Ioannis Georgoulas, Anastasios Doulamis, and Nikolaos Doulamis"
    },
    {
      "citation_id": "24",
      "title": "Learning using privileged information: similarity control and knowledge transfer",
      "authors": [
        "Vladimir Vapnik",
        "Rauf Izmailov"
      ],
      "year": "2015",
      "venue": "J. Mach. Learn. Res"
    },
    {
      "citation_id": "25",
      "title": "Distilling the knowledge in a neural network",
      "authors": [
        "Geoffrey Hinton",
        "Oriol Vinyals",
        "Jeff Dean"
      ],
      "year": "2015",
      "venue": "Distilling the knowledge in a neural network",
      "arxiv": "arXiv:1503.02531"
    },
    {
      "citation_id": "26",
      "title": "Unifying distillation and privileged information",
      "authors": [
        "David Lopez-Paz",
        "Léon Bottou",
        "Bernhard Schölkopf",
        "Vladimir Vapnik"
      ],
      "year": "2016",
      "venue": "International Conference on Learning Representations (ICLR)"
    },
    {
      "citation_id": "27",
      "title": "On the theory of learnining with privileged information",
      "authors": [
        "Dmitry Pechyony",
        "Vladimir Vapnik"
      ],
      "year": "2010",
      "venue": "Advances in neural information processing systems"
    },
    {
      "citation_id": "28",
      "title": "The ordinal nature of emotions: An emerging approach",
      "authors": [
        "Roddy Georgios N Yannakakis",
        "Carlos Cowie",
        "Busso"
      ],
      "year": "2018",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "29",
      "title": "Ranking-based emotion recognition for music organization and retrieval",
      "authors": [
        "Yi-Hsuan Yang",
        "Homer Chen"
      ],
      "year": "2010",
      "venue": "IEEE Transactions on audio, speech, and language processing"
    },
    {
      "citation_id": "30",
      "title": "Listwise approach to learning to rank: theory and algorithm",
      "authors": [
        "Fen Xia",
        "Tie-Yan Liu",
        "Jue Wang",
        "Wensheng Zhang",
        "Hang Li"
      ],
      "year": "2008",
      "venue": "Proceedings of the 25th international conference on Machine learning"
    },
    {
      "citation_id": "31",
      "title": "Ranking-based emotion recognition for experimental music",
      "authors": [
        "Jianyu Fan",
        "Miles Kivanc ¸tatar",
        "Philippe Thorogood",
        "Pasquier"
      ],
      "year": "2017",
      "venue": "ISMIR"
    },
    {
      "citation_id": "32",
      "title": "Relevant emotion ranking from text constrained with emotion relationships",
      "authors": [
        "Deyu Zhou",
        "Yang Yang",
        "Yulan He"
      ],
      "year": "2018",
      "venue": "Proceedings of the 2018 Conference of the North American Chapter"
    },
    {
      "citation_id": "33",
      "title": "Multimodal local-global ranking fusion for emotion recognition",
      "authors": [
        "Paul Pu Liang",
        "Amir Zadeh",
        "Louis-Philippe Morency"
      ],
      "year": "2018",
      "venue": "Proceedings of the 20th ACM International Conference on Multimodal Interaction"
    },
    {
      "citation_id": "34",
      "title": "Affective ranking of movie scenes using physiological signals and content analysis",
      "authors": [
        "Mohammad Soleymani",
        "Guillaume Chanel",
        "J Joep",
        "Thierry Kierkels",
        "Pun"
      ],
      "year": "2008",
      "venue": "Proceedings of the 2nd ACM Workshop on Multimedia Semantics"
    },
    {
      "citation_id": "35",
      "title": "The pixels and sounds of emotion: General-purpose representations of arousal in games",
      "authors": [
        "Konstantinos Makantasis",
        "Antonios Liapis",
        "Georgios Yannakakis"
      ],
      "year": "2021",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "36",
      "title": "Pyplt: Python preference learning toolbox",
      "authors": [
        "Elizabeth Camilleri",
        "N Georgios",
        "David Yannakakis",
        "Antonios Melhart",
        "Liapis"
      ],
      "year": "2019",
      "venue": "2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII)"
    },
    {
      "citation_id": "37",
      "title": "Space-time domain tensor neural networks: An application on human pose recognition",
      "authors": [
        "Konstantinos Makantasis",
        "Athanasios Voulodimos"
      ],
      "year": "2020",
      "venue": "Space-time domain tensor neural networks: An application on human pose recognition",
      "arxiv": "arXiv:2004.08153"
    },
    {
      "citation_id": "38",
      "title": "An overview of statistical learning theory",
      "authors": [
        "N Vladimir",
        "Vapnik"
      ],
      "year": "1999",
      "venue": "IEEE transactions on neural networks"
    },
    {
      "citation_id": "39",
      "title": "Deep face recognition",
      "authors": [
        "Andrea Omkar M Parkhi",
        "Andrew Vedaldi",
        "Zisserman"
      ],
      "year": "2015",
      "venue": "Deep face recognition"
    },
    {
      "citation_id": "40",
      "title": "Giorgos Giannakakis, and Georgios Yannakakis Antonios Liapis",
      "authors": [
        "David Melhart",
        "Konstantinos Sfikas"
      ],
      "year": "2020",
      "venue": "Workshop on Artificial Intelligence in Affective Computing"
    }
  ]
}