{
  "paper_id": "2112.06346v1",
  "title": "Valuenet: A New Dataset For Human Value Driven Dialogue System",
  "published": "2021-12-12T23:02:52Z",
  "authors": [
    "Liang Qiu",
    "Yizhou Zhao",
    "Jinchao Li",
    "Pan Lu",
    "Baolin Peng",
    "Jianfeng Gao",
    "Song-Chun Zhu"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Building a socially intelligent agent involves many challenges, one of which is to teach the agent to speak guided by its value like a human. However, value-driven chatbots are still understudied in the area of dialogue systems. Most existing datasets focus on commonsense reasoning or social norm modeling. In this work, we present a new large-scale human value dataset called VALUENET, which contains human attitudes on 21,374 text scenarios. The dataset is organized in ten dimensions that conform to the basic human value theory in intercultural research. We further develop a Transformerbased value regression model on VALUENET to learn the utility distribution. Comprehensive empirical results show that the learned value model could benefit a wide range of dialogue tasks. For example, by teaching a generative agent with reinforcement learning and the rewards from the value model, our method attains state-of-the-art performance on the personalized dialog generation dataset: PERSONA-CHAT. With values as additional features, existing emotion recognition models enable capturing rich human emotions in the context, which further improves the empathetic response generation performance in the EMPATHETICDIALOGUES dataset. To the best of our knowledge, VALUENET is the first largescale text dataset for human value modeling, and we are the first one trying to incorporate a value model into emotionally intelligent dialogue systems. The dataset is available at https://liang-qiu.github.io/ValueNet/.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Introduction",
      "text": "Value refers to desirable goals in human life. They guide the selection or evaluation of actions, policies, people, and events. A person's value priority or hierarchy profoundly affects his or her attitudes, beliefs, and traits, making it one core component of personality  (Schwartz 2012) . In dialogue systems, modeling human values is a critical step towards building socially intelligent chatbots  (Qiu et al. 2021b) . By considering values, we can estimate user behavior and cognitive patterns from their utterances and generate responses that conform to the robot's persona configuration. For example, the robot is set to be aware of human values, and it invites Jerry to drink beers, but Jerry replies, \"You know that is tempting but is not good for our fitness\". The bot could Scenario: expecting my girlfriend to do most of the housework and not seeing her as \"equal\".\n\nScenario: applying to a far-away university against my dad's wishes.\n\nScenario: letting people know when someone needs medical help.\n\nScenario: having a phone call in the bus. read from the dialogue that Jerry prefers a healthy and selfdisciplined lifestyle and steer its recommendation to healthier options in the future.\n\nThe development of socially intelligent chatbots has been one of the longest-running goals in artificial intelligence. Early dialogue systems such as Eliza  (Weizenbaum 1966) , Parry  (Colby, Weber, and Hilf 1971) , and more recent Sim-Simi 1 , Panda Ichiro  (Okuda and Shoda 2018) , Replika (Fedorenko, Smetanin, and Rodichev 2018), XiaoIce  (Zhou et al. 2020) , were designed to mimic human behavior and incorporate emotional quotients (EQ) to some extent. There are also datasets and benchmarks for studying related problems, such as emotion recognition  (McKeown et al. 2010; Hsu et al. 2018; Poria et al. 2019; Ghosal et al. 2020) , personalized dialogue generation  (Zhang et al. 2018; Liu et al. 2020) , and empathetic dialogue generation  (Rashkin et al. 2019) . Even though value plays a fundamental and critical role in human EQ, there is a lack of explicit modeling of values in the dialogue domain, based on social domain theory. We have seen recent efforts about crowdsourcing social commonsense knowledge base or benchmarks  (Forbes et al. 2020; Sap et al. 2019; Lourie, Bras, and Choi 2021; Hendrycks et al. 2020; Hwang et al. 2021; Gabriel et al. 2021) . However, it is not clearly shown how an agent can leverage this knowledge to estimate the users' value priorities or guide its own speaking and actions. In this paper, we aim to alleviate this problem and investigate the usage of a learned value function.\n\nWe start the study by curating a knowledge base of human values called VALUENET. Samples with value-related scenarios were identified based on value-defined keyword searching. Next, we asked Amazon Mechanical Turk workers about how the provided scenarios will affect one's value. This is based on the assumption that values underlie our attitudes; they are the guideline by which we evaluate things. Workers assess behaviors/events positively if they promote or protect the attainment of the goals we value. Behaviors/events are evaluated negatively if they hinder or threaten the attainment of these valued goals. The whole process gives us a large-scale (over 21k samples) multi-dimensional knowledge base of value. Figure  1  shows the overall structure of VALUENET. Each split represents a value dimension identified in the theory of basic human values  (Schwartz 2012) . The figure also illustrates the value-related keywords and scenarios. The circular arrangement of the values represents a motivational continuum. By organizing data in such a structure, we anticipate the VALUENET to provide comprehensive coverage of different aspects of human values.\n\nNext, we develop a Transformer-based value model to evaluate the utility score suggesting the positive or negative judgment given an utterance. We provide a detailed analysis of learning with multiple Transformer variants. Then we conduct a wide range of experiments to demonstrate that the value model could benefit EQ-related dialogue tasks: (i) By finetuning a generative agent with reinforcement learning and the reward from our value model, the method achieves state-of-the-art performance on the personalized dialogue dataset: PERSONA-CHAT  (Zhang et al. 2018 ); (ii) By incorporating values as additional features, in EMPATHETICDI-ALOGUES  (Rashkin et al. 2019) , we improve the emotion classification accuracy of existing models, which further facilitates the empathetic response generation; (iii) Visualization of the value model shows that it provides a numerical way of user profile modeling from their utterances.\n\nIn all, our contributions are two-fold. First, we present a large-scale dataset VALUENET for the modeling of human values that are well-defined in intercultural research. Second, we initiate to develop the value model learned from VALUENET to several EQ-related tasks and demonstrate its usage for building a value-driven dialogue system. Our methodology can be generalized to a wide range of interactive situations in socially aware dialogue systems (Zhao, Romero, and Rudnicky 2018), and human-robot interactions  (Yuan and Li 2017; Liang, He, and Anthony'Chen 2021) .",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Related Work",
      "text": "An abundance of related work inspires our work. Our work aims to make contributions to dialogue systems by incorporating the theory of human value. The dataset we collect shares a similar nature with multiple social commonsense benchmarks and knowledge bases. Besides, we apply our VALUENET for various dialogue tasks related to EQ.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Theory Of Human Value And Utility",
      "text": "In the field of intercultural research,  Schwartz (2012)  developed the theory of basic human values. The theory identifies ten basic personal values that are recognized across cultures and explains where they come from, as shown in Figure  1 . The closer any two values in either direction around the circle, the more similar their underlying motivations are; the more distant, the more antagonistic their motivations. Note that dividing the value item domain into ten distinct values is an arbitrary convenience. It is reasonable to partition the value items into more or less fine-tuned distinct values according to the needs and objectives of one's analysis 2  . Similarly, in the economics field, the concept of utility  (Fishburn 1970 ) is initially defined as a measure of pleasure or satisfaction in economics and ethics that drives human activities at all levels. Therefore, when we teach agents to speak and act in a socially intelligent way, an approach considering human value utilities should be adopted. In this paper, we aim to learn a utility function for each dimension of value and steer the dialogue system response generation accordingly.  Hendrycks et al. (2020)  present the ETHICS dataset, a benchmark that assesses a language model's knowledge of basic concepts of morality. SCRUPLES  (Lourie, Bras, and Choi 2021 ) is a large-scale dataset with ethical judgments over real-life anecdotes, motivated by descriptive ethics. SOCIAL-CHEM-101 presented by  Forbes et al. (2020)  is a corpus that catalogs rules-of-thumb as basic concept units for studying people's everyday social norms and moral judgments. They also propose Neural Norm Transformer to reason about previously unseen situations, generating relevant social rules-of-thumb. SOCIAL IQA  (Sap et al. 2019 ) is a large-scale benchmark for commonsense reasoning about social situations.  He et al. (2017)  present a task and corpus for predicting the preferable options from two sentences describing the scenarios that may involve social and cultural situations. Instead, in this work, we release a new dataset VALUENET that provides annotation of human attitudes from different value aspects.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Social Commonsense Benchmarks",
      "text": "",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Emotionally Intelligent Dialogue Datasets",
      "text": "Several datasets are presented to study emotion dynamics in dialogues. DailyDialog  (Li et al. 2017 ) is a multi-turn dialogue dataset, which reflects the way of daily communication and provides emotion labels for speakers.  Hsu et al. (2018)  present EmotionLines with emotions labeling on all utterances in each dialogue based on their textual content. MELD  (Poria et al. 2019 ) is an extension of EmotionLines for multi-modal multi-party emotion recognition.  McKeown et al. (2010)  record a corpus SEMAINE of emotion-ally coloured conversations.  Ghosal et al. (2020)  propose a framework COSMIC for emotion recognition in conversations by considering mental states, events, actions, and cause-effect relations. DialogRE  (Yu et al. 2020)  is the first human-annotated dialogue-based dataset for social relation inference  (Qiu et al. 2021a) . PERSONA-CHAT  (Zhang et al. 2018 ) (revised in ConvAI2  (Dinan et al. 2020 )) provides natural language profiles of speakers. Based on PERSONA-CHAT,  Liu et al. (2020)  propose a transmitter-receiverbased framework with explicitly human understanding modeling to enhance the quality of personalized dialogue generation. EMPATHETICDIALOGUES  (Rashkin et al. 2019 ) is a dataset that provides 25k conversations grounded in emotional situations. Each dialogue is grounded in a specific situation where a speaker was feeling a given emotion.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "The Valuenet Dataset",
      "text": "During decision-making, people tend to pick the choice that aligns more with their own values. This work aims to provide a transferable knowledge base for human value modeling in natural language. To collect the VALUENET dataset, we curated social scenarios with value-related keywords and further annotated them via Amazon Mechanical Turk. Each sample in VALUENET is a social scenario description labeled with the annotator's attitude through a specific value lens.\n\nThe entire dataset is organized in a circular structure as shown in Figure  1 , aligning with the theory of basic human values  (Schwartz 2012) . The theory identifies ten universal values that are recognized throughout major cultures. The circular structure reflects the dynamic relations among these values, i.e., the pursuit of some value may result in either accordance with another value or a conflict with another value. The ten distinct values can be further organized into four higher-order groups.\n\n• Openness to change: self-direction, stimulation • Self-enhancement: hedonism, achievement, power • Conservation: security, conformity, tradition • Self-transcendence: benevolence, universalism We describe the collection details of the VALUENET in the following sections.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Social Scenario Curation",
      "text": "We curated a set of 21,374 social scenarios from the largescale social-related database SOCIAL-CHEM-101  (Forbes et al. 2020) . Value-related scenarios are retrieved with value keywords after lemmatization and stemming. There are three sets of keywords identified for each dimension of Schwartz value: (1) the keywords in the original definition of each value in Schwartz's paper  (Schwartz 2012 ); (2) words that share a similar meaning, words that are often used to describe the original keywords, and words that are triggered by (strongly associated with) the original keywords 3 ; (3) words that are near the original keywords in the GloVe (Pennington, Socher, and Manning 2014) embedding space. The  value keywords are verified and confirmed by humans as listed in Figure  2 .",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Value-Aspect Attitude Annotation",
      "text": "We crowdsourced people's attitudes to the curated scenarios on Amazon Mechanical Turk (AMT). Figure  3  shows an example.\n\nWe follow a strict procedure to select qualified workers and ensure the workers understand the concept of each value we ask. In Figure  3 , the definition of BENEVOLENCE is shown to the workers throughout the entire annotation process. To further help the understanding, we include three examples in each assignment with correct answers being \"yes\", \"no\", and \"unrelated\", respectively. The worker is then required to answer a prerequisite question correctly to proceed to the formal survey. The formal survey is composed of ten questions, including two hidden qualification checking questions. Before publishing on the AMT, two Ph.D. students A total of 681 experienced AMT workers participated in our VALUENET annotation. 443 of them passed the qualification test. Each scenario is assigned to four different workers. The original inter-annotator agreement is 64.9%, and the Fleiss' kappa score  (Fleiss 1971 ) among the workers is 0.48, which considers the possibility of the agreement by chance. Keeping the scope of VALUENET in commonly-agreed attitudes towards social scenarios, we only retain the samples with three or more agreements. Figure  4  shows the sample size of each value split and their label distribution. The data is split into the train (75%), valid (15%), and test (10%). Similar to the polarity in sentiment analysis  (Kouloumpis, Wilson, and Moore 2011) , we quantify the annotated labels into numerical values: yes (positive): +1, no (negative): -1, unrelated (neutral): 0. We denote the numerical values as utility to describe the effect of a scenario on one's value. In other words, for people who appreciate a certain value, actions with a higher utility in this value di- mension would be more desirable to them.\n\nTable  1  shows more statistical details about the VAL-UENET dataset. In total, we collected 21,374 samples covering a wide range of scenarios in daily social life.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Value Modeling",
      "text": "We experiment using Transformer-based pre-trained language models for modeling human values from the VAL-UENET dataset.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Task Formalization",
      "text": "Given a social scenario s, we wish to learn a value function that models the utility distribution of s from the ten Schwartz value dimensions:",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Model",
      "text": "Pre-trained language model variants: BERT  (Devlin et al. 2018) , RoBERTa  (Liu et al. 2019) , DistilBERT  (Sanh et al. 2019) , BART  (Lewis et al. 2019 ) are investigated for learning the value function. A custom input format constructed as '[CLS][$VALUE]s' is fed into a Transformer encoder, i.e.,\n\nwhere TRM denotes the Transformer encoder, [CLS] is the special token for regression or classification, and [$VALUE] are special tokens we define to prompt the language models the value dimension we are interested in  (Li and Liang 2021; Brown et al. 2020; Le Scao and Rush 2021) .\n\nIn order to get the ten-dimensional output V(s), a batch size of 10 is forwarded through the model. For the BERT, Dis-tilBERT, and RoBERTa, a regression head is put on top of the models and they are trained with the Mean Squared Error (MSE) loss. We use the regression model with sigmoid activation to get a continuous estimation of the utility in the range of [-1, 1]. To evaluate the effect of different loss functions, we train the BART model with three output classes and the cross-entropy loss.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Result And Analysis",
      "text": "The learning performance of using fastText 4    (Joulin et al. 2017)  and Transformer variants are reported in of 5e-6. The prediction precision, recall, F1 score, and accuracy for regression models are computed by the utility rounded to the nearest integer.\n\nIn general, pre-trained language models perform better than the fastText baseline. However, there is not a noticeable difference between the Transformer variants. The prediction accuracy of BART is the highest among all models because it is explicitly trained for classification purposes. BERT and DistilBERT get the lowest MSE in terms of regression performance.\n\nObserving the sample imbalance across different value splits and labels (Figure  4 ), we release another two versions of VALUENET: VALUENET (balanced) and VALUENET (augmented). The original dataset is balanced by subsampling the negative and neutral data of the largest value split (BENEVOLENCE). Moreover, we augment the neutral class of the original VALUENET by assigning AMT results with less worker agreement to \"unrelated\". Data distribution of the balanced and augmented versions of VALUENET are illustrated in the Appendix. By analyzing the prediction accuracy in different value splits (Table  3 ), we find that reducing the sample number of BENEVOLENCE hurts the model performance in that dimension. Looking at the F1 score of each class in Table  2 , we conclude that augmenting the neutral class improves the F1(0) but reduces F1(1) and F1(-1). We leave it a future work to further improve the value modeling performance.\n\nIn the next sections, we show how the learned value function could benefit EQ-related tasks and help build a valuedriven dialogue system.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Persona-Chat",
      "text": "As values are closely related to one's personality, we first assess our value model on a personalized dialogue dataset: PERSONA-CHAT  (Zhang et al. 2018 ). The PERSONA-CHAT dataset contains multi-turn dialogues conditioned on personas. Each persona is encoded by at least 5 sentences of textual description, termed a profile. Example profile sentences are \"I like to ski\", \"I enjoying walking for exercise\", \"I have four children\", etc. The dataset is composed of 8,939 dialogues for training, 1,000 for validation, and 968 for testing. It also provides revised personas by rephrasing, generalizing or specializing the original ones. The dataset we use for experiments is public available in ParlAI 5  .",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Task Formalization",
      "text": "Given the agent's self persona profile p = [p 1 , p 2 , ..., p N ] and the dialogue history up to the t-th turn h s t = (x u 1 , x s 1 , ..., x u t ), x u i is the i-th utterance by Person 1 played by the user, x s i is the i-th utterance by Person 2 played by the system, we evaluate the model's performance on predicting the next utterance x s t .    (Williams 1992 ) in our experiment, and the reward assignment is described as following. Denote V(p i ) and V(x s i ) to describe the estimation of the agent's value from its profile sentence p i and generated response xs i , respectively. We want the reward to promote the alignment of the agent's profile and utterances in the value space. For instance, if the agent has profile 'I like venture' and 'I have a dog', and it says 'I plan to ski this weekend' and also 'Do you like skiing'. Both utterances should be aligned with the first persona. Here we propose a simple yet effective searching algorithm (Algorithm 1) to find a match between [V(p 1 ), V(p 2 ), ..., V(p N )] and [V(x s 1 ), V(x s 2 ), ..., V(x s T )] and return a reward R. N is the number of profile sentences and T is the length of the generated dialogue. V is normalized to ensure |r t | ≤ 1. Intuitively, the discount argument γ prevents the language model from repeating the same fact in the agent's profile.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Model",
      "text": "",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Setup",
      "text": "We evaluate the same generative model in both generation and ranking settings. In the response ranking setup, the candidates are scored with their log-likelihood. For the GPT-2  (Radford et al. 2019)  and DialoGPT  (Zhang et al. 2019)  we have finetuned, we train them for 5k steps with a training batch size of 8. The learning rate is set to 2e-6. For an illustration of computational requirements, the training with MLE on 4 NVIDIA Tesla V100 takes ∼1 hours, and the reinforcement learning takes ∼30 minutes.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Result And Analysis",
      "text": "Following  Zhang et al. (2018)  and  Liu et al. (2020) , we report the Hits@1, Perplexity and F1 to evaluate the methods in Table  4 . By the submission of this paper, P 2 BOT  (Liu et al. 2020)  is the state-of-the-art model reported in this task. We also include a generative baseline using SEQ2SEQ with attention mechanism  (Bahdanau, Cho, and Bengio 2014)  for comparison. As observed, in terms of all the metrics we evaluated, finetuning GPT2 or DialoGPT2 models with our value function provides a significant performance boost compared to simply training them with MLE. Our DialoGPT + Value model achieves new state-of-the-art performance on perplexity and F1.\n\nend for 10: end for 11: γ i ← 1, i = 1, 2, ..., N 12: for t = 1, 2, ..., T do 13: γ mt ← γ mt + 1 14: end for 15: R ← 0 16: for t = 1, 2, ..., T do 17: R ← R + sign(r t ) • |r t | sign(rt)•γm t 18: end for 19: return R/N EMPATHETICDIALOGUES EMPATHETICDIALOGUES  (Rashkin et al. 2019 ) provides 25k conversations grounded in emotional situations. It aims to test the dialogue system's capability to produce empathetic responses. Each dialogue is grounded in a specific situation where a speaker was feeling a given emotion, with a listener responding. In this section, we demonstrate how we could leverage VALUENET to improve the emotion classification accuracy and further improve the empathetic response generation.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Emotion Classification",
      "text": "An auxiliary task that is highly related to empathetic dialogue generation is emotion classification. In EMPATHETIC-DIALOGUES, each situation is written in association with a given emotion label. A total of 32 emotion labels were annotated to cover a broad range of positive and negative emotions. Model Given the situation context s, a pre-trained BERT model encodes s and gets the sentence representation from its pooling layer of the [CLS] token. The same context is parsed by our pre-trained value model to get a tendimensional vector, which serves as an additional feature for the classification:\n\nwhere W and b are learnable parameters.\n\nResult We compare the performance between our implementation and the baseline that directly applies the BERT model for emotion classification. As shown in Table  5 , the additional value information benefits emotion classification from both the DistilBERT and BERT models. Our method obtains a relative improvement of 5.2% on DistilBERT and 6.4% on BERT.    (Rashkin et al. 2019) .",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Empathetic Dialogue Generation",
      "text": "We further check whether our value model helps the empathetic dialogue generation. EMPATHETICDIALOGUES applies PREPEND-K, a strategy to add supervised information to data, when predicting the utterance given the dialogue history and the situation. We apply the strategy of prepending the top-k emotion labels for dialogue generation. The top predicted label from the classifiers of emotion is prepended to the beginning of the token sequence as encoder input, as below:\n\n• Original: \"I finally got promoted!\" • Prepend-1 emotion: \"proud I finally got promoted!\"\n\nResult The results are shown in",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Value Profiling",
      "text": "For a more comprehensive understanding, we visualize the 10-dimensional value of four example scenarios in Figure  5 .\n\nAs shown, the value model provides a numerical speaker profile. For instance, saying \"forcing my daughter to sleep in her own bed\" implies that the speaker values power and conformity; saying \"I miss mom\" implies that the speaker values benevolence; saying \"not wanting people to use my property without permissions\" implies the speaker is selfdirected and values security. The last example \"I forgot how to be happy\" results a small radar graph. It suggests that even the model could predict the overall polarity pretty well, there is still space to improve its capability of distinguishing different values.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Conclusion",
      "text": "We introduce a new dataset for human value modeling, VAL-UENET, which contains 21,374 scenarios in ten distinct human values. We also apply the learned value model from VALUENET to several EQ-related dialogue tasks. Our experiments show our approach and dataset provide a new way to control the dialogue system speaking style and numerically estimate one's value preference. We hope that our results and dataset will stimulate more research in the important direction of building human-value-driven dialogue systems.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Ethical Statement",
      "text": "The original purpose of introducing Schwartz values is to identify individual values that are recognized across cultures, which is based on surveys conducted among 82 countries. This motivates us to seek commonly agreed attitudes on social scenarios. Considering model reasoning capability and scalability, we follow the practice in recent commonsense works and provide one-sentence text descriptions to annotators. However, we acknowledge the limitation of this approach lacking external contexts such as culture and language diversity. While some scenarios might have higher levels of agreement across cultures, others might have dramatic variations. As a starting point, our study focuses on the value modeling of English-speaking cultures represented within North America. Extending this formalism to other countries and non-English speaking cultures remains a compelling area of future research. this in mind, we hope this paper could stimulate research on building scalable value-aligned AI.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Appendices",
      "text": "Here we provide the value descriptions  (Schwartz 2012) .\n\nSelf-Direction Defining goal: independent thought and action-choosing, creating, exploring. Self-direction derives from organismic needs for control and mastery and interactional requirements of autonomy and independence Both power and achievement values focus on social esteem. However, achievement values (e.g., ambitious) emphasize the active demonstration of successful performance in concrete interaction, whereas power values (e.g., authority, wealth) emphasize the attainment or preservation of a dominant position within the more general social system.\n\nSecurity Defining goal: safety, harmony, and stability of society, of relationships, and of self. Security values derive from basic individual and group requirements. Some security values serve primarily individual interests (e.g., clean), others wider group interests (e.g., national security). Even the latter, however, express, to a significant degree, the goal of security for self or those with whom one identifies. (social order, family security, national security, clean, reciprocation of favors) [healthy, moderate, sense of belonging] Conformity Defining goal: restraint of actions, inclinations, and impulses likely to upset or harm others and violate social expectations or norms. Conformity values derive from the requirement that individuals inhibit inclinations that might disrupt and undermine smooth interaction and group functioning. As I define them, conformity values emphasize self-restraint in everyday interaction, usually with close others. (obedient, self-discipline, politeness, honoring parents and elders)  [loyal, responsible]  Tradition Defining goal: respect, commitment, and acceptance of the customs and ideas that one's culture or religion provides. Groups everywhere develop practices, symbols, ideas, and beliefs that represent their shared experience and fate. These become sanctioned as valued group customs and traditions. They symbolize the group's solidarity, express its unique worth, and contribute to its survival  (Durkheim, 1912 (Durkheim, /1954;; Parsons, 1951) . They often take the form of religious rites, beliefs, and norms of behavior. (respect for tradition, humble, devout, accepting my portion in life)  [moderate, spiritual life]  Tradition and conformity values are especially close motivationally; they share the goal of subordinating the self to socially imposed expectations. They differ primarily in the objects to which one subordinates the self. Conformity entails subordination to persons with whom one frequently interacts-parents, teachers, and bosses. Tradition entails subordination to more abstract objects-religious and cultural customs and ideas. As a corollary, conformity values exhort responsiveness to current, possibly changing expectations. Tradition values demand responsiveness to immutable expectations from the past.\n\nBenevolence Defining goal: preserving and enhancing the welfare of those with whom one is in frequent personal contact (the 'in-group'). Benevolence values derive from the basic requirement for smooth group functioning and from the organismic need for affiliation. Most critical are relations within the family and other primary groups. Benevolence values emphasize voluntary concern for others' welfare.\n\n(helpful, honest, forgiving, responsible, loyal, true friendship, mature love) [sense of belonging, meaning in life, a spiritual life].\n\nBenevolence and conformity values both promote cooperative and supportive social relations. However, benevolence values provide an internalized motivational base for such behavior. In contrast, conformity values promote cooperation in order to avoid negative outcomes for self. Both values may motivate the same helpful act, separately or together.\n\nUniversalism Defining goal: understanding, appreciation, tolerance, and protection for the welfare of all people and for nature. This contrasts with the in-group focus of benevolence values. Universalism values derive from survival needs of individuals and groups. But people do not recognize these needs until they encounter others beyond the extended primary group and until they become aware of the scarcity of natural resources. People may then realize that failure to accept others who are different and treat them justly will lead to life-threatening strife. They may also realize that failure to protect the natural environment will lead to the destruction of the resources on which life depends. Universalism combines two subtypes of concern-for the welfare of those in the larger society and world and for nature (broadminded, social justice, equality, world at peace, world of beauty, unity with nature, wisdom, protecting the environment)[inner harmony, a spiritual life]",
      "page_start": 9,
      "page_end": 9
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: The presented VALUENET dataset with curated",
      "page": 1
    },
    {
      "caption": "Figure 1: shows the overall struc-",
      "page": 2
    },
    {
      "caption": "Figure 1: The closer any two values in either direction around the cir-",
      "page": 2
    },
    {
      "caption": "Figure 1: , aligning with the theory of basic human",
      "page": 3
    },
    {
      "caption": "Figure 2: Ten universal human values and related keywords",
      "page": 3
    },
    {
      "caption": "Figure 2: Value-Aspect Attitude Annotation",
      "page": 3
    },
    {
      "caption": "Figure 3: , the deﬁnition of BENEVOLENCE is",
      "page": 3
    },
    {
      "caption": "Figure 3: Value-aspect attitude annotation in AMT.",
      "page": 4
    },
    {
      "caption": "Figure 4: shows the sample",
      "page": 4
    },
    {
      "caption": "Figure 4: The sample number and label distribution of each",
      "page": 4
    },
    {
      "caption": "Figure 4: ), we release another two versions",
      "page": 5
    },
    {
      "caption": "Figure 5: Value visualization of example utterances/scenarios.",
      "page": 7
    },
    {
      "caption": "Figure 5: As shown, the value model provides a numerical speaker",
      "page": 7
    },
    {
      "caption": "Figure 6: Amazon mechanical turk interface (prerequiste).",
      "page": 10
    },
    {
      "caption": "Figure 7: Amazon mechanical turk interface (formal).",
      "page": 10
    },
    {
      "caption": "Figure 8: The sample number and label distribution of each value split in the VALUENET (original).",
      "page": 11
    },
    {
      "caption": "Figure 9: The sample number and label distribution of each value split in the VALUENET (balanced).",
      "page": 11
    },
    {
      "caption": "Figure 10: The sample number and label distribution of each value split in the VALUENET (augmented).",
      "page": 11
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "healthy, family, order, clean, safety, belonging": "stable, public, surveillance, guard, welfare, enforcement,\nensure, safekeeping, guarantee, collateral"
        },
        {
          "healthy, family, order, clean, safety, belonging": "support, protection, job, work"
        },
        {
          "healthy, family, order, clean, safety, belonging": "wealth, authority, recognition"
        },
        {
          "healthy, family, order, clean, safety, belonging": "sovereign, superior, force, dominance, leadership,\nmighty, rule, mandate, prerogative, accomplishment"
        },
        {
          "healthy, family, order, clean, safety, belonging": "influence, property, commitment, investment"
        },
        {
          "healthy, family, order, clean, safety, belonging": "influential, successful, ambitious, capable, intelligent"
        },
        {
          "healthy, family, order, clean, safety, belonging": "talented, great, intellectual, outstanding, brilliant,\ndistinguished, affluent, completion, create, rich"
        },
        {
          "healthy, family, order, clean, safety, belonging": "challenge, positive, performance, potential"
        },
        {
          "healthy, family, order, clean, safety, belonging": "pleasure, enjoy, indulgent"
        },
        {
          "healthy, family, order, clean, safety, belonging": "happiness, amusement, delight, fun, desire, joy, resort, satisfaction, sex, beauty"
        },
        {
          "healthy, family, order, clean, safety, belonging": "relax, exercise"
        },
        {
          "healthy, family, order, clean, safety, belonging": "daring, variation, excitement"
        },
        {
          "healthy, family, order, clean, safety, belonging": "exploit, courage, innovative, adventure, changing,\npassion, enthusiasm, nervous, adventure, intense"
        },
        {
          "healthy, family, order, clean, safety, belonging": "communication, production, possibilities"
        },
        {
          "healthy, family, order, clean, safety, belonging": "freedom, curious, independent, goal, privacy, respect"
        },
        {
          "healthy, family, order, clean, safety, belonging": "individual, autonomy, self-reliance, unrestricted,\nconscience, rights, exploration, interests, discover, dignity"
        },
        {
          "healthy, family, order, clean, safety, belonging": "identity"
        },
        {
          "healthy, family, order, clean, safety, belonging": "broadminded, equality, unity, protection, harmony, justice, wisdom, beauty"
        },
        {
          "healthy, family, order, clean, safety, belonging": "divine, eternal, moral, ideal, solidarity, diversity,\nsocial, democracy, peace, compassion"
        },
        {
          "healthy, family, order, clean, safety, belonging": "services, understanding"
        },
        {
          "healthy, family, order, clean, safety, belonging": "love, spiritual, helpful, friendship, forgiving, responsible, loyal"
        },
        {
          "healthy, family, order, clean, safety, belonging": "mutual, generous, sincere, kindness, sympathy,\ngenuine, faithful, charitable, mercy, humanity"
        },
        {
          "healthy, family, order, clean, safety, belonging": "culture, parents, participation, concerning"
        },
        {
          "healthy, family, order, clean, safety, belonging": "discipline, politeness, obedient"
        },
        {
          "healthy, family, order, clean, safety, belonging": "behavior, respectful, norms, strict, manner, formal,\ngentle, compliant, regulation, principle"
        },
        {
          "healthy, family, order, clean, safety, belonging": "policy, comfortable"
        },
        {
          "healthy, family, order, clean, safety, belonging": "humble, respect, devout, moderate"
        },
        {
          "healthy, family, order, clean, safety, belonging": "conservative, orthodox, pious, classic, ancient,\nintegrity, christian, buddhist, republican, islamic"
        },
        {
          "healthy, family, order, clean, safety, belonging": "responsibility, religion"
        }
      ],
      "page": 3
    },
    {
      "caption": "Table 2: , we conclude that augmenting the neutral A decoder-only Transformer-based model is used to esti-",
      "data": [
        {
          "fastText\nBERT\nDistilBERT\nRoBERTa\nBART": "fastText\nBERT\nDistilBERT\nRoBERTa\nBART"
        },
        {
          "fastText\nBERT\nDistilBERT\nRoBERTa\nBART": "fastText\nBERT\nDistilBERT\nRoBERTa\nBART"
        }
      ],
      "page": 5
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Neural machine translation by jointly learning to align and translate",
      "authors": [
        "D Bahdanau",
        "K Cho",
        "Y Bengio"
      ],
      "year": "2014",
      "venue": "Neural machine translation by jointly learning to align and translate",
      "arxiv": "arXiv:1409.0473"
    },
    {
      "citation_id": "2",
      "title": "Language models are few-shot learners",
      "authors": [
        "T Brown",
        "B Mann",
        "N Ryder",
        "M Subbiah",
        "J Kaplan",
        "P Dhariwal",
        "A Neelakantan",
        "P Shyam",
        "G Sastry",
        "A Askell"
      ],
      "year": "2020",
      "venue": "Language models are few-shot learners",
      "arxiv": "arXiv:2005.14165"
    },
    {
      "citation_id": "3",
      "title": "Artificial paranoia",
      "authors": [
        "K Colby",
        "S Weber",
        "F Hilf"
      ],
      "year": "1971",
      "venue": "Artificial Intelligence"
    },
    {
      "citation_id": "4",
      "title": "Pre-training of deep bidirectional transformers for language understanding",
      "authors": [
        "J Devlin",
        "M.-W Chang",
        "K Lee",
        "K Toutanova"
      ],
      "year": "2018",
      "venue": "Pre-training of deep bidirectional transformers for language understanding",
      "arxiv": "arXiv:1810.04805"
    },
    {
      "citation_id": "5",
      "title": "The second conversational intelligence challenge (convai2)",
      "authors": [
        "E Dinan",
        "V Logacheva",
        "V Malykh",
        "A Miller",
        "K Shuster",
        "J Urbanek",
        "D Kiela",
        "A Szlam",
        "I Serban",
        "R Lowe"
      ],
      "year": "2020",
      "venue": "The NeurIPS'18 Competition"
    },
    {
      "citation_id": "6",
      "title": "Avoiding echo-responses in a retrieval-based conversation system",
      "authors": [
        "D Fedorenko",
        "N Smetanin",
        "A Rodichev"
      ],
      "year": "2018",
      "venue": "Conference on Artificial Intelligence and Natural Language"
    },
    {
      "citation_id": "7",
      "title": "Utility theory for decision making",
      "authors": [
        "P Fishburn"
      ],
      "year": "1970",
      "venue": "Utility theory for decision making"
    },
    {
      "citation_id": "8",
      "title": "Measuring nominal scale agreement among many raters",
      "authors": [
        "J Fleiss"
      ],
      "year": "1971",
      "venue": "Psychological bulletin"
    },
    {
      "citation_id": "9",
      "title": "Learning to Reason about Social and Moral Norms",
      "authors": [
        "M Forbes",
        "J Hwang",
        "V Shwartz",
        "M Sap",
        "Y Choi"
      ],
      "year": "2020",
      "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "10",
      "title": "Paragraph-level commonsense transformers with recurrent memory",
      "authors": [
        "S Gabriel",
        "C Bhagavatula",
        "V Shwartz",
        "R Bras",
        "M Forbes",
        "Y Choi"
      ],
      "year": "2021",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)"
    },
    {
      "citation_id": "11",
      "title": "COSMIC: COmmonSense knowledge for eMotion Identification in Conversations",
      "authors": [
        "D Ghosal",
        "N Majumder",
        "A Gelbukh",
        "R Mihalcea",
        "S Poria"
      ],
      "year": "2020",
      "venue": "Findings of the Association for Computational Linguistics: EMNLP 2020"
    },
    {
      "citation_id": "12",
      "title": "Long text generation via adversarial training with leaked information",
      "authors": [
        "J Guo",
        "S Lu",
        "H Cai",
        "W Zhang",
        "Y Yu",
        "J Wang"
      ],
      "year": "2018",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)"
    },
    {
      "citation_id": "13",
      "title": "Learning Symmetric Collaborative Dialogue Agents with Dynamic Knowledge Graph Embeddings",
      "authors": [
        "H He",
        "A Balakrishnan",
        "M Eric",
        "P Liang"
      ],
      "year": "2017",
      "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "14",
      "title": "",
      "authors": [
        "Canada Vancouver"
      ],
      "venue": ""
    },
    {
      "citation_id": "15",
      "title": "Aligning ai with shared human values",
      "authors": [
        "D Hendrycks",
        "C Burns",
        "S Basart",
        "A Critch",
        "J Li",
        "D Song",
        "J Steinhardt"
      ],
      "year": "2020",
      "venue": "Aligning ai with shared human values",
      "arxiv": "arXiv:2008.02275"
    },
    {
      "citation_id": "16",
      "title": "EmotionLines: An Emotion Corpus of Multi-Party Conversations",
      "authors": [
        "C.-C Hsu",
        "S.-Y Chen",
        "C.-C Kuo",
        "T.-H Huang",
        "L.-W Ku"
      ],
      "year": "2018",
      "venue": "Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)"
    },
    {
      "citation_id": "17",
      "title": "Comet-atomic 2020: On symbolic and neural commonsense knowledge graphs",
      "authors": [
        "J Hwang",
        "C Bhagavatula",
        "R Bras",
        "J Da",
        "K Sakaguchi",
        "A Bosselut",
        "Y Choi"
      ],
      "year": "2021",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)"
    },
    {
      "citation_id": "18",
      "title": "Bag of Tricks for Efficient Text Classification",
      "authors": [
        "A Joulin",
        "E Grave",
        "P Bojanowski",
        "T Mikolov"
      ],
      "year": "2017",
      "venue": "Proceedings of the 15th Conference of the European Chapter"
    },
    {
      "citation_id": "19",
      "title": "Twitter sentiment analysis: The good the bad and the omg!",
      "authors": [
        "E Kouloumpis",
        "T Wilson",
        "J Moore",
        "T Le Scao",
        "A Rush"
      ],
      "year": "2011",
      "venue": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies"
    },
    {
      "citation_id": "20",
      "title": "Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension",
      "authors": [
        "M Lewis",
        "Y Liu",
        "N Goyal",
        "M Ghazvininejad",
        "A Mohamed",
        "O Levy",
        "V Stoyanov",
        "L Zettlemoyer"
      ],
      "year": "2019",
      "venue": "Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension",
      "arxiv": "arXiv:1910.13461"
    },
    {
      "citation_id": "21",
      "title": "Prefix-tuning: Optimizing continuous prompts for generation",
      "authors": [
        "X Li",
        "P Liang"
      ],
      "year": "2021",
      "venue": "Prefix-tuning: Optimizing continuous prompts for generation",
      "arxiv": "arXiv:2101.00190"
    },
    {
      "citation_id": "22",
      "title": "DailyDialog: A Manually Labelled Multi-turn Dialogue Dataset",
      "authors": [
        "Y Li",
        "H Su",
        "X Shen",
        "W Li",
        "Z Cao",
        "S Niu"
      ],
      "year": "2017",
      "venue": "Proceedings of the Eighth International Joint Conference on Natural Language Processing"
    },
    {
      "citation_id": "23",
      "title": "Human-Centered AI for Medical Imaging. Artificial Intelligence for Human Computer Interaction: A Modern Approach",
      "authors": [
        "Y Liang",
        "L He",
        "X Anthony'chen",
        "Q Liu",
        "Y Chen",
        "B Chen",
        "J.-G Lou",
        "Z Chen",
        "B Zhou",
        "D Zhang"
      ],
      "year": "2020",
      "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "24",
      "title": "Roberta: A robustly optimized bert pretraining approach",
      "authors": [
        "Y Liu",
        "M Ott",
        "N Goyal",
        "J Du",
        "M Joshi",
        "D Chen",
        "O Levy",
        "M Lewis",
        "L Zettlemoyer",
        "V Stoyanov"
      ],
      "year": "2019",
      "venue": "Roberta: A robustly optimized bert pretraining approach",
      "arxiv": "arXiv:1907.11692"
    },
    {
      "citation_id": "25",
      "title": "Scruples: A Corpus of Community Ethical Judgments on 32,000 Real-Life Anecdotes",
      "authors": [
        "N Lourie",
        "R Bras",
        "Y Choi"
      ],
      "year": "2021",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)"
    },
    {
      "citation_id": "26",
      "title": "The SEMAINE corpus of emotionally coloured character interactions",
      "authors": [
        "G Mckeown",
        "M Valstar",
        "R Cowie",
        "M Pantic"
      ],
      "year": "2010",
      "venue": "2010 IEEE International Conference on Multimedia and Expo"
    },
    {
      "citation_id": "27",
      "title": "AI-based chatbot service for financial industry",
      "authors": [
        "T Okuda",
        "S Shoda"
      ],
      "year": "2018",
      "venue": "Fujitsu Scientific and Technical Journal"
    },
    {
      "citation_id": "28",
      "title": "GloVe: Global Vectors for Word Representation",
      "authors": [
        "J Pennington",
        "R Socher",
        "C Manning"
      ],
      "year": "2014",
      "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)"
    },
    {
      "citation_id": "29",
      "title": "MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversations",
      "authors": [
        "S Poria",
        "D Hazarika",
        "N Majumder",
        "G Naik",
        "E Cambria",
        "R Mihalcea"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "30",
      "title": "SocAoG: Incremental Graph Parsing for Social Relation Inference in Dialogues",
      "authors": [
        "L Qiu",
        "Y Liang",
        "Y Zhao",
        "P Lu",
        "B Peng",
        "Z Yu",
        "Y Wu",
        "S.-C Zhu"
      ],
      "year": "2021",
      "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing"
    },
    {
      "citation_id": "31",
      "title": "Towards Socially Intelligent Agents with Mental State Transition and Human Utility",
      "authors": [
        "L Qiu",
        "Y Zhao",
        "Y Liang",
        "P Lu",
        "W Shi",
        "Z Yu",
        "S.-C Zhu"
      ],
      "year": "2021",
      "venue": "Towards Socially Intelligent Agents with Mental State Transition and Human Utility",
      "arxiv": "arXiv:2103.07011"
    },
    {
      "citation_id": "32",
      "title": "Language models are unsupervised multitask learners",
      "authors": [
        "A Radford",
        "J Wu",
        "R Child",
        "D Luan",
        "D Amodei",
        "I Sutskever"
      ],
      "year": "2019",
      "venue": "OpenAI blog"
    },
    {
      "citation_id": "33",
      "title": "Towards Empathetic Open-domain Conversation Models: A New Benchmark and Dataset",
      "authors": [
        "H Rashkin",
        "E Smith",
        "M Li",
        "Y.-L Boureau"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "34",
      "title": "Dis-tilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter",
      "authors": [
        "V Sanh",
        "L Debut",
        "J Chaumond",
        "T Wolf"
      ],
      "year": "2019",
      "venue": "Dis-tilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter",
      "arxiv": "arXiv:1910.01108"
    },
    {
      "citation_id": "35",
      "title": "Social IQa: Commonsense Reasoning about Social Interactions",
      "authors": [
        "M Sap",
        "H Rashkin",
        "D Chen",
        "R Le Bras",
        "Y Choi"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)"
    },
    {
      "citation_id": "36",
      "title": "An overview of the Schwartz theory of basic values",
      "authors": [
        "S Schwartz"
      ],
      "year": "2012",
      "venue": "Online readings in Psychology and Culture"
    },
    {
      "citation_id": "37",
      "title": "Refining the theory of basic individual values",
      "authors": [
        "S Schwartz",
        "J Cieciuch",
        "M Vecchione",
        "E Davidov",
        "R Fischer",
        "C Beierlein",
        "A Ramos",
        "M Verkasalo",
        "J.-E Lönnqvist",
        "K Demirutku"
      ],
      "year": "2012",
      "venue": "Journal of personality and social psychology"
    },
    {
      "citation_id": "38",
      "title": "ELIZA-a computer program for the study of natural language communication between man and machine",
      "authors": [
        "J Weizenbaum"
      ],
      "year": "1966",
      "venue": "Communications of the ACM"
    },
    {
      "citation_id": "39",
      "title": "Simple statistical gradient-following algorithms for connectionist reinforcement learning",
      "authors": [
        "R Williams"
      ],
      "year": "1992",
      "venue": "Machine learning"
    },
    {
      "citation_id": "40",
      "title": "Dialogue-Based Relation Extraction",
      "authors": [
        "D Yu",
        "K Sun",
        "C Cardie",
        "D Yu"
      ],
      "year": "2020",
      "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "41",
      "title": "Development of a humanfriendly robot for socially aware human-robot interaction",
      "authors": [
        "W Yuan",
        "Z Li"
      ],
      "year": "2017",
      "venue": "2017 2nd International Conference on Advanced Robotics and Mechatronics (ICARM)"
    },
    {
      "citation_id": "42",
      "title": "Dialogpt: Large-scale generative pre-training for conversational response generation",
      "authors": [
        "S Zhang",
        "E Dinan",
        "J Urbanek",
        "A Szlam",
        "D Kiela",
        "J Weston",
        "Y Zhang",
        "S Sun",
        "M Galley",
        "Y.-C Chen",
        "C Brockett",
        "X Gao",
        "J Gao",
        "J Liu",
        "B Dolan",
        "R Zhao",
        "O Romero",
        "A Rudnicky"
      ],
      "year": "2018",
      "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics",
      "arxiv": "arXiv:1911.00536"
    },
    {
      "citation_id": "43",
      "title": "The Design and Implementation of XiaoIce, an Empathetic Social Chatbot",
      "authors": [
        "L Zhou",
        "J Gao",
        "D Li",
        "H.-Y Shum"
      ],
      "year": "2020",
      "venue": "Computational Linguistics"
    }
  ]
}