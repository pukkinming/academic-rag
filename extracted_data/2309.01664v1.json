{
  "paper_id": "2309.01664v1",
  "title": "Fine-Grained Affective Processing Capabilities Emerging From Large Language Models",
  "published": "2023-09-04T15:32:47Z",
  "authors": [
    "Joost Broekens",
    "Bernhard Hilpert",
    "Suzan Verberne",
    "Kim Baraka",
    "Patrick Gebhard",
    "Aske Plaat"
  ],
  "keywords": [
    "ChatGPT",
    "Large Language Models",
    "sentiment analysis",
    "emotion representation",
    "computational modeling of emotion",
    "emotion elicitation"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Large language models, in particular generative pre-trained transformers (GPTs), show impressive results on a wide variety of language-related tasks. In this paper, we explore ChatGPT's zero-shot ability to perform affective computing tasks using prompting alone. We show that ChatGPT a) performs meaningful sentiment analysis in the Valence, Arousal and Dominance dimensions, b) has meaningful emotion representations in terms of emotion categories and these affective dimensions, and c) can perform basic appraisal-based emotion elicitation of situations based on a prompt-based computational implementation of the OCC appraisal model. These findings are highly relevant: First, they show that the ability to solve complex affect processing tasks emerges from language-based token prediction trained on extensive data sets. Second, they show the potential of large language models for simulating, processing and analyzing human emotions, which has important implications for various applications such as sentiment analysis, socially interactive agents, and social robotics.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "I. Introduction",
      "text": "Affective Computing focuses on measuring, understanding and impacting human emotion  [1] -  [3] . While many approaches have been somewhat successful in doing so, a longstanding challenge in the field has been to appropriately use context for emotional understanding  [4] .\n\nLarge language models (LLMs), in particular generative pre-trained transformers (GPTs), show impressive results on a wide variety of language-related tasks  [5] . This ability is driven by the fact that these models are able to take into account large contexts in the prediction of the next token  [6] .\n\nRecently, current state-of-the-art GPT-based models allow easy interaction through prompting through the use of user interfaces, effectively providing a human-friendly way of performing zero-shot tasks  [7] . And, large scale versions of such models also show impressive results on a diversity of tasks for which they were not fine-tuned  [8] .\n\nInspired by these important characteristics of GPT models we investigate the ability to perform affective computing tasks by prompting ChatGPT without any fine-tuning or examples. We address the following research questions and tasks:\n\n• RQ1: How well can ChatGPT label sentiment, as values on the dimensions Valence, Arousal and Dominance, for textual descriptions of situations and for emotion words?\n\n• RQ2: To what extent does ChatGPT represent the correct meaning of emotion words and affective dimensions, tested as its ability to map values to situations, and situations to emotion words?\n\n• RQ3: How well can ChatGPT predict the emotion class in a situation based on a particular appraisal framework, in our case the Ortony-Clore-Collins (OCC) model  [9] ? We perform a series of exploratory experiments involving prompting ChatGPT to solve the above tasks, as well as comparing the generated results to ground truth data gathered from the literature or through human expert ratings.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Ii. Background And Related Work",
      "text": "",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "A. Generative Pretrained Transformers",
      "text": "Generative Pretrained Transformers (GPT) are models trained to generate natural language text, based on the transformer architecture. While the original transformer was designed as an encoder-decoder architecture  [6] , GPT is a decoder-only model: given a prompt it generates text, word by word, based on all the previous context words. The power of transformer models to generate fluent and coherent natural language text stems from the multiple transformer layers with self-attention to compute the strength of the relation between each pair of words in a sequence. This enables the models to capture long-distance dependencies in text  [5] .\n\nThe 'pretrained' aspect of GPT models refers to the fact that they are pre-trained on huge amounts of text data; for that reason, they are commonly referred to as Large Language Models (LLMs). This pre-training process is based on a language modeling task: training the model to predict the next word or masked words in a sentence. The first generation of transformer models, including the widely popular encoder models from the BERT-family  [10] , was very successful in a large range of Natural Language Processing (NLP) tasks thanks to the possibility of fine-tuning pre-trained models on labeled data.\n\nSince GPT-3, models of the GPT family are capable of solving tasks without fine-tuning: by generating text given a prompt  [8] . When the prompt does not contain any examples of the correct output (e.g., \"for the sentences below, label the content as having a positive, negative, or neutral sentiment\"), we call this zero-shot learning, prompt-based learning, or instruction tuning  [11] . When the prompt contains a few examples (roughly 3-50) we call this few-shot learning.\n\nIn this paper, we experiment with OpenAI's model Chat-GPT. It is based on the large pre-trained GPT-3.5 model, finetuned on conversation data, and refined with reinforcement learning based on an expert-trained reward function  [7] .",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "B. Core Affective Computing Tasks",
      "text": "Affective Computing is a subfield of Artificial Intelligence whose main research includes the detection and interpretation of human affect, on the one hand,  [12] ,  [13] , and the simulation and representation of affect on the other hand in both the human users and the social interactive agents  [14] , see also  [3]  and  [15]  for overviews. In this paper, we focus on the use of LLMs for Affective Computing by testing their zero-shot capabilities in automatic affect detection, emotion representation, and the computational elicitation of emotions.\n\n1) Automatic affect detection: Automatic detection and interpretation of behavioral signals of affect involves a broad range of tasks including affect recognition from the face, body, speech, EEG and other physiological signals, and text  [12] ,  [13] ,  [16] ,  [17] . As of writing this paper, text is the only modality available in the interaction with ChatGPT. We focus on multidimensional (Valence, Arousal, Dominance) sentiment analysis from short situational descriptions and emotion words.\n\nValence refers to the positive-negativeness of an experience, Arousal to the calmness-excitation of that experience, and Dominance to the extent to which a person feels in control of the situation  [18] -  [20] . While sometimes referred to as Pleasure, we assume here that Valence and Pleasure are similar dimensions both referring to the positiveness-negativeness of an affective state/situation. We use the term Valence, being the \"technical\" term and avoiding LLM confusion with lexical or common meanings of the word pleasure.\n\n2) Affect representation: Affect representation is typically based on psychological theories of emotion and affect  [14] ,  [21] . In particular, categorical or dimensional representations are used to represent an agent's or human's emotion. We focus on the numerical and latent representation of affect in terms of Valence, Arousal, and Dominance and a mapping from this representation to situations and (categorical) emotion words.\n\n3) Computational models of emotion elicitation: Computational modeling of emotion elicitation is used to simulate affective states based on the appraisal of situations and mental states of an agent. It has been approached from different perspectives, including cognitive agent-based appraisal modeling, e.g.  [22] , embodied modeling (homeostasis-based)  [23] , hardwired appraisal (event coding), and reinforcement learning  [14] ,  [24] . In emotion elicitation, the OCC appraisal model  [9]  has arguably had a major influence  [25] . While the objective of the OCC model was to reverse-engineer a set of emotional experiences based on their cognitive antecedents rather than an exhaustive set of universal rules that represent human appraisal processes (e.g., p. 172), the logical structure of the model has been the basis for a number of computational implementations of the model in Affective Computing  [21] ,  [26] ,  [27] . As such, in this paper, we focus on the OCC model of appraisal.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "C. Related Work On Sentiment Analysis",
      "text": "While many sentiment analysis methods are based on supervised fine-tuning (see  [17]  for a review), there is evidence that generative LLMs are capable of zero-shot prediction tasks, including sentiment classification  [28] ,  [29]  and argument quality prediction  [30] . It was shown that carefully engineering prompts helps with getting better task-specific guidance  [31] . As such there is reason to believe LLMs will perform on more detailed affect extraction from text as well.\n\nMost work in sentiment focuses on coarse-grained analysis of only Valence (e.g., 2-or 5-point scales) of opinions or reviews, or classification into several basic emotions  [32] . We are interested in a more fine-grained analysis of situations, as this is a more natural test for the understanding of an emotion as experienced by a person. Our tasks/stimuli are therefore different from the sentiment classification tasks such as those used for the SemEval challenges  [32] . We use psychologically validated and fine-grained dimensional ratings of situational descriptions on Valence, Arousal and Dominance  [19] .\n\nRecent work investigated the performance of ChatGPT compared to pre-trained and fine-tuned models on a sentiment data set containing tweets with positive and negative labels  [33] . The work reports reasonable performance as compared to finetuned models but only uses a coarse-grained dataset. There is only one prior work that evaluates automatic prediction of sentiment scores using the ANET data. The authors  [34]  finetune a multi-lingual XLM-RoBERTa-large model and evaluate it on a range of datasets in multiple languages. For the ANET texts (120 items), they report ρ = 0.920 for Valence and ρ = 0.859 for Arousal. Dominance was ignored.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Iii. Method",
      "text": "We are interested in the extent to which ChatGPT can perform the three above mentioned affective computing tasks in a zero-shot setting with instruction prompting.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "A. Material",
      "text": "Our data set for RQ 1 consists of all 120 Affective Norms for English Text dataset (ANET) situations  [19]  and all 151 emotion words from Russel and Mehrabian  [20] .\n\nAs for RQ2, we focus on mapping stimulus sets to each other, with a human expert rater as ground truth. We used a subset of the words and situations (see Table  I , II), each containing the 20 most reliably rated items, as assessed by the sum over the squared standard deviation (SD) for Valence, Arousal and Dominance (lower values are considered more reliable). The SD was given by  [19]  and  [20] .\n\nFor RQ3, we created a set of by-the-authors-formulated situations that reflect each of the tested emotions in the OCC model, see Table  V . Throughout the experiment, we used the default model of ChatGPT 3.5 between February/March 2023.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "B. Experimental Set-Up",
      "text": "To address our RQs, we performed a series of conversational experiments with the model. To avoid confounding, a new chat session was initiated for each experiment. We explain the process for each of the RQs here.\n\n1) RQ1: Sentiment analysis: For RQ1.1, we prompted 1 ChatGPT to perform sentiment analysis on Valence, Arousal, and Dominance (VAD), after which the 120 situations were entered as the next prompt (20 per session). The resulting values were correlated (per dimension) with the ground truth values provided by  [19] . This serves to test the model's performance on sentiment analysis from situational text.\n\nIn RQ1.2, we tested the model's performance on sentiment analysis from emotion words in the same way. These values are correlated with the ground truth provided by  [20] .\n\n2) RQ2: Affect representation: To test the model's affect representation capability, we investigate if the model can use an affective representation in a constructive way.\n\nFor RQ2.1, we repeated RQ1, prompting ChatGPT to assign VAD-values to the 20 most reliable situations and emotion words but now in a single session. Then, we prompted the model to select for each situation the most fitting emotion word, based on this numerical representation. We computed the distance matrix between the emotion words and situation stimuli (based on the values generated by ChatGPT) and ranked the selected word according to the distance matrix. This serves to verify if ChatGPT is able to use a numerical affective representation to map two stimulus sets to each other.\n\nFor RQ2.2, we repeated the previous setup but provided ChatGPT with the situations and word lists without asking for a numerical representation. We then asked the model to pick for each situation stimulus the two most fitting emotion words. This classification was compared to a ground truth rated by an independent expert in emotion research. This serves to verify if ChatGPT is able to map two stimulus sets to each other, based on a latent affect representation.\n\nFor RQ2.3, we prompted ChatGPT to generate a new situation for 9 different value triplets that span the VAD space (1 neutral, 8 in each extreme). The generated situations are classified again by the same independent rater. This serves to verify if ChatGPT is able to generate new situations based on its latent representation of affect, prompted as values on dimensions. 1 For readability, prompts are presented alongside the results.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "3) Rq3: Appraisal-Based Emotion Elicitation:",
      "text": "To assess if ChatGPT can predict emotions according to a specific appraisal framework, we formalized a rule-based logical model of appraisal as a prompt, based on  [9] . The OCC model provides an appraisal structure, including goals as well as global and local variables such as events, agents, and objects in order to describe the elicitation process of a select set of emotions in a rule-based description. The OCC authors note that the antecedents of components such as praiseworthiness of actions (i.e standards) and appealingness of objects (i.e. attitudes) should not be seen as \"internally consistent\" (p.46) and cannot or should not be organized in a representational structure. Thus, for this experiment, we decided to focus only on the branch of event-related emotions of the OCC model.\n\nAfter formalizing the event-branch of the model in a prompt, we asked ChatGPT to appraise the set of by-the-authorsformulated situations and checked if the corresponding emotion was reported. This serves to assess if ChatGPT can follow a precise logical structure for emotion elicitation, rather than an implicit latent representation: is it 'programmable'? IV. RESULTS",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "A. Rq1: Sentiment Analysis",
      "text": "Pilot testing with prompts on the most reliable subset of situations (the 20 items subset) showed that without an explanation of the Dominance dimension, ChatGPT produces meaningless Dominance values while Valence and Arousal correlate well with the ground truth (ρ = 0.98 for Valence, ρ = 0.91 for Arousal and ρ = -0.39 for Dominance, see D * in Table  I ). As the correlation is negative, this could indicate confusion about the perspective of who experiences what. We added \"remember that dominance assesses the extent to which the main person in the situation experiences the amount of control it can assert over the situation\" (as taken from  [18] ).\n\nAs such, for RQ1, we used prompt 1: Valence, Arousal and Dominance are three affective dimensions that you can use to identify the sentiment in sentences. Assume that these dimensions can take values between 0 and 1, with 0 being low, and 1 being high. Remember that dominance assesses the extent to which the main person in the situation experiences the amount of control it can assert over the situation. Assess according to these dimensions the sentiment in the sentences I will give you after.\n\nBe precise, and output the values (up until two digits after the decimal point) in a table please. Just acknowledge you got it. [BLOCK OF ANET] The results of the sentiment analysis on all 120 ANET situations (RQ2.1) showed that the Pearson correlations for Valence, Arousal and Dominance with the ground truth data are very strong (ρ = 0.95, RM SE = 0.08; ρ = 0.82, RM SE = 0.10; ρ = 0.82, RM SE = 0.11, respectively, all p < 0.001 and N = 120), indicating a good fit of ChatGPT sentiment to the VAD ground truth values. Correlations for the 20 most reliable situation items are shown in Table  I , which are even stronger confirming the higher reliability of the items.  We repeated this process for the emotion words. RQ1.2 results show strong correlations with the ground truth (ρ = 0.89, RM SE = 0.12 for Valence, ρ = 0.66, RM SE = 0.13 for Arousal, and ρ = 0.68, RM SE = 0.13 for Dominance, all p < 0.001 and N = 151). Correlations for the 20 most reliable word items are shown in Table  II .",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "B. Rq2: Affect Representation",
      "text": "For RQ2.1, we first prompted ChatGPT with prompt 1 and the 20 item situation list, then with prompt 1 and the list of emotion words. Then we issued prompt 2:\n\nGreat! now can you use the numerical values of valence, arousal, and dominance to match each sentence from the first list to a word from the second list based on their closeness of values for these affective dimensions? We ranked the selected word for each situation according to a euclidean distance matrix in the VAD space (based on the values given by ChatGPT in this session). The results can be found in Table  III . The majority of the selected words are amongst the closest distance words, except for situations without a suitable word in the 20 item word list (all fearrelated words). This indicates that although ChatGPT is able to map situations to words, it does not seem to use a numerical representation for it, as evidenced by the bad performance on sentences where no suitable word is found semantically, but a much better choice exists numerically.\n\nTo test the free-form situation-word mapping (RQ2.2), we repeated the setup of the first part, with a small adjustment to limit ChatGPT hallucinating emotion words that were not part of the list. We prompted each of the ANET situations in an individual session together with the complete list of emotion words to pick from, according to prompt 3:\n\n[ANET SITUATION] Please pick the two words from this list that fit the situation best based on the affective meaning: [LIST OF EMOTION WORDS] The results for RQ2.2 together with the independent human expert's word selection can be found in Table  III . For 2 cases a complete match was found, while 11 of the 20 situations had a partial match. Failed matches were mostly due to perspective: the expert rated the feeling of the individual, while ChatGPT rated the situation trying to match both the feeling and the overall affect generally associated with the situation (e.g, most negative situations are rated as 'serious'). When we changed the prompt to \"Describe the feeling of the individual experiencing the situation using two words from the following list (you may not use other words):\", we observed 3 complete and 11 partial matches (words in brackets in Table  III ). However, this also pushed the model to consistently generate new better matching words for situations (emphasized words in table) dampening overall matching score. We observe that ChatGPT's capability of mapping two stimulus sets to each other based on latent affect representation seems to match human expert ratings at least in part.\n\nFor RQ2.3, we prompted ChatGPT for each of the 9 value triplets in a separate session with the same prompt, varying only VAD-values. We issued prompt 4:\n\nAssume a man, in a real-live situation that could happen to all of us. Assume that the Valence dimension represents the extent to which the situation is experienced by the man as positive (high) versus negative (low). Assume that the arousal dimension represents the extent to which the situation is experienced by the man as energetic (high) versus calm (low). Assume that the dominance dimension represents the extent to which the man is in control of the situation (high) or not (low). Can you invent a 50 word situation that matches [LOW,HIGH] valence, [LOW,HIGH] arousal, [LOW,HIGH] dominance? All situations created by ChatGPT were classified as intended by the human expert rater (see Table  IV ). This demonstrates that ChatGPT is able to create new emotional situations very reliably when prompted with a specific affective state.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "C. Rq3: Appraisal-Based Emotion Elicitation",
      "text": "For the emotion elicitation RQ3, we issued prompt 5:\n\nFor this conversation, assume we define the chatOCC computational model of emotions as follows. It is based on the OCC (Ortony, Clore, and\n\nCollins) appraisal theory. The model defines emotions as a result of cognitive appraisal of an \"event\" in relation to a specific \"goal\" a person has in a specific \"situation\". We define four appraisals: desirability, certainty of the event, confirmation of the event, and liking of another person. We define the following emotion rules from the perspective of Anne:\n\nUse ONLY these emotion rules to predict the most likely emotion for the following situation Anne might find herself in, that I will give to you. Be brief, explaining only how the rule matches the situation, and mention the intensity (low, medium, high) based on the desirability and likelihood of the event. Here is the situation: [SITUATION FROM TABLE V] For each situation a new session was used. RQ 3 results can be found in Table  V . The chatOCC model predicted 10/12 emotions correctly. Two emotions were not correctly identified: Despair (Fears-confirmed) and Disappointment.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "V. Discussion",
      "text": "",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "A. Discussion Of Rqs",
      "text": "RQ1.1: The initial negative correlation for Dominance prediction could reflect the issue of perspective-taking discussed in the literature  [18] . After correcting this, all correlations between predicted VAD-Values provided by ChatGPT and ground truth values were strong. Compared to the correlations reported by  [34]  (see Section II-C), we see that the predictions by ChatGPT have similar correlations to the fine-tuned XLM-RoBERTa-large model (ρ = 0.92 for Valence; ρ = 0.86 for Arousal). This shows that prediction of Valence, Arousal and Dominance by generative LLMs is possible without finetuning.\n\nRQ1.2: The correlations for emotion words are weaker than for situations, but still high and significant. This makes sense and highlights the importance of context for sentiment analysis: situations contain more affective context.\n\nRQ2.1: ChatGPT did not convincingly show the capability to use numerical representations of affect for mapping between stimulus sets but rather seemed to map word meanings to situations. While this proved to work out in some cases (i.e. choosing 'triumphant' for situation 8280), in other cases it either failed at representing the affective state from the perspective of the main protagonist (i.e. choosing 'excited' for 7380, 'aggressive' for 2510), or it got confused because the proper emotion word is not in the list. This indicates that instead of using the self-created VAD-values for the mapping (as instructed), the model rather seemed to choose emotion words that fit the ANET-situations on an semantic latent level.\n\nRQ2.2: Overall, ChatGPT showed reasonable partial overlap with the human expert's answers. Providing the correct rating perspective increased the overlap, but also increased the tendency to generate new better matching words when no suitable word was in the list. This shows the importance of careful prompting, and, the strong semantic bias such models have. Further, if fear-related words would be added the emotion  The man walks into a peaceful park, surrounded by blooming flowers and chirping birds. He strolls along the path, feeling content and relaxed, taking in the beauty of the scenery, simply existing within it.\n\nV+A-D-V-A+D-A man is alone at night, walking through a dark and unfamiliar neighborhood. He feels uneasy and senses someone following him, but he cannot see who it is. His heart races and his palms sweat as he quickens his pace.",
      "page_start": 5,
      "page_end": 6
    },
    {
      "section_name": "V-A+D-V-A-D+",
      "text": "A man walks into a job performance review, expecting a positive evaluation but is met with harsh criticism. He remains calm and composed throughout the meeting, taking control of the conversation and presenting a plan to improve his performance.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "V-A-A+",
      "text": "",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "V+A+D-",
      "text": "A man walks into a surprise party where his friends jump out to yell \"surprise!\" He feels elated and energetic, but also overwhelmed. Although he tries to join in, he feels like a spectator.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "V+A+D-V-A+D+",
      "text": "The man was driving home from work when suddenly a car swerved in front of him, causing him to slam on his brakes and narrowly avoid a collision. Filled with fear and anger, he honks his horn and yells out the window.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "V-A+D+",
      "text": "V+A-D+ A man confidently delivers a well-prepared presentation to a group of colleagues, receiving praise and admiration for his expertise. He maintains a calm and composed demeanor throughout the whole talk.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "V+A-D+",
      "text": "",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "V+A+D+",
      "text": "The man stood at the finish line of a marathon, cheering on his wife as she crossed it, breaking her personal best record. His heart raced with excitement, feeling a surge of pride and accomplishment. As she approached, he raised his arms victoriously.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "V+A+D+ V-A-D-",
      "text": "The man trudged through the rain-soaked streets, his soaked shoes squishing with each step. He felt powerless as he searched for shelter, his plans for the day washed away with the downpour.\n\nV-A-Dneutral A man sits alone in a quiet room, staring out of the window. There are no loud noises or sudden movements to disrupt the peaceful stillness. neutral word list, results are expected to be higher on RQ2.2. We conclude that ChatGPT performs meaningful situation to word mapping based on latent affective representations.\n\nResults from RQ2.3 show that ChatGPT is indeed able to use latent affect representations and validly map these to a newly generated situation. Two major differences in complexity of numerical mapping between RQ2.1 and RQ2.3 are: in RQ2.3 we asked for a first order mapping (VAD-state to stimulus) instead of a second order mapping (situation-to-VAD-state and VAD-state-to-word); and, VAD-states were less specific (low/high vs. exact numerical values). RQ3: ChatGPT predicted the majority of emotions correctly given a conceptual framework for appraisal and a situation to appraise. In the two cases that it failed, it incorrectly predicted the less specific emotion of distress instead of despair (aka fears-confirmed) or disappointment. Distress differs from the two latter emotion classes by the relevance of prospect  [9] . Perhaps ChatGPT did not take the prospect into account when appraising these two cases. However, this seemed only to be the case for negative prospect-based emotions, not for positive ones. It remains unclear why ChatGPT selected distress as the more adequate emotion in this case. However, most of the emotions were predicted correctly indicating a basic capability of applying an appraisal framework for the assessment of given situations and the prediction of emotion classes.",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "B. Implications For Affective Computing",
      "text": "Our results highlight the interconnection of language and human affect. ChatGPT produces outcomes that, overall, match human data. Apparently, successful use and interpretation of language results in the ability to process affect. Resentment Hope a desirable event for Anne might happen in the future. After studying for weeks, Anne feels ready to take on the exam tomorrow.\n\nHope Fear an undesirable event for Anne might happen in the future. After studying for weeks, Anne feels not ready to take on the exam tomorrow.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Fear",
      "text": "Satisfac.\n\nAn anticipated desirable event for Anne has indeed happened. Anne had taken the exam, being sure it would be a success.\n\nChecking the results now, she sees that she passed.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Satisfaction",
      "text": "Despair An anticipated undesirable event for Anne has indeed happened.\n\nAnne had taken the exam, being sure it would be a disaster.\n\nChecking the results now, she sees that she failed.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Distress",
      "text": "Relief An anticipated undesirable event for Anne did not happen. Anne had taken the exam, being sure it would be a disaster.\n\nChecking the results now, she sees that she passed.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Relief",
      "text": "Disapp.\n\nAn anticipated desirable event for Anne did not happen. Anne had taken the exam, being sure it would be a success.\n\nChecking the results now, she sees that she failed.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Distress",
      "text": "Psychological emotion research has suggested language as a crucial, inseparable and highly intertwined context variable for emotion-related processes in human adults  [35] ,  [36] .\n\nAlthough our work cannot be taken as proof for this psychological view of emotion, as LLMs have to work from language by default for affect-related tasks, and humans do not necessarily, our work does highlight that language will likely play a crucial role in future Affective Computing research. This connects to computational models of appraisal theories. While mostly spelled out as logical rules in the respective papers (e.g.,  [9] ,  [37] -  [39] ), pioneering work has been put into formalizing these theories into computational frameworks (e.g  [3] ,  [21] ,  [22] ,  [26] ). One critical problem is contextual understanding of the situation to be appraised by the formal model which needs a richly grounded symbolic system. Symbol grounding is also relevant for making user input interpretable to the computer in the right format. An LLM that interacts with a user in a natural way and extracts formalized interpretations from their input, leaves more room for researchers to focus on problems of affective processing further down the pipeline. Our work shows the potential of leveraging LLMs for this purpose: Symbolic AI is dead, long live symbolic AI! Finally, for many Affective Computing experiments, sets of stimuli have to be evaluated regarding their affective implications before working with them. This is problematic if the sets are large. While an LLM is not a valid substitute for standardized expert evaluations, given the demonstrated reliability in assigning VAD-values or emotion words to situations, this could help with automatic annotation or creation of tailored or study-customized stimuli -at least in cases where the affective meaning is not an experiment's main objective.",
      "page_start": 7,
      "page_end": 8
    },
    {
      "section_name": "C. Limitations And Future Work",
      "text": "This is an exploratory paper. To generalize these findings, more work is needed in particular using a more diverse collection of datasets for sentiment analysis and a more diverse and more complex set of computational models for appraisal modeling. Further, in this paper we did not address the underlying processing mechanisms of LLMs that enable such powerful zero-shot learning. The results reported in this paper are based on OpenAI's ChatGPT 3.5 from February and March 2023 (which is based on text-davinci-003). New versions are being developed fast. These versions might be more powerful for unseen tasks, but they also might not as the impact of supervised targets and reward-based losses on the generalization to unseen tasks is unknown. Therefore we do not know how generalizable our results are to future LLMs. Another exciting aspect is to explore how LLMs can be used to simulate the dynamics of affect, such as emotion decay and the influence of emotions on mood.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Vi. Conclusion",
      "text": "We show that ChatGPT a) performs accurate extraction of fine-grained, multi-dimensional sentiment from situations and words, compared to the level of fine-tuned models on the same dataset, even on the dimension of Dominance, b) is capable of simple numerical and latent affect representation, and shows moderate understanding of affective dimensions and emotion words, c) can perform basic appraisal-based emotion elicitation of situations based on a prompt-based computational implementation of the OCC appraisal model. These capabilities can be leveraged through appropriate prompting.\n\nThese findings are highly relevant: First, we show that the ability to solve complex affect processing tasks emerges from language-based token prediction trained on extensive data sets. Second, we show the potential of large language models for simulating, understanding and analyzing human emotions, which has important implications for various applications such as sentiment analysis, socially interactive agents, and social robotics.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Vii. Ethical Impact Statement",
      "text": "No subjects were recruited for this work. The environmental impact of the energy used for the inference of the prompts is neglectable due to the small number of prompts. The work could have a major impact on popular belief around psychological capabilities of LLMs, as addressed in the limitations: we explicitly mention this is an exploratory paper.",
      "page_start": 8,
      "page_end": 8
    }
  ],
  "figures": [],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "ID": "4650",
          "ANET text": "You are both aroused, breathless. You fall\ntogether on the couch. Kisses on your neck,\nface– warm hands fumbling with clothing, hearts pounding.",
          "V": "8.34",
          "A": "8.10",
          "D": "6.2",
          "ˆ\nV": "0.81",
          "ˆ\nA": "0.93",
          "ˆ\nD∗": "0.57",
          "ˆ\nD": "0.55"
        },
        {
          "ID": "2880",
          "ANET text": "Your\nfriend whispers to you in a meeting, and you strain to catch the words.",
          "V": "4.63",
          "A": "4.96",
          "D": "4.4",
          "ˆ\nV": "0.5",
          "ˆ\nA": "0.43",
          "ˆ\nD∗": "0.27",
          "ˆ\nD": "0.39"
        },
        {
          "ID": "6820",
          "ANET text": "You’re alone in the alley in a bad part of the city. A street gang slowly surrounds you,\nknives out,\nlaughing with menace. Your heart pounds as they close in.",
          "V": "1.62",
          "A": "8.23",
          "D": "1.78",
          "ˆ\nV": "0.06",
          "ˆ\nA": "0.86",
          "ˆ\nD∗": "0.73",
          "ˆ\nD": "0.11"
        },
        {
          "ID": "6020",
          "ANET text": "Without\nthinking, you stepped off\nthe curb into trafﬁc. Breaks\nscreech. You look up,\nfrozen, heart\njumping in your chest. A truck is skidding, hurtling towards you.",
          "V": "1.89",
          "A": "8.21",
          "D": "2.08",
          "ˆ\nV": "0.12",
          "ˆ\nA": "0.93",
          "ˆ\nD∗": "0.62",
          "ˆ\nD": "0.10"
        },
        {
          "ID": "5900",
          "ANET text": "You cringe as a ﬁerce hurricane tears the roof off your house.",
          "V": "1.81",
          "A": "7.98",
          "D": "1.83",
          "ˆ\nV": "0.05",
          "ˆ\nA": "0.63",
          "ˆ\nD∗": "0.64",
          "ˆ\nD": "0.23"
        },
        {
          "ID": "3310",
          "ANET text": "You ﬂinch, at\nthe screech of brakes; you look up, and see the speeding car\nslam into\nyour\nfriend. Her\nleg is crushed,\nthe artery torn, and blood pumps on the road.",
          "V": "1.30",
          "A": "8.15",
          "D": "2.36",
          "ˆ\nV": "0",
          "ˆ\nA": "0.89",
          "ˆ\nD∗": "0.66",
          "ˆ\nD": "0.06"
        },
        {
          "ID": "9100",
          "ANET text": "Clutching his chest, your\nfather\nfalls to the ﬂoor, unable to breathe.",
          "V": "1.30",
          "A": "8.13",
          "D": "2.23",
          "ˆ\nV": "0.12",
          "ˆ\nA": "0.71",
          "ˆ\nD∗": "0.48",
          "ˆ\nD": "0.05"
        },
        {
          "ID": "2540",
          "ANET text": "You walk through the supermarket aisles checking things off your list as you pick each\nitem you need off\nthe shelves.",
          "V": "5.54",
          "A": "3.38",
          "D": "6.7",
          "ˆ\nV": "0.63",
          "ˆ\nA": "0.29",
          "ˆ\nD∗": "0.24",
          "ˆ\nD": "0.5"
        },
        {
          "ID": "8040",
          "ANET text": "Everyone’s\nstaring at you, waiting for your presentation. You’ve misplaced all your\nnotes, graphics, everything’s lost! What will you say? They see you shaking, sweating–\nmumbling stupidly.",
          "V": "1.90",
          "A": "7.66",
          "D": "2.12",
          "ˆ\nV": "0.06",
          "ˆ\nA": "0.86",
          "ˆ\nD∗": "0.59",
          "ˆ\nD": "0.03"
        },
        {
          "ID": "8380",
          "ANET text": "It\nis a close game, and the crowd cheers as you drive in the winning run.",
          "V": "8.37",
          "A": "8.15",
          "D": "7.56",
          "ˆ\nV": "0.71",
          "ˆ\nA": "0.57",
          "ˆ\nD∗": "0.59",
          "ˆ\nD": "0.65"
        },
        {
          "ID": "2530",
          "ANET text": "You’ve been sick all week,\nlying on a lumpy couch with a bad cold.",
          "V": "2.15",
          "A": "3.32",
          "D": "3.09",
          "ˆ\nV": "0.13",
          "ˆ\nA": "0.24",
          "ˆ\nD∗": "0.23",
          "ˆ\nD": "0.05"
        },
        {
          "ID": "7380",
          "ANET text": "You gag,\nseeing a roach moving slowly over\nthe surface of\nthe pizza. You knock the\npie on the ﬂoor. Warm cheese spatters on your shoes.",
          "V": "1.92",
          "A": "6.89",
          "D": "3.95",
          "ˆ\nV": "0.03",
          "ˆ\nA": "0.75",
          "ˆ\nD∗": "0.64",
          "ˆ\nD": "0.06"
        },
        {
          "ID": "4400",
          "ANET text": "You shiver as your bodies brush together. You reach out. You want\nto touch everywhere,\nkiss everywhere. You hear\nthe words, ”I\nlove you”.",
          "V": "8.28",
          "A": "7.91",
          "D": "5.90",
          "ˆ\nV": "0.87",
          "ˆ\nA": "0.75",
          "ˆ\nD∗": "0.46",
          "ˆ\nD": "0.64"
        },
        {
          "ID": "7040",
          "ANET text": "You hold the ﬂashlight steady in order\nto get a better\nlook at\nthe map.",
          "V": "5.04",
          "A": "4.17",
          "D": "5.65",
          "ˆ\nV": "0.50",
          "ˆ\nA": "0.24",
          "ˆ\nD∗": "0.33",
          "ˆ\nD": "0.51"
        },
        {
          "ID": "8610",
          "ANET text": "At\nthe net, you go up and block the volleyball perfectly, saving the game.",
          "V": "8.40",
          "A": "7.86",
          "D": "7.82",
          "ˆ\nV": "0.69",
          "ˆ\nA": "0.57",
          "ˆ\nD∗": "0.54",
          "ˆ\nD": "0.59"
        },
        {
          "ID": "2610",
          "ANET text": "You are sitting at\nthe kitchen table with yesterday’s newspaper\nin front of you. You\npush back the chair when you hear\nthe coffee maker slow to a stop.",
          "V": "5.37",
          "A": "3.13",
          "D": "6.11",
          "ˆ\nV": "0.40",
          "ˆ\nA": "0.14",
          "ˆ\nD∗": "0.21",
          "ˆ\nD": "0.47"
        },
        {
          "ID": "2130",
          "ANET text": "You are lying in bed on a Sunday morning, half asleep and listening to the distant sound\nof bells,\nrelaxing on your day off.",
          "V": "7.41",
          "A": "2.21",
          "D": "6.76",
          "ˆ\nV": "0.70",
          "ˆ\nA": "0.18",
          "ˆ\nD∗": "0.27",
          "ˆ\nD": "0.49"
        },
        {
          "ID": "8620",
          "ANET text": "You sprint back to the other side of the court. You lunge for the ball and hit a spectacular\nbackhand down the line for\nthe win. You pump your ﬁst\nin victory.",
          "V": "8.15",
          "A": "7.31",
          "D": "8.10",
          "ˆ\nV": "0.75",
          "ˆ\nA": "0.79",
          "ˆ\nD∗": "0.64",
          "ˆ\nD": "0.65"
        },
        {
          "ID": "2640",
          "ANET text": "You laugh so hard with your\nfriends that\ntears pour down your\nface.",
          "V": "8.56",
          "A": "7.65",
          "D": "5.8",
          "ˆ\nV": "0.88",
          "ˆ\nA": "0.71",
          "ˆ\nD∗": "0.44",
          "ˆ\nD": "0.51"
        },
        {
          "ID": "2510",
          "ANET text": "People are all around you, pressing closer.\nIt’s hard to breath. You’re ﬂushed, sweaty,\ndizzy, confused. You realize it’s another attack and this time, you think, ”I will die.”",
          "V": "1.78",
          "A": "7.69",
          "D": "2.08",
          "ˆ\nV": "0.02",
          "ˆ\nA": "0.89",
          "ˆ\nD∗": "0.80",
          "ˆ\nD": "0.05"
        },
        {
          "ID": "",
          "ANET text": "ˆ\nCorrs: N = 20, p < 0.001 (except\nfailed\nD*)",
          "V": "",
          "A": "",
          "D": "",
          "ˆ\nV": "0.98",
          "ˆ\nA": "0.91",
          "ˆ\nD∗": "-0.39",
          "ˆ\nD": "0.93"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "V": "-0.65",
          "A": "-0.62",
          "D": "-0.33",
          "ˆ\nV": "0.11",
          "ˆ\nA": "0.18",
          "ˆ\nD": "0.08"
        },
        {
          "V": "0.69",
          "A": "0.57",
          "D": "0.63",
          "ˆ\nV": "0.88",
          "ˆ\nA": "0.77",
          "ˆ\nD": "0.81"
        },
        {
          "V": "0.58",
          "A": "0.61",
          "D": "0.49",
          "ˆ\nV": "0.76",
          "ˆ\nA": "0.77",
          "ˆ\nD": "0.8"
        },
        {
          "V": "0.27",
          "A": "0.24",
          "D": "0.42",
          "ˆ\nV": "0.31",
          "ˆ\nA": "0.29",
          "ˆ\nD": "0.48"
        },
        {
          "V": "0.49",
          "A": "0.57",
          "D": "0.45",
          "ˆ\nV": "0.58",
          "ˆ\nA": "0.43",
          "ˆ\nD": "0.53"
        },
        {
          "V": "0.16",
          "A": "0.88",
          "D": "-0.15",
          "ˆ\nV": "0.78",
          "ˆ\nA": "0.88",
          "ˆ\nD": "0.43"
        },
        {
          "V": "-0.47",
          "A": "-0.5",
          "D": "-0.08",
          "ˆ\nV": "0.1",
          "ˆ\nA": "0.17",
          "ˆ\nD": "0.09"
        },
        {
          "V": "0.42",
          "A": "0.58",
          "D": "0.38",
          "ˆ\nV": "0.61",
          "ˆ\nA": "0.7",
          "ˆ\nD": "0.68"
        },
        {
          "V": "0.77",
          "A": "0.44",
          "D": "0.42",
          "ˆ\nV": "0.91",
          "ˆ\nA": "0.79",
          "ˆ\nD": "0.67"
        },
        {
          "V": "0.47",
          "A": "0.34",
          "D": "0.66",
          "ˆ\nV": "0.16",
          "ˆ\nA": "0.43",
          "ˆ\nD": "0.84"
        },
        {
          "V": "0.87",
          "A": "0.54",
          "D": "-0.18",
          "ˆ\nV": "0.88",
          "ˆ\nA": "0.66",
          "ˆ\nD": "0.82"
        },
        {
          "V": "0.62",
          "A": "0.75",
          "D": "0.38",
          "ˆ\nV": "0.84",
          "ˆ\nA": "0.91",
          "ˆ\nD": "0.67"
        },
        {
          "V": "0.68",
          "A": "0.4",
          "D": "0.75",
          "ˆ\nV": "0.46",
          "ˆ\nA": "0.49",
          "ˆ\nD": "0.81"
        },
        {
          "V": "0.58",
          "A": "0.44",
          "D": "0.69",
          "ˆ\nV": "0.62",
          "ˆ\nA": "0.61",
          "ˆ\nD": "0.82"
        },
        {
          "V": "-0.25",
          "A": "0.42",
          "D": "0.11",
          "ˆ\nV": "0.26",
          "ˆ\nA": "0.7",
          "ˆ\nD": "0.49"
        },
        {
          "V": "-0.28",
          "A": "0.17",
          "D": "0.04",
          "ˆ\nV": "0.28",
          "ˆ\nA": "0.44",
          "ˆ\nD": "0.42"
        },
        {
          "V": "-0.53",
          "A": "0.27",
          "D": "-0.32",
          "ˆ\nV": "0.24",
          "ˆ\nA": "0.43",
          "ˆ\nD": "0.3"
        },
        {
          "V": "0.69",
          "A": "0.35",
          "D": "0.3",
          "ˆ\nV": "0.79",
          "ˆ\nA": "0.52",
          "ˆ\nD": "0.75"
        },
        {
          "V": "0.41",
          "A": "0.63",
          "D": "0.62",
          "ˆ\nV": "0.24",
          "ˆ\nA": "0.77",
          "ˆ\nD": "0.63"
        },
        {
          "V": "0.71",
          "A": "0.48",
          "D": "0.37",
          "ˆ\nV": "0.87",
          "ˆ\nA": "0.6",
          "ˆ\nD": "0.68"
        },
        {
          "V": "",
          "A": "",
          "D": "",
          "ˆ\nV": "0.77",
          "ˆ\nA": "0.85",
          "ˆ\nD": "0.74"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "RQ2.1 Numerical": "ChatGPT Numerical Mapping (ED)",
          "RQ2.2 latent": "ChatGPT’s free Mapping"
        },
        {
          "RQ2.1 Numerical": "excited(0.08)",
          "RQ2.2 latent": "enjoyment, excited"
        },
        {
          "RQ2.1 Numerical": "confused(0.36)",
          "RQ2.2 latent": "alert, mildly annoyed"
        },
        {
          "RQ2.1 Numerical": "aggressive(0.21)",
          "RQ2.2 latent": "serious (alert), suspicious"
        },
        {
          "RQ2.1 Numerical": "suspicious(0.45)",
          "RQ2.2 latent": "serious (astonished), alert"
        },
        {
          "RQ2.1 Numerical": "vigorous(0.74)",
          "RQ2.2 latent": "serious (mildly\nannoyed), astonished"
        },
        {
          "RQ2.1 Numerical": "astonished(0.67)",
          "RQ2.2 latent": "serious (astonished), alert"
        },
        {
          "RQ2.1 Numerical": "controlling(0.45)",
          "RQ2.2 latent": "serious, alert\n(astonished)"
        },
        {
          "RQ2.1 Numerical": "friendly(0.38)",
          "RQ2.2 latent": "alert, mildly annoyed (serious)"
        },
        {
          "RQ2.1 Numerical": "enjoyment(1.01)",
          "RQ2.2 latent": "confused, mildly annoyed (anxious)"
        },
        {
          "RQ2.1 Numerical": "triumphant(0.09)",
          "RQ2.2 latent": "triumphant, excited"
        },
        {
          "RQ2.1 Numerical": "bored(0.23)",
          "RQ2.2 latent": "serious (uninterested), mildly annoyed"
        },
        {
          "RQ2.1 Numerical": "excited(0.89)",
          "RQ2.2 latent": "astonished (disgusted), mildly annoyed"
        },
        {
          "RQ2.1 Numerical": "loved(0.39)",
          "RQ2.2 latent": "excited,\nloved"
        },
        {
          "RQ2.1 Numerical": "alert(0.46)",
          "RQ2.2 latent": "alert, serious (focused)"
        },
        {
          "RQ2.1 Numerical": "masterful(0.2)",
          "RQ2.2 latent": "triumphant, vigorous (excited)"
        },
        {
          "RQ2.1 Numerical": "bored(0.5)",
          "RQ2.2 latent": "alert, mildly annoyed"
        },
        {
          "RQ2.1 Numerical": "lucky(0.5)",
          "RQ2.2 latent": "relaxed, enjoyment"
        },
        {
          "RQ2.1 Numerical": "masterful(0.41)",
          "RQ2.2 latent": "triumphant, vigorous (excited)"
        },
        {
          "RQ2.1 Numerical": "enjoyment(0.29)",
          "RQ2.2 latent": "enjoyment,\nfriendly"
        },
        {
          "RQ2.1 Numerical": "aggressive(0.79)",
          "RQ2.2 latent": "confused, serious (panicked)"
        }
      ],
      "page": 6
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Prompt": "V+A-D-",
          "Generated Situation": "The man walks\ninto a peaceful park,\nsurrounded by blooming ﬂowers and chirping birds. He strolls along the path,\nfeeling\ncontent and relaxed,\ntaking in the beauty of\nthe scenery, simply existing within it.",
          "Rating": "V+A-D-"
        },
        {
          "Prompt": "V-A+D-",
          "Generated Situation": "A man is alone at night, walking through a dark and unfamiliar neighborhood. He feels uneasy and senses someone following\nhim, but he cannot see who it\nis. His heart\nraces and his palms sweat as he quickens his pace.",
          "Rating": "V-A+D-"
        },
        {
          "Prompt": "V-A-D+",
          "Generated Situation": "A man walks into a job performance review, expecting a positive evaluation but\nis met with harsh criticism. He remains calm\nand composed throughout\nthe meeting,\ntaking control of\nthe conversation and presenting a plan to improve his performance.",
          "Rating": "V-A-A+"
        },
        {
          "Prompt": "V+A+D-",
          "Generated Situation": "A man walks\ninto a\nsurprise party where his\nfriends\njump out\nto yell\n”surprise!” He\nfeels\nelated and energetic,\nbut\nalso\noverwhelmed. Although he tries to join in, he feels like a spectator.",
          "Rating": "V+A+D-"
        },
        {
          "Prompt": "V-A+D+",
          "Generated Situation": "The man was driving home from work when suddenly a car swerved in front of him, causing him to slam on his brakes and\nnarrowly avoid a collision. Filled with fear and anger, he honks his horn and yells out\nthe window.",
          "Rating": "V-A+D+"
        },
        {
          "Prompt": "V+A-D+",
          "Generated Situation": "A man conﬁdently delivers\na well-prepared\npresentation to a group of\ncolleagues,\nreceiving praise\nand admiration for his\nexpertise. He maintains a calm and composed demeanor\nthroughout\nthe whole talk.",
          "Rating": "V+A-D+"
        },
        {
          "Prompt": "V+A+D+",
          "Generated Situation": "The man stood at\nthe ﬁnish line of a marathon, cheering on his wife as she crossed it, breaking her personal best\nrecord. His\nheart\nraced with excitement,\nfeeling a surge of pride and accomplishment. As she approached, he raised his arms victoriously.",
          "Rating": "V+A+D+"
        },
        {
          "Prompt": "V-A-D-",
          "Generated Situation": "The man trudged through the rain-soaked streets, his soaked shoes squishing with each step. He felt powerless as he searched\nfor shelter, his plans for\nthe day washed away with the downpour.",
          "Rating": "V-A-D-"
        },
        {
          "Prompt": "neutral",
          "Generated Situation": "A man sits alone in a quiet\nroom, staring out of\nthe window. There are no loud noises or\nsudden movements\nto disrupt\nthe\npeaceful\nstillness.",
          "Rating": "neutral"
        }
      ],
      "page": 6
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Emotion": "Joy",
          "Rule": "a desirable event\nfor Anne just happened",
          "Situation": "Anne just passed her exam.",
          "Prediction": "Joy"
        },
        {
          "Emotion": "Distress",
          "Rule": "an undesirable event\nfor Anne just happened",
          "Situation": "Anne just\nfailed her exam.",
          "Prediction": "Distress"
        },
        {
          "Emotion": "Happy for",
          "Rule": "a desirable event\nfor a friend of Anne just happened",
          "Situation": "Bruno just passed his exam. Anne and Bruno get along well.",
          "Prediction": "Happy for"
        },
        {
          "Emotion": "Pity",
          "Rule": "an undesirable event\nfor a friend of Anne just happened",
          "Situation": "Bruno just\nfailed his exam. Anne and Bruno get along well.",
          "Prediction": "Pity"
        },
        {
          "Emotion": "Gloating",
          "Rule": "an undesirable event\nfor an enemy of Anne just happened",
          "Situation": "Bruno just failed her exam. Anne and Bruno do not get along\nwell.",
          "Prediction": "Gloating"
        },
        {
          "Emotion": "Resentment",
          "Rule": "a desirable event\nfor an enemy of Anne just happened.",
          "Situation": "Bruno just passed his exam. Anne and Bruno do not get along\nwell.",
          "Prediction": "Resentment"
        },
        {
          "Emotion": "Hope",
          "Rule": "a desirable event\nfor Anne might happen in the future.",
          "Situation": "After\nstudying for weeks, Anne\nfeels\nready to take on the\nexam tomorrow.",
          "Prediction": "Hope"
        },
        {
          "Emotion": "Fear",
          "Rule": "an undesirable event\nfor Anne might happen in the future.",
          "Situation": "After studying for weeks, Anne feels not ready to take on the\nexam tomorrow.",
          "Prediction": "Fear"
        },
        {
          "Emotion": "Satisfac.",
          "Rule": "An anticipated desirable event for Anne has indeed happened.",
          "Situation": "Anne had taken the exam, being sure it would be a success.\nChecking the results now, she sees that she passed.",
          "Prediction": "Satisfaction"
        },
        {
          "Emotion": "Despair",
          "Rule": "An anticipated undesirable\nevent\nfor Anne has\nindeed hap-\npened.",
          "Situation": "Anne had taken the exam, being sure it would be a disaster.\nChecking the results now, she sees that she failed.",
          "Prediction": "Distress"
        },
        {
          "Emotion": "Relief",
          "Rule": "An anticipated undesirable event\nfor Anne did not happen.",
          "Situation": "Anne had taken the exam, being sure it would be a disaster.\nChecking the results now, she sees that she passed.",
          "Prediction": "Relief"
        },
        {
          "Emotion": "Disapp.",
          "Rule": "An anticipated desirable event\nfor Anne did not happen.",
          "Situation": "Anne had taken the exam, being sure it would be a success.\nChecking the results now, she sees that she failed.",
          "Prediction": "Distress"
        }
      ],
      "page": 7
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Affective Computing",
      "authors": [
        "R Picard"
      ],
      "year": "1997",
      "venue": "Affective Computing"
    },
    {
      "citation_id": "2",
      "title": "Affective computing: challenges",
      "year": "2003",
      "venue": "International Journal of Human-Computer Studies"
    },
    {
      "citation_id": "3",
      "title": "The Oxford Handbook of Affective Computing",
      "authors": [
        "R Calvo",
        "S D'mello",
        "J Gratch",
        "A Kappas"
      ],
      "year": "2014",
      "venue": "The Oxford Handbook of Affective Computing"
    },
    {
      "citation_id": "4",
      "title": "Context in human emotion perception for automatic affect detection: A survey of audiovisual databases",
      "authors": [
        "B Dudzik",
        "M Jansen",
        "F Burger",
        "F Kaptein",
        "J Broekens",
        "D Heylen",
        "H Hung",
        "M Neerincx",
        "K Truong"
      ],
      "year": "2019",
      "venue": "2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII)"
    },
    {
      "citation_id": "5",
      "title": "Improving language understanding by generative pre-training",
      "authors": [
        "A Radford",
        "K Narasimhan",
        "T Salimans",
        "I Sutskever"
      ],
      "year": "2018",
      "venue": "Improving language understanding by generative pre-training"
    },
    {
      "citation_id": "6",
      "title": "Attention is all you need",
      "authors": [
        "A Vaswani",
        "N Shazeer",
        "N Parmar",
        "J Uszkoreit",
        "L Jones",
        "A Gomez",
        "Ł Kaiser",
        "I Polosukhin"
      ],
      "year": "2017",
      "venue": "Advances in neural information processing systems"
    },
    {
      "citation_id": "7",
      "title": "Training language models to follow instructions with human feedback",
      "authors": [
        "L Ouyang",
        "J Wu",
        "X Jiang",
        "D Almeida",
        "C Wainwright",
        "P Mishkin",
        "C Zhang",
        "S Agarwal",
        "K Slama",
        "A Ray",
        "J Schulman",
        "J Hilton",
        "F Kelton",
        "L Miller",
        "M Simens",
        "A Askell",
        "P Welinder",
        "P Christiano",
        "J Leike",
        "R Lowe"
      ],
      "year": "2022",
      "venue": "Training language models to follow instructions with human feedback"
    },
    {
      "citation_id": "8",
      "title": "Language models are few-shot learners",
      "authors": [
        "T Brown",
        "B Mann",
        "N Ryder",
        "M Subbiah",
        "J Kaplan",
        "P Dhariwal",
        "A Neelakantan",
        "P Shyam",
        "G Sastry",
        "A Askell"
      ],
      "year": "2020",
      "venue": "Advances in neural information processing systems"
    },
    {
      "citation_id": "9",
      "title": "The cognitive structure of emotions cambridge",
      "authors": [
        "A Ortony",
        "G Clore",
        "A Collins"
      ],
      "year": "1988",
      "venue": "The cognitive structure of emotions cambridge"
    },
    {
      "citation_id": "10",
      "title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "authors": [
        "J Devlin",
        "M.-W Chang",
        "K Lee",
        "K Toutanova"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference of the North American Chapter"
    },
    {
      "citation_id": "11",
      "title": "Finetuned language models are zero-shot learners",
      "authors": [
        "J Wei",
        "M Bosma",
        "V Zhao",
        "K Guu",
        "A Yu",
        "B Lester",
        "N Du",
        "A Dai",
        "Q Le"
      ],
      "year": "2021",
      "venue": "Finetuned language models are zero-shot learners",
      "arxiv": "arXiv:2109.01652"
    },
    {
      "citation_id": "12",
      "title": "A survey of affect recognition methods: Audio, visual, and spontaneous expressions",
      "authors": [
        "Z Zeng",
        "M Pantic",
        "G Roisman",
        "T Huang"
      ],
      "year": "2009",
      "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
    },
    {
      "citation_id": "13",
      "title": "Deep learning for human affect recognition: Insights and new developments",
      "authors": [
        "P Rouast",
        "M Adam",
        "R Chiong"
      ],
      "year": "2021",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "14",
      "title": "Emotion",
      "authors": [
        "J Broekens"
      ],
      "year": "2021",
      "venue": "The Handbook on Socially Interactive Agents: 20 Years of Research on Embodied Conversational Agents, Intelligent Virtual Agents, and Social Robotics"
    },
    {
      "citation_id": "15",
      "title": "The Handbook on Socially Interactive Agents: 20 Years of Research on Embodied Conversational Agents",
      "authors": [
        "B Lugrin"
      ],
      "year": "2021",
      "venue": "Methods, Behavior, Cognition, 1st ed"
    },
    {
      "citation_id": "16",
      "title": "A review of affective computing: From unimodal analysis to multimodal fusion",
      "authors": [
        "S Poria",
        "E Cambria",
        "R Bajpai",
        "A Hussain"
      ],
      "year": "2017",
      "venue": "Information fusion"
    },
    {
      "citation_id": "17",
      "title": "State of the art: a review of sentiment analysis based on sequential transfer learning",
      "authors": [
        "J -L. Chan",
        "K Bea",
        "S Leow",
        "S Phoong",
        "W Cheng"
      ],
      "year": "2023",
      "venue": "Artificial Intelligence Review"
    },
    {
      "citation_id": "18",
      "title": "In defense of dominance: Pad usage in computational representations of affect",
      "authors": [
        "J Broekens"
      ],
      "year": "2012",
      "venue": "International Journal of Synthetic Emotions (IJSE)"
    },
    {
      "citation_id": "19",
      "title": "Affective Norms for English Text (ANET): Affective ratings of text and instruction manual",
      "authors": [
        "M Bradley",
        "P Lang"
      ],
      "year": "2007",
      "venue": "Affective Norms for English Text (ANET): Affective ratings of text and instruction manual"
    },
    {
      "citation_id": "20",
      "title": "Evidence for a three-factor theory of emotions",
      "authors": [
        "J Russell",
        "A Mehrabian"
      ],
      "year": "1977",
      "venue": "Journal of research in Personality"
    },
    {
      "citation_id": "21",
      "title": "ALMA: a layered model of affect",
      "authors": [
        "P Gebhard"
      ],
      "year": "2005",
      "venue": "Proceedings of the fourth international joint conference on Autonomous agents and multiagent systems"
    },
    {
      "citation_id": "22",
      "title": "Ema: A process model of appraisal dynamics",
      "authors": [
        "S Marsella",
        "J Gratch"
      ],
      "year": "2009",
      "venue": "Cognitive Systems Research"
    },
    {
      "citation_id": "23",
      "title": "Embodied robot models for interdisciplinary emotion research",
      "authors": [
        "L Canamero"
      ],
      "year": "2019",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "24",
      "title": "A temporal difference reinforcement learning theory of emotion: unifying emotion, cognition and adaptive behavior",
      "authors": [
        "J Broekens"
      ],
      "year": "2018",
      "venue": "A temporal difference reinforcement learning theory of emotion: unifying emotion, cognition and adaptive behavior",
      "arxiv": "arXiv:1807.08941"
    },
    {
      "citation_id": "25",
      "title": "Affective computing: A review",
      "authors": [
        "J Tao",
        "T Tan"
      ],
      "year": "2005",
      "venue": "Affective Computing and Intelligent Interaction: First International Conference, ACII 2005"
    },
    {
      "citation_id": "26",
      "title": "Gamygdala: An emotion engine for games",
      "authors": [
        "A Popescu",
        "J Broekens",
        "M Van Someren"
      ],
      "year": "2013",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "27",
      "title": "Feeling and reasoning: A computational model for emotional characters",
      "authors": [
        "J Dias",
        "A Paiva"
      ],
      "year": "2005",
      "venue": "EPIA"
    },
    {
      "citation_id": "28",
      "title": "Adapting language models for zero-shot learning by meta-tuning on dataset and prompt collections",
      "authors": [
        "R Zhong",
        "K Lee",
        "Z Zhang",
        "D Klein"
      ],
      "year": "2021",
      "venue": "Findings of the Association for Computational Linguistics: EMNLP 2021"
    },
    {
      "citation_id": "29",
      "title": "Open aspect target sentiment classification with natural language prompts",
      "authors": [
        "R Seoh",
        "I Birle",
        "M Tak",
        "H.-S Chang",
        "B Pinette",
        "A Hough"
      ],
      "year": "2021",
      "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "30",
      "title": "Will it blend? mixing training paradigms & prompting for argument quality prediction",
      "authors": [
        "M Van Der Meer",
        "M Reuver",
        "U Khurana",
        "L Krause",
        "S Santamaria"
      ],
      "year": "2022",
      "venue": "Proceedings of the 9th Workshop on Argument Mining"
    },
    {
      "citation_id": "31",
      "title": "How many data points is a prompt worth",
      "authors": [
        "Le Scao",
        "A Rush"
      ],
      "year": "2021",
      "venue": "Proceedings of the 2021 Conference of the North American Chapter"
    },
    {
      "citation_id": "32",
      "title": "Semeval-2017 task 4: Sentiment analysis in twitter",
      "authors": [
        "S Rosenthal",
        "N Farra",
        "P Nakov"
      ],
      "year": "2019",
      "venue": "Semeval-2017 task 4: Sentiment analysis in twitter",
      "arxiv": "arXiv:1912.00741"
    },
    {
      "citation_id": "33",
      "title": "Will affective computing emerge from foundation models and general ai? a first evaluation on chatgpt",
      "authors": [
        "M Amin",
        "E Cambria",
        "B Schuller"
      ],
      "year": "2023",
      "venue": "Will affective computing emerge from foundation models and general ai? a first evaluation on chatgpt"
    },
    {
      "citation_id": "34",
      "title": "Quantifying valence and arousal in text with multilingual pre-trained transformers",
      "authors": [
        "G Mendes",
        "B Martins"
      ],
      "year": "2023",
      "venue": "Advances in Information Retrieval: 45th European Conference on Information Retrieval, ECIR 2023"
    },
    {
      "citation_id": "35",
      "title": "What's in a word? language constructs emotion perception",
      "authors": [
        "K Lindquist",
        "M Gendron"
      ],
      "year": "2013",
      "venue": "Emotion Review"
    },
    {
      "citation_id": "36",
      "title": "Context in emotion perception",
      "authors": [
        "L Barrett",
        "B Mesquita",
        "M Gendron"
      ],
      "year": "2011",
      "venue": "Current directions in psychological science"
    },
    {
      "citation_id": "37",
      "title": "On the nature and function of emotion: A component process approach",
      "authors": [
        "K Scherer"
      ],
      "year": "1984",
      "venue": "Approaches to emotion"
    },
    {
      "citation_id": "38",
      "title": "Emotional experience in the computational belief-desire theory of emotion",
      "authors": [
        "R Reisenzein"
      ],
      "year": "2009",
      "venue": "Emotion Review"
    },
    {
      "citation_id": "39",
      "title": "Putting appraisal in context: Toward a relational model of appraisal and emotion",
      "authors": [
        "C Smith",
        "L Kirby"
      ],
      "year": "2009",
      "venue": "Cognition and Emotion"
    }
  ]
}