{
  "paper_id": "2504.06461v1",
  "title": "Towards Intelligent Vr Training: A Physiological Adaptation Framework For Cognitive Load And Stress Detection",
  "published": "2025-04-08T22:02:34Z",
  "authors": [
    "Mahsa Nasri"
  ],
  "keywords": [
    "Virtual Reality",
    "Machine Learning",
    "Adaptation",
    "Physiological Sensing"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Adaptive Virtual Reality (VR) systems have the potential to enhance training and learning experiences by dynamically responding to users' cognitive states. This research investigates how eye tracking and heart rate variability (HRV) can be used to detect cognitive load and stress in VR environments, enabling real-time adaptation. The study follows a three-phase approach: (1) conducting a user study with the Stroop task to label cognitive load data and train machine learning models to detect high cognitive load, (2) fine-tuning these models with new users and integrating them into an adaptive VR system that dynamically adjusts training difficulty based on physiological signals, and (3) developing a privacy-aware approach to detect high cognitive load and compare this with the adaptive VR in Phase two. This research contributes to affective computing and adaptive VR using physiological sensing, with applications in education, training, and healthcare. Future work will explore scalability, real-time inference optimization, and ethical considerations in physiological adaptive VR. \n CCS CONCEPTS • Computing methodologies → Classification and regression trees; • Human-centered computing → Virtual reality.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Related Work",
      "text": "A systematic literature review was conducted using the Web of Science database, covering ACM, IEEE, and Springer publications from 2019 to 2024 to identify research gaps in affective computing, physiological sensing, and VR design. The search combined terms related to adaptation (e.g., \"personalized,\" \"adaptive\") with biofeedback-related terms (e.g., \"EEG,\" \"GSR,\" \"eye tracking\") and \"virtual reality.\" A total of 164 papers were identified, with 117 deemed relevant after the selection of the title and abstract. After filtering, 38 papers met the inclusion criteria, focusing on real-time physiological data use rather than post-analysis.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Cognitive Load, Emotion, And Physiological",
      "text": "Responses in VR\n\nCognitive load significantly influences users' emotions, particularly stress and frustration. When cognitive demands exceed a user's working memory capacity, stress levels increase, reducing performance and engagement  [30, 39] . Physiological responses such as pupil dilation and reduced HRV correlate with high cognitive load, making them valuable signals for real-time adaptation  [22] . Additionally, cognitive overload can trigger emotional distress, leading to a feedback loop where increased stress further impairs cognitive function  [39] . Understanding these physiological responses allows computational models to detect cognitive load and dynamically adjust VR experiences to mitigate stress and enhance engagement.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Vr Adaptation Mechanisms",
      "text": "VR adaptation mechanisms can be categorized into two primary approaches: rule-based adaptation and data-driven adaptation. Rule-Based Adaptation: These approaches use predefined heuristics to modify VR parameters such as task difficulty, environmental features, and interaction mechanics. Some studies adjust difficulty dynamically to maintain engagement by modifying complexity  [5, 11, 19] . Others adapt experience mechanics by altering users' virtual positions or modifying stimulus characteristics  [1, 3, 41] . Environmental adaptations, such as adjusting colors or introducing elements like fog, also play a role in immersive adaptation  [14, 16, 31] .\n\nData-Driven Adaptation: More recent approaches integrate physiological and behavioral data to adapt experiences. These models leverage physiological signals such as heart rate, EEG, and eye tracking to infer user state and modify the environment accordingly. For instance, Baldini et al.  [3]  developed a VR system that mitigates cybersickness by adapting navigation speed and scene complexity based on EEG signals. Some studies use NPC behavior adaptation, such as streamlining NPC interactions based on user responses  [7, 8] . While these adaptation mechanisms enhance immersion, most rely on predefined heuristics. To enhance adaptability, computational models that leverage real-time physiological sensing have been explored.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Computational Models For Adaptive Vr",
      "text": "Computational models for adaptation in VR fall into two primary categories: direct physiological adaptation and ML-based adaptation. Direct Physiological Adaptation: Some studies use real-time physiological signals to trigger immediate environmental changes. For example, changes in electrodermal activity (EDA) can adjust lighting or soundscapes in VR relaxation scenarios  [26, 33] . Other systems use gaze behavior to provide adaptive hints in training applications  [12] .\n\nML-Based Adaptation: More advanced models use machine learning to predict user states and adapt experiences. However, few studies have implemented real-time physiological adaptation using ML  [1, 15, 18, 32, 41] . Existing models primarily focus on arousal detection but lack multimodal emotion recognition. Techniques such as artificial neural networks (ANN), support vector machines (SVM), and random forests have been used to extract features from physiological signals and optimize virtual environments  [10, 17, 19, 21] . Despite these advancements, real-time physiological adaptation remains an underexplored area, particularly in privacy-aware adaptive systems.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Privacy And Ethical Concerns In Physiological Adaptation",
      "text": "While physiological adaptation offers promising ways to enhance VR experiences, ethical concerns remain largely unaddressed. The collection and processing of real-time physiological data raise privacy concerns, particularly regarding data security, user consent, and potential misuse  [8, 42] . None of the studies propose frameworks for privacy-aware physiological adaptation, leaving a critical gap in the field.\n\nResearch Gap: There is a need for adaptive VR systems that not only integrate physiological data for real-time adaptation but also prioritize privacy considerations. This research aims to develop a privacy-aware physiological adaptation framework that detects cognitive load and dynamically adjusts VR training experiences in real time.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Research Goals And Methodology",
      "text": "The first goal is to develop machine learning models using eyetracking and heart rate data to detect stress caused by high cognitive load. The VR system then adapts the experience to maintain an optimal cognitive state. Another goal is to create privacy-aware physiological sensing frameworks that respect user data while ensuring adaptability. The final step is to evaluate the effectiveness of adaptive VR in preventing high cognitive load and improving learning. This research seeks to answer the following questions, and the next sections are the approaches to solving them.\n\nResearch Questions:\n\n• RQ1: What physiological signals and computational models are currently used to detect and classify users' emotional states in VR? • RQ2: What design principles should guide the development of user-centered physiological adaptive VR systems? • RQ3: How do privacy-aware cognitive load detection methods impact the effectiveness of adaptive VR systems compared to direct physiological signal-based approaches?\n\nThese research questions follow a three-phase approach:",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Phase 1: Cognitive Load Detection Using Physiological Signals",
      "text": "The first phase involves conducting a user study to collect physiological data and establish cognitive load as ground truth using the Stroop task. First, in a calibration room, participants' baselines will be recorded  [20] . Then, participants' physiological responses will be recorded while completing the Stroop task, and supervised learning models will be trained based on these labeled data. Next, participants enter the VR training, where we collect their eye tracking and heart rate. After the user study, we analyze the data and train our ML model to predict high and low cognitive load (Fig.  1 .) Stroop task is widely used in cognitive research due to its ability to induce controlled levels of mental workload  [38] . Alternative techniques, such as n-back tasks, also measure cognitive load but focus more on working memory rather than response inhibition and attentional control  [25] . Physiological signals, including eye tracking and heart rate variability, will be collected during the study. Eye tracking provides insights into cognitive processing through metrics like pupil dilation, fixation duration, and fixation count  [13] . Increased pupil dilation and prolonged fixations are linked to higher cognitive load  [24] . HRV is a well-established physiological marker of autonomic nervous system activity and cognitive effort  [40] . Decreased HRV correlates with stress and high workload, making it a reliable indicator for adaptation in VR environments  [22] .",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Phase 2: Machine Learning-Based Real-Time Adaptation",
      "text": "In the second phase, the trained models from Phase 1 will be finetuned using Stroop task data from new users. Once refined, these models will be integrated into the adaptive VR system, where realtime physiological signals will dynamically adjust task difficulty.\n\nParticipants will be assigned to either an adaptive VR or regular VR group. The adaptive VR system will continuously adjust based on cognitive load detection, while the regular group will manually request hints. To evaluate the system, we will use other measures, such as NASA-TLX to assess overall mental workload, presence questionnaire to measure immersion, and a system usability scale for user experience evaluation. Performance metrics will include task completion time, error rate, and VR logs, such as the number of hints requested. Data collection will involve both physiological and self-reported measures to ensure a comprehensive evaluation.\n\nGiven the success of Multilayer Perceptron and Random Forest in prior work  [28] , these models will be used for classification. RF is known for its robustness with small datasets and high interpretability  [6] , while MLP captures complex non-linear relationships in physiological data  [23] . Performance will be evaluated using accuracy, F1-score, and AUC-ROC. The models will be fine-tuned with Stroop task data from new users before being deployed in the adaptive VR system where training difficulty dynamically adjusts based on cognitive load (Fig.  2 .)",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Phase 3: Privacy-Aware Cognitive Load Detection",
      "text": "The third phase of this research focuses on developing and evaluating a privacy-aware approach for cognitive load detection in adaptive VR systems. While eye tracking is a powerful tool for inferring cognitive states, the raw data-such as exact gaze coordinates, scanpaths, and fixation patterns-can inadvertently reveal sensitive personal information, including emotional responses, interests, intent, and even medical conditions. This raises concerns about user consent, data ownership, and the potential misuse of identifiable behavioral patterns. To address these concerns, this phase will explore feature abstraction methods that reduce privacy risks while maintaining model performance. For instance, we will investigate the use of gaze entropy, which provides a higher-level summary of gaze behavior without storing raw gaze coordinates, alongside other aggregate features such as fixation counts and dwell time distributions. These features aim to protect user privacy by making it harder to reverse-engineer identity or intent from the data. In this phase, a user study will be conducted using the Stroop task to label cognitive load data, as in previous phases. Participants' physiological responses will be recorded during task completion to establish ground truth. The collected data will then be used to compare the performance of cognitive load detection models that use privacy-aware features against those that rely on direct raw eye tracking data. We will deploy both models in two versions of an adaptive VR system and evaluate their effectiveness based on cognitive load classification accuracy, user performance metrics (completion time, error rates, number of hints), and subjective workload assessment (NASA-TLX). The goal is to determine whether the privacy-aware model can maintain comparable accuracy in detecting cognitive load and adapting the VR experience, thereby balancing personalization and ethical data use.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Results To Date",
      "text": "To date, I have co-designed and evaluated VR environments for advanced manufacturing training, particularly in cold spray technology  [29] . In another effort, I developed ML models using eye tracking metrics, including pupil dilation and fixation duration, to classify mental workload  [28] . The dataset consisted of 19 participants, with 10 labeled as experiencing high cognitive load and 9 as low, based on the mental demand subsection of the NASA-TLX.\n\nAlthough the class distribution was close to balanced, we used 3fold cross-validation during model training to reduce the risk of overfitting and ensure a robust evaluation of model performance.\n\nOur results indicate that the MLP model achieved an accuracy and precision of 0.84, indicating that the RF model reached an accuracy of 0.72 and a precision of 0.73, suggesting reasonable performance but with some overfitting compared to the MLP model. More details are depicted in Table  1 .\n\nCurrently, I am developing a privacy-aware approach leveraging eye tracking and gaze data to classify cognitive load. In this approach, I am implementing gaze entropy  [35]  alongside user behavior metrics (e.g., completion time and error rate) to classify users with high and low cognitive load.    This PhD consortium will provide invaluable feedback on my research direction, help me refine methodologies, and connect me with user modeling experts in VR and machine learning. Participating in ACM UMAP 2025 will enhance the impact of my work and ensure that my contributions align with cutting-edge research in physiological adaptive systems.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Supervisors And Phd Program",
      "text": "",
      "page_start": 4,
      "page_end": 4
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Phase 1: Initial data collection pipeline where users undergo VR calibration, including baseline measurements and the Stroop task,",
      "page": 4
    },
    {
      "caption": "Figure 2: Phase 2: Adaptive VR system where trained models are fine-tuned, real-time task difficulty is adjusted based on",
      "page": 4
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "This research aims to develop a physiological adaptation frame-": ""
        },
        {
          "This research aims to develop a physiological adaptation frame-": "work based on cognitive load detection that adjusts VR training"
        },
        {
          "This research aims to develop a physiological adaptation frame-": "difficulty in real time. Specifically, this study:"
        },
        {
          "This research aims to develop a physiological adaptation frame-": ""
        },
        {
          "This research aims to develop a physiological adaptation frame-": "• Develops a machine learning-based model using HRV and"
        },
        {
          "This research aims to develop a physiological adaptation frame-": ""
        },
        {
          "This research aims to develop a physiological adaptation frame-": "eye-tracking data to detect cognitive load and emotional"
        },
        {
          "This research aims to develop a physiological adaptation frame-": ""
        },
        {
          "This research aims to develop a physiological adaptation frame-": "stress."
        },
        {
          "This research aims to develop a physiological adaptation frame-": "• Conducts a three-phase user study to train and fine-tune ML"
        },
        {
          "This research aims to develop a physiological adaptation frame-": ""
        },
        {
          "This research aims to develop a physiological adaptation frame-": "models using the Stroop task as ground truth."
        },
        {
          "This research aims to develop a physiological adaptation frame-": ""
        },
        {
          "This research aims to develop a physiological adaptation frame-": "• Evaluates the efficiency of adaptive VR on user learning, en-"
        },
        {
          "This research aims to develop a physiological adaptation frame-": "gagement, and stress mitigation compared to privacy-aware"
        },
        {
          "This research aims to develop a physiological adaptation frame-": ""
        },
        {
          "This research aims to develop a physiological adaptation frame-": "adaptive and regular VR."
        },
        {
          "This research aims to develop a physiological adaptation frame-": ""
        },
        {
          "This research aims to develop a physiological adaptation frame-": "By addressing the interplay between cognitive load, emotions,"
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "nasri.m@northeastern.edu": ""
        },
        {
          "nasri.m@northeastern.edu": ""
        },
        {
          "nasri.m@northeastern.edu": ""
        },
        {
          "nasri.m@northeastern.edu": "ABSTRACT"
        },
        {
          "nasri.m@northeastern.edu": ""
        },
        {
          "nasri.m@northeastern.edu": "Adaptive Virtual Reality (VR) systems have the potential to enhance"
        },
        {
          "nasri.m@northeastern.edu": ""
        },
        {
          "nasri.m@northeastern.edu": "training and learning experiences by dynamically responding to"
        },
        {
          "nasri.m@northeastern.edu": ""
        },
        {
          "nasri.m@northeastern.edu": "users’ cognitive states. This research investigates how eye tracking"
        },
        {
          "nasri.m@northeastern.edu": ""
        },
        {
          "nasri.m@northeastern.edu": "and heart rate variability (HRV) can be used to detect cognitive"
        },
        {
          "nasri.m@northeastern.edu": ""
        },
        {
          "nasri.m@northeastern.edu": "load and stress in VR environments, enabling real-time adaptation."
        },
        {
          "nasri.m@northeastern.edu": ""
        },
        {
          "nasri.m@northeastern.edu": "The study follows a three-phase approach: (1) conducting a user"
        },
        {
          "nasri.m@northeastern.edu": ""
        },
        {
          "nasri.m@northeastern.edu": "study with the Stroop task to label cognitive load data and train ma-"
        },
        {
          "nasri.m@northeastern.edu": ""
        },
        {
          "nasri.m@northeastern.edu": "chine learning models to detect high cognitive load, (2) fine-tuning"
        },
        {
          "nasri.m@northeastern.edu": ""
        },
        {
          "nasri.m@northeastern.edu": "these models with new users and integrating them into an adaptive"
        },
        {
          "nasri.m@northeastern.edu": ""
        },
        {
          "nasri.m@northeastern.edu": "VR system that dynamically adjusts training difficulty based on"
        },
        {
          "nasri.m@northeastern.edu": ""
        },
        {
          "nasri.m@northeastern.edu": "physiological signals, and (3) developing a privacy-aware approach"
        },
        {
          "nasri.m@northeastern.edu": ""
        },
        {
          "nasri.m@northeastern.edu": "to detect high cognitive load and compare this with the adaptive"
        },
        {
          "nasri.m@northeastern.edu": ""
        },
        {
          "nasri.m@northeastern.edu": "VR in Phase two. This research contributes to affective computing"
        },
        {
          "nasri.m@northeastern.edu": ""
        },
        {
          "nasri.m@northeastern.edu": "and adaptive VR using physiological sensing, with applications in"
        },
        {
          "nasri.m@northeastern.edu": ""
        },
        {
          "nasri.m@northeastern.edu": "education, training, and healthcare. Future work will explore scala-"
        },
        {
          "nasri.m@northeastern.edu": ""
        },
        {
          "nasri.m@northeastern.edu": "bility, real-time inference optimization, and ethical considerations"
        },
        {
          "nasri.m@northeastern.edu": ""
        },
        {
          "nasri.m@northeastern.edu": "in physiological adaptive VR."
        },
        {
          "nasri.m@northeastern.edu": ""
        },
        {
          "nasri.m@northeastern.edu": ""
        },
        {
          "nasri.m@northeastern.edu": "CCS CONCEPTS"
        },
        {
          "nasri.m@northeastern.edu": ""
        },
        {
          "nasri.m@northeastern.edu": "• Computing methodologies → Classification and regression"
        },
        {
          "nasri.m@northeastern.edu": ""
        },
        {
          "nasri.m@northeastern.edu": "trees; • Human-centered computing → Virtual reality."
        },
        {
          "nasri.m@northeastern.edu": ""
        },
        {
          "nasri.m@northeastern.edu": ""
        },
        {
          "nasri.m@northeastern.edu": "KEYWORDS"
        },
        {
          "nasri.m@northeastern.edu": ""
        },
        {
          "nasri.m@northeastern.edu": "Virtual Reality, Machine Learning, Adaptation, Physiological Sens-"
        },
        {
          "nasri.m@northeastern.edu": ""
        },
        {
          "nasri.m@northeastern.edu": "ing"
        },
        {
          "nasri.m@northeastern.edu": ""
        },
        {
          "nasri.m@northeastern.edu": "ACM Reference Format:"
        },
        {
          "nasri.m@northeastern.edu": "Mahsa Nasri. 2025. Towards Intelligent VR Training: A Physiological Adap-"
        },
        {
          "nasri.m@northeastern.edu": "tation Framework for Cognitive Load and Stress Detection.\nIn Proceed-"
        },
        {
          "nasri.m@northeastern.edu": "ings of 33rd ACM International Conference on User Modeling, Adaptation"
        },
        {
          "nasri.m@northeastern.edu": "and Personalization (UMAP). ACM, New York, NY, USA, 5 pages. https:"
        },
        {
          "nasri.m@northeastern.edu": "//doi.org/XXXXXXX.XXXXXXX"
        },
        {
          "nasri.m@northeastern.edu": ""
        },
        {
          "nasri.m@northeastern.edu": ""
        },
        {
          "nasri.m@northeastern.edu": "1\nINTRODUCTION"
        },
        {
          "nasri.m@northeastern.edu": ""
        },
        {
          "nasri.m@northeastern.edu": "Virtual Reality (VR) is more than a technological advancement—it is"
        },
        {
          "nasri.m@northeastern.edu": "a transformative medium that redefines how we perceive, interact"
        },
        {
          "nasri.m@northeastern.edu": ""
        },
        {
          "nasri.m@northeastern.edu": "with, and adapt to digital environments. VR provides an immer-"
        },
        {
          "nasri.m@northeastern.edu": ""
        },
        {
          "nasri.m@northeastern.edu": "sive, safe, and credible simulation of real-life training environments"
        },
        {
          "nasri.m@northeastern.edu": ""
        },
        {
          "nasri.m@northeastern.edu": "Permission to make digital or hard copies of all or part of this work for personal or"
        },
        {
          "nasri.m@northeastern.edu": "classroom use is granted without fee provided that copies are not made or distributed"
        },
        {
          "nasri.m@northeastern.edu": ""
        },
        {
          "nasri.m@northeastern.edu": "for profit or commercial advantage and that copies bear this notice and the full citation"
        },
        {
          "nasri.m@northeastern.edu": "on the first page. Copyrights for components of this work owned by others than the"
        },
        {
          "nasri.m@northeastern.edu": "author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or"
        },
        {
          "nasri.m@northeastern.edu": "republish, to post on servers or to redistribute to lists, requires prior specific permission"
        },
        {
          "nasri.m@northeastern.edu": ""
        },
        {
          "nasri.m@northeastern.edu": "and/or a fee. Request permissions from permissions@acm.org."
        },
        {
          "nasri.m@northeastern.edu": "UMAP, June 16–19, 2025, NYC, NY"
        },
        {
          "nasri.m@northeastern.edu": "© 2025 Copyright held by the owner/author(s). Publication rights licensed to ACM."
        },
        {
          "nasri.m@northeastern.edu": ""
        },
        {
          "nasri.m@northeastern.edu": "ACM ISBN 978-1-4503-XXXX-X/2018/06. . . $15.00"
        },
        {
          "nasri.m@northeastern.edu": "https://doi.org/XXXXXXX.XXXXXXX"
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "UMAP, June 16–19, 2025, NYC, NY": "2\nRELATED WORK",
          "Mahsa Nasri": "Direct Physiological Adaptation: Some studies use real-time"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "",
          "Mahsa Nasri": "physiological signals to trigger immediate environmental changes."
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "A systematic literature review was conducted using the Web of",
          "Mahsa Nasri": ""
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "",
          "Mahsa Nasri": "For example, changes in electrodermal activity (EDA) can adjust"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "Science database, covering ACM, IEEE, and Springer publications",
          "Mahsa Nasri": ""
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "",
          "Mahsa Nasri": "lighting or soundscapes in VR relaxation scenarios [26, 33]. Other"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "from 2019 to 2024 to identify research gaps in affective comput-",
          "Mahsa Nasri": ""
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "",
          "Mahsa Nasri": "systems use gaze behavior to provide adaptive hints in training"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "ing, physiological sensing, and VR design. The search combined",
          "Mahsa Nasri": ""
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "",
          "Mahsa Nasri": "applications [12]."
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "terms related to adaptation (e.g., \"personalized,\" \"adaptive\") with",
          "Mahsa Nasri": ""
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "biofeedback-related terms (e.g., \"EEG,\" \"GSR,\" \"eye tracking\") and",
          "Mahsa Nasri": "ML-Based Adaptation: More advanced models use machine"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "",
          "Mahsa Nasri": "learning to predict user states and adapt experiences. However, few"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "\"virtual reality.\" A total of 164 papers were identified, with 117",
          "Mahsa Nasri": ""
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "",
          "Mahsa Nasri": "studies have implemented real-time physiological adaptation using"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "deemed relevant after the selection of the title and abstract. After",
          "Mahsa Nasri": ""
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "",
          "Mahsa Nasri": "ML [1, 15, 18, 32, 41]. Existing models primarily focus on arousal de-"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "filtering, 38 papers met the inclusion criteria, focusing on real-time",
          "Mahsa Nasri": ""
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "",
          "Mahsa Nasri": "tection but lack multimodal emotion recognition. Techniques such"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "physiological data use rather than post-analysis.",
          "Mahsa Nasri": ""
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "",
          "Mahsa Nasri": "as artificial neural networks (ANN), support vector machines (SVM),"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "",
          "Mahsa Nasri": "and random forests have been used to extract features from physio-"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "2.1\nCognitive Load, Emotion, and Physiological",
          "Mahsa Nasri": ""
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "",
          "Mahsa Nasri": "logical signals and optimize virtual environments [10, 17, 19, 21]."
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "Responses in VR",
          "Mahsa Nasri": "Despite these advancements, real-time physiological adaptation"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "Cognitive load significantly influences users’ emotions, particularly",
          "Mahsa Nasri": "remains an underexplored area, particularly in privacy-aware adap-"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "stress and frustration. When cognitive demands exceed a user’s",
          "Mahsa Nasri": "tive systems."
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "working memory capacity, stress levels increase, reducing perfor-",
          "Mahsa Nasri": ""
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "mance and engagement [30, 39]. Physiological responses such as",
          "Mahsa Nasri": ""
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "",
          "Mahsa Nasri": "2.4\nPrivacy and Ethical Concerns in"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "pupil dilation and reduced HRV correlate with high cognitive load,",
          "Mahsa Nasri": ""
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "making them valuable signals for real-time adaptation [22]. Addi-",
          "Mahsa Nasri": "Physiological Adaptation"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "tionally, cognitive overload can trigger emotional distress, leading",
          "Mahsa Nasri": "While physiological adaptation offers promising ways to enhance"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "to a feedback loop where increased stress further impairs cognitive",
          "Mahsa Nasri": "VR experiences, ethical concerns remain largely unaddressed. The"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "function [39]. Understanding these physiological responses allows",
          "Mahsa Nasri": "collection and processing of real-time physiological data raise pri-"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "computational models to detect cognitive load and dynamically",
          "Mahsa Nasri": "vacy concerns, particularly regarding data security, user consent,"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "adjust VR experiences to mitigate stress and enhance engagement.",
          "Mahsa Nasri": "and potential misuse [8, 42]. None of the studies propose frame-"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "",
          "Mahsa Nasri": "works for privacy-aware physiological adaptation, leaving a critical"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "",
          "Mahsa Nasri": "gap in the field."
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "2.2\nVR Adaptation Mechanisms",
          "Mahsa Nasri": ""
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "",
          "Mahsa Nasri": "Research Gap: There is a need for adaptive VR systems that not"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "VR adaptation mechanisms can be categorized into two primary",
          "Mahsa Nasri": ""
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "",
          "Mahsa Nasri": "only integrate physiological data for real-time adaptation but also"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "approaches: rule-based adaptation and data-driven adaptation.",
          "Mahsa Nasri": ""
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "",
          "Mahsa Nasri": "prioritize privacy considerations. This research aims to develop"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "Rule-Based Adaptation: These approaches use predefined",
          "Mahsa Nasri": ""
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "",
          "Mahsa Nasri": "a privacy-aware physiological adaptation framework that detects"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "heuristics to modify VR parameters such as task difficulty, envi-",
          "Mahsa Nasri": ""
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "",
          "Mahsa Nasri": "cognitive load and dynamically adjusts VR training experiences in"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "ronmental features, and interaction mechanics. Some studies ad-",
          "Mahsa Nasri": ""
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "",
          "Mahsa Nasri": "real time."
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "just difficulty dynamically to maintain engagement by modifying",
          "Mahsa Nasri": ""
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "complexity [5, 11, 19]. Others adapt experience mechanics by alter-",
          "Mahsa Nasri": ""
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "ing users’ virtual positions or modifying stimulus characteristics",
          "Mahsa Nasri": "3\nRESEARCH GOALS AND METHODOLOGY"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "[1, 3, 41]. Environmental adaptations, such as adjusting colors or in-",
          "Mahsa Nasri": "The first goal\nis to develop machine learning models using eye-"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "troducing elements like fog, also play a role in immersive adaptation",
          "Mahsa Nasri": "tracking and heart rate data to detect stress caused by high cogni-"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "[14, 16, 31].",
          "Mahsa Nasri": "tive load. The VR system then adapts the experience to maintain"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "Data-Driven Adaptation: More recent approaches integrate",
          "Mahsa Nasri": "an optimal cognitive state. Another goal is to create privacy-aware"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "physiological and behavioral data to adapt experiences. These mod-",
          "Mahsa Nasri": "physiological sensing frameworks that respect user data while en-"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "els leverage physiological signals such as heart rate, EEG, and eye",
          "Mahsa Nasri": "suring adaptability. The final step is to evaluate the effectiveness"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "tracking to infer user state and modify the environment accordingly.",
          "Mahsa Nasri": "of adaptive VR in preventing high cognitive load and improving"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "For instance, Baldini et al. [3] developed a VR system that mitigates",
          "Mahsa Nasri": "learning. This research seeks to answer the following questions,"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "cybersickness by adapting navigation speed and scene complexity",
          "Mahsa Nasri": "and the next sections are the approaches to solving them."
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "based on EEG signals. Some studies use NPC behavior adaptation,",
          "Mahsa Nasri": ""
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "",
          "Mahsa Nasri": "Research Questions:"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "such as streamlining NPC interactions based on user responses",
          "Mahsa Nasri": ""
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "[7, 8]. While these adaptation mechanisms enhance immersion,",
          "Mahsa Nasri": "• RQ1: What physiological signals and computational models"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "most rely on predefined heuristics. To enhance adaptability, compu-",
          "Mahsa Nasri": "are currently used to detect and classify users’ emotional"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "tational models that leverage real-time physiological sensing have",
          "Mahsa Nasri": "states in VR?"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "been explored.",
          "Mahsa Nasri": "• RQ2: What design principles should guide the development"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "",
          "Mahsa Nasri": "of user-centered physiological adaptive VR systems?"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "",
          "Mahsa Nasri": "• RQ3: How do privacy-aware cognitive load detection meth-"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "2.3\nComputational Models for Adaptive VR",
          "Mahsa Nasri": ""
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "",
          "Mahsa Nasri": "ods impact the effectiveness of adaptive VR systems com-"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "Computational models for adaptation in VR fall into two primary",
          "Mahsa Nasri": ""
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "",
          "Mahsa Nasri": "pared to direct physiological signal-based approaches?"
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "categories: direct physiological adaptation and ML-based adap-",
          "Mahsa Nasri": ""
        },
        {
          "UMAP, June 16–19, 2025, NYC, NY": "tation.",
          "Mahsa Nasri": ""
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "3.1\nPhase 1: Cognitive Load Detection Using\n3.3\nPhase 3: Privacy-Aware Cognitive Load"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "Physiological Signals\nDetection"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "The first phase involves conducting a user study to collect phys-\nThe third phase of this research focuses on developing and eval-"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "iological data and establish cognitive load as ground truth using\nuating a privacy-aware approach for cognitive load detection in"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "the Stroop task. First, in a calibration room, participants’ baselines"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "will be recorded [20]. Then, participants’ physiological responses\ninferring cognitive states, the raw data—such as exact gaze coordi-"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "will be recorded while completing the Stroop task, and supervised\nnates, scanpaths, and fixation patterns—can inadvertently reveal"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "learning models will be trained based on these labeled data. Next,\nsensitive personal information, including emotional responses, in-"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "participants enter the VR training, where we collect their eye track-\nterests, intent, and even medical conditions. This raises concerns"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "ing and heart rate. After the user study, we analyze the data and\nabout user consent, data ownership, and the potential misuse of"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "train our ML model to predict high and low cognitive load (Fig. 1.)\nidentifiable behavioral patterns. To address these concerns, this"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "Stroop task is widely used in cognitive research due to its ability\nphase will explore feature abstraction methods that reduce privacy"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "to induce controlled levels of mental workload [38]. Alternative\nrisks while maintaining model performance. For instance, we will"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "investigate the use of gaze entropy, which provides a higher-level"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "focus more on working memory rather than response inhibition\nsummary of gaze behavior without storing raw gaze coordinates,"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "and attentional control [25].\nalongside other aggregate features such as fixation counts and dwell"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "Physiological signals, including eye tracking and heart rate vari-"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "ability, will be collected during the study. Eye tracking provides"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "insights into cognitive processing through metrics like pupil di-\ndata. In this phase, a user study will be conducted using the Stroop"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "lation, fixation duration, and fixation count [13]. Increased pupil\ntask to label cognitive load data, as in previous phases. Participants’"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "dilation and prolonged fixations are linked to higher cognitive load\nphysiological responses will be recorded during task completion"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "[24]. HRV is a well-established physiological marker of autonomic\nto establish ground truth. The collected data will then be used to"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "nervous system activity and cognitive effort [40]. Decreased HRV\ncompare the performance of cognitive load detection models that"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "correlates with stress and high workload, making it a reliable indi-\nuse privacy-aware features against those that rely on direct raw"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "cator for adaptation in VR environments [22].\neye tracking data. We will deploy both models in two versions of"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "an adaptive VR system and evaluate their effectiveness based on"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "cognitive load classification accuracy, user performance metrics"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "(completion time, error rates, number of hints), and subjective work-"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "load assessment (NASA-TLX). The goal\nis to determine whether"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "the privacy-aware model can maintain comparable accuracy in"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "detecting cognitive load and adapting the VR experience, thereby"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "balancing personalization and ethical data use."
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "3.2\nPhase 2: Machine Learning-Based Real-Time"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "Adaptation"
        }
      ],
      "page": 3
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Figure 2: Phase 2: Adaptive VR system where trained models are fine-tuned, real-time task difficulty is adjusted based on": "cognitive load detection, and machine learning models are updated iteratively for improved adaptation."
        },
        {
          "Figure 2: Phase 2: Adaptive VR system where trained models are fine-tuned, real-time task difficulty is adjusted based on": "Table 1: Performance of MLP and RF models for predicting"
        },
        {
          "Figure 2: Phase 2: Adaptive VR system where trained models are fine-tuned, real-time task difficulty is adjusted based on": ""
        },
        {
          "Figure 2: Phase 2: Adaptive VR system where trained models are fine-tuned, real-time task difficulty is adjusted based on": "cognitive load using fixation duration and mean pupil di-"
        },
        {
          "Figure 2: Phase 2: Adaptive VR system where trained models are fine-tuned, real-time task difficulty is adjusted based on": "lation. The dataset included 19 participants (10 high, 9 low"
        },
        {
          "Figure 2: Phase 2: Adaptive VR system where trained models are fine-tuned, real-time task difficulty is adjusted based on": "cognitive load). Although the class distribution was nearly"
        },
        {
          "Figure 2: Phase 2: Adaptive VR system where trained models are fine-tuned, real-time task difficulty is adjusted based on": ""
        },
        {
          "Figure 2: Phase 2: Adaptive VR system where trained models are fine-tuned, real-time task difficulty is adjusted based on": "balanced, we used cross-validation to reduce the risk of bias"
        },
        {
          "Figure 2: Phase 2: Adaptive VR system where trained models are fine-tuned, real-time task difficulty is adjusted based on": ""
        },
        {
          "Figure 2: Phase 2: Adaptive VR system where trained models are fine-tuned, real-time task difficulty is adjusted based on": "in performance estimates."
        },
        {
          "Figure 2: Phase 2: Adaptive VR system where trained models are fine-tuned, real-time task difficulty is adjusted based on": ""
        },
        {
          "Figure 2: Phase 2: Adaptive VR system where trained models are fine-tuned, real-time task difficulty is adjusted based on": ""
        },
        {
          "Figure 2: Phase 2: Adaptive VR system where trained models are fine-tuned, real-time task difficulty is adjusted based on": "Model\nAccuracy\nPrecision\nRecall\nF1"
        },
        {
          "Figure 2: Phase 2: Adaptive VR system where trained models are fine-tuned, real-time task difficulty is adjusted based on": ""
        },
        {
          "Figure 2: Phase 2: Adaptive VR system where trained models are fine-tuned, real-time task difficulty is adjusted based on": "MLP\n0.84\n0.84\n0.94\n0.88"
        },
        {
          "Figure 2: Phase 2: Adaptive VR system where trained models are fine-tuned, real-time task difficulty is adjusted based on": ""
        },
        {
          "Figure 2: Phase 2: Adaptive VR system where trained models are fine-tuned, real-time task difficulty is adjusted based on": "RF\n0.72\n0.73\n0.90\n0.81"
        },
        {
          "Figure 2: Phase 2: Adaptive VR system where trained models are fine-tuned, real-time task difficulty is adjusted based on": ""
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Dissemination Plan": "• Spring 2025: Finalize VR environment development, con-",
          "tutoring systems.": ""
        },
        {
          "Dissemination Plan": "duct Phase 1 user study, collect physiological data (N=25",
          "tutoring systems.": ""
        },
        {
          "Dissemination Plan": "",
          "tutoring systems.": "REFERENCES"
        },
        {
          "Dissemination Plan": "participants, ensuring at least 90% usable physiological record-",
          "tutoring systems.": "[1] Andrea Apicella, Pasquale Arpaia, Simone Barbato, Giovanni D’Errico, Giovanna"
        },
        {
          "Dissemination Plan": "ings, submit findings to CHI and ETRA).",
          "tutoring systems.": "Mastrati, Nicola Moccaldi, Ersilia Vallefuoco, and Selina Christin Wriessnegger."
        },
        {
          "Dissemination Plan": "",
          "tutoring systems.": "2024. Domain Adaptation for Fear of Heights Classification in a VR Environment"
        },
        {
          "Dissemination Plan": "• Summer 2025: Train ML models for cognitive load detection",
          "tutoring systems.": ""
        },
        {
          "Dissemination Plan": "",
          "tutoring systems.": "Based on EEG and ECG.\nInformation Systems Frontiers (2024), 1–16."
        },
        {
          "Dissemination Plan": "(targeting at least 80% accuracy on unseen participants, submit",
          "tutoring systems.": ""
        },
        {
          "Dissemination Plan": "",
          "tutoring systems.": "Jeremy Bailenson. 2018. Experience on demand: What virtual reality is, how it"
        },
        {
          "Dissemination Plan": "findings to IEEE VR, UMAP).",
          "tutoring systems.": "works, and what it can do. WW Norton & Company."
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "(targeting acceptance at a top-tier venue such as CHI, UMAP).": ""
        },
        {
          "(targeting acceptance at a top-tier venue such as CHI, UMAP).": "• Fall 2026: Write and defend dissertation, develop recommen-"
        },
        {
          "(targeting acceptance at a top-tier venue such as CHI, UMAP).": ""
        },
        {
          "(targeting acceptance at a top-tier venue such as CHI, UMAP).": "dations for scaling adaptive VR in real-world applications."
        },
        {
          "(targeting acceptance at a top-tier venue such as CHI, UMAP).": "This PhD consortium will provide invaluable feedback on my"
        },
        {
          "(targeting acceptance at a top-tier venue such as CHI, UMAP).": "research direction, help me refine methodologies, and connect me"
        },
        {
          "(targeting acceptance at a top-tier venue such as CHI, UMAP).": "with user modeling experts in VR and machine learning. Participat-"
        },
        {
          "(targeting acceptance at a top-tier venue such as CHI, UMAP).": "ing in ACM UMAP 2025 will enhance the impact of my work and"
        },
        {
          "(targeting acceptance at a top-tier venue such as CHI, UMAP).": "ensure that my contributions align with cutting-edge research in"
        },
        {
          "(targeting acceptance at a top-tier venue such as CHI, UMAP).": "physiological adaptive systems."
        },
        {
          "(targeting acceptance at a top-tier venue such as CHI, UMAP).": ""
        },
        {
          "(targeting acceptance at a top-tier venue such as CHI, UMAP).": ""
        },
        {
          "(targeting acceptance at a top-tier venue such as CHI, UMAP).": "5.2\nSupervisors and PhD Program"
        },
        {
          "(targeting acceptance at a top-tier venue such as CHI, UMAP).": ""
        },
        {
          "(targeting acceptance at a top-tier venue such as CHI, UMAP).": "I am conducting this research under the supervision of Dr. Casper"
        },
        {
          "(targeting acceptance at a top-tier venue such as CHI, UMAP).": ""
        },
        {
          "(targeting acceptance at a top-tier venue such as CHI, UMAP).": "Harteveld and Dr. Leanne Chukoskie at Northeastern University,"
        },
        {
          "(targeting acceptance at a top-tier venue such as CHI, UMAP).": ""
        },
        {
          "(targeting acceptance at a top-tier venue such as CHI, UMAP).": "Boston, Massachusetts. I am a PhD student at the College of Art Me-"
        },
        {
          "(targeting acceptance at a top-tier venue such as CHI, UMAP).": ""
        },
        {
          "(targeting acceptance at a top-tier venue such as CHI, UMAP).": "dia and Design in the Interdisciplinary Media and Design program,"
        },
        {
          "(targeting acceptance at a top-tier venue such as CHI, UMAP).": ""
        },
        {
          "(targeting acceptance at a top-tier venue such as CHI, UMAP).": "which I am interdisciplinary between Computer Science and VR"
        },
        {
          "(targeting acceptance at a top-tier venue such as CHI, UMAP).": "Design. My research has been funded by NSF grant focusing on de-"
        },
        {
          "(targeting acceptance at a top-tier venue such as CHI, UMAP).": ""
        },
        {
          "(targeting acceptance at a top-tier venue such as CHI, UMAP).": "veloping adaptive learning extended reality system and intelligent"
        },
        {
          "(targeting acceptance at a top-tier venue such as CHI, UMAP).": "tutoring systems."
        },
        {
          "(targeting acceptance at a top-tier venue such as CHI, UMAP).": ""
        },
        {
          "(targeting acceptance at a top-tier venue such as CHI, UMAP).": ""
        },
        {
          "(targeting acceptance at a top-tier venue such as CHI, UMAP).": "REFERENCES"
        },
        {
          "(targeting acceptance at a top-tier venue such as CHI, UMAP).": "[1] Andrea Apicella, Pasquale Arpaia, Simone Barbato, Giovanni D’Errico, Giovanna"
        },
        {
          "(targeting acceptance at a top-tier venue such as CHI, UMAP).": "Mastrati, Nicola Moccaldi, Ersilia Vallefuoco, and Selina Christin Wriessnegger."
        },
        {
          "(targeting acceptance at a top-tier venue such as CHI, UMAP).": "2024. Domain Adaptation for Fear of Heights Classification in a VR Environment"
        },
        {
          "(targeting acceptance at a top-tier venue such as CHI, UMAP).": ""
        },
        {
          "(targeting acceptance at a top-tier venue such as CHI, UMAP).": "Based on EEG and ECG.\nInformation Systems Frontiers (2024), 1–16."
        },
        {
          "(targeting acceptance at a top-tier venue such as CHI, UMAP).": ""
        },
        {
          "(targeting acceptance at a top-tier venue such as CHI, UMAP).": "Jeremy Bailenson. 2018. Experience on demand: What virtual reality is, how it"
        },
        {
          "(targeting acceptance at a top-tier venue such as CHI, UMAP).": "works, and what it can do. WW Norton & Company."
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "[3] Andrea Baldini, Elisabetta Patron, Claudio Gentili, Enzo Pasquale Scilingo, and\npupillometry.\nIEEE Transactions on Learning Technologies (2023)."
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "Alberto Greco. 2024. Novel VR-based Biofeedback systems: a comparison be-\n[25] KM Miller, CC Price, MS Okun, H Montijo, and D Bowers. 2009. Is the n-back task"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "tween heart rate variability-and electrodermal activity-driven approaches.\nIEEE\na valid neuropsychological measure for assessing working memory? Archives of"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "Transactions on Affective Computing (2024).\nClinical Neuropsychology 24, 7 (2009), 711–717."
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "[4] Maryam Bigonah, Fatemeh Jamshidi, Aparana Pant, Sanjaya Poudel, Sasiki-\nJinga, Cătălin\nPetrescu,\nFlorica\n[26] Alin Moldoveanu, Oana Mitrut,, Nicolae"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "ran Reddy Nallapareddy, Atefeh Charmchian Langroudi, and Daniela Marghitu.\nMoldoveanu, Victor Asavei, Ana Magdalena Anghel, and Livia Petrescu. 2023. Im-"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "2025. A Systematic Review of Extended Reality (XR) Technologies in Agriculture\nmersive phobia therapy through adaptive virtual reality and biofeedback. Applied"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "and Related Sectors (2022-2024).\nIEEE Access (2025).\nSciences 13, 18 (2023), 10365."
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "J Blum, C Rockstroh, and AS Göritz. 2019. Heart rate variability biofeedback\n[5]\n[27] Hayoun Moon, Mohammadreza Freidouny, Mohammad Sadra Rajabi, Shokoufeh"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "based on slow-paced breathing with immersive virtual reality nature scenery.\nBozorgmehrian, Ankit Sangwan, and Myounghoon Jeon. 2023. The influence of"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "Front Psychol 10: 2172.\nolfactory and visual stimuli on students’ performance and mood in virtual reality"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "[6]\nLeo Breiman. 2001. Random forests. Machine learning 45 (2001), 5–32.\nenvironment. In Proceedings of the Human Factors and Ergonomics Society Annual"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "Francesco Chiossi, Changkun Ou, and Sven Mayer. 2024. Optimizing Visual\n[7]\nMeeting, Vol. 67. SAGE Publications Sage CA: Los Angeles, CA, 2441–2446."
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "Complexity for Physiologically-Adaptive VR Systems: Evaluating a Multimodal\n[28] Mahsa Nasri, Mehmet Kosa, Leanne Chukoskie, Mohsen Moghaddam, and Casper"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "Harteveld. 2024. Exploring Eye Tracking to Detect Cognitive Load in Complex\nDataset using EDA, ECG and EEG Features. In Proceedings of the 2024 International"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "Virtual Reality Training.\nConference on Advanced Visual Interfaces. 1–9.\nIn 2024 IEEE International Symposium on Mixed and"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "[8]\nFrancesco Chiossi, Robin Welsch, Steeven Villa, Lewis Chuang, and Sven Mayer.\nAugmented Reality Adjunct (ISMAR-Adjunct). IEEE, 51–54."
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "2022. Virtual reality adaptation using electrodermal activity to support the user\n[29] Mahsa Nasri, Uttkarsh Narayan, Mustafa Feyyaz Sonbudak, Aubrey Simonson,"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "Maria Chiu, Jason Donati, Mark Sivak, Mehmet Kosa, and Casper Harteveld. 2024.\nexperience. Big Data and Cognitive Computing 6, 2 (2022), 55."
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "[9]\nSangSu Choi, Kiwook Jung, and Sang Do Noh. 2015. Virtual reality applications in\nDesigning a Virtual Reality Training Apprenticeship for Cold Spray Advanced"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "manufacturing industries: Past research, present findings, and future directions.\nManufacturing. In 2024 IEEE International Symposium on Mixed and Augmented"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "Concurrent Engineering 23, 1 (2015), 40–63.\nReality Adjunct (ISMAR-Adjunct). IEEE, 541–544."
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "[10]\nEdirlei Soares de Lima, Bruno MC Silva, and Gabriel Teixeira Galam. 2022. Adap-\n[30]\nFred Paas, Alexander Renkl, and John Sweller. 2003. Cognitive load theory and"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "tive virtual reality horror games based on Machine learning and player modeling.\ninstructional design: Recent developments. Educational psychologist 38, 1 (2003),"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "1–4.\nEntertainment Computing 43 (2022), 100515."
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "[11] Arindam Dey, Alex Chatburn, and Mark Billinghurst. 2019. Exploration of an\n[31] Vishnunarayan Girishan Prabhu, Laura Stanley, and Robert Morgan. 2020. A"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "biofeedback enhanced adaptive virtual reality environment for managing surgical\nEEG-based cognitively adaptive training system in virtual reality. In 2019 ieee"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "pain and anxiety.\nconference on virtual reality and 3d user interfaces (vr). IEEE, 220–226.\nInternational Journal of Semantic Computing 14, 03 (2020), 375–"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "[12] Tobias Drey, Pascal Jansen, Fabian Fischbach, Julian Frommel, and Enrico Rukzio.\n393."
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "2020. Towards progress assessment for adaptive hints in educational virtual\n[32] Vishnunarayan G Prabhu, Laura M Stanley, Courtney Linder, and Robert Morgan."
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "2020. Analyzing the efficacy of a restorative virtual reality environment using\nreality games. In Extended Abstracts of the 2020 CHI Conference on Human Factors"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "in Computing Systems. 1–9.\nHRV biofeedback for pain and anxiety management. In 2020 IEEE International"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "[13] Marie Eckert, Emanuël AP Habets, and Olli S Rummukainen. 2021. Cognitive\nConference on Human-Machine Systems (ICHMS). IEEE, 1–4."
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "load estimation based on pupillometry in virtual reality with uncontrolled scene\n[33] Mikko Salminen, Simo Järvelä, Ilkka Kosunen, Antti Ruonala, Juho Hamari, Niklas"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "Ravaja, and Giulio Jacucci. 2024. Meditating in a neurofeedback virtual reality:\nlighting. In 2021 13th international conference on quality of multimedia experience"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "(qomex). IEEE, 73–76.\neffects on sense of presence, meditation depth and brain oscillations. Behaviour"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "Paulo Veloso Gomes, António Marques, João Donga, Catarina Sá, António Correia,\n[14]\n& Information Technology 43, 12 (2024), 2750–2764."
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "and Javier Pereira. 2021. Adaptive model for biofeedback data flows management\n[34] Carmen Sandi. 2013.\nStress and cognition. Wiley Interdisciplinary Reviews:"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "in the design of interactive immersive environments. Applied Sciences 11, 11\nCognitive Science 4, 3 (2013), 245–261."
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "(2021), 5067.\n[35] Brook Shiferaw, Luke Downey, and David Crewther. 2019. A review of gaze"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "Paulo Veloso Gomes, Vítor J Sá, João Donga, António Marques, Bárbara Gomes,\n[15]\nentropy as a measure of visual scanning efficiency. Neuroscience & Biobehavioral"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "Raquel Simoes de Almeida, and Javier Pereira-Loureiro. 2023. The Use of Artificial\nReviews 96 (2019), 353–366."
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "Intelligence in Interactive Virtual Reality Adaptive Environments with Real-\n[36] Dong Hee Shin. 2009. The evaluation of user experience of the virtual world in"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "relation to extrinsic and intrinsic motivation.\nTime Biofeedback Applied to Phobias Psychotherapy. In VI Congreso Xove TIC:\nInternational Journal of Human-"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "impulsando el talento científico. Octubre, 2023, A Coruña. Universidade da Coruña,\nComputer Interaction 25, 6 (2009), 530–553."
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "Servizo de Publicacións, 275–279.\n[37] Alexis D Souchet, Stéphanie Philippe, Domitile Lourdeaux, and Laure Leroy."
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "[16] Kunal Gupta, Yuewei Zhang, Tamil Selvan Gunasekaran, Nanditha Krishna,\n2022. Measuring visual fatigue and cognitive load via eye tracking while learning"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "Yun Suen Pai, and Mark Billinghurst. 2024. CAEVR: Biosignals-Driven Context-\nwith virtual reality head-mounted displays: A review.\nInternational Journal of"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "Aware Empathy in Virtual Reality.\nIEEE Transactions on Visualization and Com-\nHuman–Computer Interaction 38, 9 (2022), 801–824."
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "[38]\nputer Graphics (2024).\nJ Ridley Stroop. 1935. Studies of interference in serial verbal reactions. Journal"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "Joris Heyse, Thomas De Jonge, Maria Torres Vega, Femke De Backere, and Filip\n[17]\nof experimental psychology 18, 6 (1935), 643."
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "De Turck. 2019. A personalized virtual reality experience for relaxation therapy.\n[39]\nJohn Sweller, Jeroen JG Van Merriënboer, and Fred Paas. 2019. Cognitive archi-"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "In 2019 Eleventh International Conference on Quality of Multimedia Experience\ntecture and instructional design: 20 years later. Educational psychology review 31"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "(2019), 261–292.\n(QoMEX). Ieee, 1–3."
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "[18] Manuel López Ibáñez, Maximiliano Miranda, Nahum Alvarez, and Federico\n[40]\nJF Thayer. 2009. Heart rate variability: a neurovisceral integration model.\n(2009)."
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "Peinado. 2021. Using gestural emotions recognised through a neural network as\n[41] Ufuk Uyan and Ufuk Celikcan. 2024. CDMS: A real-time system for EEG-guided"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "cybersickness mitigation through adaptive adjustment of VR content factors.\ninput for an adaptive music system in virtual reality. Entertainment Computing"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "38 (2021), 100404.\nDisplays 83 (2024), 102704."
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "[19] Yousra Izountar, Samir Benbelkacem, Samir Otmane, Abdellah Khababa, Nadia\n[42] Ashley M Williams,\nJennifer A Hogg,\nJed A Diekfuss, Samantha B Kendall,"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "Zenati, and Mostefa Masmoudi. 2021. Towards an adaptive Virtual Reality Serious\nColton T Jenkins, Shellie N Acocello, Yu Liang, Dalei Wu, Gregory D Myer,"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "Game System for Motor Rehabilitation based on Facial Emotion Recognition. In\nand Gary B Wilkerson. 2022.\nImmersive real-time biofeedback optimized with"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "2021 International Conference on Artificial Intelligence for Cyber Security Systems\nenhanced expectancies improves motor learning: A Feasibility study. Journal of"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "and Privacy (AI-CSP). IEEE, 1–5.\nsport rehabilitation 31, 8 (2022), 1023–1030."
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "[20]\nSylvia D Kreibig. 2010. Autonomic nervous system activity in emotion: A review."
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "Biological psychology 84, 3 (2010), 394–421."
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "[21]\nJacob Kritikos, Georgios Alevizopoulos, and Dimitris Koutsouris. 2021. Personal-"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "ized virtual reality human-computer interaction for psychiatric and neurological"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "illnesses: a dynamically adaptive virtual reality environment that changes accord-"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "ing to real-time feedback from electrophysiological signal responses. Frontiers in"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "Human Neuroscience 15 (2021), 596980."
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "[22]\nSylvain Laborde, Emma Mosley, and Julian F Thayer. 2017. Heart rate variability"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "and cardiac vagal tone in psychophysiological research–recommendations for"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "experiment planning, data analysis, and data reporting. Frontiers in psychology 8"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "(2017), 213."
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "[23] Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. 2015. Deep learning. nature"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "521, 7553 (2015), 436–444."
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "[24]\nJoy Yeonjoo Lee, Nynke de Jong, Jeroen Donkers, Halszka Jarodzka, and Jeroen JG"
        },
        {
          "Towards Intelligent VR Training: A Physiological Adaptation Framework for Cognitive Load and Stress Detection\nUMAP, June 16–19, 2025, NYC, NY": "van Merriënboer. 2023. Measuring cognitive load in virtual reality training via"
        }
      ],
      "page": 5
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Domain Adaptation for Fear of Heights Classification in a VR Environment Based on EEG and ECG",
      "authors": [
        "Andrea Apicella",
        "Pasquale Arpaia",
        "Simone Barbato",
        "D' Giovanni",
        "Giovanna Errico",
        "Nicola Mastrati",
        "Ersilia Moccaldi",
        "Selina Vallefuoco",
        "Wriessnegger"
      ],
      "year": "2024",
      "venue": "Information Systems Frontiers"
    },
    {
      "citation_id": "2",
      "title": "Experience on demand: What virtual reality is, how it works, and what it can do",
      "authors": [
        "Jeremy Bailenson"
      ],
      "year": "2018",
      "venue": "Experience on demand: What virtual reality is, how it works, and what it can do"
    },
    {
      "citation_id": "3",
      "title": "Novel VR-based Biofeedback systems: a comparison between heart rate variability-and electrodermal activity-driven approaches",
      "authors": [
        "Andrea Baldini",
        "Elisabetta Patron",
        "Claudio Gentili",
        "Enzo Pasquale Scilingo",
        "Alberto Greco"
      ],
      "year": "2024",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "4",
      "title": "A Systematic Review of Extended Reality (XR) Technologies in Agriculture and Related Sectors",
      "authors": [
        "Maryam Bigonah",
        "Fatemeh Jamshidi",
        "Aparana Pant",
        "Sanjaya Poudel",
        "Sasikiran Reddy Nallapareddy",
        "Atefeh Charmchian Langroudi",
        "Daniela Marghitu"
      ],
      "year": "2022",
      "venue": "A Systematic Review of Extended Reality (XR) Technologies in Agriculture and Related Sectors"
    },
    {
      "citation_id": "5",
      "title": "Heart rate variability biofeedback based on slow-paced breathing with immersive virtual reality nature scenery",
      "authors": [
        "C Blum",
        "Rockstroh",
        "Göritz"
      ],
      "year": "2019",
      "venue": "Front Psychol"
    },
    {
      "citation_id": "6",
      "title": "Random forests",
      "authors": [
        "Leo Breiman"
      ],
      "year": "2001",
      "venue": "Machine learning"
    },
    {
      "citation_id": "7",
      "title": "Optimizing Visual Complexity for Physiologically-Adaptive VR Systems: Evaluating a Multimodal Dataset using EDA, ECG and EEG Features",
      "authors": [
        "Francesco Chiossi",
        "Changkun Ou",
        "Sven Mayer"
      ],
      "year": "2024",
      "venue": "Proceedings of the 2024 International Conference on Advanced Visual Interfaces"
    },
    {
      "citation_id": "8",
      "title": "Virtual reality adaptation using electrodermal activity to support the user experience",
      "authors": [
        "Francesco Chiossi",
        "Robin Welsch",
        "Steeven Villa",
        "Lewis Chuang",
        "Sven Mayer"
      ],
      "year": "2022",
      "venue": "Big Data and Cognitive Computing"
    },
    {
      "citation_id": "9",
      "title": "Virtual reality applications in manufacturing industries: Past research, present findings, and future directions",
      "authors": [
        "Sangsu Choi",
        "Kiwook Jung",
        "Sang Noh"
      ],
      "year": "2015",
      "venue": "Concurrent Engineering"
    },
    {
      "citation_id": "10",
      "title": "Adaptive virtual reality horror games based on Machine learning and player modeling",
      "authors": [
        "Edirlei Soares De Lima",
        "Bruno Silva",
        "Gabriel Galam"
      ],
      "year": "2022",
      "venue": "Entertainment Computing"
    },
    {
      "citation_id": "11",
      "title": "Exploration of an EEG-based cognitively adaptive training system in virtual reality",
      "authors": [
        "Arindam Dey",
        "Alex Chatburn",
        "Mark Billinghurst"
      ],
      "year": "2019",
      "venue": "2019 ieee conference on virtual reality and 3d user interfaces"
    },
    {
      "citation_id": "12",
      "title": "Towards progress assessment for adaptive hints in educational virtual reality games",
      "authors": [
        "Tobias Drey",
        "Pascal Jansen",
        "Fabian Fischbach",
        "Julian Frommel",
        "Enrico Rukzio"
      ],
      "year": "2020",
      "venue": "Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems"
    },
    {
      "citation_id": "13",
      "title": "Cognitive load estimation based on pupillometry in virtual reality with uncontrolled scene lighting",
      "authors": [
        "Marie Eckert",
        "A Emanuël",
        "Habets",
        "Olli S Rummukainen"
      ],
      "year": "2021",
      "venue": "2021 13th international conference on quality of multimedia experience (qomex)"
    },
    {
      "citation_id": "14",
      "title": "Adaptive model for biofeedback data flows management in the design of interactive immersive environments",
      "authors": [
        "Paulo Veloso Gomes",
        "António Marques",
        "João Donga",
        "Catarina Sá",
        "António Correia",
        "Javier Pereira"
      ],
      "year": "2021",
      "venue": "Applied Sciences"
    },
    {
      "citation_id": "15",
      "title": "Raquel Simoes de Almeida, and Javier Pereira-Loureiro. 2023. The Use of Artificial Intelligence in Interactive Virtual Reality Adaptive Environments with Real-Time Biofeedback Applied to Phobias Psychotherapy",
      "authors": [
        "Paulo Veloso Gomes",
        "J Vítor",
        "João Sá",
        "António Donga",
        "Bárbara Marques",
        "Gomes"
      ],
      "venue": "VI Congreso Xove TIC: impulsando el talento científico"
    },
    {
      "citation_id": "16",
      "title": "CAEVR: Biosignals-Driven Context-Aware Empathy in Virtual Reality",
      "authors": [
        "Kunal Gupta",
        "Yuewei Zhang",
        "Tamil Selvan Gunasekaran",
        "Nanditha Krishna",
        "Yun Pai",
        "Mark Billinghurst"
      ],
      "year": "2024",
      "venue": "IEEE Transactions on Visualization and Computer Graphics"
    },
    {
      "citation_id": "17",
      "title": "A personalized virtual reality experience for relaxation therapy",
      "authors": [
        "Joris Heyse",
        "Thomas De Jonge",
        "Maria Vega",
        "Femke De Backere",
        "Filip Turck"
      ],
      "year": "2019",
      "venue": "2019 Eleventh International Conference on Quality of Multimedia Experience (QoMEX)"
    },
    {
      "citation_id": "18",
      "title": "Using gestural emotions recognised through a neural network as input for an adaptive music system in virtual reality",
      "authors": [
        "Maximiliano Manuel López Ibáñez",
        "Nahum Miranda",
        "Federico Alvarez",
        "Peinado"
      ],
      "year": "2021",
      "venue": "Entertainment Computing"
    },
    {
      "citation_id": "19",
      "title": "Towards an adaptive Virtual Reality Serious Game System for Motor Rehabilitation based on Facial Emotion Recognition",
      "authors": [
        "Yousra Izountar",
        "Samir Benbelkacem",
        "Samir Otmane",
        "Abdellah Khababa",
        "Nadia Zenati",
        "Mostefa Masmoudi"
      ],
      "year": "2021",
      "venue": "2021 International Conference on Artificial Intelligence for Cyber Security Systems and Privacy"
    },
    {
      "citation_id": "20",
      "title": "Autonomic nervous system activity in emotion: A review",
      "authors": [
        "D Sylvia",
        "Kreibig"
      ],
      "year": "2010",
      "venue": "Biological psychology"
    },
    {
      "citation_id": "21",
      "title": "Personalized virtual reality human-computer interaction for psychiatric and neurological illnesses: a dynamically adaptive virtual reality environment that changes according to real-time feedback from electrophysiological signal responses",
      "authors": [
        "Jacob Kritikos",
        "Georgios Alevizopoulos",
        "Dimitris Koutsouris"
      ],
      "year": "2021",
      "venue": "Frontiers in Human Neuroscience"
    },
    {
      "citation_id": "22",
      "title": "Heart rate variability and cardiac vagal tone in psychophysiological research-recommendations for experiment planning, data analysis, and data reporting",
      "authors": [
        "Emma Sylvain Laborde",
        "Julian Mosley",
        "Thayer"
      ],
      "year": "2017",
      "venue": "Frontiers in psychology"
    },
    {
      "citation_id": "23",
      "title": "Deep learning",
      "authors": [
        "Yann Lecun",
        "Yoshua Bengio",
        "Geoffrey Hinton"
      ],
      "year": "2015",
      "venue": "nature"
    },
    {
      "citation_id": "24",
      "title": "Measuring cognitive load in virtual reality training via pupillometry",
      "authors": [
        "Joy Yeonjoo",
        "Nynke De Jong",
        "Jeroen Donkers",
        "Halszka Jarodzka",
        "Jeroen Jg Van Merriënboer"
      ],
      "year": "2023",
      "venue": "IEEE Transactions on Learning Technologies"
    },
    {
      "citation_id": "25",
      "title": "Is the n-back task a valid neuropsychological measure for assessing working memory?",
      "authors": [
        "Miller",
        "Price",
        "H Okun",
        "Montijo",
        "Bowers"
      ],
      "year": "2009",
      "venue": "Archives of Clinical Neuropsychology"
    },
    {
      "citation_id": "26",
      "title": "Immersive phobia therapy through adaptive virtual reality and biofeedback",
      "authors": [
        "Alin Moldoveanu",
        "Oana Mitrut",
        "Nicolae Jinga",
        "Cătălin Petrescu",
        "Florica Moldoveanu",
        "Victor Asavei",
        "Ana Anghel",
        "Livia Petrescu"
      ],
      "year": "2023",
      "venue": "Applied Sciences"
    },
    {
      "citation_id": "27",
      "title": "Ankit Sangwan, and Myounghoon Jeon. 2023. The influence of olfactory and visual stimuli on students' performance and mood in virtual reality environment",
      "authors": [
        "Hayoun Moon",
        "Mohammadreza Freidouny",
        "Mohammad Sadra Rajabi",
        "Shokoufeh Bozorgmehrian"
      ],
      "venue": "Proceedings of the Human Factors and Ergonomics Society Annual Meeting"
    },
    {
      "citation_id": "28",
      "title": "Exploring Eye Tracking to Detect Cognitive Load in Complex Virtual Reality Training",
      "authors": [
        "Mahsa Nasri",
        "Mehmet Kosa",
        "Leanne Chukoskie",
        "Mohsen Moghaddam",
        "Casper Harteveld"
      ],
      "year": "2024",
      "venue": "2024 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)"
    },
    {
      "citation_id": "29",
      "title": "Designing a Virtual Reality Training Apprenticeship for Cold Spray Advanced Manufacturing",
      "authors": [
        "Mahsa Nasri",
        "Uttkarsh Narayan",
        "Mustafa Sonbudak",
        "Aubrey Simonson",
        "Maria Chiu",
        "Jason Donati",
        "Mark Sivak",
        "Mehmet Kosa",
        "Casper Harteveld"
      ],
      "year": "2024",
      "venue": "2024 IEEE International Symposium on Mixed and Augmented Reality Adjunct"
    },
    {
      "citation_id": "30",
      "title": "Cognitive load theory and instructional design: Recent developments",
      "authors": [
        "Fred Paas",
        "Alexander Renkl",
        "John Sweller"
      ],
      "year": "2003",
      "venue": "Educational psychologist"
    },
    {
      "citation_id": "31",
      "title": "A biofeedback enhanced adaptive virtual reality environment for managing surgical pain and anxiety",
      "authors": [
        "Laura Vishnunarayan Girishan Prabhu",
        "Robert Stanley",
        "Morgan"
      ],
      "year": "2020",
      "venue": "International Journal of Semantic Computing"
    },
    {
      "citation_id": "32",
      "title": "Analyzing the efficacy of a restorative virtual reality environment using HRV biofeedback for pain and anxiety management",
      "authors": [
        "Laura Vishnunarayan G Prabhu",
        "Courtney Stanley",
        "Robert Linder",
        "Morgan"
      ],
      "year": "2020",
      "venue": "2020 IEEE International Conference on Human-Machine Systems (ICHMS)"
    },
    {
      "citation_id": "33",
      "title": "Meditating in a neurofeedback virtual reality: effects on sense of presence, meditation depth and brain oscillations",
      "authors": [
        "Mikko Salminen",
        "Simo Järvelä",
        "Ilkka Kosunen",
        "Antti Ruonala",
        "Juho Hamari",
        "Niklas Ravaja",
        "Giulio Jacucci"
      ],
      "year": "2024",
      "venue": "Behaviour & Information Technology"
    },
    {
      "citation_id": "34",
      "title": "Stress and cognition",
      "authors": [
        "Carmen Sandi"
      ],
      "year": "2013",
      "venue": "Stress and cognition"
    },
    {
      "citation_id": "35",
      "title": "A review of gaze entropy as a measure of visual scanning efficiency",
      "authors": [
        "Brook Shiferaw",
        "Luke Downey",
        "David Crewther"
      ],
      "year": "2019",
      "venue": "Neuroscience & Biobehavioral Reviews"
    },
    {
      "citation_id": "36",
      "title": "The evaluation of user experience of the virtual world in relation to extrinsic and intrinsic motivation",
      "authors": [
        "Dong Hee"
      ],
      "year": "2009",
      "venue": "International Journal of Human-Computer Interaction"
    },
    {
      "citation_id": "37",
      "title": "Measuring visual fatigue and cognitive load via eye tracking while learning with virtual reality head-mounted displays: A review",
      "authors": [
        "Alexis Souchet",
        "Stéphanie Philippe",
        "Domitile Lourdeaux",
        "Laure Leroy"
      ],
      "year": "2022",
      "venue": "International Journal of Human-Computer Interaction"
    },
    {
      "citation_id": "38",
      "title": "Studies of interference in serial verbal reactions",
      "authors": [
        "Stroop Ridley"
      ],
      "year": "1935",
      "venue": "Journal of experimental psychology"
    },
    {
      "citation_id": "39",
      "title": "Cognitive architecture and instructional design: 20 years later",
      "authors": [
        "John Sweller",
        "J Jeroen",
        "Fred Van Merriënboer",
        "Paas"
      ],
      "year": "2019",
      "venue": "Educational psychology review"
    },
    {
      "citation_id": "40",
      "title": "Heart rate variability: a neurovisceral integration model",
      "authors": [
        "Thayer"
      ],
      "year": "2009",
      "venue": "Heart rate variability: a neurovisceral integration model"
    },
    {
      "citation_id": "41",
      "title": "CDMS: A real-time system for EEG-guided cybersickness mitigation through adaptive adjustment of VR content factors",
      "year": "2024",
      "venue": "Displays"
    },
    {
      "citation_id": "42",
      "title": "Immersive real-time biofeedback optimized with enhanced expectancies improves motor learning: A Feasibility study",
      "authors": [
        "Jennifer Ashley M Williams",
        "Jed Hogg",
        "Samantha Diekfuss",
        "Colton Kendall",
        "Shellie Jenkins",
        "Yu Acocello",
        "Dalei Liang",
        "Gregory Wu",
        "Gary Myer",
        "Wilkerson"
      ],
      "year": "2022",
      "venue": "Journal of sport rehabilitation"
    }
  ]
}