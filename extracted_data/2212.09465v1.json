{
  "paper_id": "2212.09465v1",
  "title": "Improving The Generalizability Of Text-Based Emotion Detection By Leveraging Transformers With Psycholinguistic Features",
  "published": "2022-12-19T13:58:48Z",
  "authors": [
    "Sourabh Zanwar",
    "Daniel Wiechmann",
    "Yu Qiao",
    "Elma Kerz"
  ],
  "keywords": [
    "Kerz et"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "In recent years, there has been increased interest in building predictive models that harness natural language processing and machine learning techniques to detect emotions from various text sources, including social media posts, micro-blogs or news articles. Yet, deployment of such models in real-world sentiment and emotion applications faces challenges, in particular poor out-of-domain generalizability. This is likely due to domainspecific differences (e.g., topics, communicative goals, and annotation schemes) that make transfer between different models of emotion recognition difficult. In this work we propose approaches for text-based emotion detection that leverage transformer models (BERT and RoBERTa) in combination with Bidirectional Long Short-Term Memory (BiLSTM) networks trained on a comprehensive set of psycholinguistic features. First, we evaluate the performance of our models within-domain on two benchmark datasets: GoEmotion  (Demszky et al., 2020)  and ISEAR  (Scherer and Wallbott, 1994) . Second, we conduct transfer learning experiments on six datasets from the Unified Emotion Dataset  (Bostan and Klinger, 2018)  to evaluate their out-of-domain robustness. We find that the proposed hybrid models improve the ability to generalize to outof-distribution data compared to a standard transformer-based approach. Moreover, we observe that these models perform competitively on in-domain data.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Emotions are a key factor affecting all human behavior, which includes rational tasks such as reasoning, decision making, and social interaction  (Parrott, 2001; Loewenstein and Lerner, 2003; Lerner et al., 2015; Bericat, 2016) . Although emotions seem to be subjective by nature, they appear in objectively derivable ways in texts. Text-based emotion detection (henceforth TBED) is a branch of sentiment analysis that aims to extract textual features to identify associations with various emotions such as anger, fear, joy, sadness, surprise, etc. TBED is a rapidly developing interdisciplinary field that brings together insights from cognitive psychology, social sciences, computational linguistics, natural language processing (NLP) and machine learning  (Canales and Martínez-Barco, 2014; Acheampong et al., 2020a; Alswaidan and Menai, 2020; Deng and Ren, 2021) . TBED has a wide range of real-world applications, from healthcare  (Cambria et al., 2010a) , recommendation systems  (Majumder et al., 2019) , empathic chatbot development  (Casas et al., 2021) , offensive language detection (Plaza-del  Arco et al., 2021) , social data analysis for business intelligence  (Cambria et al., 2013; Soussan and Trovati, 2020) , and stock market prediction  (Xing et al., 2018) .\n\nThe differentiation of emotions and their classification into specific groups and categories is a subfield of affective research and has yielded several theories and models  (Borod et al., 2000; Scherer et al., 2000; Cambria et al., 2012; Sander and Nummenmaa, 2021; Susanto et al., 2020) . The grouping of models for the classification of emotions generally differs according to whether emotions are conceived as discrete/categorical or as dimensional. Categorical models of emotions, like Ekman's six basic emotions (anger, disgust, fear, joy, sadness, and surprise)  (Ekman, 1992 (Ekman, , 1999)) , assume physiologically distinct basic human emotions. Plutchik's Wheel of Emotion  (Plutchik, 1984)  is another categorical model that assumes a set of eight discrete emotions expressed in four opposing pairs (joy-sadness, anger-fear, trust-disgust, and anticipation-surprise). Dimensional emotion models, like the Circumplex Model of  Russell (1980) , groups affective states into a vector space of valence (corresponding to senti-ment/polarity), arousal (corresponding to a degree of calmness or excitement), and dominance (perceived degree of control over a given situation).\n\nCurrent approaches to TBED take the advantage of recent advances in NLP and machine learning, with deep learning techniques achieving state-of-the-art performance on benchmark emotion datasets (see  Acheampong et al. 2020a  for recent reviews). However there still remains the issue of out-of-domain generalizability of the existing emotion detection models. The way emotions are conveyed in texts may differ from domain to domain, reflecting differences in topics, communicative goals, target audience, etc. This makes the deployment of such models in real-world sentiment and emotion applications difficult. The importance of this issue has been increasingly recognized in the TBED literature. For example,  Bostan and Klinger (2018)  emphasize that \"[j]ournalists ideally tend to be objective when writing articles, authors of microblog posts need to focus on brevity\", and that \"emotion expressions in tales are more subtle and implicit than, for instance, in blogs\". To support future transfer learning and domain adaptation work for TBED, the authors constructed a unified, aggregated emotion detection dataset that encompasses different domains and annotation schemes.\n\nIn this work, we contribute to the improvement of the generalizability of emotion detection models as follows: We build hybrid models that combine pre-trained transformer language models with Bidirectional Long Short-Term Memory (BiLSTM) networks trained, to our knowledge, on the most comprehensive set of psycholinguistic features. We evaluate the performance of the proposed models in two ways: First, we conduct within-corpus emotion classification experiments (training on one corpus and testing on the same) on two emotion benchmark datasets, GoEmotion  (Demszky et al., 2020)  and ISEAR  (Scherer and Wallbott, 1994) , to show that such hybrid models outperform pretrained transformer models. Second, we conduct transfer learning experiments on six popular emotion classification datasets of the Unified Emotion Dataset  (Bostan and Klinger, 2018)  to show that our approach improves the generalizability of emotion classification across domains and emotion taxonomies. The remainder of the paper is organized as follows: In Section 2, we briefly review recent related work on TBED. Then, in Section 3, we present popular benchmark datasets for emotion detection. Section 4 details the extraction of psycholinguistic features using automated text analysis based on a sliding window approach. In Section 5, we describe our emotion detection models, and in Section 6, we present our experiments and discuss the results. Finally, we conclude with possible directions for future work in Section 7.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Related Work",
      "text": "In this section, we focus on previous TBED research conducted on two popular benchmark datasets (GoEmotions, ISEAR) to compare the performance of our models with state-of-the-art emotion recognition models, as well as previous attempts to improve generalizability using transfer learning techniques.\n\nCurrent work on TBED typically utilizes a variety of linguistic features, such as word or character n-grams, affect lexicons, and word embeddings in combination with a supervised classification model (for recent overviews see,  Sailunaz et al., 2018; Acheampong et al., 2020b; Alswaidan and Menai, 2020) . While earlier approaches relied on shallow classifiers, such as a naive Bayes, SVM or MaxEnt classifier, later approaches increasingly relied on deep learning models in combination with different word embedding methods. For example,  Polignano et al. (2019)  proposed an emotion detection model based on the use of long short-term memory (LSTM) and convolutional neural network (CNN) mediated through the use of a level of attention in combination with different word embeddings (GloVe,  Pennington et al. 2014, and Fast-Text, Bojanowski et al. 2017) .\n\nIn experiments performed on the ISEAR dataset,  Dong and Zeng (2022)  proposed a text emotion distribution learning model based on a lexiconenhanced multi-task convolutional neural network (LMT-CNN) to jointly solve the tasks of text emotion distribution prediction and emotion label classification. The LMT-CNN model is an end-to-end multi-module deep neural network that utilizes semantic information and linguistic knowledge to predict emotion distributions and labels. Based on comparative experiments on nine commonly used emotion datasets,  Dong and Zeng (2022)  showed that the LMT-CNN model can outperform two previously introduced deep-neural-network-based models: TextCNN, a convolutional neural network for text emotion classification  (Kim, 2014)  and MT-CNN  (Zhang et al., 2018) , a multi-task convo-lutional neural network model that simultaneously predicts the distribution of text emotion and the dominant emotion of the text (see Table  1  for numerical details on the performance of these models on the datasets used in the present work). In recent years, TBED research has increasingly relied on transformer-based pre-trained language models  (Acheampong et al., 2020a; Demszky et al., 2020; ?) : For example, Acheampong et al. (2020a) perform comparative analyses of BERT  (Devlin et al., 2019) , RoBERTA  (Liu et al., 2019) , DistilBERT  (Sanh et al., 2019) , and XLNet  (Yang et al., 2019)  for text-based emotion recognition on the ISEAR dataset. While all models were found to be efficient in detecting emotions from text, RoBERTa achieved the highest performance with a detection accuracy of 74.31%. The currently best-performing model on the ISEAR dataset, reaching a microaverage F1 score of 75.2%, is  Park et al. (2021) . In this work a RoBERTa-Large model was finetuned to learn conditional VAD distributions -obtained from the NRC-VAD lexicon  (Mohammad, 2018)  -through supervision of categorical labels. The learned VAD distributions were then used to predict the emotion labels for a given sentence.\n\nFor the recently introduced GoEmotions dataset,  Demszky et al. (2020)  already provided a strong baseline for modeling emotion classification by fine-tuning a BERT-base model. Their model achieved an average F1-score of 64% over an Ekman-style grouping into six coarse categories.  Cortiz (2022)  conducted comparative experiments with additional transformer-based models -BERT, DistilBERT, RoBERTa, XLNet, and ELECTRA  (Clark et al., 2020)  -on the GoEmotions dataset. As in the case of ISEAR, the best performance was achieved by RoBERTa, with an F1-score of 49% on the full GoEmotions taxonomy (28 emotion categories).\n\nPrevious TBED work has also proposed combinations of different approaches. For example,  Seol et al. (2008)  proposed a hybrid model that combines emotion keywords in a sentence using an emotional keyword dictionary with a knowledgebased artificial neural network that uses domain knowledge. To our knowledge, however, almost no TBED research has investigated hybrid models that combine transformer-based models with (psycho)linguistic features (see, however, De Bruyne et al. 2021, for an exception in Dutch). This is surprising, as such an approach has been successfully applied in related areas, for example personality prediction  (Mehta et al., 2020; Kerz et al., 2022) .\n\nThe available research aimed at improving the generalizability of transformer-based models using transfer learning techniques has so far focused on demonstrating that training on a large dataset of one domain, say Reddit comments, can contribute to increasing model accuracy for different target domains, such as tweets and personal narratives. Specifically, using three different finetuning setups -(1) finetuning BERT only on the target dataset, (2) first finetuning BERT on GoEmotions, then perform transfer learning by replacing the final dense layer, and (3) freezing all layers besides the last layer and finetuning on the target dataset -, Demszky et al.  (2020)  showed that the GoEmotions dataset generalizes well to other domains and different emotion taxonomies in nine datasets from the Unified Emotion Dataset  (Bostan and Klinger, 2018) .",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Datasets",
      "text": "We conduct experiments on a total of eight datasets. The within-domain experiments are performed on two benchmark corpora: The GoEmotions dataset  (Demszky et al., 2020)  and the International Survey on Emotion Antecedents and Reactions (ISEAR) dataset  (Scherer and Wallbott, 1994) . GoEmotions is the largest available manually annotated dataset for emotion prediction. It consists of 58 thousand Reddit comments, labeled by 80 human raters for 27 emotion categories plus a neutral category. While 83% of the items of the dataset have received a single label, GoEmotions is strictly speaking a multilabel dataset, as raters were free to select multiple emotions. The dataset has been manually reviewed to remove profanity and offensive language towards a particular ethnicity, gender, sexual orientation, or disability. The ISEAR dataset is a widely used benchmark dataset consisting of personal reports on emotional events written by 3000 people from different cultural backgrounds. It was constructed by collecting questionnaires answered by people that reported on their own emotional events. It contains a total of 7,665 sentences labeled with one of seven emotions: joy, fear, anger, sadness, shame, guilt and disgust. The transfer-learning experiments are conducted on six benchmark datasets from Unified Emotion Dataset  (Bostan and Klinger, 2018)  that were chosen based on their diversity in size and domain: (1) The AffectiveText dataset  (Strapparava and Mihalcea, 2007)  consists of 1,250 news headlines. The annotation schema follows Ekman's basic emotions, complemented by valence. It is multi-label annotated via expert annotation and emotion categories are assigned a score from 0 to 100. (2) The CrowdFlower dataset consists of 39,740 tweets annotated via crowdsourcing with one label per tweet. The dataset was previously found to be noisy in comparison with other emotion datasets  (Bostan and Klinger, 2018) . (  3 ) The dataset Electoral-Tweets  (Mohammad et al., 2015)  targets the domain of elections. It consists of over 100,000 responses to two detailed online questionnaires (the questions targeted emotions, purpose, and style in electoral tweets). The tweets are annotated via crowdsourcing. (4) The Stance Sentiment Emotion Corpus SSEC  (Schuff et al., 2017)  is an annotation of 4,868 tweets from the SemEval 2016 Twitter stance and sentiment dataset. It is annotated via expert annotation with multiple emotion labels per tweet following Plutchik's fundamental emotions. (5) The Twitter Emotion Corpus TEC  (Mohammad, 2012)  consists of 21,011 tweets. The annotation schema corresponds to Ekman's model of basic emotions. They collected tweets with hashtags corresponding to the six Ekman emotions: #anger, #disgust, #fear, #happy, #sadness, and #surprise, therefore it is distantly single-label annotated. (6) The Emotion-Stimulus dataset  (Ghazi et al., 2015)  has 1,549 sentences with their emotion analysed. The set of annotation labels comprises of Ekman's basic emotions with the addition of shame. (7) The ISEAR UED dataset that is part of the Unified Emotion Dataset has 5,477 sentences with single emotion annotations. This dataset is a filtered version of the original ISEAR dataset described above.  Bostan and Klinger (2018)  filter and keep the texts with the labels anger, disgust, joy, sadness and fear for the Unified Emotion Dataset.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Sentence-Level Measurement Of Psycholinguistic Features",
      "text": "The datasets were automatically analyzed using an automated text analysis (ATA) system that employs a sliding window technique to compute sentencelevel measurements (for recent applications of this tool across various domains, see  Qiao et al. (2020)  for fake news detection,  Kerz et al. (2021)  for predicting human affective ratings) and Wiechmann et al. (  2022 ) for predicting eye-moving patterns during reading). We extracted a set of 435 psy-cholinguistic features that can be binned into four groups: (1) features of morpho-syntactic complexity (N=19), (2) features of lexical richness, diversity and sophistication (N=77), (3) readability features (N=14), and (4) lexicon features designed to detect sentiment, emotion and/or affect (N=325). Tokenization, sentence splitting, part-of-speech tagging, lemmatization and syntactic PCFG parsing were performed using Stanford CoreNLP  (Manning et al., 2014) .\n\nThe group of morpho-syntactic complexity features includes (i) surface features related to the length of production units, such as the average length of clauses and sentences, (ii) features of the type and frequency of embeddings, such as number of dependent clauses per T-Unit or verb phrases per sentence and (iii) the frequency of particular structure types, such as the number of complex nominals per clause. This group also includes (iv) information-theoretic features of morphological and syntactic complexity based on the Deflate algorithm  (Deutsch, 1996) . The group of lexical richness, diversity and sophistication features includes six different subtypes: (i) lexical density features, such as the ratio of the number of lexical (as opposed to grammatical) words to the total number of words in a text, (ii) lexical variation, i.e. the range of vocabulary as manifested in language use, captured by text-size corrected type-token ratio, (iii) lexical sophistication, i.e. the proportion of relatively unusual or advanced words in a text, such as the number of words from the New General Service List  (Browne et al., 2013) , (iv) psycholinguistic norms of words, such as the average age of acquisition of the word  (Kuperman et al., 2012)  and two recently introduced types of features: (v) word prevalence features that capture the number of people who know the word  (Brysbaert et al., 2019; Johns et al., 2020)  and (vi) register-based n-gram frequency features that take into account both frequency rank and the number of word ngrams (n ∈ [1, 5]). The latter were derived from the five register subcomponents of the Contemporary Corpus of American English (COCA, 560 million words,  Davies, 2008) : spoken, magazine, fiction, news and academic language (see  Kerz et al., 2020,  for details see e.g.). The group of readability features combines a word familiarity variable defined by a prespecified vocabulary resource to estimate semantic difficulty along with a syntactic variable, such as average sentence length. Examples of these measures include the Fry index  (Fry, 1968)  or the SMOG  (McLaughlin, 1969) . The group of lexiconbased sentiment/emotion/affect features was derived from a total of ten lexicons that have been successfully used in personality detection, emotion recognition and sentiment analysis research: (1) The Affective Norms for English Words (ANEW)  (Bradley and Lang, 1999) , (2) the ANEW-Emo lexicons  (Stevenson et al., 2007) , (3) DepecheMood++  (Araque et al., 2019) , (  4 ) the Geneva Affect Label Coder (GALC)  (Scherer, 2005) , (5) General Inquirer  (Stone et al., 1966) , (  6 ) the LIWC dictionary  (Pennebaker et al., 2001) , (  7 ) the NRC Word-Emotion Association Lexicon  (Mohammad and Turney, 2013) , (  8 ) the NRC Valence, Arousal, and Dominance lexicon  (Mohammad, 2018) , (  9 ) SenticNet  (Cambria et al., 2010b) , and (10) the Sentiment140 lexicon  (Mohammad et al., 2013) .",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Modeling Approach",
      "text": "We construct a total of five models: (1) a fine-tuned Bidirectional Encoder Representations from Transformers (BERT) model, (2) a fine-tuned RoBERTA model (Robustly Optimized BERT pre-training Approach), (3) a bidirectional neural network classifiers trained on sentence-level measurements of psycholinguistic features described in Section 3.1, and (  4 ) and (  5 ) two hybrid models integrating BERT and RoBERTa predictions with the psycholinguistic features. We train all models in a multi-label classification setup. For the withindomain evaluation of the models on the GoEmotions dataset, we follow the procedure specified in  Demszky et al. (2020) : That is, we filtered out emotion labels selected by only a single annotator. The 93% of the original were randomly split into train (80%), dev (10%) and test (10%) sets. These splits are identical to those used by Demszky et al.. In the transfer learning setting geared to show that our modeling approach improves generalization across domains and taxonomies, we perform experiments on each of the six emotion benchmark datasets presented in section 3 using four approaches: with/without finetuning on target dataset and with/without the inclusion of the label 'neutral'. The performance of these models is evaluated using 5 times repeated 5-fold crossvalidation using a 80/20 split to counter variability due to weight initialization. We report performance metrics averaged over all runs. All models are implemented using PyTorch  (Paszke et al., 2019) . Unless specif- ically stated otherwise, we use 'BCELoss' as our loss function, 'AdamW' as optimizer, with learning rate 2 × 10 -5 and weight decay of 1 × 10 -5\n\n5.1 Transformer-based models (BERT, RoBERTa)\n\nWe used the pretrained 'bert-base-uncased' and 'roberta-base' models from the Huggingface Transformers library  (Wolf et al., 2020) . The models consist of 12 Transformer layers with hidden size 768 and 12 attention heads. We run experiments with (1) a linear fully-connected layer for classification as well as with (2) an intermediate bidirectional LSTM layer with 256 hidden units (Al-Omari et al., 2020) (BERT-BiLSTM). The following hyperparameters are used for fine-tuning: a fixed learning rate of 2 × 10 -5 is applied and L2 regularization of 1 × 10 -6 . All models were trained for 8 epochs, with batch size of 4 and maximum sequence length of 512 and dropout of 0.2. We report the results from the best performing models, i.e. RoBERTa-BiLSTM and BERT-BiLSTM.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Bidirectional Lstm Trained On Psycholinguistic Features (Psyling)",
      "text": "As a model based solely on psycholinguistic features, we constructed a 2-layer bidirectional long short-term model (BiLSTM) with a hidden state dimension of 32, which is depicted in Figure  2 .\n\nThe input to the model is a sequence CM N 1 = (CM 1 , CM 2 . . . , CM N ), where CM i , the output of the ATA-system, for the ith sentence of a document, is a 435 dimensional vector and N is the sequence length. To predict the labels of a sequence, we concatenate the last hidden states of\n\nis then transformed through a 2-layer feedforward neural network, whose activation function is Rectifier Linear Unit (ReLU). The output of this is then passed to a Dense Fully Connected Layer with a dropout of 0.2, and finally fed to a final fully connected layer. The output of this is a K dimensional vector, where K is the number of emotion labels.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Hybrid Models (Bert+Psyling, Roberta+Psyling)",
      "text": "We assemble the hybrid models by (1) obtaining a set of 256 dimensional vector from the PsyLing model and then (2) concatenating these features along with the output from the pre-trained transformer-based model part. To obtain the output of the pre-trained transformer-based model, the given text is fed to a pre-trained language model, its outputs are passed through a 2-layer BiLSTM with hidden size of 512. This is further passed through a fully connected layer to obtain a 256 dimensional vector. This concatenated vector is then fed into a 2-layer feedforward classifier. To obtain the soft labels (probabilities that a text belongs to the corresponding emotion label), sigmoid was applied to each dimension of the output vector.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Results",
      "text": "The models were evaluated using accuracy, precision, recall and F1 scores as the performance metrics. The results of the within-domain classification experiments on the GoEmotion and ISEAR datasets are shown in Table  1  (detailed results on all metrics are provided in see Table  4  in the appendix).\n\nWe focus here on the discussion of F1 scores. For both datasets and for both transformer-based models, we find that the proposed hybrid models outperform the standard transformer-based baseline models: Specifically, in the case of the GoEmotions dataset, the hybrid models (BERT+PsyLing, RoBERTa+PsyLing) exhibit an increase in F1 score of +2% relative to their respective baseline models. In the case of the ISEAR dataset, the RoBERTa+PsyLing model show an increase in F1 score of +2% relative to RoBERTa, while the BERT+PsyLing model show an increase in F1 score of +1% relative to BERT. Our hybrid models show improvements in all emotion categories, except for anger, where they are on par with their respective baseline models. These results indicate that integrating transformer-based models with BiLSTM trained on psycholinguistic features can improve emotion classification within two distinct domains: an online domain (Reddit) as well as the domain of reports of personal events. On the GoEmotion dataset, our best-performing hybrid model, RoBERTa+PsyLing, outperforms the previous SOTA model Roberta-EMD  (Park et al., 2021)  by +9.9% macro-F1. On the ISEAR dataset, both hybrid models outperform two of the three CNNs presented in  Dong and Zeng (2022) , TextCNN and MT-CNN, and are competitive with the lexiconenhanced multi-task CNN (LMT-CNN). In fact, both hybrid models outperform the LMT-CNN on two of the five emotion categories, with an increase on the joy category of +10.31% F1 (LMT-CNN vs. BERT-PsyLing) and an increase on the fear category of +4.05% F1 (LMT-CNN vs. BERT-PsyLing). The results of the comparisons with previous deep-learning TBED models on the two benchmark datasets thus indicate that the proposed approach constitutes a valuable framework for future TBED efforts.  An overview of the results of the out-of-domain experiments is presented in Table  2 . Table  3  shows comparisons of the results of our best performing model, RoBERTa+PsyLing, in the finetuning setting without the neutral label with the results of maximum entropy classifiers trained on with bag-of-words (BOW) features from  Bostan and Klinger (2018) . The results in Table  2  reveal that the RoBERTa+PsyLing hybrid model was the best performing model across all four experimental settings. Performance was generally observed to be highest in the finetuning setting without the neutral label. Importantly, the results in Table  2  reveal that the integration of psycholinguistic features matched or improved the performance of the models across all settings, with increases in F1 scores of up to 7% relative to a standard transformer-based approach. The results in Table  3  indicate that our hybrid models pretrained on GoEmotions outperform the results of the baseline models provided by  Bostan and Klinger (2018)  on five of the seven emotion datasets (TEC, CrowdFLower, ISEAR UED , elect-tweet, and affect text), with increases in performance of up to 31%. The hybrid models tied the near-perfect performance of the baseline model on the emo-stimulus dataset and fell short only on the SSEC dataset. A possible reason for the relatively low performance of our models on the latter may be due to the fact that the SSEC was rated based on Plutchik's fundamental emotions.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Conclusion",
      "text": "This paper proposed approaches for text-based emotion detection that leverage transformer models in combination with Bidirectional Long Short-Term Memory networks trained on a comprehensive set of psycholinguistic features. The results of transfer learning experiments performed on six out-of-domain emotion datasets demonstrated that the proposed hybrid models can substantially improve model generalizability to out-of-distribution data compared to a standard transformer-based model. Moreover, we found that these models perform competitively on in-domain data. In future work, we intend to extend this line of work to dimensional emotion models as well as to models that jointly solve the tasks of emotion label classification and text emotion distribution prediction.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Ethical Considerations",
      "text": "The datasets used in this study may contain biases, are not representative of global diversity and may contain potentially problematic content. Potential biases in the data include: Inherent biases in user base biases, the offensive/vulgar word lists used for data filtering, inherent or unconscious bias in assessment of offensive identity labels. All these likely affect labeling, precision, and recall for a trained model.",
      "page_start": 8,
      "page_end": 8
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Structure diagram of transformer-based emo-",
      "page": 5
    },
    {
      "caption": "Figure 2: The input to the model is a sequence CMN",
      "page": 5
    },
    {
      "caption": "Figure 2: Structure diagram of BiLSTM emotion detec-",
      "page": 6
    },
    {
      "caption": "Figure 3: Structure diagram of hybrid emotion detec-",
      "page": 6
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Model": "Train GoEmo\nBERT\nw/o ﬁnetuning RoBERTa\nw/o neutral\nPsyLing\nBERT+PsyLing\nRoBERTa+PsyLing",
          "TEC Crowdﬂ.\nISEARUED elect-tweet affect-text SSEC emo-stimulus": "23\n29\n44\n26\n36\n19\n53\n31\n23\n29\n44\n39\n21\n56\n22\n18\n25\n16\n23\n11\n38\n31\n23\n44\n27\n36\n21\n56\n23\n47\n40\n22\n61\n29\n27"
        },
        {
          "Model": "w/o ﬁnetuning BERT\nwith neutral\nRoBERTa\nPsyLing\nBERT+PsyLing\nRoBERTa+PsyLing",
          "TEC Crowdﬂ.\nISEARUED elect-tweet affect-text SSEC emo-stimulus": "20\n26\n35\n23\n13\n16\n41\n25\n18\n22\n27\n34\n14\n47\n16\n20\n17\n13\n10\n08\n23\n21\n27\n35\n24\n15\n17\n45\n23\n28\n36\n25\n16\n49\n17"
        },
        {
          "Model": "with ﬁnetuning BERT\nw/o neutral\nRoBERTa\nPsyLing\nBERT+PsyLing\nRoBERTa+PsyLing",
          "TEC Crowdﬂ.\nISEARUED elect-tweet affect-text SSEC emo-stimulus": "32\n55\n31\n63\n36\n54\n92\n56\n65\n32\n94\n30\n34\n53\n34\n23\n41\n32\n36\n24\n46\n65\n57\n32\n94\n55\n32\n39\n56\n31\n65\n41\n57\n32\n94"
        },
        {
          "Model": "with ﬁnetuning BERT\nwith neutral\nRoBERTa\nPsyLing\nBERT+PsyLing\nRoBERTa+PsyLing",
          "TEC Crowdﬂ.\nISEARUED elect-tweet affect-text SSEC emo-stimulus": "46\n33\n55\n33\n44\n29\n96\n34\n56\n44\n30\n46\n30\n95\n24\n24\n35\n28\n29\n30\n53\n47\n48\n97\n34\n55\n34\n31\n34\n56\n34\n33\n46\n47\n96"
        }
      ],
      "page": 7
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Model": "RoBERTa-EMD (Park et al 2021) F1",
          "Metric Anger Disgust Sadness Surprise\nFear\nJoy": "–\n–\n–\n–\n–\n–",
          "Average": "61.1"
        },
        {
          "Model": "Pre\nBERT\nRec\nF1",
          "Metric Anger Disgust Sadness Surprise\nFear\nJoy": "69\n38\n53\n68\n68\n88\n71\n65\n80\n77\n76\n91\n70\n48\n64\n72\n72\n90",
          "Average": "64\n77\n68"
        },
        {
          "Model": "Pre\nRoBERTa\nRec\nF1",
          "Metric Anger Disgust Sadness Surprise\nFear\nJoy": "70\n62\n79\n78\n71\n88\n71\n41\n53\n62\n70\n93\n70\n49\n63\n69\n71\n90",
          "Average": "75\n65\n69"
        },
        {
          "Model": "Pre\nPsyLing\nRec\nF1",
          "Metric Anger Disgust Sadness Surprise\nFear\nJoy": "48\n28\n47\n43\n42\n80\n53\n22\n34\n38\n29\n80\n50\n24\n40\n40\n34\n80",
          "Average": "48\n43\n45"
        },
        {
          "Model": "Pre\nBERT+PsyLing (ours)\nRec\nF1",
          "Metric Anger Disgust Sadness Surprise\nFear\nJoy": "69\n65\n68\n73\n81\n90\n71\n40\n63\n69\n56\n90\n71\n65\n49\n72\n72\n91",
          "Average": "74\n65\n70"
        },
        {
          "Model": "Pre\nRoBERTa+PsyLing (ours)\nRec\nF1",
          "Metric Anger Disgust Sadness Surprise\nFear\nJoy": "69\n65\n68\n73\n81\n90\n71\n40\n63\n69\n56\n90\n50\n65\n74\n73\n92\n70",
          "Average": "74\n65\n71"
        }
      ],
      "page": 13
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Pre\nTextCNN (Dong & Zeng 2022)\nRec\nF1": "Pre\nMT-CNN (Dong & Zeng 2022)\nRec\nF1",
          "61.36\n63.5\n76.64\n–\n70.67\n79.3\n70.84\n64.24\n74.21\n–\n71.66\n64.59\n62.14\n65.22\n76.39\n–\n72.09\n73.97": "61.31\n64.68\n80.27\n–\n72.16\n81.13\n71.62\n64.46\n77.37\n–\n73.66\n69.36\n65.68\n67.63\n77\n–\n74.25\n72.09",
          "70.29\n69.11\n69.96": "71.91\n71.29\n71.33"
        },
        {
          "Pre\nTextCNN (Dong & Zeng 2022)\nRec\nF1": "Pre\nLMT-CNN (Dong & Zeng 2022)\nRec\nF1",
          "61.36\n63.5\n76.64\n–\n70.67\n79.3\n70.84\n64.24\n74.21\n–\n71.66\n64.59\n62.14\n65.22\n76.39\n–\n72.09\n73.97": "62.28\n66\n82.07\n–\n72.5\n82.15\n72.38\n65.1\n79.34\n–\n74.4\n71.64\n66.54\n70.64\n80.68\n–\n74.95\n74.69",
          "70.29\n69.11\n69.96": "73\n72.57\n73.5"
        },
        {
          "Pre\nTextCNN (Dong & Zeng 2022)\nRec\nF1": "RoBERTa-EMD (Park et al 2021) F1",
          "61.36\n63.5\n76.64\n–\n70.67\n79.3\n70.84\n64.24\n74.21\n–\n71.66\n64.59\n62.14\n65.22\n76.39\n–\n72.09\n73.97": "–\n–\n–\n–\n–\n–",
          "70.29\n69.11\n69.96": "75.2"
        },
        {
          "Pre\nTextCNN (Dong & Zeng 2022)\nRec\nF1": "Pre\nBERT\nRec\nF1",
          "61.36\n63.5\n76.64\n–\n70.67\n79.3\n70.84\n64.24\n74.21\n–\n71.66\n64.59\n62.14\n65.22\n76.39\n–\n72.09\n73.97": "51\n74\n74\n-\n83\n84\n63\n60\n69\n-\n74\n86\n56\n65\n71\n-\n77\n84",
          "70.29\n69.11\n69.96": "73\n70\n71"
        },
        {
          "Pre\nTextCNN (Dong & Zeng 2022)\nRec\nF1": "Pre\nRoBERTa\nRec\nF1",
          "61.36\n63.5\n76.64\n–\n70.67\n79.3\n70.84\n64.24\n74.21\n–\n71.66\n64.59\n62.14\n65.22\n76.39\n–\n72.09\n73.97": "58\n68\n77\n-\n93\n86\n61\n66\n64\n-\n62\n77\n60\n69\n71\n-\n72\n84",
          "70.29\n69.11\n69.96": "77\n66\n71"
        },
        {
          "Pre\nTextCNN (Dong & Zeng 2022)\nRec\nF1": "Pre\nPsyLing\nRec\nF1",
          "61.36\n63.5\n76.64\n–\n70.67\n79.3\n70.84\n64.24\n74.21\n–\n71.66\n64.59\n62.14\n65.22\n76.39\n–\n72.09\n73.97": "26\n35\n37\n-\n46\n62\n62\n34\n63\n-\n48\n53\n38\n36\n48\n-\n48\n57",
          "70.29\n69.11\n69.96": "41\n41\n45"
        },
        {
          "Pre\nTextCNN (Dong & Zeng 2022)\nRec\nF1": "Pre\nBERT+PsyLing (ours)\nRec\nF1",
          "61.36\n63.5\n76.64\n–\n70.67\n79.3\n70.84\n64.24\n74.21\n–\n71.66\n64.59\n62.14\n65.22\n76.39\n–\n72.09\n73.97": "55\n73\n72\n-\n80\n84\n62\n68\n68\n-\n77\n86\n70\n85\n58\n70\n-\n78",
          "70.29\n69.11\n69.96": "73\n72\n72"
        },
        {
          "Pre\nTextCNN (Dong & Zeng 2022)\nRec\nF1": "Pre\nRoBERTa+PsyLing (ours)\nRec\nF1",
          "61.36\n63.5\n76.64\n–\n70.67\n79.3\n70.84\n64.24\n74.21\n–\n71.66\n64.59\n62.14\n65.22\n76.39\n–\n72.09\n73.97": "66\n72\n79\n-\n80\n80\n66\n66\n68\n-\n77\n77\n64\n73\n79\n69\n-\n79",
          "70.29\n69.11\n69.96": "75\n71\n73"
        }
      ],
      "page": 13
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Comparative analyses of bert, roberta, distilbert, and xlnet for text-based emotion recognition",
      "authors": [
        "Francisca Adoma",
        "Nunoo-Mensah Henry",
        "Wenyu Chen"
      ],
      "year": "2020",
      "venue": "2020 17th International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP)"
    },
    {
      "citation_id": "2",
      "title": "Text-based emotion detection: Advances, challenges, and opportunities",
      "authors": [
        "Francisca Adoma",
        "Chen Wenyu",
        "Henry Nunoo-Mensah"
      ],
      "year": "2020",
      "venue": "Engineering Reports"
    },
    {
      "citation_id": "3",
      "title": "Emodet2: Emotion detection in english textual dialogue using bert and bilstm models",
      "authors": [
        "Hani Al-Omari",
        "Malak Abdullah",
        "Samira Shaikh"
      ],
      "year": "2020",
      "venue": "2020 11th International Conference on Infor-mation and Communication Systems (ICICS)"
    },
    {
      "citation_id": "4",
      "title": "A survey of state-of-the-art approaches for emotion recognition in text",
      "authors": [
        "Nourah Alswaidan",
        "Bachir Menai"
      ],
      "year": "2020",
      "venue": "Knowledge and Information Systems"
    },
    {
      "citation_id": "5",
      "title": "Depechemood++: a bilingual emotion lexicon built through simple yet powerful techniques",
      "authors": [
        "Oscar Araque",
        "Lorenzo Gatti",
        "Jacopo Staiano",
        "Marco Guerini"
      ],
      "year": "2019",
      "venue": "Depechemood++: a bilingual emotion lexicon built through simple yet powerful techniques"
    },
    {
      "citation_id": "6",
      "title": "The sociology of emotions: Four decades of progress",
      "year": "2016",
      "venue": "Current Sociology"
    },
    {
      "citation_id": "7",
      "title": "Enriching word vectors with subword information. Transactions of the association for computational linguistics",
      "authors": [
        "Piotr Bojanowski",
        "Edouard Grave",
        "Armand Joulin",
        "Tomas Mikolov"
      ],
      "year": "2017",
      "venue": "Enriching word vectors with subword information. Transactions of the association for computational linguistics"
    },
    {
      "citation_id": "8",
      "title": "The neuropsychology of emotion",
      "authors": [
        "Joan Borod"
      ],
      "year": "2000",
      "venue": "The neuropsychology of emotion"
    },
    {
      "citation_id": "9",
      "title": "An analysis of annotated corpora for emotion classification in text",
      "authors": [
        "Laura-Ana-Maria Bostan",
        "Roman Klinger"
      ],
      "year": "2018",
      "venue": "Proceedings of the 27th International Conference on Computational Linguistics"
    },
    {
      "citation_id": "10",
      "title": "Affective norms for english words (ANEW): Instruction manual and affective ratings",
      "authors": [
        "M Margaret",
        "Peter Bradley",
        "Lang"
      ],
      "year": "1999",
      "venue": "Technical report C-1, the center for research in psychophysiology"
    },
    {
      "citation_id": "11",
      "title": "The new general service list: Celebrating 60 years of vocabulary learning",
      "authors": [
        "Charles Browne"
      ],
      "year": "2013",
      "venue": "The Language Teacher"
    },
    {
      "citation_id": "12",
      "title": "Word prevalence norms for 62,000 english lemmas",
      "authors": [
        "Marc Brysbaert",
        "Paweł Mandera",
        "Samantha Mc-Cormick",
        "Emmanuel Keuleers"
      ],
      "year": "2019",
      "venue": "Behavior research methods"
    },
    {
      "citation_id": "13",
      "title": "Sentic computing: Exploitation of common sense for the development of emotionsensitive systems",
      "authors": [
        "Erik Cambria",
        "Amir Hussain",
        "Catherine Havasi",
        "Chris Eckl"
      ],
      "year": "2010",
      "venue": "Development of multimodal interfaces: active listening and synchrony"
    },
    {
      "citation_id": "14",
      "title": "The hourglass of emotions",
      "authors": [
        "Erik Cambria",
        "Andrew Livingstone",
        "Amir Hussain"
      ],
      "year": "2012",
      "venue": "Cognitive behavioural systems"
    },
    {
      "citation_id": "15",
      "title": "Big social data analysis",
      "authors": [
        "Erik Cambria",
        "Dheeraj Rajagopal",
        "Daniel Olsher",
        "Dipankar Das"
      ],
      "year": "2013",
      "venue": "Big data computing"
    },
    {
      "citation_id": "16",
      "title": "Senticnet: A publicly available semantic resource for opinion mining",
      "authors": [
        "Erik Cambria",
        "Robyn Speer",
        "Catherine Havasi",
        "Amir Hussain"
      ],
      "year": "2010",
      "venue": "2010 AAAI fall symposium series"
    },
    {
      "citation_id": "17",
      "title": "Emotion detection from text: A survey",
      "authors": [
        "Lea Canales",
        "Patricio Martínez-Barco"
      ],
      "year": "2014",
      "venue": "Proceedings of the workshop on natural language processing in the 5th information systems research working days (JISIC)"
    },
    {
      "citation_id": "18",
      "title": "Enhancing conversational agents with empathic abilities",
      "authors": [
        "Jacky Casas",
        "Timo Spring",
        "Karl Daher",
        "Elena Mugellini",
        "Omar Abou Khaled",
        "Philippe Cudré-Mauroux"
      ],
      "year": "2021",
      "venue": "Proceedings of the 21st ACM International Conference on Intelligent Virtual Agents"
    },
    {
      "citation_id": "19",
      "title": "ELECTRA: Pretraining text encoders as discriminators rather than generators",
      "authors": [
        "Kevin Clark",
        "Minh-Thang Luong",
        "Quoc Le",
        "Christopher Manning"
      ],
      "year": "2020",
      "venue": "8th International Conference on Learning Representations, ICLR 2020"
    },
    {
      "citation_id": "20",
      "title": "Exploring transformers models for emotion recognition: A comparision of bert, distilbert, roberta, xlnet and electra. CCRIS '22",
      "authors": [
        "Diogo Cortiz"
      ],
      "year": "2022",
      "venue": "Exploring transformers models for emotion recognition: A comparision of bert, distilbert, roberta, xlnet and electra. CCRIS '22"
    },
    {
      "citation_id": "21",
      "title": "The Corpus of Contemporary American English (COCA): 560 million words",
      "authors": [
        "Mark Davies"
      ],
      "year": "1990",
      "venue": "The Corpus of Contemporary American English (COCA): 560 million words"
    },
    {
      "citation_id": "22",
      "title": "Emotional robbert and insensitive bertje: Combining transformers and affect lexica for dutch emotion detection",
      "authors": [
        "Luna De Bruyne",
        "Orphée De Clercq",
        "Véronique Hoste"
      ],
      "year": "2021",
      "venue": "Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis"
    },
    {
      "citation_id": "23",
      "title": "GoEmotions: A dataset of fine-grained emotions",
      "authors": [
        "Dorottya Demszky",
        "Dana Movshovitz-Attias",
        "Jeongwoo Ko",
        "Alan Cowen",
        "Gaurav Nemade",
        "Sujith Ravi"
      ],
      "year": "2020",
      "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "24",
      "title": "A survey of textual emotion recognition and its challenges",
      "authors": [
        "Jiawen Deng",
        "Fuji Ren"
      ],
      "year": "2021",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "25",
      "title": "Rfc1951: Deflate compressed data format specification version 1",
      "authors": [
        "Peter Deutsch"
      ],
      "year": "1996",
      "venue": "Rfc1951: Deflate compressed data format specification version 1"
    },
    {
      "citation_id": "26",
      "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "authors": [
        "Jacob Devlin",
        "Ming-Wei Chang",
        "Kenton Lee",
        "Kristina Toutanova"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies"
    },
    {
      "citation_id": "27",
      "title": "Lexiconenhanced multi-task convolutional neural network for emotion distribution learning",
      "authors": [
        "Yuchang Dong",
        "Xueqiang Zeng"
      ],
      "year": "2022",
      "venue": "Axioms"
    },
    {
      "citation_id": "28",
      "title": "Are there basic emotions? Psychological review",
      "authors": [
        "Paul Ekman"
      ],
      "year": "1992",
      "venue": "Are there basic emotions? Psychological review"
    },
    {
      "citation_id": "29",
      "title": "Basic emotions. Handbook of cognition and emotion",
      "authors": [
        "Paul Ekman"
      ],
      "year": "1999",
      "venue": "Basic emotions. Handbook of cognition and emotion"
    },
    {
      "citation_id": "30",
      "title": "A readability formula that saves time",
      "authors": [
        "Edward Fry"
      ],
      "year": "1968",
      "venue": "Journal of reading"
    },
    {
      "citation_id": "31",
      "title": "Detecting emotion stimuli in emotion-bearing sentences",
      "authors": [
        "Diman Ghazi",
        "Diana Inkpen",
        "Stan Szpakowicz"
      ],
      "year": "2015",
      "venue": "International Conference on Intelligent Text Processing and Computational Linguistics"
    },
    {
      "citation_id": "32",
      "title": "Estimating the prevalence and diversity of words in written language",
      "authors": [
        "Brendan Johns",
        "Melody Dye",
        "Michael Jones"
      ],
      "year": "2020",
      "venue": "Quarterly Journal of Experimental Psychology"
    },
    {
      "citation_id": "33",
      "title": "Language that captivates the audience: predicting affective ratings of ted talks in a multi-label classification task",
      "authors": [
        "Elma Kerz",
        "Yu Qiao",
        "Daniel Wiechmann"
      ],
      "year": "2021",
      "venue": "Proceedings of the Eleventh Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis"
    },
    {
      "citation_id": "34",
      "title": "Becoming linguistically mature: Modeling english and german children's writing development across school grades",
      "authors": [
        "Elma Kerz",
        "Yu Qiao",
        "Daniel Wiechmann",
        "Marcus Ströbel"
      ],
      "year": "2020",
      "venue": "Proceedings of the Fifteenth Workshop on Innovative Use of NLP for Building Educational Applications"
    },
    {
      "citation_id": "35",
      "title": "Pushing on personality detection from verbal behavior: A transformer meets text contours of psycholinguistic features",
      "authors": [
        "Elma Kerz",
        "Yu Qiao",
        "Sourabh Zanwar",
        "Daniel Wiechmann"
      ],
      "year": "2022",
      "venue": "Proceedings of the 12th Workshop on Computational Approaches to Subjectivity, Sentiment & Social Media Analysis"
    },
    {
      "citation_id": "36",
      "title": "Convolutional neural networks for sentence classification",
      "authors": [
        "Yoon Kim"
      ],
      "year": "2014",
      "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)"
    },
    {
      "citation_id": "37",
      "title": "Age-of-acquisition ratings for 30,000 English words",
      "authors": [
        "Hans Victor Kuperman",
        "Marc Stadthagen-Gonzalez",
        "Brysbaert"
      ],
      "year": "2012",
      "venue": "Behavior research methods"
    },
    {
      "citation_id": "38",
      "title": "Emotion and decision making",
      "authors": [
        "Jennifer Lerner",
        "Ye Li",
        "Piercarlo Valdesolo",
        "Karim Kassam"
      ],
      "year": "2015",
      "venue": "Annual review of psychology"
    },
    {
      "citation_id": "39",
      "title": "Roberta: A robustly optimized bert pretraining approach",
      "authors": [
        "Yinhan Liu",
        "Myle Ott",
        "Naman Goyal",
        "Jingfei Du",
        "Mandar Joshi",
        "Danqi Chen",
        "Omer Levy",
        "Mike Lewis",
        "Luke Zettlemoyer",
        "Veselin Stoyanov"
      ],
      "year": "2019",
      "venue": "Roberta: A robustly optimized bert pretraining approach",
      "arxiv": "arXiv:1907.11692"
    },
    {
      "citation_id": "40",
      "title": "The role of affect in decision making",
      "authors": [
        "G Loewenstein",
        "J Lerner"
      ],
      "year": "2003",
      "venue": "The role of affect in decision making"
    },
    {
      "citation_id": "41",
      "title": "Dialoguernn: An attentive rnn for emotion detection in conversations",
      "authors": [
        "Navonil Majumder",
        "Soujanya Poria",
        "Devamanyu Hazarika",
        "Rada Mihalcea",
        "Alexander Gelbukh",
        "Erik Cambria"
      ],
      "year": "2019",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence"
    },
    {
      "citation_id": "42",
      "title": "The stanford corenlp natural language processing toolkit",
      "authors": [
        "Christopher Manning",
        "Mihai Surdeanu",
        "John Bauer",
        "Jenny Finkel",
        "Steven Bethard",
        "David Mcclosky"
      ],
      "year": "2014",
      "venue": "Proceedings of 52nd annual meeting of the association for computational linguistics: system demonstrations"
    },
    {
      "citation_id": "43",
      "title": "Clearing the smog",
      "authors": [
        "Harry Mclaughlin"
      ],
      "year": "1969",
      "venue": "Clearing the smog"
    },
    {
      "citation_id": "44",
      "title": "Bottom-up and top-down: Predicting personality with psycholinguistic and language model features",
      "authors": [
        "Yash Mehta",
        "Samin Fatehi"
      ],
      "year": "2020",
      "venue": "2020 IEEE International Conference on Data Mining (ICDM)"
    },
    {
      "citation_id": "45",
      "title": "# emotional tweets",
      "authors": [
        "Saif Mohammad"
      ],
      "year": "2012",
      "venue": "* SEM 2012: The First Joint Conference on Lexical and Computational Semantics"
    },
    {
      "citation_id": "46",
      "title": "Obtaining reliable human ratings of valence, arousal, and dominance for 20,000 english words",
      "authors": [
        "Saif Mohammad"
      ],
      "year": "2018",
      "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "47",
      "title": "Nrc-canada: Building the state-of-theart in sentiment analysis of tweets",
      "authors": [
        "Saif Mohammad",
        "Svetlana Kiritchenko",
        "Xiaodan Zhu"
      ],
      "year": "2013",
      "venue": "Proceedings of the seventh international workshop on Semantic Evaluation Exercises (SemEval-2013)"
    },
    {
      "citation_id": "48",
      "title": "Crowdsourcing a word-emotion association lexicon",
      "authors": [
        "M Saif",
        "Peter Mohammad",
        "Turney"
      ],
      "year": "2013",
      "venue": "Computational intelligence"
    },
    {
      "citation_id": "49",
      "title": "Sentiment, emotion, purpose, and style in electoral tweets",
      "authors": [
        "Xiaodan Saif M Mohammad",
        "Svetlana Zhu",
        "Joel Kiritchenko",
        "Martin"
      ],
      "year": "2015",
      "venue": "Information Processing & Management"
    },
    {
      "citation_id": "50",
      "title": "Hee Young Park, and Alice Oh. 2021. Dimensional emotion detection from categorical emotion",
      "authors": [
        "Sungjoon Park",
        "Jiseon Kim",
        "Seonghyeon Ye",
        "Jaeyeol Jeon"
      ],
      "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "51",
      "title": "Emotions in social psychology: Essential readings",
      "authors": [
        "Gerrod Parrott"
      ],
      "year": "2001",
      "venue": "Emotions in social psychology: Essential readings"
    },
    {
      "citation_id": "52",
      "title": "Pytorch: An imperative style, high-performance deep learning library",
      "authors": [
        "Adam Paszke",
        "Sam Gross",
        "Francisco Massa",
        "Adam Lerer",
        "James Bradbury",
        "Gregory Chanan",
        "Trevor Killeen",
        "Zeming Lin",
        "Natalia Gimelshein",
        "Luca Antiga",
        "Alban Desmaison",
        "Andreas Kopf",
        "Edward Yang",
        "Zachary Devito",
        "Martin Raison",
        "Alykhan Tejani",
        "Sasank Chilamkurthy",
        "Benoit Steiner",
        "Lu Fang",
        "Junjie Bai",
        "Soumith Chintala"
      ],
      "year": "2019",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "53",
      "title": "Linguistic inquiry and word count: Liwc",
      "authors": [
        "Martha James W Pennebaker",
        "Roger Francis",
        "Booth"
      ],
      "year": "2001",
      "venue": "Linguistic inquiry and word count: Liwc"
    },
    {
      "citation_id": "54",
      "title": "Glove: Global vectors for word representation",
      "authors": [
        "Jeffrey Pennington",
        "Richard Socher",
        "Christopher Manning"
      ],
      "year": "2014",
      "venue": "Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)"
    },
    {
      "citation_id": "55",
      "title": "Multi-task learning with sentiment, emotion, and target detection to recognize hate speech and offensive language",
      "authors": [
        "Flor Miriam",
        "Plaza-Del Arco",
        "Sercan Halat",
        "Sebastian Padó",
        "Roman Klinger"
      ],
      "year": "2021",
      "venue": "Multi-task learning with sentiment, emotion, and target detection to recognize hate speech and offensive language",
      "arxiv": "arXiv:2109.10255"
    },
    {
      "citation_id": "56",
      "title": "Emotions: A general psychoevolutionary theory. Approaches to emotion",
      "authors": [
        "Robert Plutchik"
      ],
      "year": "1984",
      "venue": "Emotions: A general psychoevolutionary theory. Approaches to emotion"
    },
    {
      "citation_id": "57",
      "title": "A comparison of word-embeddings in emotion detection from text using bilstm, cnn and self-attention",
      "authors": [
        "Marco Polignano",
        "Pierpaolo Basile",
        "Marco De Gemmis",
        "Giovanni Semeraro"
      ],
      "year": "2019",
      "venue": "Adjunct Publication of the 27th Conference on User Modeling, Adaptation and Personalization"
    },
    {
      "citation_id": "58",
      "title": "A language-based approach to fake news detection through interpretable features and brnn",
      "authors": [
        "Yu Qiao",
        "Daniel Wiechmann",
        "Elma Kerz"
      ],
      "year": "2020",
      "venue": "Proceedings of the 3rd international workshop on rumours and deception in social media (RDSM)"
    },
    {
      "citation_id": "59",
      "title": "A circumplex model of affect",
      "authors": [
        "Russell James"
      ],
      "year": "1980",
      "venue": "Journal of personality and social psychology"
    },
    {
      "citation_id": "60",
      "title": "Emotion detection from text and speech: a survey",
      "authors": [
        "Kashfia Sailunaz",
        "Manmeet Dhaliwal",
        "Jon Rokne",
        "Reda Alhajj"
      ],
      "year": "2018",
      "venue": "Social Network Analysis and Mining"
    },
    {
      "citation_id": "61",
      "title": "Reward and emotion: an affective neuroscience approach",
      "authors": [
        "David Sander",
        "Lauri Nummenmaa"
      ],
      "year": "2021",
      "venue": "Current Opinion in Behavioral Sciences"
    },
    {
      "citation_id": "62",
      "title": "Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter",
      "authors": [
        "Victor Sanh",
        "Lysandre Debut",
        "Julien Chaumond",
        "Thomas Wolf"
      ],
      "year": "2019",
      "venue": "Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter",
      "arxiv": "arXiv:1910.01108"
    },
    {
      "citation_id": "63",
      "title": "What are emotions? and how can they be measured? Social science information",
      "authors": [
        "Klaus Scherer"
      ],
      "year": "2005",
      "venue": "What are emotions? and how can they be measured? Social science information"
    },
    {
      "citation_id": "64",
      "title": "Evidence for universality and cultural variation of differential emotion response patterning",
      "authors": [
        "R Klaus",
        "Harald Scherer",
        "Wallbott"
      ],
      "year": "1994",
      "venue": "Journal of personality and social psychology"
    },
    {
      "citation_id": "65",
      "title": "Psychological models of emotion. The neuropsychology of emotion",
      "authors": [
        "Klaus Scherer"
      ],
      "year": "2000",
      "venue": "Psychological models of emotion. The neuropsychology of emotion"
    },
    {
      "citation_id": "66",
      "title": "Annotation, modelling and analysis of fine-grained emotions on a stance and sentiment detection corpus",
      "authors": [
        "Hendrik Schuff",
        "Jeremy Barnes",
        "Julian Mohme",
        "Sebastian Padó",
        "Roman Klinger"
      ],
      "year": "2017",
      "venue": "Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis"
    },
    {
      "citation_id": "67",
      "title": "Emotion recognition from text using knowledge-based ann",
      "authors": [
        "Yong-Soo Seol",
        "Dong-Joo Kim",
        "Han-Woo Kim"
      ],
      "year": "2008",
      "venue": "ITC-CSCC: International Technical Conference on Circuits Systems, Computers and Communications"
    },
    {
      "citation_id": "68",
      "title": "Improved sentiment urgency emotion detection for business intelligence",
      "authors": [
        "Tariq Soussan",
        "Marcello Trovati"
      ],
      "year": "2020",
      "venue": "International Conference on Intelligent Networking and Collaborative Systems"
    },
    {
      "citation_id": "69",
      "title": "Characterization of the affective norms for english words by discrete emotional categories",
      "authors": [
        "Joseph Ryan A Stevenson",
        "Thomas Mikels",
        "James"
      ],
      "year": "2007",
      "venue": "Behavior research methods"
    },
    {
      "citation_id": "70",
      "title": "The general inquirer: A computer approach to content analysis",
      "authors": [
        "J Philip",
        "Dexter Stone",
        "Marshall Dunphy",
        "Smith"
      ],
      "year": "1966",
      "venue": "The general inquirer: A computer approach to content analysis"
    },
    {
      "citation_id": "71",
      "title": "Semeval-2007 task 14: Affective text",
      "authors": [
        "Carlo Strapparava",
        "Rada Mihalcea"
      ],
      "year": "2007",
      "venue": "Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007)"
    },
    {
      "citation_id": "72",
      "title": "Bee Chin Ng, and Erik Cambria. 2020. The hourglass model revisited",
      "authors": [
        "Yosephine Susanto",
        "Andrew Livingstone"
      ],
      "venue": "IEEE Intelligent Systems"
    },
    {
      "citation_id": "73",
      "title": "Measuring the impact of (psycho-)linguistic and readability features and their spill over effects on the prediction of eye movement patterns",
      "authors": [
        "Yu Daniel Wiechmann",
        "Elma Qiao",
        "Justus Kerz",
        "Mattern"
      ],
      "year": "2022",
      "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "74",
      "title": "Transformers: State-of-theart natural language processing",
      "authors": [
        "Thomas Wolf",
        "Julien Chaumond",
        "Lysandre Debut",
        "Victor Sanh",
        "Clement Delangue",
        "Anthony Moi",
        "Pierric Cistac",
        "Morgan Funtowicz",
        "Joe Davison",
        "Sam Shleifer"
      ],
      "year": "2020",
      "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations"
    },
    {
      "citation_id": "75",
      "title": "Natural language based financial forecasting: a survey",
      "authors": [
        "Erik Frank Z Xing",
        "Roy Cambria",
        "Welsch"
      ],
      "year": "2018",
      "venue": "Artificial Intelligence Review"
    },
    {
      "citation_id": "76",
      "title": "Xlnet: Generalized autoregressive pretraining for language understanding",
      "authors": [
        "Zhilin Yang",
        "Zihang Dai",
        "Yiming Yang",
        "Jaime Carbonell",
        "Russ Salakhutdinov",
        "Quoc V Le"
      ],
      "year": "2019",
      "venue": "Advances in neural information processing systems"
    },
    {
      "citation_id": "77",
      "title": "Text emotion distribution learning via multi-task convolutional neural network",
      "authors": [
        "Yuxiang Zhang",
        "Jiamei Fu",
        "Dongyu She",
        "Ying Zhang",
        "Senzhang Wang",
        "Jufeng Yang"
      ],
      "year": "2018",
      "venue": "IJCAI"
    },
    {
      "citation_id": "78",
      "title": "",
      "authors": [
        "Roberta+psyling"
      ],
      "venue": ""
    }
  ]
}