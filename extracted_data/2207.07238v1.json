{
  "paper_id": "2207.07238v1",
  "title": "Emotion Recognition In Conversation Using Probabilistic Soft Logic",
  "published": "2022-07-14T23:59:06Z",
  "authors": [
    "Eriq Augustine",
    "Pegah Jandaghi",
    "Alon Albalak",
    "Connor Pryor",
    "Charles Dickens",
    "William Wang",
    "Lise Getoor"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Creating agents that can both appropriately respond to conversations and understand complex human linguistic tendencies and social cues has been a long standing challenge in the NLP community. A recent pillar of research revolves around emotion recognition in conversation (ERC); a subfield of emotion recognition that focuses on conversations or dialogues that contain two or more utterances. In this work, we explore an approach to ERC that exploits the use of neural embeddings along with complex structures in dialogues. We implement our approach in a framework called Probabilistic Soft Logic (PSL), a declarative templating language that uses first-order like logical rules, that when combined with data, define a particular class of graphical model. Additionally, PSL provides functionality for the incorporation of results from neural models into PSL models. This allows our model to take advantage of advanced neural methods, such as sentence embeddings, and logical reasoning over the structure of a dialogue. We compare our method with state-of-theart purely neural ERC systems, and see almost a 20% improvement. With these results, we provide an extensive qualitative and quantitative analysis over the DailyDialog conversation dataset.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "With the growing popularity of conversational agents in daily life, the need for agents that can appropriately respond to long running conversations and that can understand complex human linguistic tendencies and social cues is becoming increasingly important. This growth in popularity has sparked a large interest in conversational research. A recent pillar of this emerging field has been around emotion recognition in conversation (ERC); a sub-field of emotion recognition that focuses on conversations or dialogues that contain two or more utterances.  Poria et al. (2019b)  provides a thorough overview of the current state of ERC. For example, in Figure  1  two friends visiting the Empire State Building for the first share a typical conversation where the speakers express surprise, neutral emotion, and then happiness. An automated assistant with access to this conversation may take very different actions depending on the emotions expressed by the speakers, e.g., checking for hours of operations if the Figure  1 : A sample conversation with representative emotions. Each utterance is labeled with a single emotion, or marked as having no emotion. emotions are positive, or searching for other local attractions that do not involve heights if the emotions are negative. In general, being able to correctly identify the emotion of utterances can aid other downstream tasks such as emotionaware dialogue agents  (Polzin and Waibel 2000; André et al. 2004; Skowron 2010; Skowron et al. 2011; Ghandeharioun et al. 2019; Ekbal 2020 ) and healthcare  (Tanana et al. 2021; Mowafey and Gardner 2012; Ghandeharioun et al. 2019) .\n\nERC stands out as a challenging problem because it combines the already difficult task of emotion recognition with the complexity of conversations. Conversations are distinctly intricate because they are influenced by a variety of factors such as topic, personality, argumentation logic, viewpoint, intent, location, number of speakers, and the mental and emotional states of the participants at the time of the conversation  (Hovy 1987; Schlöder and Fernández 2015; Ghosal et al. 2020) . In addition to the complexity of conversations, ERC also have to address a number of challenges stemming from emotions, such as bias in emotion annotations, emotional shift, and emotional reasoning  (Poria et al. 2019b) .\n\nIn this paper, we propose a general framework that uses the structure intrinsic to dialogue to aid in utterance emotion prediction. Throughout this paper we develop our method using a framework called Probabilistic Soft Logic  (Bach et al. 2017) , a declarative templating language that uses first order like logical rules, that when combined with data, define a particular class of graphical model. PSL provides a simple framework for incorporating structural conversational knowledge through first order logical rules, provides efficient and scalable statistical inference, and has shown to be effective in complex domains that benefit from collective inference  (Tomkins et al. 2017; Kouki et al. 2019; Sridhar and Getoor 2019; Embar et al. 2020) . Furthermore, PSL allows for the integration of predictions from neural networks into PSL models, allowing for the seamless use of language embeddings into structured models.\n\nOur key contributions are as follows: 1) we create a general and extendable framework for ERC using PSL that can be applied to various ERC datasets, 2) we provide a through experimental evaluation over a popular ERC dataset, Daily-Dialog, 3) we show both qualitative and quantitatively that PSL outperforms the state-of-the-art models by almost 20%, and 4) we provide a qualitative exploration of the DailyDialog dataset, in which we highlight areas of potential improvement.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Related Work",
      "text": "The broader task of emotion recognition has been a long standing problem across many fields of research, including machine learning, signal processing, social cognitive psychology, etc. The techniques used in emotion recognition heavily overlap with the related problems of sentiment analysis and opinion mining  (Pang and Lee 2008) . All of these problems share the common goal of extracting the thoughts, feelings, and opinions of others. However, where sentiment analysis considers a person's feelings towards an entity, emotion recognition focuses more broadly on the emotion that a person feels, regardless of the target of that emotion. Additionally, sentiment analysis is typically performed on more formal text sources, such as written reviews, whereas ERC is typically performed on dialogues which are less formal and more causal in nature.\n\nERC has become more popular recently with the release of public conversational datasets such as social media conversations and movie/tv-show scripts  (Zahiri and Choi 2018; Poria et al. 2019a) . Recent work in ERC focuses on solving the problem with deep learning architectures. One of the earliest networks to produce promising results for ERC was a bi-directional contextual LSTM model, bc-LSTM or CNN-cLSTM  (Poria et al. 2017) , which allowed utterances to get information from subsequent or earlier utterances. To improve upon this concept, Conversational Memory Networks (CMN)  (Hazarika et al. 2018b ) utilizes distinct memory for each speaker to model speaker specific information. This method was further improved by Interactive Conversational Memory Networks (ICON)  (Hazarika et al. 2018a)  and Interaction-aware Attention Networks (IAN)  (Yeh, Lin, and Lee 2019) , where memories were inter-connected. Di-alogueRNN  (Majumder et al. 2019 ) expands on the previous methods by using Gated Recurrent Units (GRU)  (Chung et al. 2014)  as memory cells and is specifically modeled to exploit the speaker information. Further, DialogueGCN  (Ghosal et al. 2019)  and ConGCN  (Zhang et al. 2019 ) utilize graph convolutional networks (GCN)  (Defferrard, Bresson, and Vandergheynst 2016) , and model both contextsensitive and speaker-sensitive dependence for emotion detection. Additionally, KET  (Zhong, Wang, and Miao 2019)  and COSMIC  (Ghosal et al. 2020 ) attempt to improve results by using external commonsense knowledge, while BERT DCR-Net  (Qin et al. 2020)  and BERT+MTL  (Li et al. 2020)  use BERT  (Devlin et al. 2019 ) based features to aid in sentiment recognition. Finally, CESTa  (Wang et al. 2020 ) models the ERC task as sequence tagging and uses conditional random fields (CRF)  (Sutton, McCallum, and Rohanimanesh 2007)  to model the emotional consistency in conversation.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Probabilistic Soft Logic",
      "text": "Probabilistic Soft Logic (PSL) is a probabilistic programming language used to define a special class of Markov random fields (MRF), a hinge-loss Markov random field (HL-MRF)  (Bach et al. 2017) . HL-MRFs are a class of conditional probabilistic models over continuous variables which allow for scalable and exact inference  (Bach et al. 2013) .\n\nPSL models relational dependencies and structural constraints using weighted first-order logical clauses, referred to as rules. For example, consider the rule:\n\nwhere the predicates HASEMOTION and SIMILARTEXT respectively predict the emotional label for an utterance and define the similarity of two utterances, and w acts as a learnable weight for the rule that denotes the rule's relative importance in the model. This rule encodes the domain knowledge that utterances with similar texts (Utterance1 and Utterance2) should probably be labeled with the same emotion, and establishes a dependency that similar utterances should share similar labels.\n\nGiven the rules for a model and data, PSL generates an HL-MRF by instantiating concrete instances of each rule where variables are replaced with actual entities from the data. This process is referred to as grounding, and each concrete instance of a rule is referred to as a ground rule. The logical atoms in the ground rules correspond to the random variables in the HL-MRF, while ground rules correspond to potential functions in the HL-MRF.\n\nGiven the observed variables X, unobserved variables Y , and potential functions, PSL defines a probability distribution over the unobserved variables as:\n\nwhere m is the number of potential functions, φ i is the i th hinge-loss potential function, and w i is weight of the tem-plate rule from which φ i was derived. The hinge-loss potentials are defined as:\n\nwhere l is a linear function, X and Y are in the range [0, 1], and p ∈ 1, 2 optionally squares the potential. Exact maximum a posteriori (MAP) inference on this distribution can be framed as the convex optimization problem:\n\nPSL uses ADMM  (Boyd et al. 2010 ) to efficiently solve MAP inference.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Erc In Psl",
      "text": "We now describe the rules that compose our PSL model that predicts the emotion associated with each utterance. Each rule encodes structural information about conversational emotion and can be broken into the following categories: label propagation, utterance similarity, neural classification, sum constraint, and priors.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Label Propagation",
      "text": "In this set of rules, we take advantage of the inherent structure in the dialogue to propagate labels. First, we capture the intuition that conversations tend to have overlying dominant emotion:\n\nwhere NEXTUTTERANCE ties together an utterance, Utterance1 with the next utterance in the conversation Utterance2. This rule propagates emotion from one utterance to the next utterance in a conversation. In this fashion, all utterances in a conversation are chained together and an emotional shift in one influences all others.\n\nThe next rule models a speaker maintaining a consistent emotional state between utterances:\n\nwhere NEXTSELFUTTERANCE ties together an utterance, Utterance1 with the next utterance spoken by the same speaker Utterance2.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Similarity",
      "text": "This rule ensures that similar utterances have similar emotional labels:\n\nwhere SIMILARUTTERANCE is a computed similarity between two utterances. Any similarity between two utterances can be used here. In this model, we use the cosine similarity between the embeddings for each utterance. To create embeddings, we use Google's Universal Sentence Encoder version 4  (Cer et al. 2018) . To reduce the size of the graphical model, we only include the highest 10 similarities for each utterance.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Neural Classification",
      "text": "This rule incorporates a neural model into PSL's logic-based model:\n\nwhere NEURALCLASSIFIER is a neural network that takes in the embedding for an utterance, and predicts the emotional label for that utterance. PSL incorporates the network represented by the NEURALCLASSIFIER predicate by mapping the predictions made by the network into PSL ground atoms. Figure  3  shows how neural predictions are incorporated into the PSL model.\n\nThe network used here is a simple feedforward network with a single hidden layer. The input is the utterance em-Figure  3 : An example of how neural information is incorporated into the PSL model. An utterance is encoded into a sentence embedding, which is then passed to a neural network which makes a prediction for the emotion label. The predictions from the neural network are then incorporated directly into the PSL model as atoms.\n\nbedding, the hidden layer has a size of 256 with a ReLu activation function, and the output layer has one neuron per emotion and uses a softmax activation function.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Sum Constraint",
      "text": "Next, we use a PSL hard constraint to ensure that predictions for an utterance sum to 1: UTTERANCEEMOTION(Utterance, +Emotion) = 1.0.\n\nThis constraint prevents degenerate solutions where all emotions are given full or no confidence (1 and 0 respectively). Instead all emotion predictions for an utterance must compete with one another and sum to exactly 1. The first prior pushes the predictions for all utterances and emotional labels towards zero. Pushes all values towards zero acts both as a regularizer and defaults predictions without supporting evidence to zero.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Priors",
      "text": "The second prior explicitly encodes the modeling assumption that every utterance is associated with an emotion. Specifically, this rules provides an additional penalty for predicting a label of No Emotion. This is a strong assumption that does not apply to all of ERC, but Section 6.2 goes into detail on why this assumption works well with the specific dataset we used. Therefore, in this model we assume that every utterance is associated with an emotion, and we treat every instance of an utterance labeled without emotion as a latent variable.\n\nIn combination with the sum constraint from Section 4.4, the negative prior on No Emotion allow PSL to redistribute predictive mass that would otherwise be used on No Emotion to other class labels. This allows our model to reason about other emotions even in the presence of a highly biased dataset like DailyDialog.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Dataset",
      "text": "The method we propose in this paper is designed to detect emotions in multi-turn dyadic conversations. We assume that the emotional tone is fairly consistent between utterances (i.e. there are no sudden shifts between unrelated emotions) and emotions can propagate from one utterance to another. These assumptions work best in conversations that are short and single topic, such as the dialogues in DailyDialog. DailyDialog  (Li et al. 2017 ) is a multi-turn, dyadic text dataset that was created from conversations prepared by humans for the purpose of teaching English as a second language (ESL). Accordingly, conversations in DailyDia- log tend to use simple vocabulary and grammatical structures. Each conversation is designed to be a two-person conversation one may have in their typical daily communication. Each conversation in DailyDialog is short and about revolves around a specific topic. Therefore the participants emotions in the conversations are consistent and the emotional structure of the dialogues are not complex compared to the conversations from other datasets  (Zahiri and Choi 2018; Poria et al. 2019a) , which contain both long utterances and conversations are may contain about multiple topics per conversation.\n\nThe conversations in DailyDialog average around eight utterances split between two speakers and cover various topics such as the weather, work life, family life, and traveling. The DailyDialog dataset is partitioned into a single traintest split. Table  1  shows conversation-level statistics on this dataset. Each utterance is labeled with one of seven emotional labels. The labeling for this dataset is heavily biased towards the No Emotion label, and to a lesser extent the Happiness label. Table  2  shows per-label statistics on this dataset. The per-utterance emotion labels provided in Dai-lyDialog allows us to incorporate the emotional structure of the dialogue during emotion detection, which is not viable for datasets with only conversation level labels, such as the EmpatheticDialogues dataset  (Rashkin et al. 2018) .",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "Evaluation",
      "text": "In this section, we evaluate the quantitative performance of our model against other recent ERC methods. We also perform a qualitative analysis over our results. Data and code will be made available upon publishing.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Quantitative Model Comparison",
      "text": "To evaluate the performance of our model, we compare against three recent ERC models: CNN+cLSTM  (Poria et al. 2017) , COSMIC  (Ghosal et al. 2020) , and CESTa  (Wang et al. 2020) .\n\nCNN+cLSTM  (Poria et al. 2017 ): Uses a CNN to obtain textual features for an utterance, then applies a context LSTM (cLSTM) over those features to learn contextual information.\n\nCOSMIC  (Ghosal et al. 2020 ): Uses different elements of commonsense such as mental states, events, and causal relations to learn interactions between interlocutors participating in a conversation.\n\nCESTa  (Wang et al. 2020 ): Models ERC as a sequence tagging task where a conditional random field is leveraged to learn the emotional consistency in the conversation. Uses LSTM-based encoders that capture self and inter-speaker dependency to generate contextualized utterance representations. Uses a multi-layer transformer encoder to capture long-range global context.\n\nFollowing the pattern established by the previous methods, our evaluation is performed over the single, canonical split provided with the DailyDialog dataset, and the No Emotion label is ignored when computing the Micro F1 score. Table  4  shows the results comparing our method with the previously discussed methods. Here we can clearly see the power of incorporating structure with neural components. Our PSL model performs nearly 20 percentage points better than the next leading method (CESTa).\n\nTo further verify our results, we evaluated our method over ten randomly generated splits of DailyDialog. To create these splits, the dataset was shuffled and 10% of conversations were assigned to the test set while the remaining 90% of conversations were assigned to the train set. For these splits, we also evaluated CNN+cLSTM to compare against our method 1  . Table  5  shows that when averaged over ten splits, PSL and CNN+cLSTM both achieve similar performance to the single canonical split. Our PSL method diverges by only 0.33 standard deviations while CNN+cLSTM diverges by only 1.24 standard deviations.",
      "page_start": 5,
      "page_end": 6
    },
    {
      "section_name": "Noisy Emotional Labels",
      "text": "DailyDialog contains more than a 100k labeled utterances. However despite being human annotated, several of the emotional labels are noisy. Noisy labels provides an interesting challenge for ERC systems, since these systems must overcome both the uncertain nature of human emotions in addition to the uncertain nature of noisy labels. We posit that collective/joint methods have the potential to perform well in these noisy settings, because relational information can provide additional signals to overpower the noisy labels. For example, Table  3  shows several utterances that contain questionable emotion labels, as well as the prediction PSL assigns these utterances. In these cases, PSL provides reasonable emotional predictions over the questionable labels.\n\nAs seen in Table  2 , DailyDialog is heavily biased towards the No Emotion class. At first, it may seem that this class represents utterances that have no clear emotional context, as seen in Table  6 . However, the No Emotion label is also clearly used in cases where emotional context is apparent. Table  3  shows examples where an utterance is labeled as No Emotion, but it is clear that a label associated with an emotion is more appropriate. This double use of the No Emotion label in both cases where no clear emotion is present and where an utterance merely has no label further increases the difficulty of using the DailyDialog dataset. Finally, there are cases where the No Emotion label is used for a specific utterance, but the context of the conversation provides information on what the labeling should be. Table  7  shows additional dialog context for the last two utterances in Table  6 . Both of these utterances (in bold) were labeled as No Emotion, and without any other context that label would make sense. However with the full context of the dialog (the speaker being bound, gagged, and robbed), a more appropriate label should be applied (e.g. Anger, Fear, or Sadness).\n\nThe presence of noisy emotion labels and use of the dataset for ERC. However, this difficulty provides an opportunity for collective/joint methods, such as PSL, that can incorporate contextual and domain information as well as labels into predictions. Additionally, the presence of utterances labeled No Emotion reinforces the modeling assumption made in Section 4.5, which assumes that all utterances contain some traces of emotion and should not be labeled No Emotion.",
      "page_start": 5,
      "page_end": 6
    },
    {
      "section_name": "Conclusions And Future Work",
      "text": "In this paper, we proposed a structured method for the task of ERC that combines a simple neural model with relational inference provided by PSL. Our initial experiments show that even a simple neural model combined with general-purpose logical rules can outperform complex and specific state-ofthe-art neural models. Furthermore, our qualitative analysis shows our model performing well even in situations where the dataset's labels are open to question.\n\nIn our future work, we plan to extend both the neural and logical components of our model. On the neural side, we can utilize more complex neural models. On the logical side, we can incorporate additional structure into our models by computing more sophisticated utterance similarity and integrating both conversation-level and user-level similarities. We also want to prove the generality of our approach by testing Speaker Utterance Speaker 1 Good evening, sir.\n\nI understand that you have been robbed. Speaker 2 I certainly have. Speaker 1 When did this happen? Speaker 2 About two hours ago. Speaker 1 Why didn't you report it before? Speaker 2 I couldn't. I was bound and gagged.",
      "page_start": 6,
      "page_end": 6
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: two friends visiting the Empire State Building for",
      "page": 1
    },
    {
      "caption": "Figure 1: A sample conversation with representative emo-",
      "page": 1
    },
    {
      "caption": "Figure 2: visually demonstrates the",
      "page": 3
    },
    {
      "caption": "Figure 2: A sample conversation with the structure of the",
      "page": 3
    },
    {
      "caption": "Figure 3: shows how neural predictions are incorporated into",
      "page": 3
    },
    {
      "caption": "Figure 3: An example of how neural information is incorporated into the PSL model. An utterance is encoded into a sentence",
      "page": 4
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "itative and quantitative analysis over the DailyDialog conver-": ""
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": "sation dataset."
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": ""
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": ""
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": "1\nIntroduction"
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": ""
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": "With the growing popularity of\nconversational\nagents\nin"
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": ""
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": "daily life, the need for agents that can appropriately respond"
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": ""
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": "to long running conversations and that can understand com-"
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": ""
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": "plex human linguistic tendencies and social cues is becom-"
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": ""
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": "ing increasingly important. This growth in popularity has"
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": ""
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": "sparked a large interest in conversational research. A recent"
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": ""
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": "pillar of this emerging ﬁeld has been around emotion recog-"
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": ""
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": "nition in conversation (ERC); a sub-ﬁeld of emotion recog-"
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": ""
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": "nition that focuses on conversations or dialogues that contain"
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": ""
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": "two or more utterances. Poria et al. (2019b) provides a thor-"
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": ""
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": "ough overview of the current state of ERC. For example, in"
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": ""
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": "Figure 1 two friends visiting the Empire State Building for"
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": ""
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": "the ﬁrst share a typical conversation where the speakers ex-"
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": ""
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": "press surprise, neutral emotion, and then happiness. An au-"
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": ""
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": "tomated assistant with access to this conversation may take"
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": ""
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": "very different actions depending on the emotions expressed"
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": ""
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": "by the speakers, e.g., checking for hours of operations if the"
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": ""
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": "Copyright © 2022, Association for the Advancement of Artiﬁcial"
        },
        {
          "itative and quantitative analysis over the DailyDialog conver-": "Intelligence (www.aaai.org). All rights reserved."
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Abstract": "Creating agents that can both appropriately respond to con-"
        },
        {
          "Abstract": "versations and understand complex human linguistic tenden-"
        },
        {
          "Abstract": "cies and social cues has been a long standing challenge in"
        },
        {
          "Abstract": "the NLP community. A recent pillar of\nresearch revolves"
        },
        {
          "Abstract": "around emotion recognition in conversation (ERC); a sub-"
        },
        {
          "Abstract": "ﬁeld of emotion recognition that focuses on conversations or"
        },
        {
          "Abstract": "dialogues that contain two or more utterances. In this work,"
        },
        {
          "Abstract": "we explore an approach to ERC that exploits the use of neu-"
        },
        {
          "Abstract": "ral embeddings along with complex structures in dialogues."
        },
        {
          "Abstract": "We implement our approach in a framework called Proba-"
        },
        {
          "Abstract": "bilistic Soft Logic (PSL), a declarative templating language"
        },
        {
          "Abstract": "that uses ﬁrst-order\nlike logical\nrules,\nthat when combined"
        },
        {
          "Abstract": "with data, deﬁne a particular class of graphical model. Addi-"
        },
        {
          "Abstract": "tionally, PSL provides functionality for the incorporation of"
        },
        {
          "Abstract": "results from neural models into PSL models. This allows our"
        },
        {
          "Abstract": "model to take advantage of advanced neural methods, such as"
        },
        {
          "Abstract": "sentence embeddings, and logical\nreasoning over\nthe struc-"
        },
        {
          "Abstract": "ture of a dialogue. We compare our method with state-of-the-"
        },
        {
          "Abstract": "art purely neural ERC systems, and see almost a 20% im-"
        },
        {
          "Abstract": "provement. With these results, we provide an extensive qual-"
        },
        {
          "Abstract": "itative and quantitative analysis over the DailyDialog conver-"
        },
        {
          "Abstract": ""
        },
        {
          "Abstract": "sation dataset."
        },
        {
          "Abstract": ""
        },
        {
          "Abstract": ""
        },
        {
          "Abstract": "1\nIntroduction"
        },
        {
          "Abstract": ""
        },
        {
          "Abstract": "With the growing popularity of\nconversational\nagents\nin"
        },
        {
          "Abstract": ""
        },
        {
          "Abstract": "daily life, the need for agents that can appropriately respond"
        },
        {
          "Abstract": ""
        },
        {
          "Abstract": "to long running conversations and that can understand com-"
        },
        {
          "Abstract": ""
        },
        {
          "Abstract": "plex human linguistic tendencies and social cues is becom-"
        },
        {
          "Abstract": ""
        },
        {
          "Abstract": "ing increasingly important. This growth in popularity has"
        },
        {
          "Abstract": ""
        },
        {
          "Abstract": "sparked a large interest in conversational research. A recent"
        },
        {
          "Abstract": ""
        },
        {
          "Abstract": "pillar of this emerging ﬁeld has been around emotion recog-"
        },
        {
          "Abstract": ""
        },
        {
          "Abstract": "nition in conversation (ERC); a sub-ﬁeld of emotion recog-"
        },
        {
          "Abstract": ""
        },
        {
          "Abstract": "nition that focuses on conversations or dialogues that contain"
        },
        {
          "Abstract": ""
        },
        {
          "Abstract": "two or more utterances. Poria et al. (2019b) provides a thor-"
        },
        {
          "Abstract": ""
        },
        {
          "Abstract": "ough overview of the current state of ERC. For example, in"
        },
        {
          "Abstract": ""
        },
        {
          "Abstract": "Figure 1 two friends visiting the Empire State Building for"
        },
        {
          "Abstract": ""
        },
        {
          "Abstract": "the ﬁrst share a typical conversation where the speakers ex-"
        },
        {
          "Abstract": ""
        },
        {
          "Abstract": "press surprise, neutral emotion, and then happiness. An au-"
        },
        {
          "Abstract": ""
        },
        {
          "Abstract": "tomated assistant with access to this conversation may take"
        },
        {
          "Abstract": ""
        },
        {
          "Abstract": "very different actions depending on the emotions expressed"
        },
        {
          "Abstract": ""
        },
        {
          "Abstract": "by the speakers, e.g., checking for hours of operations if the"
        },
        {
          "Abstract": ""
        },
        {
          "Abstract": "Copyright © 2022, Association for the Advancement of Artiﬁcial"
        },
        {
          "Abstract": "Intelligence (www.aaai.org). All rights reserved."
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "et\nal. 2017),\na declarative\ntemplating language\nthat uses",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "lize graph convolutional networks (GCN) (Defferrard, Bres-"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "ﬁrst order like logical rules,\nthat when combined with data,",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "son,\nand Vandergheynst 2016),\nand model both context-"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "deﬁne a particular class of graphical model. PSL provides",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "sensitive and speaker-sensitive dependence for emotion de-"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "a simple framework for\nincorporating structural conversa-",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "tection. Additionally, KET (Zhong, Wang, and Miao 2019)"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "tional knowledge through ﬁrst order logical rules, provides",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "and COSMIC (Ghosal et al. 2020) attempt to improve results"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "efﬁcient and scalable statistical inference, and has shown to",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "by using external commonsense knowledge, while BERT"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "be effective in complex domains that beneﬁt from collective",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "DCR-Net (Qin et al. 2020) and BERT+MTL (Li et al. 2020)"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "inference (Tomkins et al. 2017; Kouki et al. 2019; Sridhar",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "use BERT (Devlin et al. 2019) based features to aid in senti-"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "and Getoor 2019; Embar et al. 2020). Furthermore, PSL al-",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "ment recognition. Finally, CESTa (Wang et al. 2020) models"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "lows for the integration of predictions from neural networks",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "the ERC task as sequence tagging and uses conditional ran-"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "into PSL models, allowing for the seamless use of language",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "dom ﬁelds (CRF)\n(Sutton, McCallum, and Rohanimanesh"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "embeddings into structured models.",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "2007) to model the emotional consistency in conversation."
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "Our key contributions are as follows: 1) we create a gen-",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": ""
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "eral and extendable framework for ERC using PSL that can",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": ""
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "3\nProbabilistic Soft Logic"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "be applied to various ERC datasets, 2) we provide a through",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": ""
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "Probabilistic Soft Logic (PSL)\nis a probabilistic program-"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "experimental evaluation over a popular ERC dataset, Daily-",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": ""
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "ming language used to deﬁne a special class of Markov ran-"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "Dialog, 3) we show both qualitative and quantitatively that",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": ""
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "dom ﬁelds (MRF), a hinge-loss Markov random ﬁeld (HL-"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "PSL outperforms the state-of-the-art models by almost 20%,",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": ""
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "MRF)\n(Bach et al. 2017). HL-MRFs are a class of condi-"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "and 4) we provide a qualitative exploration of the DailyDi-",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": ""
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "tional probabilistic models over continuous variables which"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "alog dataset,\nin which we highlight areas of potential\nim-",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": ""
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "allow for scalable and exact inference (Bach et al. 2013)."
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "provement.",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": ""
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "PSL models relational dependencies and structural con-"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "straints using weighted ﬁrst-order\nlogical clauses,\nreferred"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "2\nRelated Work",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": ""
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "to as rules. For example, consider the rule:"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "The broader\ntask of emotion recognition has been a long",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": ""
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "standing problem across many ﬁelds of research,\nincluding",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": ""
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "machine learning,\nsignal processing,\nsocial cognitive psy-",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "w :HASEMOTION(Utterance1, Emotion)"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "chology, etc. The techniques used in emotion recognition",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "∧ SIMILARTEXT(Utterance1, Utterance2)"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "heavily overlap with the related problems of sentiment anal-",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": ""
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "→ HASEMOTION(Utterance2, Emotion)"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "ysis and opinion mining (Pang and Lee 2008). All of these",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": ""
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "problems share the common goal of extracting the thoughts,",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "where the predicates HASEMOTION and SIMILARTEXT re-"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "feelings, and opinions of others. However, where sentiment",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "spectively predict\nthe emotional\nlabel\nfor an utterance and"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "analysis\nconsiders\na person’s\nfeelings\ntowards\nan entity,",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "deﬁne the similarity of two utterances, and w acts as a learn-"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "emotion recognition focuses more broadly on the emotion",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "able weight for the rule that denotes the rule’s relative im-"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "that a person feels, regardless of the target of that emotion.",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "portance in the model. This rule encodes the domain knowl-"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "Additionally, sentiment analysis is typically performed on",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "edge that utterances with similar texts (Utterance1 and"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "more formal\ntext sources, such as written reviews, whereas",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "Utterance2) should probably be labeled with the same"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "ERC is typically performed on dialogues which are less for-",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "emotion, and establishes a dependency that\nsimilar utter-"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "mal and more causal in nature.",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "ances should share similar labels."
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "ERC has become more popular recently with the release",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "Given the rules for a model and data, PSL generates an"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "of public conversational datasets such as social media con-",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "HL-MRF by instantiating concrete instances of each rule"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "versations and movie/tv-show scripts (Zahiri and Choi 2018;",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "where variables are replaced with actual entities from the"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "Poria et al. 2019a). Recent work in ERC focuses on solv-",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "data. This process is referred to as grounding, and each con-"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "ing the problem with deep learning architectures. One of",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "crete instance of a rule is referred to as a ground rule. The"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "the earliest networks to produce promising results for ERC",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "logical atoms in the ground rules correspond to the random"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "was a bi-directional contextual LSTM model, bc-LSTM or",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "variables in the HL-MRF, while ground rules correspond to"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "CNN-cLSTM (Poria et al. 2017), which allowed utterances",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "potential functions in the HL-MRF."
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "to get information from subsequent or earlier utterances. To",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "Given the observed variables X, unobserved variables Y ,"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "improve upon this concept, Conversational Memory Net-",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "and potential functions, PSL deﬁnes a probability distribu-"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "works (CMN) (Hazarika et al. 2018b) utilizes distinct mem-",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "tion over the unobserved variables as:"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "ory for each speaker to model speaker speciﬁc information.",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": ""
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "1"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "This method was further\nimproved by Interactive Conver-",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": ""
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "m(cid:88) i\nP (Y |X) =\nexp(−\nwiφi(Y, X))"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "sational Memory Networks (ICON) (Hazarika et al. 2018a)",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "Z(Y )"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "=1"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "and Interaction-aware Attention Networks (IAN) (Yeh, Lin,",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": ""
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "(cid:90)"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "and Lee 2019), where memories were inter-connected. Di-",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": ""
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "m(cid:88) i\nZ(Y ) =\nexp(−\nwiφi(Y, X))"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "alogueRNN (Majumder et al. 2019) expands on the previ-",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "Y"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "=1"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "ous methods by using Gated Recurrent Units (GRU) (Chung",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": ""
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "et al. 2014) as memory cells and is\nspeciﬁcally modeled",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "is the ith\nwhere m is the number of potential functions, φi"
        },
        {
          "using a\nframework called Probabilistic Soft Logic\n(Bach": "to exploit\nthe speaker\ninformation. Further, DialogueGCN",
          "(Ghosal et al. 2019) and ConGCN (Zhang et al. 2019) uti-": "is weight of the tem-\nhinge-loss potential function, and wi"
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "plate rule from which φi was derived. The hinge-loss poten-": "tials are deﬁned as:"
        },
        {
          "plate rule from which φi was derived. The hinge-loss poten-": "φ(Y, X) = [max(0, l(Y, X))]p"
        },
        {
          "plate rule from which φi was derived. The hinge-loss poten-": "where l is a linear function, X and Y are in the range [0, 1],"
        },
        {
          "plate rule from which φi was derived. The hinge-loss poten-": "and p ∈ 1, 2 optionally squares the potential."
        },
        {
          "plate rule from which φi was derived. The hinge-loss poten-": "Exact maximum a posteriori (MAP) inference on this dis-"
        },
        {
          "plate rule from which φi was derived. The hinge-loss poten-": "tribution can be framed as the convex optimization problem:"
        }
      ],
      "page": 3
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Y": "=1"
        },
        {
          "Y": "= arg min\nLmap(w, X, Y )"
        },
        {
          "Y": "Y"
        },
        {
          "Y": "PSL uses ADMM (Boyd et al. 2010)\nto efﬁciently solve"
        },
        {
          "Y": ""
        },
        {
          "Y": "MAP inference."
        },
        {
          "Y": ""
        },
        {
          "Y": ""
        },
        {
          "Y": "4\nERC in PSL"
        },
        {
          "Y": ""
        },
        {
          "Y": ""
        },
        {
          "Y": "We now describe the rules\nthat compose our PSL model"
        },
        {
          "Y": "that predicts\nthe\nemotion associated with each utterance."
        },
        {
          "Y": "Each rule encodes\nstructural\ninformation about conversa-"
        },
        {
          "Y": "tional emotion and can be broken into the following cate-"
        },
        {
          "Y": "gories: label propagation, utterance similarity, neural classi-"
        },
        {
          "Y": "ﬁcation, sum constraint, and priors."
        }
      ],
      "page": 3
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Figure 3: An example of how neural\ninformation is incorporated into the PSL model. An utterance is encoded into a sentence": "embedding, which is then passed to a neural network which makes a prediction for the emotion label. The predictions from the"
        },
        {
          "Figure 3: An example of how neural\ninformation is incorporated into the PSL model. An utterance is encoded into a sentence": "neural network are then incorporated directly into the PSL model as atoms."
        },
        {
          "Figure 3: An example of how neural\ninformation is incorporated into the PSL model. An utterance is encoded into a sentence": "detail on why this assumption works well with the speciﬁc\nbedding, the hidden layer has a size of 256 with a ReLu ac-"
        },
        {
          "Figure 3: An example of how neural\ninformation is incorporated into the PSL model. An utterance is encoded into a sentence": "tivation function, and the output\nlayer has one neuron per\ndataset we used. Therefore,\nin this model we assume that"
        },
        {
          "Figure 3: An example of how neural\ninformation is incorporated into the PSL model. An utterance is encoded into a sentence": "emotion and uses a softmax activation function.\nevery utterance is associated with an emotion, and we treat"
        },
        {
          "Figure 3: An example of how neural\ninformation is incorporated into the PSL model. An utterance is encoded into a sentence": "every instance of an utterance labeled without emotion as a"
        },
        {
          "Figure 3: An example of how neural\ninformation is incorporated into the PSL model. An utterance is encoded into a sentence": "4.4\nSum Constraint\nlatent variable."
        },
        {
          "Figure 3: An example of how neural\ninformation is incorporated into the PSL model. An utterance is encoded into a sentence": "In combination with the sum constraint from Section 4.4,"
        },
        {
          "Figure 3: An example of how neural\ninformation is incorporated into the PSL model. An utterance is encoded into a sentence": "Next, we use a PSL hard constraint to ensure that predictions"
        },
        {
          "Figure 3: An example of how neural\ninformation is incorporated into the PSL model. An utterance is encoded into a sentence": "the negative prior on No Emotion allow PSL to redistribute"
        },
        {
          "Figure 3: An example of how neural\ninformation is incorporated into the PSL model. An utterance is encoded into a sentence": "for an utterance sum to 1:"
        },
        {
          "Figure 3: An example of how neural\ninformation is incorporated into the PSL model. An utterance is encoded into a sentence": "predictive mass that would otherwise be used on No Emo-"
        },
        {
          "Figure 3: An example of how neural\ninformation is incorporated into the PSL model. An utterance is encoded into a sentence": "tion to other class labels. This allows our model\nto reason"
        },
        {
          "Figure 3: An example of how neural\ninformation is incorporated into the PSL model. An utterance is encoded into a sentence": "UTTERANCEEMOTION(Utterance, +Emotion) = 1.0."
        },
        {
          "Figure 3: An example of how neural\ninformation is incorporated into the PSL model. An utterance is encoded into a sentence": "about other emotions even in the presence of a highly biased"
        },
        {
          "Figure 3: An example of how neural\ninformation is incorporated into the PSL model. An utterance is encoded into a sentence": "dataset like DailyDialog."
        },
        {
          "Figure 3: An example of how neural\ninformation is incorporated into the PSL model. An utterance is encoded into a sentence": "This constraint prevents degenerate solutions where all emo-"
        },
        {
          "Figure 3: An example of how neural\ninformation is incorporated into the PSL model. An utterance is encoded into a sentence": "5\nDataset"
        },
        {
          "Figure 3: An example of how neural\ninformation is incorporated into the PSL model. An utterance is encoded into a sentence": "tions are given full or no conﬁdence (1 and 0 respectively)."
        },
        {
          "Figure 3: An example of how neural\ninformation is incorporated into the PSL model. An utterance is encoded into a sentence": "Instead all emotion predictions for an utterance must com-\nThe method we propose in this paper\nis designed to de-"
        },
        {
          "Figure 3: An example of how neural\ninformation is incorporated into the PSL model. An utterance is encoded into a sentence": "pete with one another and sum to exactly 1.\ntect emotions in multi-turn dyadic conversations. We assume"
        },
        {
          "Figure 3: An example of how neural\ninformation is incorporated into the PSL model. An utterance is encoded into a sentence": "that\nthe emotional\ntone is\nfairly consistent between utter-"
        },
        {
          "Figure 3: An example of how neural\ninformation is incorporated into the PSL model. An utterance is encoded into a sentence": "4.5\nPriors\nances (i.e. there are no sudden shifts between unrelated emo-"
        },
        {
          "Figure 3: An example of how neural\ninformation is incorporated into the PSL model. An utterance is encoded into a sentence": "tions) and emotions can propagate from one utterance to an-\nFinally, we include two negative priors into our model:"
        },
        {
          "Figure 3: An example of how neural\ninformation is incorporated into the PSL model. An utterance is encoded into a sentence": "other. These assumptions work best in conversations that are"
        },
        {
          "Figure 3: An example of how neural\ninformation is incorporated into the PSL model. An utterance is encoded into a sentence": "short and single topic, such as the dialogues in DailyDialog."
        },
        {
          "Figure 3: An example of how neural\ninformation is incorporated into the PSL model. An utterance is encoded into a sentence": "UTTERANCEEMOTION(Utterance, Emotion) = 0.0"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table 4: shows the results comparing our method",
      "data": [
        {
          "Emotion Label\nCount\nPercentage": "Anger\n1022\n0.99",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "COSMIC (Ghosal\net\nal. 2020): Uses different\nelements"
        },
        {
          "Emotion Label\nCount\nPercentage": "Disgust\n353\n0.34",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "of commonsense such as mental states, events, and causal"
        },
        {
          "Emotion Label\nCount\nPercentage": "Fear\n74\n0.17",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "relations to learn interactions between interlocutors partici-"
        },
        {
          "Emotion Label\nCount\nPercentage": "Happiness\n12885\n12.51",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "pating in a conversation."
        },
        {
          "Emotion Label\nCount\nPercentage": "Sadness\n1150\n1.12",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "Surprise\n1823\n1.77",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "CESTa (Wang et\nal. 2020): Models ERC as\na\nsequence"
        },
        {
          "Emotion Label\nCount\nPercentage": "No Emotion\n85572\n83.10",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "tagging task where a conditional random ﬁeld is leveraged"
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "to learn the emotional consistency in the conversation. Uses"
        },
        {
          "Emotion Label\nCount\nPercentage": "Table 2: Label-level statistics about DailyDialog. Count rep-",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "LSTM-based encoders\nthat capture self and inter-speaker"
        },
        {
          "Emotion Label\nCount\nPercentage": "resents the total number of utterances with that emotional",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "dependency to generate contextualized utterance represen-"
        },
        {
          "Emotion Label\nCount\nPercentage": "label (one label per utterance), while Percentage represents",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "tations. Uses a multi-layer\ntransformer encoder\nto capture"
        },
        {
          "Emotion Label\nCount\nPercentage": "the percentage of utterances in the dataset with the associ-",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "long-range global context."
        },
        {
          "Emotion Label\nCount\nPercentage": "ated label.",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "Following the pattern established by the previous meth-"
        },
        {
          "Emotion Label\nCount\nPercentage": "log tend to use simple vocabulary and grammatical struc-",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "ods, our\nevaluation is performed over\nthe\nsingle,\ncanon-"
        },
        {
          "Emotion Label\nCount\nPercentage": "tures. Each conversation is designed to be a two-person con-",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "ical\nsplit provided with the DailyDialog dataset,\nand the"
        },
        {
          "Emotion Label\nCount\nPercentage": "versation one may have in their\ntypical daily communica-",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "No Emotion label\nis\nignored when computing the Micro"
        },
        {
          "Emotion Label\nCount\nPercentage": "tion. Each conversation in DailyDialog is short and about",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "F1 score. Table 4 shows the results comparing our method"
        },
        {
          "Emotion Label\nCount\nPercentage": "revolves around a speciﬁc topic. Therefore the participants",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "with the previously discussed methods. Here we can clearly"
        },
        {
          "Emotion Label\nCount\nPercentage": "emotions in the conversations are consistent and the emo-",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "see the power of incorporating structure with neural compo-"
        },
        {
          "Emotion Label\nCount\nPercentage": "tional structure of the dialogues are not complex compared",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "nents. Our PSL model performs nearly 20 percentage points"
        },
        {
          "Emotion Label\nCount\nPercentage": "to the conversations\nfrom other datasets\n(Zahiri and Choi",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "better than the next leading method (CESTa)."
        },
        {
          "Emotion Label\nCount\nPercentage": "2018; Poria et al. 2019a), which contain both long utterances",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "To further verify our\nresults, we evaluated our method"
        },
        {
          "Emotion Label\nCount\nPercentage": "and conversations are may contain about multiple topics per",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "over ten randomly generated splits of DailyDialog. To create"
        },
        {
          "Emotion Label\nCount\nPercentage": "conversation.",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "these splits,\nthe dataset was shufﬂed and 10% of conversa-"
        },
        {
          "Emotion Label\nCount\nPercentage": "The conversations\nin DailyDialog average around eight",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "tions were assigned to the test set while the remaining 90%"
        },
        {
          "Emotion Label\nCount\nPercentage": "utterances split between two speakers and cover various top-",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "of conversations were assigned to the train set. For\nthese"
        },
        {
          "Emotion Label\nCount\nPercentage": "ics such as the weather, work life, family life, and traveling.",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "splits, we also evaluated CNN+cLSTM to compare against"
        },
        {
          "Emotion Label\nCount\nPercentage": "The DailyDialog dataset\nis partitioned into a single train-",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "our method1. Table 5 shows\nthat when averaged over\nten"
        },
        {
          "Emotion Label\nCount\nPercentage": "test split. Table 1 shows conversation-level statistics on this",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "splits, PSL and CNN+cLSTM both achieve similar perfor-"
        },
        {
          "Emotion Label\nCount\nPercentage": "dataset. Each utterance is labeled with one of seven emo-",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "mance to the single canonical\nsplit. Our PSL method di-"
        },
        {
          "Emotion Label\nCount\nPercentage": "tional\nlabels. The labeling for this dataset\nis heavily biased",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "verges by only 0.33 standard deviations while CNN+cLSTM"
        },
        {
          "Emotion Label\nCount\nPercentage": "towards\nthe No Emotion label, and to a lesser extent\nthe",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "diverges by only 1.24 standard deviations."
        },
        {
          "Emotion Label\nCount\nPercentage": "Happiness label. Table 2 shows per-label statistics on this",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "dataset. The per-utterance emotion labels provided in Dai-",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "6.2\nNoisy Emotional Labels"
        },
        {
          "Emotion Label\nCount\nPercentage": "lyDialog allows us to incorporate the emotional structure of",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "DailyDialog contains more than a 100k labeled utterances."
        },
        {
          "Emotion Label\nCount\nPercentage": "the dialogue during emotion detection, which is not viable",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "However despite being human annotated, several of the emo-"
        },
        {
          "Emotion Label\nCount\nPercentage": "for datasets with only conversation level\nlabels, such as the",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "tional\nlabels are noisy. Noisy labels provides an interesting"
        },
        {
          "Emotion Label\nCount\nPercentage": "EmpatheticDialogues dataset (Rashkin et al. 2018).",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "challenge for ERC systems, since these systems must over-"
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "come both the uncertain nature of human emotions in ad-"
        },
        {
          "Emotion Label\nCount\nPercentage": "6\nEvaluation",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "dition to the uncertain nature of noisy labels. We posit\nthat"
        },
        {
          "Emotion Label\nCount\nPercentage": "In this section, we evaluate the quantitative performance of",
          "information.": "collective/joint methods have the potential\nto perform well"
        },
        {
          "Emotion Label\nCount\nPercentage": "our model against other recent ERC methods. We also per-",
          "information.": "in these noisy settings, because relational\ninformation can"
        },
        {
          "Emotion Label\nCount\nPercentage": "form a qualitative analysis over our results. Data and code",
          "information.": "provide additional signals to overpower the noisy labels. For"
        },
        {
          "Emotion Label\nCount\nPercentage": "will be made available upon publishing.",
          "information.": "example, Table 3 shows several utterances that contain ques-"
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "tionable emotion labels, as well as the prediction PSL as-"
        },
        {
          "Emotion Label\nCount\nPercentage": "6.1\nQuantitative Model Comparison",
          "information.": "signs these utterances. In these cases, PSL provides reason-"
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "able emotional predictions over the questionable labels."
        },
        {
          "Emotion Label\nCount\nPercentage": "To evaluate\nthe performance of our model, we\ncompare",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "As seen in Table 2, DailyDialog is heavily biased towards"
        },
        {
          "Emotion Label\nCount\nPercentage": "against\nthree\nrecent ERC models: CNN+cLSTM (Poria",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "the No Emotion class. At ﬁrst,\nit may seem that\nthis class"
        },
        {
          "Emotion Label\nCount\nPercentage": "et\nal. 2017), COSMIC (Ghosal\net\nal. 2020),\nand CESTa",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "represents utterances that have no clear emotional context,"
        },
        {
          "Emotion Label\nCount\nPercentage": "(Wang et al. 2020).",
          "information.": ""
        },
        {
          "Emotion Label\nCount\nPercentage": "",
          "information.": "as seen in Table 6. However,\nthe No Emotion label\nis also"
        },
        {
          "Emotion Label\nCount\nPercentage": "CNN+cLSTM (Poria et al. 2017): Uses a CNN to obtain",
          "information.": "1CNN+cLSTM was chosen for this comparison because of its"
        },
        {
          "Emotion Label\nCount\nPercentage": "textual\nfeatures\nfor\nan\nutterance,\nthen\napplies\na\ncontext",
          "information.": "relatively quick runtime and its ease-of-use when running on a new"
        },
        {
          "Emotion Label\nCount\nPercentage": "LSTM (cLSTM)\nover\nthose\nfeatures\nto\nlearn\ncontextual",
          "information.": "dataset."
        }
      ],
      "page": 5
    },
    {
      "caption": "Table 4: Comparison of the Micro F1 of multiple methods NoEmotion I’madoctor.",
      "data": [
        {
          "Label": "Anger",
          "Prediction": "Disgust",
          "Utterance": "Yuck!"
        },
        {
          "Label": "Disgust",
          "Prediction": "Anger",
          "Utterance": "My husband goes out drinking with his friends every night. I’m fed up with it."
        },
        {
          "Label": "Fear",
          "Prediction": "Happiness",
          "Utterance": "What a thrilling trip!"
        },
        {
          "Label": "Fear",
          "Prediction": "Happiness",
          "Utterance": "I love that dish as well. It is coconut chicken with rice."
        },
        {
          "Label": "Fear",
          "Prediction": "Happiness",
          "Utterance": "I am happy that you like the house. We should write down what we like so that we can remember it."
        },
        {
          "Label": "Happiness",
          "Prediction": "Anger",
          "Utterance": "Ugh!"
        },
        {
          "Label": "Surprise",
          "Prediction": "Sadness",
          "Utterance": "Was I? Sorry, I didn’y mean to be. I do apologize."
        },
        {
          "Label": "No Emotion",
          "Prediction": "Anger",
          "Utterance": "Damp it! How are you killing me with a single shot? It’s not fair! I don’t want to play anymore!"
        },
        {
          "Label": "No Emotion",
          "Prediction": "Disgust",
          "Utterance": "What a creep! Phony good luck e-mails are one thing, but sexual harassment is crossing the line."
        },
        {
          "Label": "No Emotion",
          "Prediction": "Fear",
          "Utterance": "Oh, doctor. Do I have to? I am afraid of needles!"
        },
        {
          "Label": "No Emotion",
          "Prediction": "Sadness",
          "Utterance": "I don’t know, but I feel terrible."
        },
        {
          "Label": "No Emotion",
          "Prediction": "Happiness",
          "Utterance": "And now we have a two-year-old boy. We’re very happy that he’s healthy and smart."
        },
        {
          "Label": "No Emotion",
          "Prediction": "Surprise",
          "Utterance": "Ah! You’re bleeding all over! What happened?"
        }
      ],
      "page": 6
    },
    {
      "caption": "Table 4: Comparison of the Micro F1 of multiple methods NoEmotion I’madoctor.",
      "data": [
        {
          "Table 3: Utterances with likely noisy labels along with emotion predictions made by PSL.": "Label"
        },
        {
          "Table 3: Utterances with likely noisy labels along with emotion predictions made by PSL.": "No Emotion"
        },
        {
          "Table 3: Utterances with likely noisy labels along with emotion predictions made by PSL.": "No Emotion"
        },
        {
          "Table 3: Utterances with likely noisy labels along with emotion predictions made by PSL.": ""
        },
        {
          "Table 3: Utterances with likely noisy labels along with emotion predictions made by PSL.": "No Emotion"
        },
        {
          "Table 3: Utterances with likely noisy labels along with emotion predictions made by PSL.": "No Emotion"
        },
        {
          "Table 3: Utterances with likely noisy labels along with emotion predictions made by PSL.": "No Emotion"
        },
        {
          "Table 3: Utterances with likely noisy labels along with emotion predictions made by PSL.": "No Emotion"
        },
        {
          "Table 3: Utterances with likely noisy labels along with emotion predictions made by PSL.": "No Emotion"
        }
      ],
      "page": 6
    },
    {
      "caption": "Table 4: Comparison of the Micro F1 of multiple methods NoEmotion I’madoctor.",
      "data": [
        {
          "No Emotion\nWhen’s your birthday?": "No Emotion\nI’m a doctor."
        },
        {
          "No Emotion\nWhen’s your birthday?": "No Emotion\nI certainly have."
        },
        {
          "No Emotion\nWhen’s your birthday?": "No Emotion\nAbout two hours ago."
        },
        {
          "No Emotion\nWhen’s your birthday?": "Table 6: Utterances labeled as No Emotion and showing no"
        },
        {
          "No Emotion\nWhen’s your birthday?": ""
        },
        {
          "No Emotion\nWhen’s your birthday?": "clear emotional context."
        },
        {
          "No Emotion\nWhen’s your birthday?": ""
        },
        {
          "No Emotion\nWhen’s your birthday?": ""
        },
        {
          "No Emotion\nWhen’s your birthday?": "dataset\nfor ERC. However,\nthis difﬁculty provides an op-"
        },
        {
          "No Emotion\nWhen’s your birthday?": "portunity for collective/joint methods, such as PSL, that can"
        },
        {
          "No Emotion\nWhen’s your birthday?": "incorporate contextual and domain information as well as"
        },
        {
          "No Emotion\nWhen’s your birthday?": "labels into predictions. Additionally,\nthe presence of utter-"
        },
        {
          "No Emotion\nWhen’s your birthday?": "ances labeled No Emotion reinforces the modeling assump-"
        },
        {
          "No Emotion\nWhen’s your birthday?": "tion made in Section 4.5, which assumes that all utterances"
        },
        {
          "No Emotion\nWhen’s your birthday?": "contain some traces of emotion and should not be labeled"
        },
        {
          "No Emotion\nWhen’s your birthday?": "No Emotion."
        },
        {
          "No Emotion\nWhen’s your birthday?": ""
        },
        {
          "No Emotion\nWhen’s your birthday?": ""
        },
        {
          "No Emotion\nWhen’s your birthday?": "7\nConclusions and Future Work"
        },
        {
          "No Emotion\nWhen’s your birthday?": "In this paper, we proposed a structured method for the task of"
        },
        {
          "No Emotion\nWhen’s your birthday?": "ERC that combines a simple neural model with relational in-"
        },
        {
          "No Emotion\nWhen’s your birthday?": "ference provided by PSL. Our initial experiments show that"
        },
        {
          "No Emotion\nWhen’s your birthday?": "even a simple neural model combined with general-purpose"
        },
        {
          "No Emotion\nWhen’s your birthday?": "logical rules can outperform complex and speciﬁc state-of-"
        },
        {
          "No Emotion\nWhen’s your birthday?": "the-art neural models. Furthermore, our qualitative analysis"
        },
        {
          "No Emotion\nWhen’s your birthday?": "shows our model performing well even in situations where"
        },
        {
          "No Emotion\nWhen’s your birthday?": "the dataset’s labels are open to question."
        },
        {
          "No Emotion\nWhen’s your birthday?": "In our future work, we plan to extend both the neural and"
        },
        {
          "No Emotion\nWhen’s your birthday?": "logical components of our model. On the neural side, we can"
        },
        {
          "No Emotion\nWhen’s your birthday?": "utilize more complex neural models. On the logical side, we"
        },
        {
          "No Emotion\nWhen’s your birthday?": "can incorporate additional structure into our models by com-"
        },
        {
          "No Emotion\nWhen’s your birthday?": "puting more sophisticated utterance similarity and integrat-"
        },
        {
          "No Emotion\nWhen’s your birthday?": "ing both conversation-level and user-level similarities. We"
        },
        {
          "No Emotion\nWhen’s your birthday?": "also want to prove the generality of our approach by testing"
        }
      ],
      "page": 6
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "and Getoor, L. 2020.\nContrastive Entity Linkage: Mining"
        },
        {
          "Speaker\nUtterance": "Speaker 1\nGood evening, sir.",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "Variational Attributes From Large Catalogs for Entity Link-"
        },
        {
          "Speaker\nUtterance": "I understand that you have",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "age.\nIn Automated Knowledge Base Construction (AKBC)."
        },
        {
          "Speaker\nUtterance": "been robbed.",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "Virtual."
        },
        {
          "Speaker\nUtterance": "I certainly have.\nSpeaker 2",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "Ghandeharioun, A.; McDuff, D.; Czerwinski, M.;\nand"
        },
        {
          "Speaker\nUtterance": "Speaker 1\nWhen did this happen?",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "Rowan, K. 2019.\nEMMA: An Emotion-Aware Wellbeing"
        },
        {
          "Speaker\nUtterance": "About two hours ago.\nSpeaker 2",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "Chatbot.\nIn Affective Computing and Intelligent Interaction"
        },
        {
          "Speaker\nUtterance": "Speaker 1\nWhy didn’t you report it before?",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "(ACII)."
        },
        {
          "Speaker\nUtterance": "Speaker 2\nI couldn’t. I was bound",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "and gagged.",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "Ghosal, D.; Majumder, N.; Gelbukh, A.; Mihalcea, R.; and"
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "Poria, S. 2020.\nCOSMIC: COmmonSense knowledge for"
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "eMotion Identiﬁcation in Conversations. In Empirical Meth-"
        },
        {
          "Speaker\nUtterance": "Table 7: A conversation that demonstrates the overuse of the",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "ods in Natural Language Processing (EMNLP)."
        },
        {
          "Speaker\nUtterance": "No Emotion label. The bold utterances were labeled as No",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "Emotion, but with the context of the full conversation could",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "Ghosal, D.; Majumder, N.; Poria, S.; Chhaya, N.; and Gel-"
        },
        {
          "Speaker\nUtterance": "have been more accurately labeled.",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "bukh, A. F. 2019. DialogueGCN: A Graph Convolutional"
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "Neural Network\nfor Emotion Recognition\nin Conversa-"
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "tion. In Empirical Methods in Natural Language Processing"
        },
        {
          "Speaker\nUtterance": "it on additional ERC datasets. Finally, we plan on addressing",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "(EMNLP)."
        },
        {
          "Speaker\nUtterance": "the issues discussed in Section 6.2 by relabeling the Daily-",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "Hazarika, D.; Poria, S.; Mihalcea, R.; Cambria, E.;\nand"
        },
        {
          "Speaker\nUtterance": "Dialog dataset with ﬁne-grained emotion.",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "Zimmermann, R.\n2018a.\nICON:\nInteractive Conversa-"
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "tional Memory Network for Multimodal Emotion Detec-"
        },
        {
          "Speaker\nUtterance": "References",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "tion. In Empirical Methods in Natural Language Processing"
        },
        {
          "Speaker\nUtterance": "Andr´e, E.; Rehm, M.; Minker, W.; and B¨uhler, D. 2004.",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "(EMNLP)."
        },
        {
          "Speaker\nUtterance": "Endowing Spoken Language Dialogue Systems with Emo-",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "Hazarika, D.; Poria, S.; Zadeh, A.; Cambria, E.; Morency,"
        },
        {
          "Speaker\nUtterance": "tional Intelligence.\nIn Affective Dialogue Systems (ADS).",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "L.;\nand Zimmermann, R. 2018b.\nConversational Mem-"
        },
        {
          "Speaker\nUtterance": "Bach, S.; Broecheler, M.; Huang, B.; and Getoor, L. 2017.",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "ory Network\nfor Emotion Recognition\nin Dyadic Dia-"
        },
        {
          "Speaker\nUtterance": "Hinge-Loss Markov Random Fields and Probabilistic Soft",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "logue Videos.\nIn Association for Computational Linguistics"
        },
        {
          "Speaker\nUtterance": "Logic.\nJournal of Machine Learning Research (JMLR),",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "(ACL)."
        },
        {
          "Speaker\nUtterance": "18(1): 1–67.",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "Hovy, E. 1987.\nGenerating natural\nlanguage under prag-"
        },
        {
          "Speaker\nUtterance": "Bach, S. H.; Huang, B.; London, B.; and Getoor, L. 2013.",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "matic constraints. Journal of Pragmatics, 11(6): 689–719."
        },
        {
          "Speaker\nUtterance": "Hinge-loss Markov Random Fields: Convex Inference for",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "Kouki, P.; Pujara, J.; Marcum, C.; Koehly, L.; and Getoor, L."
        },
        {
          "Speaker\nUtterance": "Intelli-\nStructured Prediction.\nIn Uncertainty in Artiﬁcial",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "2019. Collective Entity Resolution in Multi-Relational Fa-"
        },
        {
          "Speaker\nUtterance": "gence (UAI).",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "International Journal on Knowledge and\nmilial Networks."
        },
        {
          "Speaker\nUtterance": "Boyd, S.; Parikh, N.; Chu, E.; Peleato, B.; and Eckstein, J.",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "Information Systems (KAIS), 61(3): 1547–1581."
        },
        {
          "Speaker\nUtterance": "2010. Distributed Optimization and Statistical Learning via",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "Li, J.; Zhang, M.; Ji, D.; and Liu, Y. 2020. Multi-Task Learn-"
        },
        {
          "Speaker\nUtterance": "Founda-\nthe Alternating Direction Method of Multipliers.",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "ing with Auxiliary Speaker Identiﬁcation for Conversational"
        },
        {
          "Speaker\nUtterance": "tions and Trends in Machine Learning, 3(1): 1–122.",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "Emotion Recognition. arXiv."
        },
        {
          "Speaker\nUtterance": "Cer, D.; Yang, Y.; yi Kong, S.; Hua, N.; Limtiaco, N.; John,",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "Li, Y.; Su, H.; Shen, X.; Li, W.; Cao, Z.;\nand Niu, S."
        },
        {
          "Speaker\nUtterance": "R. S.; Constant, N.; Guajardo-Cespedes, M.; Yuan, S.; Tar,",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "2017. DailyDialog: A Manually Labelled Multi-turn Dia-"
        },
        {
          "Speaker\nUtterance": "C.; Sung, Y.-H.; Strope, B.; and Kurzweil, R. 2018. Univer-",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "logue Dataset. In International Joint Conference on Natural"
        },
        {
          "Speaker\nUtterance": "sal Sentence Encoder for English.\nIn Empirical Methods in",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "Language Processing (IJCNLP)."
        },
        {
          "Speaker\nUtterance": "Natural Language Processing (EMNLP).",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "Majumder, N.; Poria, S.; Hazarika, D.; Mihalcea, R.; Gel-"
        },
        {
          "Speaker\nUtterance": "Chung, J.; G¨ulc¸ehre, C¸ .; Cho, K.; and Bengio, Y. 2014. Em-",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "bukh, A. F.; and Cambria, E. 2019. DialogueRNN: An At-"
        },
        {
          "Speaker\nUtterance": "pirical Evaluation of Gated Recurrent Neural Networks on",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "tentive RNN for Emotion Detection in Conversations.\nIn"
        },
        {
          "Speaker\nUtterance": "Sequence Modeling.\nIn Neural Information Processing Sys-",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "Association for\nthe Advancement of Artiﬁcial\nIntelligence"
        },
        {
          "Speaker\nUtterance": "tems (NeurIPS).",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "(AAAI)."
        },
        {
          "Speaker\nUtterance": "Defferrard, M.; Bresson, X.; and Vandergheynst, P. 2016.",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "Convolutional Neural Networks on Graphs with Fast Local-",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "Mowafey, S.; and Gardner, S. 2012. A novel adaptive ap-"
        },
        {
          "Speaker\nUtterance": "Information Processing\nized Spectral Filtering.\nIn Neural",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "proach for home care ambient intelligent environments with"
        },
        {
          "Speaker\nUtterance": "Systems (NeurIPS).",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "an emotion-aware system. In UKACC International Confer-"
        },
        {
          "Speaker\nUtterance": "",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "ence on Control (CONTROL). IEEE."
        },
        {
          "Speaker\nUtterance": "Devlin,\nJ.; Chang, M.; Lee, K.; and Toutanova, K. 2019.",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": ""
        },
        {
          "Speaker\nUtterance": "BERT: Pre-training of Deep Bidirectional Transformers for",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "Pang, B.; and Lee, L. 2008. Opinion Mining and Sentiment"
        },
        {
          "Speaker\nUtterance": "Language Understanding. In Association for Computational",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "Analysis. Foundations and Trends in Information Retrieval"
        },
        {
          "Speaker\nUtterance": "Linguistics (ACL).",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "(FTIR), 2(1-–2): 1–135."
        },
        {
          "Speaker\nUtterance": "Ekbal, A. 2020. Towards building an affect-aware dialogue",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "Polzin, T. S.;\nand Waibel, A.\n2000.\nEmotion-sensitive"
        },
        {
          "Speaker\nUtterance": "agent with deep neural networks. CSI Transactions on ICT,",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "human-computer interfaces.\nIn ISCA Tutorial and Research"
        },
        {
          "Speaker\nUtterance": "8(2): 249–255.",
          "Embar, V.; Sisman, B.; Wei, H.; Dong, X. L.; Faloutsos, C.;": "Workshop on Speech and Emotion."
        }
      ],
      "page": 7
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "A.; and Morency, L. 2017.\nContext-Dependent Sentiment",
          "Neural Networks.\nIn Association for the Advancement of": "Artiﬁcial Intelligence (AAAI)."
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "Analysis in User-Generated Videos. In Association for Com-",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "",
          "Neural Networks.\nIn Association for the Advancement of": "Zhang, D.; Wu, L.; Sun, C.; Li, S.; Zhu, Q.; and Zhou, G."
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "putational Linguistics (ACL).",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "",
          "Neural Networks.\nIn Association for the Advancement of": "2019. Modeling both Context- and Speaker-Sensitive De-"
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "Poria, S.; Hazarika, D.; Majumder, N.; Naik, G.; Cambria,",
          "Neural Networks.\nIn Association for the Advancement of": "pendence for Emotion Detection in Multi-speaker Conver-"
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "E.; and Mihalcea, R. 2019a. MELD: A Multimodal Multi-",
          "Neural Networks.\nIn Association for the Advancement of": "sations.\nIn International Joint Conference on Artiﬁcial In-"
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "Party Dataset for Emotion Recognition in Conversations.\nIn",
          "Neural Networks.\nIn Association for the Advancement of": "telligence (IJCAI)."
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "Association for Computational Linguistics (ACL).",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "",
          "Neural Networks.\nIn Association for the Advancement of": "Zhong, P.; Wang, D.;\nand Miao, C. 2019.\nKnowledge-"
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "Poria, S.; Majumder, N.; Mihalcea, R.;\nand Hovy, E. H.",
          "Neural Networks.\nIn Association for the Advancement of": "Enriched Transformer\nfor Emotion Detection\nin Textual"
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "2019b.\nEmotion Recognition in Conversation: Research",
          "Neural Networks.\nIn Association for the Advancement of": "Conversations.\nIn Empirical Methods in Natural Language"
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "Challenges, Datasets, and Recent Advances.\nIEEE Access,",
          "Neural Networks.\nIn Association for the Advancement of": "Processing (EMNLP)."
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "7: 100943–100953.",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "Qin, L.; Che, W.; Li, Y.; Ni, M.; and Liu, T. 2020. DCR-Net:",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "A Deep Co-Interactive Relation Network for Joint Dialog",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "Act Recognition and Sentiment Classiﬁcation.\nIn Associa-",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "tion for the Advancement of Artiﬁcial Intelligence (AAAI).",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "Rashkin, H.; Smith, E. M.; Li, M.; and Boureau, Y.-L. 2018.",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "I Know the Feeling: Learning to Converse with Empathy.",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "arXiv.",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "Schl¨oder, J. J.; and Fern´andez, R. 2015.\nClarifying Inten-",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "tions in Dialogue: A Corpus Study.\nIn Computational Se-",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "mantics (IWCS).",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "Skowron, M. 2010. Affect Listeners: Acquisition of Affec-",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "tive States by Means of Conversational Systems.\nIn Devel-",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "opment of Multimodal Interfaces: Active Listening and Syn-",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "chrony.",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "Skowron, M.; Rank, S.; Theunis, M.; and Sienkiewicz,\nJ.",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "2011. The Good, the Bad and the Neutral: Affective Proﬁle",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "in Dialog System-User Communication.\nIn Affective Com-",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "puting and Intelligent Interaction (ACII). Springer.",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "Sridhar, D.; and Getoor, L. 2019. Estimating Causal Effects",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "of Tone in Online Debates.\nIn International Joint Confer-",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "ence on Artiﬁcial Intelligence (IJCAI).",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "Sutton, C.; McCallum, A.; and Rohanimanesh, K. 2007. Dy-",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "namic Conditional Random Fields: Factorized Probabilistic",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "Models for Labeling and Segmenting Sequence Data. Jour-",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "nal of Machine Learning Research (JMLR), 8: 693–723.",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "Tanana, M. J.; Soma, C. S.; Kuo, P. B.; Bertagnolli, N. M.;",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "Dembe, A.; Pace, B. T.; Srikumar, V.; Atkins, D. C.; and",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "Imel, Z. E. 2021. How do you feel? Using natural language",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "processing to automatically rate emotion in psychotherapy.",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "Behavior Research Methods, 1–14.",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "Tomkins, S.; Getoor, L.; Chen, Y.; and Zhang, Y. 2017. De-",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "tecting Cyber-Bullying From Sparse Data and Inconsistent",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "Labels.\nIn Learning from Limited Labeled Data Workshop",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "(LLD).",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "Wang, Y.; Zhang, J.; Ma, J.; Wang, S.; and Xiao, J. 2020.",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "Contextualized emotion recognition in conversation as se-",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "quence tagging. In Special Interest Group on Discourse and",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "Dialogue (SIGdial).",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "Yeh, S.; Lin, Y.; and Lee, C. 2019. An Interaction-aware At-",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "tention Network for Speech Emotion Recognition in Spoken",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "Dialogs.\nIn International Conference on Acoustics, Speech",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "and Signal Processing (ICASSP).",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "Zahiri, S. M.; and Choi, J. D. 2018. Emotion Detection on",
          "Neural Networks.\nIn Association for the Advancement of": ""
        },
        {
          "Poria, S.; Cambria, E.; Hazarika, D.; Majumder, N.; Zadeh,": "TV Show Transcripts with Sequence-Based Convolutional",
          "Neural Networks.\nIn Association for the Advancement of": ""
        }
      ],
      "page": 8
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Endowing Spoken Language Dialogue Systems with Emotional Intelligence",
      "authors": [
        "E André",
        "M Rehm",
        "W Minker",
        "D Bühler",
        "S Bach",
        "M Broecheler",
        "B Huang",
        "L Getoor"
      ],
      "year": "2004",
      "venue": "Affective Dialogue Systems (ADS)"
    },
    {
      "citation_id": "2",
      "title": "Hinge-loss Markov Random Fields: Convex Inference for Structured Prediction",
      "authors": [
        "S Bach",
        "B Huang",
        "B London",
        "L Getoor"
      ],
      "year": "2013",
      "venue": "Uncertainty in Artificial Intelligence (UAI)"
    },
    {
      "citation_id": "3",
      "title": "Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers",
      "authors": [
        "S Boyd",
        "N Parikh",
        "E Chu",
        "B Peleato",
        "J Eckstein"
      ],
      "year": "2010",
      "venue": "Foundations and Trends in Machine Learning"
    },
    {
      "citation_id": "4",
      "title": "Empirical Methods in Natural Language Processing",
      "authors": [
        "D Cer",
        "Y Yang",
        "S Yi Kong",
        "N Hua",
        "N Limtiaco",
        "R John",
        "N Constant",
        "M Guajardo-Cespedes",
        "S Yuan",
        "C Tar",
        "Y.-H Sung",
        "B Strope",
        "R Kurzweil"
      ],
      "year": "2018",
      "venue": "Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "5",
      "title": "Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling",
      "authors": [
        "J Chung",
        "C Gülc ¸ehre",
        "K Cho",
        "Y Bengio"
      ],
      "year": "2014",
      "venue": "Neural Information Processing Systems (NeurIPS)"
    },
    {
      "citation_id": "6",
      "title": "Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering",
      "authors": [
        "M Defferrard",
        "X Bresson",
        "P Vandergheynst"
      ],
      "year": "2016",
      "venue": "Neural Information Processing Systems (NeurIPS)"
    },
    {
      "citation_id": "7",
      "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "authors": [
        "J Devlin",
        "M Chang",
        "K Lee",
        "K Toutanova"
      ],
      "year": "2019",
      "venue": "Association for Computational Linguistics (ACL)"
    },
    {
      "citation_id": "8",
      "title": "Towards building an affect-aware dialogue agent with deep neural networks",
      "authors": [
        "A Ekbal"
      ],
      "year": "2020",
      "venue": "CSI Transactions on ICT"
    },
    {
      "citation_id": "9",
      "title": "Contrastive Entity Linkage: Mining Variational Attributes From Large Catalogs for Entity Linkage",
      "authors": [
        "V Embar",
        "B Sisman",
        "H Wei",
        "X Dong",
        "C Faloutsos",
        "L Getoor"
      ],
      "year": "2020",
      "venue": "Contrastive Entity Linkage: Mining Variational Attributes From Large Catalogs for Entity Linkage"
    },
    {
      "citation_id": "10",
      "title": "EMMA: An Emotion-Aware Wellbeing Chatbot",
      "authors": [
        "A Ghandeharioun",
        "D Mcduff",
        "M Czerwinski",
        "K Rowan"
      ],
      "year": "2019",
      "venue": "Affective Computing and Intelligent Interaction (ACII)"
    },
    {
      "citation_id": "11",
      "title": "COSMIC: COmmonSense knowledge for eMotion Identification in Conversations",
      "authors": [
        "D Ghosal",
        "N Majumder",
        "A Gelbukh",
        "R Mihalcea",
        "S Poria"
      ],
      "year": "2020",
      "venue": "Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "12",
      "title": "DialogueGCN: A Graph Convolutional Neural Network for Emotion Recognition in Conversation",
      "authors": [
        "D Ghosal",
        "N Majumder",
        "S Poria",
        "N Chhaya",
        "A Gelbukh"
      ],
      "year": "2019",
      "venue": "Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "13",
      "title": "ICON: Interactive Conversational Memory Network for Multimodal Emotion Detection",
      "authors": [
        "D Hazarika",
        "S Poria",
        "R Mihalcea",
        "E Cambria",
        "R Zimmermann"
      ],
      "year": "2018",
      "venue": "Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "14",
      "title": "Conversational Memory Network for Emotion Recognition in Dyadic Dialogue Videos",
      "authors": [
        "D Hazarika",
        "S Poria",
        "A Zadeh",
        "E Cambria",
        "L Morency",
        "R Zimmermann"
      ],
      "year": "2018",
      "venue": "Conversational Memory Network for Emotion Recognition in Dyadic Dialogue Videos"
    },
    {
      "citation_id": "15",
      "title": "Generating natural language under pragmatic constraints",
      "authors": [
        "E Hovy"
      ],
      "year": "1987",
      "venue": "Journal of Pragmatics"
    },
    {
      "citation_id": "16",
      "title": "Collective Entity Resolution in Multi-Relational Familial Networks",
      "authors": [
        "P Kouki",
        "J Pujara",
        "C Marcum",
        "L Koehly",
        "L Getoor"
      ],
      "year": "2019",
      "venue": "International Journal on Knowledge and Information Systems (KAIS)"
    },
    {
      "citation_id": "17",
      "title": "Multi-Task Learning with Auxiliary Speaker Identification for Conversational Emotion Recognition",
      "authors": [
        "J Li",
        "M Zhang",
        "D Ji",
        "Y Liu"
      ],
      "year": "2020",
      "venue": "Multi-Task Learning with Auxiliary Speaker Identification for Conversational Emotion Recognition"
    },
    {
      "citation_id": "18",
      "title": "DailyDialog: A Manually Labelled Multi-turn Dialogue Dataset",
      "authors": [
        "Y Li",
        "H Su",
        "X Shen",
        "W Li",
        "Z Cao",
        "S Niu"
      ],
      "year": "2017",
      "venue": "International Joint Conference on Natural Language Processing"
    },
    {
      "citation_id": "19",
      "title": "DialogueRNN: An Attentive RNN for Emotion Detection in Conversations",
      "authors": [
        "N Majumder",
        "S Poria",
        "D Hazarika",
        "R Mihalcea",
        "A Gelbukh",
        "E Cambria"
      ],
      "year": "2019",
      "venue": "Association for the Advancement of Artificial Intelligence (AAAI)"
    },
    {
      "citation_id": "20",
      "title": "A novel adaptive approach for home care ambient intelligent environments with an emotion-aware system",
      "authors": [
        "S Mowafey",
        "S Gardner"
      ],
      "year": "2012",
      "venue": "UKACC International Conference on Control (CONTROL)"
    },
    {
      "citation_id": "21",
      "title": "Opinion Mining and Sentiment Analysis",
      "authors": [
        "B Pang",
        "L Lee"
      ],
      "year": "2008",
      "venue": "Foundations and Trends in Information Retrieval (FTIR)"
    },
    {
      "citation_id": "22",
      "title": "Emotion-sensitive human-computer interfaces",
      "authors": [
        "T Polzin",
        "A Waibel"
      ],
      "year": "2000",
      "venue": "ISCA Tutorial and Research Workshop on Speech and Emotion"
    },
    {
      "citation_id": "23",
      "title": "Context-Dependent Sentiment Analysis in User-Generated Videos",
      "authors": [
        "S Poria",
        "E Cambria",
        "D Hazarika",
        "N Majumder",
        "A Zadeh",
        "L Morency"
      ],
      "year": "2017",
      "venue": "Association for Computational Linguistics (ACL)"
    },
    {
      "citation_id": "24",
      "title": "MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversations",
      "authors": [
        "S Poria",
        "D Hazarika",
        "N Majumder",
        "G Naik",
        "E Cambria",
        "R Mihalcea"
      ],
      "year": "2019",
      "venue": "MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversations"
    },
    {
      "citation_id": "25",
      "title": "Emotion Recognition in Conversation: Research Challenges, Datasets, and Recent Advances",
      "authors": [
        "S Poria",
        "N Majumder",
        "R Mihalcea",
        "E Hovy"
      ],
      "year": "2019",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "26",
      "title": "DCR-Net: A Deep Co-Interactive Relation Network for Joint Dialog Act Recognition and Sentiment Classification",
      "authors": [
        "L Qin",
        "W Che",
        "Y Li",
        "M Ni",
        "T Liu"
      ],
      "year": "2020",
      "venue": "Association for the Advancement of Artificial Intelligence (AAAI)"
    },
    {
      "citation_id": "27",
      "title": "I Know the Feeling: Learning to Converse with Empathy. arXiv",
      "authors": [
        "H Rashkin",
        "E Smith",
        "M Li",
        "Y.-L Boureau"
      ],
      "year": "2018",
      "venue": "I Know the Feeling: Learning to Converse with Empathy. arXiv"
    },
    {
      "citation_id": "28",
      "title": "Clarifying Intentions in Dialogue: A Corpus Study",
      "authors": [
        "J Schlöder",
        "R Fernández"
      ],
      "year": "2015",
      "venue": "Computational Semantics (IWCS)"
    },
    {
      "citation_id": "29",
      "title": "Affect Listeners: Acquisition of Affective States by Means of Conversational Systems",
      "authors": [
        "M Skowron"
      ],
      "year": "2010",
      "venue": "Development of Multimodal Interfaces"
    },
    {
      "citation_id": "30",
      "title": "The Good, the Bad and the Neutral: Affective Profile in Dialog System-User Communication",
      "authors": [
        "M Skowron",
        "S Rank",
        "M Theunis",
        "J Sienkiewicz"
      ],
      "year": "2011",
      "venue": "Affective Computing and Intelligent Interaction (ACII)"
    },
    {
      "citation_id": "31",
      "title": "Estimating Causal Effects of Tone in Online Debates",
      "authors": [
        "D Sridhar",
        "L Getoor"
      ],
      "year": "2019",
      "venue": "International Joint Conference on Artificial Intelligence (IJCAI)"
    },
    {
      "citation_id": "32",
      "title": "Dynamic Conditional Random Fields: Factorized Probabilistic Models for Labeling and Segmenting Sequence Data",
      "authors": [
        "C Sutton",
        "A Mccallum",
        "K Rohanimanesh"
      ],
      "year": "2007",
      "venue": "Journal of Machine Learning Research (JMLR)"
    },
    {
      "citation_id": "33",
      "title": "How do you feel? Using natural language processing to automatically rate emotion in psychotherapy",
      "authors": [
        "M Tanana",
        "C Soma",
        "P Kuo",
        "N Bertagnolli",
        "A Dembe",
        "B Pace",
        "V Srikumar",
        "D Atkins",
        "Z Imel"
      ],
      "year": "2021",
      "venue": "Behavior Research Methods"
    },
    {
      "citation_id": "34",
      "title": "Detecting Cyber-Bullying From Sparse Data and Inconsistent Labels",
      "authors": [
        "S Tomkins",
        "L Getoor",
        "Y Chen",
        "Y Zhang"
      ],
      "year": "2017",
      "venue": "Learning from Limited Labeled Data Workshop (LLD)"
    },
    {
      "citation_id": "35",
      "title": "Contextualized emotion recognition in conversation as sequence tagging",
      "authors": [
        "Y Wang",
        "J Zhang",
        "J Ma",
        "S Wang",
        "J Xiao"
      ],
      "year": "2020",
      "venue": "Special Interest Group on Discourse and Dialogue"
    },
    {
      "citation_id": "36",
      "title": "An Interaction-aware Attention Network for Speech Emotion Recognition in Spoken Dialogs",
      "authors": [
        "S Yeh",
        "Y Lin",
        "C Lee"
      ],
      "year": "2019",
      "venue": "International Conference on Acoustics, Speech and Signal Processing"
    },
    {
      "citation_id": "37",
      "title": "Emotion Detection on TV Show Transcripts with Sequence-Based Convolutional Neural Networks",
      "authors": [
        "S Zahiri",
        "J Choi"
      ],
      "year": "2018",
      "venue": "Association for the Advancement of Artificial Intelligence (AAAI)"
    },
    {
      "citation_id": "38",
      "title": "Modeling both Context-and Speaker-Sensitive Dependence for Emotion Detection in Multi-speaker Conversations",
      "authors": [
        "D Zhang",
        "L Wu",
        "C Sun",
        "S Li",
        "Q Zhu",
        "G Zhou"
      ],
      "year": "2019",
      "venue": "International Joint Conference on Artificial Intelligence (IJCAI)"
    },
    {
      "citation_id": "39",
      "title": "Knowledge-Enriched Transformer for Emotion Detection in Textual Conversations",
      "authors": [
        "P Zhong",
        "D Wang",
        "C Miao"
      ],
      "year": "2019",
      "venue": "Empirical Methods in Natural Language Processing"
    }
  ]
}