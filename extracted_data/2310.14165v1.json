{
  "paper_id": "2310.14165v1",
  "title": "Graph Convolutional Network With Connectivity Uncertainty For Eeg-Based Emotion Recognition",
  "published": "2023-10-22T03:47:11Z",
  "authors": [
    "Hongxiang Gao",
    "Xiangyao Wang",
    "Zhenghua Chen",
    "Min Wu",
    "Zhipeng Cai",
    "Lulu Zhao",
    "Jianqing Li",
    "Chengyu Liu"
  ],
  "keywords": [
    "Emotion Recognition",
    "EEG",
    "Connectivity Uncertainty",
    "Graph Neural Network"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Automatic emotion recognition based on multichannel Electroencephalography (EEG) holds great potential in advancing human-computer interaction. However, several significant challenges persist in existing research on algorithmic emotion recognition. These challenges include the need for a robust model to effectively learn discriminative node attributes over long paths, the exploration of ambiguous topological information in EEG channels and effective frequency bands, and the mapping between intrinsic data qualities and provided labels. To address these challenges, this study introduces the distribution-based uncertainty method to represent spatial dependencies and temporal-spectral relativeness in EEG signals based on Graph Convolutional Network (GCN) architecture that adaptively assigns weights to functional aggregate node features, enabling effective long-path capturing while mitigating over-smoothing phenomena. Moreover, the graph mixup technique is employed to enhance latent connected edges and mitigate noisy label issues. Furthermore, we integrate the uncertainty learning method with deep GCN weights in a one-way learning fashion, termed Connectivity Uncertainty GCN (CU-GCN). We evaluate our approach on two widely used datasets, namely SEED and SEEDIV, for emotion recognition tasks. The experimental results demonstrate the superiority of our methodology over previous methods, yielding positive and significant improvements. Ablation studies confirm the substantial contributions of each component to the overall performance.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "I. Introduction",
      "text": "T He superior cognition of human intelligence over artifi- cial intelligence is not due to computational capacity but the former's ability to comprehend emotions, a sophisticated function of the brain that mediates self-assessment  [1] . This realization has galvanized efforts towards evolving artificial intelligence to discern emotions rather than mere binary judgments. Automated emotion recognition, thus, holds immense promise across varied domains like medical treatment, fatigue monitoring, and human-computer interaction (HCI) systems.\n\nHuman emotions, intricate and multi-dimensional, are conveyed through gestures, facial expressions, physiological signals, and more. Among these, physiological signals, particularly those from the brain, have emerged as potent indicators of emotional changes due to their inherent veracity  [1] . Electroencephalogram (EEG), along with other physiological measures, has demonstrated to be highly reflective of an individual's emotional states  [2] ,  [3] . To unlock this potential, multichannel emotion EEG induction research is actively pursued, leading to the creation of open-access databases  [4] -  [7] .\n\nCurrent research delving into brain functional connectivity, as indicated by functional magnetic resonance imaging (fMRI), points towards the potential ability of individuals to maintain attention. EEG-based emotion studies have sought to capture spatial information by transforming the threedimensional electrode position into a two-dimensional matrix, thereby enabling the use of two-dimensional convolution  [8] . While conventional models such as CNN and RNN have been employed, their precision has been questioned  [9] . However, the advent of graph neural networks (GNNs) has allowed treating each EEG channel as a node and connections as edges, leading to significant advancements in EEG-based emotion classification  [10] ,  [11] .\n\nDespite their popularity, GNNs have been limited by the vanilla graph convolution network (GCN) approach, suffering from over-smoothing beyond a few layers  [12] . Numerous methods to address this have emerged, some of which include dropout  [13] , drop-edge  [14] , and residual-based approaches  [15] . While these have alleviated over-smoothing, they often involve computationally expensive operations.\n\nBrain connectivity characterizing emotions requires a nuanced approach. Simple construction of the adjacency matrix using distance coefficients or correlation indices have shown subpar performance in emotion recognition  [11] ,  [16] ,  [17] . Emotion processing in the brain is an intricate activity, asynchronous across multiple regions  [18] . Positive emotions, for instance, are linked with heightened activity in the left prefrontal cortex, while negative emotions involve the right prefrontal cortex  [19] . This understanding underscores the need for effective brain functional connectivity construction and long-path dependencies. Current research has thus far had little to offer regarding effective brain functional connectivity construction and long-path dependencies. Figure  1  represents an example of 62-channel electrode distribution and possible connection among different brain lobes.\n\nRestricted to the collection difficulties of EEG signals, all available datasets are designed in a lab environment. During trials that involve video-induced emotions, participants often encounter challenges such as insufficient stimulation or extreme variability, resulting in varying emotional states throughout the test. As depicted in Figure  2 , even for the same individual, the brain activation patterns for the same emotion over continuous periods of time exhibit noticeable variations, despite maintaining some consistent activation regions. Traditionally, one-second EEG signals have been treated as individual samples, using handcrafted features for emotion categorization  [4] ,  [5] ,  [10] ,  [11] ,  [20] . However, accurately labeling and identifying emotions based on these short segments pose difficulties. This issue has been overlooked by many researchers, except for Zhong et al., who introduced the concept of soft labels based on the spatial relationship between different emotions on the arousal-valence plane  [11] . Their approach provides a more nuanced understanding of videoinduced emotions, overcoming the limitations of traditional single-sample annotations and enhancing comprehension in this domain.\n\nDespite the aforementioned strategies, the efficacy of GCN may be constrained in certain scenarios due to the following factors: 1) Intrinsic limitations stemming from over-smoothing issues, impeding effective long-path information acquisition;\n\n2) Inadequate exploration of the brain's spatial topological structure and the significance of spectral features; and 3) Insufficient induction resulting in data-label discrepancies, thereby constraining the effectiveness of strategies.\n\nIn our endeavor to address limitations in EEG emotion recognition, we have introduced an uncertainty-guided deep Graph Convolutional Network (GCN) model. Our model efficiently mitigates the challenges of over-smoothing and noisy labels by leveraging an uncertainty-guided approach for adjacency matrix generation and Bayesian techniques to estimate connectivity probability, which enhances connectivity between local and global brain regions. We have also demonstrated that the learning of connection uncertainty within our GCN parallels the PageRank algorithm, an advancement that enables the elimination of over-smoothing issues and captures a broader range of spectral information. Furthermore, we have employed a data mixing technique to address the issue of noisy labels, thus introducing potentially connected edges for robust representation. The main contributions of our work lie in the following aspects:",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "1) We Introduce An Uncertainty-Driven Graph Convolutional",
      "text": "Network (UC-GCN), effectively addressing functional connectivity uncertainties and frequency band obscurities in EEG signals. 2) We illustrate the role of uncertainty masks in our spectral-enhanced GCN structure, mitigating oversmoothing and augmenting high-frequency information capture. 3) We innovate with a graph mixing augmentation strategy, enhancing the model's capability to discriminate ambiguous data through potentially connected edges and soft labels.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Ii. Related Works",
      "text": "",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "A. Eeg Based Emotion Classification",
      "text": "EEG signals are a key resource for assessing human emotional states. In the past, feature extraction for emotion categorization was primarily manual, with time domain characteristics such as statistical measures  [21] , higher-order correlation methods  [22] , and event-related potentials  [23]  being used. From a frequency domain perspective, features like power spectral density were used  [4] ,  [24] , along with techniques such as short-time Fourier transform and discrete wavelet transform for time-frequency domain features  [25] ,  [26] . Nonlinear dynamics and chaos-based concepts have also been examined  [27] , with nonlinear features such as fractal dimension  [28]  and multifractal detrended fluctuation analysis  [29]  showing significant correlations with different emotional states.\n\nDespite their value, these features have mostly been focused on single-channel signals, ignoring the relationships between different channels. This is a significant oversight, as research has shown that different parts of the brain can be affected differently by emotional states  [30] . To address this, recent research by Shi et al.  [31]  used differential and rational asymmetry measures to quantify differences in hemispheric brain activity. Tao et al.  [32]  proposed using an attentionbased convolutional recurrent neural network to extract both channel relationships and inherent similarities from EEG data. Li et al.  [33]  also used directed recurrent neural networks on two hemisphere areas to capture both spatial and temporal dependencies simultaneously. Graph neural networks (GNNs) have been employed by researchers to analyze intra-channel connections, with each node representing inter-channel characteristics  [10] ,  [11] ,  [20] . While promising, these GNNs often use predetermined adjacency matrices that lack a robust clinical or psychological basis.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "B. Graph Neural Network In Eeg",
      "text": "Traditional neural networks like CNNs and RNNs face challenges in non-Euclidean spaces, pushing researchers to explore alternatives. Spectral methods using Laplace transformed space for convolution have been introduced but were computationally demanding  [34] . This was improved with Chebyshev polynomials, enhancing graph convolutional networks (GCNs)  [35] . Spatially-based methods, like defining fixed neighbor vectors for graph convolution or building adjacency matrices via randomly selected neighbors, have also been proposed  [36] ,  [37] . However, deep GCNs tend to oversmooth, leading to indistinct representations  [12] . Solutions like custom PageRank matrices have been suggested to combat this issue  [38] .\n\nRegarding EEG data tasks, GNNs have shown promising results in emotion categorization  [10] ,  [11] ,  [20] , epilepsy identification  [39] , and seizure analysis  [17] . Most of the research focuses on constructing brain functional connectivity based on thresholds or constructing a graph that combines local and global regions. However, these methods often rely on a predefined graph, which may not fully capture the interconnectedness of different emotional states across individuals. Also, static connection graphs may struggle to represent brain activation patterns accurately in noisy environments. As a solution, we suggest an uncertainty-driven strategy for replacing the adjacency matrix, which integrates weighted root node features to mitigate over-smoothing and improve model performance for all emotions.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "C. Uncertainty For Graphs",
      "text": "While uncertainty quantification in CNNs has been extensively studied, it has received limited attention in the context of GNNs  [40] ,  [41] . Aleatoric uncertainty, arising from imprecise and noisy measurements, affects the observability of node characteristics, edge connectivity, and edge weights in a graph. Zhang et al.  [42]  proposed a Bayesian framework that generates graph structures and parameters using parametric random graphs to handle aleatoric uncertainty. Munikoti et al.  [43]  established a generic Bayesian framework and employed assumed density filtering to measure aleatoric uncertainty. Epistemic uncertainty, on the other hand, arises from the model's limited ability to accurately represent the underlying process. Variational inference  [20] ,  [44]  and sampling-based approaches  [45]  are commonly used to estimate posterior density functions of model parameters. Hasan et al.  [46]  presented an adaptive connection sampling-based stochastic regularization algorithm for GNNs, while Munikoti et al.  [43]  and Feng et al.  [47]  employed Monte-Carlo dropout during testing to quantify prediction uncertainty. Existing efforts in graph data analysis have primarily focused on feature qualification and model performance, assuming pre-defined graph structures. However, for EEG-related activities, the functional connectivity of the brain remains a challenging mystery. Our study explicitly incorporates uncertainty in graph structures into our paradigm, addressing this crucial aspect.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Iii. Methods",
      "text": "In this section, we then present our key idea of automatically learning the connections between different EEG channels to reconstruct the brain's functional graph for emotional response, as shown in Figure  3 .\n\nThe edges in the graph may be alternately represented using an adjacency matrix A ∈ R N ×N , where A ij = 0 indicates that node i and j are not connected and N = |V| is the number of nodes. Let the node attribute matrix be X ∈ R N ×f , where f denotes the input feature dimension and each node may be endowed with a f -dimensional node attribute vector\n\nSpectral Graph Convolution  [35]  -Spectral graph theory  [48]  study the graph topology property by means of the eigenvalues and eigenvectors of the Laplace matrix of graphs. Laplacian matrix is defined as L = D -A and its normalization matrix is L = I -D -1/2 AD -1/2 , which is a semi-definite matrix with eigenvalues as Λ and eigenvectors as U. Thus, L = UΛU T . Similar to the role of CNNs in image processing, spectral convolution on graphs can be understood as a filtering operation in the spatial domain. It is achieved by performing a multiplication between the raw graph signal X and the filter kernel G in the spectral domain, utilizing techniques such as Fourier transform  [35]  or wavelet transform  [49] ,  [50] . This spectral convolution operation allows us to extract meaningful features from graphstructured data, analogous to the way CNNs extract features from images.\n\nwhere ⊙ denotes the element-wise multiplication and Ĝ = diag(ĝ 1 , . . . , ĝN ) denotes a diagonal matrix of spectral filter coefficients. To avoid the high computation overload of matrix decomposition of L,  [35]\n\nand the corresponding filter coefficients ĝ(\n\nStep l",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "N",
      "text": "Step L Inputs",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Softmax & Linear",
      "text": "",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Outputs",
      "text": ". The framework of our Connectivity Uncertainty GCN. For a given adjacency matrix A ∈ R N ×N and node features X ∈ R N ×f l , we generate each layer a binary mask Z (l) ∈ R N ×N ×f l (l = 1, 2, ..., L -1) using an edge predictor fep(•) and element-wise multiplied with A.\n\nThe transition matrix for each layer H (l) was allocated a weighted coefficient α l to introduce both local and global information to better describe the final output.\n\nλ max denotes the largest eigenvalue of L and θ ∈ R K is a learnable vector of Chebyshev coefficients, k ∈ {0, . . . , K} means the k-th term of a K-order polynomials.\n\nGraph convolution neural network (GCN)  [51]  further approximate the Eq. (  2 ) with K = 1, θ 0 = 2, and θ 1 = -1, so that the convolution operation in Eq. (  1 ) translate into X * G = (I+D -1/2 AD -1/2 )X. Each GCN layer transformation function H is defined as:\n\nwhere\n\nis the convolutional parameter of each layer to realize the feature transformation, σ(•) denotes a nonlinear activation function and k denotes the layer number. The normalized Laplacian Lsym = I -D-1 2 Ã D-1 2 = Ũ Λ ŨT and its corresponding graph filter can be described as\n\n, where λi are eigenvalues of Ãsym . For brevity and without loss of generality, we denote A as the adjacency matrix with a self-loop and D as the degree matrix with a self-loop.\n\n2) Over-smoothing in GNNs: The aggregation progress of neighborhood information can be seen as a graph filtering step over node features with a filter expressed in Eq. (2). Obviously, the preserved spectral component in ĜΛ is dominated by the eigenvalues of T k ( Λ), i.e. Λ = { λ1 , . . . , λK } and λ1 > , . . . , > λK , which in turn represent the low to high-frequency components. Currently, practical models are usually shallow (number of layers K is 2 -4), as such a choice offers the best empirical performance which is later proved attributed to the low-pass characteristic. Besides, the transition matrix will finally collapse to an independent matrix of input without a linear interposition in Eq. (  3 ), lim k→∞\n\n. And the final decision derived from such an undiscriminating,\n\n) is merely determined by the L-hop node attributes with L denotes the total layers, provided that the graph is irreducible and aperiodic. More specifically, the learned representations will lose discriminative information provided by nodes with different topological and feature characteristics as the model goes deeper.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "B. Uncertainty-Guided Gcn For Emotion Recognition From Eeg Signals",
      "text": "1) Emotion-specific function connectivity reconstruction: In practical applications, each EEG channel is regarded as a node, with node vectors encapsulating the computed features across various frequency bands, specifically, the delta, theta, alpha, beta, and gamma bands. Our central proposition rests on leveraging the information derived from both the inherent topology of the graph in the spatial domain and the node features in the time-frequency domain to overcome prevalent challenges such as the identification of topological connections and distinct effective frequency band responses. This twopronged approach allows us to pinpoint crucial information to be assimilated into the propagation of knowledge during the design phase of the GCN.\n\nA crucial step in this procedure is the introduction of an edge predictor (EP), which computes the connection probabilities between any two nodes, paving the way for node feature learning. The edge predictor can be formally expressed as f ep : A, X → Z, where Z denotes an edge existence mask. We leverage the mask matrix Z to establish deterministic links to high-scoring non-edges and remove poorly scored linked edges. The propagation procedure is then reformulated as the following metric:\n\nIt is easy to observe that implementing node-wise and featurewise uncertainty quantization leads to different probabilistic interpretations. To provide a comprehensive measure of model uncertainty, we further extend\n\nas a 3dimensional matrix, where Z (l) uv ∈ R N ×N ×1 denotes the connection of any two nodes u, v, and Z (l) f ∈ R N ×f l denotes the mask vector of layer l on features of each node. We can rewrite and reorganize Eq. 4 in a feature-wise view as\n\nwhere\n\nthat means we allocate each frequency component with a different topological connection strategy for a better group of useful information. Z (l) [:, i] is a binary mask sampled from a Bernoulli distribution with a success rate as p l for each layer. The success rate p l is adaptive for different representations, guaranteeing the effectiveness of topology construction.\n\n2) Uncertainty Learning With Bayesian Approximation: To generate an uncertain binary mask Z (l) , we endeavor to leverage the power of Bayesian inference to train our predictor, using the predictive posterior derived from training data. Intriguingly, we illustrate in the context of this study that the dynamic process of adaptive connection learning can be elegantly transposed from the realm of output feature space to the more abstract parameter space, thereby casting it as a credible Bayesian process encapsulated within the Graph Convolutional Network (GCN) framework.\n\nTo further clarify our approach, we revisit Eq. 4 and reinterpret it from a node-wise perspective of a GCN layer, which can be described as:\n\nwhere e is assigned a distribution according to p(ω). Moreover, we postulate a vector m l of dimensions f l × f l-1 for each layer. Consequently, the predictive probability of the deep GNN model can be expressed as:\n\n3) Variational Interpretation: However, the posterior distribution p(ω|A, X) proves intractable. In light of this, we adopt a variational interpretation, where a binary mask (each row of ω) can be viewed as an approximate distribution q θ (ω) that approximates the posterior distribution p(ω|A, X). We define q θ (ω) as follows:\n\nHere, θ = {p l , m l } L l=1 represents the variational parameters, and m l denotes the mean weight matrices. The variable z l,e = {0, 1} f l corresponds to the removal of features, leading to the omission of nodes in layer l -1 as connected neighbors within the graph A (l) , solely when the entire set of features is eliminated.\n\nTo optimize the aforementioned model, we introduce the Kullback-Leibler (KL) divergence KL(q θ (ω)||(p(ω)) in order to minimize the discrepancy between the approximate posterior q θ (ω) and the prior distribution p(ω). The discrete quantized Gaussian prior distribution is commonly employed to analytically evaluate this intractable KL divergence. Considering the distribution of the edges, we have\n\n. By approximating each edge distribution as q θ l (W\n\ne -m l ), we can express the general KL term as:\n\nConsequently, the edge predictor loss L ep can be approximated as:\n\nwhere H denotes the entropy of a Bernoulli random variable with success rate p l , defined as:\n\nGiven a fixed edge connection probability p l , the entropy term remains unaffected by model weights and can be viewed as a constant regularization term during optimization, thereby rendering it negligible. However, the connectivity sampling probability inherently relies on the specific functional structure of each frequency component. The minimization of the KL divergence term equates to maximizing the entropy term with a probability of 1 -p l , which is optimally achieved when p l approximates 0.5. It becomes apparent that constant proportion sampling fails to meet the requirements for intricate functional connections and may introduce extraneous information. In order to train p l during the model training process, we must compute the derivative of the entropy objective, which presents a formidable challenge.\n\nSeveral commonly used estimators, such as Reinforce  [52]  or pathwise derivative re-parametrization methods  [44] ,  [53] ,  [54] , are inapplicable due to the discrete nature of the masks. Rather than sampling the random variable from a discrete Bernoulli distribution, we employ an approximation by substituting the discrete distribution with its continuous relaxation. This can be seen as a relaxation of the \"max\" function in the Gumbel-max trick to a \"softmax\" function. The transition from a discrete Bernoulli random variable z to a continuous variable z is reparametrized as z = g(θ, ϵ), where θ represents the model parameters and ϵ is a random variable independent of θ. Assuming that ϵ follows a uniform distribution, i.e., ϵ ∼ Unif(0, 1), we utilize the Sigmoid function to constrain the continuous value within the interval [0, 1]:\n\nwhere t is a temperature parameter. This distribution assigns most of its mass to the boundaries of the interval 0 and 1. With this concrete relaxation of the adjacency masks, we can now optimize the connection probability.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "C. Alleviating Over-Smoothing And Enhance Spectral Filter",
      "text": "Long path information, known as the high-frequency component among the graph, was demonstrated to have strong discriminative power for graph-level classification. Hence a natural research direction of research regarding GNNs is to investigate how to leverage long paths over graphs without over-smoothing the vertex features. Generalized PageRank (GPR) values  [55] ,  [56]  enable more accurate characterizations of hidden state distance and similarities and hence lead to improved performance of various graph learning techniques. Given a seed feature H (0) and another deeper hidden feature H (l) in the graph, the GPR value is defined as ∞ l=0 α l H (l) , for some GPR weight sequence {α l } l≥0 ∈ R. We rewrite the multi-step propagation with a L truncated polynomial based on Eq 4:\n\nnoted that the task of learning GPR score α for graph classification can be reformulated as learning a flexible factor over the adjacency matrix in different propagation steps, thus could be learned with Z (l) , i.e., Z(l) = α l 1 N ×N ⊙ Z (l) . That means the long-path learning could be realized with the uncertainty learning on each step. Thus, learning the optimal uncertainty mask Z (l) is equivalent to learning the optimal polynomial graph filter. As any graph filter could be approximated with a polynomial graph filter and increasing L allows one to better approximate the underlying feature extractor. The uncertaintyguided GNN is able to leverage long-path topological structure information and with an adaptive learned GPR weight, one can enhance the beneficial middle state while suppressing the harmful.\n\nAugmented Spectral Filters. More specifically, D -1 2 (A ⊙\n\nŨT corresponds to a polynomial graph filter of order L over H (0) . Wherein the α is a multiplier factor derived from Z (l) ranged in (0, 1) as proved in Eq. 14. The corresponding polynomial graph filter equals to ĝα,L ( λi ) = (1 -αl λi ) L . As proved in  [51] ,  [57] , the eigenvalues of renormalized GCN range in [0,  1.5] . When λi = 0, the amplitude of vanilla GCN is equal to robust GCN, i.e. g(0) = ĝα,L (0) = 1. Hence, the robust GCN retains the low-pass filter ability. However, when λi > 0, ĝα,L ( λi ) = (1 -αl λ i ) > g( λi ) = (1 -λi ), which provides the model more high frequency components. Besides, as αl is less than 1 and will be smaller with the stacking of the convolution layer, ĝα,K will hardly get a negative value, which is previously proved harmful for the model performance  [57] , thus enhance the robustness of such a model. We refer to the proposed model as Enhanced Graph Convolutional Network (eGCN).",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "D. Implicit Adversarial Training Strategy",
      "text": "In section III-B.3, we sparsify adjacency A with Bernoullibased uncertainty sampling to get the graph variant adjacency A ⊙ Z (l) . However, the generated adjacency matrix is able to keep the most class-specific connections but weak in adding global emotion-effective connections, which we argue should be generally existing edges for all emotional states. Besides, existing methods generate samples by segmenting raw data with a non-overlapping 1-s window, ignoring the fact that participants may not always be effectively stimulated when watching an induced material due to self-resistance or insufficient stimulation. Unwanted data are adversarial samples that are harmful to robust model training.\n\nWe propose a data-agnostic augmentation method to add latent connected edges and alleviate the mismatching problem (noisy label) by leveraging information from other positive samples of the same mini-batch. In a nutshell, we use mixup  [58]  to construct virtual training examples. Given a pair of graph samples G i , G j with the embedding X Gi , X Gj , initial adjacency matrix A Gi , A Gj and its corresponding label Y i , Y j , we interpolate contextual information by\n\nwith β ∈ [0, 1] controlling the strength of interpolation between feature-target pairs. We sample the mixup weight β from the Beta distribution Beta(ψ, ψ) with ψ as a hyperparameter  [58] -  [60] . With such an augmentation technique, the converted graph data tend to be close to its intrinsic distribution and labeled with a more convicting soft label. Let h G denote the graph embedding and the optimization objective Algorithm 1 Connectivity Uncertainty Graph Neural networks Input: Given a pair of graphs with node attributes and labels Sample a data augmentation weight: β ← Beta(ψ, ψ);\n\nGenerate the augmented feature matrix XGiGj ← βX Gi + (1 -β)X Gj and augmented adjacency matrix\n\nGenerate the corresponding label:\n\n7:\n\nSample a mask Z (l) from Eq. 14;\n\n10:\n\nGenerate the uncertain adjacency matrix: A ⊙ Z (l) ; 11:\n\nAggregate on each layer via Eq. 15;\n\n12:\n\nend for 13:\n\nPredict via Eq. 17 and calculate the total loss; 14:\n\nUpdate the parameters by gradients descending; 15: end for of graph classification can be written as:\n\nConsequently, our emotion recognition method was designed by optimizing both the classification loss L gc and uncertainty edge predictor loss L ep in Eq. (  12 )",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "Iv. Experiments And Results Analysis",
      "text": "In this section, we provide details about the datasets used in our experiments and describe the experimental settings, as well as comparisons with state-of-the-art.\n\nA. Experimental Setting 1) Datasets: Our investigation enlisted two established EEG datasets, the SJTU emotion EEG dataset (SEED)  [4]  and its successor SEEDIV dataset  [5] , in the execution of emotion recognition tasks. These datasets encompass EEG recordings from 15 youthful participants, evenly distributed by gender. The data, collected via a 62-channel ESI NeuroScan System as the subjects viewed emotionally charged film clips, were gathered over three sessions held on different days under uniform conditions to ensure data integrity. The raw EEG signals were then preprocessed, down-sampled from 1000 Hz to 200 Hz, and cleansed of artifacts stemming from eye movements (EOG) and muscle activity (EMG).\n\nThe SEED dataset comprises 15 film clips of around 4 minutes each, carefully crafted by psychologists to evoke specific emotional states -Positive, Neutral, or Negative. Hence, each participant in the SEED dataset produced 45 distinct EEG signal trials. The SEEDIV dataset, following a similar data acquisition procedure, increased the number of trials by featuring 24 film clips that lasted roughly 2 minutes each and elicited four types of emotions: Neutral, Sad, Fear, and Happy. This resulted in each participant contributing 72 EEG recording trials in the SEEDIV dataset.\n\n2) Data Splits: In the pursuit of equitable comparisons, we conducted both subject-dependent and subject-independent classifications on the SEED and SEED-IV datasets, in adherence with protocols laid out in previous investigations  [4] ,  [8] ,  [10] ,  [11] ,  [20] ,  [65] . In the subject-dependent trials on the SEED dataset, we designated the initial 3 trials from each emotional category (making up a total of 9 trials) for training purposes, while the residual 6 trials were assigned to the testing set, thereby ensuring an even distribution across categories. Notably, these experiments drew upon two sessions from each subject. We reported the final outcome as the mean accuracy across all 15 subjects.\n\nTurning to the subject-dependent trials on the SEED-IV dataset, we allocated the first 4 trials from each emotional category (a total of 16 trials) for training, whereas the remaining 8 trials served as the testing set. All three sessions were incorporated into the evaluation of model performance. As with the SEED dataset, we reported accuracy over all 15 subjects. Regarding the subject-independent trials, we espoused the leave-one-out methodology. Specifically, cross-validation was performed by excluding one session from each subject in the case of the SEED dataset, and all sessions from each subject in the case of the SEED-IV dataset. We evaluated model performance across all 15 trials.\n\n3) Model Training: We conducted our experiments using the PyTorch Geometric toolbox and trained the models on a single NVIDIA Tesla A100 GPU, utilizing the Adam optimizer. To determine the optimal hyperparameters, we performed a search on the validation set, exploring the following ranges: (a) initial learning rate within the range [1e-3, 3e-2]; (b) the number of convolutional layers within range {2, 4, 6, 8} and hidden feature dimension within range {32, 64, 128}. We set the temperature parameter t in the concrete distribution as 0.67, the Beta distribution weight ψ as 2, and the batch size as 32. The hyper-parameters were hand-tuned with the best performance over the validation set. A cosine annealing learning rate scheduler was adopted for all experiments. We adopt an early stopping strategy when the validation loss did not decrease for ten consecutive epochs.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "B. Experimental Results",
      "text": "We report the mean accuracy (Acc) and standard deviation (Std) as the main evaluation metrics for emotion recognition. This choice aligns with recent studies in the field  [4] ,  [8] ,  [10] ,  [11] ,  [20] ,  [65] , ensuring consistency in the evaluation of our results.\n\n1) Subject-dependent Test: Following the procedure of Algorithm 1, we compare the proposed model with a quantity of popular used models: (1) traditional machine learning classifying models, e.g. SVM  [5] , DBN  [4] ; (2) non-topological deep (3) spectral effectiveness: leverage features on β and γ band alone are more effective for emotion activation but greatly underperformed than using features on whole bands, somehow indicating that high-frequency information is more active with emotional activities. Our model obtained the best performance on both datasets. We attribute such a performance gain to the leverage of uncertainty-guided instance-wise adjacency matrix and the improvement of model ability on the spectral richness and alleviation to over-smoothing.\n\n2) Subject-independent Test: Physiological signals, such as EEG, present severe individual variation and greatly hinder the model generalization. Thus, we conduct the subjectindependent emotion classification to further verify our model stability. We use DE feature as the exclusive input for its remarkable discriminating property. Table  III  shows the performance of three categorical classifiers on SEED and SEEDIV. Note that for brief comparison, we conduct the test using features from all five bands on SEEDIV following previous literature settings. Not surprisingly, despite numerical value presenting a similar tendency as subject-dependent experiments in the view of all three analysis aspects, all accuracy suffered a great decrease. Our method achieves the best performance in SEEDIV and comparable results in the SEED datasets, which verifies the generalization of CU-GCN with subjectindependent EEG emotion recognition. R2G-STNN leveraged a bidirectional long short term memory (BiLSTM) to learn the region to global spatial-temporal information. BiHDM proposed a four-directed RNN based on two spatial orientations to obtain the discrepancy information between two separate brain regions and used a domain discriminator to generate  the domain-invariant feature. RGNN eliminates the individual invariant by introducing a similar domain adversarial training pattern. V-IAG was believed to promote cross-subject performance by designing a more reasonable adjacency matrix that contains an instance adaptive branch and a variational branch to learn the deterministic graphs and an uncertain graph. All these methods solve the subject-independent problem by designing a data-driven node connection graph from both regional and global space. It indicates that the key point of emotion recognition should lie in the precise combination of EEG channels.",
      "page_start": 7,
      "page_end": 8
    },
    {
      "section_name": "C. Ablation Studies And Discussions",
      "text": "We conducted ablation studies to analyze and discuss the components of our CU-GCN model and their impact on subject-independent emotion recognition. However, both vanilla GCN and SGC suffer from the oversmoothing problem, which arises as the network depth increases, leading to the loss of local information. V-IAG employed an eight-layer GCN architecture that preserved features from local to global regions by aggregating the outputs of each layer for the final decision.\n\nIn light of our previous theoretical analysis, our enhanced GCN (eGCN) is designed to address the over-smoothing problem while enhancing spectral information. In this subsection, we perform ablation studies by replacing eGCN with SGC and GCN to validate our hypothesis. Table IV presents the results, where \"eGCN → GCN(2)\" indicates the replacement of eGCN with a two-layer GCN, and similarly for SGC. As shown in Table  IV , it is evident that eGCN achieves significantly better results than the common benchmark methods.\n\nFurthermore, we conduct additional experiments by varying the number of layers (L corresponding to the number of aggregated filters in CU-GCN). The results in Table V consistently demonstrate that our method outperforms others, with the best performance achieved when L = 6, equivalent to six layers. These findings indicate that eGCN effectively mitigates the over-smoothing problem as the network depth increases. Notably, the aggregation of information from sixhops neighborhoods performs optimally, potentially due to ensuring the global connection between two hemisphere brain regions, as the relative node distance in a 2D squared matrix is nine. Overall, these results highlight the superior ability of CU-GCN to aggregate information over larger neighborhoods compared to other methods.\n\n2) Comparison Between Graph Structures: To compare the effectiveness of our uncertainty-guided edge predictor (EP) with commonly used graph construction approaches, we trained CU-GCN for subject-independent emotion recognition on the SEED and SEEDIV datasets. The second part of Table  5  presents the performance of CU-GCN with and without EPM using different adjacency matrices: distance-based (Dist), coherence-based (Coh), and random adjacency matrices. We observed that the inclusion of EP consistently yielded better results compared to other methods. Interestingly, traditional graph construction methods did not exhibit significant differences, suggesting that EEG signals in emotion recognition possess unique characteristics. Our method offers several distinct advantages: (a) It can be applied even when the physical locations of electrodes are unknown, providing flexibility in practical scenarios. (b) It captures dynamic brain connectivity patterns instead of relying solely on spatial sensor information, which is particularly desirable for emotion recognition tasks. (c) It enables adaptive selection of spectral features in EEG, facilitating precise categorization.\n\n3) What Is The Effect of Concrete Bernoulli Distribution?:\n\nIn our study, we conducted an investigation into the impact of using a learnable Bernoulli prior distribution compared to a constant edge dropout method. The learnable Bernoulli success rate p in our CU-GCN model is adaptively optimized during training. The results presented in Table VI provide compelling evidence for the effectiveness and necessity of this approach, as CU-GCN with the learnable Bernoulli prior consistently outperforms the constant p value method in terms of classification accuracy. Moreover, it is worth noting that even without the learnable Bernoulli prior, our CU-GCN approach still achieves competitive performance, often surpassing the results obtained by state-of-the-art methods. This highlights the robustness and effectiveness of CU-GCN in capturing important graph structure information and achieving accurate emotion classification, even in the absence of the learnable prior distribution. Overall, these findings emphasize the significance of incorporating the learnable Bernoulli prior distribution in CU-GCN, as it contributes to improved classi- fication accuracy and enhances the model's ability to leverage graph structure for emotion recognition tasks. 4) Is the Graph Data mixup Method Effective?: In our CU-GCN framework, we employ the graph mixup data augmentation technique to enhance the probability confidence and facilitate the learning process in the presence of noisy labels. We conducted experiments to evaluate the effectiveness of this approach, and the results are presented in Table  IV . The findings indicate that training with graph mixup leads to an improvement of 0.2∼0.3% in performance compared to training with the original dataset alone. Furthermore, the confusion matrices depicted in Figure  4  for the SEED and SEEDIV datasets demonstrate the substantial enhancement achieved by our data augmentation methods in addressing the challenges posed by noisy labels.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "V. Conclusion",
      "text": "In summary, our proposed method, which combines uncertainty-guided graph modeling and spectral-enhanced message aggregation, along with a noisy label learning approach, has achieved significant advancements in EEGbased emotion recognition. We have established new stateof-the-art performance in both subject-dependent and subjectindependent emotion classification tasks using two publicly available datasets. Our method demonstrates improved robustness and generalization capabilities. Notably, we have observed that instance adaptive graph learning methods yield more accurate recognition of emotional states compared to simply considering channel mutual relationships. Moreover, our extensive visualization experiments provide valuable support for distributionist theories in brain neuroscience. Looking ahead, our study opens up exciting possibilities for applying graph-based representations in multi-modal emotion recognition applications, as our methods are not limited to EEG alone.",
      "page_start": 10,
      "page_end": 11
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: The illustration of the four brain lobes (left) and the placement of",
      "page": 1
    },
    {
      "caption": "Figure 2: An Example of Temporal Brain Activation Maps for Three",
      "page": 2
    },
    {
      "caption": "Figure 1: represents",
      "page": 2
    },
    {
      "caption": "Figure 2: , even for the",
      "page": 2
    },
    {
      "caption": "Figure 3: A. Preliminaries",
      "page": 3
    },
    {
      "caption": "Figure 3: The framework of our Connectivity Uncertainty GCN. For a given adjacency matrix A ∈RN×N and node features X ∈RN×fl, we",
      "page": 4
    },
    {
      "caption": "Figure 4: Confusion Graph of Subject-Dependent/Subject-Independent",
      "page": 10
    },
    {
      "caption": "Figure 4: for the SEED and",
      "page": 11
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Feature": "DE",
          "Method": "SVM [4]\nDBN [4]",
          "δ band": "60.50 / 14.14\n64.32 / 12.45",
          "θ band": "60.95 / 10.20\n60.77 / 10.42",
          "α band": "66.64 / 14.41\n64.01 / 15.97",
          "β band": "80.76 / 11.56\n78.92 / 12.48",
          "γ band": "79.56 / 11.38\n79.19 / 14.58",
          "All bands": "83.99 / 09.72\n86.08 / 08.34"
        },
        {
          "Feature": "",
          "Method": "Bi-DANN [61]\nR2G-STNN [62]\nBiHDM [63]",
          "δ band": "76.97 / 10.95\n77.76 / 09.92\n-",
          "θ band": "75.56 / 07.88\n76.17 / 07.43\n-",
          "α band": "81.03 / 11.74\n82.30 / 10.21\n-",
          "β band": "89.65 / 09.59\n88.35 / 10.52\n-",
          "γ band": "88.64 / 09.46\n88.90 / 09.57\n-",
          "All bands": "92.38 / 07.04\n93.38 / 05.96\n85.40 / 07.53"
        },
        {
          "Feature": "",
          "Method": "vGCN [35]\nDGCNN [10]\nRGNN [11]\nGCB-net+BLS [64]\nV-IAG [20]",
          "δ band": "72.75 / 10.85\n74.25 / 11.42\n76.17 / 07.91\n79.98 / 08.93\n81.14 / 09.46",
          "θ band": "74.40 / 08.23\n71.52 / 05.99\n72.26 / 07.25\n76.51 / 09.56\n82.37 / 07.44",
          "α band": "73.46 / 12.17\n74.43 / 12.16\n75.33 / 08.85\n81.97 / 11.05\n84.51 / 09.68",
          "β band": "83.24 / 09.93\n83.65 / 10.17\n84.25 / 12.54\n89.06 / 08.69\n92.15 / 08.90",
          "γ band": "83.36 / 09.43\n85.73 / 10.64\n89.23 / 08.90\n89.10 / 09.55\n92.96 / 06.19",
          "All bands": "87.40 / 09.20\n90.40 / 08.49\n94.24 / 05.95\n94.24 / 06.70\n95.64 / 05.08"
        },
        {
          "Feature": "",
          "Method": "CU-GCN",
          "δ band": "82.01 / 08.76",
          "θ band": "80.62 / 08.33",
          "α band": "84.92 / 10.32",
          "β band": "92.56 / 09.17",
          "γ band": "93.32 / 05.94",
          "All bands": "95.70 / 05.32"
        }
      ],
      "page": 8
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "PSD": "",
          "SVM [4]\nDBN [4]": "vGCN [35]\nDGCNN [10]\nGCB-net+BLS [64]\nV-IAG [20]",
          "58.03 / 15.39\n60.05 / 16.66": "69.89 / 13.83\n71.23 / 11.42\n72.90 / 13.19\n-",
          "57.26 / 15.09\n55.03 / 13.88": "70.92 / 09.18\n71.20 / 08.99\n74.48 / 09.03\n-",
          "59.04 / 15.75\n52.79 / 15.38": "73.18 / 12.74\n73.45 / 12.25\n76.99 / 10.36\n-",
          "73.34 / 15.20\n60.68 / 21.31": "76.21 / 10.76\n77.45 / 10.81\n83.30 / 10.73\n-",
          "71.24 / 16.38\n63.42 / 19.66": "76.15 / 10.09\n76.60 / 11.83\n83.12 / 11.95\n-",
          "59.60 / 15.93\n61.90 / 16.65": "81.31 / 11.26\n81.73 / 09.94\n84.32 / 10.61\n86.71 / 10.25"
        },
        {
          "PSD": "",
          "SVM [4]\nDBN [4]": "CU-GCN",
          "58.03 / 15.39\n60.05 / 16.66": "74.10 / 09.78",
          "57.26 / 15.09\n55.03 / 13.88": "73.84 / 07.35",
          "59.04 / 15.75\n52.79 / 15.38": "77.00 / 09.53",
          "73.34 / 15.20\n60.68 / 21.31": "84.56 / 10.49",
          "71.24 / 16.38\n63.42 / 19.66": "85.49 / 09.17",
          "59.60 / 15.93\n61.90 / 16.65": "87.21 / 09.81"
        }
      ],
      "page": 8
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "DASM": "",
          "SVM [4]\nDBN [4]": "vGCN [35]\nDGCNN [10]\nGCB-net+BLS [64]\nV-IAG [20]",
          "48.87 / 10.49\n48.79 / 09.62": "57.07 / 06.75\n55.93 / 09.14\n62.36 / 10.66\n-",
          "53.02 / 12.76\n51.59 / 13.98": "54.80 / 09.09\n56.12 / 07.86\n65.00 / 10.31\n-",
          "59.81 / 14.67\n54.03 / 17.05": "62.97 / 13.43\n64.27 / 12.72\n70.91 / 10.84\n-",
          "75.03 / 15.72\n69.51 / 15.22": "74.97 / 13.40\n73.61 / 14.35\n85.55 / 11.39\n-",
          "73.59 / 16.57\n70.06 / 18.14": "73.28 / 13.67\n73.50 / 16.60\n86.04 / 10.85\n-",
          "72.81 / 16.57\n72.73 / 15.93": "76.00 / 13.32\n78.45 / 11.84\n82.09 / 13.14\n90.10 / 08.73"
        },
        {
          "DASM": "",
          "SVM [4]\nDBN [4]": "CU-GCN",
          "48.87 / 10.49\n48.79 / 09.62": "64.56 / 08.81",
          "53.02 / 12.76\n51.59 / 13.98": "68.77 / 10.34",
          "59.81 / 14.67\n54.03 / 17.05": "73.11 / 09.62",
          "75.03 / 15.72\n69.51 / 15.22": "87.77 / 10.69",
          "73.59 / 16.57\n70.06 / 18.14": "87.43 / 10.09",
          "72.81 / 16.57\n72.73 / 15.93": "91.04 / 09.16"
        }
      ],
      "page": 8
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "RASM": "",
          "SVM [4]\nDBN [4]": "vGCN [35]\nDGCNN [10]\nGCB-net+BLS [64]\nV-IAG [20]",
          "47.75 / 10.59\n48.05 / 10.37": "59.70 / 05.65\n57.79 / 06.90\n62.56 / 08.83\n-",
          "51.40 / 12.53\n50.62 / 14.02": "55.91 / 08.82\n55.79 / 08.10\n62.22 / 11.12\n-",
          "60.71 / 14.57\n56.15 / 15.28": "59.97 / 14.27\n61.58 / 12.63\n71.43 / 10.83\n-",
          "74.59 /16.18\n70.31 / 15.62": "79.45 / 13:32\n75.79 / 13.07\n87.03 / 11.16\n-",
          "74.61 / 15.57\n68.22 / 18.09": "79.73 / 13.22\n82.32 / 11.54\n85.59 / 11.18\n-",
          "74.74 / 14.79\n71.30 / 16.16": "84.06 / 12.86\n85.00 / 12.47\n87.73 / 10.19\n90.53 / 09.22"
        },
        {
          "RASM": "",
          "SVM [4]\nDBN [4]": "CU-GCN",
          "47.75 / 10.59\n48.05 / 10.37": "63.98 / 07.21",
          "51.40 / 12.53\n50.62 / 14.02": "64.52 / 08.79",
          "60.71 / 14.57\n56.15 / 15.28": "72.70 / 11.32",
          "74.59 /16.18\n70.31 / 15.62": "88.82 / 09.92",
          "74.61 / 15.57\n68.22 / 18.09": "86.56 / 10.72",
          "74.74 / 14.79\n71.30 / 16.16": "89.77 / 09.68"
        }
      ],
      "page": 8
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Feature": "DE",
          "Method": "SVM [5]\nDBN [4]\nBiDANN [61]\nBiHDM [63]\nvGCN† [35]\nDGCNN† [10]\nRGNN† [11]",
          "δ band": "57.58 / 12.64\n-\n-\n-\n60.23 / 12.47\n61.84 / 11.62\n64.23 / 09.83",
          "θ band": "57.98 / 12.30\n-\n-\n-\n58.07 / 12.21\n63.44 / 13.91\n62.33 / 10.14",
          "α band": "61.22 / 16.46\n-\n-\n-\n61.97 / 10.06\n63.74 / 13.15\n65.98 / 08.52",
          "β band": "66.66 / 18.80\n-\n-\n-\n68.87 / 09.12\n67.28 / 12.82\n72.47 / 09.35",
          "γ band": "66.34 / 17.49\n-\n-\n-\n66.50 / 14.01\n64.77 / 12.38\n71.66 / 09.51",
          "All bands": "70.58 / 17.01\n66.77 / 07.38\n70.29 / 12.63\n74.35 / 14.09\n70.81 / 11.56\n70.47 / 15.29\n75.90 / 12.11"
        },
        {
          "Feature": "",
          "Method": "CU-GCN",
          "δ band": "66.21 / 07.71",
          "θ band": "64.81 / 08.12",
          "α band": "65.92 / 09.69",
          "β band": "75.93 / 08.77",
          "γ band": "73.44 / 10.10",
          "All bands": "77.39 / 09.24"
        }
      ],
      "page": 8
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Method": "",
          "SEED\nSEEDIV": "δ band"
        },
        {
          "Method": "SVM [4]\nBiDANN-S [61]\nDANN [66]\nR2G-STNN [62]\nBiHDM [63]\nDGCNN [10]\nRGNN [11]\nV-IAG [20]",
          "SEED\nSEEDIV": "43.06 / 08.27\n63.01 / 07.49\n56.66 / 06.48\n63.34 / 05.31\n-\n49.79 / 10.94\n64.88 / 06.87\n-"
        },
        {
          "Method": "CU-GCN",
          "SEED\nSEEDIV": "64.72 / 05.99"
        }
      ],
      "page": 9
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "The psychophysiology of emotion",
      "authors": [
        "J Cacioppo",
        "G Berntson",
        "J Larsen",
        "K Poehlmann",
        "T Ito"
      ],
      "year": "2000",
      "venue": "Handbook of emotions"
    },
    {
      "citation_id": "2",
      "title": "Neural mechanisms and temporal dynamics of performance monitoring",
      "authors": [
        "M Ullsperger",
        "A Fischer",
        "R Nigbur",
        "T Endrass"
      ],
      "year": "2014",
      "venue": "Trends in Cognitive Sciences"
    },
    {
      "citation_id": "3",
      "title": "fnirs-based brain-computer interfaces: a review",
      "authors": [
        "N Naseer",
        "K.-S Hong"
      ],
      "year": "2015",
      "venue": "Frontiers in Human Neuroscience"
    },
    {
      "citation_id": "4",
      "title": "Investigating critical frequency bands and channels for eeg-based emotion recognition with deep neural networks",
      "authors": [
        "W.-L Zheng",
        "B.-L Lu"
      ],
      "year": "2015",
      "venue": "IEEE Transactions on Autonomous Mental Development"
    },
    {
      "citation_id": "5",
      "title": "Emotionmeter: A multimodal framework for recognizing human emotions",
      "authors": [
        "W.-L Zheng",
        "W Liu",
        "Y Lu",
        "B.-L Lu",
        "A Cichocki"
      ],
      "year": "2018",
      "venue": "IEEE Transactions on Cybernetics"
    },
    {
      "citation_id": "6",
      "title": "Spatial-temporal recurrent neural network for emotion recognition",
      "authors": [
        "T Zhang",
        "W Zheng",
        "Z Cui",
        "Y Zong",
        "Y Li"
      ],
      "year": "2018",
      "venue": "IEEE transactions on cybernetics"
    },
    {
      "citation_id": "7",
      "title": "Emotion recognition from multimodal physiological signals using a regularized deep fusion of kernel machine",
      "authors": [
        "X Zhang",
        "J Liu",
        "J Shen",
        "S Li",
        "K Hou",
        "B Hu",
        "J Gao",
        "T Zhang"
      ],
      "year": "2020",
      "venue": "IEEE transactions on cybernetics"
    },
    {
      "citation_id": "8",
      "title": "Sst-emotionnet: Spatial-spectral-temporal based attention 3d dense network for eeg emotion recognition",
      "authors": [
        "Z Jia",
        "Y Lin",
        "X Cai",
        "H Chen",
        "H Gou",
        "J Wang"
      ],
      "year": "2020",
      "venue": "Proceedings of the 28th ACM International Conference on Multimedia"
    },
    {
      "citation_id": "9",
      "title": "Neural correlates of social and nonsocial emotions: An fmri study",
      "authors": [
        "J Britton",
        "K Phan",
        "S Taylor",
        "R Welsh",
        "K Berridge",
        "I Liberzon"
      ],
      "year": "2006",
      "venue": "Neuroimage"
    },
    {
      "citation_id": "10",
      "title": "Eeg emotion recognition using dynamical graph convolutional neural networks",
      "authors": [
        "T Song",
        "W Zheng",
        "P Song",
        "Z Cui"
      ],
      "year": "2018",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "11",
      "title": "Eeg-based emotion recognition using regularized graph neural networks",
      "authors": [
        "P Zhong",
        "D Wang",
        "C Miao"
      ],
      "year": "2020",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "12",
      "title": "Deeper insights into graph convolutional networks for semi-supervised learning",
      "authors": [
        "Q Li",
        "Z Han",
        "X.-M Wu"
      ],
      "year": "2018",
      "venue": "Thirty-Second AAAI Conference on Artificial Intelligence"
    },
    {
      "citation_id": "13",
      "title": "Dropout: a simple way to prevent neural networks from overfitting",
      "authors": [
        "N Srivastava",
        "G Hinton",
        "A Krizhevsky",
        "I Sutskever",
        "R Salakhutdinov"
      ],
      "year": "2014",
      "venue": "The Journal of Machine Learning Research"
    },
    {
      "citation_id": "14",
      "title": "Dropedge: Towards deep graph convolutional networks on node classification",
      "authors": [
        "Y Rong",
        "W Huang",
        "T Xu",
        "J Huang"
      ],
      "year": "2020",
      "venue": "International Conference on Learning Representations (ICLR)"
    },
    {
      "citation_id": "15",
      "title": "Revisiting graph based collaborative filtering: A linear residual graph convolutional network approach",
      "authors": [
        "L Chen",
        "L Wu",
        "R Hong",
        "K Zhang",
        "M Wang"
      ],
      "year": "2020",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence"
    },
    {
      "citation_id": "16",
      "title": "Eeg-gnn: Graph neural networks for classification of electroencephalogram (eeg) signals",
      "authors": [
        "A Demir",
        "T Koike-Akino",
        "Y Wang",
        "M Haruna",
        "D Erdogmus"
      ],
      "year": "2021",
      "venue": "2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)"
    },
    {
      "citation_id": "17",
      "title": "Self-supervised graph neural networks for improved electroencephalographic seizure analysis",
      "authors": [
        "S Tang",
        "J Dunnmon",
        "K Saab",
        "X Zhang",
        "Q Huang",
        "F Dubost",
        "D Rubin",
        "C Lee-Messer"
      ],
      "venue": "International Conference on Learning Representations (ICLR)"
    },
    {
      "citation_id": "18",
      "title": "Rethinking the emotional brain",
      "authors": [
        "J Ledoux"
      ],
      "year": "2012",
      "venue": "Neuron"
    },
    {
      "citation_id": "19",
      "title": "Frontal eeg asymmetry of mood: A minireview",
      "authors": [
        "M Palmiero",
        "L Piccardi"
      ],
      "year": "2017",
      "venue": "Frontiers in Behavioral Neuroscience"
    },
    {
      "citation_id": "20",
      "title": "Variational instance-adaptive graph for eeg emotion recognition",
      "authors": [
        "T Song",
        "S Liu",
        "W Zheng",
        "Y Zong",
        "Z Cui",
        "Y Li",
        "X Zhou"
      ],
      "year": "2021",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "21",
      "title": "Eeg-based emotion recognition via fast and robust feature smoothing",
      "authors": [
        "C Tang",
        "D Wang",
        "A.-H Tan",
        "C Miao"
      ],
      "year": "2017",
      "venue": "International Conference on Brain Informatics"
    },
    {
      "citation_id": "22",
      "title": "Real-time eeg-based emotion monitoring using stable features",
      "authors": [
        "Z Lan",
        "O Sourina",
        "L Wang",
        "Y Liu"
      ],
      "year": "2016",
      "venue": "The Visual Computer"
    },
    {
      "citation_id": "23",
      "title": "Affective picture processing: an integrative review of erp findings",
      "authors": [
        "J Olofsson",
        "S Nordin",
        "H Sequeira",
        "J Polich"
      ],
      "year": "2008",
      "venue": "Biological Psychology"
    },
    {
      "citation_id": "24",
      "title": "Eeg-based emotion recognition in music listening",
      "authors": [
        "Y.-P Lin",
        "C.-H Wang",
        "T.-P Jung",
        "T.-L Wu",
        "S.-K Jeng",
        "J.-R Duann",
        "J.-H Chen"
      ],
      "year": "2010",
      "venue": "IEEE Transactions on Biomedical Engineering"
    },
    {
      "citation_id": "25",
      "title": "Real-time movie-induced discrete emotion recognition from eeg signals",
      "authors": [
        "Y.-J Liu",
        "M Yu",
        "G Zhao",
        "J Song",
        "Y Ge",
        "Y Shi"
      ],
      "year": "2017",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "26",
      "title": "Emotion detection from eeg signals with continuous wavelet analyzing",
      "authors": [
        "M Sorkhabi"
      ],
      "year": "2014",
      "venue": "Am. J. Comput. Res. Repos"
    },
    {
      "citation_id": "27",
      "title": "The dynamical hypothesis in cognitive science",
      "authors": [
        "T Van Gelder"
      ],
      "year": "1998",
      "venue": "Behavioral and Brain Sciences"
    },
    {
      "citation_id": "28",
      "title": "Assessing the complexity of short-term heartbeat interval series by distribution entropy",
      "authors": [
        "P Li",
        "C Liu",
        "K Li",
        "D Zheng",
        "C Liu",
        "Y Hou"
      ],
      "year": "2015",
      "venue": "Medical Biological Engineering Computing"
    },
    {
      "citation_id": "29",
      "title": "Eeg based emotion recognition system using mfdfa as feature extractor",
      "authors": [
        "S Paul",
        "A Mazumder",
        "P Ghosh",
        "D Tibarewala",
        "G Vimalarani"
      ],
      "year": "2015",
      "venue": "2015 International Conference on Robotics, Automation, Control and Embedded Systems (RACE)"
    },
    {
      "citation_id": "30",
      "title": "Electroencephalogram asymmetry during emotionally evocative films and its relation to positive and negative affectivity",
      "authors": [
        "N Jones",
        "N Fox"
      ],
      "year": "1992",
      "venue": "Brain and Cognition"
    },
    {
      "citation_id": "31",
      "title": "Differential entropy feature for eeg-based vigilance estimation",
      "authors": [
        "L.-C Shi",
        "Y.-Y Jiao",
        "B.-L Lu"
      ],
      "year": "2013",
      "venue": "2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)"
    },
    {
      "citation_id": "32",
      "title": "Eegbased emotion recognition via channel-wise attention and self attention",
      "authors": [
        "W Tao",
        "C Li",
        "R Song",
        "J Cheng",
        "Y Liu",
        "F Wan",
        "X Chen"
      ],
      "year": "2020",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "33",
      "title": "A novel bi-hemispheric discrepancy model for eeg emotion recognition",
      "authors": [
        "Y Li",
        "L Wang",
        "W Zheng",
        "Y Zong",
        "L Qi",
        "Z Cui",
        "T Zhang",
        "T Song"
      ],
      "year": "2021",
      "venue": "IEEE Transactions on Cognitive and Developmental Systems"
    },
    {
      "citation_id": "34",
      "title": "Spectral networks and deep locally connected networks on graphs",
      "authors": [
        "J Estrach",
        "W Zaremba",
        "A Szlam",
        "Y Lecun"
      ],
      "year": "2014",
      "venue": "International Conference on Learning Representations (ICLR)"
    },
    {
      "citation_id": "35",
      "title": "Convolutional neural networks on graphs with fast localized spectral filtering",
      "authors": [
        "M Defferrard",
        "X Bresson",
        "P Vandergheynst"
      ],
      "year": "2016",
      "venue": "Advances in Neural Information Processing Systems (NeurIPS)"
    },
    {
      "citation_id": "36",
      "title": "Learning convolutional neural networks for graphs",
      "authors": [
        "M Niepert",
        "M Ahmed",
        "K Kutzkov"
      ],
      "year": "2016",
      "venue": "International Conference on Machine Learning (ICML)"
    },
    {
      "citation_id": "37",
      "title": "Inductive representation learning on large graphs",
      "authors": [
        "W Hamilton",
        "Z Ying",
        "J Leskovec"
      ],
      "year": "2017",
      "venue": "Advances in Neural Information Processing Systems (NeurIPS)"
    },
    {
      "citation_id": "38",
      "title": "Predict then propagate: Graph neural networks meet personalized pagerank",
      "authors": [
        "J Gasteiger",
        "A Bojchevski",
        "S Günnemann"
      ],
      "year": "2019",
      "venue": "International Conference on Learning Representations (ICLR)"
    },
    {
      "citation_id": "39",
      "title": "Spatio-temporalspectral hierarchical graph convolutional network with semisupervised active learning for patient-specific seizure prediction",
      "authors": [
        "Y Li",
        "Y Liu",
        "Y.-Z Guo",
        "X.-F Liao",
        "B Hu",
        "T Yu"
      ],
      "year": "2021",
      "venue": "IEEE transactions on cybernetics"
    },
    {
      "citation_id": "40",
      "title": "A review of uncertainty quantification in deep learning: Techniques, applications and challenges",
      "authors": [
        "M Abdar",
        "F Pourpanah",
        "S Hussain",
        "D Rezazadegan",
        "L Liu",
        "M Ghavamzadeh",
        "P Fieguth",
        "X Cao",
        "A Khosravi",
        "U Acharya"
      ],
      "year": "2021",
      "venue": "Information Fusion"
    },
    {
      "citation_id": "41",
      "title": "A novel representation learning for dynamic graphs based on graph convolutional networks",
      "authors": [
        "C Gao",
        "J Zhu",
        "F Zhang",
        "Z Wang",
        "X Li"
      ],
      "year": "2022",
      "venue": "IEEE Transactions on Cybernetics"
    },
    {
      "citation_id": "42",
      "title": "Bayesian graph convolutional neural networks for semi-supervised classification",
      "authors": [
        "Y Zhang",
        "S Pal",
        "M Coates",
        "D Ustebay"
      ],
      "year": "2019",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence"
    },
    {
      "citation_id": "43",
      "title": "A general framework for quantifying aleatoric and epistemic uncertainty in graph neural networks",
      "authors": [
        "S Munikoti",
        "D Agarwal",
        "L Das",
        "B Natarajan"
      ],
      "year": "2022",
      "venue": "A general framework for quantifying aleatoric and epistemic uncertainty in graph neural networks",
      "arxiv": "arXiv:2205.09968"
    },
    {
      "citation_id": "44",
      "title": "Variational dropout and the local reparameterization trick",
      "authors": [
        "D Kingma",
        "T Salimans",
        "M Welling"
      ],
      "year": "2015",
      "venue": "Advances in Neural Information Processing Systems (NeurIPS)"
    },
    {
      "citation_id": "45",
      "title": "Dropout as a bayesian approximation: Representing model uncertainty in deep learning",
      "authors": [
        "Y Gal",
        "Z Ghahramani"
      ],
      "year": "2016",
      "venue": "International Conference on Machine Learning (ICML)"
    },
    {
      "citation_id": "46",
      "title": "Bayesian graph neural networks with adaptive connection sampling",
      "authors": [
        "A Hasanzadeh",
        "E Hajiramezanali",
        "S Boluki",
        "M Zhou",
        "N Duffield",
        "K Narayanan",
        "X Qian"
      ],
      "year": "2020",
      "venue": "International Conference on Machine Learning (ICML)"
    },
    {
      "citation_id": "47",
      "title": "Uag: Uncertainty-aware attention graph neural network for defending adversarial attacks",
      "authors": [
        "B Feng",
        "Y Wang",
        "Y Ding"
      ],
      "year": "2021",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence"
    },
    {
      "citation_id": "48",
      "title": "Spectral graph theory",
      "authors": [
        "F Chung",
        "F Graham"
      ],
      "year": "1997",
      "venue": "Spectral graph theory"
    },
    {
      "citation_id": "49",
      "title": "Graph wavelet neural network",
      "authors": [
        "B Xu",
        "H Shen",
        "Q Cao",
        "Y Qiu",
        "X Cheng"
      ],
      "year": "2019",
      "venue": "International Conference on Learning Representations (ICLR)"
    },
    {
      "citation_id": "50",
      "title": "How framelets enhance graph neural networks",
      "authors": [
        "X Zheng",
        "B Zhou",
        "J Gao",
        "Y Wang",
        "P Lió",
        "M Li",
        "G Montúfar"
      ],
      "year": "2021",
      "venue": "How framelets enhance graph neural networks",
      "arxiv": "arXiv:2102.06986"
    },
    {
      "citation_id": "51",
      "title": "Semi-supervised classification with graph convolutional networks",
      "authors": [
        "T Kipf",
        "M Welling"
      ],
      "year": "2017",
      "venue": "International Conference on Learning Representation"
    },
    {
      "citation_id": "52",
      "title": "Simple statistical gradient-following algorithms for connectionist reinforcement learning",
      "authors": [
        "R Williams"
      ],
      "year": "1992",
      "venue": "Machine Learning"
    },
    {
      "citation_id": "53",
      "title": "Auto-encoding variational bayes",
      "authors": [
        "D Kingma",
        "M Welling"
      ],
      "year": "2013",
      "venue": "Auto-encoding variational bayes",
      "arxiv": "arXiv:1312.6114"
    },
    {
      "citation_id": "54",
      "title": "Doubly stochastic variational bayes for non-conjugate inference",
      "authors": [
        "M Titsias",
        "M Lázaro-Gredilla"
      ],
      "year": "2014",
      "venue": "International Conference on Machine Learning (ICML)"
    },
    {
      "citation_id": "55",
      "title": "Optimizing generalized pagerank methods for seed-expansion community detection",
      "authors": [
        "P Li",
        "I Chien",
        "O Milenkovic"
      ],
      "year": "2019",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "56",
      "title": "Adaptive universal generalized pagerank graph neural network",
      "authors": [
        "E Chien",
        "J Peng",
        "P Li",
        "O Milenkovic"
      ],
      "year": "2020",
      "venue": "International Conference on Learning Representations (ICLR)"
    },
    {
      "citation_id": "57",
      "title": "Simplifying graph convolutional networks",
      "authors": [
        "F Wu",
        "A Souza",
        "T Zhang",
        "C Fifty",
        "T Yu",
        "K Weinberger"
      ],
      "year": "2019",
      "venue": "International Conference on Machine Learning (ICML)"
    },
    {
      "citation_id": "58",
      "title": "mixup: Beyond empirical risk minimization",
      "authors": [
        "H Zhang",
        "M Cisse",
        "Y Dauphin",
        "D Lopez-Paz"
      ],
      "year": "2018",
      "venue": "International Conference on Learning Representations (ICLR)"
    },
    {
      "citation_id": "59",
      "title": "Mixup for node and graph classification",
      "authors": [
        "Y Wang",
        "W Wang",
        "Y Liang",
        "Y Cai",
        "B Hooi"
      ],
      "year": "2021",
      "venue": "Proceedings of the Web Conference"
    },
    {
      "citation_id": "60",
      "title": "Handbook of beta distribution and its applications",
      "authors": [
        "A Gupta",
        "S Nadarajah"
      ],
      "year": "2004",
      "venue": "Handbook of beta distribution and its applications"
    },
    {
      "citation_id": "61",
      "title": "A bihemisphere domain adversarial neural network model for eeg emotion recognition",
      "authors": [
        "Y Li",
        "W Zheng",
        "Y Zong",
        "Z Cui",
        "T Zhang",
        "X Zhou"
      ],
      "year": "2018",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "62",
      "title": "From regional to global brain: A novel hierarchical spatial-temporal neural network model for eeg emotion recognition",
      "authors": [
        "Y Li",
        "W Zheng",
        "L Wang",
        "Y Zong",
        "Z Cui"
      ],
      "year": "2022",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "63",
      "title": "A novel bi-hemispheric discrepancy model for eeg emotion recognition",
      "authors": [
        "Y Li",
        "L Wang",
        "W Zheng",
        "Y Zong",
        "L Qi",
        "Z Cui",
        "T Zhang",
        "T Song"
      ],
      "year": "2020",
      "venue": "IEEE Transactions on Cognitive and Developmental Systems"
    },
    {
      "citation_id": "64",
      "title": "Gcb-net: Graph convolutional broad network and its application in emotion recognition",
      "authors": [
        "T Zhang",
        "X Wang",
        "X Xu",
        "C Chen"
      ],
      "year": "2019",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "65",
      "title": "Emotional state classification from eeg data using machine learning approach",
      "authors": [
        "X.-W Wang",
        "D Nie",
        "B.-L Lu"
      ],
      "year": "2014",
      "venue": "Neurocomputing"
    },
    {
      "citation_id": "66",
      "title": "Domain-adversarial training of neural networks",
      "authors": [
        "Y Ganin",
        "E Ustinova",
        "H Ajakan",
        "P Germain",
        "H Larochelle",
        "F Laviolette",
        "M Marchand",
        "V Lempitsky"
      ],
      "year": "2016",
      "venue": "The Journal of Machine Learning Research"
    }
  ]
}