{
  "paper_id": "2506.18201v1",
  "title": "Deciphering Emotions In Children Storybooks: A Comparative Analysis Of Multimodal Llms In Educational Applications",
  "published": "2025-06-22T23:20:23Z",
  "authors": [
    "Bushra Asseri",
    "Estabraq Abdelaziz",
    "Maha Al Mogren",
    "Tayef Alhefdhi",
    "Areej Al-Wabil"
  ],
  "keywords": [
    "Multimodal Large Language Models (MLLMs)",
    "Digital Storybooks",
    "Educational Technology",
    "Culturally Responsive Education",
    "Prompting Techniques",
    "Emotional Intelligence"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Emotion recognition capabilities in multimodal AI systems are crucial for developing culturally responsive educational technologies, yet remain underexplored for Arabic language contexts where culturally appropriate learning tools are critically needed. This study evaluates the emotion recognition performance of two advanced multimodal large language models, GPT-4o and Gemini 1.5 Pro, when processing Arabic children's storybook illustrations. We assessed both models across three prompting strategies (zero-shot, few-shot, and chain-of-thought) using 75 images from seven Arabic storybooks, comparing model predictions with human annotations based on Plutchik's emotional framework. GPT-4o consistently outperformed Gemini across all conditions, achieving the highest macro F1score of 59% with chain-of-thought prompting compared to Gemini's best performance of 43%. Error analysis revealed systematic misclassification patterns, with valence inversions accounting for 60.7% of errors, while both models struggled with culturally nuanced emotions and ambiguous narrative contexts. These findings highlight fundamental limitations in current models' cultural understanding and emphasize the need for culturally sensitive training approaches to develop effective emotion-aware educational technologies for Arabic-speaking learners.",
      "page_start": 1,
      "page_end": 15
    },
    {
      "section_name": "Introduction",
      "text": "Understanding emotions through visual forms is essential for effective communication and learning, especially in early childhood  [1, 2] . As the role of Artificial Intelligence (AI) in education continues to grow, the ability to interpret emotions in illustrated children's books becomes increasingly important for developing culturally responsive educational technologies  [3] . Recent advances in MLLMs, such as GPT-4o and Gemini, have significantly improved visual-textual reasoning capabilities  [4] , yet their application to non-English educational contexts remains limited  [5] . Arabic children's literature presents unique challenges for computational emotion recognition due to its expressive language, cultural symbolism, and artistic style  [6] . Despite the educational importance of emotion recognition in early literacy development highlighted by  [7] , there exists a significant gap in our understanding of how well current AI systems can interpret emotional content in Arabic visual narratives. This study addresses this research gap by systematically evaluating the emotion recognition capabilities of two advanced MLLMs, GPT-4o and Gemini Pro 1.5, when processing illustrations from Arabic children's storybooks. The primary aim of this study is to determine the accuracy and effectiveness of Large Language Models in identifying emotions in images from Arabic children's storybooks. To accomplish this aim, we pursue several specific objectives: to evaluate and compare the effectiveness of different prompting strategies (zero-shot, few-shot, chain-of-thought) on MLLMs' emotion recognition accuracy in Arabic visual narratives; to identify and categorize common error patterns when MLLMs interpret emotional content in Arabic children's literature; and to assess MLLMs' performance against human consensus when interpreting ambiguous or culturally nuanced emotional expressions.\n\nTo achieve these objectives, we compare the models' performance across three distinct prompting strategies using a dataset of 75 images from seven Arabic storybooks, with human-annotated emotions based on Plutchik's framework serving as ground truth  [8] . Beyond simple accuracy metrics, we analyze cases where models struggle with narrative complexity or misinterpret subtle emotional expressions, providing insights into the challenges of cross-cultural emotion recognition in educational AI  [9] . This research makes several contributions to the fields of educational technology and Arabic digital literacy:  (1)  it presents the first systematic evaluation of MLLMs for emotion recognition in Arabic children's literature;  (2)  it identifies specific patterns of success and failure in cross-cultural emotion recognition tasks; and (3) it provides actionable recommendations for developing more culturally sensitive AI systems for Arabic literacy education  [10] . Through exploratory experiments expanding the emotional label space and isolating individual characters from their narrative contexts, we offer additional insights into the models' emotional reasoning capabilities. The findings of this study have significant implications for the design of emotion-aware educational technologies that can effectively support Arabic literacy acquisition and social-emotional learning in culturally appropriate ways.\n\n2 Literature Review",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Emotion Recognition In Educational Technologies",
      "text": "Affective computing has facilitated the integration of emotion recognition within educational technology, enabling adaptive systems to personalize interactions by detecting engagement, confusion, frustration, and joy. Research shows that intelligent tutoring systems with emotion recognition capabilities increase student engagement and retention through responsive feedback. Recent studies highlight multimodal approaches that combine facial expressions, eye movements, and biosignal data, with empirical evidence showing significant improvements in learning outcomes when integrated into educational environments  [11] . These technological applications are grounded in established educational frameworks. Vygotsky's concept of the Zone of Proximal Development aligns with how adaptive systems adjust learning tasks based on detected emotional states  [12] , while Piaget's theory of cognitive development intersects with emotional development through the influence of emotional states on attention and focus  [13, 7] . These theoretical connections are especially relevant in cross-cultural contexts such as Arabic educational settings, where sociocultural factors significantly influence emotional expression and interpretation  [6, 14] .",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Arabic Children'S Literature And Emotional Content",
      "text": "Arabic children's literature presents unique challenges for computational emotion recognition due to its expressive language, cultural symbolism, and implicit emotional cues. The poetic tradition in Arabic literature contributes to its emotional complexity through specific formal structures and elaborate metaphors, with distinctive symbolism: desert imagery representing resilience, nature elements mirroring emotional states, and love metaphors expressing profound longing. This rich symbolic language creates challenges for computational systems trained primarily on literal expressions. Additional challenges include the morphological complexity and diglossic nature of Arabic, where Modern Standard Arabic coexists with more than 25 regional dialects that differ morphologically, phonologically, and lexically. Children's literature often contains elements of both formal and dialectal forms, particularly in dialogue, creating a complex linguistic landscape for emotion detection  [15] . Visual elements often convey emotional subtleties within Arabic children's stories, highlighting the necessity for AI models capable of nuanced multimodal understanding. Recent computational approaches have developed specialized Arabic emotion lexicons for basic emotions, demonstrating the need for culturally adapted resources  [16] . Preliminary studies suggest that existing LLMs sometimes misinterpret culturally contextual imagery, underscoring the importance of culturally anchored datasets and annotations  [17, 15] .",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Plutchik'S Emotion Model In Cross-Cultural Contexts",
      "text": "Plutchik's Wheel of Emotions, comprising eight fundamental emotions (joy, trust, fear, surprise, sadness, disgust, anger, anticipation), serves as our analytical framework  [8, 18] . Each emotion is represented at three intensity levels, with opposites arranged diametrically and potential combinations identified (e.g., joy + trust = love)  [8] . However, the model's presumed universality requires scrutiny given cultural variability in emotional expression. For instance, emotions like \"trust\" ( ) within Arabic narratives encompass broader concepts of reassurance, confidence, and relational sensibilities, diverging from Plutchik's Western-centric definitions  [11] . When applied to Arabic emotion detection, researchers have adapted the framework by developing specialized seed lexicons corresponding to the eight primary emotions  [11, 19] .\n\nCross-cultural studies provide further evidence of both universality and cultural specificity in emotion recognition.  [20]  demonstrated that while basic emotions can be recognized across unfamiliar languages, Arabic stimuli consistently yielded the lowest recognition rates among English listeners, with 92% of participants rating Arabic as the most challenging language for emotion recognition. This indicates that while core emotional expressions may be universally recognizable, cultural and linguistic factors significantly influence their interpretation.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Multimodal Llms And Prompting Techniques",
      "text": "State-of-the-art multimodal LLMs such as GPT-4o and Gemini demonstrate varying proficiencies in emotional interpretation within complex, narrative-rich scenarios. GPT-4o processes audio, vision, and text inputs in real-time, while Gemini models handle similar multimodal inputs with their \"Deep Think\" reasoning mode enhancing nuanced analysis  [4] . Recent evaluations reveal that Gemini achieves high accuracy in distinguishing emotional polarities across standard datasets but struggles with neutral expressions and complex academic emotions  [21] . Similarly, GPT models face challenges with Arabic morphology and syntax, highlighting the need for language-specific adaptation  [19] . Performance significantly depends on the prompting methodology employed. Studies suggest that chain-of-thought (CoT) prompting, which instructs models to \"think step-by-step,\" can enhance precision but may occasionally induce overinterpretation  [9] . Interestingly, research on Arabic emotion classification has found that prompts in English sometimes outperform Arabic prompts when addressing Arabic content, highlighting the complex interplay of language, culture, and model training  [19] . These models employ various architectures for multimodal processing, from early-fusion approaches that interleave image and text tokens from initial layers to dual-encoder designs that separately process different modalities before integration  [4] . The continued advancement of large context windows enables analysis of extended narratives and multi-page illustrations, critical for processing children's literature  [4, 22] .",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Educational Applications And Arabic Literacy Development",
      "text": "Integration of emotion-aware AI technologies in Arabic educational platforms remains limited despite their potential to enhance reading applications by dynamically customizing content delivery based on emotional feedback. Empirical studies demonstrate promising outcomes when emotion recognition is embedded in educational systems. A 2023 study analyzing schoolchildren's emotions and handwriting performance of Arabic letters showed that biofeedback on emotional states significantly improved learning outcomes  [23] . Arabic language textbooks are increasingly incorporating social-emotional learning components through texts, illustrations, and activities that promote selfunderstanding and respectful dialogue  [24] . However, these static materials lack the adaptive capabilities that AIpowered emotion recognition could provide. Research indicates that integrating emotional intelligence approaches in Arabic language learning yields substantial benefits for students' overall development. The current scarcity of annotated Arabic datasets and the underrepresentation of Arabic-specific content in pretraining corpora underline the importance of targeted dataset development  [11, 19] . Recent initiatives like ArPanEmo address this gap by providing manually labeled Arabic content for multiple emotion categories  [25] . Such resources are crucial for developing culturally appropriate emotion recognition systems for educational contexts in Arabic-speaking populations.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Cultural Considerations And Design Recommendations",
      "text": "Cultural context is critical in interpreting emotional expressions within educational AI applications. Systems lacking cultural sensitivity risk misinterpreting authors' intentions and fostering misunderstandings  [10] . Research in Arabic children's literature in educational settings indicates that original Arabic works often emphasize interpersonal emotional skills related to immediate social bonds rather than individual emotional competencies  [24] . This cultural orientation should be reflected in educational AI systems designed for Arabic-speaking children. Designing culturally responsive educational AI requires prioritizing explainability, multimodal processing capabilities, and native language interactions. Recent advances in Arabic-specific natural language processing provide promising foundations, with models such as AraBERT, MARBERT, and QARiB demonstrating significant improvements in emotion classification when fine-tuned on task-specific data  [11, 19] . Multimodal approaches show particular promise, combining text analysis with visual processing to capture the rich emotional content conveyed through illustrations in children's books. By integrating these modalities, systems can better understand the complementary or occasionally contradictory emotional signals present in text and images  [15] .",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Research Gaps And Study Rationale",
      "text": "This review of the literature emphasizes the critical intersection of AI technologies, emotion recognition, and culturally nuanced Arabic educational contexts. Recent advances in multimodal LLMs, Arabic-specific transformer models, and emotion detection methodologies offer promising foundations for the development of culturally appropriate systems. However, significant gaps remain in understanding how these technologies can effectively interpret the complex emotional content of Arabic children's literature. The development of Arabic-specific resources has accelerated in recent years, with new datasets like ArPanEmo (11,128 posts, ten emotions)  [25] , LAMA (8,000 tweets, eight Plutchik emotions)  [11] , and emotion lexicons providing valuable resources for training and evaluation. Similarly, transformer models pretrained on massive Arabic corpora, including MARBERT (128 GB, 50% tweets) and QARiB (420M tweets + additional text), demonstrate significant improvements in Arabic language understanding. However, these resources primarily focus on social media content rather than children's literature, leaving a critical gap in age-appropriate and educationally relevant emotional content. Cross-lingual approaches offer another promising direction, with recent research showing that translating English training data into Arabic and fine-tuning Arabic-specific models can achieve up to 90.9% relative effectiveness compared to models trained directly on Arabic data. Such approaches could help address resource scarcity while maintaining cultural nuance. To fully realize the potential of emotion-aware technologies within Arabic instructional settings, advancement in annotation frameworks, culturally responsive prompting techniques, and educational application design is essential. Future research should focus on:\n\n• Developing specialized datasets of Arabic children's literature annotated for emotional content • Creating culturally calibrated emotion models that account for Arabic-specific expressions • Designing and evaluating educational applications that leverage emotional understanding to enhance Arabic literacy development\n\n• Establishing robust evaluation methodologies that incorporate cultural expertise and educational outcomes\n\nIntegrating emotionally intelligent AI demands shifting emphasis from technical excellence toward accommodating cultural and educational nuances, thereby enriching learners' emotional experiences. Given these insights and identified research gaps from existing literature, our methodological approach is explicitly designed to systematically address these challenges and enhance emotion recognition within Arabic children's literature.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Materials And Methods",
      "text": "This study employed a multi-method comparative analysis to evaluate the emotion recognition capabilities of Multimodal Large Language Models (MLLMs) when interpreting illustrations from Arabic children's literature. The methodological framework systematically integrated quantitative performance metrics with qualitative analytical techniques, facilitating rigorous comparison between human annotator judgments and machine-generated interpretations across diverse emotional contexts, prompting strategies, and image characteristics.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Dataset",
      "text": "The visual stimuli were sourced from \"We Love Reading\" ( ) , an organization advancing Arabic literacy through culturally-relevant children's literature  [26] . Seven distinct storybooks were randomly selected, with a minimum of ten illustrations systematically extracted from each, yielding 75 unique image panels. The images were distributed proportionally based on the narrative complexity and emotional diversity within each book, ensuring representative coverage across the collection. Selection criteria prioritized diverse emotional representations, varying degrees of emotional complexity, contextual clarity, and cultural specificity. Images were preserved in their entirety without segmentation to maintain ecological validity in accordance with established principles for multimodal research  [27] .\n\nAll illustrations underwent standardization to ensure compatibility with MLLM vision processing requirements while preserving original visual information, consistent with methodological recommendations for ecologically valid evaluations of multimodal AI systems.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Human Annotation",
      "text": "Four annotators who are native Arabic speakers with full proficiency in Modern Standard Arabic and colloquial variants established ground truth classifications. Annotators received standardized instructions regarding the emotion taxonomy and classification protocols, following established guidelines for cultural annotation tasks  [28] .\n\nThe emotion classification framework employed Plutchik's Wheel of Emotions taxonomy  [8] , and was structured around nine distinct affective Arabic categories: happiness ( ), sadness ( ), anger ( ), fear ( ), surprise ( ), disgust ( ), neutral ( ), anticipation ( ), and trust ( ). This taxonomy was selected for its cultural adaptability within Arabic children's literature contexts  [16] .\n\nIn instances of classificatory divergence, a structured consensus-building procedure was implemented where annotators met to discuss their interpretations. During these consensus meetings, annotators articulated interpretive rationales, examined visual evidence, and reconciled discrepant classifications through collaborative dialogue. This approach ensured ground truth represented informed intersubjective agreement rather than statistical aggregation and fostered deeper consideration of culturally nuanced emotional expressions.",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "Selection And Interaction With Mllms",
      "text": "Two state-of-the-art MLLMs, OpenAI's GPT-4o and Google's Gemini 1.5 Pro, were selected based on their demonstrated performance on contemporary multimodal benchmarks and recognition for advanced multimodal understanding capabilities  [29] . Interactions with both models were conducted programmatically through their respective APIs (OpenAI API v1 and Google Gemini API), with special attention to maintaining consistent prompt formatting and presentation across all experimental conditions. We developed a custom Python framework to automate interactions with both APIs, ensuring methodological consistency and enabling systematic data collection. The API-based approach allowed for precise control over model parameters, systematic response collection, and reproducibility of results. All interactions occurred exclusively in Modern Standard Arabic, consistent with methodological standards for cross-lingual evaluation.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Prompting Techniques",
      "text": "Three distinct prompting paradigms were systematically implemented. In all prompting conditions, models were explicitly instructed in Modern Standard Arabic to select their response from a predefined list comprising Plutchik's eight primary emotions plus neutral to capture images lacking distinct emotional content:\n\n1. Zero-Shot Prompting involved direct instructions to identify the primary emotion from the predefined list without exemplification or methodological guidance. This approach tested models' baseline capabilities without contextual support.\n\n2. Few-Shot Prompting provided three image-emotion pairs exemplifying diverse emotional categories from the predefined list, following few-shot learning principles in contemporary vision-language research. This method examined whether exemplars enhanced recognition accuracy.\n\n3. Chain-of-Thought (CoT) Prompting incorporated explicit direction to \"think step-by-step,\" engaging in sequential reasoning to identify visual cues, integrate observations, and classify emotions from the predefined list  [9] . This approach evaluated whether structured reasoning improved performance on emotionally complex stimuli.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Data Collection And Processing",
      "text": "Responses from both GPT-4o and Gemini 1.5 across all prompting strategies were systematically collected for each image, yielding 450 machine-generated classifications (75 images × 2 models × 3 prompting strategies = 450 total classifications). Our automated data collection pipeline captured and stored model responses in a structured database with verification procedures to ensure accuracy. Each response was programmatically validated for conformity to the expected response format and manually reviewed when necessary.\n\nModel outputs were standardized by aligning variant terms strictly to the predefined taxonomy through explicit mapping procedures. This standardization process included normalizing Arabic text variations, removing diacritics, and resolving synonym usage to ensure consistent emotional categorization. For CoT responses, only the final classifications were extracted for analytical comparison, adhering to standardized evaluation protocols for multimodal emotion recognition  [30] .",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Analysis Methods",
      "text": "We employed both quantitative and qualitative analytical techniques to evaluate model performance:\n\n1. Performance Metrics: Overall performance, per-emotion precision, recall, and F1 scores were calculated for each model and prompting strategy by comparing model predictions against human-annotated ground truth.\n\n2. Error Analysis Framework: Errors were systematically categorized into three taxonomic categories: valence inversions (confusing positive/negative emotions), arousal confusions (misclassifying activation levels), and contextual/cultural misinterpretations, following established emotion recognition evaluation frameworks  [31] .",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Qualitative Case Studies:",
      "text": "Representative examples of successful and unsuccessful classifications were subjected to in-depth qualitative analysis to identify patterns in model reasoning and cultural interpretation.\n\n4. Human-AI Alignment Analysis: Agreement between model predictions and human annotations was assessed using Cohen's Kappa to measure inter-rater reliability, accounting for chance agreement and class imbalance in emotion annotation tasks.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Supplementary Methodological Variations",
      "text": "To further investigate factors influencing emotion recognition performance, we conducted two supplementary analyses using a representative subset (10%) of the original dataset. Images for this analysis were selected to maintain proportional representation of emotional categories and visual complexity levels. For the first variation, we augmented standard prompting by including an image of Plutchik's wheel of emotions directly within the prompt interface, providing models with a visual reference framework of the emotional taxonomy. This approach aimed to assess whether explicit visualization of emotional relationships would improve classification performance.\n\nIn the second variation, we implemented character-focused segmentation, isolating only the main characters in each illustration while removing contextual backgrounds and surrounding elements. This method examined whether focusing models' attention on facial expressions and body language, without potentially distracting environmental cues, would enhance recognition performance. Both variations maintained identical prompting strategies (zero-shot, few-shot, and chain-of-thought) and evaluation procedures to enable direct comparison with our primary methodology. All supplementary analyses were conducted in Modern Standard Arabic with the same predefined list of nine emotion categories.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Results",
      "text": "The experimental analysis yielded a comprehensive dataset of (N=450) distinct emotion predictions (N = 75 images × 2 models × 3 prompting techniques) derived from the evaluation of multimodal large language models in Arabic emotional content recognition. This substantial corpus of predictions facilitated robust statistical assessment across varied experimental conditions. The investigation examined the differential performance of two state-of-the-art multimodal architectures (GPT-4o and Gemini) utilizing three distinct prompting paradigms: zero-shot, few-shot, and chain-of-thought methodologies. The dataset comprised storybook illustrations annotated across nine discrete emotional categories by native Arabic speakers, with a notable distributional asymmetry, as delineated in Table  1 , wherein happiness ( ) constituted 40% of the annotations. This class imbalance is essential to consider when interpreting model performance. The analytical framework systematically addressed four principal dimensions: comparative efficacy of prompting strategies, emotion-specific classification performance, structured analysis of misclassification patterns through valence-arousal theoretical constructs, and contextual performance variations related to narrative positioning and visual ambiguity. The following sections present the quantitative and qualitative findings extracted from this substantial corpus of model predictions.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Prompting Technique Effectiveness",
      "text": "To assess their performance in Arabic emotion recognition, results are presented in terms of overall performance and per-emotion classification performance.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Overall Performance",
      "text": "Macro F1-scores were used to evaluate overall model performance while accounting for class imbalance across the nine emotional categories, as shown in Figure  1 . GPT-4o consistently outperformed Gemini 1.5 Pro across all prompting strategies. GPT-4o achieved macro F1-scores of 57% (zero-shot), 52% (few-shot), and 59% (CoT), while Gemini 1.5 Pro produced macro F1-scores of 43%, 32%, and 37% for the corresponding strategies. Chain-of-thought prompting produced the highest performance for GPT-4o (59%), representing a 2 percentage point improvement over zero-shot. For Gemini 1.5 Pro, zero-shot prompting achieved the highest macro F1-score (43%), with few-shot producing the lowest performance across both model architectures.",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "Performance By Emotional Category",
      "text": "Performance varied substantially across emotional categories, with clear distinctions between high-performing and challenging emotions. As shown in Figure  2 , happiness achieved consistently high F1-scores across all modelprompting combinations, ranging from 69% (GPT-4o zero-shot) to 85% (GPT-4o CoT). Trust demonstrated the highest individual performance with GPT-4o zero-shot achieving 71%, though performance dropped significantly for other configurations. Several emotions proved particularly challenging for both models. Neutral emotion showed consistently poor performance across all configurations, with multiple zero scores for Gemini models and GPT-4o CoT. Anticipation and anger also demonstrated substantial performance gaps between models, with Gemini frequently producing F1-scores below 30% while GPT-4o maintained moderate performance. Notable performance variability emerged within specific emotions across prompting strategies. For instance, surprise ranged from 35% (Gemini CoT) to 67% (GPT-4o few-shot and Gemini few-shot), while disgust showed extreme inconsistency with some configurations achieving 67% and others dropping to 0%. Fear and sadness demonstrated more stable performance patterns, with GPT-4o consistently outperforming Gemini across all prompting approaches.\n\nThe data reveals that model architecture had a stronger influence on emotion recognition performance than prompting strategy, with GPT-4o showing greater stability and fewer complete classification failures compared to Gemini 1.5 Pro.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Systematic Analysis Of Emotion Recognition Errors",
      "text": "Building on the prompting strategy analysis, we conducted a comprehensive examination of misclassification patterns to understand the underlying causes of model errors. We categorized misclassifications into three theoretically-grounded dimensions based on the circumplex model of emotion  [27, 32] :\n\n• Valence Inversions: Errors involving confusion between emotions of opposite polarity. The valence dimension represents the positive or negative nature of emotional states. For example, models may confuse positive emotions like happiness ( ) and trust ( ) with negative emotions such as sadness ( ) and anger ( ).\n\n• Arousal Mismatches: Errors where models correctly identify emotional valence but misclassify arousal intensity. High-arousal emotions such as fear ( ), anger ( ), joy ( ), and surprise ( ) are confused with low-arousal states including sadness ( ), trust ( ), and neutral expressions ( )  [33, 34] .  • Contextual/Cultural Misinterpretations: Cases where models correctly identify both valence and arousal but fail to capture culturally-specific emotional expressions or contextual nuances, resulting in misclassification despite partial dimensional accuracy  [35, 36] .\n\nThe error distribution, shown in Figure  3 , reveals clear patterns in model failures. Valence inversions dominated at 60.7% (122 out of 201), followed by arousal mismatches at 24.4% (49 cases) and contextual/cultural misinterpretations at 14.9% (30 cases). This pronounced imbalance demonstrates systematic rather than random error patterns, with models consistently struggling most with emotional polarity distinctions.\n\nError distribution patterns varied substantially across model-prompting combinations (Figure  4 ). GPT-4o demonstrated the lowest total error counts with zero-shot (25 errors) and CoT (26 errors) configurations, while Gemini few-shot produced the highest error count (40 errors). Valence errors dominated across all configurations, ranging from 48.1% (GPT-4o CoT) to 70.0% (Gemini few-shot). Arousal errors showed greater variability, from 20.0% (GPT-4o zero-shot) to 37.0% (GPT-4o CoT). Contextual/cultural errors remained relatively consistent across conditions, ranging from 10.0% to 20.0% of total errors. GPT-4o configurations showed more balanced error distributions compared to Gemini, which exhibited higher concentrations of valence-related misclassifications across all prompting strategies.\n\nPrecision and recall varied substantially across emotional categories (Figure  5 ). Joy achieved the highest performance with precision of 78% and recall of 80%. Disgust showed high recall (100%) but moderate precision (68%). Lowerperforming emotions included anger (precision = 32%, recall = 58%), anticipation (precision = 35%, recall = 35%), and trust (precision = 40%, recall = 42%). Neutral emotion demonstrated the poorest performance with precision of 30% and recall of 6%.",
      "page_start": 7,
      "page_end": 8
    },
    {
      "section_name": "Qualitative Case Analysis",
      "text": "To complement our quantitative analysis, we examined some representative image cases to understand how visual clarity and contextual factors influence model performance (Figure  6 ).\n\nCase 1: High Agreement on Clear Emotional Cues Panel (a) shows an image where the human annotation was happiness ( ), and all models across all prompting strategies correctly identified this emotion. The image features a child with a prominent smile and bright, cheerful visual elements. This case demonstrates successful emotion recognition when clear visual indicators are present.\n\nCase 2: Ambiguous Visual Cues Leading to Divergent Classifications Panel (b) was human-annotated as neutral ( ), but models disagreed in their classifications. GPT-4o predicted surprise ( ), while Gemini few-shot predicted fear (\n\n). The image shows more subtle facial expressions and less distinct emotional markers compared to Panel (a), resulting in varied model interpretations. ). The Arabic text content appears to describe conflict and an anger emotion, which might have influenced model predictions despite the character's calm visual appearance.\n\nCase 4: Systematic Valence Inversion Panel (d) demonstrates architectural differences in valence processing. Human annotation and all GPT-4o configurations identified happiness ( ), while all Gemini configurations systematically predicted negative emotions: sadness and fear ( , ).",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Human-Ai Alignment",
      "text": "To assess alignment between large language models and human annotators in emotion recognition from children's storybooks, we analyzed agreement rates across six model-prompting combinations compared against human-labeled ground truth using Cohen's Kappa statistics.\n\nResults revealed substantial differences in human-AI alignment across models and prompting techniques (Table  2 ). GPT-4o consistently demonstrated higher alignment with human annotations, achieving Cohen's Kappa values of 0.56 (zero-shot), 0.46 (few-shot), and 0.56 (CoT). These values indicate moderate agreement according to standard interpretation guidelines. Gemini showed notably lower performance with Cohen's Kappa values of 0.37 (zero-shot), 0.31 (few-shot), and 0.34 (CoT), indicating fair agreement levels. Prompting strategies produced different effects across models. For GPT-4o, zero-shot and CoT achieved equally high performance (κ = 0.56), while few-shot showed reduced alignment (κ = 0.46). For Gemini, zero-shot prompting yielded the highest agreement (κ = 0.37), followed by CoT (κ = 0.34) and few-shot (κ = 0.31). These patterns suggest that elaborate prompting strategies do not uniformly enhance human-AI alignment across different model architectures.\n\nThe consistent performance gap between GPT-4o and Gemini across all prompting strategies (0.15-0.22 κ difference) indicates systematic differences in human-AI alignment capabilities. GPT-4o maintained moderate agreement levels across all conditions, while Gemini consistently achieved only fair agreement, suggesting fundamental differences in emotion recognition approaches between the two architectures. We identified a subset of images where all six model-prompting combinations diverged from human-labeled emotions. These cases demonstrated high interpretive complexity, often involving multiple characters with distinct emotional  expressions, embedded symbolic elements, or contextual dependencies tied to previous narrative pages. Examples include images such as Figure  7  that consistently revealed disagreement across all configurations, indicating intrinsic ambiguity in emotional interpretation. Analysis of these discrepancies showed that models were more prone to misclassification when emotion recognition required integrating both textual context and visual semantics. This pattern underscores the challenges faced by current models when processing illustrated multimodal content that requires narrative continuity.\n\nAgreement rates varied substantially across emotional categories. Certain emotions, such as happiness ( ) and surprise (\n\n), achieved more consistent recognition across model-prompting combinations compared to others like anticipation ( ) and neutral ( ). COT prompting showed inconsistent effects on human alignment, sometimes improving agreement in specific cases while reducing it in others (Figure  8 ), indicating that prompting effects vary substantially based on image content and narrative context.",
      "page_start": 10,
      "page_end": 11
    },
    {
      "section_name": "Supplementary Analysis Results",
      "text": "To investigate factors influencing emotion recognition performance, we conducted two supplementary experiments on a representative subset (n=8, 10.7%) of our dataset. For baseline comparison, these same 8 images achieved 37.5% correct classification (3/8) for GPT-4o and 12.5% (1/8) for Gemini across all prompting strategies in the main experiment. In the character-focused segmentation experiment, we isolated individual characters from their narrative contexts. This produced divergent effects across models: GPT-4o's performance dropped to 12.5% (1/8) across all prompting strategies-a 25 percentage point decrease-while exhibiting a strong bias toward \"anticipation\" predictions (37.5% of all responses). Conversely, Gemini's performance improved to 25% (2/8) for zero-shot and few-shot-a 12.5 percentage point increase-though CoT remained at baseline (12.5%). Despite this improvement, Gemini defaulted to high-arousal emotions, particularly \"anger\" (33.3%) and \"surprise\" (29.2%). Notably, positive emotions showed complete recognition failure: both happiness instances and the single trust instance were misclassified by all model configurations, while surprise was correctly identified in 5 out of 6 attempts across all models. The Plutchik's wheel augmentation experiment produced similarly mixed results. GPT-4o's performance decreased to 25% (2/8) across all prompting strategies-a 12.5 percentage point decline from baseline. Gemini showed varied responses: zero-shot maintained baseline performance (12.5%), few-shot dropped to complete failure (0/8), while CoT improved to 25% (2/8)-doubling its baseline performance. Rather than improving classification accuracy, the expanded emotional vocabulary led to overcomplicated predictions, with models introducing 13 unique emotion labels instead of the original 9. GPT-4o exhibited a pattern of over-sophistication, labeling basic sadness as \"contemplation\" ( ) and neutral states as \"love\" ( ), while Gemini showed intensity escalation, replacing surprise with \"astonishment\" (\n\n) and anger with \"contempt\" ( ). These supplementary findings reveal model-specific sensitivities: GPT-4o appears to rely heavily on holistic scene context, while Gemini can benefit from focused attention or explicit taxonomic scaffolding, though at the cost of emotional granularity appropriate for children's literature.",
      "page_start": 12,
      "page_end": 13
    },
    {
      "section_name": "Discussion",
      "text": "",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "Architectural Differences In Multimodal Emotion Processing",
      "text": "The consistent performance advantage of GPT-4o over Gemini across all conditions suggests fundamental differences in how these architectures integrate visual and linguistic emotional information. This gap likely reflects variations in training methodologies, model scale, and multimodal fusion strategies  [29] . GPT-4o's superior stability across prompting strategies indicates more robust internal representations of emotional concepts, potentially due to more sophisticated attention mechanisms or better-calibrated visual encoders  [22] .\n\nThe text-visual interaction effects observed in our qualitative analysis further illustrate these architectural differences. Case 3 revealed that models frequently prioritize Arabic textual content over visual emotional cues, with five out of six configurations predicting anger despite neutral facial expressions when conflict-related text was present. This suggests varying capabilities in balancing multimodal information sources across different model architectures.\n\nThe failure of few-shot prompting to improve performance for either model challenges conventional assumptions about in-context learning for emotion recognition. This suggests that emotion classification may require different cognitive processes than typical few-shot tasks, possibly because emotional interpretation depends more on learned associations than pattern matching from examples  [37] .",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "The Valence Processing Deficit",
      "text": "The overwhelming prevalence of valence errors (60.7%) reveals a critical limitation in current MLLMs' understanding of emotional polarity. This finding suggests that models may process emotions as discrete categories rather than understanding the underlying dimensional structure of affect  [27, 32] . The dominance of valence over arousal errors indicates that models struggle more with the fundamental positive-negative distinction than with intensity judgments. This pattern aligns with psychological theories suggesting that valence processing requires deeper semantic understanding and cultural knowledge than arousal detection  [38] . The models' difficulty with valence may reflect their reliance on surface-level visual features rather than contextual understanding of emotional meaning within cultural frameworks.\n\nOur qualitative analysis reinforces these theoretical insights. Case 4 demonstrates how architectural differences manifest in systematic valence inversion, where GPT-4o correctly identified happiness while all Gemini configurations predicted negative emotions (sadness, fear) for the same image. This pattern exemplifies how valence processing deficits operate consistently within model architectures rather than occurring randomly.",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Cultural And Contextual Challenges",
      "text": "The models' struggle with culturally embedded emotions highlights the limitations of predominantly Western-trained AI systems when applied to Arabic contexts  [39, 40] . The systematic nature of misclassifications suggests that current training paradigms inadequately capture culture-specific emotional expressions and social contexts that influence affective interpretation  [41] .\n\nThe poor performance on neutral emotions reveals a particular challenge for AI systems: distinguishing between the absence of clear emotional signals and the presence of genuinely neutral states  [36] . This difficulty may stem from models' tendency to over-interpret visual information, seeking emotional content even in ambiguous scenarios.",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "Prompting Strategy Implications",
      "text": "The mixed effects of chain-of-thought prompting suggest that elaborate reasoning may not uniformly benefit emotion recognition tasks. For GPT-4o, CoT sometimes led to over-interpretation of narrative context, while for Gemini, it often increased inconsistency. This indicates that emotion recognition may benefit from more intuitive, system-1 type processing rather than deliberative reasoning, reflecting how humans often process emotional information rapidly and automatically. The prompting effects also suggest that different model architectures may require tailored interaction strategies, with standardized prompting approaches potentially suboptimal across diverse AI systems.",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "Theoretical Implications For Affective Ai",
      "text": "Our findings challenge the assumption that larger, more sophisticated language models automatically excel at emotion recognition  [42] . The systematic error patterns suggest that current training approaches may not adequately develop the multimodal integration and cultural understanding necessary for robust emotional AI systems.\n\nThe dominance of valence errors indicates that developing AI systems with better emotional intelligence requires moving beyond surface-level pattern recognition toward deeper understanding of affective meaning and cultural context  [31] . This suggests a need for training paradigms that explicitly model emotional dimensions rather than treating emotions as discrete, isolated categories  [16] .\n\nFor Arabic literacy applications, these findings have direct implications for educational technology deployment. Current MLLMs require careful prompt engineering and potentially specialized fine-tuning before implementation in Arabic educational contexts. The systematic nature of valence errors suggests that emotion-aware educational systems should incorporate bias detection and correction mechanisms, particularly when processing culturally-specific emotional content.",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "Implications Of Contextual And Taxonomic Constraints",
      "text": "Our supplementary analyses reveal fundamental differences in how current MLLMs process emotion in narrative contexts. The character segmentation experiment produced strikingly divergent results: GPT-4o's performance dropped from 37.5% to 12.5% (a 25 percentage point decrease), while Gemini's performance improved from 12.5% to 25% for zero-shot and few-shot approaches. This bidirectional effect suggests contrasting architectural dependencies-GPT-4o appears to rely heavily on holistic scene processing, integrating background elements and interpersonal dynamics into its emotion recognition, while Gemini may suffer from visual complexity and benefit from focused attention on facial features. The complete failure to recognize positive emotions (0% for happiness and trust) across both models, versus preserved surprise recognition (83%), reinforces that culturally-expressed emotions like happiness depend on scenic elements (colors, spatial relationships, shared activities) rather than facial features alone. The Plutchik's wheel experiment similarly revealed model-specific responses to theoretical scaffolding. While GPT-4o's performance declined from 37.5% to 25%, Gemini's CoT actually improved from 12.5% to 25%, though few-shot catastrophically dropped to 0%. This suggests that explicit taxonomic frameworks can stabilize weaker baselines but may interfere with stronger models' learned representations. The models' introduction of sophisticated emotions like \"contemplation\" for basic sadness or \"love\" for neutral states reveals what we term \"theoretical interference\"-where abstract psychological frameworks override practical pattern recognition. Critically, both experiments demonstrate that no single approach optimizes performance across models: GPT-4o requires complete scenes without theoretical scaffolding, while Gemini can benefit from constrained focus or explicit ontological cues, though at the cost of nuanced interpretation.\n\nThese findings challenge universal approaches to emotion recognition in educational AI. Rather than seeking optimal preprocessing or prompting strategies, our results suggest the need for model-adaptive pipelines that leverage each architecture's strengths. For GPT-4o, this means preserving full narrative context; for Gemini, selective attention or taxonomic guidance may improve performance on specific tasks. However, the persistent failure on positive emotions and the inappropriate sophistication introduced by Plutchik's framework underscore that emotion in children's literature serves pedagogical rather than psychological functions. Arabic educational AI development must therefore prioritize culturally-grounded, context-preserving approaches that recognize emotions as narrative devices rather than isolated psychological states.",
      "page_start": 13,
      "page_end": 14
    },
    {
      "section_name": "Limitations",
      "text": "Several methodological constraints should be acknowledged in interpreting our findings. First, we evaluated models at a specific point in time, and the rapid evolution of GPT-4o and Gemini 1.5 means that model capabilities may change with subsequent updates, potentially affecting the long-term relevance of our results. Second, these models exhibit inherent variability and sensitivity to prompt variations that could influence results, even when using consistent formats. Finally, our study lacked comparison with specialized Arabic NLP systems or purpose-built emotion recognition models, which might provide valuable performance baselines beyond general-purpose models. Future evaluations would benefit from including comparisons with specialized Arabic NLP tools  [16]  or emotion recognition systems trained specifically for affective computing tasks.",
      "page_start": 14,
      "page_end": 14
    },
    {
      "section_name": "Dataset Constraints",
      "text": "We analyzed 75 images systematically extracted from seven Arabic storybooks, with a minimum of ten illustrations from each source. A significant limitation was the highly imbalanced distribution of emotional labels in our dataset.",
      "page_start": 14,
      "page_end": 14
    },
    {
      "section_name": "Happiness (",
      "text": ") comprised 40% of all annotations (30 out of 75 images), while emotions such as anger ( ) and disgust ( ) were severely underrepresented at 2.7% (2 images) and 1.3% (1 image) respectively. Although we used macro F1-scores to account for class imbalance in evaluation metrics, the limited examples of rare emotions reduce statistical reliability and generalizability of findings for these categories.\n\nThe restricted sample size and imbalanced class distribution limit the statistical power and generalizability of our findings, particularly for underrepresented emotional categories. Furthermore, our emotion annotation framework relied on Plutchik's taxonomy supplemented with a neutral classification, which may not fully capture the complexity or culturally-specific aspects of emotions depicted in Arabic visual narratives  [8] . Although we employed four native Arabic-speaking annotators and implemented a structured consensus procedure, subjective interpretations in emotionally ambiguous cases cannot be entirely eliminated  [28] .",
      "page_start": 14,
      "page_end": 14
    },
    {
      "section_name": "Future Research Directions",
      "text": "Future work should expand the dataset to include a broader corpus of Arabic storybooks representing diverse visual styles and cultural contexts, with particular emphasis on balancing emotional categories to ensure adequate representation of less common emotions. Incorporating more complex emotional categories beyond Plutchik's framework, such as embarrassment, pride, or culturally-specific emotional concepts, would enhance the validity of the evaluation approach. Applying explainable AI (XAI) techniques  [43]  could reveal reasoning patterns behind model misclassifications, particularly in ambiguous narrative contexts where chain-of-thought prompting demonstrated inconsistent performance. Developing automated annotation and evaluation systems would improve research scalability in Arabic literacy applications.\n\nFrom an educational technology perspective, developing culturally-adaptive prompting strategies specifically for Arabic educational content represents a critical research direction. Such strategies should account for the text-visual interaction effects observed in our analysis and provide frameworks for detecting and mitigating systematic valence biases in educational applications.\n\nAdditionally, fine-tuning multilingual models on culturally-specific Arabic emotional content could significantly improve their sensitivity to subtle emotional cues and cultural nuances. Finally, educational intervention studies examining how these emotion-aware systems impact actual learning outcomes in Arabic literacy development would provide valuable insights for practical implementation in educational settings.",
      "page_start": 14,
      "page_end": 14
    },
    {
      "section_name": "Conclusion",
      "text": "This study provides the first systematic evaluation of multimodal large language models for Arabic emotion recognition in children's storybook illustrations. GPT-4o consistently outperformed Gemini 1.5 across all prompting strategies, achieving macro F1-scores of 57-59% compared to Gemini's 32-43%. Human-AI alignment showed similar patterns, with GPT-4o maintaining moderate agreement (κ = 0.46 -0.56) versus Gemini's fair agreement (κ = 0.31 -0.37). Error analysis revealed systematic patterns rather than random failures, with valence inversions dominating at 60.7% of misclassifications. Both models struggled with culturally nuanced emotions and neutral states, indicating fundamental limitations in processing affective content within Arabic cultural contexts. For educational applications, we recommend zero-shot or chain-of-thought prompting with GPT-4o, while avoiding few-shot approaches that consistently underperformed. Future work should prioritize culturally responsive training data and enhanced valence processing to develop more effective emotionally intelligent educational technologies for Arabic-speaking learners.",
      "page_start": 14,
      "page_end": 15
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: GPT-4o consistently outperformed Gemini 1.5 Pro across all prompting",
      "page": 6
    },
    {
      "caption": "Figure 1: Overall emotion recognition performance measured by macro F1-scores across models and prompting",
      "page": 7
    },
    {
      "caption": "Figure 2: , happiness achieved consistently high F1-scores across all model-",
      "page": 7
    },
    {
      "caption": "Figure 2: Per-emotion F1 scores for GPT-4o and Gemini models across prompting strategies.",
      "page": 8
    },
    {
      "caption": "Figure 3: Distribution of emotion recognition error types across valence, arousal, and contextual/cultural dimensions.",
      "page": 8
    },
    {
      "caption": "Figure 3: , reveals clear patterns in model failures. Valence inversions dominated at",
      "page": 8
    },
    {
      "caption": "Figure 4: ). GPT-4o demonstrated",
      "page": 8
    },
    {
      "caption": "Figure 5: ). Joy achieved the highest performance",
      "page": 8
    },
    {
      "caption": "Figure 4: Distribution of error types across model-prompting configurations. Error counts are categorized as valence,",
      "page": 9
    },
    {
      "caption": "Figure 5: Per-emotion precision and recall scores averaged across all model-prompting combinations.",
      "page": 9
    },
    {
      "caption": "Figure 6: Qualitative case examples showing different model-human agreement patterns. (a) High agreement scenario",
      "page": 10
    },
    {
      "caption": "Figure 7: Multi-character narrative scene illustrating the complexity of emotion recognition when multiple facial",
      "page": 11
    },
    {
      "caption": "Figure 8: Character dialogue scene demonstrating challenges in interpreting emotional context between personified and",
      "page": 11
    },
    {
      "caption": "Figure 7: that consistently revealed disagreement across all configurations, indicating intrinsic",
      "page": 11
    },
    {
      "caption": "Figure 8: ), indicating that prompting effects vary",
      "page": 11
    }
  ],
  "tables": [
    {
      "caption": "Table 1: Distribution of emotion labels in the Storybook dataset",
      "page": 6
    },
    {
      "caption": "Table 2: Cohen’s Kappa values for human-AI agreement across model-prompting combinations.",
      "page": 10
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Early Childhood Teachers as Socializers of Young Children's Emotional Competence",
      "authors": [
        "Susanne Denham",
        "H Hideko",
        "Katherine Bassett",
        "Zinsser"
      ],
      "year": "2012",
      "venue": "Early Childhood Education Journal"
    },
    {
      "citation_id": "2",
      "title": "Emotion comprehension between 3 and 11 years: Developmental periods and hierarchical organization",
      "authors": [
        "Francisco Pons",
        "Paul Harris",
        "Marc De"
      ],
      "year": "2004",
      "venue": "European Journal of Developmental Psychology",
      "doi": "10.1080/17405620344000022"
    },
    {
      "citation_id": "3",
      "title": "Application and theory gaps during the rise of Artificial Intelligence in Education",
      "authors": [
        "Xieling Chen",
        "Haoran Xie",
        "Di Zou",
        "Gwo-Jen Hwang"
      ],
      "year": "2020",
      "venue": "Computers and Education: Artificial Intelligence"
    },
    {
      "citation_id": "4",
      "title": "Flamingo: a visual language model for few-shot learning",
      "authors": [
        "Jean-Baptiste Alayrac",
        "Jeff Donahue",
        "Pauline Luc",
        "Antoine Miech",
        "Iain Barr",
        "Yana Hasson",
        "Karel Lenc",
        "Arthur Mensch",
        "Katie Millicah",
        "Malcolm Reynolds",
        "Roman Ring",
        "Eliza Rutherford",
        "Serkan Cabi",
        "Tengda Han",
        "Zhitao Gong",
        "Sina Samangooei",
        "Marianne Monteiro",
        "Jacob Menick",
        "Sebastian Borgeaud",
        "Andrew Brock",
        "Aida Nematzadeh",
        "Sahand Sharifzadeh",
        "Mikolaj Binkowski",
        "Ricardo Barreira",
        "Oriol Vinyals",
        "Andrew Zisserman",
        "Karen Simonyan"
      ],
      "year": "2022",
      "venue": "Proceedings of the 36th International Conference on Neural Information Processing Systems, NIPS '22"
    },
    {
      "citation_id": "5",
      "title": "The State and Fate of Linguistic Diversity and Inclusion in the NLP World",
      "authors": [
        "Pratik Joshi",
        "Sebastin Santy",
        "Amar Budhiraja",
        "Kalika Bali",
        "Monojit Choudhury"
      ],
      "year": "2020",
      "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "6",
      "title": "Introduction to Arabic Natural Language Processing. Synthesis Lectures on Human Language Technologies",
      "authors": [
        "Y Nizar",
        "Habash"
      ],
      "year": "2010",
      "venue": "Introduction to Arabic Natural Language Processing. Synthesis Lectures on Human Language Technologies"
    },
    {
      "citation_id": "7",
      "title": "Plays Nice With Others: Social-Emotional Learning and Academic Success",
      "authors": [
        "Susanne Denham",
        "Chavaughn Brown"
      ],
      "year": "2010",
      "venue": "Early Education and Development"
    },
    {
      "citation_id": "8",
      "title": "The Nature of Emotions: Human emotions have deep evolutionary roots, a fact that may explain their complexity and provide tools for clinical practice",
      "authors": [
        "Robert Plutchik"
      ],
      "year": "2001",
      "venue": "Publisher: Sigma Xi"
    },
    {
      "citation_id": "9",
      "title": "Chain-of-thought prompting elicits reasoning in large language models",
      "authors": [
        "Jason Wei",
        "Xuezhi Wang",
        "Dale Schuurmans",
        "Maarten Bosma",
        "Brian Ichter",
        "Fei Xia",
        "Ed Chi",
        "V Quoc",
        "Denny Le",
        "Zhou"
      ],
      "year": "2022",
      "venue": "Proceedings of the 36th International Conference on Neural Information Processing Systems, NIPS '22"
    },
    {
      "citation_id": "10",
      "title": "Data Statements for Natural Language Processing: Toward Mitigating System Bias and Enabling Better Science",
      "authors": [
        "Emily Bender",
        "Batya Friedman"
      ],
      "year": "2018",
      "venue": "Transactions of the Association for Computational Linguistics"
    },
    {
      "citation_id": "11",
      "title": "Monitoring People's Emotions and Symptoms from Arabic Tweets during the COVID-19 Pandemic",
      "authors": [
        "Ali Al",
        "Mamdouh Alenezi"
      ],
      "year": "2021",
      "venue": "Information"
    },
    {
      "citation_id": "12",
      "title": "Mind in Society: Development of Higher Psychological Processes",
      "authors": [
        "L Vygotsky"
      ],
      "year": "1978",
      "venue": "Mind in Society: Development of Higher Psychological Processes"
    },
    {
      "citation_id": "13",
      "title": "Intelligence and affectivity : their relationship during child development",
      "authors": [
        "Jean Piaget"
      ],
      "year": "1981",
      "venue": "Intelligence and affectivity : their relationship during child development"
    },
    {
      "citation_id": "14",
      "title": "Evidence for training the ability to read microexpressions of emotion",
      "authors": [
        "David Matsumoto",
        "Sung Hyi",
        "Hwang"
      ],
      "year": "2011",
      "venue": "Motivation and Emotion"
    },
    {
      "citation_id": "15",
      "title": "Casting Multi-label Emotion Classification as Span-prediction",
      "authors": [
        "Hassan Alhuzali",
        "Sophia Ananiadou",
        "Spanemo"
      ],
      "year": "2021",
      "venue": "Proceedings of the 16th Conference of the European Chapter"
    },
    {
      "citation_id": "16",
      "title": "EmoNet: Fine-Grained Emotion Detection with Gated Recurrent Neural Networks",
      "authors": [
        "Muhammad Abdul",
        "Lyle Ungar"
      ],
      "year": "2017",
      "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "17",
      "title": "ARBERT & MARBERT: Deep Bidirectional Transformers for Arabic",
      "authors": [
        "Muhammad Abdul-Mageed",
        "Abdelrahim Elmadany",
        "El Moatez",
        "Billah Nagoudi"
      ],
      "year": "2021",
      "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing"
    },
    {
      "citation_id": "18",
      "title": "Crowdsourcing a Word-Emotion Association Lexicon",
      "authors": [
        "M Saif",
        "Peter Mohammad",
        "Turney"
      ],
      "year": "2013",
      "venue": "Computational Intelligence",
      "doi": "10.1111/j.1467-8640.2012.00460.x"
    },
    {
      "citation_id": "19",
      "title": "Evaluating Arabic Emotion Recognition Task Using ChatGPT Models: A Comparative Analysis between Emotional Stimuli Prompt, Fine-Tuning, and In-Context Learning",
      "authors": [
        "El Habib",
        "Hanane Elfaik"
      ],
      "year": "2024",
      "venue": "Journal of Theoretical and Applied Electronic Commerce Research"
    },
    {
      "citation_id": "20",
      "title": "The development of cross-cultural recognition of vocal emotion during childhood and adolescence",
      "authors": [
        "Georgia Chronaki",
        "Michael Wigelsworth",
        "Marc Pell",
        "Sonja Kotz"
      ],
      "year": "2018",
      "venue": "Scientific Reports"
    },
    {
      "citation_id": "21",
      "title": "ChatGPT for good? On opportunities and challenges of large language models for education",
      "authors": [
        "Enkelejda Kasneci",
        "Kathrin Sessler",
        "Stefan Küchemann",
        "Maria Bannert",
        "Daryna Dementieva",
        "Frank Fischer",
        "Urs Gasser",
        "Georg Groh",
        "Stephan Günnemann",
        "Eyke Hüllermeier",
        "Stephan Krusche",
        "Gitta Kutyniok",
        "Tilman Michaeli",
        "Claudia Nerdel",
        "Jürgen Pfeffer",
        "Oleksandra Poquet",
        "Michael Sailer",
        "Albrecht Schmidt",
        "Tina Seidel",
        "Matthias Stadler",
        "Jochen Weller",
        "Jochen Kuhn",
        "Gjergji Kasneci"
      ],
      "year": "2023",
      "venue": "Learning and Individual Differences"
    },
    {
      "citation_id": "22",
      "title": "A Family of Highly Capable Multimodal Models",
      "authors": [
        "Gemini Team",
        "Gemini"
      ],
      "year": "2023",
      "venue": "A Family of Highly Capable Multimodal Models"
    },
    {
      "citation_id": "23",
      "title": "Somaya Al-Maadeed, and Jihad Mohamad AlJa'am. A study of children emotion and their performance while handwriting Arabic characters using a haptic device",
      "authors": [
        "Jezia Zakraoui",
        "Moutaz Saleh"
      ],
      "year": "2023",
      "venue": "Education and Information Technologies"
    },
    {
      "citation_id": "24",
      "title": "The Impact of Enhancing Students' Social and Emotional Learning: A Meta-Analysis of School-Based Universal Interventions",
      "authors": [
        "Joseph Durlak",
        "Roger Weissberg",
        "Allison Dymnicki",
        "Rebecca Taylor",
        "Kriston Schellinger"
      ],
      "year": "2011",
      "venue": "Child Development",
      "doi": "10.1111/j.1467-8624.2010.01564.x"
    },
    {
      "citation_id": "25",
      "title": "An open-source dataset for arabic fine-grained emotion recognition of online content amid COVID-19 pandemic",
      "authors": [
        "Maha Jarallah"
      ],
      "year": "2023",
      "venue": "Data in Brief"
    },
    {
      "citation_id": "26",
      "title": "We Love Reading, Arabic Children's Literature Collection",
      "year": "2023",
      "venue": "Taghyeer Association"
    },
    {
      "citation_id": "27",
      "title": "A Circumplex Model of Affect",
      "authors": [
        "James Russell"
      ],
      "year": "1980",
      "venue": "Journal of Personality and Social Psychology"
    },
    {
      "citation_id": "28",
      "title": "The Social Impact of Natural Language Processing",
      "authors": [
        "Dirk Hovy",
        "Shannon Spruit"
      ],
      "year": "2016",
      "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "29",
      "title": "BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation",
      "authors": [
        "Junnan Li",
        "Dongxu Li",
        "Caiming Xiong",
        "Steven Hoi"
      ],
      "year": "2022",
      "venue": "BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation"
    },
    {
      "citation_id": "30",
      "title": "DialogueGCN: A Graph Convolutional Neural Network for Emotion Recognition in Conversation",
      "authors": [
        "Deepanway Ghosal",
        "Navonil Majumder",
        "Soujanya Poria",
        "Ni Chhaya",
        "Alexander Gelbukh"
      ],
      "year": "2019",
      "venue": "DialogueGCN: A Graph Convolutional Neural Network for Emotion Recognition in Conversation"
    },
    {
      "citation_id": "31",
      "title": "Understanding Emotions: A Dataset of Tweets to Study Interactions between Affect Categories",
      "authors": [
        "Saif Mohammad",
        "Svetlana Kiritchenko",
        "; Nicoletta Calzolari",
        "Khalid Choukri",
        "Christopher Cieri",
        "Thierry Declerck",
        "Sara Goggi",
        "Koiti Hasida",
        "Hitoshi Isahara",
        "Bente Maegaard",
        "Joseph Mariani",
        "Hélène Mazo"
      ],
      "year": "2018",
      "venue": "Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)"
    },
    {
      "citation_id": "32",
      "title": "The circumplex model of affect: An integrative approach to affective neuroscience, cognitive development, and psychopathology",
      "authors": [
        "Jonathan Posner",
        "James Russell",
        "Bradley Peterson"
      ],
      "year": "2005",
      "venue": "Development and psychopathology"
    },
    {
      "citation_id": "33",
      "title": "Core affect, prototypical emotional episodes, and other things called emotion: dissecting the elephant",
      "authors": [
        "J Russell",
        "L Barrett"
      ],
      "year": "1999",
      "venue": "Journal of Personality and Social Psychology"
    },
    {
      "citation_id": "34",
      "title": "The neurophysiological bases of emotion: An fMRI study of the affective circumplex using emotion-denoting words",
      "authors": [
        "Jonathan Posner",
        "James Russell",
        "Andrew Gerber",
        "Daniel Gorman",
        "Tiziano Colibazzi",
        "Shan Yu",
        "Zhishun Wang",
        "Alayar Kangarlu",
        "Hongtu Zhu",
        "Bradley Peterson"
      ],
      "year": "2008",
      "venue": "Human Brain Mapping"
    },
    {
      "citation_id": "35",
      "title": "Facial expressions of emotion are not culturally universal",
      "authors": [
        "Rachael Jack",
        "G Oliver",
        "Hui Garrod",
        "Roberto Yu",
        "Philippe Caldara",
        "Schyns"
      ],
      "year": "2012",
      "venue": "Proceedings of the National Academy of Sciences"
    },
    {
      "citation_id": "36",
      "title": "Emotional Expressions Reconsidered: Challenges to Inferring Emotion From Human Facial Movements",
      "authors": [
        "Lisa Feldman",
        "Ralph Adolphs",
        "Stacy Marsella",
        "Aleix Martinez",
        "Seth Pollak"
      ],
      "year": "2019",
      "venue": "Psychological Science in the Public Interest"
    },
    {
      "citation_id": "37",
      "title": "A Survey on In-context Learning",
      "authors": [
        "Qingxiu Dong",
        "Lei Li",
        "Damai Dai",
        "Ce Zheng",
        "Jingyuan Ma",
        "Rui Li",
        "Heming Xia",
        "Jingjing Xu",
        "Zhiyong Wu",
        "Baobao Chang",
        "Xu Sun",
        "Lei Li",
        "Zhifang Sui"
      ],
      "year": "2024",
      "venue": "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "38",
      "title": "The Conceptual Act Theory: A Précis",
      "authors": [
        "Lisa Feldman"
      ],
      "year": "2014",
      "venue": "Emotion Review"
    },
    {
      "citation_id": "39",
      "title": "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?",
      "authors": [
        "Emily Bender",
        "Timnit Gebru",
        "Angelina Mcmillan-Major",
        "Shmargaret Shmitchell"
      ],
      "year": "2021",
      "venue": "Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, FAccT '21"
    },
    {
      "citation_id": "40",
      "title": "Language (Technology) is Power: A Critical Survey of \"Bias\" in NLP",
      "authors": [
        "Lin Su",
        "Solon Blodgett",
        "Hal Barocas",
        "Iii Daumé",
        "Hanna Wallach"
      ],
      "year": "2020",
      "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "41",
      "title": "Cultural Similarity's Consequences: A Distance Perspective on Cross-Cultural Differences in Emotion Recognition",
      "authors": [
        "Hillary Anger",
        "Nalini Ambady"
      ],
      "year": "2003",
      "venue": "Journal of Cross-Cultural Psychology"
    },
    {
      "citation_id": "42",
      "title": "Affective computing: (526112012-054)",
      "authors": [
        "Rosalind Picard"
      ],
      "year": "1997",
      "venue": "Affective computing: (526112012-054)"
    },
    {
      "citation_id": "43",
      "title": "Why Should I Trust You?\": Explaining the Predictions of Any Classifier",
      "authors": [
        "Marco Ribeiro",
        "Sameer Singh",
        "Carlos Guestrin"
      ],
      "year": "2016",
      "venue": "Proceedings of the 2016 Conference of the North American Chapter"
    }
  ]
}