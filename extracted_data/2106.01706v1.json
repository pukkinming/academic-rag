{
  "paper_id": "2106.01706v1",
  "title": "Emodnn: Understanding Emotions From Short Texts Through A Deep Neural Network Ensemble",
  "published": "2021-06-03T09:17:34Z",
  "authors": [
    "Sara Kamran",
    "Raziyeh Zall",
    "Mohammad Reza Kangavari",
    "Saeid Hosseini",
    "Sana Rahmani",
    "Wen Hua"
  ],
  "keywords": [
    "Affective Computing",
    "Cognitive Factors",
    "Personality",
    "Emotion recognition",
    "Ensemble learning"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "The latent knowledge in the emotions and the opinions of the individuals that are manifested via social networks are crucial to numerous applications including social management, dynamical processes, and public security. Affective computing, as an interdisciplinary research field, linking artificial intelligence to cognitive inference, is capable to exploit emotion-oriented knowledge from brief contents. The textual contents convey hidden information such as personality and cognition about corresponding authors that can determine both correlations and variations between users. Emotion recognition from brief contents should embrace the contrast between authors where the differences in personality and cognition can be traced within emotional expressions. To tackle this challenge, we devise a framework that, on the one hand, infers latent individual aspects, from brief contents and, on the other hand, presents a novel ensemble classifier equipped with dynamic dropout convnets to extract emotions from textual context. To categorize short text contents, our proposed method conjointly leverages cognitive factors and exploits hidden information. We utilize the outcome vectors in a novel embedding model to foster emotion-pertinent features that are collectively assembled by lexicon inductions. Experimental results show that compared to other competitors, our proposed model can achieve a higher performance in recognizing emotion from noisy contents.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "U NDERSTANDING emotional information from short text content finds important applications in numerous domains: (i) In conversation transcripts in user contents  [1] . (ii) In the political context, to foster the prediction of the ballet results  [2] . (iii) In health, to better recognize the people affected by extreme depressions  [3] [4] (iv) In sales and finance, to enhance the product development  [5]  and predict the market fluctuations  [6] . Nowadays, with the spread of social networks, people share their brief contents conveying latent cues such as personality that can identify the contrast between authors. Given a single short-text s i with corresponding cognitive cues p j , we aim to identify the emotions explaining s i . Compared to comprehensive formal documents, individuals usually tend more to reveal their instant emotions through composing informal social media posts. Accordingly, we can utilize such rich content to exploit real-world emotion-related social communities. However, challenges abound: Challenge 1 (Ignoring Author Latent Information)\n\nNumerous prior works  [7] [8]  [9] [10] identify the emotions from textual contents disregarding the individual differences between authors, while such contrast including personality can affect the way people express their emotions  [11] . As Holtgraves et al.  [12]  report, the personality-based correlations are more likely manifested in the emotionpertinent expressions. Table  1  demonstrates the correlation • S. Kamran, R. Zall, M. R. Kangavari, and S. Rahmani are with School of computer engineering, Iran University of Science and Technology. Email: sara.kamran72@gmail.com, zall razieh@comp.iust.ac.ir, kanagvari@iust.ac.ir, rahmany.sana@gmail.com • S. Hosseini is with the Faculty of Computing and Information Technology, Sohar University, Oman. Email: sahosseini@su.edu.om • W. Hua is with the School of Information Technology and Electrical Engineering, University of Queensland, Australia. E-mail: w.hua@uq.edu.au Here emotion vector comprises the score for each emotion [anger, disgust, etc.] where we use a similar vector to express personality through Extraversion, Openness, etc. The respective binary and floating values in the emotion and personality vectors imply whether the short-text corresponds to each emotion or cognitive factors.\n\nTo investigate how human personality can affect the emotion manifest in expressions, we consume the SemEval dataset  [13]  to set up an observation based on the distribution probabilities of the words. We select the expressions with various emotional intensities that are further pertinent to diverse cognitive factors. As Fig.  1  demonstrates, the distribution probabilities for each emotional word differ in various cognitive factors. Users with high NEU (Neuroticism) have low emotional stability and frequently use distressing words, like terrible. So their short text contents include more emotional words compared to the user of the low NEU weights. Interestingly, users with low EXT (Extraversion) are reluctant to interact with others and tend to express negative emotions such as fear, depression, and  Individuals with a high rate of CON (Conscientiousness) use a greater number of positive emotional words, such as happy, joy, and smile in their contents. From another perspective, people with high AGR (Agreeableness) weights rarely utilize emotional-related words. Therefore, the proposed consensus results reveal how cognitive factors can influence emotional expressions in short-text contents. Since individuals with identical cognitive factors exhibit similar emotions, we leverage the latent aspects of personalities to enhance our ability to detect emotions. Challenge 2 (Noisy Short Text) Short texts include important information but they are brief and error-prone. Hence, it is a tedious task to associate emotion cues with cognitive features.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Challenge 3 (The Scarceness Of Annotated Dataset)",
      "text": "All prevailing datasets have either emotional labels  [14] [13] or cognitive labels  [15] . So, due to the scarceness of the dataset which contains both emotion and cognitive annotations, one of our challenges is to create datasets that are annotated by emotion and cognitive cues. Contributions. While our prior works  [16]   [17]  handle short text contents to detect attributed segments  [18]  and identify concepts, removing the perturbation caused by external knowledge bases, this paper recognizes the emotions through leveraging the cognitive factors from similar brief context. To this end, we utilize cognitive factors of individuals to categorize short texts to feed our novel ensemble classifier. Furthermore, in our proposed framework, we detect the emotion embedding of short texts with the help of an external knowledge-base which is associated with emotion lexicons. Accordingly, we extract multi-channel features in short texts to enrich the short-text inference models. Our contributions are fourfold:\n\n• We develop a framework on emotion recognition through ensemble learning which leverages the cognitive cues to distinguish between short-text authors.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "•",
      "text": "We propose a regression approach for inferring latent cues about short-text authors.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "•",
      "text": "We design a multi-channel feature extraction algorithm based on emotion lexicons and attention mechanisms that fuse various embedding models to retrieve preferable vectors.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "•",
      "text": "We devise a cognitive aware aggregation function to combine the results of different base classifiers in the ensemble model. The rest of our paper is as follows: in Sec. 2, we study the literature; in Sec 3, we provide the problem and our framework; in Sec. 4 and 5, we respectively explain our model and experiments. The paper is concluded in Sec. 6.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Related Work",
      "text": "As briefed in Table  2 , the related work comprises personality prediction and emotion recognition.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Personality Prediction",
      "text": "Personality is a psychological construct and it aims to understand various human behaviors with stable and measurable individual characteristics  [19] . Various studies predict and identify personality traits  [15]  from social networks. The methods for cognitive prediction are of two categories: 1) Machine learning methods; 2) Deep learning models. General machine learning algorithms  [20]  leverage various features  [21]  including linguistic stats such as word count  [22]  and social network attributes like the number of friends to estimate personality traits  [23] . Deep Neural network approaches  [24] [25]  [19] [26] surpass traditional methods. Sun et al.  [25]  combine bidirectional LSTMs (Long Short Term Memory networks) with CNNs (Convolutional Neural Network) to infer structures of texts. Similarly,  [19]  devise AttRCNN structure to understand the semantic features that are amended by the statistical linguistic features. However,  [26]  utilizes essential statistics including Mairesse features, the number of words, and an average length of sentences that are combined within convnets in a hybrid manner. We initially exploit latent personal characteristics by a modified Support Vector Regression (SVR) model and subsequently adopt CNN convents to extract feeling sentiments.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Emotion Recognition",
      "text": "Affective Computing  [41]  as an emerged field of research has attracted significant attention. Because it results in systems that can automatically recognize human emotions and eminently influence decision-making procedures. Emotions can be detected by heuristic, machine learning, and deep learning approaches  [42] . The lexicon-based heuristic approaches  [27] [28] find keywords in textual contents and assign emotion labels based on lexicon tags, referenced from knowledge-base tools such as NRC-EIL  [27]  and De-pecheMood  [28] . Machine learning models  [8] [33] not only consider lexicons but also extract effective textual features from input corpus, concluded by decision rules to recognize emotions based on the trained explicit labels. The ML models include Naïve Bayes (NB)  [8] , Random Forest (RF)  [34] , Support Vector Machine (SVM)  [33][8] [29]  [34] , Logistic Regression (LR)  [32] , and some trending deep learning methods  [10][39] . The Naïve Bayes classifiers  [8]  efficiently utilize various word classes to perform prediction but result in lower accuracies. Random forests  [34]  fuse a combination of treebased predictors where each tree depends on the values of a random vector, sampled independently and with the same distribution from the trees in the forest. Random forest approaches are more efficient than the SVM methods  [8] [29] but empirically gain less accuracy. Both Esmin  [7]  and Xu  [9]  et al. use hierarchical classification techniques to perceive emotion cues. Such techniques integrate three levels: neutrality versus emotionality, sentiment analysis, and emotion recognition. Utilizing domain-specific emotion lexicons, a combination of n-grams, and part of speech (pos) tagging features can foster the classification performance of the SVM modules  [30] . On the contrary, the intelligible rulebased methods share the goal of finding regularities in data, expressing the form of If-Else rules  [31] . In emotion detection, the rule-based models infer emotion-related events that undertake the cause  [31] .\n\nDeep neural network models  [35]",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Problem Statement",
      "text": "In this section, we elucidate preliminary concepts, problem statement for author linking, and our proposed framework.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Preliminary",
      "text": "denotes the cognitive factor scores for the short text s i ∈ S where f i,j is a cognitive score for j th factor p j ∈ P . F si represents short text s i in cognitive space with q dimension according to P .",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Problem Definition",
      "text": "Problem 1. (identifying cognitive factors) Given a message s i our goal is to retrieve the cognitive vector F si for s i . Problem 2. (extracting multi-channel features) Given the set of short texts pertinent to a cognitive category c i , our goal is to extract the set of features through tracking the emotional cues. Problem 3. (recognizing emotion through cognitive factors) Given the message s i and its associated cognitive vector F si , our goal is to construct the emotion vector V si .",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Fig. 2: Framework",
      "text": "",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Framework Overview",
      "text": "The problem of emotion recognition through cognitive cues in brief contents includes two steps: (1) to extract the categories of short text messages via inclusive cognitive cues. (  2 ) to learn an effective ensemble classifier to identify emotions by leveraging the extracted categories. Fig.  2  illustrates our proposed framework.\n\nIn the offline part, since a dataset enclosed with both emotion and cognitive annotations is scarce, as a prerequisite to emotion recognition, we initially augment the cognitive annotations within the dataset. To this end, we adopt the SVR to retrieve the cognitive vectors. Considering the impact of each cognitive factor on emotion-related expressions, we then apply categorization on textual contents. As a result, each category can include highly-correlated short texts aligned with the associated cognitive vector. Consequently, we extract the set of features by tracking the emotional cues in the short texts of each cognitive category. We then apply the emotion lexicons together with word vectors to learn each of the corresponding base classifiers(e.g., extraversion).\n\nTo continue, given the short text contents enclosed with emotion annotations, we induce the ensemble classifier to convey emotion recognition. We can aggregate the base classifiers into an ensemble to convey helpful information according to the cognitive similarities. In the online part, we aim to predict emotion labels for the input short text.\n\nTo accomplish the task, we firstly extract cognitive vectors from the input. We then select a set of relevant classifiers based on the input cognitive features. Finally, we aggregate various outputs from classifiers to make the final prediction.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Methodology",
      "text": "",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Offline Phase",
      "text": "",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Inferring Cognitive Factors",
      "text": "For investigating the influence of cognitive factors on emotion recognition, we need a dataset that includes both emotional and cognitive annotations. We assume that our dataset includes emotion annotations, as ground truth. Hence, we aim to compensate the cognitive annotations.\n\nTo this end, we can leverage another source dataset with cognitive features to annotate our target dataset. We use a cognitive annotation dataset D P = {s i , F si }(i = 1, . . . , n) to infer cognitive vectors of short texts in emotional annotation dataset D E = {s i , V si }(i = 1, . . . , m) where P and E denote the source and target datasets. Here m and n denote the number of short texts in source and target datasets. To identify cognitive scores, we train a diverse model for each cognitive factor q on D P to infer the proportionate cognitive space of D E . In each model, we adopt the effective Support Vector estimation tool  [43]  to designate a decision surface to maximize the distance between different classes. In the source dataset, there are a set of points (s i , f si,j ) where x i is the feature vector extracted from s i and f si,j ∈ F si is the target value for each model j ∈ [1, ..., q]. Eq. 1 demonstrates the objective function.\n\nWhere w is the slope of the line, and b is the intercept. Our aim is to use SVR to find a surface that minimizes the prediction error in optimization function, Eq. 2. In regression, a soft-margin ( ) approach is employed similar to SVM. We add slack variables ξ i + ξ * i to guard against outliers.\n\nHere ξ and ξ * are the distance of data points that lie outside the margin.\n\nOur optimization goal is to achieve the conditions in Eq. 3 that we solve with finding the Lagrangian in Eq. 4.\n\nThe Lagrange multipliers, denoted by λ, λ * , α, α * , are nonnegative real numbers. The minimum of Eq. 4 is found by taking its partial derivatives with respect to the variables and then equating to zero. We also obtain the values of w and b through Eq. 5 and Eq. 6.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Cognitive Categorization",
      "text": "Given emotion annotated dataset D E , we aim to acquire a set of cognitive categories, denoted by C. As elucidated in Section 1, authors with different cognitive cues express their emotions using various vocabs in emotion. Given such an intuition and based on the cognitive vector F si of the set P , we can map each short text s i ∈ D E to q dimensions. Subsequently, we can obtain the set C of cognitive categories from the emotion annotation dataset D E by splitting the space into two subspaces. Where we can define the lower and upper subspaces for each cognitive factor p j ∈ P . Accordingly, the short texts with lower and higher levels of a cognitive factor, p j , will be respectively appended to the pertinent categories of c 2j-1 , c 2j . Hence, clustering  [44]  and border classifiers, like SVM  [8] , cannot cohesively distinguish the categories. To this end, we diversely adopt an entropy-based categorizing method to acquire partitioning value in each cognitive factor to obtain lower and higher bounds. To get the partitioning threshold vector a = {α j |j ∈ [1, ..., q]}, we presumed that the source dataset incorporates the cognitive factor classes. So we employed the entropy approach to attain the partition value of α j for each cognitive factor p j that minimized the impurity in the resultant categories.\n\nFor each given cognitive factor p j , we considered a set of partitioning points in a similar range as p j in D P and evaluated them based on entropy to find the best partitioning point, α j . In this regard, based on each partitioning point T , we splitted the D P into two subsets of d 1 and d 2 and computed the entropy of resulting subsets accordingly to input cognitive class of p j . We determined two classes k = {k 1 , k 2 } for each cognitive factor p j ∈ P where entropy of d i (i = {1, 2}) was defined as Eq. 7.\n\nHere P (k m , d i ) is the probability of short texts in d i pertaining class k m . Given input dataset D P , cognitive factor p j , and partitioning point T , Eq. 8 computes the class information entropy E(p j , T, D P ) for the splits made by T . Here α j is the partitioning criterion in Eq. 9.\n\nWe then used α j in Eq. 10 to obtain cognitive categories.\n\nConsequently, the pair of sets (c 2j-1 ,c 2j ) formed by α j on each parameter p j can constitute the short texts with a low and high order of cognitive factor. We now elucidate various properties for each set of cognitive categories (C = (c 1 , ..., c n )): Lemma 1. a cognitive category c i can not be empty (∀i ∈ [1, ..., 2q] :\n\nProof. Since the max. and min. values for each cognitive factor i do not equate (min(D E i ) = max(D E i )) and the splitter parameter α i is between min. and max. values (min(D E i ) < α i < max(D E i )) so we can justify that c i can not be empty (Eq. 11):\n\nLemma 2. The aggregated data for all cognitive categories forms the original dataset\n\nProof. Suppose we have two categories of c 2j ⊆ D E and c 2j-1 ⊆ D E where we assign the short text s k ∈ D E to either c 2j or c 2j-1 . So we can justify the rules in Eq. 12 for the cognitive factor j in s k :\n\nLemma 3. The intersection of two cognitive categories for the same parameter (e.g. c 2j and c 2j-1 ) partitioned by the specified threshold α j will result in null. As stated in Eq. 13, the intersection of the same pair (c 2j ,c 2j-1 ) with other cognitive categories c i can be non-empty.\n\nProof. Given cognitive factor j, each short text can be associated either with low c 2j-1 or high c 2j status, resulting in c 2j-1 ∩ c 2j = ∅. However, given all q cognitive factors for each short text with q cognitive categories every pair c 2j-1 and c i can share common textual contents. Lemma 4. Short texts in a cognitive category c m have a similar feature according to their pertinent cognitive factor m+1\n\n> α m . According to Eq. 10:\n\n1.\n\nTherefore, the assumption s j / ∈ c m with condition f j, m+1 2 > α m contradicts with our initial hypothesis. Therefore, if f i, m+1 2 > α m and f j, m+1 2 > α m , s i ∈ c m , s j will be in the same cognitive category(c m ). In this way, condition\n\n≤ α m can also be proved.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Multi-Channel Features",
      "text": "The embedding models can capture syntactic and semantic regularities within the corpus to represent each word with a real-valued vector. GloVe  [17] [45]  [16]  uses word pair co-occurrences, and CBOW  [46]  predicts a word given its context. However, the resultant word vectors fail to acknowledge emotion cues in short text contents. Let τ be the corpus containing the set of words associated with textual contents of an emotion annotated dataset, D E . We can then tokenize each short text s i into a set of words (s i = {o 1 , o 2 , ..., o |si| }) where o j ∈ τ (j ∈ {1, . . . , |s i |}) is the j th word in short text s i . We can represent the contextwise word vector corresponding to the j th by utilizing the embedding function Ω : τ → R d in Eq. 15.\n\nHere, O context j is the context-wise vector for the given word j. Let L = {l ι |ι ∈ [1, ..., t]} be the set and t as the number of emotion lexicons where DepecheMood  [28]  and NRC-EIL  [27]  infer the lexical vectors to designate each word with continuous scores for emotional or polarized orientations. Consequently, we can propose a hybrid vectorization process to include emotional aspects of the words. To this end, we assume that O emotion j = [o j,i |i ∈ [1, ..., k]] is an emotionwise word vector associated to j th word. Here, k denotes the number of basic emotions and o j,i is the i th emotion scores for the given word o j .\n\nAs Eq. 16 formalizes, the function Ψ : τ → R k receives the input word o j and retrieves the emotion scores through the lexicon knowledge-base l ι where t denotes the number of emotion lexicons and gives the concatenation of resultant vectors. We can support | O emotion j | = t ι=1 Φ(l ι ) where Φ specifies the number of emotions leveraged in l ι . Moreover, we adopt NLP processes such as POS tagging to take advantage of structural elements and syntactic patterns. Accordingly, as Eq. 17 elucidates, we can designate each short text with an alternative representation, POS tagbased feature vectors.\n\nHere, : τ → R µ is the function that receives a word o j as input and returns the vector of the size µ with POS tags. In a nutshell, the attention-based mechanisms  [47]  aim to signify the words with higher impacts to foster classification procedures. As Fig.  3  shows, we adopt an attention module to nominate prominent focus words. Given each short text s i , we can use the weighted sum of word vectors to compute the corresponding attention vector, O attention j (Eq.  18) .\n\nAs verbalized in Eq. 19, α j,y (α j,y 0) is the attention weight subjected to y α j,y = 1 where \".\" denotes the element-wise multiplication.\n\nThe score(., .) function quantifies the degree of relevance between the j th and y th words, and ϕ is the similarity function that determines the correlation ratio between the word pairs according to the pertinent emotion-wise vectors. Eq. 20 explains how the score(., .) computes the relevance between the given pair of o j and o y .\n\nWe randomly initialize the weights W a and W z and jointly learn them during the training process. The higher sentiment relevance between the given words in emotion classification, the larger inner-weights will be. To this end, we employ the simple but effective cosine similarity to calculate the weights between vectors, ϕ( O emotion j , O emotion y ).\n\nTo attain the multichannel features, we utilize both lexicon resources and POS tags. To collectively form the multichannel features, on the one hand, we concatenate the emotionwise and context-wise word vectors, and on the other hand, we combine the context-wise and POS-wise vector. Eq. 21 formulates how one can merge various vectors, including emotion-wise, context-wise, and attention vectors.\n\nWhere the ⊗ is the vector concatenation operator, we can utilize Eq. 22 to obtain M emo si ∈ R |si|×(2d+ t ι=1 Φ(lι)) as the matrix of vectors for s i where |s i | is the number of words.\n\nWe combine three vectors of POS, context, and attention in Eq. 23 to further improve the accuracy.\n\nAlso, Eq. 24 computes M pos si ∈ R |si|×(2d+µ) as the vector matrix for s i .\n\nGiven s i ∈ S comprising various number of vocabs, pertinent vectors of M pos si and M emo si will follow |s i |. Hence, we adopt the zero padding and use Γ = max ∀i=1,...,m (|s i |) as the fixed length for M si to unify short-text matrices.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Cognitive Ensemble",
      "text": "Given the dataset D E = {(s i , V si )|i = [1, ..., m]} with m short texts, V si ∈ {0, 1} k can represent a binary emotion vector for s i . Here, k denotes the number of emotion class labels. Moreover, where the j th label of emotion is not null in V Si , we assign v i,j with 1 or zero otherwise. Since s i can be concurrently involved with diverse emotions, neither singlelabel classification models  [48]  nor regression algorithms  [43]  can model such multiplexity  [35] . Hence, we employ multi-label classification by appointing each emotion label with a single task and adopting a parallel multi-task learner. An ensemble of convnet classifiers  [48]  can better learn the emotion features where we designate each cognitive category c i to a distinctive multi-task classifier h ci . Finally, we aggregate the output of trained classifiers in H (Fig.  3 ).\n\nGiven the feature learning component, we appoint the width of the filters by the dimension of word vectors, denoted by 2d + t ι=1 Φ(l ι ). We further alter the height to acquire various sets for the encoded feature vectors. To this end, we obtain the encoded set of feature vectors Q emo = {Q 1 , Q 2 , ..., Q ϕ } for the embedding matrix M emo si , by ϕ various window sizes, each denoted by δ r ∈ N. Here Q r = [q r,j |q r,j ∈ R and j ∈ [1, ..., |s i | + δ r -1]] represents the feature vectors for the r th window, Eq. 25.\n\nq r,j = φ(M emo s i {j:j+δr -1} .Wr + b)\n\nW r ∈ R δr×(2d+ t ι=1 Φ(lι)) is the filter matrix, b ∈ R δr * 1 is a bias vector, and M emo si{j:j+δr-1} is the horizontal fragment for M emo si of the size δ r . The max layer consumes output feature vectors Q emo to exploit the final encoded vector Qemo (Eq. 26). (qr,j)] (26)\n\nAs formalized in Eq. 27, we then use Qemo and Qpos in embedding matrix M pos si to get the max layer output.\n\nSuccessively, the emotion learning component consumes Q, where we collectively utilize the inter-connected layers to address the perceptual multi-label classification problem and segregate tasks in the output layer. Let l ∈ {1, .., L} be the layer index of the network in the fully connected component. Given L as the number of hidden layers, the index zero can determine the input for the emotion learning module. Fig.  4  shows the schema of a neuron in the hidden layer l. Where x 0 equates to Q, x l can specify the load for l.\n\nSimilarly, w l and z l can respectively indicate the weighting matrix and the output of layer l, to be used in the next layer, l + 1. Eq. 28 attains the input of the k th neuron in l.\n\nHere, x l k and b l k can indicate the input and the bias values for the k th neuron in l. Where the output of the i th neuron in l -1 is z l-1 i , w l-1 ik associates the weights of the i th neuron in l -1 to the k th neuron in l. Eq. 29 neutralizes the effect of non-essential features to avoid overfitting. As explained in Sec.4.1.5, the function ℘(w l-1 ik ) returns the weights between a pair of neurons. So as shown in Fig.  4 , we can pass x l k through activation function f , formalized in Eq. 30, to retrieve the intermediate output z l k .\n\nFig.  4 : Input and output of a neroun at hidden layer l\n\nThe output layer constitutes k output units, each dedicated to a single task. The output of the last layer in hidden layers, as the common feature representation learned for the k tasks, can be fed to the output layer. The constraint can be accommodated by Eq. 31, computing the network prediction output for the j th emotion, denoted by vj,i ∈ [0, 1].\n\nTo reduce the error rate, we use the back-propagation algorithm. We then employ a modified binary cross-entropy to compute the joint loss function by the predicted labels.\n\nHere vj,i is the output of the prediction network, v j,i denotes the ground-truth for e i ∈ E, associated with the short text with index j. Moreover, k and m respectively count the numbers of emotion labels and short texts. We update the weights and bias by leveraging the loss function (Eq. 33).\n\nHere, w(t) and w(t + 1) are current weights and new weights. To compute ∆w(t), we use Adam optimizer  [49]  that benefits both from AdaGrad and RMSProp.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Algorithm 1 General Dropconnect",
      "text": "Input: rate, w Output:\n\nif not r in l then   [50]  is the most credible regularization approach to revoke the overfitting issue. However, resolving the tension between bias and variance is not a trivial task.\n\nTo this end, the dropout approaches like DropConnect  [51]  Fig.  3 : Base classifier architecture eliminate the arbitrary weights and ignores the selected nodes in the connected layer.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Algorithm 2 None Significant Weight Reduction",
      "text": "Input: w, α, β, λ Output: The DropConnect algorithm (Alg. 1) turns out to be Naïve in the elimination process. Because it arbitrarily zeros out the selected weights. From another perspective, even the fixed dropout rate in DropConnect can reduce the model expressiveness and increase manual tuning requirements. Hence, we must initially infer the statistical cues from the embedding weights and then adjust the dropout rate consciously. To this end, we enhance the flexibility by retrieving the dropout rate based on the weights drawn from a dataspecific uniform distribution.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Fig. 5: Random Dropout Versus Weight Regularization",
      "text": "In a tractable approach, we can refer to each weight in the bell curve to initialize the elimination procedure empirically. In other words, as depicted in Fig.  5 , we can instantiate a weight matrix to preserve the value of the specified cell, removing or reducing the value in selected cells to adjust the activation process of the neurons. Here we can reduce the value of the given point in the matrix according to trilateral coefficients. As implemented in algorithm 2, we propose an efficient dropout technique to alter imperceptive arbitrary regularization with a distribution-aware model. We multiply the outputs of neurons, highlighted in Eq. 29, by the justified weights based on coefficients to acquire ẃ new weights. Given the neuron inner weights, we specify the drop-rate using dataset-oriented parameters, the standard deviation and the mean, denoted by µ and σ. As shown in Fig.  6 , the weights are of three categories: least (λ), minor (β), and common (α). Due to the subtle connection between the significance of the neurons and the dropout, we sufficiently reduce the weights for the least and minor sections in the curve. This not only leads to a faster convergence rate but also reduces the activation weights that cause overfitting. Similarly, we relatively increase the significance of weights in the minor and common regions, coefficients of µ and σ.\n\nThe changes make our model more mature through subsequent epochs, avoiding the neuron outputs to excessively rely on the least and minor weights. Finally, the model will utilize high-impact weights from the common section.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Online Phase",
      "text": "In the online phase, given the cognitive vector F sq of the input short text s q , the proposed method approximates the emotion vector, comprising two tasks: Detecting the cognitive factors and Estimating the emotions.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Cognitive Factors Detection",
      "text": "Social media supply our propositional datasets. Hence, our framework needs to diligently handle millions of short text contents in the Online phase. To meet efficacy requirements, we train the model in Sec. 4.1.1 infrequently. Eq. 34 can attain the cognitive vector F sq of the input query s q .\n\nFs q = m(sq) (34)",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Cognitive Aware Aggregation Method",
      "text": "In this step, given the cognitive vector corresponding to the input short-text query, we firstly select a set of relevant base classifiers to perform inference as parts of the same whole. Algorithm 3 exemplifies how we collectively select the base classifiers and combine them accordingly.\n\nIn algorithm 3, we firstly extract multi-channel features out of the input query s q using the method in Sec. 4.1.3. Given cognitive vector F sq , we can select either of the base classifiers, h 2i or h 2i-1 . To this end, we compare each element f sq,i ∈ F sq to the splitter parameter α i that divides the short text messages into various categories of low and high. By designating the whole corpus to the multi-task baseclassifier h q+1 , we can disregard the cognitive factors in learning. We can subsequently predict the emotion vectors corresponding to s q through applying the selected baseclassifiers. This results in the consensus matrix A where each element A i,j represents the predicted class by the base classifier j for an emotion i. Each column j depicts the binary opinion of model j about each of emotions in V sq .",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Algorithm 3 Cognitive Aware Aggregation Method",
      "text": "Input: H, αj(j ∈ [1, ..., q]), Fs q Output: Vs q 1: M emo s i , M pos s i = F eatureExtraction(sq) 2: for i in [1, ..., q] do 3:\n\nif fs q ,i < αi then 4:\n\nelse 6:\n\nend if 8: end for 9: A:,q+1 = hq+1(M emo s i , M pos s i ) 10: Vs q = aggregation(A) 11: return Vs q Consequently, we combine the base classifiers to compute the binary values from the given emotion classes, resulting in better approximation and improving the overall performance  [52] . To continue, we adopt the simple but effective majority voting method  [53]  to anticipate the outcomes. Given the short text query s q , Eq. 35 formalizes our approach in the prediction of various sentiments.\n\nEq. 36 shows, A j,t is the prediction of the base classifier t using the indicator function g(y, c).",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Experiment",
      "text": "We conducted extensive experiments on multiple datasets  [13] [15] to compare our proposed unified framework to other novel approaches in emotion detection. Taking advantage of various Python libraries and interfaces for neural networks, we ran the experiments on a server with a 4.20 GHz Intel Core i7-7700K CPU and 64GB of RAM. The codes are available to download 1 .",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Data",
      "text": "We used three datasets to examine our method in detecting personality and emotions from brief contents.\n\n-M yP ersonality  [15] : The MyPersonality dataset, denoted by D P , predicts the cognitive labels for our target emotion dataset  [13]  and comprises the cues for extraversion, agreeableness, conscientiousness, and neuroticism. We eliminate the effect of openness due to minor significance.\n\n-SemEval2018  [13] : This dataset (D E ) is annotated by 11 emotion tags. Like Ekman's standard  [54] , we include fear, anger, joy, disgust, and sadness.\n\n1. https://sites.google.com/view/EmoDNN -W ASSA -2017  [14] : is the destination dataset, denoted by D E , and includes fear, joy, sadness, and anger emotions. We utilize this emotion annotated dataset to evaluate the performance of our proposed framework in multi-class labeling. We enclose the statistics pertaining MyPersonality and SemEval2018 in Tables  3  and 4 , respectively.     We can calculate the metrics of Accuracy, Precision, Recall, and F-measure using TP, FP, TN, and FN. Accordingly, we can distinguish the best performance by F-measure while we apply 10-fold crossvalidation in every evaluation process.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Baselines",
      "text": "We employ the benchmark in Sec. 5.2 to examine the performance of the rival methods in emotion recognition:\n\n• U unison: This baseline  [10]  leverages a variety of deep learning modules, such as word and characterbased RNN and CNN, to improve traditional classifiers including BOW and latent semantic indexing.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "•",
      "text": "Senti HC : This model is a hierarchical classification scheme that comprises three levels in the learning process: neutrality(neutrality versus emotionality), polarity, and emotions(five basic emotions)  [7] .\n\n• SV M -Behavior: Similar to  [8] , it combines unigrams and emotion lexicons and uses SVM-Behavior to classify text contents according to emotion cues.\n\n• lexiconbased: Instead of word embedding  [28] , this model is performed by emotion lexicon.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "•",
      "text": "EmoDN N SV M : This model is based on our proposed categorization method, but the learning component employs an SVM classifier on unigrams.\n\n• EmoDN N wd : This method replaces multichannel feature learning with text embedding  [17][45] .\n\n• EmoDN N : Our proposed framework in Sec. 3.3.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Effectiveness",
      "text": "",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Impact Of Learning Parameters On Emotion Recognition",
      "text": "Given the importance of the batch size is in the dynamics of deep learning algorithms, we designate this section to measure the accuracy for each given emotion where the batch size varies. Table  5  shows where the batch size varies the accuracy fluctuates up to 5% with minimum and maximum for Disgust and Joy emotions. As a result, we select the best value of 128 tweets for the batch size in our method to maximize the performance. Similarly, we have attained the best batch size for other rivals. Similarly, Table  6  investigates the impact of the number of epochs on the accuracy. Excluding the fear and sadness emotions, where the epoch is set to 50, we gain the best effectiveness. Furthermore, we need to evaluate the embedding module. Hence, Table  7  reports the accuracy for various embedding dimensions where we opt for the value of 200 to get the best overall performance. In retrospect, the lower dimensions can better adjust to fewer data, like for fear and sadness. Because the higher the dimension in low sampling, the bigger the data sparsity will be.     We employ the benchmark (Sec. 5.2) to compare the rivals (Section 5.3) in inferring the emotions from brief contents. We observe in Fig.  8  that the performance of all the methods is more than 40% which is even better for the neural network models. However, both versions of our proposed approach, including EmoDN N SV M and EmoDN N wd , turn out to be the best classifiers with an improvement of up to 6.6% versus the best performing competitor, Unison.\n\nFrom another perspective, lack of training procedure justifies why the lexicon-based methods attain the lowest accuracy. Even though we integrated our framework with shallow machine learning methods, e.g., SVM, the modified solution was still capable of overcome other baselines, where applying deep learning modules assured better accuracy. To prevent overfitting, we introduced a new improved dropout mechanism to foster the classification task, with further improvement of 1% compared to the arbitrary dropout. We also adopted the values 1.5, 1, and 0, for α,β, and λ coefficients and utilized a modified emotionaware embedding approach instead of a pre-trained vector module, improving the accuracy by up to 1.07%.  Aiming to test out-of-samples in various folds, we study how the accuracy of our proposed method fluctuates in different emotions. We observe (Fig.  9 ) that fear and disgust  Where the highest prediction performance is for Fear and Sadness is the least, 68.5% of the correct labels. Evidently, the sadness is mostly misclassified as fear in more than 18% of the cases where the least incorrect labels for Joy is 5.7%. We note that it is almost impossible to predict Fear or Anger by the joy emotion, 0.0%.",
      "page_start": 9,
      "page_end": 10
    },
    {
      "section_name": "Efficiency",
      "text": "",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Computational Complexity Analysis",
      "text": "Our proposed framework is useful in many real-time applications. Emotion recognition from social contents can better explain the opinion of a community about a product. Also, the recommendation systems can benefit from emotion weights to improve final suggestions. Many applications need to process millions of brief contents that make the efficiency of the emotion-aware inference systems critical.\n\nHence, we examine the time requirement of our framework. Our proposed framework comprises offline and online components, where the latter is more complex than the former.\n\nIn retrospect, we can calculate the complexity for the offline section by aggregating the times of including components. Given m as the number for training samples, the complexity for the SVR-based module to infer the cognitive factors will be O(m 3 ). The complexity pertaining to two other components, cognitive categorization, and multi-channel feature extraction can be respectively computed as O(m) and O(m.Γ), with Γ denoting the number of words in each training samples. Let l and k be the respective index and the number of convolutional layers. In that case, the expected time for our network to run each category will thus yield in O(( k l=1 n l-1 .|w l | 2 .n l .Q 2 l ).m.e)  [55] . Where n l and n l-1 will respectively represent the number of filters and input channels for the l th layer, |w l | can signify the filter length, Q l , the output feature spatial size, and e, the number of epochs. Correspondingly, the time complexity for the cognitive ensemble can be aggregated by all cognitive categories, verbalized as O(2q.( k l=1 n l-1 .|w l | 2 .n l .Q 2 l ).m.e). Also, We designate q with 5 as the number of cognitive cues that as a small constant can be dismissed in time function. Where the time complexity applies to both training and testing times, though with a different scale, the weights can differ in the attention feature vector and the canonical layers of the emotion recognition network. Suppose α, γ, and β are constant multipliers. Hence, Eq. 37 can formalize the overall time complexity of our framework. However, we further need to efficiently infer millions of brief messages in the online phase. Depending on the network structure, since the time complexity of the online section is polynomial, our model can satisfy the efficacy requirements for real-time processing. The time complexity of the online section to exploit emotions from a single short text is represented by O( k l=1 n l-1 .|w l | 2 .n l .Q 2 l ).",
      "page_start": 10,
      "page_end": 11
    },
    {
      "section_name": "Conclusion",
      "text": "Our proposed unified framework in this paper leverages individual cognitive cues to recognize emotions from short text contents. Most previous efforts on emotion recognition disregard user-specific characteristics. To fill the gap, we firstly categorize short texts according to the cognitive cues. Subsequently, we then utilize the emotion lexicons alongside embedding models to obtain the emotion-aware short text vectors. Consequently, we learn corresponding base classifiers and employ a novel ensemble learning approach to aggregate the classification outputs. The results from extensive experiments on real-world datasets confirm the superiority of our proposed framework over state-of-the-art rivals in emotion recognition. However, we need to integrate transfer learning to make inner ensemble classifiers better collaborate. Moreover, we will have to empirically study the effect of various distributions on the proposed dropout module. We leave these tasks for future work.",
      "page_start": 12,
      "page_end": 12
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Emotion words connect to cognitive factors",
      "page": 1
    },
    {
      "caption": "Figure 1: demonstrates, the",
      "page": 1
    },
    {
      "caption": "Figure 2: Framework",
      "page": 3
    },
    {
      "caption": "Figure 2: illustrates our",
      "page": 3
    },
    {
      "caption": "Figure 3: shows, we adopt an attention module",
      "page": 5
    },
    {
      "caption": "Figure 4: shows the schema of a neuron in the hidden",
      "page": 6
    },
    {
      "caption": "Figure 4: Input and output of a neroun at hidden layer l",
      "page": 6
    },
    {
      "caption": "Figure 3: Base classiﬁer architecture",
      "page": 7
    },
    {
      "caption": "Figure 5: Random dropout versus weight regularization",
      "page": 7
    },
    {
      "caption": "Figure 5: , we can instantiate a",
      "page": 7
    },
    {
      "caption": "Figure 6: , the weights are of three categories: least (λ), minor (β),",
      "page": 7
    },
    {
      "caption": "Figure 6: Distribution of coefﬁcient weights",
      "page": 7
    },
    {
      "caption": "Figure 7: shows short text distribution for each given cognitive",
      "page": 8
    },
    {
      "caption": "Figure 7: Cognitive factors data distribution",
      "page": 8
    },
    {
      "caption": "Figure 8: that the performance of all the methods",
      "page": 9
    },
    {
      "caption": "Figure 8: Compare baselines accuracy",
      "page": 9
    },
    {
      "caption": "Figure 9: Compare accuracy between emotions",
      "page": 9
    },
    {
      "caption": "Figure 9: ) that fear and disgust",
      "page": 9
    },
    {
      "caption": "Figure 10: to compare the effect of the two highest accuracies",
      "page": 10
    },
    {
      "caption": "Figure 10: Compare baselines accuracy in fear and joy emotion",
      "page": 10
    },
    {
      "caption": "Figure 11: Confusion matrix for emotion prediction",
      "page": 10
    },
    {
      "caption": "Figure 11: illustrates the prediction confusion matrix for our",
      "page": 10
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "NEU": "Low\nHigh",
          "CON": "Low\nHigh",
          "EXT": "Low\nHigh",
          "AGR": "Low\nHigh"
        },
        {
          "NEU": "6200\n3717",
          "CON": "5361\n4556",
          "EXT": "5707\n4210",
          "AGR": "4649\n5268"
        },
        {
          "NEU": "4.75",
          "CON": "5",
          "EXT": "5",
          "AGR": "5"
        },
        {
          "NEU": "1.25",
          "CON": "1.45",
          "EXT": "1.33",
          "AGR": "1.65"
        },
        {
          "NEU": "2.6",
          "CON": "3.47",
          "EXT": "3.35",
          "AGR": "3.62"
        },
        {
          "NEU": "0.76",
          "CON": "0.74",
          "EXT": "0.85",
          "AGR": "0.68"
        },
        {
          "NEU": "2.6",
          "CON": "3.4",
          "EXT": "3.4",
          "AGR": "3.65"
        }
      ],
      "page": 8
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Anger": "2859",
          "Disgust": "2921",
          "Fear": "1363",
          "Joy": "2877",
          "Sadness": "2273"
        },
        {
          "Anger": "1",
          "Disgust": "1",
          "Fear": "1",
          "Joy": "1",
          "Sadness": "1"
        },
        {
          "Anger": "0",
          "Disgust": "0",
          "Fear": "0",
          "Joy": "0",
          "Sadness": "0"
        },
        {
          "Anger": "0.37",
          "Disgust": "0.378",
          "Fear": "0.18",
          "Joy": "0.37",
          "Sadness": "0.2943"
        },
        {
          "Anger": "0.48",
          "Disgust": "0.485",
          "Fear": "0.38",
          "Joy": "0.48",
          "Sadness": "0.455"
        },
        {
          "Anger": "0.0",
          "Disgust": "0.0",
          "Fear": "0.0",
          "Joy": "0.0",
          "Sadness": "0.0"
        }
      ],
      "page": 8
    },
    {
      "caption": "Table 8: , the learning rate of 10−6 results in the",
      "data": [
        {
          "learning\nrate": "",
          "Accuracy": "Anger"
        },
        {
          "learning\nrate": "10−1",
          "Accuracy": "79.86"
        },
        {
          "learning\nrate": "10−2",
          "Accuracy": "79.81"
        },
        {
          "learning\nrate": "10−3",
          "Accuracy": "79.48"
        },
        {
          "learning\nrate": "10−4",
          "Accuracy": "80.41"
        },
        {
          "learning\nrate": "10−5",
          "Accuracy": "81.11"
        },
        {
          "learning\nrate": "10−6",
          "Accuracy": "81.73"
        }
      ],
      "page": 9
    },
    {
      "caption": "Table 8: , the learning rate of 10−6 results in the",
      "data": [
        {
          "batch\nsize": "",
          "Accuracy": "Anger"
        },
        {
          "batch\nsize": "30",
          "Accuracy": "79.85"
        },
        {
          "batch\nsize": "50",
          "Accuracy": "80.06"
        },
        {
          "batch\nsize": "80",
          "Accuracy": "80.4"
        },
        {
          "batch\nsize": "100",
          "Accuracy": "80.16"
        },
        {
          "batch\nsize": "128",
          "Accuracy": "81.73"
        }
      ],
      "page": 9
    },
    {
      "caption": "Table 8: , the learning rate of 10−6 results in the",
      "data": [
        {
          "epoch": "",
          "Accuracy": "Anger\nDisgust\nFear\nJoy\nSadness"
        },
        {
          "epoch": "40",
          "Accuracy": "80.51\n76.67\n92.01\n77.27\n81.7"
        },
        {
          "epoch": "50",
          "Accuracy": "81.73\n77.67\n83.05\n89.39\n78.1"
        },
        {
          "epoch": "80",
          "Accuracy": "92.02\n80.32\n76.27\n77.49\n81.53"
        },
        {
          "epoch": "100",
          "Accuracy": "81.88\n80.35\n76.79\n91.76\n77.79"
        }
      ],
      "page": 9
    },
    {
      "caption": "Table 8: , the learning rate of 10−6 results in the",
      "data": [
        {
          "glove": "",
          "Accuracy": "Anger\nDisgust\nFear\nJoy\nSadness"
        },
        {
          "glove": "25",
          "Accuracy": "79.55\n77.07\n91.12\n74.64\n80.58"
        },
        {
          "glove": "50",
          "Accuracy": "82.22\n81.49\n76.29\n91.77\n73.29"
        },
        {
          "glove": "100",
          "Accuracy": "92\n79.96\n74.92\n76.97\n82.18"
        },
        {
          "glove": "200",
          "Accuracy": "81.73\n77.67\n83.05\n89.39\n78.1"
        }
      ],
      "page": 9
    },
    {
      "caption": "Table 10: shows Q l, the output feature spatial size, and e, the number of",
      "data": [
        {
          "methods": "",
          "Anger": "Percision",
          "Disgust": "Percision",
          "Fear": "Percision",
          "Joy": "Percision",
          "Sadness": "Percision"
        },
        {
          "methods": "Unison",
          "Anger": "0/84",
          "Disgust": "0/93",
          "Fear": "0/84",
          "Joy": "0/8",
          "Sadness": "0/84"
        },
        {
          "methods": "Senti {HC}",
          "Anger": "0/54",
          "Disgust": "0/53",
          "Fear": "0/66",
          "Joy": "0/5",
          "Sadness": "0/55"
        },
        {
          "methods": "SVM Behavior",
          "Anger": "0/68",
          "Disgust": "0/65",
          "Fear": "0/72",
          "Joy": "0/68",
          "Sadness": "0/52"
        },
        {
          "methods": "Lexicon-based",
          "Anger": "0/33",
          "Disgust": "0/34",
          "Fear": "0/54",
          "Joy": "0/33",
          "Sadness": "0/6"
        },
        {
          "methods": "EmoDNN {SVM}",
          "Anger": "0/77",
          "Disgust": "0/7",
          "Fear": "0/78",
          "Joy": "0/81",
          "Sadness": "0/68"
        },
        {
          "methods": "EmoDNN {wd}",
          "Anger": "0/7",
          "Disgust": "0/77",
          "Fear": "0/68",
          "Joy": "0/75",
          "Sadness": "0/62"
        },
        {
          "methods": "EmoDNN",
          "Anger": "0/75",
          "Disgust": "0/7",
          "Fear": "0/75",
          "Joy": "0/83",
          "Sadness": "0/64"
        }
      ],
      "page": 10
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Autoencoder for semisupervised multiple emotion detection of conversation transcripts",
      "authors": [
        "D.-A Phan",
        "Y Matsumoto",
        "H Shindo"
      ],
      "year": "2018",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "2",
      "title": "Prediction and analysis of indonesia presidential election from twitter using sentiment analysis",
      "authors": [
        "W Budiharto",
        "M Meiliana"
      ],
      "year": "2018",
      "venue": "Journal of Big data"
    },
    {
      "citation_id": "3",
      "title": "A multilingual evaluation for online hate speech detection",
      "authors": [
        "M Corazza",
        "S Menini",
        "E Cabrio",
        "S Tonelli",
        "S Villata"
      ],
      "year": "2020",
      "venue": "ACM Transactions on Internet Technology (TOIT)"
    },
    {
      "citation_id": "4",
      "title": "Emotion detection in suicide notes",
      "authors": [
        "B Desmet",
        "V Hoste"
      ],
      "year": "2013",
      "venue": "Expert Systems with Applications"
    },
    {
      "citation_id": "5",
      "title": "From valence to emotions: Exploring the distribution of emotions in online product reviews",
      "authors": [
        "R Ullah",
        "N Amblee",
        "W Kim",
        "H Lee"
      ],
      "year": "2016",
      "venue": "Decision Support Systems"
    },
    {
      "citation_id": "6",
      "title": "Twitter mood predicts the stock market",
      "authors": [
        "J Bollen",
        "H Mao",
        "X Zeng"
      ],
      "year": "2011",
      "venue": "Journal of computational science"
    },
    {
      "citation_id": "7",
      "title": "Hierarchical classification approach to emotion recognition in twitter",
      "authors": [
        "A Esmin",
        "R Oliveira",
        "S Matwin"
      ],
      "year": "2012",
      "venue": "2012 11th International Conference on ML and Applications"
    },
    {
      "citation_id": "8",
      "title": "Extraction of emotions from multilingual text using intelligent text processing and computational linguistics",
      "authors": [
        "V Jain",
        "S Kumar",
        "S Fernandes"
      ],
      "year": "2017",
      "venue": "Journal of computational science"
    },
    {
      "citation_id": "9",
      "title": "Hierarchical emotion classification and emotion component analysis on chinese micro-blog posts",
      "authors": [
        "H Xu",
        "W Yang",
        "J Wang"
      ],
      "year": "2015",
      "venue": "Expert systems with applications"
    },
    {
      "citation_id": "10",
      "title": "Emotion recognition on twitter: Comparative study and training a unison model",
      "authors": [
        "N Colneric",
        "J Demsar"
      ],
      "year": "2018",
      "venue": "IEEE transactions on affective computing"
    },
    {
      "citation_id": "11",
      "title": "On traits and temperament: General and specific factors of emotional experience and their relation to the five factors model",
      "authors": [
        "D Watson",
        "L Clark"
      ],
      "year": "1992",
      "venue": "Journal of personality"
    },
    {
      "citation_id": "12",
      "title": "Text messaging, personality, and the social context",
      "authors": [
        "T Holtgraves"
      ],
      "year": "2011",
      "venue": "Journal of research in personality"
    },
    {
      "citation_id": "13",
      "title": "Semeval-2018: Affect in tweets",
      "authors": [
        "S Mohammad",
        "F Bravo-Marquez",
        "M Salameh",
        "S Kiritchenko"
      ],
      "year": "2018",
      "venue": "Proc. of the 12th workshop on semantic evaluation"
    },
    {
      "citation_id": "14",
      "title": "Emotion intensities in tweets",
      "authors": [
        "S Mohammad",
        "F Bravo-Marquez"
      ],
      "year": "2017",
      "venue": "Proc. 6th Joint Conf. Lexical Comput. Semantics"
    },
    {
      "citation_id": "15",
      "title": "Private traits and attributes are predictable from digital records of human behavior",
      "authors": [
        "M Kosinski",
        "D Stillwell",
        "T Graepel"
      ],
      "year": "2013",
      "venue": "Proceedings of the national academy of sciences"
    },
    {
      "citation_id": "16",
      "title": "Soulmate: Short-text author linking through multi-aspect temporal-textual embedding",
      "authors": [
        "S Najafipour",
        "S Hosseini",
        "W Hua",
        "M Kangavari",
        "X Zhou"
      ],
      "year": "2020",
      "venue": "IEEE Trans. on Knowledge and Data Engineering"
    },
    {
      "citation_id": "17",
      "title": "Teags: time-aware text embedding approach to generate subgraphs",
      "authors": [
        "S Hosseini",
        "S Najafipour",
        "N.-M Cheung",
        "H Yin",
        "M Kangavari",
        "X Zhou"
      ],
      "year": "2020",
      "venue": "Data Mining and Knowledge Discovery"
    },
    {
      "citation_id": "18",
      "title": "Location oriented phrase detection in microblogs",
      "authors": [
        "S Hosseini",
        "S Unankard",
        "X Zhou",
        "S Sadiq"
      ],
      "year": "2014",
      "venue": "International Conference on Database Systems for Advanced Applications"
    },
    {
      "citation_id": "19",
      "title": "Deep learning-based personality recognition from text posts of online social networks",
      "authors": [
        "D Xue",
        "L Wu",
        "Z Hong",
        "S Guo",
        "L Gao",
        "Z Wu",
        "X Zhong",
        "J Sun"
      ],
      "year": "2018",
      "venue": "Applied Intelligence"
    },
    {
      "citation_id": "20",
      "title": "Predicting personality from twitter",
      "authors": [
        "J Golbeck",
        "C Robles",
        "M Edmondson",
        "K Turner"
      ],
      "year": "2011",
      "venue": "Proc. 3rd IEEE Int. Conf. on Social Computing"
    },
    {
      "citation_id": "21",
      "title": "Mining subgraphs from propagation networks through temporal dynamic analysis",
      "authors": [
        "S Hosseini",
        "H Yin",
        "M Zhang",
        "Y Elovici",
        "X Zhou"
      ],
      "year": "2018",
      "venue": "2018 19th IEEE International Conference on Mobile Data Management (MDM)"
    },
    {
      "citation_id": "22",
      "title": "Personality traits recognition on social network-facebook",
      "authors": [
        "F Alam",
        "E Stepanov",
        "G Riccardi"
      ],
      "year": "2013",
      "venue": "Seventh Int. AAAI Conf. on Weblogs and Social Media"
    },
    {
      "citation_id": "23",
      "title": "Our twitter profiles, our selves: Predicting personality with twitter",
      "authors": [
        "D Quercia",
        "M Kosinski",
        "D Stillwell",
        "J Crowcroft"
      ],
      "year": "2011",
      "venue": "Proc. 3rd IEEE International Conference on Social Computing"
    },
    {
      "citation_id": "24",
      "title": "Personality recognition based on user generated content",
      "authors": [
        "C Yuan",
        "J Wu",
        "H Li",
        "L Wang"
      ],
      "year": "2018",
      "venue": "2018 15th International Conference on Service Systems and Service Management (ICSSSM)"
    },
    {
      "citation_id": "25",
      "title": "Who am i? personality detection based on deep learning for texts",
      "authors": [
        "X Sun",
        "B Liu",
        "J Cao",
        "J Luo",
        "X Shen"
      ],
      "year": "2018",
      "venue": "2018 IEEE International Conference on Communications (ICC)"
    },
    {
      "citation_id": "26",
      "title": "Deep learning-based document modeling for personality detection from text",
      "authors": [
        "N Majumder",
        "S Poria",
        "A Gelbukh",
        "E Cambria"
      ],
      "year": "2017",
      "venue": "Deep learning-based document modeling for personality detection from text"
    },
    {
      "citation_id": "27",
      "title": "Word affect intensities",
      "authors": [
        "S Mohammad"
      ],
      "year": "2018",
      "venue": "Proceedings of the 11th Edition of the Language Re-sources and Evaluation Conference (LREC-2018)"
    },
    {
      "citation_id": "28",
      "title": "Depechemood++: a bilingual emotion lexicon built through simple yet powerful techniques",
      "authors": [
        "O Araque",
        "L Gatti",
        "J Staiano",
        "M Guerini"
      ],
      "year": "2019",
      "venue": "Depechemood++: a bilingual emotion lexicon built through simple yet powerful techniques"
    },
    {
      "citation_id": "29",
      "title": "Text-based emotion classification using emotion cause extraction",
      "authors": [
        "W Li",
        "H Xu"
      ],
      "year": "2014",
      "venue": "Expert Systems with Applications"
    },
    {
      "citation_id": "30",
      "title": "Lexicon based feature extraction for emotion text classification",
      "authors": [
        "A Bandhakavi",
        "N Wiratunga",
        "D Padmanabhan",
        "S Massie"
      ],
      "year": "2017",
      "venue": "Pattern recognition letters"
    },
    {
      "citation_id": "31",
      "title": "A rule-based approach to implicit emotion detection in text",
      "authors": [
        "O Udochukwu",
        "Y He"
      ],
      "year": "2015",
      "venue": "International Conference on Applications of Natural Language to Information Systems"
    },
    {
      "citation_id": "32",
      "title": "Prior and contextual emotion of words in sentential context",
      "authors": [
        "D Ghazi",
        "D Inkpen",
        "S Szpakowicz"
      ],
      "year": "2014",
      "venue": "Computer Speech & Language"
    },
    {
      "citation_id": "33",
      "title": "Intensional learning to efficiently build up automatically annotated emotion corpora",
      "authors": [
        "L Canales",
        "C Strapparava",
        "E Boldrini",
        "P Martinez-Barco"
      ],
      "year": "2017",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "34",
      "title": "A machine learning-based investigation utilizing the in-text features for the identification of dominant emotion in an email",
      "authors": [
        "Z Halim",
        "M Waqar",
        "M Tahir"
      ],
      "year": "2020",
      "venue": "Knowledge-Based Systems"
    },
    {
      "citation_id": "35",
      "title": "Multi-label emotion detection via emotion-specified feature extraction and emotion correlation learning",
      "authors": [
        "J Deng",
        "F Ren"
      ],
      "year": "2020",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "36",
      "title": "Semantic-emotion neural network for emotion recognition from text",
      "authors": [
        "E Batbaatar",
        "M Li",
        "K Ryu"
      ],
      "year": "2019",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "37",
      "title": "All-in-one: Emotion, sentiment and intensity prediction using a multi-task ensemble framework",
      "authors": [
        "S Akhtar",
        "D Ghosal",
        "A Ekbal",
        "P Bhattacharyya",
        "S Kurohashi"
      ],
      "year": "2019",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "38",
      "title": "Audio-textual emotion recognition based on improved neural networks",
      "authors": [
        "L Cai",
        "Y Hu",
        "J Dong",
        "S Zhou"
      ],
      "year": "2019",
      "venue": "Mathematical Problems in Engineering"
    },
    {
      "citation_id": "39",
      "title": "Emotion correlation mining through deep learning models on natural language text",
      "authors": [
        "X Wang",
        "L Kou",
        "V Sugumaran",
        "X Luo",
        "H Zhang"
      ],
      "year": "2020",
      "venue": "IEEE Transactions on Cybernetics"
    },
    {
      "citation_id": "40",
      "title": "Deep rolling: A novel emotion prediction model for a multi-participant communication context",
      "authors": [
        "H Rong",
        "T Ma",
        "J Cao",
        "Y Tian",
        "A Al-Dhelaan",
        "M Al-Rodhaan"
      ],
      "year": "2019",
      "venue": "Information Sciences"
    },
    {
      "citation_id": "41",
      "title": "Affective computing",
      "authors": [
        "R Picard"
      ],
      "year": "2000",
      "venue": "Affective computing"
    },
    {
      "citation_id": "42",
      "title": "A survey of textual emotion recognition and its challenges",
      "authors": [
        "J Deng",
        "F Ren"
      ],
      "year": "2021",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "43",
      "title": "Support vector regression",
      "authors": [
        "M Awad",
        "R Khanna"
      ],
      "year": "2015",
      "venue": "Efficient learning machines"
    },
    {
      "citation_id": "44",
      "title": "Methodology review: Clustering methods",
      "authors": [
        "G Milligan",
        "M Cooper"
      ],
      "year": "1987",
      "venue": "Methodology review: Clustering methods"
    },
    {
      "citation_id": "45",
      "title": "Glove: Global vectors for word representation",
      "authors": [
        "J Pennington",
        "R Socher",
        "C Manning"
      ],
      "year": "2014",
      "venue": "Proceedings of the 2014 conference on empirical methods in natural language processing"
    },
    {
      "citation_id": "46",
      "title": "Efficient estimation of word representations in vector space",
      "authors": [
        "T Mikolov",
        "K Chen",
        "G Corrado",
        "J Dean"
      ],
      "year": "2013",
      "venue": "Proceedings of International Conference on Learning Representations (ICLR 2013)"
    },
    {
      "citation_id": "47",
      "title": "Attention-based convolutional neural networks for sentence classification",
      "authors": [
        "Z Zhao",
        "Y Wu"
      ],
      "year": "2016",
      "venue": "INTER-SPEECH"
    },
    {
      "citation_id": "48",
      "title": "Hcp: A flexible cnn framework for multilabel image classification",
      "authors": [
        "Y Wei",
        "W Xia",
        "M Lin",
        "J Huang",
        "B Ni",
        "J Dong",
        "Y Zhao",
        "S Yan"
      ],
      "year": "2015",
      "venue": "Hcp: A flexible cnn framework for multilabel image classification"
    },
    {
      "citation_id": "49",
      "title": "Adam: A method for stochastic optimization",
      "authors": [
        "D Kingma",
        "J Ba"
      ],
      "year": "2015",
      "venue": "Proceedings of International Conference on Learning Representations"
    },
    {
      "citation_id": "50",
      "title": "Dropout: a simple way to prevent neural networks from overfitting",
      "authors": [
        "N Srivastava",
        "G Hinton",
        "A Krizhevsky",
        "I Sutskever",
        "R Salakhutdinov"
      ],
      "year": "2014",
      "venue": "The journal of machine learning research"
    },
    {
      "citation_id": "51",
      "title": "Regularization of neural networks using dropconnect",
      "authors": [
        "L Wan",
        "M Zeiler",
        "S Zhang",
        "Y Le Cun",
        "R Fergus"
      ],
      "year": "2013",
      "venue": "Int. conf. on ML"
    },
    {
      "citation_id": "52",
      "title": "On the construction of multi-relational classifier based on canonical correlation analysis",
      "authors": [
        "R Zall",
        "M Kangavari"
      ],
      "year": "2019",
      "venue": "International Journal of Artificial Intelligence"
    },
    {
      "citation_id": "53",
      "title": "Semi-supervised multiview ensemble learning based on extracting cross-view correlation",
      "authors": [
        "R Zall",
        "M Keyvanpour"
      ],
      "year": "2016",
      "venue": "Advances in Electrical and Computer Engineering"
    },
    {
      "citation_id": "54",
      "title": "Handbook of cognition and emotion",
      "authors": [
        "P Ekman"
      ],
      "year": "1999",
      "venue": "Handbook of cognition and emotion"
    },
    {
      "citation_id": "55",
      "title": "Convolutional neural networks at constrained time cost",
      "authors": [
        "K He",
        "J Sun"
      ],
      "year": "2015",
      "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition"
    }
  ]
}