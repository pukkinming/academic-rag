{
  "paper_id": "2404.15373v1",
  "title": "Robust Eeg-Based Emotion Recognition Using An Inception And Two-Sided Perturbation Model",
  "published": "2024-04-21T07:54:43Z",
  "authors": [
    "Shadi Sartipi",
    "Mujdat Cetin"
  ],
  "keywords": [
    "Adversarial training",
    "Brain-computer interfaces",
    "Emotion recognition",
    "Inception module",
    "Weight perturbation"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Automated emotion recognition using electroencephalogram (EEG) signals has gained substantial attention. Although deep learning approaches exhibit strong performance, they often suffer from vulnerabilities to various perturbations, like environmental noise and adversarial attacks. In this paper, we propose an Inception feature generator and two-sided perturbation (INC-TSP) approach to enhance emotion recognition in brain-computer interfaces. INC-TSP integrates the Inception module for EEG data analysis and employs two-sided perturbation (TSP) as a defensive mechanism against input perturbations. TSP introduces worst-case perturbations to the model's weights and inputs, reinforcing the model's elasticity against adversarial attacks. The proposed approach addresses the challenge of maintaining accurate emotion recognition in the presence of input uncertainties. We validate INC-TSP in a subject-independent three-class emotion recognition scenario, demonstrating robust performance.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "I. Introduction",
      "text": "Brain-computer interfaces (BCI) develop a direct pathway between the electrical activities of the human brain and the external environment, bypassing the need for typical nerves and muscles  [1] . This provides a multidisciplinary framework incorporating psychology, electronics, computers, and neuroscience to interpret the electrical activity of the brain and address health-related challenges to improve life quality  [2] . Emotions profoundly influence human daily life by impacting physiological activities and decision-making. Automated recognition of emotions can improve human-machine communication  [3] . Among various modalities for emotion recognition, electroencephalography (EEG) stands out as a preferred physiological method for collecting brain signals in BCI research due to its affordability, non-invasiveness, high temporal resolution, and portability  [3] . Various studies have investigated automated emotion recognition by focusing on feature extraction and classification model construction  [4] . Some of the widely used features in this context are differential entropy (DE), power spectral density (PSD), and functional connectivity  [5] .\n\nDeep learning (DL) approaches have shown significant performance over traditional machine learning techniques for decoding EEG signals  [6] . Convolutional neural networks (CNNs)  [7]  and recurrent neural networks (RNNs)  [6]  are widely used in this area. In  [8] , they used the combination of CNN and long short-term memory (LSTM) along with graphbased smoothed EEG data to get the temporal and spatial features for emotion recognition. Popular examples of using CNN-based networks include the DeepCNN and EEGNet proposed in  [7]  and  [9] , respectively.\n\nFor various BCI applications, most studies focus on improving the performance of DL approaches. However, one drawback of DL models is that they are often susceptible to precisely crafted minor alterations in input data, which could be due to environmental noise, individual variations, and adversarial attacks  [10] ,  [11] . These types of perturbations can lead to significant performance degradation  [11] . Few studies explored this limitation. For instance, in  [12]  the susceptibility of machine learning algorithms in EEG-based BCIs is explored. A novel loss function is proposed in  [13]  to generate universal adversarial perturbations. Since emotion recognition is utilized in mental health applications and various real-time applications  [14] , the robustness of the model alongside the model's performance should be of concern. To the best of our knowledge, there is currently no study on the robustness of EEG-based emotion recognition.\n\nIn this paper, we propose a novel DL approach called Inception feature generator and two-sided perturbation (INC-TSP) to extract effective features from EEG data and learn the model in a way that is robust against adversarial attacks for subject-independent emotion recognition. To achieve this, we integrate the Inception module  [15]  with a CNN backbone into the deep architecture. As EEG signals contain oscillatory patterns of varying temporal lengths, the Inception module enables a multiscale analysis of the input data. Two-sided perturbation (TSP), which forms an outer maximization problem  [16] , serves as our defensive mechanism. TSP applies worstcase perturbations to the weights and inputs. We evaluate the proposed approach for three-class emotion recognition. Our main contributions can be summarized as follows:\n\n• We develop an INC-based deep feature generator that performs multiscale analysis of spatial, temporal, and\n\n• A novel learning approach is used for robust EEG-based emotion recognition against input perturbations.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Ii. Method",
      "text": "Inception-based Feature Generator: The process of feature extraction plays a pivotal role in EEG emotion recognition studies. To achieve this, we draw inspiration from image classification techniques and employ the Inception module  [15]  to extract features. The designed inception-based (INC) feature generator architecture comprises a combination of multiple convolutional layers, a pooling layer, and an activation function.\n\nLet the input data be denoted as X ∈ R n×c×t , where n, c, and t are the number of frequency subbands, EEG channels, and temporal length of the data, respectively. Table  I  shows specific configurations and architectural choices for three different CNN blocks. The feature extraction process involves the initial application of a convolutional layer, C1, to acquire shallow features. Subsequently, the inception module, with different convolutional kernels, is employed to capture deeper features. The various kernel sizes allow the model to capture diverse information in both the temporal and spatial domains. The output features from the parallel convolutional layers are then merged using a concatenation layer. The concatenated features pass through another convolutional layer, C2, followed by pooling and dropout layers in the final step. ReLU activation function and batch normalization are applied in CNN layers. Finally, the features are fed to three fully connected layers with dimensions of 512, 256, and 64. Robust Generalization:The performance of deep neural networks for EEG-based emotion recognition is often vulnerable to perturbations applied to input data, which could significantly diminish the model's performance across different subjects  [11] . These perturbations are also known as adversarial attacks  [10] .\n\nTo overcome such attacks, we employ adversarial training (AT) with adversarial weight perturbation as a defensive scheme inspired by  [16] . This approach involves the use of two-sided perturbation (TSP), which applies worst-case perturbations to both the input data and the model's weights.\n\n1) Adversarial Attack: To begin, we briefly explain two widely used adversarial attack techniques targeted at computer vision models. Fast gradient sign method (FGSM)  [17]  is a single-step gradient-based method to find the perturbed example in one step by the amount of ϵ in a direction specified by the sign of the gradient of the loss function:\n\nAnother attack is projected gradient descent (PGD)  [18]  which perturbs the original sample for T iterations with stepsize η. At each iteration, PGD projects the perturbed sample back onto the ϵ-ball at the t th iteration as:\n\nwhere Π is the projection operator.\n\n2) Adversarial Defense: AT directly integrates adversarial examples into the training process to flatten the loss changes with respect to the input via the optimization problem presented below  [18] :\n\nwhere ρ(θ) is the adversarial loss, n is the number of samples, δ = ∥x ′ i -x i ∥ p , ∥.∥ p is the norm (threat model), x ′ i is the adversarial example within the ϵ-ball centered at original sample x i , f θ is the deep learning architecture, i.e., INC, with weights θ, L is the classification loss, and y i are the true labels. Following  [16] , to incorporate the flatness of the loss change with respect to the weight, we propose solving the following optimization problem:   where v is selected from the feasible region for weight perturbation. Let γ be the constraint on weight perturbation size. The weight perturbation on the l th layer with weight θ l is ∥v l ∥ ≤ γ∥θ l ∥.\n\n3) Learning process: The optimization and learning process for INC-TSP is shown in Algorithm 1. Let m be the minibatch size. The input perturbation is applied by choosing the attack type subsequently the weight perturbation is calculated. Finally, the model parameters, θ, are updated via the Adam optimizer.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Iii. Experimental Study",
      "text": "Dataset: Here, we use the publicly available SEED dataset  [5]  for emotion recognition. The dataset comprises fifteen movie clips designed to elicit three emotions: happiness, sadness, and neutrality. The experiments involved a total of 15 participants, consisting of 8 females and 7 males, and were instructed to immerse themselves in the movie clips to evoke the corresponding emotions. The EEG signals were recorded using the international 10-20 system with 62 channels. Each trial followed a specific sequence: a 5-second starting hint before the film clip, 4 minutes of the clip as an emotional stimulus, 45 seconds for self-assessment, and a 15-second break. The recorded EEG data were downsampled from 1000 Hz to 200 Hz, and a band-pass filter with a frequency range of 0.5-70 Hz was applied. We calculated the differential entropy (DE) features every 1-second with no overlap in five frequency subbands, namely, delta, theta, alpha, beta, and gamma. Results: In this section, we present the performance of the proposed approach. We employed the L 2 and L ∞ threat models. The value of ϵ is set to 8/225, and the PGD step size is set to 15/255. We evaluated the approach against various",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Study",
      "text": "Accuracy Proposed method 0.93 ± 0.03 SDDA  [19]  0.91 ± 0.07 MSFR-GCN  [20]  0.87 ± 0.05 SECT  [21]  0.85 ± 0.06 adversarial attacks. Samples of the perturbed input with 10 and 20 iterations, PGD-10 and PGD-20, are depicted in Fig.  1 . The weight perturbation size and learning rate are both set to 0.03 and 9 × 10 -5 , respectively.\n\nWe employed leave-one-subject-out (LOSO) cross validation to assess performance. The input data are normalized by subtracting the mean and dividing by the standard deviation. To evaluate the performance and show the effectiveness of the defense mechanism, we computed the robust accuracy and F1score (R-Accuracy and R-F1-score). R-Accuracy and R-F1score present the accuracy and F1-score on the perturbed test data. The average performance across subjects is presented in Table  II . As shown in Table  II , the best robust performance is 0.91±0.04 under the L 2 threat model and PGD-10 adversarial attacks. Furthermore, these results suggest that INC-TSP consistently maintains R-Accuracy and R-F1-scores, indicating its effectiveness in countering adversarial perturbations and ensuring accurate classification.\n\nFurthermore, we performed the ablation study shown in Table  III . R-Accuracy and Accuracy columns are the performance of each approach on test data with PGD-10 attack and non-perturbed data, respectively. Comparing the results without defense to those with AT (3) and TSP (4), the proposed learning process achieves the highest R-Accuracy and accuracy. For detailed performance analysis, we present the confusion matrices for classification using the INC architecture without a defense and with the proposed INC-TSP approach with PGD-20 attack in Fig.  3 . This demonstrates TSP's ability to accurately detect all three emotional states even when the model encounters perturbed inputs. Table  IV compares",
      "page_start": 4,
      "page_end": 4
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Sample EEG features for (a) original data, (b) perturbed with PGD-10,",
      "page": 3
    },
    {
      "caption": "Figure 3: This demonstrates TSP’s ability",
      "page": 3
    },
    {
      "caption": "Figure 2: (a) and (b)). The major drawback of",
      "page": 3
    },
    {
      "caption": "Figure 2: (b), the learning curves of INC-TSP for",
      "page": 3
    },
    {
      "caption": "Figure 2: Learning curve of PGD-10 attack (a) INC without defense, (b) INC-TSP, and (c) robustness of INC-TSP as a function of weight perturbation size.",
      "page": 4
    },
    {
      "caption": "Figure 3: Confusion matrices for a perturbed input with PGD (left) without",
      "page": 4
    },
    {
      "caption": "Figure 2: (c) presents the model performance across different",
      "page": 4
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "0.74\n0.15\n0.18\n0.93": "0.067\n0.044\n0.89",
          "0.11\n0.053": ""
        }
      ],
      "page": 4
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Braincomputer interfaces in medicine",
      "authors": [
        "Jerry Shih",
        "Dean Krusienski",
        "Jonathan Wolpaw"
      ],
      "year": "2012",
      "venue": "Mayo clinic proceedings"
    },
    {
      "citation_id": "2",
      "title": "Brain computer interfacing: Applications and challenges",
      "authors": [
        "Ayman Sarah N Abdulkader",
        "Mostafa-Sami M Atia",
        "Mostafa"
      ],
      "year": "2015",
      "venue": "Egyptian Informatics Journal"
    },
    {
      "citation_id": "3",
      "title": "Emotion, cognition, and behavior",
      "authors": [
        "J Raymond",
        "Dolan"
      ],
      "year": "2002",
      "venue": "science"
    },
    {
      "citation_id": "4",
      "title": "Feature extraction and selection for emotion recognition from EEG",
      "authors": [
        "Robert Jenke",
        "Angelika Peer",
        "Martin Buss"
      ],
      "year": "2014",
      "venue": "IEEE Trans. Affect. Comput"
    },
    {
      "citation_id": "5",
      "title": "Investigating critical frequency bands and channels for EEG-based emotion recognition with deep neural networks",
      "authors": [
        "Wei-Long Zheng",
        "Bao-Liang Lu"
      ],
      "year": "2015",
      "venue": "IEEE Transactions on autonomous mental development"
    },
    {
      "citation_id": "6",
      "title": "Deep learning for electroencephalogram (EEG) classification tasks: a review",
      "authors": [
        "Alexander Craik",
        "Yongtian He",
        "Jose L Contreras- Vidal"
      ],
      "year": "2019",
      "venue": "J. Neural Eng"
    },
    {
      "citation_id": "7",
      "title": "Deep learning with convolutional neural networks for EEG decoding and visualization",
      "authors": [
        "Robin Tibor"
      ],
      "year": "2017",
      "venue": "Human brain mapping"
    },
    {
      "citation_id": "8",
      "title": "A hybrid end-to-end spatio-temporal attention neural network with graph-smooth signals for EEG emotion recognition",
      "authors": [
        "Shadi Sartipi",
        "Mastaneh Torkamani-Azar",
        "Mujdat Cetin"
      ],
      "year": "2023",
      "venue": "IEEE Trans. Cogn. Develop. Syst"
    },
    {
      "citation_id": "9",
      "title": "EEGNet: a compact convolutional neural network for EEG-based brain-computer interfaces",
      "authors": [
        "J Vernon",
        "Lawhern"
      ],
      "year": "2018",
      "venue": "J. Neural Eng"
    },
    {
      "citation_id": "10",
      "title": "Intriguing properties of neural networks",
      "authors": [
        "Christian Szegedy",
        "Wojciech Zaremba",
        "Ilya Sutskever",
        "Joan Bruna",
        "Dumitru Erhan",
        "Ian Goodfellow",
        "Rob Fergus"
      ],
      "year": "2013",
      "venue": "Intriguing properties of neural networks",
      "arxiv": "arXiv:1312.6199"
    },
    {
      "citation_id": "11",
      "title": "On the vulnerability of CNN classifiers in EEG-based BCIs",
      "authors": [
        "Xiao Zhang",
        "Dongrui Wu"
      ],
      "year": "2019",
      "venue": "IEEE Trans. Neural Syst. Rehabil. Eng"
    },
    {
      "citation_id": "12",
      "title": "White-box target attack for EEG-based BCI regression problems",
      "authors": [
        "Lubin Meng"
      ],
      "year": "2019",
      "venue": "Neural Information Processing: 26th International Conference"
    },
    {
      "citation_id": "13",
      "title": "Universal adversarial perturbations for CNN classifiers in EEG-based BCIs",
      "authors": [
        "Zihan Liu",
        "Lubin Meng",
        "Xiao Zhang",
        "Weili Fang",
        "Dongrui Wu"
      ],
      "year": "2021",
      "venue": "J. Neural Eng"
    },
    {
      "citation_id": "14",
      "title": "Secure and robust machine learning for healthcare: A survey",
      "authors": [
        "Adnan Qayyum",
        "Junaid Qadir",
        "Muhammad Bilal",
        "Ala Al-Fuqaha"
      ],
      "year": "2020",
      "venue": "IEEE Reviews in Biomedical Engineering"
    },
    {
      "citation_id": "15",
      "title": "Inception-v4, inception-resnet and the impact of residual connections on learning",
      "authors": [
        "Christian Szegedy",
        "Sergey Ioffe",
        "Vincent Vanhoucke",
        "Alexander Alemi"
      ],
      "year": "2017",
      "venue": "Proceedings of the AAAI conference on artificial intelligence"
    },
    {
      "citation_id": "16",
      "title": "Adversarial weight perturbation helps robust generalization",
      "authors": [
        "Dongxian Wu",
        "Shu-Tao Xia",
        "Yisen Wang"
      ],
      "year": "2020",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "17",
      "title": "Explaining and harnessing adversarial examples",
      "authors": [
        "Ian Goodfellow",
        "Jonathon Shlens",
        "Christian Szegedy"
      ],
      "year": "2014",
      "venue": "Explaining and harnessing adversarial examples",
      "arxiv": "arXiv:1412.6572"
    },
    {
      "citation_id": "18",
      "title": "Towards deep learning models resistant to adversarial attacks",
      "authors": [
        "Aleksander Madry",
        "Aleksandar Makelov",
        "Ludwig Schmidt",
        "Dimitris Tsipras",
        "Adrian Vladu"
      ],
      "year": "2017",
      "venue": "Towards deep learning models resistant to adversarial attacks",
      "arxiv": "arXiv:1706.06083"
    },
    {
      "citation_id": "19",
      "title": "Dynamic domain adaptation for class-aware crosssubject and cross-session EEG emotion recognition",
      "authors": [
        "Zhunan Li"
      ],
      "year": "2022",
      "venue": "IEEE J. Biomed. Health Inform"
    },
    {
      "citation_id": "20",
      "title": "Msfr-gcn: A multi-scale feature reconstruction graph convolutional network for EEG emotion and cognition recognition",
      "authors": [
        "Haohao Deng Pan",
        "Feifan Zheng",
        "Yu Xu",
        "Zhe Ouyang",
        "Chu Jia",
        "Hong Wang",
        "Zeng"
      ],
      "year": "2023",
      "venue": "IEEE Trans. Neural Syst. Rehabil. Eng"
    },
    {
      "citation_id": "21",
      "title": "Sect: A method of shifted EEG channel transformer for emotion recognition",
      "authors": [
        "Zhongli Bai"
      ],
      "year": "2023",
      "venue": "IEEE J. Biomed. Health Inform"
    }
  ]
}