{
  "paper_id": "2401.09145v1",
  "title": "Your Blush Gives You Away: Detecting Hidden Mental States With Remote Photoplethysmography And Thermal Imaging",
  "published": "2024-01-17T11:38:21Z",
  "authors": [
    "Ivan Liu",
    "Fangyuan Liu",
    "Qi Zhong",
    "Fei Ma",
    "Shiguang Ni"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Multimodal emotion recognition techniques are increasingly essential for assessing mental states. Image-based methods, however, tend to focus predominantly on overt visual cues and often overlook subtler mental state changes. Psychophysiological research has demonstrated that heart rate (HR) and skin temperature are effective in detecting autonomic nervous system (ANS) activities, thereby revealing these subtle changes. However, traditional HR tools are generally more costly and less portable, while skin temperature analysis usually necessitates extensive manual processing. Advances in remote photoplethysmography (r-PPG) and automatic thermal region of interest (ROI) detection algorithms have been developed to address these issues, yet their accuracy in practical applications remains limited. This study aims to bridge this gap by integrating r-PPG with thermal imaging to enhance prediction performance. Ninety participants completed a 20-minute questionnaire to induce cognitive stress, followed by watching a film aimed at eliciting moral elevation. The results demonstrate that the combination of r-PPG and thermal imaging effectively detects emotional shifts. Using r-PPG alone, the prediction accuracy was 77% for cognitive stress and 61% for moral elevation, as determined by a support vector machine (SVM). Thermal imaging alone achieved 79% accuracy for cognitive stress and 78% for moral elevation, utilizing a random forest (RF) algorithm. An early fusion strategy of these modalities significantly improved accuracies, achieving 87% for cognitive stress and 83% for moral elevation using RF. Further analysis, which utilized statistical metrics and explainable machine learning methods including SHapley Additive exPlanations (SHAP), highlighted key features and clarified the relationship between cardiac responses and facial temperature variations. Notably, it was observed that cardiovascular features derived from r-PPG models had a more pronounced influence in data fusion, despite thermal imaging's higher predictive accuracy in unimodal analysis.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Introduction",
      "text": "Over the past two decades, the use of multimodal emotion recognition techniques (MMER, Table  1 ) in mental state assessment has gained increasing traction, offering profound insights in fields as varied as marketing, education, and mental health  (Bahreini et al., 2016; Soleymani et al., 2011) . MMER primarily utilizes image-based methodologies, analyzing facial expressions, body movements, gestures, and eye movements to assess psychological states. These methods, leveraging only camera technology, are cost-effective and non-intrusive, making them suitable for a wide range of applications. Additionally, they resonate with human visual perception, producing results that are intuitively understandable and easily explainable. However, image-based MMER primarily detects basic emotions that significantly alter appearance or behavior, such as anger, surprise, disgust, enjoyment, fear, and sadness  (Ekman, 1992) . These methods often depend on obvious visual cues, overlooking the subtler nuances of emotional states. Psychophysiological research, rooted in neuroscience, shows that physiological markers, namely heart rate (HR) and skin temperature, serve as reliable indicators of changes in mental states. These changes are reflected in autonomic balance alterations, characterized by either activation of the sympathetic nervous system (SNS) or suppression of the parasympathetic nervous system (PNS). Such dynamics lead to an increase in HR as a response to perceived threats, whereas a decrease in SNS activity along with an increase in PNS function correlates with HR reduction during relaxation phases. Given the autonomic nervous system (ANS), which encompasses both SNS and PNS, is regulated by the prefrontal cortex, and considering that mental exertions significantly tax cognitive resources and affect prefrontal cortical functions, HR fluctuations have been linked to various cognitive and affective processes. These include stress response modulation  (Cho et al., 2019c) , sustained attention  (Widjaja et al., 2015) , and emotional responses to moral beauty  (Piper et al., 2015) .\n\nThe activation of ANS plays a crucial role in thermoregulatory responses, with SNS activation in response to perceived threats leading to peripheral vasoconstriction. This reaction causes a reduction in cutaneous blood flow and, consequently, a decrease in surface body temperature  (Kistler et al., 1998) . However, cutaneous temperature changes are not solely dependent on these factors; they are also influenced by sudomotor activity (sweating), muscular contractions, and lacrimation. Research has demonstrated that emotions linked to sympathetic arousal, such as fear and anxiety, lead to a reduction in dermal temperature, particularly noticeable in the peripheral extremities and facial regions like the cheeks and nasal tips. The nasal tips, in particular, tend to exhibit a more pronounced response to stress  (Engert et al., 2014) . On the contrary, fear and anxiety may also increase muscular activity in the forehead and periorbital regions, resulting in a temperature increase in these areas  (Levine et al., 2001; Pavlidis & Levine, 2002; Vinkers et al., 2013) . Furthermore, a positive correlation exists between sustained cognitive engagement and an increase in forehead temperature  (Bando et al., 2017) .\n\nRecent developments in psychophysiological research have expanded to include the thermal effects of various emotional states.  Salazar-López et al. (2015)  noted that nasal temperature typically decreases in response to negative valence stimuli, but it also increases with positive emotions and arousal. Interestingly, these changes in nasal temperature positively correlate with participants' empathy scores and emotions like love. In a study involving fifteen three-year-olds,  Ioannou et al. (2013)  observed that sympathetic arousal caused by toy malfunctions led to a significant drop in nasal temperature. When the children were comforted, nasal temperature increased, indicative of parasympathetic activation and suggesting either distress alleviation or overcompensation. Additionally,  Ioannou et al. (2016)  found that sympathetic crying induced by sad films in female subjects resulted in increased temperatures in the forehead, periorbital region, cheeks, and chin. Conversely, the maxillary area showed a decrease in temperature, attributed to emotional sweating.\n\nCardiovascular data and thermal imaging are instrumental in uncovering concealed emotions, a key aspect of psychological analysis and various applications. However, their widespread practical application faces significant challenges. A primary obstacle is the costly and intrusive nature of heart rate detection tools such as electrocardiograms (ECG) and pulse oximeters. These devices also suffer from a lack of portability. Despite technological advancements yielding more portable commercial devices, these non-image-based methods are still not user-friendly. They necessitate the purchase of additional equipment and the need for users to carry these devices consistently. On the other hand, while thermal imaging offers a less intrusive alternative, the requirement for manual data cleaning and processing, particularly in identifying regions of interest (ROI), is a tedious and time-consuming task. This increased labor intensity and associated costs dampen enthusiasm for both research and practical usage, thus hindering the exploration of their full potential, such as in continuous monitoring scenarios.\n\nThe recent advancements in image-based heart rate detection and automatic thermal ROI detection methods shed light on the aforementioned problem. Photoplethysmography (PPG), an optical method, detects blood volume changes beneath the skin due to heartbeats  (Elgendi, 2012) . As hemoglobin's light absorption differs, blood volume changes are identified by observing the reflected light intensities. Traditionally, the contact PPG signal is obtained by employing finger oximeters with LED light  (Takano & Ohta, 2007) . Remote PPG (r-PPG), on the other hand, detects heartbeats by recording videos of faces and converting the facial skin color changes into waveforms. The main advantage of r-PPG is its capacity for non-invasive, continuous vital sign monitoring. However, the difficulty in obtaining high-quality signals curtails its acceptance both in research and in practice. While many studies have managed to produce sufficiently accurate average HR measurements-due to the robustness in calculating the average HR when signal quality is low-this metric offers limited insight into autonomic nervous system (ANS) activity, making it less pertinent for psychological studies  (Yu et al., 2019) . Conversely, while heart rate variability (HRV) offers a richer source of psychophysiological information  (Liu et al., 2020b) , it is more susceptible to slight alterations in environmental lighting and facial movements.\n\nEncouragingly, recent advances in signal processing and machine learning have markedly improved the precision of HRV metrics derived from r-PPG data.  Huang & Dung (2016)   Manual tracking of ROIs in thermal imaging processing is tedious, especially for larger datasets or prolonged monitoring. Consequently, many prior psychological studies opted for a simplified approach, manually analyzing temperature shifts before and after a stimulus was applied  (Ioannou et al., 2016) . Many early ventures into thermal imaging, on the other hand, navigated around obstacles by asking participants to stay still  (Pavlidis & Levine, 2002) , thereby limiting its applicability in real-world scenarios. Notably, advancements in machine learning-based ROI detection enable consistent temperature tracking  (Joshi et al., 2022) , even with slight head movement  (Cho et al., 2019a; Kuzdeuov et al., 2022)  Recent developments in r-PPG and thermal imaging show promise, yet there is a critical need to further enhance their accuracy. The success of automatic ROI detection, pivotal in the initial data processing stages for both r-PPG and thermal imaging, is greatly influenced by data quality. This quality hinges on various factors, such as individual movements, facial obstructions (like glasses or hair), camera angles, and environmental lighting and temperature changes. Although current signal processing methods hold potential, they typically produce satisfactory results in laboratory settings with controlled conditions. This underscores the urgent need for more advanced signal processing techniques or machine learning algorithms, essential for improving the reliability and accuracy of r-PPG and thermal imaging, particularly in real-world, uncontrolled environments.\n\nWhile researchers in the r-PPG and thermography fields struggle to mitigate the inherent low signal quality issue, they often overlook the potential of combining both methods to improve prediction accuracy further. Single-source physiological data often lacks accuracy  (Dino et al., 2020) . In contrast, data analysis across different modalities can complement each other, reducing randomness and enhancing robustness. As a result, MMER studies demonstrate superior performance compared to their single-modality counterparts  (Morency et al., 2011; Sebe et al., 2006; Wang et al., 2010; Zhao et al., 2021) . Besides, both remote PPG and thermal imaging methods can collect physiological signals non-intrusively over long periods, and despite differing in their physiological mechanism, their similar data collection, environmental, and equipment requirements make them ideal for integration. As of today, only a few pioneering studies have explored the combination of HR with thermal imaging  (Cho et al., 2019b; Cho et al., 2019c) . However, to this best knowledge of the authors, there have been no attempts to extend the literature to include the use of r-PPG, which is more suitable for use with thermal imaging as a remote ANS detection tool.\n\nThis research aims to bridge a significant gap in current literature by exploring the integration of r-PPG and thermography to improve the accuracy of predicting changes in psychological states.\n\nThe study focuses on comparing early and late data fusion strategies and employing two prevalent machine learning models: support vector machine (SVM) and random forest (RF). The goal is to ascertain how these two modalities can be effectively integrated to develop an enhanced predictive model.\n\nA critical aspect of this research involves identifying key features within the predictive model to elucidate the complex relationship between cardiovascular features, facial expressions, and psychological states. Conducting a comprehensive examination of these features is essential for optimizing model performance and facilitating more accurate adjustments and interpretations  (Du et al., 2019; Murdoch et al., 2019) . Such transparency is particularly vital in areas such as healthcare where the opacity of machine learning models presents interpretive challenges and restricts their practical application potential  (London, 2019; Tonekaboni et al., 2019; Vellido, 2019) . Moreover, an in-depth exploration of these features yields greater insights into psychophysiology and extend the understanding to the physiological responses of various mental state changes.\n\nTo meet these goals, the study conducts laboratory experiments to collect data from participants experiencing cognitive stress and moral elevation. These conditions represent the spectrum of negative and positive emotional state changes that lead to ANS-related variations in heart rate and skin temperature. Cognitive stress, a common precursor to psychological issues, is known to elicit various physiological responses, including changes in HRV and skin temperature  (Cho et al., 2019c) . On the other hand, moral elevation, defined by  Haidt (2000)  as a positive emotional response to witnessing acts of kindness and compassion, fosters a sense of warmth and promotes prosocial behavior  (Haidt, 2003) . It intensifies the desire to help others  (Han et al., 2015)  and enriches life's purpose understanding  (Oliver et al., 2012) . Previous studies have linked moral elevation to ANS activity  (Silvers & Haidt, 2008)  and HRV  (Piper et al., 2015) . Additionally, moral elevation can trigger physical sensations like chest expansion, exhilaration, tearing up, goosebumps, and a warming sensation in the chest area  (Algoe & Haidt, 2009) , potentially influencing facial temperature changes.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Materials & Methods",
      "text": "",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Participants And Experiment Procedures",
      "text": "This research forms a part of a larger study focused on the feasibility of MMER. The research protocol was approved by the ethics committee of the faculty of psychology at Beijing Normal University (No. 202203070037), and informed consent was obtained from all participants. For their involvement, each participant received a compensation of 150 RMB (approximately 20 USD).\n\nThe experimental procedure commenced with a briefing, after which participants were instructed to remain as still as possible while completing a 20-minute questionnaire. This process, inspired by  McDuff et al. (2014) , involved collecting r-PPG and thermal imaging data to assess physiological responses to cognitive stress caused by prolonged task focus  (Tanaka et al., 2014) .\n\nA built-in camera on a notebook (ThinkPad E310, Lenovo, China) recorded participants' facial reactions. Concurrently, a thermal camera (One Pro, FLIR, US) to their right measured facial temperatures. ECG data (AD8232 ECG module, Sichiray, China) were also gathered using a custom Arduino system. While minimal movement was allowed, participants were encouraged to limit it. Out of 104 participants (21% male, average age 21.33, SD 2.45), ninety viewed a short film on firefighters' sacrifice, aimed at inducing moral elevation. This session's r-PPG and thermal imaging data were used for developing a moral elevation prediction model. Among all participants, 86 provided valid r-PPG data, and 55 yielded valid thermal imaging data. After watching, they completed  Aquino et al.'s (2011)  moral elevation scale, with a t-test validating the film's efficacy in eliciting moral elevation (p < 0.001).",
      "page_start": 7,
      "page_end": 8
    },
    {
      "section_name": "R-Ppg Signal Extraction",
      "text": "This study analyzed all data with the Python package pyMMER (available at https://github.com/8n98324n/pyMMER), developed for this study. PyMMER integrates several publicly available open-source Python packages to help non-technically savvy researchers process and analyze multimodal data for research. For r-PPG data processing, adapting the code from the Python package pyVHR  (Boccignone et al., 2022) , pyMMER first identifies patches of ROIs using MediaPipe Face Mesh and continuously tracks them in all video frames (Figure  1 ). Out of the 468 facial ROI identified in MediaPipe (Google Inc), this study deliberately used only 70 regions, excluding regions close to the edges of the face, lips, and eyes to mitigate the potential interference from spontaneous facial movements and to factor in participants who wore glasses.\n\nFigure  1  The signal processing flow.\n\nPyMMER computes average color intensities for each patch across overlapping windows, producing multiple time-varying RGB signals for each temporal segment. During the signal processing phase, pyMMER utilizes the plane-orthogonal-to-skin (POS) method, as described by  Wang et al. (2016) , to convert these signals into a pulse waveform (blood volume pulse, BVP). As highlighted by  Boccignone et al. (2022) , this method ranks among the top performers in their study. pyMMER then segments the BVP into overlapping six-second windows. For each window, pyMMER determines the HR (measured in beats per minute, BPM) by identifying the most significant frequency in the power spectrum of the wave, generated within the six-second window using Fourier analysis.",
      "page_start": 8,
      "page_end": 9
    },
    {
      "section_name": "Hrv Data Processing",
      "text": "After obtaining BPM data, pyMMER identifies problematic HR points that change by more than 25 beats per minute from the previous points. It then removes either the current or the previous data point that is further from the median HR of the dataset. Subsequently, pyMMER utilizes the R language package RHRV (Martí nez et al., 2017) to calculate HRV measures. If HR or HRV exceeds a predefined threshold, the RHRV package is unable to produce HRV measures, and such data are considered outliers in this study.\n\nThere are two main types of HRV measures: time-domain and frequency-domain. The timedomain indices of HRV quantify variability in the beat-to-beat interval (BBI). This study included three commonly used time-domain measures for comparison: Root Mean Square of Successive Differences (rMSSD), Standard Deviation of NN Intervals (SDNN), and the percentage of NN interval changes larger than 50ms (pNN50). The frequency-domain components of HRV consist of four frequency bands: high frequency (HF), low frequency (LF), very low frequency (VLF), and ultra-low frequency (ULF). Given that this study only recorded five-minute videos and used two-minute segments for analysis, the ULF and VLF bands do not apply  (Shaffer & Ginsberg, 2017) . The HF and LF values were then log-transformed because they were not distributed normally  (Chalmers et al., 2016; Laborde et al., 2017) .",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Ecg Referencing",
      "text": "To ascertain the accuracy of r-PPG, this study compared HRV measurements from the r-PPG against a reference ECG. This study employed the Python package py-ecg-detectors  (Porr et al., 2023)  to transform raw ECG signals into heart rate data, utilizing the QRS detection algorithm proposed by  Elgendi et al. (2010) . This study collected 383 samples with both valid r-PPG and valid ECG data from all participants. Data from three participants were then manually excluded because the data collected from r-PPG and ECG were significantly different, possibly due to collection error. In order to achieve acceptable signal quality, previous studies have argued the importance of using a quality index to filter out potentially corrupted data  (Liu et al., 2020a) . Since there are no established quality criteria for remote PPG results generated from multiple ROIs, this study suggested using the MAE of the HR over HR (MAE/HR) obtained from all ROIs as the quality index. This study then compared the correlation coefficient and p-value of the HR and HRV measures.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Thermal Imaging",
      "text": "",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Results",
      "text": "",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Equipment Accuracy Analysis",
      "text": "",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Ecg Referencing",
      "text": "The ECG referencing analysis showed that the correlation coefficients for HR and all time-domain HRV measures increased almost monotonously when MAE/HR decreased, suggesting that MAE/HR was a robust and effective quality criterion (Table  3 ). Based on these results, this study selected MAE/HR=0.42 as a balanced point for comparison to achieve higher correlation coefficients without losing too many data points. The comparative results indicated that HR and time-domain HRV measures obtained from r-PPG closely corresponded with those derived from ECG, as illustrated in Figure  2 . Specifically, the correlation coefficient for average HR was 0.86, 0.32 for SDNN, 0.24 for rMSSD, and 0.25 for pNN50all achieving statistical significance (p<0.001). The effect sizes were small for the rMSSD, pNN50, and ln(LF), medium for SDNN and large for HR according to Cohen (1992)'s criteria. However, the congruence between ln(HF) produced by r-PPG and those from the reference ECG was not statistically significant.\n\nTable  3  The correlation coefficients of the HRV measures generated by r-PPG and the referencing ECG.",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Mae/ Hr",
      "text": "",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Machine Learning Prediction",
      "text": "This study validated the proposed method by constructing two of the frequently used machine learning models, RF and SVM, to predict mental state changes using the facial temperature and HRV measures generated by thermal imaging and r-PPG respectively. After optimizing parameters through a grid search, the prediction accuracy for attention using r-PPG data with RF was 0.75 and with SVM was 0.77 (Table  4 ). In contrast, for moral elevation, the RF and SVM models achieved accuracies of 0.58 and 0.61, respectively, using r-PPG. Using thermal imaging data, RF and SVM models predicted cognitive stress with accuracies of 0.79 and 0.72, respectively. For moral elevation, the accuracies were 0.78 with RF and 0.75 with SVM using thermal imaging. This study then considered two different multimodal fusion strategies to combine the data. The early fusion strategy directly employed SVM and RF models to analyze the combined features extracted by both r-PPG and thermal imaging  (Zhang et al., 2021) . This approach sought to capitalize on the inherent interdependencies between the data types by integrating them at an early stage before applying machine learning algorithms. Conversely, the late fusion strategy took a sequential approach and applied a decision tree using the Gini index to fuse the independent predictions generated by machine learning models based on two sources. This strategy banked on the strengths of individual modalities before combining them in a unified framework. In the data, the early fusion strategy outperformed the late fusion strategy and the single modal predictions with prediction accuracy of 0.87 and 0.83 using RF for cognitive stress and moral elevation respectively.",
      "page_start": 12,
      "page_end": 13
    },
    {
      "section_name": "Feature Importance Analysis Correlation Analysis",
      "text": "The t-test, heatmap, and correlation coefficient analysis were frequently used tools in the feature engineering process  (Rawat & Khemchandani, 2017) . This study performed a t-test on the changes in the HR and HRV measures between the last 120 seconds to the first 120 seconds (Figure  3 ). The results indicated that HR increased and HRV measures decreased in both the cognitive stress and moral elevation conditions. However, the differences were statistically significant only in the cognitive stress condition. For the thermal imaging data, this study analyzed the difference between the average of the last 120 seconds and the average of the first 120 seconds. The results showed that the temperatures of the lip and cheek increased significantly when people were paying attention to the given task, and the temperatures of the nose, nostril, lip, cheek, and chin increased when the moral elevation was triggered by films [Figure  4    , 1964) , this study followed  (Genno et al., 1997)  to choose forehead as the main comparison area. This comparison revealed that cognitive stress caused a significant relative increase only in the temperature of the lip areas.\n\nThe absolute temperature change of cheek was significant but the relative temperature changes were not. The decrease of temperature in the nose area became much more obvious, but the values did not reach statistical significance level. On the other hand, the conclusion of the relative temperature change of the moral elevation was the same as the absolute changes.",
      "page_start": 13,
      "page_end": 14
    },
    {
      "section_name": "Shap Analysis",
      "text": "To delve deeper into how various features impact the outcomes of black-box machine learning models, this study employed Shapley Additive Explanations (SHAP) analysis using the Python 'shap' package  (Lundberg & Lee, 2017) . The data analysis revealed that both the RF and SVM models predominantly relied on SDNN and rMSSD features when distinguishing participants under cognitive stress caused by attention, as illustrated in Figure  5 . Additionally, the pNN50 feature emerged as a pivotal determinant in distinguishing individuals experiencing moral elevation. For thermal imaging, this study compared the top 10 features in SHAP analysis. The nasal area  (ROI 28, 29, 30) , the eyebrow area  (ROI 18, 25) , the cheeks  (ROI 55, 56, 57) , and the area between the nose and lip  (ROI 34, 49)  were essential features for thermal imaging-based mental state prediction. This study subsequently conducted SHAP analysis for the early fusion analysis. Contrary to expectations, despite thermal imaging outperforming r-PPG in single-modal prediction analysis, features generated by r-PPG dominated the early fusion analysis when variables from both modalities were combined. The important features from thermal imaging appeared to differ in the early fusion analysis compared to those in the single-modal thermal analysis.\n\nFigure  5  Comparison of feature importance based on SHAP analysis.",
      "page_start": 16,
      "page_end": 17
    },
    {
      "section_name": "Linking R-Ppg To Thermal Imaging",
      "text": "Generally, facial temperature was more closely related to HR than HRV in both cognitive stress and moral elevation conditions (Figure  6 ). HR was negatively correlated to the temperature changes of the left eyebrow area and was positively correlated to the changes of the temperature of the cheek and outside of the lip area during the cognitive stress condition. On the other hand, HR was negatively correlated to most ROI when people were morally elevated. The HRV measures generally were less correlated to the temperature changes of the facial areas. Given that most of the correlation coefficients between facial ROIs and both HR and ln(LF)commonly used as indicators of SNS activationwere negative, it appears that SNS activation tends to reduce facial temperature in the majority of facial areas during the moral elevation condition.\n\nFigure  6  Correlation coefficients between HRV measurement changes and regional facial temperature changes.",
      "page_start": 17,
      "page_end": 18
    },
    {
      "section_name": "Discussion Principal Findings",
      "text": "The findings of this study align with the objectives and support the use of r-PPG and thermal imaging in hidden mental state detection based on only facial skin color and temperature changes. More specifically, the results of this study can be summarized in the following aspects:\n\nFirst, this study evaluated the efficacy of the multimodal approach that integrates both either r-PPG and thermal imaging to enhance prediction performance for hidden mental state changes. The accuracy of using r-PPG alone to predict mental states stood at 0.77 (SVM) for cognitive stress and 0.61 (SVM) for moral elevation. Using thermal imaging alone to predict cognitive stress and moral elevation yielded accuracies of 0.79 (RF) and 0.78 (RF), respectively. Remarkably, the early fusion approach elevated these predictive accuracies to 0.87 (RF) for cognitive stress and 0.83 (RF) for moral elevation. These results echoed the results of  Cho et al.,(2019c) , which indicated predictive accuracies for cognitive stress at 68.53% with contact PPG alone, 58.82% using only thermal imaging, and 78.33% when combining both modalities. Furthermore, compared to late fusion strategies, the findings of this study were consistent with findings from several preceding studies  (Gadzicki et al., 2020; Gunes & Piccardi, 2005)  and demonstrated the superior performance of the early fusion method.\n\nIt's noteworthy that SVM and RF models are often used in the same study; however, it is difficult to explain why one model sometimes outperforms the other  (Statnikov et al., 2008) . Ferná ndez-Delgado et al. (  2014 ) reviewed 179 classifiers across 17 categories, concluding that RF was the top performer in their extensive dataset analysis. Contrarily, studies by  Ogutu et al. (2011)  and  Wainberg et al. (2016)  observed superior performances from SVM.  Boateng et al. (2020)  argued that RF performs better when data is scarce, while  Grinsztajn et al. (2022)  found that tree-like models seem to be more robust to uninformative and non-smoothing features. The debate is further complicated by the complexity of parameter optimization; RF's performance is highly sensitive to parameter selection, as found by  Statnikov et al. (2008) , whereas SVM is less sensitive.\n\nIn this study, the unimodal analysis for predicting cognitive stress using both r-PPG and thermal imaging showed accuracies ranging from 0.72 to 0.79. For moral elevation prediction, r-PPG achieved 0.58 to 0.61, while thermal imaging attained 0.75 to 0.78. This indicates comparable SVM and RF performances, though moral elevation is less identifiable through cardiovascular features. In early fusion, integrating all variables, SVM's accuracy is more influenced by loweraccuracy variables, unlike RF, which efficiently utilizes informative features. This conclusion, drawn from a single dataset, necessitates further research for comprehensive understanding.\n\nThe SHAP analysis in this study revealed that in data fusion, cardiovascular features from r-PPG models are more influential than thermal imaging features, despite the latter's superior predictive accuracy as a single modality. This highlights two key insights: first, it underscores the enhanced predictive accuracy and benefits of multimodal fusion, combining diverse data types to overcome individual modality limitations and leveraging their combined strengths for more accurate psychological state predictions. Second, it shows that integrating multiple variables, even those with minor individual impact, significantly improves model performance, emphasizing the importance of considering a broad range of features for a comprehensive and nuanced analysis, rather than focusing only on the most dominant features.\n\nSecond, this study extends the literature on the relationship between emotions and facial temperature, applying this approach for the first time to the study of moral elevation. The data from this study showed that during experiences of moral elevation, individuals showed increased temperatures in the nose, nostrils, lips, cheeks, and chin areas-these physiological responses are clearly related to the vagus nerve system of the parasympathetic nervous system  (Haidt, 2003) .\n\nThe links between cardiovascular features and mental state changes, on the other hand, are less evident, aligning with  Nhan & Chau's (2009)  assertion that facial thermal imaging is more significant than HR (not HRV) and respiration. The findings also underscore  Ioannou et al.'s (2016)  emphasis on the importance of further exploring thermal imaging for ANS analysis, which they claimed traditionally relies heavily on HRV.\n\nMoreover, the correlation coefficient analysis in this study revealed significant temperature increases in the lips and cheeks under cognitive stress, contrasting with previous research indicating that stress typically causes a general decrease in facial temperature, particularly at the nose tip. However, the SHAP analysis, when using the RF model, pinpointed the nose tip as the most predictive variable. This discrepancy can be attributed to two factors. First, the relationship between stress and facial temperature might be nonlinear, meaning it may not be evident in simple correlation analyses but can become apparent in more complex, tree-structured models like RF. Second, the effects of stress on skin temperature could vary based on the stressor. While many studies have induced cognitive stress through social pressure  (Vinkers et al., 2013) ,  Engert et al. (2014)  found inconsistent facial temperature responses under stress caused by physical pain and social pressure. In this study, the cognitive stress, derived from sustained attention, differs from the stress induced by physical pain or social pressure. The increased temperature around the lips and cheeks echoed the finding of  Diaz-Piedra et al. (2019) , who observed that sustained attention influenced arousal levels, initially raising nasal temperatures. However, since  Wang et al. (2019)  did not find a significant correlation between cognitive load and facial expressions in their EEG and thermal imaging study, the link between cognitive stress and facial temperature changes is still inconclusive and warrants further analysis.\n\nThird, this study investigated the direct relationship between HR and facial thermography. Given the impact of SNS activity on HR, HRV, and facial temperature, this study hypothesized a direct link between these two aspects. Yet, this association has seldom been directly studied. The results of this study showed no significant relationship between cardiac features and facial temperature under cognitive stress. However, during moral elevation, a notable negative correlation emerged between HR and the temperature of the eyebrows, nose, cheeks, chin, and throat. Despite the lack of significant changes in HR during moral elevation (Figure  3 ) and in the temperatures of the eyebrows and certain cheek areas (Figure  4 ), a distinct correlation was observed between HR and these temperature areas (Figure  6 ). This suggests concealed relationships between HR and facial temperature, necessitating additional research for a more comprehensive understanding.\n\nLast, The data corroborated prior research, establishing that r-PPG accurately generates HR and HRV for mental state detection, with correlation coefficients of HR and SDNN between r-PPG and reference ECG at 0.86 and 0.32, respectively. Prediction accuracy for cognitive stress and moral elevation was 0.77 and 0.61. Previous studies indicate HR predictions via r-PPG are superior to HRV, especially in time-domain measures compared to frequency-domain HRV  (Kuss et al., 2008) . This study echoes these findings, showing HR and time-domain HRV measures as more effective. Additionally, predictive accuracy for moral elevation was lower than for cognitive stress, suggesting moral elevation may invoke subtler or more complex ANS responses, posing challenges in correlating this emotion with physiological data.\n\nThis study reinforces prior findings on the link between psychological states and HR, particularly in understanding the physiological aspects of moral elevation. Echoing ECG-based  (Eisenberg et al., 1988)  and r-PPG studies  (McDuff et al., 2014) , it observed HR increases under cognitive stress and HRV decreases due to SNS activation. However, moral elevation research is less developed.  Piper et al. (2015)  observed that moral elevation might activate both sympathetic and parasympathetic systems, affecting both HF-HRV and LF-HRV, but supporting literature is limited. This study contributes by showing no significant correlation between HR, HRV, and moral elevation. This could be due to moral elevation's complex nature, often considered a bittersweet emotion  (Oliver et al., 2018) , and its interaction with HR and HRV. Previous research shows mixed results in HR and HRV responses to emotionsfor instance, sadness correlates positively with HRV and negatively with HR  (Eisenberg et al., 1988; Goetz et al., 2010) , while other studies note reduced HRV in sadness compared to happier states  (Goetz et al., 2010; Shi et al., 2017) . The inconsistent results in moral elevation are thus expected. Future research should more precisely classify moral elevation induction methods to clarify its relationship with the ANS.",
      "page_start": 18,
      "page_end": 21
    },
    {
      "section_name": "Limitations",
      "text": "While this study achieved most of its objectives, some data lacked statistical significance, indicating areas for methodological refinement.\n\nFirst, the r-PPG data showed notable noise levels. Although signal processing has advanced, its reliability in real-world applications is still debatable. In this study, the correlation coefficient between r-PPG and ECG for HR reached 0.86 while for HRV measures was found to be only between 0.25 and 0.33, and for MAE accounted more than 20% of the mean values. The agreement with referencing devices and predictive accuracy was below several previous studies. For instance,  McDuff et al. (2014)  reported a correlation coefficient between r-PPG and the reference contacted HR device for HR and HF of 1.00 and 0.93, respectively. Their research also achieved a 0.85 predictive accuracy for cognitive stress when using an SVM model on the r-PPG signal. One possible explanation for the low signal quality was the participants' movement freedom during this experiment. To maintain external validity, this study allowed participant movement, complicating data collection due to r-PPG and thermal imaging's sensitivity to motion. Despite advancements, current facial recognition algorithms, primarily designed for static images, struggled with accuracy during spontaneous movements. Furthermore, following  Pavlidis & Levine (2002) 's methodology, participants were not required to change their hairstyles, resulting in instances where hair bangs obscured thermal signals from the forehead. Additionally, the frequent use of eyeglasses led to the exclusion of periorbital thermal imaging, omitting potential insights from areas like the supraorbital muscle, as noted by  Puri et al. (2005) . Future research should consider adjusting experimental conditions to enhance signal quality.\n\nAdditionally, the HRV measures in this study systematically underestimated HRV in comparison to the reference ECG. This could be due to the 6-second window Fourier Analysis approach to compute HR, a method which provided similar results to the average HR in the 6-second window and inherently lowers the values of the variation of the HR. Future research should weigh the balance between noise reduction and HRV deflation. Furthermore, videos were divided into 120second segments to monitor HRV changes per experimental phase. While some studies supported ultra-short-term HRV analysis, there is no consensus in the literature  (Pecchia et al., 2018) . This less-than-five-minute measuring period might partly explain r-PPG's reduced predictive accuracy as previously mentioned  (Laborde et al., 2017) .\n\nSecond, the thermal imaging signal processing algorithm also requires additional refinement. In the analysis, only 55 out of 90 participants provided valid thermal imaging data, mainly due to ineffective ROI identification. The current model uses Histogram of Oriented Gradients (HOG) and SVM techniques in a two-stage ROI identification process: initially locating the face and then pinpointing specific features. However, it often misinterprets partial facial areas as complete faces in the first stage. This could be due to the limited size and diversity of its training dataset, failing to recognize a variety of face shapes or cases with obscured faces like those with bangs, glasses, or not facing the camera directly. Head movements of participants may exacerbate this issue. The lack of established quality criteria for thermal imaging makes it challenging to filter out compromised data  (Liu et al., 2020a) . Future studies should consider these limitations.\n\nThird this study explored only a limited number of data fusion methods. The exploration was confined to two techniques: early fusion, which overlooks the temporal specifics of thermal imaging, and late fusion, using a straightforward voting method. In early fusion, this study employed a simple strategy of averaging the temperature of each ROI over a two-minute recording to align thermal imaging data with r-PPG results, which represented properties over several minutes. However, this approach potentially lost detailed information. Considering the myriad data fusion strategies available  (Gandhi et al., 2023) , future research could benefit from experimenting with alternative methodologies beyond the singular approach used in this study.\n\nFinally, this study did not sufficiently address the time delay in skin temperature changes. While HR can fluctuate within seconds,  Nakayama et al. (2005)  noted it took 220-280 seconds for nose temperature to revert to baseline. Rodent studies indicated varying return times based on regions: the back, head, and body took around 60-75 minutes, while the eyes, tails, and paws took 14, 10, and 15 minutes respectively  (Vianna & Carrive, 2005) . Future research should consider these delays, especially when there's a minimal gap between stimulus application and data recording.",
      "page_start": 21,
      "page_end": 22
    },
    {
      "section_name": "Conclusions",
      "text": "R-PPG and thermal imaging are increasingly recognized as effective tools for remotely detecting mental states. They are particularly adept at identifying subtle cognitive and emotional shifts that are less obvious in facial expressions and often missed by traditional analysis techniques. This study contributes to the academic community by validating the performance of multimodal data fusion of r-PPG and thermal imaging. It also investigates important features using both statistical analysis and explainable machine learning tools, and explores the interplay between cardiac responses and facial temperature changes in response to ANS activations. The results further corroborate the findings of previous studies regarding the effectiveness of r-PPG and thermal imaging in detecting moral elevation, a relatively understudied area. Additionally, this study has developed the 'pyMMER' package, enhancing tools available to the research community. While still in its initial stages and facing certain challenges, this study highlights the considerable potential of these methods and the importance of their ongoing refinement and optimization. However, the statistical significance of many results fell short of the expected level, highlighting the difficulty in acquiring high-quality real-world data and the challenge in ROI detection for both r-PPG and thermal imaging in more realistic settings. Future studies should compare and explore other techniques for improving prediction accuracy, including state-of-the-art machine learning models  (Lu et al., 2021; Yu et al., 2023) . This would make the proposed method more practically useful.",
      "page_start": 22,
      "page_end": 23
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: ). Out of the 468",
      "page": 8
    },
    {
      "caption": "Figure 1: The signal processing flow.",
      "page": 8
    },
    {
      "caption": "Figure 2: Specifically, the correlation coefficient for average HR was 0.86,",
      "page": 11
    },
    {
      "caption": "Figure 2: Comparison of HRV measures generated by r-PPG and the reference ECG.",
      "page": 12
    },
    {
      "caption": "Figure 3: Heat map of HRV measurement changes induced under both cognitive stress and moral elevation",
      "page": 14
    },
    {
      "caption": "Figure 4: (a)]. Since this study observed the temperature of different areas tended",
      "page": 14
    },
    {
      "caption": "Figure 4: (b)(c)]. Since the temperature",
      "page": 14
    },
    {
      "caption": "Figure 4: Heat maps depicting changes in thermal imaging induced under both cognitive stress and moral elevation",
      "page": 15
    },
    {
      "caption": "Figure 5: Additionally, the pNN50",
      "page": 16
    },
    {
      "caption": "Figure 5: Comparison of feature importance based on SHAP analysis.",
      "page": 17
    },
    {
      "caption": "Figure 6: ). HR was negatively correlated to the temperature",
      "page": 17
    },
    {
      "caption": "Figure 6: Correlation coefficients between HRV measurement changes and regional facial temperature changes.",
      "page": 18
    },
    {
      "caption": "Figure 3: ) and in the temperatures of the",
      "page": 20
    },
    {
      "caption": "Figure 4: ), a distinct correlation was observed between HR and",
      "page": 20
    },
    {
      "caption": "Figure 6: ). This suggests concealed relationships between HR and facial",
      "page": 20
    }
  ],
  "tables": [
    {
      "caption": "Table 1: ) in mental state assessment has gained increasing traction, offering profound insights in fields as",
      "page": 3
    },
    {
      "caption": "Table 1: List of Abbreviations",
      "page": 3
    },
    {
      "caption": "Table 2: The definition of thermal imaging ROIs.",
      "page": 10
    },
    {
      "caption": "Table 3: ). Based on these results, this study",
      "page": 11
    },
    {
      "caption": "Table 3: The correlation coefficients of the HRV measures generated by r-PPG and the referencing ECG.",
      "page": 11
    },
    {
      "caption": "Table 4: ). In contrast, for moral elevation, the RF and SVM",
      "page": 12
    },
    {
      "caption": "Table 4: Prediction accuracy of single-modal and multimodal machine learning models.",
      "page": 13
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Speakingfaces: A large-scale multimodal dataset of voice commands with visual and thermal video streams",
      "authors": [
        "M Abdrakhmanova",
        "A Kuzdeuov",
        "S Jarju",
        "Y Khassanov",
        "M Lewis",
        "H Varol"
      ],
      "year": "2021",
      "venue": "Sensors"
    },
    {
      "citation_id": "2",
      "title": "Witnessing excellence in action: The 'other-praising'emotions of elevation, gratitude, and admiration",
      "authors": [
        "S Algoe",
        "J Haidt"
      ],
      "year": "2009",
      "venue": "The Journal of Positive Psychology"
    },
    {
      "citation_id": "3",
      "title": "Moral identity and the experience of moral elevation in response to acts of uncommon goodness",
      "authors": [
        "K Aquino",
        "B Mcferran",
        "M Laven"
      ],
      "year": "2011",
      "venue": "Journal of Personality and Social Psychology"
    },
    {
      "citation_id": "4",
      "title": "Towards multimodal emotion recognition in elearning environments",
      "authors": [
        "K Bahreini",
        "R Nadolski",
        "W Westera"
      ],
      "year": "2016",
      "venue": "Interactive Learning Environments"
    },
    {
      "citation_id": "5",
      "title": "Evaluation of dynamics of forehead skin temperature under induced drowsiness",
      "authors": [
        "S Bando",
        "K Oiwa",
        "A Nozawa"
      ],
      "year": "2017",
      "venue": "IEEJ Transactions on Electrical and Electronic Engineering"
    },
    {
      "citation_id": "6",
      "title": "Basic Tenets of Classification Algorithms K-Nearest-Neighbor, Support Vector Machine, Random Forest and Neural Network: A Review",
      "authors": [
        "E Boateng",
        "J Otoo",
        "D Abaye"
      ],
      "year": "2020",
      "venue": "Journal of Data Analysis and Information Processing",
      "doi": "10.4236/jdaip.2020.84020"
    },
    {
      "citation_id": "7",
      "title": "pyVHR: A Python framework for remote photoplethysmography",
      "authors": [
        "G Boccignone",
        "D Conte",
        "V Cuculo",
        "A D'amelio",
        "G Grossi",
        "R Lanzarotti",
        "E Mortara"
      ],
      "year": "2022",
      "venue": "PeerJ Computer Science"
    },
    {
      "citation_id": "8",
      "title": "Worry is associated with robust reductions in heart rate variability: A transdiagnostic study of anxiety psychopathology",
      "authors": [
        "J Chalmers",
        "J Heathers",
        "M Abbott",
        "A Kemp",
        "D Quintana"
      ],
      "year": "2016",
      "venue": "Bmc Psychology"
    },
    {
      "citation_id": "9",
      "title": "Nose heat: Exploring stress-induced nasal thermal variability through mobile thermal imaging",
      "authors": [
        "Y Cho",
        "N Bianchi-Berthouze",
        "M Oliveira",
        "C Holloway",
        "S Julier"
      ],
      "year": "2019",
      "venue": "th International Conference on Affective Computing and Intelligent Interaction (ACII)"
    },
    {
      "citation_id": "10",
      "title": "Instant Automated Inference of Perceived Mental Stress through Smartphone PPG and Thermal Imaging",
      "authors": [
        "Y Cho",
        "S Julier",
        "N Bianchi-Berthouze"
      ],
      "year": "2019",
      "venue": "Journal of Medical Internet Research"
    },
    {
      "citation_id": "11",
      "title": "Instant stress: Detection of perceived mental stress through smartphone photoplethysmography and thermal imaging",
      "authors": [
        "Y Cho",
        "S Julier",
        "N Bianchi-Berthouze"
      ],
      "year": "2019",
      "venue": "JMIR Mental Health"
    },
    {
      "citation_id": "12",
      "title": "A power primer",
      "authors": [
        "J Cohen"
      ],
      "year": "1992",
      "venue": "Psychological Bulletin"
    },
    {
      "citation_id": "13",
      "title": "Human emotions detection based on a smart-thermal system of thermographic images",
      "authors": [
        "I Cruz-Albarran",
        "J Benitez-Rangel",
        "R Osornio-Rios",
        "L Morales-Hernandez"
      ],
      "year": "2017",
      "venue": "Infrared Physics & Technology"
    },
    {
      "citation_id": "14",
      "title": "Nasal skin temperature reveals changes in arousal levels due to time on task: An experimental thermal infrared imaging study",
      "authors": [
        "C Diaz-Piedra",
        "E Gomez-Milan",
        "L Di Stasi"
      ],
      "year": "2019",
      "venue": "Applied Ergonomics"
    },
    {
      "citation_id": "15",
      "title": "Facial Expression Recognition based on Hybrid Feature Extraction Techniques with Different Classifiers",
      "authors": [
        "H Dino",
        "M Abdulrazzaq",
        "S Zeebaree",
        "A Sallow",
        "R Zebari",
        "H Shukur",
        "L Haji"
      ],
      "year": "2020",
      "venue": "TEST Engineering & Management"
    },
    {
      "citation_id": "16",
      "title": "Techniques for interpretable machine learning",
      "authors": [
        "M Du",
        "N Liu",
        "X Hu"
      ],
      "year": "2019",
      "venue": "Communications of the ACM"
    },
    {
      "citation_id": "17",
      "title": "Differentiation of vicariously induced emotional reactions in children",
      "authors": [
        "N Eisenberg",
        "R Fabes",
        "D Bustamante",
        "R Mathy",
        "P Miller",
        "E Lindholm"
      ],
      "year": "1988",
      "venue": "Developmental Psychology"
    },
    {
      "citation_id": "18",
      "title": "An argument for basic emotions",
      "authors": [
        "P Ekman"
      ],
      "year": "1992",
      "venue": "Cognition & Emotion"
    },
    {
      "citation_id": "19",
      "title": "On the analysis of fingertip photoplethysmogram signals",
      "authors": [
        "M Elgendi"
      ],
      "year": "2012",
      "venue": "Current Cardiology Reviews"
    },
    {
      "citation_id": "20",
      "title": "Frequency Bands Effects on QRS Detection",
      "authors": [
        "M Elgendi",
        "M Jonkman",
        "F De Boer"
      ],
      "year": "2002",
      "venue": "Biosignals"
    },
    {
      "citation_id": "21",
      "title": "Do we need hundreds of classifiers to solve real world classification problems?",
      "authors": [
        "V Engert",
        "A Merla",
        "J Grant",
        "D Cardone",
        "A Tusche",
        "T Singer",
        "M Cernadas",
        "E Barro",
        "S Amorim"
      ],
      "year": "2014",
      "venue": "The Journal of Machine Learning Research"
    },
    {
      "citation_id": "22",
      "title": "Early vs late fusion in multimodal convolutional neural networks",
      "authors": [
        "K Gadzicki",
        "R Khamsehashari",
        "C Zetzsche"
      ],
      "year": "2020",
      "venue": "IEEE 23rd International Conference on Information Fusion (FUSION)"
    },
    {
      "citation_id": "23",
      "title": "Multimodal sentiment analysis: A systematic review of history, datasets, multimodal fusion methods, applications, challenges and future directions",
      "authors": [
        "A Gandhi",
        "K Adhvaryu",
        "S Poria",
        "E Cambria",
        "A Hussain"
      ],
      "year": "2023",
      "venue": "Information Fusion"
    },
    {
      "citation_id": "24",
      "title": "Using facial skin temperature to objectively evaluate sensations",
      "authors": [
        "H Genno",
        "K Ishikawa",
        "O Kanbara",
        "M Kikumoto",
        "Y Fujiwara",
        "R Suzuki",
        "M Osumi"
      ],
      "year": "1997",
      "venue": "International Journal of Industrial Ergonomics"
    },
    {
      "citation_id": "25",
      "title": "Compassion: An evolutionary analysis and empirical review",
      "authors": [
        "J Goetz",
        "D Keltner",
        "E Simon-Thomas"
      ],
      "year": "2010",
      "venue": "Psychological Bulletin"
    },
    {
      "citation_id": "26",
      "title": "Emotion analysis in children through facial emissivity of infrared thermal imaging",
      "authors": [
        "C Goulart",
        "C Valadã O",
        "D Delisle-Rodriguez",
        "E Caldeira",
        "T Bastos"
      ],
      "year": "2019",
      "venue": "PloS One"
    },
    {
      "citation_id": "27",
      "title": "Why do tree-based models still outperform deep learning on typical tabular data?",
      "authors": [
        "L Grinsztajn",
        "E Oyallon",
        "G Varoquaux"
      ],
      "year": "2022",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "28",
      "title": "Affect recognition from face and body: Early fusion vs. late fusion",
      "authors": [
        "H Gunes",
        "M Piccardi"
      ],
      "year": "2005",
      "venue": "IEEE International Conference on Systems, Man and Cybernetics"
    },
    {
      "citation_id": "29",
      "title": "The Positive emotion of elevation",
      "authors": [
        "J Haidt"
      ],
      "year": "2000",
      "venue": "The Positive emotion of elevation"
    },
    {
      "citation_id": "30",
      "title": "Elevation and the positive psychology of morality. Flourishing: Positive Psychology and the Life Well-Lived",
      "authors": [
        "J Haidt"
      ],
      "year": "2003",
      "venue": "Elevation and the positive psychology of morality. Flourishing: Positive Psychology and the Life Well-Lived"
    },
    {
      "citation_id": "31",
      "title": "Are attainable exemplars more effective at promoting students' moral motivation",
      "authors": [
        "H Han",
        "C Jeong",
        "W Damon",
        "G Cohen"
      ],
      "year": "2015",
      "venue": "Moral Development and Moral Education SIG Paper Session Presentation at the American Educational Research Association 2015 Annual Meeting"
    },
    {
      "citation_id": "32",
      "title": "Measurement of heart rate variability using off-the-shelf smart phones",
      "authors": [
        "R.-Y Huang",
        "L.-R Dung"
      ],
      "year": "2016",
      "venue": "BioMedical Engineering OnLine"
    },
    {
      "citation_id": "33",
      "title": "The autonomic signature of guilt in children: A thermal infrared imaging study",
      "authors": [
        "S Ioannou",
        "S Ebisch",
        "T Aureli",
        "D Bafunno",
        "H Ioannides",
        "D Cardone",
        "B Manini",
        "G Romani",
        "V Gallese",
        "A Merla"
      ],
      "year": "2013",
      "venue": "PloS One"
    },
    {
      "citation_id": "34",
      "title": "Sympathy crying: Insights from infrared thermal imaging on a female sample",
      "authors": [
        "S Ioannou",
        "P Morris",
        "S Terry",
        "M Baker",
        "V Gallese",
        "V Reddy"
      ],
      "year": "2016",
      "venue": "PloS One"
    },
    {
      "citation_id": "35",
      "title": "Self-adversarial Multi-scale Contrastive Learning for Semantic Segmentation of Thermal Facial Images",
      "authors": [
        "J Joshi",
        "N Bianchi-Berthouze",
        "Y Cho"
      ],
      "year": "2022",
      "venue": "Self-adversarial Multi-scale Contrastive Learning for Semantic Segmentation of Thermal Facial Images",
      "arxiv": "arXiv:2209.10700"
    },
    {
      "citation_id": "36",
      "title": "Fingertip temperature as an indicator for sympathetic responses",
      "authors": [
        "A Kistler",
        "C Mariauzouls",
        "K Berlepsch"
      ],
      "year": "1998",
      "venue": "International Journal of Psychophysiology"
    },
    {
      "citation_id": "37",
      "title": "Time domain parameters can be estimated with less statistical error than frequency domain parameters in the analysis of heart rate variability",
      "authors": [
        "O Kuss",
        "B Schumann",
        "A Kluttig",
        "K Greiser",
        "J Haerting"
      ],
      "year": "2008",
      "venue": "Journal of Electrocardiology"
    },
    {
      "citation_id": "38",
      "title": "SF-TL54: A Thermal Facial Landmark Dataset with Visual Pairs",
      "authors": [
        "A Kuzdeuov",
        "D Koishigarina",
        "D Aubakirova",
        "S Abushakimova",
        "H Varol"
      ],
      "year": "2022",
      "venue": "IEEE/SICE International Symposium on System Integration (SII)"
    },
    {
      "citation_id": "39",
      "title": "The face of fear",
      "authors": [
        "J Levine",
        "I Pavlidis",
        "M Cooper"
      ],
      "year": "2001",
      "venue": "The Lancet"
    },
    {
      "citation_id": "40",
      "title": "Enhancing the robustness of smartphone photoplethysmography: A signal quality index approach",
      "authors": [
        "I Liu",
        "S Ni",
        "K Peng"
      ],
      "year": "2020",
      "venue": "Sensors"
    },
    {
      "citation_id": "41",
      "title": "Happiness at your fingertips: Assessing mental health with smartphone photoplethysmogram-based heart rate variability analysis",
      "authors": [
        "I Liu",
        "S Ni",
        "K Peng"
      ],
      "year": "2020",
      "venue": "Telemedicine and E-Health"
    },
    {
      "citation_id": "42",
      "title": "Artificial intelligence and black-box medical decisions: Accuracy versus explainability",
      "authors": [
        "A London"
      ],
      "year": "2019",
      "venue": "Hastings Center Report"
    },
    {
      "citation_id": "43",
      "title": "Dual-gan: Joint bvp and noise modeling for remote physiological measurement",
      "authors": [
        "H Lu",
        "H Han",
        "S Zhou"
      ],
      "year": "2021",
      "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition"
    },
    {
      "citation_id": "44",
      "title": "A unified approach to interpreting model predictions",
      "authors": [
        "S Lundberg",
        "S.-I Lee"
      ],
      "year": "2017",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "45",
      "title": "Heart rate variability analysis with the R package RHRV",
      "authors": [
        "C Martí Nez",
        "A Quintana",
        "X Vila",
        "M Touriño",
        "L Rodrí Guez-Liñares",
        "J Presedo",
        "A Pení N"
      ],
      "year": "2017",
      "venue": "Heart rate variability analysis with the R package RHRV"
    },
    {
      "citation_id": "46",
      "title": "Remote measurement of cognitive stress via heart rate variability",
      "authors": [
        "D Mcduff",
        "S Gontarek",
        "R Picard"
      ],
      "year": "2014",
      "venue": "36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society"
    },
    {
      "citation_id": "47",
      "title": "Towards multimodal sentiment analysis: Harvesting opinions from the web",
      "authors": [
        "L.-P Morency",
        "R Mihalcea",
        "P Doshi"
      ],
      "year": "2011",
      "venue": "Proceedings of the 13th International Conference on Multimodal Interfaces"
    },
    {
      "citation_id": "48",
      "title": "Definitions, methods, and applications in interpretable machine learning",
      "authors": [
        "W Murdoch",
        "C Singh",
        "K Kumbier",
        "R Abbasi-Asl",
        "B Yu"
      ],
      "year": "2019",
      "venue": "Definitions, methods, and applications in interpretable machine learning"
    },
    {
      "citation_id": "49",
      "title": "Decrease in nasal temperature of rhesus monkeys (Macaca mulatta) in negative emotional state",
      "authors": [
        "K Nakayama",
        "S Goto",
        "K Kuraoka",
        "K Nakamura"
      ],
      "year": "2005",
      "venue": "Physiology & Behavior"
    },
    {
      "citation_id": "50",
      "title": "Classifying affective states using thermal infrared imaging of the human face",
      "authors": [
        "B Nhan",
        "T Chau"
      ],
      "year": "2009",
      "venue": "IEEE Transactions on Biomedical Engineering"
    },
    {
      "citation_id": "51",
      "title": "A comparison of random forests, boosting and support vector machines for genomic selection",
      "authors": [
        "J Ogutu",
        "H.-P Piepho",
        "T Schulz-Streeck"
      ],
      "year": "2011",
      "venue": "BMC Proceedings"
    },
    {
      "citation_id": "52",
      "title": "Elevation in response to entertainment portrayals of moral virtue",
      "authors": [
        "M Oliver",
        "T Hartmann",
        "J Woolley"
      ],
      "year": "2012",
      "venue": "Human Communication Research"
    },
    {
      "citation_id": "53",
      "title": "Self-transcendent media experiences: Taking meaningful media to a higher level",
      "authors": [
        "M Oliver",
        "A Raney",
        "M Slater",
        "M Appel",
        "T Hartmann",
        "A Bartsch",
        "F Schneider",
        "S Janicke-Bowles",
        "N Krä Mer",
        "M.-L Mares"
      ],
      "year": "2018",
      "venue": "Journal of Communication"
    },
    {
      "citation_id": "54",
      "title": "Thermal image analysis for polygraph testing",
      "authors": [
        "I Pavlidis",
        "J Levine"
      ],
      "year": "2002",
      "venue": "IEEE Engineering in Medicine and Biology Magazine"
    },
    {
      "citation_id": "55",
      "title": "Are ultra-short heart rate variability features good surrogates of short-term ones? State-of-the-art review and recommendations",
      "authors": [
        "L Pecchia",
        "R Castaldo",
        "L Montesinos",
        "P Melillo"
      ],
      "year": "2018",
      "venue": "Healthcare Technology Letters"
    },
    {
      "citation_id": "56",
      "title": "Autonomic and prefrontal events during moral elevation",
      "authors": [
        "W Piper",
        "L Saslow",
        "S Saturn"
      ],
      "year": "2015",
      "venue": "Biological Psychology"
    },
    {
      "citation_id": "57",
      "title": "Popular ECG R peak detectors written in python",
      "authors": [
        "B Porr",
        "L Howell",
        "I Stournaras",
        "Y Nir"
      ],
      "year": "2023",
      "venue": "Popular ECG R peak detectors written in python",
      "doi": "10.5281/zenodo.7652725"
    },
    {
      "citation_id": "58",
      "title": "StressCam: Non-contact measurement of users' emotional states through thermal imaging",
      "authors": [
        "C Puri",
        "L Olson",
        "I Pavlidis",
        "J Levine",
        "J Starren"
      ],
      "year": "2005",
      "venue": "CHI'05 Extended Abstracts on Human Factors in Computing Systems"
    },
    {
      "citation_id": "59",
      "title": "Measuring heart rate and heart rate variability with smartphone camera",
      "authors": [
        "D Qiao",
        "F Zulkernine",
        "R Masroor",
        "R Rasool",
        "N Jaffar"
      ],
      "year": "2021",
      "venue": "IEEE International Conference on Mobile Data Management (MDM)"
    },
    {
      "citation_id": "60",
      "title": "Feature engineering (FE) tools and techniques for better classification performance",
      "authors": [
        "T Rawat",
        "V Khemchandani"
      ],
      "year": "2017",
      "venue": "International Journal of Innovations in Engineering and Technology"
    },
    {
      "citation_id": "61",
      "title": "The mental and subjective skin: Emotion, empathy, feelings and thermography",
      "authors": [
        "E Salazar-López",
        "E Domí Nguez",
        "V Ramos",
        "J De La Fuente",
        "A Meins",
        "O Iborra",
        "G Gá Lvez",
        "M Rodrí Guez-Artacho",
        "E Gómez-Milá N"
      ],
      "year": "2015",
      "venue": "The mental and subjective skin: Emotion, empathy, feelings and thermography"
    },
    {
      "citation_id": "62",
      "title": "Emotion recognition based on joint visual and audio cues",
      "authors": [
        "N Sebe",
        "I Cohen",
        "T Gevers",
        "T Huang"
      ],
      "year": "2006",
      "venue": "18th International Conference on Pattern Recognition (ICPR'06)"
    },
    {
      "citation_id": "63",
      "title": "An overview of heart rate variability metrics and norms",
      "authors": [
        "F Shaffer",
        "J Ginsberg"
      ],
      "year": "2017",
      "venue": "Frontiers in Public Health",
      "doi": "10.3389/fpubh.2017.00258"
    },
    {
      "citation_id": "64",
      "title": "Differences of heart rate variability between happiness and sadness emotion states: A pilot study",
      "authors": [
        "H Shi",
        "L Yang",
        "L Zhao",
        "Z Su",
        "X Mao",
        "L Zhang",
        "C Liu"
      ],
      "year": "2017",
      "venue": "Journal of Medical and Biological Engineering"
    },
    {
      "citation_id": "65",
      "title": "Moral elevation can induce nursing",
      "authors": [
        "J Silvers",
        "J Haidt"
      ],
      "year": "2008",
      "venue": "Emotion"
    },
    {
      "citation_id": "66",
      "title": "Multimodal emotion recognition in response to videos",
      "authors": [
        "M Soleymani",
        "M Pantic",
        "T Pun"
      ],
      "year": "2011",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "67",
      "title": "A comprehensive comparison of random forests and support vector machines for microarray-based cancer classification",
      "authors": [
        "A Statnikov",
        "L Wang",
        "C Aliferis"
      ],
      "year": "2008",
      "venue": "BMC Bioinformatics"
    },
    {
      "citation_id": "68",
      "title": "Heart Rate Variability and Cardiac Vagal Tone in Psychophysiological Research -Recommendations for Experiment Planning, Data Analysis, and Data Reporting",
      "authors": [
        "Laborde",
        "Emma Sylvain",
        "Julian Mosley",
        "Thayer"
      ],
      "year": "2017",
      "venue": "Frontiers in Psychology"
    },
    {
      "citation_id": "69",
      "title": "Heart rate measurement based on a time-lapse image",
      "authors": [
        "C Takano",
        "Y Ohta"
      ],
      "year": "2007",
      "venue": "Medical Engineering & Physics"
    },
    {
      "citation_id": "70",
      "title": "Neural effects of mental fatigue caused by continuous attention load: A magnetoencephalography study",
      "authors": [
        "M Tanaka",
        "A Ishii",
        "Y Watanabe"
      ],
      "year": "2014",
      "venue": "Brain Research"
    },
    {
      "citation_id": "71",
      "title": "What clinicians want: Contextualizing explainable machine learning for clinical end use",
      "authors": [
        "S Tonekaboni",
        "S Joshi",
        "M Mccradden",
        "A Goldenberg"
      ],
      "year": "2019",
      "venue": "Machine Learning for Healthcare Conference"
    },
    {
      "citation_id": "72",
      "title": "The importance of interpretability and visualization in machine learning for applications in medicine and health care",
      "authors": [
        "A Vellido"
      ],
      "year": "2019",
      "venue": "Neural Computing and Applications"
    },
    {
      "citation_id": "73",
      "title": "Changes in cutaneous and body temperature during and after conditioned fear to context in the rat",
      "authors": [
        "D Vianna",
        "P Carrive"
      ],
      "year": "2005",
      "venue": "European Journal of Neuroscience"
    },
    {
      "citation_id": "74",
      "title": "The effect of stress on core and peripheral body temperature in humans",
      "authors": [
        "C Vinkers",
        "R Penning",
        "J Hellhammer",
        "J Verster",
        "J Klaessens",
        "B Olivier",
        "C Kalkman"
      ],
      "year": "2013",
      "venue": "Stress"
    },
    {
      "citation_id": "75",
      "title": "Are random forests truly the best classifiers?",
      "authors": [
        "M Wainberg",
        "B Alipanahi",
        "B Frey"
      ],
      "year": "2016",
      "venue": "The Journal of Machine Learning Research"
    },
    {
      "citation_id": "76",
      "title": "A natural visible and infrared facial expression database for expression recognition and emotion inference",
      "authors": [
        "S Wang",
        "Z Liu",
        "S Lv",
        "Y Lv",
        "G Wu",
        "P Peng",
        "F Chen",
        "X Wang"
      ],
      "year": "2010",
      "venue": "IEEE Transactions on Multimedia"
    },
    {
      "citation_id": "77",
      "title": "Algorithmic principles of remote PPG",
      "authors": [
        "W Wang",
        "A Den Brinker",
        "S Stuijk",
        "G De Haan"
      ],
      "year": "2016",
      "venue": "IEEE Transactions on Biomedical Engineering"
    },
    {
      "citation_id": "78",
      "title": "Can infrared facial thermography disclose mental workload in indoor thermal environments?",
      "authors": [
        "X Wang",
        "D Li",
        "C Menassa",
        "V Kamat"
      ],
      "year": "2019",
      "venue": "Proceedings of the 1st ACM International Workshop on Urban Building Energy Sensing, Controls, Big Data Analysis, and Visualization"
    },
    {
      "citation_id": "79",
      "title": "Cardiorespiratory information dynamics during mental arithmetic and sustained attention",
      "authors": [
        "D Widjaja",
        "A Montalto",
        "E Vlemincx",
        "D Marinazzo",
        "S Van Huffel",
        "L Faes"
      ],
      "year": "2015",
      "venue": "PLoS One"
    },
    {
      "citation_id": "80",
      "title": "Remote photoplethysmograph signal measurement from facial videos using spatio-temporal networks",
      "authors": [
        "Z Yu",
        "X Li",
        "G Zhao"
      ],
      "year": "2019",
      "venue": "Remote photoplethysmograph signal measurement from facial videos using spatio-temporal networks",
      "arxiv": "arXiv:1905.02419"
    },
    {
      "citation_id": "81",
      "title": "Physformer++: Facial video-based physiological measurement with slowfast temporal difference transformer",
      "authors": [
        "Z Yu",
        "Y Shen",
        "J Shi",
        "H Zhao",
        "Y Cui",
        "J Zhang",
        "P Torr",
        "G Zhao"
      ],
      "year": "2023",
      "venue": "International Journal of Computer Vision"
    },
    {
      "citation_id": "82",
      "title": "Deep multimodal fusion for semantic image segmentation: A survey",
      "authors": [
        "Y Zhang",
        "D Sidibé",
        "O Morel",
        "F Mé Riaudeau"
      ],
      "year": "2021",
      "venue": "Image and Vision Computing"
    },
    {
      "citation_id": "83",
      "title": "Emotion recognition from multiple modalities: Fundamentals and methodologies",
      "authors": [
        "S Zhao",
        "G Jia",
        "J Yang",
        "G Ding",
        "K Keutzer"
      ],
      "year": "2021",
      "venue": "IEEE Signal Processing Magazine"
    }
  ]
}