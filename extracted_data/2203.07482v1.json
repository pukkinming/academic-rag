{
  "paper_id": "2203.07482v1",
  "title": "Audiovisual Affect Assessment And Autonomous Automobiles: Applications",
  "published": "2022-03-14T20:39:02Z",
  "authors": [
    "Björn W. Schuller",
    "Dagmar M. Schuller"
  ],
  "keywords": [
    "Affective Computing",
    "Autonomous Vehicles",
    "Applications"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Emotion and a broader range of affective driver states can be a life decisive factor on the road. While this aspect has been investigated repeatedly, the advent of autonomous automobiles puts a new perspective on the role of computer-based emotion recognition in the car -the passenger's one. This includes amongst others the monitoring of wellbeing during the commute such as to adjust the driving style or to adapt the info-and entertainment. This contribution aims to foresee according challenges and provide potential avenues towards affect modelling in a multimodal \"audiovisual plus x\" on the road context. From the technical end, this concerns holistic passenger modelling and reliable diarisation of the individuals in a vehicle. In conclusion, automated affect analysis has just matured to the point of applicability in autonomous vehicles in first selected use-cases, which will be discussed towards the end.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "There is a general acceptance on affect and emotion recognition in vehicles possessing a multitude of highly desirable use-cases  [4, 14] . However, these usually focus on the necessity to monitor the driver in terms of emotions, for example given their safety relevance  [5] . Accordingly, technical solutions are focusing up to now mainly on the driver in a car  [9, 2, 16, 1] . With the advent of autonomous automobiles becoming an every-day reality at scale, however, this focus will naturally shift, as there simply will not be a (human) driver, but rather passengers. We argue that the shift will thereby happen towards the passengers' affect  [6] . Unfortunately, there is mainly literature up to this point on passengers' affect in an air transportation context beyond few exceptions  [10, 12] . More insight into passenger's affect in a ground transportation context for autonomous vehicles is therefore urgently needed.\n\nIn the following, we want to share a quick view on how this shift from driver's to passenger's affect in (autonomous) automobiles can lead to novel use-cases. Furthermore, we want to fuel a discussion on what technical requirements will arise from such a shift of focus by highlighting selected dominant implications. For the sake of simplicity, we focus on audio and video as modalities -however, one can easily think of similar implications for physiology or further modalities.\n\n2 From Driver's to Passenger's Affect and Emotion Assessment: Applications\n\nLet us first introduce selected applications of human's affect assessment and an autonomous automobile's reaction to it focusing on the passengers rather than the driver. Note that several of these applications arise from the simple question \"which emotional and social competence does a human driver have that an autonomous automobile is expected to take over\". Secondly, these applications arise from changes of the focus of a passenger not being a driver any longer allowing for other activity during a drive.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Driving Style Adaptation",
      "text": "The authors in  [15]  observe in a driving simulator study that there is no significant influence on the emotion of the passenger seated in the front area of a car by whether a human or an autonomous system steers the vehicle. This may lead to the conclusion that just as a human driver would have to monitor the passengers' wellbeing as influenced by the driving style, an autonomous driving system would have to adapt in similar ways. This could, for example, include aspects such as maximum and average driving speed and acceleration, distance to surrounding vehicles, or radius during turn taking.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "Passenger'S Affect'S Influence On Driving Safety",
      "text": "With the human driver as controlling element missing who is aware of passengers' affect and its role in the driving safety, it becomes necessary for the autonomous vehicle to do so. This comes, as passengers' affect can be a crucial safety factor. For example, angry infant passengers may pose a risk due to less controlled, but dangerous actions. As an example, children such as seated on rear seats arguing physically during a drive might carry out less controlled actions such as pushing each others or throwing items potentially hitting buttons in the car, damaging the car, or alike.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Passenger'S Affect'S Influence On Route Planning",
      "text": "Similar to the point above, a human driver would include the real-time monitoring of her or his passengers' affect to make decisions on the route planning. For example, decreased wellbeing of passengers can lead to the decision to make a stop for resting. In worse cases, a decision may be taken to change the route for a hospital or call for help. In addition, past passengers' affect can be used to make decisions on future route planning. For example, engagement can be exploited to estimate interest in revisiting venues  [13] . Finally, a passenger's affect can play a decisive role in favouring shorter over longer routes and vice versa  [8] . However, a car's preference about the stops, paths, and revisiting venues can of course be co-dependent on the preference of its passengers. And, this passengers' preference might not be completely related to their affective state. Likewise, the decision on these routing parameters should best be made with the passengers, as opposed to for them. In this context, the claims made above may be considered as suggestions, as backing up by literature is partially yet to come.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Computer-Mediated Communication",
      "text": "A human driver may also be a mediator in human-to-human conversation, such as when it comes to decide on priorities in route planning. Endowed with emotional competence, future autonomous automobiles may be better equipped for an according task. Furthermore, in case of emergencies such as evacuation of a vehicle in case of an accident, knowledge on a passenger's affect may be of crucial importance. Literature on this issue is mostly available from the air traffic domain, such as  [7] . Clearly, however, according considerations of the role of human communication mediation taking affective aspects into account -in particular in case of an emergency -plays a crucial role in ground transportation alike.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Entertainment And Information Management",
      "text": "With the shift from being a driver to being a passenger, there will be more allowance for entertainment and non-driving related activities and information presentation. According choices and suggestions can be based on the passenger's affect, such as affect-based music, movie, or even computer game recommendation  [3] , or pre-selection and ordering of information depending on stress level, or other affective states.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Technical Implications -Some First Insight",
      "text": "In a second set of items, we discuss most pressing technical implications arising from the anticipated shift of driver to passengers' affect monitoring in tomorrow's autonomous automobiles. Note, however, that we cannot discuss the technical implications in depth in this communication.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Emotional Target And Context",
      "text": "With the shift from driver to passenger, the base assumption of most former driver emotion recognition systems is rendered obsolete that the emotion target is mainly the driving situation. In fact, in a situation where passengers are also experiencing entertainment and information presentation during a transportation, or may communicate more with other passengers or remote communication partners, it will become crucial to identify the affect target if exploiting the affect such as in the above use-cases. For example, if the driving style should be adapted depending on a passenger's affect, a system must identify whether the affect is actually induced by the driving style. Such identification of the emotion target has, however, been largely neglected in audiovisual and general affect recognition systems up to now.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Passenger Diarisation And Priorisation",
      "text": "Given the possibility of multiple passengers in a vehicle, this will require their separation in terms of identifying who is speaking when, or re-identifying individuals in a video feed. As opposed to the present situation in automobiles, where the position in the car defines the role of an individual (driver, non-driver), this assignment of role may vanish in autonomous driving. Further, increasing safety in the future may allow for partial or complete free movement of passengers in tomorrow's autonomous vehicles. Accordingly, the challenge of diarisation of passengers will become significantly more challenging. While passenger diarisation may seem like a trivial problem from today's perspective, especially for video, this may change in the future with passengers moving around more in a car while it is moving, rather than passengers only switching between driving sessions as is mostly the case in today's cars. Re-identification (on video and audio) is also a very mature area of research in computer science, rendering this requirement a more trivial case applying existing techniques. Similarly, detection of multiple faces in the vehicle is addressed to a reasonable degree through existing computer vision algorithms. Lighting and presence of obstacles on the other side is still more of a challenge than distinguishing different faces and can be more challenging with moving passengers.\n\nAt the same time, a prioritisation strategy will be needed for how to cope with affect and emotion as input for decision-making from several individuals in an automobile without a clearly assigned driver. For example, a vehicle may choose to to adapt the driving style to the person feeling the least well.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Passenger Source Separation, Occlusions, And Group Affect",
      "text": "Related to the above, should there be overlap such as speech overtalk, the different sources will need to be separated in order to be able to assess each passenger's affective state. Similarly, if occlusions in the video feed arise due to potentially increased movement during transportation, technical solutions will be needed to cope with these. The automatic recognition of emotion and affect in such a situation is, however, largely being a white-spot in the literature to-date. Depending on the situation and strategy, the assessment of (passenger) group affect, rather than for each individual may additionally be of interest.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Reinforcement Learning",
      "text": "Affective state recognition has by and large been accomplished by supervised learning from human-labelled data or in a semi-supervised manner. In the above named use-cases, however, there exists an affective feedback-loop allowing for future passengers' affect-aware autonomous automobiles to learn in a reinforced manner. This enables to learn on a day-to-day basis from thousands of passengers potentially overcoming the field's ever present and dominant bottleneck of sparse learning data. This could include online learning, i. e., machine learning in a situation where additional data becomes available during execution of inference with the learnt model. While in the online learning context, many kinds of machine learning technique can be used, reinforcement learning would be the one where explicit human labelling would not be needed such as by a car asking every now and then its passengers how they feel. Rather, it would learn from their reactions to better assess their affect. For example, assuming a certain affective state such as fear and changing the driving style to slower speed could be followed by a presumably dissatisfied passenger's affect. This could lead a car to revisit the fear assessment made in the first place for future reference. Other than in unsupervised learning, the interaction context would thus be used to better get to know the passengers from an affective perspective without having to ask them explicitly about their emotions and affects. Thus, reinforcement learning can be considered semi-supervised or weakly supervised, but it may reduce active querying of passengers for their affect in order to get to know them better in a potentially more convenient manner. As a more concrete example, an according vehicle can adapt its driving style or music recommendations based on estimated passengers' affective state. It can then observe the change in passengers' affective state and as a reward function aim at long-term maximum passenger wellbeing. Likewise, a system can improve from interaction with the passengers both on optimising the recognition of passengers' affect and the optimal response patterns.\n\nNote that in the very limited literature on reinforcement learning for improved affect modelling, it could already be shown to be highly effective  [11] .",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Discussion And Future Work",
      "text": "Here, we provided a short listing of potential use-cases, which can neither be complete nor fully comprehensive at all times. All of the use-cases aim to use some degrees of affect to improve users' experience of autonomous vehicles. However, all of the ideas next need to be discussed in depth. In the process of researching these use-case, it will be crucial to further align these (e. g., revisiting venues, route planning discussions, entertainment, etc.) with the main goal of an autonomous vehicle: to take passengers to a destination in a safe way. For example, one error that today's human drivers could make is to rely potentially too much on the affective state of the passengers, e. g., as discussed above, to change speed and acceleration based on passengers' preferences. Therefore, a future concern will be to adapting driving style to passengers' affective states in a well-balanced manner: Obviously, safety will be first, and the car's driving behaviour should change according to passengers' affective states, only if safety is not affected.\n\nThe sketched use-cases are next to be connected with each other leading to an overarching structure. To this end, a model or framework, even a simple theoretical one, would help to link all the possible arising research areas. Having such a framework will then be useful when designing road maps for the research on the future needs of affect assessment in autonomous automobiles. It will also be helpful in identifying potentially missing further important use-cases.\n\nMore thought will further be needed on the technical issues, which in this contribution are sketched in an abstract manner at an early stage. Oncoming work will need to focus on actual technical models or proposals of such models. Similar to a model for use-cases, an early first step will be to aim at a broader theoretical framework also for the technical aspects.\n\nFurthermore, the passenger's affect depends also on their interactions with the vehicle, and importantly, on how much they trust the vehicle. Trust will likewise be a very important moderator that is not purely affective, but will influence passengers' affect and how passengers react to the vehicle's actions. Likewise, questions will arise such as should an autonomous automobile drive more slowly and safely to increase trust (and also, reduce the anxiety of the passenger, even though the drive may be taking longer)? Accordingly, the research into affect in autonomous automobiles will also need to include a model of other psychological variables such as trust.\n\nFuture work will then have to face the changing requirements of affect assessment's application in automobiles ultimately paving the way for increased passenger comfort and wellbeing during autonomous transportation. As automobiles are gradually converging towards full autonomy, and passengers might always want to be able to take part in the driving part at times or to a certain extent, it will further be interesting to also add considerations on affect and its role in semi-autonomous driving.",
      "page_start": 5,
      "page_end": 6
    },
    {
      "section_name": "Conclusion",
      "text": "This paper highlighted some interesting perspectives for discussion and future research on automatic affect assessment and its application in autonomous automobiles of the oncoming generations.\n\nWe argued that with the advent of autonomous automobiles at scale, the focus on driver affect and emotion will shift to passenger's affect and emotion for applications in emotionally intelligent automobiles. A number of exemplary applications and technical implications were discussed. However, only a small selection of most pressing such could be featured herein. Also, some of the claims made above will need further support such as by oncoming user studies. In the course of gaining more insight into actual requirements and passenger preferences, some of the ideas and use cases above will likely need to be revised. Independent of that, however, and overall, one can expect a major shift in affect recognition and exploitation systems in (autonomous) automobiles of the future.",
      "page_start": 6,
      "page_end": 6
    }
  ],
  "figures": [],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "audEERING GmbH, Gilching, Germany": "schuller@IEEE.org"
        },
        {
          "audEERING GmbH, Gilching, Germany": "Abstract. Emotion and a broader range of aﬀective driver states can be"
        },
        {
          "audEERING GmbH, Gilching, Germany": "a life decisive factor on the road. While this aspect has been investigated"
        },
        {
          "audEERING GmbH, Gilching, Germany": "repeatedly, the advent of autonomous automobiles puts a new perspec-"
        },
        {
          "audEERING GmbH, Gilching, Germany": "tive on the role of computer-based emotion recognition in the car – the"
        },
        {
          "audEERING GmbH, Gilching, Germany": "passenger’s one. This includes amongst others the monitoring of wellbe-"
        },
        {
          "audEERING GmbH, Gilching, Germany": "ing during the commute such as to adjust the driving style or to adapt"
        },
        {
          "audEERING GmbH, Gilching, Germany": "the info- and entertainment. This contribution aims to foresee according"
        },
        {
          "audEERING GmbH, Gilching, Germany": "challenges and provide potential avenues towards aﬀect modelling in a"
        },
        {
          "audEERING GmbH, Gilching, Germany": "multimodal “audiovisual plus x” on the road context. From the technical"
        },
        {
          "audEERING GmbH, Gilching, Germany": "end,\nthis concerns holistic passenger modelling and reliable diarisation"
        },
        {
          "audEERING GmbH, Gilching, Germany": "of the individuals in a vehicle.\nIn conclusion, automated aﬀect analysis"
        },
        {
          "audEERING GmbH, Gilching, Germany": "has just matured to the point of applicability in autonomous vehicles in"
        },
        {
          "audEERING GmbH, Gilching, Germany": "ﬁrst selected use-cases, which will be discussed towards the end."
        },
        {
          "audEERING GmbH, Gilching, Germany": "Keywords: Aﬀective Computing · Autonomous Vehicles · Applications."
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "1\nIntroduction": "There is a general acceptance on aﬀect and emotion recognition in vehicles pos-"
        },
        {
          "1\nIntroduction": "sessing a multitude of highly desirable use-cases [4,14]. However, these usually"
        },
        {
          "1\nIntroduction": "focus on the necessity to monitor the driver in terms of emotions,\nfor example"
        },
        {
          "1\nIntroduction": "given their safety relevance [5]. Accordingly, technical solutions are focusing up"
        },
        {
          "1\nIntroduction": "to now mainly on the driver in a car [9,2,16,1]. With the advent of autonomous"
        },
        {
          "1\nIntroduction": "automobiles becoming an every-day reality at scale, however, this focus will nat-"
        },
        {
          "1\nIntroduction": "urally shift, as there simply will not be a (human) driver, but rather passengers."
        },
        {
          "1\nIntroduction": "We argue that the shift will thereby happen towards the passengers’ aﬀect [6]."
        },
        {
          "1\nIntroduction": "Unfortunately, there is mainly literature up to this point on passengers’ aﬀect in"
        },
        {
          "1\nIntroduction": "an air transportation context beyond few exceptions [10,12]. More insight into"
        },
        {
          "1\nIntroduction": "passenger’s aﬀect in a ground transportation context for autonomous vehicles is"
        },
        {
          "1\nIntroduction": "therefore urgently needed."
        },
        {
          "1\nIntroduction": "In the following, we want to share a quick view on how this shift from driver’s"
        },
        {
          "1\nIntroduction": "to passenger’s aﬀect\nin (autonomous) automobiles can lead to novel use-cases."
        },
        {
          "1\nIntroduction": "Furthermore, we want to fuel a discussion on what technical requirements will"
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "2\nB. Schuller and D. Schuller": "arise from such a shift of\nfocus by highlighting selected dominant implications."
        },
        {
          "2\nB. Schuller and D. Schuller": "For the sake of simplicity, we focus on audio and video as modalities – however,"
        },
        {
          "2\nB. Schuller and D. Schuller": "one can easily think of similar implications for physiology or further modalities."
        },
        {
          "2\nB. Schuller and D. Schuller": "2\nFrom Driver’s to Passenger’s Aﬀect and Emotion"
        },
        {
          "2\nB. Schuller and D. Schuller": "Assessment: Applications"
        },
        {
          "2\nB. Schuller and D. Schuller": "Let us ﬁrst introduce selected applications of human’s aﬀect assessment and an"
        },
        {
          "2\nB. Schuller and D. Schuller": "autonomous automobile’s reaction to it focusing on the passengers rather than"
        },
        {
          "2\nB. Schuller and D. Schuller": "the driver. Note that several of these applications arise from the simple question"
        },
        {
          "2\nB. Schuller and D. Schuller": "“which emotional and social\ncompetence does a human driver have\nthat an"
        },
        {
          "2\nB. Schuller and D. Schuller": "autonomous automobile is expected to take over”. Secondly, these applications"
        },
        {
          "2\nB. Schuller and D. Schuller": "arise from changes of\nthe\nfocus of a passenger not being a driver any longer"
        },
        {
          "2\nB. Schuller and D. Schuller": "allowing for other activity during a drive."
        },
        {
          "2\nB. Schuller and D. Schuller": "2.1\nDriving Style Adaptation"
        },
        {
          "2\nB. Schuller and D. Schuller": "The authors\nin [15] observe in a driving simulator\nstudy that\nthere is no sig-"
        },
        {
          "2\nB. Schuller and D. Schuller": "niﬁcant inﬂuence on the emotion of the passenger seated in the front area of a"
        },
        {
          "2\nB. Schuller and D. Schuller": "car by whether a human or an autonomous system steers the vehicle. This may"
        },
        {
          "2\nB. Schuller and D. Schuller": "lead to the conclusion that\njust as a human driver would have to monitor\nthe"
        },
        {
          "2\nB. Schuller and D. Schuller": "passengers’ wellbeing as inﬂuenced by the driving style, an autonomous driving"
        },
        {
          "2\nB. Schuller and D. Schuller": "system would have to adapt\nin similar ways. This could,\nfor example,\ninclude"
        },
        {
          "2\nB. Schuller and D. Schuller": "aspects such as maximum and average driving speed and acceleration, distance"
        },
        {
          "2\nB. Schuller and D. Schuller": "to surrounding vehicles, or radius during turn taking."
        },
        {
          "2\nB. Schuller and D. Schuller": "2.2\nPassenger’s Aﬀect’s Inﬂuence on Driving Safety"
        },
        {
          "2\nB. Schuller and D. Schuller": "With the human driver as controlling element missing who is aware of passengers’"
        },
        {
          "2\nB. Schuller and D. Schuller": "aﬀect and its role in the driving safety,\nit becomes necessary for the autonomous"
        },
        {
          "2\nB. Schuller and D. Schuller": "vehicle to do so. This comes, as passengers’ aﬀect can be a crucial safety factor."
        },
        {
          "2\nB. Schuller and D. Schuller": "For example, angry infant passengers may pose a risk due to less controlled, but"
        },
        {
          "2\nB. Schuller and D. Schuller": "dangerous actions. As an example, children such as seated on rear seats arguing"
        },
        {
          "2\nB. Schuller and D. Schuller": "physically during a drive might carry out less controlled actions such as pushing"
        },
        {
          "2\nB. Schuller and D. Schuller": "each others or throwing items potentially hitting buttons in the car, damaging"
        },
        {
          "2\nB. Schuller and D. Schuller": "the car, or alike."
        },
        {
          "2\nB. Schuller and D. Schuller": "2.3\nPassenger’s Aﬀect’s Inﬂuence on Route Planning"
        },
        {
          "2\nB. Schuller and D. Schuller": "Similar to the point above, a human driver would include the real-time monitor-"
        },
        {
          "2\nB. Schuller and D. Schuller": "ing of her or his passengers’ aﬀect to make decisions on the route planning. For"
        },
        {
          "2\nB. Schuller and D. Schuller": "example, decreased wellbeing of passengers can lead to the decision to make a"
        },
        {
          "2\nB. Schuller and D. Schuller": "stop for resting. In worse cases, a decision may be taken to change the route for a"
        },
        {
          "2\nB. Schuller and D. Schuller": "hospital or call for help. In addition, past passengers’ aﬀect can be used to make"
        },
        {
          "2\nB. Schuller and D. Schuller": "decisions on future route planning. For example, engagement can be exploited to"
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n3": "estimate interest in revisiting venues [13]. Finally, a passenger’s aﬀect can play"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n3": "a decisive role in favouring shorter over longer routes and vice versa [8]."
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n3": "However, a car’s preference about\nthe\nstops, paths, and revisiting venues"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n3": "can of\ncourse be\nco-dependent on the preference of\nits passengers. And,\nthis"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n3": "passengers’ preference might not be completely related to their aﬀective state."
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n3": "Likewise,\nthe decision on these routing parameters\nshould best be made with"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n3": "the passengers, as opposed to for them.\nIn this context, the claims made above"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n3": "may be considered as suggestions, as backing up by literature is partially yet to"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n3": "come."
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n3": "2.4\nComputer-mediated Communication"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n3": "A human driver may also be a mediator in human-to-human conversation, such"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n3": "as when it comes to decide on priorities in route planning. Endowed with emo-"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n3": "tional competence,\nfuture autonomous automobiles may be better equipped for"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n3": "an according task. Furthermore,\nin case of emergencies such as evacuation of a"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n3": "vehicle in case of an accident, knowledge on a passenger’s aﬀect may be of crucial"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n3": "importance. Literature on this issue is mostly available from the air traﬃc do-"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n3": "main, such as [7]. Clearly, however, according considerations of the role of human"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n3": "communication mediation taking aﬀective aspects\ninto account – in particular"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n3": "in case of an emergency – plays a crucial role in ground transportation alike."
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n3": "2.5\nEntertainment and Information Management"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n3": "With the\nshift\nfrom being a driver\nto being a passenger,\nthere will be more"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n3": "allowance for entertainment and non-driving related activities and information"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n3": "presentation. According choices and suggestions can be based on the passenger’s"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n3": "aﬀect, such as aﬀect-based music, movie, or even computer game recommenda-"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n3": "tion [3], or pre-selection and ordering of\ninformation depending on stress level,"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n3": "or other aﬀective states."
        }
      ],
      "page": 3
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "4\nB. Schuller and D. Schuller": "partners,\nit will become crucial to identify the aﬀect target if exploiting the af-"
        },
        {
          "4\nB. Schuller and D. Schuller": "fect such as in the above use-cases. For example,\nif the driving style should be"
        },
        {
          "4\nB. Schuller and D. Schuller": "adapted depending on a passenger’s aﬀect, a system must identify whether the"
        },
        {
          "4\nB. Schuller and D. Schuller": "aﬀect\nis actually induced by the driving style. Such identiﬁcation of\nthe emo-"
        },
        {
          "4\nB. Schuller and D. Schuller": "tion target has, however, been largely neglected in audiovisual and general aﬀect"
        },
        {
          "4\nB. Schuller and D. Schuller": "recognition systems up to now."
        },
        {
          "4\nB. Schuller and D. Schuller": "3.2\nPassenger Diarisation and Priorisation"
        },
        {
          "4\nB. Schuller and D. Schuller": "Given the possibility of multiple passengers in a vehicle, this will require their"
        },
        {
          "4\nB. Schuller and D. Schuller": "separation in terms of\nidentifying who is speaking when, or re-identifying indi-"
        },
        {
          "4\nB. Schuller and D. Schuller": "viduals in a video feed. As opposed to the present situation in automobiles, where"
        },
        {
          "4\nB. Schuller and D. Schuller": "the position in the car deﬁnes the role of an individual (driver, non-driver), this"
        },
        {
          "4\nB. Schuller and D. Schuller": "assignment of role may vanish in autonomous driving. Further,\nincreasing safety"
        },
        {
          "4\nB. Schuller and D. Schuller": "in the\nfuture may allow for partial or\ncomplete\nfree movement of passengers"
        },
        {
          "4\nB. Schuller and D. Schuller": "in tomorrow’s autonomous vehicles. Accordingly, the challenge of diarisation of"
        },
        {
          "4\nB. Schuller and D. Schuller": "passengers will become\nsigniﬁcantly more\nchallenging. While passenger diari-"
        },
        {
          "4\nB. Schuller and D. Schuller": "sation may seem like a trivial problem from today’s perspective, especially for"
        },
        {
          "4\nB. Schuller and D. Schuller": "video, this may change in the future with passengers moving around more in a"
        },
        {
          "4\nB. Schuller and D. Schuller": "car while it\nis moving,\nrather\nthan passengers only switching between driving"
        },
        {
          "4\nB. Schuller and D. Schuller": "sessions as\nis mostly the case in today’s cars. Re-identiﬁcation (on video and"
        },
        {
          "4\nB. Schuller and D. Schuller": "audio) is also a very mature area of research in computer science, rendering this"
        },
        {
          "4\nB. Schuller and D. Schuller": "requirement a more trivial case applying existing techniques. Similarly, detec-"
        },
        {
          "4\nB. Schuller and D. Schuller": "tion of multiple faces in the vehicle is addressed to a reasonable degree through"
        },
        {
          "4\nB. Schuller and D. Schuller": "existing computer vision algorithms. Lighting and presence of obstacles on the"
        },
        {
          "4\nB. Schuller and D. Schuller": "other side is still more of a challenge than distinguishing diﬀerent faces and can"
        },
        {
          "4\nB. Schuller and D. Schuller": "be more challenging with moving passengers."
        },
        {
          "4\nB. Schuller and D. Schuller": "At\nthe same time, a prioritisation strategy will be needed for how to cope"
        },
        {
          "4\nB. Schuller and D. Schuller": "with aﬀect and emotion as\ninput\nfor decision-making from several\nindividuals"
        },
        {
          "4\nB. Schuller and D. Schuller": "in an automobile without a clearly assigned driver. For example, a vehicle may"
        },
        {
          "4\nB. Schuller and D. Schuller": "choose to to adapt the driving style to the person feeling the least well."
        },
        {
          "4\nB. Schuller and D. Schuller": "3.3\nPassenger Source Separation, Occlusions, and Group Aﬀect"
        },
        {
          "4\nB. Schuller and D. Schuller": "Related to the above, should there be overlap such as speech overtalk, the diﬀer-"
        },
        {
          "4\nB. Schuller and D. Schuller": "ent sources will need to be separated in order to be able to assess each passenger’s"
        },
        {
          "4\nB. Schuller and D. Schuller": "aﬀective state. Similarly,\nif occlusions in the video feed arise due to potentially"
        },
        {
          "4\nB. Schuller and D. Schuller": "increased movement during transportation, technical solutions will be needed to"
        },
        {
          "4\nB. Schuller and D. Schuller": "cope with these. The automatic recognition of emotion and aﬀect in such a situ-"
        },
        {
          "4\nB. Schuller and D. Schuller": "ation is, however, largely being a white-spot in the literature to-date. Depending"
        },
        {
          "4\nB. Schuller and D. Schuller": "on the situation and strategy, the assessment of (passenger) group aﬀect, rather"
        },
        {
          "4\nB. Schuller and D. Schuller": "than for each individual may additionally be of\ninterest."
        },
        {
          "4\nB. Schuller and D. Schuller": "3.4\nReinforcement Learning"
        },
        {
          "4\nB. Schuller and D. Schuller": "Aﬀective state recognition has by and large been accomplished by supervised"
        },
        {
          "4\nB. Schuller and D. Schuller": "learning from human-labelled data or in a semi-supervised manner. In the above"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n5": "named use-cases, however,\nthere exists an aﬀective feedback-loop allowing for"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n5": "future passengers’ aﬀect-aware autonomous automobiles to learn in a reinforced"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n5": "manner. This enables to learn on a day-to-day basis from thousands of passen-"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n5": "gers potentially overcoming the ﬁeld’s ever present and dominant bottleneck of"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n5": "sparse learning data. This could include online learning,\ni. e., machine learning"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n5": "in a situation where additional data becomes available during execution of\nin-"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n5": "ference with the learnt model. While in the online learning context, many kinds"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n5": "of machine learning technique can be used, reinforcement learning would be the"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n5": "one where explicit human labelling would not be needed such as by a car asking"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n5": "every now and then its passengers how they feel. Rather,\nit would learn from"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n5": "their reactions to better assess their aﬀect. For example, assuming a certain af-"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n5": "fective state such as fear and changing the driving style to slower speed could be"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n5": "followed by a presumably dissatisﬁed passenger’s aﬀect. This could lead a car to"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n5": "revisit the fear assessment made in the ﬁrst place for future reference. Other than"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n5": "in unsupervised learning, the interaction context would thus be used to better"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n5": "get to know the passengers from an aﬀective perspective without having to ask"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n5": "them explicitly about their emotions and aﬀects. Thus, reinforcement learning"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n5": "can be considered semi-supervised or weakly supervised, but it may reduce ac-"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n5": "tive querying of passengers for their aﬀect in order to get to know them better"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n5": "in a potentially more convenient manner."
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n5": "As a more concrete example, an according vehicle can adapt its driving style"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n5": "or music recommendations based on estimated passengers’ aﬀective state. It can"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n5": "then observe the change in passengers’ aﬀective state and as a reward function"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n5": "aim at\nlong-term maximum passenger wellbeing. Likewise, a system can im-"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n5": "prove from interaction with the passengers both on optimising the recognition"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n5": "of passengers’ aﬀect and the optimal response patterns."
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n5": "Note\nthat\nin the very limited literature on reinforcement\nlearning for\nim-"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications\n5": "proved aﬀect modelling,\nit could already be shown to be highly eﬀective [11]."
        }
      ],
      "page": 5
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "6\nB. Schuller and D. Schuller": "The\nsketched use-cases are next\nto be\nconnected with each other\nleading"
        },
        {
          "6\nB. Schuller and D. Schuller": "to an overarching structure. To this end, a model or framework, even a simple"
        },
        {
          "6\nB. Schuller and D. Schuller": "theoretical one, would help to link all the possible arising research areas. Having"
        },
        {
          "6\nB. Schuller and D. Schuller": "such a framework will then be useful when designing road maps for the research"
        },
        {
          "6\nB. Schuller and D. Schuller": "on the future needs of aﬀect assessment in autonomous automobiles. It will also"
        },
        {
          "6\nB. Schuller and D. Schuller": "be helpful\nin identifying potentially missing further important use-cases."
        },
        {
          "6\nB. Schuller and D. Schuller": "More thought will\nfurther be needed on the technical\nissues, which in this"
        },
        {
          "6\nB. Schuller and D. Schuller": "contribution are sketched in an abstract manner at an early stage. Oncoming"
        },
        {
          "6\nB. Schuller and D. Schuller": "work will need to focus on actual technical models or proposals of such models."
        },
        {
          "6\nB. Schuller and D. Schuller": "Similar to a model for the use-cases, an early ﬁrst step will be to aim at a broader"
        },
        {
          "6\nB. Schuller and D. Schuller": "theoretical\nframework also for the technical aspects."
        },
        {
          "6\nB. Schuller and D. Schuller": "Furthermore, the passenger’s aﬀect depends also on their\ninteractions with"
        },
        {
          "6\nB. Schuller and D. Schuller": "the vehicle, and importantly, on how much they trust\nthe vehicle. Trust will"
        },
        {
          "6\nB. Schuller and D. Schuller": "likewise be a very important moderator\nthat\nis not purely aﬀective, but will"
        },
        {
          "6\nB. Schuller and D. Schuller": "inﬂuence passengers’ aﬀect and how passengers\nreact\nto the vehicle’s actions."
        },
        {
          "6\nB. Schuller and D. Schuller": "Likewise, questions will arise such as\nshould an autonomous automobile drive"
        },
        {
          "6\nB. Schuller and D. Schuller": "more slowly and safely to increase trust (and also, reduce the anxiety of the pas-"
        },
        {
          "6\nB. Schuller and D. Schuller": "senger, even though the drive may be taking longer)? Accordingly, the research"
        },
        {
          "6\nB. Schuller and D. Schuller": "into aﬀect in autonomous automobiles will also need to include a model of other"
        },
        {
          "6\nB. Schuller and D. Schuller": "psychological variables such as trust."
        },
        {
          "6\nB. Schuller and D. Schuller": "Future work will\nthen have to face the changing requirements of aﬀect as-"
        },
        {
          "6\nB. Schuller and D. Schuller": "sessment’s application in automobiles ultimately paving the way for\nincreased"
        },
        {
          "6\nB. Schuller and D. Schuller": "passenger comfort and wellbeing during autonomous\ntransportation. As auto-"
        },
        {
          "6\nB. Schuller and D. Schuller": "mobiles are gradually converging towards full autonomy, and passengers might"
        },
        {
          "6\nB. Schuller and D. Schuller": "always want to be able to take part in the driving part at times or to a certain"
        },
        {
          "6\nB. Schuller and D. Schuller": "extent,\nit will\nfurther be interesting to also add considerations on aﬀect and its"
        },
        {
          "6\nB. Schuller and D. Schuller": "role in semi-autonomous driving."
        }
      ],
      "page": 6
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications": "Acknowledgement",
          "7": ""
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications": "",
          "7": ""
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications": "",
          "7": ""
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications": "",
          "7": ""
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications": "",
          "7": ""
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications": "",
          "7": "The authors would like to thank the anonymous reviewers for their valuable"
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications": "",
          "7": ""
        },
        {
          "Audiovisual Aﬀect Assessment and Autonomous Automobiles: Applications": "",
          "7": ""
        }
      ],
      "page": 7
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "References": "1. Abdi´c,\nI., Fridman, L., McDuﬀ, D., Marchi, E., Reimer, B., Schuller, B.: Driver"
        },
        {
          "References": "frustration detection from audio and video in the wild.\nIn: Proceedings of\nthe"
        },
        {
          "References": "Twenty-Fifth International Joint Conference on Artiﬁcial Intelligence (IJCAI). pp."
        },
        {
          "References": "1354–1360. AAAI Press (2016)"
        },
        {
          "References": "2. Boril, H., Sadjadi, S.O., Hansen, J.H.: UTDrive: Emotion and cognitive load clas-"
        },
        {
          "References": "siﬁcation for in-vehicle scenarios. In: Proceedings of the 5th Biennial Workshop on"
        },
        {
          "References": "Digital Signal Processing for In-Vehicle Systems. Kiel, Germany (2011)"
        },
        {
          "References": "3. Deng, J.J., Leung, C.: Emotion-based music recommendation using audio features"
        },
        {
          "References": "and user playlist.\nIn: Proceedings\nof\nthe 6th International Conference on New"
        },
        {
          "References": "Trends\nin Information Science, Service Science and Data Mining (ISSDM). pp."
        },
        {
          "References": "796–801.\nIEEE, Taipei, Taiwan (2012)"
        },
        {
          "References": "4. Eyben, F., W¨ollmer, M., Poitschke, T., Schuller, B., Blaschke, C., F¨arber, B.,"
        },
        {
          "References": "Nguyen-Thien, N.: Emotion on the road—necessity, acceptance, and feasibility of"
        },
        {
          "References": "aﬀective\ncomputing in the\ncar. Advances\nin human-computer\ninteraction 2010"
        },
        {
          "References": "(2010)"
        },
        {
          "References": "5. Hu, T.Y., Xie, X., Li, J.: Negative or positive? the eﬀect of emotion and mood on"
        },
        {
          "References": "risky driving. Transportation research part F: Traﬃc Psychology and Behaviour"
        },
        {
          "References": "16, 29–40 (2013)"
        },
        {
          "References": "6. Launonen, P., Salonen, A.O., Liimatainen, H.: Icy roads and urban environments."
        },
        {
          "References": "passenger experiences in autonomous vehicles in ﬁnland. Transportation research"
        },
        {
          "References": "part F: traﬃc psychology and behaviour 80, 34–48 (2021)"
        },
        {
          "References": "7. Miyoshi, T., Nakayasu, H., Ueno, Y., Patterson, P.: An emergency aircraft evac-"
        },
        {
          "References": "uation simulation considering passenger emotions. Computers & Industrial Engi-"
        },
        {
          "References": "neering 62(3), 746–754 (2012)"
        },
        {
          "References": "8. Morris, E.A., Guerra, E.: Are we there yet? trip duration and mood during travel."
        },
        {
          "References": "Transportation research part F: Traﬃc Psychology and Behaviour 33, 38–47 (2015)"
        },
        {
          "References": "9. Nass, C., Jonsson,\nI.M., Harris, H., Reaves, B., Endo, J., Brave, S., Takayama,"
        },
        {
          "References": "L.: Improving automotive safety by pairing driver emotion and car voice emotion."
        },
        {
          "References": "In: Proceedings of CHI’05 – Extended Abstracts on Human Factors in Computing"
        },
        {
          "References": "Systems. pp. 1973–1976. ACM, Portland, Oregon, USA (2005)"
        },
        {
          "References": "10. Raue, M., D’Ambrosio, L.A., Ward, C., Lee, C., Jacquillat, C., Coughlin, J.F.: The"
        },
        {
          "References": "inﬂuence of feelings while driving regular cars on the perception and acceptance of"
        },
        {
          "References": "self-driving cars. Risk analysis 39(2), 358–374 (2019)"
        },
        {
          "References": "11. Rudovic, O., Zhang, M., Schuller, B., Picard, R.: Multi-modal Active Learning"
        },
        {
          "References": "Using Reinforcement Learning.\nIn: Proceedings\nof\nthe 21st ACM International"
        },
        {
          "References": "Conference on Multimodal\nInteraction. ACM, Suzhou, China (October 2019), 10"
        },
        {
          "References": "pages"
        }
      ],
      "page": 7
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "8": "12.",
          "B. Schuller and D. Schuller": "Sini, J., Marceddu, A.C., Violante, M., Dess`ı, R.: Passengers’ emotions recognition"
        },
        {
          "8": "",
          "B. Schuller and D. Schuller": "to improve\nsocial\nacceptance of autonomous driving vehicles.\nIn: Progresses\nin"
        },
        {
          "8": "",
          "B. Schuller and D. Schuller": "Artiﬁcial Intelligence and Neural Systems, pp. 25–32. Springer (2021)"
        },
        {
          "8": "13. Vittersø, J., Prebensen, N.K., Hetland, A., Dahl, T.: The emotional traveler: hap-",
          "B. Schuller and D. Schuller": ""
        },
        {
          "8": "",
          "B. Schuller and D. Schuller": "piness and engagement as predictors of behavioral\nintentions among tourists\nin"
        },
        {
          "8": "",
          "B. Schuller and D. Schuller": "northern norway. In: Advances in hospitality and leisure, pp. 3–16. Emerald Pub-"
        },
        {
          "8": "",
          "B. Schuller and D. Schuller": "lishing Limited (2017)"
        },
        {
          "8": "14. V¨ogel, H.J., S¨uß, C., Hubregtsen, T., Andr´e, E., Schuller, B., H¨arri, J., Conradt,",
          "B. Schuller and D. Schuller": ""
        },
        {
          "8": "",
          "B. Schuller and D. Schuller": "J., Adi, A., Zadorojniy, A., Terken, J., et al.: Emotion-awareness\nfor\nintelligent"
        },
        {
          "8": "",
          "B. Schuller and D. Schuller": "vehicle assistants: A research agenda. In: Proceedings of the 2018 IEEE/ACM 1st"
        },
        {
          "8": "",
          "B. Schuller and D. Schuller": "International Workshop on Software Engineering for AI\nin Autonomous Systems"
        },
        {
          "8": "",
          "B. Schuller and D. Schuller": "(SEFAIAS). pp. 11–15.\nIEEE, Gothenburg, Sweden (2018)"
        },
        {
          "8": "15. Wintersberger, P., Riener, A., Frison, A.K.: Automated driving system, male, or",
          "B. Schuller and D. Schuller": ""
        },
        {
          "8": "",
          "B. Schuller and D. Schuller": "female driver: Who’d you prefer? comparative analysis of passengers’ mental con-"
        },
        {
          "8": "",
          "B. Schuller and D. Schuller": "ditions,\nemotional\nstates & qualitative\nfeedback.\nIn: Proceedings of\nthe 8th In-"
        },
        {
          "8": "",
          "B. Schuller and D. Schuller": "ternational Conference on Automotive User\nInterfaces and Interactive Vehicular"
        },
        {
          "8": "",
          "B. Schuller and D. Schuller": "Applications (AutomotiveUI). pp. 51–58. ACM, Ann Arbor, Michigan, USA (2016)"
        },
        {
          "8": "16. W¨ollmer, M., Blaschke, C., Schindl, T., Schuller, B., Farber, B., Mayer, S., Tref-",
          "B. Schuller and D. Schuller": ""
        },
        {
          "8": "",
          "B. Schuller and D. Schuller": "ﬂich, B.: Online driver distraction detection using long short-term memory. IEEE"
        },
        {
          "8": "",
          "B. Schuller and D. Schuller": "Transactions on Intelligent Transportation Systems 12(2), 574–582 (2011)"
        }
      ],
      "page": 8
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Driver frustration detection from audio and video in the wild",
      "authors": [
        "I Abdić",
        "L Fridman",
        "D Mcduff",
        "E Marchi",
        "B Reimer",
        "B Schuller"
      ],
      "year": "2016",
      "venue": "Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence (IJCAI)"
    },
    {
      "citation_id": "2",
      "title": "UTDrive: Emotion and cognitive load classification for in-vehicle scenarios",
      "authors": [
        "H Boril",
        "S Sadjadi",
        "J Hansen"
      ],
      "year": "2011",
      "venue": "Proceedings of the 5th Biennial Workshop on Digital Signal Processing for In-Vehicle Systems"
    },
    {
      "citation_id": "3",
      "title": "Emotion-based music recommendation using audio features and user playlist",
      "authors": [
        "J Deng",
        "C Leung"
      ],
      "year": "2012",
      "venue": "Proceedings of the 6th International Conference on New Trends in Information Science, Service Science and Data Mining (ISSDM)"
    },
    {
      "citation_id": "4",
      "title": "Emotion on the road-necessity, acceptance, and feasibility of affective computing in the car",
      "authors": [
        "F Eyben",
        "M Wöllmer",
        "T Poitschke",
        "B Schuller",
        "C Blaschke",
        "B Färber",
        "N Nguyen-Thien"
      ],
      "year": "2010",
      "venue": "Advances in human-computer interaction 2010"
    },
    {
      "citation_id": "5",
      "title": "Negative or positive? the effect of emotion and mood on risky driving",
      "authors": [
        "T Hu",
        "X Xie",
        "J Li"
      ],
      "year": "2013",
      "venue": "Transportation research part F: Traffic Psychology and Behaviour"
    },
    {
      "citation_id": "6",
      "title": "Icy roads and urban environments. passenger experiences in autonomous vehicles in finland",
      "authors": [
        "P Launonen",
        "A Salonen",
        "H Liimatainen"
      ],
      "year": "2021",
      "venue": "Transportation research part F: traffic psychology and behaviour"
    },
    {
      "citation_id": "7",
      "title": "An emergency aircraft evacuation simulation considering passenger emotions",
      "authors": [
        "T Miyoshi",
        "H Nakayasu",
        "Y Ueno",
        "P Patterson"
      ],
      "year": "2012",
      "venue": "Computers & Industrial Engineering"
    },
    {
      "citation_id": "8",
      "title": "Are we there yet? trip duration and mood during travel",
      "authors": [
        "E Morris",
        "E Guerra"
      ],
      "year": "2015",
      "venue": "Transportation research part F: Traffic Psychology and Behaviour"
    },
    {
      "citation_id": "9",
      "title": "Improving automotive safety by pairing driver emotion and car voice emotion",
      "authors": [
        "C Nass",
        "I Jonsson",
        "H Harris",
        "B Reaves",
        "J Endo",
        "S Brave",
        "L Takayama"
      ],
      "year": "2005",
      "venue": "Proceedings of CHI'05 -Extended Abstracts on Human Factors in Computing Systems"
    },
    {
      "citation_id": "10",
      "title": "The influence of feelings while driving regular cars on the perception and acceptance of self-driving cars",
      "authors": [
        "M Raue",
        "L D'ambrosio",
        "C Ward",
        "C Lee",
        "C Jacquillat",
        "J Coughlin"
      ],
      "year": "2019",
      "venue": "Risk analysis"
    },
    {
      "citation_id": "11",
      "title": "Multi-modal Active Learning Using Reinforcement Learning",
      "authors": [
        "O Rudovic",
        "M Zhang",
        "B Schuller",
        "R Picard"
      ],
      "year": "2019",
      "venue": "Proceedings of the 21st ACM International Conference on Multimodal Interaction"
    },
    {
      "citation_id": "12",
      "title": "Passengers' emotions recognition to improve social acceptance of autonomous driving vehicles",
      "authors": [
        "J Sini",
        "A Marceddu",
        "M Violante",
        "R Dessì"
      ],
      "year": "2021",
      "venue": "Progresses in Artificial Intelligence and Neural Systems"
    },
    {
      "citation_id": "13",
      "title": "The emotional traveler: happiness and engagement as predictors of behavioral intentions among tourists in northern norway",
      "authors": [
        "J Vittersø",
        "N Prebensen",
        "A Hetland",
        "T Dahl"
      ],
      "year": "2017",
      "venue": "Advances in hospitality and leisure"
    },
    {
      "citation_id": "14",
      "title": "Emotion-awareness for intelligent vehicle assistants: A research agenda",
      "authors": [
        "H Vögel",
        "C Süß",
        "T Hubregtsen",
        "E André",
        "B Schuller",
        "J Härri",
        "J Conradt",
        "A Adi",
        "A Zadorojniy",
        "J Terken"
      ],
      "year": "2018",
      "venue": "Proceedings of the 2018 IEEE/ACM 1st International Workshop on Software Engineering for AI in Autonomous Systems (SEFAIAS)"
    },
    {
      "citation_id": "15",
      "title": "Automated driving system, male, or female driver: Who'd you prefer? comparative analysis of passengers' mental conditions, emotional states & qualitative feedback",
      "authors": [
        "P Wintersberger",
        "A Riener",
        "A Frison"
      ],
      "year": "2016",
      "venue": "Proceedings of the 8th International Conference on Automotive User Interfaces and Interactive Vehicular Applications (AutomotiveUI)"
    },
    {
      "citation_id": "16",
      "title": "Online driver distraction detection using long short-term memory",
      "authors": [
        "M Wöllmer",
        "C Blaschke",
        "T Schindl",
        "B Schuller",
        "B Farber",
        "S Mayer",
        "B Trefflich"
      ],
      "year": "2011",
      "venue": "IEEE Transactions on Intelligent Transportation Systems"
    }
  ]
}