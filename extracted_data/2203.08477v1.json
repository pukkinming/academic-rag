{
  "paper_id": "2203.08477v1",
  "title": "Emotion Recognition Using Machine Learning And Ecg Signals",
  "published": "2022-03-16T09:09:52Z",
  "authors": [
    "Bo Sun",
    "Zihuai Lin"
  ],
  "keywords": [
    "emotion recognition",
    "ECG signals",
    "DCT",
    "SVM",
    "PSO",
    "Random Forest",
    "K-NN"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Various emotions can produce variations in electrocardiograph (ECG) signals, distinct emotions can be distinguished by different changes in ECG signals. This study is about emotion recognition using ECG signals. Data for four emotions, namely happy, exciting, calm, and tense, is gathered. The raw data is then de-noised with a finite impulse filter. We use the Discrete Cosine Transform (DCT) to extract characteristics from the obtained data to increase the accuracy of emotion recognition. The classifiers Support Vector Machine (SVM), Random Forest, and K-NN are explored. To find the optimal parameters for the SVM classifier, the Particle Swarm Optimization (PSO) technique is used. The results of the comparison of these classification methods demonstrate that the SVM approach has a greater accuracy in emotion recognition, which may be applied in practice.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "I. Introduction",
      "text": "In recent years, emotion recognition (detection) gains lots of attention. However, most emotion detection methods are based on behavior such as speech detection and face recognition  [1] ,  [2] . The major drawback for behavior based emotion recognition is uncertainty. Because the behavior induced by emotion can be suppressed. For example, facial expressions can be used to judge emotion, but no one guarantees that related cues will definitely be expressed, whether or not people are experiencing an emotion. An alternative to separating emotion is using physiological signals. The common physiological signals include the electroencephalogram (EEG)  [3] , electromyogram (EMG) and electrocardiogram (ECG). Traditionally, these types of biological signals are used for clinical diagnosis. For example, the ECG signal is used to detect and analyze diseases such as heart diseases. There are evidences showing that physiological signals are sensitive to emotion states, which indicates that the signals may convey emotional information  [4] ,  [5] .\n\nCompared with previous methods of emotion recognition, there are two benefits to using physiological signals on emotion detection. One is that physiological signals are involuntary reactions, such reactions are hard to mask. Furthermore, physiological signals can be recorded continuously by sensors attached to body. This is not like the case of speech recognition. The information only can be recorded while people are speaking.\n\nThis paper focuses on the emotion recognition using ECG signals. An ECG device records the electrical changes caused Bo Sun and Zihuai Lin are with the School of Electrical and Information Engineering, The University of Sydney, Australia (e-mail: zihuai.lin@sydney.edu.au). by activities of heart, which is collected by electrodes over the skin in a period of time. According to  [6] ,  [7] , currently, the accuracy of emotion recognition based on ECG signals is lower than above mentioned methods such as face recognition. The highest accuracy of emotion detection was around 80 percentage  [6] . However, the face recognition accuracy can reach to 90%  [8] . In this paper, we investigate different machine learning methods to improve the performance of emotional classifications based on ECG signals.\n\nData collection is one of the most important steps for emotion detection. The definition of different emotions must be explicit in this phase. If the definition is not clear, confusion may occur among different emotions in the classification phase and the classification performance will be influenced negatively. In the data collection stage, we collect the ECG signals for four emotions: happy, exciting, calm and tense, respectively. The ECG signals are collected by using a low-cost wearable ECG patch, called iRealcare  [9] -  [13] . The collected signals are pre-processed by a finite impulse filter to remove noises from raw ECG signals. Next we separate the processed data into two datasets, one set is used to build a training set and the other set is used as a test set. Moreover, to accurately recognize different emotions, the main features of different emotions must be extracted by the feature extraction from the training set and the test set. In addition, the feature extraction can delete useless information to reduce data redundancy. In our experiments, we employ the Discrete Cosine Transform (DCT) to extract features  [14] . In the classification stage, three classifiers are used to analyze emotional data. First, the support vector machine is selected as the classifier.\n\nTo improve the performance of classification, the Radial Basis Function (RBF) kernel is used to improve the data dimension. In consideration of the importance of kernel parameters, the Particle Swarm Optimization (PSO) algorithm is applied to search the optimal parameters. Second, the support vector machine classifier is replaced with Random Forest classifier. The SVM classifier originates from separating two categories. Thus, for multiple categories, the performance may be poor. Compared with support vector machine, the Random Forest is good at disposing the multi-class classification. Third, the K-NN classifier is selected as the classifier. The training complexity of K-NN is lower, compared to above two classifiers. Finally, by analyzing the results of different classifiers, we select one best classifier for emotion detection based on ECG signals.\n\nThe paper is organized as follows: Section II introduces the ECG data collection, data pre-processing and the selection of training set and test set. The method of feature extraction used in ECG signals are presented in Section III. In Section IV, we introduce classifiers used for analyzing ECG signals. Section V compares performance of different classifiers and presents a best method for emotion recognition based on ECG signals. Section VI draws the conclusion of this work.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Ii. Data Collection And Pre-Processing",
      "text": "An ECG sensor from iRealcare  [9] -  [13]  was used for collecting ECG signals of different emotions from different people. The data collected by the iRealcare ECG sensor can be transmitted to a smart phone APP via Bluetooth Low Energy (BLE) and then to a cloud. From the cloud, we can acquire the raw ECG signals. In the experiment, ECG signals were recorded from four emotions including calm, exciting, happy and tense. Except calm, each emotion is generated based on external environmental stimulus. The calm emotion describes the normal state, so the ECG signal was recorded without any external stimulus. The ECG signals for exciting, happy and tense emotions were recorded when the testing people do exercises, watch comedies and watch thriller movies, respectively. Generally, a person's emotion changes quickly, so the record duration should not be too long. The longer the duration is, the more useless information will be added into ECG signals. Thus, the record time is set to 5 minutes for each emotion. The sampling rate for the ECG signal is 128 Hz. Taking into account differences among different people, we selected 5 participants. There are 5 data groups for each emotion and total 20 data groups for four emotions.\n\nNormally, human ECG signal is non-linear and low signal to noise. The frequency range of ECG signals is from 0.05HZ to 100HZ and the dynamic range is below 4mv  [15] . Thus, the collected ECG signals are susceptible to be disturbed by external factors such as interference. To acquire ECG signals with lower interference, we need to conduct the preprocessing for the raw ECG signals. During the collection and transmission, the ECG signals are affected by different noises. Two types of interference are mainly involved in ECG signals and they are low frequency noises and high frequency noise. The low frequency noises include baseline drift. The high frequency noises include Electromyography (EMG) noise, power line interference and channel noises. The baseline drift is a low frequency noise in ECG signals and it causes by body movement and breathing. Baseline drift can make the entire ECG signal shift down or up at the axis. The frequency of baseline drift is greater than 1HZ and the influence of baseline drift is on the analysis of peak. Power-line interference can be caused by the electromagnetic field of nearby facilities and electromagnetic interference of power line. Since the iRealcare sensor used BLE instead of cables, the power-line interference only can be generated by the electromagnetic field of nearby machines.\n\nEMG noise is generated by electric activities of muscle. The noise is usually in subjects with disable persons or people who have uncontrollable tremor diseases. In addition, there is electrode contact noise in ECG signals. Electrode contact noise is caused by skin stretching. Because the impedance of skin will change when the skin is stretched. Their frequency is from 1 to 10 HZ  [16] . We used the finite impulse filter(FIR) to filter the noise. FIR filter is a reliable and simple filter. At the same time, FIR filter is a linear filter and the output will not be distorted  [17] . In design of FIR filter, the window method is used. The common window methods include Hamming window, Rectangular window, Hanning window, and Blackman window. These different windows are used to design the low pass filter and high pass filter with cut-off frequencies in FIR filter. The frequencies above the cut-off frequency is blocked and others can pass in FIR filter. In our FIR filter, the cutoff frequencies are set to 3HZ and 100Hz respectively. After de-noising collected data, currently, we have the ECG data of four emotions and each emotion has five groups. Total number of ECG data is twenty groups. Then we selected four groups of each emotion as training group and the rest one group is used as test group. The segment of ECG signals from training set and test set were displayed respectively in Figs  1  and 2 .",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Iii. Feature Extraction",
      "text": "The feature extraction is an important part in machine learning. The purpose of feature extraction is to extract the main information from data further compressing data to improve classification performances. For an ECG signal, there are three main components: P wave, T wave and QRS, which represent three phases of the ECG signal. P wave is the contraction pulse in atrial systole. QRS represents the depolarization of ventricles. T wave is re-polarization of ventricles  [18] . However, there are some valueless features in the main components and the function of feature extraction is to remove these features. There are lots of feature extraction methods in different domains. In this paper, we use frequency domain discrete cosine transform (DCT) methods to extract main information of ECG signals.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "A. Discrete Cosine Transform",
      "text": "The discrete cosine transform expresses a finite sequence as a sum of cosine functions at different frequencies. The function of discrete cosine transform converts a real signal into a signal in frequency domain. The discrete cosine transform is a Fourier transform without the conjugate part. The formula is as follows:\n\nwhere\n\nand N is the total number of elements  [19] .\n\nThe ECG signals are made up by a large amount of sample points. After DCT, it was found that each segment of ECG signals was converted to the ECG signals at frequency domain and the sample points of ECG signals were rearranged in a decreasing order.\n\nAfter the feature extraction, the ECG segments from the training set and test set are shown in Figs.  3  and 4 , respectively. Comparing with original ECG signals, the ECG signals experienced feature extraction are easier to observe the differences between distinct emotions. In the feature extraction, there is an important parameter need to be considered. It is the number of extracted feature values and the best value can be determined by comparing classification performances at different values. The number of extracted feature in Figs.  3  and 4  is 75.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Iv. The Classifier Selection",
      "text": "In the selection of classifiers, Support Vector Machine (SVM), Random Forest and K Nearest Neighbor (K-NN) were used to classify the ECG data. For the SVM classifier, it is difficult for the data from four emotions to be discriminated in low dimension due to the nonlinear characteristic of ECG data. Thus, Radial Basis function (RBF) was used. The RBF can map the data to higher dimension to separate objects. The parameters C and γ in RBF kernel play a key role on the classification and they determine the rules of classification. Thus Particle Swarm Optimization (PSO) algorithm is used to optimize parameters C and γ. Then we used Random Forest classifier and K-NN classifier to attempt classification. By comparing the classification performance of different classifiers, the best classification method was proposed. A. Support Vector Machine (SVM)\n\nThe SVM is a supervised learning method, which is used for classification and regression. The basic concept is to find an optimal hyper-plane that separates data into different classes. The hyper-plane is decided by the support vectors which lies on the hyper-plane. The optimal hyper-plane is defined as the separating hyper-plane with maximum margin (see Fig.  1 )  [20] .\n\nIn SVM, known objects are used as training sets. A training set is made up by feature values and feature labels, which is used to build the classification model. For example, there are N training data (x i , y i ), i = 1, ..., N. x i ∈ R n and y i ∈ {-1, 1}\n\nN  [22] . If data are linearly separable, there exists a weight vector w and a scalar b which satisfy the following inequalities.\n\nThe optimal hyper-plane (w 0 , b 0 ) is described as follow: where x is an input pattern. The decision function is\n\nAccording to  [21] , the support vector machine(SVM) follows the solution of eq. (  6 ) under the constraints of eqs. (  7 ) and (  8 ) in optimization problem.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "M Inimize",
      "text": "where N i=1 ξ i is the total number of errors and C is a penalty coefficient.\n\nIn practice, most problems are non-linear separable. It is difficult for SVM classifier to find the optimal hyper-planes which separate different classes in original dimensions. Thus, to complete classification, the training data set needs to be mapped into a high dimension space to find separating hyperplanes. By the use of a kernel function, the data dimension can be improved. There are several kernel functions. In our experiments, Radial basis function (RBF) kernel function was used. The formula of RBF function is shown in eq.  (9) .\n\nThen we can get the decision function of RBF kernels as shown in eq.  (10) .\n\nC and γ are two important parameters of RBF kernel function, which have an influence on separating performance. C is called the penalty coefficient and it is the tolerability of error. The bigger C is, the lower error tolerability will be, which will lead to over-classification and poor generation ability. If C is smaller, the classification error will increase. γ is a spacial parameter which controls data distribution in new feature space  [23] . The value of γ is affected by σ. The relationship between γ and σ is as follows: From eq. (  11 ), we can see that as σ becomes smaller, γ gets bigger. The small σ makes Gaussian distribution narrow and high. In this way, there is a better classification performance for known samples. However, for unknown data, the classification performance is poor. The Gaussian distribution will be wider, while σ is larger. For a larger σ, the model built by training set is not accurate and it will influence test results. As mention above, the values of C and γ are vital and it will indicate SVM classifier how to separate data. Thus searching best parameters is necessary. The particle swarm optimization (PSO) algorithm was used to search the best values of C and γ  [24] . In the PSO algorithm, the optimization problem can be solved by searching the particle position. The flow chart of the PSO algorithm is shown in Fig.  6 .\n\nAt first, particles are initialized in a feasible space. Each particle represents a possible optimal solution. The characteristics of a particle is described by its velocity, position and fitness. The velocity is a preset value. The location of each particle is updated by the individual and group extreme value. The fitness value is calculated when the position of each particle is updated. The position of the individual and group extreme value is updated by comparing the new fitness with fitness extremum. The updated formulas are as follows:\n\nwhere x i is the location of the particle; v i denotes the velocity of the particle; c 1 and c 2 are learning factors; P id is the location of the optimal individual value and P gd is the location of the optimal group value. r 1 and r 2 are random values between 0 and 1.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "B. Random Forest",
      "text": "The structure of Random forest was shown in Figure  7 . From Figure  7 , it could be seen that Random forest can be seen as a set of decision tree. By building multiple decision trees, merge their results together to get a reliable result. In machine learning, decision tree is a model, which represents the mapping between the object and the attribute of object  [25] . The nodes in trees are the analyzing conditions and the leaves of trees are the prediction results. Compared with other supervised learning algorithms, Random forest adds randomness to the analysis. It randomly selects the features from a feature set to build decision trees and finally average the results. Thus, the generalization ability of random forest is stronger than other classifiers. The random forest is an ensemble learning over bagging. Ensemble learning deals with prediction problem by combining several models  [26] . There are many decision trees in random forest and it is an ensemble of decision trees. For an ensemble classifier c 1 , c 2 , ..., c n , the training set is selected randomly from vectors X and Y . The margin function is described by\n\nwhere I is an indicator function. The margin function calculates the confidence of voting. The larger the margin is, the better classification performance will be. According to the margin function, we define the generalization error as follows:\n\nIn this paper, the random forest algorithm is inspired from the bagging and the subsets. The random forest was built by bagged decision trees. At first, Bootstrap samples from all samples are selected. Then features of samples are selected. Next, decision trees are generated by repeating above two steps. Then data will be input to all decision trees. The decision trees are the classifiers and each decision tree has a result of classification. Finally, according to the results of all classifiers, the best classification result is determined by voting.",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "C. K Nearest Neighbor(K-Nn)",
      "text": "K-NN is the simplest classification non-parametric algorithm, which classifies unclassified samples by measuring the distances between training samples and test samples. From eq. (  13 ), the rule of nearest neighbor is defined as where x i is the ith measurement, x n ′ ∈ (x 1 , x 2 , ..., x n ) and x is the objects which will be classified. Four different functions can be used to calculate the distance including cosine, Euclidean, Minkowsky and Chi square  [27] . The Euclidean distance function is the most widely used to calculate the distance metric of K-NN. The function of Euclidean distance in the space can be computed by\n\nwhere vectors X = (x 1, ..., x n ), Y = (y 1 , ..., y n ) and n is the data dimension.\n\nIn K-NN algorithm, the value of K plays an important role in the performance of classification as illustrated in Fig.  8 , which shows that the unclassified sample is assigned to different classes based on different K values.\n\nWhen K is equal to 3, the red triangle is assigned to the class of blue square. If the value of K is 5, the test sample belongs to the black hexagon class. From Fig.  8 , we can see that the K value has an influence on the result of classification. Thus, the selection of K is important. When a larger K is used, the effect from nearest neighbor decreases. The distance of the whole system needs to be calculated, so the classification has to take much more time. If K is very small, other classes may affect the classification of test samples. Usually, we select a suitable K by comparing performance of different K values.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "V. Classification Results",
      "text": "The classification was implemented in Matlab. The aim of simulation is to find a suitable method to recognize different emotions. In the simulation, the total number of training data and test data was 4000 and 1200, respectively, which were randomly selected from training groups and test groups. Three classifiers were used to conduct the classification for four emotion data, they are SVM, Random Forest and K-NN. Finally, by comparing their results, we proposed the best method to recognize emotion based on ECG signals.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "A. Svm",
      "text": "In our experiment, we first select SVM as the classifier. The SVM classification is implemented by the LIBSVM  [28] . After the PSO algorithm, the optimal parameters C and γ are determined as 100.3 and 0.016, respectively. The features from the training set are used for building the model. The test set features are used for predicting. Then we use the confusion matrix to analyze the classification accuracy by comparing the test label and prediction label. To select a suitable number of features, the number of features are tested from 20 to 80 at an interval of 5. To get a more realistic result, for each number of features, we conduct classification ten times and calculate average recognition rate of four emotions. The results are shown in Fig.  9 , from which we can see that initially there is an increasing trend on average recognition rate as the number of features increases. After reaching the peak, the recognition rate starts to fall. The classification performance is the best, when the number of extracted features is set to 75. Fig.  10  presents the classification results of four emotions. From Fig.  10 , we can be see that the detection rate of exciting is the highest and it is over 90%. The accuracy of happy and tense approach 90%. By comparing with these three emotions, the recognition rate of calm is lowest and the accuracy is around 80%. Table  I  shows the average recognition rate of four emotions simulated by PSO-SVM, when the analysis is conducted ten times. From Table  I , we can see that the average accuracy rate of three emotions (happy, exciting and tense) reaches 90%, while the average accuracy of calm is around 80%.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "B. Random Forest",
      "text": "In the later analysis, the Random Forest classifier is used to for classification. From the result of SVM, we found that the classification performance would be best as the number of  features is 75. Thus, the number of features are also set to 75. In random forest, there are two methods in classification. One is Bagging, the other is boost. In our experiments, the Bagging is used. Moreover, the number of learning cycles needs to be determined in Random Forest. The best number of learning cycle would be estimated by calculating the generalization error. At first, the number of learning cycles is set to 200 and calculate the loss error. The results can be seen in Fig.  11 , from which, we can see that the loss decreased dramatically, when the number of learners increased from 0 to 20. Then, it started to slow down. Finally, the error would remain almost the same. From Fig.  11 , we can estimate roughly the range of the best number of learners. The number of learning cycles was started from 30 to 100 and each step was 10. For each learning cycle, we run the classification algorithm for ten times From Fig.  12 , we can see that there is not a significant increase on recognition rate as the number of learner increases. There is only 3% increase on the average recognition rate, when the number of learning cycles increases from 30 to 90. The best performance of classification is achieved when the number of features and learners are set to 75 and 90, respectively.\n\nThe recognition rate is shown in Fig.  13 . We can see that the accuracy of happy is the highest and it closes to 100%. The recognition rate of tense approaches 90%. The recognition rates of calm and exciting are around 70%. Table  II  recorded the highest detection rate, lowest detection rate and average recognition rate for four different emotions, when running times is set to ten. From Table  II , we can see that the average recognition rate of happy is over 90% and the accuracy rate of tense is about 90%. However, the average detection rates of calm and exciting are relative low (under 80%). Especially, the recognition rate of exciting is only 68.46%.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "C. K-Nn",
      "text": "Finally the classification is attempted by the K-NN classifier. In K-NN algorithm , the value of K needs to be determined first. For the selection of K, the method is similar to the method used in Random Forest. The classification loss is used to measure the performance of K-NN and K is selected from 1 to 10. The number of extracted features is still set to 75. The results are shown in Fig.  14 .\n\nFrom Fig.  14 , we can see that the classification accuracy is the highest when K = 3. After determining the value of K, we used it to analyze the model. The test results are shown in Fig.  15 .\n\nFrom Fig.  15 , it can be seen the classification accuracy of calm and happy are low, both of them are around 70%. The separating accuracy of tense is over 80%. The recognition rate    III  shows the high recognition rates for both exciting and tense. They are more than 85%. For the emotion of exciting, the average detection rate is around 80%. The lowest accuracy of emotion is for the calm which is under 80%.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "D. Comparison And Analysis",
      "text": "We compare the performance of three classifiers, the results are shown in Fig.  16 .\n\nIt can be seen that performance of the PSO-SVM classifier is the best and the recognition rate is obviously higher than the recognition rates for both K-NN and Random Forest. The classification performance of K-NN and Random Forest is similar. Table  IV  shows the average classification results of the three classifiers, when the simulation times is set to 10. According to Table IV, the recognition rate of the PSO-SVM classifier reaches to 90%. The average recognition rate of Random Forest and K-NN is around 80%. Moreover, according to Tables I, II and III, the recognition rate of PSO-SVM achieves the highest accuracy for four emotions by comparing with the results of three classifiers.",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Vi. Conclusion",
      "text": "In this paper, we presented a feasible method of emotion recognition based on ECG signal. From analysis results of emotion data, we can see that the PSO-SVM scheme has the best classification performance for the ECG signals. The obtained results is better than previous researches in the emotion detection based on ECG signal. In addition, according to the classification consequences, the effectiveness of feature extraction was proved. The average detection rate experienced feature feature extraction has reached 90% and results of previous research are around 80%. The recognition rate approached to the one based on facial recognition, but the method based on ECG signal is much simpler on steps and data processes. In addition, the ECG signals can truly react the emotion of individuals, because it is difficult for individuals to mask the change on ECG signals. In our future work, we will apply radio sensing techniques, such as  [13] ,  [29] -  [32] , instead of wearable devices for emotion recognition. We will also develop privacy preservation algorithms  [33] -  [36]  to protect the users' privacy.",
      "page_start": 8,
      "page_end": 8
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: The ECG segments (training set) from four emotions",
      "page": 2
    },
    {
      "caption": "Figure 2: The ECG segments (test set) from four emotions",
      "page": 2
    },
    {
      "caption": "Figure 3: The ECG segments of training set (Feature extraction)",
      "page": 3
    },
    {
      "caption": "Figure 4: The ECG segments from test set (Feature extraction)",
      "page": 3
    },
    {
      "caption": "Figure 5: SVM classiﬁcation",
      "page": 4
    },
    {
      "caption": "Figure 6: The ﬂow chart of PSO algorithm",
      "page": 4
    },
    {
      "caption": "Figure 6: At ﬁrst, particles are initialized in a feasible space. Each par-",
      "page": 4
    },
    {
      "caption": "Figure 7: From Figure 7, it could be seen that Random forest can be",
      "page": 4
    },
    {
      "caption": "Figure 7: The structure of Random forest",
      "page": 5
    },
    {
      "caption": "Figure 8: an example K-NN model",
      "page": 5
    },
    {
      "caption": "Figure 8: , which shows that the unclassiﬁed sample is assigned to",
      "page": 5
    },
    {
      "caption": "Figure 8: , we can see",
      "page": 5
    },
    {
      "caption": "Figure 9: The recognition rate versus the number of features",
      "page": 6
    },
    {
      "caption": "Figure 9: , from which we can see that initially",
      "page": 6
    },
    {
      "caption": "Figure 10: presents the classiﬁcation results of four emotions.",
      "page": 6
    },
    {
      "caption": "Figure 10: , we can be see that the detection rate of exciting",
      "page": 6
    },
    {
      "caption": "Figure 10: The classiﬁcation of emotion recognition by SVM",
      "page": 6
    },
    {
      "caption": "Figure 11: , we can estimate roughly the range",
      "page": 6
    },
    {
      "caption": "Figure 11: The Generalization error versus the number of learning cycles",
      "page": 6
    },
    {
      "caption": "Figure 12: The average recognition rate versus the number of learning cycles",
      "page": 7
    },
    {
      "caption": "Figure 13: The classiﬁcation of emotion by Random forest",
      "page": 7
    },
    {
      "caption": "Figure 12: From Fig. 12, we can see that there is not a signiﬁcant",
      "page": 7
    },
    {
      "caption": "Figure 13: We can see that",
      "page": 7
    },
    {
      "caption": "Figure 14: The classiﬁcation accuracy versus K",
      "page": 7
    },
    {
      "caption": "Figure 14: From Fig. 14, we can see that the classiﬁcation accuracy is",
      "page": 7
    },
    {
      "caption": "Figure 15: From Fig. 15, it can be seen the classiﬁcation accuracy of",
      "page": 7
    },
    {
      "caption": "Figure 15: The classiﬁcation of emotion by K-NN",
      "page": 7
    },
    {
      "caption": "Figure 16: The performance of the three classiﬁers",
      "page": 8
    },
    {
      "caption": "Figure 16: It can be seen that performance of the PSO-SVM classiﬁer",
      "page": 8
    }
  ],
  "tables": [],
  "citations": [
    {
      "citation_id": "1",
      "title": "Emotion detection from speech to enrich multimedia content",
      "authors": [
        "F Yu",
        "E Chang",
        "Y.-Q Xu",
        "H.-Y Shum"
      ],
      "year": "2001",
      "venue": "Pacific-Rim Conference on Multimedia"
    },
    {
      "citation_id": "2",
      "title": "Facial emotion recognition using multi-modal information",
      "authors": [
        "L De Silva",
        "T Miyasato",
        "R Nakatsu"
      ],
      "year": "1997",
      "venue": "Information, Communications and Signal Processing"
    },
    {
      "citation_id": "3",
      "title": "Significant Low-dimensional Spectral-temporal Features for Seizure Detection",
      "authors": [
        "X Yan",
        "D Yang",
        "Z Lin",
        "B Vucetic"
      ],
      "year": "2022",
      "venue": "IEEE Trans Neural Syst Rehabil Eng",
      "doi": "10.1109/TNSRE.2022.3156931"
    },
    {
      "citation_id": "4",
      "title": "Real-Time Recognition of the Affective User State with Physiological Signals",
      "authors": [
        "P Ekman",
        "R Levenson",
        "W Friesen"
      ],
      "year": "2007",
      "venue": "Proc. Doctoral Consortium Conf. Affective Computing and Intelligent Interaction"
    },
    {
      "citation_id": "5",
      "title": "Emotions and Heart Rate While Sitting on a Chair",
      "authors": [
        "J Anttonen",
        "V Surakka"
      ],
      "year": "2005",
      "venue": "Proc. SIGCHI Conf. Human Factors in Computing Systems"
    },
    {
      "citation_id": "6",
      "title": "A novel ECG-based realtime detection method of negative emotions in wearable applications",
      "authors": [
        "Z Cheng",
        "L Shu",
        "J Xie",
        "C Chen"
      ],
      "year": "2017",
      "venue": "2017 International Conference on Security, Pattern Analysis, and Cybernetics (SPAC)"
    },
    {
      "citation_id": "7",
      "title": "An Efficient Method to Face and Emotion Detection",
      "authors": [
        "D Reney",
        "N Tripathi"
      ],
      "year": "2015",
      "venue": "2015 Fifth International Conference on Communication Systems and Network Technologies"
    },
    {
      "citation_id": "8",
      "title": "The Research on Emotion Recognition from ECG Signal",
      "authors": [
        "J Cai",
        "G Liu",
        "M Hao"
      ],
      "year": "2009",
      "venue": "2009 International Conference on Information Technology and Computer Science"
    },
    {
      "citation_id": "9",
      "title": "Long-term wearable electrocardiogram signal monitoring and analysis based on convolutional neural network",
      "authors": [
        "L Meng",
        "K Ge",
        "Y Song",
        "D Yang",
        "Z Lin"
      ],
      "year": "2021",
      "venue": "IEEE Transactions on Instrumentation & Measurement",
      "doi": "10.1109/TIM.2021.3072144"
    },
    {
      "citation_id": "10",
      "title": "Negative-ResNet: noisy ambulatory electrocardiogram signal classification scheme",
      "authors": [
        "Z Chen",
        "Z Lin",
        "P Wang",
        "M Ding"
      ],
      "year": "2021",
      "venue": "Neural Computing and Applications"
    },
    {
      "citation_id": "11",
      "title": "A Wearable ECG Monitor for Deep Learning-Based Real-Time Cardiovascular Disease Detection",
      "authors": [
        "Z Lin",
        "Z Chen",
        "X Yan",
        "M Ding"
      ],
      "venue": "A Wearable ECG Monitor for Deep Learning-Based Real-Time Cardiovascular Disease Detection"
    },
    {
      "citation_id": "12",
      "title": "Wireless Electrocardiograph Monitoring Based on Wavelet Convolutional Neural Network",
      "authors": [
        "X Yan",
        "Z Lin",
        "P Wang"
      ],
      "year": "2020",
      "venue": "Proceedings of the IEEE WCNC"
    },
    {
      "citation_id": "13",
      "title": "Human Biometric Signals Monitoring based on WiFi Channel State Information using Deep Learning",
      "authors": [
        "M Liu",
        "Z Lin",
        "P Xiao",
        "W Xiang"
      ],
      "year": "2022",
      "venue": "Human Biometric Signals Monitoring based on WiFi Channel State Information using Deep Learning",
      "arxiv": "arXiv:2203.03980"
    },
    {
      "citation_id": "14",
      "title": "Visual speech recognition for isolated digits using discrete cosine transform and local binary pattern features",
      "authors": [
        "A Jain",
        "G Rathna"
      ],
      "year": "2017",
      "venue": "2017 IEEE Global Conference on Signal and Information Processing (GlobalSIP)"
    },
    {
      "citation_id": "15",
      "title": "Noise Analysis and Different Denoising Techniques of ECG Signal-A Survey",
      "authors": [
        "A Velayudhan",
        "S Peter"
      ],
      "year": "2015",
      "venue": "OSR Journal of Electronics and Communication Engineering"
    },
    {
      "citation_id": "16",
      "title": "Signal Processing Techniques Noise from ECG signals",
      "authors": [
        "R Kher"
      ],
      "venue": "J Biomed Eng"
    },
    {
      "citation_id": "17",
      "title": "Comparison of the design of FIR and IIR filters for a given specification and removal of phase distortion from IIR filters",
      "year": "2017",
      "venue": "2017 International Conference on Advances in Computing, Communication and Control (ICAC3)"
    },
    {
      "citation_id": "18",
      "title": "Detection of ECG characteristic points using wavelet transforms",
      "authors": [
        "Cuiwei Li",
        "Chongxun Zheng",
        "Changfeng Tai"
      ],
      "year": "1995",
      "venue": "IEEE Transactions on biomedical Engineering"
    },
    {
      "citation_id": "19",
      "title": "Discrete cosine transform",
      "authors": [
        "N Ahmed",
        "T Natarajan",
        "K Rao"
      ],
      "year": "1974",
      "venue": "IEEE transactions on Computers"
    },
    {
      "citation_id": "20",
      "title": "Support vector. machines",
      "authors": [
        "M Hearst",
        "S Dumais",
        "E Osuna",
        "J Platt",
        "B Scholkopf"
      ],
      "year": "1998",
      "venue": "IEEE Intelligent Systems and their applications"
    },
    {
      "citation_id": "21",
      "title": "Support-Vector Networks",
      "authors": [
        "C Cortes",
        "V Vapnik"
      ],
      "year": "1995",
      "venue": "Machine Learning, journal article"
    },
    {
      "citation_id": "22",
      "title": "Short-Time Prediction of Traffic Flow Based on PSO Optimized SVM",
      "authors": [
        "M Duan"
      ],
      "year": "2018",
      "venue": "2018 International Conference on Intelligent Transportation, Big Data & Smart City (ICITBS)"
    },
    {
      "citation_id": "23",
      "title": "Identification of conductive leakage signal in power cable based on multi-classification PSO-SVM",
      "authors": [
        "Z Qian",
        "C Zhou",
        "J Cheng",
        "Q Wang"
      ],
      "year": "2017",
      "venue": "2017 IEEE 5th International Symposium on Electromagnetic Compatibility"
    },
    {
      "citation_id": "24",
      "title": "Particle swarm optimization",
      "authors": [
        "J Kennedy"
      ],
      "year": "2011",
      "venue": "Encyclopedia of machine learning"
    },
    {
      "citation_id": "25",
      "title": "Random forests",
      "authors": [
        "L Breiman"
      ],
      "year": "2001",
      "venue": "Machine learning"
    },
    {
      "citation_id": "26",
      "title": "Study on credit evaluation of electricity users based on random forest",
      "authors": [
        "Y Zhao",
        "X Ma"
      ],
      "year": "2017",
      "venue": "Study on credit evaluation of electricity users based on random forest"
    },
    {
      "citation_id": "27",
      "title": "The distance function effect on k-nearest neighbor classification for medical datasets",
      "authors": [
        "L.-Y Hu",
        "M.-W Huang",
        "S.-W Ke",
        "C.-F Tsai"
      ],
      "year": "2016",
      "venue": "SpringerPlus"
    },
    {
      "citation_id": "28",
      "title": "LIBSVM: a library for support vector machines",
      "authors": [
        "C.-C Chang",
        "C.-J Lin"
      ],
      "year": "2011",
      "venue": "ACM transactions on intelligent systems and technology (TIST)"
    },
    {
      "citation_id": "29",
      "title": "Nonrandom microwave ghost imaging",
      "authors": [
        "X Wang",
        "Z Lin"
      ],
      "year": "2018",
      "venue": "IEEE Transactions on Geoscience and Remote Sensing"
    },
    {
      "citation_id": "30",
      "title": "Microwave surveillance based on ghost imaging and distributed antennas",
      "authors": [
        "X Wang",
        "Z Lin"
      ],
      "year": "2016",
      "venue": "IEEE Antennas and Wireless Propagation Letters"
    },
    {
      "citation_id": "31",
      "title": "Microwave ghost imaging via lte-dl signals",
      "authors": [
        "Z Zhang",
        "R Luo",
        "X Wang",
        "Z Lin"
      ],
      "year": "2018",
      "venue": "2018 International Conference on Radar (RADAR)"
    },
    {
      "citation_id": "32",
      "title": "Wi-fi based device-free microwave ghost imaging indoor surveillance system",
      "authors": [
        "R Luo",
        "Z Zhang",
        "X Wang",
        "Z Lin"
      ],
      "year": "2018",
      "venue": "2018 28th International Telecommunication Networks and Applications Conference (ITNAC)"
    },
    {
      "citation_id": "33",
      "title": "When Machine Learning Meets Privacy: A Survey and Outlook",
      "authors": [
        "B Liu",
        "M Ding",
        "S Shaham",
        "W Rahayu",
        "F Farokhi",
        "Z Lin"
      ],
      "venue": "ACM Computing Surveys, ACM Computing Surveys (IF",
      "doi": "10.1145/3436755"
    },
    {
      "citation_id": "34",
      "title": "Privacy Preservation in Location-Based Services: A Novel Metric and Attack Model",
      "authors": [
        "S Shaham",
        "M Ding",
        "B Liu",
        "S Dang",
        "Z Lin",
        "J Li"
      ],
      "year": "2021",
      "venue": "IEEE Transactions on Mobile Computing",
      "doi": "10.1109/TMC.2020.2993599"
    },
    {
      "citation_id": "35",
      "title": "Privacy-Preserving Location Data Publishing: A Machine Learning Approach",
      "authors": [
        "S Shaham",
        "M Ding",
        "B Liu",
        "S Dang",
        "Z Lin",
        "J Li"
      ],
      "year": "2021",
      "venue": "IEEE Transactions on Knowledge and Data Engineering",
      "doi": "10.1109/TKDE.2020.2964658"
    },
    {
      "citation_id": "36",
      "title": "Privacy-Preserved Optimal Energy Trading, Statistics, and Forecasting for a Neighborhood Area Network",
      "authors": [
        "D Smith",
        "P Wang",
        "M Ding",
        "J Chan",
        "B Spak",
        "X Guan",
        "P Tyler",
        "T Rakotoarivelo",
        "Z Lin",
        "T Abbasi"
      ],
      "year": "2020",
      "venue": "Computer",
      "doi": "10.1109/MC.2020.2972505"
    },
    {
      "citation_id": "37",
      "title": "This figure \"PSO_flow_chart.png\" is available in \"png\" format from",
      "venue": "This figure \"PSO_flow_chart.png\" is available in \"png\" format from"
    }
  ]
}