{
  "paper_id": "2508.01161v1",
  "title": "Csiro-Lt At Semeval-2025 Task 11: Adapting Llms For Emotion Recognition For Multiple Languages",
  "published": "2025-08-02T02:55:26Z",
  "authors": [
    "Jiyu Chen",
    "Necva Bölücü",
    "Sarvnaz Karimi",
    "Diego Mollá",
    "Cécile L. Paris"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Detecting emotions across different languages is challenging due to the varied and culturally nuanced ways of emotional expressions. The Semeval 2025 Task 11: Bridging the Gap in Text-Based emotion shared task was organised to investigate emotion recognition across different languages. The goal of the task is to implement an emotion recogniser that can identify the basic emotional states that general thirdparty observers would attribute to an author based on their written text snippet, along with the intensity of those emotions. We report our investigation of various task-adaptation strategies for LLMs in emotion recognition. We show that the most effective method for this task is to fine-tune a pre-trained multilingual LLM with LoRA setting separately for each language.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Text-based emotion recognition plays a crucial role in studies related to mental health  (Golder and Macy, 2011) , emotional intelligence  (Turcan et al., 2021) , and human-computer interaction  (Li et al., 2022) . However, recognising emotions in text remains a significant challenge, especially across different languages  (Mohammad et al., 2018) . Linguistic variations, cultural differences in emotional expression, and the scarcity of annotated data for low-resourced languages make emotion recognition particularly complex  (Barrett et al., 2011; Lindquist and Gendron, 2013; Schröder et al., 2013) .\n\nThe SemEval-2025 Task 11: Bridging the Gap in Text-Based Emotion shared task  (Muhammad et al., 2025b)  1 is part of the International Workshop on Semantic Evaluation (SemEval). Its objective is to detect collectively perceived emotions within text 1 https://github.com/emotion-analysis-project/ SemEval2025-task11 snippets written in 32 different languages. Collectively perceived emotion refers to the basic emotional states-such as anger, joy, and disgust-that third-party observers from the general public can attribute to a text snippet generated by a writer. Unlike tasks aimed at identifying the writer's actual emotional states or the emotional states evoked in individual reader  (Mohammad, 2022 (Mohammad, , 2023)) , this task emphasises the shared perception of emotions by general readers. This distinction is crucial, as perceived emotions can vary significantly from both intended and personally experienced emotions.\n\nThe shared task consists of three tracks: (A) Multi-label Emotion Detection, where the goal is to predict the perceived emotional states expressed in a given text snippet, including joy, sadness, fear, anger, surprise, and disgust; (B) Emotion Intensity, where the objective is to predict the intensity scale of each perceived emotional state for a given text snippet. Each emotional state is rated on a 4-point categorical scale: 0 (no emotion), 1 (low intensity), 2 (moderate intensity), and 3 (high intensity); and (C) Cross-lingual Emotion Detection, where the goal is to predict the perceived emotion on text snippets written in a language different from the one used for model training, such as training on English-written data but making emotion recognition on Javanese-written data.\n\nOur team participated in Tracks A and B, focusing on fine-tuning Large Language Models (LLMs). LLMs have contributed to significant improvements across different NLP tasks  (Brown, 2020; Touvron et al., 2023) . However, previous studies suggest that they are ineffective for emotion classification in zero-shot and few-shot settings, even when provided with In-Context Learning (ICL) prompts  (Liu et al., 2024) . A potential improvement can be achieved by fine-tuning LLMs with instructions  (Zhang et al., 2023; Liu et al., 2024) . Drawing inspiration from  Liu et al. (2024) , we ex-plore instruction-tuning and continual fine-tuning of multilingual LLMs. We then compare the effectiveness of this adaptation for emotion recognition across different languages by fine-tuning a multilingual model individually for each language. We also propose several adaptation approaches and conduct a comparative analysis across these approaches, specifically for Track A. We develop an adaptation strategy for LLMs in emotion recognition that is effective across languages of varying resourced levels (see the categorisation of resource abundance by  Joshi et al. (2020) ;  Üstün et al. (2024) ).",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Methods",
      "text": "",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Track A: Multi-Label Emotion Detection",
      "text": "We formulate this task as a binary classification problem for the detection of each emotional state. For each input, the LLMs predict the occurrence of the six emotions-anger, disgust, fear, joy, sadness, and surprise-independently, determining whether a specific emotional state is present (1) or absent (0). The final results are aggregated for the input, to represent a multi-label emotion recognition setting. To address class imbalance, we apply oversampling to balance the binary classification instances.\n\nThe proposed adaptation strategies are described below:\n\n• Few-shot: We apply ICL based on the BM25  (Robertson et al., 1995)  scores to retrieve instances from the training set to construct a prompt for the prediction of each test instance (see the prompt template in Section 3.3). That is, we use BM25 scores to rank semantic (bag-of-words) relevancy between the given test instance (as a query) and each training instance (as a document)  (Schutze et al., 2008; Robertson et al., 2009) . We retrieve the top k most relevant instances and their manually annotated emotional state label as k-shot examples to prompt-tune LLMs for each test instance.\n\n• Supervised Fine-Tuning (SFT): We finetune pre-trained and instruction-tuned multilingual LLMs using supervised and parameterefficient settings.\n\n• English-bridged Adaptation (E-Bridge):\n\nWe apply SFT to LLMs on English-written instances and then apply continual SFT for the adaptation to other languages.\n\n• Marginalisation: We first apply SFT to LLM on Track B (see details of SFT in Section 2.2), and then use fine-tuned LLM to make predictions for instances on Track A. To align with the binary classification in Track A, predictions of 1-3 are marginalised into 1, indicating the presence of an emotional state, while predictions of zero are retained to represent its absence.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Track B: Emotion Intensity Detection",
      "text": "We frame this task as a multi-class classification problem for each emotion. Given an input text, the LLM predicts whether a specific emotion can be perceived at a given intensity level. The intensity is measured on a four-point categorical scale: 0 for no emotion, 1 for low intensity, 2 for moderate intensity, and 3 for high intensity. Thus, for a text with six emotional states, the LLM processes the input six times, once for each emotion. The final results are aggregated to the input text for the completion of multi-label emotion intensity recognition set by Track B.\n\nTo achieve this, we convert each text with multiple emotion intensities into separate instances, one for each emotion. We fine-tune pre-trained and instruction-tuned LLMs on this transformed dataset, using supervised learning to predict the emotional intensity for each emotion independently (SFT) and apply zero-shot, where we only use instruction as a baseline.\n\n3 Experimental Setup Instruction-tuning on External Dataset: We leveraged an external dataset to instruction-tune LLMs  (Liu et al., 2024) . This helps the model generalise on the external task by learning how to follow instructions for emotion recognition before fine-tuning on the dataset specific to this shared task. The selected external dataset is an extension to the SemEval-2018 Task 1: Affect in Tweets, which includes a series of subtasks related to affectual state inference: (1) emotion intensity regression;\n\n(2) emotion intensity ordinal classification;\n\n(3) valence (sentiment) regression; (4) valence ordinal classification; and, (5) emotion classification  (Mohammad and Kiritchenko, 2018; Mohammad et al., 2018)  which overlaps with the tracks of this shared task.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Evaluation Metrics",
      "text": "For both Track A and Track B, we follow the evaluation metrics specified by the shared task organ-isers. Track A uses the unweighted average of all per-emotion F 1 scores. Track B uses the average of per-emotion Pearson's correlation coefficient (r).",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Hyperparameters",
      "text": "LLMs:\n\nWe use three open-source multilingual LLMs: AYA (aya-101  (Üstün et al., 2024) , aya-32b-expanse  (Dang et al., 2024) ), and LLAMA (Llama3.1-8B-Instruct  (Dubey et al., 2024) ). aya-101 (mT5-based) offers broad multilingual support with a smaller size, while aya-32b-expanse (GPT-style) provides larger capacity and similarly wide language coverage. Llama3.1-8B-Instruct (GPT-style) is smaller but supports only seven languages. Due to its broader coverage and capacity, aya-32b-expanse was preferred, with aya-101 as a lightweight alternative. For languages jointly supported by both aya-32b-expanse and Llama3.1-8B-Instruct, such as English and German, model selection also accounts for differences in parameter size. We employ Low-Rank Adaptation (LoRA) (Hu et al., 2022) and apply 4-bits quantisation  (Jacob et al., 2018)  to LLMs for parameter-efficient SFT. We set the LoRA rank and alpha parameters to 32 and 64, respectively. The dropout ratio is set to 0.05. We limit both the input source length and the target length to 512. The training epoch size is 10 and the batch size is 2. The learning rate is set to 2e -5 for Track A and 5e -5 for Track B.\n\nThe formulations of instructions for zero-shot, few-shot (ICL), and SFT settings are as below: For BM25-based few-shot prompting, we use the rank_bm25 library  (Stuart, 2022)  and choose the default parameter setting, b = 0.75 and k 1 = 1.5, for BM25.\n\nWe use NVIDIA H100 GPUs running on one node for this experiment.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Experimental Results",
      "text": "",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Results On Testing Set",
      "text": "We present the results of the submitted predictions for ranking (testing) in Table  1 , including the baseline results per language provided by  Muhammad et al. (2025a) . We submitted results for 26 out of 32 languages in Track A and the 11 (all) languages provided in Track B.\n\nWe observed noticeable variations in effectiveness across languages for both Track A (macro F 1 ) and Track B (average r). The baseline approach is mostly effective in higher-resourced languages, such as German, English, and Russian. However, applying instruction-tuning or SFT to LLMs on mid-resourced and lower-resourced language is more effective than the baseline for emotion recognition.\n\nAdditionally, model selection plays a crucial role, as larger GPT-based models like aya-32b-expanse outperform smaller mT5-based models like aya-101, particularly in lowerresourced languages where the latter struggles.\n\nWe applied the adaptation strategies for the test set prediction based on the highest F 1 and correlation coefficient r achieved on the development set in Track A & B, respectively.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Results On Track A Development Set",
      "text": "We compared the effectiveness of the various adaptation strategies with experiments in English, Ger-    2 ). These results suggest that LLMs may not significantly benefit from instruction tuning, as direct SFT shows greater effectiveness across all four languages. E-Bridge can be viewed as a specialised form of instruction tuning, where the LLM first learns instructions in English instances before being fine-tuned in other languages. This method proves effective for German and Portuguese but is less effective for Russian, possibly due to the closer cultural alignment of German and Portuguese speakers with English speakers  (Rinke and Flores, 2021; Wikipedia, 2025) .",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Results On Track B Development Set",
      "text": "The emotion intensity results across multiple languages using both base and instruction-tuned versions of AYA and LLAMA in zero-shot and SFT settings are shown in Table  3 . Fine-tuning significantly improves performance across most languages, demonstrating that task-specific adaptation benefits intensity detection. While fine-tuning offers substantial gains across the languages, the benefits are often more pronounced in higher-resourced languages (i.e., English, Spanish). While AYA generally demonstrates stronger zero-shot performance, LLAMA benefits more from instruction tuning, showing significant improvements after fine-tuning. Instruction-tuned models (EMO-AYA and EMO-LLAMA) provide some advantages in zero-shot settings, particularly in languages with less training data, but their impact diminishes after fine-tuning, suggesting that instruction-tuning alone is often sufficient for intensity detection.\n\nHigher-resourced languages, such as English, Russian, and Spanish, consistently achieve better results, with both zero-shot and fine-tuned models performing reliably. Mid-resourced languages, including German, Portuguese, and Romanian, show moderate performance, benefiting from fine-tuning but still exhibiting variability depending on the model. The performance of all languages improves with fine-tuning, but challenges persist in making significant gains for languages where the models initially perform poorly. Despite this, the advancements show that fine-tuning and instruction tuning can help optimise model behaviour across languages, and targeted adaptation strategies may further boost results for emotion intensity detection tasks.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Conclusions",
      "text": "We participated in the SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion shared task, which included tracks for multi-label emotion detection (Track A) and emotion intensity detection (Track B). For Track A, we approached it as a binary classification problem for each emotiondetermining whether an emotional state is present in or absent from a given input text snippet. We found that direct supervised fine-tuning can effectively adapt LLMs for the detection of emotions for most languages, except for the lower-resourced languages where few-shot learning is more effective. For Track B, we achieved the best results by employing different LLMs (both direct SFT and instruction-tuned) for each language. The results in both tracks suggest that, when adapting LLMs for emotion recognition on most mid-resourced and higher-resourced language, instruction-tuning was not as effective as in other NLP tasks. A more suitable approach is to directly apply supervised fine-tuning of LLMs on task-specific datasets.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Limitations",
      "text": "The exploration of various adaptation strategies was limited to four languages (English, German, Russian, and Portuguese), which may not generalise to other languages, particularly lowerresourced ones or those with different linguistic structures. The models used may reflect biases from the training data, which could affect performance in low-resourced languages. We only explored prompt-tuning and instruction-tuning with the parameter-efficient LoRA setting for adapting LLMs.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Ethical Considerations",
      "text": "We relied on the dataset providers to remove any material from the dataset that may reveal anyone's identity in their posts used in this study. We guarantee that datasets are only used for scientific or research purposes and are not redistributed or shared with third parties. This project is subject to the ethics approval and agreement provided by the SemEval-2025 task organisers.",
      "page_start": 7,
      "page_end": 7
    }
  ],
  "figures": [],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "LLM with LoRA setting separately for each": "language."
        },
        {
          "LLM with LoRA setting separately for each": ""
        },
        {
          "LLM with LoRA setting separately for each": "1\nIntroduction"
        },
        {
          "LLM with LoRA setting separately for each": ""
        },
        {
          "LLM with LoRA setting separately for each": "Text-based emotion recognition plays a crucial role"
        },
        {
          "LLM with LoRA setting separately for each": ""
        },
        {
          "LLM with LoRA setting separately for each": "in studies\nrelated to mental health (Golder and"
        },
        {
          "LLM with LoRA setting separately for each": ""
        },
        {
          "LLM with LoRA setting separately for each": "Macy, 2011), emotional intelligence (Turcan et al.,"
        },
        {
          "LLM with LoRA setting separately for each": ""
        },
        {
          "LLM with LoRA setting separately for each": "2021), and human-computer interaction (Li et al.,"
        },
        {
          "LLM with LoRA setting separately for each": ""
        },
        {
          "LLM with LoRA setting separately for each": "2022). However, recognising emotions in text re-"
        },
        {
          "LLM with LoRA setting separately for each": ""
        },
        {
          "LLM with LoRA setting separately for each": "mains a significant challenge, especially across dif-"
        },
        {
          "LLM with LoRA setting separately for each": ""
        },
        {
          "LLM with LoRA setting separately for each": "ferent\nlanguages (Mohammad et al., 2018). Lin-"
        },
        {
          "LLM with LoRA setting separately for each": ""
        },
        {
          "LLM with LoRA setting separately for each": "guistic variations, cultural differences in emotional"
        },
        {
          "LLM with LoRA setting separately for each": ""
        },
        {
          "LLM with LoRA setting separately for each": "expression, and the scarcity of annotated data for"
        },
        {
          "LLM with LoRA setting separately for each": ""
        },
        {
          "LLM with LoRA setting separately for each": "low-resourced languages make emotion recogni-"
        },
        {
          "LLM with LoRA setting separately for each": ""
        },
        {
          "LLM with LoRA setting separately for each": "tion particularly complex (Barrett\net\nal., 2011;"
        },
        {
          "LLM with LoRA setting separately for each": ""
        },
        {
          "LLM with LoRA setting separately for each": "Lindquist\nand Gendron, 2013; Schröder\net\nal.,"
        },
        {
          "LLM with LoRA setting separately for each": ""
        },
        {
          "LLM with LoRA setting separately for each": "2013)."
        },
        {
          "LLM with LoRA setting separately for each": ""
        },
        {
          "LLM with LoRA setting separately for each": "The SemEval-2025 Task 11: Bridging the Gap in"
        },
        {
          "LLM with LoRA setting separately for each": ""
        },
        {
          "LLM with LoRA setting separately for each": "Text-Based Emotion shared task (Muhammad et al.,"
        },
        {
          "LLM with LoRA setting separately for each": ""
        },
        {
          "LLM with LoRA setting separately for each": "2025b)1 is part of the International Workshop on"
        },
        {
          "LLM with LoRA setting separately for each": ""
        },
        {
          "LLM with LoRA setting separately for each": "Semantic Evaluation (SemEval). Its objective is to"
        },
        {
          "LLM with LoRA setting separately for each": ""
        },
        {
          "LLM with LoRA setting separately for each": "detect collectively perceived emotions within text"
        },
        {
          "LLM with LoRA setting separately for each": ""
        },
        {
          "LLM with LoRA setting separately for each": ""
        },
        {
          "LLM with LoRA setting separately for each": "1https://github.com/emotion-analysis-project/"
        },
        {
          "LLM with LoRA setting separately for each": "SemEval2025-task11"
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "∗ indicates co-first authors.": "Abstract"
        },
        {
          "∗ indicates co-first authors.": ""
        },
        {
          "∗ indicates co-first authors.": "Detecting emotions across different languages"
        },
        {
          "∗ indicates co-first authors.": "is challenging due to the varied and culturally"
        },
        {
          "∗ indicates co-first authors.": ""
        },
        {
          "∗ indicates co-first authors.": "nuanced ways of emotional expressions. The"
        },
        {
          "∗ indicates co-first authors.": ""
        },
        {
          "∗ indicates co-first authors.": "Semeval 2025 Task 11: Bridging the Gap in"
        },
        {
          "∗ indicates co-first authors.": ""
        },
        {
          "∗ indicates co-first authors.": "Text-Based emotion shared task was organised"
        },
        {
          "∗ indicates co-first authors.": ""
        },
        {
          "∗ indicates co-first authors.": "to investigate emotion recognition across differ-"
        },
        {
          "∗ indicates co-first authors.": ""
        },
        {
          "∗ indicates co-first authors.": "ent languages. The goal of the task is to imple-"
        },
        {
          "∗ indicates co-first authors.": "ment an emotion recogniser that can identify"
        },
        {
          "∗ indicates co-first authors.": "the basic emotional states that general\nthird-"
        },
        {
          "∗ indicates co-first authors.": "party observers would attribute to an author"
        },
        {
          "∗ indicates co-first authors.": ""
        },
        {
          "∗ indicates co-first authors.": "based on their written text snippet, along with"
        },
        {
          "∗ indicates co-first authors.": ""
        },
        {
          "∗ indicates co-first authors.": "the intensity of those emotions. We report our"
        },
        {
          "∗ indicates co-first authors.": ""
        },
        {
          "∗ indicates co-first authors.": "investigation of various task-adaptation strate-"
        },
        {
          "∗ indicates co-first authors.": ""
        },
        {
          "∗ indicates co-first authors.": "gies\nfor LLMs\nin emotion recognition. We"
        },
        {
          "∗ indicates co-first authors.": ""
        },
        {
          "∗ indicates co-first authors.": "show that\nthe most effective method for\nthis"
        },
        {
          "∗ indicates co-first authors.": "task is to fine-tune a pre-trained multilingual"
        },
        {
          "∗ indicates co-first authors.": "LLM with LoRA setting separately for each"
        },
        {
          "∗ indicates co-first authors.": "language."
        },
        {
          "∗ indicates co-first authors.": ""
        },
        {
          "∗ indicates co-first authors.": "1\nIntroduction"
        },
        {
          "∗ indicates co-first authors.": ""
        },
        {
          "∗ indicates co-first authors.": "Text-based emotion recognition plays a crucial role"
        },
        {
          "∗ indicates co-first authors.": ""
        },
        {
          "∗ indicates co-first authors.": "in studies\nrelated to mental health (Golder and"
        },
        {
          "∗ indicates co-first authors.": ""
        },
        {
          "∗ indicates co-first authors.": "Macy, 2011), emotional intelligence (Turcan et al.,"
        },
        {
          "∗ indicates co-first authors.": ""
        },
        {
          "∗ indicates co-first authors.": "2021), and human-computer interaction (Li et al.,"
        },
        {
          "∗ indicates co-first authors.": ""
        },
        {
          "∗ indicates co-first authors.": "2022). However, recognising emotions in text re-"
        },
        {
          "∗ indicates co-first authors.": ""
        },
        {
          "∗ indicates co-first authors.": "mains a significant challenge, especially across dif-"
        },
        {
          "∗ indicates co-first authors.": ""
        },
        {
          "∗ indicates co-first authors.": "ferent\nlanguages (Mohammad et al., 2018). Lin-"
        },
        {
          "∗ indicates co-first authors.": ""
        },
        {
          "∗ indicates co-first authors.": "guistic variations, cultural differences in emotional"
        },
        {
          "∗ indicates co-first authors.": ""
        },
        {
          "∗ indicates co-first authors.": "expression, and the scarcity of annotated data for"
        },
        {
          "∗ indicates co-first authors.": ""
        },
        {
          "∗ indicates co-first authors.": "low-resourced languages make emotion recogni-"
        },
        {
          "∗ indicates co-first authors.": ""
        },
        {
          "∗ indicates co-first authors.": "tion particularly complex (Barrett\net\nal., 2011;"
        },
        {
          "∗ indicates co-first authors.": ""
        },
        {
          "∗ indicates co-first authors.": "Lindquist\nand Gendron, 2013; Schröder\net\nal.,"
        },
        {
          "∗ indicates co-first authors.": ""
        },
        {
          "∗ indicates co-first authors.": "2013)."
        },
        {
          "∗ indicates co-first authors.": ""
        },
        {
          "∗ indicates co-first authors.": "The SemEval-2025 Task 11: Bridging the Gap in"
        },
        {
          "∗ indicates co-first authors.": ""
        },
        {
          "∗ indicates co-first authors.": "Text-Based Emotion shared task (Muhammad et al.,"
        },
        {
          "∗ indicates co-first authors.": ""
        },
        {
          "∗ indicates co-first authors.": "2025b)1 is part of the International Workshop on"
        },
        {
          "∗ indicates co-first authors.": ""
        },
        {
          "∗ indicates co-first authors.": "Semantic Evaluation (SemEval). Its objective is to"
        },
        {
          "∗ indicates co-first authors.": ""
        },
        {
          "∗ indicates co-first authors.": "detect collectively perceived emotions within text"
        },
        {
          "∗ indicates co-first authors.": ""
        },
        {
          "∗ indicates co-first authors.": ""
        },
        {
          "∗ indicates co-first authors.": "1https://github.com/emotion-analysis-project/"
        },
        {
          "∗ indicates co-first authors.": "SemEval2025-task11"
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "one for each emotion. We fine-tune pre-trained": ""
        },
        {
          "one for each emotion. We fine-tune pre-trained": "and instruction-tuned LLMs on this transformed"
        },
        {
          "one for each emotion. We fine-tune pre-trained": ""
        },
        {
          "one for each emotion. We fine-tune pre-trained": "dataset, using supervised learning to predict\nthe"
        },
        {
          "one for each emotion. We fine-tune pre-trained": "emotional intensity for each emotion independently"
        },
        {
          "one for each emotion. We fine-tune pre-trained": ""
        },
        {
          "one for each emotion. We fine-tune pre-trained": "(SFT) and apply zero-shot, where we only use in-"
        },
        {
          "one for each emotion. We fine-tune pre-trained": ""
        },
        {
          "one for each emotion. We fine-tune pre-trained": "struction as a baseline."
        },
        {
          "one for each emotion. We fine-tune pre-trained": ""
        },
        {
          "one for each emotion. We fine-tune pre-trained": ""
        },
        {
          "one for each emotion. We fine-tune pre-trained": "3\nExperimental Setup"
        },
        {
          "one for each emotion. We fine-tune pre-trained": ""
        },
        {
          "one for each emotion. We fine-tune pre-trained": ""
        },
        {
          "one for each emotion. We fine-tune pre-trained": "3.1\nShared Task Dataset"
        },
        {
          "one for each emotion. We fine-tune pre-trained": ""
        },
        {
          "one for each emotion. We fine-tune pre-trained": "The dataset used in the\nshared task is\na\ncom-"
        },
        {
          "one for each emotion. We fine-tune pre-trained": ""
        },
        {
          "one for each emotion. We fine-tune pre-trained": "bination of EthioEmo (Belay et al., 2025) and"
        },
        {
          "one for each emotion. We fine-tune pre-trained": ""
        },
        {
          "one for each emotion. We fine-tune pre-trained": "BRIGHTER (Muhammad et al., 2025a), which in-"
        },
        {
          "one for each emotion. We fine-tune pre-trained": ""
        },
        {
          "one for each emotion. We fine-tune pre-trained": "cludes emotion annotations for multiple languages."
        },
        {
          "one for each emotion. We fine-tune pre-trained": ""
        },
        {
          "one for each emotion. We fine-tune pre-trained": "Specifically, 28 languages for Track A and 11 lan-"
        },
        {
          "one for each emotion. We fine-tune pre-trained": ""
        },
        {
          "one for each emotion. We fine-tune pre-trained": "guages for Track B. The statistical details of the"
        },
        {
          "one for each emotion. We fine-tune pre-trained": ""
        },
        {
          "one for each emotion. We fine-tune pre-trained": "annotated languages are detailed by Belay et al."
        },
        {
          "one for each emotion. We fine-tune pre-trained": ""
        },
        {
          "one for each emotion. We fine-tune pre-trained": "(2025) for Amharic, Oromo, Somali, and Tigrinya,"
        },
        {
          "one for each emotion. We fine-tune pre-trained": "and by Muhammad et al. (2025a) for the remaining"
        },
        {
          "one for each emotion. We fine-tune pre-trained": "languages."
        },
        {
          "one for each emotion. We fine-tune pre-trained": ""
        },
        {
          "one for each emotion. We fine-tune pre-trained": "Instruction-tuning on External Dataset:\nWe"
        },
        {
          "one for each emotion. We fine-tune pre-trained": ""
        },
        {
          "one for each emotion. We fine-tune pre-trained": "leveraged an external dataset\nto instruction-tune"
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "plore instruction-tuning and continual fine-tuning": "of multilingual LLMs. We then compare the effec-",
          "• Marginalisation: We first apply SFT to LLM": "on Track B (see details of SFT in Section 2.2),"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "tiveness of this adaptation for emotion recognition",
          "• Marginalisation: We first apply SFT to LLM": "and then use fine-tuned LLM to make predic-"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "across different languages by fine-tuning a multilin-",
          "• Marginalisation: We first apply SFT to LLM": "tions for instances on Track A. To align with"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "gual model individually for each language. We also",
          "• Marginalisation: We first apply SFT to LLM": "the binary classification in Track A, predic-"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "propose several adaptation approaches and conduct",
          "• Marginalisation: We first apply SFT to LLM": "tions of 1–3 are marginalised into 1, indicat-"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "a comparative analysis across these approaches,",
          "• Marginalisation: We first apply SFT to LLM": "ing the presence of an emotional state, while"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "specifically for Track A. We develop an adaptation",
          "• Marginalisation: We first apply SFT to LLM": "predictions of zero are retained to represent"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "strategy for LLMs in emotion recognition that\nis",
          "• Marginalisation: We first apply SFT to LLM": "its absence."
        },
        {
          "plore instruction-tuning and continual fine-tuning": "effective across languages of varying resourced lev-",
          "• Marginalisation: We first apply SFT to LLM": ""
        },
        {
          "plore instruction-tuning and continual fine-tuning": "els (see the categorisation of resource abundance",
          "• Marginalisation: We first apply SFT to LLM": "2.2\nTrack B: Emotion Intensity Detection"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "by Joshi et al. (2020); Üstün et al. (2024)).",
          "• Marginalisation: We first apply SFT to LLM": ""
        },
        {
          "plore instruction-tuning and continual fine-tuning": "",
          "• Marginalisation: We first apply SFT to LLM": "We frame this task as a multi-class classification"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "",
          "• Marginalisation: We first apply SFT to LLM": "problem for each emotion. Given an input text, the"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "2\nMethods",
          "• Marginalisation: We first apply SFT to LLM": ""
        },
        {
          "plore instruction-tuning and continual fine-tuning": "",
          "• Marginalisation: We first apply SFT to LLM": "LLM predicts whether a specific emotion can be"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "",
          "• Marginalisation: We first apply SFT to LLM": "perceived at a given intensity level. The intensity"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "2.1\nTrack A: Multi-label Emotion Detection",
          "• Marginalisation: We first apply SFT to LLM": ""
        },
        {
          "plore instruction-tuning and continual fine-tuning": "",
          "• Marginalisation: We first apply SFT to LLM": "is measured on a four-point categorical scale: 0"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "We formulate this task as a binary classification",
          "• Marginalisation: We first apply SFT to LLM": ""
        },
        {
          "plore instruction-tuning and continual fine-tuning": "",
          "• Marginalisation: We first apply SFT to LLM": "for no emotion, 1 for low intensity, 2 for moderate"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "problem for the detection of each emotional state.",
          "• Marginalisation: We first apply SFT to LLM": ""
        },
        {
          "plore instruction-tuning and continual fine-tuning": "",
          "• Marginalisation: We first apply SFT to LLM": "intensity, and 3 for high intensity. Thus, for a text"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "For each input, the LLMs predict the occurrence of",
          "• Marginalisation: We first apply SFT to LLM": ""
        },
        {
          "plore instruction-tuning and continual fine-tuning": "",
          "• Marginalisation: We first apply SFT to LLM": "with six emotional states, the LLM processes the"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "the six emotions—anger, disgust, fear, joy, sadness,",
          "• Marginalisation: We first apply SFT to LLM": ""
        },
        {
          "plore instruction-tuning and continual fine-tuning": "",
          "• Marginalisation: We first apply SFT to LLM": "input six times, once for each emotion. The final"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "and surprise—independently, determining whether",
          "• Marginalisation: We first apply SFT to LLM": ""
        },
        {
          "plore instruction-tuning and continual fine-tuning": "",
          "• Marginalisation: We first apply SFT to LLM": "results are aggregated to the input text for the com-"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "a specific emotional state is present (1) or absent",
          "• Marginalisation: We first apply SFT to LLM": ""
        },
        {
          "plore instruction-tuning and continual fine-tuning": "",
          "• Marginalisation: We first apply SFT to LLM": "pletion of multi-label emotion intensity recognition"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "(0). The final results are aggregated for the input, to",
          "• Marginalisation: We first apply SFT to LLM": ""
        },
        {
          "plore instruction-tuning and continual fine-tuning": "",
          "• Marginalisation: We first apply SFT to LLM": "set by Track B."
        },
        {
          "plore instruction-tuning and continual fine-tuning": "represent a multi-label emotion recognition setting.",
          "• Marginalisation: We first apply SFT to LLM": ""
        },
        {
          "plore instruction-tuning and continual fine-tuning": "",
          "• Marginalisation: We first apply SFT to LLM": "To achieve this, we convert each text with mul-"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "To address class imbalance, we apply oversampling",
          "• Marginalisation: We first apply SFT to LLM": ""
        },
        {
          "plore instruction-tuning and continual fine-tuning": "",
          "• Marginalisation: We first apply SFT to LLM": "tiple emotion intensities into separate instances,"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "to balance the binary classification instances.",
          "• Marginalisation: We first apply SFT to LLM": ""
        },
        {
          "plore instruction-tuning and continual fine-tuning": "",
          "• Marginalisation: We first apply SFT to LLM": "one for each emotion. We fine-tune pre-trained"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "The proposed adaptation strategies are described",
          "• Marginalisation: We first apply SFT to LLM": ""
        },
        {
          "plore instruction-tuning and continual fine-tuning": "",
          "• Marginalisation: We first apply SFT to LLM": "and instruction-tuned LLMs on this transformed"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "below:",
          "• Marginalisation: We first apply SFT to LLM": ""
        },
        {
          "plore instruction-tuning and continual fine-tuning": "",
          "• Marginalisation: We first apply SFT to LLM": "dataset, using supervised learning to predict\nthe"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "",
          "• Marginalisation: We first apply SFT to LLM": "emotional intensity for each emotion independently"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "• Few-shot:\nWe\napply\nICL based\non\nthe",
          "• Marginalisation: We first apply SFT to LLM": ""
        },
        {
          "plore instruction-tuning and continual fine-tuning": "",
          "• Marginalisation: We first apply SFT to LLM": "(SFT) and apply zero-shot, where we only use in-"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "BM25 (Robertson et al., 1995) scores to re-",
          "• Marginalisation: We first apply SFT to LLM": ""
        },
        {
          "plore instruction-tuning and continual fine-tuning": "",
          "• Marginalisation: We first apply SFT to LLM": "struction as a baseline."
        },
        {
          "plore instruction-tuning and continual fine-tuning": "trieve instances from the training set\nto con-",
          "• Marginalisation: We first apply SFT to LLM": ""
        },
        {
          "plore instruction-tuning and continual fine-tuning": "struct a prompt\nfor\nthe prediction of each",
          "• Marginalisation: We first apply SFT to LLM": ""
        },
        {
          "plore instruction-tuning and continual fine-tuning": "",
          "• Marginalisation: We first apply SFT to LLM": "3\nExperimental Setup"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "test instance (see the prompt template in Sec-",
          "• Marginalisation: We first apply SFT to LLM": ""
        },
        {
          "plore instruction-tuning and continual fine-tuning": "tion 3.3). That is, we use BM25 scores to rank",
          "• Marginalisation: We first apply SFT to LLM": ""
        },
        {
          "plore instruction-tuning and continual fine-tuning": "",
          "• Marginalisation: We first apply SFT to LLM": "3.1\nShared Task Dataset"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "semantic (bag-of-words) relevancy between",
          "• Marginalisation: We first apply SFT to LLM": ""
        },
        {
          "plore instruction-tuning and continual fine-tuning": "",
          "• Marginalisation: We first apply SFT to LLM": "The dataset used in the\nshared task is\na\ncom-"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "the given test instance (as a query) and each",
          "• Marginalisation: We first apply SFT to LLM": ""
        },
        {
          "plore instruction-tuning and continual fine-tuning": "",
          "• Marginalisation: We first apply SFT to LLM": "bination of EthioEmo (Belay et al., 2025) and"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "training instance (as a document)\n(Schutze",
          "• Marginalisation: We first apply SFT to LLM": ""
        },
        {
          "plore instruction-tuning and continual fine-tuning": "",
          "• Marginalisation: We first apply SFT to LLM": "BRIGHTER (Muhammad et al., 2025a), which in-"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "et al., 2008; Robertson et al., 2009). We re-",
          "• Marginalisation: We first apply SFT to LLM": ""
        },
        {
          "plore instruction-tuning and continual fine-tuning": "",
          "• Marginalisation: We first apply SFT to LLM": "cludes emotion annotations for multiple languages."
        },
        {
          "plore instruction-tuning and continual fine-tuning": "trieve the top k most relevant\ninstances and",
          "• Marginalisation: We first apply SFT to LLM": ""
        },
        {
          "plore instruction-tuning and continual fine-tuning": "",
          "• Marginalisation: We first apply SFT to LLM": "Specifically, 28 languages for Track A and 11 lan-"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "their manually annotated emotional state label",
          "• Marginalisation: We first apply SFT to LLM": ""
        },
        {
          "plore instruction-tuning and continual fine-tuning": "",
          "• Marginalisation: We first apply SFT to LLM": "guages for Track B. The statistical details of the"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "as k-shot examples to prompt-tune LLMs for",
          "• Marginalisation: We first apply SFT to LLM": ""
        },
        {
          "plore instruction-tuning and continual fine-tuning": "",
          "• Marginalisation: We first apply SFT to LLM": "annotated languages are detailed by Belay et al."
        },
        {
          "plore instruction-tuning and continual fine-tuning": "each test instance.",
          "• Marginalisation: We first apply SFT to LLM": ""
        },
        {
          "plore instruction-tuning and continual fine-tuning": "",
          "• Marginalisation: We first apply SFT to LLM": "(2025) for Amharic, Oromo, Somali, and Tigrinya,"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "• Supervised Fine-Tuning (SFT): We fine-",
          "• Marginalisation: We first apply SFT to LLM": "and by Muhammad et al. (2025a) for the remaining"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "tune pre-trained and instruction-tuned multi-",
          "• Marginalisation: We first apply SFT to LLM": "languages."
        },
        {
          "plore instruction-tuning and continual fine-tuning": "lingual LLMs using supervised and parameter-",
          "• Marginalisation: We first apply SFT to LLM": ""
        },
        {
          "plore instruction-tuning and continual fine-tuning": "",
          "• Marginalisation: We first apply SFT to LLM": "Instruction-tuning on External Dataset:\nWe"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "efficient settings.",
          "• Marginalisation: We first apply SFT to LLM": ""
        },
        {
          "plore instruction-tuning and continual fine-tuning": "",
          "• Marginalisation: We first apply SFT to LLM": "leveraged an external dataset\nto instruction-tune"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "(E-Bridge):\n• English-bridged Adaptation",
          "• Marginalisation: We first apply SFT to LLM": "LLMs (Liu et al., 2024).\nThis helps the model"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "We apply SFT to LLMs on English-written",
          "• Marginalisation: We first apply SFT to LLM": "generalise on the external task by learning how to"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "instances and then apply continual SFT for",
          "• Marginalisation: We first apply SFT to LLM": "follow instructions for emotion recognition before"
        },
        {
          "plore instruction-tuning and continual fine-tuning": "the adaptation to other languages.",
          "• Marginalisation: We first apply SFT to LLM": "fine-tuning on the dataset specific to this shared"
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Track A (F1)": "Ours",
          "Track B (r)": "Ours"
        },
        {
          "Track A (F1)": "31.61",
          "Track B (r)": "—"
        },
        {
          "Track A (F1)": "52.55",
          "Track B (r)": "52.11"
        },
        {
          "Track A (F1)": "58.81",
          "Track B (r)": "15.40"
        },
        {
          "Track A (F1)": "57.84",
          "Track B (r)": "54.92"
        },
        {
          "Track A (F1)": "17.27",
          "Track B (r)": "—"
        },
        {
          "Track A (F1)": "77.62",
          "Track B (r)": "72.09"
        },
        {
          "Track A (F1)": "65.72",
          "Track B (r)": "60.98"
        },
        {
          "Track A (F1)": "54.25",
          "Track B (r)": "37.15"
        },
        {
          "Track A (F1)": "73.16",
          "Track B (r)": "—"
        },
        {
          "Track A (F1)": "32.56",
          "Track B (r)": "—"
        },
        {
          "Track A (F1)": "—",
          "Track B (r)": "—"
        },
        {
          "Track A (F1)": "—",
          "Track B (r)": "—"
        },
        {
          "Track A (F1)": "—",
          "Track B (r)": "—"
        },
        {
          "Track A (F1)": "—",
          "Track B (r)": "—"
        },
        {
          "Track A (F1)": "42.95",
          "Track B (r)": "—"
        },
        {
          "Track A (F1)": "75.75",
          "Track B (r)": "—"
        },
        {
          "Track A (F1)": "—",
          "Track B (r)": "—"
        },
        {
          "Track A (F1)": "21.81",
          "Track B (r)": "—"
        },
        {
          "Track A (F1)": "39.24",
          "Track B (r)": "—"
        },
        {
          "Track A (F1)": "55.54",
          "Track B (r)": "48.88"
        },
        {
          "Track A (F1)": "—",
          "Track B (r)": "—"
        },
        {
          "Track A (F1)": "72.24",
          "Track B (r)": "59.22"
        },
        {
          "Track A (F1)": "89.10",
          "Track B (r)": "79.26"
        },
        {
          "Track A (F1)": "43.28",
          "Track B (r)": "—"
        },
        {
          "Track A (F1)": "82.00",
          "Track B (r)": "69.66"
        },
        {
          "Track A (F1)": "48.75",
          "Track B (r)": "—"
        },
        {
          "Track A (F1)": "30.31",
          "Track B (r)": "—"
        },
        {
          "Track A (F1)": "48.88",
          "Track B (r)": "—"
        },
        {
          "Track A (F1)": "53.84",
          "Track B (r)": "—"
        },
        {
          "Track A (F1)": "49.95",
          "Track B (r)": "—"
        },
        {
          "Track A (F1)": "66.40",
          "Track B (r)": "49.42"
        },
        {
          "Track A (F1)": "29.96",
          "Track B (r)": "—"
        }
      ],
      "page": 3
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Tigrinya (tir)\n46.28": "Ukrainian (ukr)\n53.45",
          "49.95\naya-101\n—\n—\n—": "66.40\naya-32\n39.94\n49.42\nemo-aya∗"
        },
        {
          "Tigrinya (tir)\n46.28": "Yoruba (yor)\n9.22",
          "49.95\naya-101\n—\n—\n—": "29.96\naya-101\n—\n—\n—"
        },
        {
          "Tigrinya (tir)\n46.28": "Table 1: Effectiveness of baseline and our approaches (SFT or zero-shot (*) of a specific model) on the test set.",
          "49.95\naya-101\n—\n—\n—": ""
        },
        {
          "Tigrinya (tir)\n46.28": "The baseline results are provided by the task organisers Muhammad et al. (2025a). Note that aya-32 denotes the",
          "49.95\naya-101\n—\n—\n—": ""
        },
        {
          "Tigrinya (tir)\n46.28": "aya-32b-expanse model, llama denotes the Llama3.1-8B-Instruct model, emo-aya denotes instruction-tuned",
          "49.95\naya-101\n—\n—\n—": ""
        },
        {
          "Tigrinya (tir)\n46.28": "aya-32b-expanse.",
          "49.95\naya-101\n—\n—\n—": ""
        },
        {
          "Tigrinya (tir)\n46.28": "task.\nThe selected external dataset\nis an exten-",
          "49.95\naya-101\n—\n—\n—": "isers. Track A uses the unweighted average of all"
        },
        {
          "Tigrinya (tir)\n46.28": "sion to the SemEval-2018 Task 1: Affect in Tweets,",
          "49.95\naya-101\n—\n—\n—": "per-emotion F1 scores. Track B uses the average of"
        },
        {
          "Tigrinya (tir)\n46.28": "which includes a series of subtasks related to af-",
          "49.95\naya-101\n—\n—\n—": "per-emotion Pearson’s correlation coefficient (r)."
        },
        {
          "Tigrinya (tir)\n46.28": "fectual state inference:\n(1) emotion intensity re-",
          "49.95\naya-101\n—\n—\n—": ""
        },
        {
          "Tigrinya (tir)\n46.28": "",
          "49.95\naya-101\n—\n—\n—": "3.3\nHyperparameters"
        },
        {
          "Tigrinya (tir)\n46.28": "gression; (2) emotion intensity ordinal classifica-",
          "49.95\naya-101\n—\n—\n—": ""
        },
        {
          "Tigrinya (tir)\n46.28": "tion; (3) valence (sentiment) regression; (4) valence",
          "49.95\naya-101\n—\n—\n—": ""
        },
        {
          "Tigrinya (tir)\n46.28": "",
          "49.95\naya-101\n—\n—\n—": "LLMs:\nWe use three open-source multilingual"
        },
        {
          "Tigrinya (tir)\n46.28": "ordinal classification; and, (5) emotion classifica-",
          "49.95\naya-101\n—\n—\n—": ""
        },
        {
          "Tigrinya (tir)\n46.28": "",
          "49.95\naya-101\n—\n—\n—": "LLMs:\nAYA (aya-101\n(Üstün\net\nal.,\n2024),"
        },
        {
          "Tigrinya (tir)\n46.28": "tion (Mohammad and Kiritchenko, 2018; Moham-",
          "49.95\naya-101\n—\n—\n—": ""
        },
        {
          "Tigrinya (tir)\n46.28": "",
          "49.95\naya-101\n—\n—\n—": "aya-32b-expanse\n(Dang\net\nal.,\n2024)),\nand"
        },
        {
          "Tigrinya (tir)\n46.28": "mad et al., 2018) which overlaps with the tracks of",
          "49.95\naya-101\n—\n—\n—": ""
        },
        {
          "Tigrinya (tir)\n46.28": "",
          "49.95\naya-101\n—\n—\n—": "LLAMA (Llama3.1-8B-Instruct (Dubey et al.,"
        },
        {
          "Tigrinya (tir)\n46.28": "this shared task.",
          "49.95\naya-101\n—\n—\n—": ""
        },
        {
          "Tigrinya (tir)\n46.28": "",
          "49.95\naya-101\n—\n—\n—": "aya-101\n2024)).\n(mT5-based)\noffers\nbroad"
        },
        {
          "Tigrinya (tir)\n46.28": "",
          "49.95\naya-101\n—\n—\n—": "multilingual\nsupport with a smaller\nsize, while"
        },
        {
          "Tigrinya (tir)\n46.28": "3.2\nEvaluation Metrics",
          "49.95\naya-101\n—\n—\n—": ""
        },
        {
          "Tigrinya (tir)\n46.28": "",
          "49.95\naya-101\n—\n—\n—": "aya-32b-expanse (GPT-style) provides larger ca-"
        },
        {
          "Tigrinya (tir)\n46.28": "For both Track A and Track B, we follow the eval-",
          "49.95\naya-101\n—\n—\n—": "pacity\nand\nsimilarly wide\nlanguage\ncoverage."
        },
        {
          "Tigrinya (tir)\n46.28": "uation metrics specified by the shared task organ-",
          "49.95\naya-101\n—\n—\n—": "Llama3.1-8B-Instruct\n(GPT-style)\nis\nsmaller"
        }
      ],
      "page": 3
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Supervised Fine-tuning (SFT)": "EMO-AYAf t",
          "Marginalisation": "",
          "Few-shots": "1-shot"
        },
        {
          "Supervised Fine-tuning (SFT)": "",
          "Marginalisation": "AYAf tb",
          "Few-shots": ""
        },
        {
          "Supervised Fine-tuning (SFT)": "73.31",
          "Marginalisation": "68.47",
          "Few-shots": "52.31"
        },
        {
          "Supervised Fine-tuning (SFT)": "52.43",
          "Marginalisation": "60.69",
          "Few-shots": "30.24"
        },
        {
          "Supervised Fine-tuning (SFT)": "53.42",
          "Marginalisation": "41.87",
          "Few-shots": "34.11"
        },
        {
          "Supervised Fine-tuning (SFT)": "87.13",
          "Marginalisation": "72.42",
          "Few-shots": "75.01"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "62.31\nGerman\n52.43\n56.21\n53.92",
          "57.94\n68.47\n72.88\n52.31": "46.65\n60.69\n54.56\n30.24"
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "61.29\nPortuguese\n53.42\n57.33\n44.55",
          "57.94\n68.47\n72.88\n52.31": "40.56\n41.87\n45.93\n34.11"
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "89.11\nRussian\n87.13\n86.16\n54.12",
          "57.94\n68.47\n72.88\n52.31": "60.56\n72.42\n55.34\n75.01"
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "Table 2: Macro F1 scores on the development split of Track A for four languages. AYAf t denotes direct SFT of",
          "57.94\n68.47\n72.88\n52.31": ""
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "the aya-32b-expanse model on the training set. EMO-AYAf t indicates first performing instruction-tuning on",
          "57.94\n68.47\n72.88\n52.31": ""
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "the aya model on the external dataset, followed by SFT on the training set. E-Bridge refers to SFT of the aya",
          "57.94\n68.47\n72.88\n52.31": ""
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "model on the training set in English, followed by continual SFT on the remaining three languages. AYAptb involves",
          "57.94\n68.47\n72.88\n52.31": ""
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "prompt-tuning a model\nin a zero-shot setting to complete the Track B objective,",
          "57.94\n68.47\n72.88\n52.31": "followed by marginalisation."
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "EMO-AYAptb represents applying instruction-tuning to aya model on the external dataset and then prompt-tuning it",
          "57.94\n68.47\n72.88\n52.31": ""
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "in a zero-shot setting on Track B, followed by marginalisation. The best results are boldfaced.",
          "57.94\n68.47\n72.88\n52.31": ""
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "but\nsupports only seven languages.\nDue to its",
          "57.94\n68.47\n72.88\n52.31": "For BM25-based few-shot prompting, we use the"
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "broader coverage and capacity, aya-32b-expanse",
          "57.94\n68.47\n72.88\n52.31": "rank_bm25 library (Stuart, 2022) and choose the"
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "was preferred, with aya-101 as a lightweight alter-",
          "57.94\n68.47\n72.88\n52.31": "default parameter setting, b = 0.75 and k1 = 1.5,"
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "native.\nFor\nlanguages jointly supported by both",
          "57.94\n68.47\n72.88\n52.31": "for BM25."
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "aya-32b-expanse and Llama3.1-8B-Instruct,",
          "57.94\n68.47\n72.88\n52.31": "We use NVIDIA H100 GPUs running on one"
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "such as English and German, model selection also",
          "57.94\n68.47\n72.88\n52.31": "node for this experiment."
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "accounts for differences in parameter size.",
          "57.94\n68.47\n72.88\n52.31": ""
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "",
          "57.94\n68.47\n72.88\n52.31": "4\nExperimental Results"
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "We employ Low-Rank Adaptation (LoRA) (Hu",
          "57.94\n68.47\n72.88\n52.31": ""
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "et al., 2022) and apply 4-bits quantisation (Jacob",
          "57.94\n68.47\n72.88\n52.31": ""
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "",
          "57.94\n68.47\n72.88\n52.31": "Results on Testing Set"
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "et al., 2018) to LLMs for parameter-efficient SFT.",
          "57.94\n68.47\n72.88\n52.31": ""
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "",
          "57.94\n68.47\n72.88\n52.31": "We present the results of the submitted predictions"
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "We set the LoRA rank and alpha parameters to 32",
          "57.94\n68.47\n72.88\n52.31": ""
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "",
          "57.94\n68.47\n72.88\n52.31": "for ranking (testing) in Table 1, including the base-"
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "and 64,\nrespectively. The dropout ratio is set\nto",
          "57.94\n68.47\n72.88\n52.31": ""
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "",
          "57.94\n68.47\n72.88\n52.31": "line results per language provided by Muhammad"
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "0.05. We limit both the input source length and the",
          "57.94\n68.47\n72.88\n52.31": ""
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "",
          "57.94\n68.47\n72.88\n52.31": "et al. (2025a). We submitted results for 26 out of"
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "target length to 512. The training epoch size is 10",
          "57.94\n68.47\n72.88\n52.31": ""
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "",
          "57.94\n68.47\n72.88\n52.31": "32 languages in Track A and the 11 (all) languages"
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "and the batch size is 2. The learning rate is set to",
          "57.94\n68.47\n72.88\n52.31": ""
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "",
          "57.94\n68.47\n72.88\n52.31": "provided in Track B."
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "2e − 5 for Track A and 5e − 5 for Track B.",
          "57.94\n68.47\n72.88\n52.31": ""
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "",
          "57.94\n68.47\n72.88\n52.31": "We observed noticeable variations in effective-"
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "The formulations of instructions for zero-shot,",
          "57.94\n68.47\n72.88\n52.31": ""
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "",
          "57.94\n68.47\n72.88\n52.31": "ness across languages for both Track A (macro F1)"
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "few-shot (ICL), and SFT settings are as below:",
          "57.94\n68.47\n72.88\n52.31": ""
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "",
          "57.94\n68.47\n72.88\n52.31": "and Track B (average r). The baseline approach"
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "",
          "57.94\n68.47\n72.88\n52.31": "is mostly effective in higher-resourced languages,"
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "• Track A: “You are detecting emotions on a",
          "57.94\n68.47\n72.88\n52.31": ""
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "",
          "57.94\n68.47\n72.88\n52.31": "such as German, English, and Russian. However,"
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "statement written in {language}. Statement:",
          "57.94\n68.47\n72.88\n52.31": ""
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "",
          "57.94\n68.47\n72.88\n52.31": "applying instruction-tuning or SFT to LLMs on"
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "{text}. Does this statement express {emotion}?",
          "57.94\n68.47\n72.88\n52.31": ""
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "",
          "57.94\n68.47\n72.88\n52.31": "mid-resourced and lower-resourced language is"
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "Answer 1 for yes and 0 for no.”",
          "57.94\n68.47\n72.88\n52.31": ""
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "",
          "57.94\n68.47\n72.88\n52.31": "more effective than the baseline for emotion recog-"
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "into\n• Track B: “Task: Categorize the tweet",
          "57.94\n68.47\n72.88\n52.31": "nition."
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "an intensity level of\nthe specified emotion E,",
          "57.94\n68.47\n72.88\n52.31": "Additionally, model\nselection\nplays\na\ncru-"
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "representing the mental state of\nthe tweeter.",
          "57.94\n68.47\n72.88\n52.31": "cial\nrole,\nas\nlarger GPT-based models\nlike"
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "0: no E can be inferred.\n1:\nlow amount of",
          "57.94\n68.47\n72.88\n52.31": "aya-32b-expanse outperform smaller mT5-based"
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "E can be inferred.\n2: moderate amount of",
          "57.94\n68.47\n72.88\n52.31": "models\nlike\naya-101,\nparticularly\nin\nlower-"
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "E can be inferred. 3: high amount of E can",
          "57.94\n68.47\n72.88\n52.31": "resourced languages where the latter struggles."
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "be inferred. Tweet: {text} Emotion {emotion}",
          "57.94\n68.47\n72.88\n52.31": "We applied the adaptation strategies for the test"
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "Intensity class:”",
          "57.94\n68.47\n72.88\n52.31": "set prediction based on the highest F1 and correla-"
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "",
          "57.94\n68.47\n72.88\n52.31": "tion coefficient r achieved on the development set"
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "where {text} is the text content of each instance, and",
          "57.94\n68.47\n72.88\n52.31": "in Track A & B, respectively."
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "{emotion} is one of the six emotional states (or five,",
          "57.94\n68.47\n72.88\n52.31": ""
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "",
          "57.94\n68.47\n72.88\n52.31": "Results on Track A Development Set"
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "excluding disgust for English and Surprise for",
          "57.94\n68.47\n72.88\n52.31": ""
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "Afrikaans). The instruction of Track B is adapted",
          "57.94\n68.47\n72.88\n52.31": "We compared the effectiveness of the various adap-"
        },
        {
          "80.12\nEnglish\n73.31\n—\n64.55": "from Liu et al. (2024).",
          "57.94\n68.47\n72.88\n52.31": "tation strategies with experiments in English, Ger-"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table 3: The average r on the development set of Track B. AYA and LLAMA refer to the base models,",
      "data": [
        {
          "Zero-shot": "LLAMA",
          "SFT": "LLAMAf t"
        },
        {
          "Zero-shot": "16.65",
          "SFT": "30.61"
        },
        {
          "Zero-shot": "11.93",
          "SFT": "25.30"
        },
        {
          "Zero-shot": "35.57",
          "SFT": "39.83"
        },
        {
          "Zero-shot": "43.87",
          "SFT": "75.87"
        },
        {
          "Zero-shot": "41.61",
          "SFT": "41.09"
        },
        {
          "Zero-shot": "16.15",
          "SFT": "45.13"
        },
        {
          "Zero-shot": "31.17",
          "SFT": "—"
        },
        {
          "Zero-shot": "47.98",
          "SFT": "50.76"
        },
        {
          "Zero-shot": "34.98",
          "SFT": "83.62"
        },
        {
          "Zero-shot": "45.80",
          "SFT": "70.07"
        },
        {
          "Zero-shot": "24.12",
          "SFT": "41.99"
        }
      ],
      "page": 5
    },
    {
      "caption": "Table 3: The average r on the development set of Track B. AYA and LLAMA refer to the base models,",
      "data": [
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "Russian (rus)\n56.01\n62.34\n34.98",
          "63.35\n47.74\n61.22\n50.76\n52.34": "83.62\n50.47\n75.44\n70.63\n82.10"
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "Spanish (Latin American) (esp)\n57.77\n54.77\n45.80",
          "63.35\n47.74\n61.22\n50.76\n52.34": "70.07\n48.69\n68.50\n64.36\n69.10"
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "50.07\nUkrainian (ukr)\n45.68\n24.12",
          "63.35\n47.74\n61.22\n50.76\n52.34": "33.05\n—\n—\n41.99\n40.56"
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "Table 3:\nThe average r on the development",
          "63.35\n47.74\n61.22\n50.76\n52.34": "set of Track B. AYA and LLAMA refer\nto the base models,"
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "aya-expanse-32b and Llama3.1-8B-Instruct, respectively. EMO-AYA and EMO-LLAMA are their instruction-",
          "63.35\n47.74\n61.22\n50.76\n52.34": ""
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "tuned versions. *f t are fine-tuned versions. The best results are boldfaced.",
          "63.35\n47.74\n61.22\n50.76\n52.34": ""
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "man, Portuguese, and Russian. All comparisons",
          "63.35\n47.74\n61.22\n50.76\n52.34": "generally demonstrates stronger zero-shot perfor-"
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "are statistically validated using hypothesis testing",
          "63.35\n47.74\n61.22\n50.76\n52.34": "mance, LLAMA benefits more from instruction"
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "with a significance threshold of p < 0.05. We",
          "63.35\n47.74\n61.22\n50.76\n52.34": "tuning,\nshowing significant\nimprovements after"
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "observed that directly applying SFT to LLMs on",
          "63.35\n47.74\n61.22\n50.76\n52.34": "fine-tuning. Instruction-tuned models (EMO-AYA"
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "the training set (AYAf t) consistently achieves the",
          "63.35\n47.74\n61.22\n50.76\n52.34": "and EMO-LLAMA) provide some advantages in"
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "highest macro F1 scores across all four languages,",
          "63.35\n47.74\n61.22\n50.76\n52.34": "zero-shot settings, particularly in languages with"
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "outperforming all of the other experimented adap-",
          "63.35\n47.74\n61.22\n50.76\n52.34": "less training data, but\ntheir impact diminishes af-"
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "tation approaches, such as: (i) BM25-based ICL (1-",
          "63.35\n47.74\n61.22\n50.76\n52.34": "ter fine-tuning, suggesting that instruction-tuning"
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "shot), (ii) instruction-tuning on the external dataset",
          "63.35\n47.74\n61.22\n50.76\n52.34": "alone is often sufficient for intensity detection."
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "before SFT on the training set (EMO-AYA), (iii)",
          "63.35\n47.74\n61.22\n50.76\n52.34": "Higher-resourced languages,\nsuch as English,"
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "bridging the adaptation with English (E-Bridge),",
          "63.35\n47.74\n61.22\n50.76\n52.34": "Russian, and Spanish, consistently achieve better"
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "or (iv) applying marginalisation to predictions of",
          "63.35\n47.74\n61.22\n50.76\n52.34": "results, with both zero-shot and fine-tuned models"
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "LLMs fine-tuned on Track B (Table 2).",
          "63.35\n47.74\n61.22\n50.76\n52.34": "performing reliably. Mid-resourced languages, in-"
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "These results suggest\nthat LLMs may not sig-",
          "63.35\n47.74\n61.22\n50.76\n52.34": "cluding German, Portuguese, and Romanian, show"
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "nificantly benefit from instruction tuning, as direct",
          "63.35\n47.74\n61.22\n50.76\n52.34": "moderate performance, benefiting from fine-tuning"
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "SFT shows greater effectiveness across all four lan-",
          "63.35\n47.74\n61.22\n50.76\n52.34": "but\nstill exhibiting variability depending on the"
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "guages. E-Bridge can be viewed as a specialised",
          "63.35\n47.74\n61.22\n50.76\n52.34": "model. The performance of all languages improves"
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "form of\ninstruction tuning, where the LLM first",
          "63.35\n47.74\n61.22\n50.76\n52.34": "with fine-tuning, but challenges persist in making"
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "learns instructions in English instances before be-",
          "63.35\n47.74\n61.22\n50.76\n52.34": "significant gains for languages where the models"
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "ing fine-tuned in other\nlanguages.\nThis method",
          "63.35\n47.74\n61.22\n50.76\n52.34": "initially perform poorly. Despite this, the advance-"
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "proves effective for German and Portuguese but",
          "63.35\n47.74\n61.22\n50.76\n52.34": "ments show that fine-tuning and instruction tun-"
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "is less effective for Russian, possibly due to the",
          "63.35\n47.74\n61.22\n50.76\n52.34": "ing can help optimise model behaviour across lan-"
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "closer\ncultural\nalignment\nof German\nand Por-",
          "63.35\n47.74\n61.22\n50.76\n52.34": "guages, and targeted adaptation strategies may fur-"
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "tuguese speakers with English speakers (Rinke and",
          "63.35\n47.74\n61.22\n50.76\n52.34": "ther boost results for emotion intensity detection"
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "Flores, 2021; Wikipedia, 2025).",
          "63.35\n47.74\n61.22\n50.76\n52.34": "tasks."
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "Results on Track B Development Set",
          "63.35\n47.74\n61.22\n50.76\n52.34": "5\nConclusions"
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "The emotion intensity results across multiple lan-",
          "63.35\n47.74\n61.22\n50.76\n52.34": "We participated in the SemEval 2025 Task 11:"
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "guages using both base and instruction-tuned ver-",
          "63.35\n47.74\n61.22\n50.76\n52.34": "Bridging the Gap in Text-Based Emotion shared"
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "sions of AYA and LLAMA in zero-shot and SFT",
          "63.35\n47.74\n61.22\n50.76\n52.34": "task, which included tracks for multi-label emotion"
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "settings are shown in Table 3.\nFine-tuning sig-",
          "63.35\n47.74\n61.22\n50.76\n52.34": "detection (Track A) and emotion intensity detec-"
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "nificantly improves performance across most lan-",
          "63.35\n47.74\n61.22\n50.76\n52.34": "tion (Track B). For Track A, we approached it as"
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "guages, demonstrating that task-specific adaptation",
          "63.35\n47.74\n61.22\n50.76\n52.34": "a binary classification problem for each emotion—"
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "benefits intensity detection. While fine-tuning of-",
          "63.35\n47.74\n61.22\n50.76\n52.34": "determining whether an emotional state is present"
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "fers substantial gains across the languages, the ben-",
          "63.35\n47.74\n61.22\n50.76\n52.34": "in or absent from a given input\ntext snippet. We"
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "efits are often more pronounced in higher-resourced",
          "63.35\n47.74\n61.22\n50.76\n52.34": "found that direct supervised fine-tuning can effec-"
        },
        {
          "Romanian (ron)\n57.92\n47.36\n47.98": "languages\n(i.e., English, Spanish). While AYA",
          "63.35\n47.74\n61.22\n50.76\n52.34": "tively adapt LLMs for the detection of emotions"
        }
      ],
      "page": 5
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "Terrence Zhao, Sandra Kublik, Meor Amer, Viraat"
        },
        {
          "for most languages, except for the lower-resourced": "languages where few-shot learning is more effec-",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": ""
        },
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "Aryabumi, Jon Ander Campos, Yi-Chern Tan, Tom"
        },
        {
          "for most languages, except for the lower-resourced": "tive. For Track B, we achieved the best results by",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": ""
        },
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "Kocmi, Florian Strub, Nathan Grinsztajn, Yannis"
        },
        {
          "for most languages, except for the lower-resourced": "employing different LLMs (both direct SFT and",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": ""
        },
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "Flet-Berliac, Acyr Locatelli, Hangyu Lin, Dwarak"
        },
        {
          "for most languages, except for the lower-resourced": "instruction-tuned) for each language. The results in",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "Talupuru, Bharat Venkitesh, David Cairuz, Bowen"
        },
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "Yang, Tim Chung, Wei-Yin Ko, Sylvie Shang Shi,"
        },
        {
          "for most languages, except for the lower-resourced": "both tracks suggest that, when adapting LLMs for",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": ""
        },
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "Amir Shukayev, Sammie Bae, Aleksandra Piktus, Ro-"
        },
        {
          "for most languages, except for the lower-resourced": "emotion recognition on most mid-resourced and",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": ""
        },
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "man Castagné, Felipe Cruz-Salinas, Eddie Kim, Lu-"
        },
        {
          "for most languages, except for the lower-resourced": "higher-resourced language, instruction-tuning was",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": ""
        },
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "cas Crawhall-Stein, Adrien Morisot, Sudip Roy, Phil"
        },
        {
          "for most languages, except for the lower-resourced": "not as effective as in other NLP tasks. A more",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "Blunsom, Ivan Zhang, Aidan Gomez, Nick Frosst,"
        },
        {
          "for most languages, except for the lower-resourced": "suitable approach is to directly apply supervised",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "Marzieh Fadaee, Beyza Ermis, Ahmet Üstün, and"
        },
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "Sara Hooker. 2024. Aya expanse: Combining Re-"
        },
        {
          "for most languages, except for the lower-resourced": "fine-tuning of LLMs on task-specific datasets.",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": ""
        },
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "search Breakthroughs for a New Multilingual Fron-"
        },
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "tier. Preprint, arXiv:2412.04261."
        },
        {
          "for most languages, except for the lower-resourced": "Limitations",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": ""
        },
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey,"
        },
        {
          "for most languages, except for the lower-resourced": "The exploration of various adaptation strategies",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": ""
        },
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman,"
        },
        {
          "for most languages, except for the lower-resourced": "was limited to four languages (English, German,",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "Akhil Mathur, Alan Schelten, Amy Yang, Angela"
        },
        {
          "for most languages, except for the lower-resourced": "Russian,\nand Portuguese), which may not gen-",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "Fan, et al. 2024. The Llama 3 herd of models. arXiv"
        },
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "preprint arXiv:2407.21783."
        },
        {
          "for most languages, except for the lower-resourced": "eralise\nto\nother\nlanguages,\nparticularly\nlower-",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": ""
        },
        {
          "for most languages, except for the lower-resourced": "resourced ones or\nthose with different\nlinguistic",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": ""
        },
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "Scott A Golder and Michael W Macy. 2011. Diurnal and"
        },
        {
          "for most languages, except for the lower-resourced": "structures.\nThe models used may reflect biases",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "seasonal mood vary with work, sleep, and daylength"
        },
        {
          "for most languages, except for the lower-resourced": "from the training data, which could affect perfor-",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "across diverse cultures.\nScience, 333(6051):1878–"
        },
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "1881."
        },
        {
          "for most languages, except for the lower-resourced": "mance in low-resourced languages. We only ex-",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": ""
        },
        {
          "for most languages, except for the lower-resourced": "plored prompt-tuning and instruction-tuning with",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": ""
        },
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "Edward J Hu, yelong shen, Phillip Wallis, Zeyuan Allen-"
        },
        {
          "for most languages, except for the lower-resourced": "the parameter-efficient LoRA setting for adapting",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu"
        },
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "Chen. 2022. LoRA: Low-rank adaptation of large"
        },
        {
          "for most languages, except for the lower-resourced": "LLMs.",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": ""
        },
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "language models.\nIn International Conference on"
        },
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "Learning Representations."
        },
        {
          "for most languages, except for the lower-resourced": "Ethical Considerations",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": ""
        },
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "Benoit\nJacob, Skirmantas Kligys, Bo Chen, Meng-"
        },
        {
          "for most languages, except for the lower-resourced": "We relied on the dataset providers to remove any",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": ""
        },
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "long Zhu, Matthew Tang, Andrew Howard, Hartwig"
        },
        {
          "for most languages, except for the lower-resourced": "material from the dataset that may reveal anyone’s",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": ""
        },
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "Adam, and Dmitry Kalenichenko. 2018.\nQuanti-"
        },
        {
          "for most languages, except for the lower-resourced": "identity in their posts used in this study. We guar-",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "zation and training of neural networks for efficient"
        },
        {
          "for most languages, except for the lower-resourced": "antee that datasets are only used for scientific or re-",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "integer-arithmetic-only inference.\nIn Proceedings of"
        },
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "the IEEE Conference on Computer Vision and Pat-"
        },
        {
          "for most languages, except for the lower-resourced": "search purposes and are not redistributed or shared",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": ""
        },
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "tern Recognition, pages 2704–2713."
        },
        {
          "for most languages, except for the lower-resourced": "with third parties. This project\nis subject\nto the",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": ""
        },
        {
          "for most languages, except for the lower-resourced": "ethics approval and agreement provided by the",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "Pratik Joshi, Sebastin Santy, Amar Budhiraja, Kalika"
        },
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "Bali, and Monojit Choudhury. 2020. The state and"
        },
        {
          "for most languages, except for the lower-resourced": "SemEval-2025 task organisers.",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": ""
        },
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "fate of linguistic diversity and inclusion in the NLP"
        },
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "world.\nIn Proceedings of the 58th Annual Meeting of"
        },
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "the Association for Computational Linguistics, pages"
        },
        {
          "for most languages, except for the lower-resourced": "References",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": ""
        },
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "6282–6293."
        },
        {
          "for most languages, except for the lower-resourced": "Lisa Feldman Barrett, Batja Mesquita, and Maria Gen-",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": ""
        },
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "Qintong Li, Piji Li, Zhaochun Ren, Pengjie Ren, and"
        },
        {
          "for most languages, except for the lower-resourced": "dron. 2011. Context in emotion perception. Current",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": ""
        },
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "Zhumin Chen. 2022. Knowledge bridging for em-"
        },
        {
          "for most languages, except for the lower-resourced": "Directions in Psychological Science, 20(5):286–290.",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": ""
        },
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "pathetic dialogue generation.\nIn Proceedings of the"
        },
        {
          "for most languages, except for the lower-resourced": "Tadesse Destaw Belay, Israel Abebe Azime, Abinew Ali",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "AAAI Conference on Artificial Intelligence, 10, pages"
        },
        {
          "for most languages, except for the lower-resourced": "Ayele, Grigori Sidorov, Dietrich Klakow, Philip",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "10993–11001."
        },
        {
          "for most languages, except for the lower-resourced": "Slusallek, Olga Kolesnikova, and Seid Muhie Yimam.",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": ""
        },
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "Kristen A Lindquist and Maria Gendron. 2013. What’s"
        },
        {
          "for most languages, except for the lower-resourced": "2025. Evaluating the Capabilities of Large Language",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": ""
        },
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "in a word? Language constructs emotion perception."
        },
        {
          "for most languages, except for the lower-resourced": "Models for Multi-label Emotion Understanding.\nIn",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": ""
        },
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "Emotion Review, 5(1):66–71."
        },
        {
          "for most languages, except for the lower-resourced": "Proceedings of the 31st International Conference on",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": ""
        },
        {
          "for most languages, except for the lower-resourced": "Computational Linguistics, pages 3523–3540. Asso-",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": ""
        },
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "Zhiwei Liu, Kailai Yang, Qianqian Xie, Tianlin Zhang,"
        },
        {
          "for most languages, except for the lower-resourced": "ciation for Computational Linguistics.",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": ""
        },
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "and Sophia Ananiadou. 2024.\nEmollms: A series"
        },
        {
          "for most languages, except for the lower-resourced": "Tom B Brown. 2020. Language models are few-shot",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "of emotional large language models and annotation"
        },
        {
          "for most languages, except for the lower-resourced": "learners. arXiv preprint arXiv:2005.14165.",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "tools for comprehensive affective analysis.\nIn Pro-"
        },
        {
          "for most languages, except for the lower-resourced": "",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "ceedings of the 30th ACM SIGKDD Conference on"
        },
        {
          "for most languages, except for the lower-resourced": "John Dang, Shivalika Singh, Daniel D’souza, Arash",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "Knowledge Discovery and Data Mining, pages 5487–"
        },
        {
          "for most languages, except for the lower-resourced": "Ahmadian, Alejandro Salamanca, Madeline Smith,",
          "Aidan Peppin, Sungjin Hong, Manoj Govindassamy,": "5496."
        }
      ],
      "page": 6
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Saif Mohammad. 2023. Best Practices in the Creation": "the\nand Use of Emotion Lexicons.\nIn Findings of",
          "Stephen Robertson, Steve Walker, Susan Jones, Miche-": "line Hancock-Beaulieu,\nand Mike Gatford. 1995."
        },
        {
          "Saif Mohammad. 2023. Best Practices in the Creation": "Association for Computational Linguistics: EACL",
          "Stephen Robertson, Steve Walker, Susan Jones, Miche-": "Okapi at TREC-3.\nIn TREC."
        },
        {
          "Saif Mohammad. 2023. Best Practices in the Creation": "2023, pages 1825–1836.",
          "Stephen Robertson, Steve Walker, Susan Jones, Miche-": ""
        },
        {
          "Saif Mohammad. 2023. Best Practices in the Creation": "",
          "Stephen Robertson, Steve Walker, Susan Jones, Miche-": "Stephen Robertson, Hugo Zaragoza, et al. 2009. The"
        },
        {
          "Saif Mohammad. 2023. Best Practices in the Creation": "",
          "Stephen Robertson, Steve Walker, Susan Jones, Miche-": "probabilistic relevance framework: BM25 and be-"
        },
        {
          "Saif Mohammad. 2023. Best Practices in the Creation": "Saif Mohammad, Felipe Bravo-Marquez, Mohammad",
          "Stephen Robertson, Steve Walker, Susan Jones, Miche-": ""
        },
        {
          "Saif Mohammad. 2023. Best Practices in the Creation": "",
          "Stephen Robertson, Steve Walker, Susan Jones, Miche-": "yond. Foundations and Trends® in Information Re-"
        },
        {
          "Saif Mohammad. 2023. Best Practices in the Creation": "Salameh, and Svetlana Kiritchenko. 2018. SemEval-",
          "Stephen Robertson, Steve Walker, Susan Jones, Miche-": ""
        },
        {
          "Saif Mohammad. 2023. Best Practices in the Creation": "",
          "Stephen Robertson, Steve Walker, Susan Jones, Miche-": "trieval, 3(4):333–389."
        },
        {
          "Saif Mohammad. 2023. Best Practices in the Creation": "2018 Task 1: Affect in Tweets.\nIn Proceedings of the",
          "Stephen Robertson, Steve Walker, Susan Jones, Miche-": ""
        },
        {
          "Saif Mohammad. 2023. Best Practices in the Creation": "12th International Workshop on Semantic Evaluation,",
          "Stephen Robertson, Steve Walker, Susan Jones, Miche-": ""
        },
        {
          "Saif Mohammad. 2023. Best Practices in the Creation": "",
          "Stephen Robertson, Steve Walker, Susan Jones, Miche-": "Tobias Schröder, Kimberly B Rogers, Shuichirou Ike,"
        },
        {
          "Saif Mohammad. 2023. Best Practices in the Creation": "pages 1–17.",
          "Stephen Robertson, Steve Walker, Susan Jones, Miche-": ""
        },
        {
          "Saif Mohammad. 2023. Best Practices in the Creation": "",
          "Stephen Robertson, Steve Walker, Susan Jones, Miche-": "Julija N Mell, and Wolfgang Scholl. 2013. Affec-"
        },
        {
          "Saif Mohammad. 2023. Best Practices in the Creation": "",
          "Stephen Robertson, Steve Walker, Susan Jones, Miche-": "tive meanings of stereotyped social groups in cross-"
        },
        {
          "Saif Mohammad. 2023. Best Practices in the Creation": "Saif Mohammad and Svetlana Kiritchenko. 2018. Un-",
          "Stephen Robertson, Steve Walker, Susan Jones, Miche-": ""
        },
        {
          "Saif Mohammad. 2023. Best Practices in the Creation": "",
          "Stephen Robertson, Steve Walker, Susan Jones, Miche-": "cultural comparison. Group Processes & Intergroup"
        },
        {
          "Saif Mohammad. 2023. Best Practices in the Creation": "derstanding Emotions: A Dataset of Tweets to Study",
          "Stephen Robertson, Steve Walker, Susan Jones, Miche-": ""
        },
        {
          "Saif Mohammad. 2023. Best Practices in the Creation": "",
          "Stephen Robertson, Steve Walker, Susan Jones, Miche-": "Relations, 16(6):717–733."
        },
        {
          "Saif Mohammad. 2023. Best Practices in the Creation": "Interactions between Affect Categories.\nIn Proceed-",
          "Stephen Robertson, Steve Walker, Susan Jones, Miche-": ""
        },
        {
          "Saif Mohammad. 2023. Best Practices in the Creation": "ings of the Eleventh International Conference on Lan-",
          "Stephen Robertson, Steve Walker, Susan Jones, Miche-": ""
        },
        {
          "Saif Mohammad. 2023. Best Practices in the Creation": "",
          "Stephen Robertson, Steve Walker, Susan Jones, Miche-": "Hinrich Schutze, Christopher D Manning, and Prab-"
        },
        {
          "Saif Mohammad. 2023. Best Practices in the Creation": "guage Resources and Evaluation (LREC 2018), pages",
          "Stephen Robertson, Steve Walker, Susan Jones, Miche-": ""
        },
        {
          "Saif Mohammad. 2023. Best Practices in the Creation": "",
          "Stephen Robertson, Steve Walker, Susan Jones, Miche-": "Introduction to information\nhakar Raghavan. 2008."
        },
        {
          "Saif Mohammad. 2023. Best Practices in the Creation": "198–209. European Language Resources Association",
          "Stephen Robertson, Steve Walker, Susan Jones, Miche-": ""
        },
        {
          "Saif Mohammad. 2023. Best Practices in the Creation": "",
          "Stephen Robertson, Steve Walker, Susan Jones, Miche-": "retrieval. Cambridge University Press."
        },
        {
          "Saif Mohammad. 2023. Best Practices in the Creation": "(ELRA).",
          "Stephen Robertson, Steve Walker, Susan Jones, Miche-": ""
        }
      ],
      "page": 7
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Context in emotion perception",
      "authors": [
        "Lisa Feldman",
        "Batja Mesquita",
        "Maria Gendron"
      ],
      "year": "2011",
      "venue": "Current Directions in Psychological Science"
    },
    {
      "citation_id": "2",
      "title": "Evaluating the Capabilities of Large Language Models for Multi-label Emotion Understanding",
      "authors": [
        "Destaw Tadesse",
        "Israel Belay",
        "Abinew Abebe Azime",
        "Grigori Ali Ayele",
        "Dietrich Sidorov",
        "Philip Klakow",
        "Olga Slusallek",
        "Seid Kolesnikova",
        "Yimam Muhie"
      ],
      "year": "2025",
      "venue": "Proceedings of the 31st International Conference on Computational Linguistics"
    },
    {
      "citation_id": "3",
      "title": "Language models are few-shot learners",
      "authors": [
        "Tom B Brown"
      ],
      "year": "2020",
      "venue": "Language models are few-shot learners",
      "arxiv": "arXiv:2005.14165"
    },
    {
      "citation_id": "4",
      "title": "",
      "authors": [
        "John Dang",
        "Shivalika Singh",
        "D' Daniel",
        "Arash Souza",
        "Alejandro Ahmadian",
        "Madeline Salamanca",
        "Aidan Smith",
        "Sungjin Peppin",
        "Manoj Hong",
        "Terrence Govindassamy",
        "Sandra Zhao",
        "Meor Kublik",
        "Viraat Amer",
        "Jon Aryabumi",
        "Yi-Chern Campos",
        "Tom Tan",
        "Florian Kocmi",
        "Nathan Strub",
        "Yannis Grinsztajn",
        "Acyr Flet-Berliac",
        "Hangyu Locatelli",
        "Dwarak Lin",
        "Bharat Talupuru",
        "David Venkitesh",
        "Bowen Cairuz",
        "Tim Yang",
        "Wei-Yin Chung",
        "Sylvie Ko",
        "Amir Shi",
        "Sammie Shukayev",
        "Bae"
      ],
      "year": "2024",
      "venue": "",
      "arxiv": "arXiv:2412.04261"
    },
    {
      "citation_id": "5",
      "title": "The Llama 3 herd of models",
      "authors": [
        "Abhimanyu Dubey",
        "Abhinav Jauhri",
        "Abhinav Pandey",
        "Abhishek Kadian",
        "Ahmad Al-Dahle",
        "Aiesha Letman",
        "Akhil Mathur",
        "Alan Schelten",
        "Amy Yang",
        "Angela Fan"
      ],
      "year": "2024",
      "venue": "The Llama 3 herd of models",
      "arxiv": "arXiv:2407.21783"
    },
    {
      "citation_id": "6",
      "title": "Diurnal and seasonal mood vary with work, sleep, and daylength across diverse cultures",
      "authors": [
        "A Scott",
        "Michael Golder",
        "Macy"
      ],
      "year": "2011",
      "venue": "Science"
    },
    {
      "citation_id": "7",
      "title": "LoRA: Low-rank adaptation of large language models",
      "authors": [
        "J Edward",
        "Phillip Hu",
        "Zeyuan Wallis",
        "Yuanzhi Allen-Zhu",
        "Shean Li",
        "Lu Wang",
        "Weizhu Wang",
        "Chen"
      ],
      "year": "2022",
      "venue": "International Conference on Learning Representations"
    },
    {
      "citation_id": "8",
      "title": "Quantization and training of neural networks for efficient integer-arithmetic-only inference",
      "authors": [
        "Benoit Jacob",
        "Skirmantas Kligys",
        "Bo Chen",
        "Menglong Zhu",
        "Matthew Tang",
        "Andrew Howard",
        "Hartwig Adam",
        "Dmitry Kalenichenko"
      ],
      "year": "2018",
      "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition"
    },
    {
      "citation_id": "9",
      "title": "The state and fate of linguistic diversity and inclusion in the NLP world",
      "authors": [
        "Pratik Joshi",
        "Sebastin Santy",
        "Amar Budhiraja",
        "Kalika Bali",
        "Monojit Choudhury"
      ],
      "year": "2020",
      "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "10",
      "title": "Knowledge bridging for empathetic dialogue generation",
      "authors": [
        "Qintong Li",
        "Piji Li",
        "Zhaochun Ren",
        "Pengjie Ren",
        "Zhumin Chen"
      ],
      "year": "2022",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence"
    },
    {
      "citation_id": "11",
      "title": "What's in a word? Language constructs emotion perception",
      "authors": [
        "Kristen Lindquist",
        "Maria Gendron"
      ],
      "year": "2013",
      "venue": "Emotion Review"
    },
    {
      "citation_id": "12",
      "title": "Emollms: A series of emotional large language models and annotation tools for comprehensive affective analysis",
      "authors": [
        "Zhiwei Liu",
        "Kailai Yang",
        "Qianqian Xie",
        "Tianlin Zhang",
        "Sophia Ananiadou"
      ],
      "year": "2024",
      "venue": "Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining"
    },
    {
      "citation_id": "13",
      "title": "Best Practices in the Creation and Use of Emotion Lexicons",
      "authors": [
        "Saif Mohammad"
      ],
      "year": "2023",
      "venue": "Findings of the Association for Computational Linguistics: EACL 2023"
    },
    {
      "citation_id": "14",
      "title": "SemEval-2018 Task 1: Affect in Tweets",
      "authors": [
        "Saif Mohammad",
        "Felipe Bravo-Marquez",
        "Mohammad Salameh",
        "Svetlana Kiritchenko"
      ],
      "year": "2018",
      "venue": "Proceedings of the 12th International Workshop on Semantic Evaluation"
    },
    {
      "citation_id": "15",
      "title": "Understanding Emotions: A Dataset of Tweets to Study Interactions between Affect Categories",
      "authors": [
        "Saif Mohammad",
        "Svetlana Kiritchenko"
      ],
      "year": "2018",
      "venue": "Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)"
    },
    {
      "citation_id": "16",
      "title": "Ethics sheet for automatic emotion recognition and sentiment analysis",
      "authors": [
        "M Saif",
        "Mohammad"
      ],
      "year": "2022",
      "venue": "Computational Linguistics"
    },
    {
      "citation_id": "17",
      "title": "",
      "authors": [
        "Shamsuddeen Hassan",
        "Nedjma Ousidhoum",
        "Idris Abdulmumin",
        "Jan Philip Wahle",
        "Terry Ruas",
        "Meriem Beloucif",
        "Christine De Kock",
        "Nirmal Surange",
        "Daniela Teodorescu",
        "Ibrahim Ahmad",
        "David Ifeoluwa Adelani",
        "Alham Fikri Aji",
        "D Felermino",
        "Ilseyar Ali",
        "Vladimir Alimova",
        "Nikolay Araujo",
        "Naomi Babakov",
        "Ana-Maria Baes",
        "Andiswa Bucur",
        "Guanqun Bukula",
        "Rodrigo Cao",
        "Rendi Cardenas",
        "Chevi"
      ],
      "year": "2025",
      "venue": "",
      "arxiv": "arXiv:2502.11926"
    },
    {
      "citation_id": "18",
      "title": "b. SemEval task 11: Bridging the gap in text-based emotion detection",
      "authors": [
        "Shamsuddeen Hassan",
        "Nedjma Ousidhoum",
        "Idris Abdulmumin",
        "Muhie Seid",
        "Jan Yimam",
        "Terry Philip Wahle",
        "Meriem Ruas",
        "Christine Beloucif",
        "Daniela De Kock ; Nirmal Surange",
        "David Teodorescu",
        "Alham Ifeoluwa Adelani",
        "Felermino Fikri Aji",
        "Vladimir Ali",
        "Abinew Araujo",
        "Oana Ali Ayele",
        "Alexander Ignat",
        "Yi Panchenko",
        "Saif Zhou",
        "Mo"
      ],
      "year": "2025",
      "venue": "Proceedings of the 19th International Workshop on Semantic Evaluation"
    },
    {
      "citation_id": "19",
      "title": "Portuguese as heritage language in Germany-A linguistic perspective",
      "authors": [
        "Esther Rinke",
        "Cristina Flores"
      ],
      "year": "2021",
      "venue": "Languages"
    },
    {
      "citation_id": "20",
      "title": "Okapi at TREC-3",
      "authors": [
        "Stephen Robertson",
        "Steve Walker",
        "Susan Jones",
        "Micheline Hancock-Beaulieu",
        "Mike Gatford"
      ],
      "year": "1995",
      "venue": "TREC"
    },
    {
      "citation_id": "21",
      "title": "The probabilistic relevance framework: BM25 and beyond",
      "authors": [
        "Stephen Robertson",
        "Hugo Zaragoza"
      ],
      "year": "2009",
      "venue": "Foundations and Trends® in Information Retrieval"
    },
    {
      "citation_id": "22",
      "title": "Affective meanings of stereotyped social groups in crosscultural comparison",
      "authors": [
        "Tobias Schröder",
        "Kimberly Rogers",
        "Shuichirou Ike",
        "Julija Mell",
        "Wolfgang Scholl"
      ],
      "year": "2013",
      "venue": "Group Processes & Intergroup Relations"
    },
    {
      "citation_id": "23",
      "title": "Introduction to information retrieval",
      "authors": [
        "Hinrich Schutze",
        "Christopher Manning",
        "Prabhakar Raghavan"
      ],
      "year": "2008",
      "venue": "Introduction to information retrieval"
    },
    {
      "citation_id": "24",
      "title": "Rank BM",
      "authors": [
        "Dorian Stuart"
      ],
      "year": "2022",
      "venue": "Rank BM"
    },
    {
      "citation_id": "25",
      "title": "Open foundation and fine-tuned chat models",
      "authors": [
        "Hugo Touvron",
        "Louis Martin",
        "Kevin Stone",
        "Peter Albert",
        "Amjad Almahairi",
        "Yasmine Babaei",
        "Nikolay Bashlykov",
        "Soumya Batra",
        "Prajjwal Bhargava",
        "Shruti Bhosale"
      ],
      "year": "2023",
      "venue": "Open foundation and fine-tuned chat models",
      "arxiv": "arXiv:2307.09288"
    },
    {
      "citation_id": "26",
      "title": "Emotion-infused models for explainable psychological stress detection",
      "authors": [
        "Elsbeth Turcan",
        "Smaranda Muresan",
        "Kathleen Mckeown"
      ],
      "year": "2021",
      "venue": "Proceedings of the 2021 conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies"
    },
    {
      "citation_id": "27",
      "title": "Aya Model: An instruction finetuned open-access multilingual language model",
      "authors": [
        "Ahmet Üstün",
        "Viraat Aryabumi",
        "Zheng-Xin Yong",
        "Wei-Yin Ko",
        "D' Daniel",
        "Gbemileke Souza",
        "Neel Onilude",
        "Shivalika Bhandari",
        "Hui-Lee Singh",
        "Amr Ooi",
        "Kayid"
      ],
      "year": "2024",
      "venue": "Aya Model: An instruction finetuned open-access multilingual language model",
      "arxiv": "arXiv:2402.07827"
    },
    {
      "citation_id": "28",
      "title": "Shared heritage of German and English",
      "authors": [
        "Wikipedia"
      ],
      "year": "2025",
      "venue": "Shared heritage of German and English"
    },
    {
      "citation_id": "29",
      "title": "Instruction tuning for large language models: A survey",
      "authors": [
        "Shengyu Zhang",
        "Linfeng Dong",
        "Xiaoya Li",
        "Sen Zhang",
        "Xiaofei Sun",
        "Shuhe Wang",
        "Jiwei Li",
        "Runyi Hu",
        "Tianwei Zhang",
        "Fei Wu"
      ],
      "year": "2023",
      "venue": "Instruction tuning for large language models: A survey",
      "arxiv": "arXiv:2308.10792"
    }
  ]
}