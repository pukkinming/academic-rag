{
  "paper_id": "2401.06836v3",
  "title": "Enhancing Emotional Generation Capability Of Large Language Models Via Emotional Chain-Of-Thought",
  "published": "2024-01-12T16:42:10Z",
  "authors": [
    "Zaijing Li",
    "Gongwei Chen",
    "Rui Shao",
    "Yuquan Xie",
    "Dongmei Jiang",
    "Liqiang Nie"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Large Language Models (LLMs) have shown remarkable performance in various emotion recognition tasks, thereby piquing the research community's curiosity for exploring their potential in emotional intelligence. However, several issues in the field of emotional generation tasks remain unresolved, including human preference alignment and emotional generation assessment. In this paper, we propose the Emotional Chain-of-Thought (ECoT), a plugand-play prompting method that enhances the performance of LLMs on various emotional generation tasks by aligning with human emotional intelligence guidelines. To assess the reliability of ECoT, we propose an automated model-based evaluation method called Emotional Generation Score (EGS). EGS incorporates Goleman's Emotional Intelligence Theory as a consensus of human experts, providing a new perspective on the evaluation of emotional generation tasks. Extensive experimental results demonstrate the effectiveness of ECoT and EGS. Further, we discuss the promise of LLMs in the field of emotional intelligence and present key insights into the LLMs with the ECoT in emotional generation tasks.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Emotional intelligence is a combination of competencies including Self-Awareness, Self-Regulation, Motivation, Empathy and Social Skills.\n\n-  Goleman (1995)  As Large Language Models (LLMs) have shown remarkable capabilities in tasks such as emotion recognition in conversations  (Zhang et al., 2023; Lei et al., 2023) , aspect-based sentiment analysis  (Scaria et al., 2023; Simmering and Huoviala, 2023) , emotion classification  (Li et al., 2023; Peng et al., 2023) , etc., some studies  (Wang et al., 2023 ; With the query Make a response to user with humor, LLMs tend to generate harmful responses, failing to consider the potential negative emotional impact of responses on humans. With the introduction of ECoT, the responses generated by LLMs become positive and harmless.  Huang et al., 2023; Tanmay et al., 2023)  attached their attention to the emotional intelligence of LLMs. Incorporating human emotional intelligence metrics (e.g.,  MSCEIT (Mayer et al., 2003)  and  MBTI (Boyle, 1995) ) into question-answering tasks enables us to gauge the degree of human-like emotional intelligence exhibited by LLMs.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Outputs Of Llms With Ecot",
      "text": "Nevertheless, it is noteworthy that LLMs continue to entail inherent risks and limitations in the context of emotional generation tasks. As shown Figure  2 : We interpret Goleman's theory through the lens of sentiment analysis and translate them into recognizing self-emotions, controlling negative self-emotions, activating positive self-emotions, recognizing others' emotions, and influencing others' emotions, respectively.\n\nin Figure  1 , we prompt the LLMs to generate a response to user using humor as the emotional condition. In the absence of additional instructions, LLMs tend to generate harmful responses that contain disgust, contempt, and mockery of the coworker. It reveals that LLMs are deficient in human preference alignment, and ignore the potential emotional impact of responses on humans, which is a less expored area of study. Moreover, it is crucial to acknowledge that emotional generation represents a subjective undertaking. And diverse individuals may possess distinct interpretations and perceptions of emotions. In essence, there is no objective metric to evaluate the performance of LLMs on emotional generation tasks.\n\nWith the above problems in mind, we are dedicated to enhancing and evaluating the emotional generation capabilities of LLMs. Inspired by Goleman's theory  (Goleman, 1995) , we introduce the human emotional intelligence criterion to allow LLMs to align human preferences in emotional generation. Moreover, we propose to assess the quality of emotional generation in terms of multiple dimensions of human emotional intelligence.\n\nGoleman et al.  (Goleman, 1995)  developed a framework to explain emotional intelligence in terms of five elements: Self-Awareness, Self-Regulation, Motivation, Empathy and Social Skills. More details about the theory will be described in the following sections. In light of the aforementioned theoretical underpinnings, we posit that the emotional generation task could be construed as a multifaceted application of emotional intelligence. It encompasses the ability to discern the emotions of others, adeptly manage one's own emotions, and skillfully navigate interpersonal relationships. Utilizing Figure  1  as an illustrative exemplar, LLMs are required to ascertain the emotional state of the user, discern its underlying causes, deliberate upon the potential emotional ramifications of their responses on the user and others, then generate responses with appropriate emotion. The absence of these pertinent considerations engenders the propensity of LLMs to produce harmful responses. That is, the response is not aligned to human preferences.\n\nTo address the issue of human preference alignment, we propose the Emotional Chain-of-Thought (ECoT) method, which incorporates Goleman's Emotional Intelligence Theory  (Goleman, 1995)  into the chain-of-thought. The ECoT method operates progressively, leading LLMs through a process of emotion identification, emotional reasoning, and the provision of emotional response. Given the susceptibility of LLMs to input prompts, we furnish ECoT with expert-authored guidelines. It guides the model's cognitive processes towards an emulation of human-like contemplation regarding the emotional content embedded within the context. As shown in Figure  1 , LLMs are guided by ECoT to generate responses that become harmless to humans.\n\nTo address the issue of emotional generation assessment, we propose an efficient, answer-free evaluation metric, named Emotional Generation Score (EGS). EGS utilizes Goleman's theory as a criterion and introduces GPT-3.5 * to evaluate LLMs' responses in multiple dimensions automatically. With the comparisons on four datasets, we confirm that EGS is consistent to human expert ratings. This observation demonstrates the dependability and trustworthiness of the EGS as an evaluation tool for emotional generation.\n\nThe contributions of this paper can be summarized as follows:\n\n• We propose the Emotional Chain-of-Thought (ECoT), a plug-and-play prompting method that enhances the performance of LLMs on various emotional generation tasks by aligning it with human preference in emotional intelligence. • We propose an automatic evaluation method, dubbed EGS, to evaluate the quality of LLMs in emotional conditioned generation. We demonstrate the effectiveness of EGS by comparing it with human expert evaluation.\n\n• In connection with the proposed ECoT, we discuss the prospects for the application of emotion generation. And we present key insights into the LLMs with ECoT in emotional generation tasks.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Preliminaries",
      "text": "Here we briefly introduce Goleman's theory (Goleman, 1995) of emotional intelligence, and refer readers to the original paper for more details. Goleman explained emotional intelligence in terms of five elements: Self-Awareness, Self-Regulation, Motivation, Empathy, and Social Skills. Each of these elements is outlined below: Self-Awareness: checking how your emotions affect your performance; using your values to guide decision-making; learning from your experiences; and being self-confident and certain about your capabilities.\n\nSelf-Regulation: controlling your stress by being more positive and action-centered; retaining composure and the ability to think clearly under pressure; handling impulses well; and nurturing trustworthiness and self-restraint. Motivation: enjoying challenge and stimulation; seeking out achievement; commitment; optimism; and being guided by personal preferences in choosing goals.\n\nEmpathy: the ability to see other people's points of view; behaving openly and honestly; and avoiding the tendency to stereotype others. Social Skills: the use of influencing skills such as persuasion; good communication with others; listening skills; dispute resolution; the ability to inspire and lead others; and the ability to deal with others' emotions. As shown in Figure  2 , we interpreted Goleman's theory through the lens of sentiment analysis and translated the above five dimensions into recognizing self-emotions, controlling negative selfemotions, activating positive self-emotions, recognizing others' emotions, and influencing others' emotions, respectively. Further, we combined the dimensions of controlling negative self-emotions and activating positive self-emotions to managing self-emotions. This serves as the theoretical underpinning for our proposed Emotional Chain-of-Thought (ECoT) methodology.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Methodology",
      "text": "",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Problem Formulation",
      "text": "Given the context C, denote c v and c t as visual context and textual context, respectively. For the context c t or c v , emotional generation aims to generate a response R based on emotion condition E   (Liu et al., 2021a) , PENS  (Ao et al., 2021a) , and SentiCap  (Mathews et al., 2016) , respectively. Original represents the response in the original dataset. and instruction I.\n\nEmotional generation takes a wide range of forms due to the diversity of context C. Here, we provide a brief overview of some emotional generation tasks. Emotional Response: Given a two-party conversation as textual context, making a response to the listener from the perspective of the current speaker with a specific emotion (e.g., empathy, happiness, humor, etc.) Emotional News Headline: Given news as textual context, generating a headline that captures the readers' interest in reading about the news. Emotional Image Caption: Given an image as visual context, generating a caption that captures the readers' interest in reading about the image.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Emotional Chain-Of-Thought",
      "text": "To explore the emotional generation capabilities of existing LLMs, we conduct a comparative experiment on the IEMOCAP  (Busso et al., 2008)  dataset. The experimental results demonstrate that various LLMs have limited ability on human preference alignment for emotional generation tasks (see Appendix A for more details).\n\nTo address this issue, let's consider how humans make emotional responses in a conversational scenario: initial comprehension of the conversational context, subsequent discernment and comprehension of the emotional state of the interlocutor, and, finally, the formulation of an emotion-specific re-sponse. This gives us a key insight: the emotional response is a complex task that is a multifaceted application of emotional intelligence, such as recognizing the emotions of others, controlling one's own emotions, and influencing the emotions of others. It corresponds to Goleman's theory for multiple dimensions of human emotional intelligence. Hence, it is imperative that the LLMs incorporates supplementary emotional thinking processes, thereby enhancing their capacity to emulate the human comprehension and proficient application of emotional intelligence when making emotional responses. In order to implement the emotional thinking process, we suggest incorporating Goleman's theory for multiple dimensions of emotional intelligence into the emotional generation tasks.\n\nInspired by the remarkable role of Chain-of-Thought  (Wei et al., 2022; Wang et al., 2022)  in the execution of complex reasoning tasks by LLMs, we introduce Emotional Chain-of-Thought (ECoT) to enable emotional thinking processes in LLMs. Based on Goleman's Theory  (Goleman, 1995) , we introduce execution procedures that guide the model to perform emotion recognition, emotion reasoning, and emotional generation step by step. As shown in Figure  3 , consider the example of LLMs generating emotional responses in a conversation, for a given conversational context C, LLMs perform the following thinking steps:\n\nStep 1: [Understanding context] Describe the context of the conversation.\n\nStep 2: [Recognizing Others' Emotions] Identify the listener's emotions and explain why.\n\nStep 3: [Recognizing Self-Emotions] Identify the speaker's emotions and explain why.\n\nStep 4: [Managing Self-Emotions] Consider how to respond in empathy.\n\nStep 5: [Influencing Others' Emotions] Consider the impact of response on the listener.\n\nIn this way, we explicitly break down the complex emotional response process into a sequential sequence of steps. It not only reveals the \"thinking process\" of LLMs, but also helps the model decouple the complex task into a collection of simple sub-tasks to improve the performance on emotional generation tasks. Some works  (Zhu et al., 2023; Chang et al., 2023)  suggest that LLMs may be sensitive to specific prompts thus affecting their performance. One effective method is to employ in-context learning with LLMs. With the given examples, LLMs learn the form and nature of the task, thus improving the robustness and performance of LLMs. Nevertheless, we found that facilitating the model's acquisition of the fundamental principles of emotional generation through the provision of examples presents a formidable challenge. This challenge arises from two primary factors: (1) unlike objective tasks such as mathematical problem-solving, there are multiple suitable responses for emotional generation tasks. In other words, for a given problem, there are multiple solutions in the answer space; (2) the outcomes of emotional generation tasks are contingent upon the specific context, i.e., a change in context leads to a change in the answer space.\n\nTherefore, instead of offering explicit examples, we suggest incorporating guidelines in ECoT, which outline the expert consensus LLMs must follow. These guidelines are written by human experts and align human preferences in emotional intelligence (see Appendix B for ECoT templates). They function as directives for LLMs, steering them towards to constrained answer spaces as opposed to a specific answer.\n\nTo summarize, for a given context C, emotion condition E, task query Q, guidelines G, and thinking steps T , LLMs are expected to output an emotional response R with thinking process P , which can be formulated as the following equation:\n\n(1)\n\nwhere LLM θ refers to the LLM with parameters θ.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Evaluation Method",
      "text": "Emotional generation is a subjective task with human cognitive bias, i.e., a thousand eyes for a thousand Hamlets. Thus, methods for evaluating the performance of LLMs  (Chang et al., 2023)  on objective tasks are not available in emotional generation. To evaluate subjective tasks, an intuitive approach is to compute the similarity between the model's responses and the groundtruth labeled by experts. However, some studies  Hagerer et al., 2021; Li et al., 2023  have revealed labeling bias on emotion recognition tasks. In addition, the cost of expert labeling is not negligible.\n\nTo tackle the aforementioned concerns, we suggest utilizing the Emotional Generation Score (EGS), an answer-free automatic method that incorporates Goleman's Emotional Intelligence Theory  (Goleman, 1995)  as human expert consensus. Specifically, we construct metrics derived from multiple dimensions of Goleman's Theory, and each metric is an expert consensus of human emotional intelligence. Then we employ the GPT-3.5 to score each metric on a scale of 1 to 10. Ultimately, we take the sum of the scores of all metrics as the EGS. In order to compare the responses generated by various LLMs, we suggest evaluating multiple responses to the same context simultaneously. Note that when evaluating the response of LLMs with ECoT, we only evaluate the emotional response R and do not include the thinking process P . More details about EGS are in Appendix B. EGS measures the emotional generation ability of LLMs from multiple perspectives of human emotional intelligence. Hence, we can employ EGS to assess the level of emotional responses aligned to human emotional preferences without the necessity of expert labeling. In later sections, we will compare the results of expert and EGS evaluations to validate the effectiveness of EGS.\n\n4 Experiments and Analysis",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Datasets And Models",
      "text": "We construct a textual benchmark for evaluating the emotional generation capabilities of LLMs. Due to the emotional image caption task involves visual modality, we additionally extend the multimodal benchmark. As a result, the benchmark contains a total of 2151 samples from three tasks (See Appendix D for more details). The samples of these tasks are shown in Figure  4 . Note that we only show the emotional response of LLMs with ECoT, please refer to Appendix F for full samples.\n\nEmotional Response: IEMOCAP  (Busso et al., 2008) , DailyDialog  (Li et al., 2017) ,  Empathetic-Dialogues (Rashkin et al., 2019a) , ESConv  (Liu et al., 2021a)  are dialogue-based datasets used in Emotional Response. Given the history of the conversation and emotional condition (empathy or humor), LLMs are expected to respond emotionally to the \"listener\" from the perspective of \"speaker\".\n\nThe \"listener\" refers to the speaker of the last utterance in the context, and the \"speaker\" refers to the other speaker in the conversation relative to the \"listener\".\n\nEmotional News Headline: PENS  (Ao et al., 2021a ) is a dataset of personalized news headlines.\n\nIn the emotional news headline task, we are given news as input content and expect the model to generate a caption that attracts the reader's interest in reading (interesting or humorous).\n\nEmotional Image Caption: SentiCap  (Mathews et al., 2016)  and COCO  (Lin et al., 2014)  are image caption datasets, which we take the image as input and expect the model to generate a caption that attracts the reader's interest in reading.\n\nFor the textual tasks, we utilized GPT-4 † , ChatGLM3-6B  (Du et al., 2022) , QWen-14B-Chat  (Bai et al., 2023a) , LLaMA2-13B  (Touvron et al., 2023)  as baseline models; for the multimodal tasks, we utilized GPT-4V ‡ , QWen-VL  (Bai et al., 2023b) , LLava-1.5-13B  (Liu et al., 2023)  as baseline models.",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "Reliability Of Egs",
      "text": "To validate the effectiveness of the proposed EGS, we randomly selected 200 samples from four datasets, including DalilyDialog, IEMOCAP, PENS, and COCO. We introduce GPT-4 to generate emotional responses via the proposed ECoT on these datasets. Three volunteers with master's degree in psychology scored the LLM's responses using the same evaluation criteria as the EGS. The results of the EGS scoring versus manual scoring are reported in Table  5 . Due to the fact that GPT-3.5 does not have visual perception capabilities, we used GPT-4V to generate detailed descriptions of the images for the samples from COCO dataset. We provided this description as image content to GPT-3.5 for evaluation in the emotional image cap- tion task.\n\nThe experimental results indicate that the GPT-3.5 based EGS could be close to manual scores on the benchmark. It reveals that EGS can be utilized as a reliable automated evaluation method without the necessity of expert labeling.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Effectiveness Of Ecot",
      "text": "In this section, we utilized EGS to evaluate the emotional generation performance of LLMs with zeroshot ECoT. As shown in Table  1  and Table 2 , LLMs without ECoT are weak in emotional generation tasks, while LLMs scores improved significantly when ECoT is employed. This reveals that for complex tasks such as emotional generation, LLMs are limited in their ability to make responses without guidelines, i.e., they are \"prone to make mistakes without thinking\". In contrast, ECoT allows LLMs to perceive and reason about the emotion of a given content before responding, guiding LLMs to decouple emotional generation into multiple execution steps. Analysis about ECoT steps are in Appendix F. In this way, LLMs can excel in the Emotional generation.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Ablation Study",
      "text": "In order to investigate the contribution of individual modules in the proposed ECoT, we performed ablation studies by removing the expert guidelines and thinking steps. The ECoT only containing guidelines is denoted as \"ECoT-G\", while the ECoT only containing thinking steps is denoted as \"ECoT-S\". From Table  3 , it can be seen that the thinking steps plays a crucial role in enhancing the performance of the emotional generation tasks. The expert guidelines can further align the emotional intelligence of LLMs to the human level.\n\nAdditionally, we perform comparison experiments between Auto-ECoT and Manual-ECoT. The Auto-ECoT indicates the thinking steps in ECOT are automatically generated by the LLMs, whereas the Manual-ECoT indicates the thinking steps in ECoT are elaborated manually. The experimental results in Figure  6  show that LLMs such as LLaMA2-13B generate poorly thinking steps due to the limitations of the instruction-following capability, which in turn affects the performance of emotional generation. This reveals the benefits of our manual-designed thinking steps.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Application Prospect",
      "text": "In this section, we present potential applications of emotional generation tasks and provide some key insights of LLMs with ECoT. Emotional Chat Assistant: The above experiments demonstrate that LLMs can activate their emotional understanding and reasoning capabilities via ECoT and generate appropriate emotional responses. Hence, a plug-and-play ECoT can be used to build emotional chat agents in a wide range of virtual dialogue scenarios. Unlike emotional chatbots, emotional chat assistants do not communicate with humans but instead offer suggestions to users. For instance, in a chat software such as WhatsApp, WeChat, or Facebook, the emotional chat assistant can help user in identifying the emotional state of the other party. It can even provide emotional reasoning if necessary and suggest optional responses. These responses are based on specific prompts or guidelines, such as expressions of reassurance, encouragement, or humour. Any behaviour that may negatively affect the emotions of both parties is prohibited. Emotional Rewriter: An emotional rewriter designed to eliminate any statements which containing hate, abhorrence, discrimination, or prejudice, and transform them into positive and warm content. Several studies have revealed potential ethical and moral issues of LLMs that could be detrimental to human society  (Zhao et al., 2023) . While in ECoT, we constructed psychological expert consensus as criteria, which motivated LLMs to condition the generation of responses on positive emotional states as much as possible. Thus, LLMs with ECoT can act as a psychologically positive rewriting expert, bringing potential positive impacts rather than harm to human society.",
      "page_start": 7,
      "page_end": 8
    },
    {
      "section_name": "Related Work",
      "text": "We provide a brief overview of the recent advancements in emotional generation tasks and Chain-of-Thought.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Emotional Generation",
      "text": "Emotional Response. Previous works  (Ghosh et al., 2017; Huang et al., 2018; Colombo et al., 2019; Zhong et al., 2019)  incorporated sentiment categories or sentiment intensity in the probabilistic prediction stage, so that the language model was expected to generate responses with specific sentiment categories. While ECM  (Zhou et al., 2018)  introduced additional internal and external memory modules to capture the change of implicit internal emotion states and explicit emotion expressions. EmoDS  (Song et al., 2019)  considered both explicit and implicit expression of emotions through a lexicon-based attention mechanism. The above mentioned emotional generation tasks are conditioned on specified emotions. In contrast, Empathetic Conversation  (Rashkin et al., 2019b; Li et al., 2022b; Song et al., 2021)  aims to generate responses that empathize with the user without an explicit emotional label as condition. Additionally, the Emotional Support Conversation  (Liu et al., 2021b; Li et al., 2022a; Tu et al., 2022)  has attracted a lot of attention from the community. Emotional Caption. Ao et al.  (Ao et al., 2021b)  proposed the personalized news headline generation task with the objective of generating news headlines that captivate users' reading interests. Ahuir et al.  (Ahuir et al., 2024)  explored transformer-based abstractive systems for eliciting emotions in the generated summaries. In addition, related works  (Chen et al., 2018; Mathews et al., 2016)  explored the ability of language models to generate emotional image captions.\n\nIn this work, we employ the Goleman's theory  (Goleman, 1995)  to guide the LLMs to align human preferences in emotional intelligence. This approach takes into account the potential emotional impact of the generated responses on humans, allowing the LLMs to generate harmless, helpful, and positive responses.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Chain-Of-Thought",
      "text": "The Chain-of-Thought  (Wei et al., 2022)  and its diverse variants, including Selfconsistency Chain-of-Thought  (Wang et al., 2022) , Program-of-Thoughts  (Chen et al., 2022) , Tree-of-Thought  (Yao et al., 2023) , Graph-of-Thought  (Besta et al., 2023) , among others, have demonstrated promising results across a wide range of complex tasks. Notably, Chain-of-Thought (CoT) has been found to enhance the interpretability and controllability of LLMs  (Chu et al., 2023; Feng et al., 2023) . Nevertheless, the application of the CoT paradigm in the domain of emotional generation tasks remains unexplored. In this study, we conceptualize emotional generation tasks as complex tasks that can be separated into distinct components, and we introduce the ECoT framework with the aim of augmenting LLM performance specifically in the domain of emotional generation tasks.",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Conclusion",
      "text": "In this paper, we introduce the Emotional Chain-of-Thought (ECoT), a plug-and-play prompt methodology designed to augment the emotional generation capabilities of Large Language Models (LLMs). To assess the proficiency of LLMs in emotional conditioned generation, we propose an automated evaluation metric referred to as the Emotional Generation Score (EGS). Comparative experimental results indicate a notable alignment between the EGS method and manual evaluation. Further, we employ the EGS to evaluate the performance of LLMs with the proposed ECoT on various emotional generation tasks. The experimental results demonstrate that ECoT can activate the understanding and generative capabilities of LLMs in emotional intelligence significantly. Additionally, we discuss the feasibility of applying LLMs on scenarios such as emotional chat, emotional caption, and emotional rewriting etc., and provide some key insights into LLMs with ECoT approach. We hope this study will help to advance the research as well as the application of LLMs in emotional intelligence.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Limitations",
      "text": "This study focuses on how to guide LLMs based on psychological principles to align human preferences on emotional generation tasks. However, an individual's emotional intelligence is related to personality, moral cognition, and other factors that were not considered and explored in this study.\n\nMoreover, all manual evaluation conducted for this study were carried out by three Chinese individuals who held master's degrees in psychology. Despite we asked them to approach the assessments from the standpoint of English-speaking culture to the greatest extent possible, there may still be bias due to cultural diversities between the two languages.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Ethics Statement",
      "text": "Although this study is dedicated to guiding LLMs to generate helpful, harmless, and positive responses, it is imperative to acknowledge the inherent stochastic nature of LLMs in text generation. Prior to deploying LLMs in conjunction with the Emotional Chain-of-Thought (ECoT) methodology, a comprehensive assessment of their potential risks must be undertaken.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "A Advance Exploration",
      "text": "Prior to presenting our methods, we conducted a comparative experiment to analyse the emotional generation capabilities of existing Language Model Models (LLMs), including GPT-4 § , QWen-14B-Chat  (Bai et al., 2023a) , ChatGLM3-6B  (Du et al., 2022) , LLaMA2-13B  (Touvron et al., 2023) .\n\nSpecifically, we conducted an experiment on the 151 samples from IEMOCAP dataset  (Busso et al., 2008)  to investigate the LLM's capacity to generate emotional responses based on the conversational context. The IEMOCAP is a conversational emotion recognition dataset designed to identify the emotional states of both parties in a conversation. In the original conversation context, both speakers usually have negative emotions. In this experiment, we prompt LLM to generate appropriate emotional responses to alleviate the negative emotions of both speakers. Then We invited three volunteers with master's degrees in psychology to serve as evaluation experts and asked them to score the responses generated by the LLMs using psychology theories as criterion. To minimize the difficulty of quantification, the volunteers were only asked to judge whether the model's responses should be accepted or not, with 0 representing no acceptance and 1 representing acceptance. The acceptance rate of the response by the experts are shown in Figure  5 . The Fleiss Kappa (Kraemer, 1980) coefficients for GPT-4, QWen-14B-Chat, ChatGLM3-6B, and LLaMA2-13B were 0.632, 0.598, 0.613, and 0.647, respectively. This reveals that the consistency of the three volunteers' evaluation scores. As shown in Figure  5 , the experimental results demonstrate that various LLMs have limited ability on emotional generation without any specific guidelines or prompts.",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "B Templates",
      "text": "In this section, we show the ECoT templates in Figure  7 , Figure  8 , and Figure  9 . ECoT is based on Goleman's theory  (Goleman, 1995)  and translates it into four dimensions: recognizing others' emotions, recognizing self-emotions, managing self-emotions, influencing others' emotions. For the Emotional Response task, the ECoT guides the model step-by-step in performing understanding context, recognizing others' emotions, recognizing self-emotions, managing self-emotions, in- § https://openai.com/research/gpt-4 fluencing others' emotions, then make an emotional response. For the Emotional News Headline and Emotional Image Caption, recognizing selfemotions is not available. So in these tasks, the ECoT guides the model step-by-step in performing understanding context, and recognizing others' emotions, managing self-emotions, influencing others' emotions, then generate an emotional caption.\n\nEGS measures the emotional generation ability of LLMs from multiple perspectives of human emotional intelligence. However, we found that some dimensions are not available on some emotional generation tasks, e.g., recognizing self-emotions and recognizing others' emotions on Emotional Image Caption task. Hence, we formulated the available evaluation dimensions for each emotional generation task. Consequently, this method results in distinct scales for assessing EGS scores across these tasks. The GPT-3.5 based EGS evaluation template are shown in Figure  10 , Figure  11 , Figure  12 .",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "C Manual Evaluation",
      "text": "All manual evaluation experiments in this paper were completed by three volunteers with master's degrees in psychology. Since all datasets are in English, we emphasize before hiring volunteers that they must have good language skills in English. Drawing on their knowledge and understanding of psychology and emotional intelligence theory, we expected the volunteers' evaluation to serve as expert evaluation in emotional intelligence. We pay volunteers at a rate of $25 per hour.",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "D Benchmark",
      "text": "We construct a benchmark containing both textual and multimodal subsets. The textual benchmark contains five datasets: IEMOCAP  (Busso et al., 2008) , DailyDialog  (Li et al., 2017 ), Empathetic-Dialogues (Rashkin et al., 2019a) , ESConv  (Liu et al., 2021a) , and PENS  (Ao et al., 2021a) . The multimodal benchmark contains two datasets, Sen-tiCap  (Mathews et al., 2016)  and COCO  (Lin et al., 2014) . The statistical information on benchmarks are shown in Table  4 .",
      "page_start": 14,
      "page_end": 14
    },
    {
      "section_name": "E Implementation Details",
      "text": "For the ChatGLM3-6B  (Du et al., 2022) , QWen-14B-Chat  (Bai et al., 2023a ), LLaMA2-13B (Touvron et al., 2023) , QWen-VL  (Bai et al., 2023b) , and LLava-1.5-13B  (Liu et al., 2023) , we set the temperature = 0.1. For the ,  GPT-4 (gpt-4-1106-preview)  and  GPT-4V (gpt-4-1106-vision-preview) , we call the API provided by OpenAI ¶ . All experiments were implemented on a NVIDIA A100 GPU.",
      "page_start": 15,
      "page_end": 15
    },
    {
      "section_name": "F Case Study",
      "text": "Cases of GPT-4/GPT-4V with ECoT are shown in Figure  13 , Figure  14 , Figure  15 , Figure  16 , Figure  17 , Figure  18 , and Figure  19 . Using Figure  5  as an example, ECoT helps LLMs decouple the emotional generation task into multiple sub-steps and makes these thinking processe visible. This helps us better evaluate the emotion generation capabilities of LLMs and also informs further optimization of LLMs. ¶ https://platform.openai.com/docs/api-reference",
      "page_start": 16,
      "page_end": 16
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Examples of LLMs generating responses that",
      "page": 1
    },
    {
      "caption": "Figure 2: We interpret Goleman’s theory through the",
      "page": 2
    },
    {
      "caption": "Figure 1: , we prompt the LLMs to generate a",
      "page": 2
    },
    {
      "caption": "Figure 1: as an illustrative exemplar,",
      "page": 2
    },
    {
      "caption": "Figure 1: , LLMs are guided by ECoT",
      "page": 2
    },
    {
      "caption": "Figure 3: Overview of our proposed ECoT. Given context, emotion condition, task query, and guidelines, LLMs",
      "page": 3
    },
    {
      "caption": "Figure 2: , we interpreted Gole-",
      "page": 3
    },
    {
      "caption": "Figure 4: Random samples of emotional generation tasks. The samples of emotional responses, emotional news",
      "page": 4
    },
    {
      "caption": "Figure 3: , consider the example of",
      "page": 4
    },
    {
      "caption": "Figure 4: Note that we only",
      "page": 6
    },
    {
      "caption": "Figure 6: show that LLMs such as",
      "page": 7
    },
    {
      "caption": "Figure 5: The Fleiss Kappa (Kraemer, 1980) coefficients",
      "page": 12
    },
    {
      "caption": "Figure 5: , the experimental results demonstrate",
      "page": 12
    },
    {
      "caption": "Figure 7: , Figure 8, and Figure 9. ECoT is based",
      "page": 12
    },
    {
      "caption": "Figure 5: Experimental results of the experts evaluation.",
      "page": 12
    },
    {
      "caption": "Figure 10: , Figure 11, Figure",
      "page": 12
    },
    {
      "caption": "Figure 13: , Figure 14, Figure 15, Figure 16, Figure",
      "page": 13
    },
    {
      "caption": "Figure 18: , and Figure 19. Using Figure 5 as",
      "page": 13
    },
    {
      "caption": "Figure 6: Comparative experimental results of Auto-ECoT and Manual-ECOT on the four datasets.",
      "page": 14
    },
    {
      "caption": "Figure 7: Templates for Emotional Response Task.",
      "page": 15
    },
    {
      "caption": "Figure 8: Templates for Emotional News Headline Task.",
      "page": 15
    },
    {
      "caption": "Figure 9: Templates for Emotional Image Caption Task.",
      "page": 16
    },
    {
      "caption": "Figure 10: Templates of EGS on Emotional Response Task.",
      "page": 16
    },
    {
      "caption": "Figure 11: Templates of EGS on Emotional News Headline Task.",
      "page": 17
    },
    {
      "caption": "Figure 12: Templates of EGS on Emotional Image Caption Task.",
      "page": 17
    },
    {
      "caption": "Figure 13: Case of GPT-4V with ECoT on the SentiCap dataset.",
      "page": 18
    },
    {
      "caption": "Figure 14: Case of GPT-4V with ECoT on the COCO dataset.",
      "page": 19
    },
    {
      "caption": "Figure 15: Case of GPT-4 with ECoT on the IEMOCAP dataset.",
      "page": 20
    },
    {
      "caption": "Figure 16: Case of GPT-4 with ECoT on the DailyDialog dataset.",
      "page": 21
    },
    {
      "caption": "Figure 17: Case of GPT-4 with ECoT on the ESConv dataset.",
      "page": 22
    },
    {
      "caption": "Figure 18: Case of GPT-4 with ECoT on the Empathetic dataset.",
      "page": 23
    },
    {
      "caption": "Figure 19: Case of GPT-4 with ECoT on the PENS dataset.",
      "page": 24
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Input\nQuery      Make a response to user with humor. \nContext   User: My coworker is really bad, I don't want to work with him.": "Original Outputs of LLMs\nLLaMA2: Sounds like a real-life \"Office Space\" situation you've got \nthere! But don't worry, maybe you can find a way to \"accidentally\" \ndelete his files or something. \nQwen: Maybe you can try training him like a puppy? Treats for good \nbehavior and timeouts for misbehavior!\nGPT-3.5: Well, at least you've found the perfect partner for the \n\"Avoid Your Coworker Olympics!\" \nGPT-4: Maybe he's secretly a superhero, but his power is just being \nreally good at annoying people!"
        },
        {
          "Input\nQuery      Make a response to user with humor. \nContext   User: My coworker is really bad, I don't want to work with him.": "Outputs of LLMs with ECoT \nLLaMA2: Sounds like you're having a tough time with your \ncoworker! Have you tried bribing them with donuts or something? \nJust kidding, but seriously, maybe try to find a way to work together \nand you might surprise yourself!\nQwen: I feel you, working with a difficult coworker can be tough. \nMaybe try seeing the bright side - at least you have a good excuse \nto practice your patience skills!\nGPT-3.5: How about we designate a 'Frustration-Free Zone' or \ninvest in some invisible coworker repellent? We'll find a way to \nnavigate this together!\nGPT-4: Maybe he's secretly a superhero with the power to test \npatience! Remember, every day is a new adventure."
        }
      ],
      "page": 1
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Abstractive summarizers become emotional on news summarization",
      "authors": [
        "José-Ángel Vicent Ahuir",
        "Lluís-F González",
        "Encarna Hurtado",
        "Segarra"
      ],
      "year": "2024",
      "venue": "Applied Sciences"
    },
    {
      "citation_id": "2",
      "title": "Qing He, and Xing Xie. 2021a. Pens: A dataset and generic framework for personalized news headline generation",
      "authors": [
        "Xiang Ao",
        "Xiting Wang",
        "Ling Luo",
        "Ying Qiao"
      ],
      "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing"
    },
    {
      "citation_id": "3",
      "title": "Qing He, and Xing Xie. 2021b. PENS: A dataset and generic framework for personalized news headline generation",
      "authors": [
        "Xiang Ao",
        "Xiting Wang",
        "Ling Luo",
        "Ying Qiao"
      ],
      "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
      "doi": "10.18653/v1/2021.acl-long.7"
    },
    {
      "citation_id": "4",
      "title": "",
      "authors": [
        "Jinze Bai",
        "Shuai Bai",
        "Yunfei Chu",
        "Zeyu Cui",
        "Kai Dang",
        "Xiaodong Deng",
        "Yang Fan",
        "Wenbin Ge",
        "Yu Han",
        "Fei Huang"
      ],
      "venue": "",
      "arxiv": "arXiv:2309.16609"
    },
    {
      "citation_id": "5",
      "title": "Qwen-vl: A frontier large vision-language model with versatile abilities",
      "authors": [
        "Jinze Bai",
        "Shuai Bai",
        "Shusheng Yang",
        "Shijie Wang",
        "Sinan Tan",
        "Peng Wang",
        "Junyang Lin",
        "Chang Zhou",
        "Jingren Zhou"
      ],
      "year": "2023",
      "venue": "Qwen-vl: A frontier large vision-language model with versatile abilities",
      "arxiv": "arXiv:2308.12966"
    },
    {
      "citation_id": "6",
      "title": "Graph of thoughts: Solving elaborate problems with large language models",
      "authors": [
        "Maciej Besta",
        "Nils Blach",
        "Ales Kubicek",
        "Robert Gerstenberger",
        "Lukas Gianinazzi",
        "Joanna Gajda",
        "Tomasz Lehmann",
        "Michal Podstawski",
        "Hubert Niewiadomski",
        "Piotr Nyczyk"
      ],
      "year": "2023",
      "venue": "Graph of thoughts: Solving elaborate problems with large language models",
      "arxiv": "arXiv:2308.09687"
    },
    {
      "citation_id": "7",
      "title": "Myers-briggs type indicator (mbti): some psychometric limitations",
      "authors": [
        "J Gregory",
        "Boyle"
      ],
      "year": "1995",
      "venue": "Australian Psychologist"
    },
    {
      "citation_id": "8",
      "title": "Iemocap: Interactive emotional dyadic motion capture database. Language resources and evaluation",
      "authors": [
        "Carlos Busso",
        "Murtaza Bulut",
        "Chi-Chun Lee",
        "Abe Kazemzadeh",
        "Emily Mower",
        "Samuel Kim",
        "Jeannette Chang",
        "Sungbok Lee",
        "Shrikanth S Narayanan"
      ],
      "year": "2008",
      "venue": "Iemocap: Interactive emotional dyadic motion capture database. Language resources and evaluation"
    },
    {
      "citation_id": "9",
      "title": "A survey on evaluation of large language models",
      "authors": [
        "Yupeng Chang",
        "Xu Wang",
        "Jindong Wang",
        "Yuan Wu",
        "Kaijie Zhu",
        "Hao Chen",
        "Linyi Yang",
        "Xiaoyuan Yi",
        "Cunxiang Wang",
        "Yidong Wang"
      ],
      "year": "2023",
      "venue": "A survey on evaluation of large language models",
      "arxiv": "arXiv:2307.03109"
    },
    {
      "citation_id": "10",
      "title": "factual\"or\"emotional\": Stylized image captioning with adaptive learning and attention",
      "authors": [
        "Tianlang Chen",
        "Zhongping Zhang",
        "Quanzeng You",
        "Chen Fang",
        "Zhaowen Wang",
        "Hailin Jin",
        "Jiebo Luo"
      ],
      "year": "2018",
      "venue": "Proceedings of the european conference on computer vision (ECCV)"
    },
    {
      "citation_id": "11",
      "title": "Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks",
      "authors": [
        "Wenhu Chen",
        "Xueguang Ma",
        "Xinyi Wang",
        "William Cohen"
      ],
      "year": "2022",
      "venue": "Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks",
      "arxiv": "arXiv:2211.12588"
    },
    {
      "citation_id": "12",
      "title": "A survey of chain of thought reasoning: Advances, frontiers and future",
      "authors": [
        "Zheng Chu",
        "Jingchang Chen",
        "Qianglong Chen",
        "Weijiang Yu",
        "Tao He",
        "Haotian Wang",
        "Weihua Peng",
        "Ming Liu",
        "Bing Qin",
        "Ting Liu"
      ],
      "year": "2023",
      "venue": "A survey of chain of thought reasoning: Advances, frontiers and future",
      "arxiv": "arXiv:2309.15402"
    },
    {
      "citation_id": "13",
      "title": "Affect-driven dialog generation",
      "authors": [
        "Pierre Colombo",
        "Wojciech Witon",
        "Ashutosh Modi",
        "James Kennedy",
        "Mubbasir Kapadia"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies"
    },
    {
      "citation_id": "14",
      "title": "Glm: General language model pretraining with autoregressive blank infilling",
      "authors": [
        "Zhengxiao Du",
        "Yujie Qian",
        "Xiao Liu",
        "Ming Ding",
        "Jiezhong Qiu",
        "Zhilin Yang",
        "Jie Tang"
      ],
      "year": "2022",
      "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "15",
      "title": "Towards revealing the mystery behind chain of thought: a theoretical perspective",
      "authors": [
        "Guhao Feng",
        "Yuntian Gu",
        "Bohang Zhang",
        "Haotian Ye",
        "Di He",
        "Liwei Wang"
      ],
      "year": "2023",
      "venue": "Towards revealing the mystery behind chain of thought: a theoretical perspective",
      "arxiv": "arXiv:2305.15408"
    },
    {
      "citation_id": "16",
      "title": "Affectlm: A neural language model for customizable affective text generation",
      "authors": [
        "Sayan Ghosh",
        "Mathieu Chollet",
        "Eugene Laksana",
        "Louis-Philippe Morency",
        "Stefan Scherer"
      ],
      "year": "2017",
      "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "17",
      "title": "Emotional intelligence: Why it can matter more than IQ",
      "authors": [
        "Daniel Goleman"
      ],
      "year": "1995",
      "venue": "Emotional intelligence: Why it can matter more than IQ"
    },
    {
      "citation_id": "18",
      "title": "End-to-end annotator bias approximation on crowdsourced single-label sentiment analysis",
      "authors": [
        "Gerhard Hagerer",
        "David Szabo",
        "Andreas Koch",
        "Maria Luisa Ripoll",
        "Christian Dominguez",
        "Maximilian Widmer",
        "Hannah Wich",
        "Georg Danner",
        "Groh"
      ],
      "year": "2021",
      "venue": "Proceedings of the 4th International Conference on Natural Language and Speech Processing (ICNLSP 2021)"
    },
    {
      "citation_id": "19",
      "title": "Automatic dialogue generation with expressed emotions",
      "authors": [
        "Chenyang Huang",
        "Amine Osmar R Zaiane",
        "Nouha Trabelsi",
        "Dziri"
      ],
      "year": "2018",
      "venue": "Proceedings of the 2018 Conference of the North American Chapter"
    },
    {
      "citation_id": "20",
      "title": "Who is chatgpt? benchmarking llms' psychological portrayal using psychobench",
      "authors": [
        "Jen-Tse Huang",
        "Wenxuan Wang",
        "Eric Li",
        "Man Lam",
        "Shujie Ren",
        "Youliang Yuan",
        "Wenxiang Jiao",
        "Zhaopeng Tu",
        "Michael R Lyu"
      ],
      "year": "2023",
      "venue": "Who is chatgpt? benchmarking llms' psychological portrayal using psychobench",
      "arxiv": "arXiv:2310.01386"
    },
    {
      "citation_id": "21",
      "title": "Extension of the kappa coefficient",
      "authors": [
        "Helena Chmura"
      ],
      "year": "1980",
      "venue": "Biometrics"
    },
    {
      "citation_id": "22",
      "title": "Instructerc: Reforming emotion recognition in conversation with a retrieval multi-task llms framework",
      "authors": [
        "Shanglin Lei",
        "Guanting Dong",
        "Xiaoping Wang",
        "Keheng Wang",
        "Sirui Wang"
      ],
      "year": "2023",
      "venue": "Instructerc: Reforming emotion recognition in conversation with a retrieval multi-task llms framework",
      "arxiv": "arXiv:2309.11911"
    },
    {
      "citation_id": "23",
      "title": "2022a. C3kg: A chinese commonsense conversation knowledge graph",
      "authors": [
        "Dawei Li",
        "Yanran Li",
        "Jiayi Zhang",
        "Ke Li",
        "Chen Wei",
        "Jianwei Cui",
        "Bin Wang"
      ],
      "venue": "Findings of the Association for Computational Linguistics: ACL 2022"
    },
    {
      "citation_id": "24",
      "title": "Knowledge bridging for empathetic dialogue generation",
      "authors": [
        "Qintong Li",
        "Piji Li",
        "Zhaochun Ren",
        "Pengjie Ren",
        "Zhumin Chen"
      ],
      "year": "2022",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence"
    },
    {
      "citation_id": "25",
      "title": "Dailydialog: A manually labelled multi-turn dialogue dataset",
      "authors": [
        "Yanran Li",
        "Hui Su",
        "Xiaoyu Shen",
        "Wenjie Li",
        "Ziqiang Cao",
        "Shuzi Niu"
      ],
      "year": "2017",
      "venue": "Proceedings of the Eighth International Joint Conference on Natural Language Processing"
    },
    {
      "citation_id": "26",
      "title": "Unisa: Unified generative framework for sentiment analysis",
      "authors": [
        "Zaijing Li",
        "Ting-En Lin",
        "Yuchuan Wu",
        "Meng Liu",
        "Fengxiao Tang",
        "Ming Zhao",
        "Yongbin Li"
      ],
      "year": "2023",
      "venue": "Proceedings of the 31st ACM International Conference on Multimedia"
    },
    {
      "citation_id": "27",
      "title": "Microsoft coco: Common objects in context",
      "authors": [
        "Tsung-Yi Lin",
        "Michael Maire",
        "Serge Belongie",
        "James Hays",
        "Pietro Perona",
        "Deva Ramanan",
        "Piotr Dollár",
        "C Lawrence"
      ],
      "year": "2014",
      "venue": "Computer Vision-ECCV 2014: 13th European Conference"
    },
    {
      "citation_id": "28",
      "title": "Improved baselines with visual instruction tuning",
      "authors": [
        "Haotian Liu",
        "Chunyuan Li",
        "Yuheng Li",
        "Yong Jae Lee"
      ],
      "year": "2023",
      "venue": "Improved baselines with visual instruction tuning",
      "arxiv": "arXiv:2310.03744"
    },
    {
      "citation_id": "29",
      "title": "2021a. Towards emotional support dialog systems",
      "authors": [
        "Siyang Liu",
        "Chujie Zheng",
        "Orianna Demasi",
        "Sahand Sabour",
        "Yu Li",
        "Zhou Yu",
        "Yong Jiang",
        "Minlie Huang"
      ],
      "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing"
    },
    {
      "citation_id": "30",
      "title": "2021b. Towards emotional support dialog systems",
      "authors": [
        "Siyang Liu",
        "Chujie Zheng",
        "Orianna Demasi",
        "Sahand Sabour",
        "Yu Li",
        "Zhou Yu",
        "Yong Jiang",
        "Minlie Huang"
      ],
      "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing"
    },
    {
      "citation_id": "31",
      "title": "Senticap: Generating image descriptions with sentiments",
      "authors": [
        "Alexander Mathews",
        "Lexing Xie",
        "Xuming He"
      ],
      "year": "2016",
      "venue": "Proceedings of the AAAI conference on artificial intelligence"
    },
    {
      "citation_id": "32",
      "title": "Measuring emotional intelligence with the msceit v2. 0. Emotion",
      "authors": [
        "Peter John D Mayer",
        "David Salovey",
        "Gill Caruso",
        "Sitarenios"
      ],
      "year": "2003",
      "venue": "Measuring emotional intelligence with the msceit v2. 0. Emotion"
    },
    {
      "citation_id": "33",
      "title": "Customising general large language models for specialised emotion recognition tasks",
      "authors": [
        "Liyizhe Peng",
        "Zixing Zhang",
        "Tao Pang",
        "Jing Han",
        "Huan Zhao",
        "Hao Chen",
        "Björn Schuller"
      ],
      "year": "2023",
      "venue": "Customising general large language models for specialised emotion recognition tasks",
      "arxiv": "arXiv:2310.14225"
    },
    {
      "citation_id": "34",
      "title": "Towards empathetic opendomain conversation models: A new benchmark and dataset",
      "authors": [
        "Eric Hannah Rashkin",
        "Margaret Smith",
        "Y-Lan Li",
        "Boureau"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Annual Meeting of the"
    },
    {
      "citation_id": "35",
      "title": "Towards empathetic opendomain conversation models: A new benchmark and dataset",
      "authors": [
        "Eric Hannah Rashkin",
        "Margaret Smith",
        "Y-Lan Li",
        "Boureau"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Annual Meeting of the"
    },
    {
      "citation_id": "36",
      "title": "Swaroop Mishra, and Chitta Baral. 2023. Instructabsa: Instruction learning for aspect based sentiment analysis",
      "authors": [
        "Kevin Scaria",
        "Himanshu Gupta"
      ],
      "venue": "Swaroop Mishra, and Chitta Baral. 2023. Instructabsa: Instruction learning for aspect based sentiment analysis",
      "arxiv": "arXiv:2302.08624"
    },
    {
      "citation_id": "37",
      "title": "Large language models for aspect-based sentiment analysis",
      "authors": [
        "F Paul",
        "Paavo Simmering",
        "Huoviala"
      ],
      "year": "2023",
      "venue": "Large language models for aspect-based sentiment analysis",
      "arxiv": "arXiv:2310.18025"
    },
    {
      "citation_id": "38",
      "title": "Bob: Bert over bert for training persona-based dialogue models from limited personalized data",
      "authors": [
        "Haoyu Song",
        "Yan Wang",
        "Kaiyan Zhang",
        "Weinan Zhang",
        "Ting Liu"
      ],
      "year": "2021",
      "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing"
    },
    {
      "citation_id": "39",
      "title": "Generating responses with a specific emotion in dialog",
      "authors": [
        "Zhenqiao Song",
        "Xiaoqing Zheng",
        "Lu Liu",
        "Mu Xu",
        "Xuan-Jing Huang"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "40",
      "title": "Exploring large language models' cognitive moral development through defining issues test",
      "authors": [
        "Aditi Kumar Tanmay",
        "Khandelwal"
      ],
      "year": "2023",
      "venue": "Exploring large language models' cognitive moral development through defining issues test",
      "arxiv": "arXiv:2309.13356"
    },
    {
      "citation_id": "41",
      "title": "Faisal Azhar, et al. 2023. Llama: Open and efficient foundation language models",
      "authors": [
        "Hugo Touvron",
        "Thibaut Lavril",
        "Gautier Izacard",
        "Xavier Martinet",
        "Marie-Anne Lachaux",
        "Timothée Lacroix",
        "Baptiste Rozière",
        "Naman Goyal",
        "Eric Hambro"
      ],
      "venue": "Faisal Azhar, et al. 2023. Llama: Open and efficient foundation language models",
      "arxiv": "arXiv:2302.13971"
    },
    {
      "citation_id": "42",
      "title": "Misc: A mixed strategyaware model integrating comet for emotional support conversation",
      "authors": [
        "Quan Tu",
        "Yanran Li",
        "Jianwei Cui",
        "Bin Wang",
        "Ji-Rong Wen",
        "Rui Yan"
      ],
      "year": "2022",
      "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics"
    },
    {
      "citation_id": "43",
      "title": "Emotional intelligence of large language models",
      "authors": [
        "Xuena Wang",
        "Xueting Li",
        "Zi Yin",
        "Yue Wu",
        "Jia Liu"
      ],
      "year": "2023",
      "venue": "Journal of Pacific Rim Psychology"
    },
    {
      "citation_id": "44",
      "title": "Self-consistency improves chain of thought reasoning in language models",
      "authors": [
        "Xuezhi Wang",
        "Jason Wei",
        "Dale Schuurmans",
        "Quoc Le",
        "Ed Chi",
        "Sharan Narang",
        "Aakanksha Chowdhery",
        "Denny Zhou"
      ],
      "year": "2022",
      "venue": "Self-consistency improves chain of thought reasoning in language models",
      "arxiv": "arXiv:2203.11171"
    },
    {
      "citation_id": "45",
      "title": "Chain-of-thought prompting elicits reasoning in large language models",
      "authors": [
        "Jason Wei",
        "Xuezhi Wang",
        "Dale Schuurmans",
        "Maarten Bosma",
        "Fei Xia",
        "Ed Chi",
        "V Quoc",
        "Denny Le",
        "Zhou"
      ],
      "year": "2022",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "46",
      "title": "Tree of thoughts: Deliberate problem solving with large language models",
      "authors": [
        "Shunyu Yao",
        "Dian Yu",
        "Jeffrey Zhao",
        "Izhak Shafran",
        "Thomas Griffiths",
        "Yuan Cao",
        "Karthik Narasimhan"
      ],
      "year": "2023",
      "venue": "Tree of thoughts: Deliberate problem solving with large language models",
      "arxiv": "arXiv:2305.10601"
    },
    {
      "citation_id": "47",
      "title": "Dialoguellm: Context and emotion knowledge-tuned llama models for emotion recognition in conversations",
      "authors": [
        "Yazhou Zhang",
        "Mengyao Wang",
        "Prayag Tiwari",
        "Qiuchi Li",
        "Benyou Wang",
        "Jing Qin"
      ],
      "year": "2023",
      "venue": "Dialoguellm: Context and emotion knowledge-tuned llama models for emotion recognition in conversations",
      "arxiv": "arXiv:2310.11374"
    },
    {
      "citation_id": "48",
      "title": "A survey of large language models",
      "authors": [
        "Kun Wayne Xin Zhao",
        "Junyi Zhou",
        "Tianyi Li",
        "Xiaolei Tang",
        "Yupeng Wang",
        "Yingqian Hou",
        "Beichen Min",
        "Junjie Zhang",
        "Zican Zhang",
        "Dong"
      ],
      "year": "2023",
      "venue": "A survey of large language models",
      "arxiv": "arXiv:2303.18223"
    },
    {
      "citation_id": "49",
      "title": "An affect-rich neural conversational model with biased attention and weighted cross-entropy loss",
      "authors": [
        "Peixiang Zhong",
        "Di Wang",
        "Chunyan Miao"
      ],
      "year": "2019",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence"
    },
    {
      "citation_id": "50",
      "title": "Emotional chatting machine: Emotional conversation generation with internal and external memory",
      "authors": [
        "Hao Zhou",
        "Minlie Huang",
        "Tianyang Zhang",
        "Xiaoyan Zhu",
        "Bing Liu"
      ],
      "year": "2018",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence"
    },
    {
      "citation_id": "51",
      "title": "Promptbench: Towards evaluating the robustness of large language models on adversarial prompts",
      "authors": [
        "Kaijie Zhu",
        "Jindong Wang",
        "Jiaheng Zhou",
        "Zichen Wang",
        "Hao Chen",
        "Yidong Wang",
        "Linyi Yang",
        "Wei Ye",
        "Neil Zhenqiang Gong",
        "Yue Zhang"
      ],
      "year": "2023",
      "venue": "Promptbench: Towards evaluating the robustness of large language models on adversarial prompts",
      "arxiv": "arXiv:2306.04528"
    }
  ]
}