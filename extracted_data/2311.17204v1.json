{
  "paper_id": "2311.17204v1",
  "title": "Optimal Eeg Electrode Set For Emotion Recognition From Brain Signals: An Empirical Quest",
  "published": "2023-11-28T20:18:42Z",
  "authors": [
    "Rumman Ahmed Prodhan",
    "Sumya Akter",
    "Tanmoy Sarkar Pias",
    "Md. Akhtaruzzaman Adnan"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "The human brain is a complex organ, still completely undiscovered, that controls almost all the parts of the body. Apart from survival, the human brain stimulates emotions. Recent research indicates that brain signals can be very effective for emotion recognition. However, which parts of the brain exhibit most of the emotions is still under-explored. In this study, we empirically analyze the contribution of each part of the brain in exhibiting emotions. We use the DEAP dataset to find the most optimal electrode set which eventually leads to the effective brain part associated with emotions. We use Fast Fourier Transformation for effective feature extraction and a 1D-CNN with residual connection for classification. Though 32 electrodes from the DEAP dataset got an accuracy of 97.34%, only 12 electrodes (F7, P8, O1, F8, C4, T7, PO3, Fp1, Fp2, O2, P3, and Fz) achieve 95.81% accuracy. This study also shows that adding more than 10 electrodes does not improve performance significantly. Moreover, the frontal lobe is the most important for recognizing emotion. \n Introduction On any given day, we experience a wide range of emotions. Some are happy, some are sad, and some are in between. But what are emotions, exactly? According to",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Literature Review",
      "text": "Numerous investigations for finding optimal electrode sets for detecting emotion have been conducted in recent years. Most researchers used the DEAP dataset, which is publicly available. In the DEAP dataset, emotions are classified into five labels which are valence, arousal, dominance, liking, and familiarity. In this study, we have used FFT for feature extraction. Many other feature extraction techniques are used in this literature. Choosing an optimal electrode set is essential for effectively classifying emotions  [6] . Table  1  shows the optimal electrode set according to the previous publications.\n\nZhang et al.  [17]  found 12 electrodes as an optimal electrode set. They used Wavelet entropy and Wavelet energy as a feature extrusion method. Moreover, KNN, NB, SVM, and RF are used as different modeling techniques. They ranked the optimal electrode set using mRMR and ReliefF techniques  [24] . Also, they worked on two labels of the DEAP dataset and got an average of 90% accuracy. Goshvarpour et al.  [18]  used RSFS, SFFS, and SFS as feature extraction techniques. Also, they used SVM as a binary classifier. After that, they ranked the electrode set using the sLORETA method  [23]  and got five electrodes as an optimal electrode set. Finally, They got an accuracy of 98.97%for arousal and 98.94% for valence.\n\nJoshi et al.  [19]  got 73.37% of accuracy by using Linear formulation of differential entropy, DE, and Hjorth parameter as feature extraction. Also, they used biLSTM as modeling technique. Then They found four electrodes as an optimal electrode set. Moreover, they classified the emotion as Happy, Angry, Sad, and Clam.\n\nWang et al.  [20]  Found eight electrodes for valence and ten electrodes for arousal as an optimal electrode set by using short-time Fourier transform as a feature extrusion method. Moreover, they used SVM as a modeling technique. After that, they ranked the optimal electrode set using the Normalized mutual information (NMI) connection matrix technique. Finally, they got an accuracy of 74.41% for valence and 73.64% for arousal from this optimal electrode set. Topic et al.  [21]  got the accuracy of 90.76% for valence, 92.92% for arousal, and 92.97% for dominance by using Computer-generated holography (CGH)  [25]  as a feature extraction method. Also, they used CNN and SVM as a classifier. After that, they ranked the electrode by using ReliefF and Neighborhood Component Analysis (NCA) method and found ten electrodes for ReliefF and ten electrodes for Neighborhood Component Analysis (NCA) as an optimal electrode set.\n\nLastly, using the Mean Squared Error(MSE) method, Msonda et al.  [22]  found eight electrodes as an optimal electrode set. They achieved 67% of accuracy by using Wavelet Decomposition as a feature extraction technique. Also, they used different modeling techniques like AdaBoost, Logistic Regression, Linear Support Vector Classifier (SVC), second order polynomial, and Random Forest (RF).",
      "page_start": 3,
      "page_end": 5
    },
    {
      "section_name": "Dataset",
      "text": "The DEAP dataset is multi-modal in nature, used to assess humans' emotional states. A group consists of 32 participants were shown 120 music videos with a one-minute length. Each participant has a .bdf file in the DEAP dataset, and they are all recorded with 48 channels at 512Hz. Two distinct locations have been used to record this dataset. Participants 1-22's data are logged in Twente, whereas participants 23-32's are logged in Geneva. The summary of the DEAP dataset is provided in figure  1 .\n\nIn the DEAP dataset, additional preprocessed files have been provided, which are down-scaled to 128Hz. The DEAP dataset offers 2 down-sampled zip files. The preprocessed Python zip file, which contains 32 files in .dat format, is used for this study. A single .dat file represents a single participant. There are 2 arrays in each file. The data array contains 8064 data over 40 channels across 40 trials. Every trial lasts for 63 seconds. As a result, the data is 128x63=8064.",
      "page_start": 5,
      "page_end": 6
    },
    {
      "section_name": "Methodology",
      "text": "Fig.  3  Workflow diagram for searching for optimal electrode set to recognize emotions using 1D-CNN Figure  3  illustrates the workflow of finding the optimal EEG electrodes for emotion recognition. At first, the DEAP dataset is selected as the source of raw EEG data. Then different types of preprocessing were applied to remove noise and artifacts. After that using FFT, the feature extraction is performed on the specific electrode set mentioned in the literature. All of the test was performed on a 1D CNN to maintain the consistency of the evaluation.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Preprocessing",
      "text": "The 512Hz EEG data has been downsized into 128Hz. Eye artifacts are eliminated using a blind source separation technique  [28] . A bandpass frequency filter with 4.0-45.0Hz is implemented. The data is averaged following the commonly used reference. The EEG channels are rearranged following the Geneva order because the EEG data was recorded in two distinct places. Each trial's data is divided into 60 seconds and a baseline of 3 seconds. The pre-trial phase is then trimmed out. Additionally, the trials are rearranged to experiment video order instead of the presentation order. Feature extraction is critical for effective learning, minimizing signal loss, overfitting, and computational overhead. In general, designing an effective feature extraction method can produce better classification performance than raw data. Frequencydomain features are used to break down signal data into the subbands represented in figure  4 . we have used 256 as a window size and 16 as a step size in this experiment. Wavelet transform (WT), fast Fourier transform (FFT), equivocator methods (EM), Fig.  5  Decomposing raw EEG data into five sub-bands etc., are frequently used for EEG feature extraction. Among these techniques, fast Fourier transform is proved to be the most effective according to recent publications  [29] ; thus, this technique is used in this study. The discrete Fourier transform or inverse discrete Fourier transform (DFT) of a sequence can be determined using the FFT technique. Most of the actual signal is composed of several frequencies. The Fourier transformation is an effective method to extract those fundamental frequencies. After, decomposing the raw EEG data with a fast Fourier transform, we have found 5 sub bands of brain waves. These are Delta ranges from 4-8Hz, Theta ranges from 8-12Hz, Alpha ranges from 12-16Hz, Beta ranges from 16-25Hz, and Gamma ranges from 25-45Hz shows in figure  5 . An actual signal can be long, so to make it faster and more accurate, FFT is used where the whole signal is divided into multiple segments on which FT is applied to extract frequencies. The DTF can be expressed as follows:",
      "page_start": 7,
      "page_end": 8
    },
    {
      "section_name": "Feature Extraction",
      "text": "In this case, the domain size is n. Each value of a discrete signal x[n] should be multiplied by an e-power to some function of n to determine the DFT for that signal.\n\nThe results obtained for a given n should then be added together. Calculating a signal's DFT is O(N 2 ) in complexity. As its name suggests, fast Fourier Transform (FFT) is much quicker than discrete Fourier Transform (DFT). The complexity is reduced using FFT from O(N 2 ) to O (NlogN).  The DEAP dataset team used an international 10-20 electrode placement system  [26]  to collect the EEG signals. The majority of the EEG electrodes associated with emotions are the frontal lobe denoted by the color blue, the parietal lobe is yellow, the occipital lobe is red, the temporal lobe is green, and the center areas in squares shown in the left of figure  6 . The letters FP, AF, F, FC, T, P, and O stand for the front polar, anterior frontal, frontal, front central, temporal, parietal, and occipital regions of the brain. An odd number suffix represents the left hemisphere, whereas an even number suffix represents the right hemisphere. These regions perfectly mirror how emotions are created physiologically. By changing the electrode distribution, it is possible to decrease the extracted feature dimension. The experiment can be made simpler and carried out more efficiently by reducing the complexity of the calculations. The position of the 32 EEG electrodes on the scalp is shown in the right of figure  6 .",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Eeg Electrodes Set",
      "text": "Firstly, identifying the part of the brain which are responsible for emotion recognition is essential. Table  2  shows the group of electrodes according to the brain areas. Those are mainly frontal, parietal, occipital, temporal, and central. After identifying the part of the brain which are responsible for emotion, it is important to find out the specific set of EEG electrodes. From the literature, the best work on emotion recognition along with their optimal EEG electrode set are extracted. All the electrodes are selected according to the valence label on the DEAP dataset to maintain consistency. The selected EEG electrode sets are shown in table  3 .",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Cnn Model Structure",
      "text": "Numerous signal processing tasks, such as early arrhythmia identification in electrocardiogram (ECG) beats  [7] , emotion recognition from EEG, activity recognition job from accelerometer data, etc., have made 1D CNN increasingly popular. Thus in this study, a 1D CNN with hidden layers shown in figure  7  is used to accurately recognize emotions from brain signals. The proposed model uses the residual connection, a kind of skip connection  [30] . Initially, the model is changed from sequential to functional to construct the residual connection. The input size of the model depends on the number of electrodes multiplied by the number of bands. Thus, the input size must be changed for each EEG electrode set.     3 . For the first 20 epochs, a massive increase in accuracy and decrease in loss is observed. The improvement is moderate from 20 to 30 epochs, and the progress is meagre from 30 to 50 epochs.\n\nTable  4  shows the previous accuracy of each electrode set proposed by different publications and the accuracy achieved by the proposed model. All the electrode set is run with the CNN model shown in figure  7  for 50 epochs.\n\nTo visualize the results more clearly, the figure  10  is plotted with testing accuracy of our proposed model vs previous work s accuracy with respect to electrode set number. The proposed CNN model outperforms almost all the previous work's accuracy except set three proposed by Goshvarpour et at.  [18] . They claim to get the high accuracy by using RSSF, Lagged Poincare Indices, and SVM. But in head to head comparison we noticed that their electrode set is not the optimal. It only got 93.63% accuracy with our model. The electrode set with all the 32 electrodes performs the best with 97.34% testing accuracy with the proposed model. The electrode set one by Zhang et al. using mRMR is the most optimal electrode set. With only 12 electrodes, it achieved 95.81% testing accuracy with the proposed 1D  To find out the correlation between the number of electrodes and testing accuracy, figure  11  is plotted. Here, electrode set 2, 6 and 7 is discarded as with the same number of electrodes there are better set which got better accuracy. It is observed that there is a clear correlation between the number of electrodes and testing accuracy. Increasing the number of electrodes from 4 to 10 greatly increases the testing accuracy. However, from the above ten electrodes, the improvement of testing accuracy is not so much. So, it can be stated that the optimal number of electrodes for emotion recognition is 10.",
      "page_start": 10,
      "page_end": 11
    },
    {
      "section_name": "Conclusion",
      "text": "Identifying precisely the electrodes which are optimal for recognizing emotions from brain wave is essential. This is because different portions of the brain have different roles, most of which are still unknown. In order to explore and reveal the emotion regions of brain, this study is conducted. Identifying the brain lobe which is more responsible for emotions and their respective electrodes makes it possible to reduce computational overhead and get the most optimal results. In this study, we demonstrate that the frontal lobe is the most important brain-region for emotions. Then the evaluation of different electrode sets created by other researchers is conducted. To do the experiments, FFT is used to extract features, and a 1D-CNN with residual connection is used. The DEAP dataset was selected for this study, and the valence label was selected for all the experiments to maintain consistency. The 32 electrode set got the best testing accuracy of 97.34%. However, the most optimal EEG electrode set is the one proposed by Zhang et al. with 12 electrodes using mRMR, which achieved 95.81%. Those 12 electrodes are F7,P8,O1,F8,C4,T7,PO3,Fp1,Fp2,O2,P3,Fz. Also, the optimal number of electrodes is 10. Nevertheless, there could be other electrode sets which are not yet been experimented with by any authors, thus not included in this study. Also, different electrodes are responsible for different labels of emotions like happy, sad, and angry. In future, we want to find the correlation between different labels of emotion with single electrode.",
      "page_start": 14,
      "page_end": 15
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: Overview of the DEAP Dataset",
      "page": 5
    },
    {
      "caption": "Figure 1: In the DEAP dataset, additional preprocessed files have been provided, which",
      "page": 5
    },
    {
      "caption": "Figure 2: A subject’s raw EEG data-segment from the DEAP dataset",
      "page": 6
    },
    {
      "caption": "Figure 3: Workflow diagram for searching for optimal electrode set to recognize emotions using 1D-",
      "page": 6
    },
    {
      "caption": "Figure 3: illustrates the workflow of finding the optimal EEG electrodes for emo-",
      "page": 7
    },
    {
      "caption": "Figure 4: Feature Extraction: FFT using sliding window",
      "page": 7
    },
    {
      "caption": "Figure 4: we have used 256 as a window size and 16 as a step size in this experiment.",
      "page": 7
    },
    {
      "caption": "Figure 5: Decomposing raw EEG data into five sub-bands",
      "page": 8
    },
    {
      "caption": "Figure 5: An actual signal can be long, so to make it",
      "page": 8
    },
    {
      "caption": "Figure 6: Illustration of the four main lobes of cerebral hemisphere [31] (left) and position of the 32",
      "page": 9
    },
    {
      "caption": "Figure 6: The letters FP, AF, F, FC, T, P, and O stand for the",
      "page": 9
    },
    {
      "caption": "Figure 7: is used to accurately recog-",
      "page": 10
    },
    {
      "caption": "Figure 7: Proposed 1D-CNN model architecture with residual connection",
      "page": 11
    },
    {
      "caption": "Figure 8: Test accuracy of electrode sets according to the lobes of cerebral hemisphere",
      "page": 11
    },
    {
      "caption": "Figure 8: , illustrates the testing accuracy for the individual electrode sets accord-",
      "page": 12
    },
    {
      "caption": "Figure 9: Training accuracy and loss for two label classification on nine electrode sets",
      "page": 12
    },
    {
      "caption": "Figure 9: plots the training accuracy and loss of every epoch for all the nine",
      "page": 12
    },
    {
      "caption": "Figure 7: for 50 epochs.",
      "page": 12
    },
    {
      "caption": "Figure 10: is plotted with testing accuracy",
      "page": 12
    },
    {
      "caption": "Figure 10: Emotion recognition accuracy of different electrode sets",
      "page": 13
    },
    {
      "caption": "Figure 11: Emotion recognition accuracy with different number of electrodes",
      "page": 14
    },
    {
      "caption": "Figure 11: is plotted. Here, electrode set 2, 6 and 7 is discarded as with the same number",
      "page": 14
    }
  ],
  "tables": [
    {
      "caption": "Table 1: shows the optimal electrode set according to the",
      "page": 3
    },
    {
      "caption": "Table 1: Literature overview of optimal EEG channels used in DEAP dataset to recognize emotion",
      "page": 4
    },
    {
      "caption": "Table 2: Electrode mapping according to the lobes of cerebral hemisphere",
      "page": 9
    },
    {
      "caption": "Table 2: shows the group of electrodes according to the brain areas.",
      "page": 10
    },
    {
      "caption": "Table 3: Electrode sets proposed in different publications",
      "page": 10
    },
    {
      "caption": "Table 3: 4.4 CNN Model Structure",
      "page": 10
    },
    {
      "caption": "Table 3: For the first 20 epochs, a massive increase in accuracy and",
      "page": 12
    },
    {
      "caption": "Table 4: shows the previous accuracy of each electrode set proposed by different",
      "page": 12
    },
    {
      "caption": "Table 4: Comparing results of electrode sets",
      "page": 13
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Human EEG recordings for 1,854 concepts presented in rapid serial visual presentation streams",
      "authors": [
        "T Grootswagers",
        "I Zhou",
        "A Robinson",
        "M Hebart",
        "T Carlson"
      ],
      "year": "2022",
      "venue": "Scientific Data",
      "doi": "10.1038/s41597-021-01102-7"
    },
    {
      "citation_id": "2",
      "title": "Exploring brain activity for positive and negative emotions by means of EEG microstates",
      "authors": [
        "G Prete",
        "P Croce",
        "F Zappasodi",
        "L Tommasi",
        "P Capotosto"
      ],
      "year": "2022",
      "venue": "Scientific Reports",
      "doi": "10.1038/s41598-022-07403-0"
    },
    {
      "citation_id": "3",
      "title": "Effects of a reduction of the number of electrodes in the EEG montage on the number of identified seizure patterns",
      "authors": [
        "M Tacke",
        "K Janson",
        "K Vill",
        "F Heinen",
        "L Gerstl",
        "K Reiter",
        "I Borggraefe"
      ],
      "year": "2022",
      "venue": "Scientific Reports",
      "doi": "10.1038/s41598-022-08628-9"
    },
    {
      "citation_id": "4",
      "title": "Towards real-world neuroscience using mobile EEG and augmented reality",
      "authors": [
        "A Krugliak",
        "A Clarke"
      ],
      "year": "2022",
      "venue": "Scientific Reports",
      "doi": "10.1038/s41598-022-06296-3"
    },
    {
      "citation_id": "5",
      "title": "Imagined speech can be decoded from low-and cross-frequency intracranial EEG features",
      "authors": [
        "T Proix",
        "J Delgado Saa",
        "A Christen",
        "S Martin",
        "B Pasley",
        "R Knight",
        "X Tian",
        "D Poeppel",
        "W Doyle",
        "O Devinsky",
        "L Arnal",
        "P Mégevand",
        "A Giraud"
      ],
      "year": "2022",
      "venue": "Nature Communications",
      "doi": "10.1038/s41467-021-27725-3"
    },
    {
      "citation_id": "6",
      "title": "Two-dimensional CNN-based distinction of human emotions from EEG channels selected by multi-objective evolutionary algorithm",
      "authors": [
        "L Moctezuma",
        "T Abe",
        "M Molinas"
      ],
      "year": "2022",
      "venue": "Scientific Reports",
      "doi": "10.1038/s41598-022-07517-5"
    },
    {
      "citation_id": "7",
      "title": "ECG Arrhythmia Classification Using 1D CNN Leveraging the Resampling Technique and Gaussian Mixture Model. 2021 Joint 10th International Conference on Informatics, Electronics & Vision (ICIEV) and 2021 5th International Conference on Imaging, Vision & Pattern Recognition (icIVPR)",
      "authors": [
        "M Apu",
        "F Akter",
        "M Lubna",
        "T Helaly",
        "T Pias"
      ],
      "year": "2021",
      "venue": "ECG Arrhythmia Classification Using 1D CNN Leveraging the Resampling Technique and Gaussian Mixture Model. 2021 Joint 10th International Conference on Informatics, Electronics & Vision (ICIEV) and 2021 5th International Conference on Imaging, Vision & Pattern Recognition (icIVPR)",
      "doi": "10.1109/icievicivpr52578.2021.9564201"
    },
    {
      "citation_id": "8",
      "title": "Human Attention Recognition with Machine Learning from Brain-EEG Signals",
      "authors": [
        "R Hassan",
        "S Hasan",
        "M Hasan",
        "M Jamader",
        "D Eisenberg",
        "T Pias"
      ],
      "year": "2020",
      "venue": "Biomedical Engineering, Healthcare and Sustainability",
      "doi": "10.1109/ecbios50299.2020.9203672"
    },
    {
      "citation_id": "9",
      "title": "EEG Signal Processing and Supervised Machine Learning to Early Diagnose Alzheimer's Disease",
      "authors": [
        "D Pirrone",
        "E Weitschek",
        "P Di Paolo",
        "S De Salvo",
        "M De Cola"
      ],
      "year": "2022",
      "venue": "Applied Sciences",
      "doi": "10.3390/app12115413"
    },
    {
      "citation_id": "10",
      "title": "SEED Dataset",
      "authors": [
        "B.-L Lu"
      ],
      "year": "2022",
      "venue": "SEED Dataset"
    },
    {
      "citation_id": "11",
      "title": "AMIGOS: A Dataset for Affect, Personality and Mood Research on Individuals and Groups",
      "authors": [
        "J Miranda-Correa",
        "M Abadi",
        "N Sebe",
        "I Patras"
      ],
      "year": "2021",
      "venue": "IEEE Transactions on Affective Computing",
      "doi": "10.1109/taffc.2018.2884461"
    },
    {
      "citation_id": "12",
      "title": "A Multimodal Database for Affect Recognition and Implicit Tagging",
      "authors": [
        "M Soleymani",
        "J Lichtenauer",
        "T Pun",
        "M Pantic"
      ],
      "year": "2012",
      "venue": "IEEE Transactions on Affective Computing",
      "doi": "10.1109/t-affc.2011.25"
    },
    {
      "citation_id": "13",
      "title": "Constants Across Cultures in the Face and Emotion",
      "authors": [
        "P Ekman",
        "W Friesen"
      ],
      "year": "1971",
      "venue": "Journal of Personality and Social Psychology"
    },
    {
      "citation_id": "14",
      "title": "Analysis of Electroencephalography (EEG) Signals and Its Categorization-A Study",
      "authors": [
        "J Kumar",
        "P Bhuvaneswari"
      ],
      "year": "2012",
      "venue": "Procedia Engineering",
      "doi": "10.1016/j.proeng.2012.06.298"
    },
    {
      "citation_id": "15",
      "title": "DEAP: A Database for Emotion Analysis ;Using Physiological Signals",
      "authors": [
        "S Koelstra",
        "C Muhl",
        "M Soleymani",
        "Jong-Seok Lee",
        "A Yazdani",
        "T Ebrahimi",
        "T Pun",
        "A Nijholt",
        "I Patras"
      ],
      "year": "2012",
      "venue": "IEEE Transactions on Affective Computing",
      "doi": "10.1109/t-affc.2011.15"
    },
    {
      "citation_id": "16",
      "title": "FFT (Fast Fourier Transform). Encyclopedia of Parallel Computing",
      "authors": [
        "F Franchetti",
        "M Püschel"
      ],
      "year": "2011",
      "venue": "FFT (Fast Fourier Transform). Encyclopedia of Parallel Computing",
      "doi": "10.1007/978-0-387-09766-4243"
    },
    {
      "citation_id": "17",
      "title": "Selection of Optimal EEG Electrodes for Human Emotion Recognition",
      "authors": [
        "J Zhang",
        "P Chen"
      ],
      "year": "2020",
      "venue": "IFAC-PapersOnLine",
      "doi": "10.1016/j.ifacol.2020.12.2753"
    },
    {
      "citation_id": "18",
      "title": "A Novel Approach for EEG Electrode Selection in Automated Emotion Recognition Based on Lagged Poincare's Indices and sLORETA",
      "authors": [
        "A Goshvarpour",
        "A Goshvarpour"
      ],
      "year": "2020",
      "venue": "Cogn Comput",
      "doi": "10.1007/s12559-019-09699-z"
    },
    {
      "citation_id": "19",
      "title": "Optimal Number of Electrode Selection for EEG Based Emotion Recognition using Linear Formulation of Differential Entropy",
      "authors": [
        "V Joshi",
        "B Ghongade"
      ],
      "year": "2020",
      "venue": "Biomedical and Pharmacology Journal",
      "doi": "10.13005/bpj/1928"
    },
    {
      "citation_id": "20",
      "title": "Channel Selection Method for EEG Emotion Recognition Using Normalized Mutual Information",
      "authors": [
        "Z Wang",
        "S Hu",
        "H Song"
      ],
      "year": "2019",
      "venue": "IEEE Access",
      "doi": "10.1109/access.2019.2944273"
    },
    {
      "citation_id": "21",
      "title": "Emotion Recognition Using a Reduced Set of EEG Channels Based on Holographic Feature Maps",
      "authors": [
        "A Topic",
        "M Russo",
        "M Stella",
        "M Saric"
      ],
      "year": "2022",
      "venue": "Sensors",
      "doi": "10.3390/s22093248"
    },
    {
      "citation_id": "22",
      "title": "Feature Reconstruction Based Channel Selection for Emotion Recognition Using EEG",
      "authors": [
        "J Msonda",
        "Z He",
        "C Lu"
      ],
      "year": "2021",
      "venue": "IEEE Signal Processing in Medicine and Biology Symposium (SPMB)",
      "doi": "10.1109/spmb52430.2021.9672258"
    },
    {
      "citation_id": "23",
      "title": "Standardized low-resolution brain electromagnetic tomography (sLORETA): technical details",
      "authors": [
        "R Pascual-Marqui"
      ],
      "year": "2002",
      "venue": "Methods Find Exp Clin Pharmacol"
    },
    {
      "citation_id": "24",
      "title": "Selection of Relevant Features from Cognitive EEG Signals Using ReliefF and MRMR Algorithm",
      "authors": [
        "A Mazumder",
        "P Ghosh",
        "A Khasnobish",
        "S Bhattacharyya",
        "D Tibarewala"
      ],
      "year": "2015",
      "venue": "Advancements of Medical Electronics"
    },
    {
      "citation_id": "25",
      "title": "Optimized CGH-based pattern recognizer",
      "authors": [
        "L Jaroszewicz",
        "K Cyran",
        "T Podeszwa"
      ],
      "year": "2000",
      "venue": "Optica Applicata"
    },
    {
      "citation_id": "26",
      "title": "Cerebral location of international 10-20 system electrode placement",
      "authors": [
        "R Homan",
        "J Herman",
        "P Purdy"
      ],
      "year": "1987",
      "venue": "Electroencephalography and clinical neurophysiology"
    },
    {
      "citation_id": "27",
      "title": "Human emotion recognition from EEGbased brain-computer interface using machine learning: a comprehensive review",
      "authors": [
        "E Houssein",
        "A Hammad",
        "A Ali"
      ],
      "year": "2022",
      "venue": "Neural Computing and Applications",
      "doi": "10.1007/s00521-022-07292-4"
    },
    {
      "citation_id": "28",
      "title": "A blind source separation technique using second-order statistics",
      "authors": [
        "A Belouchrani",
        "K Abed-Meraim",
        "J Cardoso",
        "E Moulines"
      ],
      "year": "1997",
      "venue": "IEEE Transactions on signal processing"
    },
    {
      "citation_id": "29",
      "title": "Fine-Grained Emotion Recognition from EEG Signal Using Fast Fourier Transformation and CNN",
      "authors": [
        "M Hasan",
        "Yasmin Rokhshana-Nishat-Anzum",
        "S Pias"
      ],
      "year": "2021",
      "venue": "Joint 10th International Conference on Informatics, Electronics & Vision (ICIEV) and 2021 5th International Conference on Imaging, Vision & Pattern Recognition (icIVPR)",
      "doi": "10.1109/icievicivpr52578.2021.9564204"
    },
    {
      "citation_id": "30",
      "title": "Skip connections matter: On the transferability of adversarial examples generated with resnets",
      "authors": [
        "D Wu",
        "Y Wang",
        "S Xia",
        "J Bailey",
        "X Ma"
      ],
      "year": "2020",
      "venue": "Skip connections matter: On the transferability of adversarial examples generated with resnets",
      "arxiv": "arXiv:2002.05990"
    },
    {
      "citation_id": "31",
      "title": "Effective substances",
      "authors": [
        "J Dod"
      ],
      "year": "1999",
      "venue": "The Dictionary of Substances and Their Effects"
    }
  ]
}