{
  "paper_id": "2402.17792v1",
  "title": "Egnn-C+: Interpretable Evolving Granular Neural Network And Application In Classification Of Weakly-Supervised Eeg Data Streams",
  "published": "2024-02-26T15:11:41Z",
  "authors": [
    "Daniel Leite",
    "Alisson Silva",
    "Gabriella Casalino",
    "Arnab Sharma",
    "Danielle Fortunato",
    "Axel-Cyrille Ngomo"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "We introduce a modified incremental learning algorithm for evolving Granular Neural Network Classifiers (eGNN-C+). We use double-boundary hyper-boxes to represent granules, and customize the adaptation procedures to enhance the robustness of outer boxes for data coverage and noise suppression, while ensuring that inner boxes remain flexible to capture drifts. The classifier evolves from scratch, incorporates new classes on the fly, and performs local incremental feature weighting. As an application, we focus on the classification of emotion-related patterns within electroencephalogram (EEG) signals. Emotion recognition is crucial for enhancing the realism and interactivity of computer systems. The challenge lies exactly in developing high-performance algorithms capable of effectively managing individual differences and non-stationarities in physiological data without relying on subject-specific calibration data. We extract features from the Fourier spectrum of EEG signals obtained from 28 individuals engaged in playing computer games -a public dataset. Each game elicits a different predominant emotion: boredom, calmness, horror, or joy. We analyze individual electrodes, time window lengths, and frequency bands to assess the accuracy and interpretability of resulting user-independent neural models. The findings indicate that both brain hemispheres assist classification, especially electrodes on the temporal (T8) and parietal (P7) areas, alongside contributions from frontal and occipital electrodes. While patterns may manifest in any band, the Alpha (8-13Hz), Delta (1-4Hz), and Theta (4-8Hz) bands, in this order, exhibited higher correspondence with the emotion classes. The eGNN-C+ demonstrates effectiveness in learning EEG data. It achieves an accuracy of 81.7% and a 0.0029 II interpretability using 10-second time windows, even in face of a highly-stochastic time-varying 4-class classification problem.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "I. Introduction",
      "text": "Emotion-related pattern recognition, which aims at inferring emotions from physical behaviors and data, has gained scientific, technological, and clinical attention  [1]    [2] . Emotionsintricate mental states crucial in decision-making, planning, reasoning, and other mental activities  [3]  -can manifest in physical behaviors such as facial expressions, speech, gestures, and eye movements; as well as in physiological signals obtained from the central and peripheral nervous system  [1] [3] . Electroencephalogram (EEG), electromyogram (EMG), electrocardiogram (ECG), and cameras are tools for recording data streams potentially conveying emotion-related patterns  [4] [5] . Of particular concern to the present study, incremental learning algorithms and granular neural networks are wellsuited approaches to handle the inherent uncertainty and nonstationarity of data stream scenarios  [6]    [7] . For example, humans may intentionally conceal emotions or express them in diverse and uncertain ways  [8] . Moreover, weakly labeled instances, drifts, and noise impose challenges for an accurate and interpretable pattern classification model.\n\nThe applications based on both non-physiological and physiological data are vast, encompassing various domains where machine learning and adaptive models contribute to decisionmaking support, mechatronics control, software development, virtual agents, and the enhancement of realism, efficiency, and interaction  [4]    [9] . Specific examples include: (i) healthcare, in which emotion-related data are used for detecting fatigue, drowsiness, and pain related to neurological disorders, such as autism and schizophrenia  [8] ; (ii) in marketing, for evaluating the effectiveness of advertising campaigns and understanding consumers responses to products  [10] ; (iii) in education, for obtaining insights into students' comprehension and engagement  [11] ; (iv) in brain-computer interfaces (BCI), for aiding the development of adaptive human-machine interactions  [12] ; (v) in security, for detecting signs of stress and nervousness in critical situations  [13] ; (vi) in games, for creating emotionbased adaptive scenarios and simulators  [9]    [14] . Developing emotion classifiers can enhance user experiences and facilitate human-machine communication.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "A. Related Work",
      "text": "Classifiers of EEG data commonly rely on Support Vector Machines (SVM), k-Nearest Neighbors (kNN), Naive Bayes arXiv:2402.17792v1 [eess.SP] 26 Feb 2024 (NB), Linear Discriminant Analysis (LDA), Random Forest (RF), and Multi-Layer Perceptrons (MLP)  [4] . Deep learning has also been applied to affective computing from physiological data  [2]    [13] . A deep network to classify the states of relaxation, anxiety, excitement, and fun using skin conductance and pulse signals, achieving comparable accuracy to shallow methods, is given in  [15] . A Deep Belief Network (DBN) to classify positive and negative emotions is given in  [16] . The selection of electrodes and frequency bands is performed through the distribution of weights in a trained DBN -being asymmetries between the left and right brain hemispheres relevant features. A Dynamical-Graph Convolutional Net (DG-CNN) learns an adjacency matrix among EEG channels to outperform DBN, Transductive SVM and Transfer Component Analysis in  [3] . A Two-Stage Fuzzy Fusion strategy combined with a CNN (TSFF-CNN) is described in  [17] . Facial expressions and speech modalities are aggregated for a final decision. The method manages ambiguity in emotional states. TSFF-CNN outperformed other deep models. Recent studies address explainable methods in emotion recognition  [18]    [19] .\n\nIn  [20] , Biorthogonal wavelets, combined with Fuzzy SVM, are employed to process facial images for identifying happiness, sadness, surprisingness, angriness, and fearfulness. An Adaptive Neuro-Fuzzy Inference System (ANFIS) that combines facial expression and EEG features has shown to be superior to single-source classifiers in  [21] . ANFIS identifies the valence status stimulated by watching movies. The Online weighted Adaptation Regularization for Regression (OwARR) algorithm  [22]  aims to estimate driver drowsiness from EEG data. We note that offline training is required to select OwARR domains. An ensemble of models using swarm-optimized Sugeno or Choquet aggregators for motor imagery recognition and robotic arm control is presented in  [23] .\n\nAll the learning methods mentioned above implicitly assume stationary data since models are expected to keep their training performance during tests using fixed parameters. However, physiological data can change due to artifacts, environmental conditions, and multiple users sharing a device. Fatigue, attention, and stress also affect user-dependent and independent generalized classifiers in an uncertain manner.",
      "page_start": 1,
      "page_end": 2
    },
    {
      "section_name": "B. Research And Contribution",
      "text": "We present a learning algorithm for evolving Granular Neural Networks (eGNN-C+). The network is a classifier of numerical data streams. Our motivation lies in addressing the challenges of emotion-related pattern classification within EEG signals from multiple individuals. The modifications in the algorithm for constructing eGNN-C+, as compared to other eGNN algorithms  [7] [24]  [25]  [26] , are:\n\n• the use of double-boundary hyper-box granules, where inner boxes are flexible to capture drifts, and outer boxes are more robust against noise. This is achieved by slight variations on parameter adaptation procedures; • incorporation of product aggregation and softmax neurons in the second and forth layers. New equations are introduced for local feature weighting;\n\n• operation in a supervised manner, with weak labels, for updating granules and weights. In particular, a weak label (the predominant emotion class) is propagated to all time windows within the EEG recording of an individual. It is acknowledged that not all windows may accurately reflect the predominance of the same class. The computational experiments utilize a publicly available dataset  [27] , comprising EEG signals recorded from players exposed to visual and auditory stimuli. These signals are captured using a 14-channel EEG device. We pre-process raw data using time windows and filters. From each EEG channel, ten features are extracted, namely, the maximum and mean values within the Delta (1-4Hz), Theta (4-8Hz), Alpha (8-13Hz), Beta (13-30Hz), and Gamma (30-64Hz) bands, resulting in 140 features. A unique user-independent eGNN-C+ model is developed from scratch. Following the identification of the predominant emotion according to the Arousal-Valence system, feedback can be integrated into a real or virtual environment to enhance realism.\n\nThe contributions of this paper are:\n\n• an incremental algorithm for granular neural networks that deals with uncertainties and non-stationarities in EEG data. The eGNN-C+ incorporates spatio-temporal patterns using double-boundary hyper-boxes and aggregation functions. Storing data or having prior knowledge of the task or the number of classes is needless; • an inherently interpretable model that supports decision making. The model is rooted in data-space partitions. This leads to the generation of rules describing the behavior of the data within each partition; • an analysis of the effect of window lengths, brain regions, frequency bands, and feature selection on model performance and interpretability; • a fast and evolving classification solution, which, unlike non-incremental classifiers, handles drifts and scales linearly with respect to the number of instances and features.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Ii. Interpretable Granular Neural Network For Classification Of Evolving Eeg Data",
      "text": "The eGNN (evolving Granular Neural Network)  [7]  [24] [25]  [26]  stands as an incremental machine learning framework for gradual construction of partition-based neural models from non-stationary data streams. Its foundational elements are: (i) information granules  [28] , whose components can be intervals, probability functions, fuzzy sets, rough sets, and higher order objects; (ii) synaptic weights, reflecting the importance of specific features and granules, which allow room for the implementation of feature weighting and selection in incremental procedures; (iii) aggregation operators  [29]  [30], implemented as neurons, for information fusion, possibly suppressing outlier values or artifacts; and (iv) an output element, which can, in general, be a multi-variable function -spanning from zeroorder functions, e.g., indicating a class, to functions originating from highly-parameterized locally-valid models, ultimately yielding class probabilities, real-valued predictions, or control actions for mechatronics.\n\nEach eGNN granule-neuron pair encodes the antecedent terms of a rule. Optionally, in addition to a multi-variable function, the output element of an eGNN model may also comprise granules formed by output data granulation, thereby creating a granular map between domains  [28] . This approach provides bounds to typical numerical predictions based on the parameters of active output granules, which assist in decisionmaking processes. As this paper explores the application of eGNN as a classifier for EEG data, the model outcomes are basically class probabilities. The overall network processing is transparent, meaning that its inherent interpretability can be quantified according to the II interpretability index  [31] .\n\nIn the following, we present a modified learning algorithm to develop the classifier named eGNN-C+. It is specifically tailored for numerical and noisy data streams. The emphasis is on classifying spatio-temporal patterns by examining bands of the Fourier spectrum derived from subsets of data within landmark time windows. We do not quantify instance-level uncertainty, but allow the learning algorithm to unveil patterns potentially hidden in a predominantly stochastic environment. A single supervised learning step occurs per time window, incrementally, when the true class label becomes available. The granules cover the data domain, which is, in turn, formed by features observed in the frequency bands. These granules drift, expand, and contract, to track non-stationarities and establish nonlinear class boundaries.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "A. Neural Network Architecture",
      "text": "Let (x, y) [h] , h = 1, ..., be a data stream. A real-valued vector x [h] = [x 1 ... x n ] ′ -whose features x j , j = 1, ..., n, are in particular the mean and max amplitudes within bands of the Fourier spectrum -is produced for each time window, of length L, specified over the original time-domain EEG signals. The eGNN-C+ model is structurally and parametrically developed in a supervised way, starting from scratch, based on the stream (x, y) [h] . A learning step is given whenever the true class y [h] associated with x [h] becomes available.\n\nFigure  1  shows the architecture of the four-layer network. The Input layer receives x [h] , h = 1, ..., from the frequency domain of the EEG signals. The Granular layer comprises a set of c n-dimensional granules G = {G 1 , ...G i , ..., G c } gradually stratified and updated from the stream x [h] . A variety of objects (information representation paradigms) can be employed to embody the components {G i 1 , ..., G i j , ..., G i n } of a G i . The eGNN-C+ model is composed by double-boundary hyper-boxes as granules (clusters of numerical EEG data), with no specific assumptions on the nature of the underlying inner and outer boxes. The projection of a granule onto a feature axis assembles two intervals [g i j , g i j ] and\n\n. We canonically represent G i j by four parameters in ascending order, i.e. G i j = (g i j , g i j , g i j , g i j ), which makes the operations of the learning algorithm simple and fast. The parameters of the inner box, g i j and g i j , ∀j, exhibit more flexibility than those of the outer box, g i j and g i j , ∀j, allowing for a higher flexibility to track drifts  [32] . Conversely, the outer box focuses on data coverage and exhibits greater robustness to noise. Movements of the outer box are contingent on multiple instances within a specific portion of the covered region and the previous adaptation of midpoints. The eGNN-C+ algorithm handles challenges posed by clustering in stochastic EEG environments and the influence of weak labels guiding the learning process. This is achieved by balancing inner box plasticity and outer-box stability  [33] . A granule G i points to a single class Ĉi , i = 1, ..., c; however, multiple granules may point to the same class (a one-to-many relationship). Let m be the number of classes observed so far, then m ≤ c.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Arises From The Matching Between The Instance X",
      "text": "along the x j axis, constituting a component of the inner box. The coverage of G i j is the interval [g i j , g i j ] along x j , forming a component of the outer box. In this study, we opted to maintain the similarity measure in  [7] . Notably, we adopt a pointwise consideration for x [h] , thereby\n\n.\n\n(\n\nThe Aggregation layer comprises neurons\n\n′ into a single value o i , which refers to the activation level of the rule R i that governs the region of the data space delimited by G i . While, Section II-B addresses aggregation operators, Section II-E describes an incremental approach to perform local feature weighting through w i .\n\nThe Softmax layer transforms [o 1 ... o c ] ′ into probabilities [P (o 1 ) ... P (o c )] ′ to normalize the activation levels to a prob-ability distribution over predicted classes. These probabilities are proportional to the exponential of the input values,\n\nAfter applying the softmax function, each component is in the interval [0, 1], and the components add up to 1.\n\nThe class C i * of the most active rule R i * , based on P (o i * ), in which i * = argmax(P (o 1 ), ..., P (o c )), is the output. Under assumption on specific neurons, rules extracted from eGNN-C+ are of the type",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "B. Aggregation Operators",
      "text": "Aggregation neurons are neuron models based on aggregation operators  [29]    [30] . An aggregation operator A :\n\n]. An operator satisfies the properties: (i) monotonicity in all arguments; and (ii) boundary conditions  [7] . The present study relies on the product triangular norm. Various T-S norms and parametric averaging operators have been assessed in different stream contexts  [7]    [34] .",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "C. Adaptive Expansion Regions",
      "text": "The support, core, midpoint, and width of G i j , ∀i, j, are, respectively,\n\nmp(G i j ) =\n\nLet ρ [h] ∈ [0, 1] be the maximum width that any G i j can have at time step h, i.e., wdt(G i j ) ≤ ρ [h] , ∀j, i. The hyper-parameter ρ [h] is crucial as it imposes granularity on the data space and influences the level of detail in representing classes.\n\nThe expansion region of the i-th granule in the granular layer is denoted as\n\nAt any time h, it holds that wdt(G i j ) ≤ wdt(E i j ) ∀j, i. An approach to allow an initial ρ [0] to find a value for itself based on the data is as follows. If learning starts from scratch with no a priori knowledge about the data, the default value for ρ [0] is 0.5. Let r be the number of granules created in h r steps, and η be a reference rate. If the number of granules grows faster than η, i.e. r > η, then ρ [h] is increased,\n\nThe rationale is to restrain large network structures, as they increase complexity and may not help generalization. Equation (  6 ) penalizes ρ. On the contrary, if the number of created granules is less than η, i.e. r < η, then ρ [h] is reduced,\n\nSuitable values for ρ [h]  The reduction of ρ [h] might involve shrinking certain large granules that become unsuitable for the new maximum. Outerbox contraction is based on:\n\nInner boxes [g i j , g i j ] are managed in a similar manner.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "D. Creating And Updating Granules",
      "text": "If one or more entries of x [h] are not enclosed by any of the expansion regions E i , i = 1, ..., c, the learning algorithm generates a new pointwise granule G c+1 with\n\nj = 1, ..., n. A corresponding aggregation neuron A c+1 , along with neuron connections, particularly using w c+1 j = 1, ∀j, is also created (refer to Fig.  1 ). Granule G c+1 is then associated with the class y [h] when it becomes available.\n\nIncremental updates to granules involve expanding or contracting the inner and outer boxes of G i * . The specific G i * chosen for adaptation at time step h is determined by i * = argmax(P (o 1 ), ..., P (o c )). Adaptation proceeds depending on the relative position of the entry x j of x [h] .\n\nOperations on the inner box, g i j and g i j , require the recalculation of the midpoint, mp(G i j ) =\n\nTherefore, outer box contraction may be necessary:",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "E. Updating Neural Network Weights",
      "text": "Weights w i j ∈ [0, 1], j = 1, ..., n, preceding the aggregator A i (refer to Fig.  1 ) are indicative of the local importance of the j-th feature for class discrimination. Upon the creation of a granule G c+1 , the weights in its synapses w c+1 are initialized to 1. From a number of possible recursive deterministic methods grounded in errors, losses, or feature ranking for weight updates, we opted for a straightforward and fast heuristic. The procedure assigns lower weights to local features that occasionally contributed to an incorrect classification.\n\nDefine the current estimation error as\n\nwhere ψ(.) is the sign function, specifically yielding -1 for a zero input, and +1 for positive inputs. Additionally, C [h] and Ĉi * [h] denote the actual class and the class associated with the most active G i * , with i * = argmax(P (o 1 ), ..., P (o c )). Notice that ϵ [h] is equal to -1 in the case of a correct prediction, or +1 otherwise.\n\nWeights w i * j , ∀j, associated to G i * , are updated from\n\nin which\n\nwhere R i * and W i * are counters for right and wrong predictions historically attributed to the specific granule G i * .",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "F. Deleting Granules",
      "text": "A granule is deleted from the eGNN-C+ if it is inconsistent with the current environment. We adopted a fast and simple procedure to remove a G i , along with corresponding weights w i and aggregator A i , if it does not exhibit the highest class probability P (o i * ) over h r time steps. In certain applications, if a class is rare or seasonal behaviors are anticipated, then h r can be adjusted to a large value to retain all granules. Periodic removal generally contributes to keeping the neural network updated, a particularly valuable aspect in applications like the EEG application described in this paper.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "G. Incremental Learning Algorithm",
      "text": "The learning algorithm for developing an eGNN-C+ model from evolving data streams is given below. Compute output error ϵ [h] ; 12:",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Egnn: Incremental Learning Algorithm",
      "text": "Create granule G c+1 , neuron A c+1 , weights w c+1 ; 14:\n\nAssign class C [h]  Delete inactive granules based on h r ; 20:\n\nif h = αh r , α = 1, . . . then",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "21:",
      "text": "Update max width ρ [h] based on η;\n\n22:\n\nend if 23: end for",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Iii. Methodology",
      "text": "The objective of this study is to classify emotion-related patterns within EEG data. We describe the process of feature extraction and model evaluation based on specific channels and on the multivariable brain-computer interface system.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "A. Data Pre-Processing",
      "text": "A game evokes a predominant emotion based on the quadrants of the Arousal-Valence circle  [35] . Negative emotions, such as 'angry', 'bored', and relative adjectives, are situated on the left side of the valence dimension. Positive emotions like 'happy' and 'calm' are positioned on the right side. The upper part of the circle characterizes extreme emotional arousal or behavioral expression, whereas the lower part indicates apathy. We assign numerical values to the quadrants (see Figure  2 ) to represent the classes: 'bored', 'calm', 'anger', and 'happy'. As players actively influence the game outcome, their mental activity is high. They engage in the cognitive processing of images, construct mental narratives, and critically evaluate characters and situations within the game. Initially, emotions are not inclined toward any quadrant  [36] . The raw data utilized in this study is available in  [27] . This dataset originates from 28 individuals, comprising the experimental group. Each participant engaged in four 5minute gaming sessions (20 minutes in total) using the Emotiv EPOC+ EEG device and earphones. The order of male-female (M-F) players is as follows: FMMMFFMMMMMFMMMMFFFFFMMMMMMM A single user-independent eGNN-C+ is evolved aiming at mitigating individual uncertainty, and enhancing the reliability and generalizability of the model. Brain activity is recorded using 14 electrodes positioned on the scalp according to the 10-20 System. These electrodes are located at positions Af3, Af4, F3, F4, F7, F8, Fc5, Fc6, T7, T8, P7, P8, O1, and O2. The letters indicate the corresponding lobes: F stands for Frontal, T for Temporal, P for Parietal, and O for Occipital. Even and odd numbers differentiate positions on the right and left brain hemispheres  [4] . The sampling frequency is set at 128Hz. Each player generates 38,400 instances per game, resulting in a total of 153,600 instances when considering the time domain. The experiments were conducted in a dark and quiet room, utilizing a laptop with a 15-inch screen and 16GB high-quality graphic capabilities. The games were played in a systematic order: 'Train Sim World', 'Unravel', 'Slender The Arrival', and 'Goat Simulator'. Their predominant emotion, determined by majority voting, are boredom, calmness, nervousness, and happiness (C [h] = {1, 2, 3, 4}).\n\nA fifth-order sinc filter is applied to the raw data to suppress movement artifacts  [27] . Subsequently, feature extraction is performed. We extract 10 features from each of the 14 EEG channels, i.e., a total of 140 features constitute each processed instance, which is effectively fed into the eGNN-C+. The features are the maximum and mean values of five frequency bands: Delta (1-4Hz), Theta (4-8Hz), Alpha (8-13Hz), Beta (13-30Hz), and Gamma (30-64Hz). The construction of a processed instance, ready for input into the neural classifier, is based on the frequency spectrum derived from 5-minute time windows. Given that each player engages in a 5-minute gaming session, they generate four instances, one per game. Consequently, the 28 participants collectively produce 112 processed instances. Furthermore, evaluations using 1-minute, 30-second, and 10-second windows result in 560, 1120, and 3360 processed instances, respectively. Examples of spectra, employing 30-second time windows and focusing on frontal electrodes (Af3, Af4, F3, F4), are presented in Fig.  3 . Notably, there is a greater energy level in the Delta, Theta, and Alpha bands. Obtaining the maximum and mean values per band and per channel is a straightforward process.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "B. Weak Supervision And Experiments",
      "text": "In a preliminary experiment, the analysis centers on individual electrodes. An eGNN-C+ model is fed with 10-feature instances, x [h] = [x 1 ... x 10 ] ′ , h = 1, ..., and evolves from scratch. The train-after-test approach is employed, i.e., an estimate is provided, and then the true class C [h] = {1, 2, 3, 4} of x [h] becomes available. Subsequently, the pair (x, C) [h] is used for a learning step.\n\nThe supervision is referred to as weak since players provide a label describing the predominant emotion for an entire 5minute recording. This label is propagated backward to all time windows. Note that the predominance of an emotion across the 5 minutes of interaction with a game may not precisely reflect the emotions within a specific window. However, generally, Fig.  3 : Examples of spectra and bands obtained from raw data generated by four frontal electrodes most windows tend to carry correct labels. Manually labeling all windows is unrealistic and would interrupt the interaction. Weak labels pose an additional challenge.\n\nSecond, the focus is shifted to the global 140-feature problem (multivariate time series analysis) -being 10 features extracted from each electrode. Thus, x [h] = [x 1 ... x 140 ], h = 1, ..., are the eGNN-C+ inputs. Dimension reduction is carried out using the Spearman's Correlation-based Score method  [37] . This method ranks features based on their direct association with the classes and their independence from other features. The Leave-5-Feature-Out-at-a-time method is then applied to eliminate lower-ranked features.",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "C. Performance And Interpretability",
      "text": "The classification accuracy, Acc ∈ [0, 1], is obtained recursively using\n\nin which τ := 1 if the estimate is correct, i.e., Ĉ[h] = C [h] ; and τ := 0 otherwise. In a 4-class problem, a random classifier is expected to have an accuracy of 0.25 (25%). Higher values of accuracy indicate patterns in the data. Additionally, a measure of model compactness is the average number of granules,\n\nThe index II  [31]  is useful to quantify the interpretability of eGNN-C+. The index considers factors such as balanced volumes, number of granules and dependent parameters, and features per partition. For x [h] , h = 1, ..., within the unit ncube [0, 1] n , the index II ∈ (0, 1] of a model, is\n\nis the average of the number of features used by each of the c existing granules,\n\nAs eGNN-C+ performs feature weighting but utilizes all n features in all its c granules, thus\n\nindicates the average number of parameters retained within (or associated with) the existing granules,\n\nwith θ i[h] being the number of local parameters related to G i . Furthermore,\n\nin which\n\nwhere\n\nand\n\nConstant ϵ := 10 -3n is a small value to prevent division by 0. The symbol ⋆ is an n-rectangle in this paper. Therefore, the volume of the i-th n-rectangle is the product of its edges,\n\nin which g i j and g i j are the lower and upper outer bounds. The population variance across the c max-scaled volumes, as needed in Eq. (  18 ), is\n\nin which\n\nis the current mean volume. The higher II [h] (15), the greater the model interpretability. The index says that a smaller set of concise rules supported by granules with balanced volumes, carrying fewer local parameters, contributes to a higher level of model understandability. Refer to  [31]  for a complete description.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Iv. Results",
      "text": "",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "A. Window Length And Individual Channel Analysis",
      "text": "Individual channels are evaluated to identify more promising regions of the brain for distinguishing patterns in this specific EEG application. The initial hyper-parameters of eGNN-C+ are ρ [0] = 0.6, h r = 100, and η = 2; A i ∀i is the product T-norm. The instances comprise 10 features. The accuracy  (13) , compactness  (14) , and interpretability (15) of eGNN-C+ models for the window lengths of 300, 60, 30, and 10 seconds are presented in Table  I . From Table  I , we notice that the mean accuracy for 5-minute windows, 21.2%, does not indicate learning. This suggests that the filter effect during feature extraction from larger windows suppresses the details necessary to differentiate classes. Given that emotions often have shorter duration, reducing the window length leads to an improvement in accuracy and a reduction of model complexity, c avg . The improvement is attributed to the availability of a larger pool of processed instances (as fewer instances are encapsulated per window) and the ability of the algorithm to guide the eGNN-C+ models toward a more stable configuration after deleting inactive granules. The difference between the mean accuracy of the 30-second (46.7%) and 10second (55.6%) windows is substantial. This suggests the need of further studies using smaller windows, which contradicts the result in  [9]  suggesting accuracy saturation; however using a relatively less-parametric Gaussian model. With more parameters and structural plasticity, eGNN-C+ has demonstrated more flexibility and an expanded capacity for incorporating additional class-discerning behaviors.\n\nAsymmetries in performance are observed for classifiers evolved for the left and right brain hemispheres (direct pairs of electrodes, specifically in smaller 10 and 30-second windows). While the right hemisphere is associated to emotional interpretation, creativity and intuition; logical interpretation, typical of the left hemisphere, is also evident as players seek reasons to justify decisions. Asymmetry is also related to approaching and withdrawal emotions, with approaching trends reflected in left-frontal activity, and withdrawal trends reflected in right-frontal activity. The slightly higher accuracy of the left frontal hemisphere compared to the right frontal one for 10-second windows portrays a mixture of approaching and withdrawal emotional patterns, inherent in game playing, with approaching patterns prevailing. In  [15] , differential asymmetries are input features of classifiers. Further discussions on asymmetries require specific steady-state experiments.\n\nWith focus on the 10-second window scenario, it is evident that discernible patterns exist in all channels. Notably, the parietal (P7-P8) and temporal (T7-T8) pairs, particularly channels T8 and P7, provided the best eGNN-C+ results. The temporal lobe T7-T8 is known for its relevance to audition, and visual and emotional perception, while the parietal lobe P7-P8 integrates information from various brain areas into a form we can comprehend. As the application exposes players to multiple sensory information, a high parietal activity is expected. Nonetheless, patterns arise in all regions, including the frontal and occipital lobes. For example, the channel Af4, despite displaying the lowest accuracy, 49.8% (which is still substantial), is related to motor commands for hand and arm movements, which is indirectly linked to emotions. A spectator, as opposed to a player, might have a model based solely on Af3-Af4 with diminished accuracy. The pair O1-O2 is also of key importance as it encompasses the primary visual cortex and areas of visual association. Overall, the results in Table  I  align with the findings in  [9]  and  [38] .",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "B. Feature Selection And Multiple Channel Analysis",
      "text": "The eGNN-C+ processes a multivariate 140-feature stream generated from 10-second windows over the 20-minute record-ings from each of the 28 players -this setup represents the best configuration established in the previous experiment. The features are ranked using Spearman's Correlation Score  [37] . The specific ranking of features for this dataset can be found in  [9] . To offer quantitative evidence, we sum the monotonic correlations per band (a sum of 28 items corresponding to 2 features from each of the 14 EEG channels). Figure  4  shows the result in dark yellow, and its decomposition per brain hemisphere. The precise global values are: 2.278 (Alpha), 1.748 (Delta), 1.376 (Theta), 0.664 (Beta), and 0.656 (Gamma). Higher values indicate a greater contribution of the band to class discrimination. We observe a prevalence of Alpha-band features, followed by Delta and Theta features. The strategy of leaving out five features at a time was applied to evaluate user-independent generalized eGNN-C+ models. Table  II  shows the results using product aggregation A i ∀i, η = 2, and distinct values for ρ [0] = 0.6, 0.7, and h r = 80, 100. From Table  II , we notice that spatio-temporal patterns emerge in many channels since lower-ranked features continue to positively affect the predictions. However, beyond the top 90 features, performance saturation is observed. The parameters ρ [0] = 0.7 and h r = 80 yielded more compact models, reducing the number of granules by approximately 3 in all scenarios. Simultaneously, these parameters resulted in enhanced interpretability, as indicated by the top 10-feature scenario with II = 0.0029. The highest accuracy, 81.70%, is achieved using 130 features. The stream of 3,360 instances is processed in 68.3 seconds (20.3 milliseconds per instance) on a quadcore laptop (i7-8550U, 1.80GHz, 8GB RAM). Given that an instance is generated every 10 seconds, eGNN-C+ can operate in real time with a larger structure or set of features, such as those from additional electrodes or other physiological and non-physiological means, e.g., facial image features obtained from convolutional networks. Additionally, exploring window lengths as small as around 100 milliseconds remains feasible while maintaining real-time execution.\n\nAn example of eGNN-C+ structural evolution (most accurate case, 81.70%) is shown in Fig.  5 . The average number   II . Otherwise, some knowledge distillation technique can be employed. Note that shifts due to the successive use of the EEG device may not require entirely new granules. This observation is especially true for female-male shifts. On the contrary, male-female shifts generally necessitates additional granules for data coverage. Updating double-boundary boxes and synaptic weights often proves sufficient to accommodate the different behaviors. The evolution of accuracy, as also shown in Fig.  5 , underscores the online learning capability of the classifier. Despite the non-stationary nature of EEG signals generated by multiple users engaged in games of varying styles, the mean accuracy fluctuates around 84.78% ± 3.02%. We emphasize that the eGNN-C+ model operates as a user-independent classifier. A user-specific eGNN-C+ model tends to exhibit a higher level of refinement with focus on the unique characteristics of the individual utilizing the EEG device. Figure  6  presents the confusion matrix for the most accurate model. Note that the target class 'bored', is more readily distinguishable compared to the other classes (94.4%). This is attributed to the particular windowing and feature extraction approaches, along with the new algorithm for double-boundary boxes presented. A relative balance of misclassifications across classes and confusion in all directions are observed for the remaining three classes, 'calm', 'anger', and 'happy'. Overall, the results, relying solely on EEG signals as the physiological data source and using evolving granular neural network, are promising for emotion-related pattern recognition. We introduced a modified incremental algorithm for evolving granular neural network classifiers. We have shown the effectiveness of the learning approach in emotion-related pattern recognition within weakly-supervised EEG signals in the context of game playing. Emotions such as boredom, calmness, angriness, or happiness are used to label time windows across EEG recordings. A set of 140 features is extracted from the Fourier spectrum related to 14 electrodes located at various scalp regions. We analyzed the Delta, Theta, Alpha, Beta, and Gamma bands, from 1 to 64Hz. We examined individual electrodes, window lengths, and the effect of dimensionality reduction on the eGNN-C+ accuracy. The eGNN-C+ learning algorithm updates not only synaptic weights but also the model structure, composed of double-boundary hyper-box granules where inner boxes are more flexible to capture drifts and outer boxes are more robust against noise.\n\nThe neural classifier evolves from scratch, incorporates new classes on-the-fly, and performs online feature weighting. Key observations include: (i) electrodes on both brain hemispheres -especially the electrodes on the temporal T8 and parietal P7 areas, but also electrodes on the occipital and frontal lobescontribute to the recognition of spatio-temporal patterns; (ii) while patterns can manifest in any frequency band, the Alpha (8-13 Hz) band, followed by the Delta (1-4 Hz) and Theta (4-8 Hz) bands, exhibit stronger correlations with classes; (iii) the eGNN-C+ algorithm achieves a processing time of 20.3 milliseconds per 140-feature instance. Thus, the approach is suitable for real-time applications considering multiple data sources; (iv) the highest accuracy, 81.7%, was achieved with 130 features and 10-second windows using 19.3 granules, despite the highly-stochastic dynamic nature of the 4-class classification problem. The configuration using 10 features provided the highest interpretability II, 0.0029. The resulting granular neural models are user independent. Future directions include evaluating wavelet transforms in specific frequency bands, integrating deep neural networks as feature extractors, and exploring ensembles of evolving models.",
      "page_start": 8,
      "page_end": 10
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: shows the architecture of the four-layer network.",
      "page": 3
    },
    {
      "caption": "Figure 1: eGNN-C+: Granular neural network with evolving",
      "page": 3
    },
    {
      "caption": "Figure 1: ). Granule Gc+1 is then associated",
      "page": 4
    },
    {
      "caption": "Figure 1: ) are indicative of the local importance of",
      "page": 4
    },
    {
      "caption": "Figure 2: The bi-dimensional Arousal-Valence model: a frame-",
      "page": 5
    },
    {
      "caption": "Figure 3: . Notably,",
      "page": 6
    },
    {
      "caption": "Figure 3: Examples of spectra and bands obtained from raw data",
      "page": 6
    },
    {
      "caption": "Figure 4: Spearman (monotonic) correlation between frequency",
      "page": 8
    },
    {
      "caption": "Figure 5: The average number",
      "page": 8
    },
    {
      "caption": "Figure 5: , underscores",
      "page": 9
    },
    {
      "caption": "Figure 6: presents the confusion matrix for the most accurate",
      "page": 9
    },
    {
      "caption": "Figure 5: Evolution of the granular structure and performance of",
      "page": 9
    },
    {
      "caption": "Figure 6: Confusion matrix for the most accurate 130-feature",
      "page": 9
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Left hemisphere": "II\nAcc(%)\nCh\ncavg",
          "Right hemisphere": "II\nAcc(%)\nCh\ncavg"
        },
        {
          "Left hemisphere": "Af3\n19.6\n27.3\n0.0017\nF3\n26.8\n27.1\n0.0016\nF7\n22.3\n26.6\n0.0016\nFc5\n24.1\n27.7\n0.0016\nT7\n18.8\n24.6\n0.0018\nP7\n17.9\n27.3\n0.0017\nO1\n25.0\n26.8\n0.0017",
          "Right hemisphere": "Af4\n17.0\n26.1\n0.0014\nF4\n20.5\n24.9\n0.0015\nF8\n17.9\n21.4\n0.0020\nFc6\n25.0\n22.3\n0.0019\nT8\n19.6\n25.2\n0.0017\nP8\n20.5\n30.6\n0.0015\nO2\n21.4\n24.3\n0.0017"
        },
        {
          "Left hemisphere": "Avg.\n22.1\n26.8\n0.0017",
          "Right hemisphere": "Avg.\n20.3\n25.0\n0.0017"
        }
      ],
      "page": 7
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Left hemisphere": "II\nAcc(%)\nCh\ncavg",
          "Right hemisphere": "II\nAcc(%)\nCh\ncavg"
        },
        {
          "Left hemisphere": "Af3\n37.7\n16.2\n0.0023\nF3\n33.6\n17.5\n0.0023\nF7\n38.4\n18.2\n0.0022\nFc5\n35.9\n17.1\n0.0017\nT7\n40.4\n15.3\n0.0024\nP7\n40.4\n15.6\n0.0023\nO1\n37.5\n16.0\n0.0021",
          "Right hemisphere": "Af4\n35.4\n16.7\n0.0019\nF4\n43.0\n15.0\n0.0023\nF8\n34.6\n16.4\n0.0019\nFc6\n45.0\n15.7\n0.0023\nT8\n46.4\n16.1\n0.0015\nP8\n34.6\n18.3\n0.0022\nO2\n42.3\n15.9\n0.0022"
        },
        {
          "Left hemisphere": "Avg.\n37.7\n16.6\n0.0022",
          "Right hemisphere": "Avg.\n40.2\n16.3\n0.0020"
        }
      ],
      "page": 7
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Left hemisphere": "II\nAcc(%)\nCh\ncavg",
          "Right hemisphere": "II\nAcc(%)\nCh\ncavg"
        },
        {
          "Left hemisphere": "Af3\n47.9\n13.7\n0.0019\nF3\n41.7\n11.9\n0.0018\nF7\n45.6\n12.5\n0.0026\nFc5\n46.4\n12.6\n0.0023\nT7\n47.1\n11.3\n0.0026\nP7\n50.6\n11.9\n0.0027\nO1\n47.5\n12.3\n0.0021",
          "Right hemisphere": "Af4\n43.1\n12.9\n0.0019\nF4\n46.3\n10.5\n0.0012\nF8\n39.2\n11.8\n0.0027\nFc6\n45.1\n12.5\n0.0020\nT8\n56.9\n11.8\n0.0026\nP8\n46.3\n13.8\n0.0021\nO2\n50.0\n12.8\n0.0022"
        },
        {
          "Left hemisphere": "Avg.\n46.7\n12.3\n0.0023",
          "Right hemisphere": "Avg.\n46.7\n12.3\n0.0021"
        }
      ],
      "page": 7
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Left hemisphere": "II\nAcc(%)\nCh\ncavg",
          "Right hemisphere": "II\nAcc(%)\nCh\ncavg"
        },
        {
          "Left hemisphere": "Af3\n55.7\n9.7\n0.0019\nF3\n55.1\n7.9\n0.0017\nF7\n52.5\n9.4\n0.0036\nFc5\n54.8\n8.1\n0.0029\nT7\n53.8\n7.9\n0.0026\nP7\n62.6\n8.8\n0.0029\nO1\n54.9\n8.3\n0.0033",
          "Right hemisphere": "Af4\n49.8\n7.7\n0.0019\nF4\n55.4\n7.0\n0.0018\nF8\n47.9\n7.0\n0.0036\nFc6\n59.0\n9.0\n0.0015\nT8\n64.3\n9.2\n0.0029\nP8\n57.6\n8.7\n0.0029\nO2\n55.4\n8.8\n0.0027"
        },
        {
          "Left hemisphere": "Avg.\n55.6\n8.6\n0.0027",
          "Right hemisphere": "Avg.\n55.6\n8.2\n0.0025"
        }
      ],
      "page": 7
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "ρ[0] = 0.6, hr = 100": "II\nAcc (%)\ncavg",
          "ρ[0] = 0.7, hr = 80": "II\nAcc (%)\ncavg"
        },
        {
          "ρ[0] = 0.6, hr = 100": "78.42\n23.74\n0.0001\n78.24\n23.04\n0.0001\n78.13\n22.71\n0.0001\n78.54\n22.66\n0.0001\n77.83\n22.36\n0.0001\n77.47\n21.93\n0.0002\n77.05\n21.44\n0.0002\n76.58\n21.05\n0.0002\n76.70\n20.69\n0.0002\n76.34\n20.24\n0.0002\n76.88\n20.31\n0.0002\n76.16\n19.83\n0.0002\n75.48\n19.53\n0.0002\n73.01\n19.25\n0.0003\n73.36\n18.48\n0.0003\n73.07\n18.93\n0.0003\n72.65\n17.43\n0.0003\n71.93\n17.27\n0.0004\n70.57\n17.49\n0.0004\n69.46\n16.74\n0.0003\n59.40\n14.67\n0.0005\n60.54\n14.72\n0.0006\n57.47\n13.59\n0.0005\n56.96\n12.16\n0.0008\n56.73\n11.91\n0.0011\n53.15\n11.00\n0.0006\n47.47\n9.31\n0.0009",
          "ρ[0] = 0.7, hr = 80": "81.58\n19.83\n0.0001\n81.07\n19.48\n0.0001\n81.70\n19.26\n0.0002\n81.40\n19.37\n0.0002\n81.10\n18.98\n0.0002\n81.16\n18.36\n0.0002\n80.41\n17.67\n0.0002\n80.15\n17.35\n0.0002\n79.61\n17.23\n0.0002\n78.87\n16.84\n0.0002\n79.05\n17.14\n0.0002\n77.80\n16.35\n0.0003\n77.41\n16.10\n0.0003\n77.53\n16.38\n0.0003\n78.45\n15.55\n0.0003\n77.17\n15.84\n0.0003\n78.45\n15.59\n0.0004\n77.59\n15.35\n0.0004\n77.26\n14.42\n0.0005\n75.68\n12.41\n0.0006\n73.72\n11.75\n0.0006\n72.08\n11.11\n0.0007\n73.96\n10.68\n0.0008\n73.57\n10.11\n0.0009\n74.46\n9.84\n0.0005\n71.73\n8.84\n0.0009\n67.02\n7.46\n0.0029"
        }
      ],
      "page": 9
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Cross-cultural emotion recognition with EEG and eye movement signals based on multiple stacked broad learning system",
      "authors": [
        "X Gong",
        "C Chen",
        "T Zhang"
      ],
      "year": "2023",
      "venue": "Cross-cultural emotion recognition with EEG and eye movement signals based on multiple stacked broad learning system"
    },
    {
      "citation_id": "2",
      "title": "Emotion recognition in EEG signals using deep learning methods: A review",
      "authors": [
        "M Jafari"
      ],
      "year": "2023",
      "venue": "Computers in Biology and Medicine"
    },
    {
      "citation_id": "3",
      "title": "EEG emotion recognition using dynamical graph convolutional neural networks",
      "authors": [
        "T Song",
        "W Zheng",
        "P Song",
        "Z Cui"
      ],
      "year": "2020",
      "venue": "Trans Affect Comp"
    },
    {
      "citation_id": "4",
      "title": "Emotions recognition using EEG signals: A survey",
      "authors": [
        "M Alarcao",
        "M Fonseca"
      ],
      "year": "2019",
      "venue": "Trans Affect Comp"
    },
    {
      "citation_id": "5",
      "title": "Human emotion recognition from EEG-based brain-computer interface using machine learning: a comprehensive review",
      "authors": [
        "E Houssein",
        "A Hammad",
        "A Ali"
      ],
      "year": "2022",
      "venue": "Neural Computing and Applications"
    },
    {
      "citation_id": "6",
      "title": "Evolving fuzzy and neuro-fuzzy approaches in clustering, regression, identification, and classification: A survey",
      "authors": [
        "I Skrjanc",
        "J Iglesias",
        "A Sanchis",
        "D Leite",
        "E Lughofer",
        "F Gomide"
      ],
      "year": "2019",
      "venue": "Inf Sci"
    },
    {
      "citation_id": "7",
      "title": "Evolving granular neural networks from fuzzy data streams",
      "authors": [
        "D Leite",
        "P Costa",
        "F Gomide"
      ],
      "year": "2013",
      "venue": "Neural Networks"
    },
    {
      "citation_id": "8",
      "title": "Emotion recognition and artificial intelligence: A systematic review (2014-2023) and research recommendations",
      "authors": [
        "S Khare",
        "V Blanes-Vidal",
        "E Nadimi",
        "U Acharya"
      ],
      "year": "2024",
      "venue": "Inf. Fusion"
    },
    {
      "citation_id": "9",
      "title": "Adaptive gaussian fuzzy classifier for real-time emotion recognition in computer games",
      "authors": [
        "D Leite",
        "V Frigeri",
        "R Medeiros"
      ],
      "year": "2022",
      "venue": "IEEE Latin American Conf. on Computational Intelligence (LA-CCI)"
    },
    {
      "citation_id": "10",
      "title": "How do e-commerce anchors' characteristics influence consumers' impulse buying? An emotional contagion perspective",
      "authors": [
        "L Li",
        "X Chen",
        "P Zhu"
      ],
      "year": "2024",
      "venue": "J. Retail. Consum. Serv"
    },
    {
      "citation_id": "11",
      "title": "A review on data fusion in multimodal learning analytics and educational data mining",
      "authors": [
        "W Chango",
        "J Lara",
        "R Cerezo",
        "C Romero"
      ],
      "year": "1458",
      "venue": "WIREs Data Mining Knowl. Discov"
    },
    {
      "citation_id": "12",
      "title": "Brain-computer interface: trend, challenges, and threats",
      "authors": [
        "B Maiseli",
        "A Abdalla",
        "L Massawe",
        "M Mbise",
        "K Mkocha",
        "N Nassor",
        "M Ismail",
        "J Michael",
        "S Kimambo"
      ],
      "year": "2023",
      "venue": "Brain Informatics"
    },
    {
      "citation_id": "13",
      "title": "A comprehensive survey on emotion recognition based on electroencephalograph (EEG) signals",
      "authors": [
        "K Kamble",
        "J Sengupta"
      ],
      "year": "2023",
      "venue": "Multimedia Tools and Applications"
    },
    {
      "citation_id": "14",
      "title": "An experimental protocol to access immersiveness in video games",
      "authors": [
        "M Malaspina",
        "J Barbato",
        "M Cremaschi",
        "F Gasparini",
        "A Grossi",
        "A Saibene"
      ],
      "year": "2023",
      "venue": "Proc. Art. Intell. for Human-Machine Interaction"
    },
    {
      "citation_id": "15",
      "title": "Learning deep physiological models of affect",
      "authors": [
        "H Martinez",
        "Y Bengio",
        "G Yannakakis"
      ],
      "year": "2013",
      "venue": "Comp Intell Mag"
    },
    {
      "citation_id": "16",
      "title": "Investigating critical frequency bands and channels for EEG-based emotion recognition with deep neural networks",
      "authors": [
        "W.-L Zheng",
        "B.-L Lu"
      ],
      "year": "2015",
      "venue": "IEEE Transactions on Auton Ment Dev"
    },
    {
      "citation_id": "17",
      "title": "Two-stage fuzzy fusion based-convolution neural network for dynamic emotion recognition",
      "authors": [
        "M Wu",
        "W Su",
        "L Chen",
        "W Pedrycz",
        "K Hirota"
      ],
      "year": "2020",
      "venue": "Trans Affect Comp"
    },
    {
      "citation_id": "18",
      "title": "An explanation framework and method for AI-based text emotion analysis and visualisation",
      "authors": [
        "Y Li",
        "J Chan",
        "G Peko",
        "D Sundaram"
      ],
      "year": "2024",
      "venue": "Decision Support Systems"
    },
    {
      "citation_id": "19",
      "title": "Measuring service quality based on customer emotion: An explainable AI approach",
      "authors": [
        "Y Guo",
        "Y Li",
        "D Liu",
        "S Xu"
      ],
      "year": "2024",
      "venue": "Decision Support Systems"
    },
    {
      "citation_id": "20",
      "title": "Facial emotion recognition based on biorthogonal wavelet entropy, fuzzy support vector machine, and stratified cross validation",
      "authors": [
        "Y Zhang"
      ],
      "year": "2016",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "21",
      "title": "Emotion recognition based on 3D fuzzy visual and EEG features in movie clips",
      "authors": [
        "G Lee",
        "M Kwon",
        "S Kavuri",
        "M Lee"
      ],
      "year": "2014",
      "venue": "Neurocomputing"
    },
    {
      "citation_id": "22",
      "title": "Driver drowsiness estimation from EEG signals using online weighted adaptation regularization for regression (OwARR)",
      "authors": [
        "D Wu",
        "V Lawhern",
        "S Gordon",
        "B Lance",
        "C.-T Lin"
      ],
      "year": "2016",
      "venue": "IEEE Tran Fuzzy Syst"
    },
    {
      "citation_id": "23",
      "title": "Fuzzy integral with particle swarm optimization for a motor-imagery-based brain-computer interface",
      "authors": [
        "S.-L Wu"
      ],
      "year": "2016",
      "venue": "IEEE Tran Fuzzy Syst"
    },
    {
      "citation_id": "24",
      "title": "Comparison of evolving granular classifiers applied to anomaly detection for predictive maintenance in computing centers",
      "authors": [
        "L Decker",
        "D Leite",
        "F Viola",
        "D Bonacorsi"
      ],
      "year": "2020",
      "venue": "IEEE EAIS"
    },
    {
      "citation_id": "25",
      "title": "Evolving granular neural network for fuzzy time series forecasting",
      "authors": [
        "D Leite",
        "P Costa",
        "F Gomide"
      ],
      "year": "2012",
      "venue": "IEEE IJCNN"
    },
    {
      "citation_id": "26",
      "title": "Comparison of Genetic and Incremental Learning Methods for Neural Network-Based Electrical Machine Fault Detection",
      "authors": [
        "D Leite"
      ],
      "year": "2019",
      "venue": "Comparison of Genetic and Incremental Learning Methods for Neural Network-Based Electrical Machine Fault Detection"
    },
    {
      "citation_id": "27",
      "title": "Database for an emotion recognition system based on EEG signals and various computer games -gameemo",
      "authors": [
        "T Alakus",
        "M Gonenb",
        "I Turkogluc"
      ],
      "year": "2020",
      "venue": "Biomed Signal Proces"
    },
    {
      "citation_id": "28",
      "title": "Granular Computing: Analysis and Design of Intelligent Systems",
      "authors": [
        "W Pedrycz"
      ],
      "year": "2013",
      "venue": "Granular Computing: Analysis and Design of Intelligent Systems"
    },
    {
      "citation_id": "29",
      "title": "Aggregation Functions: A Guide for Practitioners",
      "authors": [
        "G Beliakov",
        "A Pradera",
        "T Calvo"
      ],
      "year": "2007",
      "venue": "Studies in Fuzz and Soft Comp"
    },
    {
      "citation_id": "30",
      "title": "A Practical Guide to Averaging Functions",
      "authors": [
        "G Beliakov",
        "H Sola",
        "T Sanchez"
      ],
      "year": "2016",
      "venue": "Studies in Fuzz and Soft Comp"
    },
    {
      "citation_id": "31",
      "title": "Interpretability index based on balanced volumes for transparent models and agnostic explainers (To Appear)",
      "authors": [
        "D Leite",
        "A Sharma",
        "C Demir",
        "A.-C Ngomo"
      ],
      "year": "2024",
      "venue": "IEEE WCCI -FUZZ-IEEE"
    },
    {
      "citation_id": "32",
      "title": "Learning under concept drift: A review",
      "authors": [
        "J Lu",
        "A Liu",
        "F Dong",
        "F Gu",
        "J Gama",
        "G Zhang"
      ],
      "year": "2019",
      "venue": "IEEE Trans. Knowl. Data Eng"
    },
    {
      "citation_id": "33",
      "title": "The stability-plasticity dilemma: investigating the continuum from catastrophic forgetting to age-limited learning effects",
      "authors": [
        "M Mermillod",
        "A Bugaiska",
        "P Bonin"
      ],
      "year": "2013",
      "venue": "Front Psychol"
    },
    {
      "citation_id": "34",
      "title": "Ensemble of evolving optimal granular experts, owa aggregation, and time series prediction",
      "authors": [
        "D Leite",
        "I Skrjanc"
      ],
      "year": "2019",
      "venue": "Information Sciences"
    },
    {
      "citation_id": "35",
      "title": "A circumplex model of affect",
      "authors": [
        "J Russell"
      ],
      "year": "1980",
      "venue": "J. Pers. Soc. Psychol"
    },
    {
      "citation_id": "36",
      "title": "Brain-computer interface games based on consumer-grade EEG devices: A systematic literature review",
      "authors": [
        "G Vasiljevic",
        "L Miranda"
      ],
      "year": "2020",
      "venue": "Int J Hum-Comput Int"
    },
    {
      "citation_id": "37",
      "title": "Ensemble of evolving data clouds and fuzzy models for weather time series prediction",
      "authors": [
        "E Soares",
        "P Costa",
        "B Costa",
        "D Leite"
      ],
      "year": "2018",
      "venue": "Appl Soft Comput"
    },
    {
      "citation_id": "38",
      "title": "Identifying stable patterns over time for emotion recognition from EEG",
      "authors": [
        "W.-L Zheng",
        "J.-Y Zhu",
        "B.-L Lu"
      ],
      "year": "2019",
      "venue": "Trans Affect Comp"
    }
  ]
}