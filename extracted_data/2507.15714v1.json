{
  "paper_id": "2507.15714v1",
  "title": "Chinchunmei At Semeval-2025 Task 11: Boosting The Large Language Model'S Capability Of Emotion Perception Using Contrastive Learning",
  "published": "2025-07-21T15:25:47Z",
  "authors": [
    "Tian Li",
    "Yujian Sun",
    "Huizhi Liang"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "The SemEval-2025 Task 11, Bridging the Gap in Text-Based Emotion Detection, introduces an emotion recognition challenge spanning over 28 languages. This competition encourages researchers to explore more advanced approaches to address the challenges posed by the diversity of emotional expressions and background variations. It features two tracks: multi-label classification (Track A) and emotion intensity prediction (Track B), covering six emotion categories: anger, fear, joy, sadness, surprise, and disgust. In our work, we systematically explore the benefits of two contrastive learning approaches: samplebased (Contrastive Reasoning Calibration) and generation-based (DPO, SimPO) contrastive learning. The sample-based contrastive approach trains the model by comparing two samples to generate more reliable predictions. The generation-based contrastive approach trains the model to differentiate between correct and incorrect generations, refining its prediction. All models are fine-tuned from LLaMa3-Instruct-8B. Our system achieves 9th place in Track A and 6th place in Track B for English, while ranking among the top-tier performing systems for other languages.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Text-Based Emotion Detection (TBED) has long been a prominent research area in NLP, with widespread applications in social media analysis  (Kuamri and Babu, 2017; Salam and Gupta, 2018; Cassab and Kurdy, 2020) , mental health treatment  (Kusal et al., 2021; Krommyda et al., 2021) , and dialogue systems  (Liu et al., 2022; Ide and Kawahara, 2022; Hu et al., 2021) . Depending on how emotions are defined, TBED can be broadly categorized into two approaches: (1) Classification-based methods, where emotions are categorized into discrete labels  (Ekman and Friesen, 1969; Plutchik, 1982) . (2) Scoring-based methods, where emotions are treated as interrelated entities with varying intensity levels  (Russell and Mehrabian, 1977) .\n\nHowever, due to the nuanced and complex nature of emotional expression, TBED faces several key challenges  (Al Maruf et al., 2024) : (1) The distinction between different emotions is often subtle, and emotions are often conveyed implicitly-through metaphors or situational cues rather than explicit words. (2) Cultural and linguistic differences influence emotion perception. These challenges make TBED difficult to rely solely on predefined lexicons. A robust TBED system must integrate cultural context, linguistic diversity, background knowledge, and advanced semantic understanding.\n\nSemEval-2025, Task 11, titled \"Bridging the Gap in Text-Based Emotion Detection\"  (Muhammad et al., 2025b) , introduces a multilingual benchmark covering 28 languages  (Muhammad et al., 2025a; Belay et al., 2025) . The competition consists of Track A (multi-label classification) and Track B (intensity prediction). The goal is to identify the speaker's perceived emotion in a given sentence. Emotion categories follow Ekman's framework  (Ekman and Friesen, 1969) , encompassing six basic emotions: anger, fear, sadness, joy, disgust, and surprise. Task B further introduces four intensity levels for each emotion. This competition setup encapsulates both primary TBED methodologies while incorporating challenges in multilingual and fine-grained emotion recognition.\n\nTo participate in both tracks and support all languages predictions, we adopt the generative large language model (LLM). This decision is driven by its robust multi-task integration capabilities and strong support for cross-linguistic applications.\n\nIn this paper, we explore two alternative types of approaches -sample-based contrastive learning and generation-based contrastive learning -to address the complexity of emotional expression and the ambiguity of sentiment labels. The samplebased approach leverages Contrastive Reasoning Calibration technology (CRC)  (Li et al., 2024) , which enhances prediction reliability by generating multiple predictions through sample comparisons and aggregating them via majority voting. The generation-based approaches employ preference optimization techniques  (Rafailov et al., 2023; Hong et al., 2024; Meng et al., 2025) , refining the model's comprehension of sentiment labels by increasing the log probability of correct outputs while reducing that of incorrect ones. Given computational constraints, we only explore DPO  (Rafailov et al., 2023)  and SimPO  (Meng et al., 2025) , two widely acknowledged methods that do not require the reward model.\n\nOur key contributions are as follows:\n\n• We explored the impact of non-English data on English sentiment prediction under limited computational resources. Surprisingly, experimental results indicate that incorporating non-English data degrades performance in both classification tasks (Track A) and scoring tasks (Track B).\n\n• We conducted a comprehensive evaluation and bad case analysis of two contrastive approaches on the competition dataset. In the sample-based contrastive Learning, CRC technology yielded limited benefit. In the generation-based contrastive Learning, DPO demonstrated a significant positive effect on Track B. Although SimPO has achieved gains on some labels, the overall effect has dropped significantly.\n\n• In the leaderboard, our approach achieved Track A top 10 in 16 languages and 9th in English; Track B top 10 across all languages and 6th in English.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Methodology",
      "text": "To reduce our workload, we integrate both Track A and Track B into the same model by using different prompt templates for each. This unified approach enables the model to dynamically switch between prediction tasks as needed.\n\nIn our explorations, we designed three distinct tasks:\n\n• Standard Prediction (Baseline): The model is trained to directly output all emotion labels based on the input text.\n\n• Sample-Based Contrastive Learning: The model learns to compare two samples to generate more reliable predictions, leveraging contrastive reasoning to refine label predictions.\n\n• Generation-Based Contrastive Learning: The model learns to differentiate between correct and incorrect predictions, improving its ability to generate accurate label outputs.\n\nFigure  1  illustrates the training workflow of these three tasks.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Standard Prediction",
      "text": "During sample preparation, we integrate the text content into a pre-designed prompt template as input and format the label results as the ground truth output. The template details can be found in Appendix A.1. The model is then trained through supervised fine-tune (SFT) using this formatted input and corresponding output.\n\nDuring inference, we apply the same prompt template to incorporate the input text for prediction. By parsing the generated output, we extract the corresponding label predictions.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Sample-Based Contrastive Learning",
      "text": "In this category, we use CRC, a technique designed to enhance the model's ability to discern subtle differences in samples. By having the model compare the score variations between two samples, model can better understand their distinctions and generate calibrated predictions. The key to this task lies in sample preparation and inference process.\n\nDuring sample preparation, we randomly select two samples from the training set (Figure  1  middle) and construct a contrastive pair using the template in Appendix A.1. The target output comprises two components: a contrastive summary and two samples' predictions. The contrastive summary, expressed in natural language, highlights the existence or intensity difference between two samples on a specific label. The predictions provide explicit scores for both samples on the given label.\n\nGiven that random pairwise sampling can generate a vast amount of training data, we impose an upper limit on the total number of sampled pairs for each track. Specifically, for Track A, we sample 3,000 contrastive pairs per label, while for Track B, we sample 6,000 pairs per label, as Track B involves more fine-grained scoring labels compared to Track A.\n\nDuring inference, each test sample is paired with a randomly selected training sample to form a contrastive input. Since the model achieves highly accurate predictions on training samples, these trained samples serve as reliable reference points, reducing prediction uncertainty. The two samples are integrated into the CRC prompt template, with the test sample randomly assigned to either position 1 or position 2. This process is repeated N times to generate N different input instances, producing N predictions. The final score is determined through a voting mechanism, where the most frequently predicted score is selected as the final output.",
      "page_start": 3,
      "page_end": 4
    },
    {
      "section_name": "Generation-Based Contrastive Learning",
      "text": "To enhance the model's sensitivity to scoring, we incorporate preference optimization. However, due to computational constraints, we only explore techniques that do not require a reward model, such as DPO and SimPO.\n\nDPO optimizes the language model by maximizing the relative probability ratio to favor preferred outputs (Eq 1). Here, π θ and π ref represent the target and reference models, respectively, while y w and y l denote the correct and incorrect outputs. β is a scaling hyperparameter. This optimization process is applied after SFT.\n\n-logσ(βlog\n\nSimPO adopts a similar optimization objective (Eq 2), directly enhancing the probability of the target model's preferred outputs. However, it simplifies DPO by discarding the reference model and using sequence length to normalize the loss. Additionally, it adopts a hyperparameter γ to ensure that the likelihood for the correct response exceeds the incorrect response by γ. Like DPO, SimPO is also applied after SFT.\n\n-logσ(\n\n(2) During sample preparation, to enhance the model's sensitivity to label scoring, we mute only the label scores to generate y l (Figure  1  right, the Label Mutation block). The y w corresponds to the original SP ground truth, while the y l follows the same SP template but with muted scores. The probabilities of muting one, two, three, four, and five labels are [63.8%, 26.1%, 8.3%, 1.6%, 0.1%], respectively. When mutation is triggered, a random value is selected from the remaining label values as the incorrect score.\n\nFor Track A, each training sample executes five mutations, generating five contrastive samples for generation-based contrastive learning. For Track B, mutation is repeated 15 times, creating 15 contrastive samples. These settings ensured that the preference optimization dataset was comparable in size to the CRC dataset, allowing for a fair comparison between sample-based and generation-based approaches.",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Experiment",
      "text": "In All models in our experiments are fine-tuned from Llama3-Instruct-8B  (Dubey et al., 2024) , selected for its strong multilingual capabilities and acceptable computational cost. To validate its multilingual capabilities in each language, we check the consistency between original and recovered text using its tokenizer to encode and decode the text content. This experiment confirmed that the model supports all competition languages.\n\nWe first evaluate the impact of multilingual data on English-only performance in the standard prediction (SP) task. Then, we experiment with CRC, DPO, and SimPO on the English dataset to examine the effectiveness of sample-based and generationbased contrastive learning for TBED. The CRC model is trained via SFT on a combination of SP and CRC datasets. DPO and SimPO models are obtained by applying preference tuning to the Englishonly SP model.\n\nTo reduce training costs, we use LoRA  (Hu et al., 2022)  for all fine-tuning tasks, with its rank and alpha set as 8 and 16. Each training lasts for 3 epochs with a batch size of 128. Regarding the learning rate (LR), SP and CRC employ 4e-4, DPO adopts 5e-6, and SimPO uses 1e-6. All models are trained using the AdamW optimizer, with β 1 = 0.8, β 2 = 0.99. All LR scheduler employs cosine decay with a warmup ratio of 0.1. For CRC inference, we set N = 3 for Track A and N = 7 for Track B.\n\nAll experiments are conducted using 8-GPU distributed training. Due to limited computational resources, different GPUs are used across various training runs. However, all GPUs are based on the Ada Lovelace or Hopper architecture, allowing us to leverage a wide range of existing acceleration techniques to enhance training efficiency.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Results",
      "text": "Tables  1  and 2  present the performance of all models on the English test set. Table  1  corresponds to Track A, the multi-emotion classification task, while Table  2  corresponds to Track B, the emotion intensity prediction task.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Multilingual Influence",
      "text": "We observe that multilingual training underperforms compared to English-only training in both Track A and Track B. This finding highlights the significant differences in emotion perception across languages and cultural contexts, which can introduce conflicts in the model's understanding of sentiment labels. Therefore, we submit the non-English results generated by the multilingual SP model to  To further investigate the underlying reasons for these results, we conduct the bad case analysis for different techniques.\n\nFor the CRC model, we analyze Track A anger's misclassifications. We find that most misclassifications-accounting for 70% of the errors-are due to the model incorrectly predicting a neutral emotional state. Table  3  presents 4 randomly sampled bad cases, illustrating that these instances are on the borderline of the anger definition. Comparing them with other samples can easily influence their predictions, causing uncertainty and error. This suggests that the dataset may not be well-suited for sample-based comparison approach.\n\nFor the DPO model, we analyze sadness's wrong cases in Track B. We observe that over 90% of the errors differs from the ground truth by only one intensity level. This indicates that the model still has room for improvement in its recognition of label intensity.\n\nRegarding the SimPO model, we figure out that its poor performance primarily stemmed from the loss of output formatting, leading to frequent content parsing errors. This highlights the critical role of the reference model in preference tuning. While SimPO effectively increases the probability margin between correct and incorrect outputs, it may also make correct outputs no longer rank as the top generation.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Conclusion",
      "text": "The SemEVAL-2025 organizers introduce a highly challenging text-based emotion detection dataset, covering multi-label classification and intensity prediction across 28 languages. The dataset reflects the complexity of emotional expression and the diversity introduced by different linguistic and cultural backgrounds.\n\nWe explore three types of approaches in this competition. The baseline approach is the standard prediction task. The two enhanced types of approaches were sample-based contrastive learning and generation-based contrastive learning. For the sample-based approach, we try CRC. For the generation-based approach, we explore both DPO and SimPO. They all aim to improve model prediction through contrastive training-one by comparing samples and the other by discriminating between correct and incorrect generations.\n\nOur experiments reveal that different languages reflect distinct cultural backgrounds, so multilingual training does not improve English emotion detection. Meanwhile, due to the inherent ambiguity of sentiment expressions, sample-based contrastive learning raises additional uncertainty, ultimately reducing prediction accuracy. On the other hand, generation-based contrastive learning provides consistent improvements in intensity prediction, though its effectiveness varies significantly across different techniques. Notably, reference model constraint is crucial in stabilizing generationbased contrastive optimization process. It prevents excessive deviation from the original model distribution, and preserves key capabilities such as structured output generation.",
      "page_start": 9,
      "page_end": 9
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: The 3 types of technical solutions we adopted in this competition. On the left is the Standard Prediction",
      "page": 2
    },
    {
      "caption": "Figure 1: illustrates the training workflow of these",
      "page": 2
    },
    {
      "caption": "Figure 1: right, the",
      "page": 3
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "while ranking among the top-tier performing": ""
        },
        {
          "while ranking among the top-tier performing": "systems for other languages."
        },
        {
          "while ranking among the top-tier performing": ""
        },
        {
          "while ranking among the top-tier performing": ""
        },
        {
          "while ranking among the top-tier performing": "1\nIntroduction"
        },
        {
          "while ranking among the top-tier performing": ""
        },
        {
          "while ranking among the top-tier performing": "Text-Based Emotion Detection (TBED) has long"
        },
        {
          "while ranking among the top-tier performing": "been\na\nprominent\nresearch\narea\nin NLP, with"
        },
        {
          "while ranking among the top-tier performing": "widespread applications in social media analysis"
        },
        {
          "while ranking among the top-tier performing": "(Kuamri and Babu, 2017; Salam and Gupta, 2018;"
        },
        {
          "while ranking among the top-tier performing": "Cassab and Kurdy, 2020), mental health treatment"
        },
        {
          "while ranking among the top-tier performing": "(Kusal et al., 2021; Krommyda et al., 2021), and"
        },
        {
          "while ranking among the top-tier performing": "dialogue systems (Liu et al., 2022; Ide and Kawa-"
        },
        {
          "while ranking among the top-tier performing": "hara, 2022; Hu et al., 2021). Depending on how"
        },
        {
          "while ranking among the top-tier performing": "emotions are defined, TBED can be broadly catego-"
        },
        {
          "while ranking among the top-tier performing": "rized into two approaches: (1) Classification-based"
        },
        {
          "while ranking among the top-tier performing": "methods, where emotions are categorized into dis-"
        },
        {
          "while ranking among the top-tier performing": "crete labels (Ekman and Friesen, 1969; Plutchik,"
        },
        {
          "while ranking among the top-tier performing": "1982). (2) Scoring-based methods, where emotions"
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "huizhi.liang@newcastle.ac.uk"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "Abstract"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": ""
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "The SemEval-2025 Task\n11, Bridging\nthe"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": ""
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "Gap in Text-Based Emotion Detection,\nintro-"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": ""
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "duces an emotion recognition challenge span-"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": ""
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "ning over 28 languages.\nThis\ncompetition"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": ""
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "encourages\nresearchers\nto explore more ad-"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "vanced approaches to address the challenges"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "posed by the diversity of emotional expres-"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "sions and background variations.\nIt\nfeatures"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": ""
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "two tracks: multi-label classification (Track"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": ""
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "A) and emotion intensity prediction (Track B),"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": ""
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "covering six emotion categories:\nanger,\nfear,"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": ""
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "joy,\nsadness,\nsurprise,\nand disgust.\nIn our"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": ""
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "work, we systematically explore the benefits of"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "two contrastive learning approaches: sample-"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "based (Contrastive Reasoning Calibration) and"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "generation-based (DPO, SimPO) contrastive"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "learning.\nThe sample-based contrastive ap-"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": ""
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "proach trains the model by comparing two sam-"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": ""
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "ples to generate more reliable predictions. The"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": ""
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "generation-based contrastive approach trains"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": ""
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "the model\nto\ndifferentiate\nbetween\ncorrect"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": ""
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "and incorrect generations, refining its predic-"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "tion. All models are fine-tuned from LLaMa3-"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "Instruct-8B. Our system achieves 9th place in"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "Track A and 6th place in Track B for English,"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": ""
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "while ranking among the top-tier performing"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": ""
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "systems for other languages."
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": ""
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": ""
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "1\nIntroduction"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": ""
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "Text-Based Emotion Detection (TBED) has long"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "been\na\nprominent\nresearch\narea\nin NLP, with"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "widespread applications in social media analysis"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "(Kuamri and Babu, 2017; Salam and Gupta, 2018;"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "Cassab and Kurdy, 2020), mental health treatment"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "(Kusal et al., 2021; Krommyda et al., 2021), and"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "dialogue systems (Liu et al., 2022; Ide and Kawa-"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "hara, 2022; Hu et al., 2021). Depending on how"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "emotions are defined, TBED can be broadly catego-"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "rized into two approaches: (1) Classification-based"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "methods, where emotions are categorized into dis-"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "crete labels (Ekman and Friesen, 1969; Plutchik,"
        },
        {
          "t.li56@newcastle.ac.uk, sunyujian@ishumei.com,": "1982). (2) Scoring-based methods, where emotions"
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Figure 1: The 3 types of technical solutions we adopted in this competition. On the left is the Standard Prediction": "training. The middle is the sample-based contrastive training, where Samples 1, 2, 3, and 4 are randomly drawn"
        },
        {
          "Figure 1: The 3 types of technical solutions we adopted in this competition. On the left is the Standard Prediction": "from the training datasets. On the right is the generation-based contrastive training, where incorrect generations are"
        },
        {
          "Figure 1: The 3 types of technical solutions we adopted in this competition. On the left is the Standard Prediction": ""
        },
        {
          "Figure 1: The 3 types of technical solutions we adopted in this competition. On the left is the Standard Prediction": ""
        },
        {
          "Figure 1: The 3 types of technical solutions we adopted in this competition. On the left is the Standard Prediction": ""
        },
        {
          "Figure 1: The 3 types of technical solutions we adopted in this competition. On the left is the Standard Prediction": ""
        },
        {
          "Figure 1: The 3 types of technical solutions we adopted in this competition. On the left is the Standard Prediction": "2"
        },
        {
          "Figure 1: The 3 types of technical solutions we adopted in this competition. On the left is the Standard Prediction": ""
        },
        {
          "Figure 1: The 3 types of technical solutions we adopted in this competition. On the left is the Standard Prediction": ""
        },
        {
          "Figure 1: The 3 types of technical solutions we adopted in this competition. On the left is the Standard Prediction": ""
        },
        {
          "Figure 1: The 3 types of technical solutions we adopted in this competition. On the left is the Standard Prediction": ""
        },
        {
          "Figure 1: The 3 types of technical solutions we adopted in this competition. On the left is the Standard Prediction": ""
        },
        {
          "Figure 1: The 3 types of technical solutions we adopted in this competition. On the left is the Standard Prediction": ""
        },
        {
          "Figure 1: The 3 types of technical solutions we adopted in this competition. On the left is the Standard Prediction": ""
        },
        {
          "Figure 1: The 3 types of technical solutions we adopted in this competition. On the left is the Standard Prediction": ""
        },
        {
          "Figure 1: The 3 types of technical solutions we adopted in this competition. On the left is the Standard Prediction": ""
        },
        {
          "Figure 1: The 3 types of technical solutions we adopted in this competition. On the left is the Standard Prediction": "prediction tasks as needed."
        },
        {
          "Figure 1: The 3 types of technical solutions we adopted in this competition. On the left is the Standard Prediction": ""
        },
        {
          "Figure 1: The 3 types of technical solutions we adopted in this competition. On the left is the Standard Prediction": ""
        },
        {
          "Figure 1: The 3 types of technical solutions we adopted in this competition. On the left is the Standard Prediction": ""
        },
        {
          "Figure 1: The 3 types of technical solutions we adopted in this competition. On the left is the Standard Prediction": "tasks:"
        },
        {
          "Figure 1: The 3 types of technical solutions we adopted in this competition. On the left is the Standard Prediction": ""
        },
        {
          "Figure 1: The 3 types of technical solutions we adopted in this competition. On the left is the Standard Prediction": ""
        },
        {
          "Figure 1: The 3 types of technical solutions we adopted in this competition. On the left is the Standard Prediction": ""
        },
        {
          "Figure 1: The 3 types of technical solutions we adopted in this competition. On the left is the Standard Prediction": ""
        },
        {
          "Figure 1: The 3 types of technical solutions we adopted in this competition. On the left is the Standard Prediction": ""
        },
        {
          "Figure 1: The 3 types of technical solutions we adopted in this competition. On the left is the Standard Prediction": ""
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "the reward model.": ""
        },
        {
          "the reward model.": "Our key contributions are as follows:"
        },
        {
          "the reward model.": ""
        },
        {
          "the reward model.": "• We explored the impact of non-English data"
        },
        {
          "the reward model.": "on English sentiment prediction under\nlim-"
        },
        {
          "the reward model.": "ited computational\nresources.\nSurprisingly,"
        },
        {
          "the reward model.": "experimental results indicate that incorporat-"
        },
        {
          "the reward model.": "ing non-English data degrades performance in"
        },
        {
          "the reward model.": "both classification tasks (Track A) and scoring"
        },
        {
          "the reward model.": "tasks (Track B)."
        },
        {
          "the reward model.": ""
        },
        {
          "the reward model.": "• We conducted a comprehensive evaluation"
        },
        {
          "the reward model.": "and\nbad\ncase\nanalysis\nof\ntwo\ncontrastive"
        },
        {
          "the reward model.": ""
        },
        {
          "the reward model.": "approaches on the competition dataset.\nIn"
        },
        {
          "the reward model.": ""
        },
        {
          "the reward model.": "the sample-based contrastive Learning, CRC"
        },
        {
          "the reward model.": "technology yielded limited benefit.\nIn the"
        },
        {
          "the reward model.": ""
        },
        {
          "the reward model.": "generation-based contrastive Learning, DPO"
        },
        {
          "the reward model.": "demonstrated a significant positive effect on"
        },
        {
          "the reward model.": "Track B. Although SimPO has achieved gains"
        },
        {
          "the reward model.": "on some labels, the overall effect has dropped"
        },
        {
          "the reward model.": "significantly."
        },
        {
          "the reward model.": ""
        },
        {
          "the reward model.": "•\nIn the leaderboard, our approach achieved"
        },
        {
          "the reward model.": "Track A top 10 in 16 languages and 9th in"
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "During inference, we apply the same prompt": "template to incorporate the input text for prediction.",
          "DPO optimizes the language model by maximiz-": "ing the relative probability ratio to favor preferred"
        },
        {
          "During inference, we apply the same prompt": "By parsing the generated output, we extract\nthe",
          "DPO optimizes the language model by maximiz-": "represent\nthe\noutputs (Eq 1). Here, πθ and πref"
        },
        {
          "During inference, we apply the same prompt": "corresponding label predictions.",
          "DPO optimizes the language model by maximiz-": "target and reference models,\nrespectively, while"
        },
        {
          "During inference, we apply the same prompt": "",
          "DPO optimizes the language model by maximiz-": "yw and yl denote the correct and incorrect outputs."
        },
        {
          "During inference, we apply the same prompt": "2.2\nSample-based contrastive learning",
          "DPO optimizes the language model by maximiz-": "β is a scaling hyperparameter. This optimization"
        },
        {
          "During inference, we apply the same prompt": "",
          "DPO optimizes the language model by maximiz-": "process is applied after SFT."
        },
        {
          "During inference, we apply the same prompt": "In this category, we use CRC, a technique designed",
          "DPO optimizes the language model by maximiz-": ""
        },
        {
          "During inference, we apply the same prompt": "to enhance the model’s ability to discern subtle dif-",
          "DPO optimizes the language model by maximiz-": ""
        },
        {
          "During inference, we apply the same prompt": "ferences in samples. By having the model compare",
          "DPO optimizes the language model by maximiz-": ""
        },
        {
          "During inference, we apply the same prompt": "",
          "DPO optimizes the language model by maximiz-": "πθ(yw|x)\nπθ(yl|x)"
        },
        {
          "During inference, we apply the same prompt": "",
          "DPO optimizes the language model by maximiz-": "−logσ(βlog\n− βlog\n)\n(1)"
        },
        {
          "During inference, we apply the same prompt": "the score variations between two samples, model",
          "DPO optimizes the language model by maximiz-": ""
        },
        {
          "During inference, we apply the same prompt": "",
          "DPO optimizes the language model by maximiz-": "πref (yw|x)\nπref (yl|x)"
        },
        {
          "During inference, we apply the same prompt": "can better understand their distinctions and gener-",
          "DPO optimizes the language model by maximiz-": ""
        },
        {
          "During inference, we apply the same prompt": "ate calibrated predictions. The key to this task lies",
          "DPO optimizes the language model by maximiz-": "SimPO adopts a similar optimization objective"
        },
        {
          "During inference, we apply the same prompt": "in sample preparation and inference process.",
          "DPO optimizes the language model by maximiz-": "(Eq 2), directly enhancing the probability of the"
        },
        {
          "During inference, we apply the same prompt": "",
          "DPO optimizes the language model by maximiz-": "target model’s preferred outputs. However, it sim-"
        },
        {
          "During inference, we apply the same prompt": "During sample preparation, we randomly select",
          "DPO optimizes the language model by maximiz-": ""
        },
        {
          "During inference, we apply the same prompt": "",
          "DPO optimizes the language model by maximiz-": "plifies DPO by discarding the reference model and"
        },
        {
          "During inference, we apply the same prompt": "two samples from the training set (Figure 1 mid-",
          "DPO optimizes the language model by maximiz-": ""
        },
        {
          "During inference, we apply the same prompt": "",
          "DPO optimizes the language model by maximiz-": "using sequence length to normalize the loss. Ad-"
        },
        {
          "During inference, we apply the same prompt": "dle) and construct a contrastive pair using the tem-",
          "DPO optimizes the language model by maximiz-": ""
        },
        {
          "During inference, we apply the same prompt": "",
          "DPO optimizes the language model by maximiz-": "ditionally, it adopts a hyperparameter γ to ensure"
        },
        {
          "During inference, we apply the same prompt": "plate in Appendix A.1. The target output comprises",
          "DPO optimizes the language model by maximiz-": ""
        },
        {
          "During inference, we apply the same prompt": "",
          "DPO optimizes the language model by maximiz-": "that the likelihood for the correct response exceeds"
        },
        {
          "During inference, we apply the same prompt": "two components: a contrastive summary and two",
          "DPO optimizes the language model by maximiz-": ""
        },
        {
          "During inference, we apply the same prompt": "",
          "DPO optimizes the language model by maximiz-": "the incorrect response by γ. Like DPO, SimPO is"
        },
        {
          "During inference, we apply the same prompt": "samples’ predictions.\nThe contrastive summary,",
          "DPO optimizes the language model by maximiz-": ""
        },
        {
          "During inference, we apply the same prompt": "",
          "DPO optimizes the language model by maximiz-": "also applied after SFT."
        },
        {
          "During inference, we apply the same prompt": "expressed in natural language, highlights the exis-",
          "DPO optimizes the language model by maximiz-": ""
        },
        {
          "During inference, we apply the same prompt": "tence or intensity difference between two samples",
          "DPO optimizes the language model by maximiz-": ""
        },
        {
          "During inference, we apply the same prompt": "on a specific label. The predictions provide explicit",
          "DPO optimizes the language model by maximiz-": ""
        },
        {
          "During inference, we apply the same prompt": "",
          "DPO optimizes the language model by maximiz-": "β\nβ"
        },
        {
          "During inference, we apply the same prompt": "",
          "DPO optimizes the language model by maximiz-": "−logσ(\nlogπθ(yw|x) −\nlogπθ(yl|x) − γ)"
        },
        {
          "During inference, we apply the same prompt": "scores for both samples on the given label.",
          "DPO optimizes the language model by maximiz-": ""
        },
        {
          "During inference, we apply the same prompt": "",
          "DPO optimizes the language model by maximiz-": "|yw|\n|yl|"
        },
        {
          "During inference, we apply the same prompt": "Given that random pairwise sampling can gen-",
          "DPO optimizes the language model by maximiz-": "(2)"
        },
        {
          "During inference, we apply the same prompt": "erate a vast amount of training data, we impose an",
          "DPO optimizes the language model by maximiz-": "During\nsample\npreparation,\nto\nenhance\nthe"
        },
        {
          "During inference, we apply the same prompt": "upper limit on the total number of sampled pairs",
          "DPO optimizes the language model by maximiz-": "model’s sensitivity to label scoring, we mute only"
        },
        {
          "During inference, we apply the same prompt": "for each track. Specifically, for Track A, we sample",
          "DPO optimizes the language model by maximiz-": ""
        },
        {
          "During inference, we apply the same prompt": "",
          "DPO optimizes the language model by maximiz-": "the label scores to generate yl (Figure 1 right, the"
        },
        {
          "During inference, we apply the same prompt": "3,000 contrastive pairs per label, while for Track",
          "DPO optimizes the language model by maximiz-": ""
        },
        {
          "During inference, we apply the same prompt": "",
          "DPO optimizes the language model by maximiz-": "Label Mutation block). The yw corresponds to the"
        },
        {
          "During inference, we apply the same prompt": "B, we sample 6,000 pairs per label, as Track B in-",
          "DPO optimizes the language model by maximiz-": ""
        },
        {
          "During inference, we apply the same prompt": "",
          "DPO optimizes the language model by maximiz-": "original SP ground truth, while the yl follows the"
        },
        {
          "During inference, we apply the same prompt": "volves more fine-grained scoring labels compared",
          "DPO optimizes the language model by maximiz-": "same SP template but with muted scores. The prob-"
        },
        {
          "During inference, we apply the same prompt": "to Track A.",
          "DPO optimizes the language model by maximiz-": "abilities of muting one,\ntwo,\nthree, four, and five"
        },
        {
          "During inference, we apply the same prompt": "During inference, each test sample is paired with",
          "DPO optimizes the language model by maximiz-": "labels are [63.8%, 26.1%, 8.3%, 1.6%, 0.1%], re-"
        },
        {
          "During inference, we apply the same prompt": "a randomly selected training sample to form a con-",
          "DPO optimizes the language model by maximiz-": "spectively. When mutation is triggered, a random"
        },
        {
          "During inference, we apply the same prompt": "trastive input.\nSince the model achieves highly",
          "DPO optimizes the language model by maximiz-": "value is selected from the remaining label values"
        },
        {
          "During inference, we apply the same prompt": "accurate predictions on training samples,\nthese",
          "DPO optimizes the language model by maximiz-": "as the incorrect score."
        },
        {
          "During inference, we apply the same prompt": "trained samples serve as reliable reference points,",
          "DPO optimizes the language model by maximiz-": "For Track A, each training sample executes five"
        },
        {
          "During inference, we apply the same prompt": "reducing prediction uncertainty. The two samples",
          "DPO optimizes the language model by maximiz-": "mutations, generating five contrastive samples for"
        },
        {
          "During inference, we apply the same prompt": "are integrated into the CRC prompt template, with",
          "DPO optimizes the language model by maximiz-": "generation-based contrastive learning. For Track"
        },
        {
          "During inference, we apply the same prompt": "the test sample randomly assigned to either position",
          "DPO optimizes the language model by maximiz-": "B, mutation is repeated 15 times, creating 15 con-"
        },
        {
          "During inference, we apply the same prompt": "1 or position 2. This process is repeated N times to",
          "DPO optimizes the language model by maximiz-": "trastive samples. These settings ensured that\nthe"
        },
        {
          "During inference, we apply the same prompt": "generate N different input instances, producing N",
          "DPO optimizes the language model by maximiz-": "preference optimization dataset was comparable in"
        },
        {
          "During inference, we apply the same prompt": "predictions. The final score is determined through",
          "DPO optimizes the language model by maximiz-": "size to the CRC dataset, allowing for a fair compar-"
        },
        {
          "During inference, we apply the same prompt": "a voting mechanism, where the most\nfrequently",
          "DPO optimizes the language model by maximiz-": "ison between sample-based and generation-based"
        },
        {
          "During inference, we apply the same prompt": "predicted score is selected as the final output.",
          "DPO optimizes the language model by maximiz-": "approaches."
        },
        {
          "During inference, we apply the same prompt": "2.3\nGeneration-based contrastive learning",
          "DPO optimizes the language model by maximiz-": "3\nExperiment"
        },
        {
          "During inference, we apply the same prompt": "To enhance the model’s sensitivity to scoring, we",
          "DPO optimizes the language model by maximiz-": "In this competition, we participate in Track A and"
        },
        {
          "During inference, we apply the same prompt": "incorporate preference optimization. However, due",
          "DPO optimizes the language model by maximiz-": "Track B. Track A covers 28 languages, while Track"
        },
        {
          "During inference, we apply the same prompt": "to computational constraints, we only explore tech-",
          "DPO optimizes the language model by maximiz-": "B includes 11 languages. Each language contains"
        },
        {
          "During inference, we apply the same prompt": "niques that do not require a reward model, such as",
          "DPO optimizes the language model by maximiz-": "thousands of samples.\nSome languages use the"
        },
        {
          "During inference, we apply the same prompt": "DPO and SimPO.",
          "DPO optimizes the language model by maximiz-": "same dataset for both Track A and Track B. Both"
        }
      ],
      "page": 3
    },
    {
      "caption": "Table 1: corresponds",
      "data": [
        {
          "Training": "",
          "Track A - eng": ""
        },
        {
          "Training": "Language",
          "Track A - eng": "Fear"
        },
        {
          "Training": "English",
          "Track A - eng": "0.876"
        },
        {
          "Training": "Multilingual",
          "Track A - eng": "0.865"
        },
        {
          "Training": "English",
          "Track A - eng": "0.865"
        },
        {
          "Training": "English",
          "Track A - eng": "0.875"
        },
        {
          "Training": "English",
          "Track A - eng": "0.737"
        },
        {
          "Training": "",
          "Track A - eng": ""
        },
        {
          "Training": "Training",
          "Track A - eng": "Track B - eng"
        },
        {
          "Training": "",
          "Track A - eng": ""
        },
        {
          "Training": "Language",
          "Track A - eng": "Fear"
        },
        {
          "Training": "English",
          "Track A - eng": "0.841"
        },
        {
          "Training": "Multilingual",
          "Track A - eng": "0.816"
        },
        {
          "Training": "English",
          "Track A - eng": "0.807"
        },
        {
          "Training": "English",
          "Track A - eng": "0.844"
        },
        {
          "Training": "English",
          "Track A - eng": "0.737"
        },
        {
          "Training": "",
          "Track A - eng": ""
        }
      ],
      "page": 4
    },
    {
      "caption": "Table 1: corresponds",
      "data": [
        {
          "CRC\nEnglish\n0.828\n0.805": "0.846\n0.824\nDPO\nEnglish",
          "0.796\n0.807\n0.836\n0.837\n0.750": "0.844\n0.849\n0.773\n0.810\n0.846"
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "SimPO\nEnglish\n0.770\n0.741",
          "0.796\n0.807\n0.836\n0.837\n0.750": "0.700\n0.737\n0.827\n0.832\n0.607"
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "Table 2: English test set results of all models in Track B",
          "0.796\n0.807\n0.836\n0.837\n0.750": ""
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "tracks share the same sentiment labels: anger, fear,",
          "0.796\n0.807\n0.836\n0.837\n0.750": "To reduce training costs, we use LoRA (Hu et al.,"
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "joy, sadness, surprise, and disgust. However, some",
          "0.796\n0.807\n0.836\n0.837\n0.750": "2022) for all fine-tuning tasks, with its rank and"
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "languages have missing labels (e.g., English does",
          "0.796\n0.807\n0.836\n0.837\n0.750": "alpha set as 8 and 16.\nEach training lasts\nfor"
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "not include the disgust label). All sample contents",
          "0.796\n0.807\n0.836\n0.837\n0.750": "3 epochs with a batch size of 128.\nRegarding"
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "are single-turn dialogue without prior dialogue.",
          "0.796\n0.807\n0.836\n0.837\n0.750": "the learning rate (LR), SP and CRC employ 4e-"
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "Track A is evaluated using the F1 score, while",
          "0.796\n0.807\n0.836\n0.837\n0.750": "4, DPO adopts 5e-6, and SimPO uses 1e-6. All"
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "Track B uses Pearson Correlation, with both met-",
          "0.796\n0.807\n0.836\n0.837\n0.750": "models are trained using the AdamW optimizer,"
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "rics computed in Macro and Micro modes. Macro",
          "0.796\n0.807\n0.836\n0.837\n0.750": "with β1 = 0.8, β2 = 0.99. All LR scheduler em-"
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "calculates the overall score across all labels, while",
          "0.796\n0.807\n0.836\n0.837\n0.750": "ploys cosine decay with a warmup ratio of 0.1. For"
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "Micro first computes per-label scores and then av-",
          "0.796\n0.807\n0.836\n0.837\n0.750": "CRC inference, we set N = 3 for Track A and"
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "erages them. Although training, development, and",
          "0.796\n0.807\n0.836\n0.837\n0.750": "N = 7 for Track B."
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "test sets are provided,\nthe development set\nis too",
          "0.796\n0.807\n0.836\n0.837\n0.750": "All experiments are conducted using 8-GPU dis-"
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "small, leading to unstable evaluation results. There-",
          "0.796\n0.807\n0.836\n0.837\n0.750": "tributed training. Due to limited computational"
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "fore, all reported results are based on the test set.",
          "0.796\n0.807\n0.836\n0.837\n0.750": "resources, different GPUs are used across various"
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "Please see Appendix A.2 for the dev set results and",
          "0.796\n0.807\n0.836\n0.837\n0.750": "training runs. However, all GPUs are based on the"
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "discussion.",
          "0.796\n0.807\n0.836\n0.837\n0.750": "Ada Lovelace or Hopper architecture, allowing us"
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "",
          "0.796\n0.807\n0.836\n0.837\n0.750": "to leverage a wide range of existing acceleration"
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "All models in our experiments are fine-tuned",
          "0.796\n0.807\n0.836\n0.837\n0.750": ""
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "",
          "0.796\n0.807\n0.836\n0.837\n0.750": "techniques to enhance training efficiency."
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "from Llama3-Instruct-8B (Dubey et al., 2024), se-",
          "0.796\n0.807\n0.836\n0.837\n0.750": ""
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "lected for its strong multilingual capabilities and",
          "0.796\n0.807\n0.836\n0.837\n0.750": ""
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "",
          "0.796\n0.807\n0.836\n0.837\n0.750": "4\nResults"
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "acceptable computational cost. To validate its mul-",
          "0.796\n0.807\n0.836\n0.837\n0.750": ""
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "tilingual capabilities in each language, we check",
          "0.796\n0.807\n0.836\n0.837\n0.750": ""
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "",
          "0.796\n0.807\n0.836\n0.837\n0.750": "Tables 1 and 2 present the performance of all mod-"
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "the consistency between original and recovered text",
          "0.796\n0.807\n0.836\n0.837\n0.750": ""
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "",
          "0.796\n0.807\n0.836\n0.837\n0.750": "els on the English test set. Table 1 corresponds"
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "using its tokenizer to encode and decode the text",
          "0.796\n0.807\n0.836\n0.837\n0.750": ""
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "",
          "0.796\n0.807\n0.836\n0.837\n0.750": "to Track A, the multi-emotion classification task,"
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "content. This experiment confirmed that the model",
          "0.796\n0.807\n0.836\n0.837\n0.750": ""
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "",
          "0.796\n0.807\n0.836\n0.837\n0.750": "while Table 2 corresponds to Track B, the emotion"
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "supports all competition languages.",
          "0.796\n0.807\n0.836\n0.837\n0.750": ""
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "",
          "0.796\n0.807\n0.836\n0.837\n0.750": "intensity prediction task."
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "We first evaluate the impact of multilingual data",
          "0.796\n0.807\n0.836\n0.837\n0.750": ""
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "",
          "0.796\n0.807\n0.836\n0.837\n0.750": "4.1\nMultilingual influence"
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "on English-only performance in the standard pre-",
          "0.796\n0.807\n0.836\n0.837\n0.750": ""
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "diction (SP) task. Then, we experiment with CRC,",
          "0.796\n0.807\n0.836\n0.837\n0.750": "We observe that multilingual\ntraining underper-"
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "DPO, and SimPO on the English dataset to examine",
          "0.796\n0.807\n0.836\n0.837\n0.750": "forms compared to English-only training in both"
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "the effectiveness of sample-based and generation-",
          "0.796\n0.807\n0.836\n0.837\n0.750": "Track A and Track B. This finding highlights the"
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "based contrastive learning for TBED. The CRC",
          "0.796\n0.807\n0.836\n0.837\n0.750": "significant differences in emotion perception across"
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "model is trained via SFT on a combination of SP",
          "0.796\n0.807\n0.836\n0.837\n0.750": "languages and cultural contexts, which can intro-"
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "and CRC datasets. DPO and SimPO models are ob-",
          "0.796\n0.807\n0.836\n0.837\n0.750": "duce conflicts in the model’s understanding of senti-"
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "tained by applying preference tuning to the English-",
          "0.796\n0.807\n0.836\n0.837\n0.750": "ment labels. Therefore, we submit the non-English"
        },
        {
          "CRC\nEnglish\n0.828\n0.805": "only SP model.",
          "0.796\n0.807\n0.836\n0.837\n0.750": "results generated by the multilingual SP model to"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "ID": "",
          "Text": "It was growing harder for him to keep balanced with my",
          "Pred": "",
          "True": ""
        },
        {
          "ID": "eng_test_track_a_02136",
          "Text": "legs shifting every few seconds, until finally, I found the",
          "Pred": "0",
          "True": "1"
        },
        {
          "ID": "",
          "Text": "right position and his back a good shove with my knee.",
          "Pred": "",
          "True": ""
        },
        {
          "ID": "eng_test_track_a_01815",
          "Text": "So you let it shatter, breaking at my feet.",
          "Pred": "1",
          "True": "0"
        },
        {
          "ID": "eng_test_track_a_01594",
          "Text": "Dad thought it was just my imagination.",
          "Pred": "0",
          "True": "1"
        },
        {
          "ID": "",
          "Text": "There’s just something about watching an acne-ridden",
          "Pred": "",
          "True": ""
        },
        {
          "ID": "eng_test_track_a_00071",
          "Text": "high school dropout cooking my food that just doesn’t",
          "Pred": "0",
          "True": "1"
        },
        {
          "ID": "",
          "Text": "sit well in my stomach.",
          "Pred": "",
          "True": ""
        }
      ],
      "page": 5
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "There’s just something about watching an acne-ridden": "high school dropout cooking my food that just doesn’t\n0\n1"
        },
        {
          "There’s just something about watching an acne-ridden": ""
        },
        {
          "There’s just something about watching an acne-ridden": ""
        },
        {
          "There’s just something about watching an acne-ridden": "of the reference model in preference tuning. While"
        },
        {
          "There’s just something about watching an acne-ridden": "SimPO effectively increases the probability mar-"
        },
        {
          "There’s just something about watching an acne-ridden": "gin between correct and incorrect outputs, it may"
        },
        {
          "There’s just something about watching an acne-ridden": "also make correct outputs no longer rank as the top"
        },
        {
          "There’s just something about watching an acne-ridden": "generation."
        },
        {
          "There’s just something about watching an acne-ridden": ""
        },
        {
          "There’s just something about watching an acne-ridden": "5\nConclusion"
        },
        {
          "There’s just something about watching an acne-ridden": ""
        },
        {
          "There’s just something about watching an acne-ridden": "The SemEVAL-2025 organizers introduce a highly"
        },
        {
          "There’s just something about watching an acne-ridden": ""
        },
        {
          "There’s just something about watching an acne-ridden": "challenging text-based emotion detection dataset,"
        },
        {
          "There’s just something about watching an acne-ridden": ""
        },
        {
          "There’s just something about watching an acne-ridden": "covering multi-label classification and intensity pre-"
        },
        {
          "There’s just something about watching an acne-ridden": ""
        },
        {
          "There’s just something about watching an acne-ridden": "diction across 28 languages. The dataset reflects"
        },
        {
          "There’s just something about watching an acne-ridden": ""
        },
        {
          "There’s just something about watching an acne-ridden": "the complexity of emotional expression and the"
        },
        {
          "There’s just something about watching an acne-ridden": ""
        },
        {
          "There’s just something about watching an acne-ridden": "diversity introduced by different linguistic and cul-"
        },
        {
          "There’s just something about watching an acne-ridden": ""
        },
        {
          "There’s just something about watching an acne-ridden": "tural backgrounds."
        },
        {
          "There’s just something about watching an acne-ridden": ""
        },
        {
          "There’s just something about watching an acne-ridden": "We explore three types of approaches in this"
        },
        {
          "There’s just something about watching an acne-ridden": ""
        },
        {
          "There’s just something about watching an acne-ridden": "competition.\nThe baseline approach is the stan-"
        },
        {
          "There’s just something about watching an acne-ridden": ""
        },
        {
          "There’s just something about watching an acne-ridden": "dard prediction task. The two enhanced types of"
        },
        {
          "There’s just something about watching an acne-ridden": ""
        },
        {
          "There’s just something about watching an acne-ridden": "approaches were sample-based contrastive learn-"
        },
        {
          "There’s just something about watching an acne-ridden": ""
        },
        {
          "There’s just something about watching an acne-ridden": "ing and generation-based contrastive learning. For"
        },
        {
          "There’s just something about watching an acne-ridden": ""
        },
        {
          "There’s just something about watching an acne-ridden": "the sample-based approach, we try CRC. For the"
        },
        {
          "There’s just something about watching an acne-ridden": "generation-based approach, we explore both DPO"
        },
        {
          "There’s just something about watching an acne-ridden": "and SimPO. They all aim to improve model pre-"
        },
        {
          "There’s just something about watching an acne-ridden": "diction through contrastive training—one by com-"
        },
        {
          "There’s just something about watching an acne-ridden": "paring samples and the other by discriminating"
        },
        {
          "There’s just something about watching an acne-ridden": "between correct and incorrect generations."
        },
        {
          "There’s just something about watching an acne-ridden": "Our experiments reveal that different languages"
        },
        {
          "There’s just something about watching an acne-ridden": "reflect distinct cultural backgrounds, so multilin-"
        },
        {
          "There’s just something about watching an acne-ridden": "gual\ntraining does not\nimprove English emotion"
        },
        {
          "There’s just something about watching an acne-ridden": "detection. Meanwhile, due to the inherent ambi-"
        },
        {
          "There’s just something about watching an acne-ridden": "guity of sentiment expressions, sample-based con-"
        },
        {
          "There’s just something about watching an acne-ridden": "trastive learning raises additional uncertainty, ulti-"
        },
        {
          "There’s just something about watching an acne-ridden": "mately reducing prediction accuracy. On the other"
        },
        {
          "There’s just something about watching an acne-ridden": "hand, generation-based contrastive learning pro-"
        },
        {
          "There’s just something about watching an acne-ridden": "vides consistent improvements in intensity predic-"
        },
        {
          "There’s just something about watching an acne-ridden": "tion,\nthough its effectiveness varies significantly"
        },
        {
          "There’s just something about watching an acne-ridden": "across different\ntechniques.\nNotably,\nreference"
        },
        {
          "There’s just something about watching an acne-ridden": "model constraint is crucial in stabilizing generation-"
        },
        {
          "There’s just something about watching an acne-ridden": "based contrastive optimization process. It prevents"
        },
        {
          "There’s just something about watching an acne-ridden": "excessive deviation from the original model dis-"
        },
        {
          "There’s just something about watching an acne-ridden": "tribution, and preserves key capabilities such as"
        },
        {
          "There’s just something about watching an acne-ridden": "structured output generation."
        }
      ],
      "page": 5
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "Big Data and Cognitive\nniques and contribution."
        },
        {
          "References": "Abdullah Al Maruf, Fahima Khanam, Md Mahmudul",
          "based emotion detection for textual big data: Tech-": ""
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "Computing, 5(3):43."
        },
        {
          "References": "Haque, Zakaria Masud Jiyad, Firoj Mridha, and Ze-",
          "based emotion detection for textual big data: Tech-": ""
        },
        {
          "References": "yar Aung. 2024.\nChallenges and opportunities of",
          "based emotion detection for textual big data: Tech-": "Tian Li, Nicolay Rusnachenko, and Huizhi Liang. 2024."
        },
        {
          "References": "IEEE Ac-\ntext-based emotion detection: A survey.",
          "based emotion detection for textual big data: Tech-": "Chinchunmei at wassa 2024 empathy and personality"
        },
        {
          "References": "cess.",
          "based emotion detection for textual big data: Tech-": "shared task: Boosting llm’s prediction with role-play"
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "augmentation and contrastive reasoning calibration."
        },
        {
          "References": "Tadesse Destaw Belay, Israel Abebe Azime, Abinew Ali",
          "based emotion detection for textual big data: Tech-": "the 14th Workshop on Computa-\nIn Proceedings of"
        },
        {
          "References": "Ayele, Grigori Sidorov, Dietrich Klakow, Philip",
          "based emotion detection for textual big data: Tech-": "tional Approaches to Subjectivity, Sentiment, & So-"
        },
        {
          "References": "Slusallek, Olga Kolesnikova, and Seid Muhie Yimam.",
          "based emotion detection for textual big data: Tech-": "cial Media Analysis, pages 385–392."
        },
        {
          "References": "2025. Evaluating the capabilities of large language",
          "based emotion detection for textual big data: Tech-": ""
        },
        {
          "References": "models for multi-label emotion understanding.\nIn",
          "based emotion detection for textual big data: Tech-": "Yuchen Liu, Jinming Zhao, Jingwen Hu, Ruichen Li,"
        },
        {
          "References": "Proceedings of the 31st International Conference on",
          "based emotion detection for textual big data: Tech-": "and Qin Jin. 2022. Dialogueein: Emotion interaction"
        },
        {
          "References": "Computational Linguistics, pages 3523–3540, Abu",
          "based emotion detection for textual big data: Tech-": "network for dialogue affective analysis.\nIn Proceed-"
        },
        {
          "References": "Dhabi, UAE. Association for Computational Linguis-",
          "based emotion detection for textual big data: Tech-": "ings of the 29th International Conference on Compu-"
        },
        {
          "References": "tics.",
          "based emotion detection for textual big data: Tech-": "tational Linguistics, pages 684–693."
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "Yu Meng, Mengzhou Xia,\nand Danqi Chen. 2025."
        },
        {
          "References": "S\nCassab\nand Mohamad-Bassam\nKurdy.\n2020.",
          "based emotion detection for textual big data: Tech-": ""
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "Simpo:\nSimple\npreference\noptimization with\na"
        },
        {
          "References": "Ontology-based emotion detection in arabic social",
          "based emotion detection for textual big data: Tech-": ""
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "Advances in Neural\nInfor-\nreference-free reward."
        },
        {
          "References": "International Journal of Engineering Re-\nmedia.",
          "based emotion detection for textual big data: Tech-": ""
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "mation Processing Systems, 37:124198–124235."
        },
        {
          "References": "search & Technology (IJERT), 9(08):1991–2013.",
          "based emotion detection for textual big data: Tech-": ""
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "Shamsuddeen Hassan Muhammad, Nedjma Ousid-"
        },
        {
          "References": "Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey,",
          "based emotion detection for textual big data: Tech-": ""
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "houm, Idris Abdulmumin, Jan Philip Wahle, Terry"
        },
        {
          "References": "Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman,",
          "based emotion detection for textual big data: Tech-": ""
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "Ruas, Meriem Beloucif, Christine de Kock, Nirmal"
        },
        {
          "References": "Akhil Mathur, Alan Schelten, Amy Yang, Angela",
          "based emotion detection for textual big data: Tech-": ""
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "Surange, Daniela Teodorescu, Ibrahim Said Ahmad,"
        },
        {
          "References": "Fan, and 1 others. 2024. The llama 3 herd of models.",
          "based emotion detection for textual big data: Tech-": ""
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "David Ifeoluwa Adelani, Alham Fikri Aji, Felermino"
        },
        {
          "References": "arXiv preprint arXiv:2407.21783.",
          "based emotion detection for textual big data: Tech-": ""
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "D. M. A. Ali,\nIlseyar Alimova, Vladimir Araujo,"
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "Nikolay Babakov, Naomi Baes, Ana-Maria Bucur,"
        },
        {
          "References": "Paul Ekman and Wallace V Friesen. 1969. The reper-",
          "based emotion detection for textual big data: Tech-": ""
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "Andiswa Bukula, and 29 others. 2025a.\nBrighter:"
        },
        {
          "References": "toire of nonverbal behavior: Categories, origins, us-",
          "based emotion detection for textual big data: Tech-": ""
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "Bridging the gap in human-annotated textual emo-"
        },
        {
          "References": "age, and coding. semiotica, 1(1):49–98.",
          "based emotion detection for textual big data: Tech-": ""
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "tion recognition datasets for 28 languages. Preprint,"
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "arXiv:2502.11926."
        },
        {
          "References": "Jiwoo Hong, Noah Lee, and James Thorne. 2024. Orpo:",
          "based emotion detection for textual big data: Tech-": ""
        },
        {
          "References": "Monolithic preference optimization without\nrefer-",
          "based emotion detection for textual big data: Tech-": ""
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "Shamsuddeen Hassan Muhammad, Nedjma Ousidhoum,"
        },
        {
          "References": "ence model. arXiv preprint arXiv:2403.07691.",
          "based emotion detection for textual big data: Tech-": ""
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "Idris Abdulmumin, Seid Muhie Yimam, Jan Philip"
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "Wahle, Terry Ruas, Meriem Beloucif, Christine"
        },
        {
          "References": "Dou Hu, Lingwei Wei, and Xiaoyong Huai. 2021. Di-",
          "based emotion detection for textual big data: Tech-": ""
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "De Kock, Tadesse Destaw Belay, Ibrahim Said Ah-"
        },
        {
          "References": "aloguecrn: Contextual reasoning networks for emo-",
          "based emotion detection for textual big data: Tech-": ""
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "mad, Nirmal Surange, Daniela Teodorescu, David Ife-"
        },
        {
          "References": "arXiv preprint\ntion recognition in conversations.",
          "based emotion detection for textual big data: Tech-": ""
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "oluwa Adelani, Alham Fikri Aji, Felermino Ali,"
        },
        {
          "References": "arXiv:2106.01978.",
          "based emotion detection for textual big data: Tech-": ""
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "Vladimir Araujo, Abinew Ali Ayele, Oana Ignat,"
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "Alexander Panchenko, and 2 others. 2025b. SemEval"
        },
        {
          "References": "Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan",
          "based emotion detection for textual big data: Tech-": ""
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "task 11: Bridging the gap in text-based emotion de-"
        },
        {
          "References": "Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang,",
          "based emotion detection for textual big data: Tech-": ""
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "the 19th International\ntection.\nIn Proceedings of"
        },
        {
          "References": "Weizhu Chen, and 1 others. 2022. Lora: Low-rank",
          "based emotion detection for textual big data: Tech-": ""
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "Workshop on Semantic Evaluation (SemEval-2025),"
        },
        {
          "References": "adaptation of large language models.\nICLR, 1(2):3.",
          "based emotion detection for textual big data: Tech-": ""
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "Vienna, Austria. Association for Computational Lin-"
        },
        {
          "References": "Tatsuya Ide and Daisuke Kawahara. 2022. Building a",
          "based emotion detection for textual big data: Tech-": "guistics."
        },
        {
          "References": "dialogue corpus annotated with expressed and expe-",
          "based emotion detection for textual big data: Tech-": ""
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "R Plutchik. 1982.\nA psycho evolutionary theory of"
        },
        {
          "References": "rienced emotions. arXiv preprint arXiv:2205.11867.",
          "based emotion detection for textual big data: Tech-": ""
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "emotions. Social Science Information."
        },
        {
          "References": "Maria Krommyda, Anastasios Rigos, Kostas Bouklas,",
          "based emotion detection for textual big data: Tech-": ""
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "Rafael Rafailov, Archit Sharma, Eric Mitchell, Christo-"
        },
        {
          "References": "and Angelos Amditis. 2021. An experimental anal-",
          "based emotion detection for textual big data: Tech-": ""
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "pher D Manning, Stefano Ermon, and Chelsea Finn."
        },
        {
          "References": "ysis of data annotation methodologies for emotion",
          "based emotion detection for textual big data: Tech-": ""
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "2023.\nDirect preference optimization: Your\nlan-"
        },
        {
          "References": "detection in short\ntext posted on social media.\nIn",
          "based emotion detection for textual big data: Tech-": ""
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "guage model is secretly a reward model. Advances in"
        },
        {
          "References": "Informatics, volume 8, page 19. MDPI.",
          "based emotion detection for textual big data: Tech-": ""
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "Neural Information Processing Systems, 36:53728–"
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "53741."
        },
        {
          "References": "Santoshi Kuamri and C Narendra Babu. 2017. Real time",
          "based emotion detection for textual big data: Tech-": ""
        },
        {
          "References": "analysis of social media data to understand people",
          "based emotion detection for textual big data: Tech-": ""
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "James A Russell and Albert Mehrabian. 1977. Evidence"
        },
        {
          "References": "emotions towards national parties.\nIn 2017 8th inter-",
          "based emotion detection for textual big data: Tech-": "Journal of"
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "for a three-factor\ntheory of emotions."
        },
        {
          "References": "national conference on computing, communication",
          "based emotion detection for textual big data: Tech-": ""
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "research in Personality, 11(3):273–294."
        },
        {
          "References": "and networking technologies (ICCCNT), pages 1–6.",
          "based emotion detection for textual big data: Tech-": ""
        },
        {
          "References": "IEEE.",
          "based emotion detection for textual big data: Tech-": "Shaikh Abdul Salam and Rajkumar Gupta. 2018. Emo-"
        },
        {
          "References": "",
          "based emotion detection for textual big data: Tech-": "tion detection and recognition from text using ma-"
        },
        {
          "References": "Sheetal Kusal, Shruti Patil, Ketan Kotecha, Rajanikanth",
          "based emotion detection for textual big data: Tech-": "chine learning.\nInt. J. Comput. Sci. Eng, 6(6):341–"
        },
        {
          "References": "Aluvalu, and Vijayakumar Varadarajan. 2021. Ai",
          "based emotion detection for textual big data: Tech-": "345."
        }
      ],
      "page": 6
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "A": "A.1",
          "Appendix": "Prompt templates"
        },
        {
          "A": "Table 4, 5, 6, and 7 show the prompt templates used",
          "Appendix": ""
        },
        {
          "A": "",
          "Appendix": "by Standard Prediction and Contrastive Reasoning"
        },
        {
          "A": "",
          "Appendix": "Calibration on Track A and B, respectively. Pref-"
        },
        {
          "A": "",
          "Appendix": "erence Tuning also uses the Standard Prediction"
        },
        {
          "A": "template.",
          "Appendix": ""
        },
        {
          "A": "A.2",
          "Appendix": "Development set discussion"
        },
        {
          "A": "Table 8 and 9 present our system’s performance on",
          "Appendix": ""
        },
        {
          "A": "",
          "Appendix": "the English development set. However, the results"
        },
        {
          "A": "",
          "Appendix": "from this dataset are somewhat misleading due to"
        },
        {
          "A": "the following reasons:",
          "Appendix": ""
        }
      ],
      "page": 7
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "the English development set. However, the results": "from this dataset are somewhat misleading due to"
        },
        {
          "the English development set. However, the results": "the following reasons:"
        },
        {
          "the English development set. However, the results": "•"
        },
        {
          "the English development set. However, the results": ""
        },
        {
          "the English development set. However, the results": ""
        },
        {
          "the English development set. However, the results": ""
        },
        {
          "the English development set. However, the results": "•"
        },
        {
          "the English development set. However, the results": ""
        },
        {
          "the English development set. However, the results": ""
        },
        {
          "the English development set. However, the results": ""
        }
      ],
      "page": 7
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Input": "Task Description:",
          "Output": ""
        },
        {
          "Input": "You are tasked with determining the perceived emotion(s) of a speaker",
          "Output": ""
        },
        {
          "Input": "based on a conversation. Specifically, your goal is to predict the emotions",
          "Output": ""
        },
        {
          "Input": "that most people would associate with the speaker’s last utterance. The",
          "Output": ""
        },
        {
          "Input": "possible emotions are:\njoy, sadness, fear, anger, surprise, and disgust. The",
          "Output": ""
        },
        {
          "Input": "conversation may be in any of the following languages: Afrikaans,",
          "Output": ""
        },
        {
          "Input": "Algerian Arabic, Amharic, Emakhuwa, Hausa, Igbo, Kinyarwanda,",
          "Output": ""
        },
        {
          "Input": "Moroccan Arabic, Mozambican Portuguese, Nigerian-Pidgin, Oromo,",
          "Output": ""
        },
        {
          "Input": "Setswana, Somali, Swahili, Sundanese, Tigrinya, Xitsonga, IsiXhosa,",
          "Output": ""
        },
        {
          "Input": "Yoruba, isiZulu Arabic, Chinese, Hindi, Indonesian, Javanese, Marathi",
          "Output": ""
        },
        {
          "Input": "English, German, Romanian, Russian, Latin American Spanish, Tatar,",
          "Output": ""
        },
        {
          "Input": "Ukrainian, Swedish, Mozambican Portuguese, and Brazilian Portuguese.",
          "Output": ""
        },
        {
          "Input": "Instructions:",
          "Output": "joy: {joy},"
        },
        {
          "Input": "1. The language of the conversation will be explicitly indicated at the",
          "Output": "sadness: {sadness},"
        },
        {
          "Input": "first place.",
          "Output": "fear: {fear},"
        },
        {
          "Input": "2. Each turn in the conversation will be marked with \"Speaker1\" or",
          "Output": "anger: {anger},"
        },
        {
          "Input": "\"Speaker2\" to indicate the speaker.",
          "Output": "surprise: {surprise},"
        },
        {
          "Input": "3. You need to predict the emotions based on the last utterance from",
          "Output": "disgust: {disgust}."
        },
        {
          "Input": "\"Speaker1\" (and any additional context or dialogue history if provided).",
          "Output": ""
        },
        {
          "Input": "4. For each emotion, indicate whether it applies using binary labels: 1",
          "Output": ""
        },
        {
          "Input": "(emotion is present) or 0 (emotion is absent).",
          "Output": ""
        },
        {
          "Input": "Example Output Format:",
          "Output": ""
        },
        {
          "Input": "joy: {{ 1 or 0 }}, sadness: {{ 1 or 0 }}, fear: {{ 1 or 0 }}, anger: {{ 1 or",
          "Output": ""
        },
        {
          "Input": "0 }}, (optional) surprise: {{ 1 or 0 }}, (optional) disgust: {{ 1 or 0 }}.",
          "Output": ""
        },
        {
          "Input": "Language:",
          "Output": ""
        },
        {
          "Input": "{lan}",
          "Output": ""
        },
        {
          "Input": "Content:",
          "Output": ""
        },
        {
          "Input": "Speaker1: {text}",
          "Output": ""
        }
      ],
      "page": 8
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Input": "Task Description:",
          "Output": ""
        },
        {
          "Input": "You are tasked with predicting the intensity for each of the perceived",
          "Output": ""
        },
        {
          "Input": "emotion classes of a speaker based on a conversation. Specifically, your",
          "Output": ""
        },
        {
          "Input": "prediction should represent the emotional intensity most people",
          "Output": ""
        },
        {
          "Input": "associate with the speaker’s last utterance. The possible emotion classes",
          "Output": ""
        },
        {
          "Input": "are:\njoy, sadness, fear, anger, surprise, and disgust. The conversation may",
          "Output": ""
        },
        {
          "Input": "be in any of the following languages: Afrikaans, Algerian Arabic,",
          "Output": ""
        },
        {
          "Input": "Amharic, Emakhuwa, Hausa, Igbo, Kinyarwanda, Moroccan Arabic,",
          "Output": ""
        },
        {
          "Input": "Mozambican Portuguese, Nigerian-Pidgin, Oromo, Setswana, Somali,",
          "Output": ""
        },
        {
          "Input": "Swahili, Sundanese, Tigrinya, Xitsonga, IsiXhosa, Yoruba, isiZulu Arabic,",
          "Output": ""
        },
        {
          "Input": "Chinese, Hindi, Indonesian, Javanese, Marathi English, German,",
          "Output": ""
        },
        {
          "Input": "Romanian, Russian, Latin American Spanish, Tatar, Ukrainian, Swedish,",
          "Output": ""
        },
        {
          "Input": "Mozambican Portuguese, and Brazilian Portuguese.",
          "Output": ""
        },
        {
          "Input": "Instructions:",
          "Output": ""
        },
        {
          "Input": "1. The language of the conversation will be explicitly indicated at the first",
          "Output": "joy: {joy},"
        },
        {
          "Input": "place.",
          "Output": "sadness: {sadness},"
        },
        {
          "Input": "2. Each turn in the conversation will be marked with \"Speaker1\" or",
          "Output": "fear: {fear},"
        },
        {
          "Input": "\"Speaker2\" to indicate the speaker.",
          "Output": "anger: {anger},"
        },
        {
          "Input": "3. You need to predict the emotion intensity based on the last utterance",
          "Output": "surprise: {surprise},"
        },
        {
          "Input": "from \"Speaker1\" (and any additional context or dialogue history if",
          "Output": "disgust: {disgust}."
        },
        {
          "Input": "provided).",
          "Output": ""
        },
        {
          "Input": "4. For each emotion class, the ordinal intensity levels include: 0 for no",
          "Output": ""
        },
        {
          "Input": "emotion, 1 for a low degree of emotion, 2 for a moderate degree of",
          "Output": ""
        },
        {
          "Input": "emotion, and 3 for a high degree of emotion.",
          "Output": ""
        },
        {
          "Input": "Example Output Format:",
          "Output": ""
        },
        {
          "Input": "joy: {{ 0, 1, 2, or 3 }}, sadness: {{ 0, 1, 2, or 3 }}, fear: {{ 0, 1, 2, or 3 }},",
          "Output": ""
        },
        {
          "Input": "anger: {{ 0, 1, 2, or 3 }}, (optional) surprise: {{ 0, 1, 2, or 3 }}, (optional)",
          "Output": ""
        },
        {
          "Input": "disgust: {{ 0, 1, 2, or 3 }}.",
          "Output": ""
        },
        {
          "Input": "Language:",
          "Output": ""
        },
        {
          "Input": "{lan}",
          "Output": ""
        },
        {
          "Input": "Content:",
          "Output": ""
        },
        {
          "Input": "Speaker1: {text}",
          "Output": ""
        }
      ],
      "page": 9
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Input": "Task Description:",
          "Output": ""
        },
        {
          "Input": "Your task is to compare and predict the perceived emotional label",
          "Output": ""
        },
        {
          "Input": "exhibited by the speaker in two separate conversations. The target",
          "Output": ""
        },
        {
          "Input": "emotion for comparison is \"{label}\". The conversation may be in",
          "Output": ""
        },
        {
          "Input": "any of the following languages: Afrikaans, Algerian Arabic,",
          "Output": ""
        },
        {
          "Input": "Amharic, Emakhuwa, Hausa, Igbo, Kinyarwanda, Moroccan",
          "Output": ""
        },
        {
          "Input": "Arabic, Mozambican Portuguese, Nigerian-Pidgin, Oromo,",
          "Output": ""
        },
        {
          "Input": "Setswana, Somali, Swahili, Sundanese, Tigrinya, Xitsonga, IsiXhosa,",
          "Output": ""
        },
        {
          "Input": "Yoruba, isiZulu Arabic, Chinese, Hindi, Indonesian, Javanese,",
          "Output": ""
        },
        {
          "Input": "Marathi English, German, Romanian, Russian, Latin American",
          "Output": ""
        },
        {
          "Input": "Spanish, Tatar, Ukrainian, Swedish, Mozambican Portuguese, and",
          "Output": ""
        },
        {
          "Input": "Brazilian Portuguese.",
          "Output": ""
        },
        {
          "Input": "Instructions:",
          "Output": ""
        },
        {
          "Input": "1. The two conversations will be marked as \"Conversation1\" and",
          "Output": ""
        },
        {
          "Input": "\"Conversation2\". Each turn in the conversation will be marked",
          "Output": ""
        },
        {
          "Input": "as \"Speaker1\" or \"Speaker2\" to indicate the speaker.",
          "Output": ""
        },
        {
          "Input": "2. The language of the conversation will be explicitly stated at the",
          "Output": ""
        },
        {
          "Input": "beginning of each conversation.",
          "Output": ""
        },
        {
          "Input": "3. You only need to predict the emotions of \"Speaker1\" in both",
          "Output": ""
        },
        {
          "Input": "conversations. No predictions are required for \"Speaker2\".",
          "Output": "For emotion label \"{label}\","
        },
        {
          "Input": "4. Your comparison and prediction should be based on the last",
          "Output": "{{Brief summary of the"
        },
        {
          "Input": "utterance of \"Speaker1\" in each conversation, while also",
          "Output": "comparison result}}."
        },
        {
          "Input": "considering any additional background or dialogue history if",
          "Output": "Conversation1: {{1 or 0}},"
        },
        {
          "Input": "provided.",
          "Output": "Conversation2: {{1 or 0}}."
        },
        {
          "Input": "5. First, provide a brief summary of the comparison result",
          "Output": ""
        },
        {
          "Input": "between the two conversations. Then, use binary labels to indicate",
          "Output": ""
        },
        {
          "Input": "whether the specified emotion (\"{label}\") is present in each",
          "Output": ""
        },
        {
          "Input": "conversation: 1 (emotion is present) or 0 (emotion is absent).",
          "Output": ""
        },
        {
          "Input": "Example Output Format:",
          "Output": ""
        },
        {
          "Input": "For emotion label \"{label}\", {{Brief summary of the comparison",
          "Output": ""
        },
        {
          "Input": "result}}. Conversation1: {{1 or 0}}, Conversation2: {{1 or 0}}.",
          "Output": ""
        },
        {
          "Input": "Conversation1:",
          "Output": ""
        },
        {
          "Input": "Language: {lan1}",
          "Output": ""
        },
        {
          "Input": "Speaker1: {text1}",
          "Output": ""
        },
        {
          "Input": "Conversation2:",
          "Output": ""
        },
        {
          "Input": "Language: {lan2}",
          "Output": ""
        },
        {
          "Input": "Speaker1: {text2}",
          "Output": ""
        },
        {
          "Input": "For emotion label \"{label}\", {brief}.",
          "Output": ""
        },
        {
          "Input": "Conversation1: {conv1Value}, Conversation2: {conv2Value}.",
          "Output": ""
        }
      ],
      "page": 10
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Input": "Task Description:",
          "Output": ""
        },
        {
          "Input": "Your task is to compare and predict the intensity of the specific",
          "Output": ""
        },
        {
          "Input": "perceived emotion class in two separate conversations. The target",
          "Output": ""
        },
        {
          "Input": "preceived emotion class for comparison is \"{label}\". The",
          "Output": ""
        },
        {
          "Input": "conversation may be in any of the following languages: Afrikaans,",
          "Output": ""
        },
        {
          "Input": "Algerian Arabic, Amharic, Emakhuwa, Hausa, Igbo, Kinyarwanda,",
          "Output": ""
        },
        {
          "Input": "Moroccan Arabic, Mozambican Portuguese, Nigerian-Pidgin,",
          "Output": ""
        },
        {
          "Input": "Oromo, Setswana, Somali, Swahili, Sundanese, Tigrinya, Xitsonga,",
          "Output": ""
        },
        {
          "Input": "IsiXhosa, Yoruba, isiZulu Arabic, Chinese, Hindi, Indonesian,",
          "Output": ""
        },
        {
          "Input": "Javanese, Marathi English, German, Romanian, Russian, Latin",
          "Output": ""
        },
        {
          "Input": "American Spanish, Tatar, Ukrainian, Swedish, Mozambican",
          "Output": ""
        },
        {
          "Input": "Portuguese, and Brazilian Portuguese.",
          "Output": ""
        },
        {
          "Input": "Instructions:",
          "Output": ""
        },
        {
          "Input": "1. The two conversations will be marked as \"Conversation1\" and",
          "Output": ""
        },
        {
          "Input": "\"Conversation2\". Each turn in the conversation will be marked as",
          "Output": ""
        },
        {
          "Input": "\"Speaker1\" or \"Speaker2\" to indicate the speaker.",
          "Output": ""
        },
        {
          "Input": "2. The language of the conversation will be explicitly stated at the",
          "Output": ""
        },
        {
          "Input": "beginning of each conversation.",
          "Output": ""
        },
        {
          "Input": "3. You only need to predict the emotional intensity of \"Speaker1\"",
          "Output": ""
        },
        {
          "Input": "in both conversations. No predictions are required for \"Speaker2\".",
          "Output": ""
        },
        {
          "Input": "4. Your comparison and prediction should be based on the last",
          "Output": "For emotion label \"{label}\","
        },
        {
          "Input": "utterance of \"Speaker1\" in each conversation, while also",
          "Output": "{{Brief summary of the"
        },
        {
          "Input": "considering any additional background or dialogue history if",
          "Output": "comparison result}}."
        },
        {
          "Input": "provided.",
          "Output": "Conversation1: {{1 or 0}},"
        },
        {
          "Input": "5. First, provide a brief summary of the comparison result between",
          "Output": "Conversation2: {{1 or 0}}."
        },
        {
          "Input": "the two conversations. Then, use one of the four levels to indicate",
          "Output": ""
        },
        {
          "Input": "the target ordinal intensity: 0 for no emotion, 1 for a low degree of",
          "Output": ""
        },
        {
          "Input": "emotion, 2 for a moderate degree of emotion, and 3 for a high",
          "Output": ""
        },
        {
          "Input": "degree of emotion.",
          "Output": ""
        },
        {
          "Input": "Example Output Format:",
          "Output": ""
        },
        {
          "Input": "For emotion label \"{label}\", {{Brief summary of the comparison",
          "Output": ""
        },
        {
          "Input": "result}}. Conversation1: {{ 0, 1, 2, or 3 }}, Conversation2: {{ 0,",
          "Output": ""
        },
        {
          "Input": "1, 2, or 3 }}.",
          "Output": ""
        },
        {
          "Input": "Conversation1:",
          "Output": ""
        },
        {
          "Input": "Language: {lan1}",
          "Output": ""
        },
        {
          "Input": "Speaker1: {text1}",
          "Output": ""
        },
        {
          "Input": "Conversation2:",
          "Output": ""
        },
        {
          "Input": "Language: {lan2}",
          "Output": ""
        },
        {
          "Input": "Speaker1: {text2}",
          "Output": ""
        },
        {
          "Input": "For emotion label \"{label}\", {brief}.",
          "Output": ""
        },
        {
          "Input": "Conversation1: {conv1Value}, Conversation2: {conv2Value}.",
          "Output": ""
        }
      ],
      "page": 11
    },
    {
      "caption": "Table 10: SP multilingual model results on all tracks",
      "data": [
        {
          "Training": "",
          "Track A - eng Dev Set": ""
        },
        {
          "Training": "Language",
          "Track A - eng Dev Set": "Fear"
        },
        {
          "Training": "English",
          "Track A - eng Dev Set": "0.871"
        },
        {
          "Training": "Multilingual",
          "Track A - eng Dev Set": "0.862"
        },
        {
          "Training": "English",
          "Track A - eng Dev Set": "0.884"
        },
        {
          "Training": "English",
          "Track A - eng Dev Set": "0.864"
        },
        {
          "Training": "English",
          "Track A - eng Dev Set": "0.810"
        }
      ],
      "page": 12
    },
    {
      "caption": "Table 10: SP multilingual model results on all tracks",
      "data": [
        {
          "Table 8: Development set english results of all models in Track A": ""
        },
        {
          "Table 8: Development set english results of all models in Track A": ""
        },
        {
          "Table 8: Development set english results of all models in Track A": "Macro"
        },
        {
          "Table 8: Development set english results of all models in Track A": "0.834"
        },
        {
          "Table 8: Development set english results of all models in Track A": "0.818"
        },
        {
          "Table 8: Development set english results of all models in Track A": "0.793"
        },
        {
          "Table 8: Development set english results of all models in Track A": "0.840"
        },
        {
          "Table 8: Development set english results of all models in Track A": "0.756"
        }
      ],
      "page": 12
    },
    {
      "caption": "Table 10: SP multilingual model results on all tracks",
      "data": [
        {
          "SimPO": "",
          "English": "",
          "0.756": "",
          "0.731": ""
        },
        {
          "SimPO": "",
          "English": "",
          "0.756": "Track B",
          "0.731": ""
        },
        {
          "SimPO": "Language",
          "English": "",
          "0.756": "",
          "0.731": ""
        },
        {
          "SimPO": "",
          "English": "Macro",
          "0.756": "Macro",
          "0.731": "Micro"
        },
        {
          "SimPO": "eng",
          "English": "0.820",
          "0.756": "0.835",
          "0.731": "0.815"
        },
        {
          "SimPO": "ptbr",
          "English": "0.722",
          "0.756": "0.758",
          "0.731": "0.638"
        },
        {
          "SimPO": "ary",
          "English": "0.591",
          "0.756": "-",
          "0.731": "-"
        },
        {
          "SimPO": "afr",
          "English": "0.669",
          "0.756": "-",
          "0.731": "-"
        },
        {
          "SimPO": "ptmz",
          "English": "0.581",
          "0.756": "-",
          "0.731": "-"
        },
        {
          "SimPO": "kin",
          "English": "0.520",
          "0.756": "-",
          "0.731": "-"
        },
        {
          "SimPO": "pcm",
          "English": "0.693",
          "0.756": "-",
          "0.731": "-"
        },
        {
          "SimPO": "amh",
          "English": "0.778",
          "0.756": "0.764",
          "0.731": "0.726"
        },
        {
          "SimPO": "tat",
          "English": "0.767",
          "0.756": "-",
          "0.731": "-"
        },
        {
          "SimPO": "chn",
          "English": "0.756",
          "0.756": "0.781",
          "0.731": "0.661"
        },
        {
          "SimPO": "ukr",
          "English": "0.690",
          "0.756": "0.671",
          "0.731": "0.633"
        },
        {
          "SimPO": "vmw",
          "English": "0.234",
          "0.756": "-",
          "0.731": "-"
        },
        {
          "SimPO": "yor",
          "English": "0.511",
          "0.756": "-",
          "0.731": "-"
        },
        {
          "SimPO": "orm",
          "English": "0.626",
          "0.756": "-",
          "0.731": "-"
        },
        {
          "SimPO": "rus",
          "English": "0.887",
          "0.756": "0.902",
          "0.731": "0.900"
        },
        {
          "SimPO": "sun",
          "English": "0.708",
          "0.756": "-",
          "0.731": "-"
        },
        {
          "SimPO": "arq",
          "English": "0.594",
          "0.756": "0.525",
          "0.731": "0.481"
        },
        {
          "SimPO": "deu",
          "English": "0.755",
          "0.756": "0.761",
          "0.731": "0.721"
        },
        {
          "SimPO": "esp",
          "English": "0.819",
          "0.756": "0.769",
          "0.731": "0.773"
        },
        {
          "SimPO": "mar",
          "English": "0.862",
          "0.756": "-",
          "0.731": "-"
        },
        {
          "SimPO": "hau",
          "English": "0.680",
          "0.756": "0.719",
          "0.731": "0.692"
        },
        {
          "SimPO": "swa",
          "English": "0.368",
          "0.756": "-",
          "0.731": "-"
        },
        {
          "SimPO": "swe",
          "English": "0.762",
          "0.756": "-",
          "0.731": "-"
        },
        {
          "SimPO": "som",
          "English": "0.469",
          "0.756": "-",
          "0.731": "-"
        },
        {
          "SimPO": "tir",
          "English": "0.565",
          "0.756": "-",
          "0.731": "-"
        },
        {
          "SimPO": "ron",
          "English": "0.770",
          "0.756": "0.778",
          "0.731": "0.682"
        },
        {
          "SimPO": "ibo",
          "English": "0.634",
          "0.756": "-",
          "0.731": "-"
        },
        {
          "SimPO": "hin",
          "English": "0.896",
          "0.756": "-",
          "0.731": "-"
        }
      ],
      "page": 12
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Challenges and opportunities of text-based emotion detection: A survey",
      "authors": [
        "Abdullah Al Maruf",
        "Fahima Khanam",
        "Md Mahmudul Haque",
        "Zakaria Masud Jiyad",
        "Firoj Mridha",
        "Zeyar Aung"
      ],
      "year": "2024",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "2",
      "title": "Evaluating the capabilities of large language models for multi-label emotion understanding",
      "authors": [
        "Destaw Tadesse",
        "Israel Belay",
        "Abinew Abebe Azime",
        "Grigori Ali Ayele",
        "Dietrich Sidorov",
        "Philip Klakow",
        "Olga Slusallek",
        "Seid Kolesnikova",
        "Yimam Muhie"
      ],
      "year": "2025",
      "venue": "Proceedings of the 31st International Conference on Computational Linguistics"
    },
    {
      "citation_id": "3",
      "title": "Ontology-based emotion detection in arabic social media",
      "authors": [
        "S Cassab",
        "Mohamad-Bassam Kurdy"
      ],
      "year": "2020",
      "venue": "International Journal of Engineering Research & Technology (IJERT)"
    },
    {
      "citation_id": "4",
      "title": "Angela Fan, and 1 others. 2024. The llama 3 herd of models",
      "authors": [
        "Abhimanyu Dubey",
        "Abhinav Jauhri",
        "Abhinav Pandey",
        "Abhishek Kadian",
        "Ahmad Al-Dahle",
        "Aiesha Letman",
        "Akhil Mathur",
        "Alan Schelten",
        "Amy Yang"
      ],
      "venue": "Angela Fan, and 1 others. 2024. The llama 3 herd of models",
      "arxiv": "arXiv:2407.21783"
    },
    {
      "citation_id": "5",
      "title": "The repertoire of nonverbal behavior: Categories, origins, usage, and coding",
      "authors": [
        "Paul Ekman",
        "Wallace Friesen"
      ],
      "year": "1969",
      "venue": "semiotica"
    },
    {
      "citation_id": "6",
      "title": "Orpo: Monolithic preference optimization without reference model",
      "authors": [
        "Jiwoo Hong",
        "Noah Lee",
        "James Thorne"
      ],
      "year": "2024",
      "venue": "Orpo: Monolithic preference optimization without reference model",
      "arxiv": "arXiv:2403.07691"
    },
    {
      "citation_id": "7",
      "title": "Dialoguecrn: Contextual reasoning networks for emotion recognition in conversations",
      "authors": [
        "Dou Hu",
        "Lingwei Wei",
        "Xiaoyong Huai"
      ],
      "year": "2021",
      "venue": "Dialoguecrn: Contextual reasoning networks for emotion recognition in conversations",
      "arxiv": "arXiv:2106.01978"
    },
    {
      "citation_id": "8",
      "title": "Weizhu Chen, and 1 others. 2022. Lora: Low-rank adaptation of large language models",
      "authors": [
        "J Edward",
        "Yelong Hu",
        "Phillip Shen",
        "Zeyuan Wallis",
        "Yuanzhi Allen-Zhu",
        "Shean Li",
        "Lu Wang",
        "Wang"
      ],
      "venue": "ICLR"
    },
    {
      "citation_id": "9",
      "title": "Building a dialogue corpus annotated with expressed and experienced emotions",
      "authors": [
        "Tatsuya Ide",
        "Daisuke Kawahara"
      ],
      "year": "2022",
      "venue": "Building a dialogue corpus annotated with expressed and experienced emotions",
      "arxiv": "arXiv:2205.11867"
    },
    {
      "citation_id": "10",
      "title": "An experimental analysis of data annotation methodologies for emotion detection in short text posted on social media",
      "authors": [
        "Maria Krommyda",
        "Anastasios Rigos",
        "Kostas Bouklas",
        "Angelos Amditis"
      ],
      "year": "2021",
      "venue": "Informatics"
    },
    {
      "citation_id": "11",
      "title": "Real time analysis of social media data to understand people emotions towards national parties",
      "authors": [
        "Santoshi Kuamri",
        "C Narendra"
      ],
      "year": "2017",
      "venue": "2017 8th international conference on computing, communication and networking technologies (ICCCNT)"
    },
    {
      "citation_id": "12",
      "title": "Rajanikanth Aluvalu, and Vijayakumar Varadarajan. 2021. Ai based emotion detection for textual big data: Techniques and contribution",
      "authors": [
        "Sheetal Kusal",
        "Shruti Patil",
        "Ketan Kotecha"
      ],
      "venue": "Big Data and Cognitive Computing"
    },
    {
      "citation_id": "13",
      "title": "Chinchunmei at wassa 2024 empathy and personality shared task: Boosting llm's prediction with role-play augmentation and contrastive reasoning calibration",
      "authors": [
        "Tian Li",
        "Nicolay Rusnachenko",
        "Huizhi Liang"
      ],
      "year": "2024",
      "venue": "Proceedings of the 14th Workshop on Computational Approaches to Subjectivity, Sentiment, & Social Media Analysis"
    },
    {
      "citation_id": "14",
      "title": "Dialogueein: Emotion interaction network for dialogue affective analysis",
      "authors": [
        "Yuchen Liu",
        "Jinming Zhao",
        "Jingwen Hu",
        "Ruichen Li",
        "Qin Jin"
      ],
      "year": "2022",
      "venue": "Proceedings of the 29th International Conference on Computational Linguistics"
    },
    {
      "citation_id": "15",
      "title": "Simpo: Simple preference optimization with a reference-free reward",
      "authors": [
        "Yu Meng",
        "Mengzhou Xia",
        "Danqi Chen"
      ],
      "year": "2025",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "16",
      "title": "Andiswa Bukula, and 29 others. 2025a. Brighter: Bridging the gap in human-annotated textual emotion recognition datasets for 28 languages",
      "authors": [
        "Shamsuddeen Hassan",
        "Nedjma Ousidhoum",
        "Idris Abdulmumin",
        "Jan Philip Wahle",
        "Terry Ruas",
        "Meriem Beloucif",
        "Christine De Kock",
        "Nirmal Surange",
        "Daniela Teodorescu",
        "Ibrahim Ahmad",
        "David Ifeoluwa Adelani",
        "Alham Fikri Aji",
        "D Felermino",
        "Ilseyar Ali",
        "Vladimir Alimova",
        "Nikolay Araujo",
        "Naomi Babakov",
        "Ana-Maria Baes",
        "Bucur"
      ],
      "venue": "Andiswa Bukula, and 29 others. 2025a. Brighter: Bridging the gap in human-annotated textual emotion recognition datasets for 28 languages",
      "arxiv": "arXiv:2502.11926"
    },
    {
      "citation_id": "17",
      "title": "Abinew Ali Ayele, Oana Ignat, Alexander Panchenko, and 2 others. 2025b. SemEval task 11: Bridging the gap in text-based emotion detection",
      "authors": [
        "Shamsuddeen Hassan",
        "Nedjma Ousidhoum",
        "Idris Abdulmumin",
        "Muhie Seid",
        "Jan Yimam",
        "Terry Philip Wahle",
        "Meriem Ruas",
        "Christine Beloucif",
        "Daniela De Kock ; Nirmal Surange",
        "David Teodorescu",
        "Alham Ifeoluwa Adelani",
        "Felermino Fikri Aji",
        "Vladimir Ali",
        "Araujo"
      ],
      "venue": "Proceedings of the 19th International Workshop on Semantic Evaluation (SemEval-2025)"
    },
    {
      "citation_id": "18",
      "title": "A psycho evolutionary theory of emotions",
      "authors": [
        "Plutchik"
      ],
      "year": "1982",
      "venue": "Social Science Information"
    },
    {
      "citation_id": "19",
      "title": "Direct preference optimization: Your language model is secretly a reward model",
      "authors": [
        "Rafael Rafailov",
        "Archit Sharma",
        "Eric Mitchell",
        "Christopher Manning",
        "Stefano Ermon",
        "Chelsea Finn"
      ],
      "year": "2023",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "20",
      "title": "Evidence for a three-factor theory of emotions",
      "authors": [
        "A James",
        "Albert Russell",
        "Mehrabian"
      ],
      "year": "1977",
      "venue": "Journal of research in Personality"
    },
    {
      "citation_id": "21",
      "title": "Emotion detection and recognition from text using machine learning",
      "authors": [
        "Abdul Shaikh",
        "Rajkumar Salam",
        "Gupta"
      ],
      "year": "2018",
      "venue": "Int. J. Comput. Sci. Eng"
    }
  ]
}