{
  "paper_id": "2206.05017v2",
  "title": "Empathetic Conversational Systems: A Review Of Current Advances, Gaps, And Opportunities",
  "published": "2022-05-09T05:19:48Z",
  "authors": [
    "Aravind Sesagiri Raamkumar",
    "Yinping Yang"
  ],
  "keywords": [
    "Affective computing",
    "empathetic conversational systems",
    "empathetic chatbots",
    "empathetic dialogue systems",
    "empathy",
    "empathetic artificial intelligence"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Empathy is a vital factor that contributes to mutual understanding, and joint problem-solving. In recent years, a growing number of studies have recognized the benefits of empathy and started to incorporate empathy in conversational systems. We refer to this topic as empathetic conversational systems. To identify the critical gaps and future opportunities in this topic, this paper examines this rapidly growing field using five review dimensions: (i) conceptual empathy models and frameworks, (ii) adopted empathy-related concepts, (iii) datasets and algorithmic techniques developed, (iv) evaluation strategies, and (v) state-of-the-art approaches. The findings show that most studies have centered on the use of the EMPATHETICDIALOGUES dataset, and the text-based modality dominates research in this field. Studies mainly focused on extracting features from the messages of the users and the conversational systems, with minimal emphasis on user modeling and profiling. Notably, studies that have incorporated emotion causes, external knowledge, and affect matching in the response generation models, have obtained significantly better results. For implementation in diverse real-world settings, we recommend that future studies should address key gaps in areas of detecting and authenticating emotions at the entity level, handling multimodal inputs, displaying more nuanced empathetic behaviors, and encompassing additional dialogue system features.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "onversational artificial intelligence (CAI) has become a lucrative area for research and commercial applications in the form of personalized digital assistants, virtual assistants, cobots, and chatbots  [1] . They have proliferated several application domains ranging from daily life, commerce, business support, education, to healthcare  [2] ,  [3] . CAI research spans multiple topics encompassing conversational chatbot and dialogue systems  [4] ,  [5] , conversational recommender systems  [6] , conversational search systems  [7] , and conversational question and answering systems  [8] .\n\nAlthough each of these topics has specific foci, a fullscale CAI implementation would benefit from an effective integration of research ideas and outputs from these topics as the user's requirements in the real-world transition between multiple states. For example, when a user interacts with a CAI-based customer service agent, the user expresses the request to the agent in natural language (applicable to conversational search), followed by further questions and clarifications from the agent (applicable to chitchat dialogue systems) so that the agent fully understands the request. After completing the inquiries, the agent has all the details to convert the user's request to a query representation which is used to retrieve the relevant data from the databases. Subsequently, the agent might provide either a factual response (applicable to conversational question and answering ) or provide recommendations (applicable to conversational recommender systems) based on the request criteria. Hence, we opine that a complete CAI implementation should have capabilities from all the related research topics to simulate an effective real-world experience. As humans are a vital part of the loop in CAI studies, behavioral research on human-chatbot interactions  [3] ,  [9]  and information-seeking strategies  [10]  have likewise been conducted.\n\nA key objective in CAI research is to humanize systems to facilitate better and more meaningful engagement with humans  [11] . Researchers have since developed emotionally-aware systems to detect sentiments and emotions from human expressions and generate emotional responses  [12] . The implementations rely on sentiment analysis  [13]  and emotion recognition  [14]  algorithms to identify user messages' prevailing sentiments and emotions. Although identifying sentiments and emotions is a constructive step towards building an effective conversation, engaging humans with empathetic responses has proven more successful in CAI studies from domains such as health  [15]  and marketing  [16] . These studies highlight the positive experience of participants when they perceived affective empathy from the agents. The empathetic conversational feature was found to contribute to bridging the human-AI gap.\n\nBased on an analysis of about 43 definitions, Cuff et al.  [17]  summarized empathy as \"an emotional response (affective), dependent upon the interaction between trait capacities and state influences. Empathic processes are automatically elicited but are also shaped by top-down control processes. The resulting emotion is similar to one's perception (directly experienced or imagined) and understanding (cognitive empathy) of the stimulus emotion, with the recognition that the source of the emotion is not one's own\". Empathy is considered a necessary behavior, and studies have been conducted to improve empathy amongst humans in different settings  [18] ,  [19] . There are also different types of empathy, namely affective empathy, cognitive empathy, and compassionate empathy  [20] . While affective empathy and cognitive empathy are about mirroring and understanding others' feelings, respectively, compassionate empathy is about providing socially desirable responses to others' feelings.\n\nComputational modeling of empathy aids in better understanding human relations  [21] . Computational and theoretical empathy modeling studies have been conducted with variations in three main components -emotional communication competence, emotion regulation, and cognitive mechanisms  [22] . Empathetic behaviors differ based on the mechanisms related to these three components. The cataloged behaviors are mirroring, affective matching, empathic concern, consolation, altruistic helping, and perspective-taking  [22] . An ideal empathetic CAI system is expected to exhibit these behaviors depending on the conversation scenario.\n\nThe recent advancements in deep learning and natural language processing (NLP) have accelerated the research in CAI with new trends in multimodal, multitask, and long-term goal handling systems  [23] . Correspondingly, there has been increased interest in empathetic response generation approaches since the introduction of the EM-PATHETICDIALOGUES dataset, and corresponding response generation models  [24] . CAI systems can be trained to show empathy towards human feelings in text-based conversations. Subsequently, empathetic response generating CAI systems research expanded with new datasets  [25] -  [28]  and enhanced response generation models  [29] ,  [30] . CAI dialog systems can be classified into three types -(i) task-oriented, (ii) conversational, and (iii) interactive questions and answering  [31] . Based on the existing empathetic response generating systems studies covered in this review, the research topic can be characterized as conversational systems since the dialogue structure is unstructured, the number of turns is multiple, the length of the dialogues is long, and also because there is no specific task being completed by the CAI systems.\n\nIn this paper, we focus on the notion of empathetic conversational systems (ECS) as a class of CAI systems which seek to incorporate empathy. This helps to differentiate ECS from the term embodied conversational agents, or ECA  [32] .",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Need For This Review",
      "text": "Previous ECS studies have shown much promise in conceptualizing frameworks, preparing datasets, training models, and designing algorithms for embedding empathy in CAI systems. In one of the earliest surveys in this field by  Paiva et al. published  in 2017  [33] , computational empathy simulation and triggering mechanisms in virtual agents and robots were surveyed. During this survey's publication period, systems primarily employed rulebased and heuristics-based approaches instead of the current deep learning-based natural language generation (NLG) approaches. In Spring et al.  [34] , ECS studies are reviewed using a framework that comprises four stages, namely emotion expression, emotion detection classification, response generation, and response expression. ECS studies are surveyed from the perspective of functions by Ma et al.  [35] , and three types of dialogue systems are surveyed in the purview of empathetic dialogue systems. These dialogue system types are affective dialogue systems, personalized dialogue systems, and knowledgebased dialogue systems. In Wardhana et al.  [36] , the empathetic dialogue characteristics, dialogue system models, and statistical inference techniques have been reviewed.\n\nDespite these valuable reviews, there has been a distinct lack of systematic insights which have investigated empathy incorporation in ECS models in an in-depth manner. In particular, the existing reviews have not included examination about the conceptual empathy models and empathy-related concepts that have been operationalized in empirical ECS studies. Moreover, the prominent datasets used in the studies have also not been covered. Empathy is a multidimensional concept, and multiple peripheral sub-concepts are at play in human-agent interaction. A critical review of ECS studies is warranted from this frame of reference.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Objectives Of The Review",
      "text": "Our objective is to critically review existing ECS studies, and the conceptual frameworks used to understand how different studies have attempted to invoke empathy in systems. This will help delineate the advancements in this research topic so that the gaps and opportunity areas can be identified. Specifically, we examine the following questions.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "1)",
      "text": "What conceptual empathetic models are used to guide the design and development of the existing ECS implementations? What are the different empathy and empathy-related concepts operationalized by the current ECS studies?\n\n2) Which datasets are developed and used in ECS studies, and how are these datasets generated?\n\n3) What and how algorithmic models are used in ECS studies for request processing and response generation activities?\n\n4) What are the evaluation approaches and metrics used in ECS studies? 5) What are the most notable SOTA approaches in existing ECS?\n\nThis paper focuses on studies in which the systems have been trained to exhibit empathy explicitly. The studies which focus on providing emotional responses to users' messages (e.g.,  [37] ) have been reviewed in earlier reviews  [12] ,  [34] , and are not covered in this review.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Method",
      "text": "",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Article Selection",
      "text": "Multiple digital literature searches were conducted across Scopus, Google Scholar, and IEEE Xplore digital library.\n\nThe main search strategy was the discovery of papers relevant to the topic using the following query phrases without any publication year filter applied: \"empathetic conversational\", \"empathetic chatbot\", \"empathetic dialogue\", \"empathetic dialog\", \"empathic conversational\", \"empathic chatbot\", \"empathic dialogue\", \"empathic dialog\", \"empathy conversation\", \"empathy chatbot\", \"empathy dialogue\", \"empathy dialog\", \"emotion conversation\", \"emotion chatbot\", \"emotion dialogue\", \"emotion dialog\", \"empath* AI\", \"empath* agents\", \"empath* artificial intelligence\". Citations and references trail were performed on the initially identified papers using the papers' citations and references as a starting point and a total of 112 papers were identified. These papers were next assessed for relevance through analysis of article title and abstract fields. As a result, 66 papers were not considered relevant to the review. The full text of the remaining papers was scanned.\n\nIn total, we first considered 46 papers for our in-depth review. It is useful to note that we subsequently found few papers that were published as a part of the Alexa SocialBot challenge  [38] . Although these papers  [39] ,  [40]  have proposed models that were trained on ECS datasets such as the EMPATHETICDIALOGUES dataset  [24]  along with other datasets, the algorithms were not specifically conceptualized for empathetic response generation. Hence, these two papers were removed. Figure  1  depicts the article selection process flow.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Data Abstraction",
      "text": "The final list of selected papers was then subjected to a data abstraction exercise. The features used in the data abstraction include dataset name, dataset source algorithms (for emotion/sentiment recognition and empathetic response generation), study objectives, related empathy concept(s), evaluation flag, offline evaluation metrics, user evaluation metrics, ablation study flag apart from the primary paper metadata fields such as publication venue, article type and publication year. The list of ECS empirical studies along with the extracted features has been included in Appendix A.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Conceptual Empathy Models",
      "text": "Empathy, the capacity to relate to others, has been credited as a vital factor in improved relationships and outcomes based on research in several disciplines, including industry and organizational psychology, leadership development, social psychology, negotiations, neuroscience, and mental health  [41] -  [43] . It is a complex, multidimensional, and high-order social intelligence skill. According to Goleman  [44] ,  [45] , empathy involves at least three facets: cognitive empathy, affective empathy, and empathic concern.\n\nCognitive empathy is the ability to understand another person's point of view or perspective. Cognitive empathy is closely related and used interchangeably with perspective-taking. It is about \"putting oneself in others' shoes\".\n\nAffective empathy, or emotional empathy, is the ability to feel what someone else feels. Affective or emotional empathy is about \"your pain in my heart\". In complex situations, feeling fast without thinking deeply is an essential skill that is linked to human evolution.\n\nCompassionate empathy, or empathic concern, is the ability to sense what another person needs from you and do something helpful. This facet of empathy goes beyond perspective-taking and sharing others' feelings but demonstrates helpful behaviors that incorporate the information about others for more effective problem-solving.\n\nComputational approaches to incorporating empathy have presented a variety of empathy conceptualizations. De Waal's three-layer Russian-doll empathy model  [46]  forms the basis for the subsequent computational empathy models and frameworks. According to this model, empathy is perceived as a shared emotional experience between two persons when one person happens to feel a similar emotion as the other person. One person's representations of the emotional state are spontaneously activated when this person pays attention to the emotional state of the other person. At the lowest layer of this model, the model places an affective matching component exhibited by mimicry. The middle layer is for consolation, which is exhibited by sympathetic concern. The upper layer is represented by targeted helping, which is exhibited by perspective-taking.\n\nYalcin et al.  [32]  put forth a framework for equipping ECS with real-time multimodal empathic interaction capabilities based on their model of empathy. The model comprises a three-level hierarchy encompassing communication competence, affect regulation, and cognitive mechanism  [47] . The empathy framework  [32]  includes perceptual, behavior controller, and behavior manager modules. The perceptual module collects the user's input through both audio-video signals. It then sends these signals to the emotion recognition sub-module for ascertaining the emotions in the user input. The processed data is subsequently passed to the behavior controller, where the user intent is thoroughly analyzed. The empathy mechanism sub-module in the module also functions at three levels similar to the empathy model  [47]  -low level, mid-level and highlevel empathetic behavior. At the lowest level, mimicry and affect matching is exhibited while emotion regulation is enabled at the mid-level by considering user mood, personality, and likes/dislikes preferences. Cognitive processes are at the highest level of empathy where the user goals and context are considered. The empathetic response is embedded with the factual response, and it is sent back to the users through the behavior manager module in the framework.\n\nAb Aziz et al.  [48]  proposed another conceptual design model for incorporating empathy in CAI agents. The model comprises five main modules, namely i) sensing, ii) emotion analysis, personality, and event evaluation, iii) empathy analytics and behavior selection, iv) stress analytics and support, and v) feedback. The sensing module receives the user input through voice, visuals, and touchpoints facilitated by a touch screen interface. The input is passed over to the emotion analysis module for face recognition, feature extraction, and emotion recognition. The input is also processed by the personality and event evaluation on a parallel front. The output of these modules is sent to the empathy analytics module. This module is based on another proposed integrated empathy model, which combines the Belief Desire Intention (BDI) model  [49] , three types of empathy (i.e., emotional, cognitive, and compassionate), and the theory of mind  [50] . The next module is the behavior section module which comprises a database of corresponding behaviors and actions. The behaviors and actions are augmented with cues from the stress analytic and support module. The final output is relayed to the users through the feedback module in voice and screen output.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Empathetic Conversational Systems (Ecs)",
      "text": "The majority of the existing empirical ECS studies involve supervised deep learning techniques; hence the training dataset and the architecture are the essential aspects. The studies are summarized in this section based on the following characteristics: empathy-related concepts, algorithms/techniques in the architecture, datasets, and evaluation strategies. We have not considered studies that employ commercial off-the-shelf tools for developing CAI systems, as their underlying techniques are not in the public domain.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Empathy Related Concepts Representation",
      "text": "At a fundamental level, understanding human emotions and subsequently providing empathetic responses are the main functions of an ECS. Studies can be synthesized using these two functions. The functions need to be more detailed to facilitate a better representation of the different empathy components in ECS studies. Yalcin et al.  [21]  proposed three empathy components as part of an empathy model: communication competence, emotion regulation, and cognitive mechanisms to study empathic behavior. Spring et al.  [34] , on the other hand, proposed a four-stage model to study empathic chatbots. The stages are emotion expression, emotion detection, response generation, and response expression.\n\nWhile the Yalcin et al.  [21]  model is suitable for studying empathic behavior, the Spring et al.  [34]  model could be considered a pragmatic model for categorizing ECS studies during that earlier period when research in ECS was still at a nascent stage. We are using a component-based model for categorizing the existing ECS studies for this review paper. The components are the two actors (user, ECS) and their messages (including requests and responses). These components cover all the empathy-related concepts represented in the existing ECS studies. We have added one peripheral component, namely Knowledge Bases, in this model since it has been utilized in a few studies. In Figure  2 , we have illustrated the concepts from the studies and mapped them to the actors or the components of the message based on their relation.",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "User And User Messages",
      "text": "User-based activities such as user modeling and userbased filtering have not been employed in ECS studies thus far. Hence, very few concepts pertain to the user actor in Fig.  2 . The majority of the concepts are on the user messages component (n = 32). The list of concepts is included in Table  1 .\n\n(a) Emotion: Detecting emotion class in user messages has been a de-facto step towards empathetic response generation, mainly because of the usage of the EMPATHET-ICDIALOGUES dataset  [24] . Emotion class is detected in 23 studies. As per the seminal study  [24] , emotion class identification facilitates the selection of appropriate empathetic responses. These ECS studies considered a total of 32 emotion classes. Therefore, most emotional situations were covered. However, no ECS study has attempted to validate the sufficiency or redundancy of the 32 emotion classes. In addition, none of the ECS studies have leveraged algorithms or models that venture beyond emotion classification, such as affect or emotion intensity quantification  [51] .\n\n(b) Sentiment: Understanding emotions in user messages provides more insights than sentiments since sentiments, focusing on positive, negative, and neutral classification, are not as descriptive and actionable as emotions  [52] . However, a few studies have identified sentiments in user messages to respond empathetically  [53] -  [55] . With the current advancements in emotion classification research studies and the availability of pre-trained emotion classification models  [56] ,  [57] , the option of using a sentiment classifier in ECS architecture design, might not bring forth the best results in future ECS studies.\n\n(c) Positive and Negative Emotion Clusters: After identifying emotion classes, one ECS study attempted clustering positive and negative emotions separately to generate empathetic responses  [58] . As per the study findings, this emotion grouping/clustering approach is coupled with the emotion mimicry approach to produce better evaluation results, albeit the resultant model is benchmarked against only one ECS study  [59] . Understanding the user's emotion is a necessary step before exhibiting empathy  [24] ,  [29] ,  [30] ,  [52] ,\n\n[55]-  [58] ,  [65] ,  [66] ,  [73] ,  [75] ,  [76] ,  [81] ,  [82] , Sentiment Mental attitude (e.g., positive, negative, neutral) produced by feelings and perception Helps in understanding the user's attitude so that affective matching mechanisms can be activated  [53] -  [55]  Positive and Negative Emotion Clusters",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "Grouping Of Positive And Negative Emotions",
      "text": "These clusters when coupled with emotion mimicry may result in better empathetic responses  [58]  Emotion Causes Specific words in the user message that carry the causes of a particular emotion Emotion causes go beyond emotions to understand the user's issues and feelings in a more nuanced way  [26] ,  [60] ,  [61]  Dialog Act/Intent Utterance in the context of a conversational dialog that serves a function\n\nUnderstanding the user's intent is importing for charting the next steps in the dialog process  [27] ,  [28] ,  [30]  Persona\n\nThe social face an individual presents to the world Persona is highly correlated with personality which in turn influences empathy  [25] ,  [62] -  [64]  Verbal and Nonverbal Behavior",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Expressions Of Emotion In Both Textual And Non-Textual (Video, Audio) Data",
      "text": "Multimodal detection of emotion goes beyond the current dominant unimodal approaches in fully understanding the user's emotion state  [65]  Communication Mechanism\n\nThe higher-level and abstract factor relating to empathy expression Can produce better empathetic responses when integrated with other factors (dialog acts)  [30]  External Knowledge Commonsense and emotion lexicon knowledge bases queried with the words from user messages Helps with making meaningful inferences about the user's emotional state  [66] -  [69]  ECS Multiple Listeners",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Listeners Dedicated To Different Emotion Classes",
      "text": "Each listener is optimized to react to the particular emotion so that more specific empathetic responses could be generated May help in situations where the conversations are not required to be lengthy and engaging  [70]  Anticipated Emotion\n\nPredicting the future emotional state of the users based on the generated ECS response Helps in minimizing the divergence between the anticipated emotions and ground truth emotion distributions. Reciprocal altruism can also be achieved  [71] ,  [72]  Anticipated Sentiment\n\nPredicting the future sentiment of the users based on the generated ECS response May help in ensuring satisfactory sentiment polarity in future user messages  [73] ,  [74]  ECS Messages and User",
      "page_start": 5,
      "page_end": 5
    },
    {
      "section_name": "Exemplars",
      "text": "Small text snippets that have been added to the ECS responses\n\nEnforces the presence of empathetic reactions in the ECS responses  [29]  Affective Matching Mechanisms\n\nMatching or mirroring the emotional state of the user When emotional consensus is reached between the user and ECS agent, the quality of empathetic conversations seems to improve  [58] ,  [75]  User Feedback Feedback about the responses generated by the ECS agents Through either active or adversarial learning, the conversations are tailored according to user feedback so that more effective empathy is exhibited  [62] ,  [63] ,  [76] ,  [77]  (d) Emotion Causes: Emotion causes refer to the specific words in the user message that carry the causes of a particular emotion. Studies that have identified the emotion causes have generated more relevant and empathetic responses from the ECS. This area has been an active area of research due to promising improvements  [26] ,  [60] ,  [61] . For example, for the sentence \"I really wanted to get the part in the school rendition of a play. But my friend got it\", the emotion causes words are \"rendition\", \"friend\" and \"got\". The approach of extracting causes for particular emotions in natural language text applies to open-domain settings i.e., chit-chat context. For domains such as customer service, another related research topic known as aspect-based sentiment/emotion analysis  [78] ,  [79]  is more suitable as specific aspect terms and aspect descriptions or opinion terms need to be extracted from text.\n\n(e) Dialog Act/ Intent: Dialog act and intent classification is a mandatory task in task-based and goal-oriented dialog systems  [80] . For instance, when the user is seeking the help of a CAI agent for booking a flight ticket. The agent will have to detect the user intent as \"book_ticket\" so that the corresponding information could be collected from the user for completing the ticket booking. This task is not usually performed in open-domain dialog systems. Although ECS studies predominantly follow open-domain dialog systems architecture, few ECS studies have attempted to classify the dialogue act/ intent of conversations. In two ECS studies  [27] ,  [28] , new intents have been identified from the EMPATHETICDIALOGUES dataset  [24] . Eight intents were identified specifically. They are questioning, agreeing, acknowledging, sympathizing, encouraging, consoling, suggesting, and wishing. The eight new intents are combined with the existing 32 emotion classes along with a neutral class to form a hybrid emotion-intent category set. The authors opine that datasets used in ECS studies need to be annotated with these new emotion-intents to facilitate better response generation. This emotion-intent category data is utilized in another ECS study  [30]  to emphasize its usefulness.\n\n(f) Persona: Persona-based research in CAI agents mandates the agent to showcase a particular personality while interacting with users  [81] . Persona is highly correlated with personality which in turn influences empathy as per research  [82] ,  [83] . Certain ECS studies have followed this persona-based approach for improving the empathetic response generation performance  [25] ,  [62] -  [64] . A Personabased Empathetic Conversation (PEC) dataset  [25]  has also been published as a part of this research. The findings from these ECS studies indicate that persona has a greater impact on empathetic conversations than non-empathetic conversations.\n\n(g) Verbal and Non-verbal Behavior: Multimodal emotion recognition or affect detection has gained considerable attention in affective computing, where the combination of features from language, facial expressions, and tone of voice are found to perform generally better than singlemodality  [84] -  [86] . However, multimodal approaches are a rarity in ECS studies. As a part of this review, we were able to identify one study  [65]  where multimodal inputs were processed. The dataset for this study was prepared by annotating an existing human-agent video interview. Both verbal (text-based) and non-verbal (video-based) behaviors were identified to understand the user's emotions for response generation.\n\n(h) Communication Mechanism: Communication mechanism refers to a higher-level and abstract factor relating to empathy expression. It was introduced in the study where the objective was to detect empathy in the text format  [87] . There are three types of communication mechanisms namely emotional reactions, interpretations, and explorations. The emotional reactions are recorded at two levelsweak communication ( little expression of the felt emotion) and strong communication (full expression of the felt emotion). Similarly, interpretation is also recorded at weak (lower cognitive understanding of the speaker's emotional state) and strong (higher cognitive understanding of the speaker's emotional state) levels. The explorations mechanism is for improving the understanding of emotions by exploring the feelings not directly stated by the speaker. A weak exploration is one where a generic question is asked to the speaker (e.g., \"what happened?\") while a strong exploration indicates stronger empathy (e.g., \"Are you feeling alone right now?\"). This communication mechanism concept has been used in an ECS study as one of the input factors  [30] . The study highlights the usefulness of this factor in generating empathetic responses.\n\n(i) External Knowledge: Entity extraction from user messages is not a common activity in existing ECS studies. There are a few studies that have utilized this activity  [66] -  [68] . In these three studies, the entities and the relations between the entities have been extracted from preexisting knowledge stored in external knowledge bases (PolarisX in  [66] , ConceptNet in  [68] ,  [69] , and ATOMIC in  [67] ) to make meaningful inferences. ConceptNet  [88]  is queried in two studies  [68] ,  [69]  to extract both additional concepts and relations. Let us consider two examples. In the first example from  [68] , \"I was hiking in the outback from Australia the other day\", the word \"hiking\" is related to the words \"enjoy nature\" through the relation \"has_subevent\" in ConceptNet. In the second example from  [69] , \"I started to cough blood 3 days ago\", the word \"cough\" is related to the word \"illness\" in ConceptNet. Compared to Concept-Net, PolarisX can consistently collect new data from social media and the web  [89] . In the ECS study  [66] , it is used to establish relations between the words (concepts) in the user messages. ATOMIC is a knowledge base of commonsense reasoning inferences about everyday if-then events  [90] . It is used in  [67]  to infer six commonsense relations for the person involved in an emotional event. The usage of such knowledge bases in ECS studies helps in understanding the speaker/user's situation in a more detailed way by inferring implicit information which is latent in the messages.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Ecs",
      "text": "In existing studies, four concepts have been analyzed at the ECS component level (refer to Fig.  2 ). It is to be re-iterated that the responses from the ECS models are usually generated (using natural language generation models) or retrieved (using templates or responses database).\n\n(a) Multiple Listeners: In one study  [59] , response prediction is performed by combining the responses from multiple listeners (response generation models) dedicated to different emotion classes. The rationale is that each listener is optimized to react to a particular emotion. At the final level, a meta-listener softly combines the response from all the listeners. This approach did not yield better offline evaluation results but scored higher in user evaluation.\n\n(b) Response Types: In another study  [70] , the concept of preset response types was explored. In this study, three types of responses will be provided back to the users based on their corresponding utterances. The response types are empathetic, context-based, and intent-based. This approach was prototyped with a depression questionnaire chatbot which interacts with the users to get responses. The chatbot's empathetic responses included coping mechanisms depending on the answers to the particular questions. We opine that this approach is simplistic as preset responses are not scalable. Also, the response types need to be hybrid in most cases as empathy needs to be embedded in the chatbot responses whenever required.\n\n(c) Anticipated Emotion: In ECS studies, the empathetic response generation process generally takes the emotion of the current user message or the historical user messages into consideration. The anticipation of the next emotional reaction of the user is taken into the response generation study in two ECS studies. In  [71] , this approach helps in minimizing the divergence between the anticipated emotion and ground truth emotion distributions. However, this approach has not helped in producing better results for all the considered evaluation metrics. Hence, there is scope for improvement. In another study  [72] , multiple chatbots are trained to achieve reciprocal altruism based on the rationale that altruistic behaviors are exhibited by humans during interactions. In this study, a reinforcement learning model is used to predict the next emotion of the user. Along with the future emotion, a conceptual human model has also been additionally implemented to simulate future responses from the users.\n\n(d) Anticipated Sentiment: Similar to anticipated emotion, there have been a few studies that have attempted to predict or anticipate the future sentiment of the users  [73] ,  [74] . In  [73] , the anticipated sentiment concept is referred to as sentiment look-ahead, which is a reward function under a reinforcement learning framework. This framework provides higher rewards to the response generation models when the generated response improves the user's sentiment. In another related study  [74] , the anticipated sentiment is referred to as the affect label. Two new modules namely the discrimination and re-writing modules are used in this study in place of the reinforcement learning framework in the other ECS study  [73] . The discrimination module decides whether the generated response will fetch satisfactory polarity. If the condition is not met, the rewriting module rewrites the response so that the sentiment polarity is improved.",
      "page_start": 7,
      "page_end": 8
    },
    {
      "section_name": "Ecs Messages",
      "text": "At the ECS messages level, there have been a few concepts that have been analyzed.\n\n(a) Exemplars: Exemplars are small text snippets that have been added to the ECS responses so that the overall messages appear more empathetic  [29] . These exemplars are also retrieved from the same training set which is used for the main model training. Examples of exemplars are \"why what happened\", and \"oh no, why is that\". These snippets are considered exemplary relevant responses for particular contexts. In the overall architecture, an exemplar injection module sends an exemplar to the final response general model which includes the exemplars as a prefix to the final generated response. Although this approach shows promise, it was found to need improvement in multiturn contexts where the user and agent have back-andforth conversations.\n\n(b) Affective Matching Mechanisms: The affective matching mechanism has been experimented with in a few ECS studies in which the user messages and ECS messages are analyzed in a combined manner. This mechanism has been operationalized through emotional mimicry  [58]  and emotional consensus  [75] . In  [58] , the empathetic responses are made to mimic the emotion of the user while accounting for their sentiment. This study was discussed earlier under the positive and negative emotion cluster sub-section in the User Messages component. In  [75] , the affective matching mechanism is grounded on emotional consensus since empathy is triggered when the user and the agent link similar experiences with their emotions converging. For this purpose, the study makes use of a dual-generative model to construct emotional consensus. Based on the evaluation results, this approach seems to provide better results on all evaluation metrics when benchmarked against the SOTA approaches. Hence, this emotional consensus based ECS model shows promise for future ECS studies.\n\n(c) User Feedback: The user's feedback has also been sought in a few studies to improve the response generation capabilities of ECS dynamically. This feature has been achieved through active learning  [62] ,  [63]  and adversarial learning  [76] ,  [77] . Through the active learning approach used in  [62] ,  [63] , the user can provide two types of optional feedback to the ECS agent. The first feedback is about reporting unethical messages while the second feedback is the expected or correct empathetic response that the ECS agent could have provided. Other than the learning feature, the ECS model used in these studies also incorporates a persona-based finetuning so that the agent comes across with a suitable persona. In the demo website of this chatbot  [91] , emojis are embedded for both user and chatbot responses, although the rationale for emoji inclusion has not been provided in the paper. The model shows promising results in offline evaluation, but human evaluation experiment results have not been reported. The adversarial learning framework is implemented in two ECS studies  [76] ,  [77] . This framework is used for analyzing user feedback to identify whether the generated responses evoke adequate emotion perceptivity. Two discriminators (semantic and emotional) are used for this purpose to handle user feedback. In both offline and human evaluation experiments, this approach produced better results for most metrics. Hence, this adversarial learning approach can also be considered as a promising method for future ECS studies.",
      "page_start": 7,
      "page_end": 8
    },
    {
      "section_name": "Datasets",
      "text": "In Table  3 , the datasets used in ECS studies have been listed. Most of the datasets were created specifically for ECS studies while some datasets have been adopted from earlier general-purpose CAI dialog systems studies.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Datasets Created For Ecs Studies",
      "text": "The seminal EMPATHETICDIALOGUES dataset  [24]  has been used for evaluation directly or indirectly in 26 studies thus far. It contains 24,850 conversations. This dataset was prepared through a crowdsourcing approach where 810 participants played the role of a speaker or listener. They were instructed to respond for at least six turns empathetically. First, the speaker was provided with an emotion class (a total of 32 emotion classes were used), and he/she was advised to speak about a real-life scenario corresponding to the assigned emotion class. Next, the speaker was paired with a listener, and they proceed to converse about the real-world scenario. Both the speaker and listener are not made aware of the assigned emotion class. Each conversation is restricted to 4-8 utterances. A sample dialogue for the emotion class \"afraid\" is provided from the dataset in Figure  3 . In subsequent studies, the EMPATHET-ICDIALOGUES dataset has been further augmented with eight intent categories  [103]  and has been separately translated to other languages (e.g., Arabic  [93] ,  [94] ). The second most popular dataset is the Persona-based Empathetic Conversation (PEC) dataset  [25]  comprising 355,000 conversations. It was prepared with the source data extracted from Reddit, specifically from two subreddits happy and offmychest. The happy subreddit is a forum where users share happy stories and thoughts from their personal lives whereas the offmychest subreddit forum is used by users for sharing emotional anecdotes. To prepare the dataset, crowdsourced workers annotated the source data extracted from the two aforementioned subreddits with appropriate empathy labels. Three annotators were involved in the process. The inter-annotator agreement values for sentiment and empathy labels were 0.725 and 0.617, respectively. The uniqueness of the PEC dataset is that it can be used to train ECS models for exhibiting both persona and empathy. This dataset has been used by a later published ECS study  [30] .\n\nThe XiaoAI Empathetic Conversation (X-EMAC) dataset  [26]  comprises 16,873 conversations. It was prepared by extracting the base data from XiaoAI online logs. The base data was annotated with four emotion classes (sad, anger, joy, and others). Next, psychologists worked on this annotated dataset to create response templates. These responses were formulated based on counseling strategies of active listening and effective questioning. The templates were designed specifically for each emotion class. These templates were next provided as responses to those user queries that are classified into certain emotion classes (sad, anger, joy), and the next turn of real-time responses from the users was subsequently collected. For these three turns (user-template-user), annotators identified the emotion causes span and also wrote empathetic responses. There is no information provided about the inter-annotator agreement in this paper.\n\nTwo related empathetic conversational datasets, namely the Empathetic OpenSubtitles Dialogues dataset  [27]  and Emotional Dialogues in OpenSubtitles (EDOS) dataset  [28] , were prepared with base data extracted from the public OpenSubtitles dataset  [104] . The EDOS dataset comprises one million emotional conversations from movie subtitles. Each turn is annotated with 41 emotion classes. This dataset was created to launch a comprehensive empathetic dataset that is bigger than the EMPATHET-ICDIALOGUES dataset  [24] . The authors argue that movie dialogues closely mirror real-world conversations and hence can be considered to be a suitable substitute. In this study, automatic data augmentation techniques were used to expand a manually annotated set of 9K movie dialogues to the full one million emotional dialogues.\n\nAnother dataset called EMPATHETICPERSONAS  [64]  was created through crowdsourcing. This small-scale dataset of 3,324 conversations was constructed through survey responses where the respondents were asked to perform two tasks -1) respond with emotions to the question -How are you feeling? and 2) rewrite a set of base utterances to render them empathetic. No further information has been provided about the additional instructions that were provided to the respondents. Based on the provided information, the survey respondents seem to have been provided with enough leeway to rewrite utterances as per their own judgement. From the overall dataset, there are 2,143 empathetic rewritings of 45 base utterances. Two annotators were recruited to annotate the rewritings with different levels of empathy using a 3-point empathy scale (0: non-empathy, 1: weak empathy, and 2: strong empathy). No information is provided regarding the inter-annotator agreement.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Datasets Adopted From General Cai Dialog Studies",
      "text": "Apart from the empathetic conversational datasets, generic conversational datasets have also been used for pretraining, training, and evaluation of response generation modules in ECS studies. The DailyDialog dataset  [99]  is the popular dataset in this category, followed by BookCorpus  [68] , PersonaChat  [102] , and Douban Conversation Corpus  [105] . These generic datasets are mainly meant to enrich the conversation quality and make the conversations realistic.\n\nThe DailyDialog dataset  [99]  comprises 13,118 multiturn dialogues about daily life conversations with the source data extracted from various websites. The dialogues are annotated with two purposes -\"exchanging information\" and \"enhancing social bonding\" and four dialog acts (inform, questions, directives, commissive). This dataset is used in ECS studies for pretraining the response generation model in  [73] ,  [100] ; training the emotion classifier and response generation model in  [97]  and  [98]  respectively; and for evaluation in  [66] .\n\nThe next popular dataset is the BookCorpus  [101]  dataset was constructed from 11,038 books, containing a total of approximately 74 million sentences  [106] . The books are from different genres such as romance, fantasy, and science fiction. Since the dataset has extensive coverage of words, it has been used for only pre-training purposes in ECS studies  [62] ,  [63] ,  [100] .\n\nThe PersonaChat  [102]  dataset comprises 162,064 conversations between crowdsourced participants who were randomly paired. The participants were asked to act the part of a given persona. They were requested to chat naturally and get familiar with each other during the conversation. 1,155 personas were considered for this dataset. Each persona is represented by at least five sentences that given an indication about the particular persona. Similar to the BookCorpus dataset, this dataset has also been solely used for pretraining in ECS studies  [62] ,  [63] ,  [73] .",
      "page_start": 9,
      "page_end": 10
    },
    {
      "section_name": "Techniques Used For Request Processing And Response Generation",
      "text": "This section focuses on the techniques or algorithms employed in ECS studies for both request processing and response generation. In CAI system architectures, there are multiple modules such as NLP pre-processing, natural language understanding (NLU), dialogue management, and response generation  [107] . Nevertheless, these modules are not utilized together in ECS studies since the focus of these studies is to develop models to showcase empathy in an open-domain setting. Since most of these studies are centered around the EMPATHETICDIALOGUES dataset  [24] , the emotion detection module operates before the response generation phase to identify the emotion class in the user message. In certain studies  [53] -  [55] , a sentiment classifier is placed instead of an emotion classifier to ascertain the sentiment class. While different deep learning architectures are used to classify emotion/sentiment, the classifiers are tuned with pre-trained models. BERT  [108]  and RoB-ERTa  [109]  are the popular models for this pre-training purpose, with usage in four studies. Deepmoji  [110]  and VADER  [111]  algorithms have been used in one study for emotion and sentiment identification, respectively. Apart from emotion/sentiment detection, other features are extracted or identified in user messages (requests). These features have been presented in Section 4.1. In this review, the algorithms or techniques used for such feature extraction are not presented as they have not emerged as standard procedures in ECS implementations.\n\nThere are three types of response generation methods in CAI systems; rule-based, retrieval, and generative  [4] . The rule-based method is the fastest to initialize and deploy but requires constant monitoring and editing. The retrievalbased response generation method retrieves the most relevant response from a database of predefined responses  [112] . However, the retrieval-based method is not the dominant response generation method in ECS studies, and it has been used in a handful of studies  [24] ,  [74] ,  [113] . On the other hand, the generative-based method is the popular method in ECS studies, mirroring the latest trend in dialogue systems. Generative models can produce new dialogues based on large amounts of conversational training data  [4] . The standard transformer model  [114]  is the most frequently used model in response generation modules in ECS studies, followed by GPT  [115] , Seq2Seq  [116] , and GPT-2  [117] . The Text-To-Text Transfer Transformer (T5)  [118] , one of the advanced latest models providing the best results in multiple NLP tasks, is gaining prominence in ECS studies with usage in three studies. The BERT  [108]  model and its different variants, such as CoBERT  [25]  and ALBERT  [119]  have also been used for creating response generation models. DialoGPT  [120]  model, which is considered state-of-the-art in pre-trained response generation models, does not seem to poplar among ECS studies with deployment in a single study  [92] . It is perceivable that ECS studies have employed the latest deep learning architectures in both request processing and response generation modules. The techniques, or models used for emotion/sentiment detection and response generation in ECS studies, are listed in Table  3 .  [27],  [30] ,  [64] ,\n\n[68] Deepmoji  [110] , VADER  [111]  2  [29] ,  [97]  Response Generation Standard Transformer  [114]  12  [24] ,  [27] ,  [28] ,  [53] ,  [58] -  [60] ,  [67] ,  [75] -  [77] ,\n\n[98] GPT  [115]  7  [26] ,  [62] ,  [63] ,  [66] ,  [72] ,  [97] ,\n\n[100] Seq2Seq  [116]  5  [73] ,  [93] ,  [94] ,  [96] ,  [113]  GPT-2  [117]  3  [30] ,  [68] ,  [71]  Text-To-Text Transfer Transformer (T5)  [118]  3  [29] ,  [53] ,  [64]  Others (Di-aloGPT  [120] , CoBERT  [25] , BERT  [108] , AL-BERT  [119] ) 5  [25] ,  [66] ,  [72] ,  [74] ,  [92]",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Evaluation Approaches And Metrics",
      "text": "Evaluation results were reported in 37 ECS studies surveyed. Offline evaluation is the most-used evaluation approach in ECS studies, with 34 of these studies using the approach. In offline evaluation, the ECS techniques are typically evaluated based on their ability to reproduce the listener's responses to a speaker (as designated in the training dataset). In ECS architectures with an emotion/sentiment detection module, Accuracy is the primary metric used for evaluating the classification performance.\n\nFor the main task of evaluating the response generation ability, Perplexity is the most popular metric used in 22 studies, followed by BLEU  [121]  in 18 studies. Perplexity is a model-dependent metric that measures how well a probability model predicts a given sample. On the other hand, the Bilingual Evaluation Understudy Score (BLEU) compares the generated response against the gold standard (the actual response). Beyond ECS studies, BLEU is the most frequently used evaluation metric in conversational dialogue systems  [31] ,  [122] . The third most popular metric is the Distinct-n (dist-n) metric with 11 studies. This metric enumerates the percentage of unique n-grams in the responses  [123] . Typically, unigrams (dist-1), bigrams (dist-2) and trigrams (dist-3) are reported. The other prominent offline evaluation metrics are Sentence Embedding Similarity, F1, Mean Reciprocal Rank (MRR), Diversity, Loss, and Recall. Ablation study does not seem to be popular with ECS offline evaluation experiments, with only nine papers reporting ablation evaluation results.\n\nIn 26 ECS studies, user evaluation results have been reported. In these studies, human ratings are collected for specific user perception-related metrics. The three most popular user metrics are Empathy, Relevance, and Fluency measures. For the Empathy measure, the related question is \"Did the responses show understanding of the feelings of the person talking about their experience?\". The question for the Relevance measure is \"Did the responses seem appropriate to the conversation? Were they on-topic?\" and the question for the Fluency measure is \"could you understand the responses? Did the language seem accurate?\". These three metrics were first introduced in the EMPATHETICDIALOGUES study  [24] . There have a few other user metrics used in ECS studies. Net Sale Value (NSV) was proposed in  [26]  to measure the preference towards a particular ECS implementation by using the number of upvotes (likes) and downvotes (dislikes).\n\nThe formula is (#upvotes-#downvotes)*(#upvotes+#downvotes). In  [67] , Coherence and Informativeness are used along with the Empathy metric. The questions for these two metrics are: which response is more coherent in content and relevant to the context and which response conveys more information about the context? Human A/B testing has been performed in five studies  [29] ,  [58] ,  [60] ,  [75] ,  [113] . In A/B testing, human annotators are requested to pick the model with the best response for each of the sub-sampled test instances for two models, A and B.",
      "page_start": 10,
      "page_end": 11
    },
    {
      "section_name": "Notable State-Of-The-Art (Sota) Approaches In Ecs Studies",
      "text": "In this section, we discuss most notable SOTA approaches in ECS studies.\n\nFirst, the study of the EMPATHETICDIALOGUES dataset  [24]  gains the highest popularity in ECS studies, and it mandates a discussion on the response generation models proposed in the corresponding study. Three additional studies have been handpicked by the authors based on three criteria namely novelty, comprehensiveness, and performance. Novelty pertains to the impact and level of usage of empathy-related concepts which are entirely novel or operationalized from conceptual empathy models and frameworks. Comprehensiveness refers to extent of the ECS evaluation, i.e., whether the proposed model has been evaluated through offline evaluations, human evaluations, and ablation studies. The criteria also consider whether a particular study has benchmarked the proposed model(s) against the existing baseline approaches. Finally, the performance criteria provide weightage to studies that have reported better evaluation results for the considered metrics.",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Empathetic Open-Domain Conversation Models",
      "text": "As introduced in section 4.2, the EMPATHET-ICDIALOGUES dataset comprises conversations grounded in specific situations in which the speaker and listener converse with each other. The response generation models are designed to emulate the role of the listener who responds empathetically. This role has no prior knowledge of the emotion class and the grounded situation.\n\nWith a dialogue context X of n past conversation utterances that are concatenated and tokenized as {x1, x2,x3xm}, the models are trained to produce a response Y by maximizing the likelihood p(Y|X). In this study, both retrievalbased models and generative models are proposed. For this retrieval-based setup, the model is provided with a large number of potential responses and the task is to select the best suitable response i.e., When two input vectors hx and hy are provided, the best response candidates maximize the dot product of hx and hy where hx is the encoded data of the historical utterances {x1,x2,xm}, and hy is the encoded data of the possible responses {y1,y2,.ym}. The specific transformer-based architecture from  [124]  and BERT-based  [108]  architectures are experimented with for retrieval-based setup. Thereby, there are two retrievalbased architectures proposed in this study.\n\nIn the case of a generative model, the standard transformer  [114]  architecture is used. The encoder is the same as the earlier models while the decoder takes the encoder outputs for predicting a sequence of words that combine to form the response y. The model is trained to minimize the negative log-likelihood of the response y.\n\nFor the three proposed architectures in the study, multiple types of training options along with different data sources are evaluated. In addition, the authors also experiment with the inclusion of information from external predictors to check if the overall performance improves. In Table 4, the 21 different model variations are listed based on these three dimensions. For the training options, the variations experimented with are pre-trained and fine-tuned. For the response data sources, three datasets are considered. They are Reddit (R), DailyDailog  [99]  (DD) and EM-PATHETICDIALOGUES  [24]  (ED). For the external predictors, Emoprepend-1 and Topicprepend-1 are considered. Emoprepend-1 is an emotion classifier that predicts the emotion class from the situation description text. This classifier is trained on the EMPATHETICDIALOGUES dataset itself. Topicprepend-1 is a classifier to predict topics represented by the text. This classifier is trained on a newsgroup dataset  [125] .",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Table 4 Model Variations In Empatheticdialogues Ecs Study",
      "text": "",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Model Response Source",
      "text": "",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Architecture",
      "text": "",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Retrieval",
      "text": "",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Retrieval With Bert",
      "text": "",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Generative",
      "text": "Out of the 24,850 total conversations in the dataset, 19,533 conversations are allotted to the training set while 2,770 and 2,547 conversations are allotted to the validation and test sets respectively. Both offline and user evaluation experiments are conducted in this study. Three offline evaluation metrics are precision, average BLEU, and perplexity. Compared to pre-trained and external predictor model variations, the fine-tuned models (M7, M8, and M9) with EMPATHETICDIALOGUES dataset as the response source provide the best results for retrieval and generative architectures. The same models also provide the best results in the user evaluation where the metrics empathy, relevance, and fluency are first introduced in this study. For the retrieval-based architecture with BERT, topicprepend-1 models (M20) provide the best results, thereby indicating this approach might not boost the performance of smaller models but rather benefit the bigger models. The study results prove the utility of the EMPATHETICDIALOGUES dataset over the earlier published datasets and also underline the effectiveness of fine-tuning in both retrieval-based and generative models.",
      "page_start": 11,
      "page_end": 11
    },
    {
      "section_name": "Emotion Causes Oriented Empathetic Response Generation Models",
      "text": "Emotion cause is one of the promising empathy-related concepts in ECS studies since empathetic response generation is centered on particular words in the user text that allude to the cause behind the user's emotion. Out of the three ECS studies where emotion cause-oriented response generation models were proposed, we have considered one study  [60]  which satisfies our three criteria.\n\nIn this study's main model, there are two components emotion reasoner and response generator. The emotion reasoner predicts the emotion class when provided with a dialogue context and also identifies words that convey the cause for that particular emotion class. The dialogue context comprises of {u1,u2,un} of n utterances, and each utterance ui comprises of words { 1  ,  2      } of m tokens. The input sequence X {x1,x2,xn} is formed by concatenating all the utterances that are separated by a special [SEP] token. For this input sequence X, the response generator is expected to produce an appropriate empathetic response Y {y1,y2,yn}.\n\nIn the emotion reasoner, emotion prediction is the first task that is executed by a transformer encoder. This task is considered a text classification task. A representation of the words in the dialog context is fed into the encoder. Based on this data, context emotion distribution is computed. For the second task of emotion cause detection, an existing model  [126]  is leveraged. This task is considered a sequence labeling task. This is accomplished by labeling each word in the input sequence with an emotion cause label {0,1}.\n\nThe predicted emotion class and emotion cause words are input into the response generator. The standard transformer  [114]  is used as part of this module. Trainable emotion embeddings are used so the 32 emotion class labels could be represented. Each word in the input sequence is represented as a of word embedding, positional embedding and emotion embedding. First, the input sequence X is fed into the encoder section of the transformer so that contextualized word representations are made available for the decoder. The emotion cause words are forced into the response generation process through a gated attention mechanism whereby a sequence of gates G {g1,g2,gn} dynamically select elements that are related to the emotion cause words. With these gates, two strategies namely hard gating and soft gating are explored to vary the impact of the emotion-cause words on the response generation process. The former is a strict strategy while the latter is a comparatively flexible strategy.\n\nFor the evaluation experiment, the EMPATHET-ICDIALOGUES dataset  [24]  is used. The dataset is split into training, testing, and validation subsets with an 8:1:1 split. The proposed model has two variations namely soft and hard, referring to the soft gating and hard gating approaches respectively. The baselines selected for this study are MoEL (Mixture of Empathetic Listeners)  [59] , MIME (MIMicking Emotions for Empathetic Response Generation)  [58] , EmpDG (Empathetic Dialogue Generation)  [77]  and MK-EDG (Multiple Knowledge Empathetic Dialogue Generation)  [69] . These baseline models have been covered in this review. The offline evaluation metrics used in this study are BLEU, distinct-1/distinct-2, BERTscore  [127] , and accuracy (for emotion prediction). The constructs, namely empathy, relevance, and fluency, are employed for the user evaluation. Additionally, an ablation study and human a/b testing were conducted. For all the offline evaluation metrics, both the hard and soft models provided the best results. The ablation-based analysis indicated the importance of emotion prediction and emotion cause extraction in the overall proposed model's performance with the latter boosting the model's performance. The user evaluation study and human a/b testing results also underline the better performance of the proposed models when compared to the baselines.",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "External Knowledge For Empathetic Response Generation Models",
      "text": "As highlighted in section 4.1, ECS architectures can benefit from external knowledge sources such as knowledge bases since commonsense and emotion-related knowledge can help in inferring latent concepts and relations from user messages. As a part of this review, we identified four papers in which knowledge bases were used. We selected the Knowledge-aware EMPathetic response generation method (KEMP) study  [69]  since it satisfies the three criteria. The premise for this study is that there is not much overlap found between dialogue history and response messages at the non-stopword word level in the popular EMPATHETICDIALOGUES dataset  [24]  which is used in multiple ECS studies. However, when external knowledge is incorporated, the authors claim that the ECS agents can obtain useful hints from the dialogue history so that better empathetic responses could be generated.\n\nThe proposed KEMP method in this study incorporates three components which are an emotional context graph, emotional context encoder, and emotion-dependency decoder. Two knowledge bases ConcepetNet  [88]  and NRC_VAD  [128]  are leveraged. ConceptNet  [88]  is used to extract a set of candidate tuples of the structure {head concept; relation; tail concept; confidence score} for the non-stopword words in the user messages. An example given in the paper is {birthday; RelatedTo; happy; 0:19}. NRC VAD  [128]  is a lexicon of VAD (Valence-Arousal-Dominance) vectors for around 20K English words. In this study, NRC_VAD is used to score the emotion intensity for the dialogue words and the external concepts extracted from ConceptNet. The concepts with higher emotion intensity are fed into the KEMP model.\n\nThe aforementioned three components of KEMP are executed sequentially thereby forming three phases. In the first phase, the dialogue history D {x1,x2,xn} is enriched with the external knowledge to form the emotional context graph G. In the second phase, emotional signals ep of D are distilled based on the embedding and the emotion intensity data (obtained from NRC_VAD). In the third phase, the emotional signals ep and graph G are used to learn emotional dependencies using a cross-attention mechanism. In the last step, the empathetic responses Y {y1,y2,yn} are generated. A multi-task learning framework is used in KEMP to minimize the losses.\n\nSimilar to the previous SOTA approach, the evaluation experiments are conducted on the EMPATHET-ICDIALOGUES dataset  [24] . The dataset is split into the training set with 17,802 dialogues, the validation set with 2,628 dialogues, and the testing set with 2,494 dialogs. The KEMP method is compared with five baseline approaches. They are standard transformer  [114] , Emoprepend-1 from  [24] , MoEL  [59] , MIME  [58] , and EmpDG  [77] . The offline evaluation metrics used in this study are accuracy (for emotion prediction), perplexity, BLEU, and distinct-1/distinct-2. The constructs empathy, relevance and fluency are utilized for the user evaluation. Ablation study and human a/b testing results were also reported in this paper. The offline and user evaluation results indicate the superiority of the KEMP method in outperforming all the baseline approaches. The only exception is the fluency metric where EmpDG method produces slightly better results. In the ablation study, the emotional context encoder and emotiondependency decoders are replaced with standard transformers to ascertain the effectiveness of these two components. The study results indicate that the performance of the model deteriorates without these components, thereby demonstrating the utility of external knowledge and modeling dependencies. Although this KEMP model provides better performance than the earlier baseline approaches, the emotion causes model  [60]  (discussed in the previous sub-section) provides even better performance, thereby highlighting the usefulness of emotion cause extraction in ECS studies.",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "Empathetic Response Generation Based On Affect Matching",
      "text": "Affect matching through mimicry is one of the basic empathic behaviors in conceptual empathy models, which has been highlighted in Section 3. There are two ECS studies  [58] ,  [75]  that have employed the affect matching mechanism in the model architecture. We selected the study with the better affect-matching design and evaluation results. In the selected ECS study  [75] , the authors propose an approach to establish \"emotion consensus\" between the user (speaker) and the ECS agent (listener). They argue that empathy is triggered when two interlocutors attempt to link similar experiences and their emotions converge on the same point, as a result. The model proposed in this study generates pseudo-empathetic conversations for unpaired emotional data in the EMPATHETICDIALOGUES dataset  [24]  since a bidirectional process is necessitated for establishing emotion consensus.\n\nTo realize the study objectives, a dual-generative model The forward and backward dialogue models have the same architecture. In the encoder, all the utterances in C are concatenated into a long sequence. For each token w in C, three embedding spaces are summed up. They are word embedding space, positional embedding space, and role embedding space where the role is either speaker or listener. A standard transformer encoder  [114]  is used on top of the summed embedding space to get the context representation. After the encoder, the discrete latent variable ze is used to capture the emotion consensus between C and Y. This is performed by training a classifier using the crossentropy loss between the embedding space of ze and ground truth emotion label e. Finally, the decoder model focuses on emotion consensus with the application of an emotion-enhanced attention mechanism in the cross-attention layer of the transformer decoder i.e., the embedding space of ze is first concatenated with the decoder input to get representations of Y. Next Y is fed into forward decoder fdec. The DualEmp model can be trained with both paired data and unpaired data from the dataset Similar to the previous two SOTA ECS models, DualEmp model has been benchmarked against multiple baseline approaches. The five baselines considered are the Emoprepend-1 model from EMPATHETICDIALOGUES study  [24] , MoEL  [59] , MIME  [58] , EmpDG  [77] , and DualVAE  [129]  model which is a dual decoder model rarely used for benchmarking in ECS studies. Three variations of the DualEmp model are used for evaluation. They are (1) a single-paired variation with only a forward dialogue model, (2) a dual-paired variation with only paired data, and (3) the full DualEmp model with both paired and unpaired data. The evaluation is conducted on the EMPA-THETICDIALOGUES dataset  [24]  with the split ratio of 8:1:1 for the training, validation, and test sets respectively.\n\nFor the offline evaluation metrics, the usual four ECS evaluation metrics accuracy (for emotion prediction), perplexity, BLEU, and distinct-1/distinct-2 are employed. In addition, embedding-based scores are used. The constructs empathy, relevance, and fluency are utilized for the user evaluation. Ablation study and human a/b testing results were also reported for the study. The evaluation results indicate the DualEmp model outperforms the baselines in all metrics in both offline and human evaluations. The ablation study results underline the utility of both the backward model and discrete latent variable. The dual-paired variant by itself outperforms all the baselines while the single-paired variant produces comparatively poor results. In the A/B testing, pairwise comparisons highlight that responses from DualEmp models are more preferred by humans than those from baselines.",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "Gaps And Opportunities",
      "text": "The contemporary approaches in ECS studies have helped immensely in improving the experience and perceptions of users during their interaction with ECS, albeit in an opendomain setting. In this section, we are highlighting the current gaps in ECS studies in the context of both open-domain and closed-domain settings.\n\nAspect-level emotion identification. This gap has been alluded to in a previous survey paper  [35] . Many ECS studies have an emotion detection module before the empathetic response generation module. The detected emotion class influences the empathetic response generation. The emotion class is identified for each of the text messages of the users. In open-domain settings, this approach appears to be partially adequate. However, when ECS is deployed in a specific domain (e.g., customer service), the system needs to identify the entities (aspects) in the text for which the emotions are expressed. This research area is referred to as target-dependent emotion analysis or aspect-based emotion analysis (ABEA). Although the aspect-based sentiment analysis (ABSA) area has been researched extensively  [78] ,  [79] , ABEA research has not received much attention.\n\nEmpathetic behavior categories. The empathetic responses generated by the current ECS approaches may not be suitable for all scenarios due to the nature of the datasets. For example, the training datasets in existing ECS studies have been prepared through (a) crowdsourcing, (b) annotating social media data (e.g., Reddit  [25] ), and (c) annotating publicly available relevant data (e.g. OpenSubtitles  [27] ). In these datasets, the empathetic responses of humans are either solely provided or augmented with ratings. Literature on empathetic mechanisms has shown that there are multiple types of empathetic behaviors, namely mirroring, affective matching, empathic concern, consolation, altruistic helping, and perspective-taking  [22] . We posit that datasets should be annotated with empathetic behavior type labels so that models can generate more accurate empathetic responses, depending on the level of the empathy system.\n\nEmpathy incorporation approach. In current ECS studies, the empathetic responses are directly generated by the main response generation module (MRGM). Although the response generation models in this module are pre-trained with general-purpose dialogue datasets such as DailyDialog  [99]  and BookCorpus  [101]  in certain studies, the leading training datasets of conversations are annotated with emotion labels and/or empathy levels. Thus, the empathetic response is directly embedded in the primary response. Other empathy incorporation pathways can be studied. Pre-RGM and Post-RGM are two such pathways. In the Pre-RGM pathway, once the NLU model processes the user's message, the emotion class(es) of the user messages and the constituent entities along with the whole user message are passed over to an empathetic response generation model (ERGM). The ERGM generates an empathetic response in the form of a text snippet which is passed over to MRGM, which combines the empathetic snippet with the subject/intent specific response. In the case of the Post-RGM pathway, the inverse is attempted. First, the MRGM generates a response and then ERGM adds the empathetic part to the main response by rewriting the response. This empathy rewriting task is a recently proposed task that was proposed to improve the empathetic conversational abilities of counselors in mental health settings  [130] .\n\nMultimodal operationalization of conceptual empathy models and frameworks. The conceptual empathy models and frameworks (covered in Section 3) provide a blueprint for different aspects that need to be considered for an effective, empathetic response generation process. It must be noted that the existing ECS studies have not fully operationalized all the features proposed in these models and frameworks. Multimodality is one such feature. The approaches proposed in the existing studies are based on text modality. While multimodal dataset availability is an ongoing challenge in this research topic, future studies should consider audio, and video inputs as full-scale empathy can be exhibited by ECS implementations primarily with multimodal inputs  [32] . The second feature that current ECS studies have not considered is the multi-level empathy approach. As proposed in  [32] , this approach would help in implementing empathy at low, mid, and high levels. These levels are differentiated based on characteristics such as mimicry, affect matching, user mood, user personality, user likes/dislikes, user goals, and context.\n\nIntegration with traditional CAI approaches for domain-specific use cases. In the existing ECS studies, the main task is to generate empathetic responses in an opendomain setting (day-to-day usage). However, this approach is not entirely feasible in a domain-specific setting since user intent detection plays a crucial role in defining the responses. Few studies have employed commonsense KBs to extract concepts from the user's text message and deduce relationships between these concepts to generate more relevant empathetic responses  [66] -  [68] . This approach should work in a closed domain setting, in theory. Another approach is to blend different task types into a single model so that the model has an enhanced ability to respond to different user intents  [131] ,  [132] . In domainspecific CAI implementations, the NLU module is expected to detect the user intents and perform slot filling. These capabilities need to be incorporated when deploying domain-specific ECS.",
      "page_start": 14,
      "page_end": 14
    },
    {
      "section_name": "Conclusion And Future Work",
      "text": "This paper contributes to the topic of empathetic conversational dialogue systems. The state-of-the-art conceptual empathy models, frameworks, and empirical studies have been reviewed. There have been few albeit comprehensive attempts at creating theoretical empathy models based on social science theories related to empathy, such as the theory of mind, belief-desire-intention model, and perception-action-mechanism. Based on these theories, conceptual, functional models, and frameworks have been put forth to highlight the methods of extracting and processing meaningful features from multimodal input data of users, followed by affect recognition and empathetic response generation. We consider it noteworthy that the existing empirical ECS studies have not entirely operationalized all the ideas and features from the conceptual models and frameworks.\n\nThe empirical studies have been reviewed in operationalized concepts, datasets, request processing & response generation techniques, and evaluation approaches & metrics. Handpicked SOTA approaches in ECS studies were introduced to highlight the effectiveness of leveraging certain empathy-related concepts at the model design level. Under operationalized concepts, ECS studies have extracted multiple features from the user messages such as emotion, sentiment, emotion causes, persona, and entities & their relations using external knowledge bases. At the ECS messages level, studies have embedded additional features such as exemplars and emojis. To improve the communication between users and ECS agents, few studies have incorporated a feedback loop through active and adversarial learning.\n\nThe EMPATHETICDIALOGUES dataset is the seminal dataset used in most ECS studies. The active datasets are prepared through crowdsourcing or annotation of social media data (predominantly from Reddit). General-purpose dialogue datasets DailyDialog and BookCorpus have also been in certain studies for pre-training the response generation models. Transformer architectures are fairly prevalent in both request processing and response generation modules of ECS implementations. Mirroring the trend in the dialogue systems research landscape, ECS studies have incorporated the latest architectures such as T5 for improving the response generation accuracy in the models. Offline evaluation is the dominant evaluation approach employed in ECS studies. While user evaluation has been attempted in multiple studies, many evaluation metrics are quite limited and restricted to empathy, fluency, and relevance. There is scope to incorporate more in-depth user perception metrics, catering to other facets of the conversation. Among the carefully selected SOTA approaches, the significance of incorporating the emotion causes and external knowledge in the response generation process has been highlighted along with the affect matching mechanism. Since these concepts improve the empathetic abilities of the models., future ECS studies might benefit by incorporating all these three concepts in the model design. Taking the cue from these specific studies, future ECS studies should aim to design offline and human evaluation experiments with prominent baselines.\n\nWhile the current ECS approaches are tailored for general-purpose day-to-day conversations, they are not directly suitable for a domain-specific context. We opine that target-dependent emotion identification should be performed for providing fine-grained responses. The empathetic responses could be more varied with concepts adopted from existing theoretical empathy models. Different empathy incorporation pathways are to have experimented with in the response generation module as the current integrated approach will not be suitable for all domain-specific scenarios.\n\nAs a part of future work, we will start by proposing a multidomain empathy framework and subsequently implement the framework for two domains:-customer service and mental health. In our framework, we will be including multi-level empathy systems definition and corresponding design features, empathy incorporation pathways, operational modules, and enhanced evaluation metrics. This framework will be applicable for implementation in most domain settings. In addition, we plan to design and implement target-dependent/aspect-level emotion identification and emotion authentication algorithms since accurate emotion understanding is a crucial step towards providing a comprehensive, empathetic response.",
      "page_start": 14,
      "page_end": 14
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: depicts the article se-",
      "page": 3
    },
    {
      "caption": "Figure 1: Article Selection Process Flow",
      "page": 3
    },
    {
      "caption": "Figure 2: , we have illustrated the concepts from the studies",
      "page": 4
    },
    {
      "caption": "Figure 2: The majority of the concepts are on the user mes-",
      "page": 4
    },
    {
      "caption": "Figure 2: Operationalized Empathy-related Concepts in ECS Studies",
      "page": 5
    },
    {
      "caption": "Figure 2: ). It is to be re-iterated",
      "page": 7
    },
    {
      "caption": "Figure 3: In subsequent studies, the EMPATHET-",
      "page": 8
    },
    {
      "caption": "Figure 3: Sample Conversation from EMPATHET-",
      "page": 8
    }
  ],
  "tables": [
    {
      "caption": "Table 1: EMPATHY-RELATED CONCEPTS FROM ECS STUDIES",
      "data": [
        {
          "Related ECS \nConcept \nDefinition \nImprovements provided to ECS Studies \nStudies": "User Messages"
        },
        {
          "Related ECS \nConcept \nDefinition \nImprovements provided to ECS Studies \nStudies": "Emotion"
        },
        {
          "Related ECS \nConcept \nDefinition \nImprovements provided to ECS Studies \nStudies": "Sentiment"
        },
        {
          "Related ECS \nConcept \nDefinition \nImprovements provided to ECS Studies \nStudies": "Positive and \nNegative Emo-\ntion Clusters"
        },
        {
          "Related ECS \nConcept \nDefinition \nImprovements provided to ECS Studies \nStudies": "Emotion Causes"
        },
        {
          "Related ECS \nConcept \nDefinition \nImprovements provided to ECS Studies \nStudies": "Dialog Act/Intent"
        },
        {
          "Related ECS \nConcept \nDefinition \nImprovements provided to ECS Studies \nStudies": "Persona"
        },
        {
          "Related ECS \nConcept \nDefinition \nImprovements provided to ECS Studies \nStudies": "Verbal and Non-\nverbal Behavior"
        },
        {
          "Related ECS \nConcept \nDefinition \nImprovements provided to ECS Studies \nStudies": "Communication \nMechanism"
        },
        {
          "Related ECS \nConcept \nDefinition \nImprovements provided to ECS Studies \nStudies": "External \nKnowledge"
        },
        {
          "Related ECS \nConcept \nDefinition \nImprovements provided to ECS Studies \nStudies": "ECS"
        },
        {
          "Related ECS \nConcept \nDefinition \nImprovements provided to ECS Studies \nStudies": "[59] \nMultiple Listen-\nListeners  dedicated to different \nEach listener is optimized to react to the particular emotion so \ners \nemotion classes \nthat more specific empathetic responses could be generated"
        }
      ],
      "page": 5
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Response Types": "Anticipated \nEmotion",
          "Preset response templates differ \nby  the  context  of the  user mes-\nsages": "Predicting  the  future  emotional \nstate  of  the  users  based  on the \ngenerated ECS response",
          "May help in situations where the conversations are not required \nto be lengthy and engaging": "Helps  in  minimizing  the  divergence  between  the  anticipated \nemotions and ground truth emotion distributions. Reciprocal al-\ntruism can also be achieved",
          "[70]": "[71], [72]"
        },
        {
          "Response Types": "Anticipated Sen-\ntiment",
          "Preset response templates differ \nby  the  context  of the  user mes-\nsages": "Predicting  the  future  sentiment \nof the users based on the gener-\nated ECS response",
          "May help in situations where the conversations are not required \nto be lengthy and engaging": "May  help  in  ensuring  satisfactory  sentiment  polarity  in  future \nuser messages",
          "[70]": "[73], [74]"
        },
        {
          "Response Types": "ECS Messages and User",
          "Preset response templates differ \nby  the  context  of the  user mes-\nsages": "",
          "May help in situations where the conversations are not required \nto be lengthy and engaging": "",
          "[70]": ""
        },
        {
          "Response Types": "Exemplars",
          "Preset response templates differ \nby  the  context  of the  user mes-\nsages": "Small \ntext  snippets \nthat  have \nbeen  added \nto \nthe  ECS \nre-\nsponses",
          "May help in situations where the conversations are not required \nto be lengthy and engaging": "Enforces the presence of empathetic reactions in the ECS re-\nsponses",
          "[70]": "[29]"
        },
        {
          "Response Types": "Affective Match-\ning Mechanisms",
          "Preset response templates differ \nby  the  context  of the  user mes-\nsages": "Matching  or  mirroring  the  emo-\ntional state of the user",
          "May help in situations where the conversations are not required \nto be lengthy and engaging": "When emotional consensus is reached between the user and \nECS agent, the quality of empathetic conversations seems to \nimprove",
          "[70]": "[58], [75]"
        },
        {
          "Response Types": "User Feedback",
          "Preset response templates differ \nby  the  context  of the  user mes-\nsages": "Feedback  about  the  responses \ngenerated by the ECS agents",
          "May help in situations where the conversations are not required \nto be lengthy and engaging": "Through  either  active  or  adversarial  learning,  the  conversa-\ntions are tailored according to user feedback so that more ef-\nfective empathy is exhibited",
          "[70]": "[62], \n[63], \n[76], \n[77]"
        }
      ],
      "page": 6
    },
    {
      "caption": "Table 4: the ECS evaluation, i.e., whether the proposed model has MODEL VARIATIONS IN EMPATHETICDIALOGUES",
      "data": [
        {
          "Model": "",
          "Response \nSource": "",
          "Architecture": "Re-\ntrieval"
        },
        {
          "Model": "Pretrained",
          "Response \nSource": "R",
          "Architecture": "M1"
        },
        {
          "Model": "",
          "Response \nSource": "ED",
          "Architecture": "M4"
        },
        {
          "Model": "Fine-tuned",
          "Response \nSource": "ED",
          "Architecture": "M7"
        },
        {
          "Model": "",
          "Response \nSource": "ED+DD",
          "Architecture": "M10"
        },
        {
          "Model": "",
          "Response \nSource": "ED+DD+R",
          "Architecture": "M13"
        },
        {
          "Model": "Emopre-\npend-1",
          "Response \nSource": "ED",
          "Architecture": "M16"
        },
        {
          "Model": "Topicpre-\npend-1",
          "Response \nSource": "ED",
          "Architecture": "M19"
        }
      ],
      "page": 11
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Conversational AI: Dialogue Systems, Conversational Agents, and Chatbots",
      "authors": [
        "M Mctear"
      ],
      "year": "2020",
      "venue": "Conversational AI: Dialogue Systems, Conversational Agents, and Chatbots",
      "doi": "10.2200/S01060ED1V01Y202010HLT048"
    },
    {
      "citation_id": "2",
      "title": "Conversational Agents in Software Engineering: Survey, Taxonomy and Challenges",
      "authors": [
        "Q Motger",
        "X Franch",
        "J Marco"
      ],
      "venue": "Conversational Agents in Software Engineering: Survey, Taxonomy and Challenges"
    },
    {
      "citation_id": "3",
      "title": "The human side of humanchatbot interaction: A systematic literature review of ten years of research on text-based chatbots",
      "authors": [
        "A Rapp",
        "L Curti",
        "A Boldi"
      ],
      "venue": "Int. J. Hum. Comput. Stud",
      "doi": "10.1016/j.ijhcs.2021.102630"
    },
    {
      "citation_id": "4",
      "title": "Chatbots: History, technology, and applications",
      "authors": [
        "E Adamopoulou",
        "L Moussiades"
      ],
      "year": "2020",
      "venue": "Mach. Learn. with Appl",
      "doi": "10.1016/j.mlwa.2020.100006"
    },
    {
      "citation_id": "5",
      "title": "A Survey on Dialogue Systems: Recent Advances and New Frontiers",
      "authors": [
        "H Chen",
        "X Liu",
        "D Yin",
        "J Tang"
      ],
      "year": "2017",
      "venue": "ACM SIGKDD Explor. Newsl",
      "doi": "10.1145/3166054.3166058"
    },
    {
      "citation_id": "6",
      "title": "Advances and challenges in conversational recommender systems: A survey",
      "authors": [
        "C Gao",
        "W Lei",
        "X He",
        "M De Rijke",
        "T.-S Chua"
      ],
      "year": "2021",
      "venue": "AI Open",
      "doi": "10.1016/j.aiopen.2021.06.002"
    },
    {
      "citation_id": "7",
      "title": "A Theoretical Framework for Conversational Search",
      "authors": [
        "F Radlinski",
        "N Craswell"
      ],
      "year": "2017",
      "venue": "Proceedings of the 2017 Conference on Conference Human Information Interaction and Retrieval",
      "doi": "10.1145/3020165.3020183"
    },
    {
      "citation_id": "8",
      "title": "Conversational Question Answering: A Survey",
      "authors": [
        "M Zaib",
        "W Zhang",
        "Q Sheng",
        "A Mahmood",
        "Y Zhang"
      ],
      "venue": "Conversational Question Answering: A Survey"
    },
    {
      "citation_id": "9",
      "title": "It seemed like an annoying woman ': On the Perception and Ethical Considerations of Affective Language in Text-Based Conversational Agents",
      "authors": [
        "L Vanderlyn",
        "G Weber",
        "M Neumann",
        "V Dirk",
        "S Meyer",
        "N Vu"
      ],
      "year": "2021",
      "venue": "Proceedings of the 25th Conference on Computational Natural Language Learning"
    },
    {
      "citation_id": "10",
      "title": "The Impact of Information-Seeking Strategies and Social Presence on the Interaction between Customers and Conversational Agents",
      "authors": [
        "T Nguyen"
      ],
      "year": "2020",
      "venue": "The Impact of Information-Seeking Strategies and Social Presence on the Interaction between Customers and Conversational Agents"
    },
    {
      "citation_id": "11",
      "title": "Humanizing chatbots: The effects of visual, identity and conversational cues on humanness perceptions",
      "authors": [
        "E Go",
        "S Sundar"
      ],
      "year": "2019",
      "venue": "Comput. Human Behav",
      "doi": "10.1016/J.CHB.2019.01.020"
    },
    {
      "citation_id": "12",
      "title": "Emotionally-Aware Chatbots: A Survey",
      "authors": [
        "E Pamungkas"
      ],
      "year": "2019",
      "venue": "Emotionally-Aware Chatbots: A Survey"
    },
    {
      "citation_id": "13",
      "title": "Sentiment Analysis: From Opinion Mining to Human-Agent Interaction",
      "authors": [
        "C Clavel",
        "Z Callejas"
      ],
      "year": "2016",
      "venue": "IEEE Trans. Affect. Comput",
      "doi": "10.1109/TAFFC.2015.2444846"
    },
    {
      "citation_id": "14",
      "title": "A Survey of Textual Emotion Recognition and Its Challenges",
      "authors": [
        "J Deng",
        "F Ren"
      ],
      "year": "2021",
      "venue": "IEEE Trans. Affect. Comput",
      "doi": "10.1109/TAFFC.2021.3053275"
    },
    {
      "citation_id": "15",
      "title": "Should Machines Express Sympathy and Empathy? Experiments with a Health Advice Chatbot",
      "authors": [
        "B Liu",
        "S Sundar"
      ],
      "year": "2018",
      "venue": "Cyberpsychology, Behav. Soc. Netw",
      "doi": "10.1089/cyber.2018.0110"
    },
    {
      "citation_id": "16",
      "title": "Artificial empathy in marketing interactions: Bridging the human-AI gap in affective and social customer experience",
      "authors": [
        "Y Liu-Thompkins",
        "S Okazaki",
        "H Li"
      ],
      "year": "2022",
      "venue": "J. Acad. Mark. Sci",
      "doi": "10.1007/S11747-022-00892-5"
    },
    {
      "citation_id": "17",
      "title": "Empathy: A Review of the Concept",
      "authors": [
        "B Cuff",
        "S Brown",
        "L Taylor",
        "D Howat"
      ],
      "year": "2016",
      "venue": "Emot. Rev",
      "doi": "10.1177/1754073914558466"
    },
    {
      "citation_id": "18",
      "title": "The Role of Empathy in Improving Intergroup Relations",
      "authors": [
        "W Stephan",
        "K Finlay"
      ],
      "year": "1999",
      "venue": "J. Soc. Issues",
      "doi": "10.1111/0022-4537.00144"
    },
    {
      "citation_id": "19",
      "title": "Fostering prosocial behavior and empathy in young children",
      "authors": [
        "T Spinrad",
        "D Gal"
      ],
      "year": "2018",
      "venue": "Curr. Opin. Psychol",
      "doi": "10.1016/J.COPSYC.2017.08.004"
    },
    {
      "citation_id": "20",
      "title": "Situational determinants of cognitive, affective, and compassionate empathy in naturalistic digital interactions",
      "authors": [
        "P Powell",
        "J Roberts"
      ],
      "year": "2017",
      "venue": "Comput. Human Behav",
      "doi": "10.1016/j.chb.2016.11.024"
    },
    {
      "citation_id": "21",
      "title": "A computational model of empathy for interactive agents",
      "authors": [
        " Yalcin",
        "S Dipaola"
      ],
      "year": "2018",
      "venue": "Biol. Inspired Cogn. Archit",
      "doi": "10.1016/j.bica.2018.07.010"
    },
    {
      "citation_id": "22",
      "title": "Modeling empathy: building a link between affective and cognitive processes",
      "authors": [
        " Yaln",
        "S Dipaola"
      ],
      "year": "2020",
      "venue": "Artif. Intell. Rev",
      "doi": "10.1007/s10462-019-09753-0"
    },
    {
      "citation_id": "23",
      "title": "Recent Advances in Deep Learning Based Dialogue Systems: A Systematic Survey",
      "authors": [
        "J Ni",
        "T Young",
        "V Pandelea",
        "F Xue",
        "V Adiga",
        "E Cambria"
      ],
      "venue": "Recent Advances in Deep Learning Based Dialogue Systems: A Systematic Survey"
    },
    {
      "citation_id": "24",
      "title": "Towards empathetic open-domain conversation models: A new benchmark and dataset",
      "authors": [
        "H Rashkin",
        "E Smith",
        "M Li",
        "Y Boureau"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/p19-1534"
    },
    {
      "citation_id": "25",
      "title": "Towards Persona-Based Empathetic Conversational Models",
      "authors": [
        "P Zhong",
        "C Zhang",
        "H Wang",
        "Y Liu",
        "C Miao"
      ],
      "year": "2020",
      "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing",
      "doi": "10.18653/v1/2020.emnlp-main.531"
    },
    {
      "citation_id": "26",
      "title": "Towards an Online Empathetic Chatbot with Emotion Causes",
      "authors": [
        "Y Li"
      ],
      "year": "2021",
      "venue": "Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval",
      "doi": "10.1145/3404835.3463042"
    },
    {
      "citation_id": "27",
      "title": "Generating Empathetic Responses with a Large Scale Dialog Dataset",
      "authors": [
        "Y Xie",
        "P Pu"
      ],
      "venue": "Generating Empathetic Responses with a Large Scale Dialog Dataset"
    },
    {
      "citation_id": "28",
      "title": "A Large-Scale Dataset for Empathetic Response Generation",
      "authors": [
        "A Welivita",
        "Y Xie",
        "P Pu"
      ],
      "year": "2021",
      "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "29",
      "title": "Exemplars-guided Empathetic Response Generation Controlled by the Elements of Human Communication",
      "authors": [
        "N Majumder",
        "D Ghosal",
        "D Hazarika",
        "A Gelbukh",
        "R Mihalcea",
        "S Poria"
      ],
      "venue": "Exemplars-guided Empathetic Response Generation Controlled by the Elements of Human Communication"
    },
    {
      "citation_id": "30",
      "title": "CoMAE: A Multi-factor Hierarchical Framework for Empathetic Response Generation",
      "authors": [
        "C Zheng",
        "Y Liu",
        "W Chen",
        "Y Leng",
        "M Huang"
      ],
      "year": "2021",
      "venue": "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
      "doi": "10.18653/v1/2021.findings-acl.72"
    },
    {
      "citation_id": "31",
      "title": "Survey on evaluation methods for dialogue systems",
      "authors": [
        "J Deriu"
      ],
      "year": "2021",
      "venue": "Artif. Intell. Rev",
      "doi": "10.1007/S10462-020-09866-X"
    },
    {
      "citation_id": "32",
      "title": "Empathy framework for embodied conversational agents",
      "authors": [
        " Yaln"
      ],
      "year": "2020",
      "venue": "Cogn. Syst. Res",
      "doi": "10.1016/j.cogsys.2019.09.016"
    },
    {
      "citation_id": "33",
      "title": "Empathy in Virtual Agents and Robots: A Survey",
      "authors": [
        "A Paiva",
        "I Leite",
        "H Boukricha",
        "I Wachsmuth"
      ],
      "year": "2017",
      "venue": "ACM Trans. Interact. Intell. Syst",
      "doi": "10.1145/2912150"
    },
    {
      "citation_id": "34",
      "title": "Empathic Response Generation in Chatbots",
      "authors": [
        "T Spring",
        "J Casas",
        "K Daher",
        "E Mugellini",
        "O Khaled"
      ],
      "year": "2019",
      "venue": "CEUR Workshop Proceedings"
    },
    {
      "citation_id": "35",
      "title": "A survey on empathetic dialogue systems",
      "authors": [
        "Y Ma",
        "K Nguyen",
        "F Xing",
        "E Cambria"
      ],
      "year": "2020",
      "venue": "Inf. Fusion",
      "doi": "10.1016/j.inffus.2020.06.011"
    },
    {
      "citation_id": "36",
      "title": "Empathetic Chatbot Enhancement and Development: A Literature Review",
      "authors": [
        "A Wardhana",
        "R Ferdiana",
        "I Hidayah"
      ],
      "year": "2021",
      "venue": "2021 International Conference on Artificial Intelligence and Mechatronics Systems (AIMS)",
      "doi": "10.1109/aims52415.2021.9466027"
    },
    {
      "citation_id": "37",
      "title": "Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory",
      "authors": [
        "H Zhou",
        "M Huang",
        "T Zhang",
        "X Zhu",
        "B Liu"
      ],
      "year": "2018",
      "venue": "32nd AAAI Conference on Artificial Intelligence, AAAI 2018"
    },
    {
      "citation_id": "38",
      "title": "Alexa Prize SocialBot Grand Challenge -Amazon Science",
      "year": "2022",
      "venue": "Alexa Prize SocialBot Grand Challenge -Amazon Science"
    },
    {
      "citation_id": "39",
      "title": "Genuine2: An open domain chatbot based on generative models -Amazon Science",
      "authors": [
        "M Rodrguez-Cantelar",
        "D De La Cal",
        "M Estecha",
        "D Martn",
        "N Milara",
        "R Jimnez"
      ],
      "year": "2022",
      "venue": "Genuine2: An open domain chatbot based on generative models -Amazon Science"
    },
    {
      "citation_id": "40",
      "title": "Neural, neural everywhere: Controlled generation meets scaffolded, structured dialogue -Amazon Science",
      "authors": [
        "E Chi"
      ],
      "year": "2022",
      "venue": "Neural, neural everywhere: Controlled generation meets scaffolded, structured dialogue -Amazon Science"
    },
    {
      "citation_id": "41",
      "title": "The relationship between leadership and follower in role performance and satisfaction with the leader: The mediating effects of empowerment and trust in the leader",
      "authors": [
        "T Bartram",
        "G Casimir"
      ],
      "year": "2007",
      "venue": "Leadersh. Organ. Dev. J",
      "doi": "10.1108/01437730710718218/FULL/XML"
    },
    {
      "citation_id": "42",
      "title": "Examination of the neural substrates activated in memories of experiences with resonant and dissonant leaders",
      "authors": [
        "R Boyatzis"
      ],
      "year": "2012",
      "venue": "Leadersh. Q",
      "doi": "10.1016/J.LEAQUA.2011.08.003"
    },
    {
      "citation_id": "43",
      "title": "Why it Pays to Get Inside the Head of Your Opponent: The Differential Effects of Perspective Taking and Empathy in Negotiations: Research article",
      "authors": [
        "A Galinsky",
        "W Maddux",
        "D Gilin",
        "J White"
      ],
      "year": "2008",
      "venue": "Psychol. Sci",
      "doi": "10.1111/j.1467-9280.2008.02096.x"
    },
    {
      "citation_id": "44",
      "title": "The Focused Leader",
      "authors": [
        "D Goleman"
      ],
      "year": "2013",
      "venue": "Harvard Business Review"
    },
    {
      "citation_id": "45",
      "title": "Emotional Intelligence: Why It Can Matter More Than IQ. New Work: Bantam Books",
      "authors": [
        "D Goleman"
      ],
      "year": "1995",
      "venue": "Emotional Intelligence: Why It Can Matter More Than IQ. New Work: Bantam Books"
    },
    {
      "citation_id": "46",
      "title": "The 'Russian doll' model of empathy and imitation",
      "authors": [
        "F De Waal"
      ],
      "year": "2007",
      "venue": "On Being Moved: From mirror neurons to empathy, S. Brten"
    },
    {
      "citation_id": "47",
      "title": "Modeling Empathy in Embodied Conversational Agents: Extended Abstract",
      "authors": [
        "O Yaln"
      ],
      "year": "2018",
      "venue": "Proceedings of the 20th ACM International Conference on Multimodal Interaction",
      "doi": "10.1145/3242969.3264977"
    },
    {
      "citation_id": "48",
      "title": "Conceptual Design of a Socially Intelligent Agent with Triadic Empathy and Theory of Mind for Mental Health Support",
      "authors": [
        "A Aziz",
        "M Jemili"
      ],
      "year": "2022",
      "venue": "J. Hum. Centered Technol",
      "doi": "10.11113/HUMENTECH.V1N1.12"
    },
    {
      "citation_id": "49",
      "title": "Intention, Plans, and Practical Reason",
      "authors": [
        "M Bratman"
      ],
      "year": "1999",
      "venue": "Intention, Plans, and Practical Reason"
    },
    {
      "citation_id": "50",
      "title": "Differential role of the orbital frontal lobe in emotional versus cognitive perspective-taking",
      "authors": [
        "C Hynes",
        "A Baird",
        "S Grafton"
      ],
      "year": "2006",
      "venue": "Neuropsychologia",
      "doi": "10.1016/J.NEUROPSYCHOLOGIA.2005.06.011"
    },
    {
      "citation_id": "51",
      "title": "SemEval-2018 Task 1: Affect in Tweets",
      "authors": [
        "S Mohammad",
        "F Bravo-Marquez",
        "M Salameh",
        "S Kiritchenko"
      ],
      "year": "2018",
      "venue": "Proceedings of the 12th International Workshop on Semantic Evaluation",
      "doi": "10.18653/V1/S18-1001"
    },
    {
      "citation_id": "52",
      "title": "Are They Different? Affect, Feeling, Emotion, Sentiment, and Opinion Detection in Text",
      "authors": [
        "M Munezero",
        "C Montero",
        "E Sutinen",
        "J Pajunen"
      ],
      "year": "2014",
      "venue": "IEEE Trans. Affect. Comput",
      "doi": "10.1109/TAFFC.2014.2317187"
    },
    {
      "citation_id": "53",
      "title": "EmpBot: A T5-based Empathetic Chatbot focusing on Sentiments",
      "authors": [
        "E Zaranis",
        "G Paraskevopoulos",
        "A Katsamanis",
        "A Potamianos"
      ],
      "venue": "EmpBot: A T5-based Empathetic Chatbot focusing on Sentiments"
    },
    {
      "citation_id": "54",
      "title": "LENNA (Learning Emotions Neural Network Assisted): An Empathic Chatbot Designed to Study the Simulation of Emotions in a Bot and Their Analysis in a Conversation",
      "authors": [
        "R Lahoz-Beltra",
        "C Lpez"
      ],
      "year": "2021",
      "venue": "Computers",
      "doi": "10.3390/COMPUTERS10120170"
    },
    {
      "citation_id": "55",
      "title": "Generating Personalized Dialogues Based on Conversation Log Summarization and Sentiment Analysis",
      "authors": [
        "S Chen",
        "M Nakamura"
      ],
      "year": "2021",
      "venue": "iiWAS2021: The 23rd International Conference on Information Integration and Web Intelligence",
      "doi": "10.1145/3487664.3487695"
    },
    {
      "citation_id": "56",
      "title": "CrystalFeel at SemEval-2018 Task 1: Understanding and Detecting Emotion Intensity using Affective Lexicons",
      "authors": [
        "R Gupta",
        "Y Yang"
      ],
      "year": "2018",
      "venue": "Proceedings of The 12th International Workshop on Semantic Evaluation",
      "doi": "10.18653/V1/S18-1038"
    },
    {
      "citation_id": "57",
      "title": "GoEmotions: A Dataset of Fine-Grained Emotions",
      "authors": [
        "D Demszky",
        "D Movshovitz-Attias",
        "J Ko",
        "A Cowen",
        "G Nemade",
        "S Ravi"
      ],
      "year": "2020",
      "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/V1/2020.ACL-MAIN.372"
    },
    {
      "citation_id": "58",
      "title": "MIME: MIMicking Emotions for Empathetic Response Generation",
      "authors": [
        "N Majumder"
      ],
      "year": "2020",
      "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing",
      "doi": "10.18653/v1/2020.emnlp-main.721"
    },
    {
      "citation_id": "59",
      "title": "MOEL: Mixture of Empathetic Listeners",
      "authors": [
        "Z Lin",
        "A Madotto",
        "J Shin",
        "P Xu",
        "P Fung"
      ],
      "year": "2020",
      "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
      "doi": "10.18653/v1/d19-1012"
    },
    {
      "citation_id": "60",
      "title": "Improving Empathetic Response Generation by Recognizing Emotion Cause in Conversations",
      "authors": [
        "J Gao"
      ],
      "year": "2021",
      "venue": "Findings of the Association for Computational Linguistics: EMNLP 2021"
    },
    {
      "citation_id": "61",
      "title": "Perspective-taking and Pragmatics for Generating Empathetic Responses Focused on Emotion Causes",
      "authors": [
        "H Kim",
        "B Kim",
        "G Kim"
      ],
      "year": "2021",
      "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing"
    },
    {
      "citation_id": "62",
      "title": "CAiRE: An Empathetic Neural Chatbot",
      "authors": [
        "Z Lin"
      ],
      "year": "2019",
      "venue": "CAiRE: An Empathetic Neural Chatbot"
    },
    {
      "citation_id": "63",
      "title": "CAiRE: An End-to-End Empathetic Chatbot",
      "authors": [
        "Z Lin"
      ],
      "year": "2020",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence",
      "doi": "10.18653/v1/2020.acl-main.185"
    },
    {
      "citation_id": "64",
      "title": "An Empathetic AI Coach for Self-Attachment Therapy",
      "authors": [
        "L Alazraki",
        "A Ghachem",
        "N Polydorou",
        "F Khosmood",
        "A Edalat"
      ],
      "year": "2022",
      "venue": "The Third IEEE International Conference on Cognitive Machine Intelligence"
    },
    {
      "citation_id": "65",
      "title": "Multimodal Learning for Identifying Opportunities for Empathetic Responses",
      "authors": [
        "L Tavabi",
        "K Stefanov",
        "S Gilani",
        "D Traum",
        "M Soleymani"
      ],
      "year": "2019",
      "venue": "2019 International Conference on Multimodal Interaction",
      "doi": "10.1145/3340555.3353750"
    },
    {
      "citation_id": "66",
      "title": "EP-Bot: Empathetic Chatbot Using Auto-Growing Knowledge Graph",
      "authors": [
        "S Yoo",
        "O Jeong"
      ],
      "year": "2021",
      "venue": "Comput. Mater. Contin",
      "doi": "10.32604/cmc.2021.015634"
    },
    {
      "citation_id": "67",
      "title": "CEM: Commonsenseaware Empathetic Response Generation",
      "authors": [
        "S Sabour",
        "C Zheng",
        "M Huang"
      ],
      "venue": "CEM: Commonsenseaware Empathetic Response Generation"
    },
    {
      "citation_id": "68",
      "title": "Empathetic Dialogue Generation with Pre-trained RoBERTa-GPT2 and External Knowledge",
      "authors": [
        "Y Liu",
        "W Maier",
        "W Minker",
        "S Ultes"
      ],
      "venue": "Empathetic Dialogue Generation with Pre-trained RoBERTa-GPT2 and External Knowledge"
    },
    {
      "citation_id": "69",
      "title": "Knowledge Bridging for Empathetic Dialogue Generation",
      "authors": [
        "Q Li",
        "P Li",
        "Z Ren",
        "P Ren",
        "Z Chen"
      ],
      "year": "2021",
      "venue": "Knowledge Bridging for Empathetic Dialogue Generation"
    },
    {
      "citation_id": "70",
      "title": "M-Path: A Conversational System for the Empathic Virtual Agent",
      "authors": [
        " Yaln",
        "S Dipaola"
      ],
      "year": "2019",
      "venue": "Biologically Inspired Cognitive Architectures",
      "doi": "10.1007/978-3-030-25719-4_78"
    },
    {
      "citation_id": "71",
      "title": "Generating Empathetic Responses by Injecting Anticipated Emotion",
      "authors": [
        "Y Liu",
        "J Du",
        "X Li",
        "R Xu"
      ],
      "year": "2021",
      "venue": "ICASSP 2021 -2021 IEEE International Conference on Acoustics, Speech and Signal Processing",
      "doi": "10.1109/ICASSP39728.2021.9413596"
    },
    {
      "citation_id": "72",
      "title": "CheerBots: Chatbots toward Empathy and Emotionusing Reinforcement Learning",
      "authors": [
        "J.-H Jhan",
        "C.-P Liu",
        "S.-K Jeng",
        "H.-Y Lee"
      ],
      "venue": "CheerBots: Chatbots toward Empathy and Emotionusing Reinforcement Learning"
    },
    {
      "citation_id": "73",
      "title": "Generating Empathetic Responses by Looking Ahead the User's Sentiment",
      "authors": [
        "J Shin",
        "P Xu",
        "A Madotto",
        "P Fung"
      ],
      "year": "2020",
      "venue": "ICASSP 2020 -2020 IEEE International Conference on Acoustics, Speech and Signal Processing",
      "doi": "10.1109/ICASSP40776.2020.9054379"
    },
    {
      "citation_id": "74",
      "title": "Retrieve, Discriminate and Rewrite: A Simple and Effective Framework for Obtaining Affective Response in Retrieval-Based Chatbots",
      "authors": [
        "X Lu",
        "Y Tian",
        "Y Zhao",
        "B Qin"
      ],
      "year": "2021",
      "venue": "Findings of the Association for Computational Linguistics: EMNLP 2021"
    },
    {
      "citation_id": "75",
      "title": "Constructing Emotion Consensus and Utilizing Unpaired Data for Empathetic Dialogue Generation",
      "authors": [
        "L Shen",
        "J Zhang",
        "J Ou",
        "X Zhao",
        "J Zhou"
      ],
      "year": "2021",
      "venue": "Findings of the Association for Computational Linguistics: EMNLP 2021"
    },
    {
      "citation_id": "76",
      "title": "A Multi-resolution Mechanism with Multiple Decoders for Empathetic Dialogue Generation",
      "authors": [
        "M Ayshabi",
        "S Idicula"
      ],
      "year": "2021",
      "venue": "2021 8th International Conference on Smart Computing and Communications (ICSCC)",
      "doi": "10.1109/ICSCC51209.2021.9528254"
    },
    {
      "citation_id": "77",
      "title": "EmpDG: Multi-resolution Interactive Empathetic Dialogue Generation",
      "authors": [
        "Q Li",
        "H Chen",
        "Z Ren",
        "P Ren",
        "Z Tu",
        "Z Chen"
      ],
      "year": "2020",
      "venue": "Proceedings of the 28th International Conference on Computational Linguistics",
      "doi": "10.18653/v1/2020.coling-main.394"
    },
    {
      "citation_id": "78",
      "title": "SemEval-2016 Task 5: Aspect Based Sentiment Analysis",
      "authors": [
        "M Pontiki"
      ],
      "year": "2016",
      "venue": "SemEval 2016 -10th International Workshop on Semantic Evaluation, Proceedings",
      "doi": "10.18653/V1/S16-1002"
    },
    {
      "citation_id": "79",
      "title": "Deep Learning for Aspect-Based Sentiment Analysis: A Comparative Review",
      "authors": [
        "H Do",
        "P Prasad",
        "A Maag",
        "A Alsadoon"
      ],
      "year": "2019",
      "venue": "Expert Syst. Appl",
      "doi": "10.1016/j.eswa.2018.10.003"
    },
    {
      "citation_id": "80",
      "title": "Recent Neural Methods on Slot Filling and Intent Classification for Task-Oriented Dialogue Systems: A Survey",
      "authors": [
        "S Louvan",
        "B Magnini"
      ],
      "year": "2020",
      "venue": "Proceedings of the 28th International Conference on Computational Linguistics",
      "doi": "10.18653/V1/2020.COLING-MAIN.42"
    },
    {
      "citation_id": "81",
      "title": "A Persona-Based Neural Conversation Model",
      "authors": [
        "J Li",
        "M Galley",
        "C Brockett",
        "G Spithourakis",
        "J Gao",
        "B Dolan"
      ],
      "year": "2016",
      "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/P16-1094"
    },
    {
      "citation_id": "82",
      "title": "Personality and Persona: Personality Processes in Self-Presentation",
      "authors": [
        "M Leary",
        "A Allen"
      ],
      "year": "2011",
      "venue": "J. Pers",
      "doi": "10.1111/J.1467-6494.2010.00704.X"
    },
    {
      "citation_id": "83",
      "title": "Associations between Medical Student Empathy and Personality: A Multi-Institutional Study",
      "authors": [
        "P Costa",
        "R Alves",
        "I Neto",
        "P Marvo",
        "M Portela",
        "M Costa"
      ],
      "year": "2014",
      "venue": "PLoS One",
      "doi": "10.1371/JOURNAL.PONE.0089254"
    },
    {
      "citation_id": "84",
      "title": "Affect Detection: An Interdisciplinary Review of Models, Methods, and Their Applications",
      "authors": [
        "R Calvo",
        "S Mello"
      ],
      "year": "2010",
      "venue": "IEEE Trans. Affect. Comput",
      "doi": "10.1109/T-AFFC.2010.1"
    },
    {
      "citation_id": "85",
      "title": "A Review and Meta-Analysis of Multimodal Affect Detection Systems",
      "authors": [
        "S Mello",
        "J Kory"
      ],
      "year": "2015",
      "venue": "ACM Comput. Surv",
      "doi": "10.1145/2682899"
    },
    {
      "citation_id": "86",
      "title": "Exploring the contextual factors affecting multimodal emotion recognition in videos",
      "authors": [
        "P Bhattacharya",
        "R Gupta",
        "Y Yang"
      ],
      "year": "2021",
      "venue": "IEEE Trans. Affect. Comput",
      "doi": "10.1109/TAFFC.2021.3071503"
    },
    {
      "citation_id": "87",
      "title": "A Computational Approach to Understanding Empathy Expressed in Text-Based Mental Health Support",
      "authors": [
        "A Sharma",
        "A Miner",
        "D Atkins",
        "T Althoff"
      ],
      "year": "2020",
      "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing",
      "doi": "10.18653/v1/2020.emnlp-main.425"
    },
    {
      "citation_id": "88",
      "title": "ConceptNet 5.5: An Open Multilingual Graph of General Knowledge",
      "authors": [
        "R Speer",
        "J Chin",
        "C Havasi"
      ],
      "year": "2017",
      "venue": "Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence"
    },
    {
      "citation_id": "89",
      "title": "Automating the expansion of a knowledge graph",
      "authors": [
        "S Yoo",
        "O Jeong"
      ],
      "year": "2020",
      "venue": "Expert Syst. Appl",
      "doi": "10.1016/J.ESWA.2019.112965"
    },
    {
      "citation_id": "90",
      "title": "ATOMIC: An Atlas of Machine Commonsense for If-Then Reasoning",
      "authors": [
        "M Sap"
      ],
      "year": "2019",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence",
      "doi": "10.1609/AAAI.V33I01.33013027"
    },
    {
      "citation_id": "91",
      "title": "Talk with CAiRE Chatbot",
      "year": "2022",
      "venue": "Talk with CAiRE Chatbot"
    },
    {
      "citation_id": "92",
      "title": "Carl: An Empathetic Chatbot",
      "authors": [
        "G Sheen"
      ],
      "year": "2020",
      "venue": "Carl: An Empathetic Chatbot"
    },
    {
      "citation_id": "93",
      "title": "Empathetic BERT2BERT Conversational Model: Learning Arabic Language Generation with Little Data",
      "authors": [
        "T Naous",
        "W Antoun",
        "R Mahmoud",
        "H Hajj"
      ],
      "year": "2021",
      "venue": "Proceedings of the Sixth Arabic Natural Language Processing Workshop"
    },
    {
      "citation_id": "94",
      "title": "Empathy-driven arabic conversational chatbot",
      "authors": [
        "T Naous",
        "C Hokayem",
        "H Hajj"
      ],
      "year": "2020",
      "venue": "Proceedings of the Fifth Arabic Natural Language Processing Workshop"
    },
    {
      "citation_id": "95",
      "title": "CARO: An Empathetic Health Conversational Chatbot for People with Major Depression",
      "authors": [
        "N Harilal",
        "R Shah",
        "S Sharma",
        "V Bhutani"
      ],
      "year": "2020",
      "venue": "Proceedings of the 7th ACM IKDD CoDS and 25th COMAD",
      "doi": "10.1145/3371158.3371220"
    },
    {
      "citation_id": "96",
      "title": "An Empathetic Conversational Agent with Attentional Mechanism",
      "authors": [
        "R Goel",
        "S Vashisht",
        "A Dhanda",
        "S Susan"
      ],
      "year": "2021",
      "venue": "2021 International Conference on Computer Communication and Informatics, ICCCI 2021",
      "doi": "10.1109/ICCCI50826.2021.9402337"
    },
    {
      "citation_id": "97",
      "title": "Enhancing Conversational Agents with Empathic Abilities",
      "authors": [
        "J Casas",
        "T Spring",
        "K Daher",
        "E Mugellini",
        "O Khaled",
        "P Cudr-Mauroux"
      ],
      "year": "2021",
      "venue": "Proceedings of the 21th ACM International Conference on Intelligent Virtual Agents",
      "doi": "10.1145/3472306.3478344"
    },
    {
      "citation_id": "98",
      "title": "Evaluator for Emotionally Consistent Chatbots",
      "authors": [
        "C Liu",
        "G Deng",
        "T Ji",
        "D Tang",
        "S Zheng"
      ],
      "year": "2021",
      "venue": "Evaluator for Emotionally Consistent Chatbots"
    },
    {
      "citation_id": "99",
      "title": "DailyDialog: A Manually Labelled Multi-turn Dialogue Dataset",
      "authors": [
        "Y Li",
        "H Su",
        "X Shen",
        "W Li",
        "Z Cao",
        "S Niu"
      ],
      "year": "2017",
      "venue": "Proceedings ofthe The 8th International Joint Conference on Natural Language Processing"
    },
    {
      "citation_id": "100",
      "title": "EmpTransfo: A multi-head transformer architecture for creating empathetic dialog systems",
      "authors": [
        "R Zandie",
        "M Mahoor"
      ],
      "year": "2020",
      "venue": "Proceedings of the 33rd International Florida Artificial Intelligence Research Society Conference, FLAIRS 2020"
    },
    {
      "citation_id": "101",
      "title": "Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books",
      "authors": [
        "Y Zhu"
      ],
      "year": "2015",
      "venue": "Proceedings of the 2015 IEEE International Conference on Computer Vision (ICCV)",
      "doi": "10.1109/ICCV.2015.11"
    },
    {
      "citation_id": "102",
      "title": "Personalizing Dialogue Agents: I have a dog, do you have pets too?",
      "authors": [
        "S Zhang",
        "E Dinan",
        "J Urbanek",
        "A Szlam",
        "D Kiela",
        "J Weston"
      ],
      "year": "2018",
      "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/p18-1205"
    },
    {
      "citation_id": "103",
      "title": "A Taxonomy of Empathetic Response Intents in Human Social Conversations",
      "authors": [
        "A Welivita",
        "P Pu"
      ],
      "year": "2021",
      "venue": "Proceedings of the 28th International Conference on Computational Linguistics",
      "doi": "10.18653/v1/2020.coling-main.429"
    },
    {
      "citation_id": "104",
      "title": "OpenSubtitles2016: Extracting Large Parallel Corpora from Movie and Subtitles",
      "authors": [
        "P Lison",
        "J Tiedemann"
      ],
      "year": "2016",
      "venue": "Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16)"
    },
    {
      "citation_id": "105",
      "title": "Sequential Matching Network: A New Architecture for Multi-turn Response Selection in Retrieval-Based Chatbots",
      "authors": [
        "Y Wu",
        "W Wu",
        "C Xing",
        "M Zhou",
        "Z Li"
      ],
      "year": "2017",
      "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/P17-1046"
    },
    {
      "citation_id": "106",
      "title": "Addressing 'Documentation Debt' in Machine Learning Research: A Retrospective Datasheet for BookCorpus",
      "authors": [
        "J Bandy",
        "N Vincent"
      ],
      "year": "2021",
      "venue": "Addressing 'Documentation Debt' in Machine Learning Research: A Retrospective Datasheet for BookCorpus"
    },
    {
      "citation_id": "107",
      "title": "The Conversational Interface: Talking to Smart Devices",
      "authors": [
        "M Mctear",
        "Z Callejas",
        "D Griol"
      ],
      "year": "2016",
      "venue": "The Conversational Interface: Talking to Smart Devices"
    },
    {
      "citation_id": "108",
      "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "authors": [
        "J Devlin",
        "M Chang",
        "K Lee",
        "K Toutanova"
      ],
      "year": "2019",
      "venue": "Proceedings of NAACL-HLT",
      "doi": "10.18653/v1/N19-1423"
    },
    {
      "citation_id": "109",
      "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach",
      "authors": [
        "Y Liu"
      ],
      "year": "2019",
      "venue": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"
    },
    {
      "citation_id": "110",
      "title": "Using millions of emoji occurrences to learn anydomain representations for detecting sentiment, emotion and sarcasm",
      "authors": [
        "B Felbo",
        "A Mislove",
        "A Sgaard",
        "I Rahwan",
        "S Lehmann"
      ],
      "year": "2017",
      "venue": "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
      "doi": "10.18653/v1/D17-1169"
    },
    {
      "citation_id": "111",
      "title": "VADER: A Parsimonious Rule-Based Model for Sentiment Analysis of Social Media Text",
      "authors": [
        "C Hutto",
        "E Gilbert"
      ],
      "year": "2014",
      "venue": "Eighth International AAAI Conference on Weblogs and Social Media"
    },
    {
      "citation_id": "112",
      "title": "An Information Retrieval Approach to Short Text Conversation",
      "authors": [
        "Z Ji",
        "Z Lu",
        "H Li"
      ],
      "year": "2014",
      "venue": "An Information Retrieval Approach to Short Text Conversation"
    },
    {
      "citation_id": "113",
      "title": "The Design and Implementation of XiaoIce, an Empathetic Social Chatbot",
      "authors": [
        "L Zhou",
        "J Gao",
        "D Li",
        "H Shum"
      ],
      "year": "2020",
      "venue": "Comput. Linguist",
      "doi": "10.1162/COLI_a_00368"
    },
    {
      "citation_id": "114",
      "title": "Attention is All You Need",
      "authors": [
        "A Vaswani"
      ],
      "year": "2017",
      "venue": "Proceedings of the 31st International Conference on Neural Information Processing Systems",
      "doi": "10.5555/3295222.3295349"
    },
    {
      "citation_id": "115",
      "title": "Improving Language Understanding by Generative Pre-Training",
      "authors": [
        "A Radford",
        "K Narasimhan",
        "T Salimans",
        "I Sutskever"
      ],
      "year": "2018",
      "venue": "Improving Language Understanding by Generative Pre-Training"
    },
    {
      "citation_id": "116",
      "title": "Sequence to Sequence Learning with Neural Networks",
      "authors": [
        "I Sutskever",
        "O Vinyals",
        "Q Le"
      ],
      "year": "2014",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "117",
      "title": "Language Models are Unsupervised Multitask Learners",
      "authors": [
        "A Radford",
        "J Wu",
        "R Child",
        "D Lua",
        "D Amodei",
        "L Sutskever"
      ],
      "year": "2019",
      "venue": "Language Models are Unsupervised Multitask Learners"
    },
    {
      "citation_id": "118",
      "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer",
      "authors": [
        "C Raffel"
      ],
      "year": "2020",
      "venue": "J. Mach. Learn. Res"
    },
    {
      "citation_id": "119",
      "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations",
      "authors": [
        "Z Lan",
        "M Chen",
        "S Goodman",
        "K Gimpel",
        "P Sharma",
        "R Soricut"
      ],
      "year": "2019",
      "venue": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"
    },
    {
      "citation_id": "120",
      "title": "DIALOGPT : Large-Scale Generative Pretraining for Conversational Response Generation",
      "authors": [
        "Y Zhang"
      ],
      "year": "2020",
      "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations",
      "doi": "10.18653/v1/2020.acl-demos.30"
    },
    {
      "citation_id": "121",
      "title": "BLEU: A Method for Automatic Evaluation of Machine Translation",
      "authors": [
        "K Papineni",
        "S Roukos",
        "T Ward",
        "W.-J Zhu"
      ],
      "year": "2002",
      "venue": "Proceedings of the 40th Annual Meeting on Association for Computational Linguistics",
      "doi": "10.3115/1073083.1073135"
    },
    {
      "citation_id": "122",
      "title": "A Comprehensive Assessment of Dialog Evaluation Metrics",
      "authors": [
        "Y.-T Yeh",
        "M Eskenazi",
        "S Mehri"
      ],
      "year": "2021",
      "venue": "The First Workshop on Evaluations and Assessments of Neural Conversation Systems",
      "doi": "10.18653/V1/2021.EANCS-1.3"
    },
    {
      "citation_id": "123",
      "title": "A Diversity-Promoting Objective Function for Neural Conversation Models",
      "authors": [
        "J Li",
        "M Galley",
        "C Brockett",
        "J Gao",
        "B Dolan"
      ],
      "year": "2016",
      "venue": "Proc. 2016 Conf. North Am",
      "doi": "10.18653/V1/N16-1014"
    },
    {
      "citation_id": "124",
      "title": "Learning Semantic Textual Similarity from Conversations",
      "authors": [
        "Y Yang"
      ],
      "year": "2018",
      "venue": "Proceedings of The Third Workshop on Representation Learning for NLP",
      "doi": "10.18653/V1/W18-3022"
    },
    {
      "citation_id": "125",
      "title": "A Probabilistic Analysis of the Rocchio Algorithm with TFIDF for Text Categorization",
      "authors": [
        "T Joachims"
      ],
      "year": "1996",
      "venue": "A Probabilistic Analysis of the Rocchio Algorithm with TFIDF for Text Categorization"
    },
    {
      "citation_id": "126",
      "title": "Recognizing Emotion Cause in Conversations",
      "authors": [
        "S Poria"
      ],
      "year": "2021",
      "venue": "Cognit. Comput",
      "doi": "10.1007/S12559-021-09925-7"
    },
    {
      "citation_id": "127",
      "title": "BERTScore: Evaluating Text Generation with BERT",
      "authors": [
        "T Zhang",
        "V Kishore",
        "F Wu",
        "K Weinberger",
        "Y Artzi"
      ],
      "year": "2019",
      "venue": "BERTScore: Evaluating Text Generation with BERT"
    },
    {
      "citation_id": "128",
      "title": "Obtaining Reliable Human Ratings of Valence, Arousal, and Dominance for 20,000 English Words",
      "authors": [
        "S Mohammad"
      ],
      "year": "2018",
      "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/V1/P18-1017"
    },
    {
      "citation_id": "129",
      "title": "Dual Latent Variable Model for Low-Resource Natural Language Generation in Dialogue Systems",
      "authors": [
        "V Tran",
        "L Nguyen"
      ],
      "year": "2018",
      "venue": "Proceedings of the 22nd Conference on Computational Natural Language Learning",
      "doi": "10.18653/V1/K18-1003"
    },
    {
      "citation_id": "130",
      "title": "Towards Facilitating Empathic Conversations in Online Mental Health Support: A Reinforcement Learning Approach",
      "authors": [
        "A Sharma",
        "I Lin",
        "A Miner",
        "D Atkins",
        "T Althoff"
      ],
      "year": "2021",
      "venue": "Proceedings of the Web Conference 2021",
      "doi": "10.1145/3442381.3450097"
    },
    {
      "citation_id": "131",
      "title": "Recipes for Building an Open-Domain Chatbot",
      "authors": [
        "S Roller"
      ],
      "year": "2021",
      "venue": "Proceedings of the 16th Conference of the European Chapter"
    },
    {
      "citation_id": "132",
      "title": "Blender Bot 2.0: An open source chatbot that builds long-term memory and searches the internet",
      "authors": [
        "J Weston",
        "K Shuster"
      ],
      "year": "2021",
      "venue": "Facebook AI"
    },
    {
      "citation_id": "133",
      "title": "Yinping Yang received the PhD degree in information systems from the National University of Singapore. She is currently a senior scientist and group manager with the Affective Computing Group, Social and Cognitive Computing Department, Institute of High Performance Computing, A*STAR",
      "venue": "Her research interests include intelligent negotiation systems, emotion recognition, and strategic foresight"
    }
  ]
}