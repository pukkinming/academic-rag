{
  "paper_id": "2504.20744v1",
  "title": "Db-Gnn: Dual-Branch Graph Neural Network With Multi-Level Contrastive Learning For Jointly Identifying Within-And Cross-Frequency Coupled Brain Networks",
  "published": "2025-04-29T13:24:37Z",
  "authors": [
    "Xiang Wang",
    "Hui Xu",
    "Jing Cai",
    "Ta Zhou",
    "Xibei Yang",
    "Wei Xue"
  ],
  "keywords": [
    "Electroencephalogram",
    "brain network identification",
    "contrastive learning",
    "intra-frequency and cross-frequency coupling",
    "emotion recognition"
  ],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Within-frequency coupling (WFC) and crossfrequency coupling (CFC) in brain networks reflect neural synchronization within the same frequency band and cross-band oscillatory interactions, respectively. Their synergy provides a comprehensive understanding of neural mechanisms underlying cognitive states such as emotion. However, existing multi-channel EEG studies often analyze WFC or CFC separately, failing to fully leverage their complementary properties. This study proposes a dual-branch graph neural network (DB-GNN) to jointly identify within-and cross-frequency coupled brain networks. Firstly, DB-GNN leverages its unique dual-branch learning architecture to efficiently mine global collaborative information and local crossfrequency and within-frequency coupling information. Secondly, to more fully perceive the global information of cross-frequency and within-frequency coupling, the global perception branch of DB-GNN adopts a Transformer architecture. To prevent overfitting of the Transformer architecture, this study integrates prior within-and cross-frequency coupling information into the Transformer inference process, thereby enhancing the generalization capability of DB-GNN. Finally, a multi-scale graph contrastive learning regularization term is introduced to constrain the global and local perception branches of DB-GNN at both graph-level and node-level, enhancing its joint perception ability and further improving its generalization performance. Experimental validation on the emotion recognition dataset shows that DB-GNN achieves a testing accuracy of 97.88% and an F1score of 97.87%, reaching the state-of-the-art performance.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "I. Introduction",
      "text": "Electroencephalography (EEG) has proven to be an invaluable tool for understanding the intricacies of brain function due to its ability to capture both high-temporalresolution neuronal oscillations in local brain areas and broader patterns of synchronization between different regions  [1] . These properties make EEG highly suitable for investigating the neural basis of complex phenomena such as emotions, which are inherently dynamic and involve complex interactions across brain networks  [2] .\n\nThe potential of multi-channel EEG in emotion recognition lies largely in its capacity to capture both within-frequency coupling (WFC) and cross-frequency coupling (CFC), which represent two distinct yet interconnected aspects of neural communication  [3] . The WFC reflects neural activity within the same frequency band, while the CFC captures the interplay between different frequency bands, both of which provide insights into how neural processes at different temporal scales interact to support cognitive and affective states  [4] . WFC has been associated with the processing of external sensory events  [5] , the internal attentional selection  [6] , and the emotional states  [7] . The CFC has been shown to contribute to the integration of information that leads to memory consolidation  [8] , and to emotion recognition due to its enriched information  [9] .\n\nAs shown in Fig.  1 , previous studies utilizing EEG for emotion recognition have primarily focused on either WFC or CFC in isolation, without investigating the interactions between these two forms of coupling  [10] . Cui et al  [7]  demonstrated that differences exist in WFC when subjects are in different emotional states, while Zhang et al  [9]  showed that Granger causality features in CFC can further improve the recognition accuracy of emotion states. However, the simultaneous exploration of both WFC and CFC (Fig.  1 ), and how their interplay contributes to a more comprehensive understanding of emotional processing, has been largely overlooked  [11] . This gap in the literature presents an opportunity to develop a more integrated approach that can capture the full spectrum of neural dynamics underlying emotion recognition  [12] .\n\nOn the other hand ， when analyzing the EEG signals identifying the topological patterns of brain networks from multi-channel EEG signals, traditional methods rely on graph theoretical metrics for classification, such as node degree, clustering coefficient, average path length, hubs, centrality, modularity, robustness, and assortativity  [12] , which can serve as indicators of cognitive and behavioral performance. Recent development in deep learning architecture has inspired the network neuroscience community to utilize artificial neural networks to extract and classify multi-channel EEG signals in an end-to-end manner. Compared with traditional methods based on graph theoretical metrics, graph neural networks (GNNs) replace the manual feature engineering with representational learning and have proved their advantages in capturing both spatial and temporal features from neurophysiological data  [13] . However, previous work  [13]  building GNNs by neighborhood aggregation may fail to capture complex global features due to their relatively small receptive field, and those combining the Transformer structure with GNNs  [14] , even equipped with the ability of global reception, may suffer from overfitting due to the overparameterization and fail in its generalization to different brain networks . Consequently, this study proposes a dual-branch graph neural network that incorporates the local information from each WFC/CFC brain network and the global information from all WFC/CFC brain networks.\n\nThis study proposed a dual-branch graph neural network (DB-GNN) for EEG emotion recognition (Fig.  2 ). First, EEG signals are decomposed into five different frequency bands. To measure different emotion brain states, phase locking value (PLV)  [7]  is calculated within-frequency band to construct the WFC brain networks and modulation index (MI)  [16]  is computed between pairs of frequency bands to generate the CFC brain networks. Subsequently, under the constraint of the prior coupling information, a Transformer-based GNN model is proposed to perceive the global topology of brain networks. Moreover, we employ multi-level graph contrastive learning to regularize the learning process of the model, enhancing its generalizability. The contributions of our work are summarized as follows. The remaining sections of this paper are organized as follows. Section 2 summarizes related works. Furthermore, section 3 details the construction of DB-GNN. Subsequently, the comparative experiment and analysis is arranged in section 4. Finally, section 5 concludes this study.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Ii. Related Works",
      "text": "Research in analyzing brain networks for brain state classification can be categorized into two different directions: (1) Graph theoretical metrics, such as node degree, clustering coefficient, average path length, hubs, centrality, modularity, robustness, and assortativity  [12] , are extracted from both the WFC and CFC brain networks  [18]  and form the feature basis for recognition tasks. (2) Artificial neural networks from the deep learning community, such as the convolutional neural network (CNN) and the GNN, are deployed to resolve the classification of brain states in an end-to-end manner  [14] . These studies highlighted the fundamental role of WFC and CFC in brain state classification. However, a systematic way of combining the information from both WFC and CFC for analyzing brain networks is still lacking  [11] , and the potential of this direction in brain state classification tasks such as emotion recognition is worth further exploration. Designed for operating on graph-structured inputs, GNNs have emerged as a successful tool in a variety of fields, such as natural language processing  [19] , bioinformatics  [20] , and network neuroscience  [21] . Recently, GNNs have also been introduced for EEG-based emotion recognition  [14] ,  [21] . For example, several works use GNNs to capture both local and global relations among different EEG channels for better emotion recognition  [22] . Moreover, Guo et al  [14]  proposed a dynamic graph neural network model and utilized the selfattention mechanism to enhance the representational power of the output. Fan et al  [13]  proposed a RGNet based on a novel region-wise encoder and obtained an average recognition accuracy of 98.64% and 99.33% for Deap and Dreamer datasets, respectively. These results show the promising potential of obtaining graph structural information in improving the performance of emotion recognition models.\n\nGraph contrastive learning methods  [23]  have been successfully applied for learning robust and discriminative representations from graph-structured data by leveraging selfsupervised learning. These methods aim to maximize the agreement between positive pairs of graph representations while minimizing the similarity to negative samples, typically using contrastive loss functions such as InfoNCE  [23] . Graph contrastive learning techniques have shown great promise in enhancing the robustness of emotion recognition models based on multi-channel EEG signals. For instance, Gilakjani et al  [24]  employed graph contrastive learning to improve the quality of the learned representations from EEG signals and mitigate the adverse impact of inter-subject and intra-subject variability in signals corresponding to the same stimuli or emotions. Zhang et al  [25]  utilized graph contrastive learning to facilitate their synchronous training of graph convolutional networks on multisubject datasets. Given the power of the graph contrastive learning in addressing overfitting and data scarcity challenges, we decided to take advantage of these methods to constrain the training process of our proposed DB-GNN model.",
      "page_start": 2,
      "page_end": 3
    },
    {
      "section_name": "Iii. Methods",
      "text": "",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "A. Construction Of Brain Networks",
      "text": "Suppose that the raw multi-channel EEG signals are\n\n, with representing the -th channel with samples and representing the number of channels. First, we used Butterworth filter  [26]  to extract 5 different frequency bands from the multi-channel EEG signals: (1-3Hz), (3-8Hz), (8-12Hz), (12-30Hz) and (30-48Hz):\n\nTo quantify the WFC of multi-channel EEG signals, this study used the phase locking value (PLV)  [7]  to measure the strength of phase-phase coupling between different EEG channels in the same frequency band. Meanwhile, modulation index (MI)  [16]  is utilized to measure the strength of phaseamplitude coupling across frequency bands. The PLV is calculated as\n\nB C is the average amplitude of a single time bin. is the total number of bins.\n\nBased on the above equations, we constructed the adjacency matrix that quantifies the CFC and WFC of the brain network as\n\nconstructed as following:\n\nwhere T and T are manually set thresholds, which are chosen to keep 20% of the brain network density. The attention matrix l ∈ ℝ /×/ can be calculated as:",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "B. Pigtm: Prior Information-Based Graph Transformer Module",
      "text": "Unlike the Graph Attention Network (GAT)  [17] , PiGTM not only uses the adjacency matrix for masking but also injects prior coupling information into the computation of self-attention, guiding the model's perception process and enhancing its generalization performance. The self-attention computation in GAT is as follows:\n\nwhere K is the adjacency matrix of the brain network, serving as a sparse mask. ⨀ represents element-wise multiplication. Next, we inject the coupling information into the attention matrix to enhance the model's perception capability. l is updated as:\n\nwhere r ← * s $ 2 ∈ ℝ /×/ . : ℝ → ℝ are learnable scalars indexed by s $ . s $ is the degree of coupling between nodes i and j in the brain network from equation (  2 ) and (3). Therefore, the self-attention output of PiGTM is\n\nSince PiGTM adopts the Transformer architecture, its final output ~ is:\n\nwhere FFN denotes the Feed-Forward Network, and ` represents the original input features of the nodes.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "C. Db-Gnn: Dual-Branch Graph Neural Network",
      "text": "DB-GNN employs a dual-branch architecture: the global perception branch integrates information across all WFC (within-frequency coupling) and CFC (cross-frequency coupling) networks to extract global features from a holistic perspective, while the local perception branch focuses on capturing localized information within individual WFC or CFC networks, enhancing the model's ability to discern patterns from local structures. Furthermore, DB-GNN incorporates contrastive learning at both node and graph levels to regularize the training process of the dual-branch networks, thereby improving the model's generalization capability.\n\nRegarding the global branch of perception, the input adjacency matrix is G ∈ ℝ -…× 0×-…× 0 with 5 frequency bands and EEG sampling points. The mask matrix G and the prior coupling information q are used to guide the representation learning process of PiGTM (i.e., Eq. (  13 )). We then generate the global perception vector `;9: †B9 = *^\n\nis the embedding dimension) by averaging these representations from the same node across frequency bands. For the local perception branch, we input 15 adjacency matrices ℝ ×_ d . To mitigate the risk of overfitting, DB-GNN adopts a graph contrastive learning approach to enforce dual-branch learning constraints. As shown in Fig.  3 , since the dual-branch learning process extracts features from the same brain state, the feature vectors learned for the same node by the two branches are treated as positive samples. To enhance the differentiation between features of different nodes and improve the model's perception ability, feature vectors from other nodes are selected as negative samples. Given that this study focuses on the brain network classification task, we further impose feature constraints at the graph-level. As depicted in Fig.  3 , DB-GNN first uses mean pooling to obtain graph-level features. Then, the global and local features of the same brain network learned by the dual-branch structure are treated as positive samples. Meanwhile, features from other brain networks in the same batch are selected as negative samples, thereby enhancing the graph-level feature perception ability of DB-GNN. Based on the InfoNCE loss  [23] , this study constructs the following contrastive learning loss functions for both node-level and graph-level features:\n\nT is the given temperature and ¨• •ž'Ÿ\"ž represents the global representation vector of the graph. Consequently, the loss function of the DB-GNN is: IV. EXPERIMENTS",
      "page_start": 4,
      "page_end": 5
    },
    {
      "section_name": "A. Experimental Details",
      "text": "This study utilizes the SEED dataset  [27]  containing 15 subjects to evaluate the proposed DB-GNN model. The SEED dataset classifies the emotional states into three categoriesnegative, positive, and neutral. Moreover, we use a three-second time window without overlapping to extract the PLV and MI features of the five frequency bands ( , , , , ) based on multi-channel EEG signals. In terms of performance evaluation, we conducted experiments in a subject-dependent manner. 80% of the data is used as the training dataset, and the remaining 20% is used as the testing dataset.\n\nIn all experiments, we compare DB-GNN with several stateof-the-art (SOTA) baselines for graph classification: GCN  [28] , GAT  [17] , SuperGAT  [29] , AntiSymmetric  [30]  and pmlp  [31] . This experiment adopts a three-layer graph learning structure and a global mean pooling method for baselines. The setting of hyperparameters mainly refers to  [30] ,  [31] , and the grid search is utilized for parameter optimization. The Adam is adopted as the optimizer. The learning rate and (β1, β2) are set to 5e-4 and (0.9, 0.999). All models are trained for 300 steps on a NVIDIA A800 Tensor Core GPU.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "B. Verification Experiments",
      "text": "Table  I  and Table  II  present the testing accuracy and F1scores of different algorithms across 15 subjects in the SEED dataset, respectively. The proposed DB-GNN model can achieve a mean testing accuracy of 97.88 ± 0.87 and an F1-score of 97.87 ± 0.87 to classify the positive, neutral, and negative emotions in subject-dependent experiments, which is significantly better and more stable than other baselines on the SEED dataset. This result demonstrates that the coordinated feature representation learning in both WFC and CFC brain networks and the multi-level graph contrastive learning can significantly improve the model performance on emotion recognition. It is noteworthy that the AntiSymmetric algorithm exhibited extremely low performance on subjects 7, 13, and 14. In contrast, the DB-GNN consistently maintained a testing accuracy above 95%. The variation between subjects can be caused by a variety of factors, including subjects' education background, sociability and their true evoked emotional state when participating in experiments. Therefore, the consistency of better performance of our model across different subjects suggests that DB-GNN possesses strong generalization performance.\n\nIn Fig.  4 , we employed the Wilcoxon rank-sum test to assess the significance of performance differences between DB-GNN and other baselines (***: p < 0.001, **: p < 0.01, *: p < 0.05). DB-GNN significantly outperforms all comparative algorithms, with its performance distribution being not only concentrated but also higher than those of other algorithms, demonstrating the advantages and robustness of DB-GNN in the task. Table  III  presents the recent studies on the SEED dataset. The DB-GNN proposed in this study achieves the highest testing accuracy and F1-score. Furthermore, the standard deviation (std) of DB-GNN's performance metrics across different subjects is relatively low, suggesting that our proposed method exhibits a certain level of generalization capability.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "C. Ablation Experiments",
      "text": "To verify the effectiveness of the presented architecture, we conducted ablation experiments on the SEED dataset, and the specific ablation results are shown in Table  IV  and Fig.  6 . First, to verify the role of the dual-branch structure, we removed the global perception branch and only kept the local perception branch in the model (Model 1). The dramatic performance difference between Model 1 and DB-GNN demonstrates the importance of global features in model's recognition ability. Furthermore, to validate the usefulness of the coupling information (i.e., Eq. (  13 )), we added the global branch in Model 2 but omitted the prior coupling in formation q . Model 3 contained the prior coupling information but lacked the  regularization of graph contrastive learning as in DB-GNN. Therefore, by comparing Model 2 and Model 3, we conclude that the inclusion of prior coupling information in graph feature extraction is advantageous. Furthermore, by contrasting Model 3 and DB-GNN, we prove that the regularization of the learning process is indeed effective at enhancing the model's performance. Fig.  6  presents the confusion matrix of the algorithm. With the introduction of a dual-branch structure, prior coupling information, and graph contrastive learningbased regularization, the model's recognition capability gradually improves, particularly with a significant rise in the identification accuracy of positive samples and a reduction in the misclassification of positive samples as neural samples.",
      "page_start": 6,
      "page_end": 7
    },
    {
      "section_name": "V. Conclusion And Future Directions",
      "text": "This study proposed a dual-branch graph neural network (DB-GNN) with multi-level contrastive learning to jointly identify WFC and CFC brain networks for emotion recognition. The dual-branch architecture simultaneously captures local and global features of brain networks, and the PiGTM enhances global feature perception while mitigating overfitting. Moreover, multi-level graph contrastive learning was employed to regularize the learning process, further improving the model's generalization capability. Experimental results on the SEED dataset demonstrated that DB-GNN achieved SOTA performance in emotion recognition tasks. Looking ahead, several directions warrant further exploration. The current model relies on predefined frequency bands and coupling metrics (e.g., PLV and MI). Future work could explore adaptive frequency band selection and more sophisticated coupling measures to better capture the dynamic nature of brain networks. Besides, the integration of additional modalities, such as functional magnetic resonance imaging (fMRI) or physiological signals, could further enhance emotion recognition performance with complementary information.",
      "page_start": 7,
      "page_end": 7
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: , previous studies utilizing EEG for",
      "page": 1
    },
    {
      "caption": "Figure 1: ), and how their",
      "page": 2
    },
    {
      "caption": "Figure 2: ). First, EEG",
      "page": 2
    },
    {
      "caption": "Figure 1: Within-frequency and cross-frequency coupling brain networks. \u0001",
      "page": 2
    },
    {
      "caption": "Figure 2: ) by three matrices bc ∈ℝ",
      "page": 4
    },
    {
      "caption": "Figure 2: Architecture of our proposed algorithm. (a) The structure of the self-attention mechanism in the prior information-based graph transformer module",
      "page": 4
    },
    {
      "caption": "Figure 3: , since the dual-branch",
      "page": 5
    },
    {
      "caption": "Figure 3: The contrastive learning in DB-GNN. (a) Node-level contrastive",
      "page": 5
    },
    {
      "caption": "Figure 4: , we employed the Wilcoxon rank-sum test to assess",
      "page": 6
    },
    {
      "caption": "Figure 5: presents the confusion matrices of various algorithms.",
      "page": 6
    },
    {
      "caption": "Figure 4: Distribution of testing accuracy of SOTA baselines and DB-GNN in",
      "page": 6
    },
    {
      "caption": "Figure 6: presents the confusion matrix of the",
      "page": 7
    },
    {
      "caption": "Figure 6: Confusion matrices of comparison models on SEED dataset.",
      "page": 7
    },
    {
      "caption": "Figure 5: Confusion matrices of SOTA baselines and DB-GNN on SEED dataset.",
      "page": 7
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "(cid:19)\n \n(cid:19)": "A\n \n(cid:19)(cid:20)",
          "(cid:20)\n \n(cid:19)(cid:20)": "A\n \n(cid:20)",
          "(cid:1)\n \n(cid:19)(cid:1)": "A\n \n(cid:20)(cid:1)",
          "(cid:21)\n \n(cid:19)(cid:21)": "A\n \n(cid:20)(cid:21)",
          "γ\n \n(cid:19)γ": "A\n \n(cid:20)γ"
        },
        {
          "(cid:19)\n \n(cid:19)": "A\n(cid:19)(cid:1)",
          "(cid:20)\n \n(cid:19)(cid:20)": "A\n \n(cid:20)(cid:1)",
          "(cid:1)\n \n(cid:19)(cid:1)": "A\n \n(cid:1)",
          "(cid:21)\n \n(cid:19)(cid:21)": "A\n(cid:1)(cid:21)",
          "γ\n \n(cid:19)γ": "A\n \n(cid:1)γ"
        },
        {
          "(cid:19)\n \n(cid:19)": "A\n \n(cid:19)(cid:21)",
          "(cid:20)\n \n(cid:19)(cid:20)": "A\n \n(cid:20)(cid:21)",
          "(cid:1)\n \n(cid:19)(cid:1)": "A\n \n(cid:1)(cid:21)",
          "(cid:21)\n \n(cid:19)(cid:21)": "A\n \n(cid:21)",
          "γ\n \n(cid:19)γ": "A\n \n(cid:21)γ"
        },
        {
          "(cid:19)\n \n(cid:19)": "A\n \n(cid:19)γ",
          "(cid:20)\n \n(cid:19)(cid:20)": "A\n \n(cid:20)γ",
          "(cid:1)\n \n(cid:19)(cid:1)": "A\n(cid:1)γ",
          "(cid:21)\n \n(cid:19)(cid:21)": "A\n \n(cid:21)γ",
          "γ\n \n(cid:19)γ": "A\n \nγ"
        }
      ],
      "page": 4
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "EEG Source Imaging: A Practical Review of the Analysis Steps",
      "authors": [
        "C Michel",
        "D Brunet"
      ],
      "year": "2019",
      "venue": "Front. Neurol",
      "doi": "10.3389/fneur.2019.00325"
    },
    {
      "citation_id": "2",
      "title": "Emotion Downregulation Targets Interoceptive Brain Regions While Emotion Upregulation Targets Other Affective Brain Regions",
      "authors": [
        "J Min"
      ],
      "year": "2022",
      "venue": "J. Neurosci",
      "doi": "10.1523/JNEUROSCI.1865-21.2022"
    },
    {
      "citation_id": "3",
      "title": "The functional role of cross-frequency coupling",
      "authors": [
        "R Canolty",
        "R Knight"
      ],
      "year": "2010",
      "venue": "Trends Cogn. Sci",
      "doi": "10.1016/j.tics.2010.09.001"
    },
    {
      "citation_id": "4",
      "title": "Neuronal synchrony reveals working memory networks and predicts individual memory capacity",
      "authors": [
        "J Palva",
        "S Monto",
        "S Kulashekhar",
        "S Palva"
      ],
      "year": "2010",
      "venue": "Proc. Natl. Acad. Sci",
      "doi": "10.1073/pnas.0913113107"
    },
    {
      "citation_id": "5",
      "title": "Low-frequency neuronal oscillations as instruments of sensory selection",
      "authors": [
        "C Schroeder",
        "P Lakatos"
      ],
      "year": "2009",
      "venue": "Trends Neurosci",
      "doi": "10.1016/j.tins.2008.09.012"
    },
    {
      "citation_id": "6",
      "title": "Alpha-band oscillations, attention, and controlled access to stored information",
      "authors": [
        "W Klimesch"
      ],
      "year": "2012",
      "venue": "Trends Cogn. Sci",
      "doi": "10.1016/j.tics.2012.10.007"
    },
    {
      "citation_id": "7",
      "title": "Emotion recognition based on group phase locking value using convolutional neural network",
      "authors": [
        "G Cui",
        "X Li",
        "H Touyama"
      ],
      "year": "2023",
      "venue": "Sci. Rep",
      "doi": "10.1038/s41598-023-30458-6"
    },
    {
      "citation_id": "8",
      "title": "The Theta-Gamma Neural Code",
      "authors": [
        "J Lisman",
        "O Jensen"
      ],
      "year": "2013",
      "venue": "Neuron",
      "doi": "10.1016/j.neuron.2013.03.007"
    },
    {
      "citation_id": "9",
      "title": "EEG emotion recognition based on cross-frequency granger causality feature extraction and fusion in the left and right hemispheres",
      "authors": [
        "J Zhang",
        "X Zhang",
        "G Chen",
        "L Huang",
        "Y Sun"
      ],
      "year": "2022",
      "venue": "Front. Neurosci",
      "doi": "10.3389/fnins.2022.974673"
    },
    {
      "citation_id": "10",
      "title": "Graph Neural Network-Based EEG Classification: A Survey | IEEE Journals & Magazine | IEEE Xplore",
      "year": "2024",
      "venue": "Graph Neural Network-Based EEG Classification: A Survey | IEEE Journals & Magazine | IEEE Xplore"
    },
    {
      "citation_id": "11",
      "title": "Colloquium: Multiscale modeling of brain network organization",
      "authors": [
        "C Presigny",
        "F Vico"
      ],
      "year": "2022",
      "venue": "Rev. Mod. Phys",
      "doi": "10.1103/RevModPhys.94.031002"
    },
    {
      "citation_id": "12",
      "title": "Application of Graph Theory for Identifying Connectivity Patterns in Human Brain Networks: A Systematic Review",
      "authors": [
        "F Farahani",
        "W Karwowski",
        "N Lighthall"
      ],
      "year": "2019",
      "venue": "Front. Neurosci",
      "doi": "10.3389/fnins.2019.00585"
    },
    {
      "citation_id": "13",
      "title": "EEG Emotion Classification Based on Graph Convolutional Network",
      "authors": [
        "Z Fan",
        "F Chen",
        "X Xia",
        "Y Liu"
      ],
      "year": "2024",
      "venue": "Appl. Sci",
      "doi": "10.3390/app14020726"
    },
    {
      "citation_id": "14",
      "title": "EEG Emotion Recognition Based on Dynamic Graph Neural Networks",
      "authors": [
        "Y Guo",
        "C Tang",
        "H Wu",
        "B Chen"
      ],
      "year": "2024",
      "venue": "2024 IEEE International Symposium on Circuits and Systems (ISCAS)",
      "doi": "10.1109/ISCAS58744.2024.10558424"
    },
    {
      "citation_id": "15",
      "title": "SAGN: Sparse Adaptive Gated Graph Neural Network With Graph Regularization for Identifying Dual-View Brain Networks",
      "authors": [
        "W Xue",
        "H He",
        "Y Wang",
        "Y Zhao"
      ],
      "year": "2024",
      "venue": "IEEE Trans. Neural Netw. Learn. Syst",
      "doi": "10.1109/TNNLS.2024.3438835"
    },
    {
      "citation_id": "16",
      "title": "Quantification of Phase-Amplitude Coupling in Neuronal Oscillations: Comparison of Phase-Locking Value, Mean Vector Length, Modulation Index, and Generalized-Linear-Modeling-Cross-Frequency-Coupling",
      "authors": [
        "M Hülsemann",
        "E Naumann",
        "B Rasch"
      ],
      "year": "2019",
      "venue": "Front. Neurosci",
      "doi": "10.3389/fnins.2019.00573"
    },
    {
      "citation_id": "17",
      "title": "Graph Attention Networks",
      "authors": [
        "P Veličković",
        "G Cucurull",
        "A Casanova",
        "A Romero",
        "P Liò",
        "Y Bengio"
      ],
      "year": "2018",
      "venue": "Graph Attention Networks",
      "doi": "10.48550/arXiv.1710.10903",
      "arxiv": "arXiv:arXiv:1710.10903"
    },
    {
      "citation_id": "18",
      "title": "Multi-Granularity Analysis of Brain Networks Assembled With Intra-Frequency and Cross-Frequency Phase Coupling for Human EEG After Stroke",
      "authors": [
        "B Ren"
      ],
      "year": "2022",
      "venue": "Front. Comput. Neurosci",
      "doi": "10.3389/fncom.2022.785397"
    },
    {
      "citation_id": "19",
      "title": "Review of Graph Neural Network in Text Classification",
      "authors": [
        "M Malekzadeh",
        "P Hajibabaee",
        "M Heidari",
        "S Zad",
        "O Uzuner",
        "J Jones"
      ],
      "year": "2021",
      "venue": "2021 IEEE 12th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON)",
      "doi": "10.1109/UEMCON53757.2021.9666633"
    },
    {
      "citation_id": "20",
      "title": "Graph Neural Networks and Their Current Applications in Bioinformatics",
      "authors": [
        "X.-M Zhang",
        "L Liang",
        "L Liu",
        "M.-J Tang"
      ],
      "year": "2021",
      "venue": "Front. Genet",
      "doi": "10.3389/fgene.2021.690049"
    },
    {
      "citation_id": "21",
      "title": "Graph Neural Networks in Network Neuroscience",
      "authors": [
        "A Bessadok",
        "M Mahjoub",
        "I Rekik"
      ],
      "year": "2023",
      "venue": "IEEE Trans. Pattern Anal. Mach. Intell",
      "doi": "10.1109/TPAMI.2022.3209686"
    },
    {
      "citation_id": "22",
      "title": "EEG-Based Emotion Recognition Using Regularized Graph Neural Networks",
      "authors": [
        "P Zhong",
        "D Wang",
        "C Miao"
      ],
      "year": "2022",
      "venue": "IEEE Trans. Affect. Comput",
      "doi": "10.1109/TAFFC.2020.2994159"
    },
    {
      "citation_id": "23",
      "title": "Representation Learning with Contrastive Predictive Coding",
      "authors": [
        "A Van Den Oord",
        "Y Li",
        "O Vinyals"
      ],
      "year": "2019",
      "venue": "Representation Learning with Contrastive Predictive Coding",
      "doi": "10.48550/arXiv.1807.03748",
      "arxiv": "arXiv:arXiv:1807.03748"
    },
    {
      "citation_id": "24",
      "title": "A Graph Neural Network for EEG-Based Emotion Recognition With Contrastive Learning and Generative Adversarial Neural Network Data Augmentation",
      "authors": [
        "S Gilakjani",
        "H Osman"
      ],
      "year": "2024",
      "venue": "IEEE Access",
      "doi": "10.1109/ACCESS.2023.3344476"
    },
    {
      "citation_id": "25",
      "title": "Emotion recognition of EEG signals based on contrastive learning graph convolutional model",
      "authors": [
        "Y Zhang",
        "Y Liao",
        "W Chen",
        "X Zhang",
        "L Huang"
      ],
      "year": "2024",
      "venue": "J. Neural Eng",
      "doi": "10.1088/1741-2552/ad7060"
    },
    {
      "citation_id": "26",
      "title": "On the theory of filter amplifiers",
      "authors": [
        "S Butterworth"
      ],
      "year": "1930",
      "venue": "Wirel. Eng"
    },
    {
      "citation_id": "27",
      "title": "Investigating Critical Frequency Bands and Channels for EEG-Based Emotion Recognition with Deep Neural Networks",
      "authors": [
        "W.-L Zheng",
        "B.-L Lu"
      ],
      "year": "2015",
      "venue": "IEEE Trans. Auton. Ment. Dev",
      "doi": "10.1109/TAMD.2015.2431497"
    },
    {
      "citation_id": "28",
      "title": "Semi-Supervised Classification with Graph Convolutional Networks",
      "authors": [
        "T Kipf",
        "M Welling"
      ],
      "year": "2017",
      "venue": "Semi-Supervised Classification with Graph Convolutional Networks",
      "doi": "10.48550/arXiv.1609.02907",
      "arxiv": "arXiv:arXiv:1609.02907"
    },
    {
      "citation_id": "29",
      "title": "How to Find Your Friendly Neighborhood: Graph Attention Design with Self-Supervision",
      "authors": [
        "D Kim",
        "A Oh"
      ],
      "year": "2022",
      "venue": "How to Find Your Friendly Neighborhood: Graph Attention Design with Self-Supervision",
      "doi": "10.48550/arXiv.2204.04879",
      "arxiv": "arXiv:arXiv:2204.04879"
    },
    {
      "citation_id": "30",
      "title": "Edge Directionality Improves Learning on Heterophilic Graphs",
      "authors": [
        "E Rossi",
        "B Charpentier",
        "F Giovanni",
        "F Frasca",
        "S Günnemann",
        "M Bronstein"
      ],
      "year": "2024",
      "venue": "Proceedings of the Second Learning on Graphs Conference"
    },
    {
      "citation_id": "31",
      "title": "Graph Neural Networks are Inherently Good Generalizers: Insights by Bridging GNNs and MLPs",
      "authors": [
        "C Yang",
        "Q Wu",
        "J Wang",
        "J Yan"
      ],
      "year": "2023",
      "venue": "Graph Neural Networks are Inherently Good Generalizers: Insights by Bridging GNNs and MLPs",
      "doi": "10.48550/arXiv.2212.09034",
      "arxiv": "arXiv:arXiv:2212.09034"
    },
    {
      "citation_id": "32",
      "title": "How Powerful are Graph Neural Networks?",
      "authors": [
        "K Xu",
        "W Hu",
        "J Leskovec",
        "S Jegelka"
      ],
      "year": "2019",
      "venue": "How Powerful are Graph Neural Networks?",
      "doi": "10.48550/arXiv.1810.00826",
      "arxiv": "arXiv:arXiv:1810.00826"
    },
    {
      "citation_id": "33",
      "title": "Elastic Graph Transformer Networks for EEG-Based Emotion Recognition",
      "authors": [
        "W.-B Jiang",
        "X Yan",
        "W.-L Zheng",
        "B.-L Lu"
      ],
      "year": "2023",
      "venue": "ICASSP 2023 -2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",
      "doi": "10.1109/ICASSP49357.2023.10096511"
    },
    {
      "citation_id": "34",
      "title": "Variational Instance-Adaptive Graph for EEG Emotion Recognition",
      "authors": [
        "T Song"
      ],
      "year": "2023",
      "venue": "IEEE Trans. Affect. Comput",
      "doi": "10.1109/TAFFC.2021.3064940"
    },
    {
      "citation_id": "35",
      "title": "GMSS: Graph-Based Multi-Task Self-Supervised Learning for EEG Emotion Recognition",
      "authors": [
        "Y Li"
      ],
      "year": "2023",
      "venue": "IEEE Trans. Affect. Comput",
      "doi": "10.1109/TAFFC.2022.3170428"
    },
    {
      "citation_id": "36",
      "title": "MSFR-GCN: A Multi-Scale Feature Reconstruction Graph Convolutional Network for EEG Emotion and Cognition Recognition",
      "authors": [
        "D Pan"
      ],
      "year": "2023",
      "venue": "IEEE Trans. Neural Syst. Rehabil. Eng",
      "doi": "10.1109/TNSRE.2023.3304660"
    },
    {
      "citation_id": "37",
      "title": "Emotion Recognition Using Hierarchical Spatiotemporal Electroencephalogram Information from Local to Global Brain Regions",
      "authors": [
        "D.-K Jeong",
        "H.-G Kim",
        "J.-Y Kim"
      ],
      "venue": "Bioengineering"
    },
    {
      "citation_id": "39",
      "title": "EEG emotion recognition using EEG-SWTNS neural network through EEG spectral image",
      "authors": [
        "M Cai",
        "J Chen",
        "C Hua",
        "G Wen",
        "R Fu"
      ],
      "year": "2024",
      "venue": "Inf. Sci",
      "doi": "10.1016/j.ins.2024.121198"
    },
    {
      "citation_id": "40",
      "title": "Graph Convolutional Network With Connectivity Uncertainty for EEG-Based Emotion Recognition",
      "authors": [
        "H Gao"
      ],
      "year": "2024",
      "venue": "IEEE J. Biomed. Health Inform",
      "doi": "10.1109/JBHI.2024.3416944"
    },
    {
      "citation_id": "41",
      "title": "EEG-based emotion recognition using a temporal-difference minimizing neural network",
      "authors": [
        "X Ju",
        "M Li",
        "W Tian",
        "D Hu"
      ],
      "year": "2024",
      "venue": "Cogn. Neurodyn",
      "doi": "10.1007/s11571-023-10004-w"
    },
    {
      "citation_id": "42",
      "title": "An Efficient Graph Learning System for Emotion Recognition Inspired by the Cognitive Prior Graph of EEG Brain Network",
      "authors": [
        "C Li"
      ],
      "year": "2024",
      "venue": "IEEE Trans. Neural Netw. Learn. Syst",
      "doi": "10.1109/TNNLS.2024.3405663"
    }
  ]
}