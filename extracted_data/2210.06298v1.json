{
  "paper_id": "2210.06298v1",
  "title": "Cross Task Neural Architecture Search For Eeg Signal Classifications",
  "published": "2022-10-01T10:55:04Z",
  "authors": [
    "Yiqun Duan",
    "Zhen Wang",
    "Yi Li",
    "Jianhang Tang",
    "Yu-Kai Wang",
    "Chin-Teng Lin"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Electroencephalograms (EEGs) are brain dynamics measured outside of the brain, which have been widely utilized in non-invasive brain-computer interface applications. Recently, various neural network approaches have been proposed to improve the accuracy of EEG signal recognition. However, these approaches severely rely on manually designed network structures for different tasks which normally are not sharing the same empirical design cross-task-wise. In this paper, we propose a cross-task neural architecture search (CTNAS-EEG) framework for EEG signal recognition, which can automatically design the network structure across tasks and improve the recognition accuracy of EEG signals. Specifically, a compatible search space for cross-task searching and an efficient constrained searching method is proposed to overcome challenges brought by EEG signals. By unifying structure search on different EEG tasks, this work is the first to explore and analyze the searched structure difference in crosstask-wise. Moreover, by introducing architecture search, this work is the first to analyze model performance by customizing model structure for each human subject. Detailed experimental results suggest that the proposed CTNAS-EEG could reach state-of-the-art performance on different EEG tasks, such as Motor Imagery (MI) and Emotion recognition. Extensive experiments and detailed analysis are provided as a good reference for follow-up researchers. We will release the source code 1 to contribute to the open source community.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Noninvasive Brain-Computer Interface (BCI), especially Electroencephalograms (EEGs) signal, is attracting increasing interest from researchers because of its safety and the convenience of recording. EEG signals measure electrical activity in the brain by using small metal discs (electrodes) attached to the scalp. The precise recognition of EEG signals is the basis for most BCI applications, such as Motor Imaginary (MI)  (Saa and C ¸etin 2013; Keerthi Krishnan and Soman 2021) , Emotion  (Wang, Nie, and Lu 2014; Wang and Wang 2021) , Robotic Control  (Tonin et al. 2011), and Gaming (Nijholt 2009) . Previous works are mostly based on manually designed neural networks  (Lawhern et al. 2016; Liu et al. 2016)  to recognize EEG signals. However, different applications are not sharing the same neural model, designing the network architecture still requires a lot of expert knowledge and takes up much time in the EEG field. Therefore, we expect to introduce automatic neural network design to replace manual design and further improve the accuracy of EEG recognition for various applications.\n\nOur approach is inspired by Neural Architecture Search (NAS) framework  (Zoph and Le 2017a; Liu, Simonyan, and Yang 2018; Chu et al. 2020a; Xu et al. 2020) , which introduces automatic design of artificial neural networks. Yet, previous explorations are mostly in computer vision area. By utilizing NAS, we increase the automation level into mostly manual designed structure in EEG field. Moreover, this could bring neural network customization capability to each single human subject in the first time. However, adopting neural architecture search into EEG area meets critical challenges due to unique properties of EEG signals: 1) EEG signals are time series data with spatial channel distribution with a low signal-to-noise ratio (SNR), which requires a different search space compared to existing NAS methods. 2) The signal trails varies significantly between different human subjects  (Wierzgała et al. 2018) . 3) The required search space may vary severely between different recognition tasks (such as Emotion and Motor Imagery (MI)).\n\nIn this paper, we propose CTNAS-EEG (Cross Tasks Differentiable Architecture Search for EEG Signals), an efficient neural architecture search framework for general human brain dynamics, with the consideration of the listed challenges above. We propose a unique prototype network (Meta-Net) specially designed for EEG signals in Section 3.1 to overcome challenge 1) listed above, which could preserve channel-wise information and time-wise information together for the search space to utilize. Also, an efficient search space that is compatible with multiple tasks of EEG signals is proposed and described in Section 3.2 to overcome challenges 1) and 3). For challenge 2) the subject difference, we follow strategies from previous works, where we first perform searching on a mixed subjects dataset to explore a unified structure. However, since we introduce architecture search into EEG signal processing, we are first able to customize structures for each subject and report the performance, which could also alleviate challenge 2). Considering the low SNR properties of EEG signals, we propose two structure constraints in Section 3.3 to improve the performance. First, we constrain the network scale with limited sizes, which could alleviate over-fitting by reducing redundant parameters and generate more slim structures for practical use. Second, the aggregated probability of selecting 'skip connection' is constrained with a lower bound, which could provide an instant gradient backward path thus alleviating the training difficulty brought by low SNR.\n\nWe conduct detailed experiments in Section 4 and Appendix to illustrate the efficiency of our proposed CTNAS-EEG. The performance of CTNAS-EEG is compared with manually designed baselines on both MI (Section 4.3) and Emotion tasks  (Section 4.4) . Since this work is the first to unify MI and Emotion tasks with NAS, we provide crosstask searching results analysis in Section 4.5 as references for follow-up researchers. The main contributions of the CTNAS-EEG could be categorized fourfold:\n\n• CTNAS-EEG is the first approach that introduces stateof-the-art differentiable architecture search into EEG signal recognition and could unify multiple separated tasks. • A novel Meta-Net, as well as a compatible search space, is first proposed especially designed for EEG signals.\n\n• Simple yet efficient constraints are first applied to EEG structures, which could alleviate over-fitting and ensure searched structures are practical to deploy. • Experimental results suggest that the CTNAS-EEG could achieve competitive performance simultaneously on MI and Emotion datasets. Extensive studies provide a detailed analysis of search results.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Related Works",
      "text": "Both conventional approaches and deep learning approaches to recognize EEG signals have been investigated.",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Motor Imaginary (Mi):",
      "text": "The common spatial patterns (CSP)  (Koles, Lazar, and Zhou 1990)  and filter bank common spatial pattern (FBCSP)  (Kai Keng Ang et al. 2008 ) are first found effective to enhanced the performance of early machine learning methods. Later work  (Hersche et al. 2018)  has improved the accuracy by introducing a linear support vector machine (SVM) combined with Riemannian covariance matrices. As deep learning introduces better noise resistance, later deep learning methods could use both the preprocessed feature and the raw EEG signal as the input. EEG-Net  (Lawhern et al. 2016) , Shallow ConvNet  (Schirrmeister et al. 2017 ) and its variances are early works using raw input. TPCT  (Li, Han, and Duan 2019)  combines advantages from both pre-processed feature-based input and raw signals by introducing large-scale CNN. TCNet  (Ingolfsson et al. 2020 ) introduces temporal convolution and reaches a good balance between network scale and accuracy.\n\nEmotion: Support vector machine  (Atkinson and Campos 2016; Wang et al. 2019 ) and random forest  (Liu et al. 2016)  are first explored for two-category classification. Besides,  (Tuncer, Dogan, and Subasi 2021)  proposed a fractal pattern feature extraction approach for emotion recognition. Multi-frequency bands  (Zheng and Lu 2015)  are combined with deep belief networks (DBN). Spatial-temporal recurrent neural network (STRNN)  (Zhang et al. 2018)  for EEGbased emotion detection, where they also split the EEG signals into five frequency bands for extracting DE features. Besides,  (Krishna et al. 2019)  proposed a unique mixture model, which is well-performed on EEG signals interfered by noises based on asymmetric distribution.\n\nNeural Architecture Search Neural Architecture Search (NAS) has attracted extensive attention for its potential to design efficient networks automatically  (Liu et al. 2019; Ghiasi, Lin, and Le 2019; Li et al. 2020a; Gao et al. 2021) . Earlier searching works are based on reinforcement learning  (Zoph and Le 2017b; Zoph et al. 2018 ) and evolutionary algorithms  (Xie and Yuille 2017; Real et al. 2019) , where most of them require 'training-from-scratch' on various candidates and select candidates on each step by trained meta-controller (reinforcement learning) or crossover evolution. In order to reduce the searching cost, more recent works such as one-shot NAS methods  (Guo et al. 2019; Chu et al. 2019 ) and gradient-based methods  (Liu, Simonyan, and Yang 2019; He et al. 2020 ) utilized the weight sharing strategy, where the searched results are presented as subnet of a MetaNet. Basically, the searching performs weights optimization on the MetaNet which contains all possible operators and seeks a feasible structure hyper-parameters which decides the subnet, the searched result. We design our structure search methods for EEG signals based on gradientbased methods as it requires lower computation cost  (Jin et al. 2019 ). An early attempt  (Rapaport, Shriki, and Puzis 2019)  has explored simple scenarios of introducing NAS with EEG. But the search space is still the computer vision search space, yet the experiments are merely on motor imaginary and could not reach SOTA performance.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Cross Task Search For Eeg Signal",
      "text": "In this section, we will provide technical details of the proposed CTNAS-EEG 2  . We first give an overall introduction to the Meta-Net and feature design in Section 3.1 An effective and compatible search space for EEG signals is introduced in Section 3.2. Furthermore, we design structure constraint and solve the constrained optimizing problem in Section 3.3",
      "page_start": 2,
      "page_end": 2
    },
    {
      "section_name": "Meta-Net And Stem Feature Processing",
      "text": "One significant property of EEG signals is that it contains both channel-wise 3  information and time-wise information. The brain waves can present significant feature only if it is accumulated to a certain time-wise interval. Previous methods may have introduced strong human priors, such as common spatial patterns, power spectral density, and differential entropy. Since our intuition is to let the machine decide the processing structure for signals, this work directly uses raw EEG signal as input. Given EEG signal trails with shape channel × samplepoints, we first slice and stack the whole data with a sliding window with overlap as shown in Figure  1 . After that, the feature shape becomes bs × channels × slices × samplepoints. After that, a global channel-wise 1x1 convolution layer is applied to mix channel-wise information from EEG. Since the EEG channels have physical meanings, the MetaNet does not perform",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Search Space",
      "text": "As mentioned in Appendix A and Equation  7 , during the search period, the search space provides a set of potential operators to be selected by each edge. Please refer to Appendix B for detailed operators.\n\nOperators The output of each edge inside search cells is decided by the search space, as the output is weighted mixture 4 of all the operators in search space during the training period. In that case, efficient and compatible are important at the same time. Activation The activation function provides nonlinearity and improves the representation ability of a network. We add an activation layer after every operator in the search space.\n\nExtensive experiments suggest that the traditional Relu and Sigmoid function is not performing well. Instead, we use Elu and LeakyRelu  (Nwankpa et al. 2018)  in our search space. This also fits observations from previous works in EEG signal recognition.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Constraint Optimizing",
      "text": "As mentioned in introduction that we need to 1) limit the searched network scale for practical usage, and 2) improve the sampling probability of skip connection for the low signal-to-noise-ration properties of EEG signals. In that case, CTNAS-EEG introduces structure constraints to the searching process to reach our goal. Different from the original DARTS algorithm mentioned in Appendix A Preliminaries, we form our optimization objective function with structure constraints. And the structure constraint is optimized through relaxation of the objective function using Augmented Lagrangian. Please refer to Appendix E for extensive experiments on the proposed structure constraint.\n\nThe two proposed structure constraint is defined respectively as below: 1) The network parameter scale Ω(θ) is constrained within a certain range. 2) Also we constraint the network to increase the probability of using skip connection Φ(θ) to make the whole MetaNet with a more instant gradient backward path. The instant path could increase the noiseresistant ability thus stabilizing the searching process given EEG raw signals with low SNR. The optimization problem is defined in Equation  1 :\n\nwhere Ω(θ) denotes the total parameter scale given structure parameter θ, C l and C h respectively denotes the lower and upper bound correspond to current structure parameters. Φ(θ) denotes the probability indicator of selecting a skip connection, we force the network to select more skip connections in earlier stages of training. The lower bound of the probability P skip (t) = βe -t will decay to zero as the training time t increasing. Yet, the parameter scale is discrete if we directly count the parameters related to the current operator. In that case, we apply a similar relaxation with the original DARTS (Liu, Simonyan, and Yang 2018) that we relax the discrete network parameter scales to a continuous function Ω(•) of the SoftMax value of the structure θ as it defined in Equation  2 :\n\nwhere the σ is a matrix that returns the normalized resources costs of operators in the search space given the weight of operators θ (i,j) between node i and node j. Matrix σ can be determined by giving the resource cost of each operator could be calculated from its weights, where the value of resource cost is between 0 to 1 by normalizing the weights between all weights of the operators in the search space. Similarly, we define the skip connection indicator as shown in Equation  3 .\n\nwhere θ\n\no=skip denotes that we only count probabilities of skip connection to calculate Φ(θ). T is the temperature parameter widely used in knowledge distillation  (Gou et al. 2021; Wang, Liu, and Tao 2020) , which could make the output of the Softmax distributed more evenly, thus avoiding severe structure fluctuation at an earlier stage. Since the constrained problem defined in Equation 1 is not strict convex for optimization, CTNAS-EEG basically follows the effective relaxation of current DARTS papers, which alternatively update the weights w and the structure parameter θ. Meanwhile, we put the structure constraint into consideration while updating the structure parameter θ. The constraint optimization problem is solved by transferring constraint to penalty item in objective function via Augmented Lagrangian  (Boyd, Boyd, and Vandenberghe 2004) . The transformed objective function is defined in Equation  4 :\n\nwhere λ 1 and λ 2 are respectively the weight of the lower and upper bound of the network structure constraint. λ 3 is the weight of skip connection constraint. By optimizing the objective function defined in Equation  4 , the structure parameter θ could be updated while keeping the structure constrained. The overall iteration process could be summarized in Algorithm 1.",
      "page_start": 3,
      "page_end": 3
    },
    {
      "section_name": "Algorithm 1: Training Procedure Of Ctnas-Eegß",
      "text": "Require: Set of mixed operators o ( i, j) parameterized by θ ( i, j) for each edge (i, j). 1: while  Step < Max  and Not Converged do   2:  1. Fix current θ as optimal θ * , obtain optimal w * by descending along ∇L train (w(θ * )) 3:\n\n2. Fix current w as optimal w * , obtain optimal θ * by descending along ∇L lag θ as defined in Equation  4 4: end while\n\nDerive the final architecture based on the learned θ.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Experiments",
      "text": "This section presents experiments to illustrate the effectiveness of the proposed CTNAS-EEG framework. We give the description of the datasets and the experimental settings in Section 4.1 and Section 4.2. The CTNAS-EEG performance is verified in customizing networks for two important tasks, MI and Emotion, reported in Section 4.3 and Section 4.4, respectively. Due to limited paper length, please refer to Section E for a detailed ablation study. Experimental results support that the proposed CTNAS-EEG could reaches SOTA performance on both cross-subject and within-subject tasks.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Datasets",
      "text": "We compare the model performance on the datasets of two most important tasks, MI and Emotion, in EEG area.\n\nBCI Competition IV for MI For MI, we select BCI Competition IV dataset  (Tangermann et al. 2012 ) 2a to conduct our experiments. Both datasets contain EEG and EOG signals with a sampling frequency of 250 Hz from nine subjects. For dataset 2a, subjects were required to perform four classes (left hand, right hand, feet, and tongue) MI classification. The BCI-competition IV dataset is collected under a widely-used 10-20 system, where 22 EEG channels and 3 EOG channels are provided. In this experiment, we only consider the 3 seconds 'Imaginary period' 5  which contains 750 sample points in each trail. The sample distribution between different labels is balanced naturally while the data is collected.   1 , where * denotes the results from our reproduction.",
      "page_start": 4,
      "page_end": 4
    },
    {
      "section_name": "Seed Dataset For",
      "text": "For the reproduced models, we run repeat experiments and report the upper and lower bound of each model. Since for CTNAS-EEG, the searched architecture is different with each searching process, we directly report the range of the parameter scales in Table  1 . It could be observed that the search algorithm could reach a performance range of 77.0 ∼ 79.1% which could outperform the current SOTA light-weighted model EEG-TCNET with an accruacy 77.34% while keeping the parameter scales comparable (18.2k ∼ 32.1k vs. 20.5k). The best performance of 6 https://pytorch.org/ our proposal with or without structure constraint could respectively reach 79.1% and 80.4% on average accuracy on the mixed dataset while keeping the structure scale at 24.2k and 61.6k.\n\nSubject Dependent Performance One unique advantage of the proposed network searching method is that CTNAS-EEG could customize the network not only for different tasks but also for different subjects. Under this setting, the model could access the subject information during training, and fit the network with each human subject specifically, which is the first framework that could realize customization for each human user. We compare the proposed CTNAS-EEG with previous baselines with three evaluation methods as below and report the results in   (Everitt and Howell 2021)  54.47/18.48 46.41/18.88 GSCCA  (Zheng 2016)  69.08/16.66 57.21/20.72 DBN  (Zheng and Lu 2015)  66.77/07.38 56.82/17.23 GRSLR  (Li et al. 2019)  69.32/19.57 62.32/18.97 GCNN  (Defferrard 2016)  68.34/15.42 63.12/19.76 DGCNN  (Song et al. 2018)  69.88/16.29 65.34/20.36 BiDANN  (Li et al. 2018)  70.29/12.63 -A-LSTM  (Song et al. 2019)  69.50/15.65 65.10/20.20 BiHDM  (Li et al. 2020b)  74 +6.43% and +6.48%). Meanwhile, the accuracy standard deviation of CTNAS-EEG on subjects is 7.39%, which is also significantly lower than baseline methods (11.50% and 9.20), which suggests that CTNAS-EEG has a smaller performance gap between different subjects. It suggests that our searched structure could provide better optimization for previously 'harder subjects'.\n\n• Variable Structure denotes customizing specific structure & weights for each subject, which is enabled by the unique properties of our proposal. It could realize more detailed optimization for specific structures. It is observed that, by customizing the structure for each subject, the average accuracy and standard deviation respectively reach 88.52% and 7.28%. It suggests that customizing the structure for each structure could slightly improve model performance, yet the impact is not dominated. This is rational since all these subjects' samples are motor-imaginary data, it should not require extremely different operators or structures while only changing the subject under the same task. However, CTNAS-EEG provides the ability to customize the structure for each subject and reach SOTA performance for follow-up researchers' reference.",
      "page_start": 5,
      "page_end": 6
    },
    {
      "section_name": "Emotion Performance",
      "text": "As the emotion tasks have severe subject differences naturally, previous works  (Li et al. 2020b ) are mostly evaluating results based on subject-dependent performance. Thus, we directly evaluate subject-depended performance on Emotion tasks. The experimental results are reported in Table  3 .\n\nAs SEED datasets have more subjects than BCI Competition IV datasets, we directly report the average and standard deviation metrics in Table  3 . Since this work focuses on the structure, we didn't bring multi-modality input to increase model performance, where all results reported is based on raw EEG signal input. The CTNAS-EEG could respectively reach 76.21%, 77.01% on SEED-IV dataset, and reach 73.89%, 74.21% on SEED-V dataset with or without network scale constraint. This result supports that the proposed CTNAS-EEG could unify separated MI and Emotion tasks within one simple framework and both reach SOTA performance. Thus, we could first observe and compare the search operators cross-task wise, where the analysis is reported and analyzed in Section 4.5.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Cross-Task Searching Analysis",
      "text": "As mentioned in Section 3.2 that searching is learning to select proper operators 8 from the search space. Unifying searching cross tasks, we can compare suitable operators and their difference between MI and Emotion. The difference is visualized in two aspects, 1) statistical results of selecting all operators and 2) the probability distribution variance.",
      "page_start": 6,
      "page_end": 6
    },
    {
      "section_name": "Statistical Results Of All Operators",
      "text": "To analyze how each operator is useful for different tasks, we directly count the numbers of each operator selected as part of the validation 8 Please denote that 'none' operator denotes no connection between a node pair, which may change the network topology.  For MI tasks, 'narrow' operators are more likely to be selected, such as dilation convolution 'dil 3x1', 'dil 5x1', 'dil 11x1', 'sep 3x1', and 'maxpool 3x1', which suggest that operators with time-wise aggregation have a higher probability to be selected from searching. It could also be observed that the dilation convolution shows advantages over separate convolution and normal convolution. We argue this phenomenon is rational since the dilation operators could provide a larger perception field, which is important for extracting long-term time-series MI signals. For Emotion tasks, square operators such as 'sep 3x3' and 'maxpool 3x3', take advantage of others. It suggests that Emotion tasks may need more abilities to extract information across different time slices. It is also rational since the emotion task is not that 'clear' compared to MI tasks, and may need more samples from a different time domain to extract confident features.\n\nOperator variance considering topology Since the operator between different node pairs may require different properties, we visualize the operators' distribution variance on each edge of the search-able cell. It should be noted that we only listed the top 8 operators in our search space for a clear presentation. We keep the hyper-parameters as well as nodes in each search-able cell the same as the performance evalu-9 Means searched structures with performance no lower than our best results by 10%.   2 . Here, the 'none' operator denotes that there is no actual calculation of our feature flow between the given node pair. Here we selected subject 3 (S3) in the BCI Competition IV dataset to visualize the operators' distribution change of subject customized structure search as shown in Figure  3 . It is observed that, at 'shallow' layers, the degree of separation between operators is not that good, which suggest that various operators are suitable to extract shallower features from raw EEG signal. However, on deeper layers, the operators' distribution is more separable, such as 'dil 1x9' stands out to aggregate information from different time slices. Limited to paper length, we provide more visualization results in Appendix Section D.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Conclusion",
      "text": "This paper proposes the CTNAS-EEG framework to adopt neural architecture search into EEG signal processing. CTNAS-EEG is the first approach that unifies multiple separated tasks and could customize model structure for each human subject. Experimental results suggest our proposal could reach SOTA performance on both MI and Emotion tasks, which could be convenient for researchers unfamiliar with specific network design in the BCI area. Besides, cross-task searching analysis is provided to give follow-up researchers as good references.",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "A Preliminaries",
      "text": "The key factor of constructing neural architecture search (NAS) contains three aspects, search space, search strategy (optimization strategy), and evaluation metric. These three aspects respectively indicate the candidates and compilation of potential structures for searching, how we search and update the structures in defined search space, and how we decide which structure to choose during the searching process. Previous explorations mostly in the image area have revealed that if the search space is too large, the searching process would lead to severe time consumption and hardness of convergence. A modern formation is simply to connect various blocks and only search operators and their connection inside one certain block. In this work, similar to previous DARTS methods  (Liu, Simonyan, and Yang 2018; Chu et al. 2020b; Xu et al. 2019) , we use the search space as the building block as shown in Figure  4 . The block could be represented as a directed acyclic graph (DAG):\n\nwhere N is the number of intermediate nodes inside each block. The block is defined to receive two input and one output we respectively set two input nodes as x c k-2 , x c k-1 , and one output node as x c k . Each node x i is a latent representation extracted from its input. Each edge associates with a operator o (i,j) , where o (i,j) transforms x i . The feature transformation between node x i and x j could be defined as:\n\nHere, the searching task could be defined as seeking the operator o (i,j) for each edge from search space O. The selection of one specific operator normally  (Liu, Simonyan, and Yang 2018)  is relaxed as SoftMax probability over all possible operators:\n\nwhere the weights of operators assigned for edge (i, j) are defined as θ\n\n, a probability vector of dimension |O|, the number of all operators. In that case, the structure searching problem could be simplified to optimize set of architecture parameters θ = θ (i,j) o\n\n. While the optimized architecture parameters θ are finalized through searching, the network structure could be obtained by replacing each mixed operation to operators with the highest probability argmax o∈O θ (i,j) o . Under this setting, the goal is jointly to optimize architecture parameters θ and the network weights w. However, due to the complexity of strict joint optimization problems, most works relax this problem to a bi-level optimization problem:\n\nwhere the object is to find optimal structure θ for minimal loss function on the validation set L val while given local optimal w * by fixing local optimal θ from previous optimization step by minimizing loss function L train on the training set. Since this work focuses more on introducing neural architecture search methods into EEG signal processing, here we do not modify the basic problem setting of DARTS  (Liu, Simonyan, and Yang 2018) . Essentially, we use this setting to make the architecture itself a set of 'hyper parameters', thus making it searchable. The motivation of this work is to introduce automatic searching methods to overcome compared less human empirical design exploration in EEG signal processing.",
      "page_start": 10,
      "page_end": 11
    },
    {
      "section_name": "B Detailed Operators In Search Space",
      "text": "As it has mentioned in Section A and Equation  7 , during the searching period, features between each node pair are weighted by mixed operation. In that case, efficient and compatible are important at the same time. If the search space contains many inefficient operators, the 'bad' operators would bring negative effects to the descending of the MetaNet. Meanwhile, if a search space is not compatible for multiple tasks, the searching algorithm can't select proper operators as it is not existing in the search space. Especially, considering the proposed CTNAS-EEG is supposed to perform cross-task searching, a larger search space is more important. EEG signals contain information on both timeseries and spatial aspects. A typical input formation of the raw input signals collected via the 10-20 system has shape bs * datapoints * channels, where data points contain more time-series electrode variances while channels denote spatial information of different electrodes on the human brain. Given the sampling rate of 250hz, a typical sample may contain information within couple of seconds. To avoid the input signal becomes too 'long', we slice the data points dimension of the whole matrix into fragments with intersections and stack these fragments in another dimension, after which, the input signal is processed from bs * datapoints * channels to bs * slices * datapoints * channels. Considering the computational efficiency, we mostly use convolution operators to design our search space. To better adapt normal convolutional kernels to timeseries signals, we provide a series of 'narrow' and 'Flat' kernels. For the 'Narrow' kernels, we provide various lengths of kernels {3, 5, 7, 11, 17} × 1 respectively corresponding to different time-series perception fields. Considering the 250Hz sampling rate, the search space could cover a time window between 12ms to 108ms. Considering the feature flow in the whole network structures, the perception field could be extended to the whole period of the reaction time which is 1.5 seconds. For 'Flat' kernel, we provide various lengths of kernels 1 × {3, 5, 7, 9, 11} corresponding to different EEG channels. The detailed search space we used is listed in Table 4",
      "page_start": 12,
      "page_end": 12
    },
    {
      "section_name": "C Implementation Details",
      "text": "Since the training samples of the BCI IV datasets are limited, we used compared slim search space for training, where the numbers of blocks, and nodes in each blocks defined in Section 3.2 are respectively set to 3 and 3. Since the singalto-norise-rate (SNR) of EEG singals is low, we used compared slim search space for training, where the numbers of blocks, and nodes in each blocks defined in Section 3.2 are respectively set to 3 and 2. We use Adam  (Zhang 2018) , and SGD  (Bottou 2012 ) respectively for updating structure parameters and network weights. For the Adam optimizer, we use an initial learning rate of 0.01 with a multi-step learning rate decay strategy, where the beta value is between 0.5 to 0.99. For SDG optimizer, we use an initial learning rate of 0.01 with Cosine learning rate decay to a minimum value of 0.0001. Normal dropout with dropout rate 0.1 is used in the training process. The structure parameters and the network weights are updated step by step on a 1:1 ratio. The whole search algorithm is implemented in PyTorch 10 , a convenient deep learning library based on python. We release the code on Github to contribute to the open-source community 11 . Each operator in our search space is implemented in a simple block, where before the operation we put the Elu (Clevert, Unterthiner, and Hochreiter 2015) activation function, and after the operation we normalize the output feature map by the batch norm. The networks are trained on 4 Nvidia V100 GPUs, where in order to acquire larger batch size, we also apply distributed training with normal all-reducing gradient synchronization.",
      "page_start": 11,
      "page_end": 12
    },
    {
      "section_name": "D Visualization Of Searching Process D.1 Operator Variance Considering Topology",
      "text": "The mentioned experimental results in main paper Section 4 includes both unified structure search and structure search customized for each subject. In main results we only give an example of visualizing searching process on subject 3 (s3). However in Appendix, we further compare the visualization between unified structure search (on mixed subjects) and subject specific structure search. As the operator between different node pairs may require different properties, we first visualize the probability change on each edge of the search-able cell respectively on MI and Emotion under both unified search setting and subject-specific setting.\n\nBCI Competition IV Dataset for MI It should be noted that we only listed the top 8 operators in our search space for a clear presentation. We keep the hyper-parameters as well as nodes in each search-able cell the same as the performance evaluation experiments reported in Table  1  and Table 2 . Here, the 'none' operator denotes that there is no actual calculation of our feature flow between the given node pair. Here we selected subject 3 (S3) as representative of subject customized structure search as S3 is one of the best subjects in Table  2 . The results of the unified search and subject-specific search are respectively shown and stable, while the probability of different operators is distributed more evenly. However, for Emotion tasks, the network forms operator preferences quickly but also with dramatic change, which is supported by the 'pulse-like' curves reported in Figure  6 . This phenomenon is observed in both unified search and subject-specific search on the SEED V dataset. It suggests that Emotion tasks are more 'picky' than the MI tasks, which means it's harder to select proper structures for Emotion tasks. This observation is also supported by the final searched performance reported in the main paper Table  2  and Table 3 , which were respectively given the same 4 class 13  classification tasks, the performance of MI could reach 88.52% on average accuracy while the Emotion could only reach 76.16%. It is rational since the Emotion of a human subject is normally more confusing to justify compared to Motor Imaginary. This may introduce potential label noise. Meanwhile, the SEED dataset used in this paper stimulates human emotion by playing movie clips with emotional intention in front of human subjects, which may introduce unrelated stimulation from the movie contents. Still, one observation is consistent cross-task-wise, where the subject-specific search has a better degree of separation of selecting operators than the unified search. In other words, the algorithm is more confident and clear in searching structure for a certain subject rather than searching for a unified structure for all subjects. This is rational as all of these tasks share long-existing subject difference problems in the EEG area. Yet, experimental results in this paper support that searching for a specific subject is feasible and could reach competitive performance.",
      "page_start": 11,
      "page_end": 12
    },
    {
      "section_name": "D.2 Visualization Of Searched Structures",
      "text": "Searched Results on BCI Competition IV We visualize the searched whole network structure to provide a direct discussion of what kind of structures might be effective for extracting features from EEG signals. We apply repeat experiments on both mixed-subject search and subjectspecific search and selected searched structure with top 8 highest testing accuracy in Figure  7 . In both scenarios, we could postulate that parallel structure takes a major partition. We think this result is reasonable since operators arranged in parallel formation could extract the input feature with multiple scales, which means the output node of each cell could apply feature fusion from parallel operators. It has been widely mentioned in previous neural network papers  (Huang et al. 2017; Gao et al. 2019; Fang et al. 2020 ) that feature fusion from various scales could improve the accuracy. According to our searched structures, we believe this conclusion also holds for EEG signals, especially fusion between channel-wise operators (1 × n) and time-wise operators (n × 1). Meanwhile, another observation is that the structures from subject-specific search provide more diversity than those from a mixed subjects search. This phenomenon is caused by the subject difference EEG signals.\n\nSearched Results on SEED V Datasets We visualize the searched structures on the SEED V dataset basically follow-ing the setting on the BCI Competition IV dataset. The results are visualized in Figure  8 . It is observed that the structure searched in the SEED V dataset (Emotion) contains fewer skip connections. Oppositely, convolution operators with kernel sizes 3x3 and 5x5 are selected with a higher probability. This means that the Emotion tasks may need more operators to extract useful features from the raw signal.\n\nThe classification performance supports that the Emotion tasks are normally harder compared to MI. In that case, we think this phenomenon is rational. It is also observed that the operator searched in the MI task is more 'narrow' than it in Emotion tasks (eg. MI tasks normally have dilation convolution 9x1, even 17x1, however, Emotion tasks normally have separable convolution 3x3 and dilation convolution 7x1.) This suggests that the MI classification needs more abilities to extract long-time-wise information. This observation is also supported by previous works  (Riyad, Khalil, and Adib 2020; Roots, Muhammad, and Muhammad 2020; Ingolfsson et al. 2020) , which suggests that time-wise signal aggregation is of vital importance for MI classification.",
      "page_start": 13,
      "page_end": 13
    },
    {
      "section_name": "E Hyper Parameters",
      "text": "To provide a reference for follow-up papers, we also conducted additional experiments to discuss which hyperparameters could have an impact on model training for searching. We conduct ablation study majorly on BCI competition IV dataset for fair comparison.\n\nNode number of the search space As mentioned in main paper Section 3, that the basic search-able component is called a search cell, where each search cell has two fixed input and one output nodes. Inside each search cell, the node number decides the upper bound of the edge number in it.\n\nThe node number intrinsically decides the network scale of the search space. To give a more detailed discussion, we conduct an ablation study by only changing the node number of the search space and reporting the test accuracy in Figure  9 .\n\nIt is observed that the search cell with two nodes achieves the best result. Also, the model accuracy slightly decreases while the number of the nodes increasing. This phenomenon is rational as the increasing of node number lead to significantly larger search space, which is harder for searching, especially given only limited data. Throughout our experiments, node number 2 achieves the best result. where the performance of batch size 16 and 8 is far below the best accuracy. We argue this is rational for mixed subjects search. The larger the batch size, the more subjects would be included in one optimization step. Including more subjects in optimization would be crucial for the model to learn common features across different subjects. Otherwise, if the batch size is too small such as 8, the model may learn biased features for only one subject, which may lead to even lower accuracy on other subjects for mixed subjects training. For a subject-specific search, the larger a batch size is does not mean the outcomes are the better. Take subject 3 in Figure  10  as an instance, the training trail with batch size 32 reaches the highest performance 98.01%. Actually, all batch sizes could reach compared good results (above 90%) on subject 3. This result suggests that the batch size does not have a clear impact on the subject-specific training. It should be also noted that, for large batch size 256 and 128, the accuracy is lower than others. We argue this phenomenon is rational since we control the training epochs the same, larger batch size leads to smaller iteration steps. As for each subject, the training samples are extremely limited (500 to 800 trails). This may lead to an under-fit for larger batch sizes.\n\nNetwork Scale Constraint As we mentioned in main paper Section 3.3 that the proposed CTNAS-EEG applied network scale constraint for practical deployment for EEG tasks. It could be observed that, if without the structure constraint, the searched parameter scale varies from 24.1 ∼ 120k. However, according to our repeat experiments the best performance is not achieved under the largest parameter scale. To report model scales and the performance corresponding to them. By running repeat experiments, we report the parameter scales with performances in Figure  11 . It could be observed that, for searched results, the model scale is not the larger the better. For structure constrained search, the searched models could perform multiple levels of accuracy under the same parameter scale. For structure search without constraint, the models with similar accuracy may have very different parameter scales. However, the accuracy of a very large network scale, such as 120k and 105k, sug-  It is observed that, though structure constraint may lead to slight higher classification loss at early stage, the constraint searching is compared have less fluctuation at early stage.\n\nAlong with the constraint annealing, the constrained method (blue line) could reach test loss at later stage. The visualization supports the efficiency of our method.",
      "page_start": 16,
      "page_end": 17
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: After that, the feature shape becomes",
      "page": 2
    },
    {
      "caption": "Figure 1: The overall paradigm structure of CTNAS-EEG, where (a) illustrate how CTNAS receives brain dynamics from",
      "page": 3
    },
    {
      "caption": "Figure 2: The statistical results of operator selected out from",
      "page": 7
    },
    {
      "caption": "Figure 2: For MI tasks, ‘narrow’ operators are more likely to be se-",
      "page": 7
    },
    {
      "caption": "Figure 3: Probability distribution of operators through train-",
      "page": 7
    },
    {
      "caption": "Figure 1: ation experiments. Here we selected subject 3 (S3) in MI as",
      "page": 7
    },
    {
      "caption": "Figure 3: It is observed that, at ‘shallow’",
      "page": 7
    },
    {
      "caption": "Figure 4: A schematic diagram of a differentiable architec-",
      "page": 10
    },
    {
      "caption": "Figure 4: The block could be represented as a directed",
      "page": 10
    },
    {
      "caption": "Figure 5: Operator distribution change on BCI Competition IV dataset during searching considering topology, where Figure 5(a)",
      "page": 12
    },
    {
      "caption": "Figure 5: (a) and Figure 5(b) respectively. It could be ob-",
      "page": 12
    },
    {
      "caption": "Figure 6: (a)) and subject-",
      "page": 12
    },
    {
      "caption": "Figure 6: (b)) is presented following ba-",
      "page": 12
    },
    {
      "caption": "Figure 6: This phenomenon is observed in both",
      "page": 12
    },
    {
      "caption": "Figure 6: Operator distribution change on SEED V dataset during searching considering topology, where Figure 6(a) and 6(b)",
      "page": 13
    },
    {
      "caption": "Figure 7: In both scenarios, we",
      "page": 13
    },
    {
      "caption": "Figure 8: It is observed that the struc-",
      "page": 13
    },
    {
      "caption": "Figure 7: The searched structure on BCI Competition IV datasets, where Figure 7(a) and 7(b) respectively denotes the results",
      "page": 14
    },
    {
      "caption": "Figure 8: The searched structure on SEED V dataset, where Figure 8(a) and 8(b) respectively denotes the results on mixed-",
      "page": 15
    },
    {
      "caption": "Figure 9: It is observed that the search cell with two nodes achieves",
      "page": 16
    },
    {
      "caption": "Figure 9: Impact of node number on model performance",
      "page": 16
    },
    {
      "caption": "Figure 10: , where it should be noted that lines",
      "page": 16
    },
    {
      "caption": "Figure 10: Ablation study on batch size for searching, where",
      "page": 16
    },
    {
      "caption": "Figure 10: as an instance, the training trail with batch size",
      "page": 16
    },
    {
      "caption": "Figure 11: The parameter scale vs. performance distribution",
      "page": 17
    },
    {
      "caption": "Figure 12: Comparison between sparsity constrained search",
      "page": 17
    },
    {
      "caption": "Figure 12: to illustrate the efﬁciency of the proposed",
      "page": 17
    }
  ],
  "tables": [
    {
      "caption": "Table 2: Here, the ‘none’ operator denotes that there is no",
      "data": [
        {
          "Type": "Pooling",
          "Operators": "maxpool 3x3, maxpool 3x1,\nmaxpool 5x1, maxpool 1x3"
        },
        {
          "Type": "Seperable\nConvolution",
          "Operators": "sep 3x1, sep 5x1, sep 7x1, sep 11x1,\nsep 17x1, sep 3x3, sep 5x5, sep 7x7,\nsep 33x3, sep 17x3,sep 1x3, sep 1x5,\nsep 1x7, sep 1x11"
        },
        {
          "Type": "Dilation\nConvolution",
          "Operators": "dil 3x1, dil 5x1, dil 7x1, dil 11x1,\ndil 17x1, dil 3x3, dil 5x5, dil 7x7,\ndil 17x3, dil 33x3, dil 1x3, dil 1x5,\ndil 1x7, dil 1x11"
        },
        {
          "Type": "Others",
          "Operators": "none, skip connection"
        }
      ],
      "page": 11
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Improving BCI-based emotion recognition by combining EEG feature selection and kernel classifiers",
      "authors": [
        "J Atkinson",
        "D Campos"
      ],
      "year": "2016",
      "venue": "Expert Systems with Applications"
    },
    {
      "citation_id": "2",
      "title": "A theoretical analysis of feature pooling in visual recognition",
      "authors": [
        "L Bottou",
        "Springer",
        "Y.-L Boureau",
        "J Ponce",
        "Y Lecun"
      ],
      "year": "2010",
      "venue": "Neural networks: Tricks of the trade"
    },
    {
      "citation_id": "3",
      "title": "Convex optimization",
      "authors": [
        "S Boyd",
        "S Boyd",
        "L Vandenberghe"
      ],
      "year": "2004",
      "venue": "Convex optimization"
    },
    {
      "citation_id": "4",
      "title": "Random forests",
      "authors": [
        "L Breiman"
      ],
      "year": "2001",
      "venue": "Machine learning"
    },
    {
      "citation_id": "5",
      "title": "Robustly Stepping out of Performance Collapse Without Indicators",
      "authors": [
        "X Chu",
        "X Wang",
        "B Zhang",
        "S Lu",
        "X Wei",
        "J Yan"
      ],
      "year": "2020",
      "venue": "Robustly Stepping out of Performance Collapse Without Indicators",
      "arxiv": "arXiv:2009.01027"
    },
    {
      "citation_id": "6",
      "title": "Fairnas: Rethinking evaluation fairness of weight sharing neural architecture search",
      "authors": [
        "X Chu",
        "B Zhang",
        "R Xu",
        "J Li"
      ],
      "year": "2019",
      "venue": "Fairnas: Rethinking evaluation fairness of weight sharing neural architecture search",
      "arxiv": "arXiv:1907.01845"
    },
    {
      "citation_id": "7",
      "title": "Fair DARTS: Eliminating Unfair Advantages in Differentiable Architecture Search",
      "authors": [
        "X Chu",
        "T Zhou",
        "B Zhang",
        "J Li"
      ],
      "year": "2020",
      "venue": "Fair DARTS: Eliminating Unfair Advantages in Differentiable Architecture Search"
    },
    {
      "citation_id": "8",
      "title": "Fast and accurate deep network learning by exponential linear units (elus)",
      "authors": [
        "D.-A Clevert",
        "T Unterthiner",
        "S Hochreiter"
      ],
      "year": "2015",
      "venue": "Fast and accurate deep network learning by exponential linear units (elus)",
      "arxiv": "arXiv:1511.07289"
    },
    {
      "citation_id": "9",
      "title": "Convolutional neural networks on graphs with fast localized spectral filtering",
      "authors": [
        "P Defferrard",
        "Xavier"
      ],
      "year": "2016",
      "venue": "Advances in neural information processing systems"
    },
    {
      "citation_id": "10",
      "title": "Learning Internal Dense But External Sparse Structures of Deep Convolutional Neural Network",
      "authors": [
        "Y Duan",
        "C Feng"
      ],
      "year": "2019",
      "venue": "International Conference on Artificial Neural Networks"
    },
    {
      "citation_id": "11",
      "title": "Encyclopedia of Statistics in Behavioral Science",
      "authors": [
        "B Everitt",
        "D Howell"
      ],
      "year": "2021",
      "venue": "Encyclopedia of Statistics in Behavioral Science"
    },
    {
      "citation_id": "12",
      "title": "Densely connected search space for more flexible neural architecture search",
      "authors": [
        "J Fang",
        "Y Sun",
        "Q Zhang",
        "Y Li",
        "W Liu",
        "X Wang"
      ],
      "year": "2020",
      "venue": "CVPR"
    },
    {
      "citation_id": "13",
      "title": "Res2net: A new multi-scale backbone architecture",
      "authors": [
        "S Gao",
        "M.-M Cheng",
        "K Zhao",
        "X.-Y Zhang",
        "M.-H Yang",
        "P Torr"
      ],
      "year": "2019",
      "venue": "Res2net: A new multi-scale backbone architecture"
    },
    {
      "citation_id": "14",
      "title": "Global2Local: Efficient Structure Search for Video Action Segmentation",
      "authors": [
        "S.-H Gao",
        "Q Han",
        "Z.-Y Li",
        "P Peng",
        "L Wang",
        "M.-M Cheng"
      ],
      "year": "2021",
      "venue": "CVPR"
    },
    {
      "citation_id": "15",
      "title": "Nas-fpn: Learning scalable feature pyramid architecture for object detection",
      "authors": [
        "G Ghiasi",
        "T.-Y Lin",
        "Q Le"
      ],
      "year": "2019",
      "venue": "CVPR"
    },
    {
      "citation_id": "16",
      "title": "Knowledge distillation: A survey",
      "authors": [
        "J Gou",
        "B Yu",
        "S Maybank",
        "D Tao"
      ],
      "year": "2021",
      "venue": "International Journal of Computer Vision"
    },
    {
      "citation_id": "17",
      "title": "Single path one-shot neural architecture search with uniform sampling",
      "authors": [
        "Z Guo",
        "X Zhang",
        "H Mu",
        "W Heng",
        "Z Liu",
        "Y Wei",
        "J Sun"
      ],
      "year": "2019",
      "venue": "Single path one-shot neural architecture search with uniform sampling",
      "arxiv": "arXiv:1904.00420"
    },
    {
      "citation_id": "18",
      "title": "Milenas: Efficient neural architecture search via mixed-level reformulation",
      "authors": [
        "C He",
        "H Ye",
        "L Shen",
        "T Zhang"
      ],
      "year": "2020",
      "venue": "CVPR"
    },
    {
      "citation_id": "19",
      "title": "Fast and accurate multiclass inference for MI-BCIs using large multiscale temporal and spectral features",
      "authors": [
        "M Hersche",
        "T Rellstab",
        "P Schiavone",
        "L Cavigelli",
        "L Benini",
        "A Rahimi",
        "Ieee",
        "U Herwig",
        "P Satrapi",
        "C Schönfeldt-Lecuona"
      ],
      "year": "2003",
      "venue": "2018 26th European Signal Processing Conference (EUSIPCO)"
    },
    {
      "citation_id": "20",
      "title": "Densely connected convolutional networks",
      "authors": [
        "G Huang",
        "Z Liu",
        "L Van Der Maaten",
        "K Weinberger"
      ],
      "year": "2017",
      "venue": "CVPR"
    },
    {
      "citation_id": "21",
      "title": "EEG-TCNet: An Accurate Temporal Convolutional Network for Embedded Motor-Imagery Brain-Machine Interfaces",
      "authors": [
        "T Ingolfsson",
        "M Hersche",
        "X Wang",
        "N Kobayashi",
        "L Cavigelli",
        "L Benini"
      ],
      "year": "2020",
      "venue": "EEG-TCNet: An Accurate Temporal Convolutional Network for Embedded Motor-Imagery Brain-Machine Interfaces",
      "arxiv": "arXiv:2006.00622"
    },
    {
      "citation_id": "22",
      "title": "Filter Bank Common Spatial Pattern (FBCSP) in Brain-Computer Interface",
      "authors": [
        "X Jin",
        "J Wang",
        "J Slocum",
        "M.-H Yang",
        "S Dai",
        "S Yan",
        "J Feng"
      ],
      "year": "2008",
      "venue": "Rc-darts: Resource constrained differentiable architecture search",
      "arxiv": "arXiv:1912.12814"
    },
    {
      "citation_id": "23",
      "title": "CNN based classification of motor imaginary using variational mode decomposed EEG-spectrum image",
      "authors": [
        "K Keerthi Krishnan",
        "K Soman"
      ],
      "year": "2021",
      "venue": "Biomedical Engineering Letters"
    },
    {
      "citation_id": "24",
      "title": "Spatial patterns underlying population differences in the background EEG",
      "authors": [
        "Z Koles",
        "M Lazar",
        "S Zhou"
      ],
      "year": "1990",
      "venue": "Brain topography"
    },
    {
      "citation_id": "25",
      "title": "An efficient mixture model approach in brain-machine interface systems for extracting the psychological status of mentally impaired persons using EEG signals",
      "authors": [
        "N Krishna",
        "K Sekaran",
        "A Vamsi",
        "G Ghantasala",
        "P Chandana",
        "S Kadry",
        "T Blažauskas",
        "R Damaševičius"
      ],
      "year": "2019",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "26",
      "title": "EEGNet: A Compact Convolutional Network for EEG-based Brain-Computer Interfaces",
      "authors": [
        "V Lawhern",
        "A Solon",
        "N Waytowich",
        "S Gordon",
        "C Hung",
        "B Lance"
      ],
      "year": "2016",
      "venue": "Journal of Neural Engineering"
    },
    {
      "citation_id": "27",
      "title": "A novel MI-EEG imaging with the location information of electrodes",
      "authors": [
        "M.-A Li",
        "J.-F Han",
        "L.-J Duan"
      ],
      "year": "2019",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "28",
      "title": "Neural architecture search for lightweight non-local networks",
      "authors": [
        "Y Li",
        "X Jin",
        "J Mei",
        "X Lian",
        "L Yang",
        "C Xie",
        "Q Yu",
        "Y Zhou",
        "S Bai",
        "A Yuille"
      ],
      "year": "2020",
      "venue": "CVPR"
    },
    {
      "citation_id": "29",
      "title": "A novel bi-hemispheric discrepancy model for EEG emotion recognition",
      "authors": [
        "Y Li",
        "L Wang",
        "W Zheng",
        "Y Zong",
        "L Qi",
        "Z Cui",
        "T Zhang",
        "T Song"
      ],
      "year": "2020",
      "venue": "IEEE Transactions on Cognitive and Developmental Systems"
    },
    {
      "citation_id": "30",
      "title": "A Novel Neural Network Model based on Cerebral Hemispheric Asymmetry for EEG Emotion Recognition",
      "authors": [
        "Y Li",
        "W Zheng",
        "Z Cui",
        "T Zhang",
        "Y Zong"
      ],
      "year": "2018",
      "venue": "A Novel Neural Network Model based on Cerebral Hemispheric Asymmetry for EEG Emotion Recognition"
    },
    {
      "citation_id": "31",
      "title": "EEG emotion recognition based on graph regularized sparse linear regression",
      "authors": [
        "Y Li",
        "W Zheng",
        "Z Cui",
        "Y Zong",
        "S Ge"
      ],
      "year": "2019",
      "venue": "Neural Processing Letters"
    },
    {
      "citation_id": "32",
      "title": "Auto-deeplab: Hierarchical neural architecture search for semantic image segmentation",
      "authors": [
        "C Liu",
        "L.-C Chen",
        "F Schroff",
        "H Adam",
        "W Hua",
        "A Yuille",
        "L Fei-Fei"
      ],
      "year": "2019",
      "venue": "CVPR"
    },
    {
      "citation_id": "33",
      "title": "DARTS: Differentiable Architecture Search",
      "authors": [
        "H Liu",
        "K Simonyan",
        "Y Yang"
      ],
      "year": "2018",
      "venue": "DARTS: Differentiable Architecture Search"
    },
    {
      "citation_id": "34",
      "title": "DARTS: Differentiable Architecture Search",
      "authors": [
        "H Liu",
        "K Simonyan",
        "Y Yang"
      ],
      "year": "2019",
      "venue": "DARTS: Differentiable Architecture Search"
    },
    {
      "citation_id": "35",
      "title": "Emotion detection from EEG recordings",
      "authors": [
        "J Liu",
        "H Meng",
        "A Nandi",
        "M Li"
      ],
      "year": "2016",
      "venue": "2016 12th international conference on natural computation, fuzzy systems and knowledge discovery"
    },
    {
      "citation_id": "36",
      "title": "BCI for Games: A 'State of the Art' Survey",
      "authors": [
        "A Nijholt"
      ],
      "year": "2009",
      "venue": "BCI for Games: A 'State of the Art' Survey"
    },
    {
      "citation_id": "37",
      "title": "Entertainment Computing -ICEC 2008",
      "venue": "Entertainment Computing -ICEC 2008"
    },
    {
      "citation_id": "38",
      "title": "Activation functions: Comparison of trends in practice and research for deep learning",
      "authors": [
        "C Nwankpa",
        "W Ijomah",
        "A Gachagan",
        "S Marshall"
      ],
      "year": "2018",
      "venue": "Activation functions: Comparison of trends in practice and research for deep learning",
      "arxiv": "arXiv:1811.03378"
    },
    {
      "citation_id": "39",
      "title": "EEGNAS: Neural architecture search for electroencephalography data analysis and decoding",
      "authors": [
        "E Rapaport",
        "O Shriki",
        "R Puzis",
        "Springer",
        "E Real",
        "A Aggarwal",
        "Y Huang",
        "Q Le"
      ],
      "year": "2019",
      "venue": "International Workshop on Human Brain and Artificial Intelligence"
    },
    {
      "citation_id": "40",
      "title": "Incep-EEGNet: A ConvNet for Motor Imagery Decoding",
      "authors": [
        "M Riyad",
        "M Khalil",
        "A Adib"
      ],
      "year": "2020",
      "venue": "Image and Signal Processing"
    },
    {
      "citation_id": "41",
      "title": "Fusion Convolutional Neural Network for Cross-Subject EEG Motor Imagery Classification",
      "authors": [
        "K Roots",
        "Y Muhammad",
        "N Muhammad"
      ],
      "year": "2020",
      "venue": "Computers"
    },
    {
      "citation_id": "42",
      "title": "Discriminative methods for classification of asynchronous imaginary motor tasks from EEG data",
      "authors": [
        "J Saa"
      ],
      "year": "2013",
      "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering"
    },
    {
      "citation_id": "43",
      "title": "Deep learning with convolutional neural networks for EEG decoding and visualization",
      "authors": [
        "R Schirrmeister",
        "J Springenberg",
        "L Fiederer",
        "M Glasstetter",
        "K Eggensperger",
        "M Tangermann",
        "F Hutter",
        "W Burgard",
        "T Ball"
      ],
      "year": "2017",
      "venue": "Human Brain Mapping"
    },
    {
      "citation_id": "44",
      "title": "MPED: A multi-modal physiological emotion database for discrete emotion recognition",
      "authors": [
        "T Song",
        "W Zheng",
        "C Lu",
        "Y Zong",
        "X Zhang",
        "Z Cui"
      ],
      "year": "2019",
      "venue": "IEEE Access"
    },
    {
      "citation_id": "45",
      "title": "EEG emotion recognition using dynamical graph convolutional neural networks",
      "authors": [
        "T Song",
        "W Zheng",
        "P Song",
        "Z Cui"
      ],
      "year": "2018",
      "venue": "IEEE Transactions on Affective Computing"
    },
    {
      "citation_id": "46",
      "title": "Least squares support vector machine classifiers",
      "authors": [
        "J Suykens",
        "J Vandewalle"
      ],
      "year": "1999",
      "venue": "Neural processing letters"
    },
    {
      "citation_id": "47",
      "title": "Review of the BCI competition IV",
      "authors": [
        "M Tangermann",
        "K Müller",
        "A -R.; Aertsen",
        "N Birbaumer",
        "C Braun",
        "C Brunner",
        "R Leeb",
        "C Mehring",
        "K Miller",
        "G Mueller-Putz"
      ],
      "year": "2012",
      "venue": "Frontiers in neuroscience"
    },
    {
      "citation_id": "48",
      "title": "Brain-controlled telepresence robot by motor-disabled people",
      "authors": [
        "L Tonin",
        "T Carlson",
        "R Leeb",
        "J Del R. Millán"
      ],
      "year": "2011",
      "venue": "2011 Annual International Conference of the IEEE Engineering in Medicine and Biology Society"
    },
    {
      "citation_id": "49",
      "title": "A new fractal pattern feature generation function based emotion recognition method using EEG",
      "authors": [
        "T Tuncer",
        "S Dogan",
        "A Subasi"
      ],
      "year": "2021",
      "venue": "Chaos, Solitons & Fractals"
    },
    {
      "citation_id": "50",
      "title": "Review of the emotional feature extraction and classification using EEG signals",
      "authors": [
        "J Wang",
        "M Wang"
      ],
      "year": "2021",
      "venue": "Cognitive Robotics"
    },
    {
      "citation_id": "51",
      "title": "Emotional state classification from EEG data using machine learning approach",
      "authors": [
        "X.-W Wang",
        "D Nie",
        "B.-L Lu"
      ],
      "year": "2014",
      "venue": "Neurocomputing"
    },
    {
      "citation_id": "52",
      "title": "Continual Learning With Lifelong Vision Transformer",
      "authors": [
        "Z Wang",
        "L Liu",
        "Y Duan",
        "Y Kong",
        "D Tao"
      ],
      "year": "2022",
      "venue": "CVPR"
    },
    {
      "citation_id": "53",
      "title": "Deep Streaming Label Learning",
      "authors": [
        "Z Wang",
        "L Liu",
        "D Tao"
      ],
      "year": "2020",
      "venue": "ICML"
    },
    {
      "citation_id": "54",
      "title": "DBSVEC: Density-based clustering using support vector expansion",
      "authors": [
        "Z Wang",
        "R Zhang",
        "J Qi",
        "B Yuan"
      ],
      "year": "2019",
      "venue": "IEEE 35th International Conference on Data Engineering (ICDE)"
    },
    {
      "citation_id": "55",
      "title": "Most popular signal processing methods in motorimagery BCI: a review and meta-analysis",
      "authors": [
        "P Wierzgała",
        "D Zapała",
        "G Wojcik",
        "J Masiak"
      ],
      "year": "2018",
      "venue": "Frontiers in neuroinformatics"
    },
    {
      "citation_id": "56",
      "title": "Genetic cnn",
      "authors": [
        "L Xie",
        "A Yuille"
      ],
      "year": "2017",
      "venue": "CVPR"
    },
    {
      "citation_id": "57",
      "title": "PC-DARTS: Partial Channel Connections for Memory-Efficient Differentiable Architecture Search",
      "authors": [
        "Y Xu",
        "L Xie",
        "X Zhang",
        "X Chen",
        "G Qi",
        "Q Tian",
        "H Xiong"
      ],
      "year": "2019",
      "venue": "PC-DARTS: Partial Channel Connections for Memory-Efficient Differentiable Architecture Search"
    },
    {
      "citation_id": "58",
      "title": "Hierarchical fuzzy neural networks with privacy preservation for heterogeneous big data",
      "authors": [
        "Y Xu",
        "L Xie",
        "X Zhang",
        "X Chen",
        "G.-J Qi",
        "Q Tian",
        "H Xiong",
        "L Zhang",
        "Y Shi",
        "Y.-C Chang",
        "C.-T Lin"
      ],
      "year": "2020",
      "venue": "ICLR"
    },
    {
      "citation_id": "59",
      "title": "Spatial-temporal recurrent neural network for emotion recognition",
      "authors": [
        "T Zhang",
        "W Zheng",
        "Z Cui",
        "Y Zong",
        "Y Li"
      ],
      "year": "2018",
      "venue": "IEEE transactions on cybernetics"
    },
    {
      "citation_id": "60",
      "title": "Multichannel EEG-based emotion recognition via group sparse canonical correlation analysis",
      "authors": [
        "Z Zhang"
      ],
      "year": "2016",
      "venue": "2018 IEEE/ACM 26th International Symposium on Quality of Service (IWQoS)"
    },
    {
      "citation_id": "61",
      "title": "Investigating critical frequency bands and channels for EEG-based emotion recognition with deep neural networks",
      "authors": [
        "W.-L Zheng",
        "B.-L Lu"
      ],
      "year": "2015",
      "venue": "IEEE Transactions on autonomous mental development"
    },
    {
      "citation_id": "62",
      "title": "Neural Architecture Search with Reinforcement Learning",
      "authors": [
        "B Zoph",
        "Q Le"
      ],
      "venue": "Neural Architecture Search with Reinforcement Learning"
    },
    {
      "citation_id": "63",
      "title": "Learning transferable architectures for scalable image recognition",
      "authors": [
        "B Zoph",
        "Q Le",
        "B Zoph",
        "V Vasudevan",
        "J Shlens",
        "Q Le"
      ],
      "year": "2017",
      "venue": "ICLR"
    }
  ]
}