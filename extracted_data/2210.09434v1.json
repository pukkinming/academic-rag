{
  "paper_id": "2210.09434v1",
  "title": "Modelling Emotion Dynamics In Song Lyrics With State Space Models",
  "published": "2022-10-17T21:07:23Z",
  "authors": [
    "Yingjin Song",
    "Daniel Beck"
  ],
  "keywords": [],
  "sections": [
    {
      "section_name": "Abstract",
      "text": "Most previous work in music emotion recognition assumes a single or a few songlevel labels for the whole song. While it is known that different emotions can vary in intensity within a song, annotated data for this setup is scarce and difficult to obtain. In this work, we propose a method to predict emotion dynamics in song lyrics without song-level supervision. We frame each song as a time series and employ a State Space Model (SSM), combining a sentence-level emotion predictor with an Expectation-Maximization (EM) procedure to generate the full emotion dynamics. Our experiments show that applying our method consistently improves the performance of sentence-level baselines without requiring any annotated songs, making it ideal for limited training data scenarios. Further analysis through case studies shows the benefits of our method while also indicating the limitations and pointing to future directions.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Introduction",
      "text": "Music and emotions are intimately connected, with almost all music pieces being created to express and induce emotions  (Juslin and Laukka, 2004) . As a key factor of how music conveys emotion, lyrics contain part of the semantic information that the melodies cannot express  (Besson et al., 1998) . Lyrics-based music emotion recognition has attracted increasing attention driven by the demand to process massive collections of music tracks automatically, which is an important task to streaming and media service providers  (Kim et al., 2010; Malheiro et al., 2016; Agrawal et al., 2021) .\n\nMost emotion recognition studies in Natural Language Processing (NLP) assume the text in-stance expresses a static and single emotion  (Mohammad and Bravo-Márquez, 2017; Nozza et al., 2017; Mohammad et al., 2018a) . However, emotion is non-static and highly correlated with the contextual information, which makes the singlelabel assumption too simplistic in dynamic scenarios, not just in music  (Schmidt and Kim, 2011)  but also in other domains such as conversations  (Poria et al., 2019b) . Figure  1  shows an example of this dynamic behaviour, where the intensities of three different emotions vary within a song. Accurate emotion recognition systems should ideally be able to generate the full emotional dynamics for each song, as opposed to simply predicting a single label.\n\nA range of datasets and corpora for modelling dynamic emotion transitions has been developed in the literature  (McKeown et al., 2011; Li et al., 2017; Hsu et al., 2018; Poria et al., 2019a; Firdaus et al., 2020) , but most of them do not use song lyrics as the domain and assume discrete, categorical labels for emotions (either the presence or absence of one emotion). To the best of our knowledge, the dataset from  Mihalcea and Strapparava (2012)  is the only one that provides full fine-grained emotion intensity annotations for song lyrics at the verse 1  level. The lack of largescale datasets for this task poses a challenge for traditional supervised methods. While previous work proposed methods for the similar sequencebased emotion recognition task, they all assume the availability of some levels of annotated data at training time, from full emotion dynamics  (Kim et al., 2015)  to coarse, discrete document-level labels  (Täckström and McDonald, 2011b) .\n\nThe data scarcity problem motivates our main research question: \"Can we predict emotion dynamics in song lyrics without requiring annotated lyrics?\". In this work, we claim that the an-   Mihalcea and Strapparava (2012) . Note the intensities of each emotion vary from verse to verse within the song.\n\nswer is affirmative. To show this, we propose a method consisting of two major stages: (1) a sentence or verse-level regressor that leverages existing emotion lexicons, pre-trained language models and other sentence-level datasets and (2) a State Space Model (SSM) that constructs a full songlevel emotional dynamics given the initial verselevel scores. Intuitively, we treat each verse as a time step and the emotional intensity sequence as a latent time series that is inferred without any songlevel supervision, directly addressing the limited data problem. To the best of our knowledge, this scenario was never addressed before either for song lyrics or other domains.\n\nTo summarize, our main contributions are:\n\n• We propose a hybrid approach for verse-level emotion intensity prediction that combines emotion lexicons with a pre-trained language model (BERT  (Devlin et al., 2019)  used in this work), which is trained on available sentence-level data.\n\n• We further show that by using SSMs to model the song-level emotion dynamics, we can improve the performance of the verselevel approach without requiring any annotated lyrics.\n\n• We perform a qualitative analysis of our best models, highlighting its limitations and pointing to directions for future work.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Background And Related Work",
      "text": "Emotion Models. Human emotion is a longstanding research field in psychology, with many studies aiming at defining a taxonomy for emotions. In NLP, emotion analysis mainly employs the datasets which are annotated based on the categorical or the dimensional model. The categorical model assumes a fixed set of discrete emotions which can vary in intensity. Emotions can overlap but are assumed to be separate \"entities\" for each other, such as anger, joy and surprise. Taxonomies using the categorical model include Ekman's basic emotions  (Ekman, 1993 ) and Plutchik's wheel of emotions  (Plutchik, 1980) . The dimensional models place emotions in a continuous space: the VAD (Valence, Arousal and Dominance) taxonomy of  Russell (1980)  is the most commonly used in NLP. In this work, we focus on the Ekman taxonomy for purely experimental purposes, as it is the one used in the available data we employ. However, our approach is general and could be applied to other taxonomies. Dynamic Emotion Analysis. Emotion Recognition in Conversation (ERC)  (Poria et al., 2019b) , which focuses on tracking dynamic shifts of emotions, is the most similar task to our work. Within a conversation, the emotional state of each utterance is influenced by the previous state of the party and the stimulation from other parties  (Li et al., 2020; Ghosal et al., 2021) . Such an assumption of the real-time dynamic emotional changes also exists in music: the affective state of the current lyrics verse is correlated with the state of the previous verse(s) as a song progresses.\n\nContextual information in the ERC task is generally captured by deep learning models, which can be roughly categorized into sequence-based and graph-based methods  (Hu et al., 2021) . Sequence-based methods encode conversational context features using established methods like Recurrent Neural Networks  (Poria et al., 2017; Hazarika et al., 2018a,b; Majumder et al., 2019; Hu et al., 2021)  and Transformer-based architectures  (Zhong et al., 2019; Li et al., 2020) . They also include more advanced and tailored methods like Hierarchical Memory Network  (Jiao et al., 2020) , Emotion Interaction Network  (Lu et al., 2020)  and Causal Aware Network  (Zhao et al., 2022) . Graph-based methods apply specific graphical structures to model dependencies in conversations  (Ghosal et al., 2019; Zhang et al., 2019; Lian et al., 2020; Ishiwatari et al., 2020; Shen et al., 2021)  by utilizing Graph Neural Networks  (Kipf and Welling, 2017) . In contrast to these methods, we capture contextual information using a State Space Model, mainly motivated by the need for a method that can train without supervision. Extending and/or combining an SSM with a deep learning model is theoretically possible but non-trivial, and care must be taken in a low-data situation such as ours.\n\nThe time-varying nature of music emotions has been investigated in music information retrieval  (Caetano et al., 2012) . To link the human emotions with the music acoustic signal, the emotion distributions were modelled as 2D Gaussian distributions in the Arousal-Valence (A-V) space, which were used to predict A-V responses through multilabel regression  (Schmidt et al., 2010; Schmidt and Kim, 2010) . Building on previous studies,  Schmidt and Kim (2011)  applied structured prediction methods to model complex emotion-space distributions as an A-V heatmap. These studies focus on the mapping between emotions and acoustic features/signals, while our work focuses on the lyrics component.  Wu et al. (2014)  developed a hierarchical Bayesian model that utilized both acoustic and textual features, but it was only applied to predict emotions as discrete labels (presence or absence) instead of fine-grained emotion intensities as in our work.\n\nCombining pre-trained Language Models with External Knowledge. Pre-trained language models (LMs) including BERT  (Devlin et al., 2019) , XLNet  (Yang et al., 2019)  and GPT  (Brown et al., 2020)  have achieved state-of-the-art performance in numerous NLP tasks. Considerable effort has been made towards combining context-sensitive features of LMs with factual or commonsense knowledge from structured sources, including domain-specific knowledge  (Ying et al., 2019) , structured semantic information  (Zhang et al., 2020) , language-specific knowledge  (Alghanmi et al., 2020; De Bruyne et al., 2021)  and linguistic features  (Koufakou et al., 2020; Mehta et al., 2020) . This auxiliary knowledge is usually infused into the architecture by concatenating them with the Transformerbased representation before the prediction layer for downstream tasks. Our method proposes to utilize the rule-based representations derived from a bunch of affective lexicons to improve the performance of BERT by incorporating task-specific knowledge. The motivation for our proposal is the hypothesis that the extension of lexicon-based information will compensate for BERT's lack of proper representations of semantic and world knowledge  (Rogers et al., 2021) , making the model more stable across domains.\n\nState Space Models. In NLP tasks such as Part-of-Speech (POS) tagging and Named Entity Recognition, contextual information is widely acknowledged to play an important role in prediction. This leads to the adoption of structured prediction approaches such as Hidden Markov Model (HMM)  (Rabiner and Juang, 1986) , Maximum Entropy Markov Model (MEMM)  (McCallum et al., 2000)  and Conditional Random Field (CRF)  (Lafferty et al., 2001) , which relate a set of observable variables to a set of latent variables (e.g., words and their POS tags). State Space Models (SSMs) are similar to HMMs but assume continuous variables. Linear Gaussian SSM (LG-SSM) is a particular case of SSM in which all the conditional probability distributions are linear and Gaussian.\n\nFollowing the notation from Murphy (2012, Chap. 18), we briefly introduce the LG-SSM that we employ in our work. LG-SSMs assume a sequence of observed variables y 1:T as input, and the goal is to draw inferences about the corresponding hidden states z 1:T , where T is the length of the sequence. Their relationship is given at each step t by the equations as:\n\nwhere Θ = (A, C, Q, R) are the model parameters, t is the system noise and δ t is the observation noise. The equations above are also referred as transition 2  and observation equations, respectively. Given Θ and a sequence y 1:T , the goal is to obtain the posteriors p(z t ) for each step t. In an LG-SSM, this posterior is a Gaussian and can be obtained in closed form by applying the celebrated Kalman Filter  (Kalman, 1960)  .\n\nThere exist some other latent variable models to estimate temporal dynamics of emotions and sentiments in product reviews  (McDonald et al., 2007; Täckström and McDonald, 2011a,b)  and blogs  (Kim et al., 2015) .  McDonald et al. (2007)  and  Täckström and McDonald (2011a,b)  combined document-level and sentence-level supervision as the observed variables to condition on the latent sentence-level sentiment.  Kim et al. (2015)  introduced a continuous variable y t to solely determine the sentiment polarity z t , while z t is conditioned on both y t and z t-1 for each t in the LG-SSM.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Method",
      "text": "We propose a two-stage method to predict emotion dynamics without requiring annotated song lyrics. The first stage is a verse-level model that predicts initial scores for each song verse, where we use a hybrid approach combining lexicons and sentence-level annotated data from a different domain ( §3.1). The second stage contextualizes these scores in the entire song, incorporating them into an LG-SSM trained in an unsupervised way ( §3.2).",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Task Formalization. Let D Y",
      "text": "x indicate the realvalued intensity of emotion y for sentence/ verse x, where x ∈ X and y ∈ Y. Note that Y = {y 1 , y 2 , . . . , y c } is a set of c labels, each of which represents one of the basic emotions (c = 6 for the datasets we used). Given a source dataset\n\nwhere |D t | is the number of sequences (i.e., songs) and\n\nIn the song S i , the j-th verse v j is also associated with c emotion intensities as E j = {d y 1 v j , d y 2 v j , . . . , d yc v j }. Given the homogeneity of label spaces of D s and D t , the model trained by using D s can be applied to predict for D t directly. The output of verselevel model is the emotion intensity predictions Ŷ ∈ R N ×c , where N is the total number of verses in D t . Finally, we use Ŷ as the input sequences of the song-level model to produce optimized emotion intensity sequences Ẑ ∈ R |Dt|×c .",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Verse-Level Model",
      "text": "Emotion lexicons provide information on associations between words and emotions (Ramachandran and de Melo, 2020), which are proven to be beneficial in recognising textual emotions  (Mohammad et al., 2018b; Zhou et al., 2020) . Given that we would like to acquire accurate initial predictions at the verse level, we opted for a hybrid methodology that combines learning-based and lexicon-based approaches to enhance feature representation.\n\nOverview. The verse-level model architecture is called BERTLex, as illustrated in Figure  2 . The BERTLex model consists of three phases: (1) the embedding phase, (2) the integration phase, and (3) the prediction phase. In the embedding phase, the input sequence is represented as both contextualized embeddings from BERT and static word embeddings from lexicons. In the integration phase, contextualized and static word embeddings are concatenated at the sentence level by taking the pooling operations on the two embeddings separately. The prediction phase encodes the integrated sequence of feature vectors and performs the verse-level emotion intensity regression by using the D s as the training/development set and the D t as the test set.\n\nEmbedding Phase. The input sentence S is tokenized in two ways: one for the pre-trained language model and the other for the lexicon-based word embedding. These two tokenized sequences are denoted as T cxt and T lex , respectively. Then, T cxt is fed into the pre-trained BERT to produce a sequence of contextualized word embeddings\n\nTo capture task-specific information, a Lexicon embedding layer encodes a sequence of emotion and sentiment word associations for T lex , generating a sequence of lexicon-based embeddings\n\nand D lex is the lexical embedding vector dimension. We first build the vocabulary V from the text of D s and D t . For each word v i in V of T lex , we use d lexicons to generate the rule-based feature vectors i = { i 1 , i 2 , . . . , i d }, where i j is the lexical feature vector for word v i derived from the j-th lexicon and D lex = | i |. Additionally, we perform a degree-p polynomial expansion on the feature vector i j .\n\nIntegration Phase. As BERT uses the Word-Piece tokenizer  (Wu et al., 2016)  to split a number of words into a sequence of subwords, the contextualized embedding cannot be directly concatenated with the different-size static word embedding. Inspired by  Alghanmi et al. (2020) , we combine the contextualized embeddings and static word embeddings at the sentence level by pooling the two embeddings E cxt and E lex separately. To perform initial feature extraction from the raw\n\nwhere W 1 , b 1 , W 2 and b 2 are trainable parameters and k is the kernel size. We then apply the average pooling and max pooling on the feature maps, respectively:\n\nFinally, the contextualised embedding and the lexicon-based embedding are merged via a concatenation layer as Ẽcxt ⊕ Ẽlex .\n\nPrediction Phase. The prediction phase outputs the emotion intensity predictions Ŷ = {ŷ 1 , ŷ2 , . . . , ŷN } by using a single dropout  (Srivastava et al., 2014)  layer and a linear regression layer. During training, the mean squared error loss is computed and backpropagated to update the model parameters.",
      "page_start": 1,
      "page_end": 1
    },
    {
      "section_name": "Song-Level Model",
      "text": "After obtaining initial verse-level predictions, the next step involves incorporating these into a songlevel model using an LG-SSM. We take one type of emotion as an example. Specifically, we consider the predicted scores of this emotion of each song as an observed sequence ŷi . That is, we group the N predictions of Ŷ as |D t | sequences of predictions as {ŷ 1 , ŷ2 , . . . , ŷ|Dt| }. For the i-th song, the observed sequence ŷi = y 1:T is then used in an LG-SSM to obtain the latent sequence ẑ1:T that represents the song-level emotional dynamics, where T is the number of verses in the song.\n\nStandard applications of LG-SSM assume a temporal ordering in the sequence. This means that estimates of p(ẑ t ) should only depend on the observed values up to the verse step t (i.e., y 1:t ), which is the central assumption to the Kalman Filter algorithm. Given the sequence of observations, we recursively apply the Kalman Filter to calculate the mean and variance of the hidden states, whose computation steps are displayed in Algorithm 1.\n\nSince we have obtained initial predictions for all verses in a song, we can assume that observed emotion scores are available for the sequence of an entire song a priori. In other words, we can include the \"future\" data (i.e., y t+1:T ) to estimate the latent posteriors p(ẑ t ). This is achieved by using the Kalman smoothing algorithm, also known as RTS smoother  (Rauch et al., 1965) , which is shown in Algorithm 2.\n\nAs opposed to most other algorithms, the Algorithm 1: Kalman Filter Input :\n\nApply the Kalman Filter (refer to Algorithm 1);\n\nKalman Filter and Kalman Smoother algorithms are used with already known parameters. Hence, learning the SSM involves estimating the parameters Θ. If a set of gold-standard values for the complete z 1:T is available, they can be learned using a Maximum Likelihood Estimation (MLE). If only the noisy, observed sequences y 1:T are present, the Expectation-Maximization (EM) algorithm  (Dempster et al., 1977)  provides an iterative method for finding the MLEs of Θ by successively maximizing the conditional expectation of the complete data likelihood until convergence.",
      "page_start": 5,
      "page_end": 6
    },
    {
      "section_name": "Experiments",
      "text": "Our experiments aim to evaluate the method proposed to predict the emotional dynamics of song lyrics without utilizing any annotated lyrics data. We introduce datasets, lexicon resources and evaluation metric used ( §4.1), and discuss the imple-mentation details and experiment settings of verselevel model ( §4.2) and song-level model ( §4.3).",
      "page_start": 7,
      "page_end": 7
    },
    {
      "section_name": "Datasets And Evaluation",
      "text": "LyricsEmotions. This corpus was developed by  Mihalcea and Strapparava (2012) , consisting of 100 popular English songs with 4,975 verses in total. The number of verses for each song varies from 14 to 110. The LYRICSEMOTIONS dataset was constructed by extracting the parallel alignment of musical features and lyrics from MIDI tracks. These lyrics were annotated using Mechanical Turk at verse level with real-valued intensity scores ranging from 0 to 10 of six Ekman's emotions  (Ekman, 1993) : ANGER, DISGUST, FEAR, JOY, SADNESS and SURPRISE. Given that our goal is to predict emotions without relying on song-level dynamics, we use this dataset for evaluation purposes only.\n\nNewsHeadlines. To train the verse-level model, we employ the NEWSHEADLINES 3 dataset (Strapparava and  Mihalcea, 2007) , which is a collection of 1,250 news headlines. Each headline is annotated with six scores ranging from 0 to 100 for each of Ekman's emotions and one score ranging from -100 to 100 for valence.\n\nLexicons. Following  Goel et al. (2017)  and  Meisheri and Dey (2018) , we use nine emotion and sentiment related lexicons to obtain the feature vectors from the text in NEWSHEADLINES and LYRICSEMOTIONS, summarized in Table  1 .\n\nEvaluation. In line with  Mihalcea and Strapparava (2012) , we use the Pearson correlation coefficient (r) as the evaluation metric to measure the correlation between the predictions and ground truth emotion intensities. To assess statistical significance, we conduct the Williams test  (Williams, 1959)  in the differences between the Pearson correlations of each pair of models.\n\nFor baselines, our method is unsupervised at the song level, and we are not aware of prior work tackling similar cases. Therefore, we use the results of the verse-level model as our main baseline. We argue that this is a fair baseline since the SSMbased model does not require additional data. BERTLex. The sequence of embeddings for each token, including [CLS] and [SEP] at the output of the last layer of the BERT base model, is fed into a Conv1D layer with 128 filters and a kernel size of 3, followed by a 1D global average pooling layer.\n\nWe concatenate nine vector representations for every word in the established vocabulary by using the lexicons in Table  1  in the identical order to form a united feature vector. As a result, the whole word embedding is in the shape of  (3309, 25) , where 3309 is the vocabulary size and 25 is the number of lexicon-based features. To validate if adding polynomial features can make better predictions, we also perform a polynomial feature expansion with a degree of 3, extending the shape of vector representations to  (3309, 267) . Then, static word embeddings are fed a Conv1D layer with 128 filters and a kernel size of 3, followed by a global max-pooling layer.\n\nThe two pooled vectors are then concatenated through a Concatenate layer as they are in the same dimensionality. We generate the predictions of emotion intensities by using a Linear layer with a single neuron 4  for regression. Training. Instead of using the standard train/dev/test split of the NEWSHEADLINES dataset, we apply 10-fold cross-validation to tune the hyperparameters of BERT-based models. Empirically tuned hyperparameters are listed in Table  2  and are adopted in the subsequent experiments unless otherwise specified. After tuning, the final models using this set of hyperparameters are trained on the full NEWSHEADLINES data. We use an ensemble of five runs, taking the mean of the predictions as the final output.",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Song-Level Experiments",
      "text": "We apply the library pykalman (version 0.9.2) 5  , which implements the Kalman Filter, the Kalman Smoother and the EM algorithm to train SSMs. We fix the initial state mean as the first observed value in the sequence (i.e., each song's first verselevel prediction) and the initial state covariance as 2. We then conduct experiments with several groups of parameters transition matrices timization, we experiment n_iter = {1,3,5,7,10} to control the number of EM algorithm iterations. Additionally, we apply 10-fold cross-validation when choosing the optimal parameters via EM, which means each song is processed by a Kalman Filter or Kalman Smoother defined by the optimal parameters that we obtained from training on the other 90 songs.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Results And Analysis",
      "text": "In this section, we report and discuss the results of the experiments. We first compare the results of our lexicon-based, learning-based and hybrid methods at the verse level ( §5.1). We then provide the results of song-level models and investigate the impact of initial predictions from verse-level models, SSM parameters, and parameter optimization ( §5.2). We additionally show the qualitative case analysis results to understand our model's abilities and shortcomings ( §5.3).",
      "page_start": 8,
      "page_end": 8
    },
    {
      "section_name": "Results Of Verse-Level Models",
      "text": "Table  3  shows the results of verse-level models on the NEWSHEADLINES (average of 10-fold crossvalidation) and LYRICSEMOTIONS (as the test set) datasets. The domain difference is significant in news and lyrics, as we can observe from the different performances of BERT-based models on the two datasets. Overall, our BERTLex method outperforms the lexicon-only and BERT-only baselines and exhibits the highest Pearson correlation of 0.503 (BERTLex poly for JOY) in LYRICSEMO-TIONS.\n\nHaving a closer look at the results of LYRICSE-MOTIONS, we also observe the following:\n\n• The addition of lexicons for incorporating external knowledge consistently promotes the performance of BERT-based models.\n\n• BERTLex models with polynomial feature expansion are better than those without, except for DISGUST.\n\n• Our models are worst at predicting the emotion intensities of SURPRISE (lower than 0.1), which is in line with similar work in other datasets annotated with the Ekman taxonomy.",
      "page_start": 9,
      "page_end": 9
    },
    {
      "section_name": "Results Of Song-Level Models",
      "text": "Extensive experiments confirm that our song-level models utilizing the Kalman Filter and Kalman Smoother can improve the initial predictions from verse-level models combining BERT and lexicons (see Table  4  and Table 5 ). The LG-SSMs with EM-optimized parameters always perform better than those without using EM. Furthermore, the performance improvements of the strongest SSMs from their corresponding verse-level baselines are statistically significant at 0.05 confidence (marked with *), except for SURPRISE.\n\nTheoretically, the Kalman Smoother is supposed to perform better than the Kalman Filter since the former utilizes all observations in the whole sequence. According to our experimental results, however, the best-performing algorithm depends on emotion. On the other hand, running the EM algorithm consistently improves the results of SSMs that simply use the initial values, except for SURPRISE.\n\nImpact of verse-level predictions. The performances of applying Kalman Filter, Kalman   4 ). The other parameters are fixed as Q = 1, C = 1, R = 5 and n_iter = 5.\n\nSmoother and EM algorithm are associated with the initial scores predicted by verse-level models. For the same emotion, we compare the results based on the mean predictions from the BERTLex models with and without polynomial expansion on lexical features, respectively (shown in Table  4 ). We observe that the higher the Pearson correlation between the ground truth and the verse-level predictions, the more accurate the estimates obtained after using LG-SSMs accordingly. The strongest SSMs also differ with the different emotion types and initial predictions, as denoted in boldface.\n\nImpact of initial parameters. The results of Kalman Filter and Kalman Smoother are sensitive to the initial model parameters. As displayed in Table  5 , when we only change the value of tran-sition matrices A and fix the other parameters, the performance of Kalman Filter and Kalman Smoother can be decreased even worse than without them. Fortunately, this kind of diminished performance due to the initial parameter values can be diluted by optimizing the parameters with an EM algorithm.\n\nImpact of parameter optimization. For either Kalman Filter or Kalman Smoother, using the EM algorithm to optimize the parameters increases Pearson's r in most cases. Through experiments, the number of iterations does not significantly influence the performance of the EM algorithm, and 5 ∼ 10 iterations usually produce the strongest results.",
      "page_start": 10,
      "page_end": 10
    },
    {
      "section_name": "Qualitative Case Studies",
      "text": "To obtain some insights into further improvement, we examine the errors that our models are making.  emotional dynamics (see the third sub-figure in Figure  4 ). The emotional dynamics trend of estimates by song-level models is similar to verselevel models. Due to the Gaussian assumption, Kalman Filter and Kalman Smoother tend to flatten or smooth the curves of verse-level predictions. This means that applying LG-SSMs can somewhat reduce errors in the second type of emotion dynamic curves. For the first type, however, the Kalman Filter and Kalman Smoother make the results worse, as smoother estimations are not desirable in this situation.\n\nUsing text solely. Lyrics in LYRICSEMOTIONS are synchronised to acoustic features, where some verses with identical text are labelled as different emotional intensities. For instance, in Table  6 , the verse \"When it rain and rain, it rain and rain\" repeats multiple times in the song Rain by Mika, and their gold-standard SADNESS labels differ in different verses as the emotion progresses with music. However, the verse-level models can only produce the same predictions since these verses share exactly the same text, and the models do not consider the context of the whole song. Consequently, the emotion scores of different verses predicted by LG-SSMs are close, as the results of song-level models are highly related to the initial predictions from BERTLex. • While our method could apply any general verse-level model, including a pure lexiconbased one, in practice, we obtained the best results by leveraging annotated sentencelevel datasets. This naturally leads to the domain discrepancy: in our particular case, between the news and lyrics domains. Given that unlabelled song lyrics are relatively easy to obtain, one direction is to incorporate unsupervised domain adaptation techniques  (Ramponi and Plank, 2020)  to improve the performance of the verse-level model. Semisupervised learning (similar to  Täckström and McDonald (2011b) ) is another promising direction in this avenue, although methods would need to be modified to incorporate the continuous nature of the emotion labels.\n\n• Despite being able to optimize the estimates through Kalman Filter and Kalman Smoother, the simplicity of the LG-SSM makes it difficult to deal with the wide variations in emotion space dynamics, given that it is a linear model. We hypothesize that non-linear SSM extensions  (Julier and Uhlmann, 1997; Ito and Xiong, 2000; Julier and Uhlmann, 2004 ) might be a better fit for modelling emotion dynamics.\n\n• As the LYRICSEMOTIONS dataset is annotated on parallel acoustic and text features, using lyrics solely as the feature can cause inconsistencies in the model. Extending our method to a multi-modal setting would remedy this issue when the identical lyrics are companions with different musical features to appear in various verses. Taking the knowledge of song structure (e.g., Intro -Verse -Bridge -Chorus) into account has the potential to advance the recognition of emotion dynamics, assuming the way (up or down) that emotion intensities change is correlated with which part of the song the verses locate.",
      "page_start": 11,
      "page_end": 11
    }
  ],
  "figures": [
    {
      "caption": "Figure 1: shows an example of",
      "page": 1
    },
    {
      "caption": "Figure 1: An illustration of emotion dynamics of a",
      "page": 2
    },
    {
      "caption": "Figure 2: BERTLex architecture used for the verse-level model.",
      "page": 5
    },
    {
      "caption": "Figure 3: The SURPRISE emotion intensities of",
      "page": 10
    },
    {
      "caption": "Figure 3: shows the emotion dy-",
      "page": 10
    },
    {
      "caption": "Figure 4: The other is the opposite that verse-",
      "page": 10
    },
    {
      "caption": "Figure 4: Emotional dynamics of ANGER, DISGUST",
      "page": 10
    },
    {
      "caption": "Figure 4: ). The emotional dynamics trend of es-",
      "page": 10
    }
  ],
  "tables": [
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "†School of Computing and Information Systems, The University of Melbourne": "y.song5@uu.nl\nd.beck@unimelb.edu.au"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "stance expresses a static and single emotion (Mo-\nAbstract"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "hammad and Bravo-Márquez, 2017; Nozza et al.,"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "Most\nprevious work\nin music\nemotion"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "2017; Mohammad et al., 2018a). However, emo-"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "recognition assumes a single or a few song-"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "tion is non-static and highly correlated with the"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "level\nlabels\nfor\nthe whole song. While it"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "contextual\ninformation, which makes the single-"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "is known that different emotions can vary"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "label assumption too simplistic in dynamic scenar-"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "in intensity within a song,\nannotated data"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "ios, not just in music (Schmidt and Kim, 2011) but"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "for\nthis setup is scarce and difﬁcult\nto ob-"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "also in other domains such as conversations (Po-\ntain.\nIn this work, we propose a method"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "to predict emotion dynamics in song lyrics\nria et al., 2019b). Figure 1 shows an example of"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "without\nsong-level\nsupervision. We frame"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "this dynamic behaviour, where the intensities of"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "each\nsong\nas\na\ntime\nseries\nand\nemploy"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "three different emotions vary within a song. Ac-"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "a State Space Model\n(SSM), combining a"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "curate emotion recognition systems should ideally"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "sentence-level\nemotion\npredictor with\nan"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "be able to generate the full emotional dynamics for"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "Expectation-Maximization (EM) procedure"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "each song, as opposed to simply predicting a sin-"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "to generate the full emotion dynamics. Our"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "gle label.\nexperiments show that applying our method"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "consistently improves\nthe performance of\nA range of datasets and corpora for modelling"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "sentence-level baselines without\nrequiring"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "dynamic emotion transitions has been developed"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "any annotated songs, making it ideal for lim-"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "in the literature (McKeown et al., 2011; Li et al.,"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "ited training data scenarios. Further analysis"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "2017; Hsu et al., 2018; Poria et al., 2019a; Fir-"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "through case studies shows the beneﬁts of"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "daus et al., 2020), but most of\nthem do not use"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "our method while also indicating the limita-"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "song lyrics as\nthe domain and assume discrete,"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "tions and pointing to future directions."
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "categorical\nlabels\nfor emotions\n(either\nthe pres-"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "ence or\nabsence of one\nemotion).\nTo the best"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "1\nIntroduction"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "of our knowledge,\nthe dataset from Mihalcea and"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "Strapparava (2012)\nis the only one that provides"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "Music\nand\nemotions\nare\nintimately\nconnected,"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "full ﬁne-grained emotion intensity annotations for"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "with almost all music pieces being created to ex-"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "song lyrics at\nthe verse1 level. The lack of large-"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "press\nand induce\nemotions\n(Juslin and Laukka,"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "scale datasets for\nthis task poses a challenge for"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "2004).\nAs a key factor of how music\nconveys"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "traditional\nsupervised methods. While previous"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "emotion, lyrics contain part of the semantic infor-"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "work proposed methods for the similar sequence-"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "mation that\nthe melodies cannot express (Besson"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "based emotion recognition task,\nthey all assume"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "et al., 1998). Lyrics-based music emotion recog-"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "the availability of some levels of annotated data at"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "nition has attracted increasing attention driven by"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "training time,\nfrom full emotion dynamics (Kim"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "the demand to process massive collections of mu-"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "et al., 2015) to coarse, discrete document-level la-"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "sic\ntracks\nautomatically, which is\nan important"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "bels (Täckström and McDonald, 2011b)."
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "task\nto\nstreaming\nand media\nservice\nproviders"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "The data scarcity problem motivates our main"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "(Kim et al., 2010; Malheiro et al., 2016; Agrawal"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "research question: “Can we predict emotion dy-"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "et al., 2021)."
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "namics in song lyrics without requiring annotated"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "Most\nemotion\nrecognition\nstudies\nin Natural"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "lyrics?”.\nIn this work, we\nclaim that\nthe\nan-"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "Language Processing (NLP) assume the text\nin-"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "∗ This work was completed when the ﬁrst author was at\n1According\nto Mihalcea\nand\nStrapparava\n(2012),\na"
        },
        {
          "†School of Computing and Information Systems, The University of Melbourne": "The University of Melbourne.\n“verse” is deﬁned as a sentence or a line of lyrics."
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "song lyrics as\nthe domain and assume discrete,": ""
        },
        {
          "song lyrics as\nthe domain and assume discrete,": "categorical\nlabels\nfor emotions\n(either\nthe pres-"
        },
        {
          "song lyrics as\nthe domain and assume discrete,": "ence or\nabsence of one\nemotion).\nTo the best"
        },
        {
          "song lyrics as\nthe domain and assume discrete,": ""
        },
        {
          "song lyrics as\nthe domain and assume discrete,": "of our knowledge,\nthe dataset from Mihalcea and"
        },
        {
          "song lyrics as\nthe domain and assume discrete,": "Strapparava (2012)\nis the only one that provides"
        },
        {
          "song lyrics as\nthe domain and assume discrete,": ""
        },
        {
          "song lyrics as\nthe domain and assume discrete,": "full ﬁne-grained emotion intensity annotations for"
        },
        {
          "song lyrics as\nthe domain and assume discrete,": ""
        },
        {
          "song lyrics as\nthe domain and assume discrete,": "song lyrics at\nthe verse1 level. The lack of large-"
        },
        {
          "song lyrics as\nthe domain and assume discrete,": ""
        },
        {
          "song lyrics as\nthe domain and assume discrete,": "scale datasets for\nthis task poses a challenge for"
        },
        {
          "song lyrics as\nthe domain and assume discrete,": ""
        },
        {
          "song lyrics as\nthe domain and assume discrete,": "traditional\nsupervised methods. While previous"
        },
        {
          "song lyrics as\nthe domain and assume discrete,": ""
        },
        {
          "song lyrics as\nthe domain and assume discrete,": "work proposed methods for the similar sequence-"
        },
        {
          "song lyrics as\nthe domain and assume discrete,": ""
        },
        {
          "song lyrics as\nthe domain and assume discrete,": "based emotion recognition task,\nthey all assume"
        },
        {
          "song lyrics as\nthe domain and assume discrete,": ""
        },
        {
          "song lyrics as\nthe domain and assume discrete,": "the availability of some levels of annotated data at"
        },
        {
          "song lyrics as\nthe domain and assume discrete,": ""
        },
        {
          "song lyrics as\nthe domain and assume discrete,": "training time,\nfrom full emotion dynamics (Kim"
        },
        {
          "song lyrics as\nthe domain and assume discrete,": ""
        },
        {
          "song lyrics as\nthe domain and assume discrete,": "et al., 2015) to coarse, discrete document-level la-"
        },
        {
          "song lyrics as\nthe domain and assume discrete,": ""
        },
        {
          "song lyrics as\nthe domain and assume discrete,": "bels (Täckström and McDonald, 2011b)."
        },
        {
          "song lyrics as\nthe domain and assume discrete,": ""
        },
        {
          "song lyrics as\nthe domain and assume discrete,": "The data scarcity problem motivates our main"
        },
        {
          "song lyrics as\nthe domain and assume discrete,": ""
        },
        {
          "song lyrics as\nthe domain and assume discrete,": "research question: “Can we predict emotion dy-"
        },
        {
          "song lyrics as\nthe domain and assume discrete,": ""
        },
        {
          "song lyrics as\nthe domain and assume discrete,": "namics in song lyrics without requiring annotated"
        },
        {
          "song lyrics as\nthe domain and assume discrete,": ""
        },
        {
          "song lyrics as\nthe domain and assume discrete,": "lyrics?”.\nIn this work, we\nclaim that\nthe\nan-"
        },
        {
          "song lyrics as\nthe domain and assume discrete,": ""
        },
        {
          "song lyrics as\nthe domain and assume discrete,": "1According\nto Mihalcea\nand\nStrapparava\n(2012),\na"
        },
        {
          "song lyrics as\nthe domain and assume discrete,": "“verse” is deﬁned as a sentence or a line of lyrics."
        }
      ],
      "page": 1
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "song lyrics or other domains.": "To summarize, our main contributions are:",
          "of\nthe real-time dynamic emotional changes also": "exists in music:\nthe affective state of\nthe current"
        },
        {
          "song lyrics or other domains.": "",
          "of\nthe real-time dynamic emotional changes also": "lyrics verse is correlated with the state of the pre-"
        },
        {
          "song lyrics or other domains.": "• We propose a hybrid approach for verse-level",
          "of\nthe real-time dynamic emotional changes also": "vious verse(s) as a song progresses."
        },
        {
          "song lyrics or other domains.": "emotion intensity prediction that\ncombines",
          "of\nthe real-time dynamic emotional changes also": "Contextual information in the ERC task is gen-"
        },
        {
          "song lyrics or other domains.": "emotion lexicons with a pre-trained language",
          "of\nthe real-time dynamic emotional changes also": "erally captured by deep learning models, which"
        },
        {
          "song lyrics or other domains.": "model\n(BERT (Devlin et al., 2019) used in",
          "of\nthe real-time dynamic emotional changes also": "can be roughly categorized into sequence-based"
        },
        {
          "song lyrics or other domains.": "this work), which\nis\ntrained\non\navailable",
          "of\nthe real-time dynamic emotional changes also": "and\ngraph-based methods\n(Hu\net\nal.,\n2021)."
        },
        {
          "song lyrics or other domains.": "sentence-level data.",
          "of\nthe real-time dynamic emotional changes also": "Sequence-based methods\nencode\nconversational"
        },
        {
          "song lyrics or other domains.": "",
          "of\nthe real-time dynamic emotional changes also": "context\nfeatures using established methods\nlike"
        },
        {
          "song lyrics or other domains.": "• We\nfurther\nshow that\nby\nusing\nSSMs\nto",
          "of\nthe real-time dynamic emotional changes also": ""
        },
        {
          "song lyrics or other domains.": "",
          "of\nthe real-time dynamic emotional changes also": "Recurrent Neural Networks\n(Poria\net\nal., 2017;"
        },
        {
          "song lyrics or other domains.": "model\nthe song-level emotion dynamics, we",
          "of\nthe real-time dynamic emotional changes also": ""
        },
        {
          "song lyrics or other domains.": "",
          "of\nthe real-time dynamic emotional changes also": "Hazarika et al., 2018a,b; Majumder et al., 2019;"
        },
        {
          "song lyrics or other domains.": "can improve the performance of\nthe verse-",
          "of\nthe real-time dynamic emotional changes also": ""
        },
        {
          "song lyrics or other domains.": "",
          "of\nthe real-time dynamic emotional changes also": "Hu\net\nal.,\n2021)\nand Transformer-based\narchi-"
        },
        {
          "song lyrics or other domains.": "level approach without\nrequiring any anno-",
          "of\nthe real-time dynamic emotional changes also": ""
        },
        {
          "song lyrics or other domains.": "",
          "of\nthe real-time dynamic emotional changes also": "tectures\n(Zhong\net\nal.,\n2019; Li\net\nal.,\n2020)."
        },
        {
          "song lyrics or other domains.": "tated lyrics.",
          "of\nthe real-time dynamic emotional changes also": ""
        },
        {
          "song lyrics or other domains.": "",
          "of\nthe real-time dynamic emotional changes also": "They\nalso\ninclude more\nadvanced\nand\ntailored"
        },
        {
          "song lyrics or other domains.": "",
          "of\nthe real-time dynamic emotional changes also": "methods like Hierarchical Memory Network (Jiao"
        },
        {
          "song lyrics or other domains.": "• We\nperform a\nqualitative\nanalysis\nof\nour",
          "of\nthe real-time dynamic emotional changes also": ""
        },
        {
          "song lyrics or other domains.": "",
          "of\nthe real-time dynamic emotional changes also": "et\nal., 2020), Emotion Interaction Network (Lu"
        },
        {
          "song lyrics or other domains.": "best models, highlighting its limitations and",
          "of\nthe real-time dynamic emotional changes also": ""
        },
        {
          "song lyrics or other domains.": "",
          "of\nthe real-time dynamic emotional changes also": "et\nal., 2020)\nand Causal Aware Network (Zhao"
        },
        {
          "song lyrics or other domains.": "pointing to directions for future work.",
          "of\nthe real-time dynamic emotional changes also": ""
        },
        {
          "song lyrics or other domains.": "",
          "of\nthe real-time dynamic emotional changes also": "et al., 2022).\nGraph-based methods apply spe-"
        }
      ],
      "page": 2
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "the need for a method that can train without super-": "vision. Extending and/or combining an SSM with",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "model more stable across domains."
        },
        {
          "the need for a method that can train without super-": "a deep learning model is theoretically possible but",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "State\nSpace Models.\nIn NLP\ntasks\nsuch\nas"
        },
        {
          "the need for a method that can train without super-": "non-trivial, and care must be taken in a low-data",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "Part-of-Speech (POS)\ntagging and Named Entity"
        },
        {
          "the need for a method that can train without super-": "situation such as ours.",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "Recognition, contextual information is widely ac-"
        },
        {
          "the need for a method that can train without super-": "The time-varying nature of music emotions has",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "knowledged to play an important\nrole in predic-"
        },
        {
          "the need for a method that can train without super-": "been investigated in music information retrieval",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "tion.\nThis\nleads\nto the\nadoption of\nstructured"
        },
        {
          "the need for a method that can train without super-": "(Caetano et al., 2012). To link the human emotions",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "prediction\napproaches\nsuch\nas Hidden Markov"
        },
        {
          "the need for a method that can train without super-": "with the music acoustic signal, the emotion distri-",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "Model (HMM) (Rabiner and Juang, 1986), Max-"
        },
        {
          "the need for a method that can train without super-": "butions were modelled as 2D Gaussian distribu-",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "imum Entropy Markov Model (MEMM) (McCal-"
        },
        {
          "the need for a method that can train without super-": "tions in the Arousal-Valence (A-V) space, which",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "lum et al., 2000) and Conditional Random Field"
        },
        {
          "the need for a method that can train without super-": "were used to predict A-V responses through multi-",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "(CRF)\n(Lafferty et al., 2001), which relate a set"
        },
        {
          "the need for a method that can train without super-": "label\nregression (Schmidt et al., 2010; Schmidt",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "of observable variables to a set of latent variables"
        },
        {
          "the need for a method that can train without super-": "and Kim, 2010).\nBuilding on previous\nstudies,",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "(e.g., words\nand their POS tags).\nState Space"
        },
        {
          "the need for a method that can train without super-": "Schmidt and Kim (2011) applied structured pre-",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "Models (SSMs) are similar to HMMs but assume"
        },
        {
          "the need for a method that can train without super-": "diction methods to model complex emotion-space",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "continuous variables. Linear Gaussian SSM (LG-"
        },
        {
          "the need for a method that can train without super-": "distributions as an A-V heatmap. These studies fo-",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "SSM) is a particular case of SSM in which all the"
        },
        {
          "the need for a method that can train without super-": "cus on the mapping between emotions and acous-",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "conditional probability distributions are linear and"
        },
        {
          "the need for a method that can train without super-": "tic features/signals, while our work focuses on the",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "Gaussian."
        },
        {
          "the need for a method that can train without super-": "lyrics\ncomponent.\nWu et\nal.\n(2014) developed",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "Following\nthe\nnotation\nfrom Murphy\n(2012,"
        },
        {
          "the need for a method that can train without super-": "a hierarchical Bayesian model\nthat utilized both",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "Chap. 18), we brieﬂy introduce the LG-SSM that"
        },
        {
          "the need for a method that can train without super-": "acoustic and textual\nfeatures, but\nit was only ap-",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "we employ in our work. LG-SSMs assume a se-"
        },
        {
          "the need for a method that can train without super-": "plied to predict emotions as discrete labels (pres-",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "quence of observed variables y1:T as input, and the"
        },
        {
          "the need for a method that can train without super-": "ence or absence)\ninstead of ﬁne-grained emotion",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "goal is to draw inferences about the corresponding"
        },
        {
          "the need for a method that can train without super-": "intensities as in our work.",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "hidden states z1:T , where T is the length of the se-"
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "quence. Their relationship is given at each step t"
        },
        {
          "the need for a method that can train without super-": "Combining pre-trained Language Models with",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "by the equations as:"
        },
        {
          "the need for a method that can train without super-": "External\nKnowledge.\nPre-trained\nlanguage",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "models\n(LMs)\nincluding BERT (Devlin\net\nal.,",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "zt = Azt−1 + (cid:15)t,\n(cid:15)t ∼ N (0, Q)"
        },
        {
          "the need for a method that can train without super-": "2019),\nXLNet\n(Yang\net\nal.,\n2019)\nand GPT",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "(Brown et al., 2020) have achieved state-of-the-art",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "yt = Czt + δt,\nδt ∼ N (0, R)"
        },
        {
          "the need for a method that can train without super-": "performance\nin numerous NLP tasks.\nConsid-",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "where Θ = (A, C, Q, R) are the model parame-"
        },
        {
          "the need for a method that can train without super-": "erable effort has been made towards combining",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "is the observa-\nters, (cid:15)t\nis the system noise and δt"
        },
        {
          "the need for a method that can train without super-": "context-sensitive\nfeatures\nof LMs with\nfactual",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "tion noise. The equations above are also referred"
        },
        {
          "the need for a method that can train without super-": "or\ncommonsense\nknowledge\nfrom\nstructured",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "as transition2 and observation equations,\nrespec-"
        },
        {
          "the need for a method that can train without super-": "sources,\nincluding\ndomain-speciﬁc\nknowledge",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "the goal\nis\ntively. Given Θ and a sequence y1:T ,"
        },
        {
          "the need for a method that can train without super-": "(Ying\net\nal.,\n2019),\nstructured\nsemantic\ninfor-",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "to obtain the posteriors p(zt) for each step t. In an"
        },
        {
          "the need for a method that can train without super-": "mation\n(Zhang\net\nal.,\n2020),\nlanguage-speciﬁc",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "LG-SSM,\nthis posterior is a Gaussian and can be"
        },
        {
          "the need for a method that can train without super-": "knowledge\n(Alghanmi\net\nal.,\n2020; De Bruyne",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "obtained in closed form by applying the celebrated"
        },
        {
          "the need for a method that can train without super-": "et\nal.,\n2021)\nand\nlinguistic\nfeatures\n(Koufakou",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "Kalman Filter (Kalman, 1960) ."
        },
        {
          "the need for a method that can train without super-": "et al., 2020; Mehta et al., 2020).\nThis auxiliary",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "There exist some other\nlatent variable models"
        },
        {
          "the need for a method that can train without super-": "knowledge is usually infused into the architecture",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "to estimate temporal dynamics of emotions and"
        },
        {
          "the need for a method that can train without super-": "by\nconcatenating\nthem with\nthe\nTransformer-",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "sentiments in product\nreviews (McDonald et al.,"
        },
        {
          "the need for a method that can train without super-": "based representation before\nthe prediction layer",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "2007; Täckström and McDonald,\n2011a,b)\nand"
        },
        {
          "the need for a method that can train without super-": "for downstream tasks.\nOur method proposes\nto",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "blogs (Kim et al., 2015). McDonald et al. (2007)"
        },
        {
          "the need for a method that can train without super-": "utilize the rule-based representations derived from",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "and Täckström and McDonald\n(2011a,b)\ncom-"
        },
        {
          "the need for a method that can train without super-": "a bunch of affective lexicons to improve the per-",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "bined document-level and sentence-level supervi-"
        },
        {
          "the need for a method that can train without super-": "formance of BERT by incorporating task-speciﬁc",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "sion as the observed variables to condition on the"
        },
        {
          "the need for a method that can train without super-": "knowledge.\nThe motivation for our proposal\nis",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "latent sentence-level sentiment. Kim et al. (2015)"
        },
        {
          "the need for a method that can train without super-": "the hypothesis that the extension of lexicon-based",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "information will\ncompensate\nfor BERT’s\nlack",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": ""
        },
        {
          "the need for a method that can train without super-": "",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "in the\n2We omit control matrix B and control vector ut"
        },
        {
          "the need for a method that can train without super-": "of proper\nrepresentations of\nsemantic and world",
          "knowledge\n(Rogers\net\nal.,\n2021), making\nthe": "transition equation, assuming no external inﬂuence."
        }
      ],
      "page": 3
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "to solely de-\nintroduced a continuous variable yt": "is con-\ntermine the sentiment polarity zt, while zt",
          "Overview.\nThe verse-level model architecture is": "called BERTLex, as illustrated in Figure 2.\nThe"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "ditioned on both yt and zt−1 for each t in the LG-",
          "Overview.\nThe verse-level model architecture is": "BERTLex model\nconsists\nof\nthree\nphases:\n(1)"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "SSM.",
          "Overview.\nThe verse-level model architecture is": "the embedding phase,\n(2)\nthe integration phase,"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "",
          "Overview.\nThe verse-level model architecture is": "and (3)\nthe prediction phase.\nIn the embedding"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "3\nMethod",
          "Overview.\nThe verse-level model architecture is": "phase,\nthe input sequence is represented as both"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "",
          "Overview.\nThe verse-level model architecture is": "contextualized embeddings from BERT and static"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "We propose a two-stage method to predict emo-",
          "Overview.\nThe verse-level model architecture is": ""
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "",
          "Overview.\nThe verse-level model architecture is": "word embeddings from lexicons.\nIn the integra-"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "tion dynamics without\nrequiring annotated song",
          "Overview.\nThe verse-level model architecture is": ""
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "",
          "Overview.\nThe verse-level model architecture is": "tion phase, contextualized and static word embed-"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "lyrics. The ﬁrst stage is a verse-level model\nthat",
          "Overview.\nThe verse-level model architecture is": ""
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "",
          "Overview.\nThe verse-level model architecture is": "dings are concatenated at the sentence level by tak-"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "predicts initial scores for each song verse, where",
          "Overview.\nThe verse-level model architecture is": ""
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "",
          "Overview.\nThe verse-level model architecture is": "ing the pooling operations on the two embeddings"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "we use a hybrid approach combining lexicons and",
          "Overview.\nThe verse-level model architecture is": ""
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "",
          "Overview.\nThe verse-level model architecture is": "separately. The prediction phase encodes the in-"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "sentence-level annotated data from a different do-",
          "Overview.\nThe verse-level model architecture is": ""
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "",
          "Overview.\nThe verse-level model architecture is": "tegrated sequence of feature vectors and performs"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "main\n(§3.1).\nThe\nsecond\nstage\ncontextualizes",
          "Overview.\nThe verse-level model architecture is": ""
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "",
          "Overview.\nThe verse-level model architecture is": "the verse-level emotion intensity regression by us-"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "these scores in the entire song, incorporating them",
          "Overview.\nThe verse-level model architecture is": ""
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "",
          "Overview.\nThe verse-level model architecture is": "ing the Ds as the training/development set and the"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "into an LG-SSM trained in an unsupervised way",
          "Overview.\nThe verse-level model architecture is": ""
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "",
          "Overview.\nThe verse-level model architecture is": "Dt as the test set."
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "(§3.2).",
          "Overview.\nThe verse-level model architecture is": ""
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "",
          "Overview.\nThe verse-level model architecture is": "Embedding Phase.\nThe input sentence S is to-"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "Task Formalization.\nLet dy\nindicate the real-",
          "Overview.\nThe verse-level model architecture is": ""
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "",
          "Overview.\nThe verse-level model architecture is": "kenized in two ways: one for the pre-trained lan-"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "valued intensity of emotion y for sentence/ verse",
          "Overview.\nThe verse-level model architecture is": ""
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "",
          "Overview.\nThe verse-level model architecture is": "guage model and the other\nfor\nthe lexicon-based"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "x, where x ∈ X and y ∈ Y.\nNote that Y =",
          "Overview.\nThe verse-level model architecture is": ""
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "",
          "Overview.\nThe verse-level model architecture is": "word embedding. These two tokenized sequences"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "{y1, y2, . . . , yc} is a set of c labels, each of which",
          "Overview.\nThe verse-level model architecture is": "are denoted as T cxt and T lex, respectively. Then,"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "represents one of the basic emotions (c = 6 for the",
          "Overview.\nThe verse-level model architecture is": ""
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "",
          "Overview.\nThe verse-level model architecture is": "T cxt\nis\nfed\ninto\nthe\npre-trained BERT to\npro-"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "datasets we used). Given a source dataset Ds =",
          "Overview.\nThe verse-level model architecture is": "duce a sequence of contextualized word embed-"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "is\n{(x1, E1), (x2, E2), . . . , (xM , EM )}, where xi",
          "Overview.\nThe verse-level model architecture is": ""
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "",
          "Overview.\nThe verse-level model architecture is": "dings Ecxt = {e1, e2, . . . , e|T cxt|}, where Ecxt ∈"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "a sentence, Ei = {dy1\nxi , dy2\nxi , . . . , dyc\nxi } and M = |Ds|.",
          "Overview.\nThe verse-level model architecture is": ""
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "",
          "Overview.\nThe verse-level model architecture is": "is the embedding vector di-\nR|T cxt|×Dcxt and Dcxt"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "The\ntarget\ndataset\nis Dt",
          "Overview.\nThe verse-level model architecture is": ""
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "= {S1, S2, . . . , S|Dt|},",
          "Overview.\nThe verse-level model architecture is": ""
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "",
          "Overview.\nThe verse-level model architecture is": "mension."
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "where |Dt| is the number of sequences (i.e., songs)",
          "Overview.\nThe verse-level model architecture is": ""
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "",
          "Overview.\nThe verse-level model architecture is": "To capture\ntask-speciﬁc\ninformation,\na Lexi-"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "and Si = {(v1, E1), (v2, E2), . . . , (v|Si|, E|Si|)} is",
          "Overview.\nThe verse-level model architecture is": ""
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "",
          "Overview.\nThe verse-level model architecture is": "con embedding layer encodes a sequence of emo-"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "a song consisting of\n|Si| verses.\nIn the song Si,",
          "Overview.\nThe verse-level model architecture is": ""
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "",
          "Overview.\nThe verse-level model architecture is": "tion\nand\nsentiment word\nassociations\nfor T lex,"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "is also associated with c emo-\nthe j-th verse vj",
          "Overview.\nThe verse-level model architecture is": ""
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "",
          "Overview.\nThe verse-level model architecture is": "generating a\nsequence of\nlexicon-based embed-"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "tion intensities as Ej = {dy1\nvj , dy2\nvj , . . . , dyc\nvj }. Given",
          "Overview.\nThe verse-level model architecture is": ""
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "",
          "Overview.\nThe verse-level model architecture is": "dings Elex = {(cid:96)1, (cid:96)2, . . . , (cid:96)|T lex|}, where Elex ∈"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "the homogeneity of\nlabel\nspaces of Ds\nand Dt,",
          "Overview.\nThe verse-level model architecture is": ""
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "",
          "Overview.\nThe verse-level model architecture is": "R|T lex|×Dlex"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "",
          "Overview.\nThe verse-level model architecture is": "is\nthe\nlexical\nembedding\nand Dlex"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "the model\ncan be\napplied\ntrained by using Ds",
          "Overview.\nThe verse-level model architecture is": ""
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "",
          "Overview.\nThe verse-level model architecture is": "vector dimension. We ﬁrst build the vocabulary"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "to predict\nThe output of verse-\nfor Dt directly.",
          "Overview.\nThe verse-level model architecture is": ""
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "",
          "Overview.\nThe verse-level model architecture is": "V from the text of Ds and Dt. For each word vi"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "level model\nis\nthe emotion intensity predictions",
          "Overview.\nThe verse-level model architecture is": ""
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "",
          "Overview.\nThe verse-level model architecture is": "in V of T lex, we use d lexicons to generate the"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "Y ∈ RN ×c, where N is the total number of verses",
          "Overview.\nThe verse-level model architecture is": ""
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "",
          "Overview.\nThe verse-level model architecture is": "rule-based feature vectors (cid:96)i = {(cid:96)i1, (cid:96)i2, . . . , (cid:96)id},"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "in Dt. Finally, we use ˆY as the input sequences of",
          "Overview.\nThe verse-level model architecture is": ""
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "",
          "Overview.\nThe verse-level model architecture is": "is the lexical feature vector for word vi\nwhere (cid:96)ij"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "the song-level model\nto produce optimized emo-",
          "Overview.\nThe verse-level model architecture is": ""
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "",
          "Overview.\nThe verse-level model architecture is": "derived from the j-th lexicon and Dlex = |(cid:96)i|. Ad-"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "tion intensity sequences ˆZ ∈ R|Dt|×c.",
          "Overview.\nThe verse-level model architecture is": ""
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "",
          "Overview.\nThe verse-level model architecture is": "ditionally, we perform a degree-p polynomial ex-"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "",
          "Overview.\nThe verse-level model architecture is": "pansion on the feature vector (cid:96)ij ."
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "3.1\nVerse-Level Model",
          "Overview.\nThe verse-level model architecture is": ""
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "Emotion lexicons provide information on associ-",
          "Overview.\nThe verse-level model architecture is": "Integration Phase.\nAs BERT uses\nthe Word-"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "ations between words and emotions (Ramachan-",
          "Overview.\nThe verse-level model architecture is": "Piece tokenizer\n(Wu et al., 2016)\nto split a num-"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "dran and de Melo, 2020), which are proven to be",
          "Overview.\nThe verse-level model architecture is": "ber of words\ninto a\nsequence of\nsubwords,\nthe"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "beneﬁcial\nin recognising textual\nemotions\n(Mo-",
          "Overview.\nThe verse-level model architecture is": "contextualized embedding cannot be directly con-"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "hammad et al., 2018b; Zhou et al., 2020). Given",
          "Overview.\nThe verse-level model architecture is": "catenated with the different-size static word em-"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "that we would like to acquire accurate initial pre-",
          "Overview.\nThe verse-level model architecture is": "bedding.\nInspired by Alghanmi et al. (2020), we"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "dictions\nat\nthe verse\nlevel, we opted for\na hy-",
          "Overview.\nThe verse-level model architecture is": "combine the contextualized embeddings and static"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "brid methodology that\ncombines\nlearning-based",
          "Overview.\nThe verse-level model architecture is": "word embeddings at\nthe sentence level by pool-"
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "and lexicon-based approaches to enhance feature",
          "Overview.\nThe verse-level model architecture is": "ing the two embeddings Ecxt and Elex separately."
        },
        {
          "to solely de-\nintroduced a continuous variable yt": "representation.",
          "Overview.\nThe verse-level model architecture is": "To perform initial feature extraction from the raw"
        }
      ],
      "page": 4
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": "embeddings, we apply a single-layer 1D Convo-"
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": "lutional Neural Network (Kim, 2014, CNN) with"
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": "ReLU activation (Nair and Hinton, 2010) on each"
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": "embedding as:"
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": ""
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": "e(cid:48)"
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": "i = ReLU(W1[ei, ei+1, . . . , ei+k−1] + b1)"
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": ""
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": "(cid:96)(cid:48)\ni = ReLU(W2[(cid:96)i, (cid:96)i+1, . . . , (cid:96)i+k−1] + b2)"
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": ""
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": "where W1, b1, W2 and b2 are trainable param-"
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": "eters and k is the kernel size. We then apply the"
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": "average pooling and max pooling on the feature"
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": "maps, respectively:"
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": ""
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": ""
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": "1, e(cid:48)\n2, . . . , e(cid:48)\n|T cxt|−k+1)."
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": ""
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": "Elex = MaxPool((cid:96)(cid:48)\n1, (cid:96)(cid:48)\n2, . . . , (cid:96)(cid:48)\n|T lex|−k+1)."
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": ""
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": "Finally,\nthe\ncontextualised\nembedding\nand\nthe"
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": "lexicon-based embedding are merged via a con-"
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": "catenation layer as ˜Ecxt ⊕ ˜Elex."
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": ""
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": "Prediction Phase.\nThe\nprediction\nphase\nout-"
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": ""
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": "ˆ"
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": "puts\nthe\nemotion\nintensity\npredictions\nY ="
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": ""
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": "(Sri-\n{ˆy1, ˆy2, . . . , ˆyN } by using a single dropout"
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": ""
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": "vastava et al., 2014) layer and a linear regression"
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": ""
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": "layer.\nDuring training,\nthe mean squared error"
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": ""
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": "loss is computed and backpropagated to update the"
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": ""
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": "model parameters."
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": ""
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": "3.2\nSong-Level Model"
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": ""
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": "After obtaining initial verse-level predictions,\nthe"
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": ""
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": "next step involves incorporating these into a song-"
        },
        {
          "Figure 2: BERTLex architecture used for the verse-level model.": "level model using an LG-SSM. We take one type"
        }
      ],
      "page": 5
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "end": ""
        },
        {
          "end": "return ˆzT :1|T , ΣT :1|T , JT :1 ;"
        },
        {
          "end": ""
        },
        {
          "end": ""
        },
        {
          "end": ""
        },
        {
          "end": "Kalman Filter and Kalman Smoother algorithms"
        },
        {
          "end": ""
        },
        {
          "end": "are used with already known parameters. Hence,"
        },
        {
          "end": "learning the SSM involves estimating the param-"
        },
        {
          "end": ""
        },
        {
          "end": "eters Θ.\nIf a set of gold-standard values for\nthe"
        },
        {
          "end": ""
        },
        {
          "end": "is\navailable,\nthey can be\nlearned\ncomplete z1:T"
        },
        {
          "end": ""
        },
        {
          "end": "using a Maximum Likelihood Estimation (MLE)."
        },
        {
          "end": ""
        },
        {
          "end": "If only the noisy,\nare\nobserved sequences y1:T"
        },
        {
          "end": ""
        },
        {
          "end": "present,\nthe Expectation-Maximization (EM) al-"
        },
        {
          "end": ""
        },
        {
          "end": "gorithm (Dempster et al., 1977) provides an iter-"
        },
        {
          "end": ""
        },
        {
          "end": "ative method for ﬁnding the MLEs of Θ by suc-"
        },
        {
          "end": ""
        },
        {
          "end": "cessively maximizing the conditional expectation"
        },
        {
          "end": "of the complete data likelihood until convergence."
        },
        {
          "end": ""
        }
      ],
      "page": 6
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "mentation details and experiment settings of verse-": ""
        },
        {
          "mentation details and experiment settings of verse-": "level model (§4.2) and song-level model (§4.3)."
        },
        {
          "mentation details and experiment settings of verse-": ""
        },
        {
          "mentation details and experiment settings of verse-": ""
        },
        {
          "mentation details and experiment settings of verse-": "4.1\nDatasets and Evaluation"
        },
        {
          "mentation details and experiment settings of verse-": ""
        },
        {
          "mentation details and experiment settings of verse-": "LyricsEmotions.\nThis corpus was developed by"
        },
        {
          "mentation details and experiment settings of verse-": ""
        },
        {
          "mentation details and experiment settings of verse-": "Mihalcea\nand Strapparava\n(2012),\nconsisting of"
        },
        {
          "mentation details and experiment settings of verse-": ""
        },
        {
          "mentation details and experiment settings of verse-": "100 popular English songs with 4,975 verses\nin"
        },
        {
          "mentation details and experiment settings of verse-": ""
        },
        {
          "mentation details and experiment settings of verse-": "total. The number of verses for each song varies"
        },
        {
          "mentation details and experiment settings of verse-": ""
        },
        {
          "mentation details and experiment settings of verse-": "from 14 to 110.\nThe LYRICSEMOTIONS dataset"
        },
        {
          "mentation details and experiment settings of verse-": ""
        },
        {
          "mentation details and experiment settings of verse-": "was constructed by extracting the parallel align-"
        },
        {
          "mentation details and experiment settings of verse-": "ment of musical\nfeatures and lyrics\nfrom MIDI"
        },
        {
          "mentation details and experiment settings of verse-": "tracks.\nThese lyrics were annotated using Me-"
        },
        {
          "mentation details and experiment settings of verse-": "chanical Turk at verse level with real-valued in-"
        },
        {
          "mentation details and experiment settings of verse-": "tensity scores ranging from 0 to 10 of six Ekman’s"
        },
        {
          "mentation details and experiment settings of verse-": "emotions\n(Ekman,\n1993):\nANGER, DISGUST,"
        },
        {
          "mentation details and experiment settings of verse-": ""
        },
        {
          "mentation details and experiment settings of verse-": "FEAR, JOY, SADNESS and SURPRISE. Given"
        },
        {
          "mentation details and experiment settings of verse-": ""
        },
        {
          "mentation details and experiment settings of verse-": "that our goal\nis to predict emotions without rely-"
        },
        {
          "mentation details and experiment settings of verse-": ""
        },
        {
          "mentation details and experiment settings of verse-": "ing on song-level dynamics, we use this dataset"
        },
        {
          "mentation details and experiment settings of verse-": ""
        },
        {
          "mentation details and experiment settings of verse-": "for evaluation purposes only."
        },
        {
          "mentation details and experiment settings of verse-": ""
        },
        {
          "mentation details and experiment settings of verse-": ""
        },
        {
          "mentation details and experiment settings of verse-": "NewsHeadlines.\nTo train the verse-level model,"
        },
        {
          "mentation details and experiment settings of verse-": ""
        },
        {
          "mentation details and experiment settings of verse-": "we employ the NEWSHEADLINES3 dataset (Strap-"
        },
        {
          "mentation details and experiment settings of verse-": ""
        },
        {
          "mentation details and experiment settings of verse-": "parava and Mihalcea, 2007), which is a collection"
        },
        {
          "mentation details and experiment settings of verse-": ""
        },
        {
          "mentation details and experiment settings of verse-": "of 1,250 news headlines. Each headline is anno-"
        },
        {
          "mentation details and experiment settings of verse-": ""
        },
        {
          "mentation details and experiment settings of verse-": "tated with six scores\nranging from 0 to 100 for"
        },
        {
          "mentation details and experiment settings of verse-": "each of Ekman’s emotions and one score ranging"
        },
        {
          "mentation details and experiment settings of verse-": "from -100 to 100 for valence."
        },
        {
          "mentation details and experiment settings of verse-": ""
        },
        {
          "mentation details and experiment settings of verse-": ""
        },
        {
          "mentation details and experiment settings of verse-": "Lexicons.\nFollowing Goel\net\nal.\n(2017)\nand"
        },
        {
          "mentation details and experiment settings of verse-": ""
        },
        {
          "mentation details and experiment settings of verse-": "Meisheri and Dey (2018), we use nine emotion"
        },
        {
          "mentation details and experiment settings of verse-": "and sentiment\nrelated lexicons to obtain the fea-"
        },
        {
          "mentation details and experiment settings of verse-": "ture vectors\nfrom the text\nin NEWSHEADLINES"
        },
        {
          "mentation details and experiment settings of verse-": ""
        },
        {
          "mentation details and experiment settings of verse-": "and LYRICSEMOTIONS, summarized in Table 1."
        },
        {
          "mentation details and experiment settings of verse-": ""
        },
        {
          "mentation details and experiment settings of verse-": ""
        },
        {
          "mentation details and experiment settings of verse-": "Evaluation.\nIn line with Mihalcea and Strappa-"
        },
        {
          "mentation details and experiment settings of verse-": ""
        },
        {
          "mentation details and experiment settings of verse-": "rava (2012), we use the Pearson correlation co-"
        },
        {
          "mentation details and experiment settings of verse-": ""
        },
        {
          "mentation details and experiment settings of verse-": "efﬁcient\n(r) as\nthe evaluation metric to measure"
        },
        {
          "mentation details and experiment settings of verse-": ""
        },
        {
          "mentation details and experiment settings of verse-": "the correlation between the predictions and ground"
        },
        {
          "mentation details and experiment settings of verse-": ""
        },
        {
          "mentation details and experiment settings of verse-": "truth emotion intensities. To assess statistical sig-"
        },
        {
          "mentation details and experiment settings of verse-": ""
        },
        {
          "mentation details and experiment settings of verse-": "niﬁcance, we conduct the Williams test (Williams,"
        },
        {
          "mentation details and experiment settings of verse-": ""
        },
        {
          "mentation details and experiment settings of verse-": "1959) in the differences between the Pearson cor-"
        },
        {
          "mentation details and experiment settings of verse-": ""
        },
        {
          "mentation details and experiment settings of verse-": "relations of each pair of models."
        },
        {
          "mentation details and experiment settings of verse-": ""
        },
        {
          "mentation details and experiment settings of verse-": "For baselines, our method is unsupervised at the"
        },
        {
          "mentation details and experiment settings of verse-": "song level, and we are not aware of prior work"
        },
        {
          "mentation details and experiment settings of verse-": "tackling similar cases. Therefore, we use the re-"
        },
        {
          "mentation details and experiment settings of verse-": "sults of the verse-level model as our main baseline."
        },
        {
          "mentation details and experiment settings of verse-": ""
        },
        {
          "mentation details and experiment settings of verse-": "We argue that this is a fair baseline since the SSM-"
        },
        {
          "mentation details and experiment settings of verse-": ""
        },
        {
          "mentation details and experiment settings of verse-": "based model does not require additional data."
        },
        {
          "mentation details and experiment settings of verse-": ""
        },
        {
          "mentation details and experiment settings of verse-": "3http://web.eecs.umich.edu/~mihalcea/"
        },
        {
          "mentation details and experiment settings of verse-": "affectivetext/"
        }
      ],
      "page": 6
    },
    {
      "caption": "Table 2: Hyperparameter settings of BERT and CNN",
      "data": [
        {
          "Scope": "Emotion",
          "Size (PT)": "1 (4)",
          "Label": "Numerical",
          "Reference": "Mohammad (2018)"
        },
        {
          "Scope": "Sentiment",
          "Size (PT)": "2 (10)",
          "Label": "Numerical",
          "Reference": "Esuli and Sebastiani (2007)"
        },
        {
          "Scope": "Emotion",
          "Size (PT)": "1 (4)",
          "Label": "Nominal",
          "Reference": "Mohammad and Turney (2013)"
        },
        {
          "Scope": "Emotion",
          "Size (PT)": "1 (4)",
          "Label": "Numerical",
          "Reference": "Mohammad and Kiritchenko (2015)"
        },
        {
          "Scope": "Sentiment",
          "Size (PT)": "3 (20)",
          "Label": "Numerical",
          "Reference": "Mohammad et al. (2013)"
        },
        {
          "Scope": "Sentiment",
          "Size (PT)": "3 (20)",
          "Label": "Numerical",
          "Reference": "Zhu et al. (2014)"
        },
        {
          "Scope": "Sentiment",
          "Size (PT)": "3 (20)",
          "Label": "Numerical",
          "Reference": "Mohammad et al. (2013)"
        },
        {
          "Scope": "Sentiment",
          "Size (PT)": "3 (20)",
          "Label": "Numerical",
          "Reference": "Kiritchenko et al. (2014)"
        },
        {
          "Scope": "Emotion",
          "Size (PT)": "8 (165)",
          "Label": "Numerical",
          "Reference": "Staiano and Guerini (2014)"
        }
      ],
      "page": 7
    },
    {
      "caption": "Table 2: Hyperparameter settings of BERT and CNN",
      "data": [
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "CUDA (version 11.2).",
          "0.9\nβ1": "0.999\nβ2"
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "",
          "0.9\nβ1": "Batch size\n32"
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "BERTLex.\nThe",
          "0.9\nβ1": ""
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "",
          "0.9\nβ1": "Table 2: Hyperparameter settings of BERT and CNN"
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "each token, including [CLS] and [SEP] at the out-",
          "0.9\nβ1": ""
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "",
          "0.9\nβ1": "models."
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "put of the last layer of the BERTbase model, is fed",
          "0.9\nβ1": ""
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "into a Conv1D layer with 128 ﬁlters and a kernel",
          "0.9\nβ1": ""
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "",
          "0.9\nβ1": "Training.\nInstead of using the standard train/de-"
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "size of 3, followed by a 1D global average pooling",
          "0.9\nβ1": ""
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "",
          "0.9\nβ1": "v/test split of\nthe NEWSHEADLINES dataset, we"
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "layer.",
          "0.9\nβ1": ""
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "",
          "0.9\nβ1": "apply 10-fold cross-validation to tune the hyper-"
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "",
          "0.9\nβ1": ""
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "",
          "0.9\nβ1": "parameters of BERT-based models.\nEmpirically"
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "every word in the established vocabulary by us-",
          "0.9\nβ1": ""
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "",
          "0.9\nβ1": "tuned hyperparameters are listed in Table 2 and"
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "ing the lexicons in Table 1 in the identical order to",
          "0.9\nβ1": ""
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "",
          "0.9\nβ1": "are adopted in the subsequent experiments unless"
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "form a united feature vector. As a result, the whole",
          "0.9\nβ1": ""
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "",
          "0.9\nβ1": "otherwise speciﬁed. After tuning, the ﬁnal models"
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "word\nembedding\nis",
          "0.9\nβ1": ""
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "",
          "0.9\nβ1": "using this set of hyperparameters are trained on the"
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "where 3309 is the vocabulary size and 25 is the",
          "0.9\nβ1": ""
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "",
          "0.9\nβ1": "full NEWSHEADLINES data. We use an ensemble"
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "number of",
          "0.9\nβ1": ""
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "",
          "0.9\nβ1": "of ﬁve runs,\ntaking the mean of the predictions as"
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "adding polynomial",
          "0.9\nβ1": ""
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "",
          "0.9\nβ1": "the ﬁnal output."
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "dictions, we also perform a polynomial feature ex-",
          "0.9\nβ1": ""
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "pansion with a degree of 3, extending the shape of",
          "0.9\nβ1": ""
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "",
          "0.9\nβ1": "4.3\nSong-Level Experiments"
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "vector representations to (3309, 267). Then, static",
          "0.9\nβ1": ""
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "",
          "0.9\nβ1": "We apply the library pykalman (version 0.9.2)5,"
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "word embeddings are fed a Conv1D layer with 128",
          "0.9\nβ1": ""
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "",
          "0.9\nβ1": "which implements the Kalman Filter,\nthe Kalman"
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "ﬁlters and a kernel size of 3, followed by a global",
          "0.9\nβ1": ""
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "",
          "0.9\nβ1": "Smoother and the EM algorithm to train SSMs."
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "max-pooling layer.",
          "0.9\nβ1": ""
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "",
          "0.9\nβ1": "We ﬁx the initial state mean as the ﬁrst observed"
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "",
          "0.9\nβ1": ""
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "",
          "0.9\nβ1": "value in the sequence (i.e., each song’s ﬁrst verse-"
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "through a Concatenate",
          "0.9\nβ1": ""
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "",
          "0.9\nβ1": "level prediction) and the initial\nstate covariance"
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "same dimensionality. We generate the predictions",
          "0.9\nβ1": ""
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "",
          "0.9\nβ1": "as 2. We then conduct experiments with several"
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "of emotion intensities by using a Linear layer with",
          "0.9\nβ1": ""
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "",
          "0.9\nβ1": "groups of parameters transition matrices A,\ntran-"
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "a single neuron4 for regression.",
          "0.9\nβ1": ""
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "",
          "0.9\nβ1": "sition covariance Q, observation matrices C and"
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "",
          "0.9\nβ1": "observation covariance R to initialise the Kalman"
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "",
          "0.9\nβ1": ""
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "",
          "0.9\nβ1": "Filter and Kalman Smoother.\nFor parameter op-"
        },
        {
          "trained on an NVIDIA T4 Tensor Core GPU with": "all six emotions jointly, but preliminary results showed that",
          "0.9\nβ1": ""
        }
      ],
      "page": 7
    },
    {
      "caption": "Table 2: Hyperparameter settings of BERT and CNN",
      "data": [
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "Hash-Senti\nSentiment\n3 (20)",
          "Numerical\nMohammad et al. (2013)": "Numerical\nKiritchenko et al. (2014)"
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "DepecheMood\nEmotion\n8 (165)",
          "Numerical\nMohammad et al. (2013)": "Numerical\nStaiano and Guerini (2014)"
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "Table 1: Lexicons used to build lexicon-based feature vectors: PT is the feature vector size after the polynomial",
          "Numerical\nMohammad et al. (2013)": ""
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "feature expansion.",
          "Numerical\nMohammad et al. (2013)": ""
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "4.2\nVerse-level Experiments",
          "Numerical\nMohammad et al. (2013)": ""
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "",
          "Numerical\nMohammad et al. (2013)": "Parameters\nValue"
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "Setup.\nFor the pre-trained model, we choose the",
          "Numerical\nMohammad et al. (2013)": "Dropout rate\n0.1"
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "in English with all pa-\nBERTbase uncased model",
          "Numerical\nMohammad et al. (2013)": "Optimizer\nAdam"
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "rameters frozen during training. All models are",
          "Numerical\nMohammad et al. (2013)": "Learning rate\n2e-5"
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "trained on an NVIDIA T4 Tensor Core GPU with",
          "Numerical\nMohammad et al. (2013)": "0.9\nβ1"
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "CUDA (version 11.2).",
          "Numerical\nMohammad et al. (2013)": "0.999\nβ2"
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "",
          "Numerical\nMohammad et al. (2013)": "Batch size\n32"
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "BERTLex.\nThe\nsequence\nof\nembeddings\nfor",
          "Numerical\nMohammad et al. (2013)": ""
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "",
          "Numerical\nMohammad et al. (2013)": "Table 2: Hyperparameter settings of BERT and CNN"
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "each token, including [CLS] and [SEP] at the out-",
          "Numerical\nMohammad et al. (2013)": ""
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "",
          "Numerical\nMohammad et al. (2013)": "models."
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "put of the last layer of the BERTbase model, is fed",
          "Numerical\nMohammad et al. (2013)": ""
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "into a Conv1D layer with 128 ﬁlters and a kernel",
          "Numerical\nMohammad et al. (2013)": ""
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "",
          "Numerical\nMohammad et al. (2013)": "Training.\nInstead of using the standard train/de-"
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "size of 3, followed by a 1D global average pooling",
          "Numerical\nMohammad et al. (2013)": ""
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "",
          "Numerical\nMohammad et al. (2013)": "v/test split of\nthe NEWSHEADLINES dataset, we"
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "layer.",
          "Numerical\nMohammad et al. (2013)": ""
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "",
          "Numerical\nMohammad et al. (2013)": "apply 10-fold cross-validation to tune the hyper-"
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "We concatenate nine vector representations for",
          "Numerical\nMohammad et al. (2013)": ""
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "",
          "Numerical\nMohammad et al. (2013)": "parameters of BERT-based models.\nEmpirically"
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "every word in the established vocabulary by us-",
          "Numerical\nMohammad et al. (2013)": ""
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "",
          "Numerical\nMohammad et al. (2013)": "tuned hyperparameters are listed in Table 2 and"
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "ing the lexicons in Table 1 in the identical order to",
          "Numerical\nMohammad et al. (2013)": ""
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "",
          "Numerical\nMohammad et al. (2013)": "are adopted in the subsequent experiments unless"
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "form a united feature vector. As a result, the whole",
          "Numerical\nMohammad et al. (2013)": ""
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "",
          "Numerical\nMohammad et al. (2013)": "otherwise speciﬁed. After tuning, the ﬁnal models"
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "word\nembedding\nis\nin\nthe\nshape\nof\n(3309,25),",
          "Numerical\nMohammad et al. (2013)": ""
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "",
          "Numerical\nMohammad et al. (2013)": "using this set of hyperparameters are trained on the"
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "where 3309 is the vocabulary size and 25 is the",
          "Numerical\nMohammad et al. (2013)": ""
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "",
          "Numerical\nMohammad et al. (2013)": "full NEWSHEADLINES data. We use an ensemble"
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "number of\nlexicon-based features.\nTo validate if",
          "Numerical\nMohammad et al. (2013)": ""
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "",
          "Numerical\nMohammad et al. (2013)": "of ﬁve runs,\ntaking the mean of the predictions as"
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "adding polynomial\nfeatures can make better pre-",
          "Numerical\nMohammad et al. (2013)": ""
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "",
          "Numerical\nMohammad et al. (2013)": "the ﬁnal output."
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "dictions, we also perform a polynomial feature ex-",
          "Numerical\nMohammad et al. (2013)": ""
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "pansion with a degree of 3, extending the shape of",
          "Numerical\nMohammad et al. (2013)": ""
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "",
          "Numerical\nMohammad et al. (2013)": "4.3\nSong-Level Experiments"
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "vector representations to (3309, 267). Then, static",
          "Numerical\nMohammad et al. (2013)": ""
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "",
          "Numerical\nMohammad et al. (2013)": "We apply the library pykalman (version 0.9.2)5,"
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "word embeddings are fed a Conv1D layer with 128",
          "Numerical\nMohammad et al. (2013)": ""
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "",
          "Numerical\nMohammad et al. (2013)": "which implements the Kalman Filter,\nthe Kalman"
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "ﬁlters and a kernel size of 3, followed by a global",
          "Numerical\nMohammad et al. (2013)": ""
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "",
          "Numerical\nMohammad et al. (2013)": "Smoother and the EM algorithm to train SSMs."
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "max-pooling layer.",
          "Numerical\nMohammad et al. (2013)": ""
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "",
          "Numerical\nMohammad et al. (2013)": "We ﬁx the initial state mean as the ﬁrst observed"
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "The two pooled vectors are then concatenated",
          "Numerical\nMohammad et al. (2013)": ""
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "",
          "Numerical\nMohammad et al. (2013)": "value in the sequence (i.e., each song’s ﬁrst verse-"
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "through a Concatenate\nlayer\nas\nthey are\nin the",
          "Numerical\nMohammad et al. (2013)": ""
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "",
          "Numerical\nMohammad et al. (2013)": "level prediction) and the initial\nstate covariance"
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "same dimensionality. We generate the predictions",
          "Numerical\nMohammad et al. (2013)": ""
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "",
          "Numerical\nMohammad et al. (2013)": "as 2. We then conduct experiments with several"
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "of emotion intensities by using a Linear layer with",
          "Numerical\nMohammad et al. (2013)": ""
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "",
          "Numerical\nMohammad et al. (2013)": "groups of parameters transition matrices A,\ntran-"
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "a single neuron4 for regression.",
          "Numerical\nMohammad et al. (2013)": ""
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "",
          "Numerical\nMohammad et al. (2013)": "sition covariance Q, observation matrices C and"
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "",
          "Numerical\nMohammad et al. (2013)": "observation covariance R to initialise the Kalman"
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "4We experimented with a multi-task model that predicted",
          "Numerical\nMohammad et al. (2013)": ""
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "",
          "Numerical\nMohammad et al. (2013)": "Filter and Kalman Smoother.\nFor parameter op-"
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "all six emotions jointly, but preliminary results showed that",
          "Numerical\nMohammad et al. (2013)": ""
        },
        {
          "Hash-Aff-Neg\nSentiment\n3 (20)": "building separate models for each emotion performed better.",
          "Numerical\nMohammad et al. (2013)": "5https://github.com/pykalman/pykalman"
        }
      ],
      "page": 7
    },
    {
      "caption": "Table 4: and Table 5). The LG-SSMs with",
      "data": [
        {
          "Dataset": "NH",
          "ANG": "0.197",
          "DIS": "0.106",
          "FEA": "0.231",
          "JOY": "0.219",
          "SAD": "0.112",
          "SUR": "0.056"
        },
        {
          "Dataset": "LE",
          "ANG": "0.212",
          "DIS": "0.091",
          "FEA": "0.185",
          "JOY": "0.209",
          "SAD": "0.175",
          "SUR": "0.031"
        },
        {
          "Dataset": "NH",
          "ANG": "0.740",
          "DIS": "0.651",
          "FEA": "0.792",
          "JOY": "0.719",
          "SAD": "0.808",
          "SUR": "0.469"
        },
        {
          "Dataset": "LE",
          "ANG": "0.311",
          "DIS": "0.261",
          "FEA": "0.314",
          "JOY": "0.492",
          "SAD": "0.306",
          "SUR": "0.071"
        },
        {
          "Dataset": "NH",
          "ANG": "0.865",
          "DIS": "0.828",
          "FEA": "0.840",
          "JOY": "0.858",
          "SAD": "0.906",
          "SUR": "0.771"
        },
        {
          "Dataset": "LE",
          "ANG": "0.340",
          "DIS": "0.287",
          "FEA": "0.336",
          "JOY": "0.472",
          "SAD": "0.338",
          "SUR": "0.066"
        },
        {
          "Dataset": "NH",
          "ANG": "0.838",
          "DIS": "0.788",
          "FEA": "0.833",
          "JOY": "0.840",
          "SAD": "0.885",
          "SUR": "0.742"
        },
        {
          "Dataset": "LE",
          "ANG": "0.345",
          "DIS": "0.268",
          "FEA": "0.350",
          "JOY": "0.503",
          "SAD": "0.350",
          "SUR": "0.089"
        }
      ],
      "page": 8
    },
    {
      "caption": "Table 4: and Table 5). The LG-SSMs with",
      "data": [
        {
          "0.287\nLE\n0.340": "BERTLexpoly\nNH\n0.838\n0.788",
          "0.336\n0.472\n0.338\n0.066": "0.833\n0.840\n0.885\n0.742"
        },
        {
          "0.287\nLE\n0.340": "0.345\nLE\n0.268",
          "0.336\n0.472\n0.338\n0.066": "0.350\n0.503\n0.350\n0.089"
        },
        {
          "0.287\nLE\n0.340": "Table 3: Pearson correlations between gold-standard labels and predictions of the verse-level models in the NEW-",
          "0.336\n0.472\n0.338\n0.066": ""
        },
        {
          "0.287\nLE\n0.340": "SHEADLINES (NH) and LYRICSEMOTIONS (LE) datasets.",
          "0.336\n0.472\n0.338\n0.066": ""
        },
        {
          "0.287\nLE\n0.340": "timization, we experiment n_iter = {1,3,5,7,10}",
          "0.336\n0.472\n0.338\n0.066": "• The addition of lexicons for incorporating ex-"
        },
        {
          "0.287\nLE\n0.340": "to control the number of EM algorithm iterations.",
          "0.336\n0.472\n0.338\n0.066": "ternal knowledge consistently promotes\nthe"
        },
        {
          "0.287\nLE\n0.340": "Additionally, we\napply\n10-fold\ncross-validation",
          "0.336\n0.472\n0.338\n0.066": "performance of BERT-based models."
        },
        {
          "0.287\nLE\n0.340": "when choosing the optimal parameters via EM,",
          "0.336\n0.472\n0.338\n0.066": ""
        },
        {
          "0.287\nLE\n0.340": "",
          "0.336\n0.472\n0.338\n0.066": "• BERTLex models with polynomial\nfeature"
        },
        {
          "0.287\nLE\n0.340": "which means each song is processed by a Kalman",
          "0.336\n0.472\n0.338\n0.066": ""
        },
        {
          "0.287\nLE\n0.340": "",
          "0.336\n0.472\n0.338\n0.066": "expansion are better\nthan those without, ex-"
        },
        {
          "0.287\nLE\n0.340": "Filter or Kalman Smoother deﬁned by the optimal",
          "0.336\n0.472\n0.338\n0.066": ""
        },
        {
          "0.287\nLE\n0.340": "",
          "0.336\n0.472\n0.338\n0.066": "cept for DISGUST."
        },
        {
          "0.287\nLE\n0.340": "parameters that we obtained from training on the",
          "0.336\n0.472\n0.338\n0.066": ""
        },
        {
          "0.287\nLE\n0.340": "other 90 songs.",
          "0.336\n0.472\n0.338\n0.066": "• Our models are worst at predicting the emo-"
        },
        {
          "0.287\nLE\n0.340": "",
          "0.336\n0.472\n0.338\n0.066": "tion intensities of SURPRISE (lower\nthan"
        },
        {
          "0.287\nLE\n0.340": "5\nResults and Analysis",
          "0.336\n0.472\n0.338\n0.066": "0.1), which is\nin line with similar work in"
        },
        {
          "0.287\nLE\n0.340": "",
          "0.336\n0.472\n0.338\n0.066": "other datasets annotated with the Ekman tax-"
        },
        {
          "0.287\nLE\n0.340": "In this section, we report and discuss the results",
          "0.336\n0.472\n0.338\n0.066": ""
        },
        {
          "0.287\nLE\n0.340": "",
          "0.336\n0.472\n0.338\n0.066": "onomy."
        },
        {
          "0.287\nLE\n0.340": "of\nthe experiments. We ﬁrst compare the results",
          "0.336\n0.472\n0.338\n0.066": ""
        }
      ],
      "page": 8
    },
    {
      "caption": "Table 4: and Table 5). The LG-SSMs with",
      "data": [
        {
          "tion intensities of SURPRISE (lower\nthan": "0.1), which is\nin line with similar work in"
        },
        {
          "tion intensities of SURPRISE (lower\nthan": "other datasets annotated with the Ekman tax-"
        },
        {
          "tion intensities of SURPRISE (lower\nthan": ""
        },
        {
          "tion intensities of SURPRISE (lower\nthan": "onomy."
        },
        {
          "tion intensities of SURPRISE (lower\nthan": ""
        },
        {
          "tion intensities of SURPRISE (lower\nthan": "5.2\nResults of Song-level Models"
        },
        {
          "tion intensities of SURPRISE (lower\nthan": ""
        },
        {
          "tion intensities of SURPRISE (lower\nthan": "Extensive experiments conﬁrm that our song-level"
        },
        {
          "tion intensities of SURPRISE (lower\nthan": "models utilizing the Kalman Filter and Kalman"
        },
        {
          "tion intensities of SURPRISE (lower\nthan": "Smoother can improve the initial predictions from"
        },
        {
          "tion intensities of SURPRISE (lower\nthan": "verse-level models combining BERT and lexicons"
        },
        {
          "tion intensities of SURPRISE (lower\nthan": "(see Table 4 and Table 5).\nThe LG-SSMs with"
        },
        {
          "tion intensities of SURPRISE (lower\nthan": "EM-optimized parameters always perform better"
        },
        {
          "tion intensities of SURPRISE (lower\nthan": "than those without using EM. Furthermore,\nthe"
        },
        {
          "tion intensities of SURPRISE (lower\nthan": "performance improvements of the strongest SSMs"
        },
        {
          "tion intensities of SURPRISE (lower\nthan": "from their corresponding verse-level baselines are"
        },
        {
          "tion intensities of SURPRISE (lower\nthan": "statistically signiﬁcant at 0.05 conﬁdence (marked"
        },
        {
          "tion intensities of SURPRISE (lower\nthan": ""
        },
        {
          "tion intensities of SURPRISE (lower\nthan": "with *), except for SURPRISE."
        },
        {
          "tion intensities of SURPRISE (lower\nthan": ""
        },
        {
          "tion intensities of SURPRISE (lower\nthan": "Theoretically,\nthe Kalman Smoother\nis\nsup-"
        },
        {
          "tion intensities of SURPRISE (lower\nthan": ""
        },
        {
          "tion intensities of SURPRISE (lower\nthan": "posed to perform better\nthan the Kalman Filter"
        },
        {
          "tion intensities of SURPRISE (lower\nthan": ""
        },
        {
          "tion intensities of SURPRISE (lower\nthan": "since the former utilizes all observations\nin the"
        },
        {
          "tion intensities of SURPRISE (lower\nthan": ""
        },
        {
          "tion intensities of SURPRISE (lower\nthan": "whole\nsequence.\nAccording to our\nexperimen-"
        },
        {
          "tion intensities of SURPRISE (lower\nthan": ""
        },
        {
          "tion intensities of SURPRISE (lower\nthan": "tal results, however, the best-performing algorithm"
        },
        {
          "tion intensities of SURPRISE (lower\nthan": ""
        },
        {
          "tion intensities of SURPRISE (lower\nthan": "depends on emotion. On the other hand, running"
        },
        {
          "tion intensities of SURPRISE (lower\nthan": ""
        },
        {
          "tion intensities of SURPRISE (lower\nthan": "the EM algorithm consistently improves\nthe re-"
        },
        {
          "tion intensities of SURPRISE (lower\nthan": ""
        },
        {
          "tion intensities of SURPRISE (lower\nthan": "sults of SSMs that simply use the initial values,"
        },
        {
          "tion intensities of SURPRISE (lower\nthan": ""
        },
        {
          "tion intensities of SURPRISE (lower\nthan": "except for SURPRISE."
        },
        {
          "tion intensities of SURPRISE (lower\nthan": ""
        },
        {
          "tion intensities of SURPRISE (lower\nthan": "Impact\nof\nverse-level\npredictions.\nThe\nper-"
        },
        {
          "tion intensities of SURPRISE (lower\nthan": "formances\nof\napplying Kalman Filter, Kalman"
        }
      ],
      "page": 8
    },
    {
      "caption": "Table 4: ). diluted by optimizing the parameters with an EM",
      "data": [
        {
          "ANG": "0.338",
          "DIS": "0.280",
          "FEA": "0.336",
          "JOY": "0.468",
          "SAD": "0.338",
          "SUR": "0.066"
        },
        {
          "ANG": "0.359∗",
          "DIS": "0.287∗",
          "FEA": "0.352∗",
          "JOY": "0.498∗",
          "SAD": "0.361∗",
          "SUR": "0.069"
        },
        {
          "ANG": "0.362∗",
          "DIS": "0.282",
          "FEA": "0.352∗",
          "JOY": "0.501∗",
          "SAD": "0.366∗",
          "SUR": "0.064"
        },
        {
          "ANG": "0.396∗",
          "DIS": "0.293∗",
          "FEA": "0.357∗",
          "JOY": "0.522∗",
          "SAD": "0.387∗",
          "SUR": "0.069"
        },
        {
          "ANG": "",
          "DIS": "0.280",
          "FEA": "0.339",
          "JOY": "0.522∗",
          "SAD": "0.385∗",
          "SUR": "0.060"
        },
        {
          "ANG": "0.315",
          "DIS": "0.261",
          "FEA": "0.350",
          "JOY": "0.503",
          "SAD": "0.347",
          "SUR": "0.083"
        },
        {
          "ANG": "0.334∗",
          "DIS": "0.267",
          "FEA": "0.367∗",
          "JOY": "0.538∗",
          "SAD": "0.374∗",
          "SUR": "0.088"
        },
        {
          "ANG": "0.332∗",
          "DIS": "0.258",
          "FEA": "0.368∗",
          "JOY": "0.542∗",
          "SAD": "0.380∗",
          "SUR": "0.082"
        },
        {
          "ANG": "0.358∗",
          "DIS": "0.270∗",
          "FEA": "0.371∗",
          "JOY": "0.568∗",
          "SAD": "0.405∗",
          "SUR": "0.087"
        },
        {
          "ANG": "",
          "DIS": "0.251",
          "FEA": "0.355",
          "JOY": "0.570∗",
          "SAD": "0.405∗",
          "SUR": "0.079"
        }
      ],
      "page": 9
    },
    {
      "caption": "Table 4: ). diluted by optimizing the parameters with an EM",
      "data": [
        {
          "Table 5: Pearson correlations between gold-standard labels and SSMs with different values of transition matrices": ""
        },
        {
          "Table 5: Pearson correlations between gold-standard labels and SSMs with different values of transition matrices": ""
        },
        {
          "Table 5: Pearson correlations between gold-standard labels and SSMs with different values of transition matrices": "sition matrices A and ﬁx the other parameters,"
        },
        {
          "Table 5: Pearson correlations between gold-standard labels and SSMs with different values of transition matrices": "the performance of Kalman Filter\nand Kalman"
        },
        {
          "Table 5: Pearson correlations between gold-standard labels and SSMs with different values of transition matrices": "Smoother can be decreased even worse than with-"
        },
        {
          "Table 5: Pearson correlations between gold-standard labels and SSMs with different values of transition matrices": "out them. Fortunately, this kind of diminished per-"
        },
        {
          "Table 5: Pearson correlations between gold-standard labels and SSMs with different values of transition matrices": "formance due to the initial parameter values can be"
        },
        {
          "Table 5: Pearson correlations between gold-standard labels and SSMs with different values of transition matrices": "diluted by optimizing the parameters with an EM"
        },
        {
          "Table 5: Pearson correlations between gold-standard labels and SSMs with different values of transition matrices": "algorithm."
        },
        {
          "Table 5: Pearson correlations between gold-standard labels and SSMs with different values of transition matrices": ""
        },
        {
          "Table 5: Pearson correlations between gold-standard labels and SSMs with different values of transition matrices": ""
        },
        {
          "Table 5: Pearson correlations between gold-standard labels and SSMs with different values of transition matrices": "Impact of parameter optimization.\nFor either"
        },
        {
          "Table 5: Pearson correlations between gold-standard labels and SSMs with different values of transition matrices": "Kalman Filter or Kalman Smoother, using the EM"
        },
        {
          "Table 5: Pearson correlations between gold-standard labels and SSMs with different values of transition matrices": "algorithm to\noptimize\nthe\nparameters\nincreases"
        },
        {
          "Table 5: Pearson correlations between gold-standard labels and SSMs with different values of transition matrices": "Pearson’s r in most cases. Through experiments,"
        },
        {
          "Table 5: Pearson correlations between gold-standard labels and SSMs with different values of transition matrices": "the number of iterations does not signiﬁcantly in-"
        },
        {
          "Table 5: Pearson correlations between gold-standard labels and SSMs with different values of transition matrices": "ﬂuence the performance of the EM algorithm, and"
        },
        {
          "Table 5: Pearson correlations between gold-standard labels and SSMs with different values of transition matrices": "5 ∼ 10 iterations usually produce the strongest re-"
        },
        {
          "Table 5: Pearson correlations between gold-standard labels and SSMs with different values of transition matrices": "sults."
        }
      ],
      "page": 9
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "True": "BERTLex"
        },
        {
          "True": ""
        },
        {
          "True": "SSM"
        },
        {
          "True": ""
        },
        {
          "True": ""
        },
        {
          "True": ""
        },
        {
          "True": ""
        },
        {
          "True": ""
        },
        {
          "True": ""
        },
        {
          "True": "60\n80"
        },
        {
          "True": "song verse number"
        },
        {
          "True": "r(True, BERTLex) = 0.2963, r(True, SSM) = 0.2091"
        },
        {
          "True": ""
        },
        {
          "True": "True"
        },
        {
          "True": "BERTLex"
        },
        {
          "True": "SSM"
        },
        {
          "True": ""
        }
      ],
      "page": 10
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "True": "4\nBERTLex"
        },
        {
          "True": "SSM"
        },
        {
          "True": "3"
        },
        {
          "True": "predicted intensity score (DISGUST)\n2"
        },
        {
          "True": "1"
        },
        {
          "True": "0\n0\n20\n40\n60\n80"
        },
        {
          "True": "song verse number"
        },
        {
          "True": "r(True, BERTLex) = 0.4647, r(True, SSM) = 0.4127"
        },
        {
          "True": "2.5"
        },
        {
          "True": "True"
        },
        {
          "True": "BERTLex"
        },
        {
          "True": "2.0"
        },
        {
          "True": "SSM"
        },
        {
          "True": "predicted intensity score (SURPRISE)\n1.5"
        },
        {
          "True": "1.0"
        },
        {
          "True": "0.5"
        },
        {
          "True": "0.0"
        },
        {
          "True": "0\n20\n40\n60\n80\nsong verse number"
        },
        {
          "True": "r(True, BERTLex) = -0.2383, r(True, SSM) = -0.1515"
        },
        {
          "True": ""
        },
        {
          "True": "Figure 4: Emotional dynamics of ANGER, DISGUST"
        },
        {
          "True": ""
        },
        {
          "True": "and SURPRISE in Bad Romance\nby Lady Gaga:"
        },
        {
          "True": ""
        },
        {
          "True": "Pearson’s r between ground truth and predictions of"
        },
        {
          "True": ""
        },
        {
          "True": "BERTLexpoly, estimates of Kalman Filter, are reported,"
        },
        {
          "True": ""
        },
        {
          "True": "respectively."
        },
        {
          "True": ""
        },
        {
          "True": ""
        },
        {
          "True": "emotional dynamics\n(see the third sub-ﬁgure in"
        },
        {
          "True": ""
        },
        {
          "True": "Figure 4).\nThe emotional dynamics trend of es-"
        },
        {
          "True": ""
        },
        {
          "True": "timates by song-level models is similar\nto verse-"
        },
        {
          "True": ""
        },
        {
          "True": "level models.\nDue to the Gaussian assumption,"
        },
        {
          "True": ""
        },
        {
          "True": "Kalman Filter and Kalman Smoother tend to ﬂat-"
        },
        {
          "True": ""
        },
        {
          "True": "ten or smooth the curves of verse-level predictions."
        },
        {
          "True": ""
        },
        {
          "True": "This means that applying LG-SSMs can somewhat"
        },
        {
          "True": ""
        },
        {
          "True": "reduce errors in the second type of emotion dy-"
        },
        {
          "True": ""
        },
        {
          "True": "namic\ncurves.\nFor\nthe ﬁrst\ntype,\nhowever,\nthe"
        },
        {
          "True": ""
        },
        {
          "True": "Kalman Filter and Kalman Smoother make the re-"
        },
        {
          "True": ""
        },
        {
          "True": "sults worse, as smoother estimations are not desir-"
        },
        {
          "True": ""
        },
        {
          "True": "able in this situation."
        },
        {
          "True": ""
        },
        {
          "True": ""
        },
        {
          "True": "Using text solely.\nLyrics in LYRICSEMOTIONS"
        },
        {
          "True": ""
        },
        {
          "True": "are synchronised to acoustic features, where some"
        },
        {
          "True": ""
        },
        {
          "True": "verses with identical\ntext are labelled as different"
        },
        {
          "True": "emotional intensities. For instance, in Table 6, the"
        },
        {
          "True": "verse \"When it rain and rain, it rain and rain\" re-"
        },
        {
          "True": "peats multiple times in the song Rain by Mika, and"
        },
        {
          "True": "their gold-standard SADNESS labels differ in dif-"
        },
        {
          "True": "ferent verses as the emotion progresses with mu-"
        },
        {
          "True": "sic. However, the verse-level models can only pro-"
        },
        {
          "True": "duce the same predictions since these verses share"
        },
        {
          "True": "exactly the same text, and the models do not con-"
        },
        {
          "True": "sider the context of the whole song. Consequently,"
        },
        {
          "True": "the emotion scores of different verses predicted by"
        },
        {
          "True": "LG-SSMs are close, as\nthe results of\nsong-level"
        },
        {
          "True": "models are highly related to the initial predictions"
        },
        {
          "True": "from BERTLex."
        }
      ],
      "page": 10
    },
    {
      "caption": "Table 6: SADNESS scores of verses with the same",
      "data": [
        {
          "Verse ID\nGold\nBERTLex\nSmoother-EM": "",
          "and Uhlmann, 2004) might be a better ﬁt for": "modelling emotion dynamics."
        },
        {
          "Verse ID\nGold\nBERTLex\nSmoother-EM": "s55v15\n4.33\n8.65\n1.68",
          "and Uhlmann, 2004) might be a better ﬁt for": ""
        },
        {
          "Verse ID\nGold\nBERTLex\nSmoother-EM": "s55v31\n7.66\n8.65\n1.68",
          "and Uhlmann, 2004) might be a better ﬁt for": ""
        },
        {
          "Verse ID\nGold\nBERTLex\nSmoother-EM": "",
          "and Uhlmann, 2004) might be a better ﬁt for": "• As\nthe LYRICSEMOTIONS dataset\nis anno-"
        },
        {
          "Verse ID\nGold\nBERTLex\nSmoother-EM": "s55v32\n7.33\n8.65\n1.63",
          "and Uhlmann, 2004) might be a better ﬁt for": ""
        },
        {
          "Verse ID\nGold\nBERTLex\nSmoother-EM": "",
          "and Uhlmann, 2004) might be a better ﬁt for": "tated on parallel acoustic and text\nfeatures,"
        },
        {
          "Verse ID\nGold\nBERTLex\nSmoother-EM": "",
          "and Uhlmann, 2004) might be a better ﬁt for": "using lyrics\nsolely as\nthe feature can cause"
        },
        {
          "Verse ID\nGold\nBERTLex\nSmoother-EM": "Table 6:\nSADNESS scores of verses with the\nsame",
          "and Uhlmann, 2004) might be a better ﬁt for": ""
        },
        {
          "Verse ID\nGold\nBERTLex\nSmoother-EM": "",
          "and Uhlmann, 2004) might be a better ﬁt for": "inconsistencies in the model. Extending our"
        },
        {
          "Verse ID\nGold\nBERTLex\nSmoother-EM": "\"When it rain and rain,\nit rain and rain\"\nlyrics verse",
          "and Uhlmann, 2004) might be a better ﬁt for": ""
        },
        {
          "Verse ID\nGold\nBERTLex\nSmoother-EM": "but different gold-standard labels in the song.",
          "and Uhlmann, 2004) might be a better ﬁt for": "method to a multi-modal setting would rem-"
        },
        {
          "Verse ID\nGold\nBERTLex\nSmoother-EM": "",
          "and Uhlmann, 2004) might be a better ﬁt for": "edy this\nissue when the identical\nlyrics are"
        },
        {
          "Verse ID\nGold\nBERTLex\nSmoother-EM": "",
          "and Uhlmann, 2004) might be a better ﬁt for": "companions with different musical\nfeatures"
        },
        {
          "Verse ID\nGold\nBERTLex\nSmoother-EM": "6\nConclusion and Future Work",
          "and Uhlmann, 2004) might be a better ﬁt for": ""
        },
        {
          "Verse ID\nGold\nBERTLex\nSmoother-EM": "",
          "and Uhlmann, 2004) might be a better ﬁt for": "to\nappear\nin\nvarious\nverses.\nTaking\nthe"
        },
        {
          "Verse ID\nGold\nBERTLex\nSmoother-EM": "",
          "and Uhlmann, 2004) might be a better ﬁt for": "knowledge\nof\nsong\nstructure\n(e.g.,\nIntro\n-"
        },
        {
          "Verse ID\nGold\nBERTLex\nSmoother-EM": "This paper presents a two-stage BERTLex-SSM",
          "and Uhlmann, 2004) might be a better ﬁt for": ""
        },
        {
          "Verse ID\nGold\nBERTLex\nSmoother-EM": "",
          "and Uhlmann, 2004) might be a better ﬁt for": "Verse\n- Bridge\n- Chorus)\ninto account has"
        },
        {
          "Verse ID\nGold\nBERTLex\nSmoother-EM": "framework for the sequence-labelling emotion in-",
          "and Uhlmann, 2004) might be a better ﬁt for": ""
        },
        {
          "Verse ID\nGold\nBERTLex\nSmoother-EM": "",
          "and Uhlmann, 2004) might be a better ﬁt for": "the potential\nto advance the recognition of"
        },
        {
          "Verse ID\nGold\nBERTLex\nSmoother-EM": "tensity recognition tasks.\nCombining the\ncon-",
          "and Uhlmann, 2004) might be a better ﬁt for": ""
        },
        {
          "Verse ID\nGold\nBERTLex\nSmoother-EM": "",
          "and Uhlmann, 2004) might be a better ﬁt for": "emotion dynamics, assuming the way (up or"
        },
        {
          "Verse ID\nGold\nBERTLex\nSmoother-EM": "textualized embeddings with static word embed-",
          "and Uhlmann, 2004) might be a better ﬁt for": ""
        },
        {
          "Verse ID\nGold\nBERTLex\nSmoother-EM": "",
          "and Uhlmann, 2004) might be a better ﬁt for": "down) that emotion intensities change is cor-"
        },
        {
          "Verse ID\nGold\nBERTLex\nSmoother-EM": "dings and then modelling the initial predicted in-",
          "and Uhlmann, 2004) might be a better ﬁt for": ""
        },
        {
          "Verse ID\nGold\nBERTLex\nSmoother-EM": "",
          "and Uhlmann, 2004) might be a better ﬁt for": "related with which part of the song the verses"
        },
        {
          "Verse ID\nGold\nBERTLex\nSmoother-EM": "tensity scores as a State Space model, our method",
          "and Uhlmann, 2004) might be a better ﬁt for": ""
        },
        {
          "Verse ID\nGold\nBERTLex\nSmoother-EM": "",
          "and Uhlmann, 2004) might be a better ﬁt for": "locate."
        },
        {
          "Verse ID\nGold\nBERTLex\nSmoother-EM": "can utilize context-sensitive features with exter-",
          "and Uhlmann, 2004) might be a better ﬁt for": ""
        }
      ],
      "page": 11
    },
    {
      "caption": "Table 6: SADNESS scores of verses with the same",
      "data": [
        {
          "nal": "namic transitions. Experimental results show that",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": ""
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": ""
        },
        {
          "nal": "our proposed BERTLex-SSM effectively predicts",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": ""
        },
        {
          "nal": "emotion intensities in the lyrics without requiring",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": ""
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": ""
        },
        {
          "nal": "annotated lyrics data.",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": ""
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": ""
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": "Our analysis in Section 5.3 points to a range of"
        },
        {
          "nal": "directions for future work:",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": ""
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": ""
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": "• While our method could apply any general"
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": ""
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": "verse-level model,\nincluding a pure lexicon-"
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": ""
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": "based one,\nin practice, we obtained the best"
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": ""
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": "results\nby\nleveraging\nannotated\nsentence-"
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": ""
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": "level datasets. This naturally leads to the do-"
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": ""
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": "main discrepancy:\nin our particular case, be-"
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": ""
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": "tween the news and lyrics domains.\nGiven"
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": ""
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": "that unlabelled song lyrics are relatively easy"
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": ""
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": "to\nobtain,\none\ndirection\nis\nto\nincorporate"
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": ""
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": "unsupervised domain adaptation techniques"
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": "(Ramponi and Plank, 2020)\nto improve the"
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": ""
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": "performance of the verse-level model. Semi-"
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": ""
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": "supervised\nlearning\n(similar\nto Täckström"
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": ""
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": "and McDonald (2011b))\nis another promis-"
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": ""
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": "ing direction in this avenue, although meth-"
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": "ods would need to be modiﬁed to incorporate"
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": "the continuous nature of the emotion labels."
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": ""
        },
        {
          "nal": "• Despite",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": "being\nable\nto\noptimize\nthe\nesti-"
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": "mates\nthrough Kalman Filter\nand Kalman"
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": "Smoother,\nthe\nsimplicity\nof\nthe LG-SSM"
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": "makes it difﬁcult\nto deal with the wide vari-"
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": "ations\nin\nemotion\nspace\ndynamics,\ngiven"
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": "that\nit\nis\na\nlinear model.\nWe hypothesize"
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": "that non-linear SSM extensions\n(Julier and"
        },
        {
          "nal": "",
          "knowledge\nand\ncapture\nthe\nemotional\ndy-": "Uhlmann, 1997; Ito and Xiong, 2000; Julier"
        }
      ],
      "page": 11
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Amodei. 2020. Language models are few-shot": "in Neural\nInformation\nlearners.\nIn Advances",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "national Committee on Computational Linguis-"
        },
        {
          "Amodei. 2020. Language models are few-shot": "Processing Systems, volume 33, pages 1877–",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "tics."
        },
        {
          "Amodei. 2020. Language models are few-shot": "1901. Curran Associates, Inc.",
          "4441–4453, Barcelona, Spain (Online).\nInter-": ""
        },
        {
          "Amodei. 2020. Language models are few-shot": "",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "Deepanway Ghosal, Navonil Majumder, Rada Mi-"
        },
        {
          "Amodei. 2020. Language models are few-shot": "Marcelo Caetano, Athanasios Mouchtaris,\nand",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "halcea, and Soujanya Poria. 2021.\nExploring"
        },
        {
          "Amodei. 2020. Language models are few-shot": "Frans Wiering.\n2012.\nThe\nrole\nof\ntime\nin",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "the role of context\nin utterance-level emotion,"
        },
        {
          "Amodei. 2020. Language models are few-shot": "music\nemotion\nrecognition: Modeling musi-",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "act\nand intent\nclassiﬁcation in conversations:"
        },
        {
          "Amodei. 2020. Language models are few-shot": "cal emotions from time-varying music features.",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "the As-\nAn empirical\nstudy.\nIn Findings of"
        },
        {
          "Amodei. 2020. Language models are few-shot": "In International Symposium on Computer Mu-",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "sociation for Computational Linguistics: ACL-"
        },
        {
          "Amodei. 2020. Language models are few-shot": "sic Modeling\nand Retrieval,\npages\n171–196.",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "IJCNLP 2021, pages 1435–1449, Online. Asso-"
        },
        {
          "Amodei. 2020. Language models are few-shot": "Springer.",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "ciation for Computational Linguistics."
        },
        {
          "Amodei. 2020. Language models are few-shot": "Luna\nDe\nBruyne,\nOrphee\nDe\nClercq,\nand",
          "4441–4453, Barcelona, Spain (Online).\nInter-": ""
        },
        {
          "Amodei. 2020. Language models are few-shot": "",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "Deepanway Ghosal,\nNavonil Majumder,\nSou-"
        },
        {
          "Amodei. 2020. Language models are few-shot": "Veronique Hoste. 2021.\nEmotional RobBERT",
          "4441–4453, Barcelona, Spain (Online).\nInter-": ""
        },
        {
          "Amodei. 2020. Language models are few-shot": "",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "janya Poria, Niyati Chhaya, and Alexander Gel-"
        },
        {
          "Amodei. 2020. Language models are few-shot": "and insensitive BERTje: Combining transform-",
          "4441–4453, Barcelona, Spain (Online).\nInter-": ""
        },
        {
          "Amodei. 2020. Language models are few-shot": "",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "bukh. 2019.\nDialogueGCN: A graph convo-"
        },
        {
          "Amodei. 2020. Language models are few-shot": "ers and affect\nlexica for Dutch emotion detec-",
          "4441–4453, Barcelona, Spain (Online).\nInter-": ""
        },
        {
          "Amodei. 2020. Language models are few-shot": "",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "lutional neural network for\nemotion recogni-"
        },
        {
          "Amodei. 2020. Language models are few-shot": "the Eleventh Work-\ntion.\nIn Proceedings of",
          "4441–4453, Barcelona, Spain (Online).\nInter-": ""
        },
        {
          "Amodei. 2020. Language models are few-shot": "",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "the\ntion in conversation.\nIn Proceedings of"
        },
        {
          "Amodei. 2020. Language models are few-shot": "shop on Computational Approaches to Subjec-",
          "4441–4453, Barcelona, Spain (Online).\nInter-": ""
        },
        {
          "Amodei. 2020. Language models are few-shot": "",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "2019 Conference on Empirical Methods in Nat-"
        },
        {
          "Amodei. 2020. Language models are few-shot": "tivity,\nSentiment\nand\nSocial Media Analysis,",
          "4441–4453, Barcelona, Spain (Online).\nInter-": ""
        },
        {
          "Amodei. 2020. Language models are few-shot": "",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "ural Language Processing and the 9th Interna-"
        },
        {
          "Amodei. 2020. Language models are few-shot": "pages 257–263, Online. Association for Com-",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "tional Joint Conference on Natural Language"
        },
        {
          "Amodei. 2020. Language models are few-shot": "putational Linguistics.",
          "4441–4453, Barcelona, Spain (Online).\nInter-": ""
        },
        {
          "Amodei. 2020. Language models are few-shot": "",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "Processing (EMNLP-IJCNLP), pages 154–164,"
        },
        {
          "Amodei. 2020. Language models are few-shot": "",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "Hong Kong, China. Association for Computa-"
        },
        {
          "Amodei. 2020. Language models are few-shot": "Arthur P Dempster, Nan M Laird, and Donald B",
          "4441–4453, Barcelona, Spain (Online).\nInter-": ""
        },
        {
          "Amodei. 2020. Language models are few-shot": "",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "tional Linguistics."
        },
        {
          "Amodei. 2020. Language models are few-shot": "Rubin. 1977.\nMaximum likelihood from in-",
          "4441–4453, Barcelona, Spain (Online).\nInter-": ""
        },
        {
          "Amodei. 2020. Language models are few-shot": "complete data via the em algorithm. Journal of",
          "4441–4453, Barcelona, Spain (Online).\nInter-": ""
        },
        {
          "Amodei. 2020. Language models are few-shot": "",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "Pranav Goel, Devang Kulshreshtha, Prayas Jain,"
        },
        {
          "Amodei. 2020. Language models are few-shot": "the Royal Statistical Society: Series B (Method-",
          "4441–4453, Barcelona, Spain (Online).\nInter-": ""
        },
        {
          "Amodei. 2020. Language models are few-shot": "",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "and Kaushal Kumar Shukla. 2017.\nPrayas at"
        },
        {
          "Amodei. 2020. Language models are few-shot": "ological), 39(1):1–22.",
          "4441–4453, Barcelona, Spain (Online).\nInter-": ""
        },
        {
          "Amodei. 2020. Language models are few-shot": "",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "EmoInt 2017: An ensemble of deep neural ar-"
        },
        {
          "Amodei. 2020. Language models are few-shot": "",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "chitectures\nfor emotion intensity prediction in"
        },
        {
          "Amodei. 2020. Language models are few-shot": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and",
          "4441–4453, Barcelona, Spain (Online).\nInter-": ""
        },
        {
          "Amodei. 2020. Language models are few-shot": "",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "the 8th Workshop on\ntweets.\nIn Proceedings of"
        },
        {
          "Amodei. 2020. Language models are few-shot": "Kristina Toutanova. 2019. BERT: Pre-training",
          "4441–4453, Barcelona, Spain (Online).\nInter-": ""
        },
        {
          "Amodei. 2020. Language models are few-shot": "",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "Computational Approaches to Subjectivity, Sen-"
        },
        {
          "Amodei. 2020. Language models are few-shot": "of deep bidirectional\ntransformers for language",
          "4441–4453, Barcelona, Spain (Online).\nInter-": ""
        },
        {
          "Amodei. 2020. Language models are few-shot": "",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "timent and Social Media Analysis, pages 58–65,"
        },
        {
          "Amodei. 2020. Language models are few-shot": "of\nthe\n2019\nunderstanding.\nIn Proceedings",
          "4441–4453, Barcelona, Spain (Online).\nInter-": ""
        },
        {
          "Amodei. 2020. Language models are few-shot": "",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "Copenhagen, Denmark. Association for Com-"
        },
        {
          "Amodei. 2020. Language models are few-shot": "Conference\nof\nthe North American Chapter",
          "4441–4453, Barcelona, Spain (Online).\nInter-": ""
        },
        {
          "Amodei. 2020. Language models are few-shot": "",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "putational Linguistics."
        },
        {
          "Amodei. 2020. Language models are few-shot": "of\nthe Association for Computational Linguis-",
          "4441–4453, Barcelona, Spain (Online).\nInter-": ""
        },
        {
          "Amodei. 2020. Language models are few-shot": "tics: Human Language Technologies, Volume",
          "4441–4453, Barcelona, Spain (Online).\nInter-": ""
        },
        {
          "Amodei. 2020. Language models are few-shot": "",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "Devamanyu Hazarika, Soujanya Poria, Rada Mi-"
        },
        {
          "Amodei. 2020. Language models are few-shot": "1 (Long and Short Papers), pages 4171–4186,",
          "4441–4453, Barcelona, Spain (Online).\nInter-": ""
        },
        {
          "Amodei. 2020. Language models are few-shot": "",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "halcea, Erik Cambria, and Roger Zimmermann."
        },
        {
          "Amodei. 2020. Language models are few-shot": "Minneapolis, Minnesota. Association for Com-",
          "4441–4453, Barcelona, Spain (Online).\nInter-": ""
        },
        {
          "Amodei. 2020. Language models are few-shot": "",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "2018a.\nICON: Interactive conversational mem-"
        },
        {
          "Amodei. 2020. Language models are few-shot": "putational Linguistics.",
          "4441–4453, Barcelona, Spain (Online).\nInter-": ""
        },
        {
          "Amodei. 2020. Language models are few-shot": "",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "ory network for multimodal emotion detection."
        },
        {
          "Amodei. 2020. Language models are few-shot": "",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "the 2018 Conference on Em-\nIn Proceedings of"
        },
        {
          "Amodei. 2020. Language models are few-shot": "Paul Ekman. 1993.\nFacial expression and emo-",
          "4441–4453, Barcelona, Spain (Online).\nInter-": ""
        },
        {
          "Amodei. 2020. Language models are few-shot": "",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "pirical Methods in Natural Language Process-"
        },
        {
          "Amodei. 2020. Language models are few-shot": "tion. American psychologist, 48(4):384.",
          "4441–4453, Barcelona, Spain (Online).\nInter-": ""
        },
        {
          "Amodei. 2020. Language models are few-shot": "",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "ing, pages 2594–2604, Brussels, Belgium. As-"
        },
        {
          "Amodei. 2020. Language models are few-shot": "Andrea Esuli and Fabrizio Sebastiani. 2007. Sen-",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "sociation for Computational Linguistics."
        },
        {
          "Amodei. 2020. Language models are few-shot": "tiwordnet: a high-coverage lexical resource for",
          "4441–4453, Barcelona, Spain (Online).\nInter-": ""
        },
        {
          "Amodei. 2020. Language models are few-shot": "",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "Devamanyu\nHazarika,\nSoujanya\nPoria,\nAmir"
        },
        {
          "Amodei. 2020. Language models are few-shot": "opinion mining. Evaluation, 17(1):26.",
          "4441–4453, Barcelona, Spain (Online).\nInter-": ""
        },
        {
          "Amodei. 2020. Language models are few-shot": "",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "Zadeh, Erik Cambria, Louis-Philippe Morency,"
        },
        {
          "Amodei. 2020. Language models are few-shot": "Mauajama Firdaus, Hardik Chauhan, Asif Ekbal,",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "and Roger Zimmermann. 2018b.\nConversa-"
        },
        {
          "Amodei. 2020. Language models are few-shot": "and Pushpak Bhattacharyya. 2020. MEISD: A",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "tional memory network for\nemotion recogni-"
        },
        {
          "Amodei. 2020. Language models are few-shot": "multimodal multi-label emotion,\nintensity and",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "tion in dyadic dialogue videos.\nIn Proceed-"
        },
        {
          "Amodei. 2020. Language models are few-shot": "sentiment dialogue dataset\nfor emotion recog-",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "ings of the 2018 Conference of the North Amer-"
        },
        {
          "Amodei. 2020. Language models are few-shot": "nition and sentiment analysis in conversations.",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "ican Chapter of\nthe Association for Compu-"
        },
        {
          "Amodei. 2020. Language models are few-shot": "the 28th International Con-\nIn Proceedings of",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "tational Linguistics: Human Language Tech-"
        },
        {
          "Amodei. 2020. Language models are few-shot": "ference\non Computational Linguistics,\npages",
          "4441–4453, Barcelona, Spain (Online).\nInter-": "nologies, Volume 1 (Long Papers), pages 2122–"
        }
      ],
      "page": 12
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "2132, New Orleans, Louisiana. Association for": "Computational Linguistics.",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "sion, perception, and induction of musical emo-"
        },
        {
          "2132, New Orleans, Louisiana. Association for": "",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "tions: A review and a questionnaire study of"
        },
        {
          "2132, New Orleans, Louisiana. Association for": "Chao-Chun Hsu, Sheng-Yeh Chen, Chuan-Chun",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "Journal of new music re-\neveryday listening."
        },
        {
          "2132, New Orleans, Louisiana. Association for": "Kuo,\nTing-Hao\nHuang,\nand\nLun-Wei\nKu.",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "search, 33(3):217–238."
        },
        {
          "2132, New Orleans, Louisiana. Association for": "2018.\nEmotionLines:\nAn\nemotion\ncorpus",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": ""
        },
        {
          "2132, New Orleans, Louisiana. Association for": "of multi-party conversations.\nIn Proceedings",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "Rudolph Emil Kalman. 1960. A new approach to"
        },
        {
          "2132, New Orleans, Louisiana. Association for": "of\nthe Eleventh\nInternational Conference\non",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "Jour-\nlinear ﬁltering and prediction problems."
        },
        {
          "2132, New Orleans, Louisiana. Association for": "Language Resources\nand Evaluation\n(LREC",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "nal of Basic Engineering, 82(1):35–45."
        },
        {
          "2132, New Orleans, Louisiana. Association for": "2018), Miyazaki,\nJapan. European Language",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": ""
        },
        {
          "2132, New Orleans, Louisiana. Association for": "Resources Association (ELRA).",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "Seungyeon Kim,\nJoonseok Lee, Guy Lebanon,"
        },
        {
          "2132, New Orleans, Louisiana. Association for": "",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "and Haesun Park. 2015.\nEstimating temporal"
        },
        {
          "2132, New Orleans, Louisiana. Association for": "Dou Hu, Lingwei Wei, and Xiaoyong Huai. 2021.",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "dynamics of human emotions.\nIn Proceedings"
        },
        {
          "2132, New Orleans, Louisiana. Association for": "DialogueCRN: Contextual\nreasoning networks",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "of the Twenty-Ninth AAAI Conference on Artiﬁ-"
        },
        {
          "2132, New Orleans, Louisiana. Association for": "for emotion recognition in conversations.\nIn",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "cial Intelligence, January 25-30, 2015, Austin,"
        },
        {
          "2132, New Orleans, Louisiana. Association for": "Proceedings of\nthe 59th Annual Meeting of\nthe",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "Texas, USA, pages 168–174. AAAI Press."
        },
        {
          "2132, New Orleans, Louisiana. Association for": "Association for Computational Linguistics and",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": ""
        },
        {
          "2132, New Orleans, Louisiana. Association for": "the 11th International Joint Conference on Nat-",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "Yoon Kim. 2014. Convolutional neural networks"
        },
        {
          "2132, New Orleans, Louisiana. Association for": "ural Language Processing (Volume 1: Long Pa-",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "for\nsentence classiﬁcation.\nIn Proceedings of"
        },
        {
          "2132, New Orleans, Louisiana. Association for": "pers),\npages 7042–7052, Online. Association",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "the 2014 Conference on Empirical Methods in"
        },
        {
          "2132, New Orleans, Louisiana. Association for": "for Computational Linguistics.",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "Natural Language Processing (EMNLP), pages"
        },
        {
          "2132, New Orleans, Louisiana. Association for": "",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "1746–1751, Doha, Qatar. Association for Com-"
        },
        {
          "2132, New Orleans, Louisiana. Association for": "Taichi\nIshiwatari, Yuki Yasuda, Taro Miyazaki,",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "putational Linguistics."
        },
        {
          "2132, New Orleans, Louisiana. Association for": "and Jun Goto. 2020. Relation-aware graph at-",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": ""
        },
        {
          "2132, New Orleans, Louisiana. Association for": "tention networks with relational position encod-",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "Youngmoo E Kim, Erik M Schmidt, Raymond"
        },
        {
          "2132, New Orleans, Louisiana. Association for": "ings for emotion recognition in conversations.",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "Migneco, Brandon G Morton, Patrick Richard-"
        },
        {
          "2132, New Orleans, Louisiana. Association for": "the 2020 Conference on Em-\nIn Proceedings of",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "son, Jeffrey Scott, Jacquelin A Speck, and Dou-"
        },
        {
          "2132, New Orleans, Louisiana. Association for": "pirical Methods in Natural Language Process-",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "glas Turnbull. 2010. Music emotion recogni-"
        },
        {
          "2132, New Orleans, Louisiana. Association for": "ing (EMNLP), pages 7360–7370, Online. Asso-",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "tion: A state of the art review.\nIn 11th Interna-"
        },
        {
          "2132, New Orleans, Louisiana. Association for": "ciation for Computational Linguistics.",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "tional Society for Music Information Retrieval"
        },
        {
          "2132, New Orleans, Louisiana. Association for": "",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "Conference\n(ISMIR 2010),\nvolume 86,\npages"
        },
        {
          "2132, New Orleans, Louisiana. Association for": "Kazufumi\nIto and Kaiqi Xiong. 2000.\nGaussian",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "255–266."
        },
        {
          "2132, New Orleans, Louisiana. Association for": "IEEE\nﬁlters\nfor nonlinear ﬁltering problems.",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": ""
        },
        {
          "2132, New Orleans, Louisiana. Association for": "transactions on automatic control, 45(5):910–",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "Thomas N. Kipf and Max Welling. 2017.\nSemi-"
        },
        {
          "2132, New Orleans, Louisiana. Association for": "927.",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "supervised classiﬁcation with graph convolu-"
        },
        {
          "2132, New Orleans, Louisiana. Association for": "",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "tional networks.\nIn 5th International Confer-"
        },
        {
          "2132, New Orleans, Louisiana. Association for": "Wenxiang\nJiao, Michael Lyu,\nand\nIrwin King.",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "ence on Learning Representations, ICLR 2017,"
        },
        {
          "2132, New Orleans, Louisiana. Association for": "2020.\nReal-time emotion recognition via at-",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "Toulon, France, April 24-26, 2017, Conference"
        },
        {
          "2132, New Orleans, Louisiana. Association for": "tention gated hierarchical memory network.\nIn",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "Track Proceedings."
        },
        {
          "2132, New Orleans, Louisiana. Association for": "Proceedings of\nthe AAAI Conference on Artiﬁ-",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": ""
        },
        {
          "2132, New Orleans, Louisiana. Association for": "cial Intelligence, 05, pages 8002–8009.",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "Svetlana Kiritchenko, Xiaodan Zhu, and Saif M"
        },
        {
          "2132, New Orleans, Louisiana. Association for": "",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "Mohammad. 2014. Sentiment analysis of short"
        },
        {
          "2132, New Orleans, Louisiana. Association for": "Simon J Julier and Jeffrey K Uhlmann. 1997. New",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "informal texts. Journal of Artiﬁcial Intelligence"
        },
        {
          "2132, New Orleans, Louisiana. Association for": "extension of the kalman ﬁlter to nonlinear sys-",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "Research, 50:723–762."
        },
        {
          "2132, New Orleans, Louisiana. Association for": "tems.\nIn Signal processing, sensor fusion, and",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": ""
        },
        {
          "2132, New Orleans, Louisiana. Association for": "target recognition VI, volume 3068, pages 182–",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "Anna Koufakou, Endang Wahyu Pamungkas, Va-"
        },
        {
          "2132, New Orleans, Louisiana. Association for": "193.\nInternational Society for Optics and Pho-",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "lerio Basile,\nand Viviana Patti. 2020.\nHurt-"
        },
        {
          "2132, New Orleans, Louisiana. Association for": "tonics.",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "BERT:\nIncorporating\nlexical\nfeatures\nwith"
        },
        {
          "2132, New Orleans, Louisiana. Association for": "",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "BERT for the detection of abusive language.\nIn"
        },
        {
          "2132, New Orleans, Louisiana. Association for": "Simon J Julier and Jeffrey K Uhlmann. 2004. Un-",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "Proceedings of\nthe Fourth Workshop on Online"
        },
        {
          "2132, New Orleans, Louisiana. Association for": "scented ﬁltering and nonlinear estimation. Pro-",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "Abuse and Harms, pages 34–43, Online. Asso-"
        },
        {
          "2132, New Orleans, Louisiana. Association for": "ceedings of the IEEE, 92(3):401–422.",
          "Patrik N Juslin and Petri Laukka. 2004.\nExpres-": "ciation for Computational Linguistics."
        }
      ],
      "page": 13
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "nando C. N. Pereira. 2001.\nConditional\nran-",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "and Rui\nPedro\nPaiva.\n2016.\nEmotionally-"
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "dom ﬁelds: Probabilistic models for segment-",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "relevant\nfeatures\nfor classiﬁcation and regres-"
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "ing and labeling sequence data.\nIn Proceedings",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "IEEE Transactions on Af-\nsion of music lyrics."
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "of\nthe Eighteenth International Conference on",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "fective Computing, 9(2):240–254."
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "Machine Learning (ICML 2001), Williams Col-",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": ""
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "Andrew McCallum, Dayne Freitag, and Fernando"
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "lege, Williamstown, MA, USA, June 28 - July 1,",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": ""
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "C. N. Pereira. 2000. Maximum entropy markov"
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "2001, pages 282–289. Morgan Kaufmann.",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": ""
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "models for information extraction and segmen-"
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "the Seventeenth In-\ntation.\nIn Proceedings of"
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "Jingye Li, Donghong Ji, Fei Li, Meishan Zhang,",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": ""
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "ternational Conference on Machine Learning"
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "and Yijiang Liu. 2020. HiTrans: A transformer-",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": ""
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "(ICML 2000),\nStanford University,\nStanford,"
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "based context- and speaker-sensitive model for",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": ""
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "CA, USA, June 29 - July 2, 2000, pages 591–"
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "emotion detection in conversations.\nIn Proceed-",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": ""
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "598. Morgan Kaufmann."
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "ings of\nthe 28th International Conference on",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": ""
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "Computational Linguistics, pages 4190–4200,",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": ""
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "Ryan McDonald, Kerry Hannan, Tyler Neylon,"
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "Barcelona, Spain (Online).\nInternational Com-",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": ""
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "Mike Wells,\nand\nJeff Reynar.\n2007.\nStruc-"
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "mittee on Computational Linguistics.",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": ""
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "tured models for ﬁne-to-coarse sentiment analy-"
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "sis.\nIn Proceedings of the 45th Annual Meeting"
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "Yanran Li, Hui Su, Xiaoyu Shen, Wenjie Li,",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": ""
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "of\nthe Association of Computational Linguis-"
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "Ziqiang Cao, and Shuzi Niu. 2017.\nDailyDi-",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": ""
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "tics, pages 432–439, Prague, Czech Republic."
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "alog: A manually labelled multi-turn dialogue",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": ""
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "Association for Computational Linguistics."
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "the Eighth Interna-\ndataset.\nIn Proceedings of",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": ""
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "tional Joint Conference on Natural Language",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "Gary McKeown, Michel Valstar, Roddy Cowie,"
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "Processing (Volume 1:\nLong Papers),\npages",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "Maja Pantic, and Marc Schroder. 2011. The se-"
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "986–995, Taipei, Taiwan. Asian Federation of",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "maine database: Annotated multimodal records"
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "Natural Language Processing.",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "of emotionally colored conversations between a"
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "IEEE transactions\nperson and a limited agent."
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "Zheng Lian,\nJianhua Tao, Bin Liu,\nJian Huang,",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": ""
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "on affective computing, 3(1):5–17."
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "Zhanlei Yang,\nand Rongjun Li. 2020.\nCon-",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": ""
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "versational\nemotion\nrecognition\nusing\nself-",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "Yash Mehta,\nSamin\nFatehi,\nAmirmohammad"
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "attention mechanisms\nand\ngraph\nneural\nnet-",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "Kazameini, Clemens Stachl, Erik Cambria, and"
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "works.\nIn Interspeech 2020, 21st Annual Con-",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "Sauleh Eetemadi. 2020.\nBottom-up and top-"
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "ference\nof\nthe\nInternational\nSpeech Commu-",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "down:\nPredicting personality with psycholin-"
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "nication Association, Virtual Event, Shanghai,",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "guistic and language model\nfeatures.\nIn 2020"
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "China, 25-29 October 2020, pages 2347–2351.",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "IEEE International Conference on Data Mining"
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "ISCA.",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "(ICDM), pages 1184–1189. IEEE."
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "Hardik Meisheri and Lipika Dey. 2018.\nTCS re-"
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "Xin Lu, Yanyan Zhao, Yang Wu, Yijian Tian,",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": ""
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "search at SemEval-2018 task 1:\nLearning ro-"
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "Huipeng Chen,\nand Bing Qin. 2020.\nAn it-",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": ""
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "bust representations using multi-attention archi-"
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "erative\nemotion interaction network for\nemo-",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": ""
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "tecture.\nIn Proceedings of The 12th Interna-"
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "tion recognition in conversations.\nIn Proceed-",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": ""
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "tional Workshop on Semantic Evaluation, pages"
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "ings of\nthe 28th International Conference on",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": ""
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "291–299, New Orleans, Louisiana. Association"
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "Computational Linguistics, pages 4078–4088,",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": ""
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "for Computational Linguistics."
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "Barcelona, Spain (Online).\nInternational Com-",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": ""
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "mittee on Computational Linguistics.",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": ""
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "Rada Mihalcea\nand\nCarlo\nStrapparava.\n2012."
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "Lyrics, music, and emotions.\nIn Proceedings of"
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "Navonil Majumder, Soujanya Poria, Devamanyu",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": ""
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "the 2012 Joint Conference on Empirical Meth-"
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "Hazarika, Rada Mihalcea, Alexander Gelbukh,",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": ""
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "ods in Natural Language Processing and Com-"
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "and Erik Cambria. 2019.\nDialoguernn:\nAn",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": ""
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "putational Natural Language Learning, pages"
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "attentive rnn for emotion detection in conver-",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": ""
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "590–599."
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "of\nthe AAAI Con-\nsations.\nIn Proceedings",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": ""
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "ference on Artiﬁcial\nIntelligence,\nvolume 33,",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "Saif Mohammad. 2018. Word affect\nintensities."
        },
        {
          "John D. Lafferty, Andrew McCallum,\nand Fer-": "pages 6818–6825.",
          "Ricardo Malheiro, Renato Panda, Paulo Gomes,": "the Eleventh International\nIn Proceedings of"
        }
      ],
      "page": 14
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Conference on Language Resources and Evalu-": "ation (LREC 2018), Miyazaki, Japan. European",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "Messina. 2017.\nA multi-view sentiment cor-"
        },
        {
          "Conference on Language Resources and Evalu-": "Language Resources Association (ELRA).",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "the 15th Conference\npus.\nIn Proceedings of"
        },
        {
          "Conference on Language Resources and Evalu-": "",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "of\nthe European Chapter of\nthe Association for"
        },
        {
          "Conference on Language Resources and Evalu-": "Saif Mohammad, Felipe Bravo-Marquez, Moham-",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": ""
        },
        {
          "Conference on Language Resources and Evalu-": "",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "Computational Linguistics: Volume 1, Long Pa-"
        },
        {
          "Conference on Language Resources and Evalu-": "mad Salameh, and Svetlana Kiritchenko. 2018a.",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": ""
        },
        {
          "Conference on Language Resources and Evalu-": "",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "pers, pages 273–280, Valencia, Spain. Associa-"
        },
        {
          "Conference on Language Resources and Evalu-": "SemEval-2018 task 1:\nAffect\nin tweets.\nIn",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": ""
        },
        {
          "Conference on Language Resources and Evalu-": "",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "tion for Computational Linguistics."
        },
        {
          "Conference on Language Resources and Evalu-": "Proceedings of The 12th International Work-",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": ""
        },
        {
          "Conference on Language Resources and Evalu-": "shop on Semantic Evaluation, pages 1–17, New",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "Robert Plutchik. 1980.\nA general psychoevolu-"
        },
        {
          "Conference on Language Resources and Evalu-": "Orleans, Louisiana. Association for Computa-",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "tionary theory of emotion.\nIn Theories of emo-"
        },
        {
          "Conference on Language Resources and Evalu-": "tional Linguistics.",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "tion, pages 3–33. Elsevier."
        },
        {
          "Conference on Language Resources and Evalu-": "Saif Mohammad,\nFelipe Bravo-Marquez, Mo-",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": ""
        },
        {
          "Conference on Language Resources and Evalu-": "",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "Soujanya Poria, Erik Cambria, Devamanyu Haz-"
        },
        {
          "Conference on Language Resources and Evalu-": "hammad Salameh,\nand Svetlana Kiritchenko.",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": ""
        },
        {
          "Conference on Language Resources and Evalu-": "",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "arika, Navonil Majumder, Amir Zadeh,\nand"
        },
        {
          "Conference on Language Resources and Evalu-": "2018b. SemEval-2018 task 1: Affect in tweets.",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": ""
        },
        {
          "Conference on Language Resources and Evalu-": "",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "Louis-Philippe Morency.\n2017.\nContext-"
        },
        {
          "Conference on Language Resources and Evalu-": "In Proceedings of The 12th International Work-",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": ""
        },
        {
          "Conference on Language Resources and Evalu-": "",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "dependent sentiment analysis in user-generated"
        },
        {
          "Conference on Language Resources and Evalu-": "shop on Semantic Evaluation, pages 1–17, New",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": ""
        },
        {
          "Conference on Language Resources and Evalu-": "",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "of\nthe\n55th Annual\nvideos.\nIn Proceedings"
        },
        {
          "Conference on Language Resources and Evalu-": "Orleans, Louisiana. Association for Computa-",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": ""
        },
        {
          "Conference on Language Resources and Evalu-": "",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "Meeting of\nthe Association for Computational"
        },
        {
          "Conference on Language Resources and Evalu-": "tional Linguistics.",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": ""
        },
        {
          "Conference on Language Resources and Evalu-": "",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "Linguistics\n(Volume 1:\nLong Papers),\npages"
        },
        {
          "Conference on Language Resources and Evalu-": "",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "873–883, Vancouver, Canada. Association for"
        },
        {
          "Conference on Language Resources and Evalu-": "Saif Mohammad, Svetlana Kiritchenko, and Xiao-",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": ""
        },
        {
          "Conference on Language Resources and Evalu-": "",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "Computational Linguistics."
        },
        {
          "Conference on Language Resources and Evalu-": "dan Zhu. 2013. Nrc-canada: Building the state-",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": ""
        },
        {
          "Conference on Language Resources and Evalu-": "of-the-art\nin sentiment analysis of\ntweets.\nIn",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": ""
        },
        {
          "Conference on Language Resources and Evalu-": "",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "Soujanya Poria, Devamanyu Hazarika, Navonil"
        },
        {
          "Conference on Language Resources and Evalu-": "Second Joint Conference on Lexical and Com-",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": ""
        },
        {
          "Conference on Language Resources and Evalu-": "",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "Majumder, Gautam Naik, Erik Cambria,\nand"
        },
        {
          "Conference on Language Resources and Evalu-": "putational Semantics (* SEM), Volume 2: Pro-",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": ""
        },
        {
          "Conference on Language Resources and Evalu-": "",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "Rada Mihalcea. 2019a. MELD: A multimodal"
        },
        {
          "Conference on Language Resources and Evalu-": "ceedings of the Seventh International Workshop",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": ""
        },
        {
          "Conference on Language Resources and Evalu-": "",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "multi-party dataset\nfor emotion recognition in"
        },
        {
          "Conference on Language Resources and Evalu-": "on Semantic Evaluation (SemEval 2013), pages",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": ""
        },
        {
          "Conference on Language Resources and Evalu-": "",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "the 57th An-\nconversations.\nIn Proceedings of"
        },
        {
          "Conference on Language Resources and Evalu-": "321–327.",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": ""
        },
        {
          "Conference on Language Resources and Evalu-": "",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "nual Meeting of\nthe Association for Compu-"
        },
        {
          "Conference on Language Resources and Evalu-": "",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "tational Linguistics, pages 527–536, Florence,"
        },
        {
          "Conference on Language Resources and Evalu-": "Saif M Mohammad and Felipe Bravo-Márquez.",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": ""
        },
        {
          "Conference on Language Resources and Evalu-": "",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "Italy. Association for Computational Linguis-"
        },
        {
          "Conference on Language Resources and Evalu-": "2017. Wassa-2017 shared task on emotion in-",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": ""
        },
        {
          "Conference on Language Resources and Evalu-": "",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "tics."
        },
        {
          "Conference on Language Resources and Evalu-": "tensity.\nIn 8th Workshop on Computational Ap-",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": ""
        },
        {
          "Conference on Language Resources and Evalu-": "proaches to Subjectivity, Sentiment and Social",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": ""
        },
        {
          "Conference on Language Resources and Evalu-": "",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "Soujanya Poria, Navonil Majumder, Rada Mihal-"
        },
        {
          "Conference on Language Resources and Evalu-": "Media Analysis WASSA 2017: Proceedings of",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": ""
        },
        {
          "Conference on Language Resources and Evalu-": "",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "cea, and Eduard Hovy. 2019b. Emotion recog-"
        },
        {
          "Conference on Language Resources and Evalu-": "the Workshop, pages 34–49. The Association",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": ""
        },
        {
          "Conference on Language Resources and Evalu-": "",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "nition\nin\nconversation:\nResearch\nchallenges,"
        },
        {
          "Conference on Language Resources and Evalu-": "for Computational Linguistics.",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": ""
        },
        {
          "Conference on Language Resources and Evalu-": "",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "datasets,\nand recent advances.\nIEEE Access,"
        },
        {
          "Conference on Language Resources and Evalu-": "",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "7:100943–100953."
        },
        {
          "Conference on Language Resources and Evalu-": "Saif M Mohammad\nand\nSvetlana Kiritchenko.",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": ""
        },
        {
          "Conference on Language Resources and Evalu-": "2015. Using hashtags to capture ﬁne emotion",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": ""
        },
        {
          "Conference on Language Resources and Evalu-": "",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "Lawrence Rabiner and Biinghwang Juang. 1986."
        },
        {
          "Conference on Language Resources and Evalu-": "categories from tweets. Computational Intelli-",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": ""
        },
        {
          "Conference on Language Resources and Evalu-": "",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "An\nintroduction\nto\nhidden markov models."
        },
        {
          "Conference on Language Resources and Evalu-": "gence, 31(2):301–326.",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": ""
        },
        {
          "Conference on Language Resources and Evalu-": "",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "IEEE ASSP Magazine, 3(1):4–16."
        },
        {
          "Conference on Language Resources and Evalu-": "Saif M Mohammad and Peter D Turney. 2013.",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": ""
        },
        {
          "Conference on Language Resources and Evalu-": "",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "Arun Ramachandran and Gerard de Melo. 2020."
        },
        {
          "Conference on Language Resources and Evalu-": "Crowdsourcing\na\nword–emotion\nassocia-",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": ""
        },
        {
          "Conference on Language Resources and Evalu-": "",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "Cross-lingual emotion lexicon induction using"
        },
        {
          "Conference on Language Resources and Evalu-": "Computational\ntion\nlexicon.\nIntelligence,",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": ""
        },
        {
          "Conference on Language Resources and Evalu-": "",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "representation alignment\nin low-resource\nset-"
        },
        {
          "Conference on Language Resources and Evalu-": "29(3):436–465.",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": ""
        },
        {
          "Conference on Language Resources and Evalu-": "",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "of\nthe\n28th\nInterna-\ntings.\nIn Proceedings"
        },
        {
          "Conference on Language Resources and Evalu-": "Machine\nlearning:\na\nKevin P. Murphy. 2012.",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "tional Conference on Computational Linguis-"
        },
        {
          "Conference on Language Resources and Evalu-": "probabilistic perspective. MIT press.",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "tics, pages 5879–5890, Barcelona, Spain (On-"
        },
        {
          "Conference on Language Resources and Evalu-": "",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "line).\nInternational Committee\non Computa-"
        },
        {
          "Conference on Language Resources and Evalu-": "Vinod Nair and Geoffrey E Hinton. 2010.\nRec-",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": ""
        },
        {
          "Conference on Language Resources and Evalu-": "",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "tional Linguistics."
        },
        {
          "Conference on Language Resources and Evalu-": "tiﬁed linear units improve restricted boltzmann",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": ""
        },
        {
          "Conference on Language Resources and Evalu-": "the 27th Interna-\nmachines.\nIn Proceedings of",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "Alan Ramponi and Barbara Plank. 2020.\nNeu-"
        },
        {
          "Conference on Language Resources and Evalu-": "tional Conference on International Conference",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "ral unsupervised domain adaptation in NLP—"
        },
        {
          "Conference on Language Resources and Evalu-": "on Machine Learning, pages 807–814.",
          "Debora\nNozza,\nElisabetta\nFersini,\nand\nEnza": "of\nthe\n28th\nIn-\nA survey.\nIn Proceedings"
        }
      ],
      "page": 15
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "ternational Conference on Computational Lin-": "guistics,\npages 6838–6855, Barcelona, Spain",
          "The\nJournal\nof Machine Learning Research,": "15(1):1929–1958."
        },
        {
          "ternational Conference on Computational Lin-": "(Online).\nInternational Committee on Compu-",
          "The\nJournal\nof Machine Learning Research,": ""
        },
        {
          "ternational Conference on Computational Lin-": "",
          "The\nJournal\nof Machine Learning Research,": "Jacopo Staiano and Marco Guerini. 2014.\nDe-"
        },
        {
          "ternational Conference on Computational Lin-": "tational Linguistics.",
          "The\nJournal\nof Machine Learning Research,": ""
        },
        {
          "ternational Conference on Computational Lin-": "",
          "The\nJournal\nof Machine Learning Research,": "peche mood:\na\nlexicon for\nemotion analysis"
        },
        {
          "ternational Conference on Computational Lin-": "Herbert\nE\nRauch,\nF\nTung,\nand\nCharlotte\nT",
          "The\nJournal\nof Machine Learning Research,": "from crowd annotated news.\nIn Proceedings"
        },
        {
          "ternational Conference on Computational Lin-": "Striebel. 1965. Maximum likelihood estimates",
          "The\nJournal\nof Machine Learning Research,": "of\nthe 52nd Annual Meeting of\nthe Association"
        },
        {
          "ternational Conference on Computational Lin-": "of\nlinear\ndynamic\nsystems.\nAIAA journal,",
          "The\nJournal\nof Machine Learning Research,": "for Computational Linguistics (Volume 2: Short"
        },
        {
          "ternational Conference on Computational Lin-": "3(8):1445–1450.",
          "The\nJournal\nof Machine Learning Research,": "Papers), pages 427–433, Baltimore, Maryland."
        },
        {
          "ternational Conference on Computational Lin-": "",
          "The\nJournal\nof Machine Learning Research,": "Association for Computational Linguistics."
        },
        {
          "ternational Conference on Computational Lin-": "Anna\nRogers,\nOlga\nKovaleva,\nand\nAnna",
          "The\nJournal\nof Machine Learning Research,": ""
        },
        {
          "ternational Conference on Computational Lin-": "Rumshisky.\n2021.\nA Primer\nin BERTol-",
          "The\nJournal\nof Machine Learning Research,": "Carlo\nStrapparava\nand\nRada Mihalcea.\n2007."
        },
        {
          "ternational Conference on Computational Lin-": "ogy:\nWhat We Know About How BERT",
          "The\nJournal\nof Machine Learning Research,": "SemEval-2007\ntask\n14:\nAffective\ntext.\nIn"
        },
        {
          "ternational Conference on Computational Lin-": "Transactions\nof\nthe Association\nfor\nWorks.",
          "The\nJournal\nof Machine Learning Research,": "Proceedings of\nthe Fourth International Work-"
        },
        {
          "ternational Conference on Computational Lin-": "Computational Linguistics, 8:842–866.",
          "The\nJournal\nof Machine Learning Research,": "shop on Semantic Evaluations (SemEval-2007),"
        },
        {
          "ternational Conference on Computational Lin-": "",
          "The\nJournal\nof Machine Learning Research,": "pages 70–74, Prague, Czech Republic. Associ-"
        },
        {
          "ternational Conference on Computational Lin-": "James A Russell. 1980. A circumplex model of",
          "The\nJournal\nof Machine Learning Research,": ""
        },
        {
          "ternational Conference on Computational Lin-": "",
          "The\nJournal\nof Machine Learning Research,": "ation for Computational Linguistics."
        },
        {
          "ternational Conference on Computational Lin-": "Journal of personality and social psy-\naffect.",
          "The\nJournal\nof Machine Learning Research,": ""
        },
        {
          "ternational Conference on Computational Lin-": "chology, 39(6):1161–1178.",
          "The\nJournal\nof Machine Learning Research,": "Oscar Täckström and Ryan McDonald.\n2011a."
        },
        {
          "ternational Conference on Computational Lin-": "",
          "The\nJournal\nof Machine Learning Research,": "Discovering ﬁne-grained sentiment with latent"
        },
        {
          "ternational Conference on Computational Lin-": "Erik M Schmidt\nand Youngmoo E Kim. 2010.",
          "The\nJournal\nof Machine Learning Research,": ""
        },
        {
          "ternational Conference on Computational Lin-": "",
          "The\nJournal\nof Machine Learning Research,": "variable structured prediction models.\nIn Eu-"
        },
        {
          "ternational Conference on Computational Lin-": "Prediction of time-varying musical mood distri-",
          "The\nJournal\nof Machine Learning Research,": ""
        },
        {
          "ternational Conference on Computational Lin-": "",
          "The\nJournal\nof Machine Learning Research,": "ropean Conference on Information Retrieval,"
        },
        {
          "ternational Conference on Computational Lin-": "butions using kalman ﬁltering.\nIn 2010 Ninth",
          "The\nJournal\nof Machine Learning Research,": ""
        },
        {
          "ternational Conference on Computational Lin-": "",
          "The\nJournal\nof Machine Learning Research,": "pages 368–374. Springer."
        },
        {
          "ternational Conference on Computational Lin-": "International Conference on Machine Learning",
          "The\nJournal\nof Machine Learning Research,": ""
        },
        {
          "ternational Conference on Computational Lin-": "",
          "The\nJournal\nof Machine Learning Research,": "Oscar Täckström and Ryan McDonald.\n2011b."
        },
        {
          "ternational Conference on Computational Lin-": "and Applications, pages 655–660. IEEE.",
          "The\nJournal\nof Machine Learning Research,": ""
        },
        {
          "ternational Conference on Computational Lin-": "",
          "The\nJournal\nof Machine Learning Research,": "Semi-supervised\nlatent\nvariable models\nfor"
        },
        {
          "ternational Conference on Computational Lin-": "Erik M Schmidt\nand Youngmoo E Kim. 2011.",
          "The\nJournal\nof Machine Learning Research,": "sentence-level sentiment analysis.\nIn Proceed-"
        },
        {
          "ternational Conference on Computational Lin-": "Modeling musical emotion dynamics with con-",
          "The\nJournal\nof Machine Learning Research,": "ings of\nthe 49th Annual Meeting of\nthe Asso-"
        },
        {
          "ternational Conference on Computational Lin-": "the\nditional\nrandom ﬁelds.\nIn Proceedings of",
          "The\nJournal\nof Machine Learning Research,": "ciation for Computational Linguistics: Human"
        },
        {
          "ternational Conference on Computational Lin-": "12th International Society for Music Informa-",
          "The\nJournal\nof Machine Learning Research,": "Language Technologies, pages 569–574, Port-"
        },
        {
          "ternational Conference on Computational Lin-": "tion Retrieval Conference,\nISMIR, pages 777–",
          "The\nJournal\nof Machine Learning Research,": "land, Oregon, USA. Association for Computa-"
        },
        {
          "ternational Conference on Computational Lin-": "782. Miami (Florida), USA.",
          "The\nJournal\nof Machine Learning Research,": "tional Linguistics."
        },
        {
          "ternational Conference on Computational Lin-": "Erik M Schmidt, Douglas Turnbull, and Young-",
          "The\nJournal\nof Machine Learning Research,": "Evan J Williams. 1959. The comparison of regres-"
        },
        {
          "ternational Conference on Computational Lin-": "moo\nE Kim.\n2010.\nFeature\nselection\nfor",
          "The\nJournal\nof Machine Learning Research,": "Journal of\nthe Royal Statistical\nsion variables."
        },
        {
          "ternational Conference on Computational Lin-": "content-based,\ntime-varying musical\nemotion",
          "The\nJournal\nof Machine Learning Research,": "Society: Series B (Methodological), 21(2):396–"
        },
        {
          "ternational Conference on Computational Lin-": "the 11th ACM\nregression.\nIn Proceedings of",
          "The\nJournal\nof Machine Learning Research,": "399."
        },
        {
          "ternational Conference on Computational Lin-": "SIGMM International Conference on Multime-",
          "The\nJournal\nof Machine Learning Research,": ""
        },
        {
          "ternational Conference on Computational Lin-": "",
          "The\nJournal\nof Machine Learning Research,": "Bin Wu,\nErheng Zhong, Andrew Horner,\nand"
        },
        {
          "ternational Conference on Computational Lin-": "dia Information Retrieval, pages 267–274.",
          "The\nJournal\nof Machine Learning Research,": ""
        },
        {
          "ternational Conference on Computational Lin-": "",
          "The\nJournal\nof Machine Learning Research,": "Qiang Yang. 2014. Music emotion recognition"
        },
        {
          "ternational Conference on Computational Lin-": "Weizhou Shen, Siyue Wu, Yunyi Yang, and Xi-",
          "The\nJournal\nof Machine Learning Research,": "by multi-label multi-layer multi-instance multi-"
        },
        {
          "ternational Conference on Computational Lin-": "aojun Quan. 2021. Directed acyclic graph net-",
          "The\nJournal\nof Machine Learning Research,": "view learning.\nIn Proceedings of the 22nd ACM"
        },
        {
          "ternational Conference on Computational Lin-": "work for\nconversational\nemotion recognition.",
          "The\nJournal\nof Machine Learning Research,": "International Conference on Multimedia, pages"
        },
        {
          "ternational Conference on Computational Lin-": "the 59th Annual Meeting of\nIn Proceedings of",
          "The\nJournal\nof Machine Learning Research,": "117–126."
        },
        {
          "ternational Conference on Computational Lin-": "the Association for Computational Linguistics",
          "The\nJournal\nof Machine Learning Research,": ""
        },
        {
          "ternational Conference on Computational Lin-": "",
          "The\nJournal\nof Machine Learning Research,": "Yonghui Wu, Mike\nSchuster,\nZhifeng\nChen,"
        },
        {
          "ternational Conference on Computational Lin-": "and the 11th International Joint Conference on",
          "The\nJournal\nof Machine Learning Research,": ""
        },
        {
          "ternational Conference on Computational Lin-": "",
          "The\nJournal\nof Machine Learning Research,": "Quoc V. Le, Mohammad Norouzi, Wolfgang"
        },
        {
          "ternational Conference on Computational Lin-": "Natural Language Processing (Volume 1: Long",
          "The\nJournal\nof Machine Learning Research,": ""
        },
        {
          "ternational Conference on Computational Lin-": "",
          "The\nJournal\nof Machine Learning Research,": "Macherey, Maxim Krikun, Yuan Cao, Qin Gao,"
        },
        {
          "ternational Conference on Computational Lin-": "Papers), pages 1551–1560, Online. Association",
          "The\nJournal\nof Machine Learning Research,": ""
        },
        {
          "ternational Conference on Computational Lin-": "",
          "The\nJournal\nof Machine Learning Research,": "Klaus Macherey,\nJeff Klingner, Apurva Shah,"
        },
        {
          "ternational Conference on Computational Lin-": "for Computational Linguistics.",
          "The\nJournal\nof Machine Learning Research,": ""
        },
        {
          "ternational Conference on Computational Lin-": "",
          "The\nJournal\nof Machine Learning Research,": "Melvin Johnson, Xiaobing Liu, Lukasz Kaiser,"
        },
        {
          "ternational Conference on Computational Lin-": "Nitish\nSrivastava,\nGeoffrey\nE.\nHinton,\nAlex",
          "The\nJournal\nof Machine Learning Research,": "Stephan Gouws, Yoshikiyo Kato, Taku Kudo,"
        },
        {
          "ternational Conference on Computational Lin-": "Krizhevsky,\nIlya\nSutskever,\nand\nRuslan",
          "The\nJournal\nof Machine Learning Research,": "Hideto Kazawa, Keith Stevens, George Kurian,"
        },
        {
          "ternational Conference on Computational Lin-": "Salakhutdinov. 2014.\nDropout:\na simple way",
          "The\nJournal\nof Machine Learning Research,": "Nishant\nPatil, Wei Wang,\nCliff Young,\nJa-"
        },
        {
          "ternational Conference on Computational Lin-": "to\nprevent\nneural\nnetworks\nfrom overﬁtting.",
          "The\nJournal\nof Machine Learning Research,": "son Smith,\nJason Riesa, Alex Rudnick, Oriol"
        }
      ],
      "page": 16
    },
    {
      "caption": "Table: No caption found",
      "data": [
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "Jeffrey Dean.\n2016.\nGoogle’s\nneural ma-",
          "IJCNLP), pages 165–176, Hong Kong, China.": "Association for Computational Linguistics."
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "chine translation system: Bridging the gap be-",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "",
          "IJCNLP), pages 165–176, Hong Kong, China.": "Deyu Zhou, Shuangzhi Wu, Qing Wang, Jun Xie,"
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "tween human and machine translation. CoRR,",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "",
          "IJCNLP), pages 165–176, Hong Kong, China.": "Zhaopeng Tu, and Mu Li. 2020. Emotion clas-"
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "abs/1609.08144.",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "",
          "IJCNLP), pages 165–176, Hong Kong, China.": "siﬁcation by jointly learning to lexiconize and"
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "",
          "IJCNLP), pages 165–176, Hong Kong, China.": "the 28th Interna-\nclassify.\nIn Proceedings of"
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "Zhilin Yang, Zihang Dai, Yiming Yang,\nJaime",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "",
          "IJCNLP), pages 165–176, Hong Kong, China.": "tional Conference on Computational Linguis-"
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "Carbonell, Russ R Salakhutdinov, and Quoc V",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "",
          "IJCNLP), pages 165–176, Hong Kong, China.": "tics, COLING 2020, Barcelona, Spain (Online),"
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "Le. 2019.\nXlnet: Generalized autoregressive",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "",
          "IJCNLP), pages 165–176, Hong Kong, China.": "December 8-13, 2020, pages 3235–3245. Inter-"
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "pretraining for language understanding.\nIn Ad-",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "vances in Neural\nInformation Processing Sys-",
          "IJCNLP), pages 165–176, Hong Kong, China.": "national Committee on Computational Linguis-"
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "",
          "IJCNLP), pages 165–176, Hong Kong, China.": "tics."
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "tems, volume 32. Curran Associates, Inc.",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "",
          "IJCNLP), pages 165–176, Hong Kong, China.": "Xiaodan\nZhu,\nSvetlana Kiritchenko,\nand\nSaif"
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "Wenhao Ying, Rong Xiang,\nand Qin Lu. 2019.",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "",
          "IJCNLP), pages 165–176, Hong Kong, China.": "Mohammad. 2014.\nNRC-Canada-2014:\nRe-"
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "Improving multi-label emotion classiﬁcation by",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "",
          "IJCNLP), pages 165–176, Hong Kong, China.": "cent\nimprovements\nin\nthe\nsentiment\nanalysis"
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "integrating\nboth\ngeneral\nand\ndomain-speciﬁc",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "",
          "IJCNLP), pages 165–176, Hong Kong, China.": "the 8th Interna-\nof\ntweets.\nIn Proceedings of"
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "knowledge.\nIn Proceedings of the 5th Workshop",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "",
          "IJCNLP), pages 165–176, Hong Kong, China.": "tional Workshop on Semantic Evaluation (Se-"
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "on Noisy User-generated Text\n(W-NUT 2019),",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "",
          "IJCNLP), pages 165–176, Hong Kong, China.": "mEval 2014), pages 443–447, Dublin,\nIreland."
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "pages 316–321, Hong Kong, China. Associa-",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "",
          "IJCNLP), pages 165–176, Hong Kong, China.": "Association for Computational Linguistics."
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "tion for Computational Linguistics.",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "Dong Zhang,\nLiangqing Wu, Changlong\nSun,",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "Shoushan Li, Qiaoming Zhu,\nand Guodong",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "Zhou.\n2019.\nModeling\nboth\ncontext-\nand",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "speaker-sensitive dependence for emotion de-",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "tection in multi-speaker conversations.\nIn Pro-",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "ceedings\nof\nthe\nTwenty-Eighth\nInternational",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "Joint Conference on Artiﬁcial\nIntelligence,\nIJ-",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "CAI 2019, Macao, China, August 10-16, 2019,",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "pages 5415–5421. ijcai.org.",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "Zhuosheng Zhang, Yuwei Wu, Hai Zhao, Zuchao",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "Li,\nShuailiang Zhang, Xi Zhou,\nand Xiang",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "Zhou.\n2020.\nSemantics-aware\nbert\nfor\nlan-",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "the\nguage understanding.\nIn Proceedings of",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "AAAI Conference on Artiﬁcial Intelligence, vol-",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "ume 34, pages 9628–9635.",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "Weixiang Zhao, Yanyan Zhao, and Xin Lu. 2022.",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "Cauain: Causal aware interaction network for",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "emotion recognition in conversations.\nIn Pro-",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "ceedings of\nthe Thirty-First International Joint",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "Conference\non\nArtiﬁcial\nIntelligence,\nIJCAI",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "2022, Vienna, Austria, 23-29 July 2022, pages",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "4524–4530. ijcai.org.",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "Peixiang Zhong, Di Wang,\nand Chunyan Miao.",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "2019.\nKnowledge-enriched\ntransformer\nfor",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "emotion detection in textual conversations.\nIn",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "Proceedings of\nthe 2019 Conference on Em-",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "pirical Methods in Natural Language Process-",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "ing and the 9th International Joint Conference",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        },
        {
          "Vinyals, Greg Corrado, Macduff Hughes, and": "on Natural\nLanguage\nProcessing\n(EMNLP-",
          "IJCNLP), pages 165–176, Hong Kong, China.": ""
        }
      ],
      "page": 17
    }
  ],
  "citations": [
    {
      "citation_id": "1",
      "title": "Transformer-based approach towards music emotion recognition from lyrics",
      "authors": [
        "Yudhik Agrawal",
        "Ramaguru Guru",
        "Ravi Shanker",
        "Vinoo Alluri"
      ],
      "year": "2021",
      "venue": "Advances in Information Retrieval, 43rd European Conference on IR Research (ECIR 2021)",
      "doi": "10.1007/978-3-030-72240-1_12"
    },
    {
      "citation_id": "2",
      "title": "Combining BERT with static word embeddings for categorizing social media",
      "authors": [
        "Israa Alghanmi",
        "Luis Espinosa Anke",
        "Steven Schockaert"
      ],
      "year": "2020",
      "venue": "Proceedings of the Sixth Workshop on Noisy User-generated Text (W-NUT 2020)",
      "doi": "10.18653/v1/2020.wnut-1.5"
    },
    {
      "citation_id": "3",
      "title": "Singing in the brain: Independence of lyrics and tunes",
      "authors": [
        "Mireille Besson",
        "Frederique Faita",
        "Isabelle Peretz",
        "A-M Bonnel",
        "Jean Requin"
      ],
      "year": "1998",
      "venue": "Psychological Science",
      "doi": "10.1111/1467-9280.00091"
    },
    {
      "citation_id": "4",
      "title": "Language models are few-shot learners",
      "authors": [
        "Tom Brown",
        "Benjamin Mann",
        "Nick Ryder",
        "Melanie Subbiah",
        "Jared Kaplan",
        "Prafulla Dhariwal",
        "Arvind Neelakantan",
        "Pranav Shyam",
        "Girish Sastry",
        "Amanda Askell",
        "Sandhini Agarwal",
        "Ariel Herbert-Voss",
        "Gretchen Krueger",
        "Tom Henighan",
        "Rewon Child",
        "Aditya Ramesh",
        "Daniel Ziegler",
        "Jeffrey Wu",
        "Clemens Winter",
        "Chris Hesse",
        "Mark Chen",
        "Eric Sigler",
        "Mateusz Litwin",
        "Scott Gray",
        "Benjamin Chess",
        "Jack Clark",
        "Christopher Berner",
        "Sam Mccandlish",
        "Alec Radford",
        "Ilya Sutskever",
        "Dario Amodei"
      ],
      "year": "2020",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "5",
      "title": "The role of time in music emotion recognition: Modeling musical emotions from time-varying music features",
      "authors": [
        "Marcelo Caetano",
        "Athanasios Mouchtaris",
        "Frans Wiering"
      ],
      "year": "2012",
      "venue": "International Symposium on Computer Music Modeling and Retrieval",
      "doi": "10.1007/978-3-642-41248-6_10"
    },
    {
      "citation_id": "6",
      "title": "Emotional RobBERT and insensitive BERTje: Combining transformers and affect lexica for Dutch emotion detection",
      "authors": [
        "Luna De Bruyne",
        "Orphee De Clercq",
        "Veronique Hoste"
      ],
      "year": "2021",
      "venue": "Proceedings of the Eleventh Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis"
    },
    {
      "citation_id": "7",
      "title": "Maximum likelihood from incomplete data via the em algorithm",
      "authors": [
        "Nan Arthur P Dempster",
        "Donald Laird",
        "Rubin"
      ],
      "year": "1977",
      "venue": "Journal of the Royal Statistical Society: Series B (Methodological)",
      "doi": "10.1111/j.2517-6161.1977.tb01600.x"
    },
    {
      "citation_id": "8",
      "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "authors": [
        "Jacob Devlin",
        "Ming-Wei Chang",
        "Kenton Lee",
        "Kristina Toutanova"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
      "doi": "10.18653/v1/N19-1423"
    },
    {
      "citation_id": "9",
      "title": "Facial expression and emotion",
      "authors": [
        "Paul Ekman"
      ],
      "year": "1993",
      "venue": "American psychologist",
      "doi": "10.1037/0003-066X.48.4.384"
    },
    {
      "citation_id": "10",
      "title": "Sentiwordnet: a high-coverage lexical resource for opinion mining",
      "authors": [
        "Andrea Esuli",
        "Fabrizio Sebastiani"
      ],
      "year": "2007",
      "venue": "Evaluation"
    },
    {
      "citation_id": "11",
      "title": "MEISD: A multimodal multi-label emotion, intensity and sentiment dialogue dataset for emotion recognition and sentiment analysis in conversations",
      "authors": [
        "Mauajama Firdaus",
        "Hardik Chauhan",
        "Asif Ekbal",
        "Pushpak Bhattacharyya"
      ],
      "year": "2020",
      "venue": "Proceedings of the 28th International Conference on Computational Linguistics",
      "doi": "10.18653/v1/2020.coling-main.393"
    },
    {
      "citation_id": "12",
      "title": "Exploring the role of context in utterance-level emotion, act and intent classification in conversations: An empirical study",
      "authors": [
        "Deepanway Ghosal",
        "Navonil Majumder",
        "Rada Mihalcea",
        "Soujanya Poria"
      ],
      "year": "2021",
      "venue": "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
      "doi": "10.18653/v1/2021.findings-acl.124"
    },
    {
      "citation_id": "13",
      "title": "DialogueGCN: A graph convolutional neural network for emotion recognition in conversation",
      "authors": [
        "Deepanway Ghosal",
        "Navonil Majumder",
        "Soujanya Poria",
        "Niyati Chhaya",
        "Alexander Gelbukh"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
      "doi": "10.18653/v1/D19-1015"
    },
    {
      "citation_id": "14",
      "title": "Prayas at EmoInt 2017: An ensemble of deep neural architectures for emotion intensity prediction in tweets",
      "authors": [
        "Pranav Goel",
        "Devang Kulshreshtha",
        "Prayas Jain",
        "Kaushal Kumar"
      ],
      "year": "2017",
      "venue": "Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
      "doi": "10.18653/v1/W17-5207"
    },
    {
      "citation_id": "15",
      "title": "2018a. ICON: Interactive conversational memory network for multimodal emotion detection",
      "authors": [
        "Devamanyu Hazarika",
        "Soujanya Poria",
        "Rada Mihalcea",
        "Erik Cambria",
        "Roger Zimmermann"
      ],
      "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
      "doi": "10.18653/v1/D18-1280"
    },
    {
      "citation_id": "16",
      "title": "2018b. Conversational memory network for emotion recognition in dyadic dialogue videos",
      "authors": [
        "Devamanyu Hazarika",
        "Soujanya Poria",
        "Amir Zadeh",
        "Erik Cambria",
        "Louis-Philippe Morency",
        "Roger Zimmermann"
      ],
      "venue": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
      "doi": "10.18653/v1/N18-1193"
    },
    {
      "citation_id": "17",
      "title": "EmotionLines: An emotion corpus of multi-party conversations",
      "authors": [
        "Chao-Chun",
        "Sheng-Yeh Hsu",
        "Chuan-Chun Chen",
        "Ting-Hao Kuo",
        "Lun-Wei Huang",
        "Ku"
      ],
      "year": "2018",
      "venue": "Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)"
    },
    {
      "citation_id": "18",
      "title": "DialogueCRN: Contextual reasoning networks for emotion recognition in conversations",
      "authors": [
        "Dou Hu",
        "Lingwei Wei",
        "Xiaoyong Huai"
      ],
      "year": "2021",
      "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
      "doi": "10.18653/v1/2021.acl-long.547"
    },
    {
      "citation_id": "19",
      "title": "Relation-aware graph attention networks with relational position encodings for emotion recognition in conversations",
      "authors": [
        "Taichi Ishiwatari",
        "Yuki Yasuda",
        "Taro Miyazaki",
        "Jun Goto"
      ],
      "year": "2020",
      "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
      "doi": "10.18653/v1/2020.emnlp-main.597"
    },
    {
      "citation_id": "20",
      "title": "Gaussian filters for nonlinear filtering problems",
      "authors": [
        "Kazufumi Ito",
        "Kaiqi Xiong"
      ],
      "year": "2000",
      "venue": "IEEE transactions on automatic control",
      "doi": "10.1109/9.855552"
    },
    {
      "citation_id": "21",
      "title": "Real-time emotion recognition via attention gated hierarchical memory network",
      "authors": [
        "Wenxiang Jiao",
        "Michael Lyu",
        "Irwin King"
      ],
      "year": "2020",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, 05",
      "doi": "10.1609/aaai.v34i05.6309"
    },
    {
      "citation_id": "22",
      "title": "New extension of the kalman filter to nonlinear systems",
      "authors": [
        "J Simon",
        "Jeffrey Julier",
        "Uhlmann"
      ],
      "year": "1997",
      "venue": "Signal processing, sensor fusion, and target recognition VI",
      "doi": "10.1117/12.280797"
    },
    {
      "citation_id": "23",
      "title": "Unscented filtering and nonlinear estimation. Proceedings of the IEEE",
      "authors": [
        "J Simon",
        "Jeffrey Julier",
        "Uhlmann"
      ],
      "year": "2004",
      "venue": "Unscented filtering and nonlinear estimation. Proceedings of the IEEE",
      "doi": "10.1109/JPROC.2003.823141"
    },
    {
      "citation_id": "24",
      "title": "Expression, perception, and induction of musical emotions: A review and a questionnaire study of everyday listening",
      "authors": [
        "N Patrik",
        "Petri Juslin",
        "Laukka"
      ],
      "year": "2004",
      "venue": "Journal of new music research",
      "doi": "10.1080/0929821042000317813"
    },
    {
      "citation_id": "25",
      "title": "A new approach to linear filtering and prediction problems",
      "authors": [
        "Rudolph Emil"
      ],
      "year": "1960",
      "venue": "Journal of Basic Engineering",
      "doi": "10.1115/1.3662552"
    },
    {
      "citation_id": "26",
      "title": "Estimating temporal dynamics of human emotions",
      "authors": [
        "Seungyeon Kim",
        "Joonseok Lee",
        "Guy Lebanon",
        "Haesun Park"
      ],
      "year": "2015",
      "venue": "Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence",
      "doi": "10.1609/aaai.v29i1.9190"
    },
    {
      "citation_id": "27",
      "title": "Convolutional neural networks for sentence classification",
      "authors": [
        "Yoon Kim"
      ],
      "year": "2014",
      "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
      "doi": "10.3115/v1/D14-1181"
    },
    {
      "citation_id": "28",
      "title": "Music emotion recognition: A state of the art review",
      "authors": [
        "Erik Youngmoo E Kim",
        "Raymond Schmidt",
        "Migneco",
        "Patrick Brandon G Morton",
        "Jeffrey Richardson",
        "Jacquelin Scott",
        "Douglas Speck",
        "Turnbull"
      ],
      "year": "2010",
      "venue": "11th International Society for Music Information Retrieval Conference (ISMIR 2010)"
    },
    {
      "citation_id": "29",
      "title": "Semisupervised classification with graph convolutional networks",
      "authors": [
        "Thomas Kipf",
        "Max Welling"
      ],
      "year": "2017",
      "venue": "5th International Conference on Learning Representations"
    },
    {
      "citation_id": "30",
      "title": "Sentiment analysis of short informal texts",
      "authors": [
        "Svetlana Kiritchenko",
        "Xiaodan Zhu",
        "Saif M Mohammad"
      ],
      "year": "2014",
      "venue": "Journal of Artificial Intelligence Research",
      "doi": "10.1613/jair.4272"
    },
    {
      "citation_id": "31",
      "title": "Hurt-BERT: Incorporating lexical features with BERT for the detection of abusive language",
      "authors": [
        "Anna Koufakou",
        "Endang Pamungkas",
        "Valerio Basile",
        "Viviana Patti"
      ],
      "year": "2020",
      "venue": "Proceedings of the Fourth Workshop on Online Abuse and Harms",
      "doi": "10.18653/v1/2020.alw-1.5"
    },
    {
      "citation_id": "32",
      "title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data",
      "authors": [
        "John Lafferty",
        "Andrew Mccallum",
        "Fernando Pereira"
      ],
      "year": "2001",
      "venue": "Proceedings of the Eighteenth International Conference on Machine Learning",
      "doi": "10.5555/645530.655813"
    },
    {
      "citation_id": "33",
      "title": "HiTrans: A transformerbased context-and speaker-sensitive model for emotion detection in conversations",
      "authors": [
        "Jingye Li",
        "Donghong Ji",
        "Fei Li",
        "Meishan Zhang",
        "Yijiang Liu"
      ],
      "year": "2020",
      "venue": "Proceedings of the 28th International Conference on Computational Linguistics",
      "doi": "10.18653/v1/2020.coling-main.370"
    },
    {
      "citation_id": "34",
      "title": "DailyDialog: A manually labelled multi-turn dialogue dataset",
      "authors": [
        "Yanran Li",
        "Hui Su",
        "Xiaoyu Shen",
        "Wenjie Li",
        "Ziqiang Cao",
        "Shuzi Niu"
      ],
      "year": "2017",
      "venue": "Proceedings of the Eighth International Joint Conference on Natural Language Processing"
    },
    {
      "citation_id": "35",
      "title": "Conversational emotion recognition using selfattention mechanisms and graph neural networks",
      "authors": [
        "Zheng Lian",
        "Jianhua Tao",
        "Bin Liu",
        "Jian Huang",
        "Zhanlei Yang",
        "Rongjun Li"
      ],
      "year": "2020",
      "venue": "Interspeech 2020, 21st Annual Conference of the International Speech Communication Association, Virtual Event",
      "doi": "10.21437/Interspeech.2020-1703"
    },
    {
      "citation_id": "36",
      "title": "An iterative emotion interaction network for emotion recognition in conversations",
      "authors": [
        "Xin Lu",
        "Yanyan Zhao",
        "Yang Wu",
        "Yijian Tian",
        "Huipeng Chen",
        "Bing Qin"
      ],
      "year": "2020",
      "venue": "Proceedings of the 28th International Conference on Computational Linguistics",
      "doi": "10.18653/v1/2020.coling-main.360"
    },
    {
      "citation_id": "37",
      "title": "Dialoguernn: An attentive rnn for emotion detection in conversations",
      "authors": [
        "Navonil Majumder",
        "Soujanya Poria",
        "Devamanyu Hazarika",
        "Rada Mihalcea",
        "Alexander Gelbukh",
        "Erik Cambria"
      ],
      "year": "2019",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence",
      "doi": "10.1609/aaai.v33i01.33016818"
    },
    {
      "citation_id": "38",
      "title": "Emotionallyrelevant features for classification and regression of music lyrics",
      "authors": [
        "Ricardo Malheiro",
        "Renato Panda",
        "Paulo Gomes",
        "Rui Pedro"
      ],
      "year": "2016",
      "venue": "IEEE Transactions on Affective Computing",
      "doi": "10.1109/TAFFC.2016.2598569"
    },
    {
      "citation_id": "39",
      "title": "Maximum entropy markov models for information extraction and segmentation",
      "authors": [
        "Andrew Mccallum",
        "Dayne Freitag",
        "Fernando Pereira"
      ],
      "year": "2000",
      "venue": "Proceedings of the Seventeenth International Conference on Machine Learning (ICML 2000"
    },
    {
      "citation_id": "40",
      "title": "Structured models for fine-to-coarse sentiment analysis",
      "authors": [
        "Ryan Mcdonald",
        "Kerry Hannan",
        "Tyler Neylon",
        "Mike Wells",
        "Jeff Reynar"
      ],
      "year": "2007",
      "venue": "Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics"
    },
    {
      "citation_id": "41",
      "title": "The semaine database: Annotated multimodal records of emotionally colored conversations between a person and a limited agent",
      "authors": [
        "Gary Mckeown",
        "Michel Valstar",
        "Roddy Cowie",
        "Maja Pantic",
        "Marc Schroder"
      ],
      "year": "2011",
      "venue": "IEEE transactions on affective computing",
      "doi": "10.1109/T-AFFC.2011.20"
    },
    {
      "citation_id": "42",
      "title": "Bottom-up and topdown: Predicting personality with psycholinguistic and language model features",
      "authors": [
        "Yash Mehta",
        "Samin Fatehi",
        "Amirmohammad Kazameini",
        "Clemens Stachl"
      ],
      "year": "2020",
      "venue": "2020 IEEE International Conference on Data Mining (ICDM)",
      "doi": "10.1109/ICDM50108.2020.00146"
    },
    {
      "citation_id": "43",
      "title": "TCS research at SemEval-2018 task 1: Learning robust representations using multi-attention architecture",
      "authors": [
        "Hardik Meisheri",
        "Lipika Dey"
      ],
      "year": "2018",
      "venue": "Proceedings of The 12th International Workshop on Semantic Evaluation",
      "doi": "10.18653/v1/S18-1043"
    },
    {
      "citation_id": "44",
      "title": "Lyrics, music, and emotions",
      "authors": [
        "Rada Mihalcea",
        "Carlo Strapparava"
      ],
      "year": "2012",
      "venue": "Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning"
    },
    {
      "citation_id": "45",
      "title": "Word affect intensities",
      "authors": [
        "Saif Mohammad"
      ],
      "year": "2018",
      "venue": "Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)"
    },
    {
      "citation_id": "46",
      "title": "Mohammad Salameh, and Svetlana Kiritchenko. 2018a. SemEval-2018 task 1: Affect in tweets",
      "authors": [
        "Saif Mohammad",
        "Felipe Bravo-Marquez"
      ],
      "venue": "Proceedings of The 12th International Workshop on Semantic Evaluation",
      "doi": "10.18653/v1/S18-1001"
    },
    {
      "citation_id": "47",
      "title": "SemEval-2018 task 1: Affect in tweets",
      "authors": [
        "Saif Mohammad",
        "Felipe Bravo-Marquez",
        "Mohammad Salameh",
        "Svetlana Kiritchenko"
      ],
      "year": "2018",
      "venue": "Proceedings of The 12th International Workshop on Semantic Evaluation",
      "doi": "10.18653/v1/S18-1001"
    },
    {
      "citation_id": "48",
      "title": "Nrc-canada: Building the stateof-the-art in sentiment analysis of tweets",
      "authors": [
        "Saif Mohammad",
        "Svetlana Kiritchenko",
        "Xiaodan Zhu"
      ],
      "year": "2013",
      "venue": "Second Joint Conference on Lexical and Computational Semantics (* SEM)"
    },
    {
      "citation_id": "49",
      "title": "Wassa-2017 shared task on emotion intensity",
      "authors": [
        "M Saif",
        "Felipe Mohammad",
        "Bravo-Márquez"
      ],
      "year": "2017",
      "venue": "8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis WASSA 2017: Proceedings of the Workshop"
    },
    {
      "citation_id": "50",
      "title": "Using hashtags to capture fine emotion categories from tweets",
      "authors": [
        "M Saif",
        "Svetlana Mohammad",
        "Kiritchenko"
      ],
      "year": "2015",
      "venue": "Computational Intelligence",
      "doi": "10.1111/coin.12024"
    },
    {
      "citation_id": "51",
      "title": "Crowdsourcing a word-emotion association lexicon",
      "authors": [
        "M Saif",
        "Peter Mohammad",
        "Turney"
      ],
      "year": "2013",
      "venue": "Computational Intelligence",
      "doi": "10.1111/j.1467-8640.2012.00460.x"
    },
    {
      "citation_id": "52",
      "title": "Machine learning: a probabilistic perspective",
      "authors": [
        "Kevin Murphy"
      ],
      "year": "2012",
      "venue": "Machine learning: a probabilistic perspective",
      "doi": "10.5555/2380985"
    },
    {
      "citation_id": "53",
      "title": "Rectified linear units improve restricted boltzmann machines",
      "authors": [
        "Vinod Nair",
        "Geoffrey Hinton"
      ],
      "year": "2010",
      "venue": "Proceedings of the 27th International Conference on International Conference on Machine Learning",
      "doi": "10.5555/3104322.3104425"
    },
    {
      "citation_id": "54",
      "title": "A multi-view sentiment corpus",
      "authors": [
        "Debora Nozza",
        "Elisabetta Fersini",
        "Enza Messina"
      ],
      "year": "2017",
      "venue": "Proceedings of the 15th Conference of the European Chapter"
    },
    {
      "citation_id": "55",
      "title": "A general psychoevolutionary theory of emotion",
      "authors": [
        "Robert Plutchik"
      ],
      "year": "1980",
      "venue": "Theories of emotion"
    },
    {
      "citation_id": "56",
      "title": "Contextdependent sentiment analysis in user-generated videos",
      "authors": [
        "Soujanya Poria",
        "Erik Cambria",
        "Devamanyu Hazarika",
        "Navonil Majumder",
        "Amir Zadeh",
        "Louis-Philippe Morency"
      ],
      "year": "2017",
      "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/P17-1081"
    },
    {
      "citation_id": "57",
      "title": "MELD: A multimodal multi-party dataset for emotion recognition in conversations",
      "authors": [
        "Soujanya Poria",
        "Devamanyu Hazarika",
        "Navonil Majumder"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/P19-1050"
    },
    {
      "citation_id": "58",
      "title": "Emotion recognition in conversation: Research challenges, datasets, and recent advances",
      "authors": [
        "Soujanya Poria",
        "Navonil Majumder",
        "Rada Mihalcea",
        "Eduard Hovy"
      ],
      "year": "2019",
      "venue": "IEEE Access",
      "doi": "10.1109/ACCESS.2019.2929050"
    },
    {
      "citation_id": "59",
      "title": "An introduction to hidden markov models",
      "authors": [
        "Lawrence Rabiner",
        "Biinghwang Juang"
      ],
      "year": "1986",
      "venue": "IEEE ASSP Magazine",
      "doi": "10.1109/MASSP.1986.1165342"
    },
    {
      "citation_id": "60",
      "title": "Cross-lingual emotion lexicon induction using representation alignment in low-resource settings",
      "authors": [
        "Arun Ramachandran",
        "Gerard De"
      ],
      "year": "2020",
      "venue": "Proceedings of the 28th International Conference on Computational Linguistics",
      "doi": "10.18653/v1/2020.coling-main.517"
    },
    {
      "citation_id": "61",
      "title": "Neural unsupervised domain adaptation in NLP-A survey",
      "authors": [
        "Alan Ramponi",
        "Barbara Plank"
      ],
      "year": "2020",
      "venue": "Proceedings of the 28th In-ternational Conference on Computational Linguistics",
      "doi": "10.18653/v1/2020.coling-main.603"
    },
    {
      "citation_id": "62",
      "title": "Maximum likelihood estimates of linear dynamic systems",
      "authors": [
        "F Herbert E Rauch",
        "Charlotte Tung",
        "Striebel"
      ],
      "year": "1965",
      "venue": "AIAA journal",
      "doi": "10.2514/3.3166"
    },
    {
      "citation_id": "63",
      "title": "A Primer in BERTology: What We Know About How BERT Works",
      "authors": [
        "Anna Rogers",
        "Olga Kovaleva",
        "Anna Rumshisky"
      ],
      "year": "2021",
      "venue": "Transactions of the Association for Computational Linguistics",
      "doi": "10.1162/tacl_a_00349"
    },
    {
      "citation_id": "64",
      "title": "A circumplex model of affect",
      "authors": [
        "Russell James"
      ],
      "year": "1980",
      "venue": "Journal of personality and social psychology",
      "doi": "10.1037/h0077714"
    },
    {
      "citation_id": "65",
      "title": "Prediction of time-varying musical mood distributions using kalman filtering",
      "authors": [
        "M Erik",
        "Youngmoo Schmidt",
        "Kim"
      ],
      "year": "2010",
      "venue": "2010 Ninth International Conference on Machine Learning and Applications",
      "doi": "10.1109/ICMLA.2010.101"
    },
    {
      "citation_id": "66",
      "title": "Modeling musical emotion dynamics with conditional random fields",
      "authors": [
        "M Erik",
        "Youngmoo Schmidt",
        "Kim"
      ],
      "year": "2011",
      "venue": "Proceedings of the 12th International Society for Music Information Retrieval Conference, ISMIR",
      "doi": "10.5072/zenodo.242740"
    },
    {
      "citation_id": "67",
      "title": "Feature selection for content-based, time-varying musical emotion regression",
      "authors": [
        "Erik Schmidt",
        "Douglas Turnbull",
        "Youngmoo Kim"
      ],
      "year": "2010",
      "venue": "Proceedings of the 11th ACM SIGMM International Conference on Multimedia Information Retrieval",
      "doi": "10.1145/1743384.1743431"
    },
    {
      "citation_id": "68",
      "title": "Directed acyclic graph network for conversational emotion recognition",
      "authors": [
        "Weizhou Shen",
        "Siyue Wu",
        "Yunyi Yang",
        "Xiaojun Quan"
      ],
      "year": "2021",
      "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
      "doi": "10.18653/v1/2021.acl-long.123"
    },
    {
      "citation_id": "69",
      "title": "Dropout: a simple way to prevent neural networks from overfitting",
      "authors": [
        "Nitish Srivastava",
        "Geoffrey Hinton",
        "Alex Krizhevsky",
        "Ilya Sutskever",
        "Ruslan Salakhutdinov"
      ],
      "year": "2014",
      "venue": "The Journal of Machine Learning Research",
      "doi": "10.5555/2627435.2670313"
    },
    {
      "citation_id": "70",
      "title": "Depeche mood: a lexicon for emotion analysis from crowd annotated news",
      "authors": [
        "Jacopo Staiano",
        "Marco Guerini"
      ],
      "year": "2014",
      "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.3115/v1/P14-2070"
    },
    {
      "citation_id": "71",
      "title": "SemEval-2007 task 14: Affective text",
      "authors": [
        "Carlo Strapparava",
        "Rada Mihalcea"
      ],
      "year": "2007",
      "venue": "Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007)"
    },
    {
      "citation_id": "72",
      "title": "Discovering fine-grained sentiment with latent variable structured prediction models",
      "authors": [
        "Oscar Täckström",
        "Ryan Mcdonald"
      ],
      "year": "2011",
      "venue": "European Conference on Information Retrieval",
      "doi": "10.1007/978-3-642-20161-5_37"
    },
    {
      "citation_id": "73",
      "title": "Semi-supervised latent variable models for sentence-level sentiment analysis",
      "authors": [
        "Oscar Täckström",
        "Ryan Mcdonald"
      ],
      "year": "2011",
      "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies"
    },
    {
      "citation_id": "74",
      "title": "The comparison of regression variables",
      "authors": [
        "Evan J Williams"
      ],
      "year": "1959",
      "venue": "Journal of the Royal Statistical Society: Series B (Methodological)",
      "doi": "10.1111/j.2517-6161.1959.tb00346.x"
    },
    {
      "citation_id": "75",
      "title": "Music emotion recognition by multi-label multi-layer multi-instance multiview learning",
      "authors": [
        "Bin Wu",
        "Erheng Zhong",
        "Andrew Horner",
        "Qiang Yang"
      ],
      "year": "2014",
      "venue": "Proceedings of the 22nd ACM International Conference on Multimedia",
      "doi": "10.1145/2647868.2654904"
    },
    {
      "citation_id": "76",
      "title": "Google's neural machine translation system: Bridging the gap between human and machine translation",
      "authors": [
        "Yonghui Wu",
        "Mike Schuster",
        "Zhifeng Chen",
        "Quoc Le",
        "Mohammad Norouzi",
        "Wolfgang Macherey",
        "Maxim Krikun",
        "Yuan Cao",
        "Qin Gao",
        "Klaus Macherey",
        "Jeff Klingner",
        "Apurva Shah",
        "Melvin Johnson",
        "Xiaobing Liu",
        "Lukasz Kaiser",
        "Stephan Gouws",
        "Yoshikiyo Kato",
        "Taku Kudo",
        "Hideto Kazawa",
        "Keith Stevens",
        "George Kurian",
        "Nishant Patil",
        "Wei Wang",
        "Cliff Young",
        "Jason Smith",
        "Jason Riesa",
        "Alex Rudnick",
        "Oriol Vinyals",
        "Greg Corrado",
        "Macduff Hughes",
        "Jeffrey Dean"
      ],
      "year": "2016",
      "venue": "Google's neural machine translation system: Bridging the gap between human and machine translation"
    },
    {
      "citation_id": "77",
      "title": "Xlnet: Generalized autoregressive pretraining for language understanding",
      "authors": [
        "Zhilin Yang",
        "Zihang Dai",
        "Yiming Yang",
        "Jaime Carbonell",
        "Russ Salakhutdinov",
        "Quoc V Le"
      ],
      "year": "2019",
      "venue": "Advances in Neural Information Processing Systems"
    },
    {
      "citation_id": "78",
      "title": "Improving multi-label emotion classification by integrating both general and domain-specific knowledge",
      "authors": [
        "Wenhao Ying",
        "Rong Xiang",
        "Qin Lu"
      ],
      "year": "2019",
      "venue": "Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019)",
      "doi": "10.18653/v1/D19-5541"
    },
    {
      "citation_id": "79",
      "title": "Modeling both context-and speaker-sensitive dependence for emotion detection in multi-speaker conversations",
      "authors": [
        "Dong Zhang",
        "Liangqing Wu",
        "Changlong Sun",
        "Shoushan Li",
        "Qiaoming Zhu",
        "Guodong Zhou"
      ],
      "year": "2019",
      "venue": "Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJ-CAI 2019",
      "doi": "10.24963/ijcai.2019/752"
    },
    {
      "citation_id": "80",
      "title": "Semantics-aware bert for language understanding",
      "authors": [
        "Zhuosheng Zhang",
        "Yuwei Wu",
        "Hai Zhao",
        "Zuchao Li",
        "Shuailiang Zhang",
        "Xi Zhou",
        "Xiang Zhou"
      ],
      "year": "2020",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence",
      "doi": "10.1609/aaai.v34i05.6510"
    },
    {
      "citation_id": "81",
      "title": "Cauain: Causal aware interaction network for emotion recognition in conversations",
      "authors": [
        "Weixiang Zhao",
        "Yanyan Zhao",
        "Xin Lu"
      ],
      "year": "2022",
      "venue": "Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence",
      "doi": "10.24963/ijcai.2022/628"
    },
    {
      "citation_id": "82",
      "title": "Knowledge-enriched transformer for emotion detection in textual conversations",
      "authors": [
        "Peixiang Zhong",
        "Di Wang",
        "Chunyan Miao"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
      "doi": "10.18653/v1/D19-1016"
    },
    {
      "citation_id": "83",
      "title": "Emotion classification by jointly learning to lexiconize and classify",
      "authors": [
        "Deyu Zhou",
        "Shuangzhi Wu",
        "Qing Wang",
        "Jun Xie",
        "Zhaopeng Tu",
        "Mu Li"
      ],
      "year": "2020",
      "venue": "Proceedings of the 28th International Conference on Computational Linguistics, COLING 2020",
      "doi": "10.18653/v1/2020.coling-main.288"
    },
    {
      "citation_id": "84",
      "title": "NRC-Canada-2014: Recent improvements in the sentiment analysis of tweets",
      "authors": [
        "Xiaodan Zhu",
        "Svetlana Kiritchenko",
        "Saif Mohammad"
      ],
      "year": "2014",
      "venue": "Proceedings of the 8th International Workshop on Semantic Evaluation (Se-mEval 2014)",
      "doi": "10.3115/v1/S14-2077"
    }
  ]
}